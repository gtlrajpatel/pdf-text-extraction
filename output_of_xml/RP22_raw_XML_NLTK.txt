				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

Big Data Analytics: A Literature Review  

------------------- Sentence 1 -------------------

Big Data Analytics: A Literature Review

>> Tokens are: 
 ['Big', 'Data', 'Analytics', ':', 'A', 'Literature', 'Review']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'A'), ('A', 'Literature'), ('Literature', 'Review')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'A'), (':', 'A', 'Literature'), ('A', 'Literature', 'Review')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('A', 'DT'), ('Literature', 'NNP'), ('Review', 'NNP')]

>> Noun Phrases are: 
 ['Big Data Analytics', 'A Literature Review']

>> Named Entities are: 
 [('ORGANIZATION', 'Literature Review')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Literature', 'literatur'), ('Review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Literature', 'literatur'), ('Review', 'review')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('A', 'A'), ('Literature', 'Literature'), ('Review', 'Review')]



========================================== PARAGRAPH 2 ===========================================

Perspective 

------------------- Sentence 1 -------------------

Perspective

>> Tokens are: 
 ['Perspective']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Perspective', 'NN')]

>> Noun Phrases are: 
 ['Perspective']

>> Named Entities are: 
 [('GPE', 'Perspective')] 

>> Stemming using Porter Stemmer: 
 [('Perspective', 'perspect')]

>> Stemming using Snowball Stemmer: 
 [('Perspective', 'perspect')]

>> Lemmatization: 
 [('Perspective', 'Perspective')]



========================================== PARAGRAPH 3 ===========================================

Sarah Al-Shiakhli 

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 4 ===========================================

Information Security, master's level (120 credits)  

------------------- Sentence 1 -------------------

Information Security, master's level (120 credits)

>> Tokens are: 
 ['Information', 'Security', ',', 'master', "'s", 'level', '(', '120', 'credits', ')']

>> Bigrams are: 
 [('Information', 'Security'), ('Security', ','), (',', 'master'), ('master', "'s"), ("'s", 'level'), ('level', '('), ('(', '120'), ('120', 'credits'), ('credits', ')')]

>> Trigrams are: 
 [('Information', 'Security', ','), ('Security', ',', 'master'), (',', 'master', "'s"), ('master', "'s", 'level'), ("'s", 'level', '('), ('level', '(', '120'), ('(', '120', 'credits'), ('120', 'credits', ')')]

>> POS Tags are: 
 [('Information', 'NNP'), ('Security', 'NNP'), (',', ','), ('master', 'NN'), ("'s", 'POS'), ('level', 'NN'), ('(', '('), ('120', 'CD'), ('credits', 'NNS'), (')', ')')]

>> Noun Phrases are: 
 ['Information Security', 'master', 'level', 'credits']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Security', 'secur'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Security', 'secur'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')')]

>> Lemmatization: 
 [('Information', 'Information'), ('Security', 'Security'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')')]



========================================== PARAGRAPH 5 ===========================================

2019 

------------------- Sentence 1 -------------------

2019

>> Tokens are: 
 ['2019']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2019', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019')]

>> Lemmatization: 
 [('2019', '2019')]



========================================== PARAGRAPH 6 ===========================================

Luleå University of Technology  

------------------- Sentence 1 -------------------

Luleå University of Technology

>> Tokens are: 
 ['Luleå', 'University', 'Technology']

>> Bigrams are: 
 [('Luleå', 'University'), ('University', 'Technology')]

>> Trigrams are: 
 [('Luleå', 'University', 'Technology')]

>> POS Tags are: 
 [('Luleå', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP')]

>> Noun Phrases are: 
 ['Luleå University Technology']

>> Named Entities are: 
 [('PERSON', 'Luleå'), ('ORGANIZATION', 'University Technology')] 

>> Stemming using Porter Stemmer: 
 [('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog')]

>> Stemming using Snowball Stemmer: 
 [('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog')]

>> Lemmatization: 
 [('Luleå', 'Luleå'), ('University', 'University'), ('Technology', 'Technology')]



========================================== PARAGRAPH 7 ===========================================

Department of Computer Science, Electrical and Space Engineering

------------------- Sentence 1 -------------------

Department of Computer Science, Electrical and Space Engineering

>> Tokens are: 
 ['Department', 'Computer', 'Science', ',', 'Electrical', 'Space', 'Engineering']

>> Bigrams are: 
 [('Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Electrical'), ('Electrical', 'Space'), ('Space', 'Engineering')]

>> Trigrams are: 
 [('Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Electrical'), (',', 'Electrical', 'Space'), ('Electrical', 'Space', 'Engineering')]

>> POS Tags are: 
 [('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Electrical', 'JJ'), ('Space', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['Department Computer Science', 'Electrical Space Engineering']

>> Named Entities are: 
 [('ORGANIZATION', 'Electrical Space')] 

>> Stemming using Porter Stemmer: 
 [('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Electrical', 'Electrical'), ('Space', 'Space'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 8 ===========================================

Abstract  

------------------- Sentence 1 -------------------

Abstract

>> Tokens are: 
 ['Abstract']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Abstract', 'NN')]

>> Noun Phrases are: 
 ['Abstract']

>> Named Entities are: 
 [('GPE', 'Abstract')] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract')]

>> Lemmatization: 
 [('Abstract', 'Abstract')]



========================================== PARAGRAPH 9 ===========================================

Big data is currently a buzzword in both academia and industry, with the term being used to  

------------------- Sentence 1 -------------------

Big data is currently a buzzword in both academia and industry, with the term being used to

>> Tokens are: 
 ['Big', 'data', 'currently', 'buzzword', 'academia', 'industry', ',', 'term', 'used']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'currently'), ('currently', 'buzzword'), ('buzzword', 'academia'), ('academia', 'industry'), ('industry', ','), (',', 'term'), ('term', 'used')]

>> Trigrams are: 
 [('Big', 'data', 'currently'), ('data', 'currently', 'buzzword'), ('currently', 'buzzword', 'academia'), ('buzzword', 'academia', 'industry'), ('academia', 'industry', ','), ('industry', ',', 'term'), (',', 'term', 'used')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('currently', 'RB'), ('buzzword', 'VBP'), ('academia', 'NN'), ('industry', 'NN'), (',', ','), ('term', 'NN'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Big data', 'academia industry', 'term']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('currently', 'current'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industri'), (',', ','), ('term', 'term'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('currently', 'current'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industri'), (',', ','), ('term', 'term'), ('used', 'use')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('currently', 'currently'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industry'), (',', ','), ('term', 'term'), ('used', 'used')]



========================================== PARAGRAPH 10 ===========================================

describe a broad domain of concepts, ranging from extracting data from outside sources, storing  

------------------- Sentence 1 -------------------

describe a broad domain of concepts, ranging from extracting data from outside sources, storing

>> Tokens are: 
 ['describe', 'broad', 'domain', 'concepts', ',', 'ranging', 'extracting', 'data', 'outside', 'sources', ',', 'storing']

>> Bigrams are: 
 [('describe', 'broad'), ('broad', 'domain'), ('domain', 'concepts'), ('concepts', ','), (',', 'ranging'), ('ranging', 'extracting'), ('extracting', 'data'), ('data', 'outside'), ('outside', 'sources'), ('sources', ','), (',', 'storing')]

>> Trigrams are: 
 [('describe', 'broad', 'domain'), ('broad', 'domain', 'concepts'), ('domain', 'concepts', ','), ('concepts', ',', 'ranging'), (',', 'ranging', 'extracting'), ('ranging', 'extracting', 'data'), ('extracting', 'data', 'outside'), ('data', 'outside', 'sources'), ('outside', 'sources', ','), ('sources', ',', 'storing')]

>> POS Tags are: 
 [('describe', 'NN'), ('broad', 'JJ'), ('domain', 'NN'), ('concepts', 'NNS'), (',', ','), ('ranging', 'VBG'), ('extracting', 'VBG'), ('data', 'NNS'), ('outside', 'JJ'), ('sources', 'NNS'), (',', ','), ('storing', 'VBG')]

>> Noun Phrases are: 
 ['describe', 'broad domain concepts', 'data', 'outside sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('describe', 'describ'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'rang'), ('extracting', 'extract'), ('data', 'data'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('storing', 'store')]

>> Stemming using Snowball Stemmer: 
 [('describe', 'describ'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'rang'), ('extracting', 'extract'), ('data', 'data'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('storing', 'store')]

>> Lemmatization: 
 [('describe', 'describe'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'ranging'), ('extracting', 'extracting'), ('data', 'data'), ('outside', 'outside'), ('sources', 'source'), (',', ','), ('storing', 'storing')]



========================================== PARAGRAPH 11 ===========================================

and managing it, to processing such data with analytical techniques and tools.  

------------------- Sentence 1 -------------------

and managing it, to processing such data with analytical techniques and tools.

>> Tokens are: 
 ['managing', ',', 'processing', 'data', 'analytical', 'techniques', 'tools', '.']

>> Bigrams are: 
 [('managing', ','), (',', 'processing'), ('processing', 'data'), ('data', 'analytical'), ('analytical', 'techniques'), ('techniques', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('managing', ',', 'processing'), (',', 'processing', 'data'), ('processing', 'data', 'analytical'), ('data', 'analytical', 'techniques'), ('analytical', 'techniques', 'tools'), ('techniques', 'tools', '.')]

>> POS Tags are: 
 [('managing', 'NN'), (',', ','), ('processing', 'VBG'), ('data', 'NNS'), ('analytical', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['managing', 'data', 'analytical techniques tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('managing', 'manag'), (',', ','), ('processing', 'process'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('managing', 'manag'), (',', ','), ('processing', 'process'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('managing', 'managing'), (',', ','), ('processing', 'processing'), ('data', 'data'), ('analytical', 'analytical'), ('techniques', 'technique'), ('tools', 'tool'), ('.', '.')]



========================================== PARAGRAPH 12 ===========================================

This thesis work thus aims to provide a review of current big data analytics concepts in an attempt  

------------------- Sentence 1 -------------------

This thesis work thus aims to provide a review of current big data analytics concepts in an attempt

>> Tokens are: 
 ['This', 'thesis', 'work', 'thus', 'aims', 'provide', 'review', 'current', 'big', 'data', 'analytics', 'concepts', 'attempt']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'work'), ('work', 'thus'), ('thus', 'aims'), ('aims', 'provide'), ('provide', 'review'), ('review', 'current'), ('current', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'concepts'), ('concepts', 'attempt')]

>> Trigrams are: 
 [('This', 'thesis', 'work'), ('thesis', 'work', 'thus'), ('work', 'thus', 'aims'), ('thus', 'aims', 'provide'), ('aims', 'provide', 'review'), ('provide', 'review', 'current'), ('review', 'current', 'big'), ('current', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'concepts'), ('analytics', 'concepts', 'attempt')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('work', 'NN'), ('thus', 'RB'), ('aims', 'VBZ'), ('provide', 'VB'), ('review', 'NN'), ('current', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('concepts', 'NNS'), ('attempt', 'VBP')]

>> Noun Phrases are: 
 ['This thesis work', 'review', 'current big data analytics concepts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('work', 'work'), ('thus', 'thu'), ('aims', 'aim'), ('provide', 'provid'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('concepts', 'concept'), ('attempt', 'attempt')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('work', 'work'), ('thus', 'thus'), ('aims', 'aim'), ('provide', 'provid'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('concepts', 'concept'), ('attempt', 'attempt')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('work', 'work'), ('thus', 'thus'), ('aims', 'aim'), ('provide', 'provide'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('concepts', 'concept'), ('attempt', 'attempt')]



========================================== PARAGRAPH 13 ===========================================

to highlight big data analytics’ importance to decision making.   

------------------- Sentence 1 -------------------

to highlight big data analytics’ importance to decision making.

>> Tokens are: 
 ['highlight', 'big', 'data', 'analytics', '’', 'importance', 'decision', 'making', '.']

>> Bigrams are: 
 [('highlight', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '’'), ('’', 'importance'), ('importance', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('highlight', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '’'), ('analytics', '’', 'importance'), ('’', 'importance', 'decision'), ('importance', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('highlight', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('’', 'JJ'), ('importance', 'NN'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['highlight', 'big data analytics', '’ importance decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('importance', 'import'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('importance', 'import'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('’', '’'), ('importance', 'importance'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



========================================== PARAGRAPH 14 ===========================================

  


========================================== PARAGRAPH 15 ===========================================

Due to the rapid increase in interest in big data and its importance to academia, industry, and  

------------------- Sentence 1 -------------------

Due to the rapid increase in interest in big data and its importance to academia, industry, and

>> Tokens are: 
 ['Due', 'rapid', 'increase', 'interest', 'big', 'data', 'importance', 'academia', ',', 'industry', ',']

>> Bigrams are: 
 [('Due', 'rapid'), ('rapid', 'increase'), ('increase', 'interest'), ('interest', 'big'), ('big', 'data'), ('data', 'importance'), ('importance', 'academia'), ('academia', ','), (',', 'industry'), ('industry', ',')]

>> Trigrams are: 
 [('Due', 'rapid', 'increase'), ('rapid', 'increase', 'interest'), ('increase', 'interest', 'big'), ('interest', 'big', 'data'), ('big', 'data', 'importance'), ('data', 'importance', 'academia'), ('importance', 'academia', ','), ('academia', ',', 'industry'), (',', 'industry', ',')]

>> POS Tags are: 
 [('Due', 'JJ'), ('rapid', 'JJ'), ('increase', 'NN'), ('interest', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('importance', 'NN'), ('academia', 'NN'), (',', ','), ('industry', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Due rapid increase interest', 'big data importance academia', 'industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('rapid', 'rapid'), ('increase', 'increas'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'import'), ('academia', 'academia'), (',', ','), ('industry', 'industri'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('rapid', 'rapid'), ('increase', 'increas'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'import'), ('academia', 'academia'), (',', ','), ('industry', 'industri'), (',', ',')]

>> Lemmatization: 
 [('Due', 'Due'), ('rapid', 'rapid'), ('increase', 'increase'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'importance'), ('academia', 'academia'), (',', ','), ('industry', 'industry'), (',', ',')]



========================================== PARAGRAPH 16 ===========================================

society, solutions to handling data and extracting knowledge from datasets need to be developed  

------------------- Sentence 1 -------------------

society, solutions to handling data and extracting knowledge from datasets need to be developed

>> Tokens are: 
 ['society', ',', 'solutions', 'handling', 'data', 'extracting', 'knowledge', 'datasets', 'need', 'developed']

>> Bigrams are: 
 [('society', ','), (',', 'solutions'), ('solutions', 'handling'), ('handling', 'data'), ('data', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'datasets'), ('datasets', 'need'), ('need', 'developed')]

>> Trigrams are: 
 [('society', ',', 'solutions'), (',', 'solutions', 'handling'), ('solutions', 'handling', 'data'), ('handling', 'data', 'extracting'), ('data', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'datasets'), ('knowledge', 'datasets', 'need'), ('datasets', 'need', 'developed')]

>> POS Tags are: 
 [('society', 'NN'), (',', ','), ('solutions', 'NNS'), ('handling', 'VBG'), ('data', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('datasets', 'NNS'), ('need', 'VBP'), ('developed', 'VBN')]

>> Noun Phrases are: 
 ['society', 'solutions', 'data', 'knowledge datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('society', 'societi'), (',', ','), ('solutions', 'solut'), ('handling', 'handl'), ('data', 'data'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('need', 'need'), ('developed', 'develop')]

>> Stemming using Snowball Stemmer: 
 [('society', 'societi'), (',', ','), ('solutions', 'solut'), ('handling', 'handl'), ('data', 'data'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('need', 'need'), ('developed', 'develop')]

>> Lemmatization: 
 [('society', 'society'), (',', ','), ('solutions', 'solution'), ('handling', 'handling'), ('data', 'data'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('datasets', 'datasets'), ('need', 'need'), ('developed', 'developed')]



========================================== PARAGRAPH 17 ===========================================

and provided with some urgency to allow decision makers to gain valuable insights from the varied  

------------------- Sentence 1 -------------------

and provided with some urgency to allow decision makers to gain valuable insights from the varied

>> Tokens are: 
 ['provided', 'urgency', 'allow', 'decision', 'makers', 'gain', 'valuable', 'insights', 'varied']

>> Bigrams are: 
 [('provided', 'urgency'), ('urgency', 'allow'), ('allow', 'decision'), ('decision', 'makers'), ('makers', 'gain'), ('gain', 'valuable'), ('valuable', 'insights'), ('insights', 'varied')]

>> Trigrams are: 
 [('provided', 'urgency', 'allow'), ('urgency', 'allow', 'decision'), ('allow', 'decision', 'makers'), ('decision', 'makers', 'gain'), ('makers', 'gain', 'valuable'), ('gain', 'valuable', 'insights'), ('valuable', 'insights', 'varied')]

>> POS Tags are: 
 [('provided', 'VBN'), ('urgency', 'NN'), ('allow', 'JJ'), ('decision', 'NN'), ('makers', 'NNS'), ('gain', 'VBP'), ('valuable', 'JJ'), ('insights', 'NNS'), ('varied', 'VBD')]

>> Noun Phrases are: 
 ['urgency', 'allow decision makers', 'valuable insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provided', 'provid'), ('urgency', 'urgenc'), ('allow', 'allow'), ('decision', 'decis'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('varied', 'vari')]

>> Stemming using Snowball Stemmer: 
 [('provided', 'provid'), ('urgency', 'urgenc'), ('allow', 'allow'), ('decision', 'decis'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('varied', 'vari')]

>> Lemmatization: 
 [('provided', 'provided'), ('urgency', 'urgency'), ('allow', 'allow'), ('decision', 'decision'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuable'), ('insights', 'insight'), ('varied', 'varied')]



========================================== PARAGRAPH 18 ===========================================

and rapidly changing data they now have access to. Many companies are using big data analytics  

------------------- Sentence 1 -------------------

and rapidly changing data they now have access to.

>> Tokens are: 
 ['rapidly', 'changing', 'data', 'access', '.']

>> Bigrams are: 
 [('rapidly', 'changing'), ('changing', 'data'), ('data', 'access'), ('access', '.')]

>> Trigrams are: 
 [('rapidly', 'changing', 'data'), ('changing', 'data', 'access'), ('data', 'access', '.')]

>> POS Tags are: 
 [('rapidly', 'RB'), ('changing', 'VBG'), ('data', 'NNS'), ('access', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data access']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rapidly', 'rapidli'), ('changing', 'chang'), ('data', 'data'), ('access', 'access'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rapidly', 'rapid'), ('changing', 'chang'), ('data', 'data'), ('access', 'access'), ('.', '.')]

>> Lemmatization: 
 [('rapidly', 'rapidly'), ('changing', 'changing'), ('data', 'data'), ('access', 'access'), ('.', '.')]


------------------- Sentence 2 -------------------

Many companies are using big data analytics

>> Tokens are: 
 ['Many', 'companies', 'using', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('Many', 'companies'), ('companies', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Many', 'companies', 'using'), ('companies', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('Many', 'JJ'), ('companies', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Many companies', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('companies', 'compani'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('companies', 'compani'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Many', 'Many'), ('companies', 'company'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 19 ===========================================

to analyse the massive quantities of data they have, with the results influencing their decision  

------------------- Sentence 1 -------------------

to analyse the massive quantities of data they have, with the results influencing their decision

>> Tokens are: 
 ['analyse', 'massive', 'quantities', 'data', ',', 'results', 'influencing', 'decision']

>> Bigrams are: 
 [('analyse', 'massive'), ('massive', 'quantities'), ('quantities', 'data'), ('data', ','), (',', 'results'), ('results', 'influencing'), ('influencing', 'decision')]

>> Trigrams are: 
 [('analyse', 'massive', 'quantities'), ('massive', 'quantities', 'data'), ('quantities', 'data', ','), ('data', ',', 'results'), (',', 'results', 'influencing'), ('results', 'influencing', 'decision')]

>> POS Tags are: 
 [('analyse', 'RB'), ('massive', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), (',', ','), ('results', 'NNS'), ('influencing', 'VBG'), ('decision', 'NN')]

>> Noun Phrases are: 
 ['massive quantities data', 'results', 'decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyse', 'analys'), ('massive', 'massiv'), ('quantities', 'quantiti'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influenc'), ('decision', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('analyse', 'analys'), ('massive', 'massiv'), ('quantities', 'quantiti'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influenc'), ('decision', 'decis')]

>> Lemmatization: 
 [('analyse', 'analyse'), ('massive', 'massive'), ('quantities', 'quantity'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influencing'), ('decision', 'decision')]



========================================== PARAGRAPH 20 ===========================================

making. Many studies have shown the benefits of using big data in various sectors, and in this  

------------------- Sentence 1 -------------------

making.

>> Tokens are: 
 ['making', '.']

>> Bigrams are: 
 [('making', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('making', 'making'), ('.', '.')]


------------------- Sentence 2 -------------------

Many studies have shown the benefits of using big data in various sectors, and in this

>> Tokens are: 
 ['Many', 'studies', 'shown', 'benefits', 'using', 'big', 'data', 'various', 'sectors', ',']

>> Bigrams are: 
 [('Many', 'studies'), ('studies', 'shown'), ('shown', 'benefits'), ('benefits', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'various'), ('various', 'sectors'), ('sectors', ',')]

>> Trigrams are: 
 [('Many', 'studies', 'shown'), ('studies', 'shown', 'benefits'), ('shown', 'benefits', 'using'), ('benefits', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'various'), ('data', 'various', 'sectors'), ('various', 'sectors', ',')]

>> POS Tags are: 
 [('Many', 'JJ'), ('studies', 'NNS'), ('shown', 'VBN'), ('benefits', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('various', 'JJ'), ('sectors', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Many studies', 'benefits', 'big data', 'various sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('various', 'variou'), ('sectors', 'sector'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('various', 'various'), ('sectors', 'sector'), (',', ',')]

>> Lemmatization: 
 [('Many', 'Many'), ('studies', 'study'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('various', 'various'), ('sectors', 'sector'), (',', ',')]



========================================== PARAGRAPH 21 ===========================================

thesis work, various big data analytical techniques and tools are discussed to allow analysis of the  

------------------- Sentence 1 -------------------

thesis work, various big data analytical techniques and tools are discussed to allow analysis of the

>> Tokens are: 
 ['thesis', 'work', ',', 'various', 'big', 'data', 'analytical', 'techniques', 'tools', 'discussed', 'allow', 'analysis']

>> Bigrams are: 
 [('thesis', 'work'), ('work', ','), (',', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'analytical'), ('analytical', 'techniques'), ('techniques', 'tools'), ('tools', 'discussed'), ('discussed', 'allow'), ('allow', 'analysis')]

>> Trigrams are: 
 [('thesis', 'work', ','), ('work', ',', 'various'), (',', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'analytical'), ('data', 'analytical', 'techniques'), ('analytical', 'techniques', 'tools'), ('techniques', 'tools', 'discussed'), ('tools', 'discussed', 'allow'), ('discussed', 'allow', 'analysis')]

>> POS Tags are: 
 [('thesis', 'NN'), ('work', 'NN'), (',', ','), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytical', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS'), ('discussed', 'VBD'), ('allow', 'JJ'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['thesis work', 'various big data', 'analytical techniques tools', 'allow analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('thesis', 'thesi'), ('work', 'work'), (',', ','), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('discussed', 'discuss'), ('allow', 'allow'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('thesis', 'thesi'), ('work', 'work'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('discussed', 'discuss'), ('allow', 'allow'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('thesis', 'thesis'), ('work', 'work'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analytical', 'analytical'), ('techniques', 'technique'), ('tools', 'tool'), ('discussed', 'discussed'), ('allow', 'allow'), ('analysis', 'analysis')]



========================================== PARAGRAPH 22 ===========================================

application of big data analytics in several different domains.  

------------------- Sentence 1 -------------------

application of big data analytics in several different domains.

>> Tokens are: 
 ['application', 'big', 'data', 'analytics', 'several', 'different', 'domains', '.']

>> Bigrams are: 
 [('application', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'several'), ('several', 'different'), ('different', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('application', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'several'), ('analytics', 'several', 'different'), ('several', 'different', 'domains'), ('different', 'domains', '.')]

>> POS Tags are: 
 [('application', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('several', 'JJ'), ('different', 'JJ'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['application', 'big data analytics', 'several different domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('application', 'applic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('several', 'sever'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('application', 'applic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('several', 'sever'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('application', 'application'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('several', 'several'), ('different', 'different'), ('domains', 'domain'), ('.', '.')]



========================================== PARAGRAPH 23 ===========================================

   


========================================== PARAGRAPH 24 ===========================================

  


========================================== PARAGRAPH 25 ===========================================

Keywords: Literature review, big data, big data analytics and tools, decision making, big data  

------------------- Sentence 1 -------------------

Keywords: Literature review, big data, big data analytics and tools, decision making, big data

>> Tokens are: 
 ['Keywords', ':', 'Literature', 'review', ',', 'big', 'data', ',', 'big', 'data', 'analytics', 'tools', ',', 'decision', 'making', ',', 'big', 'data']

>> Bigrams are: 
 [('Keywords', ':'), (':', 'Literature'), ('Literature', 'review'), ('review', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', ','), (',', 'decision'), ('decision', 'making'), ('making', ','), (',', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Keywords', ':', 'Literature'), (':', 'Literature', 'review'), ('Literature', 'review', ','), ('review', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', ','), ('tools', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', ','), ('making', ',', 'big'), (',', 'big', 'data')]

>> POS Tags are: 
 [('Keywords', 'NNS'), (':', ':'), ('Literature', 'NNP'), ('review', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), (',', ','), ('decision', 'NN'), ('making', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Keywords', 'Literature review', 'big data', 'big data analytics tools', 'decision making', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('decision', 'decis'), ('making', 'make'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('decision', 'decis'), ('making', 'make'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Keywords', 'Keywords'), (':', ':'), ('Literature', 'Literature'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), (',', ','), ('decision', 'decision'), ('making', 'making'), (',', ','), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 26 ===========================================

applications.  

------------------- Sentence 1 -------------------

applications.

>> Tokens are: 
 ['applications', '.']

>> Bigrams are: 
 [('applications', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('.', '.')]



========================================== PARAGRAPH 27 ===========================================

  


========================================== PARAGRAPH 28 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 29 ===========================================

ii  

------------------- Sentence 1 -------------------

ii

>> Tokens are: 
 ['ii']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ii', 'NN')]

>> Noun Phrases are: 
 ['ii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ii', 'ii')]

>> Stemming using Snowball Stemmer: 
 [('ii', 'ii')]

>> Lemmatization: 
 [('ii', 'ii')]



========================================== PARAGRAPH 30 ===========================================

  


========================================== PARAGRAPH 31 ===========================================

Contents  

------------------- Sentence 1 -------------------

Contents

>> Tokens are: 
 ['Contents']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Contents', 'NNS')]

>> Noun Phrases are: 
 ['Contents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Contents', 'content')]

>> Stemming using Snowball Stemmer: 
 [('Contents', 'content')]

>> Lemmatization: 
 [('Contents', 'Contents')]



========================================== PARAGRAPH 32 ===========================================

Abstract ............................................................................................................................................ i  

------------------- Sentence 1 -------------------

Abstract ............................................................................................................................................ i

>> Tokens are: 
 ['Abstract', '............................................................................................................................................']

>> Bigrams are: 
 [('Abstract', '............................................................................................................................................')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Abstract', 'NNP'), ('............................................................................................................................................', 'NN')]

>> Noun Phrases are: 
 ['Abstract ............................................................................................................................................']

>> Named Entities are: 
 [('GPE', 'Abstract')] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract'), ('............................................................................................................................................', '............................................................................................................................................')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract'), ('............................................................................................................................................', '............................................................................................................................................')]

>> Lemmatization: 
 [('Abstract', 'Abstract'), ('............................................................................................................................................', '............................................................................................................................................')]



========================================== PARAGRAPH 33 ===========================================

Contents .......................................................................................................................................... ii  

------------------- Sentence 1 -------------------

Contents .......................................................................................................................................... ii

>> Tokens are: 
 ['Contents', '..........................................................................................................................................', 'ii']

>> Bigrams are: 
 [('Contents', '..........................................................................................................................................'), ('..........................................................................................................................................', 'ii')]

>> Trigrams are: 
 [('Contents', '..........................................................................................................................................', 'ii')]

>> POS Tags are: 
 [('Contents', 'NNS'), ('..........................................................................................................................................', 'VBP'), ('ii', 'NN')]

>> Noun Phrases are: 
 ['Contents', 'ii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Contents', 'content'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii')]

>> Stemming using Snowball Stemmer: 
 [('Contents', 'content'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii')]

>> Lemmatization: 
 [('Contents', 'Contents'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii')]



========================================== PARAGRAPH 34 ===========================================

1. Introduction ............................................................................................................................. 1  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Introduction ............................................................................................................................. 1

>> Tokens are: 
 ['Introduction', '.............................................................................................................................', '1']

>> Bigrams are: 
 [('Introduction', '.............................................................................................................................'), ('.............................................................................................................................', '1')]

>> Trigrams are: 
 [('Introduction', '.............................................................................................................................', '1')]

>> POS Tags are: 
 [('Introduction', 'NN'), ('.............................................................................................................................', 'VBZ'), ('1', 'CD')]

>> Noun Phrases are: 
 ['Introduction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1')]

>> Lemmatization: 
 [('Introduction', 'Introduction'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1')]



========================================== PARAGRAPH 35 ===========================================

2. Research Question ................................................................................................................... 2  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Research Question ................................................................................................................... 2

>> Tokens are: 
 ['Research', 'Question', '...................................................................................................................', '2']

>> Bigrams are: 
 [('Research', 'Question'), ('Question', '...................................................................................................................'), ('...................................................................................................................', '2')]

>> Trigrams are: 
 [('Research', 'Question', '...................................................................................................................'), ('Question', '...................................................................................................................', '2')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Question', 'NNP'), ('...................................................................................................................', 'VBD'), ('2', 'CD')]

>> Noun Phrases are: 
 ['Research Question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2')]

>> Lemmatization: 
 [('Research', 'Research'), ('Question', 'Question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2')]



========================================== PARAGRAPH 36 ===========================================

3. Research Method ..................................................................................................................... 3  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Research Method ..................................................................................................................... 3

>> Tokens are: 
 ['Research', 'Method', '.....................................................................................................................', '3']

>> Bigrams are: 
 [('Research', 'Method'), ('Method', '.....................................................................................................................'), ('.....................................................................................................................', '3')]

>> Trigrams are: 
 [('Research', 'Method', '.....................................................................................................................'), ('Method', '.....................................................................................................................', '3')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Method', 'NNP'), ('.....................................................................................................................', 'VBD'), ('3', 'CD')]

>> Noun Phrases are: 
 ['Research Method']

>> Named Entities are: 
 [('PERSON', 'Method')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3')]

>> Lemmatization: 
 [('Research', 'Research'), ('Method', 'Method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3')]



========================================== PARAGRAPH 37 ===========================================

4. Scope delimitation and risks .................................................................................................... 7  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Scope delimitation and risks .................................................................................................... 7

>> Tokens are: 
 ['Scope', 'delimitation', 'risks', '....................................................................................................', '7']

>> Bigrams are: 
 [('Scope', 'delimitation'), ('delimitation', 'risks'), ('risks', '....................................................................................................'), ('....................................................................................................', '7')]

>> Trigrams are: 
 [('Scope', 'delimitation', 'risks'), ('delimitation', 'risks', '....................................................................................................'), ('risks', '....................................................................................................', '7')]

>> POS Tags are: 
 [('Scope', 'NNP'), ('delimitation', 'NN'), ('risks', 'NNS'), ('....................................................................................................', 'VBP'), ('7', 'CD')]

>> Noun Phrases are: 
 ['Scope delimitation risks']

>> Named Entities are: 
 [('GPE', 'Scope')] 

>> Stemming using Porter Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7')]

>> Stemming using Snowball Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7')]

>> Lemmatization: 
 [('Scope', 'Scope'), ('delimitation', 'delimitation'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7')]



========================================== PARAGRAPH 38 ===========================================

5. What is “big data”? .................................................................................................................. 8  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

What is “big data”?

>> Tokens are: 
 ['What', '“', 'big', 'data', '”', '?']

>> Bigrams are: 
 [('What', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', '?')]

>> Trigrams are: 
 [('What', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('“', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('?', '.')]

>> Noun Phrases are: 
 ['big data ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]


------------------- Sentence 3 -------------------

.................................................................................................................. 8

>> Tokens are: 
 ['..................................................................................................................', '8']

>> Bigrams are: 
 [('..................................................................................................................', '8')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('..................................................................................................................', '$'), ('8', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8')]

>> Stemming using Snowball Stemmer: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8')]

>> Lemmatization: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8')]



========================================== PARAGRAPH 39 ===========================================

6. Big data characteristics .......................................................................................................... 15  

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data characteristics .......................................................................................................... 15

>> Tokens are: 
 ['Big', 'data', 'characteristics', '..........................................................................................................', '15']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'characteristics'), ('characteristics', '..........................................................................................................'), ('..........................................................................................................', '15')]

>> Trigrams are: 
 [('Big', 'data', 'characteristics'), ('data', 'characteristics', '..........................................................................................................'), ('characteristics', '..........................................................................................................', '15')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('characteristics', 'NNS'), ('..........................................................................................................', 'VBP'), ('15', 'CD')]

>> Noun Phrases are: 
 ['Big data characteristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('characteristics', 'characteristic'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15')]



========================================== PARAGRAPH 40 ===========================================

7. Big data analytics (BDA): tools and methods ....................................................................... 18  

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics (BDA): tools and methods ....................................................................... 18

>> Tokens are: 
 ['Big', 'data', 'analytics', '(', 'BDA', ')', ':', 'tools', 'methods', '.......................................................................', '18']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'BDA'), ('BDA', ')'), (')', ':'), (':', 'tools'), ('tools', 'methods'), ('methods', '.......................................................................'), ('.......................................................................', '18')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'BDA'), ('(', 'BDA', ')'), ('BDA', ')', ':'), (')', ':', 'tools'), (':', 'tools', 'methods'), ('tools', 'methods', '.......................................................................'), ('methods', '.......................................................................', '18')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('BDA', 'NNP'), (')', ')'), (':', ':'), ('tools', 'NNS'), ('methods', 'NNS'), ('.......................................................................', 'VBP'), ('18', 'CD')]

>> Noun Phrases are: 
 ['Big data analytics', 'BDA', 'tools methods']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('BDA', 'BDA'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18')]



========================================== PARAGRAPH 41 ===========================================

7.1. Big data storage and management .................................................................................. 18  

------------------- Sentence 1 -------------------

7.1.

>> Tokens are: 
 ['7.1', '.']

>> Bigrams are: 
 [('7.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1', '7.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1', '7.1'), ('.', '.')]

>> Lemmatization: 
 [('7.1', '7.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data storage and management .................................................................................. 18

>> Tokens are: 
 ['Big', 'data', 'storage', 'management', '..................................................................................', '18']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'storage'), ('storage', 'management'), ('management', '..................................................................................'), ('..................................................................................', '18')]

>> Trigrams are: 
 [('Big', 'data', 'storage'), ('data', 'storage', 'management'), ('storage', 'management', '..................................................................................'), ('management', '..................................................................................', '18')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN'), ('..................................................................................', 'VBD'), ('18', 'CD')]

>> Noun Phrases are: 
 ['Big data storage management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('..................................................................................', '..................................................................................'), ('18', '18')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('..................................................................................', '..................................................................................'), ('18', '18')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management'), ('..................................................................................', '..................................................................................'), ('18', '18')]



========================================== PARAGRAPH 42 ===========================================

7.2. Big data analytics processing ......................................................................................... 19  

------------------- Sentence 1 -------------------

7.2.

>> Tokens are: 
 ['7.2', '.']

>> Bigrams are: 
 [('7.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.2', '7.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.2', '7.2'), ('.', '.')]

>> Lemmatization: 
 [('7.2', '7.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics processing ......................................................................................... 19

>> Tokens are: 
 ['Big', 'data', 'analytics', 'processing', '.........................................................................................', '19']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'processing'), ('processing', '.........................................................................................'), ('.........................................................................................', '19')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'processing'), ('analytics', 'processing', '.........................................................................................'), ('processing', '.........................................................................................', '19')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'VBG'), ('.........................................................................................', '$'), ('19', 'CD')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('.........................................................................................', '.........................................................................................'), ('19', '19')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('.........................................................................................', '.........................................................................................'), ('19', '19')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing'), ('.........................................................................................', '.........................................................................................'), ('19', '19')]



========================================== PARAGRAPH 43 ===========================================

7.3. Big data analytics ........................................................................................................... 20  

------------------- Sentence 1 -------------------

7.3.

>> Tokens are: 
 ['7.3', '.']

>> Bigrams are: 
 [('7.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Lemmatization: 
 [('7.3', '7.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics ........................................................................................................... 20

>> Tokens are: 
 ['Big', 'data', 'analytics', '...........................................................................................................', '20']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '...........................................................................................................'), ('...........................................................................................................', '20')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '...........................................................................................................'), ('analytics', '...........................................................................................................', '20')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('...........................................................................................................', 'VBP'), ('20', 'CD')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20')]



========================================== PARAGRAPH 44 ===========================================

7.1.1. Supervised techniques ............................................................................................. 22  

------------------- Sentence 1 -------------------

7.1.1.

>> Tokens are: 
 ['7.1.1', '.']

>> Bigrams are: 
 [('7.1.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.1', '7.1.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.1', '7.1.1'), ('.', '.')]

>> Lemmatization: 
 [('7.1.1', '7.1.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Supervised techniques ............................................................................................. 22

>> Tokens are: 
 ['Supervised', 'techniques', '.............................................................................................', '22']

>> Bigrams are: 
 [('Supervised', 'techniques'), ('techniques', '.............................................................................................'), ('.............................................................................................', '22')]

>> Trigrams are: 
 [('Supervised', 'techniques', '.............................................................................................'), ('techniques', '.............................................................................................', '22')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('techniques', 'NNS'), ('.............................................................................................', 'VBP'), ('22', 'CD')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('.............................................................................................', '.............................................................................................'), ('22', '22')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('.............................................................................................', '.............................................................................................'), ('22', '22')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('techniques', 'technique'), ('.............................................................................................', '.............................................................................................'), ('22', '22')]



========================================== PARAGRAPH 45 ===========================================

7.1.2. Un-supervised techniques ....................................................................................... 24  

------------------- Sentence 1 -------------------

7.1.2.

>> Tokens are: 
 ['7.1.2', '.']

>> Bigrams are: 
 [('7.1.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.2', '7.1.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.2', '7.1.2'), ('.', '.')]

>> Lemmatization: 
 [('7.1.2', '7.1.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Un-supervised techniques ....................................................................................... 24

>> Tokens are: 
 ['Un-supervised', 'techniques', '.......................................................................................', '24']

>> Bigrams are: 
 [('Un-supervised', 'techniques'), ('techniques', '.......................................................................................'), ('.......................................................................................', '24')]

>> Trigrams are: 
 [('Un-supervised', 'techniques', '.......................................................................................'), ('techniques', '.......................................................................................', '24')]

>> POS Tags are: 
 [('Un-supervised', 'JJ'), ('techniques', 'NNS'), ('.......................................................................................', 'VBP'), ('24', 'CD')]

>> Noun Phrases are: 
 ['Un-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('.......................................................................................', '.......................................................................................'), ('24', '24')]

>> Stemming using Snowball Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('.......................................................................................', '.......................................................................................'), ('24', '24')]

>> Lemmatization: 
 [('Un-supervised', 'Un-supervised'), ('techniques', 'technique'), ('.......................................................................................', '.......................................................................................'), ('24', '24')]



========================================== PARAGRAPH 46 ===========================================

7.1.3. Semi-supervised techniques .................................................................................... 24  

------------------- Sentence 1 -------------------

7.1.3.

>> Tokens are: 
 ['7.1.3', '.']

>> Bigrams are: 
 [('7.1.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Lemmatization: 
 [('7.1.3', '7.1.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Semi-supervised techniques .................................................................................... 24

>> Tokens are: 
 ['Semi-supervised', 'techniques', '....................................................................................', '24']

>> Bigrams are: 
 [('Semi-supervised', 'techniques'), ('techniques', '....................................................................................'), ('....................................................................................', '24')]

>> Trigrams are: 
 [('Semi-supervised', 'techniques', '....................................................................................'), ('techniques', '....................................................................................', '24')]

>> POS Tags are: 
 [('Semi-supervised', 'JJ'), ('techniques', 'NNS'), ('....................................................................................', 'VBP'), ('24', 'CD')]

>> Noun Phrases are: 
 ['Semi-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('....................................................................................', '....................................................................................'), ('24', '24')]

>> Stemming using Snowball Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('....................................................................................', '....................................................................................'), ('24', '24')]

>> Lemmatization: 
 [('Semi-supervised', 'Semi-supervised'), ('techniques', 'technique'), ('....................................................................................', '....................................................................................'), ('24', '24')]



========================================== PARAGRAPH 47 ===========================================

7.1.4. Reinforcement learning (RL) .................................................................................. 25  

------------------- Sentence 1 -------------------

7.1.4.

>> Tokens are: 
 ['7.1.4', '.']

>> Bigrams are: 
 [('7.1.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Lemmatization: 
 [('7.1.4', '7.1.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Reinforcement learning (RL) .................................................................................. 25

>> Tokens are: 
 ['Reinforcement', 'learning', '(', 'RL', ')', '..................................................................................', '25']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', '('), ('(', 'RL'), ('RL', ')'), (')', '..................................................................................'), ('..................................................................................', '25')]

>> Trigrams are: 
 [('Reinforcement', 'learning', '('), ('learning', '(', 'RL'), ('(', 'RL', ')'), ('RL', ')', '..................................................................................'), (')', '..................................................................................', '25')]

>> POS Tags are: 
 [('Reinforcement', 'NN'), ('learning', 'NN'), ('(', '('), ('RL', 'NNP'), (')', ')'), ('..................................................................................', 'VBD'), ('25', 'CD')]

>> Noun Phrases are: 
 ['Reinforcement learning', 'RL']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('(', '('), ('RL', 'RL'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25')]



========================================== PARAGRAPH 48 ===========================================

7.4. Analytics techniques ...................................................................................................... 26  

------------------- Sentence 1 -------------------

7.4.

>> Tokens are: 
 ['7.4', '.']

>> Bigrams are: 
 [('7.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Lemmatization: 
 [('7.4', '7.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Analytics techniques ...................................................................................................... 26

>> Tokens are: 
 ['Analytics', 'techniques', '......................................................................................................', '26']

>> Bigrams are: 
 [('Analytics', 'techniques'), ('techniques', '......................................................................................................'), ('......................................................................................................', '26')]

>> Trigrams are: 
 [('Analytics', 'techniques', '......................................................................................................'), ('techniques', '......................................................................................................', '26')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('techniques', 'NNS'), ('......................................................................................................', 'VBP'), ('26', 'CD')]

>> Noun Phrases are: 
 ['Analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('......................................................................................................', '......................................................................................................'), ('26', '26')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('......................................................................................................', '......................................................................................................'), ('26', '26')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('techniques', 'technique'), ('......................................................................................................', '......................................................................................................'), ('26', '26')]



========================================== PARAGRAPH 49 ===========================================

7.5. Big data platforms and tools .......................................................................................... 30  

------------------- Sentence 1 -------------------

7.5.

>> Tokens are: 
 ['7.5', '.']

>> Bigrams are: 
 [('7.5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.5', '7.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.5', '7.5'), ('.', '.')]

>> Lemmatization: 
 [('7.5', '7.5'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data platforms and tools .......................................................................................... 30

>> Tokens are: 
 ['Big', 'data', 'platforms', 'tools', '..........................................................................................', '30']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', '..........................................................................................'), ('..........................................................................................', '30')]

>> Trigrams are: 
 [('Big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', '..........................................................................................'), ('tools', '..........................................................................................', '30')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS'), ('..........................................................................................', 'VBP'), ('30', 'CD')]

>> Noun Phrases are: 
 ['Big data platforms tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30')]



========================================== PARAGRAPH 50 ===========================================

8. Big Data Analytics and Decision Making ............................................................................. 34  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Analytics and Decision Making ............................................................................. 34

>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Decision', 'Making', '.............................................................................', '34']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Decision'), ('Decision', 'Making'), ('Making', '.............................................................................'), ('.............................................................................', '34')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Decision'), ('Analytics', 'Decision', 'Making'), ('Decision', 'Making', '.............................................................................'), ('Making', '.............................................................................', '34')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('.............................................................................', 'VBD'), ('34', 'CD')]

>> Noun Phrases are: 
 ['Big Data Analytics Decision Making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('.............................................................................', '.............................................................................'), ('34', '34')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('.............................................................................', '.............................................................................'), ('34', '34')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Decision', 'Decision'), ('Making', 'Making'), ('.............................................................................', '.............................................................................'), ('34', '34')]



========================================== PARAGRAPH 51 ===========================================

9. Big data analytics challenges ................................................................................................. 37  

------------------- Sentence 1 -------------------

9.

>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics challenges ................................................................................................. 37

>> Tokens are: 
 ['Big', 'data', 'analytics', 'challenges', '.................................................................................................', '37']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', '.................................................................................................'), ('.................................................................................................', '37')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', '.................................................................................................'), ('challenges', '.................................................................................................', '37')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('.................................................................................................', 'VBP'), ('37', 'CD')]

>> Noun Phrases are: 
 ['Big data analytics challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('.................................................................................................', '.................................................................................................'), ('37', '37')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('.................................................................................................', '.................................................................................................'), ('37', '37')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('.................................................................................................', '.................................................................................................'), ('37', '37')]



========================================== PARAGRAPH 52 ===========================================

9.1. Data Security issues ....................................................................................................... 37  

------------------- Sentence 1 -------------------

9.1.

>> Tokens are: 
 ['9.1', '.']

>> Bigrams are: 
 [('9.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.1', '9.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.1', '9.1'), ('.', '.')]

>> Lemmatization: 
 [('9.1', '9.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Data Security issues ....................................................................................................... 37

>> Tokens are: 
 ['Data', 'Security', 'issues', '.......................................................................................................', '37']

>> Bigrams are: 
 [('Data', 'Security'), ('Security', 'issues'), ('issues', '.......................................................................................................'), ('.......................................................................................................', '37')]

>> Trigrams are: 
 [('Data', 'Security', 'issues'), ('Security', 'issues', '.......................................................................................................'), ('issues', '.......................................................................................................', '37')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Security', 'NNP'), ('issues', 'NNS'), ('.......................................................................................................', 'VBP'), ('37', 'CD')]

>> Noun Phrases are: 
 ['Data Security issues']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37')]

>> Lemmatization: 
 [('Data', 'Data'), ('Security', 'Security'), ('issues', 'issue'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37')]



========================================== PARAGRAPH 53 ===========================================

9.2. Data privacy issues ......................................................................................................... 39  

------------------- Sentence 1 -------------------

9.2.

>> Tokens are: 
 ['9.2', '.']

>> Bigrams are: 
 [('9.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.2', '9.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.2', '9.2'), ('.', '.')]

>> Lemmatization: 
 [('9.2', '9.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Data privacy issues ......................................................................................................... 39

>> Tokens are: 
 ['Data', 'privacy', 'issues', '.........................................................................................................', '39']

>> Bigrams are: 
 [('Data', 'privacy'), ('privacy', 'issues'), ('issues', '.........................................................................................................'), ('.........................................................................................................', '39')]

>> Trigrams are: 
 [('Data', 'privacy', 'issues'), ('privacy', 'issues', '.........................................................................................................'), ('issues', '.........................................................................................................', '39')]

>> POS Tags are: 
 [('Data', 'NNP'), ('privacy', 'NN'), ('issues', 'NNS'), ('.........................................................................................................', 'VBP'), ('39', 'CD')]

>> Noun Phrases are: 
 ['Data privacy issues']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39')]

>> Lemmatization: 
 [('Data', 'Data'), ('privacy', 'privacy'), ('issues', 'issue'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39')]



========================================== PARAGRAPH 54 ===========================================

9.3. Data storage, data capture and quality of data ............................................................... 39  

------------------- Sentence 1 -------------------

9.3.

>> Tokens are: 
 ['9.3', '.']

>> Bigrams are: 
 [('9.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Lemmatization: 
 [('9.3', '9.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Data storage, data capture and quality of data ............................................................... 39

>> Tokens are: 
 ['Data', 'storage', ',', 'data', 'capture', 'quality', 'data', '...............................................................', '39']

>> Bigrams are: 
 [('Data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'capture'), ('capture', 'quality'), ('quality', 'data'), ('data', '...............................................................'), ('...............................................................', '39')]

>> Trigrams are: 
 [('Data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'capture'), ('data', 'capture', 'quality'), ('capture', 'quality', 'data'), ('quality', 'data', '...............................................................'), ('data', '...............................................................', '39')]

>> POS Tags are: 
 [('Data', 'NNP'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('capture', 'VBP'), ('quality', 'NN'), ('data', 'NNS'), ('...............................................................', 'VBP'), ('39', 'CD')]

>> Noun Phrases are: 
 ['Data storage', 'data', 'quality data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39')]

>> Lemmatization: 
 [('Data', 'Data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('capture', 'capture'), ('quality', 'quality'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39')]



========================================== PARAGRAPH 55 ===========================================

9.4. Challenges in data analysis and visualisation ................................................................ 40  

------------------- Sentence 1 -------------------

9.4.

>> Tokens are: 
 ['9.4', '.']

>> Bigrams are: 
 [('9.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.4', '9.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.4', '9.4'), ('.', '.')]

>> Lemmatization: 
 [('9.4', '9.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Challenges in data analysis and visualisation ................................................................ 40

>> Tokens are: 
 ['Challenges', 'data', 'analysis', 'visualisation', '................................................................', '40']

>> Bigrams are: 
 [('Challenges', 'data'), ('data', 'analysis'), ('analysis', 'visualisation'), ('visualisation', '................................................................'), ('................................................................', '40')]

>> Trigrams are: 
 [('Challenges', 'data', 'analysis'), ('data', 'analysis', 'visualisation'), ('analysis', 'visualisation', '................................................................'), ('visualisation', '................................................................', '40')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('visualisation', 'NN'), ('................................................................', 'VBD'), ('40', 'CD')]

>> Noun Phrases are: 
 ['Challenges data analysis visualisation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('................................................................', '................................................................'), ('40', '40')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('................................................................', '................................................................'), ('40', '40')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('data', 'data'), ('analysis', 'analysis'), ('visualisation', 'visualisation'), ('................................................................', '................................................................'), ('40', '40')]



========================================== PARAGRAPH 56 ===========================================

10. Big data analytics applications........................................................................................... 42  

------------------- Sentence 1 -------------------

10.

>> Tokens are: 
 ['10', '.']

>> Bigrams are: 
 [('10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics applications........................................................................................... 42

>> Tokens are: 
 ['Big', 'data', 'analytics', 'applications', '...........................................................................................', '42']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', '...........................................................................................'), ('...........................................................................................', '42')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', '...........................................................................................'), ('applications', '...........................................................................................', '42')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('...........................................................................................', 'VBP'), ('42', 'CD')]

>> Noun Phrases are: 
 ['Big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('...........................................................................................', '...........................................................................................'), ('42', '42')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('...........................................................................................', '...........................................................................................'), ('42', '42')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('...........................................................................................', '...........................................................................................'), ('42', '42')]



========================================== PARAGRAPH 57 ===========================================

10.1. Healthcare ................................................................................................................... 43  

------------------- Sentence 1 -------------------

10.1.

>> Tokens are: 
 ['10.1', '.']

>> Bigrams are: 
 [('10.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.1', '10.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.1', '10.1'), ('.', '.')]

>> Lemmatization: 
 [('10.1', '10.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Healthcare ................................................................................................................... 43

>> Tokens are: 
 ['Healthcare', '...................................................................................................................', '43']

>> Bigrams are: 
 [('Healthcare', '...................................................................................................................'), ('...................................................................................................................', '43')]

>> Trigrams are: 
 [('Healthcare', '...................................................................................................................', '43')]

>> POS Tags are: 
 [('Healthcare', 'NNP'), ('...................................................................................................................', 'VBZ'), ('43', 'CD')]

>> Noun Phrases are: 
 ['Healthcare']

>> Named Entities are: 
 [('GPE', 'Healthcare')] 

>> Stemming using Porter Stemmer: 
 [('Healthcare', 'healthcar'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43')]

>> Stemming using Snowball Stemmer: 
 [('Healthcare', 'healthcar'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43')]

>> Lemmatization: 
 [('Healthcare', 'Healthcare'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43')]



========================================== PARAGRAPH 58 ===========================================

10.2. Banking ....................................................................................................................... 43  

------------------- Sentence 1 -------------------

10.2.

>> Tokens are: 
 ['10.2', '.']

>> Bigrams are: 
 [('10.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Lemmatization: 
 [('10.2', '10.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Banking ....................................................................................................................... 43

>> Tokens are: 
 ['Banking', '.......................................................................................................................', '43']

>> Bigrams are: 
 [('Banking', '.......................................................................................................................'), ('.......................................................................................................................', '43')]

>> Trigrams are: 
 [('Banking', '.......................................................................................................................', '43')]

>> POS Tags are: 
 [('Banking', 'NN'), ('.......................................................................................................................', 'CD'), ('43', 'CD')]

>> Noun Phrases are: 
 ['Banking']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Banking', 'bank'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43')]

>> Stemming using Snowball Stemmer: 
 [('Banking', 'bank'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43')]

>> Lemmatization: 
 [('Banking', 'Banking'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43')]



========================================== PARAGRAPH 59 ===========================================

10.3. Retail ........................................................................................................................... 44  

------------------- Sentence 1 -------------------

10.3.

>> Tokens are: 
 ['10.3', '.']

>> Bigrams are: 
 [('10.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Lemmatization: 
 [('10.3', '10.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Retail ........................................................................................................................... 44

>> Tokens are: 
 ['Retail', '...........................................................................................................................', '44']

>> Bigrams are: 
 [('Retail', '...........................................................................................................................'), ('...........................................................................................................................', '44')]

>> Trigrams are: 
 [('Retail', '...........................................................................................................................', '44')]

>> POS Tags are: 
 [('Retail', 'JJ'), ('...........................................................................................................................', 'NN'), ('44', 'CD')]

>> Noun Phrases are: 
 ['Retail ...........................................................................................................................']

>> Named Entities are: 
 [('GPE', 'Retail')] 

>> Stemming using Porter Stemmer: 
 [('Retail', 'retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44')]

>> Stemming using Snowball Stemmer: 
 [('Retail', 'retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44')]

>> Lemmatization: 
 [('Retail', 'Retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44')]



========================================== PARAGRAPH 60 ===========================================

10.4. Telecommunications ................................................................................................... 45  

------------------- Sentence 1 -------------------

10.4.

>> Tokens are: 
 ['10.4', '.']

>> Bigrams are: 
 [('10.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.4', '10.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.4', '10.4'), ('.', '.')]

>> Lemmatization: 
 [('10.4', '10.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Telecommunications ................................................................................................... 45

>> Tokens are: 
 ['Telecommunications', '...................................................................................................', '45']

>> Bigrams are: 
 [('Telecommunications', '...................................................................................................'), ('...................................................................................................', '45')]

>> Trigrams are: 
 [('Telecommunications', '...................................................................................................', '45')]

>> POS Tags are: 
 [('Telecommunications', 'NNS'), ('...................................................................................................', 'VBP'), ('45', 'CD')]

>> Noun Phrases are: 
 ['Telecommunications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Telecommunications', 'telecommun'), ('...................................................................................................', '...................................................................................................'), ('45', '45')]

>> Stemming using Snowball Stemmer: 
 [('Telecommunications', 'telecommun'), ('...................................................................................................', '...................................................................................................'), ('45', '45')]

>> Lemmatization: 
 [('Telecommunications', 'Telecommunications'), ('...................................................................................................', '...................................................................................................'), ('45', '45')]



========================================== PARAGRAPH 61 ===========================================

11. Implications of research ..................................................................................................... 45  

------------------- Sentence 1 -------------------

11.

>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]


------------------- Sentence 2 -------------------

Implications of research ..................................................................................................... 45

>> Tokens are: 
 ['Implications', 'research', '.....................................................................................................', '45']

>> Bigrams are: 
 [('Implications', 'research'), ('research', '.....................................................................................................'), ('.....................................................................................................', '45')]

>> Trigrams are: 
 [('Implications', 'research', '.....................................................................................................'), ('research', '.....................................................................................................', '45')]

>> POS Tags are: 
 [('Implications', 'NNS'), ('research', 'NN'), ('.....................................................................................................', 'VBZ'), ('45', 'CD')]

>> Noun Phrases are: 
 ['Implications research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45')]

>> Stemming using Snowball Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45')]

>> Lemmatization: 
 [('Implications', 'Implications'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45')]



========================================== PARAGRAPH 62 ===========================================

12. Conclusion and Future Research ....................................................................................... 46  

------------------- Sentence 1 -------------------

12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]


------------------- Sentence 2 -------------------

Conclusion and Future Research ....................................................................................... 46

>> Tokens are: 
 ['Conclusion', 'Future', 'Research', '.......................................................................................', '46']

>> Bigrams are: 
 [('Conclusion', 'Future'), ('Future', 'Research'), ('Research', '.......................................................................................'), ('.......................................................................................', '46')]

>> Trigrams are: 
 [('Conclusion', 'Future', 'Research'), ('Future', 'Research', '.......................................................................................'), ('Research', '.......................................................................................', '46')]

>> POS Tags are: 
 [('Conclusion', 'NNP'), ('Future', 'NNP'), ('Research', 'NNP'), ('.......................................................................................', 'VBZ'), ('46', 'CD')]

>> Noun Phrases are: 
 ['Conclusion Future Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('.......................................................................................', '.......................................................................................'), ('46', '46')]

>> Stemming using Snowball Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('.......................................................................................', '.......................................................................................'), ('46', '46')]

>> Lemmatization: 
 [('Conclusion', 'Conclusion'), ('Future', 'Future'), ('Research', 'Research'), ('.......................................................................................', '.......................................................................................'), ('46', '46')]



========================================== PARAGRAPH 63 ===========================================

13. References .......................................................................................................................... 47 

------------------- Sentence 1 -------------------

13.

>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]


------------------- Sentence 2 -------------------

References .......................................................................................................................... 47

>> Tokens are: 
 ['References', '..........................................................................................................................', '47']

>> Bigrams are: 
 [('References', '..........................................................................................................................'), ('..........................................................................................................................', '47')]

>> Trigrams are: 
 [('References', '..........................................................................................................................', '47')]

>> POS Tags are: 
 [('References', 'NNS'), ('..........................................................................................................................', 'VBP'), ('47', 'CD')]

>> Noun Phrases are: 
 ['References']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('References', 'refer'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47')]

>> Stemming using Snowball Stemmer: 
 [('References', 'refer'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47')]

>> Lemmatization: 
 [('References', 'References'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47')]



========================================== PARAGRAPH 64 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 65 ===========================================

1  

------------------- Sentence 1 -------------------

1

>> Tokens are: 
 ['1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('1', '1')]

>> Lemmatization: 
 [('1', '1')]



========================================== PARAGRAPH 66 ===========================================

  


========================================== PARAGRAPH 67 ===========================================

1. Introduction   

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Introduction

>> Tokens are: 
 ['Introduction']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Introduction', 'NN')]

>> Noun Phrases are: 
 ['Introduction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct')]

>> Lemmatization: 
 [('Introduction', 'Introduction')]



========================================== PARAGRAPH 68 ===========================================

Big data refers to datasets which are both large in size and high in variety and velocity of data,  

------------------- Sentence 1 -------------------

Big data refers to datasets which are both large in size and high in variety and velocity of data,

>> Tokens are: 
 ['Big', 'data', 'refers', 'datasets', 'large', 'size', 'high', 'variety', 'velocity', 'data', ',']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'refers'), ('refers', 'datasets'), ('datasets', 'large'), ('large', 'size'), ('size', 'high'), ('high', 'variety'), ('variety', 'velocity'), ('velocity', 'data'), ('data', ',')]

>> Trigrams are: 
 [('Big', 'data', 'refers'), ('data', 'refers', 'datasets'), ('refers', 'datasets', 'large'), ('datasets', 'large', 'size'), ('large', 'size', 'high'), ('size', 'high', 'variety'), ('high', 'variety', 'velocity'), ('variety', 'velocity', 'data'), ('velocity', 'data', ',')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NN'), ('refers', 'NNS'), ('datasets', 'NNS'), ('large', 'JJ'), ('size', 'NN'), ('high', 'JJ'), ('variety', 'NN'), ('velocity', 'NN'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Big data refers datasets', 'large size', 'high variety velocity data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('refers', 'refer'), ('datasets', 'dataset'), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('variety', 'varieti'), ('velocity', 'veloc'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('refers', 'refer'), ('datasets', 'dataset'), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('variety', 'varieti'), ('velocity', 'veloc'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('refers', 'refers'), ('datasets', 'datasets'), ('large', 'large'), ('size', 'size'), ('high', 'high'), ('variety', 'variety'), ('velocity', 'velocity'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 69 ===========================================

characteristics which make it difficult for them to be handled using traditional techniques and tools  

------------------- Sentence 1 -------------------

characteristics which make it difficult for them to be handled using traditional techniques and tools

>> Tokens are: 
 ['characteristics', 'make', 'difficult', 'handled', 'using', 'traditional', 'techniques', 'tools']

>> Bigrams are: 
 [('characteristics', 'make'), ('make', 'difficult'), ('difficult', 'handled'), ('handled', 'using'), ('using', 'traditional'), ('traditional', 'techniques'), ('techniques', 'tools')]

>> Trigrams are: 
 [('characteristics', 'make', 'difficult'), ('make', 'difficult', 'handled'), ('difficult', 'handled', 'using'), ('handled', 'using', 'traditional'), ('using', 'traditional', 'techniques'), ('traditional', 'techniques', 'tools')]

>> POS Tags are: 
 [('characteristics', 'NNS'), ('make', 'VBP'), ('difficult', 'JJ'), ('handled', 'VBN'), ('using', 'VBG'), ('traditional', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['characteristics', 'traditional techniques tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('characteristics', 'characterist'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('techniques', 'techniqu'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('characteristics', 'characterist'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('techniques', 'techniqu'), ('tools', 'tool')]

>> Lemmatization: 
 [('characteristics', 'characteristic'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handled'), ('using', 'using'), ('traditional', 'traditional'), ('techniques', 'technique'), ('tools', 'tool')]



========================================== PARAGRAPH 70 ===========================================

(Constantiou, I.D. and Kallinikos, J., 2015). This has generated a need for research into and  

------------------- Sentence 1 -------------------

(Constantiou, I.D.

>> Tokens are: 
 ['(', 'Constantiou', ',', 'I.D', '.']

>> Bigrams are: 
 [('(', 'Constantiou'), ('Constantiou', ','), (',', 'I.D'), ('I.D', '.')]

>> Trigrams are: 
 [('(', 'Constantiou', ','), ('Constantiou', ',', 'I.D'), (',', 'I.D', '.')]

>> POS Tags are: 
 [('(', '('), ('Constantiou', 'NNP'), (',', ','), ('I.D', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Constantiou', 'I.D']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Constantiou', 'constanti'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Constantiou', 'constantiou'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Constantiou', 'Constantiou'), (',', ','), ('I.D', 'I.D'), ('.', '.')]


------------------- Sentence 2 -------------------

and Kallinikos, J., 2015).

>> Tokens are: 
 ['Kallinikos', ',', 'J.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Kallinikos', ','), (',', 'J.'), ('J.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Kallinikos', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Kallinikos', 'J.']

>> Named Entities are: 
 [('GPE', 'Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('J.', 'J.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

This has generated a need for research into and

>> Tokens are: 
 ['This', 'generated', 'need', 'research']

>> Bigrams are: 
 [('This', 'generated'), ('generated', 'need'), ('need', 'research')]

>> Trigrams are: 
 [('This', 'generated', 'need'), ('generated', 'need', 'research')]

>> POS Tags are: 
 [('This', 'DT'), ('generated', 'VBD'), ('need', 'MD'), ('research', 'NN')]

>> Noun Phrases are: 
 ['research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('generated', 'gener'), ('need', 'need'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('generated', 'generat'), ('need', 'need'), ('research', 'research')]

>> Lemmatization: 
 [('This', 'This'), ('generated', 'generated'), ('need', 'need'), ('research', 'research')]



========================================== PARAGRAPH 71 ===========================================

provision of solutions to handle and extract knowledge from such datasets. Due to the large  

------------------- Sentence 1 -------------------

provision of solutions to handle and extract knowledge from such datasets.

>> Tokens are: 
 ['provision', 'solutions', 'handle', 'extract', 'knowledge', 'datasets', '.']

>> Bigrams are: 
 [('provision', 'solutions'), ('solutions', 'handle'), ('handle', 'extract'), ('extract', 'knowledge'), ('knowledge', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('provision', 'solutions', 'handle'), ('solutions', 'handle', 'extract'), ('handle', 'extract', 'knowledge'), ('extract', 'knowledge', 'datasets'), ('knowledge', 'datasets', '.')]

>> POS Tags are: 
 [('provision', 'NN'), ('solutions', 'NNS'), ('handle', 'VBP'), ('extract', 'JJ'), ('knowledge', 'NN'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['provision solutions', 'extract knowledge datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provision', 'provis'), ('solutions', 'solut'), ('handle', 'handl'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('provision', 'provis'), ('solutions', 'solut'), ('handle', 'handl'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('provision', 'provision'), ('solutions', 'solution'), ('handle', 'handle'), ('extract', 'extract'), ('knowledge', 'knowledge'), ('datasets', 'datasets'), ('.', '.')]


------------------- Sentence 2 -------------------

Due to the large

>> Tokens are: 
 ['Due', 'large']

>> Bigrams are: 
 [('Due', 'large')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Due', 'JJ'), ('large', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('large', 'larg')]

>> Lemmatization: 
 [('Due', 'Due'), ('large', 'large')]



========================================== PARAGRAPH 72 ===========================================

quantities of data involved, multiple technologies and frameworks have been created in order to  

------------------- Sentence 1 -------------------

quantities of data involved, multiple technologies and frameworks have been created in order to

>> Tokens are: 
 ['quantities', 'data', 'involved', ',', 'multiple', 'technologies', 'frameworks', 'created', 'order']

>> Bigrams are: 
 [('quantities', 'data'), ('data', 'involved'), ('involved', ','), (',', 'multiple'), ('multiple', 'technologies'), ('technologies', 'frameworks'), ('frameworks', 'created'), ('created', 'order')]

>> Trigrams are: 
 [('quantities', 'data', 'involved'), ('data', 'involved', ','), ('involved', ',', 'multiple'), (',', 'multiple', 'technologies'), ('multiple', 'technologies', 'frameworks'), ('technologies', 'frameworks', 'created'), ('frameworks', 'created', 'order')]

>> POS Tags are: 
 [('quantities', 'NNS'), ('data', 'NNS'), ('involved', 'VBN'), (',', ','), ('multiple', 'JJ'), ('technologies', 'NNS'), ('frameworks', 'NNS'), ('created', 'VBD'), ('order', 'NN')]

>> Noun Phrases are: 
 ['quantities data', 'multiple technologies frameworks', 'order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('quantities', 'quantiti'), ('data', 'data'), ('involved', 'involv'), (',', ','), ('multiple', 'multipl'), ('technologies', 'technolog'), ('frameworks', 'framework'), ('created', 'creat'), ('order', 'order')]

>> Stemming using Snowball Stemmer: 
 [('quantities', 'quantiti'), ('data', 'data'), ('involved', 'involv'), (',', ','), ('multiple', 'multipl'), ('technologies', 'technolog'), ('frameworks', 'framework'), ('created', 'creat'), ('order', 'order')]

>> Lemmatization: 
 [('quantities', 'quantity'), ('data', 'data'), ('involved', 'involved'), (',', ','), ('multiple', 'multiple'), ('technologies', 'technology'), ('frameworks', 'framework'), ('created', 'created'), ('order', 'order')]



========================================== PARAGRAPH 73 ===========================================

provide additional storage capacity and real-time analysis. Many models, programs, software,  

------------------- Sentence 1 -------------------

provide additional storage capacity and real-time analysis.

>> Tokens are: 
 ['provide', 'additional', 'storage', 'capacity', 'real-time', 'analysis', '.']

>> Bigrams are: 
 [('provide', 'additional'), ('additional', 'storage'), ('storage', 'capacity'), ('capacity', 'real-time'), ('real-time', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('provide', 'additional', 'storage'), ('additional', 'storage', 'capacity'), ('storage', 'capacity', 'real-time'), ('capacity', 'real-time', 'analysis'), ('real-time', 'analysis', '.')]

>> POS Tags are: 
 [('provide', 'IN'), ('additional', 'JJ'), ('storage', 'NN'), ('capacity', 'NN'), ('real-time', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['additional storage capacity', 'real-time analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provide', 'provid'), ('additional', 'addit'), ('storage', 'storag'), ('capacity', 'capac'), ('real-time', 'real-tim'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('provide', 'provid'), ('additional', 'addit'), ('storage', 'storag'), ('capacity', 'capac'), ('real-time', 'real-tim'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('provide', 'provide'), ('additional', 'additional'), ('storage', 'storage'), ('capacity', 'capacity'), ('real-time', 'real-time'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Many models, programs, software,

>> Tokens are: 
 ['Many', 'models', ',', 'programs', ',', 'software', ',']

>> Bigrams are: 
 [('Many', 'models'), ('models', ','), (',', 'programs'), ('programs', ','), (',', 'software'), ('software', ',')]

>> Trigrams are: 
 [('Many', 'models', ','), ('models', ',', 'programs'), (',', 'programs', ','), ('programs', ',', 'software'), (',', 'software', ',')]

>> POS Tags are: 
 [('Many', 'JJ'), ('models', 'NNS'), (',', ','), ('programs', 'NNS'), (',', ','), ('software', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Many models', 'programs', 'software']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'softwar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'softwar'), (',', ',')]

>> Lemmatization: 
 [('Many', 'Many'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'software'), (',', ',')]



========================================== PARAGRAPH 74 ===========================================

hardware, and technologies have thus been designed specifically for extracting knowledge from  

------------------- Sentence 1 -------------------

hardware, and technologies have thus been designed specifically for extracting knowledge from

>> Tokens are: 
 ['hardware', ',', 'technologies', 'thus', 'designed', 'specifically', 'extracting', 'knowledge']

>> Bigrams are: 
 [('hardware', ','), (',', 'technologies'), ('technologies', 'thus'), ('thus', 'designed'), ('designed', 'specifically'), ('specifically', 'extracting'), ('extracting', 'knowledge')]

>> Trigrams are: 
 [('hardware', ',', 'technologies'), (',', 'technologies', 'thus'), ('technologies', 'thus', 'designed'), ('thus', 'designed', 'specifically'), ('designed', 'specifically', 'extracting'), ('specifically', 'extracting', 'knowledge')]

>> POS Tags are: 
 [('hardware', 'NN'), (',', ','), ('technologies', 'NNS'), ('thus', 'RB'), ('designed', 'VBN'), ('specifically', 'RB'), ('extracting', 'VBG'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['hardware', 'technologies', 'knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('hardware', 'hardwar'), (',', ','), ('technologies', 'technolog'), ('thus', 'thu'), ('designed', 'design'), ('specifically', 'specif'), ('extracting', 'extract'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('hardware', 'hardwar'), (',', ','), ('technologies', 'technolog'), ('thus', 'thus'), ('designed', 'design'), ('specifically', 'specif'), ('extracting', 'extract'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('hardware', 'hardware'), (',', ','), ('technologies', 'technology'), ('thus', 'thus'), ('designed', 'designed'), ('specifically', 'specifically'), ('extracting', 'extracting'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 75 ===========================================

big data (Oussous et al., 2018), as the extensive but rapidly changing data from daily transactions,  

------------------- Sentence 1 -------------------

big data (Oussous et al., 2018), as the extensive but rapidly changing data from daily transactions,

>> Tokens are: 
 ['big', 'data', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', ',', 'extensive', 'rapidly', 'changing', 'data', 'daily', 'transactions', ',']

>> Bigrams are: 
 [('big', 'data'), ('data', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', ','), (',', 'extensive'), ('extensive', 'rapidly'), ('rapidly', 'changing'), ('changing', 'data'), ('data', 'daily'), ('daily', 'transactions'), ('transactions', ',')]

>> Trigrams are: 
 [('big', 'data', '('), ('data', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', ','), (')', ',', 'extensive'), (',', 'extensive', 'rapidly'), ('extensive', 'rapidly', 'changing'), ('rapidly', 'changing', 'data'), ('changing', 'data', 'daily'), ('data', 'daily', 'transactions'), ('daily', 'transactions', ',')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('extensive', 'JJ'), ('rapidly', 'RB'), ('changing', 'VBG'), ('data', 'NNS'), ('daily', 'JJ'), ('transactions', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['big data', 'Oussous et al.', 'data', 'daily transactions']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extens'), ('rapidly', 'rapidli'), ('changing', 'chang'), ('data', 'data'), ('daily', 'daili'), ('transactions', 'transact'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extens'), ('rapidly', 'rapid'), ('changing', 'chang'), ('data', 'data'), ('daily', 'daili'), ('transactions', 'transact'), (',', ',')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extensive'), ('rapidly', 'rapidly'), ('changing', 'changing'), ('data', 'data'), ('daily', 'daily'), ('transactions', 'transaction'), (',', ',')]



========================================== PARAGRAPH 76 ===========================================

customer interactions, and social networks has the potential to provide decision makers with  

------------------- Sentence 1 -------------------

customer interactions, and social networks has the potential to provide decision makers with

>> Tokens are: 
 ['customer', 'interactions', ',', 'social', 'networks', 'potential', 'provide', 'decision', 'makers']

>> Bigrams are: 
 [('customer', 'interactions'), ('interactions', ','), (',', 'social'), ('social', 'networks'), ('networks', 'potential'), ('potential', 'provide'), ('provide', 'decision'), ('decision', 'makers')]

>> Trigrams are: 
 [('customer', 'interactions', ','), ('interactions', ',', 'social'), (',', 'social', 'networks'), ('social', 'networks', 'potential'), ('networks', 'potential', 'provide'), ('potential', 'provide', 'decision'), ('provide', 'decision', 'makers')]

>> POS Tags are: 
 [('customer', 'NN'), ('interactions', 'NNS'), (',', ','), ('social', 'JJ'), ('networks', 'NNS'), ('potential', 'JJ'), ('provide', 'JJ'), ('decision', 'NN'), ('makers', 'NNS')]

>> Noun Phrases are: 
 ['customer interactions', 'social networks', 'potential provide decision makers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('customer', 'custom'), ('interactions', 'interact'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potenti'), ('provide', 'provid'), ('decision', 'decis'), ('makers', 'maker')]

>> Stemming using Snowball Stemmer: 
 [('customer', 'custom'), ('interactions', 'interact'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potenti'), ('provide', 'provid'), ('decision', 'decis'), ('makers', 'maker')]

>> Lemmatization: 
 [('customer', 'customer'), ('interactions', 'interaction'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potential'), ('provide', 'provide'), ('decision', 'decision'), ('makers', 'maker')]



========================================== PARAGRAPH 77 ===========================================

valuable insights (Provost and Fawcett, 2013; Elgendy and Elragal, 2014; Elgendy and Elragal,  

------------------- Sentence 1 -------------------

valuable insights (Provost and Fawcett, 2013; Elgendy and Elragal, 2014; Elgendy and Elragal,

>> Tokens are: 
 ['valuable', 'insights', '(', 'Provost', 'Fawcett', ',', '2013', ';', 'Elgendy', 'Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',']

>> Bigrams are: 
 [('valuable', 'insights'), ('insights', '('), ('(', 'Provost'), ('Provost', 'Fawcett'), ('Fawcett', ','), (',', '2013'), ('2013', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ',')]

>> Trigrams are: 
 [('valuable', 'insights', '('), ('insights', '(', 'Provost'), ('(', 'Provost', 'Fawcett'), ('Provost', 'Fawcett', ','), ('Fawcett', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ',')]

>> POS Tags are: 
 [('valuable', 'JJ'), ('insights', 'NNS'), ('(', '('), ('Provost', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('2013', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['valuable insights', 'Provost Fawcett', 'Elgendy Elragal', 'Elgendy Elragal']

>> Named Entities are: 
 [('ORGANIZATION', 'Provost Fawcett'), ('PERSON', 'Elgendy Elragal'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('valuable', 'valuabl'), ('insights', 'insight'), ('(', '('), ('Provost', 'provost'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('valuable', 'valuabl'), ('insights', 'insight'), ('(', '('), ('Provost', 'provost'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ',')]

>> Lemmatization: 
 [('valuable', 'valuable'), ('insights', 'insight'), ('(', '('), ('Provost', 'Provost'), ('Fawcett', 'Fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ',')]



========================================== PARAGRAPH 78 ===========================================

2016).  

------------------- Sentence 1 -------------------

2016).

>> Tokens are: 
 ['2016', ')', '.']

>> Bigrams are: 
 [('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 79 ===========================================

Big data analytics have already been extensively researched in academia; however, some industrial  

------------------- Sentence 1 -------------------

Big data analytics have already been extensively researched in academia; however, some industrial

>> Tokens are: 
 ['Big', 'data', 'analytics', 'already', 'extensively', 'researched', 'academia', ';', 'however', ',', 'industrial']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'already'), ('already', 'extensively'), ('extensively', 'researched'), ('researched', 'academia'), ('academia', ';'), (';', 'however'), ('however', ','), (',', 'industrial')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'already'), ('analytics', 'already', 'extensively'), ('already', 'extensively', 'researched'), ('extensively', 'researched', 'academia'), ('researched', 'academia', ';'), ('academia', ';', 'however'), (';', 'however', ','), ('however', ',', 'industrial')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('already', 'RB'), ('extensively', 'RB'), ('researched', 'JJ'), ('academia', 'NN'), (';', ':'), ('however', 'RB'), (',', ','), ('industrial', 'JJ')]

>> Noun Phrases are: 
 ['Big data analytics', 'researched academia']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('extensively', 'extens'), ('researched', 'research'), ('academia', 'academia'), (';', ';'), ('however', 'howev'), (',', ','), ('industrial', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('extensively', 'extens'), ('researched', 'research'), ('academia', 'academia'), (';', ';'), ('however', 'howev'), (',', ','), ('industrial', 'industri')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('already', 'already'), ('extensively', 'extensively'), ('researched', 'researched'), ('academia', 'academia'), (';', ';'), ('however', 'however'), (',', ','), ('industrial', 'industrial')]



========================================== PARAGRAPH 80 ===========================================

advances and new technologies have mainly been discussed in industry papers thus far (Elgendy  

------------------- Sentence 1 -------------------

advances and new technologies have mainly been discussed in industry papers thus far (Elgendy

>> Tokens are: 
 ['advances', 'new', 'technologies', 'mainly', 'discussed', 'industry', 'papers', 'thus', 'far', '(', 'Elgendy']

>> Bigrams are: 
 [('advances', 'new'), ('new', 'technologies'), ('technologies', 'mainly'), ('mainly', 'discussed'), ('discussed', 'industry'), ('industry', 'papers'), ('papers', 'thus'), ('thus', 'far'), ('far', '('), ('(', 'Elgendy')]

>> Trigrams are: 
 [('advances', 'new', 'technologies'), ('new', 'technologies', 'mainly'), ('technologies', 'mainly', 'discussed'), ('mainly', 'discussed', 'industry'), ('discussed', 'industry', 'papers'), ('industry', 'papers', 'thus'), ('papers', 'thus', 'far'), ('thus', 'far', '('), ('far', '(', 'Elgendy')]

>> POS Tags are: 
 [('advances', 'NNS'), ('new', 'JJ'), ('technologies', 'NNS'), ('mainly', 'RB'), ('discussed', 'VBD'), ('industry', 'NN'), ('papers', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('(', '('), ('Elgendy', 'NNP')]

>> Noun Phrases are: 
 ['advances', 'new technologies', 'industry papers', 'Elgendy']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('advances', 'advanc'), ('new', 'new'), ('technologies', 'technolog'), ('mainly', 'mainli'), ('discussed', 'discuss'), ('industry', 'industri'), ('papers', 'paper'), ('thus', 'thu'), ('far', 'far'), ('(', '('), ('Elgendy', 'elgendi')]

>> Stemming using Snowball Stemmer: 
 [('advances', 'advanc'), ('new', 'new'), ('technologies', 'technolog'), ('mainly', 'main'), ('discussed', 'discuss'), ('industry', 'industri'), ('papers', 'paper'), ('thus', 'thus'), ('far', 'far'), ('(', '('), ('Elgendy', 'elgendi')]

>> Lemmatization: 
 [('advances', 'advance'), ('new', 'new'), ('technologies', 'technology'), ('mainly', 'mainly'), ('discussed', 'discussed'), ('industry', 'industry'), ('papers', 'paper'), ('thus', 'thus'), ('far', 'far'), ('(', '('), ('Elgendy', 'Elgendy')]



========================================== PARAGRAPH 81 ===========================================

and Elragal, 2014; Elragal and Klischewski, 2017). The link between research in academia and  

------------------- Sentence 1 -------------------

and Elragal, 2014; Elragal and Klischewski, 2017).

>> Tokens are: 
 ['Elragal', ',', '2014', ';', 'Elragal', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elragal'), ('Elragal', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elragal'), (';', 'Elragal', 'Klischewski'), ('Elragal', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elragal', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'Elragal Klischewski']

>> Named Entities are: 
 [('GPE', 'Elragal'), ('PERSON', 'Elragal Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'Elragal'), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The link between research in academia and

>> Tokens are: 
 ['The', 'link', 'research', 'academia']

>> Bigrams are: 
 [('The', 'link'), ('link', 'research'), ('research', 'academia')]

>> Trigrams are: 
 [('The', 'link', 'research'), ('link', 'research', 'academia')]

>> POS Tags are: 
 [('The', 'DT'), ('link', 'NN'), ('research', 'NN'), ('academia', 'NN')]

>> Noun Phrases are: 
 ['The link research academia']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('link', 'link'), ('research', 'research'), ('academia', 'academia')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('link', 'link'), ('research', 'research'), ('academia', 'academia')]

>> Lemmatization: 
 [('The', 'The'), ('link', 'link'), ('research', 'research'), ('academia', 'academia')]



========================================== PARAGRAPH 82 ===========================================

industry may be best understood when summarised and reviewed critically, and as a literature  

------------------- Sentence 1 -------------------

industry may be best understood when summarised and reviewed critically, and as a literature

>> Tokens are: 
 ['industry', 'may', 'best', 'understood', 'summarised', 'reviewed', 'critically', ',', 'literature']

>> Bigrams are: 
 [('industry', 'may'), ('may', 'best'), ('best', 'understood'), ('understood', 'summarised'), ('summarised', 'reviewed'), ('reviewed', 'critically'), ('critically', ','), (',', 'literature')]

>> Trigrams are: 
 [('industry', 'may', 'best'), ('may', 'best', 'understood'), ('best', 'understood', 'summarised'), ('understood', 'summarised', 'reviewed'), ('summarised', 'reviewed', 'critically'), ('reviewed', 'critically', ','), ('critically', ',', 'literature')]

>> POS Tags are: 
 [('industry', 'NN'), ('may', 'MD'), ('best', 'VB'), ('understood', 'NN'), ('summarised', 'VBN'), ('reviewed', 'VBN'), ('critically', 'RB'), (',', ','), ('literature', 'NN')]

>> Noun Phrases are: 
 ['industry', 'understood', 'literature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('industry', 'industri'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summaris'), ('reviewed', 'review'), ('critically', 'critic'), (',', ','), ('literature', 'literatur')]

>> Stemming using Snowball Stemmer: 
 [('industry', 'industri'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summaris'), ('reviewed', 'review'), ('critically', 'critic'), (',', ','), ('literature', 'literatur')]

>> Lemmatization: 
 [('industry', 'industry'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summarised'), ('reviewed', 'reviewed'), ('critically', 'critically'), (',', ','), ('literature', 'literature')]



========================================== PARAGRAPH 83 ===========================================

review represents the foundation for any further research in information systems, it may be  

------------------- Sentence 1 -------------------

review represents the foundation for any further research in information systems, it may be

>> Tokens are: 
 ['review', 'represents', 'foundation', 'research', 'information', 'systems', ',', 'may']

>> Bigrams are: 
 [('review', 'represents'), ('represents', 'foundation'), ('foundation', 'research'), ('research', 'information'), ('information', 'systems'), ('systems', ','), (',', 'may')]

>> Trigrams are: 
 [('review', 'represents', 'foundation'), ('represents', 'foundation', 'research'), ('foundation', 'research', 'information'), ('research', 'information', 'systems'), ('information', 'systems', ','), ('systems', ',', 'may')]

>> POS Tags are: 
 [('review', 'NN'), ('represents', 'VBZ'), ('foundation', 'JJ'), ('research', 'NN'), ('information', 'NN'), ('systems', 'NNS'), (',', ','), ('may', 'MD')]

>> Noun Phrases are: 
 ['review', 'foundation research information systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('review', 'review'), ('represents', 'repres'), ('foundation', 'foundat'), ('research', 'research'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('may', 'may')]

>> Stemming using Snowball Stemmer: 
 [('review', 'review'), ('represents', 'repres'), ('foundation', 'foundat'), ('research', 'research'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('may', 'may')]

>> Lemmatization: 
 [('review', 'review'), ('represents', 'represents'), ('foundation', 'foundation'), ('research', 'research'), ('information', 'information'), ('systems', 'system'), (',', ','), ('may', 'may')]



========================================== PARAGRAPH 84 ===========================================

regarded either as a part of such research or as research itself. However, this requires more than a  

------------------- Sentence 1 -------------------

regarded either as a part of such research or as research itself.

>> Tokens are: 
 ['regarded', 'either', 'part', 'research', 'research', '.']

>> Bigrams are: 
 [('regarded', 'either'), ('either', 'part'), ('part', 'research'), ('research', 'research'), ('research', '.')]

>> Trigrams are: 
 [('regarded', 'either', 'part'), ('either', 'part', 'research'), ('part', 'research', 'research'), ('research', 'research', '.')]

>> POS Tags are: 
 [('regarded', 'VBN'), ('either', 'CC'), ('part', 'NN'), ('research', 'NN'), ('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['part research research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('regarded', 'regard'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('regarded', 'regard'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('regarded', 'regarded'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]


------------------- Sentence 2 -------------------

However, this requires more than a

>> Tokens are: 
 ['However', ',', 'requires']

>> Bigrams are: 
 [('However', ','), (',', 'requires')]

>> Trigrams are: 
 [('However', ',', 'requires')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('requires', 'VBZ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('requires', 'requir')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('requires', 'requir')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('requires', 'requires')]



========================================== PARAGRAPH 85 ===========================================

literature summary, as it must show the relationship between different publications and identify  

------------------- Sentence 1 -------------------

literature summary, as it must show the relationship between different publications and identify

>> Tokens are: 
 ['literature', 'summary', ',', 'must', 'show', 'relationship', 'different', 'publications', 'identify']

>> Bigrams are: 
 [('literature', 'summary'), ('summary', ','), (',', 'must'), ('must', 'show'), ('show', 'relationship'), ('relationship', 'different'), ('different', 'publications'), ('publications', 'identify')]

>> Trigrams are: 
 [('literature', 'summary', ','), ('summary', ',', 'must'), (',', 'must', 'show'), ('must', 'show', 'relationship'), ('show', 'relationship', 'different'), ('relationship', 'different', 'publications'), ('different', 'publications', 'identify')]

>> POS Tags are: 
 [('literature', 'NN'), ('summary', 'NN'), (',', ','), ('must', 'MD'), ('show', 'VB'), ('relationship', 'NN'), ('different', 'JJ'), ('publications', 'NNS'), ('identify', 'VBP')]

>> Noun Phrases are: 
 ['literature summary', 'relationship', 'different publications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('literature', 'literatur'), ('summary', 'summari'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'differ'), ('publications', 'public'), ('identify', 'identifi')]

>> Stemming using Snowball Stemmer: 
 [('literature', 'literatur'), ('summary', 'summari'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'differ'), ('publications', 'public'), ('identify', 'identifi')]

>> Lemmatization: 
 [('literature', 'literature'), ('summary', 'summary'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'different'), ('publications', 'publication'), ('identify', 'identify')]



========================================== PARAGRAPH 86 ===========================================

relationships between ideas and practice.  

------------------- Sentence 1 -------------------

relationships between ideas and practice.

>> Tokens are: 
 ['relationships', 'ideas', 'practice', '.']

>> Bigrams are: 
 [('relationships', 'ideas'), ('ideas', 'practice'), ('practice', '.')]

>> Trigrams are: 
 [('relationships', 'ideas', 'practice'), ('ideas', 'practice', '.')]

>> POS Tags are: 
 [('relationships', 'NNS'), ('ideas', 'NNS'), ('practice', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['relationships ideas practice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practic'), ('.', '.')]

>> Lemmatization: 
 [('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practice'), ('.', '.')]



========================================== PARAGRAPH 87 ===========================================

An effective literature review provides the reader with state-of-the-art reporting on a specific topic  

------------------- Sentence 1 -------------------

An effective literature review provides the reader with state-of-the-art reporting on a specific topic

>> Tokens are: 
 ['An', 'effective', 'literature', 'review', 'provides', 'reader', 'state-of-the-art', 'reporting', 'specific', 'topic']

>> Bigrams are: 
 [('An', 'effective'), ('effective', 'literature'), ('literature', 'review'), ('review', 'provides'), ('provides', 'reader'), ('reader', 'state-of-the-art'), ('state-of-the-art', 'reporting'), ('reporting', 'specific'), ('specific', 'topic')]

>> Trigrams are: 
 [('An', 'effective', 'literature'), ('effective', 'literature', 'review'), ('literature', 'review', 'provides'), ('review', 'provides', 'reader'), ('provides', 'reader', 'state-of-the-art'), ('reader', 'state-of-the-art', 'reporting'), ('state-of-the-art', 'reporting', 'specific'), ('reporting', 'specific', 'topic')]

>> POS Tags are: 
 [('An', 'DT'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('provides', 'VBZ'), ('reader', 'JJR'), ('state-of-the-art', 'JJ'), ('reporting', 'NN'), ('specific', 'JJ'), ('topic', 'NN')]

>> Noun Phrases are: 
 ['An effective literature review', 'state-of-the-art reporting', 'specific topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('provides', 'provid'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'report'), ('specific', 'specif'), ('topic', 'topic')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('provides', 'provid'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'report'), ('specific', 'specif'), ('topic', 'topic')]

>> Lemmatization: 
 [('An', 'An'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review'), ('provides', 'provides'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'reporting'), ('specific', 'specific'), ('topic', 'topic')]



========================================== PARAGRAPH 88 ===========================================

and also identifies any gaps in the current state of knowledge of that topic. Literature reviews have  

------------------- Sentence 1 -------------------

and also identifies any gaps in the current state of knowledge of that topic.

>> Tokens are: 
 ['also', 'identifies', 'gaps', 'current', 'state', 'knowledge', 'topic', '.']

>> Bigrams are: 
 [('also', 'identifies'), ('identifies', 'gaps'), ('gaps', 'current'), ('current', 'state'), ('state', 'knowledge'), ('knowledge', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('also', 'identifies', 'gaps'), ('identifies', 'gaps', 'current'), ('gaps', 'current', 'state'), ('current', 'state', 'knowledge'), ('state', 'knowledge', 'topic'), ('knowledge', 'topic', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('identifies', 'VBZ'), ('gaps', 'NNS'), ('current', 'JJ'), ('state', 'NN'), ('knowledge', 'NN'), ('topic', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['gaps', 'current state knowledge topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('identifies', 'identifi'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledg'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('identifies', 'identifi'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledg'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('identifies', 'identifies'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledge'), ('topic', 'topic'), ('.', '.')]


------------------- Sentence 2 -------------------

Literature reviews have

>> Tokens are: 
 ['Literature', 'reviews']

>> Bigrams are: 
 [('Literature', 'reviews')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Literature', 'NN'), ('reviews', 'NNS')]

>> Noun Phrases are: 
 ['Literature reviews']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('reviews', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('reviews', 'review')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('reviews', 'review')]



========================================== PARAGRAPH 89 ===========================================

played a decisive role in scholarship, particularly where scientists are looking for the new  

------------------- Sentence 1 -------------------

played a decisive role in scholarship, particularly where scientists are looking for the new

>> Tokens are: 
 ['played', 'decisive', 'role', 'scholarship', ',', 'particularly', 'scientists', 'looking', 'new']

>> Bigrams are: 
 [('played', 'decisive'), ('decisive', 'role'), ('role', 'scholarship'), ('scholarship', ','), (',', 'particularly'), ('particularly', 'scientists'), ('scientists', 'looking'), ('looking', 'new')]

>> Trigrams are: 
 [('played', 'decisive', 'role'), ('decisive', 'role', 'scholarship'), ('role', 'scholarship', ','), ('scholarship', ',', 'particularly'), (',', 'particularly', 'scientists'), ('particularly', 'scientists', 'looking'), ('scientists', 'looking', 'new')]

>> POS Tags are: 
 [('played', 'VBN'), ('decisive', 'JJ'), ('role', 'NN'), ('scholarship', 'NN'), (',', ','), ('particularly', 'RB'), ('scientists', 'NNS'), ('looking', 'VBG'), ('new', 'JJ')]

>> Noun Phrases are: 
 ['decisive role scholarship', 'scientists']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('played', 'play'), ('decisive', 'decis'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particularli'), ('scientists', 'scientist'), ('looking', 'look'), ('new', 'new')]

>> Stemming using Snowball Stemmer: 
 [('played', 'play'), ('decisive', 'decis'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particular'), ('scientists', 'scientist'), ('looking', 'look'), ('new', 'new')]

>> Lemmatization: 
 [('played', 'played'), ('decisive', 'decisive'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particularly'), ('scientists', 'scientist'), ('looking', 'looking'), ('new', 'new')]



========================================== PARAGRAPH 90 ===========================================

knowledge created by explaining and combining existing knowledge processes. The literature  

------------------- Sentence 1 -------------------

knowledge created by explaining and combining existing knowledge processes.

>> Tokens are: 
 ['knowledge', 'created', 'explaining', 'combining', 'existing', 'knowledge', 'processes', '.']

>> Bigrams are: 
 [('knowledge', 'created'), ('created', 'explaining'), ('explaining', 'combining'), ('combining', 'existing'), ('existing', 'knowledge'), ('knowledge', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('knowledge', 'created', 'explaining'), ('created', 'explaining', 'combining'), ('explaining', 'combining', 'existing'), ('combining', 'existing', 'knowledge'), ('existing', 'knowledge', 'processes'), ('knowledge', 'processes', '.')]

>> POS Tags are: 
 [('knowledge', 'NN'), ('created', 'VBD'), ('explaining', 'VBG'), ('combining', 'VBG'), ('existing', 'VBG'), ('knowledge', 'NN'), ('processes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['knowledge', 'knowledge processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('knowledge', 'knowledg'), ('created', 'creat'), ('explaining', 'explain'), ('combining', 'combin'), ('existing', 'exist'), ('knowledge', 'knowledg'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('knowledge', 'knowledg'), ('created', 'creat'), ('explaining', 'explain'), ('combining', 'combin'), ('existing', 'exist'), ('knowledge', 'knowledg'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('knowledge', 'knowledge'), ('created', 'created'), ('explaining', 'explaining'), ('combining', 'combining'), ('existing', 'existing'), ('knowledge', 'knowledge'), ('processes', 'process'), ('.', '.')]


------------------- Sentence 2 -------------------

The literature

>> Tokens are: 
 ['The', 'literature']

>> Bigrams are: 
 [('The', 'literature')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('literature', 'NN')]

>> Noun Phrases are: 
 ['The literature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('literature', 'literatur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('literature', 'literatur')]

>> Lemmatization: 
 [('The', 'The'), ('literature', 'literature')]



========================================== PARAGRAPH 91 ===========================================

search process used determines the quality of a literature review (Webster and Watson, 2002), and  

------------------- Sentence 1 -------------------

search process used determines the quality of a literature review (Webster and Watson, 2002), and

>> Tokens are: 
 ['search', 'process', 'used', 'determines', 'quality', 'literature', 'review', '(', 'Webster', 'Watson', ',', '2002', ')', ',']

>> Bigrams are: 
 [('search', 'process'), ('process', 'used'), ('used', 'determines'), ('determines', 'quality'), ('quality', 'literature'), ('literature', 'review'), ('review', '('), ('(', 'Webster'), ('Webster', 'Watson'), ('Watson', ','), (',', '2002'), ('2002', ')'), (')', ',')]

>> Trigrams are: 
 [('search', 'process', 'used'), ('process', 'used', 'determines'), ('used', 'determines', 'quality'), ('determines', 'quality', 'literature'), ('quality', 'literature', 'review'), ('literature', 'review', '('), ('review', '(', 'Webster'), ('(', 'Webster', 'Watson'), ('Webster', 'Watson', ','), ('Watson', ',', '2002'), (',', '2002', ')'), ('2002', ')', ',')]

>> POS Tags are: 
 [('search', 'NN'), ('process', 'NN'), ('used', 'VBN'), ('determines', 'NNS'), ('quality', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('(', '('), ('Webster', 'NNP'), ('Watson', 'NNP'), (',', ','), ('2002', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['search process', 'determines', 'quality literature review', 'Webster Watson']

>> Named Entities are: 
 [('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('search', 'search'), ('process', 'process'), ('used', 'use'), ('determines', 'determin'), ('quality', 'qualiti'), ('literature', 'literatur'), ('review', 'review'), ('(', '('), ('Webster', 'webster'), ('Watson', 'watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('search', 'search'), ('process', 'process'), ('used', 'use'), ('determines', 'determin'), ('quality', 'qualiti'), ('literature', 'literatur'), ('review', 'review'), ('(', '('), ('Webster', 'webster'), ('Watson', 'watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('search', 'search'), ('process', 'process'), ('used', 'used'), ('determines', 'determines'), ('quality', 'quality'), ('literature', 'literature'), ('review', 'review'), ('(', '('), ('Webster', 'Webster'), ('Watson', 'Watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 92 ===========================================

the literature review writing goal is to reconstruct available knowledge in a specific domain,  

------------------- Sentence 1 -------------------

the literature review writing goal is to reconstruct available knowledge in a specific domain,

>> Tokens are: 
 ['literature', 'review', 'writing', 'goal', 'reconstruct', 'available', 'knowledge', 'specific', 'domain', ',']

>> Bigrams are: 
 [('literature', 'review'), ('review', 'writing'), ('writing', 'goal'), ('goal', 'reconstruct'), ('reconstruct', 'available'), ('available', 'knowledge'), ('knowledge', 'specific'), ('specific', 'domain'), ('domain', ',')]

>> Trigrams are: 
 [('literature', 'review', 'writing'), ('review', 'writing', 'goal'), ('writing', 'goal', 'reconstruct'), ('goal', 'reconstruct', 'available'), ('reconstruct', 'available', 'knowledge'), ('available', 'knowledge', 'specific'), ('knowledge', 'specific', 'domain'), ('specific', 'domain', ',')]

>> POS Tags are: 
 [('literature', 'NN'), ('review', 'NN'), ('writing', 'VBG'), ('goal', 'NN'), ('reconstruct', 'NN'), ('available', 'JJ'), ('knowledge', 'NN'), ('specific', 'JJ'), ('domain', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['literature review', 'goal reconstruct', 'available knowledge', 'specific domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('writing', 'write'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'avail'), ('knowledge', 'knowledg'), ('specific', 'specif'), ('domain', 'domain'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('writing', 'write'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'avail'), ('knowledge', 'knowledg'), ('specific', 'specif'), ('domain', 'domain'), (',', ',')]

>> Lemmatization: 
 [('literature', 'literature'), ('review', 'review'), ('writing', 'writing'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'available'), ('knowledge', 'knowledge'), ('specific', 'specific'), ('domain', 'domain'), (',', ',')]



========================================== PARAGRAPH 93 ===========================================

offering access to subsequent literature analysis. The process should thus be described  

------------------- Sentence 1 -------------------

offering access to subsequent literature analysis.

>> Tokens are: 
 ['offering', 'access', 'subsequent', 'literature', 'analysis', '.']

>> Bigrams are: 
 [('offering', 'access'), ('access', 'subsequent'), ('subsequent', 'literature'), ('literature', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('offering', 'access', 'subsequent'), ('access', 'subsequent', 'literature'), ('subsequent', 'literature', 'analysis'), ('literature', 'analysis', '.')]

>> POS Tags are: 
 [('offering', 'VBG'), ('access', 'NN'), ('subsequent', 'JJ'), ('literature', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['access', 'subsequent literature analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('offering', 'offer'), ('access', 'access'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('offering', 'offer'), ('access', 'access'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('offering', 'offering'), ('access', 'access'), ('subsequent', 'subsequent'), ('literature', 'literature'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

The process should thus be described

>> Tokens are: 
 ['The', 'process', 'thus', 'described']

>> Bigrams are: 
 [('The', 'process'), ('process', 'thus'), ('thus', 'described')]

>> Trigrams are: 
 [('The', 'process', 'thus'), ('process', 'thus', 'described')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('thus', 'RB'), ('described', 'VBD')]

>> Noun Phrases are: 
 ['The process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('thus', 'thu'), ('described', 'describ')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('thus', 'thus'), ('described', 'describ')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('thus', 'thus'), ('described', 'described')]



========================================== PARAGRAPH 94 ===========================================

comprehensively, allowing the reader can assess the knowledge available within the relevant field  

------------------- Sentence 1 -------------------

comprehensively, allowing the reader can assess the knowledge available within the relevant field

>> Tokens are: 
 ['comprehensively', ',', 'allowing', 'reader', 'assess', 'knowledge', 'available', 'within', 'relevant', 'field']

>> Bigrams are: 
 [('comprehensively', ','), (',', 'allowing'), ('allowing', 'reader'), ('reader', 'assess'), ('assess', 'knowledge'), ('knowledge', 'available'), ('available', 'within'), ('within', 'relevant'), ('relevant', 'field')]

>> Trigrams are: 
 [('comprehensively', ',', 'allowing'), (',', 'allowing', 'reader'), ('allowing', 'reader', 'assess'), ('reader', 'assess', 'knowledge'), ('assess', 'knowledge', 'available'), ('knowledge', 'available', 'within'), ('available', 'within', 'relevant'), ('within', 'relevant', 'field')]

>> POS Tags are: 
 [('comprehensively', 'RB'), (',', ','), ('allowing', 'VBG'), ('reader', 'JJR'), ('assess', 'NN'), ('knowledge', 'NN'), ('available', 'JJ'), ('within', 'IN'), ('relevant', 'JJ'), ('field', 'NN')]

>> Noun Phrases are: 
 ['assess knowledge', 'relevant field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comprehensively', 'comprehens'), (',', ','), ('allowing', 'allow'), ('reader', 'reader'), ('assess', 'assess'), ('knowledge', 'knowledg'), ('available', 'avail'), ('within', 'within'), ('relevant', 'relev'), ('field', 'field')]

>> Stemming using Snowball Stemmer: 
 [('comprehensively', 'comprehens'), (',', ','), ('allowing', 'allow'), ('reader', 'reader'), ('assess', 'assess'), ('knowledge', 'knowledg'), ('available', 'avail'), ('within', 'within'), ('relevant', 'relev'), ('field', 'field')]

>> Lemmatization: 
 [('comprehensively', 'comprehensively'), (',', ','), ('allowing', 'allowing'), ('reader', 'reader'), ('assess', 'ass'), ('knowledge', 'knowledge'), ('available', 'available'), ('within', 'within'), ('relevant', 'relevant'), ('field', 'field')]



========================================== PARAGRAPH 95 ===========================================

in order to use the results in further research (Vom Brocke, J. et al., 2009).  

------------------- Sentence 1 -------------------

in order to use the results in further research (Vom Brocke, J. et al., 2009).

>> Tokens are: 
 ['order', 'use', 'results', 'research', '(', 'Vom', 'Brocke', ',', 'J.', 'et', 'al.', ',', '2009', ')', '.']

>> Bigrams are: 
 [('order', 'use'), ('use', 'results'), ('results', 'research'), ('research', '('), ('(', 'Vom'), ('Vom', 'Brocke'), ('Brocke', ','), (',', 'J.'), ('J.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('order', 'use', 'results'), ('use', 'results', 'research'), ('results', 'research', '('), ('research', '(', 'Vom'), ('(', 'Vom', 'Brocke'), ('Vom', 'Brocke', ','), ('Brocke', ',', 'J.'), (',', 'J.', 'et'), ('J.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2009'), (',', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('order', 'NN'), ('use', 'NN'), ('results', 'NNS'), ('research', 'NN'), ('(', '('), ('Vom', 'NNP'), ('Brocke', 'NNP'), (',', ','), ('J.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['order use results research', 'Vom Brocke', 'J.', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'Vom'), ('Brocke', 'Brocke'), (',', ','), ('J.', 'J.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 96 ===========================================

This thesis aims to present a literature review of work on big data analytics, a pertinent  

------------------- Sentence 1 -------------------

This thesis aims to present a literature review of work on big data analytics, a pertinent

>> Tokens are: 
 ['This', 'thesis', 'aims', 'present', 'literature', 'review', 'work', 'big', 'data', 'analytics', ',', 'pertinent']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'aims'), ('aims', 'present'), ('present', 'literature'), ('literature', 'review'), ('review', 'work'), ('work', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'pertinent')]

>> Trigrams are: 
 [('This', 'thesis', 'aims'), ('thesis', 'aims', 'present'), ('aims', 'present', 'literature'), ('present', 'literature', 'review'), ('literature', 'review', 'work'), ('review', 'work', 'big'), ('work', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'pertinent')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('aims', 'VBZ'), ('present', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('work', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('pertinent', 'NN')]

>> Noun Phrases are: 
 ['This thesis', 'present literature review work', 'big data analytics', 'pertinent']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literatur'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('pertinent', 'pertin')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literatur'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('pertinent', 'pertin')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literature'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('pertinent', 'pertinent')]



========================================== PARAGRAPH 97 ===========================================

contemporary topic which has been of importance since 2010 as one of the top technologies  

------------------- Sentence 1 -------------------

contemporary topic which has been of importance since 2010 as one of the top technologies

>> Tokens are: 
 ['contemporary', 'topic', 'importance', 'since', '2010', 'one', 'top', 'technologies']

>> Bigrams are: 
 [('contemporary', 'topic'), ('topic', 'importance'), ('importance', 'since'), ('since', '2010'), ('2010', 'one'), ('one', 'top'), ('top', 'technologies')]

>> Trigrams are: 
 [('contemporary', 'topic', 'importance'), ('topic', 'importance', 'since'), ('importance', 'since', '2010'), ('since', '2010', 'one'), ('2010', 'one', 'top'), ('one', 'top', 'technologies')]

>> POS Tags are: 
 [('contemporary', 'JJ'), ('topic', 'NN'), ('importance', 'NN'), ('since', 'IN'), ('2010', 'CD'), ('one', 'CD'), ('top', 'NN'), ('technologies', 'NNS')]

>> Noun Phrases are: 
 ['contemporary topic importance', 'top technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('contemporary', 'contemporari'), ('topic', 'topic'), ('importance', 'import'), ('since', 'sinc'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technolog')]

>> Stemming using Snowball Stemmer: 
 [('contemporary', 'contemporari'), ('topic', 'topic'), ('importance', 'import'), ('since', 'sinc'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technolog')]

>> Lemmatization: 
 [('contemporary', 'contemporary'), ('topic', 'topic'), ('importance', 'importance'), ('since', 'since'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technology')]



========================================== PARAGRAPH 98 ===========================================

suggested to solve multiple academic, industrial, and societal problems. In addition, this work  

------------------- Sentence 1 -------------------

suggested to solve multiple academic, industrial, and societal problems.

>> Tokens are: 
 ['suggested', 'solve', 'multiple', 'academic', ',', 'industrial', ',', 'societal', 'problems', '.']

>> Bigrams are: 
 [('suggested', 'solve'), ('solve', 'multiple'), ('multiple', 'academic'), ('academic', ','), (',', 'industrial'), ('industrial', ','), (',', 'societal'), ('societal', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('suggested', 'solve', 'multiple'), ('solve', 'multiple', 'academic'), ('multiple', 'academic', ','), ('academic', ',', 'industrial'), (',', 'industrial', ','), ('industrial', ',', 'societal'), (',', 'societal', 'problems'), ('societal', 'problems', '.')]

>> POS Tags are: 
 [('suggested', 'VBN'), ('solve', 'JJ'), ('multiple', 'JJ'), ('academic', 'JJ'), (',', ','), ('industrial', 'JJ'), (',', ','), ('societal', 'JJ'), ('problems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['societal problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('suggested', 'suggest'), ('solve', 'solv'), ('multiple', 'multipl'), ('academic', 'academ'), (',', ','), ('industrial', 'industri'), (',', ','), ('societal', 'societ'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('suggested', 'suggest'), ('solve', 'solv'), ('multiple', 'multipl'), ('academic', 'academ'), (',', ','), ('industrial', 'industri'), (',', ','), ('societal', 'societ'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('suggested', 'suggested'), ('solve', 'solve'), ('multiple', 'multiple'), ('academic', 'academic'), (',', ','), ('industrial', 'industrial'), (',', ','), ('societal', 'societal'), ('problems', 'problem'), ('.', '.')]


------------------- Sentence 2 -------------------

In addition, this work

>> Tokens are: 
 ['In', 'addition', ',', 'work']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'work')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'work')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('work', 'NN')]

>> Noun Phrases are: 
 ['addition', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('work', 'work')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('work', 'work')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('work', 'work')]



========================================== PARAGRAPH 99 ===========================================

explains and analyses different analytic methods and tools that have been applied to big data.   

------------------- Sentence 1 -------------------

explains and analyses different analytic methods and tools that have been applied to big data.

>> Tokens are: 
 ['explains', 'analyses', 'different', 'analytic', 'methods', 'tools', 'applied', 'big', 'data', '.']

>> Bigrams are: 
 [('explains', 'analyses'), ('analyses', 'different'), ('different', 'analytic'), ('analytic', 'methods'), ('methods', 'tools'), ('tools', 'applied'), ('applied', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('explains', 'analyses', 'different'), ('analyses', 'different', 'analytic'), ('different', 'analytic', 'methods'), ('analytic', 'methods', 'tools'), ('methods', 'tools', 'applied'), ('tools', 'applied', 'big'), ('applied', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('explains', 'NNS'), ('analyses', 'VBZ'), ('different', 'JJ'), ('analytic', 'JJ'), ('methods', 'NNS'), ('tools', 'NNS'), ('applied', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['explains', 'different analytic methods tools', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('explains', 'explain'), ('analyses', 'analys'), ('different', 'differ'), ('analytic', 'analyt'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('explains', 'explain'), ('analyses', 'analys'), ('different', 'differ'), ('analytic', 'analyt'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('explains', 'explains'), ('analyses', 'analysis'), ('different', 'different'), ('analytic', 'analytic'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'applied'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 100 ===========================================

Recently, the focus has been on big data in the research and industrial domains, which has been  

------------------- Sentence 1 -------------------

Recently, the focus has been on big data in the research and industrial domains, which has been

>> Tokens are: 
 ['Recently', ',', 'focus', 'big', 'data', 'research', 'industrial', 'domains', ',']

>> Bigrams are: 
 [('Recently', ','), (',', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'research'), ('research', 'industrial'), ('industrial', 'domains'), ('domains', ',')]

>> Trigrams are: 
 [('Recently', ',', 'focus'), (',', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'research'), ('data', 'research', 'industrial'), ('research', 'industrial', 'domains'), ('industrial', 'domains', ',')]

>> POS Tags are: 
 [('Recently', 'RB'), (',', ','), ('focus', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('research', 'NN'), ('industrial', 'JJ'), ('domains', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['focus', 'big data research', 'industrial domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recently', 'recent'), (',', ','), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industri'), ('domains', 'domain'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Recently', 'recent'), (',', ','), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industri'), ('domains', 'domain'), (',', ',')]

>> Lemmatization: 
 [('Recently', 'Recently'), (',', ','), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industrial'), ('domains', 'domain'), (',', ',')]



========================================== PARAGRAPH 101 ===========================================

reflected in the sheer number of papers, conferences, and white papers discussing big data analytic  

------------------- Sentence 1 -------------------

reflected in the sheer number of papers, conferences, and white papers discussing big data analytic

>> Tokens are: 
 ['reflected', 'sheer', 'number', 'papers', ',', 'conferences', ',', 'white', 'papers', 'discussing', 'big', 'data', 'analytic']

>> Bigrams are: 
 [('reflected', 'sheer'), ('sheer', 'number'), ('number', 'papers'), ('papers', ','), (',', 'conferences'), ('conferences', ','), (',', 'white'), ('white', 'papers'), ('papers', 'discussing'), ('discussing', 'big'), ('big', 'data'), ('data', 'analytic')]

>> Trigrams are: 
 [('reflected', 'sheer', 'number'), ('sheer', 'number', 'papers'), ('number', 'papers', ','), ('papers', ',', 'conferences'), (',', 'conferences', ','), ('conferences', ',', 'white'), (',', 'white', 'papers'), ('white', 'papers', 'discussing'), ('papers', 'discussing', 'big'), ('discussing', 'big', 'data'), ('big', 'data', 'analytic')]

>> POS Tags are: 
 [('reflected', 'VBN'), ('sheer', 'NN'), ('number', 'NN'), ('papers', 'NNS'), (',', ','), ('conferences', 'NNS'), (',', ','), ('white', 'JJ'), ('papers', 'NNS'), ('discussing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ')]

>> Noun Phrases are: 
 ['sheer number papers', 'conferences', 'white papers', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reflected', 'reflect'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'confer'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('reflected', 'reflect'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'confer'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt')]

>> Lemmatization: 
 [('reflected', 'reflected'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'conference'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discussing'), ('big', 'big'), ('data', 'data'), ('analytic', 'analytic')]



========================================== PARAGRAPH 102 ===========================================

tools, methods, and applications that have been published. In writing this literature review, the  

------------------- Sentence 1 -------------------

tools, methods, and applications that have been published.

>> Tokens are: 
 ['tools', ',', 'methods', ',', 'applications', 'published', '.']

>> Bigrams are: 
 [('tools', ','), (',', 'methods'), ('methods', ','), (',', 'applications'), ('applications', 'published'), ('published', '.')]

>> Trigrams are: 
 [('tools', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'applications'), (',', 'applications', 'published'), ('applications', 'published', '.')]

>> POS Tags are: 
 [('tools', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('applications', 'NNS'), ('published', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['tools', 'methods', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'applic'), ('published', 'publish'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'applic'), ('published', 'publish'), ('.', '.')]

>> Lemmatization: 
 [('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'application'), ('published', 'published'), ('.', '.')]


------------------- Sentence 2 -------------------

In writing this literature review, the

>> Tokens are: 
 ['In', 'writing', 'literature', 'review', ',']

>> Bigrams are: 
 [('In', 'writing'), ('writing', 'literature'), ('literature', 'review'), ('review', ',')]

>> Trigrams are: 
 [('In', 'writing', 'literature'), ('writing', 'literature', 'review'), ('literature', 'review', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('writing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('writing', 'writing'), ('literature', 'literature'), ('review', 'review'), (',', ',')]



========================================== PARAGRAPH 103 ===========================================

same procedure was followed as in most commonly used literature reviews in information systems,  

------------------- Sentence 1 -------------------

same procedure was followed as in most commonly used literature reviews in information systems,

>> Tokens are: 
 ['procedure', 'followed', 'commonly', 'used', 'literature', 'reviews', 'information', 'systems', ',']

>> Bigrams are: 
 [('procedure', 'followed'), ('followed', 'commonly'), ('commonly', 'used'), ('used', 'literature'), ('literature', 'reviews'), ('reviews', 'information'), ('information', 'systems'), ('systems', ',')]

>> Trigrams are: 
 [('procedure', 'followed', 'commonly'), ('followed', 'commonly', 'used'), ('commonly', 'used', 'literature'), ('used', 'literature', 'reviews'), ('literature', 'reviews', 'information'), ('reviews', 'information', 'systems'), ('information', 'systems', ',')]

>> POS Tags are: 
 [('procedure', 'NN'), ('followed', 'VBD'), ('commonly', 'RB'), ('used', 'VBN'), ('literature', 'NN'), ('reviews', 'VBZ'), ('information', 'NN'), ('systems', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['procedure', 'literature', 'information systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('procedure', 'procedur'), ('followed', 'follow'), ('commonly', 'commonli'), ('used', 'use'), ('literature', 'literatur'), ('reviews', 'review'), ('information', 'inform'), ('systems', 'system'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('procedure', 'procedur'), ('followed', 'follow'), ('commonly', 'common'), ('used', 'use'), ('literature', 'literatur'), ('reviews', 'review'), ('information', 'inform'), ('systems', 'system'), (',', ',')]

>> Lemmatization: 
 [('procedure', 'procedure'), ('followed', 'followed'), ('commonly', 'commonly'), ('used', 'used'), ('literature', 'literature'), ('reviews', 'review'), ('information', 'information'), ('systems', 'system'), (',', ',')]



========================================== PARAGRAPH 104 ===========================================

such as Vom Brocke et al. (2009). The papers were chosen based on both novelty and discussion  

------------------- Sentence 1 -------------------

such as Vom Brocke et al.

>> Tokens are: 
 ['Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom'), ('ORGANIZATION', 'Brocke')] 

>> Stemming using Porter Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2009).

>> Tokens are: 
 ['(', '2009', ')', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The papers were chosen based on both novelty and discussion

>> Tokens are: 
 ['The', 'papers', 'chosen', 'based', 'novelty', 'discussion']

>> Bigrams are: 
 [('The', 'papers'), ('papers', 'chosen'), ('chosen', 'based'), ('based', 'novelty'), ('novelty', 'discussion')]

>> Trigrams are: 
 [('The', 'papers', 'chosen'), ('papers', 'chosen', 'based'), ('chosen', 'based', 'novelty'), ('based', 'novelty', 'discussion')]

>> POS Tags are: 
 [('The', 'DT'), ('papers', 'NNS'), ('chosen', 'VBP'), ('based', 'VBN'), ('novelty', 'NN'), ('discussion', 'NN')]

>> Noun Phrases are: 
 ['The papers', 'novelty discussion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('novelty', 'novelti'), ('discussion', 'discuss')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('novelty', 'novelti'), ('discussion', 'discuss')]

>> Lemmatization: 
 [('The', 'The'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'based'), ('novelty', 'novelty'), ('discussion', 'discussion')]



========================================== PARAGRAPH 105 ===========================================

of important topics related to big data and big data analytics in manners that serve the purpose of  

------------------- Sentence 1 -------------------

of important topics related to big data and big data analytics in manners that serve the purpose of

>> Tokens are: 
 ['important', 'topics', 'related', 'big', 'data', 'big', 'data', 'analytics', 'manners', 'serve', 'purpose']

>> Bigrams are: 
 [('important', 'topics'), ('topics', 'related'), ('related', 'big'), ('big', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'manners'), ('manners', 'serve'), ('serve', 'purpose')]

>> Trigrams are: 
 [('important', 'topics', 'related'), ('topics', 'related', 'big'), ('related', 'big', 'data'), ('big', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'manners'), ('analytics', 'manners', 'serve'), ('manners', 'serve', 'purpose')]

>> POS Tags are: 
 [('important', 'JJ'), ('topics', 'NNS'), ('related', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('manners', 'NNS'), ('serve', 'VBP'), ('purpose', 'NN')]

>> Noun Phrases are: 
 ['important topics', 'related big data', 'big data analytics manners', 'purpose']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('topics', 'topic'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('manners', 'manner'), ('serve', 'serv'), ('purpose', 'purpos')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('topics', 'topic'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('manners', 'manner'), ('serve', 'serv'), ('purpose', 'purpos')]

>> Lemmatization: 
 [('important', 'important'), ('topics', 'topic'), ('related', 'related'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('manners', 'manner'), ('serve', 'serve'), ('purpose', 'purpose')]



========================================== PARAGRAPH 106 ===========================================

the research. The selected publications thus focus on big data analytics during the period 2011 to  

------------------- Sentence 1 -------------------

the research.

>> Tokens are: 
 ['research', '.']

>> Bigrams are: 
 [('research', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('research', 'research'), ('.', '.')]


------------------- Sentence 2 -------------------

The selected publications thus focus on big data analytics during the period 2011 to

>> Tokens are: 
 ['The', 'selected', 'publications', 'thus', 'focus', 'big', 'data', 'analytics', 'period', '2011']

>> Bigrams are: 
 [('The', 'selected'), ('selected', 'publications'), ('publications', 'thus'), ('thus', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'period'), ('period', '2011')]

>> Trigrams are: 
 [('The', 'selected', 'publications'), ('selected', 'publications', 'thus'), ('publications', 'thus', 'focus'), ('thus', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'period'), ('analytics', 'period', '2011')]

>> POS Tags are: 
 [('The', 'DT'), ('selected', 'VBN'), ('publications', 'NNS'), ('thus', 'RB'), ('focus', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('period', 'NN'), ('2011', 'CD')]

>> Noun Phrases are: 
 ['publications', 'big data analytics period']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selected', 'select'), ('publications', 'public'), ('thus', 'thu'), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('period', 'period'), ('2011', '2011')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selected', 'select'), ('publications', 'public'), ('thus', 'thus'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('period', 'period'), ('2011', '2011')]

>> Lemmatization: 
 [('The', 'The'), ('selected', 'selected'), ('publications', 'publication'), ('thus', 'thus'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('period', 'period'), ('2011', '2011')]



========================================== PARAGRAPH 107 ===========================================

2019. Most of the references were selected from prestigious journals or conferences, with a limited 

------------------- Sentence 1 -------------------

2019.

>> Tokens are: 
 ['2019', '.']

>> Bigrams are: 
 [('2019', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Most of the references were selected from prestigious journals or conferences, with a limited

>> Tokens are: 
 ['Most', 'references', 'selected', 'prestigious', 'journals', 'conferences', ',', 'limited']

>> Bigrams are: 
 [('Most', 'references'), ('references', 'selected'), ('selected', 'prestigious'), ('prestigious', 'journals'), ('journals', 'conferences'), ('conferences', ','), (',', 'limited')]

>> Trigrams are: 
 [('Most', 'references', 'selected'), ('references', 'selected', 'prestigious'), ('selected', 'prestigious', 'journals'), ('prestigious', 'journals', 'conferences'), ('journals', 'conferences', ','), ('conferences', ',', 'limited')]

>> POS Tags are: 
 [('Most', 'JJS'), ('references', 'NNS'), ('selected', 'VBN'), ('prestigious', 'JJ'), ('journals', 'NNS'), ('conferences', 'NNS'), (',', ','), ('limited', 'VBD')]

>> Noun Phrases are: 
 ['references', 'prestigious journals conferences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('references', 'refer'), ('selected', 'select'), ('prestigious', 'prestigi'), ('journals', 'journal'), ('conferences', 'confer'), (',', ','), ('limited', 'limit')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('references', 'refer'), ('selected', 'select'), ('prestigious', 'prestigi'), ('journals', 'journal'), ('conferences', 'confer'), (',', ','), ('limited', 'limit')]

>> Lemmatization: 
 [('Most', 'Most'), ('references', 'reference'), ('selected', 'selected'), ('prestigious', 'prestigious'), ('journals', 'journal'), ('conferences', 'conference'), (',', ','), ('limited', 'limited')]



========================================== PARAGRAPH 108 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 109 ===========================================

2  

------------------- Sentence 1 -------------------

2

>> Tokens are: 
 ['2']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('2', '2')]

>> Lemmatization: 
 [('2', '2')]



========================================== PARAGRAPH 110 ===========================================

  


========================================== PARAGRAPH 111 ===========================================

number of white papers included; the search engines used included LTU library, Google Scholar,  

------------------- Sentence 1 -------------------

number of white papers included; the search engines used included LTU library, Google Scholar,

>> Tokens are: 
 ['number', 'white', 'papers', 'included', ';', 'search', 'engines', 'used', 'included', 'LTU', 'library', ',', 'Google', 'Scholar', ',']

>> Bigrams are: 
 [('number', 'white'), ('white', 'papers'), ('papers', 'included'), ('included', ';'), (';', 'search'), ('search', 'engines'), ('engines', 'used'), ('used', 'included'), ('included', 'LTU'), ('LTU', 'library'), ('library', ','), (',', 'Google'), ('Google', 'Scholar'), ('Scholar', ',')]

>> Trigrams are: 
 [('number', 'white', 'papers'), ('white', 'papers', 'included'), ('papers', 'included', ';'), ('included', ';', 'search'), (';', 'search', 'engines'), ('search', 'engines', 'used'), ('engines', 'used', 'included'), ('used', 'included', 'LTU'), ('included', 'LTU', 'library'), ('LTU', 'library', ','), ('library', ',', 'Google'), (',', 'Google', 'Scholar'), ('Google', 'Scholar', ',')]

>> POS Tags are: 
 [('number', 'NN'), ('white', 'JJ'), ('papers', 'NNS'), ('included', 'VBD'), (';', ':'), ('search', 'NN'), ('engines', 'NNS'), ('used', 'VBN'), ('included', 'VBD'), ('LTU', 'NNP'), ('library', 'NN'), (',', ','), ('Google', 'NNP'), ('Scholar', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['number', 'white papers', 'search engines', 'LTU library', 'Google Scholar']

>> Named Entities are: 
 [('ORGANIZATION', 'LTU'), ('PERSON', 'Google Scholar')] 

>> Stemming using Porter Stemmer: 
 [('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'includ'), (';', ';'), ('search', 'search'), ('engines', 'engin'), ('used', 'use'), ('included', 'includ'), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'includ'), (';', ';'), ('search', 'search'), ('engines', 'engin'), ('used', 'use'), ('included', 'includ'), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ',')]

>> Lemmatization: 
 [('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'included'), (';', ';'), ('search', 'search'), ('engines', 'engine'), ('used', 'used'), ('included', 'included'), ('LTU', 'LTU'), ('library', 'library'), (',', ','), ('Google', 'Google'), ('Scholar', 'Scholar'), (',', ',')]



========================================== PARAGRAPH 112 ===========================================

IEEE Xplore, Springers, ACM DL, Websco, Emerald, and Elsevier.  

------------------- Sentence 1 -------------------

IEEE Xplore, Springers, ACM DL, Websco, Emerald, and Elsevier.

>> Tokens are: 
 ['IEEE', 'Xplore', ',', 'Springers', ',', 'ACM', 'DL', ',', 'Websco', ',', 'Emerald', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('IEEE', 'Xplore'), ('Xplore', ','), (',', 'Springers'), ('Springers', ','), (',', 'ACM'), ('ACM', 'DL'), ('DL', ','), (',', 'Websco'), ('Websco', ','), (',', 'Emerald'), ('Emerald', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('IEEE', 'Xplore', ','), ('Xplore', ',', 'Springers'), (',', 'Springers', ','), ('Springers', ',', 'ACM'), (',', 'ACM', 'DL'), ('ACM', 'DL', ','), ('DL', ',', 'Websco'), (',', 'Websco', ','), ('Websco', ',', 'Emerald'), (',', 'Emerald', ','), ('Emerald', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Xplore', 'NNP'), (',', ','), ('Springers', 'NNP'), (',', ','), ('ACM', 'NNP'), ('DL', 'NNP'), (',', ','), ('Websco', 'NNP'), (',', ','), ('Emerald', 'NNP'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Xplore', 'Springers', 'ACM DL', 'Websco', 'Emerald', 'Elsevier']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('GPE', 'Xplore'), ('GPE', 'Springers'), ('ORGANIZATION', 'ACM'), ('GPE', 'Websco'), ('PERSON', 'Emerald'), ('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Springers', 'springer'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('Websco', 'websco'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Springers', 'springer'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('Websco', 'websco'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Xplore', 'Xplore'), (',', ','), ('Springers', 'Springers'), (',', ','), ('ACM', 'ACM'), ('DL', 'DL'), (',', ','), ('Websco', 'Websco'), (',', ','), ('Emerald', 'Emerald'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



========================================== PARAGRAPH 113 ===========================================

  


========================================== PARAGRAPH 114 ===========================================

2. Research Question  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Research Question

>> Tokens are: 
 ['Research', 'Question']

>> Bigrams are: 
 [('Research', 'Question')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Research', 'NNP'), ('Question', 'NN')]

>> Noun Phrases are: 
 ['Research Question']

>> Named Entities are: 
 [('GPE', 'Research')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Question', 'question')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Question', 'question')]

>> Lemmatization: 
 [('Research', 'Research'), ('Question', 'Question')]



========================================== PARAGRAPH 115 ===========================================

In order to develop a general overview of the topic, a literature study is an appropriate way to  

------------------- Sentence 1 -------------------

In order to develop a general overview of the topic, a literature study is an appropriate way to

>> Tokens are: 
 ['In', 'order', 'develop', 'general', 'overview', 'topic', ',', 'literature', 'study', 'appropriate', 'way']

>> Bigrams are: 
 [('In', 'order'), ('order', 'develop'), ('develop', 'general'), ('general', 'overview'), ('overview', 'topic'), ('topic', ','), (',', 'literature'), ('literature', 'study'), ('study', 'appropriate'), ('appropriate', 'way')]

>> Trigrams are: 
 [('In', 'order', 'develop'), ('order', 'develop', 'general'), ('develop', 'general', 'overview'), ('general', 'overview', 'topic'), ('overview', 'topic', ','), ('topic', ',', 'literature'), (',', 'literature', 'study'), ('literature', 'study', 'appropriate'), ('study', 'appropriate', 'way')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('develop', 'VB'), ('general', 'JJ'), ('overview', 'NN'), ('topic', 'NN'), (',', ','), ('literature', 'NN'), ('study', 'NN'), ('appropriate', 'JJ'), ('way', 'NN')]

>> Noun Phrases are: 
 ['order', 'general overview topic', 'literature study', 'appropriate way']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('develop', 'develop'), ('general', 'gener'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literatur'), ('study', 'studi'), ('appropriate', 'appropri'), ('way', 'way')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('develop', 'develop'), ('general', 'general'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literatur'), ('study', 'studi'), ('appropriate', 'appropri'), ('way', 'way')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('develop', 'develop'), ('general', 'general'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literature'), ('study', 'study'), ('appropriate', 'appropriate'), ('way', 'way')]



========================================== PARAGRAPH 116 ===========================================

identify the state-of-the-art in big data analytics. Big data is important because it is one of the main  

------------------- Sentence 1 -------------------

identify the state-of-the-art in big data analytics.

>> Tokens are: 
 ['identify', 'state-of-the-art', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('identify', 'state-of-the-art'), ('state-of-the-art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('identify', 'state-of-the-art', 'big'), ('state-of-the-art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('identify', 'VB'), ('state-of-the-art', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['state-of-the-art big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('identify', 'identifi'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('identify', 'identifi'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('identify', 'identify'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data is important because it is one of the main

>> Tokens are: 
 ['Big', 'data', 'important', 'one', 'main']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'important'), ('important', 'one'), ('one', 'main')]

>> Trigrams are: 
 [('Big', 'data', 'important'), ('data', 'important', 'one'), ('important', 'one', 'main')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('important', 'JJ'), ('one', 'CD'), ('main', 'JJ')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('important', 'import'), ('one', 'one'), ('main', 'main')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('important', 'import'), ('one', 'one'), ('main', 'main')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('important', 'important'), ('one', 'one'), ('main', 'main')]



========================================== PARAGRAPH 117 ===========================================

technologies currently used to solve industrial issues and to provide roadmaps for research and  

------------------- Sentence 1 -------------------

technologies currently used to solve industrial issues and to provide roadmaps for research and

>> Tokens are: 
 ['technologies', 'currently', 'used', 'solve', 'industrial', 'issues', 'provide', 'roadmaps', 'research']

>> Bigrams are: 
 [('technologies', 'currently'), ('currently', 'used'), ('used', 'solve'), ('solve', 'industrial'), ('industrial', 'issues'), ('issues', 'provide'), ('provide', 'roadmaps'), ('roadmaps', 'research')]

>> Trigrams are: 
 [('technologies', 'currently', 'used'), ('currently', 'used', 'solve'), ('used', 'solve', 'industrial'), ('solve', 'industrial', 'issues'), ('industrial', 'issues', 'provide'), ('issues', 'provide', 'roadmaps'), ('provide', 'roadmaps', 'research')]

>> POS Tags are: 
 [('technologies', 'NNS'), ('currently', 'RB'), ('used', 'VBN'), ('solve', 'VB'), ('industrial', 'JJ'), ('issues', 'NNS'), ('provide', 'VBP'), ('roadmaps', 'NNS'), ('research', 'NN')]

>> Noun Phrases are: 
 ['technologies', 'industrial issues', 'roadmaps research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('technologies', 'technolog'), ('currently', 'current'), ('used', 'use'), ('solve', 'solv'), ('industrial', 'industri'), ('issues', 'issu'), ('provide', 'provid'), ('roadmaps', 'roadmap'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('technologies', 'technolog'), ('currently', 'current'), ('used', 'use'), ('solve', 'solv'), ('industrial', 'industri'), ('issues', 'issu'), ('provide', 'provid'), ('roadmaps', 'roadmap'), ('research', 'research')]

>> Lemmatization: 
 [('technologies', 'technology'), ('currently', 'currently'), ('used', 'used'), ('solve', 'solve'), ('industrial', 'industrial'), ('issues', 'issue'), ('provide', 'provide'), ('roadmaps', 'roadmaps'), ('research', 'research')]



========================================== PARAGRAPH 118 ===========================================

education. The question thus becomes What is the state of the art in big data analytics?  

------------------- Sentence 1 -------------------

education.

>> Tokens are: 
 ['education', '.']

>> Bigrams are: 
 [('education', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('education', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['education']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('education', 'educ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('education', 'educ'), ('.', '.')]

>> Lemmatization: 
 [('education', 'education'), ('.', '.')]


------------------- Sentence 2 -------------------

The question thus becomes What is the state of the art in big data analytics?

>> Tokens are: 
 ['The', 'question', 'thus', 'becomes', 'What', 'state', 'art', 'big', 'data', 'analytics', '?']

>> Bigrams are: 
 [('The', 'question'), ('question', 'thus'), ('thus', 'becomes'), ('becomes', 'What'), ('What', 'state'), ('state', 'art'), ('art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '?')]

>> Trigrams are: 
 [('The', 'question', 'thus'), ('question', 'thus', 'becomes'), ('thus', 'becomes', 'What'), ('becomes', 'What', 'state'), ('What', 'state', 'art'), ('state', 'art', 'big'), ('art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '?')]

>> POS Tags are: 
 [('The', 'DT'), ('question', 'NN'), ('thus', 'RB'), ('becomes', 'VBZ'), ('What', 'WP'), ('state', 'NN'), ('art', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('?', '.')]

>> Noun Phrases are: 
 ['The question', 'state art', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('question', 'question'), ('thus', 'thu'), ('becomes', 'becom'), ('What', 'what'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('question', 'question'), ('thus', 'thus'), ('becomes', 'becom'), ('What', 'what'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('?', '?')]

>> Lemmatization: 
 [('The', 'The'), ('question', 'question'), ('thus', 'thus'), ('becomes', 'becomes'), ('What', 'What'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('?', '?')]



========================================== PARAGRAPH 119 ===========================================

This research question is important to academia due to a lack of similar studies addressing the state  

------------------- Sentence 1 -------------------

This research question is important to academia due to a lack of similar studies addressing the state

>> Tokens are: 
 ['This', 'research', 'question', 'important', 'academia', 'due', 'lack', 'similar', 'studies', 'addressing', 'state']

>> Bigrams are: 
 [('This', 'research'), ('research', 'question'), ('question', 'important'), ('important', 'academia'), ('academia', 'due'), ('due', 'lack'), ('lack', 'similar'), ('similar', 'studies'), ('studies', 'addressing'), ('addressing', 'state')]

>> Trigrams are: 
 [('This', 'research', 'question'), ('research', 'question', 'important'), ('question', 'important', 'academia'), ('important', 'academia', 'due'), ('academia', 'due', 'lack'), ('due', 'lack', 'similar'), ('lack', 'similar', 'studies'), ('similar', 'studies', 'addressing'), ('studies', 'addressing', 'state')]

>> POS Tags are: 
 [('This', 'DT'), ('research', 'NN'), ('question', 'NN'), ('important', 'JJ'), ('academia', 'NN'), ('due', 'JJ'), ('lack', 'NN'), ('similar', 'JJ'), ('studies', 'NNS'), ('addressing', 'VBG'), ('state', 'NN')]

>> Noun Phrases are: 
 ['This research question', 'important academia', 'due lack', 'similar studies', 'state']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('research', 'research'), ('question', 'question'), ('important', 'import'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'studi'), ('addressing', 'address'), ('state', 'state')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('research', 'research'), ('question', 'question'), ('important', 'import'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'studi'), ('addressing', 'address'), ('state', 'state')]

>> Lemmatization: 
 [('This', 'This'), ('research', 'research'), ('question', 'question'), ('important', 'important'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'study'), ('addressing', 'addressing'), ('state', 'state')]



========================================== PARAGRAPH 120 ===========================================

of the art in big data analytics. To the best of the researcher’s knowledge, no similar research has  

------------------- Sentence 1 -------------------

of the art in big data analytics.

>> Tokens are: 
 ['art', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('art', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['art', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

To the best of the researcher’s knowledge, no similar research has

>> Tokens are: 
 ['To', 'best', 'researcher', '’', 'knowledge', ',', 'similar', 'research']

>> Bigrams are: 
 [('To', 'best'), ('best', 'researcher'), ('researcher', '’'), ('’', 'knowledge'), ('knowledge', ','), (',', 'similar'), ('similar', 'research')]

>> Trigrams are: 
 [('To', 'best', 'researcher'), ('best', 'researcher', '’'), ('researcher', '’', 'knowledge'), ('’', 'knowledge', ','), ('knowledge', ',', 'similar'), (',', 'similar', 'research')]

>> POS Tags are: 
 [('To', 'TO'), ('best', 'VB'), ('researcher', 'NN'), ('’', 'NNP'), ('knowledge', 'NN'), (',', ','), ('similar', 'JJ'), ('research', 'NN')]

>> Noun Phrases are: 
 ['researcher ’ knowledge', 'similar research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('best', 'best'), ('researcher', 'research'), ('’', '’'), ('knowledge', 'knowledg'), (',', ','), ('similar', 'similar'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('best', 'best'), ('researcher', 'research'), ('’', '’'), ('knowledge', 'knowledg'), (',', ','), ('similar', 'similar'), ('research', 'research')]

>> Lemmatization: 
 [('To', 'To'), ('best', 'best'), ('researcher', 'researcher'), ('’', '’'), ('knowledge', 'knowledge'), (',', ','), ('similar', 'similar'), ('research', 'research')]



========================================== PARAGRAPH 121 ===========================================

been conducted in recent years, despite big data analytics providing a basis for advancements at  

------------------- Sentence 1 -------------------

been conducted in recent years, despite big data analytics providing a basis for advancements at

>> Tokens are: 
 ['conducted', 'recent', 'years', ',', 'despite', 'big', 'data', 'analytics', 'providing', 'basis', 'advancements']

>> Bigrams are: 
 [('conducted', 'recent'), ('recent', 'years'), ('years', ','), (',', 'despite'), ('despite', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'providing'), ('providing', 'basis'), ('basis', 'advancements')]

>> Trigrams are: 
 [('conducted', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'despite'), (',', 'despite', 'big'), ('despite', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'providing'), ('analytics', 'providing', 'basis'), ('providing', 'basis', 'advancements')]

>> POS Tags are: 
 [('conducted', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('despite', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('providing', 'VBG'), ('basis', 'NN'), ('advancements', 'NNS')]

>> Noun Phrases are: 
 ['recent years', 'big data analytics', 'basis advancements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conducted', 'conduct'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('providing', 'provid'), ('basis', 'basi'), ('advancements', 'advanc')]

>> Stemming using Snowball Stemmer: 
 [('conducted', 'conduct'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('providing', 'provid'), ('basis', 'basi'), ('advancements', 'advanc')]

>> Lemmatization: 
 [('conducted', 'conducted'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despite'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('providing', 'providing'), ('basis', 'basis'), ('advancements', 'advancement')]



========================================== PARAGRAPH 122 ===========================================

both technological and scientific levels (Nafus and Sherman, 2014; Elgendy and Elragal, 2014).  

------------------- Sentence 1 -------------------

both technological and scientific levels (Nafus and Sherman, 2014; Elgendy and Elragal, 2014).

>> Tokens are: 
 ['technological', 'scientific', 'levels', '(', 'Nafus', 'Sherman', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('technological', 'scientific'), ('scientific', 'levels'), ('levels', '('), ('(', 'Nafus'), ('Nafus', 'Sherman'), ('Sherman', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('technological', 'scientific', 'levels'), ('scientific', 'levels', '('), ('levels', '(', 'Nafus'), ('(', 'Nafus', 'Sherman'), ('Nafus', 'Sherman', ','), ('Sherman', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('technological', 'JJ'), ('scientific', 'JJ'), ('levels', 'NNS'), ('(', '('), ('Nafus', 'NNP'), ('Sherman', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['technological scientific levels', 'Nafus Sherman', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Nafus Sherman'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('technological', 'technolog'), ('scientific', 'scientif'), ('levels', 'level'), ('(', '('), ('Nafus', 'nafu'), ('Sherman', 'sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('technological', 'technolog'), ('scientific', 'scientif'), ('levels', 'level'), ('(', '('), ('Nafus', 'nafus'), ('Sherman', 'sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('technological', 'technological'), ('scientific', 'scientific'), ('levels', 'level'), ('(', '('), ('Nafus', 'Nafus'), ('Sherman', 'Sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 123 ===========================================

      


========================================== PARAGRAPH 124 ===========================================

• A literature review on big data analytics shows what is already known and what should be  known;  

------------------- Sentence 1 -------------------

• A literature review on big data analytics shows what is already known and what should be  known;

>> Tokens are: 
 ['•', 'A', 'literature', 'review', 'big', 'data', 'analytics', 'shows', 'already', 'known', 'known', ';']

>> Bigrams are: 
 [('•', 'A'), ('A', 'literature'), ('literature', 'review'), ('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'shows'), ('shows', 'already'), ('already', 'known'), ('known', 'known'), ('known', ';')]

>> Trigrams are: 
 [('•', 'A', 'literature'), ('A', 'literature', 'review'), ('literature', 'review', 'big'), ('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'shows'), ('analytics', 'shows', 'already'), ('shows', 'already', 'known'), ('already', 'known', 'known'), ('known', 'known', ';')]

>> POS Tags are: 
 [('•', 'VB'), ('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('shows', 'VBZ'), ('already', 'RB'), ('known', 'VBN'), ('known', 'VBN'), (';', ':')]

>> Noun Phrases are: 
 ['A literature review', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shows', 'show'), ('already', 'alreadi'), ('known', 'known'), ('known', 'known'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shows', 'show'), ('already', 'alreadi'), ('known', 'known'), ('known', 'known'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('shows', 'show'), ('already', 'already'), ('known', 'known'), ('known', 'known'), (';', ';')]



========================================== PARAGRAPH 125 ===========================================

• It identifies research gaps in big data analytics by noting both “hot” topics that have already  been studied extensively and solved problems in big data analytics, and those problems  

------------------- Sentence 1 -------------------

• It identifies research gaps in big data analytics by noting both “hot” topics that have already  been studied extensively and solved problems in big data analytics, and those problems

>> Tokens are: 
 ['•', 'It', 'identifies', 'research', 'gaps', 'big', 'data', 'analytics', 'noting', '“', 'hot', '”', 'topics', 'already', 'studied', 'extensively', 'solved', 'problems', 'big', 'data', 'analytics', ',', 'problems']

>> Bigrams are: 
 [('•', 'It'), ('It', 'identifies'), ('identifies', 'research'), ('research', 'gaps'), ('gaps', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'noting'), ('noting', '“'), ('“', 'hot'), ('hot', '”'), ('”', 'topics'), ('topics', 'already'), ('already', 'studied'), ('studied', 'extensively'), ('extensively', 'solved'), ('solved', 'problems'), ('problems', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'problems')]

>> Trigrams are: 
 [('•', 'It', 'identifies'), ('It', 'identifies', 'research'), ('identifies', 'research', 'gaps'), ('research', 'gaps', 'big'), ('gaps', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'noting'), ('analytics', 'noting', '“'), ('noting', '“', 'hot'), ('“', 'hot', '”'), ('hot', '”', 'topics'), ('”', 'topics', 'already'), ('topics', 'already', 'studied'), ('already', 'studied', 'extensively'), ('studied', 'extensively', 'solved'), ('extensively', 'solved', 'problems'), ('solved', 'problems', 'big'), ('problems', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'problems')]

>> POS Tags are: 
 [('•', 'VB'), ('It', 'PRP'), ('identifies', 'VBZ'), ('research', 'NN'), ('gaps', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('noting', 'VBG'), ('“', 'JJ'), ('hot', 'JJ'), ('”', 'NN'), ('topics', 'NNS'), ('already', 'RB'), ('studied', 'VBN'), ('extensively', 'RB'), ('solved', 'VBN'), ('problems', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('problems', 'NNS')]

>> Noun Phrases are: 
 ['research gaps', 'big data analytics', '“ hot ” topics', 'problems', 'big data analytics', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('It', 'it'), ('identifies', 'identifi'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('noting', 'note'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'alreadi'), ('studied', 'studi'), ('extensively', 'extens'), ('solved', 'solv'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('problems', 'problem')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('It', 'it'), ('identifies', 'identifi'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('noting', 'note'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'alreadi'), ('studied', 'studi'), ('extensively', 'extens'), ('solved', 'solv'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('problems', 'problem')]

>> Lemmatization: 
 [('•', '•'), ('It', 'It'), ('identifies', 'identifies'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('noting', 'noting'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'already'), ('studied', 'studied'), ('extensively', 'extensively'), ('solved', 'solved'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('problems', 'problem')]



========================================== PARAGRAPH 126 ===========================================

that are unsolved and research questions that remain unanswered and untouched;  

------------------- Sentence 1 -------------------

that are unsolved and research questions that remain unanswered and untouched;

>> Tokens are: 
 ['unsolved', 'research', 'questions', 'remain', 'unanswered', 'untouched', ';']

>> Bigrams are: 
 [('unsolved', 'research'), ('research', 'questions'), ('questions', 'remain'), ('remain', 'unanswered'), ('unanswered', 'untouched'), ('untouched', ';')]

>> Trigrams are: 
 [('unsolved', 'research', 'questions'), ('research', 'questions', 'remain'), ('questions', 'remain', 'unanswered'), ('remain', 'unanswered', 'untouched'), ('unanswered', 'untouched', ';')]

>> POS Tags are: 
 [('unsolved', 'JJ'), ('research', 'NN'), ('questions', 'NNS'), ('remain', 'VBP'), ('unanswered', 'JJ'), ('untouched', 'JJ'), (';', ':')]

>> Noun Phrases are: 
 ['unsolved research questions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unsolved', 'unsolv'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unansw'), ('untouched', 'untouch'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('unsolved', 'unsolv'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unansw'), ('untouched', 'untouch'), (';', ';')]

>> Lemmatization: 
 [('unsolved', 'unsolved'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unanswered'), ('untouched', 'untouched'), (';', ';')]



========================================== PARAGRAPH 127 ===========================================

  


========================================== PARAGRAPH 128 ===========================================

• It opens the door for other researchers, better supporting the explosive increase in big data  analytics;  

------------------- Sentence 1 -------------------

• It opens the door for other researchers, better supporting the explosive increase in big data  analytics;

>> Tokens are: 
 ['•', 'It', 'opens', 'door', 'researchers', ',', 'better', 'supporting', 'explosive', 'increase', 'big', 'data', 'analytics', ';']

>> Bigrams are: 
 [('•', 'It'), ('It', 'opens'), ('opens', 'door'), ('door', 'researchers'), ('researchers', ','), (',', 'better'), ('better', 'supporting'), ('supporting', 'explosive'), ('explosive', 'increase'), ('increase', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ';')]

>> Trigrams are: 
 [('•', 'It', 'opens'), ('It', 'opens', 'door'), ('opens', 'door', 'researchers'), ('door', 'researchers', ','), ('researchers', ',', 'better'), (',', 'better', 'supporting'), ('better', 'supporting', 'explosive'), ('supporting', 'explosive', 'increase'), ('explosive', 'increase', 'big'), ('increase', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ';')]

>> POS Tags are: 
 [('•', 'VB'), ('It', 'PRP'), ('opens', 'VBZ'), ('door', 'NN'), ('researchers', 'NNS'), (',', ','), ('better', 'JJR'), ('supporting', 'VBG'), ('explosive', 'JJ'), ('increase', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['door researchers', 'explosive increase', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('It', 'it'), ('opens', 'open'), ('door', 'door'), ('researchers', 'research'), (',', ','), ('better', 'better'), ('supporting', 'support'), ('explosive', 'explos'), ('increase', 'increas'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('It', 'it'), ('opens', 'open'), ('door', 'door'), ('researchers', 'research'), (',', ','), ('better', 'better'), ('supporting', 'support'), ('explosive', 'explos'), ('increase', 'increas'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('It', 'It'), ('opens', 'open'), ('door', 'door'), ('researchers', 'researcher'), (',', ','), ('better', 'better'), ('supporting', 'supporting'), ('explosive', 'explosive'), ('increase', 'increase'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (';', ';')]



========================================== PARAGRAPH 129 ===========================================

  


========================================== PARAGRAPH 130 ===========================================

• This research also frames valid research methodologies, goals, and research questions for  such proposed study (Levy and Ellis, 2006; Cronin et al., 2008; Hart, 2018).   

------------------- Sentence 1 -------------------

• This research also frames valid research methodologies, goals, and research questions for  such proposed study (Levy and Ellis, 2006; Cronin et al., 2008; Hart, 2018).

>> Tokens are: 
 ['•', 'This', 'research', 'also', 'frames', 'valid', 'research', 'methodologies', ',', 'goals', ',', 'research', 'questions', 'proposed', 'study', '(', 'Levy', 'Ellis', ',', '2006', ';', 'Cronin', 'et', 'al.', ',', '2008', ';', 'Hart', ',', '2018', ')', '.']

>> Bigrams are: 
 [('•', 'This'), ('This', 'research'), ('research', 'also'), ('also', 'frames'), ('frames', 'valid'), ('valid', 'research'), ('research', 'methodologies'), ('methodologies', ','), (',', 'goals'), ('goals', ','), (',', 'research'), ('research', 'questions'), ('questions', 'proposed'), ('proposed', 'study'), ('study', '('), ('(', 'Levy'), ('Levy', 'Ellis'), ('Ellis', ','), (',', '2006'), ('2006', ';'), (';', 'Cronin'), ('Cronin', 'et'), ('et', 'al.'), ('al.', ','), (',', '2008'), ('2008', ';'), (';', 'Hart'), ('Hart', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'This', 'research'), ('This', 'research', 'also'), ('research', 'also', 'frames'), ('also', 'frames', 'valid'), ('frames', 'valid', 'research'), ('valid', 'research', 'methodologies'), ('research', 'methodologies', ','), ('methodologies', ',', 'goals'), (',', 'goals', ','), ('goals', ',', 'research'), (',', 'research', 'questions'), ('research', 'questions', 'proposed'), ('questions', 'proposed', 'study'), ('proposed', 'study', '('), ('study', '(', 'Levy'), ('(', 'Levy', 'Ellis'), ('Levy', 'Ellis', ','), ('Ellis', ',', '2006'), (',', '2006', ';'), ('2006', ';', 'Cronin'), (';', 'Cronin', 'et'), ('Cronin', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2008'), (',', '2008', ';'), ('2008', ';', 'Hart'), (';', 'Hart', ','), ('Hart', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('This', 'DT'), ('research', 'NN'), ('also', 'RB'), ('frames', 'VBZ'), ('valid', 'JJ'), ('research', 'NN'), ('methodologies', 'NNS'), (',', ','), ('goals', 'NNS'), (',', ','), ('research', 'NN'), ('questions', 'NNS'), ('proposed', 'VBN'), ('study', 'NN'), ('(', '('), ('Levy', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (';', ':'), ('Cronin', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2008', 'CD'), (';', ':'), ('Hart', 'NNP'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['•', 'This research', 'valid research methodologies', 'goals', 'research questions', 'study', 'Levy Ellis', 'Cronin', 'al.', 'Hart']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy Ellis'), ('GPE', 'Cronin'), ('PERSON', 'Hart')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('This', 'thi'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodolog'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'propos'), ('study', 'studi'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('This', 'this'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodolog'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'propos'), ('study', 'studi'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('This', 'This'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodology'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'proposed'), ('study', 'study'), ('(', '('), ('Levy', 'Levy'), ('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'Cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'Hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 131 ===========================================

  


========================================== PARAGRAPH 132 ===========================================

For industry, a literature review helps with examining areas in big data analytics that are already  

------------------- Sentence 1 -------------------

For industry, a literature review helps with examining areas in big data analytics that are already

>> Tokens are: 
 ['For', 'industry', ',', 'literature', 'review', 'helps', 'examining', 'areas', 'big', 'data', 'analytics', 'already']

>> Bigrams are: 
 [('For', 'industry'), ('industry', ','), (',', 'literature'), ('literature', 'review'), ('review', 'helps'), ('helps', 'examining'), ('examining', 'areas'), ('areas', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'already')]

>> Trigrams are: 
 [('For', 'industry', ','), ('industry', ',', 'literature'), (',', 'literature', 'review'), ('literature', 'review', 'helps'), ('review', 'helps', 'examining'), ('helps', 'examining', 'areas'), ('examining', 'areas', 'big'), ('areas', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'already')]

>> POS Tags are: 
 [('For', 'IN'), ('industry', 'NN'), (',', ','), ('literature', 'NN'), ('review', 'NN'), ('helps', 'VBZ'), ('examining', 'VBG'), ('areas', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('already', 'RB')]

>> Noun Phrases are: 
 ['industry', 'literature review', 'areas', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('industry', 'industri'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('helps', 'help'), ('examining', 'examin'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('industry', 'industri'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('helps', 'help'), ('examining', 'examin'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi')]

>> Lemmatization: 
 [('For', 'For'), ('industry', 'industry'), (',', ','), ('literature', 'literature'), ('review', 'review'), ('helps', 'help'), ('examining', 'examining'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('already', 'already')]



========================================== PARAGRAPH 133 ===========================================

mature as well as identifying problems that have been solved and those that have not been solved  

------------------- Sentence 1 -------------------

mature as well as identifying problems that have been solved and those that have not been solved

>> Tokens are: 
 ['mature', 'well', 'identifying', 'problems', 'solved', 'solved']

>> Bigrams are: 
 [('mature', 'well'), ('well', 'identifying'), ('identifying', 'problems'), ('problems', 'solved'), ('solved', 'solved')]

>> Trigrams are: 
 [('mature', 'well', 'identifying'), ('well', 'identifying', 'problems'), ('identifying', 'problems', 'solved'), ('problems', 'solved', 'solved')]

>> POS Tags are: 
 [('mature', 'NN'), ('well', 'RB'), ('identifying', 'VBG'), ('problems', 'NNS'), ('solved', 'VBD'), ('solved', 'VBD')]

>> Noun Phrases are: 
 ['mature', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mature', 'matur'), ('well', 'well'), ('identifying', 'identifi'), ('problems', 'problem'), ('solved', 'solv'), ('solved', 'solv')]

>> Stemming using Snowball Stemmer: 
 [('mature', 'matur'), ('well', 'well'), ('identifying', 'identifi'), ('problems', 'problem'), ('solved', 'solv'), ('solved', 'solv')]

>> Lemmatization: 
 [('mature', 'mature'), ('well', 'well'), ('identifying', 'identifying'), ('problems', 'problem'), ('solved', 'solved'), ('solved', 'solved')]



========================================== PARAGRAPH 134 ===========================================

yet. This clarity helps investors and businesses to think positively about big data (Lee et al., 2014;  

------------------- Sentence 1 -------------------

yet.

>> Tokens are: 
 ['yet', '.']

>> Bigrams are: 
 [('yet', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('yet', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yet', 'yet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('yet', 'yet'), ('.', '.')]

>> Lemmatization: 
 [('yet', 'yet'), ('.', '.')]


------------------- Sentence 2 -------------------

This clarity helps investors and businesses to think positively about big data (Lee et al., 2014;

>> Tokens are: 
 ['This', 'clarity', 'helps', 'investors', 'businesses', 'think', 'positively', 'big', 'data', '(', 'Lee', 'et', 'al.', ',', '2014', ';']

>> Bigrams are: 
 [('This', 'clarity'), ('clarity', 'helps'), ('helps', 'investors'), ('investors', 'businesses'), ('businesses', 'think'), ('think', 'positively'), ('positively', 'big'), ('big', 'data'), ('data', '('), ('(', 'Lee'), ('Lee', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';')]

>> Trigrams are: 
 [('This', 'clarity', 'helps'), ('clarity', 'helps', 'investors'), ('helps', 'investors', 'businesses'), ('investors', 'businesses', 'think'), ('businesses', 'think', 'positively'), ('think', 'positively', 'big'), ('positively', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Lee'), ('(', 'Lee', 'et'), ('Lee', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';')]

>> POS Tags are: 
 [('This', 'DT'), ('clarity', 'NN'), ('helps', 'VBZ'), ('investors', 'NNS'), ('businesses', 'NNS'), ('think', 'VBP'), ('positively', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Lee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['This clarity', 'investors businesses', 'big data', 'Lee']

>> Named Entities are: 
 [('PERSON', 'Lee')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('clarity', 'clariti'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'busi'), ('think', 'think'), ('positively', 'posit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('clarity', 'clariti'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'busi'), ('think', 'think'), ('positively', 'posit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]

>> Lemmatization: 
 [('This', 'This'), ('clarity', 'clarity'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'business'), ('think', 'think'), ('positively', 'positively'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'Lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]



========================================== PARAGRAPH 135 ===========================================

Chen, M. et al., 2014).  

------------------- Sentence 1 -------------------

Chen, M. et al., 2014).

>> Tokens are: 
 ['Chen', ',', 'M.', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'M.'), ('M.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Chen', ',', 'M.'), (',', 'M.', 'et'), ('M.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'M.', 'al.']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('M.', 'M.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 136 ===========================================

  


========================================== PARAGRAPH 137 ===========================================

With regard to society, big data analytics help to address economic problems such as allocating  

------------------- Sentence 1 -------------------

With regard to society, big data analytics help to address economic problems such as allocating

>> Tokens are: 
 ['With', 'regard', 'society', ',', 'big', 'data', 'analytics', 'help', 'address', 'economic', 'problems', 'allocating']

>> Bigrams are: 
 [('With', 'regard'), ('regard', 'society'), ('society', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'help'), ('help', 'address'), ('address', 'economic'), ('economic', 'problems'), ('problems', 'allocating')]

>> Trigrams are: 
 [('With', 'regard', 'society'), ('regard', 'society', ','), ('society', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'help'), ('analytics', 'help', 'address'), ('help', 'address', 'economic'), ('address', 'economic', 'problems'), ('economic', 'problems', 'allocating')]

>> POS Tags are: 
 [('With', 'IN'), ('regard', 'JJ'), ('society', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('help', 'NN'), ('address', 'VB'), ('economic', 'JJ'), ('problems', 'NNS'), ('allocating', 'VBG')]

>> Noun Phrases are: 
 ['regard society', 'big data analytics help', 'economic problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('regard', 'regard'), ('society', 'societi'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('address', 'address'), ('economic', 'econom'), ('problems', 'problem'), ('allocating', 'alloc')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('regard', 'regard'), ('society', 'societi'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('address', 'address'), ('economic', 'econom'), ('problems', 'problem'), ('allocating', 'alloc')]

>> Lemmatization: 
 [('With', 'With'), ('regard', 'regard'), ('society', 'society'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('help', 'help'), ('address', 'address'), ('economic', 'economic'), ('problems', 'problem'), ('allocating', 'allocating')]



========================================== PARAGRAPH 138 ===========================================

funds, making strategic decisions, immigration problems, and healthcare problems such as cost  

------------------- Sentence 1 -------------------

funds, making strategic decisions, immigration problems, and healthcare problems such as cost

>> Tokens are: 
 ['funds', ',', 'making', 'strategic', 'decisions', ',', 'immigration', 'problems', ',', 'healthcare', 'problems', 'cost']

>> Bigrams are: 
 [('funds', ','), (',', 'making'), ('making', 'strategic'), ('strategic', 'decisions'), ('decisions', ','), (',', 'immigration'), ('immigration', 'problems'), ('problems', ','), (',', 'healthcare'), ('healthcare', 'problems'), ('problems', 'cost')]

>> Trigrams are: 
 [('funds', ',', 'making'), (',', 'making', 'strategic'), ('making', 'strategic', 'decisions'), ('strategic', 'decisions', ','), ('decisions', ',', 'immigration'), (',', 'immigration', 'problems'), ('immigration', 'problems', ','), ('problems', ',', 'healthcare'), (',', 'healthcare', 'problems'), ('healthcare', 'problems', 'cost')]

>> POS Tags are: 
 [('funds', 'NNS'), (',', ','), ('making', 'VBG'), ('strategic', 'JJ'), ('decisions', 'NNS'), (',', ','), ('immigration', 'NN'), ('problems', 'NNS'), (',', ','), ('healthcare', 'VB'), ('problems', 'NNS'), ('cost', 'VB')]

>> Noun Phrases are: 
 ['funds', 'strategic decisions', 'immigration problems', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('funds', 'fund'), (',', ','), ('making', 'make'), ('strategic', 'strateg'), ('decisions', 'decis'), (',', ','), ('immigration', 'immigr'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcar'), ('problems', 'problem'), ('cost', 'cost')]

>> Stemming using Snowball Stemmer: 
 [('funds', 'fund'), (',', ','), ('making', 'make'), ('strategic', 'strateg'), ('decisions', 'decis'), (',', ','), ('immigration', 'immigr'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcar'), ('problems', 'problem'), ('cost', 'cost')]

>> Lemmatization: 
 [('funds', 'fund'), (',', ','), ('making', 'making'), ('strategic', 'strategic'), ('decisions', 'decision'), (',', ','), ('immigration', 'immigration'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcare'), ('problems', 'problem'), ('cost', 'cost')]



========================================== PARAGRAPH 139 ===========================================

pressures on hospitals, adding an extra dimension to addressing such societal problems (Chen et  

------------------- Sentence 1 -------------------

pressures on hospitals, adding an extra dimension to addressing such societal problems (Chen et

>> Tokens are: 
 ['pressures', 'hospitals', ',', 'adding', 'extra', 'dimension', 'addressing', 'societal', 'problems', '(', 'Chen', 'et']

>> Bigrams are: 
 [('pressures', 'hospitals'), ('hospitals', ','), (',', 'adding'), ('adding', 'extra'), ('extra', 'dimension'), ('dimension', 'addressing'), ('addressing', 'societal'), ('societal', 'problems'), ('problems', '('), ('(', 'Chen'), ('Chen', 'et')]

>> Trigrams are: 
 [('pressures', 'hospitals', ','), ('hospitals', ',', 'adding'), (',', 'adding', 'extra'), ('adding', 'extra', 'dimension'), ('extra', 'dimension', 'addressing'), ('dimension', 'addressing', 'societal'), ('addressing', 'societal', 'problems'), ('societal', 'problems', '('), ('problems', '(', 'Chen'), ('(', 'Chen', 'et')]

>> POS Tags are: 
 [('pressures', 'NNS'), ('hospitals', 'NNS'), (',', ','), ('adding', 'VBG'), ('extra', 'JJ'), ('dimension', 'NN'), ('addressing', 'VBG'), ('societal', 'JJ'), ('problems', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('et', 'VB')]

>> Noun Phrases are: 
 ['pressures hospitals', 'extra dimension', 'societal problems', 'Chen']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('pressures', 'pressur'), ('hospitals', 'hospit'), (',', ','), ('adding', 'ad'), ('extra', 'extra'), ('dimension', 'dimens'), ('addressing', 'address'), ('societal', 'societ'), ('problems', 'problem'), ('(', '('), ('Chen', 'chen'), ('et', 'et')]

>> Stemming using Snowball Stemmer: 
 [('pressures', 'pressur'), ('hospitals', 'hospit'), (',', ','), ('adding', 'ad'), ('extra', 'extra'), ('dimension', 'dimens'), ('addressing', 'address'), ('societal', 'societ'), ('problems', 'problem'), ('(', '('), ('Chen', 'chen'), ('et', 'et')]

>> Lemmatization: 
 [('pressures', 'pressure'), ('hospitals', 'hospital'), (',', ','), ('adding', 'adding'), ('extra', 'extra'), ('dimension', 'dimension'), ('addressing', 'addressing'), ('societal', 'societal'), ('problems', 'problem'), ('(', '('), ('Chen', 'Chen'), ('et', 'et')]



========================================== PARAGRAPH 140 ===========================================

al., 2012).   

------------------- Sentence 1 -------------------

al., 2012).

>> Tokens are: 
 ['al.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('al.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('al.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('al.', 'NN'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 141 ===========================================

  


========================================== PARAGRAPH 142 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 143 ===========================================

3  

------------------- Sentence 1 -------------------

3

>> Tokens are: 
 ['3']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3')]

>> Stemming using Snowball Stemmer: 
 [('3', '3')]

>> Lemmatization: 
 [('3', '3')]



========================================== PARAGRAPH 144 ===========================================

  


========================================== PARAGRAPH 145 ===========================================

3. Research Method   

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Research Method

>> Tokens are: 
 ['Research', 'Method']

>> Bigrams are: 
 [('Research', 'Method')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Research', 'NN'), ('Method', 'NN')]

>> Noun Phrases are: 
 ['Research Method']

>> Named Entities are: 
 [('GPE', 'Research'), ('ORGANIZATION', 'Method')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Method', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Method', 'method')]

>> Lemmatization: 
 [('Research', 'Research'), ('Method', 'Method')]



========================================== PARAGRAPH 146 ===========================================

The research method for this work is a classic literature review, which is important because big  

------------------- Sentence 1 -------------------

The research method for this work is a classic literature review, which is important because big

>> Tokens are: 
 ['The', 'research', 'method', 'work', 'classic', 'literature', 'review', ',', 'important', 'big']

>> Bigrams are: 
 [('The', 'research'), ('research', 'method'), ('method', 'work'), ('work', 'classic'), ('classic', 'literature'), ('literature', 'review'), ('review', ','), (',', 'important'), ('important', 'big')]

>> Trigrams are: 
 [('The', 'research', 'method'), ('research', 'method', 'work'), ('method', 'work', 'classic'), ('work', 'classic', 'literature'), ('classic', 'literature', 'review'), ('literature', 'review', ','), ('review', ',', 'important'), (',', 'important', 'big')]

>> POS Tags are: 
 [('The', 'DT'), ('research', 'NN'), ('method', 'NN'), ('work', 'NN'), ('classic', 'JJ'), ('literature', 'NN'), ('review', 'NN'), (',', ','), ('important', 'JJ'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['The research method work', 'classic literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('important', 'import'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('important', 'import'), ('big', 'big')]

>> Lemmatization: 
 [('The', 'The'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literature'), ('review', 'review'), (',', ','), ('important', 'important'), ('big', 'big')]



========================================== PARAGRAPH 147 ===========================================

data analytics is a vital modern topic that requires a solid research base. A literature review  

------------------- Sentence 1 -------------------

data analytics is a vital modern topic that requires a solid research base.

>> Tokens are: 
 ['data', 'analytics', 'vital', 'modern', 'topic', 'requires', 'solid', 'research', 'base', '.']

>> Bigrams are: 
 [('data', 'analytics'), ('analytics', 'vital'), ('vital', 'modern'), ('modern', 'topic'), ('topic', 'requires'), ('requires', 'solid'), ('solid', 'research'), ('research', 'base'), ('base', '.')]

>> Trigrams are: 
 [('data', 'analytics', 'vital'), ('analytics', 'vital', 'modern'), ('vital', 'modern', 'topic'), ('modern', 'topic', 'requires'), ('topic', 'requires', 'solid'), ('requires', 'solid', 'research'), ('solid', 'research', 'base'), ('research', 'base', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('analytics', 'NNS'), ('vital', 'JJ'), ('modern', 'JJ'), ('topic', 'NN'), ('requires', 'VBZ'), ('solid', 'JJ'), ('research', 'NN'), ('base', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data analytics', 'vital modern topic', 'solid research base']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requir'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requir'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('analytics', 'analytics'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requires'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]


------------------- Sentence 2 -------------------

A literature review

>> Tokens are: 
 ['A', 'literature', 'review']

>> Bigrams are: 
 [('A', 'literature'), ('literature', 'review')]

>> Trigrams are: 
 [('A', 'literature', 'review')]

>> POS Tags are: 
 [('A', 'DT'), ('literature', 'NN'), ('review', 'NN')]

>> Noun Phrases are: 
 ['A literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('review', 'review')]

>> Lemmatization: 
 [('A', 'A'), ('literature', 'literature'), ('review', 'review')]



========================================== PARAGRAPH 148 ===========================================

reconstructs the knowledge available in a specific domain to support a subsequent literature  

------------------- Sentence 1 -------------------

reconstructs the knowledge available in a specific domain to support a subsequent literature

>> Tokens are: 
 ['reconstructs', 'knowledge', 'available', 'specific', 'domain', 'support', 'subsequent', 'literature']

>> Bigrams are: 
 [('reconstructs', 'knowledge'), ('knowledge', 'available'), ('available', 'specific'), ('specific', 'domain'), ('domain', 'support'), ('support', 'subsequent'), ('subsequent', 'literature')]

>> Trigrams are: 
 [('reconstructs', 'knowledge', 'available'), ('knowledge', 'available', 'specific'), ('available', 'specific', 'domain'), ('specific', 'domain', 'support'), ('domain', 'support', 'subsequent'), ('support', 'subsequent', 'literature')]

>> POS Tags are: 
 [('reconstructs', 'NNS'), ('knowledge', 'VBP'), ('available', 'JJ'), ('specific', 'JJ'), ('domain', 'NN'), ('support', 'NN'), ('subsequent', 'JJ'), ('literature', 'NN')]

>> Noun Phrases are: 
 ['reconstructs', 'available specific domain support', 'subsequent literature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reconstructs', 'reconstruct'), ('knowledge', 'knowledg'), ('available', 'avail'), ('specific', 'specif'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequ'), ('literature', 'literatur')]

>> Stemming using Snowball Stemmer: 
 [('reconstructs', 'reconstruct'), ('knowledge', 'knowledg'), ('available', 'avail'), ('specific', 'specif'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequ'), ('literature', 'literatur')]

>> Lemmatization: 
 [('reconstructs', 'reconstructs'), ('knowledge', 'knowledge'), ('available', 'available'), ('specific', 'specific'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequent'), ('literature', 'literature')]



========================================== PARAGRAPH 149 ===========================================

analysis. Many literature review processes are available, and three of the most common are shown  

------------------- Sentence 1 -------------------

analysis.

>> Tokens are: 
 ['analysis', '.']

>> Bigrams are: 
 [('analysis', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Many literature review processes are available, and three of the most common are shown

>> Tokens are: 
 ['Many', 'literature', 'review', 'processes', 'available', ',', 'three', 'common', 'shown']

>> Bigrams are: 
 [('Many', 'literature'), ('literature', 'review'), ('review', 'processes'), ('processes', 'available'), ('available', ','), (',', 'three'), ('three', 'common'), ('common', 'shown')]

>> Trigrams are: 
 [('Many', 'literature', 'review'), ('literature', 'review', 'processes'), ('review', 'processes', 'available'), ('processes', 'available', ','), ('available', ',', 'three'), (',', 'three', 'common'), ('three', 'common', 'shown')]

>> POS Tags are: 
 [('Many', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('available', 'JJ'), (',', ','), ('three', 'CD'), ('common', 'JJ'), ('shown', 'VBN')]

>> Noun Phrases are: 
 ['Many literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('available', 'avail'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('available', 'avail'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown')]

>> Lemmatization: 
 [('Many', 'Many'), ('literature', 'literature'), ('review', 'review'), ('processes', 'process'), ('available', 'available'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown')]



========================================== PARAGRAPH 150 ===========================================

in Figure 1; one of these, most commonly used in the information systems field, is followed in this  

------------------- Sentence 1 -------------------

in Figure 1; one of these, most commonly used in the information systems field, is followed in this

>> Tokens are: 
 ['Figure', '1', ';', 'one', ',', 'commonly', 'used', 'information', 'systems', 'field', ',', 'followed']

>> Bigrams are: 
 [('Figure', '1'), ('1', ';'), (';', 'one'), ('one', ','), (',', 'commonly'), ('commonly', 'used'), ('used', 'information'), ('information', 'systems'), ('systems', 'field'), ('field', ','), (',', 'followed')]

>> Trigrams are: 
 [('Figure', '1', ';'), ('1', ';', 'one'), (';', 'one', ','), ('one', ',', 'commonly'), (',', 'commonly', 'used'), ('commonly', 'used', 'information'), ('used', 'information', 'systems'), ('information', 'systems', 'field'), ('systems', 'field', ','), ('field', ',', 'followed')]

>> POS Tags are: 
 [('Figure', 'NN'), ('1', 'CD'), (';', ':'), ('one', 'CD'), (',', ','), ('commonly', 'RB'), ('used', 'VBN'), ('information', 'NN'), ('systems', 'NNS'), ('field', 'NN'), (',', ','), ('followed', 'VBD')]

>> Noun Phrases are: 
 ['Figure', 'information systems field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'commonli'), ('used', 'use'), ('information', 'inform'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'follow')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'common'), ('used', 'use'), ('information', 'inform'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'follow')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'commonly'), ('used', 'used'), ('information', 'information'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'followed')]



========================================== PARAGRAPH 151 ===========================================

work.  

------------------- Sentence 1 -------------------

work.

>> Tokens are: 
 ['work', '.']

>> Bigrams are: 
 [('work', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('work', 'work'), ('.', '.')]



========================================== PARAGRAPH 152 ===========================================

  


========================================== PARAGRAPH 153 ===========================================

Figure 1: Approaches to writing an IS literature review.  

------------------- Sentence 1 -------------------

Figure 1: Approaches to writing an IS literature review.

>> Tokens are: 
 ['Figure', '1', ':', 'Approaches', 'writing', 'IS', 'literature', 'review', '.']

>> Bigrams are: 
 [('Figure', '1'), ('1', ':'), (':', 'Approaches'), ('Approaches', 'writing'), ('writing', 'IS'), ('IS', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Figure', '1', ':'), ('1', ':', 'Approaches'), (':', 'Approaches', 'writing'), ('Approaches', 'writing', 'IS'), ('writing', 'IS', 'literature'), ('IS', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('1', 'CD'), (':', ':'), ('Approaches', 'NNS'), ('writing', 'VBG'), ('IS', 'NNP'), ('literature', 'JJ'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Approaches', 'IS', 'literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (':', ':'), ('Approaches', 'approach'), ('writing', 'write'), ('IS', 'is'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (':', ':'), ('Approaches', 'approach'), ('writing', 'write'), ('IS', 'is'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('1', '1'), (':', ':'), ('Approaches', 'Approaches'), ('writing', 'writing'), ('IS', 'IS'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]



========================================== PARAGRAPH 154 ===========================================

 


========================================== PARAGRAPH 155 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 156 ===========================================

4  

------------------- Sentence 1 -------------------

4

>> Tokens are: 
 ['4']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4')]

>> Stemming using Snowball Stemmer: 
 [('4', '4')]

>> Lemmatization: 
 [('4', '4')]



========================================== PARAGRAPH 157 ===========================================

  


========================================== PARAGRAPH 158 ===========================================

A literature search according to Webster and Watson (2002), as shown in Figure 2, includes, the  

------------------- Sentence 1 -------------------

A literature search according to Webster and Watson (2002), as shown in Figure 2, includes, the

>> Tokens are: 
 ['A', 'literature', 'search', 'according', 'Webster', 'Watson', '(', '2002', ')', ',', 'shown', 'Figure', '2', ',', 'includes', ',']

>> Bigrams are: 
 [('A', 'literature'), ('literature', 'search'), ('search', 'according'), ('according', 'Webster'), ('Webster', 'Watson'), ('Watson', '('), ('(', '2002'), ('2002', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '2'), ('2', ','), (',', 'includes'), ('includes', ',')]

>> Trigrams are: 
 [('A', 'literature', 'search'), ('literature', 'search', 'according'), ('search', 'according', 'Webster'), ('according', 'Webster', 'Watson'), ('Webster', 'Watson', '('), ('Watson', '(', '2002'), ('(', '2002', ')'), ('2002', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '2'), ('Figure', '2', ','), ('2', ',', 'includes'), (',', 'includes', ',')]

>> POS Tags are: 
 [('A', 'DT'), ('literature', 'NN'), ('search', 'NN'), ('according', 'VBG'), ('Webster', 'NNP'), ('Watson', 'NNP'), ('(', '('), ('2002', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NNP'), ('2', 'CD'), (',', ','), ('includes', 'VBZ'), (',', ',')]

>> Noun Phrases are: 
 ['A literature search', 'Webster Watson', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('search', 'search'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('2', '2'), (',', ','), ('includes', 'includ'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('search', 'search'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('2', '2'), (',', ','), ('includes', 'includ'), (',', ',')]

>> Lemmatization: 
 [('A', 'A'), ('literature', 'literature'), ('search', 'search'), ('according', 'according'), ('Webster', 'Webster'), ('Watson', 'Watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('2', '2'), (',', ','), ('includes', 'includes'), (',', ',')]



========================================== PARAGRAPH 159 ===========================================

querying of scholarly databases with keywords and backward or forward searches on the basis of  

------------------- Sentence 1 -------------------

querying of scholarly databases with keywords and backward or forward searches on the basis of

>> Tokens are: 
 ['querying', 'scholarly', 'databases', 'keywords', 'backward', 'forward', 'searches', 'basis']

>> Bigrams are: 
 [('querying', 'scholarly'), ('scholarly', 'databases'), ('databases', 'keywords'), ('keywords', 'backward'), ('backward', 'forward'), ('forward', 'searches'), ('searches', 'basis')]

>> Trigrams are: 
 [('querying', 'scholarly', 'databases'), ('scholarly', 'databases', 'keywords'), ('databases', 'keywords', 'backward'), ('keywords', 'backward', 'forward'), ('backward', 'forward', 'searches'), ('forward', 'searches', 'basis')]

>> POS Tags are: 
 [('querying', 'VBG'), ('scholarly', 'JJ'), ('databases', 'NNS'), ('keywords', 'NNS'), ('backward', 'RB'), ('forward', 'RB'), ('searches', 'VBZ'), ('basis', 'NN')]

>> Noun Phrases are: 
 ['scholarly databases keywords', 'basis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('querying', 'queri'), ('scholarly', 'scholarli'), ('databases', 'databas'), ('keywords', 'keyword'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basi')]

>> Stemming using Snowball Stemmer: 
 [('querying', 'queri'), ('scholarly', 'scholar'), ('databases', 'databas'), ('keywords', 'keyword'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basi')]

>> Lemmatization: 
 [('querying', 'querying'), ('scholarly', 'scholarly'), ('databases', 'database'), ('keywords', 'keywords'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basis')]



========================================== PARAGRAPH 160 ===========================================

relevant articles discovered. This type of research is used for conducting many literature reviews  

------------------- Sentence 1 -------------------

relevant articles discovered.

>> Tokens are: 
 ['relevant', 'articles', 'discovered', '.']

>> Bigrams are: 
 [('relevant', 'articles'), ('articles', 'discovered'), ('discovered', '.')]

>> Trigrams are: 
 [('relevant', 'articles', 'discovered'), ('articles', 'discovered', '.')]

>> POS Tags are: 
 [('relevant', 'JJ'), ('articles', 'NNS'), ('discovered', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['relevant articles']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('relevant', 'relev'), ('articles', 'articl'), ('discovered', 'discov'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('relevant', 'relev'), ('articles', 'articl'), ('discovered', 'discov'), ('.', '.')]

>> Lemmatization: 
 [('relevant', 'relevant'), ('articles', 'article'), ('discovered', 'discovered'), ('.', '.')]


------------------- Sentence 2 -------------------

This type of research is used for conducting many literature reviews

>> Tokens are: 
 ['This', 'type', 'research', 'used', 'conducting', 'many', 'literature', 'reviews']

>> Bigrams are: 
 [('This', 'type'), ('type', 'research'), ('research', 'used'), ('used', 'conducting'), ('conducting', 'many'), ('many', 'literature'), ('literature', 'reviews')]

>> Trigrams are: 
 [('This', 'type', 'research'), ('type', 'research', 'used'), ('research', 'used', 'conducting'), ('used', 'conducting', 'many'), ('conducting', 'many', 'literature'), ('many', 'literature', 'reviews')]

>> POS Tags are: 
 [('This', 'DT'), ('type', 'NN'), ('research', 'NN'), ('used', 'VBD'), ('conducting', 'VBG'), ('many', 'JJ'), ('literature', 'NN'), ('reviews', 'NNS')]

>> Noun Phrases are: 
 ['This type research', 'many literature reviews']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('type', 'type'), ('research', 'research'), ('used', 'use'), ('conducting', 'conduct'), ('many', 'mani'), ('literature', 'literatur'), ('reviews', 'review')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('type', 'type'), ('research', 'research'), ('used', 'use'), ('conducting', 'conduct'), ('many', 'mani'), ('literature', 'literatur'), ('reviews', 'review')]

>> Lemmatization: 
 [('This', 'This'), ('type', 'type'), ('research', 'research'), ('used', 'used'), ('conducting', 'conducting'), ('many', 'many'), ('literature', 'literature'), ('reviews', 'review')]



========================================== PARAGRAPH 161 ===========================================

and can be used to support a researcher’s ideas at a given time. It includes citation searching, which  

------------------- Sentence 1 -------------------

and can be used to support a researcher’s ideas at a given time.

>> Tokens are: 
 ['used', 'support', 'researcher', '’', 'ideas', 'given', 'time', '.']

>> Bigrams are: 
 [('used', 'support'), ('support', 'researcher'), ('researcher', '’'), ('’', 'ideas'), ('ideas', 'given'), ('given', 'time'), ('time', '.')]

>> Trigrams are: 
 [('used', 'support', 'researcher'), ('support', 'researcher', '’'), ('researcher', '’', 'ideas'), ('’', 'ideas', 'given'), ('ideas', 'given', 'time'), ('given', 'time', '.')]

>> POS Tags are: 
 [('used', 'VBN'), ('support', 'NN'), ('researcher', 'NN'), ('’', 'NNP'), ('ideas', 'NNS'), ('given', 'VBN'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['support researcher ’ ideas', 'time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('support', 'support'), ('researcher', 'research'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('support', 'support'), ('researcher', 'research'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('used', 'used'), ('support', 'support'), ('researcher', 'researcher'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]


------------------- Sentence 2 -------------------

It includes citation searching, which

>> Tokens are: 
 ['It', 'includes', 'citation', 'searching', ',']

>> Bigrams are: 
 [('It', 'includes'), ('includes', 'citation'), ('citation', 'searching'), ('searching', ',')]

>> Trigrams are: 
 [('It', 'includes', 'citation'), ('includes', 'citation', 'searching'), ('citation', 'searching', ',')]

>> POS Tags are: 
 [('It', 'PRP'), ('includes', 'VBZ'), ('citation', 'NN'), ('searching', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['citation searching']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('includes', 'includ'), ('citation', 'citat'), ('searching', 'search'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('includes', 'includ'), ('citation', 'citat'), ('searching', 'search'), (',', ',')]

>> Lemmatization: 
 [('It', 'It'), ('includes', 'includes'), ('citation', 'citation'), ('searching', 'searching'), (',', ',')]



========================================== PARAGRAPH 162 ===========================================

allows the use of applicable articles both backwards and forwards in time. Reviewing such an  

------------------- Sentence 1 -------------------

allows the use of applicable articles both backwards and forwards in time.

>> Tokens are: 
 ['allows', 'use', 'applicable', 'articles', 'backwards', 'forwards', 'time', '.']

>> Bigrams are: 
 [('allows', 'use'), ('use', 'applicable'), ('applicable', 'articles'), ('articles', 'backwards'), ('backwards', 'forwards'), ('forwards', 'time'), ('time', '.')]

>> Trigrams are: 
 [('allows', 'use', 'applicable'), ('use', 'applicable', 'articles'), ('applicable', 'articles', 'backwards'), ('articles', 'backwards', 'forwards'), ('backwards', 'forwards', 'time'), ('forwards', 'time', '.')]

>> POS Tags are: 
 [('allows', 'NNS'), ('use', 'VBP'), ('applicable', 'JJ'), ('articles', 'NNS'), ('backwards', 'NNS'), ('forwards', 'NNS'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['allows', 'applicable articles backwards forwards time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('allows', 'allow'), ('use', 'use'), ('applicable', 'applic'), ('articles', 'articl'), ('backwards', 'backward'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('allows', 'allow'), ('use', 'use'), ('applicable', 'applic'), ('articles', 'articl'), ('backwards', 'backward'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('allows', 'allows'), ('use', 'use'), ('applicable', 'applicable'), ('articles', 'article'), ('backwards', 'backwards'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]


------------------- Sentence 2 -------------------

Reviewing such an

>> Tokens are: 
 ['Reviewing']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Reviewing', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reviewing', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Reviewing', 'review')]

>> Lemmatization: 
 [('Reviewing', 'Reviewing')]



========================================== PARAGRAPH 163 ===========================================

article’s references list to identify older articles that influenced or contributed to the author's work  

------------------- Sentence 1 -------------------

article’s references list to identify older articles that influenced or contributed to the author's work

>> Tokens are: 
 ['article', '’', 'references', 'list', 'identify', 'older', 'articles', 'influenced', 'contributed', 'author', "'s", 'work']

>> Bigrams are: 
 [('article', '’'), ('’', 'references'), ('references', 'list'), ('list', 'identify'), ('identify', 'older'), ('older', 'articles'), ('articles', 'influenced'), ('influenced', 'contributed'), ('contributed', 'author'), ('author', "'s"), ("'s", 'work')]

>> Trigrams are: 
 [('article', '’', 'references'), ('’', 'references', 'list'), ('references', 'list', 'identify'), ('list', 'identify', 'older'), ('identify', 'older', 'articles'), ('older', 'articles', 'influenced'), ('articles', 'influenced', 'contributed'), ('influenced', 'contributed', 'author'), ('contributed', 'author', "'s"), ('author', "'s", 'work')]

>> POS Tags are: 
 [('article', 'NN'), ('’', 'NNP'), ('references', 'NNS'), ('list', 'NN'), ('identify', 'NN'), ('older', 'JJR'), ('articles', 'NNS'), ('influenced', 'VBD'), ('contributed', 'VBD'), ('author', 'NN'), ("'s", 'POS'), ('work', 'NN')]

>> Noun Phrases are: 
 ['article ’ references list identify', 'articles', 'author', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('article', 'articl'), ('’', '’'), ('references', 'refer'), ('list', 'list'), ('identify', 'identifi'), ('older', 'older'), ('articles', 'articl'), ('influenced', 'influenc'), ('contributed', 'contribut'), ('author', 'author'), ("'s", "'s"), ('work', 'work')]

>> Stemming using Snowball Stemmer: 
 [('article', 'articl'), ('’', '’'), ('references', 'refer'), ('list', 'list'), ('identify', 'identifi'), ('older', 'older'), ('articles', 'articl'), ('influenced', 'influenc'), ('contributed', 'contribut'), ('author', 'author'), ("'s", "'s"), ('work', 'work')]

>> Lemmatization: 
 [('article', 'article'), ('’', '’'), ('references', 'reference'), ('list', 'list'), ('identify', 'identify'), ('older', 'older'), ('articles', 'article'), ('influenced', 'influenced'), ('contributed', 'contributed'), ('author', 'author'), ("'s", "'s"), ('work', 'work')]



========================================== PARAGRAPH 164 ===========================================

is called a backward search, while finding more recent articles that cite the article is called a  

------------------- Sentence 1 -------------------

is called a backward search, while finding more recent articles that cite the article is called a

>> Tokens are: 
 ['called', 'backward', 'search', ',', 'finding', 'recent', 'articles', 'cite', 'article', 'called']

>> Bigrams are: 
 [('called', 'backward'), ('backward', 'search'), ('search', ','), (',', 'finding'), ('finding', 'recent'), ('recent', 'articles'), ('articles', 'cite'), ('cite', 'article'), ('article', 'called')]

>> Trigrams are: 
 [('called', 'backward', 'search'), ('backward', 'search', ','), ('search', ',', 'finding'), (',', 'finding', 'recent'), ('finding', 'recent', 'articles'), ('recent', 'articles', 'cite'), ('articles', 'cite', 'article'), ('cite', 'article', 'called')]

>> POS Tags are: 
 [('called', 'VBN'), ('backward', 'NN'), ('search', 'NN'), (',', ','), ('finding', 'VBG'), ('recent', 'JJ'), ('articles', 'NNS'), ('cite', 'VBP'), ('article', 'NN'), ('called', 'VBN')]

>> Noun Phrases are: 
 ['backward search', 'recent articles', 'article']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('called', 'call'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'find'), ('recent', 'recent'), ('articles', 'articl'), ('cite', 'cite'), ('article', 'articl'), ('called', 'call')]

>> Stemming using Snowball Stemmer: 
 [('called', 'call'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'find'), ('recent', 'recent'), ('articles', 'articl'), ('cite', 'cite'), ('article', 'articl'), ('called', 'call')]

>> Lemmatization: 
 [('called', 'called'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'finding'), ('recent', 'recent'), ('articles', 'article'), ('cite', 'cite'), ('article', 'article'), ('called', 'called')]



========================================== PARAGRAPH 165 ===========================================

forward search.  

------------------- Sentence 1 -------------------

forward search.

>> Tokens are: 
 ['forward', 'search', '.']

>> Bigrams are: 
 [('forward', 'search'), ('search', '.')]

>> Trigrams are: 
 [('forward', 'search', '.')]

>> POS Tags are: 
 [('forward', 'RB'), ('search', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('forward', 'forward'), ('search', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('forward', 'forward'), ('search', 'search'), ('.', '.')]

>> Lemmatization: 
 [('forward', 'forward'), ('search', 'search'), ('.', '.')]



========================================== PARAGRAPH 166 ===========================================

            


========================================== PARAGRAPH 167 ===========================================

  


========================================== PARAGRAPH 168 ===========================================

Figure 2: Research method according to Webster and Watson (2002).  

------------------- Sentence 1 -------------------

Figure 2: Research method according to Webster and Watson (2002).

>> Tokens are: 
 ['Figure', '2', ':', 'Research', 'method', 'according', 'Webster', 'Watson', '(', '2002', ')', '.']

>> Bigrams are: 
 [('Figure', '2'), ('2', ':'), (':', 'Research'), ('Research', 'method'), ('method', 'according'), ('according', 'Webster'), ('Webster', 'Watson'), ('Watson', '('), ('(', '2002'), ('2002', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '2', ':'), ('2', ':', 'Research'), (':', 'Research', 'method'), ('Research', 'method', 'according'), ('method', 'according', 'Webster'), ('according', 'Webster', 'Watson'), ('Webster', 'Watson', '('), ('Watson', '(', '2002'), ('(', '2002', ')'), ('2002', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('2', 'CD'), (':', ':'), ('Research', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('Webster', 'NNP'), ('Watson', 'NNP'), ('(', '('), ('2002', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Research method', 'Webster Watson']

>> Named Entities are: 
 [('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('2', '2'), (':', ':'), ('Research', 'research'), ('method', 'method'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('2', '2'), (':', ':'), ('Research', 'research'), ('method', 'method'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('2', '2'), (':', ':'), ('Research', 'Research'), ('method', 'method'), ('according', 'according'), ('Webster', 'Webster'), ('Watson', 'Watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 169 ===========================================

  


========================================== PARAGRAPH 170 ===========================================

However, Levy and Ellis (2006) suggest a more systematic framework for a literature review. A  

------------------- Sentence 1 -------------------

However, Levy and Ellis (2006) suggest a more systematic framework for a literature review.

>> Tokens are: 
 ['However', ',', 'Levy', 'Ellis', '(', '2006', ')', 'suggest', 'systematic', 'framework', 'literature', 'review', '.']

>> Bigrams are: 
 [('However', ','), (',', 'Levy'), ('Levy', 'Ellis'), ('Ellis', '('), ('(', '2006'), ('2006', ')'), (')', 'suggest'), ('suggest', 'systematic'), ('systematic', 'framework'), ('framework', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('However', ',', 'Levy'), (',', 'Levy', 'Ellis'), ('Levy', 'Ellis', '('), ('Ellis', '(', '2006'), ('(', '2006', ')'), ('2006', ')', 'suggest'), (')', 'suggest', 'systematic'), ('suggest', 'systematic', 'framework'), ('systematic', 'framework', 'literature'), ('framework', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('Levy', 'NNP'), ('Ellis', 'NNP'), ('(', '('), ('2006', 'CD'), (')', ')'), ('suggest', 'VBP'), ('systematic', 'JJ'), ('framework', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Levy Ellis', 'systematic framework literature review']

>> Named Entities are: 
 [('PERSON', 'Levy Ellis')] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('Levy', 'levi'), ('Ellis', 'elli'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systemat'), ('framework', 'framework'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('Levy', 'levi'), ('Ellis', 'elli'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systemat'), ('framework', 'framework'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('Levy', 'Levy'), ('Ellis', 'Ellis'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systematic'), ('framework', 'framework'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]


------------------- Sentence 2 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 171 ===========================================

three-stage approach as shown in Figure 3 is suggested by the proposed framework: 1. Inputs, 2.  

------------------- Sentence 1 -------------------

three-stage approach as shown in Figure 3 is suggested by the proposed framework: 1.

>> Tokens are: 
 ['three-stage', 'approach', 'shown', 'Figure', '3', 'suggested', 'proposed', 'framework', ':', '1', '.']

>> Bigrams are: 
 [('three-stage', 'approach'), ('approach', 'shown'), ('shown', 'Figure'), ('Figure', '3'), ('3', 'suggested'), ('suggested', 'proposed'), ('proposed', 'framework'), ('framework', ':'), (':', '1'), ('1', '.')]

>> Trigrams are: 
 [('three-stage', 'approach', 'shown'), ('approach', 'shown', 'Figure'), ('shown', 'Figure', '3'), ('Figure', '3', 'suggested'), ('3', 'suggested', 'proposed'), ('suggested', 'proposed', 'framework'), ('proposed', 'framework', ':'), ('framework', ':', '1'), (':', '1', '.')]

>> POS Tags are: 
 [('three-stage', 'JJ'), ('approach', 'NN'), ('shown', 'VBN'), ('Figure', 'NNP'), ('3', 'CD'), ('suggested', 'VBD'), ('proposed', 'VBN'), ('framework', 'NN'), (':', ':'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['three-stage approach', 'Figure', 'framework']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('three-stage', 'three-stag'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'figur'), ('3', '3'), ('suggested', 'suggest'), ('proposed', 'propos'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('three-stage', 'three-stag'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'figur'), ('3', '3'), ('suggested', 'suggest'), ('proposed', 'propos'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('three-stage', 'three-stage'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'Figure'), ('3', '3'), ('suggested', 'suggested'), ('proposed', 'proposed'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Inputs, 2.

>> Tokens are: 
 ['Inputs', ',', '2', '.']

>> Bigrams are: 
 [('Inputs', ','), (',', '2'), ('2', '.')]

>> Trigrams are: 
 [('Inputs', ',', '2'), (',', '2', '.')]

>> POS Tags are: 
 [('Inputs', 'NNP'), (',', ','), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Inputs']

>> Named Entities are: 
 [('GPE', 'Inputs')] 

>> Stemming using Porter Stemmer: 
 [('Inputs', 'input'), (',', ','), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inputs', 'input'), (',', ','), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Inputs', 'Inputs'), (',', ','), ('2', '2'), ('.', '.')]



========================================== PARAGRAPH 172 ===========================================

Processing, 3. Outputs. The process should include “all sources that contain IS research  

------------------- Sentence 1 -------------------

Processing, 3.

>> Tokens are: 
 ['Processing', ',', '3', '.']

>> Bigrams are: 
 [('Processing', ','), (',', '3'), ('3', '.')]

>> Trigrams are: 
 [('Processing', ',', '3'), (',', '3', '.')]

>> POS Tags are: 
 [('Processing', 'NN'), (',', ','), ('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), (',', ','), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), (',', ','), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Processing', 'Processing'), (',', ','), ('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Outputs.

>> Tokens are: 
 ['Outputs', '.']

>> Bigrams are: 
 [('Outputs', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Outputs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Outputs', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Outputs', 'output'), ('.', '.')]

>> Lemmatization: 
 [('Outputs', 'Outputs'), ('.', '.')]


------------------- Sentence 3 -------------------

The process should include “all sources that contain IS research

>> Tokens are: 
 ['The', 'process', 'include', '“', 'sources', 'contain', 'IS', 'research']

>> Bigrams are: 
 [('The', 'process'), ('process', 'include'), ('include', '“'), ('“', 'sources'), ('sources', 'contain'), ('contain', 'IS'), ('IS', 'research')]

>> Trigrams are: 
 [('The', 'process', 'include'), ('process', 'include', '“'), ('include', '“', 'sources'), ('“', 'sources', 'contain'), ('sources', 'contain', 'IS'), ('contain', 'IS', 'research')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('include', 'VBP'), ('“', 'JJ'), ('sources', 'NNS'), ('contain', 'VBP'), ('IS', 'NNP'), ('research', 'NN')]

>> Noun Phrases are: 
 ['The process', '“ sources', 'IS research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('include', 'includ'), ('“', '“'), ('sources', 'sourc'), ('contain', 'contain'), ('IS', 'is'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('include', 'includ'), ('“', '“'), ('sources', 'sourc'), ('contain', 'contain'), ('IS', 'is'), ('research', 'research')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('include', 'include'), ('“', '“'), ('sources', 'source'), ('contain', 'contain'), ('IS', 'IS'), ('research', 'research')]



========================================== PARAGRAPH 173 ===========================================

publications”, though this is challenging, as it is difficult and complicated to search and analyse  

------------------- Sentence 1 -------------------

publications”, though this is challenging, as it is difficult and complicated to search and analyse

>> Tokens are: 
 ['publications', '”', ',', 'though', 'challenging', ',', 'difficult', 'complicated', 'search', 'analyse']

>> Bigrams are: 
 [('publications', '”'), ('”', ','), (',', 'though'), ('though', 'challenging'), ('challenging', ','), (',', 'difficult'), ('difficult', 'complicated'), ('complicated', 'search'), ('search', 'analyse')]

>> Trigrams are: 
 [('publications', '”', ','), ('”', ',', 'though'), (',', 'though', 'challenging'), ('though', 'challenging', ','), ('challenging', ',', 'difficult'), (',', 'difficult', 'complicated'), ('difficult', 'complicated', 'search'), ('complicated', 'search', 'analyse')]

>> POS Tags are: 
 [('publications', 'NNS'), ('”', 'VBP'), (',', ','), ('though', 'IN'), ('challenging', 'JJ'), (',', ','), ('difficult', 'JJ'), ('complicated', 'VBN'), ('search', 'NN'), ('analyse', 'NN')]

>> Noun Phrases are: 
 ['publications', 'search analyse']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('publications', 'public'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challeng'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complic'), ('search', 'search'), ('analyse', 'analys')]

>> Stemming using Snowball Stemmer: 
 [('publications', 'public'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challeng'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complic'), ('search', 'search'), ('analyse', 'analys')]

>> Lemmatization: 
 [('publications', 'publication'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challenging'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complicated'), ('search', 'search'), ('analyse', 'analyse')]



========================================== PARAGRAPH 174 ===========================================

such a vast quantity of articles (Levy and Ellis, 2006).  

------------------- Sentence 1 -------------------

such a vast quantity of articles (Levy and Ellis, 2006).

>> Tokens are: 
 ['vast', 'quantity', 'articles', '(', 'Levy', 'Ellis', ',', '2006', ')', '.']

>> Bigrams are: 
 [('vast', 'quantity'), ('quantity', 'articles'), ('articles', '('), ('(', 'Levy'), ('Levy', 'Ellis'), ('Ellis', ','), (',', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('vast', 'quantity', 'articles'), ('quantity', 'articles', '('), ('articles', '(', 'Levy'), ('(', 'Levy', 'Ellis'), ('Levy', 'Ellis', ','), ('Ellis', ',', '2006'), (',', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('vast', 'JJ'), ('quantity', 'NN'), ('articles', 'NNS'), ('(', '('), ('Levy', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['vast quantity articles', 'Levy Ellis']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy Ellis')] 

>> Stemming using Porter Stemmer: 
 [('vast', 'vast'), ('quantity', 'quantiti'), ('articles', 'articl'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('vast', 'vast'), ('quantity', 'quantiti'), ('articles', 'articl'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('vast', 'vast'), ('quantity', 'quantity'), ('articles', 'article'), ('(', '('), ('Levy', 'Levy'), ('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 175 ===========================================

  


========================================== PARAGRAPH 176 ===========================================

  


========================================== PARAGRAPH 177 ===========================================

Figure 3: The three stages of the effective literature review process, adopted from (Levy and  

------------------- Sentence 1 -------------------

Figure 3: The three stages of the effective literature review process, adopted from (Levy and

>> Tokens are: 
 ['Figure', '3', ':', 'The', 'three', 'stages', 'effective', 'literature', 'review', 'process', ',', 'adopted', '(', 'Levy']

>> Bigrams are: 
 [('Figure', '3'), ('3', ':'), (':', 'The'), ('The', 'three'), ('three', 'stages'), ('stages', 'effective'), ('effective', 'literature'), ('literature', 'review'), ('review', 'process'), ('process', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Levy')]

>> Trigrams are: 
 [('Figure', '3', ':'), ('3', ':', 'The'), (':', 'The', 'three'), ('The', 'three', 'stages'), ('three', 'stages', 'effective'), ('stages', 'effective', 'literature'), ('effective', 'literature', 'review'), ('literature', 'review', 'process'), ('review', 'process', ','), ('process', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Levy')]

>> POS Tags are: 
 [('Figure', 'NN'), ('3', 'CD'), (':', ':'), ('The', 'DT'), ('three', 'CD'), ('stages', 'NNS'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('process', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Levy', 'NNP')]

>> Noun Phrases are: 
 ['Figure', 'stages', 'effective literature review process', 'Levy']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('3', '3'), (':', ':'), ('The', 'the'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Levy', 'levi')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('3', '3'), (':', ':'), ('The', 'the'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Levy', 'levi')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('3', '3'), (':', ':'), ('The', 'The'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Levy', 'Levy')]



========================================== PARAGRAPH 178 ===========================================

Ellis, 2006).  

------------------- Sentence 1 -------------------

Ellis, 2006).

>> Tokens are: 
 ['Ellis', ',', '2006', ')', '.']

>> Bigrams are: 
 [('Ellis', ','), (',', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('Ellis', ',', '2006'), (',', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Ellis']

>> Named Entities are: 
 [('GPE', 'Ellis')] 

>> Stemming using Porter Stemmer: 
 [('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 179 ===========================================

The third research method, described by Vom Brocke et al. (2009) shows that only five research  

------------------- Sentence 1 -------------------

The third research method, described by Vom Brocke et al.

>> Tokens are: 
 ['The', 'third', 'research', 'method', ',', 'described', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'third'), ('third', 'research'), ('research', 'method'), ('method', ','), (',', 'described'), ('described', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'third', 'research'), ('third', 'research', 'method'), ('research', 'method', ','), ('method', ',', 'described'), (',', 'described', 'Vom'), ('described', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('research', 'NN'), ('method', 'NN'), (',', ','), ('described', 'VBN'), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The third research method', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'describ'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'describ'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'described'), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2009) shows that only five research

>> Tokens are: 
 ['(', '2009', ')', 'shows', 'five', 'research']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', 'shows'), ('shows', 'five'), ('five', 'research')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', 'shows'), (')', 'shows', 'five'), ('shows', 'five', 'research')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('shows', 'VBZ'), ('five', 'CD'), ('research', 'NN')]

>> Noun Phrases are: 
 ['research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research')]



========================================== PARAGRAPH 180 ===========================================

papers are required for a review as long as they contain sufficient information and are chosen for  

------------------- Sentence 1 -------------------

papers are required for a review as long as they contain sufficient information and are chosen for

>> Tokens are: 
 ['papers', 'required', 'review', 'long', 'contain', 'sufficient', 'information', 'chosen']

>> Bigrams are: 
 [('papers', 'required'), ('required', 'review'), ('review', 'long'), ('long', 'contain'), ('contain', 'sufficient'), ('sufficient', 'information'), ('information', 'chosen')]

>> Trigrams are: 
 [('papers', 'required', 'review'), ('required', 'review', 'long'), ('review', 'long', 'contain'), ('long', 'contain', 'sufficient'), ('contain', 'sufficient', 'information'), ('sufficient', 'information', 'chosen')]

>> POS Tags are: 
 [('papers', 'NNS'), ('required', 'VBD'), ('review', 'NN'), ('long', 'RB'), ('contain', 'JJ'), ('sufficient', 'JJ'), ('information', 'NN'), ('chosen', 'NN')]

>> Noun Phrases are: 
 ['papers', 'review', 'contain sufficient information chosen']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('papers', 'paper'), ('required', 'requir'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'suffici'), ('information', 'inform'), ('chosen', 'chosen')]

>> Stemming using Snowball Stemmer: 
 [('papers', 'paper'), ('required', 'requir'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'suffici'), ('information', 'inform'), ('chosen', 'chosen')]

>> Lemmatization: 
 [('papers', 'paper'), ('required', 'required'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'sufficient'), ('information', 'information'), ('chosen', 'chosen')]



========================================== PARAGRAPH 181 ===========================================

sensible reasons, and that this can be regarded as adding more value to both the authors and the 

------------------- Sentence 1 -------------------

sensible reasons, and that this can be regarded as adding more value to both the authors and the

>> Tokens are: 
 ['sensible', 'reasons', ',', 'regarded', 'adding', 'value', 'authors']

>> Bigrams are: 
 [('sensible', 'reasons'), ('reasons', ','), (',', 'regarded'), ('regarded', 'adding'), ('adding', 'value'), ('value', 'authors')]

>> Trigrams are: 
 [('sensible', 'reasons', ','), ('reasons', ',', 'regarded'), (',', 'regarded', 'adding'), ('regarded', 'adding', 'value'), ('adding', 'value', 'authors')]

>> POS Tags are: 
 [('sensible', 'JJ'), ('reasons', 'NNS'), (',', ','), ('regarded', 'VBD'), ('adding', 'VBG'), ('value', 'NN'), ('authors', 'NNS')]

>> Noun Phrases are: 
 ['sensible reasons', 'value authors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sensible', 'sensibl'), ('reasons', 'reason'), (',', ','), ('regarded', 'regard'), ('adding', 'ad'), ('value', 'valu'), ('authors', 'author')]

>> Stemming using Snowball Stemmer: 
 [('sensible', 'sensibl'), ('reasons', 'reason'), (',', ','), ('regarded', 'regard'), ('adding', 'ad'), ('value', 'valu'), ('authors', 'author')]

>> Lemmatization: 
 [('sensible', 'sensible'), ('reasons', 'reason'), (',', ','), ('regarded', 'regarded'), ('adding', 'adding'), ('value', 'value'), ('authors', 'author')]



========================================== PARAGRAPH 182 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 183 ===========================================

5  

------------------- Sentence 1 -------------------

5

>> Tokens are: 
 ['5']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('5', '5')]

>> Lemmatization: 
 [('5', '5')]



========================================== PARAGRAPH 184 ===========================================

  


========================================== PARAGRAPH 185 ===========================================

community than a review with a broad range of contribution analysis without sufficient  

------------------- Sentence 1 -------------------

community than a review with a broad range of contribution analysis without sufficient

>> Tokens are: 
 ['community', 'review', 'broad', 'range', 'contribution', 'analysis', 'without', 'sufficient']

>> Bigrams are: 
 [('community', 'review'), ('review', 'broad'), ('broad', 'range'), ('range', 'contribution'), ('contribution', 'analysis'), ('analysis', 'without'), ('without', 'sufficient')]

>> Trigrams are: 
 [('community', 'review', 'broad'), ('review', 'broad', 'range'), ('broad', 'range', 'contribution'), ('range', 'contribution', 'analysis'), ('contribution', 'analysis', 'without'), ('analysis', 'without', 'sufficient')]

>> POS Tags are: 
 [('community', 'NN'), ('review', 'NN'), ('broad', 'JJ'), ('range', 'NN'), ('contribution', 'NN'), ('analysis', 'NN'), ('without', 'IN'), ('sufficient', 'JJ')]

>> Noun Phrases are: 
 ['community review', 'broad range contribution analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('community', 'commun'), ('review', 'review'), ('broad', 'broad'), ('range', 'rang'), ('contribution', 'contribut'), ('analysis', 'analysi'), ('without', 'without'), ('sufficient', 'suffici')]

>> Stemming using Snowball Stemmer: 
 [('community', 'communiti'), ('review', 'review'), ('broad', 'broad'), ('range', 'rang'), ('contribution', 'contribut'), ('analysis', 'analysi'), ('without', 'without'), ('sufficient', 'suffici')]

>> Lemmatization: 
 [('community', 'community'), ('review', 'review'), ('broad', 'broad'), ('range', 'range'), ('contribution', 'contribution'), ('analysis', 'analysis'), ('without', 'without'), ('sufficient', 'sufficient')]



========================================== PARAGRAPH 186 ===========================================

information about where, why, and what literature was obtained. Such literature reviews are useful  

------------------- Sentence 1 -------------------

information about where, why, and what literature was obtained.

>> Tokens are: 
 ['information', ',', ',', 'literature', 'obtained', '.']

>> Bigrams are: 
 [('information', ','), (',', ','), (',', 'literature'), ('literature', 'obtained'), ('obtained', '.')]

>> Trigrams are: 
 [('information', ',', ','), (',', ',', 'literature'), (',', 'literature', 'obtained'), ('literature', 'obtained', '.')]

>> POS Tags are: 
 [('information', 'NN'), (',', ','), (',', ','), ('literature', 'NN'), ('obtained', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['information', 'literature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), (',', ','), (',', ','), ('literature', 'literatur'), ('obtained', 'obtain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), (',', ','), (',', ','), ('literature', 'literatur'), ('obtained', 'obtain'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), (',', ','), (',', ','), ('literature', 'literature'), ('obtained', 'obtained'), ('.', '.')]


------------------- Sentence 2 -------------------

Such literature reviews are useful

>> Tokens are: 
 ['Such', 'literature', 'reviews', 'useful']

>> Bigrams are: 
 [('Such', 'literature'), ('literature', 'reviews'), ('reviews', 'useful')]

>> Trigrams are: 
 [('Such', 'literature', 'reviews'), ('literature', 'reviews', 'useful')]

>> POS Tags are: 
 [('Such', 'JJ'), ('literature', 'NN'), ('reviews', 'NNS'), ('useful', 'JJ')]

>> Noun Phrases are: 
 ['Such literature reviews']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('literature', 'literatur'), ('reviews', 'review'), ('useful', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('literature', 'literatur'), ('reviews', 'review'), ('useful', 'use')]

>> Lemmatization: 
 [('Such', 'Such'), ('literature', 'literature'), ('reviews', 'review'), ('useful', 'useful')]



========================================== PARAGRAPH 187 ===========================================

as any review article must document the literature search process. This method is based on the  

------------------- Sentence 1 -------------------

as any review article must document the literature search process.

>> Tokens are: 
 ['review', 'article', 'must', 'document', 'literature', 'search', 'process', '.']

>> Bigrams are: 
 [('review', 'article'), ('article', 'must'), ('must', 'document'), ('document', 'literature'), ('literature', 'search'), ('search', 'process'), ('process', '.')]

>> Trigrams are: 
 [('review', 'article', 'must'), ('article', 'must', 'document'), ('must', 'document', 'literature'), ('document', 'literature', 'search'), ('literature', 'search', 'process'), ('search', 'process', '.')]

>> POS Tags are: 
 [('review', 'NN'), ('article', 'NN'), ('must', 'MD'), ('document', 'VB'), ('literature', 'NN'), ('search', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['review article', 'literature search process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('review', 'review'), ('article', 'articl'), ('must', 'must'), ('document', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('review', 'review'), ('article', 'articl'), ('must', 'must'), ('document', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('review', 'review'), ('article', 'article'), ('must', 'must'), ('document', 'document'), ('literature', 'literature'), ('search', 'search'), ('process', 'process'), ('.', '.')]


------------------- Sentence 2 -------------------

This method is based on the

>> Tokens are: 
 ['This', 'method', 'based']

>> Bigrams are: 
 [('This', 'method'), ('method', 'based')]

>> Trigrams are: 
 [('This', 'method', 'based')]

>> POS Tags are: 
 [('This', 'DT'), ('method', 'NN'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['This method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('method', 'method'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('method', 'method'), ('based', 'base')]

>> Lemmatization: 
 [('This', 'This'), ('method', 'method'), ('based', 'based')]



========================================== PARAGRAPH 188 ===========================================

literature review analysis of results gained from ten of the most important information systems  

------------------- Sentence 1 -------------------

literature review analysis of results gained from ten of the most important information systems

>> Tokens are: 
 ['literature', 'review', 'analysis', 'results', 'gained', 'ten', 'important', 'information', 'systems']

>> Bigrams are: 
 [('literature', 'review'), ('review', 'analysis'), ('analysis', 'results'), ('results', 'gained'), ('gained', 'ten'), ('ten', 'important'), ('important', 'information'), ('information', 'systems')]

>> Trigrams are: 
 [('literature', 'review', 'analysis'), ('review', 'analysis', 'results'), ('analysis', 'results', 'gained'), ('results', 'gained', 'ten'), ('gained', 'ten', 'important'), ('ten', 'important', 'information'), ('important', 'information', 'systems')]

>> POS Tags are: 
 [('literature', 'NN'), ('review', 'NN'), ('analysis', 'NN'), ('results', 'NNS'), ('gained', 'VBD'), ('ten', 'JJ'), ('important', 'JJ'), ('information', 'NN'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['literature review analysis results', 'ten important information systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('analysis', 'analysi'), ('results', 'result'), ('gained', 'gain'), ('ten', 'ten'), ('important', 'import'), ('information', 'inform'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('analysis', 'analysi'), ('results', 'result'), ('gained', 'gain'), ('ten', 'ten'), ('important', 'import'), ('information', 'inform'), ('systems', 'system')]

>> Lemmatization: 
 [('literature', 'literature'), ('review', 'review'), ('analysis', 'analysis'), ('results', 'result'), ('gained', 'gained'), ('ten', 'ten'), ('important', 'important'), ('information', 'information'), ('systems', 'system')]



========================================== PARAGRAPH 189 ===========================================

outlets based on a keyword search and a defined time period; it thus deliberately does not consider  

------------------- Sentence 1 -------------------

outlets based on a keyword search and a defined time period; it thus deliberately does not consider

>> Tokens are: 
 ['outlets', 'based', 'keyword', 'search', 'defined', 'time', 'period', ';', 'thus', 'deliberately', 'consider']

>> Bigrams are: 
 [('outlets', 'based'), ('based', 'keyword'), ('keyword', 'search'), ('search', 'defined'), ('defined', 'time'), ('time', 'period'), ('period', ';'), (';', 'thus'), ('thus', 'deliberately'), ('deliberately', 'consider')]

>> Trigrams are: 
 [('outlets', 'based', 'keyword'), ('based', 'keyword', 'search'), ('keyword', 'search', 'defined'), ('search', 'defined', 'time'), ('defined', 'time', 'period'), ('time', 'period', ';'), ('period', ';', 'thus'), (';', 'thus', 'deliberately'), ('thus', 'deliberately', 'consider')]

>> POS Tags are: 
 [('outlets', 'NNS'), ('based', 'VBN'), ('keyword', 'JJ'), ('search', 'NN'), ('defined', 'VBD'), ('time', 'NN'), ('period', 'NN'), (';', ':'), ('thus', 'RB'), ('deliberately', 'RB'), ('consider', 'VB')]

>> Noun Phrases are: 
 ['outlets', 'keyword search', 'time period']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('outlets', 'outlet'), ('based', 'base'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defin'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thu'), ('deliberately', 'deliber'), ('consider', 'consid')]

>> Stemming using Snowball Stemmer: 
 [('outlets', 'outlet'), ('based', 'base'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defin'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thus'), ('deliberately', 'deliber'), ('consider', 'consid')]

>> Lemmatization: 
 [('outlets', 'outlet'), ('based', 'based'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defined'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thus'), ('deliberately', 'deliberately'), ('consider', 'consider')]



========================================== PARAGRAPH 190 ===========================================

taking all available IS research papers or sources and analysing them. The processes for this are  

------------------- Sentence 1 -------------------

taking all available IS research papers or sources and analysing them.

>> Tokens are: 
 ['taking', 'available', 'IS', 'research', 'papers', 'sources', 'analysing', '.']

>> Bigrams are: 
 [('taking', 'available'), ('available', 'IS'), ('IS', 'research'), ('research', 'papers'), ('papers', 'sources'), ('sources', 'analysing'), ('analysing', '.')]

>> Trigrams are: 
 [('taking', 'available', 'IS'), ('available', 'IS', 'research'), ('IS', 'research', 'papers'), ('research', 'papers', 'sources'), ('papers', 'sources', 'analysing'), ('sources', 'analysing', '.')]

>> POS Tags are: 
 [('taking', 'VBG'), ('available', 'JJ'), ('IS', 'NNP'), ('research', 'NN'), ('papers', 'NNS'), ('sources', 'NNS'), ('analysing', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['available IS research papers sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('taking', 'take'), ('available', 'avail'), ('IS', 'is'), ('research', 'research'), ('papers', 'paper'), ('sources', 'sourc'), ('analysing', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('taking', 'take'), ('available', 'avail'), ('IS', 'is'), ('research', 'research'), ('papers', 'paper'), ('sources', 'sourc'), ('analysing', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('taking', 'taking'), ('available', 'available'), ('IS', 'IS'), ('research', 'research'), ('papers', 'paper'), ('sources', 'source'), ('analysing', 'analysing'), ('.', '.')]


------------------- Sentence 2 -------------------

The processes for this are

>> Tokens are: 
 ['The', 'processes']

>> Bigrams are: 
 [('The', 'processes')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('processes', 'NNS')]

>> Noun Phrases are: 
 ['The processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('processes', 'process')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('processes', 'process')]

>> Lemmatization: 
 [('The', 'The'), ('processes', 'process')]



========================================== PARAGRAPH 191 ===========================================

shown in  Figure 4.  

------------------- Sentence 1 -------------------

shown in  Figure 4.

>> Tokens are: 
 ['shown', 'Figure', '4', '.']

>> Bigrams are: 
 [('shown', 'Figure'), ('Figure', '4'), ('4', '.')]

>> Trigrams are: 
 [('shown', 'Figure', '4'), ('Figure', '4', '.')]

>> POS Tags are: 
 [('shown', 'VBN'), ('Figure', 'NN'), ('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('shown', 'shown'), ('Figure', 'Figure'), ('4', '4'), ('.', '.')]



========================================== PARAGRAPH 192 ===========================================

  


========================================== PARAGRAPH 193 ===========================================

This research follows the procedure suggested by Vom Brocke et al. (2009) for writing a literature  

------------------- Sentence 1 -------------------

This research follows the procedure suggested by Vom Brocke et al.

>> Tokens are: 
 ['This', 'research', 'follows', 'procedure', 'suggested', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('This', 'research'), ('research', 'follows'), ('follows', 'procedure'), ('procedure', 'suggested'), ('suggested', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('This', 'research', 'follows'), ('research', 'follows', 'procedure'), ('follows', 'procedure', 'suggested'), ('procedure', 'suggested', 'Vom'), ('suggested', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('research', 'NN'), ('follows', 'VBZ'), ('procedure', 'NN'), ('suggested', 'VBD'), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This research', 'procedure', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('research', 'research'), ('follows', 'follow'), ('procedure', 'procedur'), ('suggested', 'suggest'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('research', 'research'), ('follows', 'follow'), ('procedure', 'procedur'), ('suggested', 'suggest'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('research', 'research'), ('follows', 'follows'), ('procedure', 'procedure'), ('suggested', 'suggested'), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2009) for writing a literature

>> Tokens are: 
 ['(', '2009', ')', 'writing', 'literature']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', 'writing'), ('writing', 'literature')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', 'writing'), (')', 'writing', 'literature')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('writing', 'NN'), ('literature', 'NN')]

>> Noun Phrases are: 
 ['writing literature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'write'), ('literature', 'literatur')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'write'), ('literature', 'literatur')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'writing'), ('literature', 'literature')]



========================================== PARAGRAPH 194 ===========================================

review as this method focuses on choosing papers for sensible reasons. The criteria for choice are  

------------------- Sentence 1 -------------------

review as this method focuses on choosing papers for sensible reasons.

>> Tokens are: 
 ['review', 'method', 'focuses', 'choosing', 'papers', 'sensible', 'reasons', '.']

>> Bigrams are: 
 [('review', 'method'), ('method', 'focuses'), ('focuses', 'choosing'), ('choosing', 'papers'), ('papers', 'sensible'), ('sensible', 'reasons'), ('reasons', '.')]

>> Trigrams are: 
 [('review', 'method', 'focuses'), ('method', 'focuses', 'choosing'), ('focuses', 'choosing', 'papers'), ('choosing', 'papers', 'sensible'), ('papers', 'sensible', 'reasons'), ('sensible', 'reasons', '.')]

>> POS Tags are: 
 [('review', 'NN'), ('method', 'NN'), ('focuses', 'VBZ'), ('choosing', 'VBG'), ('papers', 'NNS'), ('sensible', 'JJ'), ('reasons', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['review method', 'papers', 'sensible reasons']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choos'), ('papers', 'paper'), ('sensible', 'sensibl'), ('reasons', 'reason'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choos'), ('papers', 'paper'), ('sensible', 'sensibl'), ('reasons', 'reason'), ('.', '.')]

>> Lemmatization: 
 [('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choosing'), ('papers', 'paper'), ('sensible', 'sensible'), ('reasons', 'reason'), ('.', '.')]


------------------- Sentence 2 -------------------

The criteria for choice are

>> Tokens are: 
 ['The', 'criteria', 'choice']

>> Bigrams are: 
 [('The', 'criteria'), ('criteria', 'choice')]

>> Trigrams are: 
 [('The', 'criteria', 'choice')]

>> POS Tags are: 
 [('The', 'DT'), ('criteria', 'NN'), ('choice', 'NN')]

>> Noun Phrases are: 
 ['The criteria choice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('criteria', 'criteria'), ('choice', 'choic')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('criteria', 'criteria'), ('choice', 'choic')]

>> Lemmatization: 
 [('The', 'The'), ('criteria', 'criterion'), ('choice', 'choice')]



========================================== PARAGRAPH 195 ===========================================

dependent on the useful information that can be gained from such papers, the period of interest,  

------------------- Sentence 1 -------------------

dependent on the useful information that can be gained from such papers, the period of interest,

>> Tokens are: 
 ['dependent', 'useful', 'information', 'gained', 'papers', ',', 'period', 'interest', ',']

>> Bigrams are: 
 [('dependent', 'useful'), ('useful', 'information'), ('information', 'gained'), ('gained', 'papers'), ('papers', ','), (',', 'period'), ('period', 'interest'), ('interest', ',')]

>> Trigrams are: 
 [('dependent', 'useful', 'information'), ('useful', 'information', 'gained'), ('information', 'gained', 'papers'), ('gained', 'papers', ','), ('papers', ',', 'period'), (',', 'period', 'interest'), ('period', 'interest', ',')]

>> POS Tags are: 
 [('dependent', 'JJ'), ('useful', 'JJ'), ('information', 'NN'), ('gained', 'VBD'), ('papers', 'NNS'), (',', ','), ('period', 'NN'), ('interest', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['dependent useful information', 'papers', 'period interest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dependent', 'depend'), ('useful', 'use'), ('information', 'inform'), ('gained', 'gain'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('dependent', 'depend'), ('useful', 'use'), ('information', 'inform'), ('gained', 'gain'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ',')]

>> Lemmatization: 
 [('dependent', 'dependent'), ('useful', 'useful'), ('information', 'information'), ('gained', 'gained'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ',')]



========================================== PARAGRAPH 196 ===========================================

and the number of citations, as well as whether the paper is from a peer-reviewed journal,  

------------------- Sentence 1 -------------------

and the number of citations, as well as whether the paper is from a peer-reviewed journal,

>> Tokens are: 
 ['number', 'citations', ',', 'well', 'whether', 'paper', 'peer-reviewed', 'journal', ',']

>> Bigrams are: 
 [('number', 'citations'), ('citations', ','), (',', 'well'), ('well', 'whether'), ('whether', 'paper'), ('paper', 'peer-reviewed'), ('peer-reviewed', 'journal'), ('journal', ',')]

>> Trigrams are: 
 [('number', 'citations', ','), ('citations', ',', 'well'), (',', 'well', 'whether'), ('well', 'whether', 'paper'), ('whether', 'paper', 'peer-reviewed'), ('paper', 'peer-reviewed', 'journal'), ('peer-reviewed', 'journal', ',')]

>> POS Tags are: 
 [('number', 'NN'), ('citations', 'NNS'), (',', ','), ('well', 'RB'), ('whether', 'IN'), ('paper', 'NN'), ('peer-reviewed', 'JJ'), ('journal', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['number citations', 'paper', 'peer-reviewed journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('number', 'number'), ('citations', 'citat'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-review'), ('journal', 'journal'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('number', 'number'), ('citations', 'citat'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-review'), ('journal', 'journal'), (',', ',')]

>> Lemmatization: 
 [('number', 'number'), ('citations', 'citation'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-reviewed'), ('journal', 'journal'), (',', ',')]



========================================== PARAGRAPH 197 ===========================================

conference, or other respectable source. These criteria are thus not randomly dependent on time  

------------------- Sentence 1 -------------------

conference, or other respectable source.

>> Tokens are: 
 ['conference', ',', 'respectable', 'source', '.']

>> Bigrams are: 
 [('conference', ','), (',', 'respectable'), ('respectable', 'source'), ('source', '.')]

>> Trigrams are: 
 [('conference', ',', 'respectable'), (',', 'respectable', 'source'), ('respectable', 'source', '.')]

>> POS Tags are: 
 [('conference', 'NN'), (',', ','), ('respectable', 'JJ'), ('source', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['conference', 'respectable source']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conference', 'confer'), (',', ','), ('respectable', 'respect'), ('source', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conference', 'confer'), (',', ','), ('respectable', 'respect'), ('source', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('conference', 'conference'), (',', ','), ('respectable', 'respectable'), ('source', 'source'), ('.', '.')]


------------------- Sentence 2 -------------------

These criteria are thus not randomly dependent on time

>> Tokens are: 
 ['These', 'criteria', 'thus', 'randomly', 'dependent', 'time']

>> Bigrams are: 
 [('These', 'criteria'), ('criteria', 'thus'), ('thus', 'randomly'), ('randomly', 'dependent'), ('dependent', 'time')]

>> Trigrams are: 
 [('These', 'criteria', 'thus'), ('criteria', 'thus', 'randomly'), ('thus', 'randomly', 'dependent'), ('randomly', 'dependent', 'time')]

>> POS Tags are: 
 [('These', 'DT'), ('criteria', 'NNS'), ('thus', 'RB'), ('randomly', 'RB'), ('dependent', 'JJ'), ('time', 'NN')]

>> Noun Phrases are: 
 ['These criteria', 'dependent time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('criteria', 'criteria'), ('thus', 'thu'), ('randomly', 'randomli'), ('dependent', 'depend'), ('time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('criteria', 'criteria'), ('thus', 'thus'), ('randomly', 'random'), ('dependent', 'depend'), ('time', 'time')]

>> Lemmatization: 
 [('These', 'These'), ('criteria', 'criterion'), ('thus', 'thus'), ('randomly', 'randomly'), ('dependent', 'dependent'), ('time', 'time')]



========================================== PARAGRAPH 198 ===========================================

periods or gathering all sources within all of the research field’s publications.  

------------------- Sentence 1 -------------------

periods or gathering all sources within all of the research field’s publications.

>> Tokens are: 
 ['periods', 'gathering', 'sources', 'within', 'research', 'field', '’', 'publications', '.']

>> Bigrams are: 
 [('periods', 'gathering'), ('gathering', 'sources'), ('sources', 'within'), ('within', 'research'), ('research', 'field'), ('field', '’'), ('’', 'publications'), ('publications', '.')]

>> Trigrams are: 
 [('periods', 'gathering', 'sources'), ('gathering', 'sources', 'within'), ('sources', 'within', 'research'), ('within', 'research', 'field'), ('research', 'field', '’'), ('field', '’', 'publications'), ('’', 'publications', '.')]

>> POS Tags are: 
 [('periods', 'NNS'), ('gathering', 'NN'), ('sources', 'NNS'), ('within', 'IN'), ('research', 'NN'), ('field', 'NN'), ('’', 'NNP'), ('publications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['periods gathering sources', 'research field ’ publications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('periods', 'period'), ('gathering', 'gather'), ('sources', 'sourc'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'public'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('periods', 'period'), ('gathering', 'gather'), ('sources', 'sourc'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'public'), ('.', '.')]

>> Lemmatization: 
 [('periods', 'period'), ('gathering', 'gathering'), ('sources', 'source'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'publication'), ('.', '.')]



========================================== PARAGRAPH 199 ===========================================

  


========================================== PARAGRAPH 200 ===========================================

 Figure 4: Stages of the effective search for the literature review process1  

------------------- Sentence 1 -------------------

 Figure 4: Stages of the effective search for the literature review process1

>> Tokens are: 
 ['Figure', '4', ':', 'Stages', 'effective', 'search', 'literature', 'review', 'process1']

>> Bigrams are: 
 [('Figure', '4'), ('4', ':'), (':', 'Stages'), ('Stages', 'effective'), ('effective', 'search'), ('search', 'literature'), ('literature', 'review'), ('review', 'process1')]

>> Trigrams are: 
 [('Figure', '4', ':'), ('4', ':', 'Stages'), (':', 'Stages', 'effective'), ('Stages', 'effective', 'search'), ('effective', 'search', 'literature'), ('search', 'literature', 'review'), ('literature', 'review', 'process1')]

>> POS Tags are: 
 [('Figure', 'NN'), ('4', 'CD'), (':', ':'), ('Stages', 'NNS'), ('effective', 'JJ'), ('search', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('process1', 'NN')]

>> Noun Phrases are: 
 ['Figure', 'Stages', 'effective search literature review process1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('4', '4'), (':', ':'), ('Stages', 'stage'), ('effective', 'effect'), ('search', 'search'), ('literature', 'literatur'), ('review', 'review'), ('process1', 'process1')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('4', '4'), (':', ':'), ('Stages', 'stage'), ('effective', 'effect'), ('search', 'search'), ('literature', 'literatur'), ('review', 'review'), ('process1', 'process1')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('4', '4'), (':', ':'), ('Stages', 'Stages'), ('effective', 'effective'), ('search', 'search'), ('literature', 'literature'), ('review', 'review'), ('process1', 'process1')]



========================================== PARAGRAPH 201 ===========================================

  


========================================== PARAGRAPH 202 ===========================================

  


========================================== PARAGRAPH 203 ===========================================

                                                  1 Based on (Vom Brocke et al., 2009)   

------------------- Sentence 1 -------------------

                                                  1 Based on (Vom Brocke et al., 2009)

>> Tokens are: 
 ['1', 'Based', '(', 'Vom', 'Brocke', 'et', 'al.', ',', '2009', ')']

>> Bigrams are: 
 [('1', 'Based'), ('Based', '('), ('(', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al.'), ('al.', ','), (',', '2009'), ('2009', ')')]

>> Trigrams are: 
 [('1', 'Based', '('), ('Based', '(', 'Vom'), ('(', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2009'), (',', '2009', ')')]

>> POS Tags are: 
 [('1', 'CD'), ('Based', 'VBN'), ('(', '('), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2009', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Vom Brocke', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('Based', 'base'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('Based', 'base'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')')]

>> Lemmatization: 
 [('1', '1'), ('Based', 'Based'), ('(', '('), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')')]



========================================== PARAGRAPH 204 ===========================================

Select a reference 

------------------- Sentence 1 -------------------

Select a reference

>> Tokens are: 
 ['Select', 'reference']

>> Bigrams are: 
 [('Select', 'reference')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Select', 'JJ'), ('reference', 'NN')]

>> Noun Phrases are: 
 ['Select reference']

>> Named Entities are: 
 [('GPE', 'Select')] 

>> Stemming using Porter Stemmer: 
 [('Select', 'select'), ('reference', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('Select', 'select'), ('reference', 'refer')]

>> Lemmatization: 
 [('Select', 'Select'), ('reference', 'reference')]



========================================== PARAGRAPH 205 ===========================================

Sources: Top-ten-ranked peer-reviewed IS  Journals, conferences, or books  

------------------- Sentence 1 -------------------

Sources: Top-ten-ranked peer-reviewed IS  Journals, conferences, or books

>> Tokens are: 
 ['Sources', ':', 'Top-ten-ranked', 'peer-reviewed', 'IS', 'Journals', ',', 'conferences', ',', 'books']

>> Bigrams are: 
 [('Sources', ':'), (':', 'Top-ten-ranked'), ('Top-ten-ranked', 'peer-reviewed'), ('peer-reviewed', 'IS'), ('IS', 'Journals'), ('Journals', ','), (',', 'conferences'), ('conferences', ','), (',', 'books')]

>> Trigrams are: 
 [('Sources', ':', 'Top-ten-ranked'), (':', 'Top-ten-ranked', 'peer-reviewed'), ('Top-ten-ranked', 'peer-reviewed', 'IS'), ('peer-reviewed', 'IS', 'Journals'), ('IS', 'Journals', ','), ('Journals', ',', 'conferences'), (',', 'conferences', ','), ('conferences', ',', 'books')]

>> POS Tags are: 
 [('Sources', 'NNS'), (':', ':'), ('Top-ten-ranked', 'JJ'), ('peer-reviewed', 'NN'), ('IS', 'NNP'), ('Journals', 'NNP'), (',', ','), ('conferences', 'NNS'), (',', ','), ('books', 'NNS')]

>> Noun Phrases are: 
 ['Sources', 'Top-ten-ranked peer-reviewed IS Journals', 'conferences', 'books']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sources', 'sourc'), (':', ':'), ('Top-ten-ranked', 'top-ten-rank'), ('peer-reviewed', 'peer-review'), ('IS', 'is'), ('Journals', 'journal'), (',', ','), ('conferences', 'confer'), (',', ','), ('books', 'book')]

>> Stemming using Snowball Stemmer: 
 [('Sources', 'sourc'), (':', ':'), ('Top-ten-ranked', 'top-ten-rank'), ('peer-reviewed', 'peer-review'), ('IS', 'is'), ('Journals', 'journal'), (',', ','), ('conferences', 'confer'), (',', ','), ('books', 'book')]

>> Lemmatization: 
 [('Sources', 'Sources'), (':', ':'), ('Top-ten-ranked', 'Top-ten-ranked'), ('peer-reviewed', 'peer-reviewed'), ('IS', 'IS'), ('Journals', 'Journals'), (',', ','), ('conferences', 'conference'), (',', ','), ('books', 'book')]



========================================== PARAGRAPH 206 ===========================================

Consider Keyword search 

------------------- Sentence 1 -------------------

Consider Keyword search

>> Tokens are: 
 ['Consider', 'Keyword', 'search']

>> Bigrams are: 
 [('Consider', 'Keyword'), ('Keyword', 'search')]

>> Trigrams are: 
 [('Consider', 'Keyword', 'search')]

>> POS Tags are: 
 [('Consider', 'VB'), ('Keyword', 'NNP'), ('search', 'NN')]

>> Noun Phrases are: 
 ['Keyword search']

>> Named Entities are: 
 [('PERSON', 'Keyword')] 

>> Stemming using Porter Stemmer: 
 [('Consider', 'consid'), ('Keyword', 'keyword'), ('search', 'search')]

>> Stemming using Snowball Stemmer: 
 [('Consider', 'consid'), ('Keyword', 'keyword'), ('search', 'search')]

>> Lemmatization: 
 [('Consider', 'Consider'), ('Keyword', 'Keyword'), ('search', 'search')]



========================================== PARAGRAPH 207 ===========================================

Consider Period covered 

------------------- Sentence 1 -------------------

Consider Period covered

>> Tokens are: 
 ['Consider', 'Period', 'covered']

>> Bigrams are: 
 [('Consider', 'Period'), ('Period', 'covered')]

>> Trigrams are: 
 [('Consider', 'Period', 'covered')]

>> POS Tags are: 
 [('Consider', 'VB'), ('Period', 'NNP'), ('covered', 'VBD')]

>> Noun Phrases are: 
 ['Period']

>> Named Entities are: 
 [('PERSON', 'Period')] 

>> Stemming using Porter Stemmer: 
 [('Consider', 'consid'), ('Period', 'period'), ('covered', 'cover')]

>> Stemming using Snowball Stemmer: 
 [('Consider', 'consid'), ('Period', 'period'), ('covered', 'cover')]

>> Lemmatization: 
 [('Consider', 'Consider'), ('Period', 'Period'), ('covered', 'covered')]



========================================== PARAGRAPH 208 ===========================================

Consider Number of citations 

------------------- Sentence 1 -------------------

Consider Number of citations

>> Tokens are: 
 ['Consider', 'Number', 'citations']

>> Bigrams are: 
 [('Consider', 'Number'), ('Number', 'citations')]

>> Trigrams are: 
 [('Consider', 'Number', 'citations')]

>> POS Tags are: 
 [('Consider', 'VB'), ('Number', 'NNP'), ('citations', 'NNS')]

>> Noun Phrases are: 
 ['Number citations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Consider', 'consid'), ('Number', 'number'), ('citations', 'citat')]

>> Stemming using Snowball Stemmer: 
 [('Consider', 'consid'), ('Number', 'number'), ('citations', 'citat')]

>> Lemmatization: 
 [('Consider', 'Consider'), ('Number', 'Number'), ('citations', 'citation')]



========================================== PARAGRAPH 209 ===========================================

Consider Literature search

------------------- Sentence 1 -------------------

Consider Literature search

>> Tokens are: 
 ['Consider', 'Literature', 'search']

>> Bigrams are: 
 [('Consider', 'Literature'), ('Literature', 'search')]

>> Trigrams are: 
 [('Consider', 'Literature', 'search')]

>> POS Tags are: 
 [('Consider', 'VB'), ('Literature', 'NNP'), ('search', 'NN')]

>> Noun Phrases are: 
 ['Literature search']

>> Named Entities are: 
 [('ORGANIZATION', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Consider', 'consid'), ('Literature', 'literatur'), ('search', 'search')]

>> Stemming using Snowball Stemmer: 
 [('Consider', 'consid'), ('Literature', 'literatur'), ('search', 'search')]

>> Lemmatization: 
 [('Consider', 'Consider'), ('Literature', 'Literature'), ('search', 'search')]



========================================== PARAGRAPH 210 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 211 ===========================================

6  

------------------- Sentence 1 -------------------

6

>> Tokens are: 
 ['6']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6')]

>> Stemming using Snowball Stemmer: 
 [('6', '6')]

>> Lemmatization: 
 [('6', '6')]



========================================== PARAGRAPH 212 ===========================================

  


========================================== PARAGRAPH 213 ===========================================

The literature review processes followed in this thesis are shown in Figure 5. They include  

------------------- Sentence 1 -------------------

The literature review processes followed in this thesis are shown in Figure 5.

>> Tokens are: 
 ['The', 'literature', 'review', 'processes', 'followed', 'thesis', 'shown', 'Figure', '5', '.']

>> Bigrams are: 
 [('The', 'literature'), ('literature', 'review'), ('review', 'processes'), ('processes', 'followed'), ('followed', 'thesis'), ('thesis', 'shown'), ('shown', 'Figure'), ('Figure', '5'), ('5', '.')]

>> Trigrams are: 
 [('The', 'literature', 'review'), ('literature', 'review', 'processes'), ('review', 'processes', 'followed'), ('processes', 'followed', 'thesis'), ('followed', 'thesis', 'shown'), ('thesis', 'shown', 'Figure'), ('shown', 'Figure', '5'), ('Figure', '5', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('followed', 'JJ'), ('thesis', 'NN'), ('shown', 'VBN'), ('Figure', 'NNP'), ('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The literature review', 'followed thesis', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('followed', 'follow'), ('thesis', 'thesi'), ('shown', 'shown'), ('Figure', 'figur'), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('followed', 'follow'), ('thesis', 'thesi'), ('shown', 'shown'), ('Figure', 'figur'), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('literature', 'literature'), ('review', 'review'), ('processes', 'process'), ('followed', 'followed'), ('thesis', 'thesis'), ('shown', 'shown'), ('Figure', 'Figure'), ('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

They include

>> Tokens are: 
 ['They', 'include']

>> Bigrams are: 
 [('They', 'include')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('They', 'PRP'), ('include', 'VBP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('include', 'includ')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('include', 'includ')]

>> Lemmatization: 
 [('They', 'They'), ('include', 'include')]



========================================== PARAGRAPH 214 ===========================================

Identifying the concept and review scope  

------------------- Sentence 1 -------------------

Identifying the concept and review scope

>> Tokens are: 
 ['Identifying', 'concept', 'review', 'scope']

>> Bigrams are: 
 [('Identifying', 'concept'), ('concept', 'review'), ('review', 'scope')]

>> Trigrams are: 
 [('Identifying', 'concept', 'review'), ('concept', 'review', 'scope')]

>> POS Tags are: 
 [('Identifying', 'VBG'), ('concept', 'NN'), ('review', 'NN'), ('scope', 'NN')]

>> Noun Phrases are: 
 ['concept review scope']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Identifying', 'identifi'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope')]

>> Stemming using Snowball Stemmer: 
 [('Identifying', 'identifi'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope')]

>> Lemmatization: 
 [('Identifying', 'Identifying'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope')]



========================================== PARAGRAPH 215 ===========================================

 Identifying the concept means determining what is needed to achieve the goal, and what  work should be done to deliver the project. Such planning consists of documenting the  

------------------- Sentence 1 -------------------

 Identifying the concept means determining what is needed to achieve the goal, and what  work should be done to deliver the project.

>> Tokens are: 
 ['\uf075', 'Identifying', 'concept', 'means', 'determining', 'needed', 'achieve', 'goal', ',', 'work', 'done', 'deliver', 'project', '.']

>> Bigrams are: 
 [('\uf075', 'Identifying'), ('Identifying', 'concept'), ('concept', 'means'), ('means', 'determining'), ('determining', 'needed'), ('needed', 'achieve'), ('achieve', 'goal'), ('goal', ','), (',', 'work'), ('work', 'done'), ('done', 'deliver'), ('deliver', 'project'), ('project', '.')]

>> Trigrams are: 
 [('\uf075', 'Identifying', 'concept'), ('Identifying', 'concept', 'means'), ('concept', 'means', 'determining'), ('means', 'determining', 'needed'), ('determining', 'needed', 'achieve'), ('needed', 'achieve', 'goal'), ('achieve', 'goal', ','), ('goal', ',', 'work'), (',', 'work', 'done'), ('work', 'done', 'deliver'), ('done', 'deliver', 'project'), ('deliver', 'project', '.')]

>> POS Tags are: 
 [('\uf075', 'NN'), ('Identifying', 'NNP'), ('concept', 'NN'), ('means', 'VBZ'), ('determining', 'VBG'), ('needed', 'VBN'), ('achieve', 'JJ'), ('goal', 'NN'), (',', ','), ('work', 'NN'), ('done', 'VBN'), ('deliver', 'NN'), ('project', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['\uf075 Identifying concept', 'achieve goal', 'work', 'deliver project']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('Identifying', 'identifi'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determin'), ('needed', 'need'), ('achieve', 'achiev'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliv'), ('project', 'project'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('Identifying', 'identifi'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determin'), ('needed', 'need'), ('achieve', 'achiev'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliv'), ('project', 'project'), ('.', '.')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('Identifying', 'Identifying'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determining'), ('needed', 'needed'), ('achieve', 'achieve'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliver'), ('project', 'project'), ('.', '.')]


------------------- Sentence 2 -------------------

Such planning consists of documenting the

>> Tokens are: 
 ['Such', 'planning', 'consists', 'documenting']

>> Bigrams are: 
 [('Such', 'planning'), ('planning', 'consists'), ('consists', 'documenting')]

>> Trigrams are: 
 [('Such', 'planning', 'consists'), ('planning', 'consists', 'documenting')]

>> POS Tags are: 
 [('Such', 'JJ'), ('planning', 'NN'), ('consists', 'VBZ'), ('documenting', 'VBG')]

>> Noun Phrases are: 
 ['Such planning']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('planning', 'plan'), ('consists', 'consist'), ('documenting', 'document')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('planning', 'plan'), ('consists', 'consist'), ('documenting', 'document')]

>> Lemmatization: 
 [('Such', 'Such'), ('planning', 'planning'), ('consists', 'consists'), ('documenting', 'documenting')]



========================================== PARAGRAPH 216 ===========================================

project goals, features, tasks, and deadlines. In this research, this referred to the process of  

------------------- Sentence 1 -------------------

project goals, features, tasks, and deadlines.

>> Tokens are: 
 ['project', 'goals', ',', 'features', ',', 'tasks', ',', 'deadlines', '.']

>> Bigrams are: 
 [('project', 'goals'), ('goals', ','), (',', 'features'), ('features', ','), (',', 'tasks'), ('tasks', ','), (',', 'deadlines'), ('deadlines', '.')]

>> Trigrams are: 
 [('project', 'goals', ','), ('goals', ',', 'features'), (',', 'features', ','), ('features', ',', 'tasks'), (',', 'tasks', ','), ('tasks', ',', 'deadlines'), (',', 'deadlines', '.')]

>> POS Tags are: 
 [('project', 'NN'), ('goals', 'NNS'), (',', ','), ('features', 'NNS'), (',', ','), ('tasks', 'NNS'), (',', ','), ('deadlines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['project goals', 'features', 'tasks', 'deadlines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'featur'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadlin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'featur'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadlin'), ('.', '.')]

>> Lemmatization: 
 [('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'feature'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadline'), ('.', '.')]


------------------- Sentence 2 -------------------

In this research, this referred to the process of

>> Tokens are: 
 ['In', 'research', ',', 'referred', 'process']

>> Bigrams are: 
 [('In', 'research'), ('research', ','), (',', 'referred'), ('referred', 'process')]

>> Trigrams are: 
 [('In', 'research', ','), ('research', ',', 'referred'), (',', 'referred', 'process')]

>> POS Tags are: 
 [('In', 'IN'), ('research', 'NN'), (',', ','), ('referred', 'VBD'), ('process', 'NN')]

>> Noun Phrases are: 
 ['research', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('research', 'research'), (',', ','), ('referred', 'refer'), ('process', 'process')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('research', 'research'), (',', ','), ('referred', 'refer'), ('process', 'process')]

>> Lemmatization: 
 [('In', 'In'), ('research', 'research'), (',', ','), ('referred', 'referred'), ('process', 'process')]



========================================== PARAGRAPH 217 ===========================================

developing a literature review perspective on big data analytics.   

------------------- Sentence 1 -------------------

developing a literature review perspective on big data analytics.

>> Tokens are: 
 ['developing', 'literature', 'review', 'perspective', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('developing', 'literature'), ('literature', 'review'), ('review', 'perspective'), ('perspective', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('developing', 'literature', 'review'), ('literature', 'review', 'perspective'), ('review', 'perspective', 'big'), ('perspective', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('developing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), ('perspective', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['literature review', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('developing', 'develop'), ('literature', 'literatur'), ('review', 'review'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('developing', 'develop'), ('literature', 'literatur'), ('review', 'review'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('developing', 'developing'), ('literature', 'literature'), ('review', 'review'), ('perspective', 'perspective'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 218 ===========================================

Finding related databases and sources  

------------------- Sentence 1 -------------------

Finding related databases and sources

>> Tokens are: 
 ['Finding', 'related', 'databases', 'sources']

>> Bigrams are: 
 [('Finding', 'related'), ('related', 'databases'), ('databases', 'sources')]

>> Trigrams are: 
 [('Finding', 'related', 'databases'), ('related', 'databases', 'sources')]

>> POS Tags are: 
 [('Finding', 'VBG'), ('related', 'JJ'), ('databases', 'NNS'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['related databases sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finding', 'find'), ('related', 'relat'), ('databases', 'databas'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('Finding', 'find'), ('related', 'relat'), ('databases', 'databas'), ('sources', 'sourc')]

>> Lemmatization: 
 [('Finding', 'Finding'), ('related', 'related'), ('databases', 'database'), ('sources', 'source')]



========================================== PARAGRAPH 219 ===========================================

 The search procedure for this thesis included the use of a range of relevant sources, such  as ACM DL, IEEE Xplore, Emerald, EBSCO, WoS, LTU library, Google Scholar,  

------------------- Sentence 1 -------------------

 The search procedure for this thesis included the use of a range of relevant sources, such  as ACM DL, IEEE Xplore, Emerald, EBSCO, WoS, LTU library, Google Scholar,

>> Tokens are: 
 ['\uf075', 'The', 'search', 'procedure', 'thesis', 'included', 'use', 'range', 'relevant', 'sources', ',', 'ACM', 'DL', ',', 'IEEE', 'Xplore', ',', 'Emerald', ',', 'EBSCO', ',', 'WoS', ',', 'LTU', 'library', ',', 'Google', 'Scholar', ',']

>> Bigrams are: 
 [('\uf075', 'The'), ('The', 'search'), ('search', 'procedure'), ('procedure', 'thesis'), ('thesis', 'included'), ('included', 'use'), ('use', 'range'), ('range', 'relevant'), ('relevant', 'sources'), ('sources', ','), (',', 'ACM'), ('ACM', 'DL'), ('DL', ','), (',', 'IEEE'), ('IEEE', 'Xplore'), ('Xplore', ','), (',', 'Emerald'), ('Emerald', ','), (',', 'EBSCO'), ('EBSCO', ','), (',', 'WoS'), ('WoS', ','), (',', 'LTU'), ('LTU', 'library'), ('library', ','), (',', 'Google'), ('Google', 'Scholar'), ('Scholar', ',')]

>> Trigrams are: 
 [('\uf075', 'The', 'search'), ('The', 'search', 'procedure'), ('search', 'procedure', 'thesis'), ('procedure', 'thesis', 'included'), ('thesis', 'included', 'use'), ('included', 'use', 'range'), ('use', 'range', 'relevant'), ('range', 'relevant', 'sources'), ('relevant', 'sources', ','), ('sources', ',', 'ACM'), (',', 'ACM', 'DL'), ('ACM', 'DL', ','), ('DL', ',', 'IEEE'), (',', 'IEEE', 'Xplore'), ('IEEE', 'Xplore', ','), ('Xplore', ',', 'Emerald'), (',', 'Emerald', ','), ('Emerald', ',', 'EBSCO'), (',', 'EBSCO', ','), ('EBSCO', ',', 'WoS'), (',', 'WoS', ','), ('WoS', ',', 'LTU'), (',', 'LTU', 'library'), ('LTU', 'library', ','), ('library', ',', 'Google'), (',', 'Google', 'Scholar'), ('Google', 'Scholar', ',')]

>> POS Tags are: 
 [('\uf075', 'IN'), ('The', 'DT'), ('search', 'NN'), ('procedure', 'NN'), ('thesis', 'NN'), ('included', 'VBD'), ('use', 'NN'), ('range', 'NN'), ('relevant', 'JJ'), ('sources', 'NNS'), (',', ','), ('ACM', 'NNP'), ('DL', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Xplore', 'NNP'), (',', ','), ('Emerald', 'NNP'), (',', ','), ('EBSCO', 'NNP'), (',', ','), ('WoS', 'NNP'), (',', ','), ('LTU', 'NNP'), ('library', 'NN'), (',', ','), ('Google', 'NNP'), ('Scholar', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['The search procedure thesis', 'use range', 'relevant sources', 'ACM DL', 'IEEE Xplore', 'Emerald', 'EBSCO', 'WoS', 'LTU library', 'Google Scholar']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'IEEE Xplore'), ('PERSON', 'Emerald'), ('ORGANIZATION', 'EBSCO'), ('ORGANIZATION', 'WoS'), ('ORGANIZATION', 'LTU'), ('PERSON', 'Google Scholar')] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('search', 'search'), ('procedure', 'procedur'), ('thesis', 'thesi'), ('included', 'includ'), ('use', 'use'), ('range', 'rang'), ('relevant', 'relev'), ('sources', 'sourc'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('EBSCO', 'ebsco'), (',', ','), ('WoS', 'wo'), (',', ','), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('search', 'search'), ('procedure', 'procedur'), ('thesis', 'thesi'), ('included', 'includ'), ('use', 'use'), ('range', 'rang'), ('relevant', 'relev'), ('sources', 'sourc'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('EBSCO', 'ebsco'), (',', ','), ('WoS', 'wos'), (',', ','), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ',')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('The', 'The'), ('search', 'search'), ('procedure', 'procedure'), ('thesis', 'thesis'), ('included', 'included'), ('use', 'use'), ('range', 'range'), ('relevant', 'relevant'), ('sources', 'source'), (',', ','), ('ACM', 'ACM'), ('DL', 'DL'), (',', ','), ('IEEE', 'IEEE'), ('Xplore', 'Xplore'), (',', ','), ('Emerald', 'Emerald'), (',', ','), ('EBSCO', 'EBSCO'), (',', ','), ('WoS', 'WoS'), (',', ','), ('LTU', 'LTU'), ('library', 'library'), (',', ','), ('Google', 'Google'), ('Scholar', 'Scholar'), (',', ',')]



========================================== PARAGRAPH 220 ===========================================

Springers, and Elsevier.  

------------------- Sentence 1 -------------------

Springers, and Elsevier.

>> Tokens are: 
 ['Springers', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('Springers', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('Springers', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('Springers', 'NNS'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springers', 'Elsevier']

>> Named Entities are: 
 [('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('Springers', 'springer'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springers', 'springer'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('Springers', 'Springers'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



========================================== PARAGRAPH 221 ===========================================

 The resulting papers were then filtered based on year, abstract, content, citations, etc. The  searches on big data analytics were filtered based on the top ten ranked peer-reviewed  

------------------- Sentence 1 -------------------

 The resulting papers were then filtered based on year, abstract, content, citations, etc.

>> Tokens are: 
 ['\uf075', 'The', 'resulting', 'papers', 'filtered', 'based', 'year', ',', 'abstract', ',', 'content', ',', 'citations', ',', 'etc', '.']

>> Bigrams are: 
 [('\uf075', 'The'), ('The', 'resulting'), ('resulting', 'papers'), ('papers', 'filtered'), ('filtered', 'based'), ('based', 'year'), ('year', ','), (',', 'abstract'), ('abstract', ','), (',', 'content'), ('content', ','), (',', 'citations'), ('citations', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('\uf075', 'The', 'resulting'), ('The', 'resulting', 'papers'), ('resulting', 'papers', 'filtered'), ('papers', 'filtered', 'based'), ('filtered', 'based', 'year'), ('based', 'year', ','), ('year', ',', 'abstract'), (',', 'abstract', ','), ('abstract', ',', 'content'), (',', 'content', ','), ('content', ',', 'citations'), (',', 'citations', ','), ('citations', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('\uf075', 'IN'), ('The', 'DT'), ('resulting', 'VBG'), ('papers', 'NNS'), ('filtered', 'VBD'), ('based', 'VBN'), ('year', 'NN'), (',', ','), ('abstract', 'NN'), (',', ','), ('content', 'NN'), (',', ','), ('citations', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['papers', 'year', 'abstract', 'content', 'citations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('resulting', 'result'), ('papers', 'paper'), ('filtered', 'filter'), ('based', 'base'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citat'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('resulting', 'result'), ('papers', 'paper'), ('filtered', 'filter'), ('based', 'base'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citat'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('The', 'The'), ('resulting', 'resulting'), ('papers', 'paper'), ('filtered', 'filtered'), ('based', 'based'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citation'), (',', ','), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

The  searches on big data analytics were filtered based on the top ten ranked peer-reviewed

>> Tokens are: 
 ['The', 'searches', 'big', 'data', 'analytics', 'filtered', 'based', 'top', 'ten', 'ranked', 'peer-reviewed']

>> Bigrams are: 
 [('The', 'searches'), ('searches', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'filtered'), ('filtered', 'based'), ('based', 'top'), ('top', 'ten'), ('ten', 'ranked'), ('ranked', 'peer-reviewed')]

>> Trigrams are: 
 [('The', 'searches', 'big'), ('searches', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'filtered'), ('analytics', 'filtered', 'based'), ('filtered', 'based', 'top'), ('based', 'top', 'ten'), ('top', 'ten', 'ranked'), ('ten', 'ranked', 'peer-reviewed')]

>> POS Tags are: 
 [('The', 'DT'), ('searches', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('filtered', 'VBD'), ('based', 'VBN'), ('top', 'JJ'), ('ten', 'NN'), ('ranked', 'VBD'), ('peer-reviewed', 'JJ')]

>> Noun Phrases are: 
 ['The searches', 'big data analytics', 'top ten']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('filtered', 'filter'), ('based', 'base'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'rank'), ('peer-reviewed', 'peer-review')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('filtered', 'filter'), ('based', 'base'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'rank'), ('peer-reviewed', 'peer-review')]

>> Lemmatization: 
 [('The', 'The'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('filtered', 'filtered'), ('based', 'based'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'ranked'), ('peer-reviewed', 'peer-reviewed')]



========================================== PARAGRAPH 222 ===========================================

papers such as MIS Quarterly: Management Information Systems and Information Systems  

------------------- Sentence 1 -------------------

papers such as MIS Quarterly: Management Information Systems and Information Systems

>> Tokens are: 
 ['papers', 'MIS', 'Quarterly', ':', 'Management', 'Information', 'Systems', 'Information', 'Systems']

>> Bigrams are: 
 [('papers', 'MIS'), ('MIS', 'Quarterly'), ('Quarterly', ':'), (':', 'Management'), ('Management', 'Information'), ('Information', 'Systems'), ('Systems', 'Information'), ('Information', 'Systems')]

>> Trigrams are: 
 [('papers', 'MIS', 'Quarterly'), ('MIS', 'Quarterly', ':'), ('Quarterly', ':', 'Management'), (':', 'Management', 'Information'), ('Management', 'Information', 'Systems'), ('Information', 'Systems', 'Information'), ('Systems', 'Information', 'Systems')]

>> POS Tags are: 
 [('papers', 'NNS'), ('MIS', 'NNP'), ('Quarterly', 'NNP'), (':', ':'), ('Management', 'JJ'), ('Information', 'NNP'), ('Systems', 'NNPS'), ('Information', 'NNP'), ('Systems', 'NNP')]

>> Noun Phrases are: 
 ['papers MIS Quarterly', 'Management Information', 'Information Systems']

>> Named Entities are: 
 [('ORGANIZATION', 'MIS'), ('ORGANIZATION', 'Information Systems Information Systems')] 

>> Stemming using Porter Stemmer: 
 [('papers', 'paper'), ('MIS', 'mi'), ('Quarterly', 'quarterli'), (':', ':'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), ('Information', 'inform'), ('Systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('papers', 'paper'), ('MIS', 'mis'), ('Quarterly', 'quarter'), (':', ':'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), ('Information', 'inform'), ('Systems', 'system')]

>> Lemmatization: 
 [('papers', 'paper'), ('MIS', 'MIS'), ('Quarterly', 'Quarterly'), (':', ':'), ('Management', 'Management'), ('Information', 'Information'), ('Systems', 'Systems'), ('Information', 'Information'), ('Systems', 'Systems')]



========================================== PARAGRAPH 223 ===========================================

Research, with keyword searches including terms such as “Big data” and “big data  

------------------- Sentence 1 -------------------

Research, with keyword searches including terms such as “Big data” and “big data

>> Tokens are: 
 ['Research', ',', 'keyword', 'searches', 'including', 'terms', '“', 'Big', 'data', '”', '“', 'big', 'data']

>> Bigrams are: 
 [('Research', ','), (',', 'keyword'), ('keyword', 'searches'), ('searches', 'including'), ('including', 'terms'), ('terms', '“'), ('“', 'Big'), ('Big', 'data'), ('data', '”'), ('”', '“'), ('“', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Research', ',', 'keyword'), (',', 'keyword', 'searches'), ('keyword', 'searches', 'including'), ('searches', 'including', 'terms'), ('including', 'terms', '“'), ('terms', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', '”'), ('data', '”', '“'), ('”', '“', 'big'), ('“', 'big', 'data')]

>> POS Tags are: 
 [('Research', 'NN'), (',', ','), ('keyword', 'NN'), ('searches', 'NNS'), ('including', 'VBG'), ('terms', 'NNS'), ('“', 'VBP'), ('Big', 'NNP'), ('data', 'NNS'), ('”', 'NNP'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Research', 'keyword searches', 'terms', 'Big data ” “', 'big data']

>> Named Entities are: 
 [('GPE', 'Research')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'includ'), ('terms', 'term'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'includ'), ('terms', 'term'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Research', 'Research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'including'), ('terms', 'term'), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 224 ===========================================

analytics” for the period 2011 to 2019.  

------------------- Sentence 1 -------------------

analytics” for the period 2011 to 2019.

>> Tokens are: 
 ['analytics', '”', 'period', '2011', '2019', '.']

>> Bigrams are: 
 [('analytics', '”'), ('”', 'period'), ('period', '2011'), ('2011', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('analytics', '”', 'period'), ('”', 'period', '2011'), ('period', '2011', '2019'), ('2011', '2019', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('”', 'VBP'), ('period', 'NN'), ('2011', 'CD'), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics', 'period']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]



========================================== PARAGRAPH 225 ===========================================

Literature search  

------------------- Sentence 1 -------------------

Literature search

>> Tokens are: 
 ['Literature', 'search']

>> Bigrams are: 
 [('Literature', 'search')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Literature', 'NN'), ('search', 'NN')]

>> Noun Phrases are: 
 ['Literature search']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('search', 'search')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('search', 'search')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('search', 'search')]



========================================== PARAGRAPH 226 ===========================================

 Analytical reading of papers refers to reading the papers chosen based on the  aforementioned criteria deeply in order to understand the goals and the messages of those  

------------------- Sentence 1 -------------------

 Analytical reading of papers refers to reading the papers chosen based on the  aforementioned criteria deeply in order to understand the goals and the messages of those

>> Tokens are: 
 ['\uf075', 'Analytical', 'reading', 'papers', 'refers', 'reading', 'papers', 'chosen', 'based', 'aforementioned', 'criteria', 'deeply', 'order', 'understand', 'goals', 'messages']

>> Bigrams are: 
 [('\uf075', 'Analytical'), ('Analytical', 'reading'), ('reading', 'papers'), ('papers', 'refers'), ('refers', 'reading'), ('reading', 'papers'), ('papers', 'chosen'), ('chosen', 'based'), ('based', 'aforementioned'), ('aforementioned', 'criteria'), ('criteria', 'deeply'), ('deeply', 'order'), ('order', 'understand'), ('understand', 'goals'), ('goals', 'messages')]

>> Trigrams are: 
 [('\uf075', 'Analytical', 'reading'), ('Analytical', 'reading', 'papers'), ('reading', 'papers', 'refers'), ('papers', 'refers', 'reading'), ('refers', 'reading', 'papers'), ('reading', 'papers', 'chosen'), ('papers', 'chosen', 'based'), ('chosen', 'based', 'aforementioned'), ('based', 'aforementioned', 'criteria'), ('aforementioned', 'criteria', 'deeply'), ('criteria', 'deeply', 'order'), ('deeply', 'order', 'understand'), ('order', 'understand', 'goals'), ('understand', 'goals', 'messages')]

>> POS Tags are: 
 [('\uf075', 'JJ'), ('Analytical', 'NNP'), ('reading', 'NN'), ('papers', 'NNS'), ('refers', 'NNS'), ('reading', 'VBG'), ('papers', 'NNS'), ('chosen', 'VBP'), ('based', 'VBN'), ('aforementioned', 'JJ'), ('criteria', 'NNS'), ('deeply', 'RB'), ('order', 'NN'), ('understand', 'JJ'), ('goals', 'NNS'), ('messages', 'NNS')]

>> Noun Phrases are: 
 ['\uf075 Analytical reading papers refers', 'papers', 'aforementioned criteria', 'order', 'understand goals messages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('Analytical', 'analyt'), ('reading', 'read'), ('papers', 'paper'), ('refers', 'refer'), ('reading', 'read'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('aforementioned', 'aforement'), ('criteria', 'criteria'), ('deeply', 'deepli'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'messag')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('Analytical', 'analyt'), ('reading', 'read'), ('papers', 'paper'), ('refers', 'refer'), ('reading', 'read'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('aforementioned', 'aforement'), ('criteria', 'criteria'), ('deeply', 'deepli'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'messag')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('Analytical', 'Analytical'), ('reading', 'reading'), ('papers', 'paper'), ('refers', 'refers'), ('reading', 'reading'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'based'), ('aforementioned', 'aforementioned'), ('criteria', 'criterion'), ('deeply', 'deeply'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'message')]



========================================== PARAGRAPH 227 ===========================================

papers. Accordingly, the first step is to prepare the reading, reading the paper more than  

------------------- Sentence 1 -------------------

papers.

>> Tokens are: 
 ['papers', '.']

>> Bigrams are: 
 [('papers', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('papers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['papers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('papers', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('papers', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('papers', 'paper'), ('.', '.')]


------------------- Sentence 2 -------------------

Accordingly, the first step is to prepare the reading, reading the paper more than

>> Tokens are: 
 ['Accordingly', ',', 'first', 'step', 'prepare', 'reading', ',', 'reading', 'paper']

>> Bigrams are: 
 [('Accordingly', ','), (',', 'first'), ('first', 'step'), ('step', 'prepare'), ('prepare', 'reading'), ('reading', ','), (',', 'reading'), ('reading', 'paper')]

>> Trigrams are: 
 [('Accordingly', ',', 'first'), (',', 'first', 'step'), ('first', 'step', 'prepare'), ('step', 'prepare', 'reading'), ('prepare', 'reading', ','), ('reading', ',', 'reading'), (',', 'reading', 'paper')]

>> POS Tags are: 
 [('Accordingly', 'RB'), (',', ','), ('first', 'JJ'), ('step', 'NN'), ('prepare', 'NN'), ('reading', 'NN'), (',', ','), ('reading', 'VBG'), ('paper', 'NN')]

>> Noun Phrases are: 
 ['first step prepare reading', 'paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accordingly', 'accordingli'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepar'), ('reading', 'read'), (',', ','), ('reading', 'read'), ('paper', 'paper')]

>> Stemming using Snowball Stemmer: 
 [('Accordingly', 'accord'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepar'), ('reading', 'read'), (',', ','), ('reading', 'read'), ('paper', 'paper')]

>> Lemmatization: 
 [('Accordingly', 'Accordingly'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepare'), ('reading', 'reading'), (',', ','), ('reading', 'reading'), ('paper', 'paper')]



========================================== PARAGRAPH 228 ===========================================

once and writing notes. The second is to use advanced reading techniques to re-read the  

------------------- Sentence 1 -------------------

once and writing notes.

>> Tokens are: 
 ['writing', 'notes', '.']

>> Bigrams are: 
 [('writing', 'notes'), ('notes', '.')]

>> Trigrams are: 
 [('writing', 'notes', '.')]

>> POS Tags are: 
 [('writing', 'VBG'), ('notes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['notes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('writing', 'write'), ('notes', 'note'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('writing', 'write'), ('notes', 'note'), ('.', '.')]

>> Lemmatization: 
 [('writing', 'writing'), ('notes', 'note'), ('.', '.')]


------------------- Sentence 2 -------------------

The second is to use advanced reading techniques to re-read the

>> Tokens are: 
 ['The', 'second', 'use', 'advanced', 'reading', 'techniques', 're-read']

>> Bigrams are: 
 [('The', 'second'), ('second', 'use'), ('use', 'advanced'), ('advanced', 'reading'), ('reading', 'techniques'), ('techniques', 're-read')]

>> Trigrams are: 
 [('The', 'second', 'use'), ('second', 'use', 'advanced'), ('use', 'advanced', 'reading'), ('advanced', 'reading', 'techniques'), ('reading', 'techniques', 're-read')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('use', 'NN'), ('advanced', 'VBD'), ('reading', 'VBG'), ('techniques', 'NNS'), ('re-read', 'JJ')]

>> Noun Phrases are: 
 ['The second use', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanc'), ('reading', 'read'), ('techniques', 'techniqu'), ('re-read', 're-read')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanc'), ('reading', 'read'), ('techniques', 'techniqu'), ('re-read', 're-read')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanced'), ('reading', 'reading'), ('techniques', 'technique'), ('re-read', 're-read')]



========================================== PARAGRAPH 229 ===========================================

paper to gain a better picture of and more insight into the paper’s work as well as  

------------------- Sentence 1 -------------------

paper to gain a better picture of and more insight into the paper’s work as well as

>> Tokens are: 
 ['paper', 'gain', 'better', 'picture', 'insight', 'paper', '’', 'work', 'well']

>> Bigrams are: 
 [('paper', 'gain'), ('gain', 'better'), ('better', 'picture'), ('picture', 'insight'), ('insight', 'paper'), ('paper', '’'), ('’', 'work'), ('work', 'well')]

>> Trigrams are: 
 [('paper', 'gain', 'better'), ('gain', 'better', 'picture'), ('better', 'picture', 'insight'), ('picture', 'insight', 'paper'), ('insight', 'paper', '’'), ('paper', '’', 'work'), ('’', 'work', 'well')]

>> POS Tags are: 
 [('paper', 'NN'), ('gain', 'NN'), ('better', 'RBR'), ('picture', 'NN'), ('insight', 'JJ'), ('paper', 'NN'), ('’', 'NN'), ('work', 'NN'), ('well', 'RB')]

>> Noun Phrases are: 
 ['paper gain', 'picture', 'insight paper ’ work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'pictur'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well')]

>> Stemming using Snowball Stemmer: 
 [('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'pictur'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well')]

>> Lemmatization: 
 [('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'picture'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well')]



========================================== PARAGRAPH 230 ===========================================

developing a better understanding. A final evaluative reading of the paper is then required.  

------------------- Sentence 1 -------------------

developing a better understanding.

>> Tokens are: 
 ['developing', 'better', 'understanding', '.']

>> Bigrams are: 
 [('developing', 'better'), ('better', 'understanding'), ('understanding', '.')]

>> Trigrams are: 
 [('developing', 'better', 'understanding'), ('better', 'understanding', '.')]

>> POS Tags are: 
 [('developing', 'VBG'), ('better', 'RBR'), ('understanding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('developing', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('developing', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('developing', 'developing'), ('better', 'better'), ('understanding', 'understanding'), ('.', '.')]


------------------- Sentence 2 -------------------

A final evaluative reading of the paper is then required.

>> Tokens are: 
 ['A', 'final', 'evaluative', 'reading', 'paper', 'required', '.']

>> Bigrams are: 
 [('A', 'final'), ('final', 'evaluative'), ('evaluative', 'reading'), ('reading', 'paper'), ('paper', 'required'), ('required', '.')]

>> Trigrams are: 
 [('A', 'final', 'evaluative'), ('final', 'evaluative', 'reading'), ('evaluative', 'reading', 'paper'), ('reading', 'paper', 'required'), ('paper', 'required', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('final', 'JJ'), ('evaluative', 'NN'), ('reading', 'VBG'), ('paper', 'NN'), ('required', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['A final evaluative', 'paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('final', 'final'), ('evaluative', 'evalu'), ('reading', 'read'), ('paper', 'paper'), ('required', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('final', 'final'), ('evaluative', 'evalu'), ('reading', 'read'), ('paper', 'paper'), ('required', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('final', 'final'), ('evaluative', 'evaluative'), ('reading', 'reading'), ('paper', 'paper'), ('required', 'required'), ('.', '.')]



========================================== PARAGRAPH 231 ===========================================

Literature analysis and synthesis   

------------------- Sentence 1 -------------------

Literature analysis and synthesis

>> Tokens are: 
 ['Literature', 'analysis', 'synthesis']

>> Bigrams are: 
 [('Literature', 'analysis'), ('analysis', 'synthesis')]

>> Trigrams are: 
 [('Literature', 'analysis', 'synthesis')]

>> POS Tags are: 
 [('Literature', 'NN'), ('analysis', 'NN'), ('synthesis', 'NN')]

>> Noun Phrases are: 
 ['Literature analysis synthesis']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('analysis', 'analysi'), ('synthesis', 'synthesi')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('analysis', 'analysi'), ('synthesis', 'synthesi')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('analysis', 'analysis'), ('synthesis', 'synthesis')]



========================================== PARAGRAPH 232 ===========================================

 This literature review seeks to provide a description and evaluation of the current state of  big data analytics. It designed to give an overview of the explored sources based on  

------------------- Sentence 1 -------------------

 This literature review seeks to provide a description and evaluation of the current state of  big data analytics.

>> Tokens are: 
 ['\uf075', 'This', 'literature', 'review', 'seeks', 'provide', 'description', 'evaluation', 'current', 'state', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('\uf075', 'This'), ('This', 'literature'), ('literature', 'review'), ('review', 'seeks'), ('seeks', 'provide'), ('provide', 'description'), ('description', 'evaluation'), ('evaluation', 'current'), ('current', 'state'), ('state', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('\uf075', 'This', 'literature'), ('This', 'literature', 'review'), ('literature', 'review', 'seeks'), ('review', 'seeks', 'provide'), ('seeks', 'provide', 'description'), ('provide', 'description', 'evaluation'), ('description', 'evaluation', 'current'), ('evaluation', 'current', 'state'), ('current', 'state', 'big'), ('state', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('\uf075', 'NN'), ('This', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('seeks', 'VBZ'), ('provide', 'JJ'), ('description', 'NN'), ('evaluation', 'NN'), ('current', 'JJ'), ('state', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['\uf075', 'This literature review', 'provide description evaluation', 'current state', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('This', 'thi'), ('literature', 'literatur'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provid'), ('description', 'descript'), ('evaluation', 'evalu'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('This', 'this'), ('literature', 'literatur'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provid'), ('description', 'descript'), ('evaluation', 'evalu'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('This', 'This'), ('literature', 'literature'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provide'), ('description', 'description'), ('evaluation', 'evaluation'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

It designed to give an overview of the explored sources based on

>> Tokens are: 
 ['It', 'designed', 'give', 'overview', 'explored', 'sources', 'based']

>> Bigrams are: 
 [('It', 'designed'), ('designed', 'give'), ('give', 'overview'), ('overview', 'explored'), ('explored', 'sources'), ('sources', 'based')]

>> Trigrams are: 
 [('It', 'designed', 'give'), ('designed', 'give', 'overview'), ('give', 'overview', 'explored'), ('overview', 'explored', 'sources'), ('explored', 'sources', 'based')]

>> POS Tags are: 
 [('It', 'PRP'), ('designed', 'VBD'), ('give', 'JJ'), ('overview', 'NN'), ('explored', 'VBD'), ('sources', 'NNS'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['give overview', 'sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('designed', 'design'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explor'), ('sources', 'sourc'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('designed', 'design'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explor'), ('sources', 'sourc'), ('based', 'base')]

>> Lemmatization: 
 [('It', 'It'), ('designed', 'designed'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explored'), ('sources', 'source'), ('based', 'based')]



========================================== PARAGRAPH 233 ===========================================

extensive searches around this topic, showing how the research covers a large study field  

------------------- Sentence 1 -------------------

extensive searches around this topic, showing how the research covers a large study field

>> Tokens are: 
 ['extensive', 'searches', 'around', 'topic', ',', 'showing', 'research', 'covers', 'large', 'study', 'field']

>> Bigrams are: 
 [('extensive', 'searches'), ('searches', 'around'), ('around', 'topic'), ('topic', ','), (',', 'showing'), ('showing', 'research'), ('research', 'covers'), ('covers', 'large'), ('large', 'study'), ('study', 'field')]

>> Trigrams are: 
 [('extensive', 'searches', 'around'), ('searches', 'around', 'topic'), ('around', 'topic', ','), ('topic', ',', 'showing'), (',', 'showing', 'research'), ('showing', 'research', 'covers'), ('research', 'covers', 'large'), ('covers', 'large', 'study'), ('large', 'study', 'field')]

>> POS Tags are: 
 [('extensive', 'JJ'), ('searches', 'NNS'), ('around', 'IN'), ('topic', 'NN'), (',', ','), ('showing', 'VBG'), ('research', 'NN'), ('covers', 'VBZ'), ('large', 'JJ'), ('study', 'NN'), ('field', 'NN')]

>> Noun Phrases are: 
 ['extensive searches', 'topic', 'research', 'large study field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extensive', 'extens'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'show'), ('research', 'research'), ('covers', 'cover'), ('large', 'larg'), ('study', 'studi'), ('field', 'field')]

>> Stemming using Snowball Stemmer: 
 [('extensive', 'extens'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'show'), ('research', 'research'), ('covers', 'cover'), ('large', 'larg'), ('study', 'studi'), ('field', 'field')]

>> Lemmatization: 
 [('extensive', 'extensive'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'showing'), ('research', 'research'), ('covers', 'cover'), ('large', 'large'), ('study', 'study'), ('field', 'field')]



========================================== PARAGRAPH 234 ===========================================

in both academia and industry.   

------------------- Sentence 1 -------------------

in both academia and industry.

>> Tokens are: 
 ['academia', 'industry', '.']

>> Bigrams are: 
 [('academia', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('academia', 'industry', '.')]

>> POS Tags are: 
 [('academia', 'NN'), ('industry', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['academia industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('academia', 'academia'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('academia', 'academia'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('academia', 'academia'), ('industry', 'industry'), ('.', '.')]



========================================== PARAGRAPH 235 ===========================================

 Writing a literary analysis and synthesis for this topic thus involved generating a discussion  based on several sources and showing the relationships between the sources, particularly  

------------------- Sentence 1 -------------------

 Writing a literary analysis and synthesis for this topic thus involved generating a discussion  based on several sources and showing the relationships between the sources, particularly

>> Tokens are: 
 ['\uf075', 'Writing', 'literary', 'analysis', 'synthesis', 'topic', 'thus', 'involved', 'generating', 'discussion', 'based', 'several', 'sources', 'showing', 'relationships', 'sources', ',', 'particularly']

>> Bigrams are: 
 [('\uf075', 'Writing'), ('Writing', 'literary'), ('literary', 'analysis'), ('analysis', 'synthesis'), ('synthesis', 'topic'), ('topic', 'thus'), ('thus', 'involved'), ('involved', 'generating'), ('generating', 'discussion'), ('discussion', 'based'), ('based', 'several'), ('several', 'sources'), ('sources', 'showing'), ('showing', 'relationships'), ('relationships', 'sources'), ('sources', ','), (',', 'particularly')]

>> Trigrams are: 
 [('\uf075', 'Writing', 'literary'), ('Writing', 'literary', 'analysis'), ('literary', 'analysis', 'synthesis'), ('analysis', 'synthesis', 'topic'), ('synthesis', 'topic', 'thus'), ('topic', 'thus', 'involved'), ('thus', 'involved', 'generating'), ('involved', 'generating', 'discussion'), ('generating', 'discussion', 'based'), ('discussion', 'based', 'several'), ('based', 'several', 'sources'), ('several', 'sources', 'showing'), ('sources', 'showing', 'relationships'), ('showing', 'relationships', 'sources'), ('relationships', 'sources', ','), ('sources', ',', 'particularly')]

>> POS Tags are: 
 [('\uf075', 'NN'), ('Writing', 'NNP'), ('literary', 'JJ'), ('analysis', 'NN'), ('synthesis', 'NN'), ('topic', 'NN'), ('thus', 'RB'), ('involved', 'JJ'), ('generating', 'VBG'), ('discussion', 'NN'), ('based', 'VBN'), ('several', 'JJ'), ('sources', 'NNS'), ('showing', 'VBG'), ('relationships', 'NNS'), ('sources', 'NNS'), (',', ','), ('particularly', 'RB')]

>> Noun Phrases are: 
 ['\uf075 Writing', 'literary analysis synthesis topic', 'discussion', 'several sources', 'relationships sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('Writing', 'write'), ('literary', 'literari'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('topic', 'topic'), ('thus', 'thu'), ('involved', 'involv'), ('generating', 'gener'), ('discussion', 'discuss'), ('based', 'base'), ('several', 'sever'), ('sources', 'sourc'), ('showing', 'show'), ('relationships', 'relationship'), ('sources', 'sourc'), (',', ','), ('particularly', 'particularli')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('Writing', 'write'), ('literary', 'literari'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('topic', 'topic'), ('thus', 'thus'), ('involved', 'involv'), ('generating', 'generat'), ('discussion', 'discuss'), ('based', 'base'), ('several', 'sever'), ('sources', 'sourc'), ('showing', 'show'), ('relationships', 'relationship'), ('sources', 'sourc'), (',', ','), ('particularly', 'particular')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('Writing', 'Writing'), ('literary', 'literary'), ('analysis', 'analysis'), ('synthesis', 'synthesis'), ('topic', 'topic'), ('thus', 'thus'), ('involved', 'involved'), ('generating', 'generating'), ('discussion', 'discussion'), ('based', 'based'), ('several', 'several'), ('sources', 'source'), ('showing', 'showing'), ('relationships', 'relationship'), ('sources', 'source'), (',', ','), ('particularly', 'particularly')]



========================================== PARAGRAPH 236 ===========================================

when different ideas or focuses emerged in the research that required explanation or  

------------------- Sentence 1 -------------------

when different ideas or focuses emerged in the research that required explanation or

>> Tokens are: 
 ['different', 'ideas', 'focuses', 'emerged', 'research', 'required', 'explanation']

>> Bigrams are: 
 [('different', 'ideas'), ('ideas', 'focuses'), ('focuses', 'emerged'), ('emerged', 'research'), ('research', 'required'), ('required', 'explanation')]

>> Trigrams are: 
 [('different', 'ideas', 'focuses'), ('ideas', 'focuses', 'emerged'), ('focuses', 'emerged', 'research'), ('emerged', 'research', 'required'), ('research', 'required', 'explanation')]

>> POS Tags are: 
 [('different', 'JJ'), ('ideas', 'NNS'), ('focuses', 'VBZ'), ('emerged', 'VBD'), ('research', 'NN'), ('required', 'VBN'), ('explanation', 'NN')]

>> Noun Phrases are: 
 ['different ideas', 'research', 'explanation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerg'), ('research', 'research'), ('required', 'requir'), ('explanation', 'explan')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerg'), ('research', 'research'), ('required', 'requir'), ('explanation', 'explan')]

>> Lemmatization: 
 [('different', 'different'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerged'), ('research', 'research'), ('required', 'required'), ('explanation', 'explanation')]



========================================== PARAGRAPH 237 ===========================================

demonstrated new ideas or theories.  

------------------- Sentence 1 -------------------

demonstrated new ideas or theories.

>> Tokens are: 
 ['demonstrated', 'new', 'ideas', 'theories', '.']

>> Bigrams are: 
 [('demonstrated', 'new'), ('new', 'ideas'), ('ideas', 'theories'), ('theories', '.')]

>> Trigrams are: 
 [('demonstrated', 'new', 'ideas'), ('new', 'ideas', 'theories'), ('ideas', 'theories', '.')]

>> POS Tags are: 
 [('demonstrated', 'VBN'), ('new', 'JJ'), ('ideas', 'NNS'), ('theories', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['new ideas theories']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('demonstrated', 'demonstr'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('demonstrated', 'demonstr'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('demonstrated', 'demonstrated'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theory'), ('.', '.')]



========================================== PARAGRAPH 238 ===========================================

Reviewing and combining the result  

------------------- Sentence 1 -------------------

Reviewing and combining the result

>> Tokens are: 
 ['Reviewing', 'combining', 'result']

>> Bigrams are: 
 [('Reviewing', 'combining'), ('combining', 'result')]

>> Trigrams are: 
 [('Reviewing', 'combining', 'result')]

>> POS Tags are: 
 [('Reviewing', 'VBG'), ('combining', 'VBG'), ('result', 'NN')]

>> Noun Phrases are: 
 ['result']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reviewing', 'review'), ('combining', 'combin'), ('result', 'result')]

>> Stemming using Snowball Stemmer: 
 [('Reviewing', 'review'), ('combining', 'combin'), ('result', 'result')]

>> Lemmatization: 
 [('Reviewing', 'Reviewing'), ('combining', 'combining'), ('result', 'result')]



========================================== PARAGRAPH 239 ===========================================

 The research results from the big data analytics literature review are combined, then the  work is reviewed, alongside an explanation of the methodology used and the debates  

------------------- Sentence 1 -------------------

 The research results from the big data analytics literature review are combined, then the  work is reviewed, alongside an explanation of the methodology used and the debates

>> Tokens are: 
 ['\uf075', 'The', 'research', 'results', 'big', 'data', 'analytics', 'literature', 'review', 'combined', ',', 'work', 'reviewed', ',', 'alongside', 'explanation', 'methodology', 'used', 'debates']

>> Bigrams are: 
 [('\uf075', 'The'), ('The', 'research'), ('research', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'literature'), ('literature', 'review'), ('review', 'combined'), ('combined', ','), (',', 'work'), ('work', 'reviewed'), ('reviewed', ','), (',', 'alongside'), ('alongside', 'explanation'), ('explanation', 'methodology'), ('methodology', 'used'), ('used', 'debates')]

>> Trigrams are: 
 [('\uf075', 'The', 'research'), ('The', 'research', 'results'), ('research', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'literature'), ('analytics', 'literature', 'review'), ('literature', 'review', 'combined'), ('review', 'combined', ','), ('combined', ',', 'work'), (',', 'work', 'reviewed'), ('work', 'reviewed', ','), ('reviewed', ',', 'alongside'), (',', 'alongside', 'explanation'), ('alongside', 'explanation', 'methodology'), ('explanation', 'methodology', 'used'), ('methodology', 'used', 'debates')]

>> POS Tags are: 
 [('\uf075', 'IN'), ('The', 'DT'), ('research', 'NN'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('literature', 'VBP'), ('review', 'NN'), ('combined', 'VBN'), (',', ','), ('work', 'NN'), ('reviewed', 'VBD'), (',', ','), ('alongside', 'JJ'), ('explanation', 'NN'), ('methodology', 'NN'), ('used', 'VBN'), ('debates', 'NNS')]

>> Noun Phrases are: 
 ['The research results', 'big data analytics', 'review', 'work', 'alongside explanation methodology', 'debates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('literature', 'literatur'), ('review', 'review'), ('combined', 'combin'), (',', ','), ('work', 'work'), ('reviewed', 'review'), (',', ','), ('alongside', 'alongsid'), ('explanation', 'explan'), ('methodology', 'methodolog'), ('used', 'use'), ('debates', 'debat')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('literature', 'literatur'), ('review', 'review'), ('combined', 'combin'), (',', ','), ('work', 'work'), ('reviewed', 'review'), (',', ','), ('alongside', 'alongsid'), ('explanation', 'explan'), ('methodology', 'methodolog'), ('used', 'use'), ('debates', 'debat')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('The', 'The'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('literature', 'literature'), ('review', 'review'), ('combined', 'combined'), (',', ','), ('work', 'work'), ('reviewed', 'reviewed'), (',', ','), ('alongside', 'alongside'), ('explanation', 'explanation'), ('methodology', 'methodology'), ('used', 'used'), ('debates', 'debate')]



========================================== PARAGRAPH 240 ===========================================

arising.  

------------------- Sentence 1 -------------------

arising.

>> Tokens are: 
 ['arising', '.']

>> Bigrams are: 
 [('arising', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('arising', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arising', 'aris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('arising', 'aris'), ('.', '.')]

>> Lemmatization: 
 [('arising', 'arising'), ('.', '.')]



========================================== PARAGRAPH 241 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 242 ===========================================

7  

------------------- Sentence 1 -------------------

7

>> Tokens are: 
 ['7']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7')]

>> Stemming using Snowball Stemmer: 
 [('7', '7')]

>> Lemmatization: 
 [('7', '7')]



========================================== PARAGRAPH 243 ===========================================

  


========================================== PARAGRAPH 244 ===========================================

  


========================================== PARAGRAPH 245 ===========================================

Figure 5: Literature review processes.  

------------------- Sentence 1 -------------------

Figure 5: Literature review processes.

>> Tokens are: 
 ['Figure', '5', ':', 'Literature', 'review', 'processes', '.']

>> Bigrams are: 
 [('Figure', '5'), ('5', ':'), (':', 'Literature'), ('Literature', 'review'), ('review', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('Figure', '5', ':'), ('5', ':', 'Literature'), (':', 'Literature', 'review'), ('Literature', 'review', 'processes'), ('review', 'processes', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('5', 'CD'), (':', ':'), ('Literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('5', '5'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('5', '5'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('5', '5'), (':', ':'), ('Literature', 'Literature'), ('review', 'review'), ('processes', 'process'), ('.', '.')]



========================================== PARAGRAPH 246 ===========================================

  


========================================== PARAGRAPH 247 ===========================================

4. Scope delimitation and risks   

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Scope delimitation and risks

>> Tokens are: 
 ['Scope', 'delimitation', 'risks']

>> Bigrams are: 
 [('Scope', 'delimitation'), ('delimitation', 'risks')]

>> Trigrams are: 
 [('Scope', 'delimitation', 'risks')]

>> POS Tags are: 
 [('Scope', 'NNP'), ('delimitation', 'NN'), ('risks', 'NNS')]

>> Noun Phrases are: 
 ['Scope delimitation risks']

>> Named Entities are: 
 [('GPE', 'Scope')] 

>> Stemming using Porter Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk')]

>> Stemming using Snowball Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk')]

>> Lemmatization: 
 [('Scope', 'Scope'), ('delimitation', 'delimitation'), ('risks', 'risk')]



========================================== PARAGRAPH 248 ===========================================

The scope of this research will be determining the shortcomings in reviewing big data analytics,  

------------------- Sentence 1 -------------------

The scope of this research will be determining the shortcomings in reviewing big data analytics,

>> Tokens are: 
 ['The', 'scope', 'research', 'determining', 'shortcomings', 'reviewing', 'big', 'data', 'analytics', ',']

>> Bigrams are: 
 [('The', 'scope'), ('scope', 'research'), ('research', 'determining'), ('determining', 'shortcomings'), ('shortcomings', 'reviewing'), ('reviewing', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ',')]

>> Trigrams are: 
 [('The', 'scope', 'research'), ('scope', 'research', 'determining'), ('research', 'determining', 'shortcomings'), ('determining', 'shortcomings', 'reviewing'), ('shortcomings', 'reviewing', 'big'), ('reviewing', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('scope', 'NN'), ('research', 'NN'), ('determining', 'VBG'), ('shortcomings', 'NNS'), ('reviewing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['The scope research', 'shortcomings', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determin'), ('shortcomings', 'shortcom'), ('reviewing', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determin'), ('shortcomings', 'shortcom'), ('reviewing', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determining'), ('shortcomings', 'shortcoming'), ('reviewing', 'reviewing'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ',')]



========================================== PARAGRAPH 249 ===========================================

one can determine what has been defined and what is the criteria for selecting the analytics and  

------------------- Sentence 1 -------------------

one can determine what has been defined and what is the criteria for selecting the analytics and

>> Tokens are: 
 ['one', 'determine', 'defined', 'criteria', 'selecting', 'analytics']

>> Bigrams are: 
 [('one', 'determine'), ('determine', 'defined'), ('defined', 'criteria'), ('criteria', 'selecting'), ('selecting', 'analytics')]

>> Trigrams are: 
 [('one', 'determine', 'defined'), ('determine', 'defined', 'criteria'), ('defined', 'criteria', 'selecting'), ('criteria', 'selecting', 'analytics')]

>> POS Tags are: 
 [('one', 'CD'), ('determine', 'NN'), ('defined', 'VBN'), ('criteria', 'NNS'), ('selecting', 'VBG'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['determine', 'criteria', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('determine', 'determin'), ('defined', 'defin'), ('criteria', 'criteria'), ('selecting', 'select'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('determine', 'determin'), ('defined', 'defin'), ('criteria', 'criteria'), ('selecting', 'select'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('one', 'one'), ('determine', 'determine'), ('defined', 'defined'), ('criteria', 'criterion'), ('selecting', 'selecting'), ('analytics', 'analytics')]



========================================== PARAGRAPH 250 ===========================================

tools for big data. The review can reveal which problems have been solved, and what else should  

------------------- Sentence 1 -------------------

tools for big data.

>> Tokens are: 
 ['tools', 'big', 'data', '.']

>> Bigrams are: 
 [('tools', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('tools', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('tools', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['tools', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The review can reveal which problems have been solved, and what else should

>> Tokens are: 
 ['The', 'review', 'reveal', 'problems', 'solved', ',', 'else']

>> Bigrams are: 
 [('The', 'review'), ('review', 'reveal'), ('reveal', 'problems'), ('problems', 'solved'), ('solved', ','), (',', 'else')]

>> Trigrams are: 
 [('The', 'review', 'reveal'), ('review', 'reveal', 'problems'), ('reveal', 'problems', 'solved'), ('problems', 'solved', ','), ('solved', ',', 'else')]

>> POS Tags are: 
 [('The', 'DT'), ('review', 'NN'), ('reveal', 'NN'), ('problems', 'NNS'), ('solved', 'VBD'), (',', ','), ('else', 'RB')]

>> Noun Phrases are: 
 ['The review reveal problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solv'), (',', ','), ('else', 'els')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solv'), (',', ','), ('else', 'els')]

>> Lemmatization: 
 [('The', 'The'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solved'), (',', ','), ('else', 'else')]



========================================== PARAGRAPH 251 ===========================================

be known. Moreover, it helps notifying the researchers about what have been presented which  

------------------- Sentence 1 -------------------

be known.

>> Tokens are: 
 ['known', '.']

>> Bigrams are: 
 [('known', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('known', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('known', 'known'), ('.', '.')]


------------------- Sentence 2 -------------------

Moreover, it helps notifying the researchers about what have been presented which

>> Tokens are: 
 ['Moreover', ',', 'helps', 'notifying', 'researchers', 'presented']

>> Bigrams are: 
 [('Moreover', ','), (',', 'helps'), ('helps', 'notifying'), ('notifying', 'researchers'), ('researchers', 'presented')]

>> Trigrams are: 
 [('Moreover', ',', 'helps'), (',', 'helps', 'notifying'), ('helps', 'notifying', 'researchers'), ('notifying', 'researchers', 'presented')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('helps', 'VBZ'), ('notifying', 'VBG'), ('researchers', 'NNS'), ('presented', 'VBD')]

>> Noun Phrases are: 
 ['researchers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('helps', 'help'), ('notifying', 'notifi'), ('researchers', 'research'), ('presented', 'present')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('helps', 'help'), ('notifying', 'notifi'), ('researchers', 'research'), ('presented', 'present')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('helps', 'help'), ('notifying', 'notifying'), ('researchers', 'researcher'), ('presented', 'presented')]



========================================== PARAGRAPH 252 ===========================================

might open the doors for them to conduct more analytics for big data being an important topic  

------------------- Sentence 1 -------------------

might open the doors for them to conduct more analytics for big data being an important topic

>> Tokens are: 
 ['might', 'open', 'doors', 'conduct', 'analytics', 'big', 'data', 'important', 'topic']

>> Bigrams are: 
 [('might', 'open'), ('open', 'doors'), ('doors', 'conduct'), ('conduct', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'important'), ('important', 'topic')]

>> Trigrams are: 
 [('might', 'open', 'doors'), ('open', 'doors', 'conduct'), ('doors', 'conduct', 'analytics'), ('conduct', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'important'), ('data', 'important', 'topic')]

>> POS Tags are: 
 [('might', 'MD'), ('open', 'VB'), ('doors', 'NNS'), ('conduct', 'VBP'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('important', 'JJ'), ('topic', 'NN')]

>> Noun Phrases are: 
 ['doors', 'analytics', 'big data', 'important topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('topic', 'topic')]

>> Stemming using Snowball Stemmer: 
 [('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('topic', 'topic')]

>> Lemmatization: 
 [('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('important', 'important'), ('topic', 'topic')]



========================================== PARAGRAPH 253 ===========================================

nowadays and people directing toward this concept.   

------------------- Sentence 1 -------------------

nowadays and people directing toward this concept.

>> Tokens are: 
 ['nowadays', 'people', 'directing', 'toward', 'concept', '.']

>> Bigrams are: 
 [('nowadays', 'people'), ('people', 'directing'), ('directing', 'toward'), ('toward', 'concept'), ('concept', '.')]

>> Trigrams are: 
 [('nowadays', 'people', 'directing'), ('people', 'directing', 'toward'), ('directing', 'toward', 'concept'), ('toward', 'concept', '.')]

>> POS Tags are: 
 [('nowadays', 'NNS'), ('people', 'NNS'), ('directing', 'VBG'), ('toward', 'IN'), ('concept', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['nowadays people', 'concept']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('nowadays', 'nowaday'), ('people', 'peopl'), ('directing', 'direct'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('nowadays', 'nowaday'), ('people', 'peopl'), ('directing', 'direct'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]

>> Lemmatization: 
 [('nowadays', 'nowadays'), ('people', 'people'), ('directing', 'directing'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]



========================================== PARAGRAPH 254 ===========================================

The main challenges of using big data, which need to be resolved before it can be used effectively,  

------------------- Sentence 1 -------------------

The main challenges of using big data, which need to be resolved before it can be used effectively,

>> Tokens are: 
 ['The', 'main', 'challenges', 'using', 'big', 'data', ',', 'need', 'resolved', 'used', 'effectively', ',']

>> Bigrams are: 
 [('The', 'main'), ('main', 'challenges'), ('challenges', 'using'), ('using', 'big'), ('big', 'data'), ('data', ','), (',', 'need'), ('need', 'resolved'), ('resolved', 'used'), ('used', 'effectively'), ('effectively', ',')]

>> Trigrams are: 
 [('The', 'main', 'challenges'), ('main', 'challenges', 'using'), ('challenges', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'need'), (',', 'need', 'resolved'), ('need', 'resolved', 'used'), ('resolved', 'used', 'effectively'), ('used', 'effectively', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('challenges', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('need', 'VBP'), ('resolved', 'VBN'), ('used', 'JJ'), ('effectively', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['The main challenges', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('challenges', 'challenge'), ('using', 'using'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolved'), ('used', 'used'), ('effectively', 'effectively'), (',', ',')]



========================================== PARAGRAPH 255 ===========================================

include security and privacy issues, data capturing issues, and challenges in data analysis and  

------------------- Sentence 1 -------------------

include security and privacy issues, data capturing issues, and challenges in data analysis and

>> Tokens are: 
 ['include', 'security', 'privacy', 'issues', ',', 'data', 'capturing', 'issues', ',', 'challenges', 'data', 'analysis']

>> Bigrams are: 
 [('include', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', ','), (',', 'data'), ('data', 'capturing'), ('capturing', 'issues'), ('issues', ','), (',', 'challenges'), ('challenges', 'data'), ('data', 'analysis')]

>> Trigrams are: 
 [('include', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', ','), ('issues', ',', 'data'), (',', 'data', 'capturing'), ('data', 'capturing', 'issues'), ('capturing', 'issues', ','), ('issues', ',', 'challenges'), (',', 'challenges', 'data'), ('challenges', 'data', 'analysis')]

>> POS Tags are: 
 [('include', 'JJ'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), (',', ','), ('data', 'NNS'), ('capturing', 'VBG'), ('issues', 'NNS'), (',', ','), ('challenges', 'NNS'), ('data', 'VBP'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['include security privacy issues', 'data', 'issues', 'challenges', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('include', 'includ'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('capturing', 'captur'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('include', 'includ'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('capturing', 'captur'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('include', 'include'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), (',', ','), ('data', 'data'), ('capturing', 'capturing'), ('issues', 'issue'), (',', ','), ('challenges', 'challenge'), ('data', 'data'), ('analysis', 'analysis')]



========================================== PARAGRAPH 256 ===========================================

visualization to raise the positive role of big data analytics to many sectors. Storing the massive  

------------------- Sentence 1 -------------------

visualization to raise the positive role of big data analytics to many sectors.

>> Tokens are: 
 ['visualization', 'raise', 'positive', 'role', 'big', 'data', 'analytics', 'many', 'sectors', '.']

>> Bigrams are: 
 [('visualization', 'raise'), ('raise', 'positive'), ('positive', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'many'), ('many', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('visualization', 'raise', 'positive'), ('raise', 'positive', 'role'), ('positive', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'many'), ('analytics', 'many', 'sectors'), ('many', 'sectors', '.')]

>> POS Tags are: 
 [('visualization', 'NN'), ('raise', 'VB'), ('positive', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('many', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['visualization', 'positive role', 'big data analytics', 'many sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('visualization', 'visual'), ('raise', 'rais'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('visualization', 'visual'), ('raise', 'rais'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('visualization', 'visualization'), ('raise', 'raise'), ('positive', 'positive'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('many', 'many'), ('sectors', 'sector'), ('.', '.')]


------------------- Sentence 2 -------------------

Storing the massive

>> Tokens are: 
 ['Storing', 'massive']

>> Bigrams are: 
 [('Storing', 'massive')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Storing', 'VBG'), ('massive', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Storing', 'store'), ('massive', 'massiv')]

>> Stemming using Snowball Stemmer: 
 [('Storing', 'store'), ('massive', 'massiv')]

>> Lemmatization: 
 [('Storing', 'Storing'), ('massive', 'massive')]



========================================== PARAGRAPH 257 ===========================================

volume of data coming from different sources is another key point that needs to be addressed yet  

------------------- Sentence 1 -------------------

volume of data coming from different sources is another key point that needs to be addressed yet

>> Tokens are: 
 ['volume', 'data', 'coming', 'different', 'sources', 'another', 'key', 'point', 'needs', 'addressed', 'yet']

>> Bigrams are: 
 [('volume', 'data'), ('data', 'coming'), ('coming', 'different'), ('different', 'sources'), ('sources', 'another'), ('another', 'key'), ('key', 'point'), ('point', 'needs'), ('needs', 'addressed'), ('addressed', 'yet')]

>> Trigrams are: 
 [('volume', 'data', 'coming'), ('data', 'coming', 'different'), ('coming', 'different', 'sources'), ('different', 'sources', 'another'), ('sources', 'another', 'key'), ('another', 'key', 'point'), ('key', 'point', 'needs'), ('point', 'needs', 'addressed'), ('needs', 'addressed', 'yet')]

>> POS Tags are: 
 [('volume', 'NN'), ('data', 'NNS'), ('coming', 'VBG'), ('different', 'JJ'), ('sources', 'NNS'), ('another', 'DT'), ('key', 'JJ'), ('point', 'NN'), ('needs', 'NNS'), ('addressed', 'VBD'), ('yet', 'RB')]

>> Noun Phrases are: 
 ['volume data', 'different sources', 'another key point needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('coming', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('another', 'anoth'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'address'), ('yet', 'yet')]

>> Stemming using Snowball Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('coming', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('another', 'anoth'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'address'), ('yet', 'yet')]

>> Lemmatization: 
 [('volume', 'volume'), ('data', 'data'), ('coming', 'coming'), ('different', 'different'), ('sources', 'source'), ('another', 'another'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'addressed'), ('yet', 'yet')]



========================================== PARAGRAPH 258 ===========================================

not currently resolved with the available tools. That created a need for studying and exploring new  

------------------- Sentence 1 -------------------

not currently resolved with the available tools.

>> Tokens are: 
 ['currently', 'resolved', 'available', 'tools', '.']

>> Bigrams are: 
 [('currently', 'resolved'), ('resolved', 'available'), ('available', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('currently', 'resolved', 'available'), ('resolved', 'available', 'tools'), ('available', 'tools', '.')]

>> POS Tags are: 
 [('currently', 'RB'), ('resolved', 'VBN'), ('available', 'JJ'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['available tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('currently', 'current'), ('resolved', 'resolv'), ('available', 'avail'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('currently', 'current'), ('resolved', 'resolv'), ('available', 'avail'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('currently', 'currently'), ('resolved', 'resolved'), ('available', 'available'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

That created a need for studying and exploring new

>> Tokens are: 
 ['That', 'created', 'need', 'studying', 'exploring', 'new']

>> Bigrams are: 
 [('That', 'created'), ('created', 'need'), ('need', 'studying'), ('studying', 'exploring'), ('exploring', 'new')]

>> Trigrams are: 
 [('That', 'created', 'need'), ('created', 'need', 'studying'), ('need', 'studying', 'exploring'), ('studying', 'exploring', 'new')]

>> POS Tags are: 
 [('That', 'DT'), ('created', 'VBD'), ('need', 'MD'), ('studying', 'VBG'), ('exploring', 'VBG'), ('new', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('created', 'creat'), ('need', 'need'), ('studying', 'studi'), ('exploring', 'explor'), ('new', 'new')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('created', 'creat'), ('need', 'need'), ('studying', 'studi'), ('exploring', 'explor'), ('new', 'new')]

>> Lemmatization: 
 [('That', 'That'), ('created', 'created'), ('need', 'need'), ('studying', 'studying'), ('exploring', 'exploring'), ('new', 'new')]



========================================== PARAGRAPH 259 ===========================================

analytics method which might help in addressing some difficulties in some sectors such as in retail,  

------------------- Sentence 1 -------------------

analytics method which might help in addressing some difficulties in some sectors such as in retail,

>> Tokens are: 
 ['analytics', 'method', 'might', 'help', 'addressing', 'difficulties', 'sectors', 'retail', ',']

>> Bigrams are: 
 [('analytics', 'method'), ('method', 'might'), ('might', 'help'), ('help', 'addressing'), ('addressing', 'difficulties'), ('difficulties', 'sectors'), ('sectors', 'retail'), ('retail', ',')]

>> Trigrams are: 
 [('analytics', 'method', 'might'), ('method', 'might', 'help'), ('might', 'help', 'addressing'), ('help', 'addressing', 'difficulties'), ('addressing', 'difficulties', 'sectors'), ('difficulties', 'sectors', 'retail'), ('sectors', 'retail', ',')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('method', 'NN'), ('might', 'MD'), ('help', 'VB'), ('addressing', 'VBG'), ('difficulties', 'NNS'), ('sectors', 'NNS'), ('retail', 'VBP'), (',', ',')]

>> Noun Phrases are: 
 ['analytics method', 'difficulties sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'address'), ('difficulties', 'difficulti'), ('sectors', 'sector'), ('retail', 'retail'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'address'), ('difficulties', 'difficulti'), ('sectors', 'sector'), ('retail', 'retail'), (',', ',')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'addressing'), ('difficulties', 'difficulty'), ('sectors', 'sector'), ('retail', 'retail'), (',', ',')]



========================================== PARAGRAPH 260 ===========================================

banking, healthcare, etc.  

------------------- Sentence 1 -------------------

banking, healthcare, etc.

>> Tokens are: 
 ['banking', ',', 'healthcare', ',', 'etc', '.']

>> Bigrams are: 
 [('banking', ','), (',', 'healthcare'), ('healthcare', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('banking', ',', 'healthcare'), (',', 'healthcare', ','), ('healthcare', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('banking', 'NN'), (',', ','), ('healthcare', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['banking', 'healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('banking', 'bank'), (',', ','), ('healthcare', 'healthcar'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('banking', 'bank'), (',', ','), ('healthcare', 'healthcar'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('banking', 'banking'), (',', ','), ('healthcare', 'healthcare'), (',', ','), ('etc', 'etc'), ('.', '.')]



========================================== PARAGRAPH 261 ===========================================

Determining the possible solutions to the shortcomings with, data visualization, predictive  

------------------- Sentence 1 -------------------

Determining the possible solutions to the shortcomings with, data visualization, predictive

>> Tokens are: 
 ['Determining', 'possible', 'solutions', 'shortcomings', ',', 'data', 'visualization', ',', 'predictive']

>> Bigrams are: 
 [('Determining', 'possible'), ('possible', 'solutions'), ('solutions', 'shortcomings'), ('shortcomings', ','), (',', 'data'), ('data', 'visualization'), ('visualization', ','), (',', 'predictive')]

>> Trigrams are: 
 [('Determining', 'possible', 'solutions'), ('possible', 'solutions', 'shortcomings'), ('solutions', 'shortcomings', ','), ('shortcomings', ',', 'data'), (',', 'data', 'visualization'), ('data', 'visualization', ','), ('visualization', ',', 'predictive')]

>> POS Tags are: 
 [('Determining', 'VBG'), ('possible', 'JJ'), ('solutions', 'NNS'), ('shortcomings', 'NNS'), (',', ','), ('data', 'NNS'), ('visualization', 'NN'), (',', ','), ('predictive', 'JJ')]

>> Noun Phrases are: 
 ['possible solutions shortcomings', 'data visualization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Determining', 'determin'), ('possible', 'possibl'), ('solutions', 'solut'), ('shortcomings', 'shortcom'), (',', ','), ('data', 'data'), ('visualization', 'visual'), (',', ','), ('predictive', 'predict')]

>> Stemming using Snowball Stemmer: 
 [('Determining', 'determin'), ('possible', 'possibl'), ('solutions', 'solut'), ('shortcomings', 'shortcom'), (',', ','), ('data', 'data'), ('visualization', 'visual'), (',', ','), ('predictive', 'predict')]

>> Lemmatization: 
 [('Determining', 'Determining'), ('possible', 'possible'), ('solutions', 'solution'), ('shortcomings', 'shortcoming'), (',', ','), ('data', 'data'), ('visualization', 'visualization'), (',', ','), ('predictive', 'predictive')]



========================================== PARAGRAPH 262 ===========================================

analytics, descriptive analytics, and diagnostic analytics which are solutions to big data challenges  

------------------- Sentence 1 -------------------

analytics, descriptive analytics, and diagnostic analytics which are solutions to big data challenges

>> Tokens are: 
 ['analytics', ',', 'descriptive', 'analytics', ',', 'diagnostic', 'analytics', 'solutions', 'big', 'data', 'challenges']

>> Bigrams are: 
 [('analytics', ','), (',', 'descriptive'), ('descriptive', 'analytics'), ('analytics', ','), (',', 'diagnostic'), ('diagnostic', 'analytics'), ('analytics', 'solutions'), ('solutions', 'big'), ('big', 'data'), ('data', 'challenges')]

>> Trigrams are: 
 [('analytics', ',', 'descriptive'), (',', 'descriptive', 'analytics'), ('descriptive', 'analytics', ','), ('analytics', ',', 'diagnostic'), (',', 'diagnostic', 'analytics'), ('diagnostic', 'analytics', 'solutions'), ('analytics', 'solutions', 'big'), ('solutions', 'big', 'data'), ('big', 'data', 'challenges')]

>> POS Tags are: 
 [('analytics', 'NNS'), (',', ','), ('descriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('diagnostic', 'JJ'), ('analytics', 'NNS'), ('solutions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS')]

>> Noun Phrases are: 
 ['analytics', 'descriptive analytics', 'diagnostic analytics solutions', 'big data challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), (',', ','), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), (',', ','), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng')]

>> Lemmatization: 
 [('analytics', 'analytics'), (',', ','), ('descriptive', 'descriptive'), ('analytics', 'analytics'), (',', ','), ('diagnostic', 'diagnostic'), ('analytics', 'analytics'), ('solutions', 'solution'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge')]



========================================== PARAGRAPH 263 ===========================================

in capturing and analysing the data. Organisations and individual use statistical models and 

------------------- Sentence 1 -------------------

in capturing and analysing the data.

>> Tokens are: 
 ['capturing', 'analysing', 'data', '.']

>> Bigrams are: 
 [('capturing', 'analysing'), ('analysing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('capturing', 'analysing', 'data'), ('analysing', 'data', '.')]

>> POS Tags are: 
 [('capturing', 'VBG'), ('analysing', 'VBG'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('capturing', 'captur'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('capturing', 'captur'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('capturing', 'capturing'), ('analysing', 'analysing'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Organisations and individual use statistical models and

>> Tokens are: 
 ['Organisations', 'individual', 'use', 'statistical', 'models']

>> Bigrams are: 
 [('Organisations', 'individual'), ('individual', 'use'), ('use', 'statistical'), ('statistical', 'models')]

>> Trigrams are: 
 [('Organisations', 'individual', 'use'), ('individual', 'use', 'statistical'), ('use', 'statistical', 'models')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('individual', 'JJ'), ('use', 'RB'), ('statistical', 'JJ'), ('models', 'NNS')]

>> Noun Phrases are: 
 ['Organisations', 'statistical models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('individual', 'individual'), ('use', 'use'), ('statistical', 'statistical'), ('models', 'model')]



========================================== PARAGRAPH 264 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 265 ===========================================

8  

------------------- Sentence 1 -------------------

8

>> Tokens are: 
 ['8']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8')]

>> Stemming using Snowball Stemmer: 
 [('8', '8')]

>> Lemmatization: 
 [('8', '8')]



========================================== PARAGRAPH 266 ===========================================

  


========================================== PARAGRAPH 267 ===========================================

artificial intelligence modelling. Also, machine learning algorithms can integrate statistical and  

------------------- Sentence 1 -------------------

artificial intelligence modelling.

>> Tokens are: 
 ['artificial', 'intelligence', 'modelling', '.']

>> Bigrams are: 
 [('artificial', 'intelligence'), ('intelligence', 'modelling'), ('modelling', '.')]

>> Trigrams are: 
 [('artificial', 'intelligence', 'modelling'), ('intelligence', 'modelling', '.')]

>> POS Tags are: 
 [('artificial', 'JJ'), ('intelligence', 'NN'), ('modelling', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['artificial intelligence modelling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('.', '.')]

>> Lemmatization: 
 [('artificial', 'artificial'), ('intelligence', 'intelligence'), ('modelling', 'modelling'), ('.', '.')]


------------------- Sentence 2 -------------------

Also, machine learning algorithms can integrate statistical and

>> Tokens are: 
 ['Also', ',', 'machine', 'learning', 'algorithms', 'integrate', 'statistical']

>> Bigrams are: 
 [('Also', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'integrate'), ('integrate', 'statistical')]

>> Trigrams are: 
 [('Also', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'integrate'), ('algorithms', 'integrate', 'statistical')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('integrate', 'JJ'), ('statistical', 'NN')]

>> Noun Phrases are: 
 ['machine', 'algorithms integrate statistical']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('integrate', 'integr'), ('statistical', 'statist')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('integrate', 'integr'), ('statistical', 'statist')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('integrate', 'integrate'), ('statistical', 'statistical')]



========================================== PARAGRAPH 268 ===========================================

artificial intelligence methods to analyse massive amounts of data with high-performance. One  

------------------- Sentence 1 -------------------

artificial intelligence methods to analyse massive amounts of data with high-performance.

>> Tokens are: 
 ['artificial', 'intelligence', 'methods', 'analyse', 'massive', 'amounts', 'data', 'high-performance', '.']

>> Bigrams are: 
 [('artificial', 'intelligence'), ('intelligence', 'methods'), ('methods', 'analyse'), ('analyse', 'massive'), ('massive', 'amounts'), ('amounts', 'data'), ('data', 'high-performance'), ('high-performance', '.')]

>> Trigrams are: 
 [('artificial', 'intelligence', 'methods'), ('intelligence', 'methods', 'analyse'), ('methods', 'analyse', 'massive'), ('analyse', 'massive', 'amounts'), ('massive', 'amounts', 'data'), ('amounts', 'data', 'high-performance'), ('data', 'high-performance', '.')]

>> POS Tags are: 
 [('artificial', 'JJ'), ('intelligence', 'NN'), ('methods', 'NNS'), ('analyse', 'VBP'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('high-performance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['artificial intelligence methods', 'massive amounts data high-performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('analyse', 'analys'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('analyse', 'analys'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('.', '.')]

>> Lemmatization: 
 [('artificial', 'artificial'), ('intelligence', 'intelligence'), ('methods', 'method'), ('analyse', 'analyse'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-performance'), ('.', '.')]


------------------- Sentence 2 -------------------

One

>> Tokens are: 
 ['One']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('One', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one')]

>> Lemmatization: 
 [('One', 'One')]



========================================== PARAGRAPH 269 ===========================================

solution for the storage challenge is utilizing Hadoop (Apache platform) that has the power to  

------------------- Sentence 1 -------------------

solution for the storage challenge is utilizing Hadoop (Apache platform) that has the power to

>> Tokens are: 
 ['solution', 'storage', 'challenge', 'utilizing', 'Hadoop', '(', 'Apache', 'platform', ')', 'power']

>> Bigrams are: 
 [('solution', 'storage'), ('storage', 'challenge'), ('challenge', 'utilizing'), ('utilizing', 'Hadoop'), ('Hadoop', '('), ('(', 'Apache'), ('Apache', 'platform'), ('platform', ')'), (')', 'power')]

>> Trigrams are: 
 [('solution', 'storage', 'challenge'), ('storage', 'challenge', 'utilizing'), ('challenge', 'utilizing', 'Hadoop'), ('utilizing', 'Hadoop', '('), ('Hadoop', '(', 'Apache'), ('(', 'Apache', 'platform'), ('Apache', 'platform', ')'), ('platform', ')', 'power')]

>> POS Tags are: 
 [('solution', 'NN'), ('storage', 'NN'), ('challenge', 'NN'), ('utilizing', 'VBG'), ('Hadoop', 'NNP'), ('(', '('), ('Apache', 'NNP'), ('platform', 'NN'), (')', ')'), ('power', 'NN')]

>> Noun Phrases are: 
 ['solution storage challenge', 'Hadoop', 'Apache platform', 'power']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'Apache')] 

>> Stemming using Porter Stemmer: 
 [('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('utilizing', 'util'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), ('power', 'power')]

>> Stemming using Snowball Stemmer: 
 [('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('utilizing', 'util'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), ('power', 'power')]

>> Lemmatization: 
 [('solution', 'solution'), ('storage', 'storage'), ('challenge', 'challenge'), ('utilizing', 'utilizing'), ('Hadoop', 'Hadoop'), ('(', '('), ('Apache', 'Apache'), ('platform', 'platform'), (')', ')'), ('power', 'power')]



========================================== PARAGRAPH 270 ===========================================

process highly large amounts of data. By separating the data into smaller parts then assigning some  

------------------- Sentence 1 -------------------

process highly large amounts of data.

>> Tokens are: 
 ['process', 'highly', 'large', 'amounts', 'data', '.']

>> Bigrams are: 
 [('process', 'highly'), ('highly', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', '.')]

>> Trigrams are: 
 [('process', 'highly', 'large'), ('highly', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', '.')]

>> POS Tags are: 
 [('process', 'NN'), ('highly', 'RB'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['process', 'large amounts data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('highly', 'highli'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('highly', 'high'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('process', 'process'), ('highly', 'highly'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

By separating the data into smaller parts then assigning some

>> Tokens are: 
 ['By', 'separating', 'data', 'smaller', 'parts', 'assigning']

>> Bigrams are: 
 [('By', 'separating'), ('separating', 'data'), ('data', 'smaller'), ('smaller', 'parts'), ('parts', 'assigning')]

>> Trigrams are: 
 [('By', 'separating', 'data'), ('separating', 'data', 'smaller'), ('data', 'smaller', 'parts'), ('smaller', 'parts', 'assigning')]

>> POS Tags are: 
 [('By', 'IN'), ('separating', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('parts', 'NNS'), ('assigning', 'VBG')]

>> Noun Phrases are: 
 ['data', 'parts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('separating', 'separ'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assign')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('separating', 'separ'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assign')]

>> Lemmatization: 
 [('By', 'By'), ('separating', 'separating'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assigning')]



========================================== PARAGRAPH 271 ===========================================

parts of the datasets to separate servers (nodes). Organizations should observe data sources, with  

------------------- Sentence 1 -------------------

parts of the datasets to separate servers (nodes).

>> Tokens are: 
 ['parts', 'datasets', 'separate', 'servers', '(', 'nodes', ')', '.']

>> Bigrams are: 
 [('parts', 'datasets'), ('datasets', 'separate'), ('separate', 'servers'), ('servers', '('), ('(', 'nodes'), ('nodes', ')'), (')', '.')]

>> Trigrams are: 
 [('parts', 'datasets', 'separate'), ('datasets', 'separate', 'servers'), ('separate', 'servers', '('), ('servers', '(', 'nodes'), ('(', 'nodes', ')'), ('nodes', ')', '.')]

>> POS Tags are: 
 [('parts', 'NNS'), ('datasets', 'NNS'), ('separate', 'JJ'), ('servers', 'NNS'), ('(', '('), ('nodes', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['parts datasets', 'separate servers', 'nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('parts', 'part'), ('datasets', 'datasets'), ('separate', 'separate'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Organizations should observe data sources, with

>> Tokens are: 
 ['Organizations', 'observe', 'data', 'sources', ',']

>> Bigrams are: 
 [('Organizations', 'observe'), ('observe', 'data'), ('data', 'sources'), ('sources', ',')]

>> Trigrams are: 
 [('Organizations', 'observe', 'data'), ('observe', 'data', 'sources'), ('data', 'sources', ',')]

>> POS Tags are: 
 [('Organizations', 'NNS'), ('observe', 'VBP'), ('data', 'NNS'), ('sources', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Organizations', 'data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organizations', 'organ'), ('observe', 'observ'), ('data', 'data'), ('sources', 'sourc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Organizations', 'organ'), ('observe', 'observ'), ('data', 'data'), ('sources', 'sourc'), (',', ',')]

>> Lemmatization: 
 [('Organizations', 'Organizations'), ('observe', 'observe'), ('data', 'data'), ('sources', 'source'), (',', ',')]



========================================== PARAGRAPH 272 ===========================================

end-to-end encryption used to prevent gaining access to the data in transit.   

------------------- Sentence 1 -------------------

end-to-end encryption used to prevent gaining access to the data in transit.

>> Tokens are: 
 ['end-to-end', 'encryption', 'used', 'prevent', 'gaining', 'access', 'data', 'transit', '.']

>> Bigrams are: 
 [('end-to-end', 'encryption'), ('encryption', 'used'), ('used', 'prevent'), ('prevent', 'gaining'), ('gaining', 'access'), ('access', 'data'), ('data', 'transit'), ('transit', '.')]

>> Trigrams are: 
 [('end-to-end', 'encryption', 'used'), ('encryption', 'used', 'prevent'), ('used', 'prevent', 'gaining'), ('prevent', 'gaining', 'access'), ('gaining', 'access', 'data'), ('access', 'data', 'transit'), ('data', 'transit', '.')]

>> POS Tags are: 
 [('end-to-end', 'JJ'), ('encryption', 'NN'), ('used', 'VBN'), ('prevent', 'NN'), ('gaining', 'VBG'), ('access', 'NN'), ('data', 'NNS'), ('transit', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['end-to-end encryption', 'prevent', 'access data transit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('gaining', 'gain'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('gaining', 'gain'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Lemmatization: 
 [('end-to-end', 'end-to-end'), ('encryption', 'encryption'), ('used', 'used'), ('prevent', 'prevent'), ('gaining', 'gaining'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]



========================================== PARAGRAPH 273 ===========================================

  


========================================== PARAGRAPH 274 ===========================================

Companies must examine their cloud providers, as many cloud providers do not encrypt the data  

------------------- Sentence 1 -------------------

Companies must examine their cloud providers, as many cloud providers do not encrypt the data

>> Tokens are: 
 ['Companies', 'must', 'examine', 'cloud', 'providers', ',', 'many', 'cloud', 'providers', 'encrypt', 'data']

>> Bigrams are: 
 [('Companies', 'must'), ('must', 'examine'), ('examine', 'cloud'), ('cloud', 'providers'), ('providers', ','), (',', 'many'), ('many', 'cloud'), ('cloud', 'providers'), ('providers', 'encrypt'), ('encrypt', 'data')]

>> Trigrams are: 
 [('Companies', 'must', 'examine'), ('must', 'examine', 'cloud'), ('examine', 'cloud', 'providers'), ('cloud', 'providers', ','), ('providers', ',', 'many'), (',', 'many', 'cloud'), ('many', 'cloud', 'providers'), ('cloud', 'providers', 'encrypt'), ('providers', 'encrypt', 'data')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('must', 'MD'), ('examine', 'VB'), ('cloud', 'NN'), ('providers', 'NNS'), (',', ','), ('many', 'JJ'), ('cloud', 'VBP'), ('providers', 'NNS'), ('encrypt', 'VBP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Companies', 'cloud providers', 'providers', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('must', 'must'), ('examine', 'examin'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('must', 'must'), ('examine', 'examin'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('must', 'must'), ('examine', 'examine'), ('cloud', 'cloud'), ('providers', 'provider'), (',', ','), ('many', 'many'), ('cloud', 'cloud'), ('providers', 'provider'), ('encrypt', 'encrypt'), ('data', 'data')]



========================================== PARAGRAPH 275 ===========================================

because of the massive amount of data convey at any given time, while encryption/decryption  

------------------- Sentence 1 -------------------

because of the massive amount of data convey at any given time, while encryption/decryption

>> Tokens are: 
 ['massive', 'amount', 'data', 'convey', 'given', 'time', ',', 'encryption/decryption']

>> Bigrams are: 
 [('massive', 'amount'), ('amount', 'data'), ('data', 'convey'), ('convey', 'given'), ('given', 'time'), ('time', ','), (',', 'encryption/decryption')]

>> Trigrams are: 
 [('massive', 'amount', 'data'), ('amount', 'data', 'convey'), ('data', 'convey', 'given'), ('convey', 'given', 'time'), ('given', 'time', ','), ('time', ',', 'encryption/decryption')]

>> POS Tags are: 
 [('massive', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('convey', 'VB'), ('given', 'VBN'), ('time', 'NN'), (',', ','), ('encryption/decryption', 'NN')]

>> Noun Phrases are: 
 ['massive amount data', 'time', 'encryption/decryption']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('massive', 'massiv'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt')]

>> Stemming using Snowball Stemmer: 
 [('massive', 'massiv'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt')]

>> Lemmatization: 
 [('massive', 'massive'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decryption')]



========================================== PARAGRAPH 276 ===========================================

slows down the stream of data. Big data privacy solutions include protecting personal data privacy  

------------------- Sentence 1 -------------------

slows down the stream of data.

>> Tokens are: 
 ['slows', 'stream', 'data', '.']

>> Bigrams are: 
 [('slows', 'stream'), ('stream', 'data'), ('data', '.')]

>> Trigrams are: 
 [('slows', 'stream', 'data'), ('stream', 'data', '.')]

>> POS Tags are: 
 [('slows', 'NNS'), ('stream', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['slows stream data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('slows', 'slow'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('slows', 'slow'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('slows', 'slows'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data privacy solutions include protecting personal data privacy

>> Tokens are: 
 ['Big', 'data', 'privacy', 'solutions', 'include', 'protecting', 'personal', 'data', 'privacy']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'privacy'), ('privacy', 'solutions'), ('solutions', 'include'), ('include', 'protecting'), ('protecting', 'personal'), ('personal', 'data'), ('data', 'privacy')]

>> Trigrams are: 
 [('Big', 'data', 'privacy'), ('data', 'privacy', 'solutions'), ('privacy', 'solutions', 'include'), ('solutions', 'include', 'protecting'), ('include', 'protecting', 'personal'), ('protecting', 'personal', 'data'), ('personal', 'data', 'privacy')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('privacy', 'NN'), ('solutions', 'NNS'), ('include', 'VBP'), ('protecting', 'VBG'), ('personal', 'JJ'), ('data', 'NNS'), ('privacy', 'NN')]

>> Noun Phrases are: 
 ['Big data privacy solutions', 'personal data privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('solutions', 'solut'), ('include', 'includ'), ('protecting', 'protect'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('solutions', 'solut'), ('include', 'includ'), ('protecting', 'protect'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('privacy', 'privacy'), ('solutions', 'solution'), ('include', 'include'), ('protecting', 'protecting'), ('personal', 'personal'), ('data', 'data'), ('privacy', 'privacy')]



========================================== PARAGRAPH 277 ===========================================

during gathering data such as personal interests, habits, and body properties, etc. of users who do  

------------------- Sentence 1 -------------------

during gathering data such as personal interests, habits, and body properties, etc.

>> Tokens are: 
 ['gathering', 'data', 'personal', 'interests', ',', 'habits', ',', 'body', 'properties', ',', 'etc', '.']

>> Bigrams are: 
 [('gathering', 'data'), ('data', 'personal'), ('personal', 'interests'), ('interests', ','), (',', 'habits'), ('habits', ','), (',', 'body'), ('body', 'properties'), ('properties', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('gathering', 'data', 'personal'), ('data', 'personal', 'interests'), ('personal', 'interests', ','), ('interests', ',', 'habits'), (',', 'habits', ','), ('habits', ',', 'body'), (',', 'body', 'properties'), ('body', 'properties', ','), ('properties', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('gathering', 'VBG'), ('data', 'NNS'), ('personal', 'JJ'), ('interests', 'NNS'), (',', ','), ('habits', 'NNS'), (',', ','), ('body', 'NN'), ('properties', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'personal interests', 'habits', 'body properties']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('gathering', 'gather'), ('data', 'data'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('gathering', 'gather'), ('data', 'data'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('gathering', 'gathering'), ('data', 'data'), ('personal', 'personal'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'body'), ('properties', 'property'), (',', ','), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

of users who do

>> Tokens are: 
 ['users']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('users', 'NNS')]

>> Noun Phrases are: 
 ['users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('users', 'user')]

>> Stemming using Snowball Stemmer: 
 [('users', 'user')]

>> Lemmatization: 
 [('users', 'user')]



========================================== PARAGRAPH 278 ===========================================

not aware or easy to gain information from them. Also, protecting personal privacy data which  

------------------- Sentence 1 -------------------

not aware or easy to gain information from them.

>> Tokens are: 
 ['aware', 'easy', 'gain', 'information', '.']

>> Bigrams are: 
 [('aware', 'easy'), ('easy', 'gain'), ('gain', 'information'), ('information', '.')]

>> Trigrams are: 
 [('aware', 'easy', 'gain'), ('easy', 'gain', 'information'), ('gain', 'information', '.')]

>> POS Tags are: 
 [('aware', 'JJ'), ('easy', 'JJ'), ('gain', 'NN'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['aware easy gain information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('aware', 'aware'), ('easy', 'easy'), ('gain', 'gain'), ('information', 'information'), ('.', '.')]


------------------- Sentence 2 -------------------

Also, protecting personal privacy data which

>> Tokens are: 
 ['Also', ',', 'protecting', 'personal', 'privacy', 'data']

>> Bigrams are: 
 [('Also', ','), (',', 'protecting'), ('protecting', 'personal'), ('personal', 'privacy'), ('privacy', 'data')]

>> Trigrams are: 
 [('Also', ',', 'protecting'), (',', 'protecting', 'personal'), ('protecting', 'personal', 'privacy'), ('personal', 'privacy', 'data')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('protecting', 'VBG'), ('personal', 'JJ'), ('privacy', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['personal privacy data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('protecting', 'protect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('protecting', 'protect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('protecting', 'protecting'), ('personal', 'personal'), ('privacy', 'privacy'), ('data', 'data')]



========================================== PARAGRAPH 279 ===========================================

might discharge during storage, transmission, and usage, even if it gained with the user permission.  

------------------- Sentence 1 -------------------

might discharge during storage, transmission, and usage, even if it gained with the user permission.

>> Tokens are: 
 ['might', 'discharge', 'storage', ',', 'transmission', ',', 'usage', ',', 'even', 'gained', 'user', 'permission', '.']

>> Bigrams are: 
 [('might', 'discharge'), ('discharge', 'storage'), ('storage', ','), (',', 'transmission'), ('transmission', ','), (',', 'usage'), ('usage', ','), (',', 'even'), ('even', 'gained'), ('gained', 'user'), ('user', 'permission'), ('permission', '.')]

>> Trigrams are: 
 [('might', 'discharge', 'storage'), ('discharge', 'storage', ','), ('storage', ',', 'transmission'), (',', 'transmission', ','), ('transmission', ',', 'usage'), (',', 'usage', ','), ('usage', ',', 'even'), (',', 'even', 'gained'), ('even', 'gained', 'user'), ('gained', 'user', 'permission'), ('user', 'permission', '.')]

>> POS Tags are: 
 [('might', 'MD'), ('discharge', 'VB'), ('storage', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('usage', 'NN'), (',', ','), ('even', 'RB'), ('gained', 'VBD'), ('user', 'JJ'), ('permission', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['storage', 'transmission', 'usage', 'user permission']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Lemmatization: 
 [('might', 'might'), ('discharge', 'discharge'), ('storage', 'storage'), (',', ','), ('transmission', 'transmission'), (',', ','), ('usage', 'usage'), (',', ','), ('even', 'even'), ('gained', 'gained'), ('user', 'user'), ('permission', 'permission'), ('.', '.')]



========================================== PARAGRAPH 280 ===========================================

  


========================================== PARAGRAPH 281 ===========================================

Possible risks for this thesis could be in conducting the research which is how to identify a suitable  

------------------- Sentence 1 -------------------

Possible risks for this thesis could be in conducting the research which is how to identify a suitable

>> Tokens are: 
 ['Possible', 'risks', 'thesis', 'could', 'conducting', 'research', 'identify', 'suitable']

>> Bigrams are: 
 [('Possible', 'risks'), ('risks', 'thesis'), ('thesis', 'could'), ('could', 'conducting'), ('conducting', 'research'), ('research', 'identify'), ('identify', 'suitable')]

>> Trigrams are: 
 [('Possible', 'risks', 'thesis'), ('risks', 'thesis', 'could'), ('thesis', 'could', 'conducting'), ('could', 'conducting', 'research'), ('conducting', 'research', 'identify'), ('research', 'identify', 'suitable')]

>> POS Tags are: 
 [('Possible', 'JJ'), ('risks', 'NNS'), ('thesis', 'NN'), ('could', 'MD'), ('conducting', 'VB'), ('research', 'NN'), ('identify', 'NN'), ('suitable', 'JJ')]

>> Noun Phrases are: 
 ['Possible risks thesis', 'research identify']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Possible', 'possibl'), ('risks', 'risk'), ('thesis', 'thesi'), ('could', 'could'), ('conducting', 'conduct'), ('research', 'research'), ('identify', 'identifi'), ('suitable', 'suitabl')]

>> Stemming using Snowball Stemmer: 
 [('Possible', 'possibl'), ('risks', 'risk'), ('thesis', 'thesi'), ('could', 'could'), ('conducting', 'conduct'), ('research', 'research'), ('identify', 'identifi'), ('suitable', 'suitabl')]

>> Lemmatization: 
 [('Possible', 'Possible'), ('risks', 'risk'), ('thesis', 'thesis'), ('could', 'could'), ('conducting', 'conducting'), ('research', 'research'), ('identify', 'identify'), ('suitable', 'suitable')]



========================================== PARAGRAPH 282 ===========================================

subject based on the important point of finding a personal practical or professional need or a  

------------------- Sentence 1 -------------------

subject based on the important point of finding a personal practical or professional need or a

>> Tokens are: 
 ['subject', 'based', 'important', 'point', 'finding', 'personal', 'practical', 'professional', 'need']

>> Bigrams are: 
 [('subject', 'based'), ('based', 'important'), ('important', 'point'), ('point', 'finding'), ('finding', 'personal'), ('personal', 'practical'), ('practical', 'professional'), ('professional', 'need')]

>> Trigrams are: 
 [('subject', 'based', 'important'), ('based', 'important', 'point'), ('important', 'point', 'finding'), ('point', 'finding', 'personal'), ('finding', 'personal', 'practical'), ('personal', 'practical', 'professional'), ('practical', 'professional', 'need')]

>> POS Tags are: 
 [('subject', 'NN'), ('based', 'VBN'), ('important', 'JJ'), ('point', 'NN'), ('finding', 'VBG'), ('personal', 'JJ'), ('practical', 'JJ'), ('professional', 'NN'), ('need', 'NN')]

>> Noun Phrases are: 
 ['subject', 'important point', 'personal practical professional need']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('subject', 'subject'), ('based', 'base'), ('important', 'import'), ('point', 'point'), ('finding', 'find'), ('personal', 'person'), ('practical', 'practic'), ('professional', 'profession'), ('need', 'need')]

>> Stemming using Snowball Stemmer: 
 [('subject', 'subject'), ('based', 'base'), ('important', 'import'), ('point', 'point'), ('finding', 'find'), ('personal', 'person'), ('practical', 'practic'), ('professional', 'profession'), ('need', 'need')]

>> Lemmatization: 
 [('subject', 'subject'), ('based', 'based'), ('important', 'important'), ('point', 'point'), ('finding', 'finding'), ('personal', 'personal'), ('practical', 'practical'), ('professional', 'professional'), ('need', 'need')]



========================================== PARAGRAPH 283 ===========================================

personal urge to face the research question. The risk was to confront two essential sources of  

------------------- Sentence 1 -------------------

personal urge to face the research question.

>> Tokens are: 
 ['personal', 'urge', 'face', 'research', 'question', '.']

>> Bigrams are: 
 [('personal', 'urge'), ('urge', 'face'), ('face', 'research'), ('research', 'question'), ('question', '.')]

>> Trigrams are: 
 [('personal', 'urge', 'face'), ('urge', 'face', 'research'), ('face', 'research', 'question'), ('research', 'question', '.')]

>> POS Tags are: 
 [('personal', 'JJ'), ('urge', 'NN'), ('face', 'NN'), ('research', 'NN'), ('question', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['personal urge face research question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('personal', 'person'), ('urge', 'urg'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('personal', 'person'), ('urge', 'urg'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]

>> Lemmatization: 
 [('personal', 'personal'), ('urge', 'urge'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]


------------------- Sentence 2 -------------------

The risk was to confront two essential sources of

>> Tokens are: 
 ['The', 'risk', 'confront', 'two', 'essential', 'sources']

>> Bigrams are: 
 [('The', 'risk'), ('risk', 'confront'), ('confront', 'two'), ('two', 'essential'), ('essential', 'sources')]

>> Trigrams are: 
 [('The', 'risk', 'confront'), ('risk', 'confront', 'two'), ('confront', 'two', 'essential'), ('two', 'essential', 'sources')]

>> POS Tags are: 
 [('The', 'DT'), ('risk', 'NN'), ('confront', 'NN'), ('two', 'CD'), ('essential', 'JJ'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['The risk confront', 'essential sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essenti'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essenti'), ('sources', 'sourc')]

>> Lemmatization: 
 [('The', 'The'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essential'), ('sources', 'source')]



========================================== PARAGRAPH 284 ===========================================

confusion concerning the final success means in thesis writing. The first was the uncertainty about  

------------------- Sentence 1 -------------------

confusion concerning the final success means in thesis writing.

>> Tokens are: 
 ['confusion', 'concerning', 'final', 'success', 'means', 'thesis', 'writing', '.']

>> Bigrams are: 
 [('confusion', 'concerning'), ('concerning', 'final'), ('final', 'success'), ('success', 'means'), ('means', 'thesis'), ('thesis', 'writing'), ('writing', '.')]

>> Trigrams are: 
 [('confusion', 'concerning', 'final'), ('concerning', 'final', 'success'), ('final', 'success', 'means'), ('success', 'means', 'thesis'), ('means', 'thesis', 'writing'), ('thesis', 'writing', '.')]

>> POS Tags are: 
 [('confusion', 'NN'), ('concerning', 'VBG'), ('final', 'JJ'), ('success', 'NN'), ('means', 'VBZ'), ('thesis', 'NN'), ('writing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['confusion', 'final success', 'thesis writing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('confusion', 'confus'), ('concerning', 'concern'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesi'), ('writing', 'write'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('confusion', 'confus'), ('concerning', 'concern'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesi'), ('writing', 'write'), ('.', '.')]

>> Lemmatization: 
 [('confusion', 'confusion'), ('concerning', 'concerning'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesis'), ('writing', 'writing'), ('.', '.')]


------------------- Sentence 2 -------------------

The first was the uncertainty about

>> Tokens are: 
 ['The', 'first', 'uncertainty']

>> Bigrams are: 
 [('The', 'first'), ('first', 'uncertainty')]

>> Trigrams are: 
 [('The', 'first', 'uncertainty')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('uncertainty', 'NN')]

>> Noun Phrases are: 
 ['The first uncertainty']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('uncertainty', 'uncertainti')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('uncertainty', 'uncertainti')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('uncertainty', 'uncertainty')]



========================================== PARAGRAPH 285 ===========================================

the understanding of the assessment criteria that will be applied to the work. The second relates to  

------------------- Sentence 1 -------------------

the understanding of the assessment criteria that will be applied to the work.

>> Tokens are: 
 ['understanding', 'assessment', 'criteria', 'applied', 'work', '.']

>> Bigrams are: 
 [('understanding', 'assessment'), ('assessment', 'criteria'), ('criteria', 'applied'), ('applied', 'work'), ('work', '.')]

>> Trigrams are: 
 [('understanding', 'assessment', 'criteria'), ('assessment', 'criteria', 'applied'), ('criteria', 'applied', 'work'), ('applied', 'work', '.')]

>> POS Tags are: 
 [('understanding', 'VBG'), ('assessment', 'JJ'), ('criteria', 'NNS'), ('applied', 'VBN'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['assessment criteria', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understanding', 'understand'), ('assessment', 'assess'), ('criteria', 'criteria'), ('applied', 'appli'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understanding', 'understand'), ('assessment', 'assess'), ('criteria', 'criteria'), ('applied', 'appli'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('understanding', 'understanding'), ('assessment', 'assessment'), ('criteria', 'criterion'), ('applied', 'applied'), ('work', 'work'), ('.', '.')]


------------------- Sentence 2 -------------------

The second relates to

>> Tokens are: 
 ['The', 'second', 'relates']

>> Bigrams are: 
 [('The', 'second'), ('second', 'relates')]

>> Trigrams are: 
 [('The', 'second', 'relates')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('relates', 'NNS')]

>> Noun Phrases are: 
 ['The second relates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('relates', 'relat')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('relates', 'relat')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('relates', 'relates')]



========================================== PARAGRAPH 286 ===========================================

the insecurity concerning the risks that will be faced along the journey. The limitations of the study  

------------------- Sentence 1 -------------------

the insecurity concerning the risks that will be faced along the journey.

>> Tokens are: 
 ['insecurity', 'concerning', 'risks', 'faced', 'along', 'journey', '.']

>> Bigrams are: 
 [('insecurity', 'concerning'), ('concerning', 'risks'), ('risks', 'faced'), ('faced', 'along'), ('along', 'journey'), ('journey', '.')]

>> Trigrams are: 
 [('insecurity', 'concerning', 'risks'), ('concerning', 'risks', 'faced'), ('risks', 'faced', 'along'), ('faced', 'along', 'journey'), ('along', 'journey', '.')]

>> POS Tags are: 
 [('insecurity', 'NN'), ('concerning', 'VBG'), ('risks', 'NNS'), ('faced', 'VBN'), ('along', 'IN'), ('journey', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['insecurity', 'risks', 'journey']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('insecurity', 'insecur'), ('concerning', 'concern'), ('risks', 'risk'), ('faced', 'face'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('insecurity', 'insecur'), ('concerning', 'concern'), ('risks', 'risk'), ('faced', 'face'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]

>> Lemmatization: 
 [('insecurity', 'insecurity'), ('concerning', 'concerning'), ('risks', 'risk'), ('faced', 'faced'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]


------------------- Sentence 2 -------------------

The limitations of the study

>> Tokens are: 
 ['The', 'limitations', 'study']

>> Bigrams are: 
 [('The', 'limitations'), ('limitations', 'study')]

>> Trigrams are: 
 [('The', 'limitations', 'study')]

>> POS Tags are: 
 [('The', 'DT'), ('limitations', 'NNS'), ('study', 'VBP')]

>> Noun Phrases are: 
 ['The limitations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('limitations', 'limit'), ('study', 'studi')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('limitations', 'limit'), ('study', 'studi')]

>> Lemmatization: 
 [('The', 'The'), ('limitations', 'limitation'), ('study', 'study')]



========================================== PARAGRAPH 287 ===========================================

were those characteristics of design and the methodology that have been chosen which impacted  

------------------- Sentence 1 -------------------

were those characteristics of design and the methodology that have been chosen which impacted

>> Tokens are: 
 ['characteristics', 'design', 'methodology', 'chosen', 'impacted']

>> Bigrams are: 
 [('characteristics', 'design'), ('design', 'methodology'), ('methodology', 'chosen'), ('chosen', 'impacted')]

>> Trigrams are: 
 [('characteristics', 'design', 'methodology'), ('design', 'methodology', 'chosen'), ('methodology', 'chosen', 'impacted')]

>> POS Tags are: 
 [('characteristics', 'NNS'), ('design', 'NN'), ('methodology', 'NN'), ('chosen', 'VBN'), ('impacted', 'JJ')]

>> Noun Phrases are: 
 ['characteristics design methodology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('characteristics', 'characterist'), ('design', 'design'), ('methodology', 'methodolog'), ('chosen', 'chosen'), ('impacted', 'impact')]

>> Stemming using Snowball Stemmer: 
 [('characteristics', 'characterist'), ('design', 'design'), ('methodology', 'methodolog'), ('chosen', 'chosen'), ('impacted', 'impact')]

>> Lemmatization: 
 [('characteristics', 'characteristic'), ('design', 'design'), ('methodology', 'methodology'), ('chosen', 'chosen'), ('impacted', 'impacted')]



========================================== PARAGRAPH 288 ===========================================

the application results of the study. As the chosen method was a literature review according to  

------------------- Sentence 1 -------------------

the application results of the study.

>> Tokens are: 
 ['application', 'results', 'study', '.']

>> Bigrams are: 
 [('application', 'results'), ('results', 'study'), ('study', '.')]

>> Trigrams are: 
 [('application', 'results', 'study'), ('results', 'study', '.')]

>> POS Tags are: 
 [('application', 'NN'), ('results', 'NNS'), ('study', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['application results study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('application', 'applic'), ('results', 'result'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('application', 'applic'), ('results', 'result'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('application', 'application'), ('results', 'result'), ('study', 'study'), ('.', '.')]


------------------- Sentence 2 -------------------

As the chosen method was a literature review according to

>> Tokens are: 
 ['As', 'chosen', 'method', 'literature', 'review', 'according']

>> Bigrams are: 
 [('As', 'chosen'), ('chosen', 'method'), ('method', 'literature'), ('literature', 'review'), ('review', 'according')]

>> Trigrams are: 
 [('As', 'chosen', 'method'), ('chosen', 'method', 'literature'), ('method', 'literature', 'review'), ('literature', 'review', 'according')]

>> POS Tags are: 
 [('As', 'IN'), ('chosen', 'VBN'), ('method', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('according', 'VBG')]

>> Noun Phrases are: 
 ['method literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literatur'), ('review', 'review'), ('according', 'accord')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literatur'), ('review', 'review'), ('according', 'accord')]

>> Lemmatization: 
 [('As', 'As'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literature'), ('review', 'review'), ('according', 'according')]



========================================== PARAGRAPH 289 ===========================================

Vom Brocke et al. (2009), the criteria for selecting references was not easy and a lot of references  

------------------- Sentence 1 -------------------

Vom Brocke et al.

>> Tokens are: 
 ['Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom'), ('ORGANIZATION', 'Brocke')] 

>> Stemming using Porter Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2009), the criteria for selecting references was not easy and a lot of references

>> Tokens are: 
 ['(', '2009', ')', ',', 'criteria', 'selecting', 'references', 'easy', 'lot', 'references']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', ','), (',', 'criteria'), ('criteria', 'selecting'), ('selecting', 'references'), ('references', 'easy'), ('easy', 'lot'), ('lot', 'references')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', ','), (')', ',', 'criteria'), (',', 'criteria', 'selecting'), ('criteria', 'selecting', 'references'), ('selecting', 'references', 'easy'), ('references', 'easy', 'lot'), ('easy', 'lot', 'references')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), (',', ','), ('criteria', 'NNS'), ('selecting', 'VBG'), ('references', 'NNS'), ('easy', 'JJ'), ('lot', 'NN'), ('references', 'NNS')]

>> Noun Phrases are: 
 ['criteria', 'references', 'easy lot references']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criteria'), ('selecting', 'select'), ('references', 'refer'), ('easy', 'easi'), ('lot', 'lot'), ('references', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criteria'), ('selecting', 'select'), ('references', 'refer'), ('easy', 'easi'), ('lot', 'lot'), ('references', 'refer')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criterion'), ('selecting', 'selecting'), ('references', 'reference'), ('easy', 'easy'), ('lot', 'lot'), ('references', 'reference')]



========================================== PARAGRAPH 290 ===========================================

comply to the criteria of multi-dimension as aforementioned in the research method section.  

------------------- Sentence 1 -------------------

comply to the criteria of multi-dimension as aforementioned in the research method section.

>> Tokens are: 
 ['comply', 'criteria', 'multi-dimension', 'aforementioned', 'research', 'method', 'section', '.']

>> Bigrams are: 
 [('comply', 'criteria'), ('criteria', 'multi-dimension'), ('multi-dimension', 'aforementioned'), ('aforementioned', 'research'), ('research', 'method'), ('method', 'section'), ('section', '.')]

>> Trigrams are: 
 [('comply', 'criteria', 'multi-dimension'), ('criteria', 'multi-dimension', 'aforementioned'), ('multi-dimension', 'aforementioned', 'research'), ('aforementioned', 'research', 'method'), ('research', 'method', 'section'), ('method', 'section', '.')]

>> POS Tags are: 
 [('comply', 'NN'), ('criteria', 'NNS'), ('multi-dimension', 'NN'), ('aforementioned', 'VBD'), ('research', 'NN'), ('method', 'NN'), ('section', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['comply criteria multi-dimension', 'research method section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comply', 'compli'), ('criteria', 'criteria'), ('multi-dimension', 'multi-dimens'), ('aforementioned', 'aforement'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('comply', 'compli'), ('criteria', 'criteria'), ('multi-dimension', 'multi-dimens'), ('aforementioned', 'aforement'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]

>> Lemmatization: 
 [('comply', 'comply'), ('criteria', 'criterion'), ('multi-dimension', 'multi-dimension'), ('aforementioned', 'aforementioned'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]



========================================== PARAGRAPH 291 ===========================================

  


========================================== PARAGRAPH 292 ===========================================

5. What is “big data”?  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

What is “big data”?

>> Tokens are: 
 ['What', '“', 'big', 'data', '”', '?']

>> Bigrams are: 
 [('What', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', '?')]

>> Trigrams are: 
 [('What', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('“', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('?', '.')]

>> Noun Phrases are: 
 ['big data ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]



========================================== PARAGRAPH 293 ===========================================

Big data generally refers datasets that have grown too large for and become too difficult to work  

------------------- Sentence 1 -------------------

Big data generally refers datasets that have grown too large for and become too difficult to work

>> Tokens are: 
 ['Big', 'data', 'generally', 'refers', 'datasets', 'grown', 'large', 'become', 'difficult', 'work']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'generally'), ('generally', 'refers'), ('refers', 'datasets'), ('datasets', 'grown'), ('grown', 'large'), ('large', 'become'), ('become', 'difficult'), ('difficult', 'work')]

>> Trigrams are: 
 [('Big', 'data', 'generally'), ('data', 'generally', 'refers'), ('generally', 'refers', 'datasets'), ('refers', 'datasets', 'grown'), ('datasets', 'grown', 'large'), ('grown', 'large', 'become'), ('large', 'become', 'difficult'), ('become', 'difficult', 'work')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('generally', 'RB'), ('refers', 'NNS'), ('datasets', 'NNS'), ('grown', 'VBP'), ('large', 'JJ'), ('become', 'NN'), ('difficult', 'JJ'), ('work', 'NN')]

>> Noun Phrases are: 
 ['Big data', 'refers datasets', 'large become', 'difficult work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('generally', 'gener'), ('refers', 'refer'), ('datasets', 'dataset'), ('grown', 'grown'), ('large', 'larg'), ('become', 'becom'), ('difficult', 'difficult'), ('work', 'work')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('generally', 'general'), ('refers', 'refer'), ('datasets', 'dataset'), ('grown', 'grown'), ('large', 'larg'), ('become', 'becom'), ('difficult', 'difficult'), ('work', 'work')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('generally', 'generally'), ('refers', 'refers'), ('datasets', 'datasets'), ('grown', 'grown'), ('large', 'large'), ('become', 'become'), ('difficult', 'difficult'), ('work', 'work')]



========================================== PARAGRAPH 294 ===========================================

with by means of traditional tools and database management systems. It also implies datasets that  

------------------- Sentence 1 -------------------

with by means of traditional tools and database management systems.

>> Tokens are: 
 ['means', 'traditional', 'tools', 'database', 'management', 'systems', '.']

>> Bigrams are: 
 [('means', 'traditional'), ('traditional', 'tools'), ('tools', 'database'), ('database', 'management'), ('management', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('means', 'traditional', 'tools'), ('traditional', 'tools', 'database'), ('tools', 'database', 'management'), ('database', 'management', 'systems'), ('management', 'systems', '.')]

>> POS Tags are: 
 [('means', 'NNS'), ('traditional', 'JJ'), ('tools', 'NNS'), ('database', 'JJ'), ('management', 'NN'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['means', 'traditional tools', 'database management systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('means', 'mean'), ('traditional', 'tradit'), ('tools', 'tool'), ('database', 'databas'), ('management', 'manag'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('means', 'mean'), ('traditional', 'tradit'), ('tools', 'tool'), ('database', 'databas'), ('management', 'manag'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('means', 'mean'), ('traditional', 'traditional'), ('tools', 'tool'), ('database', 'database'), ('management', 'management'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

It also implies datasets that

>> Tokens are: 
 ['It', 'also', 'implies', 'datasets']

>> Bigrams are: 
 [('It', 'also'), ('also', 'implies'), ('implies', 'datasets')]

>> Trigrams are: 
 [('It', 'also', 'implies'), ('also', 'implies', 'datasets')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('implies', 'VBZ'), ('datasets', 'NNS')]

>> Noun Phrases are: 
 ['datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('implies', 'impli'), ('datasets', 'dataset')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('implies', 'impli'), ('datasets', 'dataset')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('implies', 'implies'), ('datasets', 'datasets')]



========================================== PARAGRAPH 295 ===========================================

have a great deal of variety and velocity, generating a need to develop possible solutions to extract  

------------------- Sentence 1 -------------------

have a great deal of variety and velocity, generating a need to develop possible solutions to extract

>> Tokens are: 
 ['great', 'deal', 'variety', 'velocity', ',', 'generating', 'need', 'develop', 'possible', 'solutions', 'extract']

>> Bigrams are: 
 [('great', 'deal'), ('deal', 'variety'), ('variety', 'velocity'), ('velocity', ','), (',', 'generating'), ('generating', 'need'), ('need', 'develop'), ('develop', 'possible'), ('possible', 'solutions'), ('solutions', 'extract')]

>> Trigrams are: 
 [('great', 'deal', 'variety'), ('deal', 'variety', 'velocity'), ('variety', 'velocity', ','), ('velocity', ',', 'generating'), (',', 'generating', 'need'), ('generating', 'need', 'develop'), ('need', 'develop', 'possible'), ('develop', 'possible', 'solutions'), ('possible', 'solutions', 'extract')]

>> POS Tags are: 
 [('great', 'JJ'), ('deal', 'NN'), ('variety', 'NN'), ('velocity', 'NN'), (',', ','), ('generating', 'VBG'), ('need', 'NN'), ('develop', 'VB'), ('possible', 'JJ'), ('solutions', 'NNS'), ('extract', 'VBP')]

>> Noun Phrases are: 
 ['great deal variety velocity', 'need', 'possible solutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('great', 'great'), ('deal', 'deal'), ('variety', 'varieti'), ('velocity', 'veloc'), (',', ','), ('generating', 'gener'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possibl'), ('solutions', 'solut'), ('extract', 'extract')]

>> Stemming using Snowball Stemmer: 
 [('great', 'great'), ('deal', 'deal'), ('variety', 'varieti'), ('velocity', 'veloc'), (',', ','), ('generating', 'generat'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possibl'), ('solutions', 'solut'), ('extract', 'extract')]

>> Lemmatization: 
 [('great', 'great'), ('deal', 'deal'), ('variety', 'variety'), ('velocity', 'velocity'), (',', ','), ('generating', 'generating'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possible'), ('solutions', 'solution'), ('extract', 'extract')]



========================================== PARAGRAPH 296 ===========================================

value and knowledge from wide-ranging, fast-moving datasets (Elgendy, N. and Elragal, A.,  

------------------- Sentence 1 -------------------

value and knowledge from wide-ranging, fast-moving datasets (Elgendy, N. and Elragal, A.,

>> Tokens are: 
 ['value', 'knowledge', 'wide-ranging', ',', 'fast-moving', 'datasets', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',']

>> Bigrams are: 
 [('value', 'knowledge'), ('knowledge', 'wide-ranging'), ('wide-ranging', ','), (',', 'fast-moving'), ('fast-moving', 'datasets'), ('datasets', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ',')]

>> Trigrams are: 
 [('value', 'knowledge', 'wide-ranging'), ('knowledge', 'wide-ranging', ','), ('wide-ranging', ',', 'fast-moving'), (',', 'fast-moving', 'datasets'), ('fast-moving', 'datasets', '('), ('datasets', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ',')]

>> POS Tags are: 
 [('value', 'NN'), ('knowledge', 'NN'), ('wide-ranging', 'JJ'), (',', ','), ('fast-moving', 'JJ'), ('datasets', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['value knowledge', 'fast-moving datasets', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('value', 'valu'), ('knowledge', 'knowledg'), ('wide-ranging', 'wide-rang'), (',', ','), ('fast-moving', 'fast-mov'), ('datasets', 'dataset'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('value', 'valu'), ('knowledge', 'knowledg'), ('wide-ranging', 'wide-rang'), (',', ','), ('fast-moving', 'fast-mov'), ('datasets', 'dataset'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Lemmatization: 
 [('value', 'value'), ('knowledge', 'knowledge'), ('wide-ranging', 'wide-ranging'), (',', ','), ('fast-moving', 'fast-moving'), ('datasets', 'datasets'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ',')]



========================================== PARAGRAPH 297 ===========================================

2014).  

------------------- Sentence 1 -------------------

2014).

>> Tokens are: 
 ['2014', ')', '.']

>> Bigrams are: 
 [('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 298 ===========================================

According to the Oxford English Dictionary, “Big data” as a term is defined as “extremely large  

------------------- Sentence 1 -------------------

According to the Oxford English Dictionary, “Big data” as a term is defined as “extremely large

>> Tokens are: 
 ['According', 'Oxford', 'English', 'Dictionary', ',', '“', 'Big', 'data', '”', 'term', 'defined', '“', 'extremely', 'large']

>> Bigrams are: 
 [('According', 'Oxford'), ('Oxford', 'English'), ('English', 'Dictionary'), ('Dictionary', ','), (',', '“'), ('“', 'Big'), ('Big', 'data'), ('data', '”'), ('”', 'term'), ('term', 'defined'), ('defined', '“'), ('“', 'extremely'), ('extremely', 'large')]

>> Trigrams are: 
 [('According', 'Oxford', 'English'), ('Oxford', 'English', 'Dictionary'), ('English', 'Dictionary', ','), ('Dictionary', ',', '“'), (',', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', '”'), ('data', '”', 'term'), ('”', 'term', 'defined'), ('term', 'defined', '“'), ('defined', '“', 'extremely'), ('“', 'extremely', 'large')]

>> POS Tags are: 
 [('According', 'VBG'), ('Oxford', 'NNP'), ('English', 'NNP'), ('Dictionary', 'NNP'), (',', ','), ('“', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('”', 'NNP'), ('term', 'NN'), ('defined', 'VBD'), ('“', 'NNP'), ('extremely', 'RB'), ('large', 'JJ')]

>> Noun Phrases are: 
 ['Oxford English Dictionary', '“ Big data ” term', '“']

>> Named Entities are: 
 [('PERSON', 'Oxford English Dictionary')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Oxford', 'oxford'), ('English', 'english'), ('Dictionary', 'dictionari'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defin'), ('“', '“'), ('extremely', 'extrem'), ('large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Oxford', 'oxford'), ('English', 'english'), ('Dictionary', 'dictionari'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defin'), ('“', '“'), ('extremely', 'extrem'), ('large', 'larg')]

>> Lemmatization: 
 [('According', 'According'), ('Oxford', 'Oxford'), ('English', 'English'), ('Dictionary', 'Dictionary'), (',', ','), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defined'), ('“', '“'), ('extremely', 'extremely'), ('large', 'large')]



========================================== PARAGRAPH 299 ===========================================

data sets that may be analysed computationally to reveal patterns, trends, and associations,  

------------------- Sentence 1 -------------------

data sets that may be analysed computationally to reveal patterns, trends, and associations,

>> Tokens are: 
 ['data', 'sets', 'may', 'analysed', 'computationally', 'reveal', 'patterns', ',', 'trends', ',', 'associations', ',']

>> Bigrams are: 
 [('data', 'sets'), ('sets', 'may'), ('may', 'analysed'), ('analysed', 'computationally'), ('computationally', 'reveal'), ('reveal', 'patterns'), ('patterns', ','), (',', 'trends'), ('trends', ','), (',', 'associations'), ('associations', ',')]

>> Trigrams are: 
 [('data', 'sets', 'may'), ('sets', 'may', 'analysed'), ('may', 'analysed', 'computationally'), ('analysed', 'computationally', 'reveal'), ('computationally', 'reveal', 'patterns'), ('reveal', 'patterns', ','), ('patterns', ',', 'trends'), (',', 'trends', ','), ('trends', ',', 'associations'), (',', 'associations', ',')]

>> POS Tags are: 
 [('data', 'NNS'), ('sets', 'NNS'), ('may', 'MD'), ('analysed', 'VBN'), ('computationally', 'RB'), ('reveal', 'JJ'), ('patterns', 'NNS'), (',', ','), ('trends', 'NNS'), (',', ','), ('associations', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['data sets', 'reveal patterns', 'trends', 'associations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analys'), ('computationally', 'comput'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'associ'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analys'), ('computationally', 'comput'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'associ'), (',', ',')]

>> Lemmatization: 
 [('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analysed'), ('computationally', 'computationally'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'association'), (',', ',')]



========================================== PARAGRAPH 300 ===========================================

especially relating to human behaviour and interactions”. Arunachalam et al. (2018) argued that  

------------------- Sentence 1 -------------------

especially relating to human behaviour and interactions”.

>> Tokens are: 
 ['especially', 'relating', 'human', 'behaviour', 'interactions', '”', '.']

>> Bigrams are: 
 [('especially', 'relating'), ('relating', 'human'), ('human', 'behaviour'), ('behaviour', 'interactions'), ('interactions', '”'), ('”', '.')]

>> Trigrams are: 
 [('especially', 'relating', 'human'), ('relating', 'human', 'behaviour'), ('human', 'behaviour', 'interactions'), ('behaviour', 'interactions', '”'), ('interactions', '”', '.')]

>> POS Tags are: 
 [('especially', 'RB'), ('relating', 'VBG'), ('human', 'JJ'), ('behaviour', 'NN'), ('interactions', 'NNS'), ('”', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['human behaviour interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('especially', 'especi'), ('relating', 'relat'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interact'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('especially', 'especi'), ('relating', 'relat'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interact'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('especially', 'especially'), ('relating', 'relating'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interaction'), ('”', '”'), ('.', '.')]


------------------- Sentence 2 -------------------

Arunachalam et al.

>> Tokens are: 
 ['Arunachalam', 'et', 'al', '.']

>> Bigrams are: 
 [('Arunachalam', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Arunachalam', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Arunachalam', 'al']

>> Named Entities are: 
 [('GPE', 'Arunachalam')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(2018) argued that

>> Tokens are: 
 ['(', '2018', ')', 'argued']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'argued')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'argued')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('argued', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argued')]



========================================== PARAGRAPH 301 ===========================================

this definition does not give the whole picture of big data, however, as big data must be  

------------------- Sentence 1 -------------------

this definition does not give the whole picture of big data, however, as big data must be

>> Tokens are: 
 ['definition', 'give', 'whole', 'picture', 'big', 'data', ',', 'however', ',', 'big', 'data', 'must']

>> Bigrams are: 
 [('definition', 'give'), ('give', 'whole'), ('whole', 'picture'), ('picture', 'big'), ('big', 'data'), ('data', ','), (',', 'however'), ('however', ','), (',', 'big'), ('big', 'data'), ('data', 'must')]

>> Trigrams are: 
 [('definition', 'give', 'whole'), ('give', 'whole', 'picture'), ('whole', 'picture', 'big'), ('picture', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'however'), (',', 'however', ','), ('however', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'must')]

>> POS Tags are: 
 [('definition', 'NN'), ('give', 'JJ'), ('whole', 'JJ'), ('picture', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('must', 'MD')]

>> Noun Phrases are: 
 ['definition', 'give whole picture', 'big data', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('definition', 'definit'), ('give', 'give'), ('whole', 'whole'), ('picture', 'pictur'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must')]

>> Stemming using Snowball Stemmer: 
 [('definition', 'definit'), ('give', 'give'), ('whole', 'whole'), ('picture', 'pictur'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must')]

>> Lemmatization: 
 [('definition', 'definition'), ('give', 'give'), ('whole', 'whole'), ('picture', 'picture'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'however'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must')]



========================================== PARAGRAPH 302 ===========================================

differentiated from data as being difficult to handle using traditional data analyses. Big data thus  

------------------- Sentence 1 -------------------

differentiated from data as being difficult to handle using traditional data analyses.

>> Tokens are: 
 ['differentiated', 'data', 'difficult', 'handle', 'using', 'traditional', 'data', 'analyses', '.']

>> Bigrams are: 
 [('differentiated', 'data'), ('data', 'difficult'), ('difficult', 'handle'), ('handle', 'using'), ('using', 'traditional'), ('traditional', 'data'), ('data', 'analyses'), ('analyses', '.')]

>> Trigrams are: 
 [('differentiated', 'data', 'difficult'), ('data', 'difficult', 'handle'), ('difficult', 'handle', 'using'), ('handle', 'using', 'traditional'), ('using', 'traditional', 'data'), ('traditional', 'data', 'analyses'), ('data', 'analyses', '.')]

>> POS Tags are: 
 [('differentiated', 'VBN'), ('data', 'NNS'), ('difficult', 'JJ'), ('handle', 'JJ'), ('using', 'VBG'), ('traditional', 'JJ'), ('data', 'NN'), ('analyses', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'traditional data analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('differentiated', 'differenti'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('differentiated', 'differenti'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('differentiated', 'differentiated'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handle'), ('using', 'using'), ('traditional', 'traditional'), ('data', 'data'), ('analyses', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data thus

>> Tokens are: 
 ['Big', 'data', 'thus']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'thus')]

>> Trigrams are: 
 [('Big', 'data', 'thus')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('thus', 'RB')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('thus', 'thu')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('thus', 'thus')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('thus', 'thus')]



========================================== PARAGRAPH 303 ===========================================

inherently requires more sophisticated techniques for handling complexity, as this is exponentially  

------------------- Sentence 1 -------------------

inherently requires more sophisticated techniques for handling complexity, as this is exponentially

>> Tokens are: 
 ['inherently', 'requires', 'sophisticated', 'techniques', 'handling', 'complexity', ',', 'exponentially']

>> Bigrams are: 
 [('inherently', 'requires'), ('requires', 'sophisticated'), ('sophisticated', 'techniques'), ('techniques', 'handling'), ('handling', 'complexity'), ('complexity', ','), (',', 'exponentially')]

>> Trigrams are: 
 [('inherently', 'requires', 'sophisticated'), ('requires', 'sophisticated', 'techniques'), ('sophisticated', 'techniques', 'handling'), ('techniques', 'handling', 'complexity'), ('handling', 'complexity', ','), ('complexity', ',', 'exponentially')]

>> POS Tags are: 
 [('inherently', 'RB'), ('requires', 'VBZ'), ('sophisticated', 'JJ'), ('techniques', 'NNS'), ('handling', 'VBG'), ('complexity', 'NN'), (',', ','), ('exponentially', 'RB')]

>> Noun Phrases are: 
 ['sophisticated techniques', 'complexity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('inherently', 'inher'), ('requires', 'requir'), ('sophisticated', 'sophist'), ('techniques', 'techniqu'), ('handling', 'handl'), ('complexity', 'complex'), (',', ','), ('exponentially', 'exponenti')]

>> Stemming using Snowball Stemmer: 
 [('inherently', 'inher'), ('requires', 'requir'), ('sophisticated', 'sophist'), ('techniques', 'techniqu'), ('handling', 'handl'), ('complexity', 'complex'), (',', ','), ('exponentially', 'exponenti')]

>> Lemmatization: 
 [('inherently', 'inherently'), ('requires', 'requires'), ('sophisticated', 'sophisticated'), ('techniques', 'technique'), ('handling', 'handling'), ('complexity', 'complexity'), (',', ','), ('exponentially', 'exponentially')]



========================================== PARAGRAPH 304 ===========================================

increased.  

------------------- Sentence 1 -------------------

increased.

>> Tokens are: 
 ['increased', '.']

>> Bigrams are: 
 [('increased', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('increased', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('increased', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('increased', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('increased', 'increased'), ('.', '.')]



========================================== PARAGRAPH 305 ===========================================

By 2011, the term big data had become quite widespread, but shows the frequency distribution of  

------------------- Sentence 1 -------------------

By 2011, the term big data had become quite widespread, but shows the frequency distribution of

>> Tokens are: 
 ['By', '2011', ',', 'term', 'big', 'data', 'become', 'quite', 'widespread', ',', 'shows', 'frequency', 'distribution']

>> Bigrams are: 
 [('By', '2011'), ('2011', ','), (',', 'term'), ('term', 'big'), ('big', 'data'), ('data', 'become'), ('become', 'quite'), ('quite', 'widespread'), ('widespread', ','), (',', 'shows'), ('shows', 'frequency'), ('frequency', 'distribution')]

>> Trigrams are: 
 [('By', '2011', ','), ('2011', ',', 'term'), (',', 'term', 'big'), ('term', 'big', 'data'), ('big', 'data', 'become'), ('data', 'become', 'quite'), ('become', 'quite', 'widespread'), ('quite', 'widespread', ','), ('widespread', ',', 'shows'), (',', 'shows', 'frequency'), ('shows', 'frequency', 'distribution')]

>> POS Tags are: 
 [('By', 'IN'), ('2011', 'CD'), (',', ','), ('term', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('become', 'VBP'), ('quite', 'RB'), ('widespread', 'JJ'), (',', ','), ('shows', 'VBZ'), ('frequency', 'NN'), ('distribution', 'NN')]

>> Noun Phrases are: 
 ['term', 'big data', 'frequency distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'becom'), ('quite', 'quit'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequenc'), ('distribution', 'distribut')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'becom'), ('quite', 'quit'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequenc'), ('distribution', 'distribut')]

>> Lemmatization: 
 [('By', 'By'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'become'), ('quite', 'quite'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequency'), ('distribution', 'distribution')]



========================================== PARAGRAPH 306 ===========================================

the “big data” in the ProQuest Research Library more clearly (Gandomi and Haider, 2015). 

------------------- Sentence 1 -------------------

the “big data” in the ProQuest Research Library more clearly (Gandomi and Haider, 2015).

>> Tokens are: 
 ['“', 'big', 'data', '”', 'ProQuest', 'Research', 'Library', 'clearly', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'ProQuest'), ('ProQuest', 'Research'), ('Research', 'Library'), ('Library', 'clearly'), ('clearly', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'ProQuest'), ('”', 'ProQuest', 'Research'), ('ProQuest', 'Research', 'Library'), ('Research', 'Library', 'clearly'), ('Library', 'clearly', '('), ('clearly', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('“', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('ProQuest', 'NNP'), ('Research', 'NNP'), ('Library', 'NNP'), ('clearly', 'RB'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['big data ” ProQuest Research Library', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'ProQuest Research'), ('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('clearly', 'clearli'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('clearly', 'clear'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'ProQuest'), ('Research', 'Research'), ('Library', 'Library'), ('clearly', 'clearly'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 307 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 308 ===========================================

9  

------------------- Sentence 1 -------------------

9

>> Tokens are: 
 ['9']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9')]

>> Stemming using Snowball Stemmer: 
 [('9', '9')]

>> Lemmatization: 
 [('9', '9')]



========================================== PARAGRAPH 309 ===========================================

  


========================================== PARAGRAPH 310 ===========================================

  


========================================== PARAGRAPH 311 ===========================================

Figure 6: Frequency distribution of “big data” in the ProQuest Research Library (Gandomi and  

------------------- Sentence 1 -------------------

Figure 6: Frequency distribution of “big data” in the ProQuest Research Library (Gandomi and

>> Tokens are: 
 ['Figure', '6', ':', 'Frequency', 'distribution', '“', 'big', 'data', '”', 'ProQuest', 'Research', 'Library', '(', 'Gandomi']

>> Bigrams are: 
 [('Figure', '6'), ('6', ':'), (':', 'Frequency'), ('Frequency', 'distribution'), ('distribution', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'ProQuest'), ('ProQuest', 'Research'), ('Research', 'Library'), ('Library', '('), ('(', 'Gandomi')]

>> Trigrams are: 
 [('Figure', '6', ':'), ('6', ':', 'Frequency'), (':', 'Frequency', 'distribution'), ('Frequency', 'distribution', '“'), ('distribution', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'ProQuest'), ('”', 'ProQuest', 'Research'), ('ProQuest', 'Research', 'Library'), ('Research', 'Library', '('), ('Library', '(', 'Gandomi')]

>> POS Tags are: 
 [('Figure', 'NN'), ('6', 'CD'), (':', ':'), ('Frequency', 'NN'), ('distribution', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('ProQuest', 'NNP'), ('Research', 'NNP'), ('Library', 'NNP'), ('(', '('), ('Gandomi', 'NNP')]

>> Noun Phrases are: 
 ['Figure', 'Frequency distribution “', 'big data ” ProQuest Research Library', 'Gandomi']

>> Named Entities are: 
 [('ORGANIZATION', 'ProQuest Research'), ('ORGANIZATION', 'Gandomi')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('6', '6'), (':', ':'), ('Frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('(', '('), ('Gandomi', 'gandomi')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('6', '6'), (':', ':'), ('Frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('(', '('), ('Gandomi', 'gandomi')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('6', '6'), (':', ':'), ('Frequency', 'Frequency'), ('distribution', 'distribution'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'ProQuest'), ('Research', 'Research'), ('Library', 'Library'), ('(', '('), ('Gandomi', 'Gandomi')]



========================================== PARAGRAPH 312 ===========================================

Haider, 2015).  

------------------- Sentence 1 -------------------

Haider, 2015).

>> Tokens are: 
 ['Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Haider']

>> Named Entities are: 
 [('GPE', 'Haider')] 

>> Stemming using Porter Stemmer: 
 [('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 313 ===========================================

Research by Gandomi and Haider (2015) shows that different definitions of big data are used in  

------------------- Sentence 1 -------------------

Research by Gandomi and Haider (2015) shows that different definitions of big data are used in

>> Tokens are: 
 ['Research', 'Gandomi', 'Haider', '(', '2015', ')', 'shows', 'different', 'definitions', 'big', 'data', 'used']

>> Bigrams are: 
 [('Research', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', '('), ('(', '2015'), ('2015', ')'), (')', 'shows'), ('shows', 'different'), ('different', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'used')]

>> Trigrams are: 
 [('Research', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', '('), ('Haider', '(', '2015'), ('(', '2015', ')'), ('2015', ')', 'shows'), (')', 'shows', 'different'), ('shows', 'different', 'definitions'), ('different', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'used')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('shows', 'VBZ'), ('different', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Research Gandomi Haider', 'different definitions', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('used', 'use')]

>> Lemmatization: 
 [('Research', 'Research'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'different'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('used', 'used')]



========================================== PARAGRAPH 314 ===========================================

research and business. These big data definitions are vary depending on the understanding of the  

------------------- Sentence 1 -------------------

research and business.

>> Tokens are: 
 ['research', 'business', '.']

>> Bigrams are: 
 [('research', 'business'), ('business', '.')]

>> Trigrams are: 
 [('research', 'business', '.')]

>> POS Tags are: 
 [('research', 'NN'), ('business', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['research business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('business', 'busi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('business', 'busi'), ('.', '.')]

>> Lemmatization: 
 [('research', 'research'), ('business', 'business'), ('.', '.')]


------------------- Sentence 2 -------------------

These big data definitions are vary depending on the understanding of the

>> Tokens are: 
 ['These', 'big', 'data', 'definitions', 'vary', 'depending', 'understanding']

>> Bigrams are: 
 [('These', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'vary'), ('vary', 'depending'), ('depending', 'understanding')]

>> Trigrams are: 
 [('These', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'vary'), ('definitions', 'vary', 'depending'), ('vary', 'depending', 'understanding')]

>> POS Tags are: 
 [('These', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('vary', 'VBP'), ('depending', 'VBG'), ('understanding', 'NN')]

>> Noun Phrases are: 
 ['These big data definitions', 'understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('vary', 'vari'), ('depending', 'depend'), ('understanding', 'understand')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('vary', 'vari'), ('depending', 'depend'), ('understanding', 'understand')]

>> Lemmatization: 
 [('These', 'These'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('vary', 'vary'), ('depending', 'depending'), ('understanding', 'understanding')]



========================================== PARAGRAPH 315 ===========================================

user, with some focused on the characteristics of big data in terms of volume, variety, and velocity,  

------------------- Sentence 1 -------------------

user, with some focused on the characteristics of big data in terms of volume, variety, and velocity,

>> Tokens are: 
 ['user', ',', 'focused', 'characteristics', 'big', 'data', 'terms', 'volume', ',', 'variety', ',', 'velocity', ',']

>> Bigrams are: 
 [('user', ','), (',', 'focused'), ('focused', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', 'terms'), ('terms', 'volume'), ('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', ',')]

>> Trigrams are: 
 [('user', ',', 'focused'), (',', 'focused', 'characteristics'), ('focused', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', 'terms'), ('data', 'terms', 'volume'), ('terms', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', ',')]

>> POS Tags are: 
 [('user', 'NN'), (',', ','), ('focused', 'VBD'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('terms', 'NNS'), ('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['user', 'characteristics', 'big data terms volume', 'variety', 'velocity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('user', 'user'), (',', ','), ('focused', 'focus'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('user', 'user'), (',', ','), ('focused', 'focus'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ',')]

>> Lemmatization: 
 [('user', 'user'), (',', ','), ('focused', 'focused'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), (',', ',')]



========================================== PARAGRAPH 316 ===========================================

some focused on what it does, and others defining it dependent on their business’s requirements.  

------------------- Sentence 1 -------------------

some focused on what it does, and others defining it dependent on their business’s requirements.

>> Tokens are: 
 ['focused', ',', 'others', 'defining', 'dependent', 'business', '’', 'requirements', '.']

>> Bigrams are: 
 [('focused', ','), (',', 'others'), ('others', 'defining'), ('defining', 'dependent'), ('dependent', 'business'), ('business', '’'), ('’', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('focused', ',', 'others'), (',', 'others', 'defining'), ('others', 'defining', 'dependent'), ('defining', 'dependent', 'business'), ('dependent', 'business', '’'), ('business', '’', 'requirements'), ('’', 'requirements', '.')]

>> POS Tags are: 
 [('focused', 'VBN'), (',', ','), ('others', 'NNS'), ('defining', 'VBG'), ('dependent', 'NN'), ('business', 'NN'), ('’', 'NN'), ('requirements', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['others', 'dependent business ’ requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('focused', 'focus'), (',', ','), ('others', 'other'), ('defining', 'defin'), ('dependent', 'depend'), ('business', 'busi'), ('’', '’'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('focused', 'focus'), (',', ','), ('others', 'other'), ('defining', 'defin'), ('dependent', 'depend'), ('business', 'busi'), ('’', '’'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('focused', 'focused'), (',', ','), ('others', 'others'), ('defining', 'defining'), ('dependent', 'dependent'), ('business', 'business'), ('’', '’'), ('requirements', 'requirement'), ('.', '.')]



========================================== PARAGRAPH 317 ===========================================

Figure 7 shows the different definitions of big found in an online survey of 154 C-suite global  

------------------- Sentence 1 -------------------

Figure 7 shows the different definitions of big found in an online survey of 154 C-suite global

>> Tokens are: 
 ['Figure', '7', 'shows', 'different', 'definitions', 'big', 'found', 'online', 'survey', '154', 'C-suite', 'global']

>> Bigrams are: 
 [('Figure', '7'), ('7', 'shows'), ('shows', 'different'), ('different', 'definitions'), ('definitions', 'big'), ('big', 'found'), ('found', 'online'), ('online', 'survey'), ('survey', '154'), ('154', 'C-suite'), ('C-suite', 'global')]

>> Trigrams are: 
 [('Figure', '7', 'shows'), ('7', 'shows', 'different'), ('shows', 'different', 'definitions'), ('different', 'definitions', 'big'), ('definitions', 'big', 'found'), ('big', 'found', 'online'), ('found', 'online', 'survey'), ('online', 'survey', '154'), ('survey', '154', 'C-suite'), ('154', 'C-suite', 'global')]

>> POS Tags are: 
 [('Figure', 'NN'), ('7', 'CD'), ('shows', 'NNS'), ('different', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('found', 'VBD'), ('online', 'JJ'), ('survey', 'NN'), ('154', 'CD'), ('C-suite', 'JJ'), ('global', 'JJ')]

>> Noun Phrases are: 
 ['Figure', 'shows', 'different definitions', 'online survey']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('7', '7'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('found', 'found'), ('online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'c-suit'), ('global', 'global')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('7', '7'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('found', 'found'), ('online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'c-suit'), ('global', 'global')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('7', '7'), ('shows', 'show'), ('different', 'different'), ('definitions', 'definition'), ('big', 'big'), ('found', 'found'), ('online', 'online'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'C-suite'), ('global', 'global')]



========================================== PARAGRAPH 318 ===========================================

executives conducted by Harris Interactive on behalf of SAP in April 2012.   

------------------- Sentence 1 -------------------

executives conducted by Harris Interactive on behalf of SAP in April 2012.

>> Tokens are: 
 ['executives', 'conducted', 'Harris', 'Interactive', 'behalf', 'SAP', 'April', '2012', '.']

>> Bigrams are: 
 [('executives', 'conducted'), ('conducted', 'Harris'), ('Harris', 'Interactive'), ('Interactive', 'behalf'), ('behalf', 'SAP'), ('SAP', 'April'), ('April', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('executives', 'conducted', 'Harris'), ('conducted', 'Harris', 'Interactive'), ('Harris', 'Interactive', 'behalf'), ('Interactive', 'behalf', 'SAP'), ('behalf', 'SAP', 'April'), ('SAP', 'April', '2012'), ('April', '2012', '.')]

>> POS Tags are: 
 [('executives', 'NNS'), ('conducted', 'VBD'), ('Harris', 'NNP'), ('Interactive', 'NNP'), ('behalf', 'NN'), ('SAP', 'NNP'), ('April', 'NNP'), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['executives', 'Harris Interactive behalf SAP April']

>> Named Entities are: 
 [('PERSON', 'Harris Interactive'), ('ORGANIZATION', 'SAP')] 

>> Stemming using Porter Stemmer: 
 [('executives', 'execut'), ('conducted', 'conduct'), ('Harris', 'harri'), ('Interactive', 'interact'), ('behalf', 'behalf'), ('SAP', 'sap'), ('April', 'april'), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('executives', 'execut'), ('conducted', 'conduct'), ('Harris', 'harri'), ('Interactive', 'interact'), ('behalf', 'behalf'), ('SAP', 'sap'), ('April', 'april'), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('executives', 'executive'), ('conducted', 'conducted'), ('Harris', 'Harris'), ('Interactive', 'Interactive'), ('behalf', 'behalf'), ('SAP', 'SAP'), ('April', 'April'), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 319 ===========================================

Early research work (Laney, 2001) focused on big data definition based on the 3Vs (volume,  

------------------- Sentence 1 -------------------

Early research work (Laney, 2001) focused on big data definition based on the 3Vs (volume,

>> Tokens are: 
 ['Early', 'research', 'work', '(', 'Laney', ',', '2001', ')', 'focused', 'big', 'data', 'definition', 'based', '3Vs', '(', 'volume', ',']

>> Bigrams are: 
 [('Early', 'research'), ('research', 'work'), ('work', '('), ('(', 'Laney'), ('Laney', ','), (',', '2001'), ('2001', ')'), (')', 'focused'), ('focused', 'big'), ('big', 'data'), ('data', 'definition'), ('definition', 'based'), ('based', '3Vs'), ('3Vs', '('), ('(', 'volume'), ('volume', ',')]

>> Trigrams are: 
 [('Early', 'research', 'work'), ('research', 'work', '('), ('work', '(', 'Laney'), ('(', 'Laney', ','), ('Laney', ',', '2001'), (',', '2001', ')'), ('2001', ')', 'focused'), (')', 'focused', 'big'), ('focused', 'big', 'data'), ('big', 'data', 'definition'), ('data', 'definition', 'based'), ('definition', 'based', '3Vs'), ('based', '3Vs', '('), ('3Vs', '(', 'volume'), ('(', 'volume', ',')]

>> POS Tags are: 
 [('Early', 'JJ'), ('research', 'NN'), ('work', 'NN'), ('(', '('), ('Laney', 'NNP'), (',', ','), ('2001', 'CD'), (')', ')'), ('focused', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('definition', 'NN'), ('based', 'VBN'), ('3Vs', 'CD'), ('(', '('), ('volume', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Early research work', 'Laney', 'big data definition', 'volume']

>> Named Entities are: 
 [('GPE', 'Early'), ('PERSON', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('Early', 'earli'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focus'), ('big', 'big'), ('data', 'data'), ('definition', 'definit'), ('based', 'base'), ('3Vs', '3v'), ('(', '('), ('volume', 'volum'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Early', 'earli'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focus'), ('big', 'big'), ('data', 'data'), ('definition', 'definit'), ('based', 'base'), ('3Vs', '3vs'), ('(', '('), ('volume', 'volum'), (',', ',')]

>> Lemmatization: 
 [('Early', 'Early'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'Laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focused'), ('big', 'big'), ('data', 'data'), ('definition', 'definition'), ('based', 'based'), ('3Vs', '3Vs'), ('(', '('), ('volume', 'volume'), (',', ',')]



========================================== PARAGRAPH 320 ===========================================

velocity, and variety). Sagiroglu and Sinanc (2013) later presented a big data research review and  

------------------- Sentence 1 -------------------

velocity, and variety).

>> Tokens are: 
 ['velocity', ',', 'variety', ')', '.']

>> Bigrams are: 
 [('velocity', ','), (',', 'variety'), ('variety', ')'), (')', '.')]

>> Trigrams are: 
 [('velocity', ',', 'variety'), (',', 'variety', ')'), ('variety', ')', '.')]

>> POS Tags are: 
 [('velocity', 'NN'), (',', ','), ('variety', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['velocity', 'variety']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Sagiroglu and Sinanc (2013) later presented a big data research review and

>> Tokens are: 
 ['Sagiroglu', 'Sinanc', '(', '2013', ')', 'later', 'presented', 'big', 'data', 'research', 'review']

>> Bigrams are: 
 [('Sagiroglu', 'Sinanc'), ('Sinanc', '('), ('(', '2013'), ('2013', ')'), (')', 'later'), ('later', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'research'), ('research', 'review')]

>> Trigrams are: 
 [('Sagiroglu', 'Sinanc', '('), ('Sinanc', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'later'), (')', 'later', 'presented'), ('later', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'research'), ('data', 'research', 'review')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), ('Sinanc', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('later', 'RB'), ('presented', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('research', 'NN'), ('review', 'NN')]

>> Noun Phrases are: 
 ['Sagiroglu Sinanc', 'big data research review']

>> Named Entities are: 
 [('PERSON', 'Sagiroglu'), ('ORGANIZATION', 'Sinanc')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), ('Sinanc', 'Sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review')]



========================================== PARAGRAPH 321 ===========================================

examined its security issues, while Lomotey et al. (2014) defined big data by 5Vs, extending the  

------------------- Sentence 1 -------------------

examined its security issues, while Lomotey et al.

>> Tokens are: 
 ['examined', 'security', 'issues', ',', 'Lomotey', 'et', 'al', '.']

>> Bigrams are: 
 [('examined', 'security'), ('security', 'issues'), ('issues', ','), (',', 'Lomotey'), ('Lomotey', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('examined', 'security', 'issues'), ('security', 'issues', ','), ('issues', ',', 'Lomotey'), (',', 'Lomotey', 'et'), ('Lomotey', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('examined', 'JJ'), ('security', 'NN'), ('issues', 'NNS'), (',', ','), ('Lomotey', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['examined security issues', 'Lomotey', 'al']

>> Named Entities are: 
 [('PERSON', 'Lomotey')] 

>> Stemming using Porter Stemmer: 
 [('examined', 'examin'), ('security', 'secur'), ('issues', 'issu'), (',', ','), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('examined', 'examin'), ('security', 'secur'), ('issues', 'issu'), (',', ','), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('examined', 'examined'), ('security', 'security'), ('issues', 'issue'), (',', ','), ('Lomotey', 'Lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2014) defined big data by 5Vs, extending the

>> Tokens are: 
 ['(', '2014', ')', 'defined', 'big', 'data', '5Vs', ',', 'extending']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'defined'), ('defined', 'big'), ('big', 'data'), ('data', '5Vs'), ('5Vs', ','), (',', 'extending')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'defined'), (')', 'defined', 'big'), ('defined', 'big', 'data'), ('big', 'data', '5Vs'), ('data', '5Vs', ','), ('5Vs', ',', 'extending')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('defined', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('5Vs', 'CD'), (',', ','), ('extending', 'VBG')]

>> Noun Phrases are: 
 ['big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5v'), (',', ','), ('extending', 'extend')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5vs'), (',', ','), ('extending', 'extend')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defined'), ('big', 'big'), ('data', 'data'), ('5Vs', '5Vs'), (',', ','), ('extending', 'extending')]



========================================== PARAGRAPH 322 ===========================================

work done by Laney (2001) from 3Vs to include value, and veracity (Al-Barashdi and Al-Karousi,  

------------------- Sentence 1 -------------------

work done by Laney (2001) from 3Vs to include value, and veracity (Al-Barashdi and Al-Karousi,

>> Tokens are: 
 ['work', 'done', 'Laney', '(', '2001', ')', '3Vs', 'include', 'value', ',', 'veracity', '(', 'Al-Barashdi', 'Al-Karousi', ',']

>> Bigrams are: 
 [('work', 'done'), ('done', 'Laney'), ('Laney', '('), ('(', '2001'), ('2001', ')'), (')', '3Vs'), ('3Vs', 'include'), ('include', 'value'), ('value', ','), (',', 'veracity'), ('veracity', '('), ('(', 'Al-Barashdi'), ('Al-Barashdi', 'Al-Karousi'), ('Al-Karousi', ',')]

>> Trigrams are: 
 [('work', 'done', 'Laney'), ('done', 'Laney', '('), ('Laney', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '3Vs'), (')', '3Vs', 'include'), ('3Vs', 'include', 'value'), ('include', 'value', ','), ('value', ',', 'veracity'), (',', 'veracity', '('), ('veracity', '(', 'Al-Barashdi'), ('(', 'Al-Barashdi', 'Al-Karousi'), ('Al-Barashdi', 'Al-Karousi', ',')]

>> POS Tags are: 
 [('work', 'NN'), ('done', 'VBN'), ('Laney', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('3Vs', 'CD'), ('include', 'VBP'), ('value', 'NN'), (',', ','), ('veracity', 'NN'), ('(', '('), ('Al-Barashdi', 'JJ'), ('Al-Karousi', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['work', 'Laney', 'value', 'veracity', 'Al-Barashdi Al-Karousi']

>> Named Entities are: 
 [('GPE', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('work', 'work'), ('done', 'done'), ('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3v'), ('include', 'includ'), ('value', 'valu'), (',', ','), ('veracity', 'verac'), ('(', '('), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('work', 'work'), ('done', 'done'), ('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3vs'), ('include', 'includ'), ('value', 'valu'), (',', ','), ('veracity', 'verac'), ('(', '('), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ',')]

>> Lemmatization: 
 [('work', 'work'), ('done', 'done'), ('Laney', 'Laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3Vs'), ('include', 'include'), ('value', 'value'), (',', ','), ('veracity', 'veracity'), ('(', '('), ('Al-Barashdi', 'Al-Barashdi'), ('Al-Karousi', 'Al-Karousi'), (',', ',')]



========================================== PARAGRAPH 323 ===========================================

2019 ).   

------------------- Sentence 1 -------------------

2019 ).

>> Tokens are: 
 ['2019', ')', '.']

>> Bigrams are: 
 [('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2019', ')', '.')]

>> POS Tags are: 
 [('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 324 ===========================================

Ren et al. (2019) thus recently developed a set of up-to-date big data definitions, as shown in Table  

------------------- Sentence 1 -------------------

Ren et al.

>> Tokens are: 
 ['Ren', 'et', 'al', '.']

>> Bigrams are: 
 [('Ren', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Ren', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Ren', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ren', 'al']

>> Named Entities are: 
 [('PERSON', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('Ren', 'ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ren', 'ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Ren', 'Ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2019) thus recently developed a set of up-to-date big data definitions, as shown in Table

>> Tokens are: 
 ['(', '2019', ')', 'thus', 'recently', 'developed', 'set', 'up-to-date', 'big', 'data', 'definitions', ',', 'shown', 'Table']

>> Bigrams are: 
 [('(', '2019'), ('2019', ')'), (')', 'thus'), ('thus', 'recently'), ('recently', 'developed'), ('developed', 'set'), ('set', 'up-to-date'), ('up-to-date', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', ','), (',', 'shown'), ('shown', 'Table')]

>> Trigrams are: 
 [('(', '2019', ')'), ('2019', ')', 'thus'), (')', 'thus', 'recently'), ('thus', 'recently', 'developed'), ('recently', 'developed', 'set'), ('developed', 'set', 'up-to-date'), ('set', 'up-to-date', 'big'), ('up-to-date', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', ','), ('definitions', ',', 'shown'), (',', 'shown', 'Table')]

>> POS Tags are: 
 [('(', '('), ('2019', 'CD'), (')', ')'), ('thus', 'RB'), ('recently', 'RB'), ('developed', 'VBN'), ('set', 'VBN'), ('up-to-date', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), (',', ','), ('shown', 'VBN'), ('Table', 'NN')]

>> Noun Phrases are: 
 ['up-to-date big data definitions', 'Table']

>> Named Entities are: 
 [('PERSON', 'Table')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thu'), ('recently', 'recent'), ('developed', 'develop'), ('set', 'set'), ('up-to-date', 'up-to-d'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('shown', 'shown'), ('Table', 'tabl')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thus'), ('recently', 'recent'), ('developed', 'develop'), ('set', 'set'), ('up-to-date', 'up-to-d'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('shown', 'shown'), ('Table', 'tabl')]

>> Lemmatization: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thus'), ('recently', 'recently'), ('developed', 'developed'), ('set', 'set'), ('up-to-date', 'up-to-date'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), (',', ','), ('shown', 'shown'), ('Table', 'Table')]



========================================== PARAGRAPH 325 ===========================================

1. Figure 8 shows predictions of global data volume provided by International Data Corporation  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Figure 8 shows predictions of global data volume provided by International Data Corporation

>> Tokens are: 
 ['Figure', '8', 'shows', 'predictions', 'global', 'data', 'volume', 'provided', 'International', 'Data', 'Corporation']

>> Bigrams are: 
 [('Figure', '8'), ('8', 'shows'), ('shows', 'predictions'), ('predictions', 'global'), ('global', 'data'), ('data', 'volume'), ('volume', 'provided'), ('provided', 'International'), ('International', 'Data'), ('Data', 'Corporation')]

>> Trigrams are: 
 [('Figure', '8', 'shows'), ('8', 'shows', 'predictions'), ('shows', 'predictions', 'global'), ('predictions', 'global', 'data'), ('global', 'data', 'volume'), ('data', 'volume', 'provided'), ('volume', 'provided', 'International'), ('provided', 'International', 'Data'), ('International', 'Data', 'Corporation')]

>> POS Tags are: 
 [('Figure', 'NN'), ('8', 'CD'), ('shows', 'NNS'), ('predictions', 'NNS'), ('global', 'JJ'), ('data', 'NN'), ('volume', 'NN'), ('provided', 'VBD'), ('International', 'NNP'), ('Data', 'NNP'), ('Corporation', 'NNP')]

>> Noun Phrases are: 
 ['Figure', 'shows predictions', 'global data volume', 'International Data Corporation']

>> Named Entities are: 
 [('ORGANIZATION', 'International Data Corporation')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('8', '8'), ('shows', 'show'), ('predictions', 'predict'), ('global', 'global'), ('data', 'data'), ('volume', 'volum'), ('provided', 'provid'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('8', '8'), ('shows', 'show'), ('predictions', 'predict'), ('global', 'global'), ('data', 'data'), ('volume', 'volum'), ('provided', 'provid'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('8', '8'), ('shows', 'show'), ('predictions', 'prediction'), ('global', 'global'), ('data', 'data'), ('volume', 'volume'), ('provided', 'provided'), ('International', 'International'), ('Data', 'Data'), ('Corporation', 'Corporation')]



========================================== PARAGRAPH 326 ===========================================

(IDC) (Tien, J.M., 2013). Besides the massive volume of big data, the complex structure of this  

------------------- Sentence 1 -------------------

(IDC) (Tien, J.M., 2013).

>> Tokens are: 
 ['(', 'IDC', ')', '(', 'Tien', ',', 'J.M.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('(', 'IDC'), ('IDC', ')'), (')', '('), ('(', 'Tien'), ('Tien', ','), (',', 'J.M.'), ('J.M.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'IDC', ')'), ('IDC', ')', '('), (')', '(', 'Tien'), ('(', 'Tien', ','), ('Tien', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('IDC', 'NNP'), (')', ')'), ('(', '('), ('Tien', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['IDC', 'Tien', 'J.M.']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC'), ('ORGANIZATION', 'Tien')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('IDC', 'idc'), (')', ')'), ('(', '('), ('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('IDC', 'idc'), (')', ')'), ('(', '('), ('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('IDC', 'IDC'), (')', ')'), ('(', '('), ('Tien', 'Tien'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Besides the massive volume of big data, the complex structure of this

>> Tokens are: 
 ['Besides', 'massive', 'volume', 'big', 'data', ',', 'complex', 'structure']

>> Bigrams are: 
 [('Besides', 'massive'), ('massive', 'volume'), ('volume', 'big'), ('big', 'data'), ('data', ','), (',', 'complex'), ('complex', 'structure')]

>> Trigrams are: 
 [('Besides', 'massive', 'volume'), ('massive', 'volume', 'big'), ('volume', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'complex'), (',', 'complex', 'structure')]

>> POS Tags are: 
 [('Besides', 'IN'), ('massive', 'JJ'), ('volume', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('complex', 'JJ'), ('structure', 'NN')]

>> Noun Phrases are: 
 ['massive volume', 'big data', 'complex structure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Besides', 'besid'), ('massive', 'massiv'), ('volume', 'volum'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('Besides', 'besid'), ('massive', 'massiv'), ('volume', 'volum'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structur')]

>> Lemmatization: 
 [('Besides', 'Besides'), ('massive', 'massive'), ('volume', 'volume'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structure')]



========================================== PARAGRAPH 327 ===========================================

new data and the difficulty in managing and protecting such data have added further issues. Since  

------------------- Sentence 1 -------------------

new data and the difficulty in managing and protecting such data have added further issues.

>> Tokens are: 
 ['new', 'data', 'difficulty', 'managing', 'protecting', 'data', 'added', 'issues', '.']

>> Bigrams are: 
 [('new', 'data'), ('data', 'difficulty'), ('difficulty', 'managing'), ('managing', 'protecting'), ('protecting', 'data'), ('data', 'added'), ('added', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('new', 'data', 'difficulty'), ('data', 'difficulty', 'managing'), ('difficulty', 'managing', 'protecting'), ('managing', 'protecting', 'data'), ('protecting', 'data', 'added'), ('data', 'added', 'issues'), ('added', 'issues', '.')]

>> POS Tags are: 
 [('new', 'JJ'), ('data', 'NNS'), ('difficulty', 'NN'), ('managing', 'VBG'), ('protecting', 'VBG'), ('data', 'NNS'), ('added', 'VBD'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['new data difficulty', 'data', 'issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('new', 'new'), ('data', 'data'), ('difficulty', 'difficulti'), ('managing', 'manag'), ('protecting', 'protect'), ('data', 'data'), ('added', 'ad'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('new', 'new'), ('data', 'data'), ('difficulty', 'difficulti'), ('managing', 'manag'), ('protecting', 'protect'), ('data', 'data'), ('added', 'ad'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('new', 'new'), ('data', 'data'), ('difficulty', 'difficulty'), ('managing', 'managing'), ('protecting', 'protecting'), ('data', 'data'), ('added', 'added'), ('issues', 'issue'), ('.', '.')]


------------------- Sentence 2 -------------------

Since

>> Tokens are: 
 ['Since']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Since', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc')]

>> Lemmatization: 
 [('Since', 'Since')]



========================================== PARAGRAPH 328 ===========================================

the idea of big data was raised, it has thus become one of the most popular focuses in both technical  

------------------- Sentence 1 -------------------

the idea of big data was raised, it has thus become one of the most popular focuses in both technical

>> Tokens are: 
 ['idea', 'big', 'data', 'raised', ',', 'thus', 'become', 'one', 'popular', 'focuses', 'technical']

>> Bigrams are: 
 [('idea', 'big'), ('big', 'data'), ('data', 'raised'), ('raised', ','), (',', 'thus'), ('thus', 'become'), ('become', 'one'), ('one', 'popular'), ('popular', 'focuses'), ('focuses', 'technical')]

>> Trigrams are: 
 [('idea', 'big', 'data'), ('big', 'data', 'raised'), ('data', 'raised', ','), ('raised', ',', 'thus'), (',', 'thus', 'become'), ('thus', 'become', 'one'), ('become', 'one', 'popular'), ('one', 'popular', 'focuses'), ('popular', 'focuses', 'technical')]

>> POS Tags are: 
 [('idea', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('raised', 'VBD'), (',', ','), ('thus', 'RB'), ('become', 'VB'), ('one', 'CD'), ('popular', 'JJ'), ('focuses', 'VBZ'), ('technical', 'JJ')]

>> Noun Phrases are: 
 ['idea', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'rais'), (',', ','), ('thus', 'thu'), ('become', 'becom'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technic')]

>> Stemming using Snowball Stemmer: 
 [('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'rais'), (',', ','), ('thus', 'thus'), ('become', 'becom'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technic')]

>> Lemmatization: 
 [('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'raised'), (',', ','), ('thus', 'thus'), ('become', 'become'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technical')]



========================================== PARAGRAPH 329 ===========================================

and engineering areas (Wang et al., 2016).  

------------------- Sentence 1 -------------------

and engineering areas (Wang et al., 2016).

>> Tokens are: 
 ['engineering', 'areas', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('engineering', 'areas'), ('areas', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('engineering', 'areas', '('), ('areas', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('engineering', 'NN'), ('areas', 'NNS'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['engineering areas', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('engineering', 'engin'), ('areas', 'area'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('engineering', 'engin'), ('areas', 'area'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('engineering', 'engineering'), ('areas', 'area'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 330 ===========================================

  


========================================== PARAGRAPH 331 ===========================================

 


========================================== PARAGRAPH 332 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 333 ===========================================

10  

------------------- Sentence 1 -------------------

10

>> Tokens are: 
 ['10']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10')]

>> Stemming using Snowball Stemmer: 
 [('10', '10')]

>> Lemmatization: 
 [('10', '10')]



========================================== PARAGRAPH 334 ===========================================

  


========================================== PARAGRAPH 335 ===========================================

  


========================================== PARAGRAPH 336 ===========================================

Figure 7: Definitions of big data (Online survey of 154 global executives in April 2012,  

------------------- Sentence 1 -------------------

Figure 7: Definitions of big data (Online survey of 154 global executives in April 2012,

>> Tokens are: 
 ['Figure', '7', ':', 'Definitions', 'big', 'data', '(', 'Online', 'survey', '154', 'global', 'executives', 'April', '2012', ',']

>> Bigrams are: 
 [('Figure', '7'), ('7', ':'), (':', 'Definitions'), ('Definitions', 'big'), ('big', 'data'), ('data', '('), ('(', 'Online'), ('Online', 'survey'), ('survey', '154'), ('154', 'global'), ('global', 'executives'), ('executives', 'April'), ('April', '2012'), ('2012', ',')]

>> Trigrams are: 
 [('Figure', '7', ':'), ('7', ':', 'Definitions'), (':', 'Definitions', 'big'), ('Definitions', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Online'), ('(', 'Online', 'survey'), ('Online', 'survey', '154'), ('survey', '154', 'global'), ('154', 'global', 'executives'), ('global', 'executives', 'April'), ('executives', 'April', '2012'), ('April', '2012', ',')]

>> POS Tags are: 
 [('Figure', 'NN'), ('7', 'CD'), (':', ':'), ('Definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Online', 'NNP'), ('survey', 'NN'), ('154', 'CD'), ('global', 'JJ'), ('executives', 'NNS'), ('April', 'NNP'), ('2012', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['Figure', 'Definitions', 'big data', 'Online survey', 'global executives April']

>> Named Entities are: 
 [('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('7', '7'), (':', ':'), ('Definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'execut'), ('April', 'april'), ('2012', '2012'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('7', '7'), (':', ':'), ('Definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'execut'), ('April', 'april'), ('2012', '2012'), (',', ',')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('7', '7'), (':', ':'), ('Definitions', 'Definitions'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'Online'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'executive'), ('April', 'April'), ('2012', '2012'), (',', ',')]



========================================== PARAGRAPH 337 ===========================================

Gandomi and Haider, 2015).  

------------------- Sentence 1 -------------------

Gandomi and Haider, 2015).

>> Tokens are: 
 ['Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Gandomi Haider']

>> Named Entities are: 
 [('PERSON', 'Gandomi'), ('GPE', 'Haider')] 

>> Stemming using Porter Stemmer: 
 [('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 338 ===========================================

  


========================================== PARAGRAPH 339 ===========================================

To realise big data’s potential, the data should be gathered in a new way which enables it to be  

------------------- Sentence 1 -------------------

To realise big data’s potential, the data should be gathered in a new way which enables it to be

>> Tokens are: 
 ['To', 'realise', 'big', 'data', '’', 'potential', ',', 'data', 'gathered', 'new', 'way', 'enables']

>> Bigrams are: 
 [('To', 'realise'), ('realise', 'big'), ('big', 'data'), ('data', '’'), ('’', 'potential'), ('potential', ','), (',', 'data'), ('data', 'gathered'), ('gathered', 'new'), ('new', 'way'), ('way', 'enables')]

>> Trigrams are: 
 [('To', 'realise', 'big'), ('realise', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'potential'), ('’', 'potential', ','), ('potential', ',', 'data'), (',', 'data', 'gathered'), ('data', 'gathered', 'new'), ('gathered', 'new', 'way'), ('new', 'way', 'enables')]

>> POS Tags are: 
 [('To', 'TO'), ('realise', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'MD'), ('potential', 'JJ'), (',', ','), ('data', 'NNS'), ('gathered', 'VBD'), ('new', 'JJ'), ('way', 'NN'), ('enables', 'NNS')]

>> Noun Phrases are: 
 ['big data', 'data', 'new way enables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('realise', 'realis'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), (',', ','), ('data', 'data'), ('gathered', 'gather'), ('new', 'new'), ('way', 'way'), ('enables', 'enabl')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('realise', 'realis'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), (',', ','), ('data', 'data'), ('gathered', 'gather'), ('new', 'new'), ('way', 'way'), ('enables', 'enabl')]

>> Lemmatization: 
 [('To', 'To'), ('realise', 'realise'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potential'), (',', ','), ('data', 'data'), ('gathered', 'gathered'), ('new', 'new'), ('way', 'way'), ('enables', 'enables')]



========================================== PARAGRAPH 340 ===========================================

utilised for different purposes many times without recollection; this can be seen today in the many  

------------------- Sentence 1 -------------------

utilised for different purposes many times without recollection; this can be seen today in the many

>> Tokens are: 
 ['utilised', 'different', 'purposes', 'many', 'times', 'without', 'recollection', ';', 'seen', 'today', 'many']

>> Bigrams are: 
 [('utilised', 'different'), ('different', 'purposes'), ('purposes', 'many'), ('many', 'times'), ('times', 'without'), ('without', 'recollection'), ('recollection', ';'), (';', 'seen'), ('seen', 'today'), ('today', 'many')]

>> Trigrams are: 
 [('utilised', 'different', 'purposes'), ('different', 'purposes', 'many'), ('purposes', 'many', 'times'), ('many', 'times', 'without'), ('times', 'without', 'recollection'), ('without', 'recollection', ';'), ('recollection', ';', 'seen'), (';', 'seen', 'today'), ('seen', 'today', 'many')]

>> POS Tags are: 
 [('utilised', 'JJ'), ('different', 'JJ'), ('purposes', 'NNS'), ('many', 'JJ'), ('times', 'NNS'), ('without', 'IN'), ('recollection', 'NN'), (';', ':'), ('seen', 'VBN'), ('today', 'NN'), ('many', 'JJ')]

>> Noun Phrases are: 
 ['utilised different purposes', 'many times', 'recollection', 'today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('utilised', 'utilis'), ('different', 'differ'), ('purposes', 'purpos'), ('many', 'mani'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollect'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'mani')]

>> Stemming using Snowball Stemmer: 
 [('utilised', 'utilis'), ('different', 'differ'), ('purposes', 'purpos'), ('many', 'mani'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollect'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'mani')]

>> Lemmatization: 
 [('utilised', 'utilised'), ('different', 'different'), ('purposes', 'purpose'), ('many', 'many'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollection'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'many')]



========================================== PARAGRAPH 341 ===========================================

devices connected to the internet and the huge amount of data accesses even by individuals. By  

------------------- Sentence 1 -------------------

devices connected to the internet and the huge amount of data accesses even by individuals.

>> Tokens are: 
 ['devices', 'connected', 'internet', 'huge', 'amount', 'data', 'accesses', 'even', 'individuals', '.']

>> Bigrams are: 
 [('devices', 'connected'), ('connected', 'internet'), ('internet', 'huge'), ('huge', 'amount'), ('amount', 'data'), ('data', 'accesses'), ('accesses', 'even'), ('even', 'individuals'), ('individuals', '.')]

>> Trigrams are: 
 [('devices', 'connected', 'internet'), ('connected', 'internet', 'huge'), ('internet', 'huge', 'amount'), ('huge', 'amount', 'data'), ('amount', 'data', 'accesses'), ('data', 'accesses', 'even'), ('accesses', 'even', 'individuals'), ('even', 'individuals', '.')]

>> POS Tags are: 
 [('devices', 'NNS'), ('connected', 'VBN'), ('internet', 'RB'), ('huge', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('accesses', 'NNS'), ('even', 'RB'), ('individuals', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['devices', 'huge amount data accesses', 'individuals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('devices', 'devic'), ('connected', 'connect'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('devices', 'devic'), ('connected', 'connect'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individu'), ('.', '.')]

>> Lemmatization: 
 [('devices', 'device'), ('connected', 'connected'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individual'), ('.', '.')]


------------------- Sentence 2 -------------------

By

>> Tokens are: 
 ['By']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('By', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by')]

>> Lemmatization: 
 [('By', 'By')]



========================================== PARAGRAPH 342 ===========================================

2020, the predicted value of data is posited to double every 24 months (Mayer-Schonberger and  

------------------- Sentence 1 -------------------

2020, the predicted value of data is posited to double every 24 months (Mayer-Schonberger and

>> Tokens are: 
 ['2020', ',', 'predicted', 'value', 'data', 'posited', 'double', 'every', '24', 'months', '(', 'Mayer-Schonberger']

>> Bigrams are: 
 [('2020', ','), (',', 'predicted'), ('predicted', 'value'), ('value', 'data'), ('data', 'posited'), ('posited', 'double'), ('double', 'every'), ('every', '24'), ('24', 'months'), ('months', '('), ('(', 'Mayer-Schonberger')]

>> Trigrams are: 
 [('2020', ',', 'predicted'), (',', 'predicted', 'value'), ('predicted', 'value', 'data'), ('value', 'data', 'posited'), ('data', 'posited', 'double'), ('posited', 'double', 'every'), ('double', 'every', '24'), ('every', '24', 'months'), ('24', 'months', '('), ('months', '(', 'Mayer-Schonberger')]

>> POS Tags are: 
 [('2020', 'CD'), (',', ','), ('predicted', 'VBD'), ('value', 'NN'), ('data', 'NNS'), ('posited', 'VBD'), ('double', 'JJ'), ('every', 'DT'), ('24', 'CD'), ('months', 'NNS'), ('(', '('), ('Mayer-Schonberger', 'NNP')]

>> Noun Phrases are: 
 ['value data', 'months', 'Mayer-Schonberger']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2020', '2020'), (',', ','), ('predicted', 'predict'), ('value', 'valu'), ('data', 'data'), ('posited', 'posit'), ('double', 'doubl'), ('every', 'everi'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'mayer-schonberg')]

>> Stemming using Snowball Stemmer: 
 [('2020', '2020'), (',', ','), ('predicted', 'predict'), ('value', 'valu'), ('data', 'data'), ('posited', 'posit'), ('double', 'doubl'), ('every', 'everi'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'mayer-schonberg')]

>> Lemmatization: 
 [('2020', '2020'), (',', ','), ('predicted', 'predicted'), ('value', 'value'), ('data', 'data'), ('posited', 'posited'), ('double', 'double'), ('every', 'every'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'Mayer-Schonberger')]



========================================== PARAGRAPH 343 ===========================================

Padova, 2015).  

------------------- Sentence 1 -------------------

Padova, 2015).

>> Tokens are: 
 ['Padova', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Padova', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Padova', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Padova', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Padova']

>> Named Entities are: 
 [('GPE', 'Padova')] 

>> Stemming using Porter Stemmer: 
 [('Padova', 'padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Padova', 'padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Padova', 'Padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 344 ===========================================

  


========================================== PARAGRAPH 345 ===========================================

Figure 8: Global data volume predicted by IDC (Wang et al., 2016)  

------------------- Sentence 1 -------------------

Figure 8: Global data volume predicted by IDC (Wang et al., 2016)

>> Tokens are: 
 ['Figure', '8', ':', 'Global', 'data', 'volume', 'predicted', 'IDC', '(', 'Wang', 'et', 'al.', ',', '2016', ')']

>> Bigrams are: 
 [('Figure', '8'), ('8', ':'), (':', 'Global'), ('Global', 'data'), ('data', 'volume'), ('volume', 'predicted'), ('predicted', 'IDC'), ('IDC', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')')]

>> Trigrams are: 
 [('Figure', '8', ':'), ('8', ':', 'Global'), (':', 'Global', 'data'), ('Global', 'data', 'volume'), ('data', 'volume', 'predicted'), ('volume', 'predicted', 'IDC'), ('predicted', 'IDC', '('), ('IDC', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')')]

>> POS Tags are: 
 [('Figure', 'NN'), ('8', 'CD'), (':', ':'), ('Global', 'JJ'), ('data', 'NN'), ('volume', 'NN'), ('predicted', 'VBD'), ('IDC', 'NNP'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Figure', 'Global data volume', 'IDC', 'Wang']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC'), ('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('8', '8'), (':', ':'), ('Global', 'global'), ('data', 'data'), ('volume', 'volum'), ('predicted', 'predict'), ('IDC', 'idc'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('8', '8'), (':', ':'), ('Global', 'global'), ('data', 'data'), ('volume', 'volum'), ('predicted', 'predict'), ('IDC', 'idc'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('8', '8'), (':', ':'), ('Global', 'Global'), ('data', 'data'), ('volume', 'volume'), ('predicted', 'predicted'), ('IDC', 'IDC'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]



========================================== PARAGRAPH 346 ===========================================

 


========================================== PARAGRAPH 347 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 348 ===========================================

11  

------------------- Sentence 1 -------------------

11

>> Tokens are: 
 ['11']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11')]

>> Stemming using Snowball Stemmer: 
 [('11', '11')]

>> Lemmatization: 
 [('11', '11')]



========================================== PARAGRAPH 349 ===========================================

  


========================================== PARAGRAPH 350 ===========================================

  


========================================== PARAGRAPH 351 ===========================================

Table 1 shows various big data definitions or characteristics from the period 2001 to 2017.  

------------------- Sentence 1 -------------------

Table 1 shows various big data definitions or characteristics from the period 2001 to 2017.

>> Tokens are: 
 ['Table', '1', 'shows', 'various', 'big', 'data', 'definitions', 'characteristics', 'period', '2001', '2017', '.']

>> Bigrams are: 
 [('Table', '1'), ('1', 'shows'), ('shows', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'characteristics'), ('characteristics', 'period'), ('period', '2001'), ('2001', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Table', '1', 'shows'), ('1', 'shows', 'various'), ('shows', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'characteristics'), ('definitions', 'characteristics', 'period'), ('characteristics', 'period', '2001'), ('period', '2001', '2017'), ('2001', '2017', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('1', 'CD'), ('shows', 'NNS'), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('characteristics', 'NNS'), ('period', 'NN'), ('2001', 'CD'), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['shows', 'various big data definitions characteristics period']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('1', '1'), ('shows', 'show'), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('1', '1'), ('shows', 'show'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('1', '1'), ('shows', 'show'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('characteristics', 'characteristic'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]



========================================== PARAGRAPH 352 ===========================================

Table 1: Six representative definitions of big data adopted from (Ren et al., 2019).  

------------------- Sentence 1 -------------------

Table 1: Six representative definitions of big data adopted from (Ren et al., 2019).

>> Tokens are: 
 ['Table', '1', ':', 'Six', 'representative', 'definitions', 'big', 'data', 'adopted', '(', 'Ren', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Table', '1'), ('1', ':'), (':', 'Six'), ('Six', 'representative'), ('representative', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'adopted'), ('adopted', '('), ('(', 'Ren'), ('Ren', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Table', '1', ':'), ('1', ':', 'Six'), (':', 'Six', 'representative'), ('Six', 'representative', 'definitions'), ('representative', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'adopted'), ('data', 'adopted', '('), ('adopted', '(', 'Ren'), ('(', 'Ren', 'et'), ('Ren', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('1', 'CD'), (':', ':'), ('Six', 'CD'), ('representative', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('adopted', 'VBD'), ('(', '('), ('Ren', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['representative definitions', 'big data', 'Ren']

>> Named Entities are: 
 [('ORGANIZATION', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('1', '1'), (':', ':'), ('Six', 'Six'), ('representative', 'representative'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopted'), ('(', '('), ('Ren', 'Ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 353 ===========================================

  


========================================== PARAGRAPH 354 ===========================================

  


========================================== PARAGRAPH 355 ===========================================

 


========================================== PARAGRAPH 356 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 357 ===========================================

12  

------------------- Sentence 1 -------------------

12

>> Tokens are: 
 ['12']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12')]

>> Stemming using Snowball Stemmer: 
 [('12', '12')]

>> Lemmatization: 
 [('12', '12')]



========================================== PARAGRAPH 358 ===========================================

  


========================================== PARAGRAPH 359 ===========================================

Grover and Kar (2017) highlight that the number of big data articles published in reputable journals  

------------------- Sentence 1 -------------------

Grover and Kar (2017) highlight that the number of big data articles published in reputable journals

>> Tokens are: 
 ['Grover', 'Kar', '(', '2017', ')', 'highlight', 'number', 'big', 'data', 'articles', 'published', 'reputable', 'journals']

>> Bigrams are: 
 [('Grover', 'Kar'), ('Kar', '('), ('(', '2017'), ('2017', ')'), (')', 'highlight'), ('highlight', 'number'), ('number', 'big'), ('big', 'data'), ('data', 'articles'), ('articles', 'published'), ('published', 'reputable'), ('reputable', 'journals')]

>> Trigrams are: 
 [('Grover', 'Kar', '('), ('Kar', '(', '2017'), ('(', '2017', ')'), ('2017', ')', 'highlight'), (')', 'highlight', 'number'), ('highlight', 'number', 'big'), ('number', 'big', 'data'), ('big', 'data', 'articles'), ('data', 'articles', 'published'), ('articles', 'published', 'reputable'), ('published', 'reputable', 'journals')]

>> POS Tags are: 
 [('Grover', 'NNP'), ('Kar', 'NNP'), ('(', '('), ('2017', 'CD'), (')', ')'), ('highlight', 'VBD'), ('number', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('articles', 'NNS'), ('published', 'VBN'), ('reputable', 'JJ'), ('journals', 'NNS')]

>> Noun Phrases are: 
 ['Grover Kar', 'number', 'big data articles', 'reputable journals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'articl'), ('published', 'publish'), ('reputable', 'reput'), ('journals', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'articl'), ('published', 'publish'), ('reputable', 'reput'), ('journals', 'journal')]

>> Lemmatization: 
 [('Grover', 'Grover'), ('Kar', 'Kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'article'), ('published', 'published'), ('reputable', 'reputable'), ('journals', 'journal')]



========================================== PARAGRAPH 360 ===========================================

is increasing, as shown in Figure 9.  

------------------- Sentence 1 -------------------

is increasing, as shown in Figure 9.

>> Tokens are: 
 ['increasing', ',', 'shown', 'Figure', '9', '.']

>> Bigrams are: 
 [('increasing', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '9'), ('9', '.')]

>> Trigrams are: 
 [('increasing', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '9'), ('Figure', '9', '.')]

>> POS Tags are: 
 [('increasing', 'VBG'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('increasing', 'increas'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('increasing', 'increas'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('increasing', 'increasing'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('9', '9'), ('.', '.')]



========================================== PARAGRAPH 361 ===========================================

  


========================================== PARAGRAPH 362 ===========================================

  


========================================== PARAGRAPH 363 ===========================================

Figure 9: Yearly distribution of “big data” research studies (Grover and Kar, 2017).  

------------------- Sentence 1 -------------------

Figure 9: Yearly distribution of “big data” research studies (Grover and Kar, 2017).

>> Tokens are: 
 ['Figure', '9', ':', 'Yearly', 'distribution', '“', 'big', 'data', '”', 'research', 'studies', '(', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Figure', '9'), ('9', ':'), (':', 'Yearly'), ('Yearly', 'distribution'), ('distribution', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'research'), ('research', 'studies'), ('studies', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '9', ':'), ('9', ':', 'Yearly'), (':', 'Yearly', 'distribution'), ('Yearly', 'distribution', '“'), ('distribution', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'research'), ('”', 'research', 'studies'), ('research', 'studies', '('), ('studies', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('9', 'CD'), (':', ':'), ('Yearly', 'JJ'), ('distribution', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'VBP'), ('research', 'NN'), ('studies', 'NNS'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Yearly distribution “', 'big data', 'research studies', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('9', '9'), (':', ':'), ('Yearly', 'yearli'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'studi'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('9', '9'), (':', ':'), ('Yearly', 'year'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'studi'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('9', '9'), (':', ':'), ('Yearly', 'Yearly'), ('distribution', 'distribution'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'study'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 364 ===========================================

  


========================================== PARAGRAPH 365 ===========================================

Mikalef et al. (2018) also provided an overview of big data definitions in past studies, as shown  

------------------- Sentence 1 -------------------

Mikalef et al.

>> Tokens are: 
 ['Mikalef', 'et', 'al', '.']

>> Bigrams are: 
 [('Mikalef', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Mikalef', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Mikalef', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mikalef', 'al']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Mikalef', 'Mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018) also provided an overview of big data definitions in past studies, as shown

>> Tokens are: 
 ['(', '2018', ')', 'also', 'provided', 'overview', 'big', 'data', 'definitions', 'past', 'studies', ',', 'shown']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'also'), ('also', 'provided'), ('provided', 'overview'), ('overview', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'past'), ('past', 'studies'), ('studies', ','), (',', 'shown')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'also'), (')', 'also', 'provided'), ('also', 'provided', 'overview'), ('provided', 'overview', 'big'), ('overview', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'past'), ('definitions', 'past', 'studies'), ('past', 'studies', ','), ('studies', ',', 'shown')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('also', 'RB'), ('provided', 'VBN'), ('overview', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('past', 'IN'), ('studies', 'NNS'), (',', ','), ('shown', 'VBN')]

>> Noun Phrases are: 
 ['overview', 'big data definitions', 'studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provid'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('past', 'past'), ('studies', 'studi'), (',', ','), ('shown', 'shown')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provid'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('past', 'past'), ('studies', 'studi'), (',', ','), ('shown', 'shown')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provided'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('past', 'past'), ('studies', 'study'), (',', ','), ('shown', 'shown')]



========================================== PARAGRAPH 366 ===========================================

in Table 2. 

------------------- Sentence 1 -------------------

in Table 2.

>> Tokens are: 
 ['Table', '2', '.']

>> Bigrams are: 
 [('Table', '2'), ('2', '.')]

>> Trigrams are: 
 [('Table', '2', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('2', '2'), ('.', '.')]



========================================== PARAGRAPH 367 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 368 ===========================================

13  

------------------- Sentence 1 -------------------

13

>> Tokens are: 
 ['13']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13')]

>> Stemming using Snowball Stemmer: 
 [('13', '13')]

>> Lemmatization: 
 [('13', '13')]



========================================== PARAGRAPH 369 ===========================================

  


========================================== PARAGRAPH 370 ===========================================

Table 2: Sample definitions of big data adopted from (Mikalef et al., 2018).  

------------------- Sentence 1 -------------------

Table 2: Sample definitions of big data adopted from (Mikalef et al., 2018).

>> Tokens are: 
 ['Table', '2', ':', 'Sample', 'definitions', 'big', 'data', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Table', '2'), ('2', ':'), (':', 'Sample'), ('Sample', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Table', '2', ':'), ('2', ':', 'Sample'), (':', 'Sample', 'definitions'), ('Sample', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'adopted'), ('data', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('2', 'CD'), (':', ':'), ('Sample', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('adopted', 'VBD'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Sample definitions', 'big data', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('2', '2'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('2', '2'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('2', '2'), (':', ':'), ('Sample', 'Sample'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 371 ===========================================

  


========================================== PARAGRAPH 372 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 373 ===========================================

14  

------------------- Sentence 1 -------------------

14

>> Tokens are: 
 ['14']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14')]

>> Stemming using Snowball Stemmer: 
 [('14', '14')]

>> Lemmatization: 
 [('14', '14')]



========================================== PARAGRAPH 374 ===========================================

  


========================================== PARAGRAPH 375 ===========================================

  


========================================== PARAGRAPH 376 ===========================================

  


========================================== PARAGRAPH 377 ===========================================

The abovementioned definitions are complimentary to each other at some points such as defining  

------------------- Sentence 1 -------------------

The abovementioned definitions are complimentary to each other at some points such as defining

>> Tokens are: 
 ['The', 'abovementioned', 'definitions', 'complimentary', 'points', 'defining']

>> Bigrams are: 
 [('The', 'abovementioned'), ('abovementioned', 'definitions'), ('definitions', 'complimentary'), ('complimentary', 'points'), ('points', 'defining')]

>> Trigrams are: 
 [('The', 'abovementioned', 'definitions'), ('abovementioned', 'definitions', 'complimentary'), ('definitions', 'complimentary', 'points'), ('complimentary', 'points', 'defining')]

>> POS Tags are: 
 [('The', 'DT'), ('abovementioned', 'JJ'), ('definitions', 'NNS'), ('complimentary', 'JJ'), ('points', 'NNS'), ('defining', 'VBG')]

>> Noun Phrases are: 
 ['The abovementioned definitions', 'complimentary points']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('abovementioned', 'abovement'), ('definitions', 'definit'), ('complimentary', 'complimentari'), ('points', 'point'), ('defining', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('abovementioned', 'abovement'), ('definitions', 'definit'), ('complimentary', 'complimentari'), ('points', 'point'), ('defining', 'defin')]

>> Lemmatization: 
 [('The', 'The'), ('abovementioned', 'abovementioned'), ('definitions', 'definition'), ('complimentary', 'complimentary'), ('points', 'point'), ('defining', 'defining')]



========================================== PARAGRAPH 378 ===========================================

the big data by 5Vs in Lomotey et al. (2014). At other points, some of them are contradicting with  

------------------- Sentence 1 -------------------

the big data by 5Vs in Lomotey et al.

>> Tokens are: 
 ['big', 'data', '5Vs', 'Lomotey', 'et', 'al', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', '5Vs'), ('5Vs', 'Lomotey'), ('Lomotey', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('big', 'data', '5Vs'), ('data', '5Vs', 'Lomotey'), ('5Vs', 'Lomotey', 'et'), ('Lomotey', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('5Vs', 'CD'), ('Lomotey', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'Lomotey', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('5Vs', '5v'), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('5Vs', '5vs'), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('5Vs', '5Vs'), ('Lomotey', 'Lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2014).

>> Tokens are: 
 ['(', '2014', ')', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

At other points, some of them are contradicting with

>> Tokens are: 
 ['At', 'points', ',', 'contradicting']

>> Bigrams are: 
 [('At', 'points'), ('points', ','), (',', 'contradicting')]

>> Trigrams are: 
 [('At', 'points', ','), ('points', ',', 'contradicting')]

>> POS Tags are: 
 [('At', 'IN'), ('points', 'NNS'), (',', ','), ('contradicting', 'VBG')]

>> Noun Phrases are: 
 ['points']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('points', 'point'), (',', ','), ('contradicting', 'contradict')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('points', 'point'), (',', ','), ('contradicting', 'contradict')]

>> Lemmatization: 
 [('At', 'At'), ('points', 'point'), (',', ','), ('contradicting', 'contradicting')]



========================================== PARAGRAPH 379 ===========================================

the six representative definitions adopted from (Ren et al., 2019) that are shown in Table 1. They  

------------------- Sentence 1 -------------------

the six representative definitions adopted from (Ren et al., 2019) that are shown in Table 1.

>> Tokens are: 
 ['six', 'representative', 'definitions', 'adopted', '(', 'Ren', 'et', 'al.', ',', '2019', ')', 'shown', 'Table', '1', '.']

>> Bigrams are: 
 [('six', 'representative'), ('representative', 'definitions'), ('definitions', 'adopted'), ('adopted', '('), ('(', 'Ren'), ('Ren', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', 'shown'), ('shown', 'Table'), ('Table', '1'), ('1', '.')]

>> Trigrams are: 
 [('six', 'representative', 'definitions'), ('representative', 'definitions', 'adopted'), ('definitions', 'adopted', '('), ('adopted', '(', 'Ren'), ('(', 'Ren', 'et'), ('Ren', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', 'shown'), (')', 'shown', 'Table'), ('shown', 'Table', '1'), ('Table', '1', '.')]

>> POS Tags are: 
 [('six', 'CD'), ('representative', 'JJ'), ('definitions', 'NNS'), ('adopted', 'VBN'), ('(', '('), ('Ren', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('shown', 'VBN'), ('Table', 'JJ'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['representative definitions', 'Ren']

>> Named Entities are: 
 [('ORGANIZATION', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('six', 'six'), ('representative', 'representative'), ('definitions', 'definition'), ('adopted', 'adopted'), ('(', '('), ('Ren', 'Ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'Table'), ('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

They

>> Tokens are: 
 ['They']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('They', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they')]

>> Lemmatization: 
 [('They', 'They')]



========================================== PARAGRAPH 380 ===========================================

defined big data in term of three ‘Vs’ and they focused on the size of data ignoring the other  

------------------- Sentence 1 -------------------

defined big data in term of three ‘Vs’ and they focused on the size of data ignoring the other

>> Tokens are: 
 ['defined', 'big', 'data', 'term', 'three', '‘', 'Vs', '’', 'focused', 'size', 'data', 'ignoring']

>> Bigrams are: 
 [('defined', 'big'), ('big', 'data'), ('data', 'term'), ('term', 'three'), ('three', '‘'), ('‘', 'Vs'), ('Vs', '’'), ('’', 'focused'), ('focused', 'size'), ('size', 'data'), ('data', 'ignoring')]

>> Trigrams are: 
 [('defined', 'big', 'data'), ('big', 'data', 'term'), ('data', 'term', 'three'), ('term', 'three', '‘'), ('three', '‘', 'Vs'), ('‘', 'Vs', '’'), ('Vs', '’', 'focused'), ('’', 'focused', 'size'), ('focused', 'size', 'data'), ('size', 'data', 'ignoring')]

>> POS Tags are: 
 [('defined', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('term', 'NN'), ('three', 'CD'), ('‘', 'NNP'), ('Vs', 'NNP'), ('’', 'NNP'), ('focused', 'VBD'), ('size', 'NN'), ('data', 'NNS'), ('ignoring', 'VBG')]

>> Noun Phrases are: 
 ['big data term', '‘ Vs ’', 'size data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'vs'), ('’', '’'), ('focused', 'focus'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignor')]

>> Stemming using Snowball Stemmer: 
 [('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'vs'), ('’', '’'), ('focused', 'focus'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignor')]

>> Lemmatization: 
 [('defined', 'defined'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'Vs'), ('’', '’'), ('focused', 'focused'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignoring')]



========================================== PARAGRAPH 381 ===========================================

dimensions.   

------------------- Sentence 1 -------------------

dimensions.

>> Tokens are: 
 ['dimensions', '.']

>> Bigrams are: 
 [('dimensions', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('dimensions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dimensions', 'dimens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dimensions', 'dimens'), ('.', '.')]

>> Lemmatization: 
 [('dimensions', 'dimension'), ('.', '.')]



========================================== PARAGRAPH 382 ===========================================

When taken from the user understanding viewpoints, these definitions show different angles of big  

------------------- Sentence 1 -------------------

When taken from the user understanding viewpoints, these definitions show different angles of big

>> Tokens are: 
 ['When', 'taken', 'user', 'understanding', 'viewpoints', ',', 'definitions', 'show', 'different', 'angles', 'big']

>> Bigrams are: 
 [('When', 'taken'), ('taken', 'user'), ('user', 'understanding'), ('understanding', 'viewpoints'), ('viewpoints', ','), (',', 'definitions'), ('definitions', 'show'), ('show', 'different'), ('different', 'angles'), ('angles', 'big')]

>> Trigrams are: 
 [('When', 'taken', 'user'), ('taken', 'user', 'understanding'), ('user', 'understanding', 'viewpoints'), ('understanding', 'viewpoints', ','), ('viewpoints', ',', 'definitions'), (',', 'definitions', 'show'), ('definitions', 'show', 'different'), ('show', 'different', 'angles'), ('different', 'angles', 'big')]

>> POS Tags are: 
 [('When', 'WRB'), ('taken', 'VBN'), ('user', 'RB'), ('understanding', 'JJ'), ('viewpoints', 'NNS'), (',', ','), ('definitions', 'NNS'), ('show', 'VBP'), ('different', 'JJ'), ('angles', 'NNS'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['understanding viewpoints', 'definitions', 'different angles']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understand'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definit'), ('show', 'show'), ('different', 'differ'), ('angles', 'angl'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understand'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definit'), ('show', 'show'), ('different', 'differ'), ('angles', 'angl'), ('big', 'big')]

>> Lemmatization: 
 [('When', 'When'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understanding'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definition'), ('show', 'show'), ('different', 'different'), ('angles', 'angle'), ('big', 'big')]



========================================== PARAGRAPH 383 ===========================================

data used in research and business as in Gandomi and Haider (2015). The characteristics in terms  

------------------- Sentence 1 -------------------

data used in research and business as in Gandomi and Haider (2015).

>> Tokens are: 
 ['data', 'used', 'research', 'business', 'Gandomi', 'Haider', '(', '2015', ')', '.']

>> Bigrams are: 
 [('data', 'used'), ('used', 'research'), ('research', 'business'), ('business', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'used', 'research'), ('used', 'research', 'business'), ('research', 'business', 'Gandomi'), ('business', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', '('), ('Haider', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('used', 'VBN'), ('research', 'NN'), ('business', 'NN'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'research business Gandomi Haider']

>> Named Entities are: 
 [('PERSON', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('used', 'used'), ('research', 'research'), ('business', 'business'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The characteristics in terms

>> Tokens are: 
 ['The', 'characteristics', 'terms']

>> Bigrams are: 
 [('The', 'characteristics'), ('characteristics', 'terms')]

>> Trigrams are: 
 [('The', 'characteristics', 'terms')]

>> POS Tags are: 
 [('The', 'DT'), ('characteristics', 'NNS'), ('terms', 'NNS')]

>> Noun Phrases are: 
 ['The characteristics terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('characteristics', 'characterist'), ('terms', 'term')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('characteristics', 'characterist'), ('terms', 'term')]

>> Lemmatization: 
 [('The', 'The'), ('characteristics', 'characteristic'), ('terms', 'term')]



========================================== PARAGRAPH 384 ===========================================

of volume, variety, and velocity are the focus in some of them, whilst the function and  

------------------- Sentence 1 -------------------

of volume, variety, and velocity are the focus in some of them, whilst the function and

>> Tokens are: 
 ['volume', ',', 'variety', ',', 'velocity', 'focus', ',', 'whilst', 'function']

>> Bigrams are: 
 [('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', 'focus'), ('focus', ','), (',', 'whilst'), ('whilst', 'function')]

>> Trigrams are: 
 [('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', 'focus'), ('velocity', 'focus', ','), ('focus', ',', 'whilst'), (',', 'whilst', 'function')]

>> POS Tags are: 
 [('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), ('focus', 'NN'), (',', ','), ('whilst', 'NN'), ('function', 'NN')]

>> Noun Phrases are: 
 ['volume', 'variety', 'velocity focus', 'whilst function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), ('focus', 'focu'), (',', ','), ('whilst', 'whilst'), ('function', 'function')]

>> Stemming using Snowball Stemmer: 
 [('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), ('focus', 'focus'), (',', ','), ('whilst', 'whilst'), ('function', 'function')]

>> Lemmatization: 
 [('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), ('focus', 'focus'), (',', ','), ('whilst', 'whilst'), ('function', 'function')]



========================================== PARAGRAPH 385 ===========================================

requirements are the focus points in others such as the business requirements and how the data is  

------------------- Sentence 1 -------------------

requirements are the focus points in others such as the business requirements and how the data is

>> Tokens are: 
 ['requirements', 'focus', 'points', 'others', 'business', 'requirements', 'data']

>> Bigrams are: 
 [('requirements', 'focus'), ('focus', 'points'), ('points', 'others'), ('others', 'business'), ('business', 'requirements'), ('requirements', 'data')]

>> Trigrams are: 
 [('requirements', 'focus', 'points'), ('focus', 'points', 'others'), ('points', 'others', 'business'), ('others', 'business', 'requirements'), ('business', 'requirements', 'data')]

>> POS Tags are: 
 [('requirements', 'NNS'), ('focus', 'VBP'), ('points', 'NNS'), ('others', 'NNS'), ('business', 'NN'), ('requirements', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['requirements', 'points others business requirements data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('requirements', 'requir'), ('focus', 'focu'), ('points', 'point'), ('others', 'other'), ('business', 'busi'), ('requirements', 'requir'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('requirements', 'requir'), ('focus', 'focus'), ('points', 'point'), ('others', 'other'), ('business', 'busi'), ('requirements', 'requir'), ('data', 'data')]

>> Lemmatization: 
 [('requirements', 'requirement'), ('focus', 'focus'), ('points', 'point'), ('others', 'others'), ('business', 'business'), ('requirements', 'requirement'), ('data', 'data')]



========================================== PARAGRAPH 386 ===========================================

stored.   

------------------- Sentence 1 -------------------

stored.

>> Tokens are: 
 ['stored', '.']

>> Bigrams are: 
 [('stored', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('stored', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('stored', 'store'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('stored', 'store'), ('.', '.')]

>> Lemmatization: 
 [('stored', 'stored'), ('.', '.')]



========================================== PARAGRAPH 387 ===========================================

However, the definition adopted in this work is the one that contains all the dimensions (i.e.- the  

------------------- Sentence 1 -------------------

However, the definition adopted in this work is the one that contains all the dimensions (i.e.- the

>> Tokens are: 
 ['However', ',', 'definition', 'adopted', 'work', 'one', 'contains', 'dimensions', '(', 'i.e.-']

>> Bigrams are: 
 [('However', ','), (',', 'definition'), ('definition', 'adopted'), ('adopted', 'work'), ('work', 'one'), ('one', 'contains'), ('contains', 'dimensions'), ('dimensions', '('), ('(', 'i.e.-')]

>> Trigrams are: 
 [('However', ',', 'definition'), (',', 'definition', 'adopted'), ('definition', 'adopted', 'work'), ('adopted', 'work', 'one'), ('work', 'one', 'contains'), ('one', 'contains', 'dimensions'), ('contains', 'dimensions', '('), ('dimensions', '(', 'i.e.-')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('definition', 'NN'), ('adopted', 'VBD'), ('work', 'NN'), ('one', 'CD'), ('contains', 'VBZ'), ('dimensions', 'NNS'), ('(', '('), ('i.e.-', 'JJ')]

>> Noun Phrases are: 
 ['definition', 'work', 'dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('definition', 'definit'), ('adopted', 'adopt'), ('work', 'work'), ('one', 'one'), ('contains', 'contain'), ('dimensions', 'dimens'), ('(', '('), ('i.e.-', 'i.e.-')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('definition', 'definit'), ('adopted', 'adopt'), ('work', 'work'), ('one', 'one'), ('contains', 'contain'), ('dimensions', 'dimens'), ('(', '('), ('i.e.-', 'i.e.-')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('definition', 'definition'), ('adopted', 'adopted'), ('work', 'work'), ('one', 'one'), ('contains', 'contains'), ('dimensions', 'dimension'), ('(', '('), ('i.e.-', 'i.e.-')]



========================================== PARAGRAPH 388 ===========================================

5Vs). This is because it is regarded as being of very high density, timeliness, and different  

------------------- Sentence 1 -------------------

5Vs).

>> Tokens are: 
 ['5Vs', ')', '.']

>> Bigrams are: 
 [('5Vs', ')'), (')', '.')]

>> Trigrams are: 
 [('5Vs', ')', '.')]

>> POS Tags are: 
 [('5Vs', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5Vs', '5v'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5Vs', '5vs'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('5Vs', '5Vs'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

This is because it is regarded as being of very high density, timeliness, and different

>> Tokens are: 
 ['This', 'regarded', 'high', 'density', ',', 'timeliness', ',', 'different']

>> Bigrams are: 
 [('This', 'regarded'), ('regarded', 'high'), ('high', 'density'), ('density', ','), (',', 'timeliness'), ('timeliness', ','), (',', 'different')]

>> Trigrams are: 
 [('This', 'regarded', 'high'), ('regarded', 'high', 'density'), ('high', 'density', ','), ('density', ',', 'timeliness'), (',', 'timeliness', ','), ('timeliness', ',', 'different')]

>> POS Tags are: 
 [('This', 'DT'), ('regarded', 'VBD'), ('high', 'JJ'), ('density', 'NN'), (',', ','), ('timeliness', 'NN'), (',', ','), ('different', 'JJ')]

>> Noun Phrases are: 
 ['high density', 'timeliness']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('regarded', 'regard'), ('high', 'high'), ('density', 'densiti'), (',', ','), ('timeliness', 'timeli'), (',', ','), ('different', 'differ')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('regarded', 'regard'), ('high', 'high'), ('density', 'densiti'), (',', ','), ('timeliness', 'timeli'), (',', ','), ('different', 'differ')]

>> Lemmatization: 
 [('This', 'This'), ('regarded', 'regarded'), ('high', 'high'), ('density', 'density'), (',', ','), ('timeliness', 'timeliness'), (',', ','), ('different', 'different')]



========================================== PARAGRAPH 389 ===========================================

structure, format, and sources, which requires high performing processing.  

------------------- Sentence 1 -------------------

structure, format, and sources, which requires high performing processing.

>> Tokens are: 
 ['structure', ',', 'format', ',', 'sources', ',', 'requires', 'high', 'performing', 'processing', '.']

>> Bigrams are: 
 [('structure', ','), (',', 'format'), ('format', ','), (',', 'sources'), ('sources', ','), (',', 'requires'), ('requires', 'high'), ('high', 'performing'), ('performing', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('structure', ',', 'format'), (',', 'format', ','), ('format', ',', 'sources'), (',', 'sources', ','), ('sources', ',', 'requires'), (',', 'requires', 'high'), ('requires', 'high', 'performing'), ('high', 'performing', 'processing'), ('performing', 'processing', '.')]

>> POS Tags are: 
 [('structure', 'NN'), (',', ','), ('format', 'NN'), (',', ','), ('sources', 'NNS'), (',', ','), ('requires', 'VBZ'), ('high', 'JJ'), ('performing', 'VBG'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['structure', 'format', 'sources', 'processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('structure', 'structur'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'sourc'), (',', ','), ('requires', 'requir'), ('high', 'high'), ('performing', 'perform'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('structure', 'structur'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'sourc'), (',', ','), ('requires', 'requir'), ('high', 'high'), ('performing', 'perform'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('structure', 'structure'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'source'), (',', ','), ('requires', 'requires'), ('high', 'high'), ('performing', 'performing'), ('processing', 'processing'), ('.', '.')]



========================================== PARAGRAPH 390 ===========================================

  


========================================== PARAGRAPH 391 ===========================================

  


========================================== PARAGRAPH 392 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 393 ===========================================

15  

------------------- Sentence 1 -------------------

15

>> Tokens are: 
 ['15']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('15', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15')]

>> Stemming using Snowball Stemmer: 
 [('15', '15')]

>> Lemmatization: 
 [('15', '15')]



========================================== PARAGRAPH 394 ===========================================

  


========================================== PARAGRAPH 395 ===========================================

6. Big data characteristics   

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data characteristics

>> Tokens are: 
 ['Big', 'data', 'characteristics']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'characteristics')]

>> Trigrams are: 
 [('Big', 'data', 'characteristics')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('characteristics', 'NNS')]

>> Noun Phrases are: 
 ['Big data characteristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('characteristics', 'characteristic')]



========================================== PARAGRAPH 396 ===========================================

Based on the various big data definitions, it is obvious that the size is the dominating characteristic  

------------------- Sentence 1 -------------------

Based on the various big data definitions, it is obvious that the size is the dominating characteristic

>> Tokens are: 
 ['Based', 'various', 'big', 'data', 'definitions', ',', 'obvious', 'size', 'dominating', 'characteristic']

>> Bigrams are: 
 [('Based', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', ','), (',', 'obvious'), ('obvious', 'size'), ('size', 'dominating'), ('dominating', 'characteristic')]

>> Trigrams are: 
 [('Based', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', ','), ('definitions', ',', 'obvious'), (',', 'obvious', 'size'), ('obvious', 'size', 'dominating'), ('size', 'dominating', 'characteristic')]

>> POS Tags are: 
 [('Based', 'VBN'), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), (',', ','), ('obvious', 'JJ'), ('size', 'NN'), ('dominating', 'VBG'), ('characteristic', 'JJ')]

>> Noun Phrases are: 
 ['various big data definitions', 'obvious size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('obvious', 'obviou'), ('size', 'size'), ('dominating', 'domin'), ('characteristic', 'characterist')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('obvious', 'obvious'), ('size', 'size'), ('dominating', 'domin'), ('characteristic', 'characterist')]

>> Lemmatization: 
 [('Based', 'Based'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), (',', ','), ('obvious', 'obvious'), ('size', 'size'), ('dominating', 'dominating'), ('characteristic', 'characteristic')]



========================================== PARAGRAPH 397 ===========================================

despite other characteristics’ importance. Laney (2001) proposed the three V’s as the dimensions  

------------------- Sentence 1 -------------------

despite other characteristics’ importance.

>> Tokens are: 
 ['despite', 'characteristics', '’', 'importance', '.']

>> Bigrams are: 
 [('despite', 'characteristics'), ('characteristics', '’'), ('’', 'importance'), ('importance', '.')]

>> Trigrams are: 
 [('despite', 'characteristics', '’'), ('characteristics', '’', 'importance'), ('’', 'importance', '.')]

>> POS Tags are: 
 [('despite', 'IN'), ('characteristics', 'NNS'), ('’', 'JJ'), ('importance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['characteristics', '’ importance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('despite', 'despit'), ('characteristics', 'characterist'), ('’', '’'), ('importance', 'import'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('despite', 'despit'), ('characteristics', 'characterist'), ('’', '’'), ('importance', 'import'), ('.', '.')]

>> Lemmatization: 
 [('despite', 'despite'), ('characteristics', 'characteristic'), ('’', '’'), ('importance', 'importance'), ('.', '.')]


------------------- Sentence 2 -------------------

Laney (2001) proposed the three V’s as the dimensions

>> Tokens are: 
 ['Laney', '(', '2001', ')', 'proposed', 'three', 'V', '’', 'dimensions']

>> Bigrams are: 
 [('Laney', '('), ('(', '2001'), ('2001', ')'), (')', 'proposed'), ('proposed', 'three'), ('three', 'V'), ('V', '’'), ('’', 'dimensions')]

>> Trigrams are: 
 [('Laney', '(', '2001'), ('(', '2001', ')'), ('2001', ')', 'proposed'), (')', 'proposed', 'three'), ('proposed', 'three', 'V'), ('three', 'V', '’'), ('V', '’', 'dimensions')]

>> POS Tags are: 
 [('Laney', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('proposed', 'VBD'), ('three', 'CD'), ('V', 'NNP'), ('’', 'CD'), ('dimensions', 'NNS')]

>> Noun Phrases are: 
 ['Laney', 'V', 'dimensions']

>> Named Entities are: 
 [('GPE', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'propos'), ('three', 'three'), ('V', 'v'), ('’', '’'), ('dimensions', 'dimens')]

>> Stemming using Snowball Stemmer: 
 [('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'propos'), ('three', 'three'), ('V', 'v'), ('’', '’'), ('dimensions', 'dimens')]

>> Lemmatization: 
 [('Laney', 'Laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'proposed'), ('three', 'three'), ('V', 'V'), ('’', '’'), ('dimensions', 'dimension')]



========================================== PARAGRAPH 398 ===========================================

of challenge to data management, and the three V's constitute a common framework (Laney, 2001;  

------------------- Sentence 1 -------------------

of challenge to data management, and the three V's constitute a common framework (Laney, 2001;

>> Tokens are: 
 ['challenge', 'data', 'management', ',', 'three', 'V', "'s", 'constitute', 'common', 'framework', '(', 'Laney', ',', '2001', ';']

>> Bigrams are: 
 [('challenge', 'data'), ('data', 'management'), ('management', ','), (',', 'three'), ('three', 'V'), ('V', "'s"), ("'s", 'constitute'), ('constitute', 'common'), ('common', 'framework'), ('framework', '('), ('(', 'Laney'), ('Laney', ','), (',', '2001'), ('2001', ';')]

>> Trigrams are: 
 [('challenge', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'three'), (',', 'three', 'V'), ('three', 'V', "'s"), ('V', "'s", 'constitute'), ("'s", 'constitute', 'common'), ('constitute', 'common', 'framework'), ('common', 'framework', '('), ('framework', '(', 'Laney'), ('(', 'Laney', ','), ('Laney', ',', '2001'), (',', '2001', ';')]

>> POS Tags are: 
 [('challenge', 'NN'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('three', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('constitute', 'NN'), ('common', 'JJ'), ('framework', 'NN'), ('(', '('), ('Laney', 'NNP'), (',', ','), ('2001', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['challenge data management', 'V', 'constitute', 'common framework', 'Laney']

>> Named Entities are: 
 [('PERSON', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('challenge', 'challeng'), ('data', 'data'), ('management', 'manag'), (',', ','), ('three', 'three'), ('V', 'v'), ("'s", "'s"), ('constitute', 'constitut'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('challenge', 'challeng'), ('data', 'data'), ('management', 'manag'), (',', ','), ('three', 'three'), ('V', 'v'), ("'s", "'s"), ('constitute', 'constitut'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (';', ';')]

>> Lemmatization: 
 [('challenge', 'challenge'), ('data', 'data'), ('management', 'management'), (',', ','), ('three', 'three'), ('V', 'V'), ("'s", "'s"), ('constitute', 'constitute'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'Laney'), (',', ','), ('2001', '2001'), (';', ';')]



========================================== PARAGRAPH 399 ===========================================

Chen et al., 2012). These three dimensions are not independent of each other; if one-dimension  

------------------- Sentence 1 -------------------

Chen et al., 2012).

>> Tokens are: 
 ['Chen', 'et', 'al.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('et', 'CC'), ('al.', 'NN'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'al.']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

These three dimensions are not independent of each other; if one-dimension

>> Tokens are: 
 ['These', 'three', 'dimensions', 'independent', ';', 'one-dimension']

>> Bigrams are: 
 [('These', 'three'), ('three', 'dimensions'), ('dimensions', 'independent'), ('independent', ';'), (';', 'one-dimension')]

>> Trigrams are: 
 [('These', 'three', 'dimensions'), ('three', 'dimensions', 'independent'), ('dimensions', 'independent', ';'), ('independent', ';', 'one-dimension')]

>> POS Tags are: 
 [('These', 'DT'), ('three', 'CD'), ('dimensions', 'NNS'), ('independent', 'JJ'), (';', ':'), ('one-dimension', 'NN')]

>> Noun Phrases are: 
 ['dimensions', 'one-dimension']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('three', 'three'), ('dimensions', 'dimens'), ('independent', 'independ'), (';', ';'), ('one-dimension', 'one-dimens')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('three', 'three'), ('dimensions', 'dimens'), ('independent', 'independ'), (';', ';'), ('one-dimension', 'one-dimens')]

>> Lemmatization: 
 [('These', 'These'), ('three', 'three'), ('dimensions', 'dimension'), ('independent', 'independent'), (';', ';'), ('one-dimension', 'one-dimension')]



========================================== PARAGRAPH 400 ===========================================

changes, the probability of changing another dimension also increases (Gandomi and Haider,  

------------------- Sentence 1 -------------------

changes, the probability of changing another dimension also increases (Gandomi and Haider,

>> Tokens are: 
 ['changes', ',', 'probability', 'changing', 'another', 'dimension', 'also', 'increases', '(', 'Gandomi', 'Haider', ',']

>> Bigrams are: 
 [('changes', ','), (',', 'probability'), ('probability', 'changing'), ('changing', 'another'), ('another', 'dimension'), ('dimension', 'also'), ('also', 'increases'), ('increases', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ',')]

>> Trigrams are: 
 [('changes', ',', 'probability'), (',', 'probability', 'changing'), ('probability', 'changing', 'another'), ('changing', 'another', 'dimension'), ('another', 'dimension', 'also'), ('dimension', 'also', 'increases'), ('also', 'increases', '('), ('increases', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ',')]

>> POS Tags are: 
 [('changes', 'NNS'), (',', ','), ('probability', 'NN'), ('changing', 'VBG'), ('another', 'DT'), ('dimension', 'NN'), ('also', 'RB'), ('increases', 'VBZ'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['changes', 'probability', 'another dimension', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('changes', 'chang'), (',', ','), ('probability', 'probabl'), ('changing', 'chang'), ('another', 'anoth'), ('dimension', 'dimens'), ('also', 'also'), ('increases', 'increas'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('changes', 'chang'), (',', ','), ('probability', 'probabl'), ('changing', 'chang'), ('another', 'anoth'), ('dimension', 'dimens'), ('also', 'also'), ('increases', 'increas'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ',')]

>> Lemmatization: 
 [('changes', 'change'), (',', ','), ('probability', 'probability'), ('changing', 'changing'), ('another', 'another'), ('dimension', 'dimension'), ('also', 'also'), ('increases', 'increase'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ',')]



========================================== PARAGRAPH 401 ===========================================

2015).   

------------------- Sentence 1 -------------------

2015).

>> Tokens are: 
 ['2015', ')', '.']

>> Bigrams are: 
 [('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('2015', ')', '.')]

>> POS Tags are: 
 [('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 402 ===========================================

A further two dimensions are often added to the big data characteristics, veracity and variability  

------------------- Sentence 1 -------------------

A further two dimensions are often added to the big data characteristics, veracity and variability

>> Tokens are: 
 ['A', 'two', 'dimensions', 'often', 'added', 'big', 'data', 'characteristics', ',', 'veracity', 'variability']

>> Bigrams are: 
 [('A', 'two'), ('two', 'dimensions'), ('dimensions', 'often'), ('often', 'added'), ('added', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', ','), (',', 'veracity'), ('veracity', 'variability')]

>> Trigrams are: 
 [('A', 'two', 'dimensions'), ('two', 'dimensions', 'often'), ('dimensions', 'often', 'added'), ('often', 'added', 'big'), ('added', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', ','), ('characteristics', ',', 'veracity'), (',', 'veracity', 'variability')]

>> POS Tags are: 
 [('A', 'DT'), ('two', 'CD'), ('dimensions', 'NNS'), ('often', 'RB'), ('added', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), (',', ','), ('veracity', 'NN'), ('variability', 'NN')]

>> Noun Phrases are: 
 ['dimensions', 'big data characteristics', 'veracity variability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('two', 'two'), ('dimensions', 'dimens'), ('often', 'often'), ('added', 'ad'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('veracity', 'verac'), ('variability', 'variabl')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('two', 'two'), ('dimensions', 'dimens'), ('often', 'often'), ('added', 'ad'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('veracity', 'verac'), ('variability', 'variabl')]

>> Lemmatization: 
 [('A', 'A'), ('two', 'two'), ('dimensions', 'dimension'), ('often', 'often'), ('added', 'added'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), (',', ','), ('veracity', 'veracity'), ('variability', 'variability')]



========================================== PARAGRAPH 403 ===========================================

(Gandomi, A. and Haider, M., 2015) as shown in Figure 10. The five V's reflect the growing  

------------------- Sentence 1 -------------------

(Gandomi, A. and Haider, M., 2015) as shown in Figure 10.

>> Tokens are: 
 ['(', 'Gandomi', ',', 'A.', 'Haider', ',', 'M.', ',', '2015', ')', 'shown', 'Figure', '10', '.']

>> Bigrams are: 
 [('(', 'Gandomi'), ('Gandomi', ','), (',', 'A.'), ('A.', 'Haider'), ('Haider', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', ')'), (')', 'shown'), ('shown', 'Figure'), ('Figure', '10'), ('10', '.')]

>> Trigrams are: 
 [('(', 'Gandomi', ','), ('Gandomi', ',', 'A.'), (',', 'A.', 'Haider'), ('A.', 'Haider', ','), ('Haider', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'shown'), (')', 'shown', 'Figure'), ('shown', 'Figure', '10'), ('Figure', '10', '.')]

>> POS Tags are: 
 [('(', '('), ('Gandomi', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haider', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('shown', 'VBN'), ('Figure', 'NNP'), ('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Gandomi', 'A. Haider', 'M.', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'figur'), ('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'figur'), ('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Gandomi', 'Gandomi'), (',', ','), ('A.', 'A.'), ('Haider', 'Haider'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'Figure'), ('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

The five V's reflect the growing

>> Tokens are: 
 ['The', 'five', 'V', "'s", 'reflect', 'growing']

>> Bigrams are: 
 [('The', 'five'), ('five', 'V'), ('V', "'s"), ("'s", 'reflect'), ('reflect', 'growing')]

>> Trigrams are: 
 [('The', 'five', 'V'), ('five', 'V', "'s"), ('V', "'s", 'reflect'), ("'s", 'reflect', 'growing')]

>> POS Tags are: 
 [('The', 'DT'), ('five', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('reflect', 'NN'), ('growing', 'NN')]

>> Noun Phrases are: 
 ['V', 'reflect growing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('five', 'five'), ('V', 'v'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'grow')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('five', 'five'), ('V', 'v'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'grow')]

>> Lemmatization: 
 [('The', 'The'), ('five', 'five'), ('V', 'V'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'growing')]



========================================== PARAGRAPH 404 ===========================================

popularity of big data. The first V is, as always, volume, which is related to the amount of generated  

------------------- Sentence 1 -------------------

popularity of big data.

>> Tokens are: 
 ['popularity', 'big', 'data', '.']

>> Bigrams are: 
 [('popularity', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('popularity', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('popularity', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['popularity', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('popularity', 'popular'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('popularity', 'popular'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('popularity', 'popularity'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The first V is, as always, volume, which is related to the amount of generated

>> Tokens are: 
 ['The', 'first', 'V', ',', 'always', ',', 'volume', ',', 'related', 'amount', 'generated']

>> Bigrams are: 
 [('The', 'first'), ('first', 'V'), ('V', ','), (',', 'always'), ('always', ','), (',', 'volume'), ('volume', ','), (',', 'related'), ('related', 'amount'), ('amount', 'generated')]

>> Trigrams are: 
 [('The', 'first', 'V'), ('first', 'V', ','), ('V', ',', 'always'), (',', 'always', ','), ('always', ',', 'volume'), (',', 'volume', ','), ('volume', ',', 'related'), (',', 'related', 'amount'), ('related', 'amount', 'generated')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('V', 'NNP'), (',', ','), ('always', 'RB'), (',', ','), ('volume', 'NN'), (',', ','), ('related', 'JJ'), ('amount', 'NN'), ('generated', 'VBD')]

>> Noun Phrases are: 
 ['The first V', 'volume', 'related amount']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('V', 'v'), (',', ','), ('always', 'alway'), (',', ','), ('volume', 'volum'), (',', ','), ('related', 'relat'), ('amount', 'amount'), ('generated', 'gener')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('V', 'v'), (',', ','), ('always', 'alway'), (',', ','), ('volume', 'volum'), (',', ','), ('related', 'relat'), ('amount', 'amount'), ('generated', 'generat')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('V', 'V'), (',', ','), ('always', 'always'), (',', ','), ('volume', 'volume'), (',', ','), ('related', 'related'), ('amount', 'amount'), ('generated', 'generated')]



========================================== PARAGRAPH 405 ===========================================

data (Grover and Kar, 2017). The second V is for the velocity (big data timeliness), as all data  

------------------- Sentence 1 -------------------

data (Grover and Kar, 2017).

>> Tokens are: 
 ['data', '(', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('data', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('data', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The second V is for the velocity (big data timeliness), as all data

>> Tokens are: 
 ['The', 'second', 'V', 'velocity', '(', 'big', 'data', 'timeliness', ')', ',', 'data']

>> Bigrams are: 
 [('The', 'second'), ('second', 'V'), ('V', 'velocity'), ('velocity', '('), ('(', 'big'), ('big', 'data'), ('data', 'timeliness'), ('timeliness', ')'), (')', ','), (',', 'data')]

>> Trigrams are: 
 [('The', 'second', 'V'), ('second', 'V', 'velocity'), ('V', 'velocity', '('), ('velocity', '(', 'big'), ('(', 'big', 'data'), ('big', 'data', 'timeliness'), ('data', 'timeliness', ')'), ('timeliness', ')', ','), (')', ',', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('V', 'NNP'), ('velocity', 'NN'), ('(', '('), ('big', 'JJ'), ('data', 'NNS'), ('timeliness', 'NN'), (')', ')'), (',', ','), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The second V velocity', 'big data timeliness', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('V', 'v'), ('velocity', 'veloc'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeli'), (')', ')'), (',', ','), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('V', 'v'), ('velocity', 'veloc'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeli'), (')', ')'), (',', ','), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('V', 'V'), ('velocity', 'velocity'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeliness'), (')', ')'), (',', ','), ('data', 'data')]



========================================== PARAGRAPH 406 ===========================================

collection and analysis should be conducted in a timely manner (Chen, M., Mao, S. and Liu, Y.,  

------------------- Sentence 1 -------------------

collection and analysis should be conducted in a timely manner (Chen, M., Mao, S. and Liu, Y.,

>> Tokens are: 
 ['collection', 'analysis', 'conducted', 'timely', 'manner', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',']

>> Bigrams are: 
 [('collection', 'analysis'), ('analysis', 'conducted'), ('conducted', 'timely'), ('timely', 'manner'), ('manner', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ',')]

>> Trigrams are: 
 [('collection', 'analysis', 'conducted'), ('analysis', 'conducted', 'timely'), ('conducted', 'timely', 'manner'), ('timely', 'manner', '('), ('manner', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ',')]

>> POS Tags are: 
 [('collection', 'NN'), ('analysis', 'NN'), ('conducted', 'VBN'), ('timely', 'JJ'), ('manner', 'NN'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['collection analysis', 'timely manner', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('collection', 'collect'), ('analysis', 'analysi'), ('conducted', 'conduct'), ('timely', 'time'), ('manner', 'manner'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('collection', 'collect'), ('analysis', 'analysi'), ('conducted', 'conduct'), ('timely', 'time'), ('manner', 'manner'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ',')]

>> Lemmatization: 
 [('collection', 'collection'), ('analysis', 'analysis'), ('conducted', 'conducted'), ('timely', 'timely'), ('manner', 'manner'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ',')]



========================================== PARAGRAPH 407 ===========================================

2014). The third V refers to variety, as big data comes in many different formats and structures  

------------------- Sentence 1 -------------------

2014).

>> Tokens are: 
 ['2014', ')', '.']

>> Bigrams are: 
 [('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The third V refers to variety, as big data comes in many different formats and structures

>> Tokens are: 
 ['The', 'third', 'V', 'refers', 'variety', ',', 'big', 'data', 'comes', 'many', 'different', 'formats', 'structures']

>> Bigrams are: 
 [('The', 'third'), ('third', 'V'), ('V', 'refers'), ('refers', 'variety'), ('variety', ','), (',', 'big'), ('big', 'data'), ('data', 'comes'), ('comes', 'many'), ('many', 'different'), ('different', 'formats'), ('formats', 'structures')]

>> Trigrams are: 
 [('The', 'third', 'V'), ('third', 'V', 'refers'), ('V', 'refers', 'variety'), ('refers', 'variety', ','), ('variety', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'comes'), ('data', 'comes', 'many'), ('comes', 'many', 'different'), ('many', 'different', 'formats'), ('different', 'formats', 'structures')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('V', 'NNP'), ('refers', 'NNS'), ('variety', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('comes', 'VBZ'), ('many', 'JJ'), ('different', 'JJ'), ('formats', 'NNS'), ('structures', 'NNS')]

>> Noun Phrases are: 
 ['The third V refers variety', 'big data', 'many different formats structures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('V', 'v'), ('refers', 'refer'), ('variety', 'varieti'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('formats', 'format'), ('structures', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('V', 'v'), ('refers', 'refer'), ('variety', 'varieti'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('formats', 'format'), ('structures', 'structur')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('V', 'V'), ('refers', 'refers'), ('variety', 'variety'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'many'), ('different', 'different'), ('formats', 'format'), ('structures', 'structure')]



========================================== PARAGRAPH 408 ===========================================

such as ERP data, emails and tweets, or audio and video (Russom, 2011; Elragal, 2014; Watson,  

------------------- Sentence 1 -------------------

such as ERP data, emails and tweets, or audio and video (Russom, 2011; Elragal, 2014; Watson,

>> Tokens are: 
 ['ERP', 'data', ',', 'emails', 'tweets', ',', 'audio', 'video', '(', 'Russom', ',', '2011', ';', 'Elragal', ',', '2014', ';', 'Watson', ',']

>> Bigrams are: 
 [('ERP', 'data'), ('data', ','), (',', 'emails'), ('emails', 'tweets'), ('tweets', ','), (',', 'audio'), ('audio', 'video'), ('video', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Watson'), ('Watson', ',')]

>> Trigrams are: 
 [('ERP', 'data', ','), ('data', ',', 'emails'), (',', 'emails', 'tweets'), ('emails', 'tweets', ','), ('tweets', ',', 'audio'), (',', 'audio', 'video'), ('audio', 'video', '('), ('video', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elragal'), (';', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Watson'), (';', 'Watson', ',')]

>> POS Tags are: 
 [('ERP', 'NNP'), ('data', 'NNS'), (',', ','), ('emails', 'JJ'), ('tweets', 'NNS'), (',', ','), ('audio', 'JJ'), ('video', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['ERP data', 'emails tweets', 'audio video', 'Russom', 'Elragal', 'Watson']

>> Named Entities are: 
 [('GPE', 'Russom'), ('GPE', 'Elragal'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('ERP', 'erp'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('ERP', 'erp'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ',')]

>> Lemmatization: 
 [('ERP', 'ERP'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'Watson'), (',', ',')]



========================================== PARAGRAPH 409 ===========================================

2014; Watson, 2019). The fourth V refers to big data’s “huge value but very low density”, causing  

------------------- Sentence 1 -------------------

2014; Watson, 2019).

>> Tokens are: 
 ['2014', ';', 'Watson', ',', '2019', ')', '.']

>> Bigrams are: 
 [('2014', ';'), (';', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ';', 'Watson'), (';', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The fourth V refers to big data’s “huge value but very low density”, causing

>> Tokens are: 
 ['The', 'fourth', 'V', 'refers', 'big', 'data', '’', '“', 'huge', 'value', 'low', 'density', '”', ',', 'causing']

>> Bigrams are: 
 [('The', 'fourth'), ('fourth', 'V'), ('V', 'refers'), ('refers', 'big'), ('big', 'data'), ('data', '’'), ('’', '“'), ('“', 'huge'), ('huge', 'value'), ('value', 'low'), ('low', 'density'), ('density', '”'), ('”', ','), (',', 'causing')]

>> Trigrams are: 
 [('The', 'fourth', 'V'), ('fourth', 'V', 'refers'), ('V', 'refers', 'big'), ('refers', 'big', 'data'), ('big', 'data', '’'), ('data', '’', '“'), ('’', '“', 'huge'), ('“', 'huge', 'value'), ('huge', 'value', 'low'), ('value', 'low', 'density'), ('low', 'density', '”'), ('density', '”', ','), ('”', ',', 'causing')]

>> POS Tags are: 
 [('The', 'DT'), ('fourth', 'JJ'), ('V', 'NNP'), ('refers', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'VBZ'), ('“', 'NNP'), ('huge', 'JJ'), ('value', 'NN'), ('low', 'JJ'), ('density', 'NN'), ('”', 'NNP'), (',', ','), ('causing', 'VBG')]

>> Noun Phrases are: 
 ['The fourth V refers', 'big data', '“', 'huge value', 'low density ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('fourth', 'fourth'), ('V', 'v'), ('refers', 'refer'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'valu'), ('low', 'low'), ('density', 'densiti'), ('”', '”'), (',', ','), ('causing', 'caus')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('fourth', 'fourth'), ('V', 'v'), ('refers', 'refer'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'valu'), ('low', 'low'), ('density', 'densiti'), ('”', '”'), (',', ','), ('causing', 'caus')]

>> Lemmatization: 
 [('The', 'The'), ('fourth', 'fourth'), ('V', 'V'), ('refers', 'refers'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'value'), ('low', 'low'), ('density', 'density'), ('”', '”'), (',', ','), ('causing', 'causing')]



========================================== PARAGRAPH 410 ===========================================

critical problems in terms of extracting value from datasets (Elragal, 2014; Chen et al., 2014;  

------------------- Sentence 1 -------------------

critical problems in terms of extracting value from datasets (Elragal, 2014; Chen et al., 2014;

>> Tokens are: 
 ['critical', 'problems', 'terms', 'extracting', 'value', 'datasets', '(', 'Elragal', ',', '2014', ';', 'Chen', 'et', 'al.', ',', '2014', ';']

>> Bigrams are: 
 [('critical', 'problems'), ('problems', 'terms'), ('terms', 'extracting'), ('extracting', 'value'), ('value', 'datasets'), ('datasets', '('), ('(', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';')]

>> Trigrams are: 
 [('critical', 'problems', 'terms'), ('problems', 'terms', 'extracting'), ('terms', 'extracting', 'value'), ('extracting', 'value', 'datasets'), ('value', 'datasets', '('), ('datasets', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Chen'), (';', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';')]

>> POS Tags are: 
 [('critical', 'JJ'), ('problems', 'NNS'), ('terms', 'NNS'), ('extracting', 'VBG'), ('value', 'NN'), ('datasets', 'NNS'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Chen', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['critical problems terms', 'value datasets', 'Elragal', 'Chen', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('critical', 'critic'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extract'), ('value', 'valu'), ('datasets', 'dataset'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('critical', 'critic'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extract'), ('value', 'valu'), ('datasets', 'dataset'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]

>> Lemmatization: 
 [('critical', 'critical'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extracting'), ('value', 'value'), ('datasets', 'datasets'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';')]



========================================== PARAGRAPH 411 ===========================================

Raghupathi and Raghupathi, 2014). The fifth V references veracity, and questions big data  

------------------- Sentence 1 -------------------

Raghupathi and Raghupathi, 2014).

>> Tokens are: 
 ['Raghupathi', 'Raghupathi', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Raghupathi', 'Raghupathi', ','), ('Raghupathi', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Raghupathi Raghupathi']

>> Named Entities are: 
 [('PERSON', 'Raghupathi'), ('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The fifth V references veracity, and questions big data

>> Tokens are: 
 ['The', 'fifth', 'V', 'references', 'veracity', ',', 'questions', 'big', 'data']

>> Bigrams are: 
 [('The', 'fifth'), ('fifth', 'V'), ('V', 'references'), ('references', 'veracity'), ('veracity', ','), (',', 'questions'), ('questions', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'fifth', 'V'), ('fifth', 'V', 'references'), ('V', 'references', 'veracity'), ('references', 'veracity', ','), ('veracity', ',', 'questions'), (',', 'questions', 'big'), ('questions', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('fifth', 'JJ'), ('V', 'NNP'), ('references', 'NNS'), ('veracity', 'NN'), (',', ','), ('questions', 'NNS'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The fifth V references veracity', 'questions', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('fifth', 'fifth'), ('V', 'v'), ('references', 'refer'), ('veracity', 'verac'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('fifth', 'fifth'), ('V', 'v'), ('references', 'refer'), ('veracity', 'verac'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('fifth', 'fifth'), ('V', 'V'), ('references', 'reference'), ('veracity', 'veracity'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 412 ===========================================

credibility where sources are external, as in most cases (Addo-Tenkorang and Helo, 2016; Grover  

------------------- Sentence 1 -------------------

credibility where sources are external, as in most cases (Addo-Tenkorang and Helo, 2016; Grover

>> Tokens are: 
 ['credibility', 'sources', 'external', ',', 'cases', '(', 'Addo-Tenkorang', 'Helo', ',', '2016', ';', 'Grover']

>> Bigrams are: 
 [('credibility', 'sources'), ('sources', 'external'), ('external', ','), (',', 'cases'), ('cases', '('), ('(', 'Addo-Tenkorang'), ('Addo-Tenkorang', 'Helo'), ('Helo', ','), (',', '2016'), ('2016', ';'), (';', 'Grover')]

>> Trigrams are: 
 [('credibility', 'sources', 'external'), ('sources', 'external', ','), ('external', ',', 'cases'), (',', 'cases', '('), ('cases', '(', 'Addo-Tenkorang'), ('(', 'Addo-Tenkorang', 'Helo'), ('Addo-Tenkorang', 'Helo', ','), ('Helo', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Grover')]

>> POS Tags are: 
 [('credibility', 'NN'), ('sources', 'NNS'), ('external', 'JJ'), (',', ','), ('cases', 'NNS'), ('(', '('), ('Addo-Tenkorang', 'NNP'), ('Helo', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Grover', 'NNP')]

>> Noun Phrases are: 
 ['credibility sources', 'cases', 'Addo-Tenkorang Helo', 'Grover']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('credibility', 'credibl'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'addo-tenkorang'), ('Helo', 'helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover')]

>> Stemming using Snowball Stemmer: 
 [('credibility', 'credibl'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'addo-tenkorang'), ('Helo', 'helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover')]

>> Lemmatization: 
 [('credibility', 'credibility'), ('sources', 'source'), ('external', 'external'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'Addo-Tenkorang'), ('Helo', 'Helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'Grover')]



========================================== PARAGRAPH 413 ===========================================

and Kar, 2017; Al-Barashdi and Al-Karousi, 2019 ). Veracity is related to credibility, the data  

------------------- Sentence 1 -------------------

and Kar, 2017; Al-Barashdi and Al-Karousi, 2019 ).

>> Tokens are: 
 ['Kar', ',', '2017', ';', 'Al-Barashdi', 'Al-Karousi', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Kar', ','), (',', '2017'), ('2017', ';'), (';', 'Al-Barashdi'), ('Al-Barashdi', 'Al-Karousi'), ('Al-Karousi', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Kar', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Al-Barashdi'), (';', 'Al-Barashdi', 'Al-Karousi'), ('Al-Barashdi', 'Al-Karousi', ','), ('Al-Karousi', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (';', ':'), ('Al-Barashdi', 'JJ'), ('Al-Karousi', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Kar', 'Al-Barashdi Al-Karousi']

>> Named Entities are: 
 [('GPE', 'Kar')] 

>> Stemming using Porter Stemmer: 
 [('Kar', 'kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kar', 'kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Kar', 'Kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'Al-Barashdi'), ('Al-Karousi', 'Al-Karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Veracity is related to credibility, the data

>> Tokens are: 
 ['Veracity', 'related', 'credibility', ',', 'data']

>> Bigrams are: 
 [('Veracity', 'related'), ('related', 'credibility'), ('credibility', ','), (',', 'data')]

>> Trigrams are: 
 [('Veracity', 'related', 'credibility'), ('related', 'credibility', ','), ('credibility', ',', 'data')]

>> POS Tags are: 
 [('Veracity', 'NNP'), ('related', 'JJ'), ('credibility', 'NN'), (',', ','), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Veracity', 'related credibility', 'data']

>> Named Entities are: 
 [('GPE', 'Veracity')] 

>> Stemming using Porter Stemmer: 
 [('Veracity', 'verac'), ('related', 'relat'), ('credibility', 'credibl'), (',', ','), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Veracity', 'verac'), ('related', 'relat'), ('credibility', 'credibl'), (',', ','), ('data', 'data')]

>> Lemmatization: 
 [('Veracity', 'Veracity'), ('related', 'related'), ('credibility', 'credibility'), (',', ','), ('data', 'data')]



========================================== PARAGRAPH 414 ===========================================

source’s accuracy, and how suitable the data is for the proposed of use (Elragal, A, 2014).  

------------------- Sentence 1 -------------------

source’s accuracy, and how suitable the data is for the proposed of use (Elragal, A, 2014).

>> Tokens are: 
 ['source', '’', 'accuracy', ',', 'suitable', 'data', 'proposed', 'use', '(', 'Elragal', ',', 'A', ',', '2014', ')', '.']

>> Bigrams are: 
 [('source', '’'), ('’', 'accuracy'), ('accuracy', ','), (',', 'suitable'), ('suitable', 'data'), ('data', 'proposed'), ('proposed', 'use'), ('use', '('), ('(', 'Elragal'), ('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('source', '’', 'accuracy'), ('’', 'accuracy', ','), ('accuracy', ',', 'suitable'), (',', 'suitable', 'data'), ('suitable', 'data', 'proposed'), ('data', 'proposed', 'use'), ('proposed', 'use', '('), ('use', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('source', 'NN'), ('’', 'NN'), ('accuracy', 'NN'), (',', ','), ('suitable', 'JJ'), ('data', 'NNS'), ('proposed', 'VBN'), ('use', 'NN'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['source ’ accuracy', 'suitable data', 'use', 'Elragal', 'A']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('source', 'sourc'), ('’', '’'), ('accuracy', 'accuraci'), (',', ','), ('suitable', 'suitabl'), ('data', 'data'), ('proposed', 'propos'), ('use', 'use'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('source', 'sourc'), ('’', '’'), ('accuracy', 'accuraci'), (',', ','), ('suitable', 'suitabl'), ('data', 'data'), ('proposed', 'propos'), ('use', 'use'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('source', 'source'), ('’', '’'), ('accuracy', 'accuracy'), (',', ','), ('suitable', 'suitable'), ('data', 'data'), ('proposed', 'proposed'), ('use', 'use'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 415 ===========================================

Using big data requires the correct technical architecture, analytics, and tools to enable insights to  

------------------- Sentence 1 -------------------

Using big data requires the correct technical architecture, analytics, and tools to enable insights to

>> Tokens are: 
 ['Using', 'big', 'data', 'requires', 'correct', 'technical', 'architecture', ',', 'analytics', ',', 'tools', 'enable', 'insights']

>> Bigrams are: 
 [('Using', 'big'), ('big', 'data'), ('data', 'requires'), ('requires', 'correct'), ('correct', 'technical'), ('technical', 'architecture'), ('architecture', ','), (',', 'analytics'), ('analytics', ','), (',', 'tools'), ('tools', 'enable'), ('enable', 'insights')]

>> Trigrams are: 
 [('Using', 'big', 'data'), ('big', 'data', 'requires'), ('data', 'requires', 'correct'), ('requires', 'correct', 'technical'), ('correct', 'technical', 'architecture'), ('technical', 'architecture', ','), ('architecture', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'tools'), (',', 'tools', 'enable'), ('tools', 'enable', 'insights')]

>> POS Tags are: 
 [('Using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('requires', 'VBZ'), ('correct', 'JJ'), ('technical', 'JJ'), ('architecture', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('tools', 'NNS'), ('enable', 'JJ'), ('insights', 'NNS')]

>> Noun Phrases are: 
 ['big data', 'correct technical architecture', 'analytics', 'tools', 'enable insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('big', 'big'), ('data', 'data'), ('requires', 'requir'), ('correct', 'correct'), ('technical', 'technic'), ('architecture', 'architectur'), (',', ','), ('analytics', 'analyt'), (',', ','), ('tools', 'tool'), ('enable', 'enabl'), ('insights', 'insight')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('big', 'big'), ('data', 'data'), ('requires', 'requir'), ('correct', 'correct'), ('technical', 'technic'), ('architecture', 'architectur'), (',', ','), ('analytics', 'analyt'), (',', ','), ('tools', 'tool'), ('enable', 'enabl'), ('insights', 'insight')]

>> Lemmatization: 
 [('Using', 'Using'), ('big', 'big'), ('data', 'data'), ('requires', 'requires'), ('correct', 'correct'), ('technical', 'technical'), ('architecture', 'architecture'), (',', ','), ('analytics', 'analytics'), (',', ','), ('tools', 'tool'), ('enable', 'enable'), ('insights', 'insight')]



========================================== PARAGRAPH 416 ===========================================

emerge from hidden knowledge to generate value for business, and these depend on the data scale,  

------------------- Sentence 1 -------------------

emerge from hidden knowledge to generate value for business, and these depend on the data scale,

>> Tokens are: 
 ['emerge', 'hidden', 'knowledge', 'generate', 'value', 'business', ',', 'depend', 'data', 'scale', ',']

>> Bigrams are: 
 [('emerge', 'hidden'), ('hidden', 'knowledge'), ('knowledge', 'generate'), ('generate', 'value'), ('value', 'business'), ('business', ','), (',', 'depend'), ('depend', 'data'), ('data', 'scale'), ('scale', ',')]

>> Trigrams are: 
 [('emerge', 'hidden', 'knowledge'), ('hidden', 'knowledge', 'generate'), ('knowledge', 'generate', 'value'), ('generate', 'value', 'business'), ('value', 'business', ','), ('business', ',', 'depend'), (',', 'depend', 'data'), ('depend', 'data', 'scale'), ('data', 'scale', ',')]

>> POS Tags are: 
 [('emerge', 'NN'), ('hidden', 'NN'), ('knowledge', 'NN'), ('generate', 'NN'), ('value', 'NN'), ('business', 'NN'), (',', ','), ('depend', 'VBP'), ('data', 'NNS'), ('scale', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['emerge hidden knowledge generate value business', 'data scale']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('emerge', 'emerg'), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('generate', 'gener'), ('value', 'valu'), ('business', 'busi'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('emerge', 'emerg'), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('generate', 'generat'), ('value', 'valu'), ('business', 'busi'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ',')]

>> Lemmatization: 
 [('emerge', 'emerge'), ('hidden', 'hidden'), ('knowledge', 'knowledge'), ('generate', 'generate'), ('value', 'value'), ('business', 'business'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ',')]



========================================== PARAGRAPH 417 ===========================================

distribution, diversity, and velocity (Russom, 2011). Big data is most easily characterised by its  

------------------- Sentence 1 -------------------

distribution, diversity, and velocity (Russom, 2011).

>> Tokens are: 
 ['distribution', ',', 'diversity', ',', 'velocity', '(', 'Russom', ',', '2011', ')', '.']

>> Bigrams are: 
 [('distribution', ','), (',', 'diversity'), ('diversity', ','), (',', 'velocity'), ('velocity', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('distribution', ',', 'diversity'), (',', 'diversity', ','), ('diversity', ',', 'velocity'), (',', 'velocity', '('), ('velocity', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('distribution', 'NN'), (',', ','), ('diversity', 'NN'), (',', ','), ('velocity', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['distribution', 'diversity', 'velocity', 'Russom']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('distribution', 'distribut'), (',', ','), ('diversity', 'divers'), (',', ','), ('velocity', 'veloc'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('distribution', 'distribut'), (',', ','), ('diversity', 'divers'), (',', ','), ('velocity', 'veloc'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('distribution', 'distribution'), (',', ','), ('diversity', 'diversity'), (',', ','), ('velocity', 'velocity'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data is most easily characterised by its

>> Tokens are: 
 ['Big', 'data', 'easily', 'characterised']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'easily'), ('easily', 'characterised')]

>> Trigrams are: 
 [('Big', 'data', 'easily'), ('data', 'easily', 'characterised')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('easily', 'RB'), ('characterised', 'VBD')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('easily', 'easili'), ('characterised', 'characteris')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('easily', 'easili'), ('characterised', 'characteris')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('easily', 'easily'), ('characterised', 'characterised')]



========================================== PARAGRAPH 418 ===========================================

three main features, however: Data Volume (size), Velocity (data change rate) and Variety (data  

------------------- Sentence 1 -------------------

three main features, however: Data Volume (size), Velocity (data change rate) and Variety (data

>> Tokens are: 
 ['three', 'main', 'features', ',', 'however', ':', 'Data', 'Volume', '(', 'size', ')', ',', 'Velocity', '(', 'data', 'change', 'rate', ')', 'Variety', '(', 'data']

>> Bigrams are: 
 [('three', 'main'), ('main', 'features'), ('features', ','), (',', 'however'), ('however', ':'), (':', 'Data'), ('Data', 'Volume'), ('Volume', '('), ('(', 'size'), ('size', ')'), (')', ','), (',', 'Velocity'), ('Velocity', '('), ('(', 'data'), ('data', 'change'), ('change', 'rate'), ('rate', ')'), (')', 'Variety'), ('Variety', '('), ('(', 'data')]

>> Trigrams are: 
 [('three', 'main', 'features'), ('main', 'features', ','), ('features', ',', 'however'), (',', 'however', ':'), ('however', ':', 'Data'), (':', 'Data', 'Volume'), ('Data', 'Volume', '('), ('Volume', '(', 'size'), ('(', 'size', ')'), ('size', ')', ','), (')', ',', 'Velocity'), (',', 'Velocity', '('), ('Velocity', '(', 'data'), ('(', 'data', 'change'), ('data', 'change', 'rate'), ('change', 'rate', ')'), ('rate', ')', 'Variety'), (')', 'Variety', '('), ('Variety', '(', 'data')]

>> POS Tags are: 
 [('three', 'CD'), ('main', 'JJ'), ('features', 'NNS'), (',', ','), ('however', 'RB'), (':', ':'), ('Data', 'NNS'), ('Volume', 'NN'), ('(', '('), ('size', 'NN'), (')', ')'), (',', ','), ('Velocity', 'NNP'), ('(', '('), ('data', 'NNS'), ('change', 'NN'), ('rate', 'NN'), (')', ')'), ('Variety', 'NNP'), ('(', '('), ('data', 'NNS')]

>> Noun Phrases are: 
 ['main features', 'Data Volume', 'size', 'Velocity', 'data change rate', 'Variety', 'data']

>> Named Entities are: 
 [('GPE', 'Volume'), ('GPE', 'Velocity'), ('GPE', 'Variety')] 

>> Stemming using Porter Stemmer: 
 [('three', 'three'), ('main', 'main'), ('features', 'featur'), (',', ','), ('however', 'howev'), (':', ':'), ('Data', 'data'), ('Volume', 'volum'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'veloc'), ('(', '('), ('data', 'data'), ('change', 'chang'), ('rate', 'rate'), (')', ')'), ('Variety', 'varieti'), ('(', '('), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('three', 'three'), ('main', 'main'), ('features', 'featur'), (',', ','), ('however', 'howev'), (':', ':'), ('Data', 'data'), ('Volume', 'volum'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'veloc'), ('(', '('), ('data', 'data'), ('change', 'chang'), ('rate', 'rate'), (')', ')'), ('Variety', 'varieti'), ('(', '('), ('data', 'data')]

>> Lemmatization: 
 [('three', 'three'), ('main', 'main'), ('features', 'feature'), (',', ','), ('however', 'however'), (':', ':'), ('Data', 'Data'), ('Volume', 'Volume'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'Velocity'), ('(', '('), ('data', 'data'), ('change', 'change'), ('rate', 'rate'), (')', ')'), ('Variety', 'Variety'), ('(', '('), ('data', 'data')]



========================================== PARAGRAPH 419 ===========================================

formats and types as well the data analysis types required) (Elgendy and Elragal, 2014; Schelén,  

------------------- Sentence 1 -------------------

formats and types as well the data analysis types required) (Elgendy and Elragal, 2014; Schelén,

>> Tokens are: 
 ['formats', 'types', 'well', 'data', 'analysis', 'types', 'required', ')', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Schelén', ',']

>> Bigrams are: 
 [('formats', 'types'), ('types', 'well'), ('well', 'data'), ('data', 'analysis'), ('analysis', 'types'), ('types', 'required'), ('required', ')'), (')', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Schelén'), ('Schelén', ',')]

>> Trigrams are: 
 [('formats', 'types', 'well'), ('types', 'well', 'data'), ('well', 'data', 'analysis'), ('data', 'analysis', 'types'), ('analysis', 'types', 'required'), ('types', 'required', ')'), ('required', ')', '('), (')', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Schelén'), (';', 'Schelén', ',')]

>> POS Tags are: 
 [('formats', 'NNS'), ('types', 'VBP'), ('well', 'RB'), ('data', 'NNS'), ('analysis', 'NN'), ('types', 'NNS'), ('required', 'VBN'), (')', ')'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Schelén', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['formats', 'data analysis types', 'Elgendy Elragal', 'Schelén']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Schelén')] 

>> Stemming using Porter Stemmer: 
 [('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysi'), ('types', 'type'), ('required', 'requir'), (')', ')'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'schelén'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysi'), ('types', 'type'), ('required', 'requir'), (')', ')'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'schelén'), (',', ',')]

>> Lemmatization: 
 [('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysis'), ('types', 'type'), ('required', 'required'), (')', ')'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'Schelén'), (',', ',')]



========================================== PARAGRAPH 420 ===========================================

Elragal, and Haddara, 2015; Chen and Guo, 2016; Elragal and Klischewski, 2017).  

------------------- Sentence 1 -------------------

Elragal, and Haddara, 2015; Chen and Guo, 2016; Elragal and Klischewski, 2017).

>> Tokens are: 
 ['Elragal', ',', 'Haddara', ',', '2015', ';', 'Chen', 'Guo', ',', '2016', ';', 'Elragal', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', 'Haddara'), ('Haddara', ','), (',', '2015'), ('2015', ';'), (';', 'Chen'), ('Chen', 'Guo'), ('Guo', ','), (',', '2016'), ('2016', ';'), (';', 'Elragal'), ('Elragal', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Elragal', ',', 'Haddara'), (',', 'Haddara', ','), ('Haddara', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Chen'), (';', 'Chen', 'Guo'), ('Chen', 'Guo', ','), ('Guo', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Elragal'), (';', 'Elragal', 'Klischewski'), ('Elragal', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('Haddara', 'NNP'), (',', ','), ('2015', 'CD'), (';', ':'), ('Chen', 'NNP'), ('Guo', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Elragal', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'Haddara', 'Chen Guo', 'Elragal Klischewski']

>> Named Entities are: 
 [('GPE', 'Elragal'), ('GPE', 'Haddara'), ('PERSON', 'Chen Guo'), ('PERSON', 'Elragal Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('Haddara', 'haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'chen'), ('Guo', 'guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('Haddara', 'haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'chen'), ('Guo', 'guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('Haddara', 'Haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'Chen'), ('Guo', 'Guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'Elragal'), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 421 ===========================================

Streaming data is the leading edge of big data, as it can be collected in real-time from multiple  

------------------- Sentence 1 -------------------

Streaming data is the leading edge of big data, as it can be collected in real-time from multiple

>> Tokens are: 
 ['Streaming', 'data', 'leading', 'edge', 'big', 'data', ',', 'collected', 'real-time', 'multiple']

>> Bigrams are: 
 [('Streaming', 'data'), ('data', 'leading'), ('leading', 'edge'), ('edge', 'big'), ('big', 'data'), ('data', ','), (',', 'collected'), ('collected', 'real-time'), ('real-time', 'multiple')]

>> Trigrams are: 
 [('Streaming', 'data', 'leading'), ('data', 'leading', 'edge'), ('leading', 'edge', 'big'), ('edge', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'collected'), (',', 'collected', 'real-time'), ('collected', 'real-time', 'multiple')]

>> POS Tags are: 
 [('Streaming', 'VBG'), ('data', 'NNS'), ('leading', 'VBG'), ('edge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('collected', 'VBD'), ('real-time', 'JJ'), ('multiple', 'NN')]

>> Noun Phrases are: 
 ['data', 'edge', 'big data', 'real-time multiple']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Streaming', 'stream'), ('data', 'data'), ('leading', 'lead'), ('edge', 'edg'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collect'), ('real-time', 'real-tim'), ('multiple', 'multipl')]

>> Stemming using Snowball Stemmer: 
 [('Streaming', 'stream'), ('data', 'data'), ('leading', 'lead'), ('edge', 'edg'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collect'), ('real-time', 'real-tim'), ('multiple', 'multipl')]

>> Lemmatization: 
 [('Streaming', 'Streaming'), ('data', 'data'), ('leading', 'leading'), ('edge', 'edge'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collected'), ('real-time', 'real-time'), ('multiple', 'multiple')]



========================================== PARAGRAPH 422 ===========================================

websites. The addition of the final V, veracity, has been discussed by several researchers and  

------------------- Sentence 1 -------------------

websites.

>> Tokens are: 
 ['websites', '.']

>> Bigrams are: 
 [('websites', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('websites', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['websites']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('websites', 'websit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('websites', 'websit'), ('.', '.')]

>> Lemmatization: 
 [('websites', 'website'), ('.', '.')]


------------------- Sentence 2 -------------------

The addition of the final V, veracity, has been discussed by several researchers and

>> Tokens are: 
 ['The', 'addition', 'final', 'V', ',', 'veracity', ',', 'discussed', 'several', 'researchers']

>> Bigrams are: 
 [('The', 'addition'), ('addition', 'final'), ('final', 'V'), ('V', ','), (',', 'veracity'), ('veracity', ','), (',', 'discussed'), ('discussed', 'several'), ('several', 'researchers')]

>> Trigrams are: 
 [('The', 'addition', 'final'), ('addition', 'final', 'V'), ('final', 'V', ','), ('V', ',', 'veracity'), (',', 'veracity', ','), ('veracity', ',', 'discussed'), (',', 'discussed', 'several'), ('discussed', 'several', 'researchers')]

>> POS Tags are: 
 [('The', 'DT'), ('addition', 'NN'), ('final', 'JJ'), ('V', 'NNP'), (',', ','), ('veracity', 'NN'), (',', ','), ('discussed', 'VBD'), ('several', 'JJ'), ('researchers', 'NNS')]

>> Noun Phrases are: 
 ['The addition', 'final V', 'veracity', 'several researchers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('addition', 'addit'), ('final', 'final'), ('V', 'v'), (',', ','), ('veracity', 'verac'), (',', ','), ('discussed', 'discuss'), ('several', 'sever'), ('researchers', 'research')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('addition', 'addit'), ('final', 'final'), ('V', 'v'), (',', ','), ('veracity', 'verac'), (',', ','), ('discussed', 'discuss'), ('several', 'sever'), ('researchers', 'research')]

>> Lemmatization: 
 [('The', 'The'), ('addition', 'addition'), ('final', 'final'), ('V', 'V'), (',', ','), ('veracity', 'veracity'), (',', ','), ('discussed', 'discussed'), ('several', 'several'), ('researchers', 'researcher')]



========================================== PARAGRAPH 423 ===========================================

organisations in this context. Veracity focuses on the quality of the data, which may be good, bad,  

------------------- Sentence 1 -------------------

organisations in this context.

>> Tokens are: 
 ['organisations', 'context', '.']

>> Bigrams are: 
 [('organisations', 'context'), ('context', '.')]

>> Trigrams are: 
 [('organisations', 'context', '.')]

>> POS Tags are: 
 [('organisations', 'NNS'), ('context', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['organisations context']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organisations', 'organis'), ('context', 'context'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('organisations', 'organis'), ('context', 'context'), ('.', '.')]

>> Lemmatization: 
 [('organisations', 'organisation'), ('context', 'context'), ('.', '.')]


------------------- Sentence 2 -------------------

Veracity focuses on the quality of the data, which may be good, bad,

>> Tokens are: 
 ['Veracity', 'focuses', 'quality', 'data', ',', 'may', 'good', ',', 'bad', ',']

>> Bigrams are: 
 [('Veracity', 'focuses'), ('focuses', 'quality'), ('quality', 'data'), ('data', ','), (',', 'may'), ('may', 'good'), ('good', ','), (',', 'bad'), ('bad', ',')]

>> Trigrams are: 
 [('Veracity', 'focuses', 'quality'), ('focuses', 'quality', 'data'), ('quality', 'data', ','), ('data', ',', 'may'), (',', 'may', 'good'), ('may', 'good', ','), ('good', ',', 'bad'), (',', 'bad', ',')]

>> POS Tags are: 
 [('Veracity', 'NN'), ('focuses', 'VBZ'), ('quality', 'NN'), ('data', 'NNS'), (',', ','), ('may', 'MD'), ('good', 'VB'), (',', ','), ('bad', 'JJ'), (',', ',')]

>> Noun Phrases are: 
 ['Veracity', 'quality data']

>> Named Entities are: 
 [('GPE', 'Veracity')] 

>> Stemming using Porter Stemmer: 
 [('Veracity', 'verac'), ('focuses', 'focus'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Veracity', 'verac'), ('focuses', 'focus'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ',')]

>> Lemmatization: 
 [('Veracity', 'Veracity'), ('focuses', 'focus'), ('quality', 'quality'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ',')]



========================================== PARAGRAPH 424 ===========================================

or undefined due to data inconsistency, incompleteness, ambiguity, latency, deception, or  

------------------- Sentence 1 -------------------

or undefined due to data inconsistency, incompleteness, ambiguity, latency, deception, or

>> Tokens are: 
 ['undefined', 'due', 'data', 'inconsistency', ',', 'incompleteness', ',', 'ambiguity', ',', 'latency', ',', 'deception', ',']

>> Bigrams are: 
 [('undefined', 'due'), ('due', 'data'), ('data', 'inconsistency'), ('inconsistency', ','), (',', 'incompleteness'), ('incompleteness', ','), (',', 'ambiguity'), ('ambiguity', ','), (',', 'latency'), ('latency', ','), (',', 'deception'), ('deception', ',')]

>> Trigrams are: 
 [('undefined', 'due', 'data'), ('due', 'data', 'inconsistency'), ('data', 'inconsistency', ','), ('inconsistency', ',', 'incompleteness'), (',', 'incompleteness', ','), ('incompleteness', ',', 'ambiguity'), (',', 'ambiguity', ','), ('ambiguity', ',', 'latency'), (',', 'latency', ','), ('latency', ',', 'deception'), (',', 'deception', ',')]

>> POS Tags are: 
 [('undefined', 'JJ'), ('due', 'JJ'), ('data', 'NNS'), ('inconsistency', 'NN'), (',', ','), ('incompleteness', 'NN'), (',', ','), ('ambiguity', 'NN'), (',', ','), ('latency', 'NN'), (',', ','), ('deception', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['undefined due data inconsistency', 'incompleteness', 'ambiguity', 'latency', 'deception']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('undefined', 'undefin'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('undefined', 'undefin'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ',')]

>> Lemmatization: 
 [('undefined', 'undefined'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsistency'), (',', ','), ('incompleteness', 'incompleteness'), (',', ','), ('ambiguity', 'ambiguity'), (',', ','), ('latency', 'latency'), (',', ','), ('deception', 'deception'), (',', ',')]



========================================== PARAGRAPH 425 ===========================================

approximations. As most big data sources are external, they lack governance and have little  

------------------- Sentence 1 -------------------

approximations.

>> Tokens are: 
 ['approximations', '.']

>> Bigrams are: 
 [('approximations', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('approximations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['approximations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approximations', 'approxim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approximations', 'approxim'), ('.', '.')]

>> Lemmatization: 
 [('approximations', 'approximation'), ('.', '.')]


------------------- Sentence 2 -------------------

As most big data sources are external, they lack governance and have little

>> Tokens are: 
 ['As', 'big', 'data', 'sources', 'external', ',', 'lack', 'governance', 'little']

>> Bigrams are: 
 [('As', 'big'), ('big', 'data'), ('data', 'sources'), ('sources', 'external'), ('external', ','), (',', 'lack'), ('lack', 'governance'), ('governance', 'little')]

>> Trigrams are: 
 [('As', 'big', 'data'), ('big', 'data', 'sources'), ('data', 'sources', 'external'), ('sources', 'external', ','), ('external', ',', 'lack'), (',', 'lack', 'governance'), ('lack', 'governance', 'little')]

>> POS Tags are: 
 [('As', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('external', 'JJ'), (',', ','), ('lack', 'JJ'), ('governance', 'NN'), ('little', 'JJ')]

>> Noun Phrases are: 
 ['big data sources', 'lack governance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('lack', 'lack'), ('governance', 'govern'), ('little', 'littl')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('lack', 'lack'), ('governance', 'govern'), ('little', 'littl')]

>> Lemmatization: 
 [('As', 'As'), ('big', 'big'), ('data', 'data'), ('sources', 'source'), ('external', 'external'), (',', ','), ('lack', 'lack'), ('governance', 'governance'), ('little', 'little')]



========================================== PARAGRAPH 426 ===========================================

homogeneity (Elragal, 2014; Elgendy and Elragal, 2014; Russom, 2011).  

------------------- Sentence 1 -------------------

homogeneity (Elragal, 2014; Elgendy and Elragal, 2014; Russom, 2011).

>> Tokens are: 
 ['homogeneity', '(', 'Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ';', 'Russom', ',', '2011', ')', '.']

>> Bigrams are: 
 [('homogeneity', '('), ('(', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('homogeneity', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Russom'), (';', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('homogeneity', 'NN'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['homogeneity', 'Elragal', 'Elgendy Elragal', 'Russom']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal'), ('PERSON', 'Elgendy Elragal'), ('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('homogeneity', 'homogen'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('homogeneity', 'homogen'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('homogeneity', 'homogeneity'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 427 ===========================================

The important thing for modern organisations seeking competitive advantages is how to manage  

------------------- Sentence 1 -------------------

The important thing for modern organisations seeking competitive advantages is how to manage

>> Tokens are: 
 ['The', 'important', 'thing', 'modern', 'organisations', 'seeking', 'competitive', 'advantages', 'manage']

>> Bigrams are: 
 [('The', 'important'), ('important', 'thing'), ('thing', 'modern'), ('modern', 'organisations'), ('organisations', 'seeking'), ('seeking', 'competitive'), ('competitive', 'advantages'), ('advantages', 'manage')]

>> Trigrams are: 
 [('The', 'important', 'thing'), ('important', 'thing', 'modern'), ('thing', 'modern', 'organisations'), ('modern', 'organisations', 'seeking'), ('organisations', 'seeking', 'competitive'), ('seeking', 'competitive', 'advantages'), ('competitive', 'advantages', 'manage')]

>> POS Tags are: 
 [('The', 'DT'), ('important', 'JJ'), ('thing', 'NN'), ('modern', 'JJ'), ('organisations', 'NNS'), ('seeking', 'VBG'), ('competitive', 'JJ'), ('advantages', 'NNS'), ('manage', 'VBP')]

>> Noun Phrases are: 
 ['The important thing', 'modern organisations', 'competitive advantages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('important', 'import'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organis'), ('seeking', 'seek'), ('competitive', 'competit'), ('advantages', 'advantag'), ('manage', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('important', 'import'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organis'), ('seeking', 'seek'), ('competitive', 'competit'), ('advantages', 'advantag'), ('manage', 'manag')]

>> Lemmatization: 
 [('The', 'The'), ('important', 'important'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organisation'), ('seeking', 'seeking'), ('competitive', 'competitive'), ('advantages', 'advantage'), ('manage', 'manage')]



========================================== PARAGRAPH 428 ===========================================

and extract the value from data. Big data combines technical challenges with multiple  

------------------- Sentence 1 -------------------

and extract the value from data.

>> Tokens are: 
 ['extract', 'value', 'data', '.']

>> Bigrams are: 
 [('extract', 'value'), ('value', 'data'), ('data', '.')]

>> Trigrams are: 
 [('extract', 'value', 'data'), ('value', 'data', '.')]

>> POS Tags are: 
 [('extract', 'JJ'), ('value', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['extract value data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extract', 'extract'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('extract', 'extract'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('extract', 'extract'), ('value', 'value'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data combines technical challenges with multiple

>> Tokens are: 
 ['Big', 'data', 'combines', 'technical', 'challenges', 'multiple']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'combines'), ('combines', 'technical'), ('technical', 'challenges'), ('challenges', 'multiple')]

>> Trigrams are: 
 [('Big', 'data', 'combines'), ('data', 'combines', 'technical'), ('combines', 'technical', 'challenges'), ('technical', 'challenges', 'multiple')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('combines', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('multiple', 'VBP')]

>> Noun Phrases are: 
 ['Big data combines', 'technical challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('combines', 'combin'), ('technical', 'technic'), ('challenges', 'challeng'), ('multiple', 'multipl')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('combines', 'combin'), ('technical', 'technic'), ('challenges', 'challeng'), ('multiple', 'multipl')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('combines', 'combine'), ('technical', 'technical'), ('challenges', 'challenge'), ('multiple', 'multiple')]



========================================== PARAGRAPH 429 ===========================================

opportunities, and thus extracting business value represents both challenge and opportunity at the  

------------------- Sentence 1 -------------------

opportunities, and thus extracting business value represents both challenge and opportunity at the

>> Tokens are: 
 ['opportunities', ',', 'thus', 'extracting', 'business', 'value', 'represents', 'challenge', 'opportunity']

>> Bigrams are: 
 [('opportunities', ','), (',', 'thus'), ('thus', 'extracting'), ('extracting', 'business'), ('business', 'value'), ('value', 'represents'), ('represents', 'challenge'), ('challenge', 'opportunity')]

>> Trigrams are: 
 [('opportunities', ',', 'thus'), (',', 'thus', 'extracting'), ('thus', 'extracting', 'business'), ('extracting', 'business', 'value'), ('business', 'value', 'represents'), ('value', 'represents', 'challenge'), ('represents', 'challenge', 'opportunity')]

>> POS Tags are: 
 [('opportunities', 'NNS'), (',', ','), ('thus', 'RB'), ('extracting', 'VBG'), ('business', 'NN'), ('value', 'NN'), ('represents', 'VBZ'), ('challenge', 'VBP'), ('opportunity', 'NN')]

>> Noun Phrases are: 
 ['opportunities', 'business value', 'opportunity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('opportunities', 'opportun'), (',', ','), ('thus', 'thu'), ('extracting', 'extract'), ('business', 'busi'), ('value', 'valu'), ('represents', 'repres'), ('challenge', 'challeng'), ('opportunity', 'opportun')]

>> Stemming using Snowball Stemmer: 
 [('opportunities', 'opportun'), (',', ','), ('thus', 'thus'), ('extracting', 'extract'), ('business', 'busi'), ('value', 'valu'), ('represents', 'repres'), ('challenge', 'challeng'), ('opportunity', 'opportun')]

>> Lemmatization: 
 [('opportunities', 'opportunity'), (',', ','), ('thus', 'thus'), ('extracting', 'extracting'), ('business', 'business'), ('value', 'value'), ('represents', 'represents'), ('challenge', 'challenge'), ('opportunity', 'opportunity')]



========================================== PARAGRAPH 430 ===========================================

same time. This puts big data business perspective side-by-side with technical aspects and showing  

------------------- Sentence 1 -------------------

same time.

>> Tokens are: 
 ['time', '.']

>> Bigrams are: 
 [('time', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('time', 'time'), ('.', '.')]


------------------- Sentence 2 -------------------

This puts big data business perspective side-by-side with technical aspects and showing

>> Tokens are: 
 ['This', 'puts', 'big', 'data', 'business', 'perspective', 'side-by-side', 'technical', 'aspects', 'showing']

>> Bigrams are: 
 [('This', 'puts'), ('puts', 'big'), ('big', 'data'), ('data', 'business'), ('business', 'perspective'), ('perspective', 'side-by-side'), ('side-by-side', 'technical'), ('technical', 'aspects'), ('aspects', 'showing')]

>> Trigrams are: 
 [('This', 'puts', 'big'), ('puts', 'big', 'data'), ('big', 'data', 'business'), ('data', 'business', 'perspective'), ('business', 'perspective', 'side-by-side'), ('perspective', 'side-by-side', 'technical'), ('side-by-side', 'technical', 'aspects'), ('technical', 'aspects', 'showing')]

>> POS Tags are: 
 [('This', 'DT'), ('puts', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('business', 'NN'), ('perspective', 'JJ'), ('side-by-side', 'JJ'), ('technical', 'JJ'), ('aspects', 'NNS'), ('showing', 'VBG')]

>> Noun Phrases are: 
 ['big data business', 'perspective side-by-side technical aspects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('perspective', 'perspect'), ('side-by-side', 'side-by-sid'), ('technical', 'technic'), ('aspects', 'aspect'), ('showing', 'show')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('perspective', 'perspect'), ('side-by-side', 'side-by-sid'), ('technical', 'technic'), ('aspects', 'aspect'), ('showing', 'show')]

>> Lemmatization: 
 [('This', 'This'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'business'), ('perspective', 'perspective'), ('side-by-side', 'side-by-side'), ('technical', 'technical'), ('aspects', 'aspect'), ('showing', 'showing')]



========================================== PARAGRAPH 431 ===========================================

how big data adds value to organisational objectives has become a crucial aspect of research in  

------------------- Sentence 1 -------------------

how big data adds value to organisational objectives has become a crucial aspect of research in

>> Tokens are: 
 ['big', 'data', 'adds', 'value', 'organisational', 'objectives', 'become', 'crucial', 'aspect', 'research']

>> Bigrams are: 
 [('big', 'data'), ('data', 'adds'), ('adds', 'value'), ('value', 'organisational'), ('organisational', 'objectives'), ('objectives', 'become'), ('become', 'crucial'), ('crucial', 'aspect'), ('aspect', 'research')]

>> Trigrams are: 
 [('big', 'data', 'adds'), ('data', 'adds', 'value'), ('adds', 'value', 'organisational'), ('value', 'organisational', 'objectives'), ('organisational', 'objectives', 'become'), ('objectives', 'become', 'crucial'), ('become', 'crucial', 'aspect'), ('crucial', 'aspect', 'research')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('adds', 'VBZ'), ('value', 'NN'), ('organisational', 'JJ'), ('objectives', 'VBZ'), ('become', 'VBN'), ('crucial', 'JJ'), ('aspect', 'JJ'), ('research', 'NN')]

>> Noun Phrases are: 
 ['big data', 'value', 'crucial aspect research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'valu'), ('organisational', 'organis'), ('objectives', 'object'), ('become', 'becom'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'valu'), ('organisational', 'organis'), ('objectives', 'object'), ('become', 'becom'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'value'), ('organisational', 'organisational'), ('objectives', 'objective'), ('become', 'become'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research')]



========================================== PARAGRAPH 432 ===========================================

this field. Manyika et al. (2011) clarified how big data can generate value-add for organisations by  

------------------- Sentence 1 -------------------

this field.

>> Tokens are: 
 ['field', '.']

>> Bigrams are: 
 [('field', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('field', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('field', 'field'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('field', 'field'), ('.', '.')]

>> Lemmatization: 
 [('field', 'field'), ('.', '.')]


------------------- Sentence 2 -------------------

Manyika et al.

>> Tokens are: 
 ['Manyika', 'et', 'al', '.']

>> Bigrams are: 
 [('Manyika', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Manyika', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Manyika', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Manyika', 'al']

>> Named Entities are: 
 [('GPE', 'Manyika')] 

>> Stemming using Porter Stemmer: 
 [('Manyika', 'manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Manyika', 'manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Manyika', 'Manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(2011) clarified how big data can generate value-add for organisations by

>> Tokens are: 
 ['(', '2011', ')', 'clarified', 'big', 'data', 'generate', 'value-add', 'organisations']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', 'clarified'), ('clarified', 'big'), ('big', 'data'), ('data', 'generate'), ('generate', 'value-add'), ('value-add', 'organisations')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', 'clarified'), (')', 'clarified', 'big'), ('clarified', 'big', 'data'), ('big', 'data', 'generate'), ('data', 'generate', 'value-add'), ('generate', 'value-add', 'organisations')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('clarified', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('generate', 'NN'), ('value-add', 'JJ'), ('organisations', 'NNS')]

>> Noun Phrases are: 
 ['big data generate', 'value-add organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarifi'), ('big', 'big'), ('data', 'data'), ('generate', 'gener'), ('value-add', 'value-add'), ('organisations', 'organis')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarifi'), ('big', 'big'), ('data', 'data'), ('generate', 'generat'), ('value-add', 'value-add'), ('organisations', 'organis')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarified'), ('big', 'big'), ('data', 'data'), ('generate', 'generate'), ('value-add', 'value-add'), ('organisations', 'organisation')]



========================================== PARAGRAPH 433 ===========================================

➢ making information clear and applicable more frequently;  ➢ allowing organisations to create and store transactional data in digital form, making it  

------------------- Sentence 1 -------------------

➢ making information clear and applicable more frequently;  ➢ allowing organisations to create and store transactional data in digital form, making it

>> Tokens are: 
 ['➢', 'making', 'information', 'clear', 'applicable', 'frequently', ';', '➢', 'allowing', 'organisations', 'create', 'store', 'transactional', 'data', 'digital', 'form', ',', 'making']

>> Bigrams are: 
 [('➢', 'making'), ('making', 'information'), ('information', 'clear'), ('clear', 'applicable'), ('applicable', 'frequently'), ('frequently', ';'), (';', '➢'), ('➢', 'allowing'), ('allowing', 'organisations'), ('organisations', 'create'), ('create', 'store'), ('store', 'transactional'), ('transactional', 'data'), ('data', 'digital'), ('digital', 'form'), ('form', ','), (',', 'making')]

>> Trigrams are: 
 [('➢', 'making', 'information'), ('making', 'information', 'clear'), ('information', 'clear', 'applicable'), ('clear', 'applicable', 'frequently'), ('applicable', 'frequently', ';'), ('frequently', ';', '➢'), (';', '➢', 'allowing'), ('➢', 'allowing', 'organisations'), ('allowing', 'organisations', 'create'), ('organisations', 'create', 'store'), ('create', 'store', 'transactional'), ('store', 'transactional', 'data'), ('transactional', 'data', 'digital'), ('data', 'digital', 'form'), ('digital', 'form', ','), ('form', ',', 'making')]

>> POS Tags are: 
 [('➢', 'NN'), ('making', 'VBG'), ('information', 'NN'), ('clear', 'JJ'), ('applicable', 'JJ'), ('frequently', 'RB'), (';', ':'), ('➢', 'CC'), ('allowing', 'VBG'), ('organisations', 'NNS'), ('create', 'VBP'), ('store', 'VBP'), ('transactional', 'JJ'), ('data', 'NNS'), ('digital', 'JJ'), ('form', 'NN'), (',', ','), ('making', 'VBG')]

>> Noun Phrases are: 
 ['➢', 'information', 'organisations', 'transactional data', 'digital form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('making', 'make'), ('information', 'inform'), ('clear', 'clear'), ('applicable', 'applic'), ('frequently', 'frequent'), (';', ';'), ('➢', '➢'), ('allowing', 'allow'), ('organisations', 'organis'), ('create', 'creat'), ('store', 'store'), ('transactional', 'transact'), ('data', 'data'), ('digital', 'digit'), ('form', 'form'), (',', ','), ('making', 'make')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('making', 'make'), ('information', 'inform'), ('clear', 'clear'), ('applicable', 'applic'), ('frequently', 'frequent'), (';', ';'), ('➢', '➢'), ('allowing', 'allow'), ('organisations', 'organis'), ('create', 'creat'), ('store', 'store'), ('transactional', 'transact'), ('data', 'data'), ('digital', 'digit'), ('form', 'form'), (',', ','), ('making', 'make')]

>> Lemmatization: 
 [('➢', '➢'), ('making', 'making'), ('information', 'information'), ('clear', 'clear'), ('applicable', 'applicable'), ('frequently', 'frequently'), (';', ';'), ('➢', '➢'), ('allowing', 'allowing'), ('organisations', 'organisation'), ('create', 'create'), ('store', 'store'), ('transactional', 'transactional'), ('data', 'data'), ('digital', 'digital'), ('form', 'form'), (',', ','), ('making', 'making')]



========================================== PARAGRAPH 434 ===========================================

easier for them to gather more precise information about inventories and products;  

------------------- Sentence 1 -------------------

easier for them to gather more precise information about inventories and products;

>> Tokens are: 
 ['easier', 'gather', 'precise', 'information', 'inventories', 'products', ';']

>> Bigrams are: 
 [('easier', 'gather'), ('gather', 'precise'), ('precise', 'information'), ('information', 'inventories'), ('inventories', 'products'), ('products', ';')]

>> Trigrams are: 
 [('easier', 'gather', 'precise'), ('gather', 'precise', 'information'), ('precise', 'information', 'inventories'), ('information', 'inventories', 'products'), ('inventories', 'products', ';')]

>> POS Tags are: 
 [('easier', 'JJR'), ('gather', 'NN'), ('precise', 'NN'), ('information', 'NN'), ('inventories', 'NNS'), ('products', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['gather precise information inventories products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('easier', 'easier'), ('gather', 'gather'), ('precise', 'precis'), ('information', 'inform'), ('inventories', 'inventori'), ('products', 'product'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('easier', 'easier'), ('gather', 'gather'), ('precise', 'precis'), ('information', 'inform'), ('inventories', 'inventori'), ('products', 'product'), (';', ';')]

>> Lemmatization: 
 [('easier', 'easier'), ('gather', 'gather'), ('precise', 'precise'), ('information', 'information'), ('inventories', 'inventory'), ('products', 'product'), (';', ';')]



========================================== PARAGRAPH 435 ===========================================

➢ using sophisticated big data analytics to improve decision making quality; 

------------------- Sentence 1 -------------------

➢ using sophisticated big data analytics to improve decision making quality;

>> Tokens are: 
 ['➢', 'using', 'sophisticated', 'big', 'data', 'analytics', 'improve', 'decision', 'making', 'quality', ';']

>> Bigrams are: 
 [('➢', 'using'), ('using', 'sophisticated'), ('sophisticated', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'improve'), ('improve', 'decision'), ('decision', 'making'), ('making', 'quality'), ('quality', ';')]

>> Trigrams are: 
 [('➢', 'using', 'sophisticated'), ('using', 'sophisticated', 'big'), ('sophisticated', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'improve'), ('analytics', 'improve', 'decision'), ('improve', 'decision', 'making'), ('decision', 'making', 'quality'), ('making', 'quality', ';')]

>> POS Tags are: 
 [('➢', 'NN'), ('using', 'VBG'), ('sophisticated', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('improve', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('quality', 'NN'), (';', ':')]

>> Noun Phrases are: 
 ['➢', 'sophisticated big data analytics', 'decision making quality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('using', 'use'), ('sophisticated', 'sophist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('decision', 'decis'), ('making', 'make'), ('quality', 'qualiti'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('using', 'use'), ('sophisticated', 'sophist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('decision', 'decis'), ('making', 'make'), ('quality', 'qualiti'), (';', ';')]

>> Lemmatization: 
 [('➢', '➢'), ('using', 'using'), ('sophisticated', 'sophisticated'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('improve', 'improve'), ('decision', 'decision'), ('making', 'making'), ('quality', 'quality'), (';', ';')]



========================================== PARAGRAPH 436 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 437 ===========================================

16  

------------------- Sentence 1 -------------------

16

>> Tokens are: 
 ['16']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('16', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16')]

>> Stemming using Snowball Stemmer: 
 [('16', '16')]

>> Lemmatization: 
 [('16', '16')]



========================================== PARAGRAPH 438 ===========================================

  


========================================== PARAGRAPH 439 ===========================================

➢ utilising big data to shape the next generation of products and services (Elragal, A, 2014).  

------------------- Sentence 1 -------------------

➢ utilising big data to shape the next generation of products and services (Elragal, A, 2014).

>> Tokens are: 
 ['➢', 'utilising', 'big', 'data', 'shape', 'next', 'generation', 'products', 'services', '(', 'Elragal', ',', 'A', ',', '2014', ')', '.']

>> Bigrams are: 
 [('➢', 'utilising'), ('utilising', 'big'), ('big', 'data'), ('data', 'shape'), ('shape', 'next'), ('next', 'generation'), ('generation', 'products'), ('products', 'services'), ('services', '('), ('(', 'Elragal'), ('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('➢', 'utilising', 'big'), ('utilising', 'big', 'data'), ('big', 'data', 'shape'), ('data', 'shape', 'next'), ('shape', 'next', 'generation'), ('next', 'generation', 'products'), ('generation', 'products', 'services'), ('products', 'services', '('), ('services', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('➢', 'NN'), ('utilising', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('shape', 'NN'), ('next', 'IN'), ('generation', 'NN'), ('products', 'NNS'), ('services', 'NNS'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['➢', 'big data shape', 'generation products services', 'Elragal', 'A']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('utilising', 'utilis'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'gener'), ('products', 'product'), ('services', 'servic'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('utilising', 'utilis'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'generat'), ('products', 'product'), ('services', 'servic'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('utilising', 'utilising'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'generation'), ('products', 'product'), ('services', 'service'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 440 ===========================================

Quantifying big data can be done in terms of storage size, number of records, transactions, tables,  

------------------- Sentence 1 -------------------

Quantifying big data can be done in terms of storage size, number of records, transactions, tables,

>> Tokens are: 
 ['Quantifying', 'big', 'data', 'done', 'terms', 'storage', 'size', ',', 'number', 'records', ',', 'transactions', ',', 'tables', ',']

>> Bigrams are: 
 [('Quantifying', 'big'), ('big', 'data'), ('data', 'done'), ('done', 'terms'), ('terms', 'storage'), ('storage', 'size'), ('size', ','), (',', 'number'), ('number', 'records'), ('records', ','), (',', 'transactions'), ('transactions', ','), (',', 'tables'), ('tables', ',')]

>> Trigrams are: 
 [('Quantifying', 'big', 'data'), ('big', 'data', 'done'), ('data', 'done', 'terms'), ('done', 'terms', 'storage'), ('terms', 'storage', 'size'), ('storage', 'size', ','), ('size', ',', 'number'), (',', 'number', 'records'), ('number', 'records', ','), ('records', ',', 'transactions'), (',', 'transactions', ','), ('transactions', ',', 'tables'), (',', 'tables', ',')]

>> POS Tags are: 
 [('Quantifying', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('done', 'VBN'), ('terms', 'NNS'), ('storage', 'NN'), ('size', 'NN'), (',', ','), ('number', 'NN'), ('records', 'NNS'), (',', ','), ('transactions', 'NNS'), (',', ','), ('tables', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['big data', 'terms storage size', 'number records', 'transactions', 'tables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Quantifying', 'quantifi'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storag'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transact'), (',', ','), ('tables', 'tabl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Quantifying', 'quantifi'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storag'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transact'), (',', ','), ('tables', 'tabl'), (',', ',')]

>> Lemmatization: 
 [('Quantifying', 'Quantifying'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storage'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transaction'), (',', ','), ('tables', 'table'), (',', ',')]



========================================== PARAGRAPH 441 ===========================================

or files. Big data comes from multiple diverse sources collected for many purposes (Constantiou  

------------------- Sentence 1 -------------------

or files.

>> Tokens are: 
 ['files', '.']

>> Bigrams are: 
 [('files', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('files', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['files']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('files', 'file'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('files', 'file'), ('.', '.')]

>> Lemmatization: 
 [('files', 'file'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data comes from multiple diverse sources collected for many purposes (Constantiou

>> Tokens are: 
 ['Big', 'data', 'comes', 'multiple', 'diverse', 'sources', 'collected', 'many', 'purposes', '(', 'Constantiou']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'comes'), ('comes', 'multiple'), ('multiple', 'diverse'), ('diverse', 'sources'), ('sources', 'collected'), ('collected', 'many'), ('many', 'purposes'), ('purposes', '('), ('(', 'Constantiou')]

>> Trigrams are: 
 [('Big', 'data', 'comes'), ('data', 'comes', 'multiple'), ('comes', 'multiple', 'diverse'), ('multiple', 'diverse', 'sources'), ('diverse', 'sources', 'collected'), ('sources', 'collected', 'many'), ('collected', 'many', 'purposes'), ('many', 'purposes', '('), ('purposes', '(', 'Constantiou')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('comes', 'VBZ'), ('multiple', 'JJ'), ('diverse', 'JJ'), ('sources', 'NNS'), ('collected', 'VBD'), ('many', 'JJ'), ('purposes', 'NNS'), ('(', '('), ('Constantiou', 'NNP')]

>> Noun Phrases are: 
 ['Big data', 'multiple diverse sources', 'many purposes', 'Constantiou']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multipl'), ('diverse', 'divers'), ('sources', 'sourc'), ('collected', 'collect'), ('many', 'mani'), ('purposes', 'purpos'), ('(', '('), ('Constantiou', 'constanti')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multipl'), ('diverse', 'divers'), ('sources', 'sourc'), ('collected', 'collect'), ('many', 'mani'), ('purposes', 'purpos'), ('(', '('), ('Constantiou', 'constantiou')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multiple'), ('diverse', 'diverse'), ('sources', 'source'), ('collected', 'collected'), ('many', 'many'), ('purposes', 'purpose'), ('(', '('), ('Constantiou', 'Constantiou')]



========================================== PARAGRAPH 442 ===========================================

and Kallinikos, 2015), including IoT data, logs, clickstreams, and social media. For all of those  

------------------- Sentence 1 -------------------

and Kallinikos, 2015), including IoT data, logs, clickstreams, and social media.

>> Tokens are: 
 ['Kallinikos', ',', '2015', ')', ',', 'including', 'IoT', 'data', ',', 'logs', ',', 'clickstreams', ',', 'social', 'media', '.']

>> Bigrams are: 
 [('Kallinikos', ','), (',', '2015'), ('2015', ')'), (')', ','), (',', 'including'), ('including', 'IoT'), ('IoT', 'data'), ('data', ','), (',', 'logs'), ('logs', ','), (',', 'clickstreams'), ('clickstreams', ','), (',', 'social'), ('social', 'media'), ('media', '.')]

>> Trigrams are: 
 [('Kallinikos', ',', '2015'), (',', '2015', ')'), ('2015', ')', ','), (')', ',', 'including'), (',', 'including', 'IoT'), ('including', 'IoT', 'data'), ('IoT', 'data', ','), ('data', ',', 'logs'), (',', 'logs', ','), ('logs', ',', 'clickstreams'), (',', 'clickstreams', ','), ('clickstreams', ',', 'social'), (',', 'social', 'media'), ('social', 'media', '.')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), (',', ','), ('including', 'VBG'), ('IoT', 'NNP'), ('data', 'NN'), (',', ','), ('logs', 'NNS'), (',', ','), ('clickstreams', 'NNS'), (',', ','), ('social', 'JJ'), ('media', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Kallinikos', 'IoT data', 'logs', 'clickstreams', 'social media']

>> Named Entities are: 
 [('GPE', 'Kallinikos'), ('ORGANIZATION', 'IoT')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'includ'), ('IoT', 'iot'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstream'), (',', ','), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'includ'), ('IoT', 'iot'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstream'), (',', ','), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'including'), ('IoT', 'IoT'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstreams'), (',', ','), ('social', 'social'), ('media', 'medium'), ('.', '.')]


------------------- Sentence 2 -------------------

For all of those

>> Tokens are: 
 ['For']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('For', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for')]

>> Lemmatization: 
 [('For', 'For')]



========================================== PARAGRAPH 443 ===========================================

sources to be used for analytics requires joining up unstructured data (such as texts in natural  

------------------- Sentence 1 -------------------

sources to be used for analytics requires joining up unstructured data (such as texts in natural

>> Tokens are: 
 ['sources', 'used', 'analytics', 'requires', 'joining', 'unstructured', 'data', '(', 'texts', 'natural']

>> Bigrams are: 
 [('sources', 'used'), ('used', 'analytics'), ('analytics', 'requires'), ('requires', 'joining'), ('joining', 'unstructured'), ('unstructured', 'data'), ('data', '('), ('(', 'texts'), ('texts', 'natural')]

>> Trigrams are: 
 [('sources', 'used', 'analytics'), ('used', 'analytics', 'requires'), ('analytics', 'requires', 'joining'), ('requires', 'joining', 'unstructured'), ('joining', 'unstructured', 'data'), ('unstructured', 'data', '('), ('data', '(', 'texts'), ('(', 'texts', 'natural')]

>> POS Tags are: 
 [('sources', 'NNS'), ('used', 'VBD'), ('analytics', 'NNS'), ('requires', 'VBZ'), ('joining', 'VBG'), ('unstructured', 'JJ'), ('data', 'NNS'), ('(', '('), ('texts', 'JJ'), ('natural', 'JJ')]

>> Noun Phrases are: 
 ['sources', 'analytics', 'unstructured data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sources', 'sourc'), ('used', 'use'), ('analytics', 'analyt'), ('requires', 'requir'), ('joining', 'join'), ('unstructured', 'unstructur'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('sources', 'sourc'), ('used', 'use'), ('analytics', 'analyt'), ('requires', 'requir'), ('joining', 'join'), ('unstructured', 'unstructur'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natur')]

>> Lemmatization: 
 [('sources', 'source'), ('used', 'used'), ('analytics', 'analytics'), ('requires', 'requires'), ('joining', 'joining'), ('unstructured', 'unstructured'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natural')]



========================================== PARAGRAPH 444 ===========================================

language) and semi-structured data (such as extensible mark-up language (XML), JSON or rich  

------------------- Sentence 1 -------------------

language) and semi-structured data (such as extensible mark-up language (XML), JSON or rich

>> Tokens are: 
 ['language', ')', 'semi-structured', 'data', '(', 'extensible', 'mark-up', 'language', '(', 'XML', ')', ',', 'JSON', 'rich']

>> Bigrams are: 
 [('language', ')'), (')', 'semi-structured'), ('semi-structured', 'data'), ('data', '('), ('(', 'extensible'), ('extensible', 'mark-up'), ('mark-up', 'language'), ('language', '('), ('(', 'XML'), ('XML', ')'), (')', ','), (',', 'JSON'), ('JSON', 'rich')]

>> Trigrams are: 
 [('language', ')', 'semi-structured'), (')', 'semi-structured', 'data'), ('semi-structured', 'data', '('), ('data', '(', 'extensible'), ('(', 'extensible', 'mark-up'), ('extensible', 'mark-up', 'language'), ('mark-up', 'language', '('), ('language', '(', 'XML'), ('(', 'XML', ')'), ('XML', ')', ','), (')', ',', 'JSON'), (',', 'JSON', 'rich')]

>> POS Tags are: 
 [('language', 'NN'), (')', ')'), ('semi-structured', 'JJ'), ('data', 'NNS'), ('(', '('), ('extensible', 'JJ'), ('mark-up', 'JJ'), ('language', 'NN'), ('(', '('), ('XML', 'NNP'), (')', ')'), (',', ','), ('JSON', 'NNP'), ('rich', 'VBD')]

>> Noun Phrases are: 
 ['language', 'semi-structured data', 'extensible mark-up language', 'XML', 'JSON']

>> Named Entities are: 
 [('ORGANIZATION', 'XML'), ('ORGANIZATION', 'JSON')] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), (')', ')'), ('semi-structured', 'semi-structur'), ('data', 'data'), ('(', '('), ('extensible', 'extens'), ('mark-up', 'mark-up'), ('language', 'languag'), ('(', '('), ('XML', 'xml'), (')', ')'), (',', ','), ('JSON', 'json'), ('rich', 'rich')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), (')', ')'), ('semi-structured', 'semi-structur'), ('data', 'data'), ('(', '('), ('extensible', 'extens'), ('mark-up', 'mark-up'), ('language', 'languag'), ('(', '('), ('XML', 'xml'), (')', ')'), (',', ','), ('JSON', 'json'), ('rich', 'rich')]

>> Lemmatization: 
 [('language', 'language'), (')', ')'), ('semi-structured', 'semi-structured'), ('data', 'data'), ('(', '('), ('extensible', 'extensible'), ('mark-up', 'mark-up'), ('language', 'language'), ('(', '('), ('XML', 'XML'), (')', ')'), (',', ','), ('JSON', 'JSON'), ('rich', 'rich')]



========================================== PARAGRAPH 445 ===========================================

site summary (RSS) feeds) to a common structured data framework (Elgendy and Elragal, 2014;  

------------------- Sentence 1 -------------------

site summary (RSS) feeds) to a common structured data framework (Elgendy and Elragal, 2014;

>> Tokens are: 
 ['site', 'summary', '(', 'RSS', ')', 'feeds', ')', 'common', 'structured', 'data', 'framework', '(', 'Elgendy', 'Elragal', ',', '2014', ';']

>> Bigrams are: 
 [('site', 'summary'), ('summary', '('), ('(', 'RSS'), ('RSS', ')'), (')', 'feeds'), ('feeds', ')'), (')', 'common'), ('common', 'structured'), ('structured', 'data'), ('data', 'framework'), ('framework', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';')]

>> Trigrams are: 
 [('site', 'summary', '('), ('summary', '(', 'RSS'), ('(', 'RSS', ')'), ('RSS', ')', 'feeds'), (')', 'feeds', ')'), ('feeds', ')', 'common'), (')', 'common', 'structured'), ('common', 'structured', 'data'), ('structured', 'data', 'framework'), ('data', 'framework', '('), ('framework', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';')]

>> POS Tags are: 
 [('site', 'NN'), ('summary', 'NN'), ('(', '('), ('RSS', 'NNP'), (')', ')'), ('feeds', 'NNS'), (')', ')'), ('common', 'JJ'), ('structured', 'VBN'), ('data', 'NNS'), ('framework', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['site summary', 'RSS', 'feeds', 'data framework', 'Elgendy Elragal']

>> Named Entities are: 
 [('ORGANIZATION', 'RSS'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('site', 'site'), ('summary', 'summari'), ('(', '('), ('RSS', 'rss'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structur'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('site', 'site'), ('summary', 'summari'), ('(', '('), ('RSS', 'rss'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structur'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';')]

>> Lemmatization: 
 [('site', 'site'), ('summary', 'summary'), ('(', '('), ('RSS', 'RSS'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structured'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';')]



========================================== PARAGRAPH 446 ===========================================

Elragal, 2014).   

------------------- Sentence 1 -------------------

Elragal, 2014).

>> Tokens are: 
 ['Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal']

>> Named Entities are: 
 [('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 447 ===========================================

  


========================================== PARAGRAPH 448 ===========================================

  


========================================== PARAGRAPH 449 ===========================================

Figure 10: Big data in terms of the 5 V's.  

------------------- Sentence 1 -------------------

Figure 10: Big data in terms of the 5 V's.

>> Tokens are: 
 ['Figure', '10', ':', 'Big', 'data', 'terms', '5', 'V', "'s", '.']

>> Bigrams are: 
 [('Figure', '10'), ('10', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'terms'), ('terms', '5'), ('5', 'V'), ('V', "'s"), ("'s", '.')]

>> Trigrams are: 
 [('Figure', '10', ':'), ('10', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'terms'), ('data', 'terms', '5'), ('terms', '5', 'V'), ('5', 'V', "'s"), ('V', "'s", '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('10', 'CD'), (':', ':'), ('Big', 'JJ'), ('data', 'NNS'), ('terms', 'NNS'), ('5', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Big data terms', 'V']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('10', '10'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'v'), ("'s", "'s"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('10', '10'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'v'), ("'s", "'s"), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('10', '10'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'V'), ("'s", "'s"), ('.', '.')]



========================================== PARAGRAPH 450 ===========================================

  


========================================== PARAGRAPH 451 ===========================================

Multi-dimensional data can be used to add historical context to big data. The variety of big data is  

------------------- Sentence 1 -------------------

Multi-dimensional data can be used to add historical context to big data.

>> Tokens are: 
 ['Multi-dimensional', 'data', 'used', 'add', 'historical', 'context', 'big', 'data', '.']

>> Bigrams are: 
 [('Multi-dimensional', 'data'), ('data', 'used'), ('used', 'add'), ('add', 'historical'), ('historical', 'context'), ('context', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Multi-dimensional', 'data', 'used'), ('data', 'used', 'add'), ('used', 'add', 'historical'), ('add', 'historical', 'context'), ('historical', 'context', 'big'), ('context', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Multi-dimensional', 'JJ'), ('data', 'NNS'), ('used', 'VBN'), ('add', 'JJ'), ('historical', 'JJ'), ('context', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Multi-dimensional data', 'add historical context', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Multi-dimensional', 'multi-dimension'), ('data', 'data'), ('used', 'use'), ('add', 'add'), ('historical', 'histor'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Multi-dimensional', 'multi-dimension'), ('data', 'data'), ('used', 'use'), ('add', 'add'), ('historical', 'histor'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Multi-dimensional', 'Multi-dimensional'), ('data', 'data'), ('used', 'used'), ('add', 'add'), ('historical', 'historical'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The variety of big data is

>> Tokens are: 
 ['The', 'variety', 'big', 'data']

>> Bigrams are: 
 [('The', 'variety'), ('variety', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'variety', 'big'), ('variety', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('variety', 'NN'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The variety', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('variety', 'varieti'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('variety', 'varieti'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('variety', 'variety'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 452 ===========================================

as important as its volume, while velocity or speed can describe how difficult big data may be to 

------------------- Sentence 1 -------------------

as important as its volume, while velocity or speed can describe how difficult big data may be to

>> Tokens are: 
 ['important', 'volume', ',', 'velocity', 'speed', 'describe', 'difficult', 'big', 'data', 'may']

>> Bigrams are: 
 [('important', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', 'speed'), ('speed', 'describe'), ('describe', 'difficult'), ('difficult', 'big'), ('big', 'data'), ('data', 'may')]

>> Trigrams are: 
 [('important', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', 'speed'), ('velocity', 'speed', 'describe'), ('speed', 'describe', 'difficult'), ('describe', 'difficult', 'big'), ('difficult', 'big', 'data'), ('big', 'data', 'may')]

>> POS Tags are: 
 [('important', 'JJ'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), ('speed', 'NN'), ('describe', 'NN'), ('difficult', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('may', 'MD')]

>> Noun Phrases are: 
 ['important volume', 'velocity speed describe', 'difficult big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('speed', 'speed'), ('describe', 'describ'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('speed', 'speed'), ('describe', 'describ'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may')]

>> Lemmatization: 
 [('important', 'important'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), ('speed', 'speed'), ('describe', 'describe'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may')]



========================================== PARAGRAPH 453 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 454 ===========================================

17  

------------------- Sentence 1 -------------------

17

>> Tokens are: 
 ['17']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('17', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('17', '17')]

>> Stemming using Snowball Stemmer: 
 [('17', '17')]

>> Lemmatization: 
 [('17', '17')]



========================================== PARAGRAPH 455 ===========================================

  


========================================== PARAGRAPH 456 ===========================================

handle. Velocity may refer to data generation frequency or data delivery frequency. Depending on  

------------------- Sentence 1 -------------------

handle.

>> Tokens are: 
 ['handle', '.']

>> Bigrams are: 
 [('handle', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('handle', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['handle']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('handle', 'handl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('handle', 'handl'), ('.', '.')]

>> Lemmatization: 
 [('handle', 'handle'), ('.', '.')]


------------------- Sentence 2 -------------------

Velocity may refer to data generation frequency or data delivery frequency.

>> Tokens are: 
 ['Velocity', 'may', 'refer', 'data', 'generation', 'frequency', 'data', 'delivery', 'frequency', '.']

>> Bigrams are: 
 [('Velocity', 'may'), ('may', 'refer'), ('refer', 'data'), ('data', 'generation'), ('generation', 'frequency'), ('frequency', 'data'), ('data', 'delivery'), ('delivery', 'frequency'), ('frequency', '.')]

>> Trigrams are: 
 [('Velocity', 'may', 'refer'), ('may', 'refer', 'data'), ('refer', 'data', 'generation'), ('data', 'generation', 'frequency'), ('generation', 'frequency', 'data'), ('frequency', 'data', 'delivery'), ('data', 'delivery', 'frequency'), ('delivery', 'frequency', '.')]

>> POS Tags are: 
 [('Velocity', 'NN'), ('may', 'MD'), ('refer', 'VB'), ('data', 'NNS'), ('generation', 'NN'), ('frequency', 'NN'), ('data', 'NNS'), ('delivery', 'NN'), ('frequency', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Velocity', 'data generation frequency data delivery frequency']

>> Named Entities are: 
 [('GPE', 'Velocity')] 

>> Stemming using Porter Stemmer: 
 [('Velocity', 'veloc'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'gener'), ('frequency', 'frequenc'), ('data', 'data'), ('delivery', 'deliveri'), ('frequency', 'frequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Velocity', 'veloc'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'generat'), ('frequency', 'frequenc'), ('data', 'data'), ('delivery', 'deliveri'), ('frequency', 'frequenc'), ('.', '.')]

>> Lemmatization: 
 [('Velocity', 'Velocity'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'generation'), ('frequency', 'frequency'), ('data', 'data'), ('delivery', 'delivery'), ('frequency', 'frequency'), ('.', '.')]


------------------- Sentence 3 -------------------

Depending on

>> Tokens are: 
 ['Depending']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Depending', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Depending', 'depend')]

>> Stemming using Snowball Stemmer: 
 [('Depending', 'depend')]

>> Lemmatization: 
 [('Depending', 'Depending')]



========================================== PARAGRAPH 457 ===========================================

data inconsistency, incompleteness, ambiguity, latency, deception, and approximations, big data  

------------------- Sentence 1 -------------------

data inconsistency, incompleteness, ambiguity, latency, deception, and approximations, big data

>> Tokens are: 
 ['data', 'inconsistency', ',', 'incompleteness', ',', 'ambiguity', ',', 'latency', ',', 'deception', ',', 'approximations', ',', 'big', 'data']

>> Bigrams are: 
 [('data', 'inconsistency'), ('inconsistency', ','), (',', 'incompleteness'), ('incompleteness', ','), (',', 'ambiguity'), ('ambiguity', ','), (',', 'latency'), ('latency', ','), (',', 'deception'), ('deception', ','), (',', 'approximations'), ('approximations', ','), (',', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('data', 'inconsistency', ','), ('inconsistency', ',', 'incompleteness'), (',', 'incompleteness', ','), ('incompleteness', ',', 'ambiguity'), (',', 'ambiguity', ','), ('ambiguity', ',', 'latency'), (',', 'latency', ','), ('latency', ',', 'deception'), (',', 'deception', ','), ('deception', ',', 'approximations'), (',', 'approximations', ','), ('approximations', ',', 'big'), (',', 'big', 'data')]

>> POS Tags are: 
 [('data', 'NNS'), ('inconsistency', 'NN'), (',', ','), ('incompleteness', 'NN'), (',', ','), ('ambiguity', 'NN'), (',', ','), ('latency', 'NN'), (',', ','), ('deception', 'NN'), (',', ','), ('approximations', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['data inconsistency', 'incompleteness', 'ambiguity', 'latency', 'deception', 'approximations', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('data', 'data'), ('inconsistency', 'inconsistency'), (',', ','), ('incompleteness', 'incompleteness'), (',', ','), ('ambiguity', 'ambiguity'), (',', ','), ('latency', 'latency'), (',', ','), ('deception', 'deception'), (',', ','), ('approximations', 'approximation'), (',', ','), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 458 ===========================================

quality can also be characterised as undefined, good, or bad (Data, D.B., 2012).  

------------------- Sentence 1 -------------------

quality can also be characterised as undefined, good, or bad (Data, D.B., 2012).

>> Tokens are: 
 ['quality', 'also', 'characterised', 'undefined', ',', 'good', ',', 'bad', '(', 'Data', ',', 'D.B.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('quality', 'also'), ('also', 'characterised'), ('characterised', 'undefined'), ('undefined', ','), (',', 'good'), ('good', ','), (',', 'bad'), ('bad', '('), ('(', 'Data'), ('Data', ','), (',', 'D.B.'), ('D.B.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('quality', 'also', 'characterised'), ('also', 'characterised', 'undefined'), ('characterised', 'undefined', ','), ('undefined', ',', 'good'), (',', 'good', ','), ('good', ',', 'bad'), (',', 'bad', '('), ('bad', '(', 'Data'), ('(', 'Data', ','), ('Data', ',', 'D.B.'), (',', 'D.B.', ','), ('D.B.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('quality', 'NN'), ('also', 'RB'), ('characterised', 'VBD'), ('undefined', 'JJ'), (',', ','), ('good', 'JJ'), (',', ','), ('bad', 'JJ'), ('(', '('), ('Data', 'NNP'), (',', ','), ('D.B.', 'NNP'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['quality', 'Data', 'D.B.']

>> Named Entities are: 
 [('ORGANIZATION', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('quality', 'qualiti'), ('also', 'also'), ('characterised', 'characteris'), ('undefined', 'undefin'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('quality', 'qualiti'), ('also', 'also'), ('characterised', 'characteris'), ('undefined', 'undefin'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('quality', 'quality'), ('also', 'also'), ('characterised', 'characterised'), ('undefined', 'undefined'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'Data'), (',', ','), ('D.B.', 'D.B.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 459 ===========================================

  


========================================== PARAGRAPH 460 ===========================================

According to Mikalef et al. (2018), various researchers focus on different aspects of big data, as  

------------------- Sentence 1 -------------------

According to Mikalef et al.

>> Tokens are: 
 ['According', 'Mikalef', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Mikalef', 'et'), ('Mikalef', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Mikalef', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mikalef et al']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018), various researchers focus on different aspects of big data, as

>> Tokens are: 
 ['(', '2018', ')', ',', 'various', 'researchers', 'focus', 'different', 'aspects', 'big', 'data', ',']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', ','), (',', 'various'), ('various', 'researchers'), ('researchers', 'focus'), ('focus', 'different'), ('different', 'aspects'), ('aspects', 'big'), ('big', 'data'), ('data', ',')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', ','), (')', ',', 'various'), (',', 'various', 'researchers'), ('various', 'researchers', 'focus'), ('researchers', 'focus', 'different'), ('focus', 'different', 'aspects'), ('different', 'aspects', 'big'), ('aspects', 'big', 'data'), ('big', 'data', ',')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), (',', ','), ('various', 'JJ'), ('researchers', 'NNS'), ('focus', 'VBP'), ('different', 'JJ'), ('aspects', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['various researchers', 'different aspects', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'variou'), ('researchers', 'research'), ('focus', 'focu'), ('different', 'differ'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'various'), ('researchers', 'research'), ('focus', 'focus'), ('different', 'differ'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'various'), ('researchers', 'researcher'), ('focus', 'focus'), ('different', 'different'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 461 ===========================================

shown in Table 3.  

------------------- Sentence 1 -------------------

shown in Table 3.

>> Tokens are: 
 ['shown', 'Table', '3', '.']

>> Bigrams are: 
 [('shown', 'Table'), ('Table', '3'), ('3', '.')]

>> Trigrams are: 
 [('shown', 'Table', '3'), ('Table', '3', '.')]

>> POS Tags are: 
 [('shown', 'VBN'), ('Table', 'JJ'), ('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('Table', 'tabl'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('Table', 'tabl'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('shown', 'shown'), ('Table', 'Table'), ('3', '3'), ('.', '.')]



========================================== PARAGRAPH 462 ===========================================

  


========================================== PARAGRAPH 463 ===========================================

Table 3: Defining characteristics of big data, adopted from (Mikalef et al., 2018)  

------------------- Sentence 1 -------------------

Table 3: Defining characteristics of big data, adopted from (Mikalef et al., 2018)

>> Tokens are: 
 ['Table', '3', ':', 'Defining', 'characteristics', 'big', 'data', ',', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')']

>> Bigrams are: 
 [('Table', '3'), ('3', ':'), (':', 'Defining'), ('Defining', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')')]

>> Trigrams are: 
 [('Table', '3', ':'), ('3', ':', 'Defining'), (':', 'Defining', 'characteristics'), ('Defining', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')')]

>> POS Tags are: 
 [('Table', 'JJ'), ('3', 'CD'), (':', ':'), ('Defining', 'NN'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Defining characteristics', 'big data', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('3', '3'), (':', ':'), ('Defining', 'defin'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('3', '3'), (':', ':'), ('Defining', 'defin'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]

>> Lemmatization: 
 [('Table', 'Table'), ('3', '3'), (':', ':'), ('Defining', 'Defining'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]



========================================== PARAGRAPH 464 ===========================================

  


========================================== PARAGRAPH 465 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 466 ===========================================

18  

------------------- Sentence 1 -------------------

18

>> Tokens are: 
 ['18']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('18', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('18', '18')]

>> Stemming using Snowball Stemmer: 
 [('18', '18')]

>> Lemmatization: 
 [('18', '18')]



========================================== PARAGRAPH 467 ===========================================

  


========================================== PARAGRAPH 468 ===========================================

7. Big data analytics (BDA): tools and methods  

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics (BDA): tools and methods

>> Tokens are: 
 ['Big', 'data', 'analytics', '(', 'BDA', ')', ':', 'tools', 'methods']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'BDA'), ('BDA', ')'), (')', ':'), (':', 'tools'), ('tools', 'methods')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'BDA'), ('(', 'BDA', ')'), ('BDA', ')', ':'), (')', ':', 'tools'), (':', 'tools', 'methods')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('BDA', 'NNP'), (')', ')'), (':', ':'), ('tools', 'NNS'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics', 'BDA', 'tools methods']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('BDA', 'BDA'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method')]



========================================== PARAGRAPH 469 ===========================================

7.1. Big data storage and management  

------------------- Sentence 1 -------------------

7.1.

>> Tokens are: 
 ['7.1', '.']

>> Bigrams are: 
 [('7.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1', '7.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1', '7.1'), ('.', '.')]

>> Lemmatization: 
 [('7.1', '7.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data storage and management

>> Tokens are: 
 ['Big', 'data', 'storage', 'management']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'storage'), ('storage', 'management')]

>> Trigrams are: 
 [('Big', 'data', 'storage'), ('data', 'storage', 'management')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN')]

>> Noun Phrases are: 
 ['Big data storage management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management')]



========================================== PARAGRAPH 470 ===========================================

The most difficult problem that needs to be solved to handle big data effectively is storage; it is  

------------------- Sentence 1 -------------------

The most difficult problem that needs to be solved to handle big data effectively is storage; it is

>> Tokens are: 
 ['The', 'difficult', 'problem', 'needs', 'solved', 'handle', 'big', 'data', 'effectively', 'storage', ';']

>> Bigrams are: 
 [('The', 'difficult'), ('difficult', 'problem'), ('problem', 'needs'), ('needs', 'solved'), ('solved', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'effectively'), ('effectively', 'storage'), ('storage', ';')]

>> Trigrams are: 
 [('The', 'difficult', 'problem'), ('difficult', 'problem', 'needs'), ('problem', 'needs', 'solved'), ('needs', 'solved', 'handle'), ('solved', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'effectively'), ('data', 'effectively', 'storage'), ('effectively', 'storage', ';')]

>> POS Tags are: 
 [('The', 'DT'), ('difficult', 'JJ'), ('problem', 'NN'), ('needs', 'VBZ'), ('solved', 'VBN'), ('handle', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('effectively', 'RB'), ('storage', 'NN'), (';', ':')]

>> Noun Phrases are: 
 ['The difficult problem', 'handle big data', 'storage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solv'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('effectively', 'effect'), ('storage', 'storag'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solv'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('effectively', 'effect'), ('storage', 'storag'), (';', ';')]

>> Lemmatization: 
 [('The', 'The'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solved'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('effectively', 'effectively'), ('storage', 'storage'), (';', ';')]



========================================== PARAGRAPH 471 ===========================================

not necessarily easy to deal with large quantities and varieties of data (Elgendy and Elragal, 2014;  

------------------- Sentence 1 -------------------

not necessarily easy to deal with large quantities and varieties of data (Elgendy and Elragal, 2014;

>> Tokens are: 
 ['necessarily', 'easy', 'deal', 'large', 'quantities', 'varieties', 'data', '(', 'Elgendy', 'Elragal', ',', '2014', ';']

>> Bigrams are: 
 [('necessarily', 'easy'), ('easy', 'deal'), ('deal', 'large'), ('large', 'quantities'), ('quantities', 'varieties'), ('varieties', 'data'), ('data', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';')]

>> Trigrams are: 
 [('necessarily', 'easy', 'deal'), ('easy', 'deal', 'large'), ('deal', 'large', 'quantities'), ('large', 'quantities', 'varieties'), ('quantities', 'varieties', 'data'), ('varieties', 'data', '('), ('data', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';')]

>> POS Tags are: 
 [('necessarily', 'RB'), ('easy', 'JJ'), ('deal', 'NN'), ('large', 'JJ'), ('quantities', 'NNS'), ('varieties', 'NNS'), ('data', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['easy deal', 'large quantities varieties data', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('necessarily', 'necessarili'), ('easy', 'easi'), ('deal', 'deal'), ('large', 'larg'), ('quantities', 'quantiti'), ('varieties', 'varieti'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('necessarily', 'necessarili'), ('easy', 'easi'), ('deal', 'deal'), ('large', 'larg'), ('quantities', 'quantiti'), ('varieties', 'varieti'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';')]

>> Lemmatization: 
 [('necessarily', 'necessarily'), ('easy', 'easy'), ('deal', 'deal'), ('large', 'large'), ('quantities', 'quantity'), ('varieties', 'variety'), ('data', 'data'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';')]



========================================== PARAGRAPH 472 ===========================================

Zhong, et al., 2016; Lv, Z. et al., 2017).   

------------------- Sentence 1 -------------------

Zhong, et al., 2016; Lv, Z. et al., 2017).

>> Tokens are: 
 ['Zhong', ',', 'et', 'al.', ',', '2016', ';', 'Lv', ',', 'Z.', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Zhong', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Lv'), ('Lv', ','), (',', 'Z.'), ('Z.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Zhong', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Lv'), (';', 'Lv', ','), ('Lv', ',', 'Z.'), (',', 'Z.', 'et'), ('Z.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Zhong', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Lv', 'NNP'), (',', ','), ('Z.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhong', 'al.', 'Lv', 'Z.', 'al.']

>> Named Entities are: 
 [('GPE', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'lv'), (',', ','), ('Z.', 'z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'lv'), (',', ','), ('Z.', 'z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Zhong', 'Zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'Lv'), (',', ','), ('Z.', 'Z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 473 ===========================================

There are many big data storage and analysis models. Where the large amount of data is caused by  

------------------- Sentence 1 -------------------

There are many big data storage and analysis models.

>> Tokens are: 
 ['There', 'many', 'big', 'data', 'storage', 'analysis', 'models', '.']

>> Bigrams are: 
 [('There', 'many'), ('many', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'analysis'), ('analysis', 'models'), ('models', '.')]

>> Trigrams are: 
 [('There', 'many', 'big'), ('many', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'analysis'), ('storage', 'analysis', 'models'), ('analysis', 'models', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('many', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('analysis', 'NN'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['many big data storage analysis models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('analysis', 'analysi'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('analysis', 'analysi'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('many', 'many'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('analysis', 'analysis'), ('models', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

Where the large amount of data is caused by

>> Tokens are: 
 ['Where', 'large', 'amount', 'data', 'caused']

>> Bigrams are: 
 [('Where', 'large'), ('large', 'amount'), ('amount', 'data'), ('data', 'caused')]

>> Trigrams are: 
 [('Where', 'large', 'amount'), ('large', 'amount', 'data'), ('amount', 'data', 'caused')]

>> POS Tags are: 
 [('Where', 'WRB'), ('large', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('caused', 'VBD')]

>> Noun Phrases are: 
 ['large amount data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caus')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caus')]

>> Lemmatization: 
 [('Where', 'Where'), ('large', 'large'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caused')]



========================================== PARAGRAPH 474 ===========================================

the sheer variety of users and devices, a data centre may be necessary for storing and processing  

------------------- Sentence 1 -------------------

the sheer variety of users and devices, a data centre may be necessary for storing and processing

>> Tokens are: 
 ['sheer', 'variety', 'users', 'devices', ',', 'data', 'centre', 'may', 'necessary', 'storing', 'processing']

>> Bigrams are: 
 [('sheer', 'variety'), ('variety', 'users'), ('users', 'devices'), ('devices', ','), (',', 'data'), ('data', 'centre'), ('centre', 'may'), ('may', 'necessary'), ('necessary', 'storing'), ('storing', 'processing')]

>> Trigrams are: 
 [('sheer', 'variety', 'users'), ('variety', 'users', 'devices'), ('users', 'devices', ','), ('devices', ',', 'data'), (',', 'data', 'centre'), ('data', 'centre', 'may'), ('centre', 'may', 'necessary'), ('may', 'necessary', 'storing'), ('necessary', 'storing', 'processing')]

>> POS Tags are: 
 [('sheer', 'NN'), ('variety', 'NN'), ('users', 'NNS'), ('devices', 'NNS'), (',', ','), ('data', 'NNS'), ('centre', 'NN'), ('may', 'MD'), ('necessary', 'JJ'), ('storing', 'NN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['sheer variety users devices', 'data centre', 'necessary storing processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sheer', 'sheer'), ('variety', 'varieti'), ('users', 'user'), ('devices', 'devic'), (',', ','), ('data', 'data'), ('centre', 'centr'), ('may', 'may'), ('necessary', 'necessari'), ('storing', 'store'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('sheer', 'sheer'), ('variety', 'varieti'), ('users', 'user'), ('devices', 'devic'), (',', ','), ('data', 'data'), ('centre', 'centr'), ('may', 'may'), ('necessary', 'necessari'), ('storing', 'store'), ('processing', 'process')]

>> Lemmatization: 
 [('sheer', 'sheer'), ('variety', 'variety'), ('users', 'user'), ('devices', 'device'), (',', ','), ('data', 'data'), ('centre', 'centre'), ('may', 'may'), ('necessary', 'necessary'), ('storing', 'storing'), ('processing', 'processing')]



========================================== PARAGRAPH 475 ===========================================

the data. Establishing network infrastructure is necessary to help gather this rapidly generated data,  

------------------- Sentence 1 -------------------

the data.

>> Tokens are: 
 ['data', '.']

>> Bigrams are: 
 [('data', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Establishing network infrastructure is necessary to help gather this rapidly generated data,

>> Tokens are: 
 ['Establishing', 'network', 'infrastructure', 'necessary', 'help', 'gather', 'rapidly', 'generated', 'data', ',']

>> Bigrams are: 
 [('Establishing', 'network'), ('network', 'infrastructure'), ('infrastructure', 'necessary'), ('necessary', 'help'), ('help', 'gather'), ('gather', 'rapidly'), ('rapidly', 'generated'), ('generated', 'data'), ('data', ',')]

>> Trigrams are: 
 [('Establishing', 'network', 'infrastructure'), ('network', 'infrastructure', 'necessary'), ('infrastructure', 'necessary', 'help'), ('necessary', 'help', 'gather'), ('help', 'gather', 'rapidly'), ('gather', 'rapidly', 'generated'), ('rapidly', 'generated', 'data'), ('generated', 'data', ',')]

>> POS Tags are: 
 [('Establishing', 'VBG'), ('network', 'NN'), ('infrastructure', 'NN'), ('necessary', 'JJ'), ('help', 'NN'), ('gather', 'VB'), ('rapidly', 'RB'), ('generated', 'VBN'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['network infrastructure', 'necessary help', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Establishing', 'establish'), ('network', 'network'), ('infrastructure', 'infrastructur'), ('necessary', 'necessari'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapidli'), ('generated', 'gener'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Establishing', 'establish'), ('network', 'network'), ('infrastructure', 'infrastructur'), ('necessary', 'necessari'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapid'), ('generated', 'generat'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('Establishing', 'Establishing'), ('network', 'network'), ('infrastructure', 'infrastructure'), ('necessary', 'necessary'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapidly'), ('generated', 'generated'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 476 ===========================================

which is then sent to the data centre before being accessed by users (Lv et al., 2017).  

------------------- Sentence 1 -------------------

which is then sent to the data centre before being accessed by users (Lv et al., 2017).

>> Tokens are: 
 ['sent', 'data', 'centre', 'accessed', 'users', '(', 'Lv', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('sent', 'data'), ('data', 'centre'), ('centre', 'accessed'), ('accessed', 'users'), ('users', '('), ('(', 'Lv'), ('Lv', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('sent', 'data', 'centre'), ('data', 'centre', 'accessed'), ('centre', 'accessed', 'users'), ('accessed', 'users', '('), ('users', '(', 'Lv'), ('(', 'Lv', 'et'), ('Lv', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('sent', 'VBN'), ('data', 'NNS'), ('centre', 'NNS'), ('accessed', 'VBD'), ('users', 'NNS'), ('(', '('), ('Lv', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data centre', 'users', 'Lv']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sent', 'sent'), ('data', 'data'), ('centre', 'centr'), ('accessed', 'access'), ('users', 'user'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sent', 'sent'), ('data', 'data'), ('centre', 'centr'), ('accessed', 'access'), ('users', 'user'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('sent', 'sent'), ('data', 'data'), ('centre', 'centre'), ('accessed', 'accessed'), ('users', 'user'), ('(', '('), ('Lv', 'Lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 477 ===========================================

Research by Yi et al. (2014) identifies the components of the network that must be established,  

------------------- Sentence 1 -------------------

Research by Yi et al.

>> Tokens are: 
 ['Research', 'Yi', 'et', 'al', '.']

>> Bigrams are: 
 [('Research', 'Yi'), ('Yi', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Research', 'Yi', 'et'), ('Yi', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Yi', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Research Yi', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Yi', 'yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Yi', 'yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Yi', 'Yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2014) identifies the components of the network that must be established,

>> Tokens are: 
 ['(', '2014', ')', 'identifies', 'components', 'network', 'must', 'established', ',']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'identifies'), ('identifies', 'components'), ('components', 'network'), ('network', 'must'), ('must', 'established'), ('established', ',')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'identifies'), (')', 'identifies', 'components'), ('identifies', 'components', 'network'), ('components', 'network', 'must'), ('network', 'must', 'established'), ('must', 'established', ',')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('identifies', 'VBZ'), ('components', 'NNS'), ('network', 'NN'), ('must', 'MD'), ('established', 'VB'), (',', ',')]

>> Noun Phrases are: 
 ['components network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifi'), ('components', 'compon'), ('network', 'network'), ('must', 'must'), ('established', 'establish'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifi'), ('components', 'compon'), ('network', 'network'), ('must', 'must'), ('established', 'establish'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifies'), ('components', 'component'), ('network', 'network'), ('must', 'must'), ('established', 'established'), (',', ',')]



========================================== PARAGRAPH 478 ===========================================

such as an original data network, the bridges used for connecting and transmitting to data centres,  

------------------- Sentence 1 -------------------

such as an original data network, the bridges used for connecting and transmitting to data centres,

>> Tokens are: 
 ['original', 'data', 'network', ',', 'bridges', 'used', 'connecting', 'transmitting', 'data', 'centres', ',']

>> Bigrams are: 
 [('original', 'data'), ('data', 'network'), ('network', ','), (',', 'bridges'), ('bridges', 'used'), ('used', 'connecting'), ('connecting', 'transmitting'), ('transmitting', 'data'), ('data', 'centres'), ('centres', ',')]

>> Trigrams are: 
 [('original', 'data', 'network'), ('data', 'network', ','), ('network', ',', 'bridges'), (',', 'bridges', 'used'), ('bridges', 'used', 'connecting'), ('used', 'connecting', 'transmitting'), ('connecting', 'transmitting', 'data'), ('transmitting', 'data', 'centres'), ('data', 'centres', ',')]

>> POS Tags are: 
 [('original', 'JJ'), ('data', 'NN'), ('network', 'NN'), (',', ','), ('bridges', 'NNS'), ('used', 'VBD'), ('connecting', 'VBG'), ('transmitting', 'VBG'), ('data', 'NNS'), ('centres', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['original data network', 'bridges', 'data centres']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('original', 'origin'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridg'), ('used', 'use'), ('connecting', 'connect'), ('transmitting', 'transmit'), ('data', 'data'), ('centres', 'centr'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('original', 'origin'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridg'), ('used', 'use'), ('connecting', 'connect'), ('transmitting', 'transmit'), ('data', 'data'), ('centres', 'centr'), (',', ',')]

>> Lemmatization: 
 [('original', 'original'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridge'), ('used', 'used'), ('connecting', 'connecting'), ('transmitting', 'transmitting'), ('data', 'data'), ('centres', 'centre'), (',', ',')]



========================================== PARAGRAPH 479 ===========================================

and at least one data centre.  

------------------- Sentence 1 -------------------

and at least one data centre.

>> Tokens are: 
 ['least', 'one', 'data', 'centre', '.']

>> Bigrams are: 
 [('least', 'one'), ('one', 'data'), ('data', 'centre'), ('centre', '.')]

>> Trigrams are: 
 [('least', 'one', 'data'), ('one', 'data', 'centre'), ('data', 'centre', '.')]

>> POS Tags are: 
 [('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('centre', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data centre']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centr'), ('.', '.')]

>> Lemmatization: 
 [('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centre'), ('.', '.')]



========================================== PARAGRAPH 480 ===========================================

Another study (H. Eszter, 2015) highlighted the issues in using big data through specific locations  

------------------- Sentence 1 -------------------

Another study (H. Eszter, 2015) highlighted the issues in using big data through specific locations

>> Tokens are: 
 ['Another', 'study', '(', 'H.', 'Eszter', ',', '2015', ')', 'highlighted', 'issues', 'using', 'big', 'data', 'specific', 'locations']

>> Bigrams are: 
 [('Another', 'study'), ('study', '('), ('(', 'H.'), ('H.', 'Eszter'), ('Eszter', ','), (',', '2015'), ('2015', ')'), (')', 'highlighted'), ('highlighted', 'issues'), ('issues', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'specific'), ('specific', 'locations')]

>> Trigrams are: 
 [('Another', 'study', '('), ('study', '(', 'H.'), ('(', 'H.', 'Eszter'), ('H.', 'Eszter', ','), ('Eszter', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'highlighted'), (')', 'highlighted', 'issues'), ('highlighted', 'issues', 'using'), ('issues', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'specific'), ('data', 'specific', 'locations')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('(', '('), ('H.', 'NNP'), ('Eszter', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('highlighted', 'VBD'), ('issues', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('specific', 'JJ'), ('locations', 'NNS')]

>> Noun Phrases are: 
 ['Another study', 'H. Eszter', 'issues', 'big data', 'specific locations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('(', '('), ('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlight'), ('issues', 'issu'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('specific', 'specif'), ('locations', 'locat')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('(', '('), ('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlight'), ('issues', 'issu'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('specific', 'specif'), ('locations', 'locat')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('(', '('), ('H.', 'H.'), ('Eszter', 'Eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlighted'), ('issues', 'issue'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('specific', 'specific'), ('locations', 'location')]



========================================== PARAGRAPH 481 ===========================================

and showed that the users could not select data through the data network. For storage models, the  

------------------- Sentence 1 -------------------

and showed that the users could not select data through the data network.

>> Tokens are: 
 ['showed', 'users', 'could', 'select', 'data', 'data', 'network', '.']

>> Bigrams are: 
 [('showed', 'users'), ('users', 'could'), ('could', 'select'), ('select', 'data'), ('data', 'data'), ('data', 'network'), ('network', '.')]

>> Trigrams are: 
 [('showed', 'users', 'could'), ('users', 'could', 'select'), ('could', 'select', 'data'), ('select', 'data', 'data'), ('data', 'data', 'network'), ('data', 'network', '.')]

>> POS Tags are: 
 [('showed', 'VBD'), ('users', 'NNS'), ('could', 'MD'), ('select', 'VB'), ('data', 'NNS'), ('data', 'NNS'), ('network', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['users', 'data data network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('showed', 'show'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('showed', 'show'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('showed', 'showed'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

For storage models, the

>> Tokens are: 
 ['For', 'storage', 'models', ',']

>> Bigrams are: 
 [('For', 'storage'), ('storage', 'models'), ('models', ',')]

>> Trigrams are: 
 [('For', 'storage', 'models'), ('storage', 'models', ',')]

>> POS Tags are: 
 [('For', 'IN'), ('storage', 'NN'), ('models', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['storage models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('storage', 'storag'), ('models', 'model'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('storage', 'storag'), ('models', 'model'), (',', ',')]

>> Lemmatization: 
 [('For', 'For'), ('storage', 'storage'), ('models', 'model'), (',', ',')]



========================================== PARAGRAPH 482 ===========================================

most important challenge is how to deal with the sheer amount of data, as ultra-scalable solutions  

------------------- Sentence 1 -------------------

most important challenge is how to deal with the sheer amount of data, as ultra-scalable solutions

>> Tokens are: 
 ['important', 'challenge', 'deal', 'sheer', 'amount', 'data', ',', 'ultra-scalable', 'solutions']

>> Bigrams are: 
 [('important', 'challenge'), ('challenge', 'deal'), ('deal', 'sheer'), ('sheer', 'amount'), ('amount', 'data'), ('data', ','), (',', 'ultra-scalable'), ('ultra-scalable', 'solutions')]

>> Trigrams are: 
 [('important', 'challenge', 'deal'), ('challenge', 'deal', 'sheer'), ('deal', 'sheer', 'amount'), ('sheer', 'amount', 'data'), ('amount', 'data', ','), ('data', ',', 'ultra-scalable'), (',', 'ultra-scalable', 'solutions')]

>> POS Tags are: 
 [('important', 'JJ'), ('challenge', 'NN'), ('deal', 'NN'), ('sheer', 'NN'), ('amount', 'NN'), ('data', 'NNS'), (',', ','), ('ultra-scalable', 'JJ'), ('solutions', 'NNS')]

>> Noun Phrases are: 
 ['important challenge deal sheer amount data', 'ultra-scalable solutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('challenge', 'challeng'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scal'), ('solutions', 'solut')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('challenge', 'challeng'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scal'), ('solutions', 'solut')]

>> Lemmatization: 
 [('important', 'important'), ('challenge', 'challenge'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scalable'), ('solutions', 'solution')]



========================================== PARAGRAPH 483 ===========================================

can block the processing of certain data sources, causing inefficiency. Building more scalable big  

------------------- Sentence 1 -------------------

can block the processing of certain data sources, causing inefficiency.

>> Tokens are: 
 ['block', 'processing', 'certain', 'data', 'sources', ',', 'causing', 'inefficiency', '.']

>> Bigrams are: 
 [('block', 'processing'), ('processing', 'certain'), ('certain', 'data'), ('data', 'sources'), ('sources', ','), (',', 'causing'), ('causing', 'inefficiency'), ('inefficiency', '.')]

>> Trigrams are: 
 [('block', 'processing', 'certain'), ('processing', 'certain', 'data'), ('certain', 'data', 'sources'), ('data', 'sources', ','), ('sources', ',', 'causing'), (',', 'causing', 'inefficiency'), ('causing', 'inefficiency', '.')]

>> POS Tags are: 
 [('block', 'NN'), ('processing', 'NN'), ('certain', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), (',', ','), ('causing', 'VBG'), ('inefficiency', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['block processing', 'certain data sources', 'inefficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('block', 'block'), ('processing', 'process'), ('certain', 'certain'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('causing', 'caus'), ('inefficiency', 'ineffici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('block', 'block'), ('processing', 'process'), ('certain', 'certain'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('causing', 'caus'), ('inefficiency', 'ineffici'), ('.', '.')]

>> Lemmatization: 
 [('block', 'block'), ('processing', 'processing'), ('certain', 'certain'), ('data', 'data'), ('sources', 'source'), (',', ','), ('causing', 'causing'), ('inefficiency', 'inefficiency'), ('.', '.')]


------------------- Sentence 2 -------------------

Building more scalable big

>> Tokens are: 
 ['Building', 'scalable', 'big']

>> Bigrams are: 
 [('Building', 'scalable'), ('scalable', 'big')]

>> Trigrams are: 
 [('Building', 'scalable', 'big')]

>> POS Tags are: 
 [('Building', 'VBG'), ('scalable', 'JJ'), ('big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Building', 'build'), ('scalable', 'scalabl'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Building', 'build'), ('scalable', 'scalabl'), ('big', 'big')]

>> Lemmatization: 
 [('Building', 'Building'), ('scalable', 'scalable'), ('big', 'big')]



========================================== PARAGRAPH 484 ===========================================

data technology is a challenge, and any new technology must offer data gathering and distribution  

------------------- Sentence 1 -------------------

data technology is a challenge, and any new technology must offer data gathering and distribution

>> Tokens are: 
 ['data', 'technology', 'challenge', ',', 'new', 'technology', 'must', 'offer', 'data', 'gathering', 'distribution']

>> Bigrams are: 
 [('data', 'technology'), ('technology', 'challenge'), ('challenge', ','), (',', 'new'), ('new', 'technology'), ('technology', 'must'), ('must', 'offer'), ('offer', 'data'), ('data', 'gathering'), ('gathering', 'distribution')]

>> Trigrams are: 
 [('data', 'technology', 'challenge'), ('technology', 'challenge', ','), ('challenge', ',', 'new'), (',', 'new', 'technology'), ('new', 'technology', 'must'), ('technology', 'must', 'offer'), ('must', 'offer', 'data'), ('offer', 'data', 'gathering'), ('data', 'gathering', 'distribution')]

>> POS Tags are: 
 [('data', 'NNS'), ('technology', 'NN'), ('challenge', 'NN'), (',', ','), ('new', 'JJ'), ('technology', 'NN'), ('must', 'MD'), ('offer', 'VB'), ('data', 'NNS'), ('gathering', 'VBG'), ('distribution', 'NN')]

>> Noun Phrases are: 
 ['data technology challenge', 'new technology', 'data', 'distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('technology', 'technolog'), ('challenge', 'challeng'), (',', ','), ('new', 'new'), ('technology', 'technolog'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gather'), ('distribution', 'distribut')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('technology', 'technolog'), ('challenge', 'challeng'), (',', ','), ('new', 'new'), ('technology', 'technolog'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gather'), ('distribution', 'distribut')]

>> Lemmatization: 
 [('data', 'data'), ('technology', 'technology'), ('challenge', 'challenge'), (',', ','), ('new', 'new'), ('technology', 'technology'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gathering'), ('distribution', 'distribution')]



========================================== PARAGRAPH 485 ===========================================

among nodes spread through the world (Lv et al., 2017).  

------------------- Sentence 1 -------------------

among nodes spread through the world (Lv et al., 2017).

>> Tokens are: 
 ['among', 'nodes', 'spread', 'world', '(', 'Lv', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('among', 'nodes'), ('nodes', 'spread'), ('spread', 'world'), ('world', '('), ('(', 'Lv'), ('Lv', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('among', 'nodes', 'spread'), ('nodes', 'spread', 'world'), ('spread', 'world', '('), ('world', '(', 'Lv'), ('(', 'Lv', 'et'), ('Lv', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('among', 'IN'), ('nodes', 'NNS'), ('spread', 'JJ'), ('world', 'NN'), ('(', '('), ('Lv', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['nodes', 'spread world', 'Lv']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'Lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 486 ===========================================

Structured data storage and retrieval methods include “relational databases, data marts, and data  

------------------- Sentence 1 -------------------

Structured data storage and retrieval methods include “relational databases, data marts, and data

>> Tokens are: 
 ['Structured', 'data', 'storage', 'retrieval', 'methods', 'include', '“', 'relational', 'databases', ',', 'data', 'marts', ',', 'data']

>> Bigrams are: 
 [('Structured', 'data'), ('data', 'storage'), ('storage', 'retrieval'), ('retrieval', 'methods'), ('methods', 'include'), ('include', '“'), ('“', 'relational'), ('relational', 'databases'), ('databases', ','), (',', 'data'), ('data', 'marts'), ('marts', ','), (',', 'data')]

>> Trigrams are: 
 [('Structured', 'data', 'storage'), ('data', 'storage', 'retrieval'), ('storage', 'retrieval', 'methods'), ('retrieval', 'methods', 'include'), ('methods', 'include', '“'), ('include', '“', 'relational'), ('“', 'relational', 'databases'), ('relational', 'databases', ','), ('databases', ',', 'data'), (',', 'data', 'marts'), ('data', 'marts', ','), ('marts', ',', 'data')]

>> POS Tags are: 
 [('Structured', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('retrieval', 'NN'), ('methods', 'NNS'), ('include', 'VBP'), ('“', 'JJ'), ('relational', 'JJ'), ('databases', 'NNS'), (',', ','), ('data', 'NNS'), ('marts', 'NNS'), (',', ','), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Structured data storage retrieval methods', '“ relational databases', 'data marts', 'data']

>> Named Entities are: 
 [('GPE', 'Structured')] 

>> Stemming using Porter Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('storage', 'storag'), ('retrieval', 'retriev'), ('methods', 'method'), ('include', 'includ'), ('“', '“'), ('relational', 'relat'), ('databases', 'databas'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('storage', 'storag'), ('retrieval', 'retriev'), ('methods', 'method'), ('include', 'includ'), ('“', '“'), ('relational', 'relat'), ('databases', 'databas'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data')]

>> Lemmatization: 
 [('Structured', 'Structured'), ('data', 'data'), ('storage', 'storage'), ('retrieval', 'retrieval'), ('methods', 'method'), ('include', 'include'), ('“', '“'), ('relational', 'relational'), ('databases', 'database'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data')]



========================================== PARAGRAPH 487 ===========================================

warehouses” (Elgendy, N. and Elragal, A., 2014). Data is extracted from outside sources, then  

------------------- Sentence 1 -------------------

warehouses” (Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['warehouses', '”', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('warehouses', '”'), ('”', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('warehouses', '”', '('), ('”', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('warehouses', 'NNS'), ('”', 'NNP'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['warehouses ”', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('warehouses', 'warehous'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('warehouses', 'warehous'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('warehouses', 'warehouse'), ('”', '”'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Data is extracted from outside sources, then

>> Tokens are: 
 ['Data', 'extracted', 'outside', 'sources', ',']

>> Bigrams are: 
 [('Data', 'extracted'), ('extracted', 'outside'), ('outside', 'sources'), ('sources', ',')]

>> Trigrams are: 
 [('Data', 'extracted', 'outside'), ('extracted', 'outside', 'sources'), ('outside', 'sources', ',')]

>> POS Tags are: 
 [('Data', 'NNP'), ('extracted', 'VBD'), ('outside', 'JJ'), ('sources', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Data', 'outside sources']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('extracted', 'extract'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('extracted', 'extract'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ',')]

>> Lemmatization: 
 [('Data', 'Data'), ('extracted', 'extracted'), ('outside', 'outside'), ('sources', 'source'), (',', ',')]



========================================== PARAGRAPH 488 ===========================================

transformed to fit operational needs, and finally loaded into the database. The data is then uploaded  

------------------- Sentence 1 -------------------

transformed to fit operational needs, and finally loaded into the database.

>> Tokens are: 
 ['transformed', 'fit', 'operational', 'needs', ',', 'finally', 'loaded', 'database', '.']

>> Bigrams are: 
 [('transformed', 'fit'), ('fit', 'operational'), ('operational', 'needs'), ('needs', ','), (',', 'finally'), ('finally', 'loaded'), ('loaded', 'database'), ('database', '.')]

>> Trigrams are: 
 [('transformed', 'fit', 'operational'), ('fit', 'operational', 'needs'), ('operational', 'needs', ','), ('needs', ',', 'finally'), (',', 'finally', 'loaded'), ('finally', 'loaded', 'database'), ('loaded', 'database', '.')]

>> POS Tags are: 
 [('transformed', 'VBN'), ('fit', 'JJ'), ('operational', 'JJ'), ('needs', 'NNS'), (',', ','), ('finally', 'RB'), ('loaded', 'JJ'), ('database', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['fit operational needs', 'loaded database']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('transformed', 'transform'), ('fit', 'fit'), ('operational', 'oper'), ('needs', 'need'), (',', ','), ('finally', 'final'), ('loaded', 'load'), ('database', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('transformed', 'transform'), ('fit', 'fit'), ('operational', 'oper'), ('needs', 'need'), (',', ','), ('finally', 'final'), ('loaded', 'load'), ('database', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('transformed', 'transformed'), ('fit', 'fit'), ('operational', 'operational'), ('needs', 'need'), (',', ','), ('finally', 'finally'), ('loaded', 'loaded'), ('database', 'database'), ('.', '.')]


------------------- Sentence 2 -------------------

The data is then uploaded

>> Tokens are: 
 ['The', 'data', 'uploaded']

>> Bigrams are: 
 [('The', 'data'), ('data', 'uploaded')]

>> Trigrams are: 
 [('The', 'data', 'uploaded')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('uploaded', 'VBD')]

>> Noun Phrases are: 
 ['The data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('uploaded', 'upload')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('uploaded', 'upload')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('uploaded', 'uploaded')]



========================================== PARAGRAPH 489 ===========================================

from the operational data store to longer-term storage using Extract, Transform, Load (ETL) or  

------------------- Sentence 1 -------------------

from the operational data store to longer-term storage using Extract, Transform, Load (ETL) or

>> Tokens are: 
 ['operational', 'data', 'store', 'longer-term', 'storage', 'using', 'Extract', ',', 'Transform', ',', 'Load', '(', 'ETL', ')']

>> Bigrams are: 
 [('operational', 'data'), ('data', 'store'), ('store', 'longer-term'), ('longer-term', 'storage'), ('storage', 'using'), ('using', 'Extract'), ('Extract', ','), (',', 'Transform'), ('Transform', ','), (',', 'Load'), ('Load', '('), ('(', 'ETL'), ('ETL', ')')]

>> Trigrams are: 
 [('operational', 'data', 'store'), ('data', 'store', 'longer-term'), ('store', 'longer-term', 'storage'), ('longer-term', 'storage', 'using'), ('storage', 'using', 'Extract'), ('using', 'Extract', ','), ('Extract', ',', 'Transform'), (',', 'Transform', ','), ('Transform', ',', 'Load'), (',', 'Load', '('), ('Load', '(', 'ETL'), ('(', 'ETL', ')')]

>> POS Tags are: 
 [('operational', 'JJ'), ('data', 'NNS'), ('store', 'RB'), ('longer-term', 'JJ'), ('storage', 'NN'), ('using', 'VBG'), ('Extract', 'NNP'), (',', ','), ('Transform', 'NNP'), (',', ','), ('Load', 'NNP'), ('(', '('), ('ETL', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['operational data', 'longer-term storage', 'Extract', 'Transform', 'Load', 'ETL']

>> Named Entities are: 
 [('PERSON', 'Extract'), ('PERSON', 'Transform'), ('GPE', 'Load'), ('ORGANIZATION', 'ETL')] 

>> Stemming using Porter Stemmer: 
 [('operational', 'oper'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storag'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('(', '('), ('ETL', 'etl'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('operational', 'oper'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storag'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('(', '('), ('ETL', 'etl'), (')', ')')]

>> Lemmatization: 
 [('operational', 'operational'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storage'), ('using', 'using'), ('Extract', 'Extract'), (',', ','), ('Transform', 'Transform'), (',', ','), ('Load', 'Load'), ('(', '('), ('ETL', 'ETL'), (')', ')')]



========================================== PARAGRAPH 490 ===========================================

Extract, Load, Transform (ELT) tools. The data is then cleaned, transformed, and catalogued  

------------------- Sentence 1 -------------------

Extract, Load, Transform (ELT) tools.

>> Tokens are: 
 ['Extract', ',', 'Load', ',', 'Transform', '(', 'ELT', ')', 'tools', '.']

>> Bigrams are: 
 [('Extract', ','), (',', 'Load'), ('Load', ','), (',', 'Transform'), ('Transform', '('), ('(', 'ELT'), ('ELT', ')'), (')', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Extract', ',', 'Load'), (',', 'Load', ','), ('Load', ',', 'Transform'), (',', 'Transform', '('), ('Transform', '(', 'ELT'), ('(', 'ELT', ')'), ('ELT', ')', 'tools'), (')', 'tools', '.')]

>> POS Tags are: 
 [('Extract', 'NNP'), (',', ','), ('Load', 'NNP'), (',', ','), ('Transform', 'NNP'), ('(', '('), ('ELT', 'NNP'), (')', ')'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Extract', 'Load', 'Transform', 'ELT', 'tools']

>> Named Entities are: 
 [('GPE', 'Extract'), ('PERSON', 'Load'), ('GPE', 'Transform'), ('ORGANIZATION', 'ELT')] 

>> Stemming using Porter Stemmer: 
 [('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ELT', 'elt'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ELT', 'elt'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Extract', 'Extract'), (',', ','), ('Load', 'Load'), (',', ','), ('Transform', 'Transform'), ('(', '('), ('ELT', 'ELT'), (')', ')'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

The data is then cleaned, transformed, and catalogued

>> Tokens are: 
 ['The', 'data', 'cleaned', ',', 'transformed', ',', 'catalogued']

>> Bigrams are: 
 [('The', 'data'), ('data', 'cleaned'), ('cleaned', ','), (',', 'transformed'), ('transformed', ','), (',', 'catalogued')]

>> Trigrams are: 
 [('The', 'data', 'cleaned'), ('data', 'cleaned', ','), ('cleaned', ',', 'transformed'), (',', 'transformed', ','), ('transformed', ',', 'catalogued')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('cleaned', 'VBD'), (',', ','), ('transformed', 'VBD'), (',', ','), ('catalogued', 'VBD')]

>> Noun Phrases are: 
 ['The data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('cleaned', 'clean'), (',', ','), ('transformed', 'transform'), (',', ','), ('catalogued', 'catalogu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('cleaned', 'clean'), (',', ','), ('transformed', 'transform'), (',', ','), ('catalogued', 'catalogu')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('cleaned', 'cleaned'), (',', ','), ('transformed', 'transformed'), (',', ','), ('catalogued', 'catalogued')]



========================================== PARAGRAPH 491 ===========================================

before use (Bakshi, 2012; Elgendy and Elragal, 2014).  

------------------- Sentence 1 -------------------

before use (Bakshi, 2012; Elgendy and Elragal, 2014).

>> Tokens are: 
 ['use', '(', 'Bakshi', ',', '2012', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('use', '('), ('(', 'Bakshi'), ('Bakshi', ','), (',', '2012'), ('2012', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('use', '(', 'Bakshi'), ('(', 'Bakshi', ','), ('Bakshi', ',', '2012'), (',', '2012', ';'), ('2012', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('use', 'NN'), ('(', '('), ('Bakshi', 'NNP'), (',', ','), ('2012', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['use', 'Bakshi', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Bakshi'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('use', 'use'), ('(', '('), ('Bakshi', 'bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('use', 'use'), ('(', '('), ('Bakshi', 'bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('use', 'use'), ('(', '('), ('Bakshi', 'Bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 492 ===========================================

  


========================================== PARAGRAPH 493 ===========================================

A big data environment requires analysis skills, unlike the Enterprise Data Warehouse (EDW)  

------------------- Sentence 1 -------------------

A big data environment requires analysis skills, unlike the Enterprise Data Warehouse (EDW)

>> Tokens are: 
 ['A', 'big', 'data', 'environment', 'requires', 'analysis', 'skills', ',', 'unlike', 'Enterprise', 'Data', 'Warehouse', '(', 'EDW', ')']

>> Bigrams are: 
 [('A', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', 'requires'), ('requires', 'analysis'), ('analysis', 'skills'), ('skills', ','), (',', 'unlike'), ('unlike', 'Enterprise'), ('Enterprise', 'Data'), ('Data', 'Warehouse'), ('Warehouse', '('), ('(', 'EDW'), ('EDW', ')')]

>> Trigrams are: 
 [('A', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', 'requires'), ('environment', 'requires', 'analysis'), ('requires', 'analysis', 'skills'), ('analysis', 'skills', ','), ('skills', ',', 'unlike'), (',', 'unlike', 'Enterprise'), ('unlike', 'Enterprise', 'Data'), ('Enterprise', 'Data', 'Warehouse'), ('Data', 'Warehouse', '('), ('Warehouse', '(', 'EDW'), ('(', 'EDW', ')')]

>> POS Tags are: 
 [('A', 'DT'), ('big', 'JJ'), ('data', 'NN'), ('environment', 'NN'), ('requires', 'VBZ'), ('analysis', 'NN'), ('skills', 'NNS'), (',', ','), ('unlike', 'IN'), ('Enterprise', 'NNP'), ('Data', 'NNP'), ('Warehouse', 'NNP'), ('(', '('), ('EDW', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['A big data environment', 'analysis skills', 'Enterprise Data Warehouse', 'EDW']

>> Named Entities are: 
 [('PERSON', 'Enterprise Data Warehouse'), ('ORGANIZATION', 'EDW')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('requires', 'requir'), ('analysis', 'analysi'), ('skills', 'skill'), (',', ','), ('unlike', 'unlik'), ('Enterprise', 'enterpris'), ('Data', 'data'), ('Warehouse', 'warehous'), ('(', '('), ('EDW', 'edw'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('requires', 'requir'), ('analysis', 'analysi'), ('skills', 'skill'), (',', ','), ('unlike', 'unlik'), ('Enterprise', 'enterpris'), ('Data', 'data'), ('Warehouse', 'warehous'), ('(', '('), ('EDW', 'edw'), (')', ')')]

>> Lemmatization: 
 [('A', 'A'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('requires', 'requires'), ('analysis', 'analysis'), ('skills', 'skill'), (',', ','), ('unlike', 'unlike'), ('Enterprise', 'Enterprise'), ('Data', 'Data'), ('Warehouse', 'Warehouse'), ('(', '('), ('EDW', 'EDW'), (')', ')')]



========================================== PARAGRAPH 494 ===========================================

traditional environment (Hartmann, T. et al., 2019).  

------------------- Sentence 1 -------------------

traditional environment (Hartmann, T. et al., 2019).

>> Tokens are: 
 ['traditional', 'environment', '(', 'Hartmann', ',', 'T.', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('traditional', 'environment'), ('environment', '('), ('(', 'Hartmann'), ('Hartmann', ','), (',', 'T.'), ('T.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('traditional', 'environment', '('), ('environment', '(', 'Hartmann'), ('(', 'Hartmann', ','), ('Hartmann', ',', 'T.'), (',', 'T.', 'et'), ('T.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('traditional', 'JJ'), ('environment', 'NN'), ('(', '('), ('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional environment', 'Hartmann', 'T.', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('traditional', 'tradit'), ('environment', 'environ'), ('(', '('), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('traditional', 'tradit'), ('environment', 'environ'), ('(', '('), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('traditional', 'traditional'), ('environment', 'environment'), ('(', '('), ('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 495 ===========================================

  


========================================== PARAGRAPH 496 ===========================================

➢ The big data environment accepts and demands all possible data sources. On the other  hand, EDW approaches data sources with caution, as it is more streamlined towards  

------------------- Sentence 1 -------------------

➢ The big data environment accepts and demands all possible data sources.

>> Tokens are: 
 ['➢', 'The', 'big', 'data', 'environment', 'accepts', 'demands', 'possible', 'data', 'sources', '.']

>> Bigrams are: 
 [('➢', 'The'), ('The', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', 'accepts'), ('accepts', 'demands'), ('demands', 'possible'), ('possible', 'data'), ('data', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('➢', 'The', 'big'), ('The', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', 'accepts'), ('environment', 'accepts', 'demands'), ('accepts', 'demands', 'possible'), ('demands', 'possible', 'data'), ('possible', 'data', 'sources'), ('data', 'sources', '.')]

>> POS Tags are: 
 [('➢', 'IN'), ('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('accepts', 'NNS'), ('demands', 'VBZ'), ('possible', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The big data environment accepts', 'possible data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('accepts', 'accept'), ('demands', 'demand'), ('possible', 'possibl'), ('data', 'data'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('accepts', 'accept'), ('demands', 'demand'), ('possible', 'possibl'), ('data', 'data'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('The', 'The'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('accepts', 'accepts'), ('demands', 'demand'), ('possible', 'possible'), ('data', 'data'), ('sources', 'source'), ('.', '.')]


------------------- Sentence 2 -------------------

On the other  hand, EDW approaches data sources with caution, as it is more streamlined towards

>> Tokens are: 
 ['On', 'hand', ',', 'EDW', 'approaches', 'data', 'sources', 'caution', ',', 'streamlined', 'towards']

>> Bigrams are: 
 [('On', 'hand'), ('hand', ','), (',', 'EDW'), ('EDW', 'approaches'), ('approaches', 'data'), ('data', 'sources'), ('sources', 'caution'), ('caution', ','), (',', 'streamlined'), ('streamlined', 'towards')]

>> Trigrams are: 
 [('On', 'hand', ','), ('hand', ',', 'EDW'), (',', 'EDW', 'approaches'), ('EDW', 'approaches', 'data'), ('approaches', 'data', 'sources'), ('data', 'sources', 'caution'), ('sources', 'caution', ','), ('caution', ',', 'streamlined'), (',', 'streamlined', 'towards')]

>> POS Tags are: 
 [('On', 'IN'), ('hand', 'NN'), (',', ','), ('EDW', 'NNP'), ('approaches', 'VBZ'), ('data', 'NNS'), ('sources', 'NNS'), ('caution', 'NN'), (',', ','), ('streamlined', 'VBD'), ('towards', 'NNS')]

>> Noun Phrases are: 
 ['hand', 'EDW', 'data sources caution', 'towards']

>> Named Entities are: 
 [('ORGANIZATION', 'EDW')] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('EDW', 'edw'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'sourc'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlin'), ('towards', 'toward')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('EDW', 'edw'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'sourc'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlin'), ('towards', 'toward')]

>> Lemmatization: 
 [('On', 'On'), ('hand', 'hand'), (',', ','), ('EDW', 'EDW'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'source'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlined'), ('towards', 'towards')]



========================================== PARAGRAPH 497 ===========================================

supporting structured data (Elgendy and Elragal, 2014; Hartmann et al., 2019).  

------------------- Sentence 1 -------------------

supporting structured data (Elgendy and Elragal, 2014; Hartmann et al., 2019).

>> Tokens are: 
 ['supporting', 'structured', 'data', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('supporting', 'structured'), ('structured', 'data'), ('data', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('supporting', 'structured', 'data'), ('structured', 'data', '('), ('data', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', 'et'), ('Hartmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('supporting', 'VBG'), ('structured', 'VBN'), ('data', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'Elgendy Elragal', 'Hartmann', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('supporting', 'support'), ('structured', 'structur'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('supporting', 'support'), ('structured', 'structur'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('supporting', 'supporting'), ('structured', 'structured'), ('data', 'data'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 498 ===========================================

  


========================================== PARAGRAPH 499 ===========================================

➢ Due to increasing number of data sources and data analyses possible, big data storage  requires agile databases to give analysts the opportunity to produce and adapt to data easily  

------------------- Sentence 1 -------------------

➢ Due to increasing number of data sources and data analyses possible, big data storage  requires agile databases to give analysts the opportunity to produce and adapt to data easily

>> Tokens are: 
 ['➢', 'Due', 'increasing', 'number', 'data', 'sources', 'data', 'analyses', 'possible', ',', 'big', 'data', 'storage', 'requires', 'agile', 'databases', 'give', 'analysts', 'opportunity', 'produce', 'adapt', 'data', 'easily']

>> Bigrams are: 
 [('➢', 'Due'), ('Due', 'increasing'), ('increasing', 'number'), ('number', 'data'), ('data', 'sources'), ('sources', 'data'), ('data', 'analyses'), ('analyses', 'possible'), ('possible', ','), (',', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'requires'), ('requires', 'agile'), ('agile', 'databases'), ('databases', 'give'), ('give', 'analysts'), ('analysts', 'opportunity'), ('opportunity', 'produce'), ('produce', 'adapt'), ('adapt', 'data'), ('data', 'easily')]

>> Trigrams are: 
 [('➢', 'Due', 'increasing'), ('Due', 'increasing', 'number'), ('increasing', 'number', 'data'), ('number', 'data', 'sources'), ('data', 'sources', 'data'), ('sources', 'data', 'analyses'), ('data', 'analyses', 'possible'), ('analyses', 'possible', ','), ('possible', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'requires'), ('storage', 'requires', 'agile'), ('requires', 'agile', 'databases'), ('agile', 'databases', 'give'), ('databases', 'give', 'analysts'), ('give', 'analysts', 'opportunity'), ('analysts', 'opportunity', 'produce'), ('opportunity', 'produce', 'adapt'), ('produce', 'adapt', 'data'), ('adapt', 'data', 'easily')]

>> POS Tags are: 
 [('➢', 'NNS'), ('Due', 'NNP'), ('increasing', 'VBG'), ('number', 'NN'), ('data', 'NNS'), ('sources', 'NNS'), ('data', 'VBP'), ('analyses', 'NNS'), ('possible', 'JJ'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('requires', 'VBZ'), ('agile', 'JJ'), ('databases', 'NNS'), ('give', 'VBP'), ('analysts', 'NNS'), ('opportunity', 'NN'), ('produce', 'VBP'), ('adapt', 'JJ'), ('data', 'NNS'), ('easily', 'RB')]

>> Noun Phrases are: 
 ['➢ Due', 'number data sources', 'analyses', 'big data storage', 'agile databases', 'analysts opportunity', 'adapt data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('Due', 'due'), ('increasing', 'increas'), ('number', 'number'), ('data', 'data'), ('sources', 'sourc'), ('data', 'data'), ('analyses', 'analys'), ('possible', 'possibl'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('requires', 'requir'), ('agile', 'agil'), ('databases', 'databas'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportun'), ('produce', 'produc'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easili')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('Due', 'due'), ('increasing', 'increas'), ('number', 'number'), ('data', 'data'), ('sources', 'sourc'), ('data', 'data'), ('analyses', 'analys'), ('possible', 'possibl'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('requires', 'requir'), ('agile', 'agil'), ('databases', 'databas'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportun'), ('produce', 'produc'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easili')]

>> Lemmatization: 
 [('➢', '➢'), ('Due', 'Due'), ('increasing', 'increasing'), ('number', 'number'), ('data', 'data'), ('sources', 'source'), ('data', 'data'), ('analyses', 'analysis'), ('possible', 'possible'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('requires', 'requires'), ('agile', 'agile'), ('databases', 'database'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportunity'), ('produce', 'produce'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easily')]



========================================== PARAGRAPH 500 ===========================================

and quickly (Elgendy and Elragal, 2014; Hartmann et al., 2019).  

------------------- Sentence 1 -------------------

and quickly (Elgendy and Elragal, 2014; Hartmann et al., 2019).

>> Tokens are: 
 ['quickly', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('quickly', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('quickly', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', 'et'), ('Hartmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('quickly', 'RB'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy Elragal', 'Hartmann', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('quickly', 'quickli'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('quickly', 'quick'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('quickly', 'quickly'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 501 ===========================================

  


========================================== PARAGRAPH 502 ===========================================

➢ A big data repository must be deep, allowing analysts to analyse the datasets deeply by  using complex statistical methods (Elgendy and Elragal, 2014; Hartmann, T. et al., 2019).  

------------------- Sentence 1 -------------------

➢ A big data repository must be deep, allowing analysts to analyse the datasets deeply by  using complex statistical methods (Elgendy and Elragal, 2014; Hartmann, T. et al., 2019).

>> Tokens are: 
 ['➢', 'A', 'big', 'data', 'repository', 'must', 'deep', ',', 'allowing', 'analysts', 'analyse', 'datasets', 'deeply', 'using', 'complex', 'statistical', 'methods', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', ',', 'T.', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('➢', 'A'), ('A', 'big'), ('big', 'data'), ('data', 'repository'), ('repository', 'must'), ('must', 'deep'), ('deep', ','), (',', 'allowing'), ('allowing', 'analysts'), ('analysts', 'analyse'), ('analyse', 'datasets'), ('datasets', 'deeply'), ('deeply', 'using'), ('using', 'complex'), ('complex', 'statistical'), ('statistical', 'methods'), ('methods', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', ','), (',', 'T.'), ('T.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('➢', 'A', 'big'), ('A', 'big', 'data'), ('big', 'data', 'repository'), ('data', 'repository', 'must'), ('repository', 'must', 'deep'), ('must', 'deep', ','), ('deep', ',', 'allowing'), (',', 'allowing', 'analysts'), ('allowing', 'analysts', 'analyse'), ('analysts', 'analyse', 'datasets'), ('analyse', 'datasets', 'deeply'), ('datasets', 'deeply', 'using'), ('deeply', 'using', 'complex'), ('using', 'complex', 'statistical'), ('complex', 'statistical', 'methods'), ('statistical', 'methods', '('), ('methods', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', ','), ('Hartmann', ',', 'T.'), (',', 'T.', 'et'), ('T.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('➢', 'VB'), ('A', 'DT'), ('big', 'JJ'), ('data', 'NN'), ('repository', 'NN'), ('must', 'MD'), ('deep', 'VB'), (',', ','), ('allowing', 'VBG'), ('analysts', 'NNS'), ('analyse', 'VBP'), ('datasets', 'NNS'), ('deeply', 'RB'), ('using', 'VBG'), ('complex', 'JJ'), ('statistical', 'JJ'), ('methods', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['A big data repository', 'analysts', 'datasets', 'complex statistical methods', 'Elgendy Elragal', 'Hartmann', 'T.', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('repository', 'repositori'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allow'), ('analysts', 'analyst'), ('analyse', 'analys'), ('datasets', 'dataset'), ('deeply', 'deepli'), ('using', 'use'), ('complex', 'complex'), ('statistical', 'statist'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('repository', 'repositori'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allow'), ('analysts', 'analyst'), ('analyse', 'analys'), ('datasets', 'dataset'), ('deeply', 'deepli'), ('using', 'use'), ('complex', 'complex'), ('statistical', 'statist'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('A', 'A'), ('big', 'big'), ('data', 'data'), ('repository', 'repository'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allowing'), ('analysts', 'analyst'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('deeply', 'deeply'), ('using', 'using'), ('complex', 'complex'), ('statistical', 'statistical'), ('methods', 'method'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 503 ===========================================

  


========================================== PARAGRAPH 504 ===========================================

Hadoop is a popular big data analytics framework. Hadoop “provides reliability, scalability, and  

------------------- Sentence 1 -------------------

Hadoop is a popular big data analytics framework.

>> Tokens are: 
 ['Hadoop', 'popular', 'big', 'data', 'analytics', 'framework', '.']

>> Bigrams are: 
 [('Hadoop', 'popular'), ('popular', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'framework'), ('framework', '.')]

>> Trigrams are: 
 [('Hadoop', 'popular', 'big'), ('popular', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'framework'), ('analytics', 'framework', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('popular', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('framework', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hadoop', 'popular big data analytics framework']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('framework', 'framework'), ('.', '.')]


------------------- Sentence 2 -------------------

Hadoop “provides reliability, scalability, and

>> Tokens are: 
 ['Hadoop', '“', 'provides', 'reliability', ',', 'scalability', ',']

>> Bigrams are: 
 [('Hadoop', '“'), ('“', 'provides'), ('provides', 'reliability'), ('reliability', ','), (',', 'scalability'), ('scalability', ',')]

>> Trigrams are: 
 [('Hadoop', '“', 'provides'), ('“', 'provides', 'reliability'), ('provides', 'reliability', ','), ('reliability', ',', 'scalability'), (',', 'scalability', ',')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('“', 'NNP'), ('provides', 'VBZ'), ('reliability', 'NN'), (',', ','), ('scalability', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Hadoop “', 'reliability', 'scalability']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('“', '“'), ('provides', 'provid'), ('reliability', 'reliabl'), (',', ','), ('scalability', 'scalabl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('“', '“'), ('provides', 'provid'), ('reliability', 'reliabl'), (',', ','), ('scalability', 'scalabl'), (',', ',')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('“', '“'), ('provides', 'provides'), ('reliability', 'reliability'), (',', ','), ('scalability', 'scalability'), (',', ',')]



========================================== PARAGRAPH 505 ===========================================

manageability by providing an implementation for the MapReduce paradigm as well as gluing the  

------------------- Sentence 1 -------------------

manageability by providing an implementation for the MapReduce paradigm as well as gluing the

>> Tokens are: 
 ['manageability', 'providing', 'implementation', 'MapReduce', 'paradigm', 'well', 'gluing']

>> Bigrams are: 
 [('manageability', 'providing'), ('providing', 'implementation'), ('implementation', 'MapReduce'), ('MapReduce', 'paradigm'), ('paradigm', 'well'), ('well', 'gluing')]

>> Trigrams are: 
 [('manageability', 'providing', 'implementation'), ('providing', 'implementation', 'MapReduce'), ('implementation', 'MapReduce', 'paradigm'), ('MapReduce', 'paradigm', 'well'), ('paradigm', 'well', 'gluing')]

>> POS Tags are: 
 [('manageability', 'NN'), ('providing', 'VBG'), ('implementation', 'NN'), ('MapReduce', 'NNP'), ('paradigm', 'NN'), ('well', 'RB'), ('gluing', 'VBG')]

>> Noun Phrases are: 
 ['manageability', 'implementation MapReduce paradigm']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('manageability', 'manag'), ('providing', 'provid'), ('implementation', 'implement'), ('MapReduce', 'mapreduc'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'glu')]

>> Stemming using Snowball Stemmer: 
 [('manageability', 'manag'), ('providing', 'provid'), ('implementation', 'implement'), ('MapReduce', 'mapreduc'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'glu')]

>> Lemmatization: 
 [('manageability', 'manageability'), ('providing', 'providing'), ('implementation', 'implementation'), ('MapReduce', 'MapReduce'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'gluing')]



========================================== PARAGRAPH 506 ===========================================

storage and analytics together” (Elgendy, N. and Elragal, A., 2014). Hadoop includes HDFS which 

------------------- Sentence 1 -------------------

storage and analytics together” (Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['storage', 'analytics', 'together', '”', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('storage', 'analytics'), ('analytics', 'together'), ('together', '”'), ('”', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('storage', 'analytics', 'together'), ('analytics', 'together', '”'), ('together', '”', '('), ('”', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('storage', 'NN'), ('analytics', 'NNS'), ('together', 'RB'), ('”', 'NNP'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['storage analytics', '”', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('storage', 'storag'), ('analytics', 'analyt'), ('together', 'togeth'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('storage', 'storag'), ('analytics', 'analyt'), ('together', 'togeth'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('storage', 'storage'), ('analytics', 'analytics'), ('together', 'together'), ('”', '”'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Hadoop includes HDFS which

>> Tokens are: 
 ['Hadoop', 'includes', 'HDFS']

>> Bigrams are: 
 [('Hadoop', 'includes'), ('includes', 'HDFS')]

>> Trigrams are: 
 [('Hadoop', 'includes', 'HDFS')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('includes', 'VBZ'), ('HDFS', 'NNP')]

>> Noun Phrases are: 
 ['Hadoop', 'HDFS']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'HDFS')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('includes', 'includ'), ('HDFS', 'hdf')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('includes', 'includ'), ('HDFS', 'hdfs')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('includes', 'includes'), ('HDFS', 'HDFS')]



========================================== PARAGRAPH 507 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 508 ===========================================

19  

------------------- Sentence 1 -------------------

19

>> Tokens are: 
 ['19']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('19', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19')]

>> Stemming using Snowball Stemmer: 
 [('19', '19')]

>> Lemmatization: 
 [('19', '19')]



========================================== PARAGRAPH 509 ===========================================

  


========================================== PARAGRAPH 510 ===========================================

is for the big data storage and MapReduce for big data analytics, and it can process extremely large  

------------------- Sentence 1 -------------------

is for the big data storage and MapReduce for big data analytics, and it can process extremely large

>> Tokens are: 
 ['big', 'data', 'storage', 'MapReduce', 'big', 'data', 'analytics', ',', 'process', 'extremely', 'large']

>> Bigrams are: 
 [('big', 'data'), ('data', 'storage'), ('storage', 'MapReduce'), ('MapReduce', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'process'), ('process', 'extremely'), ('extremely', 'large')]

>> Trigrams are: 
 [('big', 'data', 'storage'), ('data', 'storage', 'MapReduce'), ('storage', 'MapReduce', 'big'), ('MapReduce', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'process'), (',', 'process', 'extremely'), ('process', 'extremely', 'large')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('MapReduce', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('process', 'NN'), ('extremely', 'RB'), ('large', 'JJ')]

>> Noun Phrases are: 
 ['big data storage MapReduce', 'big data analytics', 'process']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('MapReduce', 'mapreduc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('MapReduce', 'mapreduc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('MapReduce', 'MapReduce'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('process', 'process'), ('extremely', 'extremely'), ('large', 'large')]



========================================== PARAGRAPH 511 ===========================================

amount of data by dividing the data into smaller blocks, then specifying datasets to be distributed  

------------------- Sentence 1 -------------------

amount of data by dividing the data into smaller blocks, then specifying datasets to be distributed

>> Tokens are: 
 ['amount', 'data', 'dividing', 'data', 'smaller', 'blocks', ',', 'specifying', 'datasets', 'distributed']

>> Bigrams are: 
 [('amount', 'data'), ('data', 'dividing'), ('dividing', 'data'), ('data', 'smaller'), ('smaller', 'blocks'), ('blocks', ','), (',', 'specifying'), ('specifying', 'datasets'), ('datasets', 'distributed')]

>> Trigrams are: 
 [('amount', 'data', 'dividing'), ('data', 'dividing', 'data'), ('dividing', 'data', 'smaller'), ('data', 'smaller', 'blocks'), ('smaller', 'blocks', ','), ('blocks', ',', 'specifying'), (',', 'specifying', 'datasets'), ('specifying', 'datasets', 'distributed')]

>> POS Tags are: 
 [('amount', 'NN'), ('data', 'NNS'), ('dividing', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('blocks', 'NNS'), (',', ','), ('specifying', 'VBG'), ('datasets', 'NNS'), ('distributed', 'VBD')]

>> Noun Phrases are: 
 ['amount data', 'data', 'blocks', 'datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('amount', 'amount'), ('data', 'data'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifi'), ('datasets', 'dataset'), ('distributed', 'distribut')]

>> Stemming using Snowball Stemmer: 
 [('amount', 'amount'), ('data', 'data'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifi'), ('datasets', 'dataset'), ('distributed', 'distribut')]

>> Lemmatization: 
 [('amount', 'amount'), ('data', 'data'), ('dividing', 'dividing'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifying'), ('datasets', 'datasets'), ('distributed', 'distributed')]



========================================== PARAGRAPH 512 ===========================================

across cluster nodes (Raghupathi and Raghupathi, 2014; Elgendy and Elragal, 2014). Hadoop  

------------------- Sentence 1 -------------------

across cluster nodes (Raghupathi and Raghupathi, 2014; Elgendy and Elragal, 2014).

>> Tokens are: 
 ['across', 'cluster', 'nodes', '(', 'Raghupathi', 'Raghupathi', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('across', 'cluster'), ('cluster', 'nodes'), ('nodes', '('), ('(', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('Raghupathi', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('across', 'cluster', 'nodes'), ('cluster', 'nodes', '('), ('nodes', '(', 'Raghupathi'), ('(', 'Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi', ','), ('Raghupathi', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('across', 'IN'), ('cluster', 'NN'), ('nodes', 'NNS'), ('(', '('), ('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['cluster nodes', 'Raghupathi Raghupathi', 'Elgendy Elragal']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi Raghupathi'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Hadoop

>> Tokens are: 
 ['Hadoop']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Hadoop', 'NN')]

>> Noun Phrases are: 
 ['Hadoop']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop')]



========================================== PARAGRAPH 513 ===========================================

incorporates several technologies: “Hive is a data warehouse implementation for Hadoop,  

------------------- Sentence 1 -------------------

incorporates several technologies: “Hive is a data warehouse implementation for Hadoop,

>> Tokens are: 
 ['incorporates', 'several', 'technologies', ':', '“', 'Hive', 'data', 'warehouse', 'implementation', 'Hadoop', ',']

>> Bigrams are: 
 [('incorporates', 'several'), ('several', 'technologies'), ('technologies', ':'), (':', '“'), ('“', 'Hive'), ('Hive', 'data'), ('data', 'warehouse'), ('warehouse', 'implementation'), ('implementation', 'Hadoop'), ('Hadoop', ',')]

>> Trigrams are: 
 [('incorporates', 'several', 'technologies'), ('several', 'technologies', ':'), ('technologies', ':', '“'), (':', '“', 'Hive'), ('“', 'Hive', 'data'), ('Hive', 'data', 'warehouse'), ('data', 'warehouse', 'implementation'), ('warehouse', 'implementation', 'Hadoop'), ('implementation', 'Hadoop', ',')]

>> POS Tags are: 
 [('incorporates', 'NNS'), ('several', 'JJ'), ('technologies', 'NNS'), (':', ':'), ('“', 'VB'), ('Hive', 'NNP'), ('data', 'NNS'), ('warehouse', 'NN'), ('implementation', 'NN'), ('Hadoop', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['incorporates', 'several technologies', 'Hive data warehouse implementation Hadoop']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('incorporates', 'incorpor'), ('several', 'sever'), ('technologies', 'technolog'), (':', ':'), ('“', '“'), ('Hive', 'hive'), ('data', 'data'), ('warehouse', 'warehous'), ('implementation', 'implement'), ('Hadoop', 'hadoop'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('incorporates', 'incorpor'), ('several', 'sever'), ('technologies', 'technolog'), (':', ':'), ('“', '“'), ('Hive', 'hive'), ('data', 'data'), ('warehouse', 'warehous'), ('implementation', 'implement'), ('Hadoop', 'hadoop'), (',', ',')]

>> Lemmatization: 
 [('incorporates', 'incorporates'), ('several', 'several'), ('technologies', 'technology'), (':', ':'), ('“', '“'), ('Hive', 'Hive'), ('data', 'data'), ('warehouse', 'warehouse'), ('implementation', 'implementation'), ('Hadoop', 'Hadoop'), (',', ',')]



========================================== PARAGRAPH 514 ===========================================

MapReduce is a programming model in Hadoop, and Pig is a querying language for Hadoop  

------------------- Sentence 1 -------------------

MapReduce is a programming model in Hadoop, and Pig is a querying language for Hadoop

>> Tokens are: 
 ['MapReduce', 'programming', 'model', 'Hadoop', ',', 'Pig', 'querying', 'language', 'Hadoop']

>> Bigrams are: 
 [('MapReduce', 'programming'), ('programming', 'model'), ('model', 'Hadoop'), ('Hadoop', ','), (',', 'Pig'), ('Pig', 'querying'), ('querying', 'language'), ('language', 'Hadoop')]

>> Trigrams are: 
 [('MapReduce', 'programming', 'model'), ('programming', 'model', 'Hadoop'), ('model', 'Hadoop', ','), ('Hadoop', ',', 'Pig'), (',', 'Pig', 'querying'), ('Pig', 'querying', 'language'), ('querying', 'language', 'Hadoop')]

>> POS Tags are: 
 [('MapReduce', 'NNP'), ('programming', 'VBG'), ('model', 'NN'), ('Hadoop', 'NNP'), (',', ','), ('Pig', 'NNP'), ('querying', 'VBG'), ('language', 'NN'), ('Hadoop', 'NNP')]

>> Noun Phrases are: 
 ['MapReduce', 'model Hadoop', 'Pig', 'language Hadoop']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Pig'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('MapReduce', 'mapreduc'), ('programming', 'program'), ('model', 'model'), ('Hadoop', 'hadoop'), (',', ','), ('Pig', 'pig'), ('querying', 'queri'), ('language', 'languag'), ('Hadoop', 'hadoop')]

>> Stemming using Snowball Stemmer: 
 [('MapReduce', 'mapreduc'), ('programming', 'program'), ('model', 'model'), ('Hadoop', 'hadoop'), (',', ','), ('Pig', 'pig'), ('querying', 'queri'), ('language', 'languag'), ('Hadoop', 'hadoop')]

>> Lemmatization: 
 [('MapReduce', 'MapReduce'), ('programming', 'programming'), ('model', 'model'), ('Hadoop', 'Hadoop'), (',', ','), ('Pig', 'Pig'), ('querying', 'querying'), ('language', 'language'), ('Hadoop', 'Hadoop')]



========================================== PARAGRAPH 515 ===========================================

which has similarities to the SQL language for relational databases” (Zuech et al., 2015).    

------------------- Sentence 1 -------------------

which has similarities to the SQL language for relational databases” (Zuech et al., 2015).

>> Tokens are: 
 ['similarities', 'SQL', 'language', 'relational', 'databases', '”', '(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('similarities', 'SQL'), ('SQL', 'language'), ('language', 'relational'), ('relational', 'databases'), ('databases', '”'), ('”', '('), ('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('similarities', 'SQL', 'language'), ('SQL', 'language', 'relational'), ('language', 'relational', 'databases'), ('relational', 'databases', '”'), ('databases', '”', '('), ('”', '(', 'Zuech'), ('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('similarities', 'NNS'), ('SQL', 'NNP'), ('language', 'NN'), ('relational', 'JJ'), ('databases', 'NNS'), ('”', 'VBP'), ('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['similarities SQL language', 'relational databases', 'Zuech']

>> Named Entities are: 
 [('ORGANIZATION', 'SQL'), ('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('similarities', 'similar'), ('SQL', 'sql'), ('language', 'languag'), ('relational', 'relat'), ('databases', 'databas'), ('”', '”'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('similarities', 'similar'), ('SQL', 'sql'), ('language', 'languag'), ('relational', 'relat'), ('databases', 'databas'), ('”', '”'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('similarities', 'similarity'), ('SQL', 'SQL'), ('language', 'language'), ('relational', 'relational'), ('databases', 'database'), ('”', '”'), ('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 516 ===========================================

First-generation technology generated the Apache Spark project in software terms (Watson, 2019),  

------------------- Sentence 1 -------------------

First-generation technology generated the Apache Spark project in software terms (Watson, 2019),

>> Tokens are: 
 ['First-generation', 'technology', 'generated', 'Apache', 'Spark', 'project', 'software', 'terms', '(', 'Watson', ',', '2019', ')', ',']

>> Bigrams are: 
 [('First-generation', 'technology'), ('technology', 'generated'), ('generated', 'Apache'), ('Apache', 'Spark'), ('Spark', 'project'), ('project', 'software'), ('software', 'terms'), ('terms', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ',')]

>> Trigrams are: 
 [('First-generation', 'technology', 'generated'), ('technology', 'generated', 'Apache'), ('generated', 'Apache', 'Spark'), ('Apache', 'Spark', 'project'), ('Spark', 'project', 'software'), ('project', 'software', 'terms'), ('software', 'terms', '('), ('terms', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ',')]

>> POS Tags are: 
 [('First-generation', 'NNP'), ('technology', 'NN'), ('generated', 'VBD'), ('Apache', 'NNP'), ('Spark', 'NNP'), ('project', 'NN'), ('software', 'NN'), ('terms', 'NNS'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['First-generation technology', 'Apache Spark project software terms', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Apache Spark'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('First-generation', 'first-gener'), ('technology', 'technolog'), ('generated', 'gener'), ('Apache', 'apach'), ('Spark', 'spark'), ('project', 'project'), ('software', 'softwar'), ('terms', 'term'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('First-generation', 'first-gener'), ('technology', 'technolog'), ('generated', 'generat'), ('Apache', 'apach'), ('Spark', 'spark'), ('project', 'project'), ('software', 'softwar'), ('terms', 'term'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('First-generation', 'First-generation'), ('technology', 'technology'), ('generated', 'generated'), ('Apache', 'Apache'), ('Spark', 'Spark'), ('project', 'project'), ('software', 'software'), ('terms', 'term'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 517 ===========================================

but Hadoop has a great deal more power, which offers advantages to analytics in terms of memory.  

------------------- Sentence 1 -------------------

but Hadoop has a great deal more power, which offers advantages to analytics in terms of memory.

>> Tokens are: 
 ['Hadoop', 'great', 'deal', 'power', ',', 'offers', 'advantages', 'analytics', 'terms', 'memory', '.']

>> Bigrams are: 
 [('Hadoop', 'great'), ('great', 'deal'), ('deal', 'power'), ('power', ','), (',', 'offers'), ('offers', 'advantages'), ('advantages', 'analytics'), ('analytics', 'terms'), ('terms', 'memory'), ('memory', '.')]

>> Trigrams are: 
 [('Hadoop', 'great', 'deal'), ('great', 'deal', 'power'), ('deal', 'power', ','), ('power', ',', 'offers'), (',', 'offers', 'advantages'), ('offers', 'advantages', 'analytics'), ('advantages', 'analytics', 'terms'), ('analytics', 'terms', 'memory'), ('terms', 'memory', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('great', 'JJ'), ('deal', 'NN'), ('power', 'NN'), (',', ','), ('offers', 'VBZ'), ('advantages', 'NNS'), ('analytics', 'NNS'), ('terms', 'NNS'), ('memory', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hadoop', 'great deal power', 'advantages analytics terms memory']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantag'), ('analytics', 'analyt'), ('terms', 'term'), ('memory', 'memori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantag'), ('analytics', 'analyt'), ('terms', 'term'), ('memory', 'memori'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantage'), ('analytics', 'analytics'), ('terms', 'term'), ('memory', 'memory'), ('.', '.')]



========================================== PARAGRAPH 518 ===========================================

It can work with both batch and real-time workloads, is easy to program with Java code, and can  

------------------- Sentence 1 -------------------

It can work with both batch and real-time workloads, is easy to program with Java code, and can

>> Tokens are: 
 ['It', 'work', 'batch', 'real-time', 'workloads', ',', 'easy', 'program', 'Java', 'code', ',']

>> Bigrams are: 
 [('It', 'work'), ('work', 'batch'), ('batch', 'real-time'), ('real-time', 'workloads'), ('workloads', ','), (',', 'easy'), ('easy', 'program'), ('program', 'Java'), ('Java', 'code'), ('code', ',')]

>> Trigrams are: 
 [('It', 'work', 'batch'), ('work', 'batch', 'real-time'), ('batch', 'real-time', 'workloads'), ('real-time', 'workloads', ','), ('workloads', ',', 'easy'), (',', 'easy', 'program'), ('easy', 'program', 'Java'), ('program', 'Java', 'code'), ('Java', 'code', ',')]

>> POS Tags are: 
 [('It', 'PRP'), ('work', 'VBD'), ('batch', 'RB'), ('real-time', 'JJ'), ('workloads', 'NNS'), (',', ','), ('easy', 'JJ'), ('program', 'NN'), ('Java', 'NNP'), ('code', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['real-time workloads', 'easy program Java code']

>> Named Entities are: 
 [('PERSON', 'Java')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-tim'), ('workloads', 'workload'), (',', ','), ('easy', 'easi'), ('program', 'program'), ('Java', 'java'), ('code', 'code'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-tim'), ('workloads', 'workload'), (',', ','), ('easy', 'easi'), ('program', 'program'), ('Java', 'java'), ('code', 'code'), (',', ',')]

>> Lemmatization: 
 [('It', 'It'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-time'), ('workloads', 'workload'), (',', ','), ('easy', 'easy'), ('program', 'program'), ('Java', 'Java'), ('code', 'code'), (',', ',')]



========================================== PARAGRAPH 519 ===========================================

connect to Apache projects and other software within a closed ecosystem. Hadoop’s components  

------------------- Sentence 1 -------------------

connect to Apache projects and other software within a closed ecosystem.

>> Tokens are: 
 ['connect', 'Apache', 'projects', 'software', 'within', 'closed', 'ecosystem', '.']

>> Bigrams are: 
 [('connect', 'Apache'), ('Apache', 'projects'), ('projects', 'software'), ('software', 'within'), ('within', 'closed'), ('closed', 'ecosystem'), ('ecosystem', '.')]

>> Trigrams are: 
 [('connect', 'Apache', 'projects'), ('Apache', 'projects', 'software'), ('projects', 'software', 'within'), ('software', 'within', 'closed'), ('within', 'closed', 'ecosystem'), ('closed', 'ecosystem', '.')]

>> POS Tags are: 
 [('connect', 'NN'), ('Apache', 'NNP'), ('projects', 'NNS'), ('software', 'NN'), ('within', 'IN'), ('closed', 'JJ'), ('ecosystem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['connect Apache projects software', 'closed ecosystem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('connect', 'connect'), ('Apache', 'apach'), ('projects', 'project'), ('software', 'softwar'), ('within', 'within'), ('closed', 'close'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('connect', 'connect'), ('Apache', 'apach'), ('projects', 'project'), ('software', 'softwar'), ('within', 'within'), ('closed', 'close'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Lemmatization: 
 [('connect', 'connect'), ('Apache', 'Apache'), ('projects', 'project'), ('software', 'software'), ('within', 'within'), ('closed', 'closed'), ('ecosystem', 'ecosystem'), ('.', '.')]


------------------- Sentence 2 -------------------

Hadoop’s components

>> Tokens are: 
 ['Hadoop', '’', 'components']

>> Bigrams are: 
 [('Hadoop', '’'), ('’', 'components')]

>> Trigrams are: 
 [('Hadoop', '’', 'components')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('’', 'CD'), ('components', 'NNS')]

>> Noun Phrases are: 
 ['Hadoop', 'components']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('’', '’'), ('components', 'compon')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('’', '’'), ('components', 'compon')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('’', '’'), ('components', 'component')]



========================================== PARAGRAPH 520 ===========================================

are shown in Figure 11 (Watson, 2019):   

------------------- Sentence 1 -------------------

are shown in Figure 11 (Watson, 2019):

>> Tokens are: 
 ['shown', 'Figure', '11', '(', 'Watson', ',', '2019', ')', ':']

>> Bigrams are: 
 [('shown', 'Figure'), ('Figure', '11'), ('11', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ':')]

>> Trigrams are: 
 [('shown', 'Figure', '11'), ('Figure', '11', '('), ('11', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ':')]

>> POS Tags are: 
 [('shown', 'VBN'), ('Figure', 'NN'), ('11', 'CD'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (':', ':')]

>> Noun Phrases are: 
 ['Figure', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('11', '11'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('11', '11'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':')]

>> Lemmatization: 
 [('shown', 'shown'), ('Figure', 'Figure'), ('11', '11'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':')]



========================================== PARAGRAPH 521 ===========================================

1. Spark SQL runs SQL-like queries on structured data.   2. Spark streaming provides real-time data processing.  3. MLib provides a machine learning library of algorithms and utilities.  4. Graph X provides application algorithms.  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Spark SQL runs SQL-like queries on structured data.

>> Tokens are: 
 ['Spark', 'SQL', 'runs', 'SQL-like', 'queries', 'structured', 'data', '.']

>> Bigrams are: 
 [('Spark', 'SQL'), ('SQL', 'runs'), ('runs', 'SQL-like'), ('SQL-like', 'queries'), ('queries', 'structured'), ('structured', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Spark', 'SQL', 'runs'), ('SQL', 'runs', 'SQL-like'), ('runs', 'SQL-like', 'queries'), ('SQL-like', 'queries', 'structured'), ('queries', 'structured', 'data'), ('structured', 'data', '.')]

>> POS Tags are: 
 [('Spark', 'NNP'), ('SQL', 'NNP'), ('runs', 'VBZ'), ('SQL-like', 'JJ'), ('queries', 'NNS'), ('structured', 'VBN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Spark SQL', 'SQL-like queries', 'data']

>> Named Entities are: 
 [('PERSON', 'Spark'), ('ORGANIZATION', 'SQL')] 

>> Stemming using Porter Stemmer: 
 [('Spark', 'spark'), ('SQL', 'sql'), ('runs', 'run'), ('SQL-like', 'sql-like'), ('queries', 'queri'), ('structured', 'structur'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spark', 'spark'), ('SQL', 'sql'), ('runs', 'run'), ('SQL-like', 'sql-like'), ('queries', 'queri'), ('structured', 'structur'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Spark', 'Spark'), ('SQL', 'SQL'), ('runs', 'run'), ('SQL-like', 'SQL-like'), ('queries', 'query'), ('structured', 'structured'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 4 -------------------

Spark streaming provides real-time data processing.

>> Tokens are: 
 ['Spark', 'streaming', 'provides', 'real-time', 'data', 'processing', '.']

>> Bigrams are: 
 [('Spark', 'streaming'), ('streaming', 'provides'), ('provides', 'real-time'), ('real-time', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Spark', 'streaming', 'provides'), ('streaming', 'provides', 'real-time'), ('provides', 'real-time', 'data'), ('real-time', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('Spark', 'NNP'), ('streaming', 'VBG'), ('provides', 'VBZ'), ('real-time', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Spark', 'real-time data processing']

>> Named Entities are: 
 [('GPE', 'Spark')] 

>> Stemming using Porter Stemmer: 
 [('Spark', 'spark'), ('streaming', 'stream'), ('provides', 'provid'), ('real-time', 'real-tim'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spark', 'spark'), ('streaming', 'stream'), ('provides', 'provid'), ('real-time', 'real-tim'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Spark', 'Spark'), ('streaming', 'streaming'), ('provides', 'provides'), ('real-time', 'real-time'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 5 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 6 -------------------

MLib provides a machine learning library of algorithms and utilities.

>> Tokens are: 
 ['MLib', 'provides', 'machine', 'learning', 'library', 'algorithms', 'utilities', '.']

>> Bigrams are: 
 [('MLib', 'provides'), ('provides', 'machine'), ('machine', 'learning'), ('learning', 'library'), ('library', 'algorithms'), ('algorithms', 'utilities'), ('utilities', '.')]

>> Trigrams are: 
 [('MLib', 'provides', 'machine'), ('provides', 'machine', 'learning'), ('machine', 'learning', 'library'), ('learning', 'library', 'algorithms'), ('library', 'algorithms', 'utilities'), ('algorithms', 'utilities', '.')]

>> POS Tags are: 
 [('MLib', 'NNP'), ('provides', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('library', 'JJ'), ('algorithms', 'NN'), ('utilities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['MLib', 'machine', 'library algorithms utilities']

>> Named Entities are: 
 [('ORGANIZATION', 'MLib')] 

>> Stemming using Porter Stemmer: 
 [('MLib', 'mlib'), ('provides', 'provid'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('algorithms', 'algorithm'), ('utilities', 'util'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MLib', 'mlib'), ('provides', 'provid'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('algorithms', 'algorithm'), ('utilities', 'util'), ('.', '.')]

>> Lemmatization: 
 [('MLib', 'MLib'), ('provides', 'provides'), ('machine', 'machine'), ('learning', 'learning'), ('library', 'library'), ('algorithms', 'algorithm'), ('utilities', 'utility'), ('.', '.')]


------------------- Sentence 7 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 8 -------------------

Graph X provides application algorithms.

>> Tokens are: 
 ['Graph', 'X', 'provides', 'application', 'algorithms', '.']

>> Bigrams are: 
 [('Graph', 'X'), ('X', 'provides'), ('provides', 'application'), ('application', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Graph', 'X', 'provides'), ('X', 'provides', 'application'), ('provides', 'application', 'algorithms'), ('application', 'algorithms', '.')]

>> POS Tags are: 
 [('Graph', 'NNP'), ('X', 'NNP'), ('provides', 'VBZ'), ('application', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Graph X', 'application algorithms']

>> Named Entities are: 
 [('PERSON', 'Graph')] 

>> Stemming using Porter Stemmer: 
 [('Graph', 'graph'), ('X', 'x'), ('provides', 'provid'), ('application', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Graph', 'graph'), ('X', 'x'), ('provides', 'provid'), ('application', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Graph', 'Graph'), ('X', 'X'), ('provides', 'provides'), ('application', 'application'), ('algorithms', 'algorithm'), ('.', '.')]



========================================== PARAGRAPH 522 ===========================================

  


========================================== PARAGRAPH 523 ===========================================

  


========================================== PARAGRAPH 524 ===========================================

  


========================================== PARAGRAPH 525 ===========================================

Figure 11: Spark Components (Watson, 2019)  

------------------- Sentence 1 -------------------

Figure 11: Spark Components (Watson, 2019)

>> Tokens are: 
 ['Figure', '11', ':', 'Spark', 'Components', '(', 'Watson', ',', '2019', ')']

>> Bigrams are: 
 [('Figure', '11'), ('11', ':'), (':', 'Spark'), ('Spark', 'Components'), ('Components', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')')]

>> Trigrams are: 
 [('Figure', '11', ':'), ('11', ':', 'Spark'), (':', 'Spark', 'Components'), ('Spark', 'Components', '('), ('Components', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')')]

>> POS Tags are: 
 [('Figure', 'NN'), ('11', 'CD'), (':', ':'), ('Spark', 'NN'), ('Components', 'NNS'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Figure', 'Spark Components', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('11', '11'), (':', ':'), ('Spark', 'spark'), ('Components', 'compon'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('11', '11'), (':', ':'), ('Spark', 'spark'), ('Components', 'compon'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('11', '11'), (':', ':'), ('Spark', 'Spark'), ('Components', 'Components'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')')]



========================================== PARAGRAPH 526 ===========================================

  


========================================== PARAGRAPH 527 ===========================================

  


========================================== PARAGRAPH 528 ===========================================

7.2. Big data analytics processing  

------------------- Sentence 1 -------------------

7.2.

>> Tokens are: 
 ['7.2', '.']

>> Bigrams are: 
 [('7.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.2', '7.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.2', '7.2'), ('.', '.')]

>> Lemmatization: 
 [('7.2', '7.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics processing

>> Tokens are: 
 ['Big', 'data', 'analytics', 'processing']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'processing')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'processing')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing')]



========================================== PARAGRAPH 529 ===========================================

Analytics processing is the next issue after big data storage. According to He et al. (2011), big  

------------------- Sentence 1 -------------------

Analytics processing is the next issue after big data storage.

>> Tokens are: 
 ['Analytics', 'processing', 'next', 'issue', 'big', 'data', 'storage', '.']

>> Bigrams are: 
 [('Analytics', 'processing'), ('processing', 'next'), ('next', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', '.')]

>> Trigrams are: 
 [('Analytics', 'processing', 'next'), ('processing', 'next', 'issue'), ('next', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('processing', 'VBG'), ('next', 'JJ'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Analytics', 'next issue', 'big data storage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('processing', 'process'), ('next', 'next'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('processing', 'process'), ('next', 'next'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('processing', 'processing'), ('next', 'next'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('.', '.')]


------------------- Sentence 2 -------------------

According to He et al.

>> Tokens are: 
 ['According', 'He', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'He'), ('He', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'He', 'et'), ('He', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('He', 'PRP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('He', 'he'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('He', 'he'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('He', 'He'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(2011), big

>> Tokens are: 
 ['(', '2011', ')', ',', 'big']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', ','), (',', 'big')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', ','), (')', ',', 'big')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), (',', ','), ('big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big')]



========================================== PARAGRAPH 530 ===========================================

data analytics processing has four critical requirements:  

------------------- Sentence 1 -------------------

data analytics processing has four critical requirements:

>> Tokens are: 
 ['data', 'analytics', 'processing', 'four', 'critical', 'requirements', ':']

>> Bigrams are: 
 [('data', 'analytics'), ('analytics', 'processing'), ('processing', 'four'), ('four', 'critical'), ('critical', 'requirements'), ('requirements', ':')]

>> Trigrams are: 
 [('data', 'analytics', 'processing'), ('analytics', 'processing', 'four'), ('processing', 'four', 'critical'), ('four', 'critical', 'requirements'), ('critical', 'requirements', ':')]

>> POS Tags are: 
 [('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'VBG'), ('four', 'CD'), ('critical', 'JJ'), ('requirements', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['data analytics', 'critical requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('four', 'four'), ('critical', 'critic'), ('requirements', 'requir'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('four', 'four'), ('critical', 'critic'), ('requirements', 'requir'), (':', ':')]

>> Lemmatization: 
 [('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing'), ('four', 'four'), ('critical', 'critical'), ('requirements', 'requirement'), (':', ':')]



========================================== PARAGRAPH 531 ===========================================

a) Fast data loading: limited interference between disk and network, to speed up query  execution.  

------------------- Sentence 1 -------------------

a) Fast data loading: limited interference between disk and network, to speed up query  execution.

>> Tokens are: 
 [')', 'Fast', 'data', 'loading', ':', 'limited', 'interference', 'disk', 'network', ',', 'speed', 'query', 'execution', '.']

>> Bigrams are: 
 [(')', 'Fast'), ('Fast', 'data'), ('data', 'loading'), ('loading', ':'), (':', 'limited'), ('limited', 'interference'), ('interference', 'disk'), ('disk', 'network'), ('network', ','), (',', 'speed'), ('speed', 'query'), ('query', 'execution'), ('execution', '.')]

>> Trigrams are: 
 [(')', 'Fast', 'data'), ('Fast', 'data', 'loading'), ('data', 'loading', ':'), ('loading', ':', 'limited'), (':', 'limited', 'interference'), ('limited', 'interference', 'disk'), ('interference', 'disk', 'network'), ('disk', 'network', ','), ('network', ',', 'speed'), (',', 'speed', 'query'), ('speed', 'query', 'execution'), ('query', 'execution', '.')]

>> POS Tags are: 
 [(')', ')'), ('Fast', 'NNP'), ('data', 'NN'), ('loading', 'NN'), (':', ':'), ('limited', 'JJ'), ('interference', 'NN'), ('disk', 'NN'), ('network', 'NN'), (',', ','), ('speed', 'NN'), ('query', 'NN'), ('execution', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Fast data loading', 'limited interference disk network', 'speed query execution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(')', ')'), ('Fast', 'fast'), ('data', 'data'), ('loading', 'load'), (':', ':'), ('limited', 'limit'), ('interference', 'interfer'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'queri'), ('execution', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(')', ')'), ('Fast', 'fast'), ('data', 'data'), ('loading', 'load'), (':', ':'), ('limited', 'limit'), ('interference', 'interfer'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'queri'), ('execution', 'execut'), ('.', '.')]

>> Lemmatization: 
 [(')', ')'), ('Fast', 'Fast'), ('data', 'data'), ('loading', 'loading'), (':', ':'), ('limited', 'limited'), ('interference', 'interference'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'query'), ('execution', 'execution'), ('.', '.')]



========================================== PARAGRAPH 532 ===========================================

  


========================================== PARAGRAPH 533 ===========================================

b) Fast query processing: workloads are heavy, therefore real-time requests should be  processed as quickly as possible to satisfy user requirements. The data placement structure  

------------------- Sentence 1 -------------------

b) Fast query processing: workloads are heavy, therefore real-time requests should be  processed as quickly as possible to satisfy user requirements.

>> Tokens are: 
 ['b', ')', 'Fast', 'query', 'processing', ':', 'workloads', 'heavy', ',', 'therefore', 'real-time', 'requests', 'processed', 'quickly', 'possible', 'satisfy', 'user', 'requirements', '.']

>> Bigrams are: 
 [('b', ')'), (')', 'Fast'), ('Fast', 'query'), ('query', 'processing'), ('processing', ':'), (':', 'workloads'), ('workloads', 'heavy'), ('heavy', ','), (',', 'therefore'), ('therefore', 'real-time'), ('real-time', 'requests'), ('requests', 'processed'), ('processed', 'quickly'), ('quickly', 'possible'), ('possible', 'satisfy'), ('satisfy', 'user'), ('user', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('b', ')', 'Fast'), (')', 'Fast', 'query'), ('Fast', 'query', 'processing'), ('query', 'processing', ':'), ('processing', ':', 'workloads'), (':', 'workloads', 'heavy'), ('workloads', 'heavy', ','), ('heavy', ',', 'therefore'), (',', 'therefore', 'real-time'), ('therefore', 'real-time', 'requests'), ('real-time', 'requests', 'processed'), ('requests', 'processed', 'quickly'), ('processed', 'quickly', 'possible'), ('quickly', 'possible', 'satisfy'), ('possible', 'satisfy', 'user'), ('satisfy', 'user', 'requirements'), ('user', 'requirements', '.')]

>> POS Tags are: 
 [('b', 'NN'), (')', ')'), ('Fast', 'NNP'), ('query', 'NN'), ('processing', 'NN'), (':', ':'), ('workloads', 'NNS'), ('heavy', 'VBP'), (',', ','), ('therefore', 'RB'), ('real-time', 'JJ'), ('requests', 'NNS'), ('processed', 'VBD'), ('quickly', 'RB'), ('possible', 'JJ'), ('satisfy', 'NN'), ('user', 'NN'), ('requirements', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['b', 'Fast query processing', 'workloads', 'real-time requests', 'possible satisfy user requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), (')', ')'), ('Fast', 'fast'), ('query', 'queri'), ('processing', 'process'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavi'), (',', ','), ('therefore', 'therefor'), ('real-time', 'real-tim'), ('requests', 'request'), ('processed', 'process'), ('quickly', 'quickli'), ('possible', 'possibl'), ('satisfy', 'satisfi'), ('user', 'user'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), (')', ')'), ('Fast', 'fast'), ('query', 'queri'), ('processing', 'process'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavi'), (',', ','), ('therefore', 'therefor'), ('real-time', 'real-tim'), ('requests', 'request'), ('processed', 'process'), ('quickly', 'quick'), ('possible', 'possibl'), ('satisfy', 'satisfi'), ('user', 'user'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), (')', ')'), ('Fast', 'Fast'), ('query', 'query'), ('processing', 'processing'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavy'), (',', ','), ('therefore', 'therefore'), ('real-time', 'real-time'), ('requests', 'request'), ('processed', 'processed'), ('quickly', 'quickly'), ('possible', 'possible'), ('satisfy', 'satisfy'), ('user', 'user'), ('requirements', 'requirement'), ('.', '.')]


------------------- Sentence 2 -------------------

The data placement structure

>> Tokens are: 
 ['The', 'data', 'placement', 'structure']

>> Bigrams are: 
 [('The', 'data'), ('data', 'placement'), ('placement', 'structure')]

>> Trigrams are: 
 [('The', 'data', 'placement'), ('data', 'placement', 'structure')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('placement', 'NN'), ('structure', 'NN')]

>> Noun Phrases are: 
 ['The data placement structure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structure')]



========================================== PARAGRAPH 534 ===========================================

should also have the ability process multiple queries as query volumes increase.  

------------------- Sentence 1 -------------------

should also have the ability process multiple queries as query volumes increase.

>> Tokens are: 
 ['also', 'ability', 'process', 'multiple', 'queries', 'query', 'volumes', 'increase', '.']

>> Bigrams are: 
 [('also', 'ability'), ('ability', 'process'), ('process', 'multiple'), ('multiple', 'queries'), ('queries', 'query'), ('query', 'volumes'), ('volumes', 'increase'), ('increase', '.')]

>> Trigrams are: 
 [('also', 'ability', 'process'), ('ability', 'process', 'multiple'), ('process', 'multiple', 'queries'), ('multiple', 'queries', 'query'), ('queries', 'query', 'volumes'), ('query', 'volumes', 'increase'), ('volumes', 'increase', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('ability', 'NN'), ('process', 'NN'), ('multiple', 'JJ'), ('queries', 'NNS'), ('query', 'VBP'), ('volumes', 'JJ'), ('increase', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ability process', 'multiple queries', 'volumes increase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('ability', 'abil'), ('process', 'process'), ('multiple', 'multipl'), ('queries', 'queri'), ('query', 'queri'), ('volumes', 'volum'), ('increase', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('ability', 'abil'), ('process', 'process'), ('multiple', 'multipl'), ('queries', 'queri'), ('query', 'queri'), ('volumes', 'volum'), ('increase', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('ability', 'ability'), ('process', 'process'), ('multiple', 'multiple'), ('queries', 'query'), ('query', 'query'), ('volumes', 'volume'), ('increase', 'increase'), ('.', '.')]



========================================== PARAGRAPH 535 ===========================================

 


========================================== PARAGRAPH 536 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 537 ===========================================

20  

------------------- Sentence 1 -------------------

20

>> Tokens are: 
 ['20']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('20', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('20', '20')]

>> Stemming using Snowball Stemmer: 
 [('20', '20')]

>> Lemmatization: 
 [('20', '20')]



========================================== PARAGRAPH 538 ===========================================

  


========================================== PARAGRAPH 539 ===========================================

c) Highly efficient utilization of storage space: as user activities grow rapidly, they need  scalable storage capacity and computing power. As disk space is limited, it is necessary to  

------------------- Sentence 1 -------------------

c) Highly efficient utilization of storage space: as user activities grow rapidly, they need  scalable storage capacity and computing power.

>> Tokens are: 
 ['c', ')', 'Highly', 'efficient', 'utilization', 'storage', 'space', ':', 'user', 'activities', 'grow', 'rapidly', ',', 'need', 'scalable', 'storage', 'capacity', 'computing', 'power', '.']

>> Bigrams are: 
 [('c', ')'), (')', 'Highly'), ('Highly', 'efficient'), ('efficient', 'utilization'), ('utilization', 'storage'), ('storage', 'space'), ('space', ':'), (':', 'user'), ('user', 'activities'), ('activities', 'grow'), ('grow', 'rapidly'), ('rapidly', ','), (',', 'need'), ('need', 'scalable'), ('scalable', 'storage'), ('storage', 'capacity'), ('capacity', 'computing'), ('computing', 'power'), ('power', '.')]

>> Trigrams are: 
 [('c', ')', 'Highly'), (')', 'Highly', 'efficient'), ('Highly', 'efficient', 'utilization'), ('efficient', 'utilization', 'storage'), ('utilization', 'storage', 'space'), ('storage', 'space', ':'), ('space', ':', 'user'), (':', 'user', 'activities'), ('user', 'activities', 'grow'), ('activities', 'grow', 'rapidly'), ('grow', 'rapidly', ','), ('rapidly', ',', 'need'), (',', 'need', 'scalable'), ('need', 'scalable', 'storage'), ('scalable', 'storage', 'capacity'), ('storage', 'capacity', 'computing'), ('capacity', 'computing', 'power'), ('computing', 'power', '.')]

>> POS Tags are: 
 [('c', 'NNS'), (')', ')'), ('Highly', 'NNP'), ('efficient', 'JJ'), ('utilization', 'NN'), ('storage', 'NN'), ('space', 'NN'), (':', ':'), ('user', 'NN'), ('activities', 'NNS'), ('grow', 'VBP'), ('rapidly', 'RB'), (',', ','), ('need', 'VBP'), ('scalable', 'JJ'), ('storage', 'NN'), ('capacity', 'NN'), ('computing', 'VBG'), ('power', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['c', 'Highly', 'efficient utilization storage space', 'user activities', 'scalable storage capacity', 'power']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('c', 'c'), (')', ')'), ('Highly', 'highli'), ('efficient', 'effici'), ('utilization', 'util'), ('storage', 'storag'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activ'), ('grow', 'grow'), ('rapidly', 'rapidli'), (',', ','), ('need', 'need'), ('scalable', 'scalabl'), ('storage', 'storag'), ('capacity', 'capac'), ('computing', 'comput'), ('power', 'power'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('c', 'c'), (')', ')'), ('Highly', 'high'), ('efficient', 'effici'), ('utilization', 'util'), ('storage', 'storag'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activ'), ('grow', 'grow'), ('rapidly', 'rapid'), (',', ','), ('need', 'need'), ('scalable', 'scalabl'), ('storage', 'storag'), ('capacity', 'capac'), ('computing', 'comput'), ('power', 'power'), ('.', '.')]

>> Lemmatization: 
 [('c', 'c'), (')', ')'), ('Highly', 'Highly'), ('efficient', 'efficient'), ('utilization', 'utilization'), ('storage', 'storage'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activity'), ('grow', 'grow'), ('rapidly', 'rapidly'), (',', ','), ('need', 'need'), ('scalable', 'scalable'), ('storage', 'storage'), ('capacity', 'capacity'), ('computing', 'computing'), ('power', 'power'), ('.', '.')]


------------------- Sentence 2 -------------------

As disk space is limited, it is necessary to

>> Tokens are: 
 ['As', 'disk', 'space', 'limited', ',', 'necessary']

>> Bigrams are: 
 [('As', 'disk'), ('disk', 'space'), ('space', 'limited'), ('limited', ','), (',', 'necessary')]

>> Trigrams are: 
 [('As', 'disk', 'space'), ('disk', 'space', 'limited'), ('space', 'limited', ','), ('limited', ',', 'necessary')]

>> POS Tags are: 
 [('As', 'IN'), ('disk', 'NN'), ('space', 'NN'), ('limited', 'VBD'), (',', ','), ('necessary', 'JJ')]

>> Noun Phrases are: 
 ['disk space']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limit'), (',', ','), ('necessary', 'necessari')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limit'), (',', ','), ('necessary', 'necessari')]

>> Lemmatization: 
 [('As', 'As'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limited'), (',', ','), ('necessary', 'necessary')]



========================================== PARAGRAPH 540 ===========================================

manage data storage during processing and address the space issues adaptively.  

------------------- Sentence 1 -------------------

manage data storage during processing and address the space issues adaptively.

>> Tokens are: 
 ['manage', 'data', 'storage', 'processing', 'address', 'space', 'issues', 'adaptively', '.']

>> Bigrams are: 
 [('manage', 'data'), ('data', 'storage'), ('storage', 'processing'), ('processing', 'address'), ('address', 'space'), ('space', 'issues'), ('issues', 'adaptively'), ('adaptively', '.')]

>> Trigrams are: 
 [('manage', 'data', 'storage'), ('data', 'storage', 'processing'), ('storage', 'processing', 'address'), ('processing', 'address', 'space'), ('address', 'space', 'issues'), ('space', 'issues', 'adaptively'), ('issues', 'adaptively', '.')]

>> POS Tags are: 
 [('manage', 'NN'), ('data', 'NNS'), ('storage', 'NN'), ('processing', 'NN'), ('address', 'JJ'), ('space', 'NN'), ('issues', 'NNS'), ('adaptively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['manage data storage processing', 'address space issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('manage', 'manag'), ('data', 'data'), ('storage', 'storag'), ('processing', 'process'), ('address', 'address'), ('space', 'space'), ('issues', 'issu'), ('adaptively', 'adapt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('manage', 'manag'), ('data', 'data'), ('storage', 'storag'), ('processing', 'process'), ('address', 'address'), ('space', 'space'), ('issues', 'issu'), ('adaptively', 'adapt'), ('.', '.')]

>> Lemmatization: 
 [('manage', 'manage'), ('data', 'data'), ('storage', 'storage'), ('processing', 'processing'), ('address', 'address'), ('space', 'space'), ('issues', 'issue'), ('adaptively', 'adaptively'), ('.', '.')]



========================================== PARAGRAPH 541 ===========================================

  


========================================== PARAGRAPH 542 ===========================================

d) Strong adaptivity to highly dynamic workload patterns: the underlying system should be  highly adaptive, as data processes have different workload patterns and the analysing of  

------------------- Sentence 1 -------------------

d) Strong adaptivity to highly dynamic workload patterns: the underlying system should be  highly adaptive, as data processes have different workload patterns and the analysing of

>> Tokens are: 
 [')', 'Strong', 'adaptivity', 'highly', 'dynamic', 'workload', 'patterns', ':', 'underlying', 'system', 'highly', 'adaptive', ',', 'data', 'processes', 'different', 'workload', 'patterns', 'analysing']

>> Bigrams are: 
 [(')', 'Strong'), ('Strong', 'adaptivity'), ('adaptivity', 'highly'), ('highly', 'dynamic'), ('dynamic', 'workload'), ('workload', 'patterns'), ('patterns', ':'), (':', 'underlying'), ('underlying', 'system'), ('system', 'highly'), ('highly', 'adaptive'), ('adaptive', ','), (',', 'data'), ('data', 'processes'), ('processes', 'different'), ('different', 'workload'), ('workload', 'patterns'), ('patterns', 'analysing')]

>> Trigrams are: 
 [(')', 'Strong', 'adaptivity'), ('Strong', 'adaptivity', 'highly'), ('adaptivity', 'highly', 'dynamic'), ('highly', 'dynamic', 'workload'), ('dynamic', 'workload', 'patterns'), ('workload', 'patterns', ':'), ('patterns', ':', 'underlying'), (':', 'underlying', 'system'), ('underlying', 'system', 'highly'), ('system', 'highly', 'adaptive'), ('highly', 'adaptive', ','), ('adaptive', ',', 'data'), (',', 'data', 'processes'), ('data', 'processes', 'different'), ('processes', 'different', 'workload'), ('different', 'workload', 'patterns'), ('workload', 'patterns', 'analysing')]

>> POS Tags are: 
 [(')', ')'), ('Strong', 'NNP'), ('adaptivity', 'NN'), ('highly', 'RB'), ('dynamic', 'JJ'), ('workload', 'NN'), ('patterns', 'NNS'), (':', ':'), ('underlying', 'VBG'), ('system', 'NN'), ('highly', 'RB'), ('adaptive', 'JJ'), (',', ','), ('data', 'JJ'), ('processes', 'NNS'), ('different', 'JJ'), ('workload', 'NN'), ('patterns', 'NNS'), ('analysing', 'VBG')]

>> Noun Phrases are: 
 ['Strong adaptivity', 'dynamic workload patterns', 'system', 'data processes', 'different workload patterns']

>> Named Entities are: 
 [('GPE', 'Strong')] 

>> Stemming using Porter Stemmer: 
 [(')', ')'), ('Strong', 'strong'), ('adaptivity', 'adapt'), ('highly', 'highli'), ('dynamic', 'dynam'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'underli'), ('system', 'system'), ('highly', 'highli'), ('adaptive', 'adapt'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'differ'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analys')]

>> Stemming using Snowball Stemmer: 
 [(')', ')'), ('Strong', 'strong'), ('adaptivity', 'adapt'), ('highly', 'high'), ('dynamic', 'dynam'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'under'), ('system', 'system'), ('highly', 'high'), ('adaptive', 'adapt'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'differ'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analys')]

>> Lemmatization: 
 [(')', ')'), ('Strong', 'Strong'), ('adaptivity', 'adaptivity'), ('highly', 'highly'), ('dynamic', 'dynamic'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'underlying'), ('system', 'system'), ('highly', 'highly'), ('adaptive', 'adaptive'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'different'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analysing')]



========================================== PARAGRAPH 543 ===========================================

big datasets has many different applications and users, with different purposes and methods  

------------------- Sentence 1 -------------------

big datasets has many different applications and users, with different purposes and methods

>> Tokens are: 
 ['big', 'datasets', 'many', 'different', 'applications', 'users', ',', 'different', 'purposes', 'methods']

>> Bigrams are: 
 [('big', 'datasets'), ('datasets', 'many'), ('many', 'different'), ('different', 'applications'), ('applications', 'users'), ('users', ','), (',', 'different'), ('different', 'purposes'), ('purposes', 'methods')]

>> Trigrams are: 
 [('big', 'datasets', 'many'), ('datasets', 'many', 'different'), ('many', 'different', 'applications'), ('different', 'applications', 'users'), ('applications', 'users', ','), ('users', ',', 'different'), (',', 'different', 'purposes'), ('different', 'purposes', 'methods')]

>> POS Tags are: 
 [('big', 'JJ'), ('datasets', 'NNS'), ('many', 'JJ'), ('different', 'JJ'), ('applications', 'NNS'), ('users', 'NNS'), (',', ','), ('different', 'JJ'), ('purposes', 'NNS'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['big datasets', 'many different applications users', 'different purposes methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('datasets', 'dataset'), ('many', 'mani'), ('different', 'differ'), ('applications', 'applic'), ('users', 'user'), (',', ','), ('different', 'differ'), ('purposes', 'purpos'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('datasets', 'dataset'), ('many', 'mani'), ('different', 'differ'), ('applications', 'applic'), ('users', 'user'), (',', ','), ('different', 'differ'), ('purposes', 'purpos'), ('methods', 'method')]

>> Lemmatization: 
 [('big', 'big'), ('datasets', 'datasets'), ('many', 'many'), ('different', 'different'), ('applications', 'application'), ('users', 'user'), (',', ','), ('different', 'different'), ('purposes', 'purpose'), ('methods', 'method')]



========================================== PARAGRAPH 544 ===========================================

(Elgendy, N. and Elragal, A., 2014).  

------------------- Sentence 1 -------------------

(Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 545 ===========================================

The work presented by García et al. (2016) shows that using big data frameworks for storing,  

------------------- Sentence 1 -------------------

The work presented by García et al.

>> Tokens are: 
 ['The', 'work', 'presented', 'García', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'work'), ('work', 'presented'), ('presented', 'García'), ('García', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'work', 'presented'), ('work', 'presented', 'García'), ('presented', 'García', 'et'), ('García', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('work', 'NN'), ('presented', 'VBD'), ('García', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The work', 'García', 'al']

>> Named Entities are: 
 [('PERSON', 'García')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('work', 'work'), ('presented', 'present'), ('García', 'garcía'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('work', 'work'), ('presented', 'present'), ('García', 'garcía'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('work', 'work'), ('presented', 'presented'), ('García', 'García'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016) shows that using big data frameworks for storing,

>> Tokens are: 
 ['(', '2016', ')', 'shows', 'using', 'big', 'data', 'frameworks', 'storing', ',']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'shows'), ('shows', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'frameworks'), ('frameworks', 'storing'), ('storing', ',')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'shows'), (')', 'shows', 'using'), ('shows', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'frameworks'), ('data', 'frameworks', 'storing'), ('frameworks', 'storing', ',')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('shows', 'VBZ'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('frameworks', 'NNS'), ('storing', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['big data frameworks storing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'store'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'store'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'storing'), (',', ',')]



========================================== PARAGRAPH 546 ===========================================

processing, and analysing data has changed the context of knowledge discovery from data,  

------------------- Sentence 1 -------------------

processing, and analysing data has changed the context of knowledge discovery from data,

>> Tokens are: 
 ['processing', ',', 'analysing', 'data', 'changed', 'context', 'knowledge', 'discovery', 'data', ',']

>> Bigrams are: 
 [('processing', ','), (',', 'analysing'), ('analysing', 'data'), ('data', 'changed'), ('changed', 'context'), ('context', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'data'), ('data', ',')]

>> Trigrams are: 
 [('processing', ',', 'analysing'), (',', 'analysing', 'data'), ('analysing', 'data', 'changed'), ('data', 'changed', 'context'), ('changed', 'context', 'knowledge'), ('context', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'data'), ('discovery', 'data', ',')]

>> POS Tags are: 
 [('processing', 'NN'), (',', ','), ('analysing', 'VBG'), ('data', 'NNS'), ('changed', 'VBD'), ('context', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['processing', 'data', 'context knowledge discovery data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('processing', 'process'), (',', ','), ('analysing', 'analys'), ('data', 'data'), ('changed', 'chang'), ('context', 'context'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('processing', 'process'), (',', ','), ('analysing', 'analys'), ('data', 'data'), ('changed', 'chang'), ('context', 'context'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('processing', 'processing'), (',', ','), ('analysing', 'analysing'), ('data', 'data'), ('changed', 'changed'), ('context', 'context'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 547 ===========================================

mainly in terms of data mining processes and pre-processing, with a particular focus on the  

------------------- Sentence 1 -------------------

mainly in terms of data mining processes and pre-processing, with a particular focus on the

>> Tokens are: 
 ['mainly', 'terms', 'data', 'mining', 'processes', 'pre-processing', ',', 'particular', 'focus']

>> Bigrams are: 
 [('mainly', 'terms'), ('terms', 'data'), ('data', 'mining'), ('mining', 'processes'), ('processes', 'pre-processing'), ('pre-processing', ','), (',', 'particular'), ('particular', 'focus')]

>> Trigrams are: 
 [('mainly', 'terms', 'data'), ('terms', 'data', 'mining'), ('data', 'mining', 'processes'), ('mining', 'processes', 'pre-processing'), ('processes', 'pre-processing', ','), ('pre-processing', ',', 'particular'), (',', 'particular', 'focus')]

>> POS Tags are: 
 [('mainly', 'RB'), ('terms', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('processes', 'VBZ'), ('pre-processing', 'NN'), (',', ','), ('particular', 'JJ'), ('focus', 'NN')]

>> Noun Phrases are: 
 ['terms data mining', 'pre-processing', 'particular focus']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mainly', 'mainli'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('processes', 'process'), ('pre-processing', 'pre-process'), (',', ','), ('particular', 'particular'), ('focus', 'focu')]

>> Stemming using Snowball Stemmer: 
 [('mainly', 'main'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('processes', 'process'), ('pre-processing', 'pre-process'), (',', ','), ('particular', 'particular'), ('focus', 'focus')]

>> Lemmatization: 
 [('mainly', 'mainly'), ('terms', 'term'), ('data', 'data'), ('mining', 'mining'), ('processes', 'process'), ('pre-processing', 'pre-processing'), (',', ','), ('particular', 'particular'), ('focus', 'focus')]



========================================== PARAGRAPH 548 ===========================================

rise of data pre-processing in cloud computing. The presented solution covered various data  

------------------- Sentence 1 -------------------

rise of data pre-processing in cloud computing.

>> Tokens are: 
 ['rise', 'data', 'pre-processing', 'cloud', 'computing', '.']

>> Bigrams are: 
 [('rise', 'data'), ('data', 'pre-processing'), ('pre-processing', 'cloud'), ('cloud', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('rise', 'data', 'pre-processing'), ('data', 'pre-processing', 'cloud'), ('pre-processing', 'cloud', 'computing'), ('cloud', 'computing', '.')]

>> POS Tags are: 
 [('rise', 'NN'), ('data', 'NNS'), ('pre-processing', 'JJ'), ('cloud', 'NN'), ('computing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['rise data', 'pre-processing cloud computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-process'), ('cloud', 'cloud'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-process'), ('cloud', 'cloud'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('cloud', 'cloud'), ('computing', 'computing'), ('.', '.')]


------------------- Sentence 2 -------------------

The presented solution covered various data

>> Tokens are: 
 ['The', 'presented', 'solution', 'covered', 'various', 'data']

>> Bigrams are: 
 [('The', 'presented'), ('presented', 'solution'), ('solution', 'covered'), ('covered', 'various'), ('various', 'data')]

>> Trigrams are: 
 [('The', 'presented', 'solution'), ('presented', 'solution', 'covered'), ('solution', 'covered', 'various'), ('covered', 'various', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('presented', 'JJ'), ('solution', 'NN'), ('covered', 'VBD'), ('various', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The presented solution', 'various data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('presented', 'present'), ('solution', 'solut'), ('covered', 'cover'), ('various', 'variou'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('presented', 'present'), ('solution', 'solut'), ('covered', 'cover'), ('various', 'various'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('presented', 'presented'), ('solution', 'solution'), ('covered', 'covered'), ('various', 'various'), ('data', 'data')]



========================================== PARAGRAPH 549 ===========================================

pre-processing technique families with factors such as maximum size supported examined in  

------------------- Sentence 1 -------------------

pre-processing technique families with factors such as maximum size supported examined in

>> Tokens are: 
 ['pre-processing', 'technique', 'families', 'factors', 'maximum', 'size', 'supported', 'examined']

>> Bigrams are: 
 [('pre-processing', 'technique'), ('technique', 'families'), ('families', 'factors'), ('factors', 'maximum'), ('maximum', 'size'), ('size', 'supported'), ('supported', 'examined')]

>> Trigrams are: 
 [('pre-processing', 'technique', 'families'), ('technique', 'families', 'factors'), ('families', 'factors', 'maximum'), ('factors', 'maximum', 'size'), ('maximum', 'size', 'supported'), ('size', 'supported', 'examined')]

>> POS Tags are: 
 [('pre-processing', 'NN'), ('technique', 'NN'), ('families', 'NNS'), ('factors', 'NNS'), ('maximum', 'JJ'), ('size', 'NN'), ('supported', 'VBD'), ('examined', 'VBD')]

>> Noun Phrases are: 
 ['pre-processing technique families factors', 'maximum size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('families', 'famili'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'support'), ('examined', 'examin')]

>> Stemming using Snowball Stemmer: 
 [('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('families', 'famili'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'support'), ('examined', 'examin')]

>> Lemmatization: 
 [('pre-processing', 'pre-processing'), ('technique', 'technique'), ('families', 'family'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'supported'), ('examined', 'examined')]



========================================== PARAGRAPH 550 ===========================================

terms of big data and data pre-processing throughout all of the families of methods. Moreover,  

------------------- Sentence 1 -------------------

terms of big data and data pre-processing throughout all of the families of methods.

>> Tokens are: 
 ['terms', 'big', 'data', 'data', 'pre-processing', 'throughout', 'families', 'methods', '.']

>> Bigrams are: 
 [('terms', 'big'), ('big', 'data'), ('data', 'data'), ('data', 'pre-processing'), ('pre-processing', 'throughout'), ('throughout', 'families'), ('families', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('terms', 'big', 'data'), ('big', 'data', 'data'), ('data', 'data', 'pre-processing'), ('data', 'pre-processing', 'throughout'), ('pre-processing', 'throughout', 'families'), ('throughout', 'families', 'methods'), ('families', 'methods', '.')]

>> POS Tags are: 
 [('terms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('data', 'NNS'), ('pre-processing', 'NN'), ('throughout', 'IN'), ('families', 'NNS'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['terms', 'big data data pre-processing', 'families methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-process'), ('throughout', 'throughout'), ('families', 'famili'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-process'), ('throughout', 'throughout'), ('families', 'famili'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('throughout', 'throughout'), ('families', 'family'), ('methods', 'method'), ('.', '.')]


------------------- Sentence 2 -------------------

Moreover,

>> Tokens are: 
 ['Moreover', ',']

>> Bigrams are: 
 [('Moreover', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ',')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ',')]



========================================== PARAGRAPH 551 ===========================================

various big data framework such as Hadoop, Spark, and Flink were discussed.   

------------------- Sentence 1 -------------------

various big data framework such as Hadoop, Spark, and Flink were discussed.

>> Tokens are: 
 ['various', 'big', 'data', 'framework', 'Hadoop', ',', 'Spark', ',', 'Flink', 'discussed', '.']

>> Bigrams are: 
 [('various', 'big'), ('big', 'data'), ('data', 'framework'), ('framework', 'Hadoop'), ('Hadoop', ','), (',', 'Spark'), ('Spark', ','), (',', 'Flink'), ('Flink', 'discussed'), ('discussed', '.')]

>> Trigrams are: 
 [('various', 'big', 'data'), ('big', 'data', 'framework'), ('data', 'framework', 'Hadoop'), ('framework', 'Hadoop', ','), ('Hadoop', ',', 'Spark'), (',', 'Spark', ','), ('Spark', ',', 'Flink'), (',', 'Flink', 'discussed'), ('Flink', 'discussed', '.')]

>> POS Tags are: 
 [('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('framework', 'NN'), ('Hadoop', 'NNP'), (',', ','), ('Spark', 'NNP'), (',', ','), ('Flink', 'NNP'), ('discussed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['various big data framework Hadoop', 'Spark', 'Flink']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('GPE', 'Spark'), ('PERSON', 'Flink')] 

>> Stemming using Porter Stemmer: 
 [('various', 'variou'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'hadoop'), (',', ','), ('Spark', 'spark'), (',', ','), ('Flink', 'flink'), ('discussed', 'discuss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('various', 'various'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'hadoop'), (',', ','), ('Spark', 'spark'), (',', ','), ('Flink', 'flink'), ('discussed', 'discuss'), ('.', '.')]

>> Lemmatization: 
 [('various', 'various'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'Hadoop'), (',', ','), ('Spark', 'Spark'), (',', ','), ('Flink', 'Flink'), ('discussed', 'discussed'), ('.', '.')]



========================================== PARAGRAPH 552 ===========================================

  


========================================== PARAGRAPH 553 ===========================================

7.3. Big data analytics  

------------------- Sentence 1 -------------------

7.3.

>> Tokens are: 
 ['7.3', '.']

>> Bigrams are: 
 [('7.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Lemmatization: 
 [('7.3', '7.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics

>> Tokens are: 
 ['Big', 'data', 'analytics']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Big', 'data', 'analytics')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 554 ===========================================

Big data growth continues apace, and many organisations are now interested in managing and  

------------------- Sentence 1 -------------------

Big data growth continues apace, and many organisations are now interested in managing and

>> Tokens are: 
 ['Big', 'data', 'growth', 'continues', 'apace', ',', 'many', 'organisations', 'interested', 'managing']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'growth'), ('growth', 'continues'), ('continues', 'apace'), ('apace', ','), (',', 'many'), ('many', 'organisations'), ('organisations', 'interested'), ('interested', 'managing')]

>> Trigrams are: 
 [('Big', 'data', 'growth'), ('data', 'growth', 'continues'), ('growth', 'continues', 'apace'), ('continues', 'apace', ','), ('apace', ',', 'many'), (',', 'many', 'organisations'), ('many', 'organisations', 'interested'), ('organisations', 'interested', 'managing')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('growth', 'NN'), ('continues', 'VBZ'), ('apace', 'NN'), (',', ','), ('many', 'JJ'), ('organisations', 'NNS'), ('interested', 'JJ'), ('managing', 'VBG')]

>> Noun Phrases are: 
 ['Big data growth', 'apace', 'many organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continu'), ('apace', 'apac'), (',', ','), ('many', 'mani'), ('organisations', 'organis'), ('interested', 'interest'), ('managing', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continu'), ('apace', 'apac'), (',', ','), ('many', 'mani'), ('organisations', 'organis'), ('interested', 'interest'), ('managing', 'manag')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continues'), ('apace', 'apace'), (',', ','), ('many', 'many'), ('organisations', 'organisation'), ('interested', 'interested'), ('managing', 'managing')]



========================================== PARAGRAPH 555 ===========================================

analysing data. Organisations trying to benefit from big data are adopting big data analytics to  

------------------- Sentence 1 -------------------

analysing data.

>> Tokens are: 
 ['analysing', 'data', '.']

>> Bigrams are: 
 [('analysing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('analysing', 'data', '.')]

>> POS Tags are: 
 [('analysing', 'VBG'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('analysing', 'analysing'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Organisations trying to benefit from big data are adopting big data analytics to

>> Tokens are: 
 ['Organisations', 'trying', 'benefit', 'big', 'data', 'adopting', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('Organisations', 'trying'), ('trying', 'benefit'), ('benefit', 'big'), ('big', 'data'), ('data', 'adopting'), ('adopting', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Organisations', 'trying', 'benefit'), ('trying', 'benefit', 'big'), ('benefit', 'big', 'data'), ('big', 'data', 'adopting'), ('data', 'adopting', 'big'), ('adopting', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('trying', 'VBG'), ('benefit', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('adopting', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Organisations', 'benefit', 'big data', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('trying', 'tri'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('trying', 'tri'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('trying', 'trying'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopting'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 556 ===========================================

facilitate faster and better decisions, as it is not easy to analyse datasets with analysis techniques  

------------------- Sentence 1 -------------------

facilitate faster and better decisions, as it is not easy to analyse datasets with analysis techniques

>> Tokens are: 
 ['facilitate', 'faster', 'better', 'decisions', ',', 'easy', 'analyse', 'datasets', 'analysis', 'techniques']

>> Bigrams are: 
 [('facilitate', 'faster'), ('faster', 'better'), ('better', 'decisions'), ('decisions', ','), (',', 'easy'), ('easy', 'analyse'), ('analyse', 'datasets'), ('datasets', 'analysis'), ('analysis', 'techniques')]

>> Trigrams are: 
 [('facilitate', 'faster', 'better'), ('faster', 'better', 'decisions'), ('better', 'decisions', ','), ('decisions', ',', 'easy'), (',', 'easy', 'analyse'), ('easy', 'analyse', 'datasets'), ('analyse', 'datasets', 'analysis'), ('datasets', 'analysis', 'techniques')]

>> POS Tags are: 
 [('facilitate', 'NN'), ('faster', 'RBR'), ('better', 'JJR'), ('decisions', 'NNS'), (',', ','), ('easy', 'JJ'), ('analyse', 'JJ'), ('datasets', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['facilitate', 'decisions', 'easy analyse datasets analysis techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('facilitate', 'facilit'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decis'), (',', ','), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('analysis', 'analysi'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('facilitate', 'facilit'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decis'), (',', ','), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('analysis', 'analysi'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('facilitate', 'facilitate'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decision'), (',', ','), ('easy', 'easy'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('analysis', 'analysis'), ('techniques', 'technique')]



========================================== PARAGRAPH 557 ===========================================

and infrastructure based on traditional data management (Constantiou et al., 2015). The need for  

------------------- Sentence 1 -------------------

and infrastructure based on traditional data management (Constantiou et al., 2015).

>> Tokens are: 
 ['infrastructure', 'based', 'traditional', 'data', 'management', '(', 'Constantiou', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('infrastructure', 'based'), ('based', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', '('), ('(', 'Constantiou'), ('Constantiou', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('infrastructure', 'based', 'traditional'), ('based', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', '('), ('management', '(', 'Constantiou'), ('(', 'Constantiou', 'et'), ('Constantiou', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('infrastructure', 'NN'), ('based', 'VBN'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('(', '('), ('Constantiou', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['infrastructure', 'traditional data management', 'Constantiou']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('infrastructure', 'infrastructur'), ('based', 'base'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('(', '('), ('Constantiou', 'constanti'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('infrastructure', 'infrastructur'), ('based', 'base'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('(', '('), ('Constantiou', 'constantiou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('infrastructure', 'infrastructure'), ('based', 'based'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), ('(', '('), ('Constantiou', 'Constantiou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The need for

>> Tokens are: 
 ['The', 'need']

>> Bigrams are: 
 [('The', 'need')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('need', 'NN')]

>> Noun Phrases are: 
 ['The need']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('need', 'need')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('need', 'need')]

>> Lemmatization: 
 [('The', 'The'), ('need', 'need')]



========================================== PARAGRAPH 558 ===========================================

new tools and methods specialised for big data analytics is thus also growing. The emergence of  

------------------- Sentence 1 -------------------

new tools and methods specialised for big data analytics is thus also growing.

>> Tokens are: 
 ['new', 'tools', 'methods', 'specialised', 'big', 'data', 'analytics', 'thus', 'also', 'growing', '.']

>> Bigrams are: 
 [('new', 'tools'), ('tools', 'methods'), ('methods', 'specialised'), ('specialised', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'also'), ('also', 'growing'), ('growing', '.')]

>> Trigrams are: 
 [('new', 'tools', 'methods'), ('tools', 'methods', 'specialised'), ('methods', 'specialised', 'big'), ('specialised', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'also'), ('thus', 'also', 'growing'), ('also', 'growing', '.')]

>> POS Tags are: 
 [('new', 'JJ'), ('tools', 'NNS'), ('methods', 'NNS'), ('specialised', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('also', 'RB'), ('growing', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['new tools methods', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialis'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('also', 'also'), ('growing', 'grow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialis'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('also', 'also'), ('growing', 'grow'), ('.', '.')]

>> Lemmatization: 
 [('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialised'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('also', 'also'), ('growing', 'growing'), ('.', '.')]


------------------- Sentence 2 -------------------

The emergence of

>> Tokens are: 
 ['The', 'emergence']

>> Bigrams are: 
 [('The', 'emergence')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('emergence', 'NN')]

>> Noun Phrases are: 
 ['The emergence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('emergence', 'emerg')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('emergence', 'emerg')]

>> Lemmatization: 
 [('The', 'The'), ('emergence', 'emergence')]



========================================== PARAGRAPH 559 ===========================================

big data is affecting everything from data itself to its collection and processing, and, finally, the  

------------------- Sentence 1 -------------------

big data is affecting everything from data itself to its collection and processing, and, finally, the

>> Tokens are: 
 ['big', 'data', 'affecting', 'everything', 'data', 'collection', 'processing', ',', ',', 'finally', ',']

>> Bigrams are: 
 [('big', 'data'), ('data', 'affecting'), ('affecting', 'everything'), ('everything', 'data'), ('data', 'collection'), ('collection', 'processing'), ('processing', ','), (',', ','), (',', 'finally'), ('finally', ',')]

>> Trigrams are: 
 [('big', 'data', 'affecting'), ('data', 'affecting', 'everything'), ('affecting', 'everything', 'data'), ('everything', 'data', 'collection'), ('data', 'collection', 'processing'), ('collection', 'processing', ','), ('processing', ',', ','), (',', ',', 'finally'), (',', 'finally', ',')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('affecting', 'VBG'), ('everything', 'NN'), ('data', 'NNS'), ('collection', 'NN'), ('processing', 'NN'), (',', ','), (',', ','), ('finally', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['big data', 'everything data collection processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('affecting', 'affect'), ('everything', 'everyth'), ('data', 'data'), ('collection', 'collect'), ('processing', 'process'), (',', ','), (',', ','), ('finally', 'final'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('affecting', 'affect'), ('everything', 'everyth'), ('data', 'data'), ('collection', 'collect'), ('processing', 'process'), (',', ','), (',', ','), ('finally', 'final'), (',', ',')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('affecting', 'affecting'), ('everything', 'everything'), ('data', 'data'), ('collection', 'collection'), ('processing', 'processing'), (',', ','), (',', ','), ('finally', 'finally'), (',', ',')]



========================================== PARAGRAPH 560 ===========================================

extracted decisions. Providing big data tools and technologies can help in managing the growth of  

------------------- Sentence 1 -------------------

extracted decisions.

>> Tokens are: 
 ['extracted', 'decisions', '.']

>> Bigrams are: 
 [('extracted', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('extracted', 'decisions', '.')]

>> POS Tags are: 
 [('extracted', 'VBN'), ('decisions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extracted', 'extract'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('extracted', 'extract'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('extracted', 'extracted'), ('decisions', 'decision'), ('.', '.')]


------------------- Sentence 2 -------------------

Providing big data tools and technologies can help in managing the growth of

>> Tokens are: 
 ['Providing', 'big', 'data', 'tools', 'technologies', 'help', 'managing', 'growth']

>> Bigrams are: 
 [('Providing', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'technologies'), ('technologies', 'help'), ('help', 'managing'), ('managing', 'growth')]

>> Trigrams are: 
 [('Providing', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'technologies'), ('tools', 'technologies', 'help'), ('technologies', 'help', 'managing'), ('help', 'managing', 'growth')]

>> POS Tags are: 
 [('Providing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('tools', 'NNS'), ('technologies', 'NNS'), ('help', 'VBP'), ('managing', 'VBG'), ('growth', 'NN')]

>> Noun Phrases are: 
 ['big data tools technologies', 'growth']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Providing', 'provid'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technolog'), ('help', 'help'), ('managing', 'manag'), ('growth', 'growth')]

>> Stemming using Snowball Stemmer: 
 [('Providing', 'provid'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technolog'), ('help', 'help'), ('managing', 'manag'), ('growth', 'growth')]

>> Lemmatization: 
 [('Providing', 'Providing'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technology'), ('help', 'help'), ('managing', 'managing'), ('growth', 'growth')]



========================================== PARAGRAPH 561 ===========================================

network-produced data, which is otherwise exponential, as well as in increasing the capability of  

------------------- Sentence 1 -------------------

network-produced data, which is otherwise exponential, as well as in increasing the capability of

>> Tokens are: 
 ['network-produced', 'data', ',', 'otherwise', 'exponential', ',', 'well', 'increasing', 'capability']

>> Bigrams are: 
 [('network-produced', 'data'), ('data', ','), (',', 'otherwise'), ('otherwise', 'exponential'), ('exponential', ','), (',', 'well'), ('well', 'increasing'), ('increasing', 'capability')]

>> Trigrams are: 
 [('network-produced', 'data', ','), ('data', ',', 'otherwise'), (',', 'otherwise', 'exponential'), ('otherwise', 'exponential', ','), ('exponential', ',', 'well'), (',', 'well', 'increasing'), ('well', 'increasing', 'capability')]

>> POS Tags are: 
 [('network-produced', 'JJ'), ('data', 'NNS'), (',', ','), ('otherwise', 'RB'), ('exponential', 'JJ'), (',', ','), ('well', 'RB'), ('increasing', 'VBG'), ('capability', 'NN')]

>> Noun Phrases are: 
 ['network-produced data', 'capability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('network-produced', 'network-produc'), ('data', 'data'), (',', ','), ('otherwise', 'otherwis'), ('exponential', 'exponenti'), (',', ','), ('well', 'well'), ('increasing', 'increas'), ('capability', 'capabl')]

>> Stemming using Snowball Stemmer: 
 [('network-produced', 'network-produc'), ('data', 'data'), (',', ','), ('otherwise', 'otherwis'), ('exponential', 'exponenti'), (',', ','), ('well', 'well'), ('increasing', 'increas'), ('capability', 'capabl')]

>> Lemmatization: 
 [('network-produced', 'network-produced'), ('data', 'data'), (',', ','), ('otherwise', 'otherwise'), ('exponential', 'exponential'), (',', ','), ('well', 'well'), ('increasing', 'increasing'), ('capability', 'capability')]



========================================== PARAGRAPH 562 ===========================================

organisations to scale and capture the required data to reduce database performance problems  

------------------- Sentence 1 -------------------

organisations to scale and capture the required data to reduce database performance problems

>> Tokens are: 
 ['organisations', 'scale', 'capture', 'required', 'data', 'reduce', 'database', 'performance', 'problems']

>> Bigrams are: 
 [('organisations', 'scale'), ('scale', 'capture'), ('capture', 'required'), ('required', 'data'), ('data', 'reduce'), ('reduce', 'database'), ('database', 'performance'), ('performance', 'problems')]

>> Trigrams are: 
 [('organisations', 'scale', 'capture'), ('scale', 'capture', 'required'), ('capture', 'required', 'data'), ('required', 'data', 'reduce'), ('data', 'reduce', 'database'), ('reduce', 'database', 'performance'), ('database', 'performance', 'problems')]

>> POS Tags are: 
 [('organisations', 'NNS'), ('scale', 'JJ'), ('capture', 'NN'), ('required', 'VBN'), ('data', 'NNS'), ('reduce', 'VB'), ('database', 'NN'), ('performance', 'NN'), ('problems', 'NNS')]

>> Noun Phrases are: 
 ['organisations', 'scale capture', 'data', 'database performance problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organisations', 'organis'), ('scale', 'scale'), ('capture', 'captur'), ('required', 'requir'), ('data', 'data'), ('reduce', 'reduc'), ('database', 'databas'), ('performance', 'perform'), ('problems', 'problem')]

>> Stemming using Snowball Stemmer: 
 [('organisations', 'organis'), ('scale', 'scale'), ('capture', 'captur'), ('required', 'requir'), ('data', 'data'), ('reduce', 'reduc'), ('database', 'databas'), ('performance', 'perform'), ('problems', 'problem')]

>> Lemmatization: 
 [('organisations', 'organisation'), ('scale', 'scale'), ('capture', 'capture'), ('required', 'required'), ('data', 'data'), ('reduce', 'reduce'), ('database', 'database'), ('performance', 'performance'), ('problems', 'problem')]



========================================== PARAGRAPH 563 ===========================================

(Elgendy, N. and Elragal, A., 2014). Further big data analytics definitions are clarified in Table 4.  

------------------- Sentence 1 -------------------

(Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Further big data analytics definitions are clarified in Table 4.

>> Tokens are: 
 ['Further', 'big', 'data', 'analytics', 'definitions', 'clarified', 'Table', '4', '.']

>> Bigrams are: 
 [('Further', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'definitions'), ('definitions', 'clarified'), ('clarified', 'Table'), ('Table', '4'), ('4', '.')]

>> Trigrams are: 
 [('Further', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'definitions'), ('analytics', 'definitions', 'clarified'), ('definitions', 'clarified', 'Table'), ('clarified', 'Table', '4'), ('Table', '4', '.')]

>> POS Tags are: 
 [('Further', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('definitions', 'NNS'), ('clarified', 'VBD'), ('Table', 'JJ'), ('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics definitions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Further', 'further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('definitions', 'definit'), ('clarified', 'clarifi'), ('Table', 'tabl'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Further', 'further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('definitions', 'definit'), ('clarified', 'clarifi'), ('Table', 'tabl'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Further', 'Further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('definitions', 'definition'), ('clarified', 'clarified'), ('Table', 'Table'), ('4', '4'), ('.', '.')]



========================================== PARAGRAPH 564 ===========================================

Opening any popular scientific or business publication today, whether online or in the physical  

------------------- Sentence 1 -------------------

Opening any popular scientific or business publication today, whether online or in the physical

>> Tokens are: 
 ['Opening', 'popular', 'scientific', 'business', 'publication', 'today', ',', 'whether', 'online', 'physical']

>> Bigrams are: 
 [('Opening', 'popular'), ('popular', 'scientific'), ('scientific', 'business'), ('business', 'publication'), ('publication', 'today'), ('today', ','), (',', 'whether'), ('whether', 'online'), ('online', 'physical')]

>> Trigrams are: 
 [('Opening', 'popular', 'scientific'), ('popular', 'scientific', 'business'), ('scientific', 'business', 'publication'), ('business', 'publication', 'today'), ('publication', 'today', ','), ('today', ',', 'whether'), (',', 'whether', 'online'), ('whether', 'online', 'physical')]

>> POS Tags are: 
 [('Opening', 'VBG'), ('popular', 'JJ'), ('scientific', 'JJ'), ('business', 'NN'), ('publication', 'NN'), ('today', 'NN'), (',', ','), ('whether', 'IN'), ('online', 'JJ'), ('physical', 'JJ')]

>> Noun Phrases are: 
 ['popular scientific business publication today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Opening', 'open'), ('popular', 'popular'), ('scientific', 'scientif'), ('business', 'busi'), ('publication', 'public'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'onlin'), ('physical', 'physic')]

>> Stemming using Snowball Stemmer: 
 [('Opening', 'open'), ('popular', 'popular'), ('scientific', 'scientif'), ('business', 'busi'), ('publication', 'public'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'onlin'), ('physical', 'physic')]

>> Lemmatization: 
 [('Opening', 'Opening'), ('popular', 'popular'), ('scientific', 'scientific'), ('business', 'business'), ('publication', 'publication'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'online'), ('physical', 'physical')]



========================================== PARAGRAPH 565 ===========================================

world, generally involves running into a reference to data science, analytics, big data, or some  

------------------- Sentence 1 -------------------

world, generally involves running into a reference to data science, analytics, big data, or some

>> Tokens are: 
 ['world', ',', 'generally', 'involves', 'running', 'reference', 'data', 'science', ',', 'analytics', ',', 'big', 'data', ',']

>> Bigrams are: 
 [('world', ','), (',', 'generally'), ('generally', 'involves'), ('involves', 'running'), ('running', 'reference'), ('reference', 'data'), ('data', 'science'), ('science', ','), (',', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', ',')]

>> Trigrams are: 
 [('world', ',', 'generally'), (',', 'generally', 'involves'), ('generally', 'involves', 'running'), ('involves', 'running', 'reference'), ('running', 'reference', 'data'), ('reference', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ',')]

>> POS Tags are: 
 [('world', 'NN'), (',', ','), ('generally', 'RB'), ('involves', 'VBZ'), ('running', 'VBG'), ('reference', 'NN'), ('data', 'NNS'), ('science', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['world', 'reference data science', 'analytics', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('world', 'world'), (',', ','), ('generally', 'gener'), ('involves', 'involv'), ('running', 'run'), ('reference', 'refer'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('world', 'world'), (',', ','), ('generally', 'general'), ('involves', 'involv'), ('running', 'run'), ('reference', 'refer'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('world', 'world'), (',', ','), ('generally', 'generally'), ('involves', 'involves'), ('running', 'running'), ('reference', 'reference'), ('data', 'data'), ('science', 'science'), (',', ','), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 566 ===========================================

combination of these terms (Agarwal and Dhar, 2014). Some researchers are focusing on big data  

------------------- Sentence 1 -------------------

combination of these terms (Agarwal and Dhar, 2014).

>> Tokens are: 
 ['combination', 'terms', '(', 'Agarwal', 'Dhar', ',', '2014', ')', '.']

>> Bigrams are: 
 [('combination', 'terms'), ('terms', '('), ('(', 'Agarwal'), ('Agarwal', 'Dhar'), ('Dhar', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('combination', 'terms', '('), ('terms', '(', 'Agarwal'), ('(', 'Agarwal', 'Dhar'), ('Agarwal', 'Dhar', ','), ('Dhar', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('combination', 'NN'), ('terms', 'NNS'), ('(', '('), ('Agarwal', 'NNP'), ('Dhar', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['combination terms', 'Agarwal Dhar']

>> Named Entities are: 
 [('ORGANIZATION', 'Agarwal Dhar')] 

>> Stemming using Porter Stemmer: 
 [('combination', 'combin'), ('terms', 'term'), ('(', '('), ('Agarwal', 'agarw'), ('Dhar', 'dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('combination', 'combin'), ('terms', 'term'), ('(', '('), ('Agarwal', 'agarw'), ('Dhar', 'dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('combination', 'combination'), ('terms', 'term'), ('(', '('), ('Agarwal', 'Agarwal'), ('Dhar', 'Dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Some researchers are focusing on big data

>> Tokens are: 
 ['Some', 'researchers', 'focusing', 'big', 'data']

>> Bigrams are: 
 [('Some', 'researchers'), ('researchers', 'focusing'), ('focusing', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Some', 'researchers', 'focusing'), ('researchers', 'focusing', 'big'), ('focusing', 'big', 'data')]

>> POS Tags are: 
 [('Some', 'DT'), ('researchers', 'NNS'), ('focusing', 'VBG'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Some researchers', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('researchers', 'research'), ('focusing', 'focus'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('researchers', 'research'), ('focusing', 'focus'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Some', 'Some'), ('researchers', 'researcher'), ('focusing', 'focusing'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 567 ===========================================

definitions (Akter et al., 2016; Mikalef et al., 2018), while others analyse the tools, techniques,  

------------------- Sentence 1 -------------------

definitions (Akter et al., 2016; Mikalef et al., 2018), while others analyse the tools, techniques,

>> Tokens are: 
 ['definitions', '(', 'Akter', 'et', 'al.', ',', '2016', ';', 'Mikalef', 'et', 'al.', ',', '2018', ')', ',', 'others', 'analyse', 'tools', ',', 'techniques', ',']

>> Bigrams are: 
 [('definitions', '('), ('(', 'Akter'), ('Akter', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', ','), (',', 'others'), ('others', 'analyse'), ('analyse', 'tools'), ('tools', ','), (',', 'techniques'), ('techniques', ',')]

>> Trigrams are: 
 [('definitions', '(', 'Akter'), ('(', 'Akter', 'et'), ('Akter', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Mikalef'), (';', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', ','), (')', ',', 'others'), (',', 'others', 'analyse'), ('others', 'analyse', 'tools'), ('analyse', 'tools', ','), ('tools', ',', 'techniques'), (',', 'techniques', ',')]

>> POS Tags are: 
 [('definitions', 'NNS'), ('(', '('), ('Akter', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (';', ':'), ('Mikalef', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('others', 'NNS'), ('analyse', 'VBP'), ('tools', 'NNS'), (',', ','), ('techniques', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['definitions', 'Akter', 'Mikalef', 'al.', 'others', 'tools', 'techniques']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('definitions', 'definit'), ('(', '('), ('Akter', 'akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'other'), ('analyse', 'analys'), ('tools', 'tool'), (',', ','), ('techniques', 'techniqu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('definitions', 'definit'), ('(', '('), ('Akter', 'akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'other'), ('analyse', 'analys'), ('tools', 'tool'), (',', ','), ('techniques', 'techniqu'), (',', ',')]

>> Lemmatization: 
 [('definitions', 'definition'), ('(', '('), ('Akter', 'Akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'others'), ('analyse', 'analyse'), ('tools', 'tool'), (',', ','), ('techniques', 'technique'), (',', ',')]



========================================== PARAGRAPH 568 ===========================================

and procedures required for analysis (Russom, 2011), and others seek to explain big data analytics’  

------------------- Sentence 1 -------------------

and procedures required for analysis (Russom, 2011), and others seek to explain big data analytics’

>> Tokens are: 
 ['procedures', 'required', 'analysis', '(', 'Russom', ',', '2011', ')', ',', 'others', 'seek', 'explain', 'big', 'data', 'analytics', '’']

>> Bigrams are: 
 [('procedures', 'required'), ('required', 'analysis'), ('analysis', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', ','), (',', 'others'), ('others', 'seek'), ('seek', 'explain'), ('explain', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '’')]

>> Trigrams are: 
 [('procedures', 'required', 'analysis'), ('required', 'analysis', '('), ('analysis', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', ','), (')', ',', 'others'), (',', 'others', 'seek'), ('others', 'seek', 'explain'), ('seek', 'explain', 'big'), ('explain', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '’')]

>> POS Tags are: 
 [('procedures', 'NNS'), ('required', 'VBN'), ('analysis', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), (',', ','), ('others', 'NNS'), ('seek', 'VBP'), ('explain', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('’', 'VBP')]

>> Noun Phrases are: 
 ['procedures', 'analysis', 'Russom', 'others', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('procedures', 'procedur'), ('required', 'requir'), ('analysis', 'analysi'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'other'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’')]

>> Stemming using Snowball Stemmer: 
 [('procedures', 'procedur'), ('required', 'requir'), ('analysis', 'analysi'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'other'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’')]

>> Lemmatization: 
 [('procedures', 'procedure'), ('required', 'required'), ('analysis', 'analysis'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'others'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('’', '’')]



========================================== PARAGRAPH 569 ===========================================

impact on business value ( Mikalef et al., 2018). 

------------------- Sentence 1 -------------------

impact on business value ( Mikalef et al., 2018).

>> Tokens are: 
 ['impact', 'business', 'value', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('impact', 'business'), ('business', 'value'), ('value', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('impact', 'business', 'value'), ('business', 'value', '('), ('value', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('impact', 'NN'), ('business', 'NN'), ('value', 'NN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['impact business value', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('impact', 'impact'), ('business', 'busi'), ('value', 'valu'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('impact', 'impact'), ('business', 'busi'), ('value', 'valu'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('impact', 'impact'), ('business', 'business'), ('value', 'value'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 570 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 571 ===========================================

21  

------------------- Sentence 1 -------------------

21

>> Tokens are: 
 ['21']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('21', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('21', '21')]

>> Stemming using Snowball Stemmer: 
 [('21', '21')]

>> Lemmatization: 
 [('21', '21')]



========================================== PARAGRAPH 572 ===========================================

  


========================================== PARAGRAPH 573 ===========================================

Table 4: Sample definitions of big data analytics, adopted from (Mikalef et al., 2018)  

------------------- Sentence 1 -------------------

Table 4: Sample definitions of big data analytics, adopted from (Mikalef et al., 2018)

>> Tokens are: 
 ['Table', '4', ':', 'Sample', 'definitions', 'big', 'data', 'analytics', ',', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')']

>> Bigrams are: 
 [('Table', '4'), ('4', ':'), (':', 'Sample'), ('Sample', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')')]

>> Trigrams are: 
 [('Table', '4', ':'), ('4', ':', 'Sample'), (':', 'Sample', 'definitions'), ('Sample', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')')]

>> POS Tags are: 
 [('Table', 'JJ'), ('4', 'CD'), (':', ':'), ('Sample', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Sample definitions', 'big data analytics', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('4', '4'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('4', '4'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]

>> Lemmatization: 
 [('Table', 'Table'), ('4', '4'), (':', ':'), ('Sample', 'Sample'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')')]



========================================== PARAGRAPH 574 ===========================================

  


========================================== PARAGRAPH 575 ===========================================

  


========================================== PARAGRAPH 576 ===========================================

People now aim to both to collect data and understand its importance and meaning for use in  

------------------- Sentence 1 -------------------

People now aim to both to collect data and understand its importance and meaning for use in

>> Tokens are: 
 ['People', 'aim', 'collect', 'data', 'understand', 'importance', 'meaning', 'use']

>> Bigrams are: 
 [('People', 'aim'), ('aim', 'collect'), ('collect', 'data'), ('data', 'understand'), ('understand', 'importance'), ('importance', 'meaning'), ('meaning', 'use')]

>> Trigrams are: 
 [('People', 'aim', 'collect'), ('aim', 'collect', 'data'), ('collect', 'data', 'understand'), ('data', 'understand', 'importance'), ('understand', 'importance', 'meaning'), ('importance', 'meaning', 'use')]

>> POS Tags are: 
 [('People', 'NNS'), ('aim', 'VBP'), ('collect', 'JJ'), ('data', 'NNS'), ('understand', 'VBP'), ('importance', 'NN'), ('meaning', 'NN'), ('use', 'NN')]

>> Noun Phrases are: 
 ['People', 'collect data', 'importance meaning use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('People', 'peopl'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'import'), ('meaning', 'mean'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('People', 'peopl'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'import'), ('meaning', 'mean'), ('use', 'use')]

>> Lemmatization: 
 [('People', 'People'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'importance'), ('meaning', 'meaning'), ('use', 'use')]



========================================== PARAGRAPH 577 ===========================================

making decisions. The data to be analysed is large in volume and consists of various types.  

------------------- Sentence 1 -------------------

making decisions.

>> Tokens are: 
 ['making', 'decisions', '.']

>> Bigrams are: 
 [('making', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('making', 'decisions', '.')]

>> POS Tags are: 
 [('making', 'VBG'), ('decisions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('making', 'make'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('making', 'make'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('making', 'making'), ('decisions', 'decision'), ('.', '.')]


------------------- Sentence 2 -------------------

The data to be analysed is large in volume and consists of various types.

>> Tokens are: 
 ['The', 'data', 'analysed', 'large', 'volume', 'consists', 'various', 'types', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'analysed'), ('analysed', 'large'), ('large', 'volume'), ('volume', 'consists'), ('consists', 'various'), ('various', 'types'), ('types', '.')]

>> Trigrams are: 
 [('The', 'data', 'analysed'), ('data', 'analysed', 'large'), ('analysed', 'large', 'volume'), ('large', 'volume', 'consists'), ('volume', 'consists', 'various'), ('consists', 'various', 'types'), ('various', 'types', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('analysed', 'VBD'), ('large', 'JJ'), ('volume', 'NN'), ('consists', 'VBZ'), ('various', 'JJ'), ('types', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The data', 'large volume', 'various types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('analysed', 'analys'), ('large', 'larg'), ('volume', 'volum'), ('consists', 'consist'), ('various', 'variou'), ('types', 'type'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('analysed', 'analys'), ('large', 'larg'), ('volume', 'volum'), ('consists', 'consist'), ('various', 'various'), ('types', 'type'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('analysed', 'analysed'), ('large', 'large'), ('volume', 'volume'), ('consists', 'consists'), ('various', 'various'), ('types', 'type'), ('.', '.')]



========================================== PARAGRAPH 578 ===========================================

"Massive, high dimensional, heterogeneous, complex, unstructured, incomplete, noisy, and  

------------------- Sentence 1 -------------------

"Massive, high dimensional, heterogeneous, complex, unstructured, incomplete, noisy, and

>> Tokens are: 
 ['``', 'Massive', ',', 'high', 'dimensional', ',', 'heterogeneous', ',', 'complex', ',', 'unstructured', ',', 'incomplete', ',', 'noisy', ',']

>> Bigrams are: 
 [('``', 'Massive'), ('Massive', ','), (',', 'high'), ('high', 'dimensional'), ('dimensional', ','), (',', 'heterogeneous'), ('heterogeneous', ','), (',', 'complex'), ('complex', ','), (',', 'unstructured'), ('unstructured', ','), (',', 'incomplete'), ('incomplete', ','), (',', 'noisy'), ('noisy', ',')]

>> Trigrams are: 
 [('``', 'Massive', ','), ('Massive', ',', 'high'), (',', 'high', 'dimensional'), ('high', 'dimensional', ','), ('dimensional', ',', 'heterogeneous'), (',', 'heterogeneous', ','), ('heterogeneous', ',', 'complex'), (',', 'complex', ','), ('complex', ',', 'unstructured'), (',', 'unstructured', ','), ('unstructured', ',', 'incomplete'), (',', 'incomplete', ','), ('incomplete', ',', 'noisy'), (',', 'noisy', ',')]

>> POS Tags are: 
 [('``', '``'), ('Massive', 'NNP'), (',', ','), ('high', 'JJ'), ('dimensional', 'NN'), (',', ','), ('heterogeneous', 'JJ'), (',', ','), ('complex', 'JJ'), (',', ','), ('unstructured', 'JJ'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('noisy', 'JJ'), (',', ',')]

>> Noun Phrases are: 
 ['Massive', 'high dimensional']

>> Named Entities are: 
 [('PERSON', 'Massive')] 

>> Stemming using Porter Stemmer: 
 [('``', '``'), ('Massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('``', '``'), ('Massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ',')]

>> Lemmatization: 
 [('``', '``'), ('Massive', 'Massive'), (',', ','), ('high', 'high'), ('dimensional', 'dimensional'), (',', ','), ('heterogeneous', 'heterogeneous'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructured'), (',', ','), ('incomplete', 'incomplete'), (',', ','), ('noisy', 'noisy'), (',', ',')]



========================================== PARAGRAPH 579 ===========================================

erroneous" (Ma et al., 2014), are features of big data that require changes in statistical and data  

------------------- Sentence 1 -------------------

erroneous" (Ma et al., 2014), are features of big data that require changes in statistical and data

>> Tokens are: 
 ['erroneous', "''", '(', 'Ma', 'et', 'al.', ',', '2014', ')', ',', 'features', 'big', 'data', 'require', 'changes', 'statistical', 'data']

>> Bigrams are: 
 [('erroneous', "''"), ("''", '('), ('(', 'Ma'), ('Ma', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', ','), (',', 'features'), ('features', 'big'), ('big', 'data'), ('data', 'require'), ('require', 'changes'), ('changes', 'statistical'), ('statistical', 'data')]

>> Trigrams are: 
 [('erroneous', "''", '('), ("''", '(', 'Ma'), ('(', 'Ma', 'et'), ('Ma', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ','), (')', ',', 'features'), (',', 'features', 'big'), ('features', 'big', 'data'), ('big', 'data', 'require'), ('data', 'require', 'changes'), ('require', 'changes', 'statistical'), ('changes', 'statistical', 'data')]

>> POS Tags are: 
 [('erroneous', 'JJ'), ("''", "''"), ('(', '('), ('Ma', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), (',', ','), ('features', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('require', 'VBP'), ('changes', 'NNS'), ('statistical', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Ma', 'big data', 'changes', 'statistical data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('erroneous', 'erron'), ("''", "''"), ('(', '('), ('Ma', 'ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('changes', 'chang'), ('statistical', 'statist'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('erroneous', 'erron'), ("''", "''"), ('(', '('), ('Ma', 'ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('changes', 'chang'), ('statistical', 'statist'), ('data', 'data')]

>> Lemmatization: 
 [('erroneous', 'erroneous'), ("''", "''"), ('(', '('), ('Ma', 'Ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'feature'), ('big', 'big'), ('data', 'data'), ('require', 'require'), ('changes', 'change'), ('statistical', 'statistical'), ('data', 'data')]



========================================== PARAGRAPH 580 ===========================================

analysis approaches.   

------------------- Sentence 1 -------------------

analysis approaches.

>> Tokens are: 
 ['analysis', 'approaches', '.']

>> Bigrams are: 
 [('analysis', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('analysis', 'approaches', '.')]

>> POS Tags are: 
 [('analysis', 'NN'), ('approaches', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('approaches', 'approach'), ('.', '.')]



========================================== PARAGRAPH 581 ===========================================

It is also important to understand the content of big data. The process of applying algorithms to  

------------------- Sentence 1 -------------------

It is also important to understand the content of big data.

>> Tokens are: 
 ['It', 'also', 'important', 'understand', 'content', 'big', 'data', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'important'), ('important', 'understand'), ('understand', 'content'), ('content', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('It', 'also', 'important'), ('also', 'important', 'understand'), ('important', 'understand', 'content'), ('understand', 'content', 'big'), ('content', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('important', 'JJ'), ('understand', 'NN'), ('content', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['important understand content', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('important', 'import'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('important', 'import'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('important', 'important'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The process of applying algorithms to

>> Tokens are: 
 ['The', 'process', 'applying', 'algorithms']

>> Bigrams are: 
 [('The', 'process'), ('process', 'applying'), ('applying', 'algorithms')]

>> Trigrams are: 
 [('The', 'process', 'applying'), ('process', 'applying', 'algorithms')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('applying', 'VBG'), ('algorithms', 'NN')]

>> Noun Phrases are: 
 ['The process', 'algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('applying', 'applying'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 582 ===========================================

analyse the content of big data is part of data analytics, which is used for 1) analysing sets of data  

------------------- Sentence 1 -------------------

analyse the content of big data is part of data analytics, which is used for 1) analysing sets of data

>> Tokens are: 
 ['analyse', 'content', 'big', 'data', 'part', 'data', 'analytics', ',', 'used', '1', ')', 'analysing', 'sets', 'data']

>> Bigrams are: 
 [('analyse', 'content'), ('content', 'big'), ('big', 'data'), ('data', 'part'), ('part', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'used'), ('used', '1'), ('1', ')'), (')', 'analysing'), ('analysing', 'sets'), ('sets', 'data')]

>> Trigrams are: 
 [('analyse', 'content', 'big'), ('content', 'big', 'data'), ('big', 'data', 'part'), ('data', 'part', 'data'), ('part', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'used'), (',', 'used', '1'), ('used', '1', ')'), ('1', ')', 'analysing'), (')', 'analysing', 'sets'), ('analysing', 'sets', 'data')]

>> POS Tags are: 
 [('analyse', 'NN'), ('content', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('part', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('used', 'VBD'), ('1', 'CD'), (')', ')'), ('analysing', 'VBG'), ('sets', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['analyse content', 'big data part data analytics', 'sets data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyse', 'analys'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('used', 'use'), ('1', '1'), (')', ')'), ('analysing', 'analys'), ('sets', 'set'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('analyse', 'analys'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('used', 'use'), ('1', '1'), (')', ')'), ('analysing', 'analys'), ('sets', 'set'), ('data', 'data')]

>> Lemmatization: 
 [('analyse', 'analyse'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('used', 'used'), ('1', '1'), (')', ')'), ('analysing', 'analysing'), ('sets', 'set'), ('data', 'data')]



========================================== PARAGRAPH 583 ===========================================

information and their relationships, 2) extracting previously unknown valid patterns, and 3) for  

------------------- Sentence 1 -------------------

information and their relationships, 2) extracting previously unknown valid patterns, and 3) for

>> Tokens are: 
 ['information', 'relationships', ',', '2', ')', 'extracting', 'previously', 'unknown', 'valid', 'patterns', ',', '3', ')']

>> Bigrams are: 
 [('information', 'relationships'), ('relationships', ','), (',', '2'), ('2', ')'), (')', 'extracting'), ('extracting', 'previously'), ('previously', 'unknown'), ('unknown', 'valid'), ('valid', 'patterns'), ('patterns', ','), (',', '3'), ('3', ')')]

>> Trigrams are: 
 [('information', 'relationships', ','), ('relationships', ',', '2'), (',', '2', ')'), ('2', ')', 'extracting'), (')', 'extracting', 'previously'), ('extracting', 'previously', 'unknown'), ('previously', 'unknown', 'valid'), ('unknown', 'valid', 'patterns'), ('valid', 'patterns', ','), ('patterns', ',', '3'), (',', '3', ')')]

>> POS Tags are: 
 [('information', 'NN'), ('relationships', 'NNS'), (',', ','), ('2', 'CD'), (')', ')'), ('extracting', 'VBG'), ('previously', 'RB'), ('unknown', 'JJ'), ('valid', 'JJ'), ('patterns', 'NNS'), (',', ','), ('3', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['information relationships', 'unknown valid patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extract'), ('previously', 'previous'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extract'), ('previously', 'previous'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')')]

>> Lemmatization: 
 [('information', 'information'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extracting'), ('previously', 'previously'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')')]



========================================== PARAGRAPH 584 ===========================================

detecting important relationships between stored variables.   

------------------- Sentence 1 -------------------

detecting important relationships between stored variables.

>> Tokens are: 
 ['detecting', 'important', 'relationships', 'stored', 'variables', '.']

>> Bigrams are: 
 [('detecting', 'important'), ('important', 'relationships'), ('relationships', 'stored'), ('stored', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('detecting', 'important', 'relationships'), ('important', 'relationships', 'stored'), ('relationships', 'stored', 'variables'), ('stored', 'variables', '.')]

>> POS Tags are: 
 [('detecting', 'VBG'), ('important', 'JJ'), ('relationships', 'NNS'), ('stored', 'VBD'), ('variables', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['important relationships', 'variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('detecting', 'detect'), ('important', 'import'), ('relationships', 'relationship'), ('stored', 'store'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('detecting', 'detect'), ('important', 'import'), ('relationships', 'relationship'), ('stored', 'store'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('detecting', 'detecting'), ('important', 'important'), ('relationships', 'relationship'), ('stored', 'stored'), ('variables', 'variable'), ('.', '.')]



========================================== PARAGRAPH 585 ===========================================

In this section, various big data analyses will be discussed, beginning with the data analysis  

------------------- Sentence 1 -------------------

In this section, various big data analyses will be discussed, beginning with the data analysis

>> Tokens are: 
 ['In', 'section', ',', 'various', 'big', 'data', 'analyses', 'discussed', ',', 'beginning', 'data', 'analysis']

>> Bigrams are: 
 [('In', 'section'), ('section', ','), (',', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'analyses'), ('analyses', 'discussed'), ('discussed', ','), (',', 'beginning'), ('beginning', 'data'), ('data', 'analysis')]

>> Trigrams are: 
 [('In', 'section', ','), ('section', ',', 'various'), (',', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'analyses'), ('data', 'analyses', 'discussed'), ('analyses', 'discussed', ','), ('discussed', ',', 'beginning'), (',', 'beginning', 'data'), ('beginning', 'data', 'analysis')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), (',', ','), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analyses', 'NNS'), ('discussed', 'VBD'), (',', ','), ('beginning', 'VBG'), ('data', 'NNS'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['section', 'various big data analyses', 'data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('analyses', 'analys'), ('discussed', 'discuss'), (',', ','), ('beginning', 'begin'), ('data', 'data'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analyses', 'analys'), ('discussed', 'discuss'), (',', ','), ('beginning', 'begin'), ('data', 'data'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analyses', 'analysis'), ('discussed', 'discussed'), (',', ','), ('beginning', 'beginning'), ('data', 'data'), ('analysis', 'analysis')]



========================================== PARAGRAPH 586 ===========================================

techniques available and some of the common big data analytics suites, finally discussing several  

------------------- Sentence 1 -------------------

techniques available and some of the common big data analytics suites, finally discussing several

>> Tokens are: 
 ['techniques', 'available', 'common', 'big', 'data', 'analytics', 'suites', ',', 'finally', 'discussing', 'several']

>> Bigrams are: 
 [('techniques', 'available'), ('available', 'common'), ('common', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'suites'), ('suites', ','), (',', 'finally'), ('finally', 'discussing'), ('discussing', 'several')]

>> Trigrams are: 
 [('techniques', 'available', 'common'), ('available', 'common', 'big'), ('common', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'suites'), ('analytics', 'suites', ','), ('suites', ',', 'finally'), (',', 'finally', 'discussing'), ('finally', 'discussing', 'several')]

>> POS Tags are: 
 [('techniques', 'NNS'), ('available', 'JJ'), ('common', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('suites', 'NNS'), (',', ','), ('finally', 'RB'), ('discussing', 'VBG'), ('several', 'JJ')]

>> Noun Phrases are: 
 ['techniques', 'available common big data analytics suites']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('available', 'avail'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('suites', 'suit'), (',', ','), ('finally', 'final'), ('discussing', 'discuss'), ('several', 'sever')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('available', 'avail'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('suites', 'suit'), (',', ','), ('finally', 'final'), ('discussing', 'discuss'), ('several', 'sever')]

>> Lemmatization: 
 [('techniques', 'technique'), ('available', 'available'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('suites', 'suite'), (',', ','), ('finally', 'finally'), ('discussing', 'discussing'), ('several', 'several')]



========================================== PARAGRAPH 587 ===========================================

big data platforms and tools. Data analysis techniques can be characterised into four types, as  

------------------- Sentence 1 -------------------

big data platforms and tools.

>> Tokens are: 
 ['big', 'data', 'platforms', 'tools', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data platforms tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

Data analysis techniques can be characterised into four types, as

>> Tokens are: 
 ['Data', 'analysis', 'techniques', 'characterised', 'four', 'types', ',']

>> Bigrams are: 
 [('Data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'characterised'), ('characterised', 'four'), ('four', 'types'), ('types', ',')]

>> Trigrams are: 
 [('Data', 'analysis', 'techniques'), ('analysis', 'techniques', 'characterised'), ('techniques', 'characterised', 'four'), ('characterised', 'four', 'types'), ('four', 'types', ',')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analysis', 'NN'), ('techniques', 'NNS'), ('characterised', 'VBD'), ('four', 'CD'), ('types', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Data analysis techniques', 'types']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('types', 'type'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('types', 'type'), (',', ',')]

>> Lemmatization: 
 [('Data', 'Data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('characterised', 'characterised'), ('four', 'four'), ('types', 'type'), (',', ',')]



========================================== PARAGRAPH 588 ===========================================

shown in Figure 12:  

------------------- Sentence 1 -------------------

shown in Figure 12:

>> Tokens are: 
 ['shown', 'Figure', '12', ':']

>> Bigrams are: 
 [('shown', 'Figure'), ('Figure', '12'), ('12', ':')]

>> Trigrams are: 
 [('shown', 'Figure', '12'), ('Figure', '12', ':')]

>> POS Tags are: 
 [('shown', 'VBN'), ('Figure', 'NN'), ('12', 'CD'), (':', ':')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('12', '12'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('12', '12'), (':', ':')]

>> Lemmatization: 
 [('shown', 'shown'), ('Figure', 'Figure'), ('12', '12'), (':', ':')]



========================================== PARAGRAPH 589 ===========================================

 


========================================== PARAGRAPH 590 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 591 ===========================================

22  

------------------- Sentence 1 -------------------

22

>> Tokens are: 
 ['22']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('22', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22')]

>> Stemming using Snowball Stemmer: 
 [('22', '22')]

>> Lemmatization: 
 [('22', '22')]



========================================== PARAGRAPH 592 ===========================================

  


========================================== PARAGRAPH 593 ===========================================

  


========================================== PARAGRAPH 594 ===========================================

Figure 12: Data analysis techniques  

------------------- Sentence 1 -------------------

Figure 12: Data analysis techniques

>> Tokens are: 
 ['Figure', '12', ':', 'Data', 'analysis', 'techniques']

>> Bigrams are: 
 [('Figure', '12'), ('12', ':'), (':', 'Data'), ('Data', 'analysis'), ('analysis', 'techniques')]

>> Trigrams are: 
 [('Figure', '12', ':'), ('12', ':', 'Data'), (':', 'Data', 'analysis'), ('Data', 'analysis', 'techniques')]

>> POS Tags are: 
 [('Figure', 'NN'), ('12', 'CD'), (':', ':'), ('Data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Figure', 'Data analysis techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('12', '12'), (':', ':'), ('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('12', '12'), (':', ':'), ('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('12', '12'), (':', ':'), ('Data', 'Data'), ('analysis', 'analysis'), ('techniques', 'technique')]



========================================== PARAGRAPH 595 ===========================================

  


========================================== PARAGRAPH 596 ===========================================

  


========================================== PARAGRAPH 597 ===========================================

7.1.1. Supervised techniques    

------------------- Sentence 1 -------------------

7.1.1.

>> Tokens are: 
 ['7.1.1', '.']

>> Bigrams are: 
 [('7.1.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.1', '7.1.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.1', '7.1.1'), ('.', '.')]

>> Lemmatization: 
 [('7.1.1', '7.1.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Supervised techniques

>> Tokens are: 
 ['Supervised', 'techniques']

>> Bigrams are: 
 [('Supervised', 'techniques')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Supervised', 'VBN'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('techniques', 'technique')]



========================================== PARAGRAPH 598 ===========================================

A supervised technique refers to where data are trained and tested, and the training data is labelled.  

------------------- Sentence 1 -------------------

A supervised technique refers to where data are trained and tested, and the training data is labelled.

>> Tokens are: 
 ['A', 'supervised', 'technique', 'refers', 'data', 'trained', 'tested', ',', 'training', 'data', 'labelled', '.']

>> Bigrams are: 
 [('A', 'supervised'), ('supervised', 'technique'), ('technique', 'refers'), ('refers', 'data'), ('data', 'trained'), ('trained', 'tested'), ('tested', ','), (',', 'training'), ('training', 'data'), ('data', 'labelled'), ('labelled', '.')]

>> Trigrams are: 
 [('A', 'supervised', 'technique'), ('supervised', 'technique', 'refers'), ('technique', 'refers', 'data'), ('refers', 'data', 'trained'), ('data', 'trained', 'tested'), ('trained', 'tested', ','), ('tested', ',', 'training'), (',', 'training', 'data'), ('training', 'data', 'labelled'), ('data', 'labelled', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('supervised', 'JJ'), ('technique', 'NN'), ('refers', 'NNS'), ('data', 'NNS'), ('trained', 'VBD'), ('tested', 'VBN'), (',', ','), ('training', 'VBG'), ('data', 'NNS'), ('labelled', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['A supervised technique refers data', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('supervised', 'supervis'), ('technique', 'techniqu'), ('refers', 'refer'), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), (',', ','), ('training', 'train'), ('data', 'data'), ('labelled', 'label'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('supervised', 'supervis'), ('technique', 'techniqu'), ('refers', 'refer'), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), (',', ','), ('training', 'train'), ('data', 'data'), ('labelled', 'label'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('supervised', 'supervised'), ('technique', 'technique'), ('refers', 'refers'), ('data', 'data'), ('trained', 'trained'), ('tested', 'tested'), (',', ','), ('training', 'training'), ('data', 'data'), ('labelled', 'labelled'), ('.', '.')]



========================================== PARAGRAPH 599 ===========================================

Labelled means that the full history of what has happened to the data is known, and thus the history  

------------------- Sentence 1 -------------------

Labelled means that the full history of what has happened to the data is known, and thus the history

>> Tokens are: 
 ['Labelled', 'means', 'full', 'history', 'happened', 'data', 'known', ',', 'thus', 'history']

>> Bigrams are: 
 [('Labelled', 'means'), ('means', 'full'), ('full', 'history'), ('history', 'happened'), ('happened', 'data'), ('data', 'known'), ('known', ','), (',', 'thus'), ('thus', 'history')]

>> Trigrams are: 
 [('Labelled', 'means', 'full'), ('means', 'full', 'history'), ('full', 'history', 'happened'), ('history', 'happened', 'data'), ('happened', 'data', 'known'), ('data', 'known', ','), ('known', ',', 'thus'), (',', 'thus', 'history')]

>> POS Tags are: 
 [('Labelled', 'VBN'), ('means', 'NNS'), ('full', 'JJ'), ('history', 'NN'), ('happened', 'VBD'), ('data', 'NNS'), ('known', 'VBN'), (',', ','), ('thus', 'RB'), ('history', 'NN')]

>> Noun Phrases are: 
 ['means', 'full history', 'data', 'history']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Labelled', 'label'), ('means', 'mean'), ('full', 'full'), ('history', 'histori'), ('happened', 'happen'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thu'), ('history', 'histori')]

>> Stemming using Snowball Stemmer: 
 [('Labelled', 'label'), ('means', 'mean'), ('full', 'full'), ('history', 'histori'), ('happened', 'happen'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thus'), ('history', 'histori')]

>> Lemmatization: 
 [('Labelled', 'Labelled'), ('means', 'mean'), ('full', 'full'), ('history', 'history'), ('happened', 'happened'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thus'), ('history', 'history')]



========================================== PARAGRAPH 600 ===========================================

for the data variables is known.   

------------------- Sentence 1 -------------------

for the data variables is known.

>> Tokens are: 
 ['data', 'variables', 'known', '.']

>> Bigrams are: 
 [('data', 'variables'), ('variables', 'known'), ('known', '.')]

>> Trigrams are: 
 [('data', 'variables', 'known'), ('variables', 'known', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('variables', 'NNS'), ('known', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['data variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('variables', 'variabl'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('variables', 'variabl'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('variables', 'variable'), ('known', 'known'), ('.', '.')]



========================================== PARAGRAPH 601 ===========================================

Supervised learning involves training a system based on labelled data and this requires a supervisor  

------------------- Sentence 1 -------------------

Supervised learning involves training a system based on labelled data and this requires a supervisor

>> Tokens are: 
 ['Supervised', 'learning', 'involves', 'training', 'system', 'based', 'labelled', 'data', 'requires', 'supervisor']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'involves'), ('involves', 'training'), ('training', 'system'), ('system', 'based'), ('based', 'labelled'), ('labelled', 'data'), ('data', 'requires'), ('requires', 'supervisor')]

>> Trigrams are: 
 [('Supervised', 'learning', 'involves'), ('learning', 'involves', 'training'), ('involves', 'training', 'system'), ('training', 'system', 'based'), ('system', 'based', 'labelled'), ('based', 'labelled', 'data'), ('labelled', 'data', 'requires'), ('data', 'requires', 'supervisor')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'VBG'), ('involves', 'NNS'), ('training', 'VBG'), ('system', 'NN'), ('based', 'VBN'), ('labelled', 'VBN'), ('data', 'NNS'), ('requires', 'VBZ'), ('supervisor', 'NN')]

>> Noun Phrases are: 
 ['involves', 'system', 'data', 'supervisor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('involves', 'involv'), ('training', 'train'), ('system', 'system'), ('based', 'base'), ('labelled', 'label'), ('data', 'data'), ('requires', 'requir'), ('supervisor', 'supervisor')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('involves', 'involv'), ('training', 'train'), ('system', 'system'), ('based', 'base'), ('labelled', 'label'), ('data', 'data'), ('requires', 'requir'), ('supervisor', 'supervisor')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('involves', 'involves'), ('training', 'training'), ('system', 'system'), ('based', 'based'), ('labelled', 'labelled'), ('data', 'data'), ('requires', 'requires'), ('supervisor', 'supervisor')]



========================================== PARAGRAPH 602 ===========================================

with the ability to expect the output from each input that can train the system according to its  

------------------- Sentence 1 -------------------

with the ability to expect the output from each input that can train the system according to its

>> Tokens are: 
 ['ability', 'expect', 'output', 'input', 'train', 'system', 'according']

>> Bigrams are: 
 [('ability', 'expect'), ('expect', 'output'), ('output', 'input'), ('input', 'train'), ('train', 'system'), ('system', 'according')]

>> Trigrams are: 
 [('ability', 'expect', 'output'), ('expect', 'output', 'input'), ('output', 'input', 'train'), ('input', 'train', 'system'), ('train', 'system', 'according')]

>> POS Tags are: 
 [('ability', 'NN'), ('expect', 'VBP'), ('output', 'NN'), ('input', 'NN'), ('train', 'NN'), ('system', 'NN'), ('according', 'VBG')]

>> Noun Phrases are: 
 ['ability', 'output input train system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ability', 'abil'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'accord')]

>> Stemming using Snowball Stemmer: 
 [('ability', 'abil'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'accord')]

>> Lemmatization: 
 [('ability', 'ability'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'according')]



========================================== PARAGRAPH 603 ===========================================

expectations. When the system is trained, it can give predictions within “many applications of  

------------------- Sentence 1 -------------------

expectations.

>> Tokens are: 
 ['expectations', '.']

>> Bigrams are: 
 [('expectations', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('expectations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['expectations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('expectations', 'expect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('expectations', 'expect'), ('.', '.')]

>> Lemmatization: 
 [('expectations', 'expectation'), ('.', '.')]


------------------- Sentence 2 -------------------

When the system is trained, it can give predictions within “many applications of

>> Tokens are: 
 ['When', 'system', 'trained', ',', 'give', 'predictions', 'within', '“', 'many', 'applications']

>> Bigrams are: 
 [('When', 'system'), ('system', 'trained'), ('trained', ','), (',', 'give'), ('give', 'predictions'), ('predictions', 'within'), ('within', '“'), ('“', 'many'), ('many', 'applications')]

>> Trigrams are: 
 [('When', 'system', 'trained'), ('system', 'trained', ','), ('trained', ',', 'give'), (',', 'give', 'predictions'), ('give', 'predictions', 'within'), ('predictions', 'within', '“'), ('within', '“', 'many'), ('“', 'many', 'applications')]

>> POS Tags are: 
 [('When', 'WRB'), ('system', 'NN'), ('trained', 'VBD'), (',', ','), ('give', 'JJ'), ('predictions', 'NNS'), ('within', 'IN'), ('“', 'NNP'), ('many', 'JJ'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['system', 'give predictions', '“', 'many applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('system', 'system'), ('trained', 'train'), (',', ','), ('give', 'give'), ('predictions', 'predict'), ('within', 'within'), ('“', '“'), ('many', 'mani'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('system', 'system'), ('trained', 'train'), (',', ','), ('give', 'give'), ('predictions', 'predict'), ('within', 'within'), ('“', '“'), ('many', 'mani'), ('applications', 'applic')]

>> Lemmatization: 
 [('When', 'When'), ('system', 'system'), ('trained', 'trained'), (',', ','), ('give', 'give'), ('predictions', 'prediction'), ('within', 'within'), ('“', '“'), ('many', 'many'), ('applications', 'application')]



========================================== PARAGRAPH 604 ===========================================

classification and fault detection and channel coding and decoding” (Kotsiantis, et al., 2007; Cui,  

------------------- Sentence 1 -------------------

classification and fault detection and channel coding and decoding” (Kotsiantis, et al., 2007; Cui,

>> Tokens are: 
 ['classification', 'fault', 'detection', 'channel', 'coding', 'decoding', '”', '(', 'Kotsiantis', ',', 'et', 'al.', ',', '2007', ';', 'Cui', ',']

>> Bigrams are: 
 [('classification', 'fault'), ('fault', 'detection'), ('detection', 'channel'), ('channel', 'coding'), ('coding', 'decoding'), ('decoding', '”'), ('”', '('), ('(', 'Kotsiantis'), ('Kotsiantis', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2007'), ('2007', ';'), (';', 'Cui'), ('Cui', ',')]

>> Trigrams are: 
 [('classification', 'fault', 'detection'), ('fault', 'detection', 'channel'), ('detection', 'channel', 'coding'), ('channel', 'coding', 'decoding'), ('coding', 'decoding', '”'), ('decoding', '”', '('), ('”', '(', 'Kotsiantis'), ('(', 'Kotsiantis', ','), ('Kotsiantis', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2007'), (',', '2007', ';'), ('2007', ';', 'Cui'), (';', 'Cui', ',')]

>> POS Tags are: 
 [('classification', 'NN'), ('fault', 'NN'), ('detection', 'NN'), ('channel', 'NN'), ('coding', 'VBG'), ('decoding', 'VBG'), ('”', 'NNP'), ('(', '('), ('Kotsiantis', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2007', 'CD'), (';', ':'), ('Cui', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['classification fault detection channel', '”', 'Kotsiantis', 'al.', 'Cui']

>> Named Entities are: 
 [('ORGANIZATION', 'Kotsiantis'), ('PERSON', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('fault', 'fault'), ('detection', 'detect'), ('channel', 'channel'), ('coding', 'code'), ('decoding', 'decod'), ('”', '”'), ('(', '('), ('Kotsiantis', 'kotsianti'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'cui'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('fault', 'fault'), ('detection', 'detect'), ('channel', 'channel'), ('coding', 'code'), ('decoding', 'decod'), ('”', '”'), ('(', '('), ('Kotsiantis', 'kotsianti'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'cui'), (',', ',')]

>> Lemmatization: 
 [('classification', 'classification'), ('fault', 'fault'), ('detection', 'detection'), ('channel', 'channel'), ('coding', 'coding'), ('decoding', 'decoding'), ('”', '”'), ('(', '('), ('Kotsiantis', 'Kotsiantis'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'Cui'), (',', ',')]



========================================== PARAGRAPH 605 ===========================================

et al., 2019). This technique is used for approximating a function between the input and output.  

------------------- Sentence 1 -------------------

et al., 2019).

>> Tokens are: 
 ['et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

This technique is used for approximating a function between the input and output.

>> Tokens are: 
 ['This', 'technique', 'used', 'approximating', 'function', 'input', 'output', '.']

>> Bigrams are: 
 [('This', 'technique'), ('technique', 'used'), ('used', 'approximating'), ('approximating', 'function'), ('function', 'input'), ('input', 'output'), ('output', '.')]

>> Trigrams are: 
 [('This', 'technique', 'used'), ('technique', 'used', 'approximating'), ('used', 'approximating', 'function'), ('approximating', 'function', 'input'), ('function', 'input', 'output'), ('input', 'output', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('technique', 'NN'), ('used', 'VBD'), ('approximating', 'VBG'), ('function', 'NN'), ('input', 'NN'), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This technique', 'function input output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('technique', 'techniqu'), ('used', 'use'), ('approximating', 'approxim'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('technique', 'techniqu'), ('used', 'use'), ('approximating', 'approxim'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('technique', 'technique'), ('used', 'used'), ('approximating', 'approximating'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]



========================================== PARAGRAPH 606 ===========================================

The idea is for the system to learn the training dataset’s classifiers (the labelled documents) then  

------------------- Sentence 1 -------------------

The idea is for the system to learn the training dataset’s classifiers (the labelled documents) then

>> Tokens are: 
 ['The', 'idea', 'system', 'learn', 'training', 'dataset', '’', 'classifiers', '(', 'labelled', 'documents', ')']

>> Bigrams are: 
 [('The', 'idea'), ('idea', 'system'), ('system', 'learn'), ('learn', 'training'), ('training', 'dataset'), ('dataset', '’'), ('’', 'classifiers'), ('classifiers', '('), ('(', 'labelled'), ('labelled', 'documents'), ('documents', ')')]

>> Trigrams are: 
 [('The', 'idea', 'system'), ('idea', 'system', 'learn'), ('system', 'learn', 'training'), ('learn', 'training', 'dataset'), ('training', 'dataset', '’'), ('dataset', '’', 'classifiers'), ('’', 'classifiers', '('), ('classifiers', '(', 'labelled'), ('(', 'labelled', 'documents'), ('labelled', 'documents', ')')]

>> POS Tags are: 
 [('The', 'DT'), ('idea', 'NN'), ('system', 'NN'), ('learn', 'JJ'), ('training', 'NN'), ('dataset', 'NN'), ('’', 'NN'), ('classifiers', 'NNS'), ('(', '('), ('labelled', 'JJ'), ('documents', 'NNS'), (')', ')')]

>> Noun Phrases are: 
 ['The idea system', 'learn training dataset ’ classifiers', 'labelled documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'train'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('(', '('), ('labelled', 'label'), ('documents', 'document'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'train'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('(', '('), ('labelled', 'label'), ('documents', 'document'), (')', ')')]

>> Lemmatization: 
 [('The', 'The'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'training'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifier'), ('(', '('), ('labelled', 'labelled'), ('documents', 'document'), (')', ')')]



========================================== PARAGRAPH 607 ===========================================

to automatically apply this classification to an unknown dataset’s un-labelled documents. This  

------------------- Sentence 1 -------------------

to automatically apply this classification to an unknown dataset’s un-labelled documents.

>> Tokens are: 
 ['automatically', 'apply', 'classification', 'unknown', 'dataset', '’', 'un-labelled', 'documents', '.']

>> Bigrams are: 
 [('automatically', 'apply'), ('apply', 'classification'), ('classification', 'unknown'), ('unknown', 'dataset'), ('dataset', '’'), ('’', 'un-labelled'), ('un-labelled', 'documents'), ('documents', '.')]

>> Trigrams are: 
 [('automatically', 'apply', 'classification'), ('apply', 'classification', 'unknown'), ('classification', 'unknown', 'dataset'), ('unknown', 'dataset', '’'), ('dataset', '’', 'un-labelled'), ('’', 'un-labelled', 'documents'), ('un-labelled', 'documents', '.')]

>> POS Tags are: 
 [('automatically', 'RB'), ('apply', 'VB'), ('classification', 'NN'), ('unknown', 'JJ'), ('dataset', 'NN'), ('’', 'VBD'), ('un-labelled', 'JJ'), ('documents', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification', 'unknown dataset', 'un-labelled documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatically', 'automat'), ('apply', 'appli'), ('classification', 'classif'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-label'), ('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatically', 'automat'), ('apply', 'appli'), ('classification', 'classif'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-label'), ('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('automatically', 'automatically'), ('apply', 'apply'), ('classification', 'classification'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-labelled'), ('documents', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

This

>> Tokens are: 
 ['This']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('This', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this')]

>> Lemmatization: 
 [('This', 'This')]



========================================== PARAGRAPH 608 ===========================================

learning technology thus involves learning from example (Boyd-Graber et al., 2014; Müller et al.,  

------------------- Sentence 1 -------------------

learning technology thus involves learning from example (Boyd-Graber et al., 2014; Müller et al.,

>> Tokens are: 
 ['learning', 'technology', 'thus', 'involves', 'learning', 'example', '(', 'Boyd-Graber', 'et', 'al.', ',', '2014', ';', 'Müller', 'et', 'al.', ',']

>> Bigrams are: 
 [('learning', 'technology'), ('technology', 'thus'), ('thus', 'involves'), ('involves', 'learning'), ('learning', 'example'), ('example', '('), ('(', 'Boyd-Graber'), ('Boyd-Graber', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('learning', 'technology', 'thus'), ('technology', 'thus', 'involves'), ('thus', 'involves', 'learning'), ('involves', 'learning', 'example'), ('learning', 'example', '('), ('example', '(', 'Boyd-Graber'), ('(', 'Boyd-Graber', 'et'), ('Boyd-Graber', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Müller'), (';', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('learning', 'VBG'), ('technology', 'NN'), ('thus', 'RB'), ('involves', 'VBZ'), ('learning', 'VBG'), ('example', 'NN'), ('(', '('), ('Boyd-Graber', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Müller', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['technology', 'example', 'Boyd-Graber', 'al.', 'Müller', 'al.']

>> Named Entities are: 
 [('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('technology', 'technolog'), ('thus', 'thu'), ('involves', 'involv'), ('learning', 'learn'), ('example', 'exampl'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('technology', 'technolog'), ('thus', 'thus'), ('involves', 'involv'), ('learning', 'learn'), ('example', 'exampl'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('learning', 'learning'), ('technology', 'technology'), ('thus', 'thus'), ('involves', 'involves'), ('learning', 'learning'), ('example', 'example'), ('(', '('), ('Boyd-Graber', 'Boyd-Graber'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 609 ===========================================

2016; Breed and Verster, 2019).  

------------------- Sentence 1 -------------------

2016; Breed and Verster, 2019).

>> Tokens are: 
 ['2016', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 610 ===========================================

Regression is an example of the supervised learning algorithm, as are Linear Regression, Decision  

------------------- Sentence 1 -------------------

Regression is an example of the supervised learning algorithm, as are Linear Regression, Decision

>> Tokens are: 
 ['Regression', 'example', 'supervised', 'learning', 'algorithm', ',', 'Linear', 'Regression', ',', 'Decision']

>> Bigrams are: 
 [('Regression', 'example'), ('example', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithm'), ('algorithm', ','), (',', 'Linear'), ('Linear', 'Regression'), ('Regression', ','), (',', 'Decision')]

>> Trigrams are: 
 [('Regression', 'example', 'supervised'), ('example', 'supervised', 'learning'), ('supervised', 'learning', 'algorithm'), ('learning', 'algorithm', ','), ('algorithm', ',', 'Linear'), (',', 'Linear', 'Regression'), ('Linear', 'Regression', ','), ('Regression', ',', 'Decision')]

>> POS Tags are: 
 [('Regression', 'NNP'), ('example', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('algorithm', 'NN'), (',', ','), ('Linear', 'NNP'), ('Regression', 'NNP'), (',', ','), ('Decision', 'NNP')]

>> Noun Phrases are: 
 ['Regression example', 'algorithm', 'Linear Regression', 'Decision']

>> Named Entities are: 
 [('PERSON', 'Linear Regression')] 

>> Stemming using Porter Stemmer: 
 [('Regression', 'regress'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'linear'), ('Regression', 'regress'), (',', ','), ('Decision', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('Regression', 'regress'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'linear'), ('Regression', 'regress'), (',', ','), ('Decision', 'decis')]

>> Lemmatization: 
 [('Regression', 'Regression'), ('example', 'example'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'Linear'), ('Regression', 'Regression'), (',', ','), ('Decision', 'Decision')]



========================================== PARAGRAPH 611 ===========================================

Trees (DT), Support Vector Machine (SVM), K Nearest Neighbour (K-NN), Naive Bayes  

------------------- Sentence 1 -------------------

Trees (DT), Support Vector Machine (SVM), K Nearest Neighbour (K-NN), Naive Bayes

>> Tokens are: 
 ['Trees', '(', 'DT', ')', ',', 'Support', 'Vector', 'Machine', '(', 'SVM', ')', ',', 'K', 'Nearest', 'Neighbour', '(', 'K-NN', ')', ',', 'Naive', 'Bayes']

>> Bigrams are: 
 [('Trees', '('), ('(', 'DT'), ('DT', ')'), (')', ','), (',', 'Support'), ('Support', 'Vector'), ('Vector', 'Machine'), ('Machine', '('), ('(', 'SVM'), ('SVM', ')'), (')', ','), (',', 'K'), ('K', 'Nearest'), ('Nearest', 'Neighbour'), ('Neighbour', '('), ('(', 'K-NN'), ('K-NN', ')'), (')', ','), (',', 'Naive'), ('Naive', 'Bayes')]

>> Trigrams are: 
 [('Trees', '(', 'DT'), ('(', 'DT', ')'), ('DT', ')', ','), (')', ',', 'Support'), (',', 'Support', 'Vector'), ('Support', 'Vector', 'Machine'), ('Vector', 'Machine', '('), ('Machine', '(', 'SVM'), ('(', 'SVM', ')'), ('SVM', ')', ','), (')', ',', 'K'), (',', 'K', 'Nearest'), ('K', 'Nearest', 'Neighbour'), ('Nearest', 'Neighbour', '('), ('Neighbour', '(', 'K-NN'), ('(', 'K-NN', ')'), ('K-NN', ')', ','), (')', ',', 'Naive'), (',', 'Naive', 'Bayes')]

>> POS Tags are: 
 [('Trees', 'NNS'), ('(', '('), ('DT', 'NNP'), (')', ')'), (',', ','), ('Support', 'NNP'), ('Vector', 'NNP'), ('Machine', 'NNP'), ('(', '('), ('SVM', 'NNP'), (')', ')'), (',', ','), ('K', 'NNP'), ('Nearest', 'NNP'), ('Neighbour', 'NNP'), ('(', '('), ('K-NN', 'NNP'), (')', ')'), (',', ','), ('Naive', 'JJ'), ('Bayes', 'NNP')]

>> Noun Phrases are: 
 ['Trees', 'DT', 'Support Vector Machine', 'SVM', 'K Nearest Neighbour', 'K-NN', 'Naive Bayes']

>> Named Entities are: 
 [('GPE', 'Trees'), ('PERSON', 'Support Vector Machine'), ('ORGANIZATION', 'SVM'), ('PERSON', 'K Nearest Neighbour'), ('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), (',', ','), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), (',', ','), ('K', 'k'), ('Nearest', 'nearest'), ('Neighbour', 'neighbour'), ('(', '('), ('K-NN', 'k-nn'), (')', ')'), (',', ','), ('Naive', 'naiv'), ('Bayes', 'bay')]

>> Stemming using Snowball Stemmer: 
 [('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), (',', ','), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), (',', ','), ('K', 'k'), ('Nearest', 'nearest'), ('Neighbour', 'neighbour'), ('(', '('), ('K-NN', 'k-nn'), (')', ')'), (',', ','), ('Naive', 'naiv'), ('Bayes', 'bay')]

>> Lemmatization: 
 [('Trees', 'Trees'), ('(', '('), ('DT', 'DT'), (')', ')'), (',', ','), ('Support', 'Support'), ('Vector', 'Vector'), ('Machine', 'Machine'), ('(', '('), ('SVM', 'SVM'), (')', ')'), (',', ','), ('K', 'K'), ('Nearest', 'Nearest'), ('Neighbour', 'Neighbour'), ('(', '('), ('K-NN', 'K-NN'), (')', ')'), (',', ','), ('Naive', 'Naive'), ('Bayes', 'Bayes')]



========================================== PARAGRAPH 612 ===========================================

Classifier (NBC), Random Forest, and neural networks (NN). However, many of these supervised  

------------------- Sentence 1 -------------------

Classifier (NBC), Random Forest, and neural networks (NN).

>> Tokens are: 
 ['Classifier', '(', 'NBC', ')', ',', 'Random', 'Forest', ',', 'neural', 'networks', '(', 'NN', ')', '.']

>> Bigrams are: 
 [('Classifier', '('), ('(', 'NBC'), ('NBC', ')'), (')', ','), (',', 'Random'), ('Random', 'Forest'), ('Forest', ','), (',', 'neural'), ('neural', 'networks'), ('networks', '('), ('(', 'NN'), ('NN', ')'), (')', '.')]

>> Trigrams are: 
 [('Classifier', '(', 'NBC'), ('(', 'NBC', ')'), ('NBC', ')', ','), (')', ',', 'Random'), (',', 'Random', 'Forest'), ('Random', 'Forest', ','), ('Forest', ',', 'neural'), (',', 'neural', 'networks'), ('neural', 'networks', '('), ('networks', '(', 'NN'), ('(', 'NN', ')'), ('NN', ')', '.')]

>> POS Tags are: 
 [('Classifier', 'NNP'), ('(', '('), ('NBC', 'NNP'), (')', ')'), (',', ','), ('Random', 'NNP'), ('Forest', 'NNP'), (',', ','), ('neural', 'JJ'), ('networks', 'NNS'), ('(', '('), ('NN', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Classifier', 'NBC', 'Random Forest', 'neural networks', 'NN']

>> Named Entities are: 
 [('GPE', 'Classifier'), ('ORGANIZATION', 'NBC'), ('PERSON', 'Random Forest')] 

>> Stemming using Porter Stemmer: 
 [('Classifier', 'classifi'), ('(', '('), ('NBC', 'nbc'), (')', ')'), (',', ','), ('Random', 'random'), ('Forest', 'forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'nn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Classifier', 'classifi'), ('(', '('), ('NBC', 'nbc'), (')', ')'), (',', ','), ('Random', 'random'), ('Forest', 'forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'nn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Classifier', 'Classifier'), ('(', '('), ('NBC', 'NBC'), (')', ')'), (',', ','), ('Random', 'Random'), ('Forest', 'Forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'NN'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

However, many of these supervised

>> Tokens are: 
 ['However', ',', 'many', 'supervised']

>> Bigrams are: 
 [('However', ','), (',', 'many'), ('many', 'supervised')]

>> Trigrams are: 
 [('However', ',', 'many'), (',', 'many', 'supervised')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('many', 'JJ'), ('supervised', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('many', 'mani'), ('supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('many', 'mani'), ('supervised', 'supervis')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('many', 'many'), ('supervised', 'supervised')]



========================================== PARAGRAPH 613 ===========================================

techniques cannot be used with wireless networks, and as the learning techniques are dependent  

------------------- Sentence 1 -------------------

techniques cannot be used with wireless networks, and as the learning techniques are dependent

>> Tokens are: 
 ['techniques', 'used', 'wireless', 'networks', ',', 'learning', 'techniques', 'dependent']

>> Bigrams are: 
 [('techniques', 'used'), ('used', 'wireless'), ('wireless', 'networks'), ('networks', ','), (',', 'learning'), ('learning', 'techniques'), ('techniques', 'dependent')]

>> Trigrams are: 
 [('techniques', 'used', 'wireless'), ('used', 'wireless', 'networks'), ('wireless', 'networks', ','), ('networks', ',', 'learning'), (',', 'learning', 'techniques'), ('learning', 'techniques', 'dependent')]

>> POS Tags are: 
 [('techniques', 'NNS'), ('used', 'VBN'), ('wireless', 'NN'), ('networks', 'NNS'), (',', ','), ('learning', 'VBG'), ('techniques', 'NNS'), ('dependent', 'JJ')]

>> Noun Phrases are: 
 ['techniques', 'wireless networks', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('used', 'use'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learn'), ('techniques', 'techniqu'), ('dependent', 'depend')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('used', 'use'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learn'), ('techniques', 'techniqu'), ('dependent', 'depend')]

>> Lemmatization: 
 [('techniques', 'technique'), ('used', 'used'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learning'), ('techniques', 'technique'), ('dependent', 'dependent')]



========================================== PARAGRAPH 614 ===========================================

on the data training, the results are also restricted (Cui et al., 2019).  

------------------- Sentence 1 -------------------

on the data training, the results are also restricted (Cui et al., 2019).

>> Tokens are: 
 ['data', 'training', ',', 'results', 'also', 'restricted', '(', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('data', 'training'), ('training', ','), (',', 'results'), ('results', 'also'), ('also', 'restricted'), ('restricted', '('), ('(', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'training', ','), ('training', ',', 'results'), (',', 'results', 'also'), ('results', 'also', 'restricted'), ('also', 'restricted', '('), ('restricted', '(', 'Cui'), ('(', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('training', 'NN'), (',', ','), ('results', 'NNS'), ('also', 'RB'), ('restricted', 'VBD'), ('(', '('), ('Cui', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data training', 'results', 'Cui']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('training', 'train'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restrict'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('training', 'train'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restrict'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('training', 'training'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restricted'), ('(', '('), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 615 ===========================================

 


========================================== PARAGRAPH 616 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 617 ===========================================

23  

------------------- Sentence 1 -------------------

23

>> Tokens are: 
 ['23']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('23', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('23', '23')]

>> Stemming using Snowball Stemmer: 
 [('23', '23')]

>> Lemmatization: 
 [('23', '23')]



========================================== PARAGRAPH 618 ===========================================

  


========================================== PARAGRAPH 619 ===========================================

  


========================================== PARAGRAPH 620 ===========================================

Regression Analysis: is mathematical tool used to discover correlations between several variables  

------------------- Sentence 1 -------------------

Regression Analysis: is mathematical tool used to discover correlations between several variables

>> Tokens are: 
 ['Regression', 'Analysis', ':', 'mathematical', 'tool', 'used', 'discover', 'correlations', 'several', 'variables']

>> Bigrams are: 
 [('Regression', 'Analysis'), ('Analysis', ':'), (':', 'mathematical'), ('mathematical', 'tool'), ('tool', 'used'), ('used', 'discover'), ('discover', 'correlations'), ('correlations', 'several'), ('several', 'variables')]

>> Trigrams are: 
 [('Regression', 'Analysis', ':'), ('Analysis', ':', 'mathematical'), (':', 'mathematical', 'tool'), ('mathematical', 'tool', 'used'), ('tool', 'used', 'discover'), ('used', 'discover', 'correlations'), ('discover', 'correlations', 'several'), ('correlations', 'several', 'variables')]

>> POS Tags are: 
 [('Regression', 'NN'), ('Analysis', 'NN'), (':', ':'), ('mathematical', 'JJ'), ('tool', 'NN'), ('used', 'VBN'), ('discover', 'NN'), ('correlations', 'NNS'), ('several', 'JJ'), ('variables', 'NNS')]

>> Noun Phrases are: 
 ['Regression Analysis', 'mathematical tool', 'discover correlations', 'several variables']

>> Named Entities are: 
 [('GPE', 'Regression'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Regression', 'regress'), ('Analysis', 'analysi'), (':', ':'), ('mathematical', 'mathemat'), ('tool', 'tool'), ('used', 'use'), ('discover', 'discov'), ('correlations', 'correl'), ('several', 'sever'), ('variables', 'variabl')]

>> Stemming using Snowball Stemmer: 
 [('Regression', 'regress'), ('Analysis', 'analysi'), (':', ':'), ('mathematical', 'mathemat'), ('tool', 'tool'), ('used', 'use'), ('discover', 'discov'), ('correlations', 'correl'), ('several', 'sever'), ('variables', 'variabl')]

>> Lemmatization: 
 [('Regression', 'Regression'), ('Analysis', 'Analysis'), (':', ':'), ('mathematical', 'mathematical'), ('tool', 'tool'), ('used', 'used'), ('discover', 'discover'), ('correlations', 'correlation'), ('several', 'several'), ('variables', 'variable')]



========================================== PARAGRAPH 621 ===========================================

based on experimental or observed data. Where analysis defines the relationships between  

------------------- Sentence 1 -------------------

based on experimental or observed data.

>> Tokens are: 
 ['based', 'experimental', 'observed', 'data', '.']

>> Bigrams are: 
 [('based', 'experimental'), ('experimental', 'observed'), ('observed', 'data'), ('data', '.')]

>> Trigrams are: 
 [('based', 'experimental', 'observed'), ('experimental', 'observed', 'data'), ('observed', 'data', '.')]

>> POS Tags are: 
 [('based', 'VBN'), ('experimental', 'JJ'), ('observed', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['experimental observed data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('based', 'base'), ('experimental', 'experiment'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('based', 'base'), ('experimental', 'experiment'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('based', 'based'), ('experimental', 'experimental'), ('observed', 'observed'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Where analysis defines the relationships between

>> Tokens are: 
 ['Where', 'analysis', 'defines', 'relationships']

>> Bigrams are: 
 [('Where', 'analysis'), ('analysis', 'defines'), ('defines', 'relationships')]

>> Trigrams are: 
 [('Where', 'analysis', 'defines'), ('analysis', 'defines', 'relationships')]

>> POS Tags are: 
 [('Where', 'WRB'), ('analysis', 'NN'), ('defines', 'VBZ'), ('relationships', 'NNS')]

>> Noun Phrases are: 
 ['analysis', 'relationships']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('analysis', 'analysi'), ('defines', 'defin'), ('relationships', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('analysis', 'analysi'), ('defines', 'defin'), ('relationships', 'relationship')]

>> Lemmatization: 
 [('Where', 'Where'), ('analysis', 'analysis'), ('defines', 'defines'), ('relationships', 'relationship')]



========================================== PARAGRAPH 622 ===========================================

variables as non-random, such analysis may make the correlations between variables appear  

------------------- Sentence 1 -------------------

variables as non-random, such analysis may make the correlations between variables appear

>> Tokens are: 
 ['variables', 'non-random', ',', 'analysis', 'may', 'make', 'correlations', 'variables', 'appear']

>> Bigrams are: 
 [('variables', 'non-random'), ('non-random', ','), (',', 'analysis'), ('analysis', 'may'), ('may', 'make'), ('make', 'correlations'), ('correlations', 'variables'), ('variables', 'appear')]

>> Trigrams are: 
 [('variables', 'non-random', ','), ('non-random', ',', 'analysis'), (',', 'analysis', 'may'), ('analysis', 'may', 'make'), ('may', 'make', 'correlations'), ('make', 'correlations', 'variables'), ('correlations', 'variables', 'appear')]

>> POS Tags are: 
 [('variables', 'NNS'), ('non-random', 'RB'), (',', ','), ('analysis', 'NN'), ('may', 'MD'), ('make', 'VB'), ('correlations', 'NNS'), ('variables', 'NNS'), ('appear', 'VBP')]

>> Noun Phrases are: 
 ['variables', 'analysis', 'correlations variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variables', 'variabl'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysi'), ('may', 'may'), ('make', 'make'), ('correlations', 'correl'), ('variables', 'variabl'), ('appear', 'appear')]

>> Stemming using Snowball Stemmer: 
 [('variables', 'variabl'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysi'), ('may', 'may'), ('make', 'make'), ('correlations', 'correl'), ('variables', 'variabl'), ('appear', 'appear')]

>> Lemmatization: 
 [('variables', 'variable'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysis'), ('may', 'may'), ('make', 'make'), ('correlations', 'correlation'), ('variables', 'variable'), ('appear', 'appear')]



========================================== PARAGRAPH 623 ===========================================

simpler and more regular (Lei et al., 2016), as shown in Figure 13.  

------------------- Sentence 1 -------------------

simpler and more regular (Lei et al., 2016), as shown in Figure 13.

>> Tokens are: 
 ['simpler', 'regular', '(', 'Lei', 'et', 'al.', ',', '2016', ')', ',', 'shown', 'Figure', '13', '.']

>> Bigrams are: 
 [('simpler', 'regular'), ('regular', '('), ('(', 'Lei'), ('Lei', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '13'), ('13', '.')]

>> Trigrams are: 
 [('simpler', 'regular', '('), ('regular', '(', 'Lei'), ('(', 'Lei', 'et'), ('Lei', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '13'), ('Figure', '13', '.')]

>> POS Tags are: 
 [('simpler', 'NN'), ('regular', 'NN'), ('(', '('), ('Lei', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['simpler regular', 'Lei', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Lei')] 

>> Stemming using Porter Stemmer: 
 [('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'Lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('13', '13'), ('.', '.')]



========================================== PARAGRAPH 624 ===========================================

  


========================================== PARAGRAPH 625 ===========================================

  


========================================== PARAGRAPH 626 ===========================================

  


========================================== PARAGRAPH 627 ===========================================

  


========================================== PARAGRAPH 628 ===========================================

Figure 13: Regression analysis  

------------------- Sentence 1 -------------------

Figure 13: Regression analysis

>> Tokens are: 
 ['Figure', '13', ':', 'Regression', 'analysis']

>> Bigrams are: 
 [('Figure', '13'), ('13', ':'), (':', 'Regression'), ('Regression', 'analysis')]

>> Trigrams are: 
 [('Figure', '13', ':'), ('13', ':', 'Regression'), (':', 'Regression', 'analysis')]

>> POS Tags are: 
 [('Figure', 'NN'), ('13', 'CD'), (':', ':'), ('Regression', 'NN'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['Figure', 'Regression analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('13', '13'), (':', ':'), ('Regression', 'regress'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('13', '13'), (':', ':'), ('Regression', 'regress'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('13', '13'), (':', ':'), ('Regression', 'Regression'), ('analysis', 'analysis')]



========================================== PARAGRAPH 629 ===========================================

  


========================================== PARAGRAPH 630 ===========================================

Structured data mostly utilises predictive analytics, and this overshadows other analytics forms for  

------------------- Sentence 1 -------------------

Structured data mostly utilises predictive analytics, and this overshadows other analytics forms for

>> Tokens are: 
 ['Structured', 'data', 'mostly', 'utilises', 'predictive', 'analytics', ',', 'overshadows', 'analytics', 'forms']

>> Bigrams are: 
 [('Structured', 'data'), ('data', 'mostly'), ('mostly', 'utilises'), ('utilises', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'overshadows'), ('overshadows', 'analytics'), ('analytics', 'forms')]

>> Trigrams are: 
 [('Structured', 'data', 'mostly'), ('data', 'mostly', 'utilises'), ('mostly', 'utilises', 'predictive'), ('utilises', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'overshadows'), (',', 'overshadows', 'analytics'), ('overshadows', 'analytics', 'forms')]

>> POS Tags are: 
 [('Structured', 'NNP'), ('data', 'NNS'), ('mostly', 'RB'), ('utilises', 'VBZ'), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('overshadows', 'VBZ'), ('analytics', 'NNS'), ('forms', 'NNS')]

>> Noun Phrases are: 
 ['Structured data', 'predictive analytics', 'analytics forms']

>> Named Entities are: 
 [('GPE', 'Structured')] 

>> Stemming using Porter Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('mostly', 'mostli'), ('utilises', 'utilis'), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('overshadows', 'overshadow'), ('analytics', 'analyt'), ('forms', 'form')]

>> Stemming using Snowball Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('mostly', 'most'), ('utilises', 'utilis'), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('overshadows', 'overshadow'), ('analytics', 'analyt'), ('forms', 'form')]

>> Lemmatization: 
 [('Structured', 'Structured'), ('data', 'data'), ('mostly', 'mostly'), ('utilises', 'utilises'), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('overshadows', 'overshadows'), ('analytics', 'analytics'), ('forms', 'form')]



========================================== PARAGRAPH 631 ===========================================

95% of big data (Gandomi and Haider, 2015). However, new statistical techniques for big data  

------------------- Sentence 1 -------------------

95% of big data (Gandomi and Haider, 2015).

>> Tokens are: 
 ['95', '%', 'big', 'data', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('95', '%'), ('%', 'big'), ('big', 'data'), ('data', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('95', '%', 'big'), ('%', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('95', 'CD'), ('%', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['%', 'big data', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

However, new statistical techniques for big data

>> Tokens are: 
 ['However', ',', 'new', 'statistical', 'techniques', 'big', 'data']

>> Bigrams are: 
 [('However', ','), (',', 'new'), ('new', 'statistical'), ('statistical', 'techniques'), ('techniques', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('However', ',', 'new'), (',', 'new', 'statistical'), ('new', 'statistical', 'techniques'), ('statistical', 'techniques', 'big'), ('techniques', 'big', 'data')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('new', 'JJ'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['new statistical techniques', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('new', 'new'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('new', 'new'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('new', 'new'), ('statistical', 'statistical'), ('techniques', 'technique'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 632 ===========================================

have emerged which clarify the differentiation of big data from smaller data sets. In practice,  

------------------- Sentence 1 -------------------

have emerged which clarify the differentiation of big data from smaller data sets.

>> Tokens are: 
 ['emerged', 'clarify', 'differentiation', 'big', 'data', 'smaller', 'data', 'sets', '.']

>> Bigrams are: 
 [('emerged', 'clarify'), ('clarify', 'differentiation'), ('differentiation', 'big'), ('big', 'data'), ('data', 'smaller'), ('smaller', 'data'), ('data', 'sets'), ('sets', '.')]

>> Trigrams are: 
 [('emerged', 'clarify', 'differentiation'), ('clarify', 'differentiation', 'big'), ('differentiation', 'big', 'data'), ('big', 'data', 'smaller'), ('data', 'smaller', 'data'), ('smaller', 'data', 'sets'), ('data', 'sets', '.')]

>> POS Tags are: 
 [('emerged', 'VBN'), ('clarify', 'NN'), ('differentiation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('smaller', 'JJR'), ('data', 'NNS'), ('sets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['clarify differentiation', 'big data', 'data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('emerged', 'emerg'), ('clarify', 'clarifi'), ('differentiation', 'differenti'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('emerged', 'emerg'), ('clarify', 'clarifi'), ('differentiation', 'differenti'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Lemmatization: 
 [('emerged', 'emerged'), ('clarify', 'clarify'), ('differentiation', 'differentiation'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]


------------------- Sentence 2 -------------------

In practice,

>> Tokens are: 
 ['In', 'practice', ',']

>> Bigrams are: 
 [('In', 'practice'), ('practice', ',')]

>> Trigrams are: 
 [('In', 'practice', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('practice', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['practice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('practice', 'practice'), (',', ',')]



========================================== PARAGRAPH 633 ===========================================

however, most statistical methods were designed for smaller datasets, in particular, samples.  

------------------- Sentence 1 -------------------

however, most statistical methods were designed for smaller datasets, in particular, samples.

>> Tokens are: 
 ['however', ',', 'statistical', 'methods', 'designed', 'smaller', 'datasets', ',', 'particular', ',', 'samples', '.']

>> Bigrams are: 
 [('however', ','), (',', 'statistical'), ('statistical', 'methods'), ('methods', 'designed'), ('designed', 'smaller'), ('smaller', 'datasets'), ('datasets', ','), (',', 'particular'), ('particular', ','), (',', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('however', ',', 'statistical'), (',', 'statistical', 'methods'), ('statistical', 'methods', 'designed'), ('methods', 'designed', 'smaller'), ('designed', 'smaller', 'datasets'), ('smaller', 'datasets', ','), ('datasets', ',', 'particular'), (',', 'particular', ','), ('particular', ',', 'samples'), (',', 'samples', '.')]

>> POS Tags are: 
 [('however', 'RB'), (',', ','), ('statistical', 'JJ'), ('methods', 'NNS'), ('designed', 'VBN'), ('smaller', 'JJR'), ('datasets', 'NNS'), (',', ','), ('particular', 'JJ'), (',', ','), ('samples', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['statistical methods', 'datasets', 'samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('however', 'howev'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('designed', 'design'), ('smaller', 'smaller'), ('datasets', 'dataset'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('however', 'howev'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('designed', 'design'), ('smaller', 'smaller'), ('datasets', 'dataset'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('however', 'however'), (',', ','), ('statistical', 'statistical'), ('methods', 'method'), ('designed', 'designed'), ('smaller', 'smaller'), ('datasets', 'datasets'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sample'), ('.', '.')]



========================================== PARAGRAPH 634 ===========================================

Usually, scientists make predictions based on theories in the prediction domain. However, big data  

------------------- Sentence 1 -------------------

Usually, scientists make predictions based on theories in the prediction domain.

>> Tokens are: 
 ['Usually', ',', 'scientists', 'make', 'predictions', 'based', 'theories', 'prediction', 'domain', '.']

>> Bigrams are: 
 [('Usually', ','), (',', 'scientists'), ('scientists', 'make'), ('make', 'predictions'), ('predictions', 'based'), ('based', 'theories'), ('theories', 'prediction'), ('prediction', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('Usually', ',', 'scientists'), (',', 'scientists', 'make'), ('scientists', 'make', 'predictions'), ('make', 'predictions', 'based'), ('predictions', 'based', 'theories'), ('based', 'theories', 'prediction'), ('theories', 'prediction', 'domain'), ('prediction', 'domain', '.')]

>> POS Tags are: 
 [('Usually', 'RB'), (',', ','), ('scientists', 'NNS'), ('make', 'VBP'), ('predictions', 'NNS'), ('based', 'VBN'), ('theories', 'NNS'), ('prediction', 'NN'), ('domain', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['scientists', 'predictions', 'theories prediction domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Usually', 'usual'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'predict'), ('based', 'base'), ('theories', 'theori'), ('prediction', 'predict'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Usually', 'usual'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'predict'), ('based', 'base'), ('theories', 'theori'), ('prediction', 'predict'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('Usually', 'Usually'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'prediction'), ('based', 'based'), ('theories', 'theory'), ('prediction', 'prediction'), ('domain', 'domain'), ('.', '.')]


------------------- Sentence 2 -------------------

However, big data

>> Tokens are: 
 ['However', ',', 'big', 'data']

>> Bigrams are: 
 [('However', ','), (',', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('However', ',', 'big'), (',', 'big', 'data')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 635 ===========================================

analytics can deliver predictions that depend on the sequence of data processing and execution.  

------------------- Sentence 1 -------------------

analytics can deliver predictions that depend on the sequence of data processing and execution.

>> Tokens are: 
 ['analytics', 'deliver', 'predictions', 'depend', 'sequence', 'data', 'processing', 'execution', '.']

>> Bigrams are: 
 [('analytics', 'deliver'), ('deliver', 'predictions'), ('predictions', 'depend'), ('depend', 'sequence'), ('sequence', 'data'), ('data', 'processing'), ('processing', 'execution'), ('execution', '.')]

>> Trigrams are: 
 [('analytics', 'deliver', 'predictions'), ('deliver', 'predictions', 'depend'), ('predictions', 'depend', 'sequence'), ('depend', 'sequence', 'data'), ('sequence', 'data', 'processing'), ('data', 'processing', 'execution'), ('processing', 'execution', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('deliver', 'VBP'), ('predictions', 'NNS'), ('depend', 'VBP'), ('sequence', 'NN'), ('data', 'NNS'), ('processing', 'NN'), ('execution', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics', 'predictions', 'sequence data processing execution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('deliver', 'deliv'), ('predictions', 'predict'), ('depend', 'depend'), ('sequence', 'sequenc'), ('data', 'data'), ('processing', 'process'), ('execution', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('deliver', 'deliv'), ('predictions', 'predict'), ('depend', 'depend'), ('sequence', 'sequenc'), ('data', 'data'), ('processing', 'process'), ('execution', 'execut'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('deliver', 'deliver'), ('predictions', 'prediction'), ('depend', 'depend'), ('sequence', 'sequence'), ('data', 'data'), ('processing', 'processing'), ('execution', 'execution'), ('.', '.')]



========================================== PARAGRAPH 636 ===========================================

According to Kitchin (2014) and Müller et al. (2016),  

------------------- Sentence 1 -------------------

According to Kitchin (2014) and Müller et al.

>> Tokens are: 
 ['According', 'Kitchin', '(', '2014', ')', 'Müller', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Kitchin'), ('Kitchin', '('), ('(', '2014'), ('2014', ')'), (')', 'Müller'), ('Müller', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Kitchin', '('), ('Kitchin', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'Müller'), (')', 'Müller', 'et'), ('Müller', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Kitchin', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('Müller', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Kitchin', 'Müller', 'al']

>> Named Entities are: 
 [('GPE', 'Kitchin'), ('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Kitchin', 'kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Kitchin', 'kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Kitchin', 'Kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'Müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016),

>> Tokens are: 
 ['(', '2016', ')', ',']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', ',')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', ',')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 637 ===========================================

• big data brings new challenge as it is generated from different system sources. The data  retrieved from each source system should thus be sent to a central repository;  

------------------- Sentence 1 -------------------

• big data brings new challenge as it is generated from different system sources.

>> Tokens are: 
 ['•', 'big', 'data', 'brings', 'new', 'challenge', 'generated', 'different', 'system', 'sources', '.']

>> Bigrams are: 
 [('•', 'big'), ('big', 'data'), ('data', 'brings'), ('brings', 'new'), ('new', 'challenge'), ('challenge', 'generated'), ('generated', 'different'), ('different', 'system'), ('system', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('•', 'big', 'data'), ('big', 'data', 'brings'), ('data', 'brings', 'new'), ('brings', 'new', 'challenge'), ('new', 'challenge', 'generated'), ('challenge', 'generated', 'different'), ('generated', 'different', 'system'), ('different', 'system', 'sources'), ('system', 'sources', '.')]

>> POS Tags are: 
 [('•', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('brings', 'VBZ'), ('new', 'JJ'), ('challenge', 'NN'), ('generated', 'VBN'), ('different', 'JJ'), ('system', 'NN'), ('sources', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'new challenge', 'different system sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'bring'), ('new', 'new'), ('challenge', 'challeng'), ('generated', 'gener'), ('different', 'differ'), ('system', 'system'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'bring'), ('new', 'new'), ('challenge', 'challeng'), ('generated', 'generat'), ('different', 'differ'), ('system', 'system'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'brings'), ('new', 'new'), ('challenge', 'challenge'), ('generated', 'generated'), ('different', 'different'), ('system', 'system'), ('sources', 'source'), ('.', '.')]


------------------- Sentence 2 -------------------

The data  retrieved from each source system should thus be sent to a central repository;

>> Tokens are: 
 ['The', 'data', 'retrieved', 'source', 'system', 'thus', 'sent', 'central', 'repository', ';']

>> Bigrams are: 
 [('The', 'data'), ('data', 'retrieved'), ('retrieved', 'source'), ('source', 'system'), ('system', 'thus'), ('thus', 'sent'), ('sent', 'central'), ('central', 'repository'), ('repository', ';')]

>> Trigrams are: 
 [('The', 'data', 'retrieved'), ('data', 'retrieved', 'source'), ('retrieved', 'source', 'system'), ('source', 'system', 'thus'), ('system', 'thus', 'sent'), ('thus', 'sent', 'central'), ('sent', 'central', 'repository'), ('central', 'repository', ';')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('retrieved', 'VBN'), ('source', 'NN'), ('system', 'NN'), ('thus', 'RB'), ('sent', 'JJ'), ('central', 'JJ'), ('repository', 'NN'), (';', ':')]

>> Noun Phrases are: 
 ['The data', 'source system', 'sent central repository']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('retrieved', 'retriev'), ('source', 'sourc'), ('system', 'system'), ('thus', 'thu'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repositori'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('retrieved', 'retriev'), ('source', 'sourc'), ('system', 'system'), ('thus', 'thus'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repositori'), (';', ';')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('retrieved', 'retrieved'), ('source', 'source'), ('system', 'system'), ('thus', 'thus'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repository'), (';', ';')]



========================================== PARAGRAPH 638 ===========================================

• the relationship between operations should be defined to allow reconstruction of datasets  from multiple sources;  

------------------- Sentence 1 -------------------

• the relationship between operations should be defined to allow reconstruction of datasets  from multiple sources;

>> Tokens are: 
 ['•', 'relationship', 'operations', 'defined', 'allow', 'reconstruction', 'datasets', 'multiple', 'sources', ';']

>> Bigrams are: 
 [('•', 'relationship'), ('relationship', 'operations'), ('operations', 'defined'), ('defined', 'allow'), ('allow', 'reconstruction'), ('reconstruction', 'datasets'), ('datasets', 'multiple'), ('multiple', 'sources'), ('sources', ';')]

>> Trigrams are: 
 [('•', 'relationship', 'operations'), ('relationship', 'operations', 'defined'), ('operations', 'defined', 'allow'), ('defined', 'allow', 'reconstruction'), ('allow', 'reconstruction', 'datasets'), ('reconstruction', 'datasets', 'multiple'), ('datasets', 'multiple', 'sources'), ('multiple', 'sources', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('relationship', 'NN'), ('operations', 'NNS'), ('defined', 'VBD'), ('allow', 'JJ'), ('reconstruction', 'NN'), ('datasets', 'NNS'), ('multiple', 'JJ'), ('sources', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['• relationship operations', 'allow reconstruction datasets', 'multiple sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('relationship', 'relationship'), ('operations', 'oper'), ('defined', 'defin'), ('allow', 'allow'), ('reconstruction', 'reconstruct'), ('datasets', 'dataset'), ('multiple', 'multipl'), ('sources', 'sourc'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('relationship', 'relationship'), ('operations', 'oper'), ('defined', 'defin'), ('allow', 'allow'), ('reconstruction', 'reconstruct'), ('datasets', 'dataset'), ('multiple', 'multipl'), ('sources', 'sourc'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('relationship', 'relationship'), ('operations', 'operation'), ('defined', 'defined'), ('allow', 'allow'), ('reconstruction', 'reconstruction'), ('datasets', 'datasets'), ('multiple', 'multiple'), ('sources', 'source'), (';', ';')]



========================================== PARAGRAPH 639 ===========================================

• the knowledge discovery process should be automated from data or datasets to make  predictions;  

------------------- Sentence 1 -------------------

• the knowledge discovery process should be automated from data or datasets to make  predictions;

>> Tokens are: 
 ['•', 'knowledge', 'discovery', 'process', 'automated', 'data', 'datasets', 'make', 'predictions', ';']

>> Bigrams are: 
 [('•', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'process'), ('process', 'automated'), ('automated', 'data'), ('data', 'datasets'), ('datasets', 'make'), ('make', 'predictions'), ('predictions', ';')]

>> Trigrams are: 
 [('•', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'process'), ('discovery', 'process', 'automated'), ('process', 'automated', 'data'), ('automated', 'data', 'datasets'), ('data', 'datasets', 'make'), ('datasets', 'make', 'predictions'), ('make', 'predictions', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('process', 'NN'), ('automated', 'VBD'), ('data', 'NNS'), ('datasets', 'NNS'), ('make', 'VBP'), ('predictions', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['• knowledge discovery process', 'data datasets', 'predictions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('automated', 'autom'), ('data', 'data'), ('datasets', 'dataset'), ('make', 'make'), ('predictions', 'predict'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('automated', 'autom'), ('data', 'data'), ('datasets', 'dataset'), ('make', 'make'), ('predictions', 'predict'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('process', 'process'), ('automated', 'automated'), ('data', 'data'), ('datasets', 'datasets'), ('make', 'make'), ('predictions', 'prediction'), (';', ';')]



========================================== PARAGRAPH 640 ===========================================

• generating new theories is required to create and improve models. Predicted target theory  generates a set of predictors; however, some theories explain the relationships between  

------------------- Sentence 1 -------------------

• generating new theories is required to create and improve models.

>> Tokens are: 
 ['•', 'generating', 'new', 'theories', 'required', 'create', 'improve', 'models', '.']

>> Bigrams are: 
 [('•', 'generating'), ('generating', 'new'), ('new', 'theories'), ('theories', 'required'), ('required', 'create'), ('create', 'improve'), ('improve', 'models'), ('models', '.')]

>> Trigrams are: 
 [('•', 'generating', 'new'), ('generating', 'new', 'theories'), ('new', 'theories', 'required'), ('theories', 'required', 'create'), ('required', 'create', 'improve'), ('create', 'improve', 'models'), ('improve', 'models', '.')]

>> POS Tags are: 
 [('•', 'NNS'), ('generating', 'VBG'), ('new', 'JJ'), ('theories', 'NNS'), ('required', 'VBN'), ('create', 'VBP'), ('improve', 'JJ'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['•', 'new theories', 'improve models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('generating', 'gener'), ('new', 'new'), ('theories', 'theori'), ('required', 'requir'), ('create', 'creat'), ('improve', 'improv'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('generating', 'generat'), ('new', 'new'), ('theories', 'theori'), ('required', 'requir'), ('create', 'creat'), ('improve', 'improv'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('generating', 'generating'), ('new', 'new'), ('theories', 'theory'), ('required', 'required'), ('create', 'create'), ('improve', 'improve'), ('models', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

Predicted target theory  generates a set of predictors; however, some theories explain the relationships between

>> Tokens are: 
 ['Predicted', 'target', 'theory', 'generates', 'set', 'predictors', ';', 'however', ',', 'theories', 'explain', 'relationships']

>> Bigrams are: 
 [('Predicted', 'target'), ('target', 'theory'), ('theory', 'generates'), ('generates', 'set'), ('set', 'predictors'), ('predictors', ';'), (';', 'however'), ('however', ','), (',', 'theories'), ('theories', 'explain'), ('explain', 'relationships')]

>> Trigrams are: 
 [('Predicted', 'target', 'theory'), ('target', 'theory', 'generates'), ('theory', 'generates', 'set'), ('generates', 'set', 'predictors'), ('set', 'predictors', ';'), ('predictors', ';', 'however'), (';', 'however', ','), ('however', ',', 'theories'), (',', 'theories', 'explain'), ('theories', 'explain', 'relationships')]

>> POS Tags are: 
 [('Predicted', 'VBN'), ('target', 'NN'), ('theory', 'NN'), ('generates', 'VBZ'), ('set', 'VBN'), ('predictors', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('theories', 'NNS'), ('explain', 'VBP'), ('relationships', 'NNS')]

>> Noun Phrases are: 
 ['target theory', 'predictors', 'theories', 'relationships']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predicted', 'predict'), ('target', 'target'), ('theory', 'theori'), ('generates', 'gener'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'howev'), (',', ','), ('theories', 'theori'), ('explain', 'explain'), ('relationships', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [('Predicted', 'predict'), ('target', 'target'), ('theory', 'theori'), ('generates', 'generat'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'howev'), (',', ','), ('theories', 'theori'), ('explain', 'explain'), ('relationships', 'relationship')]

>> Lemmatization: 
 [('Predicted', 'Predicted'), ('target', 'target'), ('theory', 'theory'), ('generates', 'generates'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'however'), (',', ','), ('theories', 'theory'), ('explain', 'explain'), ('relationships', 'relationship')]



========================================== PARAGRAPH 641 ===========================================

independent and dependent predictors more effectively;  

------------------- Sentence 1 -------------------

independent and dependent predictors more effectively;

>> Tokens are: 
 ['independent', 'dependent', 'predictors', 'effectively', ';']

>> Bigrams are: 
 [('independent', 'dependent'), ('dependent', 'predictors'), ('predictors', 'effectively'), ('effectively', ';')]

>> Trigrams are: 
 [('independent', 'dependent', 'predictors'), ('dependent', 'predictors', 'effectively'), ('predictors', 'effectively', ';')]

>> POS Tags are: 
 [('independent', 'JJ'), ('dependent', 'JJ'), ('predictors', 'NNS'), ('effectively', 'RB'), (';', ':')]

>> Noun Phrases are: 
 ['independent dependent predictors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('independent', 'independ'), ('dependent', 'depend'), ('predictors', 'predictor'), ('effectively', 'effect'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('independent', 'independ'), ('dependent', 'depend'), ('predictors', 'predictor'), ('effectively', 'effect'), (';', ';')]

>> Lemmatization: 
 [('independent', 'independent'), ('dependent', 'dependent'), ('predictors', 'predictor'), ('effectively', 'effectively'), (';', ';')]



========================================== PARAGRAPH 642 ===========================================

• there is a shift from theory-driven to process-driven prediction based on analysing the  BDA steps and identifying the challenges, theoretically informing future BDA needs  

------------------- Sentence 1 -------------------

• there is a shift from theory-driven to process-driven prediction based on analysing the  BDA steps and identifying the challenges, theoretically informing future BDA needs

>> Tokens are: 
 ['•', 'shift', 'theory-driven', 'process-driven', 'prediction', 'based', 'analysing', 'BDA', 'steps', 'identifying', 'challenges', ',', 'theoretically', 'informing', 'future', 'BDA', 'needs']

>> Bigrams are: 
 [('•', 'shift'), ('shift', 'theory-driven'), ('theory-driven', 'process-driven'), ('process-driven', 'prediction'), ('prediction', 'based'), ('based', 'analysing'), ('analysing', 'BDA'), ('BDA', 'steps'), ('steps', 'identifying'), ('identifying', 'challenges'), ('challenges', ','), (',', 'theoretically'), ('theoretically', 'informing'), ('informing', 'future'), ('future', 'BDA'), ('BDA', 'needs')]

>> Trigrams are: 
 [('•', 'shift', 'theory-driven'), ('shift', 'theory-driven', 'process-driven'), ('theory-driven', 'process-driven', 'prediction'), ('process-driven', 'prediction', 'based'), ('prediction', 'based', 'analysing'), ('based', 'analysing', 'BDA'), ('analysing', 'BDA', 'steps'), ('BDA', 'steps', 'identifying'), ('steps', 'identifying', 'challenges'), ('identifying', 'challenges', ','), ('challenges', ',', 'theoretically'), (',', 'theoretically', 'informing'), ('theoretically', 'informing', 'future'), ('informing', 'future', 'BDA'), ('future', 'BDA', 'needs')]

>> POS Tags are: 
 [('•', 'JJ'), ('shift', 'VB'), ('theory-driven', 'JJ'), ('process-driven', 'JJ'), ('prediction', 'NN'), ('based', 'VBN'), ('analysing', 'VBG'), ('BDA', 'NNP'), ('steps', 'NNS'), ('identifying', 'VBG'), ('challenges', 'NNS'), (',', ','), ('theoretically', 'RB'), ('informing', 'VBG'), ('future', 'JJ'), ('BDA', 'NNP'), ('needs', 'NNS')]

>> Noun Phrases are: 
 ['theory-driven process-driven prediction', 'BDA steps', 'challenges', 'future BDA needs']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA'), ('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('based', 'base'), ('analysing', 'analys'), ('BDA', 'bda'), ('steps', 'step'), ('identifying', 'identifi'), ('challenges', 'challeng'), (',', ','), ('theoretically', 'theoret'), ('informing', 'inform'), ('future', 'futur'), ('BDA', 'bda'), ('needs', 'need')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('based', 'base'), ('analysing', 'analys'), ('BDA', 'bda'), ('steps', 'step'), ('identifying', 'identifi'), ('challenges', 'challeng'), (',', ','), ('theoretically', 'theoret'), ('informing', 'inform'), ('future', 'futur'), ('BDA', 'bda'), ('needs', 'need')]

>> Lemmatization: 
 [('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'prediction'), ('based', 'based'), ('analysing', 'analysing'), ('BDA', 'BDA'), ('steps', 'step'), ('identifying', 'identifying'), ('challenges', 'challenge'), (',', ','), ('theoretically', 'theoretically'), ('informing', 'informing'), ('future', 'future'), ('BDA', 'BDA'), ('needs', 'need')]



========================================== PARAGRAPH 643 ===========================================

throughout data acquisition, pre-processing analysis, and interpretation.   

------------------- Sentence 1 -------------------

throughout data acquisition, pre-processing analysis, and interpretation.

>> Tokens are: 
 ['throughout', 'data', 'acquisition', ',', 'pre-processing', 'analysis', ',', 'interpretation', '.']

>> Bigrams are: 
 [('throughout', 'data'), ('data', 'acquisition'), ('acquisition', ','), (',', 'pre-processing'), ('pre-processing', 'analysis'), ('analysis', ','), (',', 'interpretation'), ('interpretation', '.')]

>> Trigrams are: 
 [('throughout', 'data', 'acquisition'), ('data', 'acquisition', ','), ('acquisition', ',', 'pre-processing'), (',', 'pre-processing', 'analysis'), ('pre-processing', 'analysis', ','), ('analysis', ',', 'interpretation'), (',', 'interpretation', '.')]

>> POS Tags are: 
 [('throughout', 'IN'), ('data', 'NNS'), ('acquisition', 'NN'), (',', ','), ('pre-processing', 'JJ'), ('analysis', 'NN'), (',', ','), ('interpretation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data acquisition', 'pre-processing analysis', 'interpretation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('pre-processing', 'pre-process'), ('analysis', 'analysi'), (',', ','), ('interpretation', 'interpret'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('pre-processing', 'pre-process'), ('analysis', 'analysi'), (',', ','), ('interpretation', 'interpret'), ('.', '.')]

>> Lemmatization: 
 [('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisition'), (',', ','), ('pre-processing', 'pre-processing'), ('analysis', 'analysis'), (',', ','), ('interpretation', 'interpretation'), ('.', '.')]



========================================== PARAGRAPH 644 ===========================================

 


========================================== PARAGRAPH 645 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 646 ===========================================

24  

------------------- Sentence 1 -------------------

24

>> Tokens are: 
 ['24']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('24', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('24', '24')]

>> Stemming using Snowball Stemmer: 
 [('24', '24')]

>> Lemmatization: 
 [('24', '24')]



========================================== PARAGRAPH 647 ===========================================

  


========================================== PARAGRAPH 648 ===========================================

7.1.2. Un-supervised techniques    

------------------- Sentence 1 -------------------

7.1.2.

>> Tokens are: 
 ['7.1.2', '.']

>> Bigrams are: 
 [('7.1.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.2', '7.1.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.2', '7.1.2'), ('.', '.')]

>> Lemmatization: 
 [('7.1.2', '7.1.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Un-supervised techniques

>> Tokens are: 
 ['Un-supervised', 'techniques']

>> Bigrams are: 
 [('Un-supervised', 'techniques')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Un-supervised', 'JJ'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Un-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Un-supervised', 'Un-supervised'), ('techniques', 'technique')]



========================================== PARAGRAPH 649 ===========================================

Here, the training data is unlabelled. Unlabelled means that the history of the data is missing, there  

------------------- Sentence 1 -------------------

Here, the training data is unlabelled.

>> Tokens are: 
 ['Here', ',', 'training', 'data', 'unlabelled', '.']

>> Bigrams are: 
 [('Here', ','), (',', 'training'), ('training', 'data'), ('data', 'unlabelled'), ('unlabelled', '.')]

>> Trigrams are: 
 [('Here', ',', 'training'), (',', 'training', 'data'), ('training', 'data', 'unlabelled'), ('data', 'unlabelled', '.')]

>> POS Tags are: 
 [('Here', 'RB'), (',', ','), ('training', 'VBG'), ('data', 'NNS'), ('unlabelled', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), (',', ','), ('training', 'train'), ('data', 'data'), ('unlabelled', 'unlabel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), (',', ','), ('training', 'train'), ('data', 'data'), ('unlabelled', 'unlabel'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), (',', ','), ('training', 'training'), ('data', 'data'), ('unlabelled', 'unlabelled'), ('.', '.')]


------------------- Sentence 2 -------------------

Unlabelled means that the history of the data is missing, there

>> Tokens are: 
 ['Unlabelled', 'means', 'history', 'data', 'missing', ',']

>> Bigrams are: 
 [('Unlabelled', 'means'), ('means', 'history'), ('history', 'data'), ('data', 'missing'), ('missing', ',')]

>> Trigrams are: 
 [('Unlabelled', 'means', 'history'), ('means', 'history', 'data'), ('history', 'data', 'missing'), ('data', 'missing', ',')]

>> POS Tags are: 
 [('Unlabelled', 'VBN'), ('means', 'NNS'), ('history', 'NN'), ('data', 'NNS'), ('missing', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['means history data missing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlabelled', 'unlabel'), ('means', 'mean'), ('history', 'histori'), ('data', 'data'), ('missing', 'miss'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Unlabelled', 'unlabel'), ('means', 'mean'), ('history', 'histori'), ('data', 'data'), ('missing', 'miss'), (',', ',')]

>> Lemmatization: 
 [('Unlabelled', 'Unlabelled'), ('means', 'mean'), ('history', 'history'), ('data', 'data'), ('missing', 'missing'), (',', ',')]



========================================== PARAGRAPH 650 ===========================================

is no history available for data variables, and the data have not been trained and tested. Thus,  

------------------- Sentence 1 -------------------

is no history available for data variables, and the data have not been trained and tested.

>> Tokens are: 
 ['history', 'available', 'data', 'variables', ',', 'data', 'trained', 'tested', '.']

>> Bigrams are: 
 [('history', 'available'), ('available', 'data'), ('data', 'variables'), ('variables', ','), (',', 'data'), ('data', 'trained'), ('trained', 'tested'), ('tested', '.')]

>> Trigrams are: 
 [('history', 'available', 'data'), ('available', 'data', 'variables'), ('data', 'variables', ','), ('variables', ',', 'data'), (',', 'data', 'trained'), ('data', 'trained', 'tested'), ('trained', 'tested', '.')]

>> POS Tags are: 
 [('history', 'NN'), ('available', 'JJ'), ('data', 'NNS'), ('variables', 'NNS'), (',', ','), ('data', 'NNS'), ('trained', 'VBD'), ('tested', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['history', 'available data variables', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('history', 'histori'), ('available', 'avail'), ('data', 'data'), ('variables', 'variabl'), (',', ','), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('history', 'histori'), ('available', 'avail'), ('data', 'data'), ('variables', 'variabl'), (',', ','), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), ('.', '.')]

>> Lemmatization: 
 [('history', 'history'), ('available', 'available'), ('data', 'data'), ('variables', 'variable'), (',', ','), ('data', 'data'), ('trained', 'trained'), ('tested', 'tested'), ('.', '.')]


------------------- Sentence 2 -------------------

Thus,

>> Tokens are: 
 ['Thus', ',']

>> Bigrams are: 
 [('Thus', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Thus', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ',')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ',')]



========================================== PARAGRAPH 651 ===========================================

unsupervised techniques require separate training data (Boyd-Graber et al., 2014; Müller et al.,  

------------------- Sentence 1 -------------------

unsupervised techniques require separate training data (Boyd-Graber et al., 2014; Müller et al.,

>> Tokens are: 
 ['unsupervised', 'techniques', 'require', 'separate', 'training', 'data', '(', 'Boyd-Graber', 'et', 'al.', ',', '2014', ';', 'Müller', 'et', 'al.', ',']

>> Bigrams are: 
 [('unsupervised', 'techniques'), ('techniques', 'require'), ('require', 'separate'), ('separate', 'training'), ('training', 'data'), ('data', '('), ('(', 'Boyd-Graber'), ('Boyd-Graber', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('unsupervised', 'techniques', 'require'), ('techniques', 'require', 'separate'), ('require', 'separate', 'training'), ('separate', 'training', 'data'), ('training', 'data', '('), ('data', '(', 'Boyd-Graber'), ('(', 'Boyd-Graber', 'et'), ('Boyd-Graber', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Müller'), (';', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('unsupervised', 'JJ'), ('techniques', 'NNS'), ('require', 'VBP'), ('separate', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('(', '('), ('Boyd-Graber', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Müller', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['unsupervised techniques', 'separate training data', 'Boyd-Graber', 'al.', 'Müller', 'al.']

>> Named Entities are: 
 [('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('require', 'requir'), ('separate', 'separ'), ('training', 'train'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('require', 'requir'), ('separate', 'separ'), ('training', 'train'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('require', 'require'), ('separate', 'separate'), ('training', 'training'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'Boyd-Graber'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 652 ===========================================

2016; Breed and Verster, 2019).   

------------------- Sentence 1 -------------------

2016; Breed and Verster, 2019).

>> Tokens are: 
 ['2016', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 653 ===========================================

Unsupervised learning requires deducing functions for presenting unknown structures from  

------------------- Sentence 1 -------------------

Unsupervised learning requires deducing functions for presenting unknown structures from

>> Tokens are: 
 ['Unsupervised', 'learning', 'requires', 'deducing', 'functions', 'presenting', 'unknown', 'structures']

>> Bigrams are: 
 [('Unsupervised', 'learning'), ('learning', 'requires'), ('requires', 'deducing'), ('deducing', 'functions'), ('functions', 'presenting'), ('presenting', 'unknown'), ('unknown', 'structures')]

>> Trigrams are: 
 [('Unsupervised', 'learning', 'requires'), ('learning', 'requires', 'deducing'), ('requires', 'deducing', 'functions'), ('deducing', 'functions', 'presenting'), ('functions', 'presenting', 'unknown'), ('presenting', 'unknown', 'structures')]

>> POS Tags are: 
 [('Unsupervised', 'VBN'), ('learning', 'NN'), ('requires', 'VBZ'), ('deducing', 'VBG'), ('functions', 'NNS'), ('presenting', 'VBG'), ('unknown', 'JJ'), ('structures', 'NNS')]

>> Noun Phrases are: 
 ['learning', 'functions', 'unknown structures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('requires', 'requir'), ('deducing', 'deduc'), ('functions', 'function'), ('presenting', 'present'), ('unknown', 'unknown'), ('structures', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('requires', 'requir'), ('deducing', 'deduc'), ('functions', 'function'), ('presenting', 'present'), ('unknown', 'unknown'), ('structures', 'structur')]

>> Lemmatization: 
 [('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('requires', 'requires'), ('deducing', 'deducing'), ('functions', 'function'), ('presenting', 'presenting'), ('unknown', 'unknown'), ('structures', 'structure')]



========================================== PARAGRAPH 654 ===========================================

unlabelled data. This technique does not require a supervisor, which means that the system must  

------------------- Sentence 1 -------------------

unlabelled data.

>> Tokens are: 
 ['unlabelled', 'data', '.']

>> Bigrams are: 
 [('unlabelled', 'data'), ('data', '.')]

>> Trigrams are: 
 [('unlabelled', 'data', '.')]

>> POS Tags are: 
 [('unlabelled', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['unlabelled data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unlabelled', 'unlabel'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unlabelled', 'unlabel'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('unlabelled', 'unlabelled'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

This technique does not require a supervisor, which means that the system must

>> Tokens are: 
 ['This', 'technique', 'require', 'supervisor', ',', 'means', 'system', 'must']

>> Bigrams are: 
 [('This', 'technique'), ('technique', 'require'), ('require', 'supervisor'), ('supervisor', ','), (',', 'means'), ('means', 'system'), ('system', 'must')]

>> Trigrams are: 
 [('This', 'technique', 'require'), ('technique', 'require', 'supervisor'), ('require', 'supervisor', ','), ('supervisor', ',', 'means'), (',', 'means', 'system'), ('means', 'system', 'must')]

>> POS Tags are: 
 [('This', 'DT'), ('technique', 'NN'), ('require', 'NN'), ('supervisor', 'NN'), (',', ','), ('means', 'VBZ'), ('system', 'NN'), ('must', 'MD')]

>> Noun Phrases are: 
 ['This technique require supervisor', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('technique', 'techniqu'), ('require', 'requir'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('technique', 'techniqu'), ('require', 'requir'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must')]

>> Lemmatization: 
 [('This', 'This'), ('technique', 'technique'), ('require', 'require'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must')]



========================================== PARAGRAPH 655 ===========================================

have the ability to proceed independently with training based on unlabelled data input (Cui et al.,  

------------------- Sentence 1 -------------------

have the ability to proceed independently with training based on unlabelled data input (Cui et al.,

>> Tokens are: 
 ['ability', 'proceed', 'independently', 'training', 'based', 'unlabelled', 'data', 'input', '(', 'Cui', 'et', 'al.', ',']

>> Bigrams are: 
 [('ability', 'proceed'), ('proceed', 'independently'), ('independently', 'training'), ('training', 'based'), ('based', 'unlabelled'), ('unlabelled', 'data'), ('data', 'input'), ('input', '('), ('(', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('ability', 'proceed', 'independently'), ('proceed', 'independently', 'training'), ('independently', 'training', 'based'), ('training', 'based', 'unlabelled'), ('based', 'unlabelled', 'data'), ('unlabelled', 'data', 'input'), ('data', 'input', '('), ('input', '(', 'Cui'), ('(', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('ability', 'NN'), ('proceed', 'VBP'), ('independently', 'RB'), ('training', 'VBG'), ('based', 'VBN'), ('unlabelled', 'JJ'), ('data', 'NNS'), ('input', 'NN'), ('(', '('), ('Cui', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['ability', 'unlabelled data input', 'Cui']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('ability', 'abil'), ('proceed', 'proceed'), ('independently', 'independ'), ('training', 'train'), ('based', 'base'), ('unlabelled', 'unlabel'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('ability', 'abil'), ('proceed', 'proceed'), ('independently', 'independ'), ('training', 'train'), ('based', 'base'), ('unlabelled', 'unlabel'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('ability', 'ability'), ('proceed', 'proceed'), ('independently', 'independently'), ('training', 'training'), ('based', 'based'), ('unlabelled', 'unlabelled'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 656 ===========================================

2019).  

------------------- Sentence 1 -------------------

2019).

>> Tokens are: 
 ['2019', ')', '.']

>> Bigrams are: 
 [('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2019', ')', '.')]

>> POS Tags are: 
 [('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 657 ===========================================

Examples of unsupervised learning algorithms include clustering algorithms, combinatorial  

------------------- Sentence 1 -------------------

Examples of unsupervised learning algorithms include clustering algorithms, combinatorial

>> Tokens are: 
 ['Examples', 'unsupervised', 'learning', 'algorithms', 'include', 'clustering', 'algorithms', ',', 'combinatorial']

>> Bigrams are: 
 [('Examples', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'include'), ('include', 'clustering'), ('clustering', 'algorithms'), ('algorithms', ','), (',', 'combinatorial')]

>> Trigrams are: 
 [('Examples', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'include'), ('algorithms', 'include', 'clustering'), ('include', 'clustering', 'algorithms'), ('clustering', 'algorithms', ','), ('algorithms', ',', 'combinatorial')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('include', 'VBP'), ('clustering', 'VBG'), ('algorithms', 'NN'), (',', ','), ('combinatorial', 'JJ')]

>> Noun Phrases are: 
 ['Examples', 'algorithms']

>> Named Entities are: 
 [('PERSON', 'Examples')] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('include', 'includ'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatori')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('include', 'includ'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatori')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('include', 'include'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatorial')]



========================================== PARAGRAPH 658 ===========================================

algorithms, A priori algorithms, Self-Organizing Maps (SOM), and applications of game theory.  

------------------- Sentence 1 -------------------

algorithms, A priori algorithms, Self-Organizing Maps (SOM), and applications of game theory.

>> Tokens are: 
 ['algorithms', ',', 'A', 'priori', 'algorithms', ',', 'Self-Organizing', 'Maps', '(', 'SOM', ')', ',', 'applications', 'game', 'theory', '.']

>> Bigrams are: 
 [('algorithms', ','), (',', 'A'), ('A', 'priori'), ('priori', 'algorithms'), ('algorithms', ','), (',', 'Self-Organizing'), ('Self-Organizing', 'Maps'), ('Maps', '('), ('(', 'SOM'), ('SOM', ')'), (')', ','), (',', 'applications'), ('applications', 'game'), ('game', 'theory'), ('theory', '.')]

>> Trigrams are: 
 [('algorithms', ',', 'A'), (',', 'A', 'priori'), ('A', 'priori', 'algorithms'), ('priori', 'algorithms', ','), ('algorithms', ',', 'Self-Organizing'), (',', 'Self-Organizing', 'Maps'), ('Self-Organizing', 'Maps', '('), ('Maps', '(', 'SOM'), ('(', 'SOM', ')'), ('SOM', ')', ','), (')', ',', 'applications'), (',', 'applications', 'game'), ('applications', 'game', 'theory'), ('game', 'theory', '.')]

>> POS Tags are: 
 [('algorithms', 'NN'), (',', ','), ('A', 'NNP'), ('priori', 'FW'), ('algorithms', 'NN'), (',', ','), ('Self-Organizing', 'JJ'), ('Maps', 'NNP'), ('(', '('), ('SOM', 'NNP'), (')', ')'), (',', ','), ('applications', 'NNS'), ('game', 'NN'), ('theory', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms', 'A', 'algorithms', 'Self-Organizing Maps', 'SOM', 'applications game theory']

>> Named Entities are: 
 [('ORGANIZATION', 'SOM')] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), (',', ','), ('A', 'a'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'self-organ'), ('Maps', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), (',', ','), ('applications', 'applic'), ('game', 'game'), ('theory', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), (',', ','), ('A', 'a'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'self-organ'), ('Maps', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), (',', ','), ('applications', 'applic'), ('game', 'game'), ('theory', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), (',', ','), ('A', 'A'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'Self-Organizing'), ('Maps', 'Maps'), ('(', '('), ('SOM', 'SOM'), (')', ')'), (',', ','), ('applications', 'application'), ('game', 'game'), ('theory', 'theory'), ('.', '.')]



========================================== PARAGRAPH 659 ===========================================

These techniques are used for classifying the input data into different clusters or classes based on  

------------------- Sentence 1 -------------------

These techniques are used for classifying the input data into different clusters or classes based on

>> Tokens are: 
 ['These', 'techniques', 'used', 'classifying', 'input', 'data', 'different', 'clusters', 'classes', 'based']

>> Bigrams are: 
 [('These', 'techniques'), ('techniques', 'used'), ('used', 'classifying'), ('classifying', 'input'), ('input', 'data'), ('data', 'different'), ('different', 'clusters'), ('clusters', 'classes'), ('classes', 'based')]

>> Trigrams are: 
 [('These', 'techniques', 'used'), ('techniques', 'used', 'classifying'), ('used', 'classifying', 'input'), ('classifying', 'input', 'data'), ('input', 'data', 'different'), ('data', 'different', 'clusters'), ('different', 'clusters', 'classes'), ('clusters', 'classes', 'based')]

>> POS Tags are: 
 [('These', 'DT'), ('techniques', 'NNS'), ('used', 'VBD'), ('classifying', 'VBG'), ('input', 'NN'), ('data', 'NNS'), ('different', 'JJ'), ('clusters', 'NNS'), ('classes', 'NNS'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['These techniques', 'input data', 'different clusters classes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('techniques', 'techniqu'), ('used', 'use'), ('classifying', 'classifi'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('techniques', 'techniqu'), ('used', 'use'), ('classifying', 'classifi'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'base')]

>> Lemmatization: 
 [('These', 'These'), ('techniques', 'technique'), ('used', 'used'), ('classifying', 'classifying'), ('input', 'input'), ('data', 'data'), ('different', 'different'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'based')]



========================================== PARAGRAPH 660 ===========================================

the data distribution (Jiang et al., 2017; Cui et al., 2019).  

------------------- Sentence 1 -------------------

the data distribution (Jiang et al., 2017; Cui et al., 2019).

>> Tokens are: 
 ['data', 'distribution', '(', 'Jiang', 'et', 'al.', ',', '2017', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('data', 'distribution'), ('distribution', '('), ('(', 'Jiang'), ('Jiang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'distribution', '('), ('distribution', '(', 'Jiang'), ('(', 'Jiang', 'et'), ('Jiang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('distribution', 'NN'), ('(', '('), ('Jiang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data distribution', 'Jiang', 'Cui', 'al.']

>> Named Entities are: 
 [('PERSON', 'Jiang')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('distribution', 'distribut'), ('(', '('), ('Jiang', 'jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('distribution', 'distribut'), ('(', '('), ('Jiang', 'jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('distribution', 'distribution'), ('(', '('), ('Jiang', 'Jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 661 ===========================================

Cluster Analysis: This method is based on grouping objects and classifying them depending on  

------------------- Sentence 1 -------------------

Cluster Analysis: This method is based on grouping objects and classifying them depending on

>> Tokens are: 
 ['Cluster', 'Analysis', ':', 'This', 'method', 'based', 'grouping', 'objects', 'classifying', 'depending']

>> Bigrams are: 
 [('Cluster', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'method'), ('method', 'based'), ('based', 'grouping'), ('grouping', 'objects'), ('objects', 'classifying'), ('classifying', 'depending')]

>> Trigrams are: 
 [('Cluster', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'method'), ('This', 'method', 'based'), ('method', 'based', 'grouping'), ('based', 'grouping', 'objects'), ('grouping', 'objects', 'classifying'), ('objects', 'classifying', 'depending')]

>> POS Tags are: 
 [('Cluster', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('method', 'NN'), ('based', 'VBN'), ('grouping', 'VBG'), ('objects', 'NNS'), ('classifying', 'VBG'), ('depending', 'VBG')]

>> Noun Phrases are: 
 ['Cluster Analysis', 'This method', 'objects']

>> Named Entities are: 
 [('GPE', 'Cluster'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Cluster', 'cluster'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('method', 'method'), ('based', 'base'), ('grouping', 'group'), ('objects', 'object'), ('classifying', 'classifi'), ('depending', 'depend')]

>> Stemming using Snowball Stemmer: 
 [('Cluster', 'cluster'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('method', 'method'), ('based', 'base'), ('grouping', 'group'), ('objects', 'object'), ('classifying', 'classifi'), ('depending', 'depend')]

>> Lemmatization: 
 [('Cluster', 'Cluster'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('method', 'method'), ('based', 'based'), ('grouping', 'grouping'), ('objects', 'object'), ('classifying', 'classifying'), ('depending', 'depending')]



========================================== PARAGRAPH 662 ===========================================

shared features. It is used for differentiation between objects to allow division into clusters. Thus,  

------------------- Sentence 1 -------------------

shared features.

>> Tokens are: 
 ['shared', 'features', '.']

>> Bigrams are: 
 [('shared', 'features'), ('features', '.')]

>> Trigrams are: 
 [('shared', 'features', '.')]

>> POS Tags are: 
 [('shared', 'VBN'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('shared', 'share'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('shared', 'share'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('shared', 'shared'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

It is used for differentiation between objects to allow division into clusters.

>> Tokens are: 
 ['It', 'used', 'differentiation', 'objects', 'allow', 'division', 'clusters', '.']

>> Bigrams are: 
 [('It', 'used'), ('used', 'differentiation'), ('differentiation', 'objects'), ('objects', 'allow'), ('allow', 'division'), ('division', 'clusters'), ('clusters', '.')]

>> Trigrams are: 
 [('It', 'used', 'differentiation'), ('used', 'differentiation', 'objects'), ('differentiation', 'objects', 'allow'), ('objects', 'allow', 'division'), ('allow', 'division', 'clusters'), ('division', 'clusters', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('used', 'VBD'), ('differentiation', 'NN'), ('objects', 'NNS'), ('allow', 'VBP'), ('division', 'NN'), ('clusters', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['differentiation objects', 'division clusters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('used', 'use'), ('differentiation', 'differenti'), ('objects', 'object'), ('allow', 'allow'), ('division', 'divis'), ('clusters', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('used', 'use'), ('differentiation', 'differenti'), ('objects', 'object'), ('allow', 'allow'), ('division', 'divis'), ('clusters', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('used', 'used'), ('differentiation', 'differentiation'), ('objects', 'object'), ('allow', 'allow'), ('division', 'division'), ('clusters', 'cluster'), ('.', '.')]


------------------- Sentence 3 -------------------

Thus,

>> Tokens are: 
 ['Thus', ',']

>> Bigrams are: 
 [('Thus', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Thus', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ',')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ',')]



========================================== PARAGRAPH 663 ===========================================

data which are related to each other or have the same features will be placed in a cluster or a group  

------------------- Sentence 1 -------------------

data which are related to each other or have the same features will be placed in a cluster or a group

>> Tokens are: 
 ['data', 'related', 'features', 'placed', 'cluster', 'group']

>> Bigrams are: 
 [('data', 'related'), ('related', 'features'), ('features', 'placed'), ('placed', 'cluster'), ('cluster', 'group')]

>> Trigrams are: 
 [('data', 'related', 'features'), ('related', 'features', 'placed'), ('features', 'placed', 'cluster'), ('placed', 'cluster', 'group')]

>> POS Tags are: 
 [('data', 'NNS'), ('related', 'JJ'), ('features', 'NNS'), ('placed', 'VBN'), ('cluster', 'NN'), ('group', 'NN')]

>> Noun Phrases are: 
 ['data', 'related features', 'cluster group']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('related', 'relat'), ('features', 'featur'), ('placed', 'place'), ('cluster', 'cluster'), ('group', 'group')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('related', 'relat'), ('features', 'featur'), ('placed', 'place'), ('cluster', 'cluster'), ('group', 'group')]

>> Lemmatization: 
 [('data', 'data'), ('related', 'related'), ('features', 'feature'), ('placed', 'placed'), ('cluster', 'cluster'), ('group', 'group')]



========================================== PARAGRAPH 664 ===========================================

and unrelated data will be in other groups (Wu et al., 2018; Cui et al., 2019), as shown in Figure  

------------------- Sentence 1 -------------------

and unrelated data will be in other groups (Wu et al., 2018; Cui et al., 2019), as shown in Figure

>> Tokens are: 
 ['unrelated', 'data', 'groups', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', ',', 'shown', 'Figure']

>> Bigrams are: 
 [('unrelated', 'data'), ('data', 'groups'), ('groups', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure')]

>> Trigrams are: 
 [('unrelated', 'data', 'groups'), ('data', 'groups', '('), ('groups', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure')]

>> POS Tags are: 
 [('unrelated', 'JJ'), ('data', 'NNS'), ('groups', 'NNS'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN')]

>> Noun Phrases are: 
 ['unrelated data groups', 'Wu', 'Cui', 'al.', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Figure')] 

>> Stemming using Porter Stemmer: 
 [('unrelated', 'unrel'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur')]

>> Stemming using Snowball Stemmer: 
 [('unrelated', 'unrel'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur')]

>> Lemmatization: 
 [('unrelated', 'unrelated'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure')]



========================================== PARAGRAPH 665 ===========================================

14.  

------------------- Sentence 1 -------------------

14.

>> Tokens are: 
 ['14', '.']

>> Bigrams are: 
 [('14', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('.', '.')]



========================================== PARAGRAPH 666 ===========================================

  


========================================== PARAGRAPH 667 ===========================================

  


========================================== PARAGRAPH 668 ===========================================

  


========================================== PARAGRAPH 669 ===========================================

Figure 14: Cluster analysis.  

------------------- Sentence 1 -------------------

Figure 14: Cluster analysis.

>> Tokens are: 
 ['Figure', '14', ':', 'Cluster', 'analysis', '.']

>> Bigrams are: 
 [('Figure', '14'), ('14', ':'), (':', 'Cluster'), ('Cluster', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Figure', '14', ':'), ('14', ':', 'Cluster'), (':', 'Cluster', 'analysis'), ('Cluster', 'analysis', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('14', 'CD'), (':', ':'), ('Cluster', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Cluster analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('14', '14'), (':', ':'), ('Cluster', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('14', '14'), (':', ':'), ('Cluster', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('14', '14'), (':', ':'), ('Cluster', 'Cluster'), ('analysis', 'analysis'), ('.', '.')]



========================================== PARAGRAPH 670 ===========================================

  


========================================== PARAGRAPH 671 ===========================================

7.1.3. Semi-supervised techniques    

------------------- Sentence 1 -------------------

7.1.3.

>> Tokens are: 
 ['7.1.3', '.']

>> Bigrams are: 
 [('7.1.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Lemmatization: 
 [('7.1.3', '7.1.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Semi-supervised techniques

>> Tokens are: 
 ['Semi-supervised', 'techniques']

>> Bigrams are: 
 [('Semi-supervised', 'techniques')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Semi-supervised', 'JJ'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Semi-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Semi-supervised', 'Semi-supervised'), ('techniques', 'technique')]



========================================== PARAGRAPH 672 ===========================================

Where some of the data is labelled and some is unlabelled, supervised and unsupervised techniques  

------------------- Sentence 1 -------------------

Where some of the data is labelled and some is unlabelled, supervised and unsupervised techniques

>> Tokens are: 
 ['Where', 'data', 'labelled', 'unlabelled', ',', 'supervised', 'unsupervised', 'techniques']

>> Bigrams are: 
 [('Where', 'data'), ('data', 'labelled'), ('labelled', 'unlabelled'), ('unlabelled', ','), (',', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'techniques')]

>> Trigrams are: 
 [('Where', 'data', 'labelled'), ('data', 'labelled', 'unlabelled'), ('labelled', 'unlabelled', ','), ('unlabelled', ',', 'supervised'), (',', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'techniques')]

>> POS Tags are: 
 [('Where', 'WRB'), ('data', 'NNS'), ('labelled', 'VBD'), ('unlabelled', 'JJ'), (',', ','), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['data', 'unsupervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('labelled', 'label'), ('unlabelled', 'unlabel'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('labelled', 'label'), ('unlabelled', 'unlabel'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Where', 'Where'), ('data', 'data'), ('labelled', 'labelled'), ('unlabelled', 'unlabelled'), (',', ','), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('techniques', 'technique')]



========================================== PARAGRAPH 673 ===========================================

can also be mixed. Algorithms are applied for both labelled and unlabelled data, and even with  

------------------- Sentence 1 -------------------

can also be mixed.

>> Tokens are: 
 ['also', 'mixed', '.']

>> Bigrams are: 
 [('also', 'mixed'), ('mixed', '.')]

>> Trigrams are: 
 [('also', 'mixed', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('mixed', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('mixed', 'mix'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('mixed', 'mix'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('mixed', 'mixed'), ('.', '.')]


------------------- Sentence 2 -------------------

Algorithms are applied for both labelled and unlabelled data, and even with

>> Tokens are: 
 ['Algorithms', 'applied', 'labelled', 'unlabelled', 'data', ',', 'even']

>> Bigrams are: 
 [('Algorithms', 'applied'), ('applied', 'labelled'), ('labelled', 'unlabelled'), ('unlabelled', 'data'), ('data', ','), (',', 'even')]

>> Trigrams are: 
 [('Algorithms', 'applied', 'labelled'), ('applied', 'labelled', 'unlabelled'), ('labelled', 'unlabelled', 'data'), ('unlabelled', 'data', ','), ('data', ',', 'even')]

>> POS Tags are: 
 [('Algorithms', 'NNP'), ('applied', 'VBD'), ('labelled', 'VBN'), ('unlabelled', 'JJ'), ('data', 'NNS'), (',', ','), ('even', 'RB')]

>> Noun Phrases are: 
 ['Algorithms', 'unlabelled data']

>> Named Entities are: 
 [('PERSON', 'Algorithms')] 

>> Stemming using Porter Stemmer: 
 [('Algorithms', 'algorithm'), ('applied', 'appli'), ('labelled', 'label'), ('unlabelled', 'unlabel'), ('data', 'data'), (',', ','), ('even', 'even')]

>> Stemming using Snowball Stemmer: 
 [('Algorithms', 'algorithm'), ('applied', 'appli'), ('labelled', 'label'), ('unlabelled', 'unlabel'), ('data', 'data'), (',', ','), ('even', 'even')]

>> Lemmatization: 
 [('Algorithms', 'Algorithms'), ('applied', 'applied'), ('labelled', 'labelled'), ('unlabelled', 'unlabelled'), ('data', 'data'), (',', ','), ('even', 'even')]



========================================== PARAGRAPH 674 ===========================================

incomplete information or missing training sets, some of the dataset’s classifiers can be learned. 

------------------- Sentence 1 -------------------

incomplete information or missing training sets, some of the dataset’s classifiers can be learned.

>> Tokens are: 
 ['incomplete', 'information', 'missing', 'training', 'sets', ',', 'dataset', '’', 'classifiers', 'learned', '.']

>> Bigrams are: 
 [('incomplete', 'information'), ('information', 'missing'), ('missing', 'training'), ('training', 'sets'), ('sets', ','), (',', 'dataset'), ('dataset', '’'), ('’', 'classifiers'), ('classifiers', 'learned'), ('learned', '.')]

>> Trigrams are: 
 [('incomplete', 'information', 'missing'), ('information', 'missing', 'training'), ('missing', 'training', 'sets'), ('training', 'sets', ','), ('sets', ',', 'dataset'), (',', 'dataset', '’'), ('dataset', '’', 'classifiers'), ('’', 'classifiers', 'learned'), ('classifiers', 'learned', '.')]

>> POS Tags are: 
 [('incomplete', 'JJ'), ('information', 'NN'), ('missing', 'VBG'), ('training', 'NN'), ('sets', 'NNS'), (',', ','), ('dataset', 'VBN'), ('’', 'NN'), ('classifiers', 'NNS'), ('learned', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['incomplete information', 'training sets', '’ classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('incomplete', 'incomplet'), ('information', 'inform'), ('missing', 'miss'), ('training', 'train'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('learned', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('incomplete', 'incomplet'), ('information', 'inform'), ('missing', 'miss'), ('training', 'train'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('learned', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('incomplete', 'incomplete'), ('information', 'information'), ('missing', 'missing'), ('training', 'training'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifier'), ('learned', 'learned'), ('.', '.')]



========================================== PARAGRAPH 675 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 676 ===========================================

25  

------------------- Sentence 1 -------------------

25

>> Tokens are: 
 ['25']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('25', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25')]

>> Stemming using Snowball Stemmer: 
 [('25', '25')]

>> Lemmatization: 
 [('25', '25')]



========================================== PARAGRAPH 677 ===========================================

  


========================================== PARAGRAPH 678 ===========================================

Both supervised and unsupervised techniques focus on one aspect (target separation or  

------------------- Sentence 1 -------------------

Both supervised and unsupervised techniques focus on one aspect (target separation or

>> Tokens are: 
 ['Both', 'supervised', 'unsupervised', 'techniques', 'focus', 'one', 'aspect', '(', 'target', 'separation']

>> Bigrams are: 
 [('Both', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'techniques'), ('techniques', 'focus'), ('focus', 'one'), ('one', 'aspect'), ('aspect', '('), ('(', 'target'), ('target', 'separation')]

>> Trigrams are: 
 [('Both', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'techniques'), ('unsupervised', 'techniques', 'focus'), ('techniques', 'focus', 'one'), ('focus', 'one', 'aspect'), ('one', 'aspect', '('), ('aspect', '(', 'target'), ('(', 'target', 'separation')]

>> POS Tags are: 
 [('Both', 'DT'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('techniques', 'NNS'), ('focus', 'VBP'), ('one', 'CD'), ('aspect', 'NN'), ('(', '('), ('target', 'NN'), ('separation', 'NN')]

>> Noun Phrases are: 
 ['unsupervised techniques', 'aspect', 'target separation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Both', 'both'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('focus', 'focu'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separ')]

>> Stemming using Snowball Stemmer: 
 [('Both', 'both'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('focus', 'focus'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separ')]

>> Lemmatization: 
 [('Both', 'Both'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('focus', 'focus'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separation')]



========================================== PARAGRAPH 679 ===========================================

independent variable distribution, respectively), and using them together may thus give better  

------------------- Sentence 1 -------------------

independent variable distribution, respectively), and using them together may thus give better

>> Tokens are: 
 ['independent', 'variable', 'distribution', ',', 'respectively', ')', ',', 'using', 'together', 'may', 'thus', 'give', 'better']

>> Bigrams are: 
 [('independent', 'variable'), ('variable', 'distribution'), ('distribution', ','), (',', 'respectively'), ('respectively', ')'), (')', ','), (',', 'using'), ('using', 'together'), ('together', 'may'), ('may', 'thus'), ('thus', 'give'), ('give', 'better')]

>> Trigrams are: 
 [('independent', 'variable', 'distribution'), ('variable', 'distribution', ','), ('distribution', ',', 'respectively'), (',', 'respectively', ')'), ('respectively', ')', ','), (')', ',', 'using'), (',', 'using', 'together'), ('using', 'together', 'may'), ('together', 'may', 'thus'), ('may', 'thus', 'give'), ('thus', 'give', 'better')]

>> POS Tags are: 
 [('independent', 'JJ'), ('variable', 'JJ'), ('distribution', 'NN'), (',', ','), ('respectively', 'RB'), (')', ')'), (',', ','), ('using', 'VBG'), ('together', 'RB'), ('may', 'MD'), ('thus', 'RB'), ('give', 'VB'), ('better', 'JJR')]

>> Noun Phrases are: 
 ['independent variable distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('independent', 'independ'), ('variable', 'variabl'), ('distribution', 'distribut'), (',', ','), ('respectively', 'respect'), (')', ')'), (',', ','), ('using', 'use'), ('together', 'togeth'), ('may', 'may'), ('thus', 'thu'), ('give', 'give'), ('better', 'better')]

>> Stemming using Snowball Stemmer: 
 [('independent', 'independ'), ('variable', 'variabl'), ('distribution', 'distribut'), (',', ','), ('respectively', 'respect'), (')', ')'), (',', ','), ('using', 'use'), ('together', 'togeth'), ('may', 'may'), ('thus', 'thus'), ('give', 'give'), ('better', 'better')]

>> Lemmatization: 
 [('independent', 'independent'), ('variable', 'variable'), ('distribution', 'distribution'), (',', ','), ('respectively', 'respectively'), (')', ')'), (',', ','), ('using', 'using'), ('together', 'together'), ('may', 'may'), ('thus', 'thus'), ('give', 'give'), ('better', 'better')]



========================================== PARAGRAPH 680 ===========================================

results (Breed, D.G. and Verster, T., 2019).  

------------------- Sentence 1 -------------------

results (Breed, D.G.

>> Tokens are: 
 ['results', '(', 'Breed', ',', 'D.G', '.']

>> Bigrams are: 
 [('results', '('), ('(', 'Breed'), ('Breed', ','), (',', 'D.G'), ('D.G', '.')]

>> Trigrams are: 
 [('results', '(', 'Breed'), ('(', 'Breed', ','), ('Breed', ',', 'D.G'), (',', 'D.G', '.')]

>> POS Tags are: 
 [('results', 'NNS'), ('(', '('), ('Breed', 'NNP'), (',', ','), ('D.G', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['results', 'Breed', 'D.G']

>> Named Entities are: 
 [('PERSON', 'Breed')] 

>> Stemming using Porter Stemmer: 
 [('results', 'result'), ('(', '('), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('results', 'result'), ('(', '('), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Lemmatization: 
 [('results', 'result'), ('(', '('), ('Breed', 'Breed'), (',', ','), ('D.G', 'D.G'), ('.', '.')]


------------------- Sentence 2 -------------------

and Verster, T., 2019).

>> Tokens are: 
 ['Verster', ',', 'T.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Verster', ','), (',', 'T.'), ('T.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Verster', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Verster', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Verster', 'T.']

>> Named Entities are: 
 [('PERSON', 'Verster')] 

>> Stemming using Porter Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Verster', 'Verster'), (',', ','), ('T.', 'T.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 681 ===========================================

  


========================================== PARAGRAPH 682 ===========================================

7.1.4. Reinforcement learning (RL)    

------------------- Sentence 1 -------------------

7.1.4.

>> Tokens are: 
 ['7.1.4', '.']

>> Bigrams are: 
 [('7.1.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Lemmatization: 
 [('7.1.4', '7.1.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Reinforcement learning (RL)

>> Tokens are: 
 ['Reinforcement', 'learning', '(', 'RL', ')']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', '('), ('(', 'RL'), ('RL', ')')]

>> Trigrams are: 
 [('Reinforcement', 'learning', '('), ('learning', '(', 'RL'), ('(', 'RL', ')')]

>> POS Tags are: 
 [('Reinforcement', 'NN'), ('learning', 'NN'), ('(', '('), ('RL', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['Reinforcement learning', 'RL']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('(', '('), ('RL', 'RL'), (')', ')')]



========================================== PARAGRAPH 683 ===========================================

Reinforcement learning involves setting and classifying real-time data changes in a way that allows  

------------------- Sentence 1 -------------------

Reinforcement learning involves setting and classifying real-time data changes in a way that allows

>> Tokens are: 
 ['Reinforcement', 'learning', 'involves', 'setting', 'classifying', 'real-time', 'data', 'changes', 'way', 'allows']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', 'involves'), ('involves', 'setting'), ('setting', 'classifying'), ('classifying', 'real-time'), ('real-time', 'data'), ('data', 'changes'), ('changes', 'way'), ('way', 'allows')]

>> Trigrams are: 
 [('Reinforcement', 'learning', 'involves'), ('learning', 'involves', 'setting'), ('involves', 'setting', 'classifying'), ('setting', 'classifying', 'real-time'), ('classifying', 'real-time', 'data'), ('real-time', 'data', 'changes'), ('data', 'changes', 'way'), ('changes', 'way', 'allows')]

>> POS Tags are: 
 [('Reinforcement', 'NNP'), ('learning', 'VBG'), ('involves', 'NNS'), ('setting', 'VBG'), ('classifying', 'VBG'), ('real-time', 'JJ'), ('data', 'NNS'), ('changes', 'NNS'), ('way', 'NN'), ('allows', 'NNS')]

>> Noun Phrases are: 
 ['Reinforcement', 'involves', 'real-time data changes way allows']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('involves', 'involv'), ('setting', 'set'), ('classifying', 'classifi'), ('real-time', 'real-tim'), ('data', 'data'), ('changes', 'chang'), ('way', 'way'), ('allows', 'allow')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('involves', 'involv'), ('setting', 'set'), ('classifying', 'classifi'), ('real-time', 'real-tim'), ('data', 'data'), ('changes', 'chang'), ('way', 'way'), ('allows', 'allow')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('involves', 'involves'), ('setting', 'setting'), ('classifying', 'classifying'), ('real-time', 'real-time'), ('data', 'data'), ('changes', 'change'), ('way', 'way'), ('allows', 'allows')]



========================================== PARAGRAPH 684 ===========================================

the learning framework to adapt based on those changes (Wu et al., 2018; Cui et al., 2019).   

------------------- Sentence 1 -------------------

the learning framework to adapt based on those changes (Wu et al., 2018; Cui et al., 2019).

>> Tokens are: 
 ['learning', 'framework', 'adapt', 'based', 'changes', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('learning', 'framework'), ('framework', 'adapt'), ('adapt', 'based'), ('based', 'changes'), ('changes', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('learning', 'framework', 'adapt'), ('framework', 'adapt', 'based'), ('adapt', 'based', 'changes'), ('based', 'changes', '('), ('changes', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('framework', 'NN'), ('adapt', 'NN'), ('based', 'VBN'), ('changes', 'NNS'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['framework adapt', 'changes', 'Wu', 'Cui', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'base'), ('changes', 'chang'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'base'), ('changes', 'chang'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'based'), ('changes', 'change'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 685 ===========================================

The components of an RL algorithm are the agent; the environment; and the actions. The actions  

------------------- Sentence 1 -------------------

The components of an RL algorithm are the agent; the environment; and the actions.

>> Tokens are: 
 ['The', 'components', 'RL', 'algorithm', 'agent', ';', 'environment', ';', 'actions', '.']

>> Bigrams are: 
 [('The', 'components'), ('components', 'RL'), ('RL', 'algorithm'), ('algorithm', 'agent'), ('agent', ';'), (';', 'environment'), ('environment', ';'), (';', 'actions'), ('actions', '.')]

>> Trigrams are: 
 [('The', 'components', 'RL'), ('components', 'RL', 'algorithm'), ('RL', 'algorithm', 'agent'), ('algorithm', 'agent', ';'), ('agent', ';', 'environment'), (';', 'environment', ';'), ('environment', ';', 'actions'), (';', 'actions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('components', 'NNS'), ('RL', 'NNP'), ('algorithm', 'VBP'), ('agent', 'NN'), (';', ':'), ('environment', 'NN'), (';', ':'), ('actions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The components RL', 'agent', 'environment', 'actions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('components', 'compon'), ('RL', 'rl'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environ'), (';', ';'), ('actions', 'action'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('components', 'compon'), ('RL', 'rl'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environ'), (';', ';'), ('actions', 'action'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('components', 'component'), ('RL', 'RL'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environment'), (';', ';'), ('actions', 'action'), ('.', '.')]


------------------- Sentence 2 -------------------

The actions

>> Tokens are: 
 ['The', 'actions']

>> Bigrams are: 
 [('The', 'actions')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('actions', 'NNS')]

>> Noun Phrases are: 
 ['The actions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('actions', 'action')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('actions', 'action')]

>> Lemmatization: 
 [('The', 'The'), ('actions', 'action')]



========================================== PARAGRAPH 686 ===========================================

are taken by the algorithm based on the environment, and depending on the feedback from the  

------------------- Sentence 1 -------------------

are taken by the algorithm based on the environment, and depending on the feedback from the

>> Tokens are: 
 ['taken', 'algorithm', 'based', 'environment', ',', 'depending', 'feedback']

>> Bigrams are: 
 [('taken', 'algorithm'), ('algorithm', 'based'), ('based', 'environment'), ('environment', ','), (',', 'depending'), ('depending', 'feedback')]

>> Trigrams are: 
 [('taken', 'algorithm', 'based'), ('algorithm', 'based', 'environment'), ('based', 'environment', ','), ('environment', ',', 'depending'), (',', 'depending', 'feedback')]

>> POS Tags are: 
 [('taken', 'VBN'), ('algorithm', 'NNS'), ('based', 'VBN'), ('environment', 'NN'), (',', ','), ('depending', 'VBG'), ('feedback', 'NN')]

>> Noun Phrases are: 
 ['algorithm', 'environment', 'feedback']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'base'), ('environment', 'environ'), (',', ','), ('depending', 'depend'), ('feedback', 'feedback')]

>> Stemming using Snowball Stemmer: 
 [('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'base'), ('environment', 'environ'), (',', ','), ('depending', 'depend'), ('feedback', 'feedback')]

>> Lemmatization: 
 [('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'based'), ('environment', 'environment'), (',', ','), ('depending', 'depending'), ('feedback', 'feedback')]



========================================== PARAGRAPH 687 ===========================================

environment, it determines whether the action is positive, thus using it again in future, or negative,  

------------------- Sentence 1 -------------------

environment, it determines whether the action is positive, thus using it again in future, or negative,

>> Tokens are: 
 ['environment', ',', 'determines', 'whether', 'action', 'positive', ',', 'thus', 'using', 'future', ',', 'negative', ',']

>> Bigrams are: 
 [('environment', ','), (',', 'determines'), ('determines', 'whether'), ('whether', 'action'), ('action', 'positive'), ('positive', ','), (',', 'thus'), ('thus', 'using'), ('using', 'future'), ('future', ','), (',', 'negative'), ('negative', ',')]

>> Trigrams are: 
 [('environment', ',', 'determines'), (',', 'determines', 'whether'), ('determines', 'whether', 'action'), ('whether', 'action', 'positive'), ('action', 'positive', ','), ('positive', ',', 'thus'), (',', 'thus', 'using'), ('thus', 'using', 'future'), ('using', 'future', ','), ('future', ',', 'negative'), (',', 'negative', ',')]

>> POS Tags are: 
 [('environment', 'NN'), (',', ','), ('determines', 'VBZ'), ('whether', 'IN'), ('action', 'NN'), ('positive', 'JJ'), (',', ','), ('thus', 'RB'), ('using', 'VBG'), ('future', 'JJ'), (',', ','), ('negative', 'JJ'), (',', ',')]

>> Noun Phrases are: 
 ['environment', 'action']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('environment', 'environ'), (',', ','), ('determines', 'determin'), ('whether', 'whether'), ('action', 'action'), ('positive', 'posit'), (',', ','), ('thus', 'thu'), ('using', 'use'), ('future', 'futur'), (',', ','), ('negative', 'neg'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('environment', 'environ'), (',', ','), ('determines', 'determin'), ('whether', 'whether'), ('action', 'action'), ('positive', 'posit'), (',', ','), ('thus', 'thus'), ('using', 'use'), ('future', 'futur'), (',', ','), ('negative', 'negat'), (',', ',')]

>> Lemmatization: 
 [('environment', 'environment'), (',', ','), ('determines', 'determines'), ('whether', 'whether'), ('action', 'action'), ('positive', 'positive'), (',', ','), ('thus', 'thus'), ('using', 'using'), ('future', 'future'), (',', ','), ('negative', 'negative'), (',', ',')]



========================================== PARAGRAPH 688 ===========================================

thus discarding it. An example of reinforcement learning is Markov Chains (Markov Decision  

------------------- Sentence 1 -------------------

thus discarding it.

>> Tokens are: 
 ['thus', 'discarding', '.']

>> Bigrams are: 
 [('thus', 'discarding'), ('discarding', '.')]

>> Trigrams are: 
 [('thus', 'discarding', '.')]

>> POS Tags are: 
 [('thus', 'RB'), ('discarding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['discarding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('thus', 'thu'), ('discarding', 'discard'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('thus', 'thus'), ('discarding', 'discard'), ('.', '.')]

>> Lemmatization: 
 [('thus', 'thus'), ('discarding', 'discarding'), ('.', '.')]


------------------- Sentence 2 -------------------

An example of reinforcement learning is Markov Chains (Markov Decision

>> Tokens are: 
 ['An', 'example', 'reinforcement', 'learning', 'Markov', 'Chains', '(', 'Markov', 'Decision']

>> Bigrams are: 
 [('An', 'example'), ('example', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'Markov'), ('Markov', 'Chains'), ('Chains', '('), ('(', 'Markov'), ('Markov', 'Decision')]

>> Trigrams are: 
 [('An', 'example', 'reinforcement'), ('example', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'Markov'), ('learning', 'Markov', 'Chains'), ('Markov', 'Chains', '('), ('Chains', '(', 'Markov'), ('(', 'Markov', 'Decision')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('Markov', 'NNP'), ('Chains', 'NNP'), ('(', '('), ('Markov', 'NNP'), ('Decision', 'NNP')]

>> Noun Phrases are: 
 ['An example reinforcement', 'Markov Chains', 'Markov Decision']

>> Named Entities are: 
 [('PERSON', 'Markov Chains'), ('PERSON', 'Markov Decision')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('Markov', 'markov'), ('Chains', 'chain'), ('(', '('), ('Markov', 'markov'), ('Decision', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('Markov', 'markov'), ('Chains', 'chain'), ('(', '('), ('Markov', 'markov'), ('Decision', 'decis')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('Markov', 'Markov'), ('Chains', 'Chains'), ('(', '('), ('Markov', 'Markov'), ('Decision', 'Decision')]



========================================== PARAGRAPH 689 ===========================================

Process) (Müller et al., 2016). The difference between RL and supervised or unsupervised learning  

------------------- Sentence 1 -------------------

Process) (Müller et al., 2016).

>> Tokens are: 
 ['Process', ')', '(', 'Müller', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Process', ')'), (')', '('), ('(', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Process', ')', '('), (')', '(', 'Müller'), ('(', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Process', 'NN'), (')', ')'), ('(', '('), ('Müller', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Process', 'Müller']

>> Named Entities are: 
 [('GPE', 'Process'), ('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('Process', 'process'), (')', ')'), ('(', '('), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Process', 'process'), (')', ')'), ('(', '('), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Process', 'Process'), (')', ')'), ('(', '('), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The difference between RL and supervised or unsupervised learning

>> Tokens are: 
 ['The', 'difference', 'RL', 'supervised', 'unsupervised', 'learning']

>> Bigrams are: 
 [('The', 'difference'), ('difference', 'RL'), ('RL', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning')]

>> Trigrams are: 
 [('The', 'difference', 'RL'), ('difference', 'RL', 'supervised'), ('RL', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning')]

>> POS Tags are: 
 [('The', 'DT'), ('difference', 'NN'), ('RL', 'NNP'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['The difference RL', 'unsupervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('difference', 'differ'), ('RL', 'rl'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('difference', 'differ'), ('RL', 'rl'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn')]

>> Lemmatization: 
 [('The', 'The'), ('difference', 'difference'), ('RL', 'RL'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning')]



========================================== PARAGRAPH 690 ===========================================

is that RL works based on the feedback which is either good or not depending on the situation and  

------------------- Sentence 1 -------------------

is that RL works based on the feedback which is either good or not depending on the situation and

>> Tokens are: 
 ['RL', 'works', 'based', 'feedback', 'either', 'good', 'depending', 'situation']

>> Bigrams are: 
 [('RL', 'works'), ('works', 'based'), ('based', 'feedback'), ('feedback', 'either'), ('either', 'good'), ('good', 'depending'), ('depending', 'situation')]

>> Trigrams are: 
 [('RL', 'works', 'based'), ('works', 'based', 'feedback'), ('based', 'feedback', 'either'), ('feedback', 'either', 'good'), ('either', 'good', 'depending'), ('good', 'depending', 'situation')]

>> POS Tags are: 
 [('RL', 'NNP'), ('works', 'NNS'), ('based', 'VBN'), ('feedback', 'RB'), ('either', 'RB'), ('good', 'JJ'), ('depending', 'VBG'), ('situation', 'NN')]

>> Noun Phrases are: 
 ['RL works', 'situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('RL', 'rl'), ('works', 'work'), ('based', 'base'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depend'), ('situation', 'situat')]

>> Stemming using Snowball Stemmer: 
 [('RL', 'rl'), ('works', 'work'), ('based', 'base'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depend'), ('situation', 'situat')]

>> Lemmatization: 
 [('RL', 'RL'), ('works', 'work'), ('based', 'based'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depending'), ('situation', 'situation')]



========================================== PARAGRAPH 691 ===========================================

is hence dynamic, while supervised and unsupervised learning give static solutions (Cui, et al.,  

------------------- Sentence 1 -------------------

is hence dynamic, while supervised and unsupervised learning give static solutions (Cui, et al.,

>> Tokens are: 
 ['hence', 'dynamic', ',', 'supervised', 'unsupervised', 'learning', 'give', 'static', 'solutions', '(', 'Cui', ',', 'et', 'al.', ',']

>> Bigrams are: 
 [('hence', 'dynamic'), ('dynamic', ','), (',', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'give'), ('give', 'static'), ('static', 'solutions'), ('solutions', '('), ('(', 'Cui'), ('Cui', ','), (',', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('hence', 'dynamic', ','), ('dynamic', ',', 'supervised'), (',', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'give'), ('learning', 'give', 'static'), ('give', 'static', 'solutions'), ('static', 'solutions', '('), ('solutions', '(', 'Cui'), ('(', 'Cui', ','), ('Cui', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('hence', 'RB'), ('dynamic', 'JJ'), (',', ','), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('give', 'JJ'), ('static', 'JJ'), ('solutions', 'NNS'), ('(', '('), ('Cui', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['give static solutions', 'Cui', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('hence', 'henc'), ('dynamic', 'dynam'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('give', 'give'), ('static', 'static'), ('solutions', 'solut'), ('(', '('), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('hence', 'henc'), ('dynamic', 'dynam'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('give', 'give'), ('static', 'static'), ('solutions', 'solut'), ('(', '('), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('hence', 'hence'), ('dynamic', 'dynamic'), (',', ','), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('give', 'give'), ('static', 'static'), ('solutions', 'solution'), ('(', '('), ('Cui', 'Cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 692 ===========================================

2019).  

------------------- Sentence 1 -------------------

2019).

>> Tokens are: 
 ['2019', ')', '.']

>> Bigrams are: 
 [('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2019', ')', '.')]

>> POS Tags are: 
 [('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 693 ===========================================

The RL process includes an actor which acts in the environment with its own copy of the data; the  

------------------- Sentence 1 -------------------

The RL process includes an actor which acts in the environment with its own copy of the data; the

>> Tokens are: 
 ['The', 'RL', 'process', 'includes', 'actor', 'acts', 'environment', 'copy', 'data', ';']

>> Bigrams are: 
 [('The', 'RL'), ('RL', 'process'), ('process', 'includes'), ('includes', 'actor'), ('actor', 'acts'), ('acts', 'environment'), ('environment', 'copy'), ('copy', 'data'), ('data', ';')]

>> Trigrams are: 
 [('The', 'RL', 'process'), ('RL', 'process', 'includes'), ('process', 'includes', 'actor'), ('includes', 'actor', 'acts'), ('actor', 'acts', 'environment'), ('acts', 'environment', 'copy'), ('environment', 'copy', 'data'), ('copy', 'data', ';')]

>> POS Tags are: 
 [('The', 'DT'), ('RL', 'NNP'), ('process', 'NN'), ('includes', 'VBZ'), ('actor', 'NN'), ('acts', 'NNS'), ('environment', 'NN'), ('copy', 'NN'), ('data', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['The RL process', 'actor acts environment copy data']

>> Named Entities are: 
 [('ORGANIZATION', 'RL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('RL', 'rl'), ('process', 'process'), ('includes', 'includ'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environ'), ('copy', 'copi'), ('data', 'data'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('RL', 'rl'), ('process', 'process'), ('includes', 'includ'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environ'), ('copy', 'copi'), ('data', 'data'), (';', ';')]

>> Lemmatization: 
 [('The', 'The'), ('RL', 'RL'), ('process', 'process'), ('includes', 'includes'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environment'), ('copy', 'copy'), ('data', 'data'), (';', ';')]



========================================== PARAGRAPH 694 ===========================================

data can thus be stored in a separate replay memory and sampled by the learner to be computed  

------------------- Sentence 1 -------------------

data can thus be stored in a separate replay memory and sampled by the learner to be computed

>> Tokens are: 
 ['data', 'thus', 'stored', 'separate', 'replay', 'memory', 'sampled', 'learner', 'computed']

>> Bigrams are: 
 [('data', 'thus'), ('thus', 'stored'), ('stored', 'separate'), ('separate', 'replay'), ('replay', 'memory'), ('memory', 'sampled'), ('sampled', 'learner'), ('learner', 'computed')]

>> Trigrams are: 
 [('data', 'thus', 'stored'), ('thus', 'stored', 'separate'), ('stored', 'separate', 'replay'), ('separate', 'replay', 'memory'), ('replay', 'memory', 'sampled'), ('memory', 'sampled', 'learner'), ('sampled', 'learner', 'computed')]

>> POS Tags are: 
 [('data', 'NNS'), ('thus', 'RB'), ('stored', 'VBN'), ('separate', 'JJ'), ('replay', 'NN'), ('memory', 'NN'), ('sampled', 'VBD'), ('learner', 'NN'), ('computed', 'VBD')]

>> Noun Phrases are: 
 ['data', 'separate replay memory', 'learner']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('thus', 'thu'), ('stored', 'store'), ('separate', 'separ'), ('replay', 'replay'), ('memory', 'memori'), ('sampled', 'sampl'), ('learner', 'learner'), ('computed', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('thus', 'thus'), ('stored', 'store'), ('separate', 'separ'), ('replay', 'replay'), ('memory', 'memori'), ('sampled', 'sampl'), ('learner', 'learner'), ('computed', 'comput')]

>> Lemmatization: 
 [('data', 'data'), ('thus', 'thus'), ('stored', 'stored'), ('separate', 'separate'), ('replay', 'replay'), ('memory', 'memory'), ('sampled', 'sampled'), ('learner', 'learner'), ('computed', 'computed')]



========================================== PARAGRAPH 695 ===========================================

within the policy parameters. The actor learners then receive the updated policy parameters (Mnih  

------------------- Sentence 1 -------------------

within the policy parameters.

>> Tokens are: 
 ['within', 'policy', 'parameters', '.']

>> Bigrams are: 
 [('within', 'policy'), ('policy', 'parameters'), ('parameters', '.')]

>> Trigrams are: 
 [('within', 'policy', 'parameters'), ('policy', 'parameters', '.')]

>> POS Tags are: 
 [('within', 'IN'), ('policy', 'NN'), ('parameters', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['policy parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('within', 'within'), ('policy', 'polici'), ('parameters', 'paramet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('within', 'within'), ('policy', 'polici'), ('parameters', 'paramet'), ('.', '.')]

>> Lemmatization: 
 [('within', 'within'), ('policy', 'policy'), ('parameters', 'parameter'), ('.', '.')]


------------------- Sentence 2 -------------------

The actor learners then receive the updated policy parameters (Mnih

>> Tokens are: 
 ['The', 'actor', 'learners', 'receive', 'updated', 'policy', 'parameters', '(', 'Mnih']

>> Bigrams are: 
 [('The', 'actor'), ('actor', 'learners'), ('learners', 'receive'), ('receive', 'updated'), ('updated', 'policy'), ('policy', 'parameters'), ('parameters', '('), ('(', 'Mnih')]

>> Trigrams are: 
 [('The', 'actor', 'learners'), ('actor', 'learners', 'receive'), ('learners', 'receive', 'updated'), ('receive', 'updated', 'policy'), ('updated', 'policy', 'parameters'), ('policy', 'parameters', '('), ('parameters', '(', 'Mnih')]

>> POS Tags are: 
 [('The', 'DT'), ('actor', 'NN'), ('learners', 'NNS'), ('receive', 'VBP'), ('updated', 'JJ'), ('policy', 'NN'), ('parameters', 'NNS'), ('(', '('), ('Mnih', 'NNP')]

>> Noun Phrases are: 
 ['The actor learners', 'updated policy parameters', 'Mnih']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receiv'), ('updated', 'updat'), ('policy', 'polici'), ('parameters', 'paramet'), ('(', '('), ('Mnih', 'mnih')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receiv'), ('updated', 'updat'), ('policy', 'polici'), ('parameters', 'paramet'), ('(', '('), ('Mnih', 'mnih')]

>> Lemmatization: 
 [('The', 'The'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receive'), ('updated', 'updated'), ('policy', 'policy'), ('parameters', 'parameter'), ('(', '('), ('Mnih', 'Mnih')]



========================================== PARAGRAPH 696 ===========================================

et al., 2015; Mnih et al., 2016).  

------------------- Sentence 1 -------------------

et al., 2015; Mnih et al., 2016).

>> Tokens are: 
 ['et', 'al.', ',', '2015', ';', 'Mnih', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.', 'Mnih', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 697 ===========================================

The Map-Reduce framework was utilized by Li and Schuurmans (2011) for parallelising batch  

------------------- Sentence 1 -------------------

The Map-Reduce framework was utilized by Li and Schuurmans (2011) for parallelising batch

>> Tokens are: 
 ['The', 'Map-Reduce', 'framework', 'utilized', 'Li', 'Schuurmans', '(', '2011', ')', 'parallelising', 'batch']

>> Bigrams are: 
 [('The', 'Map-Reduce'), ('Map-Reduce', 'framework'), ('framework', 'utilized'), ('utilized', 'Li'), ('Li', 'Schuurmans'), ('Schuurmans', '('), ('(', '2011'), ('2011', ')'), (')', 'parallelising'), ('parallelising', 'batch')]

>> Trigrams are: 
 [('The', 'Map-Reduce', 'framework'), ('Map-Reduce', 'framework', 'utilized'), ('framework', 'utilized', 'Li'), ('utilized', 'Li', 'Schuurmans'), ('Li', 'Schuurmans', '('), ('Schuurmans', '(', '2011'), ('(', '2011', ')'), ('2011', ')', 'parallelising'), (')', 'parallelising', 'batch')]

>> POS Tags are: 
 [('The', 'DT'), ('Map-Reduce', 'NNP'), ('framework', 'NN'), ('utilized', 'JJ'), ('Li', 'NNP'), ('Schuurmans', 'NNP'), ('(', '('), ('2011', 'CD'), (')', ')'), ('parallelising', 'VBG'), ('batch', 'NN')]

>> Noun Phrases are: 
 ['The Map-Reduce framework', 'utilized Li Schuurmans', 'batch']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Map-Reduce', 'map-reduc'), ('framework', 'framework'), ('utilized', 'util'), ('Li', 'li'), ('Schuurmans', 'schuurman'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelis'), ('batch', 'batch')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Map-Reduce', 'map-reduc'), ('framework', 'framework'), ('utilized', 'util'), ('Li', 'li'), ('Schuurmans', 'schuurman'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelis'), ('batch', 'batch')]

>> Lemmatization: 
 [('The', 'The'), ('Map-Reduce', 'Map-Reduce'), ('framework', 'framework'), ('utilized', 'utilized'), ('Li', 'Li'), ('Schuurmans', 'Schuurmans'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelising'), ('batch', 'batch')]



========================================== PARAGRAPH 698 ===========================================

reinforcement learning methods with linear function approximation (Mnih et al., 2016). Applying  

------------------- Sentence 1 -------------------

reinforcement learning methods with linear function approximation (Mnih et al., 2016).

>> Tokens are: 
 ['reinforcement', 'learning', 'methods', 'linear', 'function', 'approximation', '(', 'Mnih', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('reinforcement', 'learning'), ('learning', 'methods'), ('methods', 'linear'), ('linear', 'function'), ('function', 'approximation'), ('approximation', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('reinforcement', 'learning', 'methods'), ('learning', 'methods', 'linear'), ('methods', 'linear', 'function'), ('linear', 'function', 'approximation'), ('function', 'approximation', '('), ('approximation', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('reinforcement', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('approximation', 'NN'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['reinforcement', 'methods', 'linear function approximation', 'Mnih']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('reinforcement', 'reinforc'), ('learning', 'learn'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reinforcement', 'reinforc'), ('learning', 'learn'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('reinforcement', 'reinforcement'), ('learning', 'learning'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approximation'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Applying

>> Tokens are: 
 ['Applying']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Applying', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli')]

>> Lemmatization: 
 [('Applying', 'Applying')]



========================================== PARAGRAPH 699 ===========================================

parallelism helped speed up large matrix operations but did not assist the collection of experience  

------------------- Sentence 1 -------------------

parallelism helped speed up large matrix operations but did not assist the collection of experience

>> Tokens are: 
 ['parallelism', 'helped', 'speed', 'large', 'matrix', 'operations', 'assist', 'collection', 'experience']

>> Bigrams are: 
 [('parallelism', 'helped'), ('helped', 'speed'), ('speed', 'large'), ('large', 'matrix'), ('matrix', 'operations'), ('operations', 'assist'), ('assist', 'collection'), ('collection', 'experience')]

>> Trigrams are: 
 [('parallelism', 'helped', 'speed'), ('helped', 'speed', 'large'), ('speed', 'large', 'matrix'), ('large', 'matrix', 'operations'), ('matrix', 'operations', 'assist'), ('operations', 'assist', 'collection'), ('assist', 'collection', 'experience')]

>> POS Tags are: 
 [('parallelism', 'NN'), ('helped', 'VBD'), ('speed', 'VB'), ('large', 'JJ'), ('matrix', 'NN'), ('operations', 'NNS'), ('assist', 'VBP'), ('collection', 'NN'), ('experience', 'NN')]

>> Noun Phrases are: 
 ['parallelism', 'large matrix operations', 'collection experience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parallelism', 'parallel'), ('helped', 'help'), ('speed', 'speed'), ('large', 'larg'), ('matrix', 'matrix'), ('operations', 'oper'), ('assist', 'assist'), ('collection', 'collect'), ('experience', 'experi')]

>> Stemming using Snowball Stemmer: 
 [('parallelism', 'parallel'), ('helped', 'help'), ('speed', 'speed'), ('large', 'larg'), ('matrix', 'matrix'), ('operations', 'oper'), ('assist', 'assist'), ('collection', 'collect'), ('experience', 'experi')]

>> Lemmatization: 
 [('parallelism', 'parallelism'), ('helped', 'helped'), ('speed', 'speed'), ('large', 'large'), ('matrix', 'matrix'), ('operations', 'operation'), ('assist', 'assist'), ('collection', 'collection'), ('experience', 'experience')]



========================================== PARAGRAPH 700 ===========================================

or stabilise learning.  

------------------- Sentence 1 -------------------

or stabilise learning.

>> Tokens are: 
 ['stabilise', 'learning', '.']

>> Bigrams are: 
 [('stabilise', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('stabilise', 'learning', '.')]

>> POS Tags are: 
 [('stabilise', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['stabilise learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('stabilise', 'stabilis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('stabilise', 'stabilis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('stabilise', 'stabilise'), ('learning', 'learning'), ('.', '.')]



========================================== PARAGRAPH 701 ===========================================

The reinforcement learning goal is to develop policies that help in decision making. An example,  

------------------- Sentence 1 -------------------

The reinforcement learning goal is to develop policies that help in decision making.

>> Tokens are: 
 ['The', 'reinforcement', 'learning', 'goal', 'develop', 'policies', 'help', 'decision', 'making', '.']

>> Bigrams are: 
 [('The', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'goal'), ('goal', 'develop'), ('develop', 'policies'), ('policies', 'help'), ('help', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('The', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'goal'), ('learning', 'goal', 'develop'), ('goal', 'develop', 'policies'), ('develop', 'policies', 'help'), ('policies', 'help', 'decision'), ('help', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('goal', 'NN'), ('develop', 'VB'), ('policies', 'NNS'), ('help', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The reinforcement', 'goal', 'policies', 'decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'polici'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'polici'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'policy'), ('help', 'help'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]


------------------- Sentence 2 -------------------

An example,

>> Tokens are: 
 ['An', 'example', ',']

>> Bigrams are: 
 [('An', 'example'), ('example', ',')]

>> Trigrams are: 
 [('An', 'example', ',')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['An example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), (',', ',')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), (',', ',')]



========================================== PARAGRAPH 702 ===========================================

is Q-learning, where the algorithm has no knowledge of the data but has the ability to find out  

------------------- Sentence 1 -------------------

is Q-learning, where the algorithm has no knowledge of the data but has the ability to find out

>> Tokens are: 
 ['Q-learning', ',', 'algorithm', 'knowledge', 'data', 'ability', 'find']

>> Bigrams are: 
 [('Q-learning', ','), (',', 'algorithm'), ('algorithm', 'knowledge'), ('knowledge', 'data'), ('data', 'ability'), ('ability', 'find')]

>> Trigrams are: 
 [('Q-learning', ',', 'algorithm'), (',', 'algorithm', 'knowledge'), ('algorithm', 'knowledge', 'data'), ('knowledge', 'data', 'ability'), ('data', 'ability', 'find')]

>> POS Tags are: 
 [('Q-learning', 'NN'), (',', ','), ('algorithm', 'JJ'), ('knowledge', 'NN'), ('data', 'NNS'), ('ability', 'NN'), ('find', 'VBP')]

>> Noun Phrases are: 
 ['Q-learning', 'algorithm knowledge data ability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Q-learning', 'q-learn'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledg'), ('data', 'data'), ('ability', 'abil'), ('find', 'find')]

>> Stemming using Snowball Stemmer: 
 [('Q-learning', 'q-learn'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledg'), ('data', 'data'), ('ability', 'abil'), ('find', 'find')]

>> Lemmatization: 
 [('Q-learning', 'Q-learning'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledge'), ('data', 'data'), ('ability', 'ability'), ('find', 'find')]



========================================== PARAGRAPH 703 ===========================================

about the data in an automated way (Wu et al., 2018; Cui et al., 2019). Q-learning is one of the  

------------------- Sentence 1 -------------------

about the data in an automated way (Wu et al., 2018; Cui et al., 2019).

>> Tokens are: 
 ['data', 'automated', 'way', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('data', 'automated'), ('automated', 'way'), ('way', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'automated', 'way'), ('automated', 'way', '('), ('way', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('automated', 'VBD'), ('way', 'NN'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'way', 'Wu', 'Cui', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('automated', 'autom'), ('way', 'way'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('automated', 'autom'), ('way', 'way'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('automated', 'automated'), ('way', 'way'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Q-learning is one of the

>> Tokens are: 
 ['Q-learning', 'one']

>> Bigrams are: 
 [('Q-learning', 'one')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Q-learning', 'VBG'), ('one', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Q-learning', 'q-learn'), ('one', 'one')]

>> Stemming using Snowball Stemmer: 
 [('Q-learning', 'q-learn'), ('one', 'one')]

>> Lemmatization: 
 [('Q-learning', 'Q-learning'), ('one', 'one')]



========================================== PARAGRAPH 704 ===========================================

most popular reinforcement learning algorithms, though it learns unrealistically high action values  

------------------- Sentence 1 -------------------

most popular reinforcement learning algorithms, though it learns unrealistically high action values

>> Tokens are: 
 ['popular', 'reinforcement', 'learning', 'algorithms', ',', 'though', 'learns', 'unrealistically', 'high', 'action', 'values']

>> Bigrams are: 
 [('popular', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'algorithms'), ('algorithms', ','), (',', 'though'), ('though', 'learns'), ('learns', 'unrealistically'), ('unrealistically', 'high'), ('high', 'action'), ('action', 'values')]

>> Trigrams are: 
 [('popular', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'algorithms'), ('learning', 'algorithms', ','), ('algorithms', ',', 'though'), (',', 'though', 'learns'), ('though', 'learns', 'unrealistically'), ('learns', 'unrealistically', 'high'), ('unrealistically', 'high', 'action'), ('high', 'action', 'values')]

>> POS Tags are: 
 [('popular', 'JJ'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('algorithms', 'NN'), (',', ','), ('though', 'IN'), ('learns', 'NNS'), ('unrealistically', 'RB'), ('high', 'JJ'), ('action', 'NN'), ('values', 'NNS')]

>> Noun Phrases are: 
 ['popular reinforcement', 'algorithms', 'learns', 'high action values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('popular', 'popular'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learn'), ('unrealistically', 'unrealist'), ('high', 'high'), ('action', 'action'), ('values', 'valu')]

>> Stemming using Snowball Stemmer: 
 [('popular', 'popular'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learn'), ('unrealistically', 'unrealist'), ('high', 'high'), ('action', 'action'), ('values', 'valu')]

>> Lemmatization: 
 [('popular', 'popular'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learns'), ('unrealistically', 'unrealistically'), ('high', 'high'), ('action', 'action'), ('values', 'value')]



========================================== PARAGRAPH 705 ===========================================

as it includes ”a maximization step of overestimated action values, which tends to prefer  

------------------- Sentence 1 -------------------

as it includes ”a maximization step of overestimated action values, which tends to prefer

>> Tokens are: 
 ['includes', '”', 'maximization', 'step', 'overestimated', 'action', 'values', ',', 'tends', 'prefer']

>> Bigrams are: 
 [('includes', '”'), ('”', 'maximization'), ('maximization', 'step'), ('step', 'overestimated'), ('overestimated', 'action'), ('action', 'values'), ('values', ','), (',', 'tends'), ('tends', 'prefer')]

>> Trigrams are: 
 [('includes', '”', 'maximization'), ('”', 'maximization', 'step'), ('maximization', 'step', 'overestimated'), ('step', 'overestimated', 'action'), ('overestimated', 'action', 'values'), ('action', 'values', ','), ('values', ',', 'tends'), (',', 'tends', 'prefer')]

>> POS Tags are: 
 [('includes', 'VBZ'), ('”', 'JJ'), ('maximization', 'NN'), ('step', 'NN'), ('overestimated', 'VBN'), ('action', 'NN'), ('values', 'NNS'), (',', ','), ('tends', 'VBZ'), ('prefer', 'VBP')]

>> Noun Phrases are: 
 ['” maximization step', 'action values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('includes', 'includ'), ('”', '”'), ('maximization', 'maxim'), ('step', 'step'), ('overestimated', 'overestim'), ('action', 'action'), ('values', 'valu'), (',', ','), ('tends', 'tend'), ('prefer', 'prefer')]

>> Stemming using Snowball Stemmer: 
 [('includes', 'includ'), ('”', '”'), ('maximization', 'maxim'), ('step', 'step'), ('overestimated', 'overestim'), ('action', 'action'), ('values', 'valu'), (',', ','), ('tends', 'tend'), ('prefer', 'prefer')]

>> Lemmatization: 
 [('includes', 'includes'), ('”', '”'), ('maximization', 'maximization'), ('step', 'step'), ('overestimated', 'overestimated'), ('action', 'action'), ('values', 'value'), (',', ','), ('tends', 'tends'), ('prefer', 'prefer')]



========================================== PARAGRAPH 706 ===========================================

overestimated to underestimated values” (Hester et al., 2018). The Q-learning algorithm is thus  

------------------- Sentence 1 -------------------

overestimated to underestimated values” (Hester et al., 2018).

>> Tokens are: 
 ['overestimated', 'underestimated', 'values', '”', '(', 'Hester', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('overestimated', 'underestimated'), ('underestimated', 'values'), ('values', '”'), ('”', '('), ('(', 'Hester'), ('Hester', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('overestimated', 'underestimated', 'values'), ('underestimated', 'values', '”'), ('values', '”', '('), ('”', '(', 'Hester'), ('(', 'Hester', 'et'), ('Hester', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('overestimated', 'VBN'), ('underestimated', 'JJ'), ('values', 'NNS'), ('”', 'VBP'), ('(', '('), ('Hester', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['underestimated values', 'Hester']

>> Named Entities are: 
 [('PERSON', 'Hester')] 

>> Stemming using Porter Stemmer: 
 [('overestimated', 'overestim'), ('underestimated', 'underestim'), ('values', 'valu'), ('”', '”'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('overestimated', 'overestim'), ('underestimated', 'underestim'), ('values', 'valu'), ('”', '”'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('overestimated', 'overestimated'), ('underestimated', 'underestimated'), ('values', 'value'), ('”', '”'), ('(', '('), ('Hester', 'Hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The Q-learning algorithm is thus

>> Tokens are: 
 ['The', 'Q-learning', 'algorithm', 'thus']

>> Bigrams are: 
 [('The', 'Q-learning'), ('Q-learning', 'algorithm'), ('algorithm', 'thus')]

>> Trigrams are: 
 [('The', 'Q-learning', 'algorithm'), ('Q-learning', 'algorithm', 'thus')]

>> POS Tags are: 
 [('The', 'DT'), ('Q-learning', 'JJ'), ('algorithm', 'NN'), ('thus', 'RB')]

>> Noun Phrases are: 
 ['The Q-learning algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('thus', 'thu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('thus', 'thus')]

>> Lemmatization: 
 [('The', 'The'), ('Q-learning', 'Q-learning'), ('algorithm', 'algorithm'), ('thus', 'thus')]



========================================== PARAGRAPH 707 ===========================================

best used for overestimating action values in specific conditions.  

------------------- Sentence 1 -------------------

best used for overestimating action values in specific conditions.

>> Tokens are: 
 ['best', 'used', 'overestimating', 'action', 'values', 'specific', 'conditions', '.']

>> Bigrams are: 
 [('best', 'used'), ('used', 'overestimating'), ('overestimating', 'action'), ('action', 'values'), ('values', 'specific'), ('specific', 'conditions'), ('conditions', '.')]

>> Trigrams are: 
 [('best', 'used', 'overestimating'), ('used', 'overestimating', 'action'), ('overestimating', 'action', 'values'), ('action', 'values', 'specific'), ('values', 'specific', 'conditions'), ('specific', 'conditions', '.')]

>> POS Tags are: 
 [('best', 'JJS'), ('used', 'VBN'), ('overestimating', 'VBG'), ('action', 'NN'), ('values', 'NNS'), ('specific', 'JJ'), ('conditions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['action values', 'specific conditions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('best', 'best'), ('used', 'use'), ('overestimating', 'overestim'), ('action', 'action'), ('values', 'valu'), ('specific', 'specif'), ('conditions', 'condit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('best', 'best'), ('used', 'use'), ('overestimating', 'overestim'), ('action', 'action'), ('values', 'valu'), ('specific', 'specif'), ('conditions', 'condit'), ('.', '.')]

>> Lemmatization: 
 [('best', 'best'), ('used', 'used'), ('overestimating', 'overestimating'), ('action', 'action'), ('values', 'value'), ('specific', 'specific'), ('conditions', 'condition'), ('.', '.')]



========================================== PARAGRAPH 708 ===========================================

  


========================================== PARAGRAPH 709 ===========================================

Recently, Q-learning has been combined with deep neural networks to produce Double Q-learning  

------------------- Sentence 1 -------------------

Recently, Q-learning has been combined with deep neural networks to produce Double Q-learning

>> Tokens are: 
 ['Recently', ',', 'Q-learning', 'combined', 'deep', 'neural', 'networks', 'produce', 'Double', 'Q-learning']

>> Bigrams are: 
 [('Recently', ','), (',', 'Q-learning'), ('Q-learning', 'combined'), ('combined', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'produce'), ('produce', 'Double'), ('Double', 'Q-learning')]

>> Trigrams are: 
 [('Recently', ',', 'Q-learning'), (',', 'Q-learning', 'combined'), ('Q-learning', 'combined', 'deep'), ('combined', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'produce'), ('networks', 'produce', 'Double'), ('produce', 'Double', 'Q-learning')]

>> POS Tags are: 
 [('Recently', 'RB'), (',', ','), ('Q-learning', 'NNP'), ('combined', 'VBD'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('produce', 'VBP'), ('Double', 'JJ'), ('Q-learning', 'NN')]

>> Noun Phrases are: 
 ['Q-learning', 'deep neural networks', 'Double Q-learning']

>> Named Entities are: 
 [('PERSON', 'Double')] 

>> Stemming using Porter Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Q-learning', 'q-learn'), ('combined', 'combin'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produc'), ('Double', 'doubl'), ('Q-learning', 'q-learn')]

>> Stemming using Snowball Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Q-learning', 'q-learn'), ('combined', 'combin'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produc'), ('Double', 'doubl'), ('Q-learning', 'q-learn')]

>> Lemmatization: 
 [('Recently', 'Recently'), (',', ','), ('Q-learning', 'Q-learning'), ('combined', 'combined'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produce'), ('Double', 'Double'), ('Q-learning', 'Q-learning')]



========================================== PARAGRAPH 710 ===========================================

(DQN); that combination also suffers from overestimations (Mnih et al.,2015). Deep neural  

------------------- Sentence 1 -------------------

(DQN); that combination also suffers from overestimations (Mnih et al.,2015).

>> Tokens are: 
 ['(', 'DQN', ')', ';', 'combination', 'also', 'suffers', 'overestimations', '(', 'Mnih', 'et', 'al.,2015', ')', '.']

>> Bigrams are: 
 [('(', 'DQN'), ('DQN', ')'), (')', ';'), (';', 'combination'), ('combination', 'also'), ('also', 'suffers'), ('suffers', 'overestimations'), ('overestimations', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.,2015'), ('al.,2015', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'DQN', ')'), ('DQN', ')', ';'), (')', ';', 'combination'), (';', 'combination', 'also'), ('combination', 'also', 'suffers'), ('also', 'suffers', 'overestimations'), ('suffers', 'overestimations', '('), ('overestimations', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.,2015'), ('et', 'al.,2015', ')'), ('al.,2015', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('DQN', 'NNP'), (')', ')'), (';', ':'), ('combination', 'NN'), ('also', 'RB'), ('suffers', 'VBZ'), ('overestimations', 'NNS'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.,2015', 'RB'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['DQN', 'combination', 'overestimations', 'Mnih']

>> Named Entities are: 
 [('ORGANIZATION', 'DQN'), ('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('DQN', 'dqn'), (')', ')'), (';', ';'), ('combination', 'combin'), ('also', 'also'), ('suffers', 'suffer'), ('overestimations', 'overestim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('DQN', 'dqn'), (')', ')'), (';', ';'), ('combination', 'combin'), ('also', 'also'), ('suffers', 'suffer'), ('overestimations', 'overestim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('DQN', 'DQN'), (')', ')'), (';', ';'), ('combination', 'combination'), ('also', 'also'), ('suffers', 'suffers'), ('overestimations', 'overestimation'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep neural

>> Tokens are: 
 ['Deep', 'neural']

>> Bigrams are: 
 [('Deep', 'neural')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Deep', 'JJ'), ('neural', 'NN')]

>> Noun Phrases are: 
 ['Deep neural']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('neural', 'neural')]



========================================== PARAGRAPH 711 ===========================================

networks are artificial neural networks with multiple layers between the input and output layer,  

------------------- Sentence 1 -------------------

networks are artificial neural networks with multiple layers between the input and output layer,

>> Tokens are: 
 ['networks', 'artificial', 'neural', 'networks', 'multiple', 'layers', 'input', 'output', 'layer', ',']

>> Bigrams are: 
 [('networks', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'multiple'), ('multiple', 'layers'), ('layers', 'input'), ('input', 'output'), ('output', 'layer'), ('layer', ',')]

>> Trigrams are: 
 [('networks', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'multiple'), ('networks', 'multiple', 'layers'), ('multiple', 'layers', 'input'), ('layers', 'input', 'output'), ('input', 'output', 'layer'), ('output', 'layer', ',')]

>> POS Tags are: 
 [('networks', 'NNS'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('multiple', 'JJ'), ('layers', 'NNS'), ('input', 'VBP'), ('output', 'NN'), ('layer', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['networks', 'artificial neural networks', 'multiple layers', 'output layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('networks', 'network'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multipl'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('networks', 'network'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multipl'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ',')]

>> Lemmatization: 
 [('networks', 'network'), ('artificial', 'artificial'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multiple'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ',')]



========================================== PARAGRAPH 712 ===========================================

which help RL algorithms to provide effective performance. However, it was previously thought  

------------------- Sentence 1 -------------------

which help RL algorithms to provide effective performance.

>> Tokens are: 
 ['help', 'RL', 'algorithms', 'provide', 'effective', 'performance', '.']

>> Bigrams are: 
 [('help', 'RL'), ('RL', 'algorithms'), ('algorithms', 'provide'), ('provide', 'effective'), ('effective', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('help', 'RL', 'algorithms'), ('RL', 'algorithms', 'provide'), ('algorithms', 'provide', 'effective'), ('provide', 'effective', 'performance'), ('effective', 'performance', '.')]

>> POS Tags are: 
 [('help', 'NN'), ('RL', 'NNP'), ('algorithms', 'VBZ'), ('provide', 'RB'), ('effective', 'JJ'), ('performance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['help RL', 'effective performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('help', 'help'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('effective', 'effect'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('help', 'help'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('effective', 'effect'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('help', 'help'), ('RL', 'RL'), ('algorithms', 'algorithm'), ('provide', 'provide'), ('effective', 'effective'), ('performance', 'performance'), ('.', '.')]


------------------- Sentence 2 -------------------

However, it was previously thought

>> Tokens are: 
 ['However', ',', 'previously', 'thought']

>> Bigrams are: 
 [('However', ','), (',', 'previously'), ('previously', 'thought')]

>> Trigrams are: 
 [('However', ',', 'previously'), (',', 'previously', 'thought')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('previously', 'RB'), ('thought', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('previously', 'previous'), ('thought', 'thought')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('previously', 'previous'), ('thought', 'thought')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('previously', 'previously'), ('thought', 'thought')]



========================================== PARAGRAPH 713 ===========================================

was that combining simple online RL algorithms with deep neural networks was unstable (Mnih  

------------------- Sentence 1 -------------------

was that combining simple online RL algorithms with deep neural networks was unstable (Mnih

>> Tokens are: 
 ['combining', 'simple', 'online', 'RL', 'algorithms', 'deep', 'neural', 'networks', 'unstable', '(', 'Mnih']

>> Bigrams are: 
 [('combining', 'simple'), ('simple', 'online'), ('online', 'RL'), ('RL', 'algorithms'), ('algorithms', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'unstable'), ('unstable', '('), ('(', 'Mnih')]

>> Trigrams are: 
 [('combining', 'simple', 'online'), ('simple', 'online', 'RL'), ('online', 'RL', 'algorithms'), ('RL', 'algorithms', 'deep'), ('algorithms', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'unstable'), ('networks', 'unstable', '('), ('unstable', '(', 'Mnih')]

>> POS Tags are: 
 [('combining', 'VBG'), ('simple', 'JJ'), ('online', 'JJ'), ('RL', 'NNP'), ('algorithms', 'NN'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('unstable', 'JJ'), ('(', '('), ('Mnih', 'NNP')]

>> Noun Phrases are: 
 ['simple online RL algorithms', 'deep neural networks', 'Mnih']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('combining', 'combin'), ('simple', 'simpl'), ('online', 'onlin'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstabl'), ('(', '('), ('Mnih', 'mnih')]

>> Stemming using Snowball Stemmer: 
 [('combining', 'combin'), ('simple', 'simpl'), ('online', 'onlin'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstabl'), ('(', '('), ('Mnih', 'mnih')]

>> Lemmatization: 
 [('combining', 'combining'), ('simple', 'simple'), ('online', 'online'), ('RL', 'RL'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstable'), ('(', '('), ('Mnih', 'Mnih')]



========================================== PARAGRAPH 714 ===========================================

et al., 2013; Mnih et al., 2015; Schulman et al., 2015; Mnih et al., 2016; Van Hasselt et al., 2016).  

------------------- Sentence 1 -------------------

et al., 2013; Mnih et al., 2015; Schulman et al., 2015; Mnih et al., 2016; Van Hasselt et al., 2016).

>> Tokens are: 
 ['et', 'al.', ',', '2013', ';', 'Mnih', 'et', 'al.', ',', '2015', ';', 'Schulman', 'et', 'al.', ',', '2015', ';', 'Mnih', 'et', 'al.', ',', '2016', ';', 'Van', 'Hasselt', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Schulman'), ('Schulman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Van'), ('Van', 'Hasselt'), ('Hasselt', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Schulman'), (';', 'Schulman', 'et'), ('Schulman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Van'), (';', 'Van', 'Hasselt'), ('Van', 'Hasselt', 'et'), ('Hasselt', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2013', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (';', ':'), ('Schulman', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Van', 'NNP'), ('Hasselt', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.', 'Mnih', 'al.', 'Schulman', 'Mnih', 'al.', 'Van Hasselt', 'al.']

>> Named Entities are: 
 [('PERSON', 'Schulman'), ('PERSON', 'Van Hasselt')] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'Schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'Van'), ('Hasselt', 'Hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 715 ===========================================

The common idea arising from early studies was that the data sequences observed by online RL  

------------------- Sentence 1 -------------------

The common idea arising from early studies was that the data sequences observed by online RL

>> Tokens are: 
 ['The', 'common', 'idea', 'arising', 'early', 'studies', 'data', 'sequences', 'observed', 'online', 'RL']

>> Bigrams are: 
 [('The', 'common'), ('common', 'idea'), ('idea', 'arising'), ('arising', 'early'), ('early', 'studies'), ('studies', 'data'), ('data', 'sequences'), ('sequences', 'observed'), ('observed', 'online'), ('online', 'RL')]

>> Trigrams are: 
 [('The', 'common', 'idea'), ('common', 'idea', 'arising'), ('idea', 'arising', 'early'), ('arising', 'early', 'studies'), ('early', 'studies', 'data'), ('studies', 'data', 'sequences'), ('data', 'sequences', 'observed'), ('sequences', 'observed', 'online'), ('observed', 'online', 'RL')]

>> POS Tags are: 
 [('The', 'DT'), ('common', 'JJ'), ('idea', 'NN'), ('arising', 'VBG'), ('early', 'JJ'), ('studies', 'NNS'), ('data', 'NNS'), ('sequences', 'NNS'), ('observed', 'VBD'), ('online', 'JJ'), ('RL', 'NNP')]

>> Noun Phrases are: 
 ['The common idea', 'early studies data sequences', 'online RL']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('common', 'common'), ('idea', 'idea'), ('arising', 'aris'), ('early', 'earli'), ('studies', 'studi'), ('data', 'data'), ('sequences', 'sequenc'), ('observed', 'observ'), ('online', 'onlin'), ('RL', 'rl')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('common', 'common'), ('idea', 'idea'), ('arising', 'aris'), ('early', 'earli'), ('studies', 'studi'), ('data', 'data'), ('sequences', 'sequenc'), ('observed', 'observ'), ('online', 'onlin'), ('RL', 'rl')]

>> Lemmatization: 
 [('The', 'The'), ('common', 'common'), ('idea', 'idea'), ('arising', 'arising'), ('early', 'early'), ('studies', 'study'), ('data', 'data'), ('sequences', 'sequence'), ('observed', 'observed'), ('online', 'online'), ('RL', 'RL')]



========================================== PARAGRAPH 716 ===========================================

agents were not stable, and had no strong correlations to RL updates. However, data can be batched  

------------------- Sentence 1 -------------------

agents were not stable, and had no strong correlations to RL updates.

>> Tokens are: 
 ['agents', 'stable', ',', 'strong', 'correlations', 'RL', 'updates', '.']

>> Bigrams are: 
 [('agents', 'stable'), ('stable', ','), (',', 'strong'), ('strong', 'correlations'), ('correlations', 'RL'), ('RL', 'updates'), ('updates', '.')]

>> Trigrams are: 
 [('agents', 'stable', ','), ('stable', ',', 'strong'), (',', 'strong', 'correlations'), ('strong', 'correlations', 'RL'), ('correlations', 'RL', 'updates'), ('RL', 'updates', '.')]

>> POS Tags are: 
 [('agents', 'NNS'), ('stable', 'JJ'), (',', ','), ('strong', 'JJ'), ('correlations', 'NNS'), ('RL', 'NNP'), ('updates', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['agents', 'strong correlations RL updates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('agents', 'agent'), ('stable', 'stabl'), (',', ','), ('strong', 'strong'), ('correlations', 'correl'), ('RL', 'rl'), ('updates', 'updat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('agents', 'agent'), ('stable', 'stabl'), (',', ','), ('strong', 'strong'), ('correlations', 'correl'), ('RL', 'rl'), ('updates', 'updat'), ('.', '.')]

>> Lemmatization: 
 [('agents', 'agent'), ('stable', 'stable'), (',', ','), ('strong', 'strong'), ('correlations', 'correlation'), ('RL', 'RL'), ('updates', 'update'), ('.', '.')]


------------------- Sentence 2 -------------------

However, data can be batched

>> Tokens are: 
 ['However', ',', 'data', 'batched']

>> Bigrams are: 
 [('However', ','), (',', 'data'), ('data', 'batched')]

>> Trigrams are: 
 [('However', ',', 'data'), (',', 'data', 'batched')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('data', 'NNS'), ('batched', 'VBD')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('batched', 'batch')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('batched', 'batch')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('data', 'data'), ('batched', 'batched')]



========================================== PARAGRAPH 717 ===========================================

if the agent's data are stored in an experience replay memory (Schulman et al., 2015) or sampled  

------------------- Sentence 1 -------------------

if the agent's data are stored in an experience replay memory (Schulman et al., 2015) or sampled

>> Tokens are: 
 ['agent', "'s", 'data', 'stored', 'experience', 'replay', 'memory', '(', 'Schulman', 'et', 'al.', ',', '2015', ')', 'sampled']

>> Bigrams are: 
 [('agent', "'s"), ("'s", 'data'), ('data', 'stored'), ('stored', 'experience'), ('experience', 'replay'), ('replay', 'memory'), ('memory', '('), ('(', 'Schulman'), ('Schulman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', 'sampled')]

>> Trigrams are: 
 [('agent', "'s", 'data'), ("'s", 'data', 'stored'), ('data', 'stored', 'experience'), ('stored', 'experience', 'replay'), ('experience', 'replay', 'memory'), ('replay', 'memory', '('), ('memory', '(', 'Schulman'), ('(', 'Schulman', 'et'), ('Schulman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'sampled')]

>> POS Tags are: 
 [('agent', 'NN'), ("'s", 'POS'), ('data', 'NNS'), ('stored', 'VBD'), ('experience', 'NN'), ('replay', 'NN'), ('memory', 'NN'), ('(', '('), ('Schulman', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('sampled', 'VBD')]

>> Noun Phrases are: 
 ['agent', 'data', 'experience replay memory', 'Schulman']

>> Named Entities are: 
 [('ORGANIZATION', 'Schulman')] 

>> Stemming using Porter Stemmer: 
 [('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'store'), ('experience', 'experi'), ('replay', 'replay'), ('memory', 'memori'), ('(', '('), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampl')]

>> Stemming using Snowball Stemmer: 
 [('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'store'), ('experience', 'experi'), ('replay', 'replay'), ('memory', 'memori'), ('(', '('), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampl')]

>> Lemmatization: 
 [('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'stored'), ('experience', 'experience'), ('replay', 'replay'), ('memory', 'memory'), ('(', '('), ('Schulman', 'Schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampled')]



========================================== PARAGRAPH 718 ===========================================

from different time steps randomly (Mnih et al., 2013; Mnih et al. , 2016; Van Hasselt et al., 2016),  

------------------- Sentence 1 -------------------

from different time steps randomly (Mnih et al., 2013; Mnih et al.

>> Tokens are: 
 ['different', 'time', 'steps', 'randomly', '(', 'Mnih', 'et', 'al.', ',', '2013', ';', 'Mnih', 'et', 'al', '.']

>> Bigrams are: 
 [('different', 'time'), ('time', 'steps'), ('steps', 'randomly'), ('randomly', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('different', 'time', 'steps'), ('time', 'steps', 'randomly'), ('steps', 'randomly', '('), ('randomly', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('different', 'JJ'), ('time', 'NN'), ('steps', 'NNS'), ('randomly', 'RB'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['different time steps', 'Mnih', 'Mnih', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('time', 'time'), ('steps', 'step'), ('randomly', 'randomli'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('time', 'time'), ('steps', 'step'), ('randomly', 'random'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('different', 'different'), ('time', 'time'), ('steps', 'step'), ('randomly', 'randomly'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

, 2016; Van Hasselt et al., 2016),

>> Tokens are: 
 [',', '2016', ';', 'Van', 'Hasselt', 'et', 'al.', ',', '2016', ')', ',']

>> Bigrams are: 
 [(',', '2016'), ('2016', ';'), (';', 'Van'), ('Van', 'Hasselt'), ('Hasselt', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', ',')]

>> Trigrams are: 
 [(',', '2016', ';'), ('2016', ';', 'Van'), (';', 'Van', 'Hasselt'), ('Van', 'Hasselt', 'et'), ('Hasselt', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', ',')]

>> POS Tags are: 
 [(',', ','), ('2016', 'CD'), (';', ':'), ('Van', 'NNP'), ('Hasselt', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['Van Hasselt', 'al.']

>> Named Entities are: 
 [('PERSON', 'Van Hasselt')] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'Van'), ('Hasselt', 'Hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 719 ===========================================

and the Double Q-learning algorithm can work with large-scale function approximation (Hasselt, 

------------------- Sentence 1 -------------------

and the Double Q-learning algorithm can work with large-scale function approximation (Hasselt,

>> Tokens are: 
 ['Double', 'Q-learning', 'algorithm', 'work', 'large-scale', 'function', 'approximation', '(', 'Hasselt', ',']

>> Bigrams are: 
 [('Double', 'Q-learning'), ('Q-learning', 'algorithm'), ('algorithm', 'work'), ('work', 'large-scale'), ('large-scale', 'function'), ('function', 'approximation'), ('approximation', '('), ('(', 'Hasselt'), ('Hasselt', ',')]

>> Trigrams are: 
 [('Double', 'Q-learning', 'algorithm'), ('Q-learning', 'algorithm', 'work'), ('algorithm', 'work', 'large-scale'), ('work', 'large-scale', 'function'), ('large-scale', 'function', 'approximation'), ('function', 'approximation', '('), ('approximation', '(', 'Hasselt'), ('(', 'Hasselt', ',')]

>> POS Tags are: 
 [('Double', 'JJ'), ('Q-learning', 'JJ'), ('algorithm', 'NN'), ('work', 'NN'), ('large-scale', 'JJ'), ('function', 'NN'), ('approximation', 'NN'), ('(', '('), ('Hasselt', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Double Q-learning algorithm work', 'large-scale function approximation', 'Hasselt']

>> Named Entities are: 
 [('GPE', 'Double'), ('ORGANIZATION', 'Hasselt')] 

>> Stemming using Porter Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scal'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Hasselt', 'hasselt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scal'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Hasselt', 'hasselt'), (',', ',')]

>> Lemmatization: 
 [('Double', 'Double'), ('Q-learning', 'Q-learning'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scale'), ('function', 'function'), ('approximation', 'approximation'), ('(', '('), ('Hasselt', 'Hasselt'), (',', ',')]



========================================== PARAGRAPH 720 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 721 ===========================================

26  

------------------- Sentence 1 -------------------

26

>> Tokens are: 
 ['26']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('26', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('26', '26')]

>> Stemming using Snowball Stemmer: 
 [('26', '26')]

>> Lemmatization: 
 [('26', '26')]



========================================== PARAGRAPH 722 ===========================================

  


========================================== PARAGRAPH 723 ===========================================

H.V., 2010). Thus, a new algorithm known as Double DQN (a combination of Double Q-learning  

------------------- Sentence 1 -------------------

H.V., 2010).

>> Tokens are: 
 ['H.V.', ',', '2010', ')', '.']

>> Bigrams are: 
 [('H.V.', ','), (',', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('H.V.', ',', '2010'), (',', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('H.V.', 'NNP'), (',', ','), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['H.V.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('H.V.', 'H.V.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Thus, a new algorithm known as Double DQN (a combination of Double Q-learning

>> Tokens are: 
 ['Thus', ',', 'new', 'algorithm', 'known', 'Double', 'DQN', '(', 'combination', 'Double', 'Q-learning']

>> Bigrams are: 
 [('Thus', ','), (',', 'new'), ('new', 'algorithm'), ('algorithm', 'known'), ('known', 'Double'), ('Double', 'DQN'), ('DQN', '('), ('(', 'combination'), ('combination', 'Double'), ('Double', 'Q-learning')]

>> Trigrams are: 
 [('Thus', ',', 'new'), (',', 'new', 'algorithm'), ('new', 'algorithm', 'known'), ('algorithm', 'known', 'Double'), ('known', 'Double', 'DQN'), ('Double', 'DQN', '('), ('DQN', '(', 'combination'), ('(', 'combination', 'Double'), ('combination', 'Double', 'Q-learning')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('new', 'JJ'), ('algorithm', 'NN'), ('known', 'VBN'), ('Double', 'NNP'), ('DQN', 'NNP'), ('(', '('), ('combination', 'NN'), ('Double', 'NNP'), ('Q-learning', 'NN')]

>> Noun Phrases are: 
 ['new algorithm', 'Double DQN', 'combination Double Q-learning']

>> Named Entities are: 
 [('PERSON', 'Double DQN'), ('PERSON', 'Double')] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'doubl'), ('DQN', 'dqn'), ('(', '('), ('combination', 'combin'), ('Double', 'doubl'), ('Q-learning', 'q-learn')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'doubl'), ('DQN', 'dqn'), ('(', '('), ('combination', 'combin'), ('Double', 'doubl'), ('Q-learning', 'q-learn')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'Double'), ('DQN', 'DQN'), ('(', '('), ('combination', 'combination'), ('Double', 'Double'), ('Q-learning', 'Q-learning')]



========================================== PARAGRAPH 724 ===========================================

with neural networks) has been constructed which offers higher scores on several games; however,  

------------------- Sentence 1 -------------------

with neural networks) has been constructed which offers higher scores on several games; however,

>> Tokens are: 
 ['neural', 'networks', ')', 'constructed', 'offers', 'higher', 'scores', 'several', 'games', ';', 'however', ',']

>> Bigrams are: 
 [('neural', 'networks'), ('networks', ')'), (')', 'constructed'), ('constructed', 'offers'), ('offers', 'higher'), ('higher', 'scores'), ('scores', 'several'), ('several', 'games'), ('games', ';'), (';', 'however'), ('however', ',')]

>> Trigrams are: 
 [('neural', 'networks', ')'), ('networks', ')', 'constructed'), (')', 'constructed', 'offers'), ('constructed', 'offers', 'higher'), ('offers', 'higher', 'scores'), ('higher', 'scores', 'several'), ('scores', 'several', 'games'), ('several', 'games', ';'), ('games', ';', 'however'), (';', 'however', ',')]

>> POS Tags are: 
 [('neural', 'JJ'), ('networks', 'NNS'), (')', ')'), ('constructed', 'VBD'), ('offers', 'NNS'), ('higher', 'RBR'), ('scores', 'NNS'), ('several', 'JJ'), ('games', 'NNS'), (';', ':'), ('however', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['neural networks', 'offers', 'scores', 'several games']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'construct'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'sever'), ('games', 'game'), (';', ';'), ('however', 'howev'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'construct'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'sever'), ('games', 'game'), (';', ';'), ('however', 'howev'), (',', ',')]

>> Lemmatization: 
 [('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'constructed'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'several'), ('games', 'game'), (';', ';'), ('however', 'however'), (',', ',')]



========================================== PARAGRAPH 725 ===========================================

this algorithm has not displayed more accurate value estimation (Hester et al., 2018).  

------------------- Sentence 1 -------------------

this algorithm has not displayed more accurate value estimation (Hester et al., 2018).

>> Tokens are: 
 ['algorithm', 'displayed', 'accurate', 'value', 'estimation', '(', 'Hester', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('algorithm', 'displayed'), ('displayed', 'accurate'), ('accurate', 'value'), ('value', 'estimation'), ('estimation', '('), ('(', 'Hester'), ('Hester', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('algorithm', 'displayed', 'accurate'), ('displayed', 'accurate', 'value'), ('accurate', 'value', 'estimation'), ('value', 'estimation', '('), ('estimation', '(', 'Hester'), ('(', 'Hester', 'et'), ('Hester', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('algorithm', 'RB'), ('displayed', 'VBN'), ('accurate', 'JJ'), ('value', 'NN'), ('estimation', 'NN'), ('(', '('), ('Hester', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['accurate value estimation', 'Hester']

>> Named Entities are: 
 [('PERSON', 'Hester')] 

>> Stemming using Porter Stemmer: 
 [('algorithm', 'algorithm'), ('displayed', 'display'), ('accurate', 'accur'), ('value', 'valu'), ('estimation', 'estim'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithm', 'algorithm'), ('displayed', 'display'), ('accurate', 'accur'), ('value', 'valu'), ('estimation', 'estim'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('algorithm', 'algorithm'), ('displayed', 'displayed'), ('accurate', 'accurate'), ('value', 'value'), ('estimation', 'estimation'), ('(', '('), ('Hester', 'Hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 726 ===========================================

  


========================================== PARAGRAPH 727 ===========================================

7.4. Analytics techniques  

------------------- Sentence 1 -------------------

7.4.

>> Tokens are: 
 ['7.4', '.']

>> Bigrams are: 
 [('7.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Lemmatization: 
 [('7.4', '7.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Analytics techniques

>> Tokens are: 
 ['Analytics', 'techniques']

>> Bigrams are: 
 [('Analytics', 'techniques')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Analytics', 'NNS'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('techniques', 'technique')]



========================================== PARAGRAPH 728 ===========================================

  


========================================== PARAGRAPH 729 ===========================================

 Correlation Analysis: this is an analytical method used to determine the relationships such as  

------------------- Sentence 1 -------------------

 Correlation Analysis: this is an analytical method used to determine the relationships such as

>> Tokens are: 
 ['Correlation', 'Analysis', ':', 'analytical', 'method', 'used', 'determine', 'relationships']

>> Bigrams are: 
 [('Correlation', 'Analysis'), ('Analysis', ':'), (':', 'analytical'), ('analytical', 'method'), ('method', 'used'), ('used', 'determine'), ('determine', 'relationships')]

>> Trigrams are: 
 [('Correlation', 'Analysis', ':'), ('Analysis', ':', 'analytical'), (':', 'analytical', 'method'), ('analytical', 'method', 'used'), ('method', 'used', 'determine'), ('used', 'determine', 'relationships')]

>> POS Tags are: 
 [('Correlation', 'NN'), ('Analysis', 'NN'), (':', ':'), ('analytical', 'JJ'), ('method', 'NN'), ('used', 'VBN'), ('determine', 'JJ'), ('relationships', 'NNS')]

>> Noun Phrases are: 
 ['Correlation Analysis', 'analytical method', 'determine relationships']

>> Named Entities are: 
 [('GPE', 'Correlation'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Correlation', 'correl'), ('Analysis', 'analysi'), (':', ':'), ('analytical', 'analyt'), ('method', 'method'), ('used', 'use'), ('determine', 'determin'), ('relationships', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [('Correlation', 'correl'), ('Analysis', 'analysi'), (':', ':'), ('analytical', 'analyt'), ('method', 'method'), ('used', 'use'), ('determine', 'determin'), ('relationships', 'relationship')]

>> Lemmatization: 
 [('Correlation', 'Correlation'), ('Analysis', 'Analysis'), (':', ':'), ('analytical', 'analytical'), ('method', 'method'), ('used', 'used'), ('determine', 'determine'), ('relationships', 'relationship')]



========================================== PARAGRAPH 730 ===========================================

“correlation, correlative dependence, and mutual restriction, among observed phenomena and  

------------------- Sentence 1 -------------------

“correlation, correlative dependence, and mutual restriction, among observed phenomena and

>> Tokens are: 
 ['“', 'correlation', ',', 'correlative', 'dependence', ',', 'mutual', 'restriction', ',', 'among', 'observed', 'phenomena']

>> Bigrams are: 
 [('“', 'correlation'), ('correlation', ','), (',', 'correlative'), ('correlative', 'dependence'), ('dependence', ','), (',', 'mutual'), ('mutual', 'restriction'), ('restriction', ','), (',', 'among'), ('among', 'observed'), ('observed', 'phenomena')]

>> Trigrams are: 
 [('“', 'correlation', ','), ('correlation', ',', 'correlative'), (',', 'correlative', 'dependence'), ('correlative', 'dependence', ','), ('dependence', ',', 'mutual'), (',', 'mutual', 'restriction'), ('mutual', 'restriction', ','), ('restriction', ',', 'among'), (',', 'among', 'observed'), ('among', 'observed', 'phenomena')]

>> POS Tags are: 
 [('“', 'JJ'), ('correlation', 'NN'), (',', ','), ('correlative', 'JJ'), ('dependence', 'NN'), (',', ','), ('mutual', 'JJ'), ('restriction', 'NN'), (',', ','), ('among', 'IN'), ('observed', 'JJ'), ('phenomena', 'NNS')]

>> Noun Phrases are: 
 ['“ correlation', 'correlative dependence', 'mutual restriction', 'observed phenomena']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('correlation', 'correl'), (',', ','), ('correlative', 'correl'), ('dependence', 'depend'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restrict'), (',', ','), ('among', 'among'), ('observed', 'observ'), ('phenomena', 'phenomena')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('correlation', 'correl'), (',', ','), ('correlative', 'correl'), ('dependence', 'depend'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restrict'), (',', ','), ('among', 'among'), ('observed', 'observ'), ('phenomena', 'phenomena')]

>> Lemmatization: 
 [('“', '“'), ('correlation', 'correlation'), (',', ','), ('correlative', 'correlative'), ('dependence', 'dependence'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restriction'), (',', ','), ('among', 'among'), ('observed', 'observed'), ('phenomena', 'phenomenon')]



========================================== PARAGRAPH 731 ===========================================

accordingly conducting forecast and control” (Chen, M., Mao, S. and Liu, Y., 2014), as shown in  

------------------- Sentence 1 -------------------

accordingly conducting forecast and control” (Chen, M., Mao, S. and Liu, Y., 2014), as shown in

>> Tokens are: 
 ['accordingly', 'conducting', 'forecast', 'control', '”', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', ',', 'shown']

>> Bigrams are: 
 [('accordingly', 'conducting'), ('conducting', 'forecast'), ('forecast', 'control'), ('control', '”'), ('”', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', ','), (',', 'shown')]

>> Trigrams are: 
 [('accordingly', 'conducting', 'forecast'), ('conducting', 'forecast', 'control'), ('forecast', 'control', '”'), ('control', '”', '('), ('”', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ','), (')', ',', 'shown')]

>> POS Tags are: 
 [('accordingly', 'RB'), ('conducting', 'VBG'), ('forecast', 'VBN'), ('control', 'NN'), ('”', 'NNP'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN')]

>> Noun Phrases are: 
 ['control ”', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('accordingly', 'accordingli'), ('conducting', 'conduct'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown')]

>> Stemming using Snowball Stemmer: 
 [('accordingly', 'accord'), ('conducting', 'conduct'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown')]

>> Lemmatization: 
 [('accordingly', 'accordingly'), ('conducting', 'conducting'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown')]



========================================== PARAGRAPH 732 ===========================================

Figure 15. Positive correlation, on the left means while one variable increases so does the other.  

------------------- Sentence 1 -------------------

Figure 15.

>> Tokens are: 
 ['Figure', '15', '.']

>> Bigrams are: 
 [('Figure', '15'), ('15', '.')]

>> Trigrams are: 
 [('Figure', '15', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('15', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('15', '15'), ('.', '.')]


------------------- Sentence 2 -------------------

Positive correlation, on the left means while one variable increases so does the other.

>> Tokens are: 
 ['Positive', 'correlation', ',', 'left', 'means', 'one', 'variable', 'increases', '.']

>> Bigrams are: 
 [('Positive', 'correlation'), ('correlation', ','), (',', 'left'), ('left', 'means'), ('means', 'one'), ('one', 'variable'), ('variable', 'increases'), ('increases', '.')]

>> Trigrams are: 
 [('Positive', 'correlation', ','), ('correlation', ',', 'left'), (',', 'left', 'means'), ('left', 'means', 'one'), ('means', 'one', 'variable'), ('one', 'variable', 'increases'), ('variable', 'increases', '.')]

>> POS Tags are: 
 [('Positive', 'JJ'), ('correlation', 'NN'), (',', ','), ('left', 'VBD'), ('means', 'VBZ'), ('one', 'CD'), ('variable', 'NN'), ('increases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Positive correlation', 'variable increases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Positive', 'posit'), ('correlation', 'correl'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Positive', 'posit'), ('correlation', 'correl'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('Positive', 'Positive'), ('correlation', 'correlation'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variable'), ('increases', 'increase'), ('.', '.')]



========================================== PARAGRAPH 733 ===========================================

No linear correlation on the middle means there is no visible relationship between the variables.  

------------------- Sentence 1 -------------------

No linear correlation on the middle means there is no visible relationship between the variables.

>> Tokens are: 
 ['No', 'linear', 'correlation', 'middle', 'means', 'visible', 'relationship', 'variables', '.']

>> Bigrams are: 
 [('No', 'linear'), ('linear', 'correlation'), ('correlation', 'middle'), ('middle', 'means'), ('means', 'visible'), ('visible', 'relationship'), ('relationship', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('No', 'linear', 'correlation'), ('linear', 'correlation', 'middle'), ('correlation', 'middle', 'means'), ('middle', 'means', 'visible'), ('means', 'visible', 'relationship'), ('visible', 'relationship', 'variables'), ('relationship', 'variables', '.')]

>> POS Tags are: 
 [('No', 'DT'), ('linear', 'JJ'), ('correlation', 'NN'), ('middle', 'NN'), ('means', 'VBZ'), ('visible', 'JJ'), ('relationship', 'NN'), ('variables', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['No linear correlation middle', 'visible relationship variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('No', 'no'), ('linear', 'linear'), ('correlation', 'correl'), ('middle', 'middl'), ('means', 'mean'), ('visible', 'visibl'), ('relationship', 'relationship'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('No', 'no'), ('linear', 'linear'), ('correlation', 'correl'), ('middle', 'middl'), ('means', 'mean'), ('visible', 'visibl'), ('relationship', 'relationship'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('No', 'No'), ('linear', 'linear'), ('correlation', 'correlation'), ('middle', 'middle'), ('means', 'mean'), ('visible', 'visible'), ('relationship', 'relationship'), ('variables', 'variable'), ('.', '.')]



========================================== PARAGRAPH 734 ===========================================

Negative correlation on the right means as one variable increases, the other decreases (Chen, M.,  

------------------- Sentence 1 -------------------

Negative correlation on the right means as one variable increases, the other decreases (Chen, M.,

>> Tokens are: 
 ['Negative', 'correlation', 'right', 'means', 'one', 'variable', 'increases', ',', 'decreases', '(', 'Chen', ',', 'M.', ',']

>> Bigrams are: 
 [('Negative', 'correlation'), ('correlation', 'right'), ('right', 'means'), ('means', 'one'), ('one', 'variable'), ('variable', 'increases'), ('increases', ','), (',', 'decreases'), ('decreases', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ',')]

>> Trigrams are: 
 [('Negative', 'correlation', 'right'), ('correlation', 'right', 'means'), ('right', 'means', 'one'), ('means', 'one', 'variable'), ('one', 'variable', 'increases'), ('variable', 'increases', ','), ('increases', ',', 'decreases'), (',', 'decreases', '('), ('decreases', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ',')]

>> POS Tags are: 
 [('Negative', 'JJ'), ('correlation', 'NN'), ('right', 'RB'), ('means', 'VBZ'), ('one', 'CD'), ('variable', 'NN'), ('increases', 'NNS'), (',', ','), ('decreases', 'NNS'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Negative correlation', 'variable increases', 'decreases', 'Chen', 'M.']

>> Named Entities are: 
 [('GPE', 'Negative'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Negative', 'neg'), ('correlation', 'correl'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), (',', ','), ('decreases', 'decreas'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Negative', 'negat'), ('correlation', 'correl'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), (',', ','), ('decreases', 'decreas'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ',')]

>> Lemmatization: 
 [('Negative', 'Negative'), ('correlation', 'correlation'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variable'), ('increases', 'increase'), (',', ','), ('decreases', 'decrease'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ',')]



========================================== PARAGRAPH 735 ===========================================

Mao, S. and Liu, Y., 2014).   

------------------- Sentence 1 -------------------

Mao, S. and Liu, Y., 2014).

>> Tokens are: 
 ['Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 736 ===========================================

  


========================================== PARAGRAPH 737 ===========================================

  


========================================== PARAGRAPH 738 ===========================================

Figure 15: Correlation Analysis.  

------------------- Sentence 1 -------------------

Figure 15: Correlation Analysis.

>> Tokens are: 
 ['Figure', '15', ':', 'Correlation', 'Analysis', '.']

>> Bigrams are: 
 [('Figure', '15'), ('15', ':'), (':', 'Correlation'), ('Correlation', 'Analysis'), ('Analysis', '.')]

>> Trigrams are: 
 [('Figure', '15', ':'), ('15', ':', 'Correlation'), (':', 'Correlation', 'Analysis'), ('Correlation', 'Analysis', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('15', 'CD'), (':', ':'), ('Correlation', 'NN'), ('Analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Correlation Analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('15', '15'), (':', ':'), ('Correlation', 'correl'), ('Analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('15', '15'), (':', ':'), ('Correlation', 'correl'), ('Analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('15', '15'), (':', ':'), ('Correlation', 'Correlation'), ('Analysis', 'Analysis'), ('.', '.')]



========================================== PARAGRAPH 739 ===========================================

  


========================================== PARAGRAPH 740 ===========================================

Text Mining: This converts the content from unstructured text to structured text in order to help  

------------------- Sentence 1 -------------------

Text Mining: This converts the content from unstructured text to structured text in order to help

>> Tokens are: 
 ['Text', 'Mining', ':', 'This', 'converts', 'content', 'unstructured', 'text', 'structured', 'text', 'order', 'help']

>> Bigrams are: 
 [('Text', 'Mining'), ('Mining', ':'), (':', 'This'), ('This', 'converts'), ('converts', 'content'), ('content', 'unstructured'), ('unstructured', 'text'), ('text', 'structured'), ('structured', 'text'), ('text', 'order'), ('order', 'help')]

>> Trigrams are: 
 [('Text', 'Mining', ':'), ('Mining', ':', 'This'), (':', 'This', 'converts'), ('This', 'converts', 'content'), ('converts', 'content', 'unstructured'), ('content', 'unstructured', 'text'), ('unstructured', 'text', 'structured'), ('text', 'structured', 'text'), ('structured', 'text', 'order'), ('text', 'order', 'help')]

>> POS Tags are: 
 [('Text', 'NN'), ('Mining', 'NN'), (':', ':'), ('This', 'DT'), ('converts', 'VBZ'), ('content', 'NN'), ('unstructured', 'JJ'), ('text', 'NN'), ('structured', 'VBD'), ('text', 'JJ'), ('order', 'NN'), ('help', 'NN')]

>> Noun Phrases are: 
 ['Text Mining', 'content', 'unstructured text', 'text order help']

>> Named Entities are: 
 [('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('Mining', 'mine'), (':', ':'), ('This', 'thi'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructur'), ('text', 'text'), ('structured', 'structur'), ('text', 'text'), ('order', 'order'), ('help', 'help')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('Mining', 'mine'), (':', ':'), ('This', 'this'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructur'), ('text', 'text'), ('structured', 'structur'), ('text', 'text'), ('order', 'order'), ('help', 'help')]

>> Lemmatization: 
 [('Text', 'Text'), ('Mining', 'Mining'), (':', ':'), ('This', 'This'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructured'), ('text', 'text'), ('structured', 'structured'), ('text', 'text'), ('order', 'order'), ('help', 'help')]



========================================== PARAGRAPH 741 ===========================================

uncover the meaning and the information contained.  

------------------- Sentence 1 -------------------

uncover the meaning and the information contained.

>> Tokens are: 
 ['uncover', 'meaning', 'information', 'contained', '.']

>> Bigrams are: 
 [('uncover', 'meaning'), ('meaning', 'information'), ('information', 'contained'), ('contained', '.')]

>> Trigrams are: 
 [('uncover', 'meaning', 'information'), ('meaning', 'information', 'contained'), ('information', 'contained', '.')]

>> POS Tags are: 
 [('uncover', 'RB'), ('meaning', 'VBG'), ('information', 'NN'), ('contained', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('uncover', 'uncov'), ('meaning', 'mean'), ('information', 'inform'), ('contained', 'contain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('uncover', 'uncov'), ('meaning', 'mean'), ('information', 'inform'), ('contained', 'contain'), ('.', '.')]

>> Lemmatization: 
 [('uncover', 'uncover'), ('meaning', 'meaning'), ('information', 'information'), ('contained', 'contained'), ('.', '.')]



========================================== PARAGRAPH 742 ===========================================

  


========================================== PARAGRAPH 743 ===========================================

Factor Analysis: This groups several related variables into a single factor, which means that fewer  

------------------- Sentence 1 -------------------

Factor Analysis: This groups several related variables into a single factor, which means that fewer

>> Tokens are: 
 ['Factor', 'Analysis', ':', 'This', 'groups', 'several', 'related', 'variables', 'single', 'factor', ',', 'means', 'fewer']

>> Bigrams are: 
 [('Factor', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'groups'), ('groups', 'several'), ('several', 'related'), ('related', 'variables'), ('variables', 'single'), ('single', 'factor'), ('factor', ','), (',', 'means'), ('means', 'fewer')]

>> Trigrams are: 
 [('Factor', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'groups'), ('This', 'groups', 'several'), ('groups', 'several', 'related'), ('several', 'related', 'variables'), ('related', 'variables', 'single'), ('variables', 'single', 'factor'), ('single', 'factor', ','), ('factor', ',', 'means'), (',', 'means', 'fewer')]

>> POS Tags are: 
 [('Factor', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('groups', 'NNS'), ('several', 'JJ'), ('related', 'JJ'), ('variables', 'NNS'), ('single', 'JJ'), ('factor', 'NN'), (',', ','), ('means', 'VBZ'), ('fewer', 'JJR')]

>> Noun Phrases are: 
 ['Factor Analysis', 'This groups', 'several related variables', 'single factor']

>> Named Entities are: 
 [('GPE', 'Factor'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Factor', 'factor'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('groups', 'group'), ('several', 'sever'), ('related', 'relat'), ('variables', 'variabl'), ('single', 'singl'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer')]

>> Stemming using Snowball Stemmer: 
 [('Factor', 'factor'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('groups', 'group'), ('several', 'sever'), ('related', 'relat'), ('variables', 'variabl'), ('single', 'singl'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer')]

>> Lemmatization: 
 [('Factor', 'Factor'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('groups', 'group'), ('several', 'several'), ('related', 'related'), ('variables', 'variable'), ('single', 'single'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer')]



========================================== PARAGRAPH 744 ===========================================

factors are used in analysis, which is thus simpler.  

------------------- Sentence 1 -------------------

factors are used in analysis, which is thus simpler.

>> Tokens are: 
 ['factors', 'used', 'analysis', ',', 'thus', 'simpler', '.']

>> Bigrams are: 
 [('factors', 'used'), ('used', 'analysis'), ('analysis', ','), (',', 'thus'), ('thus', 'simpler'), ('simpler', '.')]

>> Trigrams are: 
 [('factors', 'used', 'analysis'), ('used', 'analysis', ','), ('analysis', ',', 'thus'), (',', 'thus', 'simpler'), ('thus', 'simpler', '.')]

>> POS Tags are: 
 [('factors', 'NNS'), ('used', 'VBD'), ('analysis', 'NN'), (',', ','), ('thus', 'RB'), ('simpler', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['factors', 'analysis', 'simpler']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('factors', 'factor'), ('used', 'use'), ('analysis', 'analysi'), (',', ','), ('thus', 'thu'), ('simpler', 'simpler'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('factors', 'factor'), ('used', 'use'), ('analysis', 'analysi'), (',', ','), ('thus', 'thus'), ('simpler', 'simpler'), ('.', '.')]

>> Lemmatization: 
 [('factors', 'factor'), ('used', 'used'), ('analysis', 'analysis'), (',', ','), ('thus', 'thus'), ('simpler', 'simpler'), ('.', '.')]



========================================== PARAGRAPH 745 ===========================================

  


========================================== PARAGRAPH 746 ===========================================

The research presented in Schelén et al. (2015) examines the state-of-the-art in big data at that time  

------------------- Sentence 1 -------------------

The research presented in Schelén et al.

>> Tokens are: 
 ['The', 'research', 'presented', 'Schelén', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'research'), ('research', 'presented'), ('presented', 'Schelén'), ('Schelén', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'research', 'presented'), ('research', 'presented', 'Schelén'), ('presented', 'Schelén', 'et'), ('Schelén', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('research', 'NN'), ('presented', 'VBD'), ('Schelén', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The research', 'Schelén', 'al']

>> Named Entities are: 
 [('PERSON', 'Schelén')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('research', 'research'), ('presented', 'present'), ('Schelén', 'schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('research', 'research'), ('presented', 'present'), ('Schelén', 'schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('research', 'research'), ('presented', 'presented'), ('Schelén', 'Schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2015) examines the state-of-the-art in big data at that time

>> Tokens are: 
 ['(', '2015', ')', 'examines', 'state-of-the-art', 'big', 'data', 'time']

>> Bigrams are: 
 [('(', '2015'), ('2015', ')'), (')', 'examines'), ('examines', 'state-of-the-art'), ('state-of-the-art', 'big'), ('big', 'data'), ('data', 'time')]

>> Trigrams are: 
 [('(', '2015', ')'), ('2015', ')', 'examines'), (')', 'examines', 'state-of-the-art'), ('examines', 'state-of-the-art', 'big'), ('state-of-the-art', 'big', 'data'), ('big', 'data', 'time')]

>> POS Tags are: 
 [('(', '('), ('2015', 'CD'), (')', ')'), ('examines', 'VBZ'), ('state-of-the-art', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('time', 'NN')]

>> Noun Phrases are: 
 ['state-of-the-art big data time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examin'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examin'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time')]

>> Lemmatization: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examines'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time')]



========================================== PARAGRAPH 747 ===========================================

and discusses research agendas. In addition, it defines the basic technology and toolsets used. It is  

------------------- Sentence 1 -------------------

and discusses research agendas.

>> Tokens are: 
 ['discusses', 'research', 'agendas', '.']

>> Bigrams are: 
 [('discusses', 'research'), ('research', 'agendas'), ('agendas', '.')]

>> Trigrams are: 
 [('discusses', 'research', 'agendas'), ('research', 'agendas', '.')]

>> POS Tags are: 
 [('discusses', 'NNS'), ('research', 'NN'), ('agendas', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['discusses research agendas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discusses', 'discuss'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discusses', 'discuss'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]

>> Lemmatization: 
 [('discusses', 'discus'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]


------------------- Sentence 2 -------------------

In addition, it defines the basic technology and toolsets used.

>> Tokens are: 
 ['In', 'addition', ',', 'defines', 'basic', 'technology', 'toolsets', 'used', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'defines'), ('defines', 'basic'), ('basic', 'technology'), ('technology', 'toolsets'), ('toolsets', 'used'), ('used', '.')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'defines'), (',', 'defines', 'basic'), ('defines', 'basic', 'technology'), ('basic', 'technology', 'toolsets'), ('technology', 'toolsets', 'used'), ('toolsets', 'used', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('defines', 'NNS'), ('basic', 'JJ'), ('technology', 'NN'), ('toolsets', 'NNS'), ('used', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'defines', 'basic technology toolsets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('defines', 'defin'), ('basic', 'basic'), ('technology', 'technolog'), ('toolsets', 'toolset'), ('used', 'use'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('defines', 'defin'), ('basic', 'basic'), ('technology', 'technolog'), ('toolsets', 'toolset'), ('used', 'use'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('defines', 'defines'), ('basic', 'basic'), ('technology', 'technology'), ('toolsets', 'toolsets'), ('used', 'used'), ('.', '.')]


------------------- Sentence 3 -------------------

It is

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 748 ===========================================

not easy to analyse datasets with traditional data management techniques (Constantiou and  

------------------- Sentence 1 -------------------

not easy to analyse datasets with traditional data management techniques (Constantiou and

>> Tokens are: 
 ['easy', 'analyse', 'datasets', 'traditional', 'data', 'management', 'techniques', '(', 'Constantiou']

>> Bigrams are: 
 [('easy', 'analyse'), ('analyse', 'datasets'), ('datasets', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', 'techniques'), ('techniques', '('), ('(', 'Constantiou')]

>> Trigrams are: 
 [('easy', 'analyse', 'datasets'), ('analyse', 'datasets', 'traditional'), ('datasets', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', 'techniques'), ('management', 'techniques', '('), ('techniques', '(', 'Constantiou')]

>> POS Tags are: 
 [('easy', 'JJ'), ('analyse', 'JJ'), ('datasets', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('techniques', 'NNS'), ('(', '('), ('Constantiou', 'NNP')]

>> Noun Phrases are: 
 ['easy analyse datasets', 'traditional data management techniques', 'Constantiou']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('techniques', 'techniqu'), ('(', '('), ('Constantiou', 'constanti')]

>> Stemming using Snowball Stemmer: 
 [('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('techniques', 'techniqu'), ('(', '('), ('Constantiou', 'constantiou')]

>> Lemmatization: 
 [('easy', 'easy'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), ('techniques', 'technique'), ('(', '('), ('Constantiou', 'Constantiou')]



========================================== PARAGRAPH 749 ===========================================

Kallinikos, 2015); therefore, new methods and tools have been developed for big data analytics,  

------------------- Sentence 1 -------------------

Kallinikos, 2015); therefore, new methods and tools have been developed for big data analytics,

>> Tokens are: 
 ['Kallinikos', ',', '2015', ')', ';', 'therefore', ',', 'new', 'methods', 'tools', 'developed', 'big', 'data', 'analytics', ',']

>> Bigrams are: 
 [('Kallinikos', ','), (',', '2015'), ('2015', ')'), (')', ';'), (';', 'therefore'), ('therefore', ','), (',', 'new'), ('new', 'methods'), ('methods', 'tools'), ('tools', 'developed'), ('developed', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ',')]

>> Trigrams are: 
 [('Kallinikos', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';'), (')', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'new'), (',', 'new', 'methods'), ('new', 'methods', 'tools'), ('methods', 'tools', 'developed'), ('tools', 'developed', 'big'), ('developed', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ',')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':'), ('therefore', 'RB'), (',', ','), ('new', 'JJ'), ('methods', 'NNS'), ('tools', 'NNS'), ('developed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Kallinikos', 'new methods tools', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'developed'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ',')]



========================================== PARAGRAPH 750 ===========================================

as well as for storing and managing such data. These solutions thus need to be studied in terms of  

------------------- Sentence 1 -------------------

as well as for storing and managing such data.

>> Tokens are: 
 ['well', 'storing', 'managing', 'data', '.']

>> Bigrams are: 
 [('well', 'storing'), ('storing', 'managing'), ('managing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('well', 'storing', 'managing'), ('storing', 'managing', 'data'), ('managing', 'data', '.')]

>> POS Tags are: 
 [('well', 'RB'), ('storing', 'VBG'), ('managing', 'VBG'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('well', 'well'), ('storing', 'store'), ('managing', 'manag'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('well', 'well'), ('storing', 'store'), ('managing', 'manag'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('well', 'well'), ('storing', 'storing'), ('managing', 'managing'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

These solutions thus need to be studied in terms of

>> Tokens are: 
 ['These', 'solutions', 'thus', 'need', 'studied', 'terms']

>> Bigrams are: 
 [('These', 'solutions'), ('solutions', 'thus'), ('thus', 'need'), ('need', 'studied'), ('studied', 'terms')]

>> Trigrams are: 
 [('These', 'solutions', 'thus'), ('solutions', 'thus', 'need'), ('thus', 'need', 'studied'), ('need', 'studied', 'terms')]

>> POS Tags are: 
 [('These', 'DT'), ('solutions', 'NNS'), ('thus', 'RB'), ('need', 'VBP'), ('studied', 'JJ'), ('terms', 'NNS')]

>> Noun Phrases are: 
 ['These solutions', 'studied terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('solutions', 'solut'), ('thus', 'thu'), ('need', 'need'), ('studied', 'studi'), ('terms', 'term')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('solutions', 'solut'), ('thus', 'thus'), ('need', 'need'), ('studied', 'studi'), ('terms', 'term')]

>> Lemmatization: 
 [('These', 'These'), ('solutions', 'solution'), ('thus', 'thus'), ('need', 'need'), ('studied', 'studied'), ('terms', 'term')]



========================================== PARAGRAPH 751 ===========================================

handling datasets and extracting knowledge and value. In addition, the rapid changes in data  

------------------- Sentence 1 -------------------

handling datasets and extracting knowledge and value.

>> Tokens are: 
 ['handling', 'datasets', 'extracting', 'knowledge', 'value', '.']

>> Bigrams are: 
 [('handling', 'datasets'), ('datasets', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'value'), ('value', '.')]

>> Trigrams are: 
 [('handling', 'datasets', 'extracting'), ('datasets', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'value'), ('knowledge', 'value', '.')]

>> POS Tags are: 
 [('handling', 'VBG'), ('datasets', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('value', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['datasets', 'knowledge value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('handling', 'handl'), ('datasets', 'dataset'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('handling', 'handl'), ('datasets', 'dataset'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('handling', 'handling'), ('datasets', 'datasets'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('value', 'value'), ('.', '.')]


------------------- Sentence 2 -------------------

In addition, the rapid changes in data

>> Tokens are: 
 ['In', 'addition', ',', 'rapid', 'changes', 'data']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'rapid'), ('rapid', 'changes'), ('changes', 'data')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'rapid'), (',', 'rapid', 'changes'), ('rapid', 'changes', 'data')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('rapid', 'JJ'), ('changes', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['addition', 'rapid changes data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('rapid', 'rapid'), ('changes', 'chang'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('rapid', 'rapid'), ('changes', 'chang'), ('data', 'data')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('rapid', 'rapid'), ('changes', 'change'), ('data', 'data')]



========================================== PARAGRAPH 752 ===========================================

volume, variety, velocity, and value require decision makers to know how to obtain valuable  

------------------- Sentence 1 -------------------

volume, variety, velocity, and value require decision makers to know how to obtain valuable

>> Tokens are: 
 ['volume', ',', 'variety', ',', 'velocity', ',', 'value', 'require', 'decision', 'makers', 'know', 'obtain', 'valuable']

>> Bigrams are: 
 [('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', ','), (',', 'value'), ('value', 'require'), ('require', 'decision'), ('decision', 'makers'), ('makers', 'know'), ('know', 'obtain'), ('obtain', 'valuable')]

>> Trigrams are: 
 [('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'value'), (',', 'value', 'require'), ('value', 'require', 'decision'), ('require', 'decision', 'makers'), ('decision', 'makers', 'know'), ('makers', 'know', 'obtain'), ('know', 'obtain', 'valuable')]

>> POS Tags are: 
 [('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('value', 'NN'), ('require', 'VB'), ('decision', 'NN'), ('makers', 'NNS'), ('know', 'VBP'), ('obtain', 'VB'), ('valuable', 'JJ')]

>> Noun Phrases are: 
 ['volume', 'variety', 'velocity', 'value', 'decision makers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('value', 'valu'), ('require', 'requir'), ('decision', 'decis'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuabl')]

>> Stemming using Snowball Stemmer: 
 [('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('value', 'valu'), ('require', 'requir'), ('decision', 'decis'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuabl')]

>> Lemmatization: 
 [('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), (',', ','), ('value', 'value'), ('require', 'require'), ('decision', 'decision'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuable')]



========================================== PARAGRAPH 753 ===========================================

insights.  

------------------- Sentence 1 -------------------

insights.

>> Tokens are: 
 ['insights', '.']

>> Bigrams are: 
 [('insights', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('insights', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('insights', 'insight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('insights', 'insight'), ('.', '.')]

>> Lemmatization: 
 [('insights', 'insight'), ('.', '.')]



========================================== PARAGRAPH 754 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 755 ===========================================

27  

------------------- Sentence 1 -------------------

27

>> Tokens are: 
 ['27']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('27', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('27', '27')]

>> Stemming using Snowball Stemmer: 
 [('27', '27')]

>> Lemmatization: 
 [('27', '27')]



========================================== PARAGRAPH 756 ===========================================

  


========================================== PARAGRAPH 757 ===========================================

Traditional data analysis uses formal statistical methods to analyse data, constructing, extracting,  

------------------- Sentence 1 -------------------

Traditional data analysis uses formal statistical methods to analyse data, constructing, extracting,

>> Tokens are: 
 ['Traditional', 'data', 'analysis', 'uses', 'formal', 'statistical', 'methods', 'analyse', 'data', ',', 'constructing', ',', 'extracting', ',']

>> Bigrams are: 
 [('Traditional', 'data'), ('data', 'analysis'), ('analysis', 'uses'), ('uses', 'formal'), ('formal', 'statistical'), ('statistical', 'methods'), ('methods', 'analyse'), ('analyse', 'data'), ('data', ','), (',', 'constructing'), ('constructing', ','), (',', 'extracting'), ('extracting', ',')]

>> Trigrams are: 
 [('Traditional', 'data', 'analysis'), ('data', 'analysis', 'uses'), ('analysis', 'uses', 'formal'), ('uses', 'formal', 'statistical'), ('formal', 'statistical', 'methods'), ('statistical', 'methods', 'analyse'), ('methods', 'analyse', 'data'), ('analyse', 'data', ','), ('data', ',', 'constructing'), (',', 'constructing', ','), ('constructing', ',', 'extracting'), (',', 'extracting', ',')]

>> POS Tags are: 
 [('Traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('uses', 'VBZ'), ('formal', 'JJ'), ('statistical', 'JJ'), ('methods', 'NNS'), ('analyse', 'RB'), ('data', 'NNS'), (',', ','), ('constructing', 'NN'), (',', ','), ('extracting', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Traditional data analysis', 'formal statistical methods', 'data', 'constructing', 'extracting']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('uses', 'use'), ('formal', 'formal'), ('statistical', 'statist'), ('methods', 'method'), ('analyse', 'analys'), ('data', 'data'), (',', ','), ('constructing', 'construct'), (',', ','), ('extracting', 'extract'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('uses', 'use'), ('formal', 'formal'), ('statistical', 'statist'), ('methods', 'method'), ('analyse', 'analys'), ('data', 'data'), (',', ','), ('constructing', 'construct'), (',', ','), ('extracting', 'extract'), (',', ',')]

>> Lemmatization: 
 [('Traditional', 'Traditional'), ('data', 'data'), ('analysis', 'analysis'), ('uses', 'us'), ('formal', 'formal'), ('statistical', 'statistical'), ('methods', 'method'), ('analyse', 'analyse'), ('data', 'data'), (',', ','), ('constructing', 'constructing'), (',', ','), ('extracting', 'extracting'), (',', ',')]



========================================== PARAGRAPH 758 ===========================================

and refining useful data, and identifying subject matter relationships in order to maximise the value  

------------------- Sentence 1 -------------------

and refining useful data, and identifying subject matter relationships in order to maximise the value

>> Tokens are: 
 ['refining', 'useful', 'data', ',', 'identifying', 'subject', 'matter', 'relationships', 'order', 'maximise', 'value']

>> Bigrams are: 
 [('refining', 'useful'), ('useful', 'data'), ('data', ','), (',', 'identifying'), ('identifying', 'subject'), ('subject', 'matter'), ('matter', 'relationships'), ('relationships', 'order'), ('order', 'maximise'), ('maximise', 'value')]

>> Trigrams are: 
 [('refining', 'useful', 'data'), ('useful', 'data', ','), ('data', ',', 'identifying'), (',', 'identifying', 'subject'), ('identifying', 'subject', 'matter'), ('subject', 'matter', 'relationships'), ('matter', 'relationships', 'order'), ('relationships', 'order', 'maximise'), ('order', 'maximise', 'value')]

>> POS Tags are: 
 [('refining', 'VBG'), ('useful', 'JJ'), ('data', 'NNS'), (',', ','), ('identifying', 'VBG'), ('subject', 'JJ'), ('matter', 'NN'), ('relationships', 'NNS'), ('order', 'NN'), ('maximise', 'NN'), ('value', 'NN')]

>> Noun Phrases are: 
 ['useful data', 'subject matter relationships order maximise value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('refining', 'refin'), ('useful', 'use'), ('data', 'data'), (',', ','), ('identifying', 'identifi'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximis'), ('value', 'valu')]

>> Stemming using Snowball Stemmer: 
 [('refining', 'refin'), ('useful', 'use'), ('data', 'data'), (',', ','), ('identifying', 'identifi'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximis'), ('value', 'valu')]

>> Lemmatization: 
 [('refining', 'refining'), ('useful', 'useful'), ('data', 'data'), (',', ','), ('identifying', 'identifying'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximise'), ('value', 'value')]



========================================== PARAGRAPH 759 ===========================================

of data. It can now be regarded as an analysis technique to be used for special kinds of data, though  

------------------- Sentence 1 -------------------

of data.

>> Tokens are: 
 ['data', '.']

>> Bigrams are: 
 [('data', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

It can now be regarded as an analysis technique to be used for special kinds of data, though

>> Tokens are: 
 ['It', 'regarded', 'analysis', 'technique', 'used', 'special', 'kinds', 'data', ',', 'though']

>> Bigrams are: 
 [('It', 'regarded'), ('regarded', 'analysis'), ('analysis', 'technique'), ('technique', 'used'), ('used', 'special'), ('special', 'kinds'), ('kinds', 'data'), ('data', ','), (',', 'though')]

>> Trigrams are: 
 [('It', 'regarded', 'analysis'), ('regarded', 'analysis', 'technique'), ('analysis', 'technique', 'used'), ('technique', 'used', 'special'), ('used', 'special', 'kinds'), ('special', 'kinds', 'data'), ('kinds', 'data', ','), ('data', ',', 'though')]

>> POS Tags are: 
 [('It', 'PRP'), ('regarded', 'VBD'), ('analysis', 'NN'), ('technique', 'NN'), ('used', 'VBN'), ('special', 'JJ'), ('kinds', 'NNS'), ('data', 'NNS'), (',', ','), ('though', 'IN')]

>> Noun Phrases are: 
 ['analysis technique', 'special kinds data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('regarded', 'regard'), ('analysis', 'analysi'), ('technique', 'techniqu'), ('used', 'use'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('regarded', 'regard'), ('analysis', 'analysi'), ('technique', 'techniqu'), ('used', 'use'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though')]

>> Lemmatization: 
 [('It', 'It'), ('regarded', 'regarded'), ('analysis', 'analysis'), ('technique', 'technique'), ('used', 'used'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though')]



========================================== PARAGRAPH 760 ===========================================

many traditional data analysis methods are still be used for big data analysis where analysts have  

------------------- Sentence 1 -------------------

many traditional data analysis methods are still be used for big data analysis where analysts have

>> Tokens are: 
 ['many', 'traditional', 'data', 'analysis', 'methods', 'still', 'used', 'big', 'data', 'analysis', 'analysts']

>> Bigrams are: 
 [('many', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'still'), ('still', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'analysts')]

>> Trigrams are: 
 [('many', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'still'), ('methods', 'still', 'used'), ('still', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'analysts')]

>> POS Tags are: 
 [('many', 'JJ'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('still', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('analysts', 'NNS')]

>> Noun Phrases are: 
 ['many traditional data analysis methods', 'big data analysis analysts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('many', 'mani'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('still', 'still'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('analysts', 'analyst')]

>> Stemming using Snowball Stemmer: 
 [('many', 'mani'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('still', 'still'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('analysts', 'analyst')]

>> Lemmatization: 
 [('many', 'many'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('still', 'still'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('analysts', 'analyst')]



========================================== PARAGRAPH 761 ===========================================

backgrounds in statistics and computer science.  

------------------- Sentence 1 -------------------

backgrounds in statistics and computer science.

>> Tokens are: 
 ['backgrounds', 'statistics', 'computer', 'science', '.']

>> Bigrams are: 
 [('backgrounds', 'statistics'), ('statistics', 'computer'), ('computer', 'science'), ('science', '.')]

>> Trigrams are: 
 [('backgrounds', 'statistics', 'computer'), ('statistics', 'computer', 'science'), ('computer', 'science', '.')]

>> POS Tags are: 
 [('backgrounds', 'NNS'), ('statistics', 'NNS'), ('computer', 'NN'), ('science', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['backgrounds statistics computer science']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('backgrounds', 'background'), ('statistics', 'statist'), ('computer', 'comput'), ('science', 'scienc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('backgrounds', 'background'), ('statistics', 'statist'), ('computer', 'comput'), ('science', 'scienc'), ('.', '.')]

>> Lemmatization: 
 [('backgrounds', 'background'), ('statistics', 'statistic'), ('computer', 'computer'), ('science', 'science'), ('.', '.')]



========================================== PARAGRAPH 762 ===========================================

Association rules, clustering, classification, decision trees, and regression are the most common  

------------------- Sentence 1 -------------------

Association rules, clustering, classification, decision trees, and regression are the most common

>> Tokens are: 
 ['Association', 'rules', ',', 'clustering', ',', 'classification', ',', 'decision', 'trees', ',', 'regression', 'common']

>> Bigrams are: 
 [('Association', 'rules'), ('rules', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'regression'), ('regression', 'common')]

>> Trigrams are: 
 [('Association', 'rules', ','), ('rules', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'decision'), (',', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'regression'), (',', 'regression', 'common')]

>> POS Tags are: 
 [('Association', 'NNP'), ('rules', 'NNS'), (',', ','), ('clustering', 'VBG'), (',', ','), ('classification', 'NN'), (',', ','), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('regression', 'NN'), ('common', 'JJ')]

>> Noun Phrases are: 
 ['Association rules', 'classification', 'decision trees', 'regression']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), ('common', 'common')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), ('common', 'common')]

>> Lemmatization: 
 [('Association', 'Association'), ('rules', 'rule'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('regression', 'regression'), ('common', 'common')]



========================================== PARAGRAPH 763 ===========================================

data analytics methods; however, some additional analyses have become common in terms of big  

------------------- Sentence 1 -------------------

data analytics methods; however, some additional analyses have become common in terms of big

>> Tokens are: 
 ['data', 'analytics', 'methods', ';', 'however', ',', 'additional', 'analyses', 'become', 'common', 'terms', 'big']

>> Bigrams are: 
 [('data', 'analytics'), ('analytics', 'methods'), ('methods', ';'), (';', 'however'), ('however', ','), (',', 'additional'), ('additional', 'analyses'), ('analyses', 'become'), ('become', 'common'), ('common', 'terms'), ('terms', 'big')]

>> Trigrams are: 
 [('data', 'analytics', 'methods'), ('analytics', 'methods', ';'), ('methods', ';', 'however'), (';', 'however', ','), ('however', ',', 'additional'), (',', 'additional', 'analyses'), ('additional', 'analyses', 'become'), ('analyses', 'become', 'common'), ('become', 'common', 'terms'), ('common', 'terms', 'big')]

>> POS Tags are: 
 [('data', 'NNS'), ('analytics', 'NNS'), ('methods', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('additional', 'JJ'), ('analyses', 'VBZ'), ('become', 'JJ'), ('common', 'JJ'), ('terms', 'NNS'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['data analytics methods', 'become common terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), (';', ';'), ('however', 'howev'), (',', ','), ('additional', 'addit'), ('analyses', 'analys'), ('become', 'becom'), ('common', 'common'), ('terms', 'term'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), (';', ';'), ('however', 'howev'), (',', ','), ('additional', 'addit'), ('analyses', 'analys'), ('become', 'becom'), ('common', 'common'), ('terms', 'term'), ('big', 'big')]

>> Lemmatization: 
 [('data', 'data'), ('analytics', 'analytics'), ('methods', 'method'), (';', ';'), ('however', 'however'), (',', ','), ('additional', 'additional'), ('analyses', 'analysis'), ('become', 'become'), ('common', 'common'), ('terms', 'term'), ('big', 'big')]



========================================== PARAGRAPH 764 ===========================================

data, especially in terms of social media, which relies on social networking and content sharing.  

------------------- Sentence 1 -------------------

data, especially in terms of social media, which relies on social networking and content sharing.

>> Tokens are: 
 ['data', ',', 'especially', 'terms', 'social', 'media', ',', 'relies', 'social', 'networking', 'content', 'sharing', '.']

>> Bigrams are: 
 [('data', ','), (',', 'especially'), ('especially', 'terms'), ('terms', 'social'), ('social', 'media'), ('media', ','), (',', 'relies'), ('relies', 'social'), ('social', 'networking'), ('networking', 'content'), ('content', 'sharing'), ('sharing', '.')]

>> Trigrams are: 
 [('data', ',', 'especially'), (',', 'especially', 'terms'), ('especially', 'terms', 'social'), ('terms', 'social', 'media'), ('social', 'media', ','), ('media', ',', 'relies'), (',', 'relies', 'social'), ('relies', 'social', 'networking'), ('social', 'networking', 'content'), ('networking', 'content', 'sharing'), ('content', 'sharing', '.')]

>> POS Tags are: 
 [('data', 'NNS'), (',', ','), ('especially', 'RB'), ('terms', 'NNS'), ('social', 'JJ'), ('media', 'NNS'), (',', ','), ('relies', 'NNS'), ('social', 'JJ'), ('networking', 'JJ'), ('content', 'NN'), ('sharing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'terms', 'social media', 'relies', 'social networking content sharing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), (',', ','), ('especially', 'especi'), ('terms', 'term'), ('social', 'social'), ('media', 'media'), (',', ','), ('relies', 'reli'), ('social', 'social'), ('networking', 'network'), ('content', 'content'), ('sharing', 'share'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), (',', ','), ('especially', 'especi'), ('terms', 'term'), ('social', 'social'), ('media', 'media'), (',', ','), ('relies', 'reli'), ('social', 'social'), ('networking', 'network'), ('content', 'content'), ('sharing', 'share'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), (',', ','), ('especially', 'especially'), ('terms', 'term'), ('social', 'social'), ('media', 'medium'), (',', ','), ('relies', 'relies'), ('social', 'social'), ('networking', 'networking'), ('content', 'content'), ('sharing', 'sharing'), ('.', '.')]



========================================== PARAGRAPH 765 ===========================================

Social network analysis is thus dependent on the relationships between social entities. Text mining  

------------------- Sentence 1 -------------------

Social network analysis is thus dependent on the relationships between social entities.

>> Tokens are: 
 ['Social', 'network', 'analysis', 'thus', 'dependent', 'relationships', 'social', 'entities', '.']

>> Bigrams are: 
 [('Social', 'network'), ('network', 'analysis'), ('analysis', 'thus'), ('thus', 'dependent'), ('dependent', 'relationships'), ('relationships', 'social'), ('social', 'entities'), ('entities', '.')]

>> Trigrams are: 
 [('Social', 'network', 'analysis'), ('network', 'analysis', 'thus'), ('analysis', 'thus', 'dependent'), ('thus', 'dependent', 'relationships'), ('dependent', 'relationships', 'social'), ('relationships', 'social', 'entities'), ('social', 'entities', '.')]

>> POS Tags are: 
 [('Social', 'NNP'), ('network', 'NN'), ('analysis', 'NN'), ('thus', 'RB'), ('dependent', 'JJ'), ('relationships', 'NNS'), ('social', 'JJ'), ('entities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Social network analysis', 'dependent relationships', 'social entities']

>> Named Entities are: 
 [('GPE', 'Social')] 

>> Stemming using Porter Stemmer: 
 [('Social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('thus', 'thu'), ('dependent', 'depend'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('thus', 'thus'), ('dependent', 'depend'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entiti'), ('.', '.')]

>> Lemmatization: 
 [('Social', 'Social'), ('network', 'network'), ('analysis', 'analysis'), ('thus', 'thus'), ('dependent', 'dependent'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entity'), ('.', '.')]


------------------- Sentence 2 -------------------

Text mining

>> Tokens are: 
 ['Text', 'mining']

>> Bigrams are: 
 [('Text', 'mining')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Text', 'NN'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['Text mining']

>> Named Entities are: 
 [('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('mining', 'mine')]

>> Lemmatization: 
 [('Text', 'Text'), ('mining', 'mining')]



========================================== PARAGRAPH 766 ===========================================

used to analyse the contents of documents and to develop an understanding of the information  

------------------- Sentence 1 -------------------

used to analyse the contents of documents and to develop an understanding of the information

>> Tokens are: 
 ['used', 'analyse', 'contents', 'documents', 'develop', 'understanding', 'information']

>> Bigrams are: 
 [('used', 'analyse'), ('analyse', 'contents'), ('contents', 'documents'), ('documents', 'develop'), ('develop', 'understanding'), ('understanding', 'information')]

>> Trigrams are: 
 [('used', 'analyse', 'contents'), ('analyse', 'contents', 'documents'), ('contents', 'documents', 'develop'), ('documents', 'develop', 'understanding'), ('develop', 'understanding', 'information')]

>> POS Tags are: 
 [('used', 'VBN'), ('analyse', 'JJ'), ('contents', 'NNS'), ('documents', 'NNS'), ('develop', 'VB'), ('understanding', 'JJ'), ('information', 'NN')]

>> Noun Phrases are: 
 ['analyse contents documents', 'understanding information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('analyse', 'analys'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understand'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('analyse', 'analys'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understand'), ('information', 'inform')]

>> Lemmatization: 
 [('used', 'used'), ('analyse', 'analyse'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understanding'), ('information', 'information')]



========================================== PARAGRAPH 767 ===========================================

therein. Sentiment analysis is then used to analyse the emotions underlying that content, and this  

------------------- Sentence 1 -------------------

therein.

>> Tokens are: 
 ['therein', '.']

>> Bigrams are: 
 [('therein', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('therein', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['therein']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('therein', 'therein'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('therein', 'therein'), ('.', '.')]

>> Lemmatization: 
 [('therein', 'therein'), ('.', '.')]


------------------- Sentence 2 -------------------

Sentiment analysis is then used to analyse the emotions underlying that content, and this

>> Tokens are: 
 ['Sentiment', 'analysis', 'used', 'analyse', 'emotions', 'underlying', 'content', ',']

>> Bigrams are: 
 [('Sentiment', 'analysis'), ('analysis', 'used'), ('used', 'analyse'), ('analyse', 'emotions'), ('emotions', 'underlying'), ('underlying', 'content'), ('content', ',')]

>> Trigrams are: 
 [('Sentiment', 'analysis', 'used'), ('analysis', 'used', 'analyse'), ('used', 'analyse', 'emotions'), ('analyse', 'emotions', 'underlying'), ('emotions', 'underlying', 'content'), ('underlying', 'content', ',')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('analysis', 'NN'), ('used', 'VBN'), ('analyse', 'JJ'), ('emotions', 'NNS'), ('underlying', 'VBG'), ('content', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Sentiment analysis', 'analyse emotions', 'content']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('used', 'use'), ('analyse', 'analys'), ('emotions', 'emot'), ('underlying', 'underli'), ('content', 'content'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('used', 'use'), ('analyse', 'analys'), ('emotions', 'emot'), ('underlying', 'under'), ('content', 'content'), (',', ',')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analysis', 'analysis'), ('used', 'used'), ('analyse', 'analyse'), ('emotions', 'emotion'), ('underlying', 'underlying'), ('content', 'content'), (',', ',')]



========================================== PARAGRAPH 768 ===========================================

more important form of analysis uses language processing to identify such information.  

------------------- Sentence 1 -------------------

more important form of analysis uses language processing to identify such information.

>> Tokens are: 
 ['important', 'form', 'analysis', 'uses', 'language', 'processing', 'identify', 'information', '.']

>> Bigrams are: 
 [('important', 'form'), ('form', 'analysis'), ('analysis', 'uses'), ('uses', 'language'), ('language', 'processing'), ('processing', 'identify'), ('identify', 'information'), ('information', '.')]

>> Trigrams are: 
 [('important', 'form', 'analysis'), ('form', 'analysis', 'uses'), ('analysis', 'uses', 'language'), ('uses', 'language', 'processing'), ('language', 'processing', 'identify'), ('processing', 'identify', 'information'), ('identify', 'information', '.')]

>> POS Tags are: 
 [('important', 'JJ'), ('form', 'NN'), ('analysis', 'NN'), ('uses', 'VBZ'), ('language', 'NN'), ('processing', 'VBG'), ('identify', 'JJ'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['important form analysis', 'language', 'identify information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('form', 'form'), ('analysis', 'analysi'), ('uses', 'use'), ('language', 'languag'), ('processing', 'process'), ('identify', 'identifi'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('form', 'form'), ('analysis', 'analysi'), ('uses', 'use'), ('language', 'languag'), ('processing', 'process'), ('identify', 'identifi'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('important', 'important'), ('form', 'form'), ('analysis', 'analysis'), ('uses', 'us'), ('language', 'language'), ('processing', 'processing'), ('identify', 'identify'), ('information', 'information'), ('.', '.')]



========================================== PARAGRAPH 769 ===========================================

  


========================================== PARAGRAPH 770 ===========================================

Finally, advanced data visualisation is becoming an important analysis tool, as this enables faster  

------------------- Sentence 1 -------------------

Finally, advanced data visualisation is becoming an important analysis tool, as this enables faster

>> Tokens are: 
 ['Finally', ',', 'advanced', 'data', 'visualisation', 'becoming', 'important', 'analysis', 'tool', ',', 'enables', 'faster']

>> Bigrams are: 
 [('Finally', ','), (',', 'advanced'), ('advanced', 'data'), ('data', 'visualisation'), ('visualisation', 'becoming'), ('becoming', 'important'), ('important', 'analysis'), ('analysis', 'tool'), ('tool', ','), (',', 'enables'), ('enables', 'faster')]

>> Trigrams are: 
 [('Finally', ',', 'advanced'), (',', 'advanced', 'data'), ('advanced', 'data', 'visualisation'), ('data', 'visualisation', 'becoming'), ('visualisation', 'becoming', 'important'), ('becoming', 'important', 'analysis'), ('important', 'analysis', 'tool'), ('analysis', 'tool', ','), ('tool', ',', 'enables'), (',', 'enables', 'faster')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('advanced', 'VBD'), ('data', 'NNS'), ('visualisation', 'NN'), ('becoming', 'VBG'), ('important', 'JJ'), ('analysis', 'NN'), ('tool', 'NN'), (',', ','), ('enables', 'VBZ'), ('faster', 'RBR')]

>> Noun Phrases are: 
 ['data visualisation', 'important analysis tool']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('advanced', 'advanc'), ('data', 'data'), ('visualisation', 'visualis'), ('becoming', 'becom'), ('important', 'import'), ('analysis', 'analysi'), ('tool', 'tool'), (',', ','), ('enables', 'enabl'), ('faster', 'faster')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('advanced', 'advanc'), ('data', 'data'), ('visualisation', 'visualis'), ('becoming', 'becom'), ('important', 'import'), ('analysis', 'analysi'), ('tool', 'tool'), (',', ','), ('enables', 'enabl'), ('faster', 'faster')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('advanced', 'advanced'), ('data', 'data'), ('visualisation', 'visualisation'), ('becoming', 'becoming'), ('important', 'important'), ('analysis', 'analysis'), ('tool', 'tool'), (',', ','), ('enables', 'enables'), ('faster', 'faster')]



========================================== PARAGRAPH 771 ===========================================

and better decision making (Russom, 2011; Elgendy and Elragal, 2016). Some of the more  

------------------- Sentence 1 -------------------

and better decision making (Russom, 2011; Elgendy and Elragal, 2016).

>> Tokens are: 
 ['better', 'decision', 'making', '(', 'Russom', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('better', 'decision'), ('decision', 'making'), ('making', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('better', 'decision', 'making'), ('decision', 'making', '('), ('making', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('better', 'JJR'), ('decision', 'NN'), ('making', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['decision making', 'Russom', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Russom'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('better', 'better'), ('decision', 'decis'), ('making', 'make'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('better', 'better'), ('decision', 'decis'), ('making', 'make'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('better', 'better'), ('decision', 'decision'), ('making', 'making'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Some of the more

>> Tokens are: 
 ['Some']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Some', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some')]

>> Lemmatization: 
 [('Some', 'Some')]



========================================== PARAGRAPH 772 ===========================================

common models and analyses are explained further below, and shown in Figure 16:  

------------------- Sentence 1 -------------------

common models and analyses are explained further below, and shown in Figure 16:

>> Tokens are: 
 ['common', 'models', 'analyses', 'explained', ',', 'shown', 'Figure', '16', ':']

>> Bigrams are: 
 [('common', 'models'), ('models', 'analyses'), ('analyses', 'explained'), ('explained', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '16'), ('16', ':')]

>> Trigrams are: 
 [('common', 'models', 'analyses'), ('models', 'analyses', 'explained'), ('analyses', 'explained', ','), ('explained', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '16'), ('Figure', '16', ':')]

>> POS Tags are: 
 [('common', 'JJ'), ('models', 'NNS'), ('analyses', 'NNS'), ('explained', 'VBD'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('16', 'CD'), (':', ':')]

>> Noun Phrases are: 
 ['common models analyses', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('common', 'common'), ('models', 'model'), ('analyses', 'analys'), ('explained', 'explain'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('16', '16'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('common', 'common'), ('models', 'model'), ('analyses', 'analys'), ('explained', 'explain'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('16', '16'), (':', ':')]

>> Lemmatization: 
 [('common', 'common'), ('models', 'model'), ('analyses', 'analysis'), ('explained', 'explained'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('16', '16'), (':', ':')]



========================================== PARAGRAPH 773 ===========================================

  


========================================== PARAGRAPH 774 ===========================================

• Text analytics:  ➢ Sentiment Analysis: This is based on understanding the subjects’ emotions from  

------------------- Sentence 1 -------------------

• Text analytics:  ➢ Sentiment Analysis: This is based on understanding the subjects’ emotions from

>> Tokens are: 
 ['•', 'Text', 'analytics', ':', '➢', 'Sentiment', 'Analysis', ':', 'This', 'based', 'understanding', 'subjects', '’', 'emotions']

>> Bigrams are: 
 [('•', 'Text'), ('Text', 'analytics'), ('analytics', ':'), (':', '➢'), ('➢', 'Sentiment'), ('Sentiment', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'based'), ('based', 'understanding'), ('understanding', 'subjects'), ('subjects', '’'), ('’', 'emotions')]

>> Trigrams are: 
 [('•', 'Text', 'analytics'), ('Text', 'analytics', ':'), ('analytics', ':', '➢'), (':', '➢', 'Sentiment'), ('➢', 'Sentiment', 'Analysis'), ('Sentiment', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'based'), ('This', 'based', 'understanding'), ('based', 'understanding', 'subjects'), ('understanding', 'subjects', '’'), ('subjects', '’', 'emotions')]

>> POS Tags are: 
 [('•', 'JJ'), ('Text', 'NNP'), ('analytics', 'NNS'), (':', ':'), ('➢', 'JJ'), ('Sentiment', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('based', 'VBN'), ('understanding', 'JJ'), ('subjects', 'NNS'), ('’', 'JJ'), ('emotions', 'NNS')]

>> Noun Phrases are: 
 ['• Text analytics', '➢ Sentiment Analysis', 'understanding subjects', '’ emotions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Text', 'text'), ('analytics', 'analyt'), (':', ':'), ('➢', '➢'), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('based', 'base'), ('understanding', 'understand'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emot')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Text', 'text'), ('analytics', 'analyt'), (':', ':'), ('➢', '➢'), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('based', 'base'), ('understanding', 'understand'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emot')]

>> Lemmatization: 
 [('•', '•'), ('Text', 'Text'), ('analytics', 'analytics'), (':', ':'), ('➢', '➢'), ('Sentiment', 'Sentiment'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('based', 'based'), ('understanding', 'understanding'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emotion')]



========================================== PARAGRAPH 775 ===========================================

their text patterns to help in organising viewpoints into good or bad, positive or  

------------------- Sentence 1 -------------------

their text patterns to help in organising viewpoints into good or bad, positive or

>> Tokens are: 
 ['text', 'patterns', 'help', 'organising', 'viewpoints', 'good', 'bad', ',', 'positive']

>> Bigrams are: 
 [('text', 'patterns'), ('patterns', 'help'), ('help', 'organising'), ('organising', 'viewpoints'), ('viewpoints', 'good'), ('good', 'bad'), ('bad', ','), (',', 'positive')]

>> Trigrams are: 
 [('text', 'patterns', 'help'), ('patterns', 'help', 'organising'), ('help', 'organising', 'viewpoints'), ('organising', 'viewpoints', 'good'), ('viewpoints', 'good', 'bad'), ('good', 'bad', ','), ('bad', ',', 'positive')]

>> POS Tags are: 
 [('text', 'NN'), ('patterns', 'NNS'), ('help', 'VBP'), ('organising', 'VBG'), ('viewpoints', 'NNS'), ('good', 'JJ'), ('bad', 'JJ'), (',', ','), ('positive', 'JJ')]

>> Noun Phrases are: 
 ['text patterns', 'viewpoints']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organis'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'posit')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organis'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'posit')]

>> Lemmatization: 
 [('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organising'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'positive')]



========================================== PARAGRAPH 776 ===========================================

negative (Mouthami et al., 2013). This analysis helps firms by alerting them where  

------------------- Sentence 1 -------------------

negative (Mouthami et al., 2013).

>> Tokens are: 
 ['negative', '(', 'Mouthami', 'et', 'al.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('negative', '('), ('(', 'Mouthami'), ('Mouthami', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('negative', '(', 'Mouthami'), ('(', 'Mouthami', 'et'), ('Mouthami', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('negative', 'JJ'), ('(', '('), ('Mouthami', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Mouthami']

>> Named Entities are: 
 [('ORGANIZATION', 'Mouthami')] 

>> Stemming using Porter Stemmer: 
 [('negative', 'neg'), ('(', '('), ('Mouthami', 'mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('negative', 'negat'), ('(', '('), ('Mouthami', 'mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('negative', 'negative'), ('(', '('), ('Mouthami', 'Mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

This analysis helps firms by alerting them where

>> Tokens are: 
 ['This', 'analysis', 'helps', 'firms', 'alerting']

>> Bigrams are: 
 [('This', 'analysis'), ('analysis', 'helps'), ('helps', 'firms'), ('firms', 'alerting')]

>> Trigrams are: 
 [('This', 'analysis', 'helps'), ('analysis', 'helps', 'firms'), ('helps', 'firms', 'alerting')]

>> POS Tags are: 
 [('This', 'DT'), ('analysis', 'NN'), ('helps', 'VBZ'), ('firms', 'NNS'), ('alerting', 'VBG')]

>> Noun Phrases are: 
 ['This analysis', 'firms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('analysis', 'analysi'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alert')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('analysis', 'analysi'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alert')]

>> Lemmatization: 
 [('This', 'This'), ('analysis', 'analysis'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alerting')]



========================================== PARAGRAPH 777 ===========================================

customers are dissatisfied or seeking to shift to other products, allowing  

------------------- Sentence 1 -------------------

customers are dissatisfied or seeking to shift to other products, allowing

>> Tokens are: 
 ['customers', 'dissatisfied', 'seeking', 'shift', 'products', ',', 'allowing']

>> Bigrams are: 
 [('customers', 'dissatisfied'), ('dissatisfied', 'seeking'), ('seeking', 'shift'), ('shift', 'products'), ('products', ','), (',', 'allowing')]

>> Trigrams are: 
 [('customers', 'dissatisfied', 'seeking'), ('dissatisfied', 'seeking', 'shift'), ('seeking', 'shift', 'products'), ('shift', 'products', ','), ('products', ',', 'allowing')]

>> POS Tags are: 
 [('customers', 'NNS'), ('dissatisfied', 'VBD'), ('seeking', 'VBG'), ('shift', 'NN'), ('products', 'NNS'), (',', ','), ('allowing', 'VBG')]

>> Noun Phrases are: 
 ['customers', 'shift products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('customers', 'custom'), ('dissatisfied', 'dissatisfi'), ('seeking', 'seek'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allow')]

>> Stemming using Snowball Stemmer: 
 [('customers', 'custom'), ('dissatisfied', 'dissatisfi'), ('seeking', 'seek'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allow')]

>> Lemmatization: 
 [('customers', 'customer'), ('dissatisfied', 'dissatisfied'), ('seeking', 'seeking'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allowing')]



========================================== PARAGRAPH 778 ===========================================

preventative actions to be taken (Elgendy, N. and Elragal, A., 2014).  

------------------- Sentence 1 -------------------

preventative actions to be taken (Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['preventative', 'actions', 'taken', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('preventative', 'actions'), ('actions', 'taken'), ('taken', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('preventative', 'actions', 'taken'), ('actions', 'taken', '('), ('taken', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('preventative', 'JJ'), ('actions', 'NNS'), ('taken', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['preventative actions', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('preventative', 'prevent'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('preventative', 'prevent'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('preventative', 'preventative'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 779 ===========================================

  


========================================== PARAGRAPH 780 ===========================================

• Audio analytics or speech analytics using technical approaches:  ➢ LVCSR: large-vocabulary continuous speech recognition, indexing and searching.  ➢ Phonetic-based systems: work with sounds or phonemes (Gandomi and Haider,  

------------------- Sentence 1 -------------------

• Audio analytics or speech analytics using technical approaches:  ➢ LVCSR: large-vocabulary continuous speech recognition, indexing and searching.

>> Tokens are: 
 ['•', 'Audio', 'analytics', 'speech', 'analytics', 'using', 'technical', 'approaches', ':', '➢', 'LVCSR', ':', 'large-vocabulary', 'continuous', 'speech', 'recognition', ',', 'indexing', 'searching', '.']

>> Bigrams are: 
 [('•', 'Audio'), ('Audio', 'analytics'), ('analytics', 'speech'), ('speech', 'analytics'), ('analytics', 'using'), ('using', 'technical'), ('technical', 'approaches'), ('approaches', ':'), (':', '➢'), ('➢', 'LVCSR'), ('LVCSR', ':'), (':', 'large-vocabulary'), ('large-vocabulary', 'continuous'), ('continuous', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'indexing'), ('indexing', 'searching'), ('searching', '.')]

>> Trigrams are: 
 [('•', 'Audio', 'analytics'), ('Audio', 'analytics', 'speech'), ('analytics', 'speech', 'analytics'), ('speech', 'analytics', 'using'), ('analytics', 'using', 'technical'), ('using', 'technical', 'approaches'), ('technical', 'approaches', ':'), ('approaches', ':', '➢'), (':', '➢', 'LVCSR'), ('➢', 'LVCSR', ':'), ('LVCSR', ':', 'large-vocabulary'), (':', 'large-vocabulary', 'continuous'), ('large-vocabulary', 'continuous', 'speech'), ('continuous', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'indexing'), (',', 'indexing', 'searching'), ('indexing', 'searching', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Audio', 'NNP'), ('analytics', 'NNS'), ('speech', 'VBP'), ('analytics', 'NNS'), ('using', 'VBG'), ('technical', 'JJ'), ('approaches', 'NNS'), (':', ':'), ('➢', 'JJ'), ('LVCSR', 'NNP'), (':', ':'), ('large-vocabulary', 'JJ'), ('continuous', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('indexing', 'VBG'), ('searching', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['• Audio analytics', 'analytics', 'technical approaches', '➢ LVCSR', 'large-vocabulary continuous speech recognition', 'searching']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Audio', 'audio'), ('analytics', 'analyt'), ('speech', 'speech'), ('analytics', 'analyt'), ('using', 'use'), ('technical', 'technic'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'lvcsr'), (':', ':'), ('large-vocabulary', 'large-vocabulari'), ('continuous', 'continu'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('indexing', 'index'), ('searching', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Audio', 'audio'), ('analytics', 'analyt'), ('speech', 'speech'), ('analytics', 'analyt'), ('using', 'use'), ('technical', 'technic'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'lvcsr'), (':', ':'), ('large-vocabulary', 'large-vocabulari'), ('continuous', 'continu'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('indexing', 'index'), ('searching', 'search'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Audio', 'Audio'), ('analytics', 'analytics'), ('speech', 'speech'), ('analytics', 'analytics'), ('using', 'using'), ('technical', 'technical'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'LVCSR'), (':', ':'), ('large-vocabulary', 'large-vocabulary'), ('continuous', 'continuous'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('indexing', 'indexing'), ('searching', 'searching'), ('.', '.')]


------------------- Sentence 2 -------------------

➢ Phonetic-based systems: work with sounds or phonemes (Gandomi and Haider,

>> Tokens are: 
 ['➢', 'Phonetic-based', 'systems', ':', 'work', 'sounds', 'phonemes', '(', 'Gandomi', 'Haider', ',']

>> Bigrams are: 
 [('➢', 'Phonetic-based'), ('Phonetic-based', 'systems'), ('systems', ':'), (':', 'work'), ('work', 'sounds'), ('sounds', 'phonemes'), ('phonemes', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ',')]

>> Trigrams are: 
 [('➢', 'Phonetic-based', 'systems'), ('Phonetic-based', 'systems', ':'), ('systems', ':', 'work'), (':', 'work', 'sounds'), ('work', 'sounds', 'phonemes'), ('sounds', 'phonemes', '('), ('phonemes', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ',')]

>> POS Tags are: 
 [('➢', 'JJ'), ('Phonetic-based', 'JJ'), ('systems', 'NNS'), (':', ':'), ('work', 'NN'), ('sounds', 'VBZ'), ('phonemes', 'NNS'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['➢ Phonetic-based systems', 'work', 'phonemes', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('Phonetic-based', 'phonetic-bas'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phonem'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('Phonetic-based', 'phonetic-bas'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phonem'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ',')]

>> Lemmatization: 
 [('➢', '➢'), ('Phonetic-based', 'Phonetic-based'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phoneme'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ',')]



========================================== PARAGRAPH 781 ===========================================

2015).  

------------------- Sentence 1 -------------------

2015).

>> Tokens are: 
 ['2015', ')', '.']

>> Bigrams are: 
 [('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('2015', ')', '.')]

>> POS Tags are: 
 [('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 782 ===========================================

  


========================================== PARAGRAPH 783 ===========================================

• Social media and social network analysis (SNA): Social media depends on multiple tools  and frameworks for collecting, monitoring, summarising, analysing, and visualising social  

------------------- Sentence 1 -------------------

• Social media and social network analysis (SNA): Social media depends on multiple tools  and frameworks for collecting, monitoring, summarising, analysing, and visualising social

>> Tokens are: 
 ['•', 'Social', 'media', 'social', 'network', 'analysis', '(', 'SNA', ')', ':', 'Social', 'media', 'depends', 'multiple', 'tools', 'frameworks', 'collecting', ',', 'monitoring', ',', 'summarising', ',', 'analysing', ',', 'visualising', 'social']

>> Bigrams are: 
 [('•', 'Social'), ('Social', 'media'), ('media', 'social'), ('social', 'network'), ('network', 'analysis'), ('analysis', '('), ('(', 'SNA'), ('SNA', ')'), (')', ':'), (':', 'Social'), ('Social', 'media'), ('media', 'depends'), ('depends', 'multiple'), ('multiple', 'tools'), ('tools', 'frameworks'), ('frameworks', 'collecting'), ('collecting', ','), (',', 'monitoring'), ('monitoring', ','), (',', 'summarising'), ('summarising', ','), (',', 'analysing'), ('analysing', ','), (',', 'visualising'), ('visualising', 'social')]

>> Trigrams are: 
 [('•', 'Social', 'media'), ('Social', 'media', 'social'), ('media', 'social', 'network'), ('social', 'network', 'analysis'), ('network', 'analysis', '('), ('analysis', '(', 'SNA'), ('(', 'SNA', ')'), ('SNA', ')', ':'), (')', ':', 'Social'), (':', 'Social', 'media'), ('Social', 'media', 'depends'), ('media', 'depends', 'multiple'), ('depends', 'multiple', 'tools'), ('multiple', 'tools', 'frameworks'), ('tools', 'frameworks', 'collecting'), ('frameworks', 'collecting', ','), ('collecting', ',', 'monitoring'), (',', 'monitoring', ','), ('monitoring', ',', 'summarising'), (',', 'summarising', ','), ('summarising', ',', 'analysing'), (',', 'analysing', ','), ('analysing', ',', 'visualising'), (',', 'visualising', 'social')]

>> POS Tags are: 
 [('•', 'JJ'), ('Social', 'NNP'), ('media', 'NNS'), ('social', 'JJ'), ('network', 'NN'), ('analysis', 'NN'), ('(', '('), ('SNA', 'NNP'), (')', ')'), (':', ':'), ('Social', 'JJ'), ('media', 'NNS'), ('depends', 'VBZ'), ('multiple', 'JJ'), ('tools', 'NNS'), ('frameworks', 'NNS'), ('collecting', 'VBG'), (',', ','), ('monitoring', 'NN'), (',', ','), ('summarising', 'VBG'), (',', ','), ('analysing', 'VBG'), (',', ','), ('visualising', 'VBG'), ('social', 'JJ')]

>> Noun Phrases are: 
 ['• Social media', 'social network analysis', 'SNA', 'Social media', 'multiple tools frameworks', 'monitoring']

>> Named Entities are: 
 [('ORGANIZATION', 'Social'), ('ORGANIZATION', 'SNA')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Social', 'social'), ('media', 'media'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('(', '('), ('SNA', 'sna'), (')', ')'), (':', ':'), ('Social', 'social'), ('media', 'media'), ('depends', 'depend'), ('multiple', 'multipl'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collect'), (',', ','), ('monitoring', 'monitor'), (',', ','), ('summarising', 'summaris'), (',', ','), ('analysing', 'analys'), (',', ','), ('visualising', 'visualis'), ('social', 'social')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Social', 'social'), ('media', 'media'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('(', '('), ('SNA', 'sna'), (')', ')'), (':', ':'), ('Social', 'social'), ('media', 'media'), ('depends', 'depend'), ('multiple', 'multipl'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collect'), (',', ','), ('monitoring', 'monitor'), (',', ','), ('summarising', 'summaris'), (',', ','), ('analysing', 'analys'), (',', ','), ('visualising', 'visualis'), ('social', 'social')]

>> Lemmatization: 
 [('•', '•'), ('Social', 'Social'), ('media', 'medium'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysis'), ('(', '('), ('SNA', 'SNA'), (')', ')'), (':', ':'), ('Social', 'Social'), ('media', 'medium'), ('depends', 'depends'), ('multiple', 'multiple'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collecting'), (',', ','), ('monitoring', 'monitoring'), (',', ','), ('summarising', 'summarising'), (',', ','), ('analysing', 'analysing'), (',', ','), ('visualising', 'visualising'), ('social', 'social')]



========================================== PARAGRAPH 784 ===========================================

media data, and SNA depends on social entities’ relationships with each other to measure  

------------------- Sentence 1 -------------------

media data, and SNA depends on social entities’ relationships with each other to measure

>> Tokens are: 
 ['media', 'data', ',', 'SNA', 'depends', 'social', 'entities', '’', 'relationships', 'measure']

>> Bigrams are: 
 [('media', 'data'), ('data', ','), (',', 'SNA'), ('SNA', 'depends'), ('depends', 'social'), ('social', 'entities'), ('entities', '’'), ('’', 'relationships'), ('relationships', 'measure')]

>> Trigrams are: 
 [('media', 'data', ','), ('data', ',', 'SNA'), (',', 'SNA', 'depends'), ('SNA', 'depends', 'social'), ('depends', 'social', 'entities'), ('social', 'entities', '’'), ('entities', '’', 'relationships'), ('’', 'relationships', 'measure')]

>> POS Tags are: 
 [('media', 'NNS'), ('data', 'NNS'), (',', ','), ('SNA', 'NNP'), ('depends', 'VBZ'), ('social', 'JJ'), ('entities', 'NNS'), ('’', 'VBP'), ('relationships', 'NNS'), ('measure', 'NN')]

>> Noun Phrases are: 
 ['media data', 'SNA', 'social entities', 'relationships measure']

>> Named Entities are: 
 [('ORGANIZATION', 'SNA')] 

>> Stemming using Porter Stemmer: 
 [('media', 'media'), ('data', 'data'), (',', ','), ('SNA', 'sna'), ('depends', 'depend'), ('social', 'social'), ('entities', 'entiti'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measur')]

>> Stemming using Snowball Stemmer: 
 [('media', 'media'), ('data', 'data'), (',', ','), ('SNA', 'sna'), ('depends', 'depend'), ('social', 'social'), ('entities', 'entiti'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measur')]

>> Lemmatization: 
 [('media', 'medium'), ('data', 'data'), (',', ','), ('SNA', 'SNA'), ('depends', 'depends'), ('social', 'social'), ('entities', 'entity'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measure')]



========================================== PARAGRAPH 785 ===========================================

the knowledge linking parties, including who shares information, what information, and  

------------------- Sentence 1 -------------------

the knowledge linking parties, including who shares information, what information, and

>> Tokens are: 
 ['knowledge', 'linking', 'parties', ',', 'including', 'shares', 'information', ',', 'information', ',']

>> Bigrams are: 
 [('knowledge', 'linking'), ('linking', 'parties'), ('parties', ','), (',', 'including'), ('including', 'shares'), ('shares', 'information'), ('information', ','), (',', 'information'), ('information', ',')]

>> Trigrams are: 
 [('knowledge', 'linking', 'parties'), ('linking', 'parties', ','), ('parties', ',', 'including'), (',', 'including', 'shares'), ('including', 'shares', 'information'), ('shares', 'information', ','), ('information', ',', 'information'), (',', 'information', ',')]

>> POS Tags are: 
 [('knowledge', 'NN'), ('linking', 'VBG'), ('parties', 'NNS'), (',', ','), ('including', 'VBG'), ('shares', 'NNS'), ('information', 'NN'), (',', ','), ('information', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['knowledge', 'parties', 'shares information', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('knowledge', 'knowledg'), ('linking', 'link'), ('parties', 'parti'), (',', ','), ('including', 'includ'), ('shares', 'share'), ('information', 'inform'), (',', ','), ('information', 'inform'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('knowledge', 'knowledg'), ('linking', 'link'), ('parties', 'parti'), (',', ','), ('including', 'includ'), ('shares', 'share'), ('information', 'inform'), (',', ','), ('information', 'inform'), (',', ',')]

>> Lemmatization: 
 [('knowledge', 'knowledge'), ('linking', 'linking'), ('parties', 'party'), (',', ','), ('including', 'including'), ('shares', 'share'), ('information', 'information'), (',', ','), ('information', 'information'), (',', ',')]



========================================== PARAGRAPH 786 ===========================================

with whom. SNA tries to get develop network patterns, while social media tries to uncover  

------------------- Sentence 1 -------------------

with whom.

>> Tokens are: 
 ['.']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('.', '.')]

>> Lemmatization: 
 [('.', '.')]


------------------- Sentence 2 -------------------

SNA tries to get develop network patterns, while social media tries to uncover

>> Tokens are: 
 ['SNA', 'tries', 'get', 'develop', 'network', 'patterns', ',', 'social', 'media', 'tries', 'uncover']

>> Bigrams are: 
 [('SNA', 'tries'), ('tries', 'get'), ('get', 'develop'), ('develop', 'network'), ('network', 'patterns'), ('patterns', ','), (',', 'social'), ('social', 'media'), ('media', 'tries'), ('tries', 'uncover')]

>> Trigrams are: 
 [('SNA', 'tries', 'get'), ('tries', 'get', 'develop'), ('get', 'develop', 'network'), ('develop', 'network', 'patterns'), ('network', 'patterns', ','), ('patterns', ',', 'social'), (',', 'social', 'media'), ('social', 'media', 'tries'), ('media', 'tries', 'uncover')]

>> POS Tags are: 
 [('SNA', 'NNP'), ('tries', 'VBZ'), ('get', 'VBP'), ('develop', 'VB'), ('network', 'NN'), ('patterns', 'NNS'), (',', ','), ('social', 'JJ'), ('media', 'NNS'), ('tries', 'NNS'), ('uncover', 'RB')]

>> Noun Phrases are: 
 ['SNA', 'network patterns', 'social media tries']

>> Named Entities are: 
 [('ORGANIZATION', 'SNA')] 

>> Stemming using Porter Stemmer: 
 [('SNA', 'sna'), ('tries', 'tri'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'media'), ('tries', 'tri'), ('uncover', 'uncov')]

>> Stemming using Snowball Stemmer: 
 [('SNA', 'sna'), ('tries', 'tri'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'media'), ('tries', 'tri'), ('uncover', 'uncov')]

>> Lemmatization: 
 [('SNA', 'SNA'), ('tries', 'try'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'medium'), ('tries', 'try'), ('uncover', 'uncover')]



========================================== PARAGRAPH 787 ===========================================

useful patterns and user information using text mining or sentiment analysis (Elgendy and  

------------------- Sentence 1 -------------------

useful patterns and user information using text mining or sentiment analysis (Elgendy and

>> Tokens are: 
 ['useful', 'patterns', 'user', 'information', 'using', 'text', 'mining', 'sentiment', 'analysis', '(', 'Elgendy']

>> Bigrams are: 
 [('useful', 'patterns'), ('patterns', 'user'), ('user', 'information'), ('information', 'using'), ('using', 'text'), ('text', 'mining'), ('mining', 'sentiment'), ('sentiment', 'analysis'), ('analysis', '('), ('(', 'Elgendy')]

>> Trigrams are: 
 [('useful', 'patterns', 'user'), ('patterns', 'user', 'information'), ('user', 'information', 'using'), ('information', 'using', 'text'), ('using', 'text', 'mining'), ('text', 'mining', 'sentiment'), ('mining', 'sentiment', 'analysis'), ('sentiment', 'analysis', '('), ('analysis', '(', 'Elgendy')]

>> POS Tags are: 
 [('useful', 'JJ'), ('patterns', 'NNS'), ('user', 'JJ'), ('information', 'NN'), ('using', 'VBG'), ('text', 'NN'), ('mining', 'NN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('(', '('), ('Elgendy', 'NNP')]

>> Noun Phrases are: 
 ['useful patterns', 'user information', 'text mining sentiment analysis', 'Elgendy']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('useful', 'use'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'inform'), ('using', 'use'), ('text', 'text'), ('mining', 'mine'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('(', '('), ('Elgendy', 'elgendi')]

>> Stemming using Snowball Stemmer: 
 [('useful', 'use'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'inform'), ('using', 'use'), ('text', 'text'), ('mining', 'mine'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('(', '('), ('Elgendy', 'elgendi')]

>> Lemmatization: 
 [('useful', 'useful'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'information'), ('using', 'using'), ('text', 'text'), ('mining', 'mining'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('(', '('), ('Elgendy', 'Elgendy')]



========================================== PARAGRAPH 788 ===========================================

Elragal, 2014; Gandomi and Haider, 2015).  

------------------- Sentence 1 -------------------

Elragal, 2014; Gandomi and Haider, 2015).

>> Tokens are: 
 ['Elragal', ',', '2014', ';', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Gandomi'), (';', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'Gandomi Haider']

>> Named Entities are: 
 [('GPE', 'Elragal'), ('PERSON', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 789 ===========================================

  


========================================== PARAGRAPH 790 ===========================================

• Data Visualisation: This can be used even by decision makers with little knowledge about  the data, as it presents the information visually prior to deep analysis. Advanced Data  

------------------- Sentence 1 -------------------

• Data Visualisation: This can be used even by decision makers with little knowledge about  the data, as it presents the information visually prior to deep analysis.

>> Tokens are: 
 ['•', 'Data', 'Visualisation', ':', 'This', 'used', 'even', 'decision', 'makers', 'little', 'knowledge', 'data', ',', 'presents', 'information', 'visually', 'prior', 'deep', 'analysis', '.']

>> Bigrams are: 
 [('•', 'Data'), ('Data', 'Visualisation'), ('Visualisation', ':'), (':', 'This'), ('This', 'used'), ('used', 'even'), ('even', 'decision'), ('decision', 'makers'), ('makers', 'little'), ('little', 'knowledge'), ('knowledge', 'data'), ('data', ','), (',', 'presents'), ('presents', 'information'), ('information', 'visually'), ('visually', 'prior'), ('prior', 'deep'), ('deep', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('•', 'Data', 'Visualisation'), ('Data', 'Visualisation', ':'), ('Visualisation', ':', 'This'), (':', 'This', 'used'), ('This', 'used', 'even'), ('used', 'even', 'decision'), ('even', 'decision', 'makers'), ('decision', 'makers', 'little'), ('makers', 'little', 'knowledge'), ('little', 'knowledge', 'data'), ('knowledge', 'data', ','), ('data', ',', 'presents'), (',', 'presents', 'information'), ('presents', 'information', 'visually'), ('information', 'visually', 'prior'), ('visually', 'prior', 'deep'), ('prior', 'deep', 'analysis'), ('deep', 'analysis', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('Data', 'NNP'), ('Visualisation', 'NN'), (':', ':'), ('This', 'DT'), ('used', 'VBD'), ('even', 'RB'), ('decision', 'NN'), ('makers', 'NNS'), ('little', 'JJ'), ('knowledge', 'NN'), ('data', 'NNS'), (',', ','), ('presents', 'NNS'), ('information', 'NN'), ('visually', 'RB'), ('prior', 'RB'), ('deep', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['• Data Visualisation', 'decision makers', 'little knowledge data', 'presents information', 'deep analysis']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Data', 'data'), ('Visualisation', 'visualis'), (':', ':'), ('This', 'thi'), ('used', 'use'), ('even', 'even'), ('decision', 'decis'), ('makers', 'maker'), ('little', 'littl'), ('knowledge', 'knowledg'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'inform'), ('visually', 'visual'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Data', 'data'), ('Visualisation', 'visualis'), (':', ':'), ('This', 'this'), ('used', 'use'), ('even', 'even'), ('decision', 'decis'), ('makers', 'maker'), ('little', 'littl'), ('knowledge', 'knowledg'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'inform'), ('visually', 'visual'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Data', 'Data'), ('Visualisation', 'Visualisation'), (':', ':'), ('This', 'This'), ('used', 'used'), ('even', 'even'), ('decision', 'decision'), ('makers', 'maker'), ('little', 'little'), ('knowledge', 'knowledge'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'information'), ('visually', 'visually'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Advanced Data

>> Tokens are: 
 ['Advanced', 'Data']

>> Bigrams are: 
 [('Advanced', 'Data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Advanced', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['Advanced Data']

>> Named Entities are: 
 [('PERSON', 'Advanced'), ('ORGANIZATION', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Advanced', 'advanc'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Advanced', 'advanc'), ('Data', 'data')]

>> Lemmatization: 
 [('Advanced', 'Advanced'), ('Data', 'Data')]



========================================== PARAGRAPH 791 ===========================================

visualisation (ADV) offers strong potential growth to big data analytics as it allows analysis  

------------------- Sentence 1 -------------------

visualisation (ADV) offers strong potential growth to big data analytics as it allows analysis

>> Tokens are: 
 ['visualisation', '(', 'ADV', ')', 'offers', 'strong', 'potential', 'growth', 'big', 'data', 'analytics', 'allows', 'analysis']

>> Bigrams are: 
 [('visualisation', '('), ('(', 'ADV'), ('ADV', ')'), (')', 'offers'), ('offers', 'strong'), ('strong', 'potential'), ('potential', 'growth'), ('growth', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'allows'), ('allows', 'analysis')]

>> Trigrams are: 
 [('visualisation', '(', 'ADV'), ('(', 'ADV', ')'), ('ADV', ')', 'offers'), (')', 'offers', 'strong'), ('offers', 'strong', 'potential'), ('strong', 'potential', 'growth'), ('potential', 'growth', 'big'), ('growth', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'allows'), ('analytics', 'allows', 'analysis')]

>> POS Tags are: 
 [('visualisation', 'NN'), ('(', '('), ('ADV', 'NNP'), (')', ')'), ('offers', 'VBZ'), ('strong', 'JJ'), ('potential', 'JJ'), ('growth', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('allows', 'NNS'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['visualisation', 'ADV', 'strong potential growth', 'big data analytics allows analysis']

>> Named Entities are: 
 [('ORGANIZATION', 'ADV')] 

>> Stemming using Porter Stemmer: 
 [('visualisation', 'visualis'), ('(', '('), ('ADV', 'adv'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potenti'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('allows', 'allow'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('visualisation', 'visualis'), ('(', '('), ('ADV', 'adv'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potenti'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('allows', 'allow'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('visualisation', 'visualisation'), ('(', '('), ('ADV', 'ADV'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potential'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('allows', 'allows'), ('analysis', 'analysis')]



========================================== PARAGRAPH 792 ===========================================

of data at several levels by taking advantage of human perceptual and reasoning abilities  

------------------- Sentence 1 -------------------

of data at several levels by taking advantage of human perceptual and reasoning abilities

>> Tokens are: 
 ['data', 'several', 'levels', 'taking', 'advantage', 'human', 'perceptual', 'reasoning', 'abilities']

>> Bigrams are: 
 [('data', 'several'), ('several', 'levels'), ('levels', 'taking'), ('taking', 'advantage'), ('advantage', 'human'), ('human', 'perceptual'), ('perceptual', 'reasoning'), ('reasoning', 'abilities')]

>> Trigrams are: 
 [('data', 'several', 'levels'), ('several', 'levels', 'taking'), ('levels', 'taking', 'advantage'), ('taking', 'advantage', 'human'), ('advantage', 'human', 'perceptual'), ('human', 'perceptual', 'reasoning'), ('perceptual', 'reasoning', 'abilities')]

>> POS Tags are: 
 [('data', 'NNS'), ('several', 'JJ'), ('levels', 'NNS'), ('taking', 'VBG'), ('advantage', 'NN'), ('human', 'JJ'), ('perceptual', 'JJ'), ('reasoning', 'NN'), ('abilities', 'NNS')]

>> Noun Phrases are: 
 ['data', 'several levels', 'advantage', 'human perceptual reasoning abilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('several', 'sever'), ('levels', 'level'), ('taking', 'take'), ('advantage', 'advantag'), ('human', 'human'), ('perceptual', 'perceptu'), ('reasoning', 'reason'), ('abilities', 'abil')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('several', 'sever'), ('levels', 'level'), ('taking', 'take'), ('advantage', 'advantag'), ('human', 'human'), ('perceptual', 'perceptu'), ('reasoning', 'reason'), ('abilities', 'abil')]

>> Lemmatization: 
 [('data', 'data'), ('several', 'several'), ('levels', 'level'), ('taking', 'taking'), ('advantage', 'advantage'), ('human', 'human'), ('perceptual', 'perceptual'), ('reasoning', 'reasoning'), ('abilities', 'ability')]



========================================== PARAGRAPH 793 ===========================================

(Manyika et al., 2011; Russom, 2011; Elragal, and Klischewski, 2017).   

------------------- Sentence 1 -------------------

(Manyika et al., 2011; Russom, 2011; Elragal, and Klischewski, 2017).

>> Tokens are: 
 ['(', 'Manyika', 'et', 'al.', ',', '2011', ';', 'Russom', ',', '2011', ';', 'Elragal', ',', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('(', 'Manyika'), ('Manyika', 'et'), ('et', 'al.'), ('al.', ','), (',', '2011'), ('2011', ';'), (';', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elragal'), ('Elragal', ','), (',', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Manyika', 'et'), ('Manyika', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Russom'), (';', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elragal'), (';', 'Elragal', ','), ('Elragal', ',', 'Klischewski'), (',', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Manyika', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2011', 'CD'), (';', ':'), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elragal', 'NNP'), (',', ','), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Manyika', 'Russom', 'Elragal', 'Klischewski']

>> Named Entities are: 
 [('PERSON', 'Manyika'), ('GPE', 'Russom'), ('GPE', 'Elragal'), ('GPE', 'Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Manyika', 'Manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'Elragal'), (',', ','), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 794 ===========================================

 


========================================== PARAGRAPH 795 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 796 ===========================================

28  

------------------- Sentence 1 -------------------

28

>> Tokens are: 
 ['28']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('28', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('28', '28')]

>> Stemming using Snowball Stemmer: 
 [('28', '28')]

>> Lemmatization: 
 [('28', '28')]



========================================== PARAGRAPH 797 ===========================================

  


========================================== PARAGRAPH 798 ===========================================

• Predictive analytics: This is based on statistical methods such as associative rules,  clustering, classification and decision trees, regression, and factor analysis (Fan et al.,  

------------------- Sentence 1 -------------------

• Predictive analytics: This is based on statistical methods such as associative rules,  clustering, classification and decision trees, regression, and factor analysis (Fan et al.,

>> Tokens are: 
 ['•', 'Predictive', 'analytics', ':', 'This', 'based', 'statistical', 'methods', 'associative', 'rules', ',', 'clustering', ',', 'classification', 'decision', 'trees', ',', 'regression', ',', 'factor', 'analysis', '(', 'Fan', 'et', 'al.', ',']

>> Bigrams are: 
 [('•', 'Predictive'), ('Predictive', 'analytics'), ('analytics', ':'), (':', 'This'), ('This', 'based'), ('based', 'statistical'), ('statistical', 'methods'), ('methods', 'associative'), ('associative', 'rules'), ('rules', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'regression'), ('regression', ','), (',', 'factor'), ('factor', 'analysis'), ('analysis', '('), ('(', 'Fan'), ('Fan', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('•', 'Predictive', 'analytics'), ('Predictive', 'analytics', ':'), ('analytics', ':', 'This'), (':', 'This', 'based'), ('This', 'based', 'statistical'), ('based', 'statistical', 'methods'), ('statistical', 'methods', 'associative'), ('methods', 'associative', 'rules'), ('associative', 'rules', ','), ('rules', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', 'decision'), ('classification', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'regression'), (',', 'regression', ','), ('regression', ',', 'factor'), (',', 'factor', 'analysis'), ('factor', 'analysis', '('), ('analysis', '(', 'Fan'), ('(', 'Fan', 'et'), ('Fan', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('•', 'RB'), ('Predictive', 'JJ'), ('analytics', 'NNS'), (':', ':'), ('This', 'DT'), ('based', 'VBN'), ('statistical', 'JJ'), ('methods', 'NNS'), ('associative', 'JJ'), ('rules', 'NNS'), (',', ','), ('clustering', 'VBG'), (',', ','), ('classification', 'NN'), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('regression', 'NN'), (',', ','), ('factor', 'NN'), ('analysis', 'NN'), ('(', '('), ('Fan', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['Predictive analytics', 'statistical methods', 'associative rules', 'classification decision trees', 'regression', 'factor analysis', 'Fan']

>> Named Entities are: 
 [('ORGANIZATION', 'Fan')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Predictive', 'predict'), ('analytics', 'analyt'), (':', ':'), ('This', 'thi'), ('based', 'base'), ('statistical', 'statist'), ('methods', 'method'), ('associative', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analysis', 'analysi'), ('(', '('), ('Fan', 'fan'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Predictive', 'predict'), ('analytics', 'analyt'), (':', ':'), ('This', 'this'), ('based', 'base'), ('statistical', 'statist'), ('methods', 'method'), ('associative', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analysis', 'analysi'), ('(', '('), ('Fan', 'fan'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('•', '•'), ('Predictive', 'Predictive'), ('analytics', 'analytics'), (':', ':'), ('This', 'This'), ('based', 'based'), ('statistical', 'statistical'), ('methods', 'method'), ('associative', 'associative'), ('rules', 'rule'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('regression', 'regression'), (',', ','), ('factor', 'factor'), ('analysis', 'analysis'), ('(', '('), ('Fan', 'Fan'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 799 ===========================================

2014; Bradlow et al., 2017; Breed and Verster, 2019).  

------------------- Sentence 1 -------------------

2014; Bradlow et al., 2017; Breed and Verster, 2019).

>> Tokens are: 
 ['2014', ';', 'Bradlow', 'et', 'al.', ',', '2017', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('2014', ';'), (';', 'Bradlow'), ('Bradlow', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ';', 'Bradlow'), (';', 'Bradlow', 'et'), ('Bradlow', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('Bradlow', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Bradlow', 'al.', 'Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Bradlow'), ('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('Bradlow', 'bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('Bradlow', 'bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('Bradlow', 'Bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 800 ===========================================

   


========================================== PARAGRAPH 801 ===========================================

  


========================================== PARAGRAPH 802 ===========================================

  


========================================== PARAGRAPH 803 ===========================================

  


========================================== PARAGRAPH 804 ===========================================

Figure 16: Common big data analytic methods.  

------------------- Sentence 1 -------------------

Figure 16: Common big data analytic methods.

>> Tokens are: 
 ['Figure', '16', ':', 'Common', 'big', 'data', 'analytic', 'methods', '.']

>> Bigrams are: 
 [('Figure', '16'), ('16', ':'), (':', 'Common'), ('Common', 'big'), ('big', 'data'), ('data', 'analytic'), ('analytic', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('Figure', '16', ':'), ('16', ':', 'Common'), (':', 'Common', 'big'), ('Common', 'big', 'data'), ('big', 'data', 'analytic'), ('data', 'analytic', 'methods'), ('analytic', 'methods', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('16', 'CD'), (':', ':'), ('Common', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'Common big data', 'analytic methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('16', '16'), (':', ':'), ('Common', 'common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('16', '16'), (':', ':'), ('Common', 'common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('16', '16'), (':', ':'), ('Common', 'Common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analytic'), ('methods', 'method'), ('.', '.')]



========================================== PARAGRAPH 805 ===========================================

  


========================================== PARAGRAPH 806 ===========================================

The other types of big data analytics used for systematic review are presented by Grover and Kar  

------------------- Sentence 1 -------------------

The other types of big data analytics used for systematic review are presented by Grover and Kar

>> Tokens are: 
 ['The', 'types', 'big', 'data', 'analytics', 'used', 'systematic', 'review', 'presented', 'Grover', 'Kar']

>> Bigrams are: 
 [('The', 'types'), ('types', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'systematic'), ('systematic', 'review'), ('review', 'presented'), ('presented', 'Grover'), ('Grover', 'Kar')]

>> Trigrams are: 
 [('The', 'types', 'big'), ('types', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'systematic'), ('used', 'systematic', 'review'), ('systematic', 'review', 'presented'), ('review', 'presented', 'Grover'), ('presented', 'Grover', 'Kar')]

>> POS Tags are: 
 [('The', 'DT'), ('types', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('systematic', 'JJ'), ('review', 'NN'), ('presented', 'VBD'), ('Grover', 'NNP'), ('Kar', 'NNP')]

>> Noun Phrases are: 
 ['The types', 'big data analytics', 'systematic review', 'Grover Kar']

>> Named Entities are: 
 [('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('systematic', 'systemat'), ('review', 'review'), ('presented', 'present'), ('Grover', 'grover'), ('Kar', 'kar')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('systematic', 'systemat'), ('review', 'review'), ('presented', 'present'), ('Grover', 'grover'), ('Kar', 'kar')]

>> Lemmatization: 
 [('The', 'The'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('systematic', 'systematic'), ('review', 'review'), ('presented', 'presented'), ('Grover', 'Grover'), ('Kar', 'Kar')]



========================================== PARAGRAPH 807 ===========================================

(2017), and these include descriptive analytics, diagnostic analytics, predictive analytics, and  

------------------- Sentence 1 -------------------

(2017), and these include descriptive analytics, diagnostic analytics, predictive analytics, and

>> Tokens are: 
 ['(', '2017', ')', ',', 'include', 'descriptive', 'analytics', ',', 'diagnostic', 'analytics', ',', 'predictive', 'analytics', ',']

>> Bigrams are: 
 [('(', '2017'), ('2017', ')'), (')', ','), (',', 'include'), ('include', 'descriptive'), ('descriptive', 'analytics'), ('analytics', ','), (',', 'diagnostic'), ('diagnostic', 'analytics'), ('analytics', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', ',')]

>> Trigrams are: 
 [('(', '2017', ')'), ('2017', ')', ','), (')', ',', 'include'), (',', 'include', 'descriptive'), ('include', 'descriptive', 'analytics'), ('descriptive', 'analytics', ','), ('analytics', ',', 'diagnostic'), (',', 'diagnostic', 'analytics'), ('diagnostic', 'analytics', ','), ('analytics', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', ',')]

>> POS Tags are: 
 [('(', '('), ('2017', 'CD'), (')', ')'), (',', ','), ('include', 'VBP'), ('descriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('diagnostic', 'JJ'), ('analytics', 'NNS'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['descriptive analytics', 'diagnostic analytics', 'predictive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'includ'), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'includ'), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'include'), ('descriptive', 'descriptive'), ('analytics', 'analytics'), (',', ','), ('diagnostic', 'diagnostic'), ('analytics', 'analytics'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ',')]



========================================== PARAGRAPH 808 ===========================================

prescriptive analytics, as shown in Figure 17.  

------------------- Sentence 1 -------------------

prescriptive analytics, as shown in Figure 17.

>> Tokens are: 
 ['prescriptive', 'analytics', ',', 'shown', 'Figure', '17', '.']

>> Bigrams are: 
 [('prescriptive', 'analytics'), ('analytics', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '17'), ('17', '.')]

>> Trigrams are: 
 [('prescriptive', 'analytics', ','), ('analytics', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '17'), ('Figure', '17', '.')]

>> POS Tags are: 
 [('prescriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('17', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['prescriptive analytics', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prescriptive', 'prescript'), ('analytics', 'analyt'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('prescriptive', 'prescript'), ('analytics', 'analyt'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('prescriptive', 'prescriptive'), ('analytics', 'analytics'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('17', '17'), ('.', '.')]



========================================== PARAGRAPH 809 ===========================================

Organisations and individual rend to use statistical models for predictive purposes, as most  

------------------- Sentence 1 -------------------

Organisations and individual rend to use statistical models for predictive purposes, as most

>> Tokens are: 
 ['Organisations', 'individual', 'rend', 'use', 'statistical', 'models', 'predictive', 'purposes', ',']

>> Bigrams are: 
 [('Organisations', 'individual'), ('individual', 'rend'), ('rend', 'use'), ('use', 'statistical'), ('statistical', 'models'), ('models', 'predictive'), ('predictive', 'purposes'), ('purposes', ',')]

>> Trigrams are: 
 [('Organisations', 'individual', 'rend'), ('individual', 'rend', 'use'), ('rend', 'use', 'statistical'), ('use', 'statistical', 'models'), ('statistical', 'models', 'predictive'), ('models', 'predictive', 'purposes'), ('predictive', 'purposes', ',')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('individual', 'JJ'), ('rend', 'VBP'), ('use', 'JJ'), ('statistical', 'JJ'), ('models', 'NNS'), ('predictive', 'JJ'), ('purposes', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Organisations', 'use statistical models', 'predictive purposes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('predictive', 'predict'), ('purposes', 'purpos'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('predictive', 'predict'), ('purposes', 'purpos'), (',', ',')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('individual', 'individual'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statistical'), ('models', 'model'), ('predictive', 'predictive'), ('purposes', 'purpose'), (',', ',')]



========================================== PARAGRAPH 810 ===========================================

predictive models are built with statistical criteria. Artificial intelligence modelling is also 

------------------- Sentence 1 -------------------

predictive models are built with statistical criteria.

>> Tokens are: 
 ['predictive', 'models', 'built', 'statistical', 'criteria', '.']

>> Bigrams are: 
 [('predictive', 'models'), ('models', 'built'), ('built', 'statistical'), ('statistical', 'criteria'), ('criteria', '.')]

>> Trigrams are: 
 [('predictive', 'models', 'built'), ('models', 'built', 'statistical'), ('built', 'statistical', 'criteria'), ('statistical', 'criteria', '.')]

>> POS Tags are: 
 [('predictive', 'JJ'), ('models', 'NNS'), ('built', 'VBN'), ('statistical', 'JJ'), ('criteria', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['predictive models', 'statistical criteria']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('predictive', 'predict'), ('models', 'model'), ('built', 'built'), ('statistical', 'statist'), ('criteria', 'criteria'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('predictive', 'predict'), ('models', 'model'), ('built', 'built'), ('statistical', 'statist'), ('criteria', 'criteria'), ('.', '.')]

>> Lemmatization: 
 [('predictive', 'predictive'), ('models', 'model'), ('built', 'built'), ('statistical', 'statistical'), ('criteria', 'criterion'), ('.', '.')]


------------------- Sentence 2 -------------------

Artificial intelligence modelling is also

>> Tokens are: 
 ['Artificial', 'intelligence', 'modelling', 'also']

>> Bigrams are: 
 [('Artificial', 'intelligence'), ('intelligence', 'modelling'), ('modelling', 'also')]

>> Trigrams are: 
 [('Artificial', 'intelligence', 'modelling'), ('intelligence', 'modelling', 'also')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('intelligence', 'NN'), ('modelling', 'NN'), ('also', 'RB')]

>> Noun Phrases are: 
 ['Artificial intelligence modelling']

>> Named Entities are: 
 [('GPE', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('also', 'also')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('modelling', 'modelling'), ('also', 'also')]



========================================== PARAGRAPH 811 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 812 ===========================================

29  

------------------- Sentence 1 -------------------

29

>> Tokens are: 
 ['29']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('29', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('29', '29')]

>> Stemming using Snowball Stemmer: 
 [('29', '29')]

>> Lemmatization: 
 [('29', '29')]



========================================== PARAGRAPH 813 ===========================================

  


========================================== PARAGRAPH 814 ===========================================

becoming more popular. Machine learning algorithms can combine statistical and artificial  

------------------- Sentence 1 -------------------

becoming more popular.

>> Tokens are: 
 ['becoming', 'popular', '.']

>> Bigrams are: 
 [('becoming', 'popular'), ('popular', '.')]

>> Trigrams are: 
 [('becoming', 'popular', '.')]

>> POS Tags are: 
 [('becoming', 'VBG'), ('popular', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('becoming', 'becom'), ('popular', 'popular'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('becoming', 'becom'), ('popular', 'popular'), ('.', '.')]

>> Lemmatization: 
 [('becoming', 'becoming'), ('popular', 'popular'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine learning algorithms can combine statistical and artificial

>> Tokens are: 
 ['Machine', 'learning', 'algorithms', 'combine', 'statistical', 'artificial']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'combine'), ('combine', 'statistical'), ('statistical', 'artificial')]

>> Trigrams are: 
 [('Machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'combine'), ('algorithms', 'combine', 'statistical'), ('combine', 'statistical', 'artificial')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('combine', 'JJ'), ('statistical', 'JJ'), ('artificial', 'NN')]

>> Noun Phrases are: 
 ['Machine', 'algorithms combine statistical artificial']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('combine', 'combin'), ('statistical', 'statist'), ('artificial', 'artifici')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('combine', 'combin'), ('statistical', 'statist'), ('artificial', 'artifici')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('combine', 'combine'), ('statistical', 'statistical'), ('artificial', 'artificial')]



========================================== PARAGRAPH 815 ===========================================

intelligence methods in order to analyse large amounts of data with high-performance (Watson,  

------------------- Sentence 1 -------------------

intelligence methods in order to analyse large amounts of data with high-performance (Watson,

>> Tokens are: 
 ['intelligence', 'methods', 'order', 'analyse', 'large', 'amounts', 'data', 'high-performance', '(', 'Watson', ',']

>> Bigrams are: 
 [('intelligence', 'methods'), ('methods', 'order'), ('order', 'analyse'), ('analyse', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', 'high-performance'), ('high-performance', '('), ('(', 'Watson'), ('Watson', ',')]

>> Trigrams are: 
 [('intelligence', 'methods', 'order'), ('methods', 'order', 'analyse'), ('order', 'analyse', 'large'), ('analyse', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', 'high-performance'), ('data', 'high-performance', '('), ('high-performance', '(', 'Watson'), ('(', 'Watson', ',')]

>> POS Tags are: 
 [('intelligence', 'NN'), ('methods', 'NNS'), ('order', 'NN'), ('analyse', 'VBP'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('high-performance', 'NN'), ('(', '('), ('Watson', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['intelligence methods order', 'large amounts data high-performance', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('intelligence', 'intellig'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analys'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('(', '('), ('Watson', 'watson'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('intelligence', 'intellig'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analys'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('(', '('), ('Watson', 'watson'), (',', ',')]

>> Lemmatization: 
 [('intelligence', 'intelligence'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analyse'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-performance'), ('(', '('), ('Watson', 'Watson'), (',', ',')]



========================================== PARAGRAPH 816 ===========================================

2019).  

------------------- Sentence 1 -------------------

2019).

>> Tokens are: 
 ['2019', ')', '.']

>> Bigrams are: 
 [('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2019', ')', '.')]

>> POS Tags are: 
 [('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 817 ===========================================

  


========================================== PARAGRAPH 818 ===========================================

  


========================================== PARAGRAPH 819 ===========================================

Figure 17: Other types of big data analytics2  

------------------- Sentence 1 -------------------

Figure 17: Other types of big data analytics2

>> Tokens are: 
 ['Figure', '17', ':', 'Other', 'types', 'big', 'data', 'analytics2']

>> Bigrams are: 
 [('Figure', '17'), ('17', ':'), (':', 'Other'), ('Other', 'types'), ('types', 'big'), ('big', 'data'), ('data', 'analytics2')]

>> Trigrams are: 
 [('Figure', '17', ':'), ('17', ':', 'Other'), (':', 'Other', 'types'), ('Other', 'types', 'big'), ('types', 'big', 'data'), ('big', 'data', 'analytics2')]

>> POS Tags are: 
 [('Figure', 'NN'), ('17', 'CD'), (':', ':'), ('Other', 'JJ'), ('types', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics2', 'NN')]

>> Noun Phrases are: 
 ['Figure', 'Other types', 'big data analytics2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('17', '17'), (':', ':'), ('Other', 'other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('17', '17'), (':', ':'), ('Other', 'other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('17', '17'), (':', ':'), ('Other', 'Other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2')]



========================================== PARAGRAPH 820 ===========================================

Descriptive analytics describes either what has happened or what is going to happen, while  

------------------- Sentence 1 -------------------

Descriptive analytics describes either what has happened or what is going to happen, while

>> Tokens are: 
 ['Descriptive', 'analytics', 'describes', 'either', 'happened', 'going', 'happen', ',']

>> Bigrams are: 
 [('Descriptive', 'analytics'), ('analytics', 'describes'), ('describes', 'either'), ('either', 'happened'), ('happened', 'going'), ('going', 'happen'), ('happen', ',')]

>> Trigrams are: 
 [('Descriptive', 'analytics', 'describes'), ('analytics', 'describes', 'either'), ('describes', 'either', 'happened'), ('either', 'happened', 'going'), ('happened', 'going', 'happen'), ('going', 'happen', ',')]

>> POS Tags are: 
 [('Descriptive', 'JJ'), ('analytics', 'NNS'), ('describes', 'VBP'), ('either', 'DT'), ('happened', 'VBD'), ('going', 'VBG'), ('happen', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Descriptive analytics', 'happen']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Descriptive', 'descript'), ('analytics', 'analyt'), ('describes', 'describ'), ('either', 'either'), ('happened', 'happen'), ('going', 'go'), ('happen', 'happen'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Descriptive', 'descript'), ('analytics', 'analyt'), ('describes', 'describ'), ('either', 'either'), ('happened', 'happen'), ('going', 'go'), ('happen', 'happen'), (',', ',')]

>> Lemmatization: 
 [('Descriptive', 'Descriptive'), ('analytics', 'analytics'), ('describes', 'describes'), ('either', 'either'), ('happened', 'happened'), ('going', 'going'), ('happen', 'happen'), (',', ',')]



========================================== PARAGRAPH 821 ===========================================

diagnostic analytics estimates the reason for something having happened, which requires  

------------------- Sentence 1 -------------------

diagnostic analytics estimates the reason for something having happened, which requires

>> Tokens are: 
 ['diagnostic', 'analytics', 'estimates', 'reason', 'something', 'happened', ',', 'requires']

>> Bigrams are: 
 [('diagnostic', 'analytics'), ('analytics', 'estimates'), ('estimates', 'reason'), ('reason', 'something'), ('something', 'happened'), ('happened', ','), (',', 'requires')]

>> Trigrams are: 
 [('diagnostic', 'analytics', 'estimates'), ('analytics', 'estimates', 'reason'), ('estimates', 'reason', 'something'), ('reason', 'something', 'happened'), ('something', 'happened', ','), ('happened', ',', 'requires')]

>> POS Tags are: 
 [('diagnostic', 'JJ'), ('analytics', 'NNS'), ('estimates', 'NNS'), ('reason', 'NN'), ('something', 'NN'), ('happened', 'VBD'), (',', ','), ('requires', 'VBZ')]

>> Noun Phrases are: 
 ['diagnostic analytics estimates reason something']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('estimates', 'estim'), ('reason', 'reason'), ('something', 'someth'), ('happened', 'happen'), (',', ','), ('requires', 'requir')]

>> Stemming using Snowball Stemmer: 
 [('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('estimates', 'estim'), ('reason', 'reason'), ('something', 'someth'), ('happened', 'happen'), (',', ','), ('requires', 'requir')]

>> Lemmatization: 
 [('diagnostic', 'diagnostic'), ('analytics', 'analytics'), ('estimates', 'estimate'), ('reason', 'reason'), ('something', 'something'), ('happened', 'happened'), (',', ','), ('requires', 'requires')]



========================================== PARAGRAPH 822 ===========================================

techniques for discovering a problem’s root causes. Predictive analytics attempts to determine the  

------------------- Sentence 1 -------------------

techniques for discovering a problem’s root causes.

>> Tokens are: 
 ['techniques', 'discovering', 'problem', '’', 'root', 'causes', '.']

>> Bigrams are: 
 [('techniques', 'discovering'), ('discovering', 'problem'), ('problem', '’'), ('’', 'root'), ('root', 'causes'), ('causes', '.')]

>> Trigrams are: 
 [('techniques', 'discovering', 'problem'), ('discovering', 'problem', '’'), ('problem', '’', 'root'), ('’', 'root', 'causes'), ('root', 'causes', '.')]

>> POS Tags are: 
 [('techniques', 'NNS'), ('discovering', 'VBG'), ('problem', 'NN'), ('’', 'NN'), ('root', 'NN'), ('causes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques', 'problem ’ root causes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('discovering', 'discov'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'caus'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('discovering', 'discov'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'caus'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), ('discovering', 'discovering'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'cause'), ('.', '.')]


------------------- Sentence 2 -------------------

Predictive analytics attempts to determine the

>> Tokens are: 
 ['Predictive', 'analytics', 'attempts', 'determine']

>> Bigrams are: 
 [('Predictive', 'analytics'), ('analytics', 'attempts'), ('attempts', 'determine')]

>> Trigrams are: 
 [('Predictive', 'analytics', 'attempts'), ('analytics', 'attempts', 'determine')]

>> POS Tags are: 
 [('Predictive', 'JJ'), ('analytics', 'NNS'), ('attempts', 'NNS'), ('determine', 'VBP')]

>> Noun Phrases are: 
 ['Predictive analytics attempts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('attempts', 'attempt'), ('determine', 'determin')]

>> Stemming using Snowball Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('attempts', 'attempt'), ('determine', 'determin')]

>> Lemmatization: 
 [('Predictive', 'Predictive'), ('analytics', 'analytics'), ('attempts', 'attempt'), ('determine', 'determine')]



========================================== PARAGRAPH 823 ===========================================

most likely future outcomes by applying statistical models (Waller and Fawcett, 2013), while  

------------------- Sentence 1 -------------------

most likely future outcomes by applying statistical models (Waller and Fawcett, 2013), while

>> Tokens are: 
 ['likely', 'future', 'outcomes', 'applying', 'statistical', 'models', '(', 'Waller', 'Fawcett', ',', '2013', ')', ',']

>> Bigrams are: 
 [('likely', 'future'), ('future', 'outcomes'), ('outcomes', 'applying'), ('applying', 'statistical'), ('statistical', 'models'), ('models', '('), ('(', 'Waller'), ('Waller', 'Fawcett'), ('Fawcett', ','), (',', '2013'), ('2013', ')'), (')', ',')]

>> Trigrams are: 
 [('likely', 'future', 'outcomes'), ('future', 'outcomes', 'applying'), ('outcomes', 'applying', 'statistical'), ('applying', 'statistical', 'models'), ('statistical', 'models', '('), ('models', '(', 'Waller'), ('(', 'Waller', 'Fawcett'), ('Waller', 'Fawcett', ','), ('Fawcett', ',', '2013'), (',', '2013', ')'), ('2013', ')', ',')]

>> POS Tags are: 
 [('likely', 'JJ'), ('future', 'NN'), ('outcomes', 'VBZ'), ('applying', 'VBG'), ('statistical', 'JJ'), ('models', 'NNS'), ('(', '('), ('Waller', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['likely future', 'statistical models', 'Waller Fawcett']

>> Named Entities are: 
 [('PERSON', 'Waller Fawcett')] 

>> Stemming using Porter Stemmer: 
 [('likely', 'like'), ('future', 'futur'), ('outcomes', 'outcom'), ('applying', 'appli'), ('statistical', 'statist'), ('models', 'model'), ('(', '('), ('Waller', 'waller'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('likely', 'like'), ('future', 'futur'), ('outcomes', 'outcom'), ('applying', 'appli'), ('statistical', 'statist'), ('models', 'model'), ('(', '('), ('Waller', 'waller'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('likely', 'likely'), ('future', 'future'), ('outcomes', 'outcome'), ('applying', 'applying'), ('statistical', 'statistical'), ('models', 'model'), ('(', '('), ('Waller', 'Waller'), ('Fawcett', 'Fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 824 ===========================================

prescriptive analytics explains and predicts the future and describes outcomes using tools such as   

------------------- Sentence 1 -------------------

prescriptive analytics explains and predicts the future and describes outcomes using tools such as

>> Tokens are: 
 ['prescriptive', 'analytics', 'explains', 'predicts', 'future', 'describes', 'outcomes', 'using', 'tools']

>> Bigrams are: 
 [('prescriptive', 'analytics'), ('analytics', 'explains'), ('explains', 'predicts'), ('predicts', 'future'), ('future', 'describes'), ('describes', 'outcomes'), ('outcomes', 'using'), ('using', 'tools')]

>> Trigrams are: 
 [('prescriptive', 'analytics', 'explains'), ('analytics', 'explains', 'predicts'), ('explains', 'predicts', 'future'), ('predicts', 'future', 'describes'), ('future', 'describes', 'outcomes'), ('describes', 'outcomes', 'using'), ('outcomes', 'using', 'tools')]

>> POS Tags are: 
 [('prescriptive', 'JJ'), ('analytics', 'NNS'), ('explains', 'VBZ'), ('predicts', 'NNS'), ('future', 'JJ'), ('describes', 'NNS'), ('outcomes', 'NNS'), ('using', 'VBG'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['prescriptive analytics', 'predicts', 'future describes outcomes', 'tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prescriptive', 'prescript'), ('analytics', 'analyt'), ('explains', 'explain'), ('predicts', 'predict'), ('future', 'futur'), ('describes', 'describ'), ('outcomes', 'outcom'), ('using', 'use'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('prescriptive', 'prescript'), ('analytics', 'analyt'), ('explains', 'explain'), ('predicts', 'predict'), ('future', 'futur'), ('describes', 'describ'), ('outcomes', 'outcom'), ('using', 'use'), ('tools', 'tool')]

>> Lemmatization: 
 [('prescriptive', 'prescriptive'), ('analytics', 'analytics'), ('explains', 'explains'), ('predicts', 'predicts'), ('future', 'future'), ('describes', 'describes'), ('outcomes', 'outcome'), ('using', 'using'), ('tools', 'tool')]



========================================== PARAGRAPH 825 ===========================================

optimisation, simulation, business rules, algorithms, and machine learning (Banerjee et al., 2013;  

------------------- Sentence 1 -------------------

optimisation, simulation, business rules, algorithms, and machine learning (Banerjee et al., 2013;

>> Tokens are: 
 ['optimisation', ',', 'simulation', ',', 'business', 'rules', ',', 'algorithms', ',', 'machine', 'learning', '(', 'Banerjee', 'et', 'al.', ',', '2013', ';']

>> Bigrams are: 
 [('optimisation', ','), (',', 'simulation'), ('simulation', ','), (',', 'business'), ('business', 'rules'), ('rules', ','), (',', 'algorithms'), ('algorithms', ','), (',', 'machine'), ('machine', 'learning'), ('learning', '('), ('(', 'Banerjee'), ('Banerjee', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';')]

>> Trigrams are: 
 [('optimisation', ',', 'simulation'), (',', 'simulation', ','), ('simulation', ',', 'business'), (',', 'business', 'rules'), ('business', 'rules', ','), ('rules', ',', 'algorithms'), (',', 'algorithms', ','), ('algorithms', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', '('), ('learning', '(', 'Banerjee'), ('(', 'Banerjee', 'et'), ('Banerjee', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';')]

>> POS Tags are: 
 [('optimisation', 'NN'), (',', ','), ('simulation', 'NN'), (',', ','), ('business', 'NN'), ('rules', 'NNS'), (',', ','), ('algorithms', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('(', '('), ('Banerjee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['optimisation', 'simulation', 'business rules', 'algorithms', 'machine learning', 'Banerjee']

>> Named Entities are: 
 [('ORGANIZATION', 'Banerjee')] 

>> Stemming using Porter Stemmer: 
 [('optimisation', 'optimis'), (',', ','), ('simulation', 'simul'), (',', ','), ('business', 'busi'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('optimisation', 'optimis'), (',', ','), ('simulation', 'simul'), (',', ','), ('business', 'busi'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';')]

>> Lemmatization: 
 [('optimisation', 'optimisation'), (',', ','), ('simulation', 'simulation'), (',', ','), ('business', 'business'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('(', '('), ('Banerjee', 'Banerjee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';')]



========================================== PARAGRAPH 826 ===========================================

Grover and Kar, 2017).   

------------------- Sentence 1 -------------------

Grover and Kar, 2017).

>> Tokens are: 
 ['Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Grover Kar']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 827 ===========================================

                                                  2 Based on (Grover and Kar, 2017) 

------------------- Sentence 1 -------------------

                                                  2 Based on (Grover and Kar, 2017)

>> Tokens are: 
 ['2', 'Based', '(', 'Grover', 'Kar', ',', '2017', ')']

>> Bigrams are: 
 [('2', 'Based'), ('Based', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')')]

>> Trigrams are: 
 [('2', 'Based', '('), ('Based', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')')]

>> POS Tags are: 
 [('2', 'CD'), ('Based', 'VBN'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('Based', 'base'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('Based', 'base'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')')]

>> Lemmatization: 
 [('2', '2'), ('Based', 'Based'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')')]



========================================== PARAGRAPH 828 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 829 ===========================================

30  

------------------- Sentence 1 -------------------

30

>> Tokens are: 
 ['30']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('30', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('30', '30')]

>> Stemming using Snowball Stemmer: 
 [('30', '30')]

>> Lemmatization: 
 [('30', '30')]



========================================== PARAGRAPH 830 ===========================================

  


========================================== PARAGRAPH 831 ===========================================

The distribution of the research studies selected for systematic review across industry domains and  

------------------- Sentence 1 -------------------

The distribution of the research studies selected for systematic review across industry domains and

>> Tokens are: 
 ['The', 'distribution', 'research', 'studies', 'selected', 'systematic', 'review', 'across', 'industry', 'domains']

>> Bigrams are: 
 [('The', 'distribution'), ('distribution', 'research'), ('research', 'studies'), ('studies', 'selected'), ('selected', 'systematic'), ('systematic', 'review'), ('review', 'across'), ('across', 'industry'), ('industry', 'domains')]

>> Trigrams are: 
 [('The', 'distribution', 'research'), ('distribution', 'research', 'studies'), ('research', 'studies', 'selected'), ('studies', 'selected', 'systematic'), ('selected', 'systematic', 'review'), ('systematic', 'review', 'across'), ('review', 'across', 'industry'), ('across', 'industry', 'domains')]

>> POS Tags are: 
 [('The', 'DT'), ('distribution', 'NN'), ('research', 'NN'), ('studies', 'NNS'), ('selected', 'VBN'), ('systematic', 'JJ'), ('review', 'NN'), ('across', 'IN'), ('industry', 'NN'), ('domains', 'NNS')]

>> Noun Phrases are: 
 ['The distribution research studies', 'systematic review', 'industry domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain')]

>> Lemmatization: 
 [('The', 'The'), ('distribution', 'distribution'), ('research', 'research'), ('studies', 'study'), ('selected', 'selected'), ('systematic', 'systematic'), ('review', 'review'), ('across', 'across'), ('industry', 'industry'), ('domains', 'domain')]



========================================== PARAGRAPH 832 ===========================================

analytic types in terms of big data analytics is shown in Figure 18.  

------------------- Sentence 1 -------------------

analytic types in terms of big data analytics is shown in Figure 18.

>> Tokens are: 
 ['analytic', 'types', 'terms', 'big', 'data', 'analytics', 'shown', 'Figure', '18', '.']

>> Bigrams are: 
 [('analytic', 'types'), ('types', 'terms'), ('terms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'shown'), ('shown', 'Figure'), ('Figure', '18'), ('18', '.')]

>> Trigrams are: 
 [('analytic', 'types', 'terms'), ('types', 'terms', 'big'), ('terms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'shown'), ('analytics', 'shown', 'Figure'), ('shown', 'Figure', '18'), ('Figure', '18', '.')]

>> POS Tags are: 
 [('analytic', 'JJ'), ('types', 'NNS'), ('terms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('shown', 'VBN'), ('Figure', 'NNP'), ('18', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['analytic types terms', 'big data analytics', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytic', 'analyt'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shown', 'shown'), ('Figure', 'figur'), ('18', '18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytic', 'analyt'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shown', 'shown'), ('Figure', 'figur'), ('18', '18'), ('.', '.')]

>> Lemmatization: 
 [('analytic', 'analytic'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('shown', 'shown'), ('Figure', 'Figure'), ('18', '18'), ('.', '.')]



========================================== PARAGRAPH 833 ===========================================

  


========================================== PARAGRAPH 834 ===========================================

  


========================================== PARAGRAPH 835 ===========================================

Figure 18: Distribution of research studies selected for systematic review across industry  

------------------- Sentence 1 -------------------

Figure 18: Distribution of research studies selected for systematic review across industry

>> Tokens are: 
 ['Figure', '18', ':', 'Distribution', 'research', 'studies', 'selected', 'systematic', 'review', 'across', 'industry']

>> Bigrams are: 
 [('Figure', '18'), ('18', ':'), (':', 'Distribution'), ('Distribution', 'research'), ('research', 'studies'), ('studies', 'selected'), ('selected', 'systematic'), ('systematic', 'review'), ('review', 'across'), ('across', 'industry')]

>> Trigrams are: 
 [('Figure', '18', ':'), ('18', ':', 'Distribution'), (':', 'Distribution', 'research'), ('Distribution', 'research', 'studies'), ('research', 'studies', 'selected'), ('studies', 'selected', 'systematic'), ('selected', 'systematic', 'review'), ('systematic', 'review', 'across'), ('review', 'across', 'industry')]

>> POS Tags are: 
 [('Figure', 'NN'), ('18', 'CD'), (':', ':'), ('Distribution', 'NN'), ('research', 'NN'), ('studies', 'NNS'), ('selected', 'VBN'), ('systematic', 'JJ'), ('review', 'NN'), ('across', 'IN'), ('industry', 'NN')]

>> Noun Phrases are: 
 ['Figure', 'Distribution research studies', 'systematic review', 'industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('18', '18'), (':', ':'), ('Distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('18', '18'), (':', ':'), ('Distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('18', '18'), (':', ':'), ('Distribution', 'Distribution'), ('research', 'research'), ('studies', 'study'), ('selected', 'selected'), ('systematic', 'systematic'), ('review', 'review'), ('across', 'across'), ('industry', 'industry')]



========================================== PARAGRAPH 836 ===========================================

domains and analytics types, adopted from (Grover and Kar, 2017)  

------------------- Sentence 1 -------------------

domains and analytics types, adopted from (Grover and Kar, 2017)

>> Tokens are: 
 ['domains', 'analytics', 'types', ',', 'adopted', '(', 'Grover', 'Kar', ',', '2017', ')']

>> Bigrams are: 
 [('domains', 'analytics'), ('analytics', 'types'), ('types', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')')]

>> Trigrams are: 
 [('domains', 'analytics', 'types'), ('analytics', 'types', ','), ('types', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')')]

>> POS Tags are: 
 [('domains', 'NNS'), ('analytics', 'NNS'), ('types', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['domains analytics types', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('domains', 'domain'), ('analytics', 'analyt'), ('types', 'type'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('domains', 'domain'), ('analytics', 'analyt'), ('types', 'type'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')')]

>> Lemmatization: 
 [('domains', 'domain'), ('analytics', 'analytics'), ('types', 'type'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')')]



========================================== PARAGRAPH 837 ===========================================

7.5. Big data platforms and tools  

------------------- Sentence 1 -------------------

7.5.

>> Tokens are: 
 ['7.5', '.']

>> Bigrams are: 
 [('7.5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.5', '7.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.5', '7.5'), ('.', '.')]

>> Lemmatization: 
 [('7.5', '7.5'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data platforms and tools

>> Tokens are: 
 ['Big', 'data', 'platforms', 'tools']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'platforms'), ('platforms', 'tools')]

>> Trigrams are: 
 [('Big', 'data', 'platforms'), ('data', 'platforms', 'tools')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['Big data platforms tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool')]



========================================== PARAGRAPH 838 ===========================================

There are now multiple big data analytics tools and the study done by Oussous et al. (2018) showed  

------------------- Sentence 1 -------------------

There are now multiple big data analytics tools and the study done by Oussous et al.

>> Tokens are: 
 ['There', 'multiple', 'big', 'data', 'analytics', 'tools', 'study', 'done', 'Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('There', 'multiple'), ('multiple', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'study'), ('study', 'done'), ('done', 'Oussous'), ('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('There', 'multiple', 'big'), ('multiple', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'study'), ('tools', 'study', 'done'), ('study', 'done', 'Oussous'), ('done', 'Oussous', 'et'), ('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('multiple', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('study', 'VBP'), ('done', 'VBN'), ('Oussous', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multiple big data analytics tools', 'Oussous', 'al']

>> Named Entities are: 
 [('PERSON', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('multiple', 'multipl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('study', 'studi'), ('done', 'done'), ('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('multiple', 'multipl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('study', 'studi'), ('done', 'done'), ('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('multiple', 'multiple'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('study', 'study'), ('done', 'done'), ('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018) showed

>> Tokens are: 
 ['(', '2018', ')', 'showed']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'showed')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'showed')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('showed', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'show')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'show')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'showed')]



========================================== PARAGRAPH 839 ===========================================

the importance of carefully choosing the right tool for the circumstances. The choice is dependent  

------------------- Sentence 1 -------------------

the importance of carefully choosing the right tool for the circumstances.

>> Tokens are: 
 ['importance', 'carefully', 'choosing', 'right', 'tool', 'circumstances', '.']

>> Bigrams are: 
 [('importance', 'carefully'), ('carefully', 'choosing'), ('choosing', 'right'), ('right', 'tool'), ('tool', 'circumstances'), ('circumstances', '.')]

>> Trigrams are: 
 [('importance', 'carefully', 'choosing'), ('carefully', 'choosing', 'right'), ('choosing', 'right', 'tool'), ('right', 'tool', 'circumstances'), ('tool', 'circumstances', '.')]

>> POS Tags are: 
 [('importance', 'NN'), ('carefully', 'RB'), ('choosing', 'VBG'), ('right', 'JJ'), ('tool', 'NN'), ('circumstances', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['importance', 'right tool circumstances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('importance', 'import'), ('carefully', 'care'), ('choosing', 'choos'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('importance', 'import'), ('carefully', 'care'), ('choosing', 'choos'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumst'), ('.', '.')]

>> Lemmatization: 
 [('importance', 'importance'), ('carefully', 'carefully'), ('choosing', 'choosing'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumstance'), ('.', '.')]


------------------- Sentence 2 -------------------

The choice is dependent

>> Tokens are: 
 ['The', 'choice', 'dependent']

>> Bigrams are: 
 [('The', 'choice'), ('choice', 'dependent')]

>> Trigrams are: 
 [('The', 'choice', 'dependent')]

>> POS Tags are: 
 [('The', 'DT'), ('choice', 'NN'), ('dependent', 'NN')]

>> Noun Phrases are: 
 ['The choice dependent']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('dependent', 'depend')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('dependent', 'depend')]

>> Lemmatization: 
 [('The', 'The'), ('choice', 'choice'), ('dependent', 'dependent')]



========================================== PARAGRAPH 840 ===========================================

on the “nature of datasets (i.e.-, volumes, streams, distribution), the complexity of analytical  

------------------- Sentence 1 -------------------

on the “nature of datasets (i.e.-, volumes, streams, distribution), the complexity of analytical

>> Tokens are: 
 ['“', 'nature', 'datasets', '(', 'i.e.-', ',', 'volumes', ',', 'streams', ',', 'distribution', ')', ',', 'complexity', 'analytical']

>> Bigrams are: 
 [('“', 'nature'), ('nature', 'datasets'), ('datasets', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'volumes'), ('volumes', ','), (',', 'streams'), ('streams', ','), (',', 'distribution'), ('distribution', ')'), (')', ','), (',', 'complexity'), ('complexity', 'analytical')]

>> Trigrams are: 
 [('“', 'nature', 'datasets'), ('nature', 'datasets', '('), ('datasets', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'volumes'), (',', 'volumes', ','), ('volumes', ',', 'streams'), (',', 'streams', ','), ('streams', ',', 'distribution'), (',', 'distribution', ')'), ('distribution', ')', ','), (')', ',', 'complexity'), (',', 'complexity', 'analytical')]

>> POS Tags are: 
 [('“', 'JJ'), ('nature', 'NN'), ('datasets', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('volumes', 'NNS'), (',', ','), ('streams', 'NNS'), (',', ','), ('distribution', 'NN'), (')', ')'), (',', ','), ('complexity', 'NN'), ('analytical', 'JJ')]

>> Noun Phrases are: 
 ['“ nature datasets', 'volumes', 'streams', 'distribution', 'complexity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('nature', 'natur'), ('datasets', 'dataset'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volum'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribut'), (')', ')'), (',', ','), ('complexity', 'complex'), ('analytical', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('nature', 'natur'), ('datasets', 'dataset'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volum'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribut'), (')', ')'), (',', ','), ('complexity', 'complex'), ('analytical', 'analyt')]

>> Lemmatization: 
 [('“', '“'), ('nature', 'nature'), ('datasets', 'datasets'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volume'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribution'), (')', ')'), (',', ','), ('complexity', 'complexity'), ('analytical', 'analytical')]



========================================== PARAGRAPH 841 ===========================================

problems, algorithms and analytical solutions used, systems capabilities, security and privacy  

------------------- Sentence 1 -------------------

problems, algorithms and analytical solutions used, systems capabilities, security and privacy

>> Tokens are: 
 ['problems', ',', 'algorithms', 'analytical', 'solutions', 'used', ',', 'systems', 'capabilities', ',', 'security', 'privacy']

>> Bigrams are: 
 [('problems', ','), (',', 'algorithms'), ('algorithms', 'analytical'), ('analytical', 'solutions'), ('solutions', 'used'), ('used', ','), (',', 'systems'), ('systems', 'capabilities'), ('capabilities', ','), (',', 'security'), ('security', 'privacy')]

>> Trigrams are: 
 [('problems', ',', 'algorithms'), (',', 'algorithms', 'analytical'), ('algorithms', 'analytical', 'solutions'), ('analytical', 'solutions', 'used'), ('solutions', 'used', ','), ('used', ',', 'systems'), (',', 'systems', 'capabilities'), ('systems', 'capabilities', ','), ('capabilities', ',', 'security'), (',', 'security', 'privacy')]

>> POS Tags are: 
 [('problems', 'NNS'), (',', ','), ('algorithms', 'RB'), ('analytical', 'JJ'), ('solutions', 'NNS'), ('used', 'VBN'), (',', ','), ('systems', 'NNS'), ('capabilities', 'NNS'), (',', ','), ('security', 'NN'), ('privacy', 'NN')]

>> Noun Phrases are: 
 ['problems', 'analytical solutions', 'systems capabilities', 'security privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analyt'), ('solutions', 'solut'), ('used', 'use'), (',', ','), ('systems', 'system'), ('capabilities', 'capabl'), (',', ','), ('security', 'secur'), ('privacy', 'privaci')]

>> Stemming using Snowball Stemmer: 
 [('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analyt'), ('solutions', 'solut'), ('used', 'use'), (',', ','), ('systems', 'system'), ('capabilities', 'capabl'), (',', ','), ('security', 'secur'), ('privacy', 'privaci')]

>> Lemmatization: 
 [('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analytical'), ('solutions', 'solution'), ('used', 'used'), (',', ','), ('systems', 'system'), ('capabilities', 'capability'), (',', ','), ('security', 'security'), ('privacy', 'privacy')]



========================================== PARAGRAPH 842 ===========================================

issues, the required performance and scalability in addition to the available budget” (ibid). Some  

------------------- Sentence 1 -------------------

issues, the required performance and scalability in addition to the available budget” (ibid).

>> Tokens are: 
 ['issues', ',', 'required', 'performance', 'scalability', 'addition', 'available', 'budget', '”', '(', 'ibid', ')', '.']

>> Bigrams are: 
 [('issues', ','), (',', 'required'), ('required', 'performance'), ('performance', 'scalability'), ('scalability', 'addition'), ('addition', 'available'), ('available', 'budget'), ('budget', '”'), ('”', '('), ('(', 'ibid'), ('ibid', ')'), (')', '.')]

>> Trigrams are: 
 [('issues', ',', 'required'), (',', 'required', 'performance'), ('required', 'performance', 'scalability'), ('performance', 'scalability', 'addition'), ('scalability', 'addition', 'available'), ('addition', 'available', 'budget'), ('available', 'budget', '”'), ('budget', '”', '('), ('”', '(', 'ibid'), ('(', 'ibid', ')'), ('ibid', ')', '.')]

>> POS Tags are: 
 [('issues', 'NNS'), (',', ','), ('required', 'VBN'), ('performance', 'NN'), ('scalability', 'NN'), ('addition', 'NN'), ('available', 'JJ'), ('budget', 'NN'), ('”', 'NN'), ('(', '('), ('ibid', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['issues', 'performance scalability addition', 'available budget ”', 'ibid']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('issues', 'issu'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('scalability', 'scalabl'), ('addition', 'addit'), ('available', 'avail'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('issues', 'issu'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('scalability', 'scalabl'), ('addition', 'addit'), ('available', 'avail'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('issues', 'issue'), (',', ','), ('required', 'required'), ('performance', 'performance'), ('scalability', 'scalability'), ('addition', 'addition'), ('available', 'available'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Some

>> Tokens are: 
 ['Some']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Some', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some')]

>> Lemmatization: 
 [('Some', 'Some')]



========================================== PARAGRAPH 843 ===========================================

of big data platforms and tools are shown in Figure 20.  

------------------- Sentence 1 -------------------

of big data platforms and tools are shown in Figure 20.

>> Tokens are: 
 ['big', 'data', 'platforms', 'tools', 'shown', 'Figure', '20', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', 'shown'), ('shown', 'Figure'), ('Figure', '20'), ('20', '.')]

>> Trigrams are: 
 [('big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', 'shown'), ('tools', 'shown', 'Figure'), ('shown', 'Figure', '20'), ('Figure', '20', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'VBP'), ('shown', 'VBN'), ('Figure', 'NNP'), ('20', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['big data platforms', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'figur'), ('20', '20'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'figur'), ('20', '20'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'Figure'), ('20', '20'), ('.', '.')]



========================================== PARAGRAPH 844 ===========================================

• Apache Mahout:  This is an open source machine learning software library that can be  used for executing algorithms via MapReduce, a framework for processing large datasets  

------------------- Sentence 1 -------------------

• Apache Mahout:  This is an open source machine learning software library that can be  used for executing algorithms via MapReduce, a framework for processing large datasets

>> Tokens are: 
 ['•', 'Apache', 'Mahout', ':', 'This', 'open', 'source', 'machine', 'learning', 'software', 'library', 'used', 'executing', 'algorithms', 'via', 'MapReduce', ',', 'framework', 'processing', 'large', 'datasets']

>> Bigrams are: 
 [('•', 'Apache'), ('Apache', 'Mahout'), ('Mahout', ':'), (':', 'This'), ('This', 'open'), ('open', 'source'), ('source', 'machine'), ('machine', 'learning'), ('learning', 'software'), ('software', 'library'), ('library', 'used'), ('used', 'executing'), ('executing', 'algorithms'), ('algorithms', 'via'), ('via', 'MapReduce'), ('MapReduce', ','), (',', 'framework'), ('framework', 'processing'), ('processing', 'large'), ('large', 'datasets')]

>> Trigrams are: 
 [('•', 'Apache', 'Mahout'), ('Apache', 'Mahout', ':'), ('Mahout', ':', 'This'), (':', 'This', 'open'), ('This', 'open', 'source'), ('open', 'source', 'machine'), ('source', 'machine', 'learning'), ('machine', 'learning', 'software'), ('learning', 'software', 'library'), ('software', 'library', 'used'), ('library', 'used', 'executing'), ('used', 'executing', 'algorithms'), ('executing', 'algorithms', 'via'), ('algorithms', 'via', 'MapReduce'), ('via', 'MapReduce', ','), ('MapReduce', ',', 'framework'), (',', 'framework', 'processing'), ('framework', 'processing', 'large'), ('processing', 'large', 'datasets')]

>> POS Tags are: 
 [('•', 'JJ'), ('Apache', 'NNP'), ('Mahout', 'NN'), (':', ':'), ('This', 'DT'), ('open', 'JJ'), ('source', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('software', 'NN'), ('library', 'NN'), ('used', 'VBD'), ('executing', 'VBG'), ('algorithms', 'JJ'), ('via', 'IN'), ('MapReduce', 'NNP'), (',', ','), ('framework', 'NN'), ('processing', 'VBG'), ('large', 'JJ'), ('datasets', 'NNS')]

>> Noun Phrases are: 
 ['• Apache Mahout', 'This open source machine', 'software library', 'MapReduce', 'framework', 'large datasets']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Apache', 'apach'), ('Mahout', 'mahout'), (':', ':'), ('This', 'thi'), ('open', 'open'), ('source', 'sourc'), ('machine', 'machin'), ('learning', 'learn'), ('software', 'softwar'), ('library', 'librari'), ('used', 'use'), ('executing', 'execut'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'mapreduc'), (',', ','), ('framework', 'framework'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Apache', 'apach'), ('Mahout', 'mahout'), (':', ':'), ('This', 'this'), ('open', 'open'), ('source', 'sourc'), ('machine', 'machin'), ('learning', 'learn'), ('software', 'softwar'), ('library', 'librari'), ('used', 'use'), ('executing', 'execut'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'mapreduc'), (',', ','), ('framework', 'framework'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset')]

>> Lemmatization: 
 [('•', '•'), ('Apache', 'Apache'), ('Mahout', 'Mahout'), (':', ':'), ('This', 'This'), ('open', 'open'), ('source', 'source'), ('machine', 'machine'), ('learning', 'learning'), ('software', 'software'), ('library', 'library'), ('used', 'used'), ('executing', 'executing'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'MapReduce'), (',', ','), ('framework', 'framework'), ('processing', 'processing'), ('large', 'large'), ('datasets', 'datasets')]



========================================== PARAGRAPH 845 ===========================================

(Eldawy and Mokbel, 2015). Mahout encompasses several Java libraries, ensuring  

------------------- Sentence 1 -------------------

(Eldawy and Mokbel, 2015).

>> Tokens are: 
 ['(', 'Eldawy', 'Mokbel', ',', '2015', ')', '.']

>> Bigrams are: 
 [('(', 'Eldawy'), ('Eldawy', 'Mokbel'), ('Mokbel', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Eldawy', 'Mokbel'), ('Eldawy', 'Mokbel', ','), ('Mokbel', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Eldawy', 'NNP'), ('Mokbel', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Eldawy Mokbel']

>> Named Entities are: 
 [('ORGANIZATION', 'Eldawy Mokbel')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Eldawy', 'eldawi'), ('Mokbel', 'mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Eldawy', 'eldawi'), ('Mokbel', 'mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Eldawy', 'Eldawy'), ('Mokbel', 'Mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Mahout encompasses several Java libraries, ensuring

>> Tokens are: 
 ['Mahout', 'encompasses', 'several', 'Java', 'libraries', ',', 'ensuring']

>> Bigrams are: 
 [('Mahout', 'encompasses'), ('encompasses', 'several'), ('several', 'Java'), ('Java', 'libraries'), ('libraries', ','), (',', 'ensuring')]

>> Trigrams are: 
 [('Mahout', 'encompasses', 'several'), ('encompasses', 'several', 'Java'), ('several', 'Java', 'libraries'), ('Java', 'libraries', ','), ('libraries', ',', 'ensuring')]

>> POS Tags are: 
 [('Mahout', 'NNP'), ('encompasses', 'VBZ'), ('several', 'JJ'), ('Java', 'NNP'), ('libraries', 'NNS'), (',', ','), ('ensuring', 'VBG')]

>> Noun Phrases are: 
 ['Mahout', 'several Java libraries']

>> Named Entities are: 
 [('GPE', 'Mahout')] 

>> Stemming using Porter Stemmer: 
 [('Mahout', 'mahout'), ('encompasses', 'encompass'), ('several', 'sever'), ('Java', 'java'), ('libraries', 'librari'), (',', ','), ('ensuring', 'ensur')]

>> Stemming using Snowball Stemmer: 
 [('Mahout', 'mahout'), ('encompasses', 'encompass'), ('several', 'sever'), ('Java', 'java'), ('libraries', 'librari'), (',', ','), ('ensuring', 'ensur')]

>> Lemmatization: 
 [('Mahout', 'Mahout'), ('encompasses', 'encompasses'), ('several', 'several'), ('Java', 'Java'), ('libraries', 'library'), (',', ','), ('ensuring', 'ensuring')]



========================================== PARAGRAPH 846 ===========================================

efficiency of processing large datasets by allowing application of large-scale machine  

------------------- Sentence 1 -------------------

efficiency of processing large datasets by allowing application of large-scale machine

>> Tokens are: 
 ['efficiency', 'processing', 'large', 'datasets', 'allowing', 'application', 'large-scale', 'machine']

>> Bigrams are: 
 [('efficiency', 'processing'), ('processing', 'large'), ('large', 'datasets'), ('datasets', 'allowing'), ('allowing', 'application'), ('application', 'large-scale'), ('large-scale', 'machine')]

>> Trigrams are: 
 [('efficiency', 'processing', 'large'), ('processing', 'large', 'datasets'), ('large', 'datasets', 'allowing'), ('datasets', 'allowing', 'application'), ('allowing', 'application', 'large-scale'), ('application', 'large-scale', 'machine')]

>> POS Tags are: 
 [('efficiency', 'NN'), ('processing', 'VBG'), ('large', 'JJ'), ('datasets', 'NNS'), ('allowing', 'VBG'), ('application', 'NN'), ('large-scale', 'JJ'), ('machine', 'NN')]

>> Noun Phrases are: 
 ['efficiency', 'large datasets', 'application', 'large-scale machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('efficiency', 'effici'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('allowing', 'allow'), ('application', 'applic'), ('large-scale', 'large-scal'), ('machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('efficiency', 'effici'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('allowing', 'allow'), ('application', 'applic'), ('large-scale', 'large-scal'), ('machine', 'machin')]

>> Lemmatization: 
 [('efficiency', 'efficiency'), ('processing', 'processing'), ('large', 'large'), ('datasets', 'datasets'), ('allowing', 'allowing'), ('application', 'application'), ('large-scale', 'large-scale'), ('machine', 'machine')]



========================================== PARAGRAPH 847 ===========================================

learning applications and algorithms. It provides an optimised algorithm in which Mahout  

------------------- Sentence 1 -------------------

learning applications and algorithms.

>> Tokens are: 
 ['learning', 'applications', 'algorithms', '.']

>> Bigrams are: 
 [('learning', 'applications'), ('applications', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('learning', 'applications', 'algorithms'), ('applications', 'algorithms', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('applications', 'NNS'), ('algorithms', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('applications', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('applications', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('applications', 'application'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

It provides an optimised algorithm in which Mahout

>> Tokens are: 
 ['It', 'provides', 'optimised', 'algorithm', 'Mahout']

>> Bigrams are: 
 [('It', 'provides'), ('provides', 'optimised'), ('optimised', 'algorithm'), ('algorithm', 'Mahout')]

>> Trigrams are: 
 [('It', 'provides', 'optimised'), ('provides', 'optimised', 'algorithm'), ('optimised', 'algorithm', 'Mahout')]

>> POS Tags are: 
 [('It', 'PRP'), ('provides', 'VBZ'), ('optimised', 'JJ'), ('algorithm', 'NN'), ('Mahout', 'NN')]

>> Noun Phrases are: 
 ['optimised algorithm Mahout']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('optimised', 'optimis'), ('algorithm', 'algorithm'), ('Mahout', 'mahout')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('optimised', 'optimis'), ('algorithm', 'algorithm'), ('Mahout', 'mahout')]

>> Lemmatization: 
 [('It', 'It'), ('provides', 'provides'), ('optimised', 'optimised'), ('algorithm', 'algorithm'), ('Mahout', 'Mahout')]



========================================== PARAGRAPH 848 ===========================================

converts machine learning tasks presented in Java into MapReduce jobs (Acharjya et al.,  

------------------- Sentence 1 -------------------

converts machine learning tasks presented in Java into MapReduce jobs (Acharjya et al.,

>> Tokens are: 
 ['converts', 'machine', 'learning', 'tasks', 'presented', 'Java', 'MapReduce', 'jobs', '(', 'Acharjya', 'et', 'al.', ',']

>> Bigrams are: 
 [('converts', 'machine'), ('machine', 'learning'), ('learning', 'tasks'), ('tasks', 'presented'), ('presented', 'Java'), ('Java', 'MapReduce'), ('MapReduce', 'jobs'), ('jobs', '('), ('(', 'Acharjya'), ('Acharjya', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('converts', 'machine', 'learning'), ('machine', 'learning', 'tasks'), ('learning', 'tasks', 'presented'), ('tasks', 'presented', 'Java'), ('presented', 'Java', 'MapReduce'), ('Java', 'MapReduce', 'jobs'), ('MapReduce', 'jobs', '('), ('jobs', '(', 'Acharjya'), ('(', 'Acharjya', 'et'), ('Acharjya', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('converts', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('tasks', 'NNS'), ('presented', 'VBN'), ('Java', 'NNP'), ('MapReduce', 'NNP'), ('jobs', 'NNS'), ('(', '('), ('Acharjya', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['converts machine', 'tasks', 'Java MapReduce jobs', 'Acharjya']

>> Named Entities are: 
 [('PERSON', 'Java MapReduce'), ('ORGANIZATION', 'Acharjya')] 

>> Stemming using Porter Stemmer: 
 [('converts', 'convert'), ('machine', 'machin'), ('learning', 'learn'), ('tasks', 'task'), ('presented', 'present'), ('Java', 'java'), ('MapReduce', 'mapreduc'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('converts', 'convert'), ('machine', 'machin'), ('learning', 'learn'), ('tasks', 'task'), ('presented', 'present'), ('Java', 'java'), ('MapReduce', 'mapreduc'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('converts', 'convert'), ('machine', 'machine'), ('learning', 'learning'), ('tasks', 'task'), ('presented', 'presented'), ('Java', 'Java'), ('MapReduce', 'MapReduce'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'Acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 849 ===========================================

2016).  

------------------- Sentence 1 -------------------

2016).

>> Tokens are: 
 ['2016', ')', '.']

>> Bigrams are: 
 [('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 850 ===========================================

  


========================================== PARAGRAPH 851 ===========================================

• R: This is a programming language often used for big data analysis, which offers relatively  easy solutions to performing advanced analysis on large data sets via Hadoop. As compared  

------------------- Sentence 1 -------------------

• R: This is a programming language often used for big data analysis, which offers relatively  easy solutions to performing advanced analysis on large data sets via Hadoop.

>> Tokens are: 
 ['•', 'R', ':', 'This', 'programming', 'language', 'often', 'used', 'big', 'data', 'analysis', ',', 'offers', 'relatively', 'easy', 'solutions', 'performing', 'advanced', 'analysis', 'large', 'data', 'sets', 'via', 'Hadoop', '.']

>> Bigrams are: 
 [('•', 'R'), ('R', ':'), (':', 'This'), ('This', 'programming'), ('programming', 'language'), ('language', 'often'), ('often', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'offers'), ('offers', 'relatively'), ('relatively', 'easy'), ('easy', 'solutions'), ('solutions', 'performing'), ('performing', 'advanced'), ('advanced', 'analysis'), ('analysis', 'large'), ('large', 'data'), ('data', 'sets'), ('sets', 'via'), ('via', 'Hadoop'), ('Hadoop', '.')]

>> Trigrams are: 
 [('•', 'R', ':'), ('R', ':', 'This'), (':', 'This', 'programming'), ('This', 'programming', 'language'), ('programming', 'language', 'often'), ('language', 'often', 'used'), ('often', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'offers'), (',', 'offers', 'relatively'), ('offers', 'relatively', 'easy'), ('relatively', 'easy', 'solutions'), ('easy', 'solutions', 'performing'), ('solutions', 'performing', 'advanced'), ('performing', 'advanced', 'analysis'), ('advanced', 'analysis', 'large'), ('analysis', 'large', 'data'), ('large', 'data', 'sets'), ('data', 'sets', 'via'), ('sets', 'via', 'Hadoop'), ('via', 'Hadoop', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('R', 'NN'), (':', ':'), ('This', 'DT'), ('programming', 'NN'), ('language', 'NN'), ('often', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('offers', 'VBZ'), ('relatively', 'RB'), ('easy', 'JJ'), ('solutions', 'NNS'), ('performing', 'VBG'), ('advanced', 'JJ'), ('analysis', 'NN'), ('large', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('via', 'IN'), ('Hadoop', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['• R', 'This programming language', 'big data analysis', 'easy solutions', 'advanced analysis', 'large data sets', 'Hadoop']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('R', 'r'), (':', ':'), ('This', 'thi'), ('programming', 'program'), ('language', 'languag'), ('often', 'often'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('offers', 'offer'), ('relatively', 'rel'), ('easy', 'easi'), ('solutions', 'solut'), ('performing', 'perform'), ('advanced', 'advanc'), ('analysis', 'analysi'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('R', 'r'), (':', ':'), ('This', 'this'), ('programming', 'program'), ('language', 'languag'), ('often', 'often'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('offers', 'offer'), ('relatively', 'relat'), ('easy', 'easi'), ('solutions', 'solut'), ('performing', 'perform'), ('advanced', 'advanc'), ('analysis', 'analysi'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('R', 'R'), (':', ':'), ('This', 'This'), ('programming', 'programming'), ('language', 'language'), ('often', 'often'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('offers', 'offer'), ('relatively', 'relatively'), ('easy', 'easy'), ('solutions', 'solution'), ('performing', 'performing'), ('advanced', 'advanced'), ('analysis', 'analysis'), ('large', 'large'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'Hadoop'), ('.', '.')]


------------------- Sentence 2 -------------------

As compared

>> Tokens are: 
 ['As', 'compared']

>> Bigrams are: 
 [('As', 'compared')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('As', 'IN'), ('compared', 'VBN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('compared', 'compar')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('compared', 'compar')]

>> Lemmatization: 
 [('As', 'As'), ('compared', 'compared')]



========================================== PARAGRAPH 852 ===========================================

to Mahout, in term of types and algorithms, R provides a more complete set of classification  

------------------- Sentence 1 -------------------

to Mahout, in term of types and algorithms, R provides a more complete set of classification

>> Tokens are: 
 ['Mahout', ',', 'term', 'types', 'algorithms', ',', 'R', 'provides', 'complete', 'set', 'classification']

>> Bigrams are: 
 [('Mahout', ','), (',', 'term'), ('term', 'types'), ('types', 'algorithms'), ('algorithms', ','), (',', 'R'), ('R', 'provides'), ('provides', 'complete'), ('complete', 'set'), ('set', 'classification')]

>> Trigrams are: 
 [('Mahout', ',', 'term'), (',', 'term', 'types'), ('term', 'types', 'algorithms'), ('types', 'algorithms', ','), ('algorithms', ',', 'R'), (',', 'R', 'provides'), ('R', 'provides', 'complete'), ('provides', 'complete', 'set'), ('complete', 'set', 'classification')]

>> POS Tags are: 
 [('Mahout', 'NNP'), (',', ','), ('term', 'NN'), ('types', 'NNS'), ('algorithms', 'VBP'), (',', ','), ('R', 'NNP'), ('provides', 'VBZ'), ('complete', 'JJ'), ('set', 'VBN'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['Mahout', 'term types', 'R', 'classification']

>> Named Entities are: 
 [('GPE', 'Mahout'), ('ORGANIZATION', 'R')] 

>> Stemming using Porter Stemmer: 
 [('Mahout', 'mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('provides', 'provid'), ('complete', 'complet'), ('set', 'set'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('Mahout', 'mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('provides', 'provid'), ('complete', 'complet'), ('set', 'set'), ('classification', 'classif')]

>> Lemmatization: 
 [('Mahout', 'Mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'R'), ('provides', 'provides'), ('complete', 'complete'), ('set', 'set'), ('classification', 'classification')]



========================================== PARAGRAPH 853 ===========================================

models; however, it is limited by its nature as an object-oriented programming language,  

------------------- Sentence 1 -------------------

models; however, it is limited by its nature as an object-oriented programming language,

>> Tokens are: 
 ['models', ';', 'however', ',', 'limited', 'nature', 'object-oriented', 'programming', 'language', ',']

>> Bigrams are: 
 [('models', ';'), (';', 'however'), ('however', ','), (',', 'limited'), ('limited', 'nature'), ('nature', 'object-oriented'), ('object-oriented', 'programming'), ('programming', 'language'), ('language', ',')]

>> Trigrams are: 
 [('models', ';', 'however'), (';', 'however', ','), ('however', ',', 'limited'), (',', 'limited', 'nature'), ('limited', 'nature', 'object-oriented'), ('nature', 'object-oriented', 'programming'), ('object-oriented', 'programming', 'language'), ('programming', 'language', ',')]

>> POS Tags are: 
 [('models', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('limited', 'JJ'), ('nature', 'NN'), ('object-oriented', 'JJ'), ('programming', 'NN'), ('language', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['models', 'limited nature', 'object-oriented programming language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('models', 'model'), (';', ';'), ('however', 'howev'), (',', ','), ('limited', 'limit'), ('nature', 'natur'), ('object-oriented', 'object-ori'), ('programming', 'program'), ('language', 'languag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('models', 'model'), (';', ';'), ('however', 'howev'), (',', ','), ('limited', 'limit'), ('nature', 'natur'), ('object-oriented', 'object-ori'), ('programming', 'program'), ('language', 'languag'), (',', ',')]

>> Lemmatization: 
 [('models', 'model'), (';', ';'), ('however', 'however'), (',', ','), ('limited', 'limited'), ('nature', 'nature'), ('object-oriented', 'object-oriented'), ('programming', 'programming'), ('language', 'language'), (',', ',')]



========================================== PARAGRAPH 854 ===========================================

which can cause problems with memory management compared to other solutions. In many 

------------------- Sentence 1 -------------------

which can cause problems with memory management compared to other solutions.

>> Tokens are: 
 ['cause', 'problems', 'memory', 'management', 'compared', 'solutions', '.']

>> Bigrams are: 
 [('cause', 'problems'), ('problems', 'memory'), ('memory', 'management'), ('management', 'compared'), ('compared', 'solutions'), ('solutions', '.')]

>> Trigrams are: 
 [('cause', 'problems', 'memory'), ('problems', 'memory', 'management'), ('memory', 'management', 'compared'), ('management', 'compared', 'solutions'), ('compared', 'solutions', '.')]

>> POS Tags are: 
 [('cause', 'NN'), ('problems', 'NNS'), ('memory', 'JJ'), ('management', 'NN'), ('compared', 'VBN'), ('solutions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['cause problems', 'memory management', 'solutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cause', 'caus'), ('problems', 'problem'), ('memory', 'memori'), ('management', 'manag'), ('compared', 'compar'), ('solutions', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cause', 'caus'), ('problems', 'problem'), ('memory', 'memori'), ('management', 'manag'), ('compared', 'compar'), ('solutions', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('cause', 'cause'), ('problems', 'problem'), ('memory', 'memory'), ('management', 'management'), ('compared', 'compared'), ('solutions', 'solution'), ('.', '.')]


------------------- Sentence 2 -------------------

In many

>> Tokens are: 
 ['In', 'many']

>> Bigrams are: 
 [('In', 'many')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('many', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('many', 'mani')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('many', 'mani')]

>> Lemmatization: 
 [('In', 'In'), ('many', 'many')]



========================================== PARAGRAPH 855 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 856 ===========================================

31  

------------------- Sentence 1 -------------------

31

>> Tokens are: 
 ['31']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('31', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('31', '31')]

>> Stemming using Snowball Stemmer: 
 [('31', '31')]

>> Lemmatization: 
 [('31', '31')]



========================================== PARAGRAPH 857 ===========================================

  


========================================== PARAGRAPH 858 ===========================================

cases, use in combination with Mahout is thus recommended (Team, R.C., 2000), as R can  

------------------- Sentence 1 -------------------

cases, use in combination with Mahout is thus recommended (Team, R.C., 2000), as R can

>> Tokens are: 
 ['cases', ',', 'use', 'combination', 'Mahout', 'thus', 'recommended', '(', 'Team', ',', 'R.C.', ',', '2000', ')', ',', 'R']

>> Bigrams are: 
 [('cases', ','), (',', 'use'), ('use', 'combination'), ('combination', 'Mahout'), ('Mahout', 'thus'), ('thus', 'recommended'), ('recommended', '('), ('(', 'Team'), ('Team', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2000'), ('2000', ')'), (')', ','), (',', 'R')]

>> Trigrams are: 
 [('cases', ',', 'use'), (',', 'use', 'combination'), ('use', 'combination', 'Mahout'), ('combination', 'Mahout', 'thus'), ('Mahout', 'thus', 'recommended'), ('thus', 'recommended', '('), ('recommended', '(', 'Team'), ('(', 'Team', ','), ('Team', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2000'), (',', '2000', ')'), ('2000', ')', ','), (')', ',', 'R')]

>> POS Tags are: 
 [('cases', 'NNS'), (',', ','), ('use', 'NN'), ('combination', 'NN'), ('Mahout', 'NNP'), ('thus', 'RB'), ('recommended', 'VBD'), ('(', '('), ('Team', 'NNP'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2000', 'CD'), (')', ')'), (',', ','), ('R', 'NNP')]

>> Noun Phrases are: 
 ['cases', 'use combination Mahout', 'Team', 'R.C.', 'R']

>> Named Entities are: 
 [('PERSON', 'Mahout'), ('ORGANIZATION', 'Team')] 

>> Stemming using Porter Stemmer: 
 [('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combin'), ('Mahout', 'mahout'), ('thus', 'thu'), ('recommended', 'recommend'), ('(', '('), ('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'r')]

>> Stemming using Snowball Stemmer: 
 [('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combin'), ('Mahout', 'mahout'), ('thus', 'thus'), ('recommended', 'recommend'), ('(', '('), ('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'r')]

>> Lemmatization: 
 [('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combination'), ('Mahout', 'Mahout'), ('thus', 'thus'), ('recommended', 'recommended'), ('(', '('), ('Team', 'Team'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'R')]



========================================== PARAGRAPH 859 ===========================================

be used to execute small data exploration while Hadoop/Jaql executes the larger operations.  

------------------- Sentence 1 -------------------

be used to execute small data exploration while Hadoop/Jaql executes the larger operations.

>> Tokens are: 
 ['used', 'execute', 'small', 'data', 'exploration', 'Hadoop/Jaql', 'executes', 'larger', 'operations', '.']

>> Bigrams are: 
 [('used', 'execute'), ('execute', 'small'), ('small', 'data'), ('data', 'exploration'), ('exploration', 'Hadoop/Jaql'), ('Hadoop/Jaql', 'executes'), ('executes', 'larger'), ('larger', 'operations'), ('operations', '.')]

>> Trigrams are: 
 [('used', 'execute', 'small'), ('execute', 'small', 'data'), ('small', 'data', 'exploration'), ('data', 'exploration', 'Hadoop/Jaql'), ('exploration', 'Hadoop/Jaql', 'executes'), ('Hadoop/Jaql', 'executes', 'larger'), ('executes', 'larger', 'operations'), ('larger', 'operations', '.')]

>> POS Tags are: 
 [('used', 'VBN'), ('execute', 'VB'), ('small', 'JJ'), ('data', 'NNS'), ('exploration', 'NN'), ('Hadoop/Jaql', 'NNP'), ('executes', 'VBZ'), ('larger', 'JJR'), ('operations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['small data exploration Hadoop/Jaql', 'operations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('execute', 'execut'), ('small', 'small'), ('data', 'data'), ('exploration', 'explor'), ('Hadoop/Jaql', 'hadoop/jaql'), ('executes', 'execut'), ('larger', 'larger'), ('operations', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('execute', 'execut'), ('small', 'small'), ('data', 'data'), ('exploration', 'explor'), ('Hadoop/Jaql', 'hadoop/jaql'), ('executes', 'execut'), ('larger', 'larger'), ('operations', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('used', 'used'), ('execute', 'execute'), ('small', 'small'), ('data', 'data'), ('exploration', 'exploration'), ('Hadoop/Jaql', 'Hadoop/Jaql'), ('executes', 'executes'), ('larger', 'larger'), ('operations', 'operation'), ('.', '.')]



========================================== PARAGRAPH 860 ===========================================

  


========================================== PARAGRAPH 861 ===========================================

• Alteryx: This tool offers data blending and an advanced analytics platform where analysts  can merge internal business processes, third-party tools, and cloud data centres. Also, it  

------------------- Sentence 1 -------------------

• Alteryx: This tool offers data blending and an advanced analytics platform where analysts  can merge internal business processes, third-party tools, and cloud data centres.

>> Tokens are: 
 ['•', 'Alteryx', ':', 'This', 'tool', 'offers', 'data', 'blending', 'advanced', 'analytics', 'platform', 'analysts', 'merge', 'internal', 'business', 'processes', ',', 'third-party', 'tools', ',', 'cloud', 'data', 'centres', '.']

>> Bigrams are: 
 [('•', 'Alteryx'), ('Alteryx', ':'), (':', 'This'), ('This', 'tool'), ('tool', 'offers'), ('offers', 'data'), ('data', 'blending'), ('blending', 'advanced'), ('advanced', 'analytics'), ('analytics', 'platform'), ('platform', 'analysts'), ('analysts', 'merge'), ('merge', 'internal'), ('internal', 'business'), ('business', 'processes'), ('processes', ','), (',', 'third-party'), ('third-party', 'tools'), ('tools', ','), (',', 'cloud'), ('cloud', 'data'), ('data', 'centres'), ('centres', '.')]

>> Trigrams are: 
 [('•', 'Alteryx', ':'), ('Alteryx', ':', 'This'), (':', 'This', 'tool'), ('This', 'tool', 'offers'), ('tool', 'offers', 'data'), ('offers', 'data', 'blending'), ('data', 'blending', 'advanced'), ('blending', 'advanced', 'analytics'), ('advanced', 'analytics', 'platform'), ('analytics', 'platform', 'analysts'), ('platform', 'analysts', 'merge'), ('analysts', 'merge', 'internal'), ('merge', 'internal', 'business'), ('internal', 'business', 'processes'), ('business', 'processes', ','), ('processes', ',', 'third-party'), (',', 'third-party', 'tools'), ('third-party', 'tools', ','), ('tools', ',', 'cloud'), (',', 'cloud', 'data'), ('cloud', 'data', 'centres'), ('data', 'centres', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Alteryx', 'NNP'), (':', ':'), ('This', 'DT'), ('tool', 'NN'), ('offers', 'VBZ'), ('data', 'NNS'), ('blending', 'NN'), ('advanced', 'VBD'), ('analytics', 'NNS'), ('platform', 'NN'), ('analysts', 'NNS'), ('merge', 'VBP'), ('internal', 'JJ'), ('business', 'NN'), ('processes', 'NNS'), (',', ','), ('third-party', 'JJ'), ('tools', 'NNS'), (',', ','), ('cloud', 'NN'), ('data', 'NNS'), ('centres', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['• Alteryx', 'This tool', 'data blending', 'analytics platform analysts', 'internal business processes', 'third-party tools', 'cloud data centres']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Alteryx', 'alteryx'), (':', ':'), ('This', 'thi'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blend'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merg'), ('internal', 'intern'), ('business', 'busi'), ('processes', 'process'), (',', ','), ('third-party', 'third-parti'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Alteryx', 'alteryx'), (':', ':'), ('This', 'this'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blend'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merg'), ('internal', 'intern'), ('business', 'busi'), ('processes', 'process'), (',', ','), ('third-party', 'third-parti'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centr'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Alteryx', 'Alteryx'), (':', ':'), ('This', 'This'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blending'), ('advanced', 'advanced'), ('analytics', 'analytics'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merge'), ('internal', 'internal'), ('business', 'business'), ('processes', 'process'), (',', ','), ('third-party', 'third-party'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centre'), ('.', '.')]


------------------- Sentence 2 -------------------

Also, it

>> Tokens are: 
 ['Also', ',']

>> Bigrams are: 
 [('Also', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Also', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ',')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ',')]



========================================== PARAGRAPH 862 ===========================================

allows data analytics utilizing some tools in a single workflow (ur Rehman et al., 2016).  

------------------- Sentence 1 -------------------

allows data analytics utilizing some tools in a single workflow (ur Rehman et al., 2016).

>> Tokens are: 
 ['allows', 'data', 'analytics', 'utilizing', 'tools', 'single', 'workflow', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('allows', 'data'), ('data', 'analytics'), ('analytics', 'utilizing'), ('utilizing', 'tools'), ('tools', 'single'), ('single', 'workflow'), ('workflow', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('allows', 'data', 'analytics'), ('data', 'analytics', 'utilizing'), ('analytics', 'utilizing', 'tools'), ('utilizing', 'tools', 'single'), ('tools', 'single', 'workflow'), ('single', 'workflow', '('), ('workflow', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('allows', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('utilizing', 'JJ'), ('tools', 'NNS'), ('single', 'JJ'), ('workflow', 'NN'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['allows data analytics', 'utilizing tools', 'single workflow', 'ur Rehman et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('allows', 'allow'), ('data', 'data'), ('analytics', 'analyt'), ('utilizing', 'util'), ('tools', 'tool'), ('single', 'singl'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('allows', 'allow'), ('data', 'data'), ('analytics', 'analyt'), ('utilizing', 'util'), ('tools', 'tool'), ('single', 'singl'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('allows', 'allows'), ('data', 'data'), ('analytics', 'analytics'), ('utilizing', 'utilizing'), ('tools', 'tool'), ('single', 'single'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 863 ===========================================

  


========================================== PARAGRAPH 864 ===========================================

• Google Cloud Platform (GCP) is one of the leaders among cloud Application  Programming Interfaces (APIs). Despite the fact that it was established a few years ago,  

------------------- Sentence 1 -------------------

• Google Cloud Platform (GCP) is one of the leaders among cloud Application  Programming Interfaces (APIs).

>> Tokens are: 
 ['•', 'Google', 'Cloud', 'Platform', '(', 'GCP', ')', 'one', 'leaders', 'among', 'cloud', 'Application', 'Programming', 'Interfaces', '(', 'APIs', ')', '.']

>> Bigrams are: 
 [('•', 'Google'), ('Google', 'Cloud'), ('Cloud', 'Platform'), ('Platform', '('), ('(', 'GCP'), ('GCP', ')'), (')', 'one'), ('one', 'leaders'), ('leaders', 'among'), ('among', 'cloud'), ('cloud', 'Application'), ('Application', 'Programming'), ('Programming', 'Interfaces'), ('Interfaces', '('), ('(', 'APIs'), ('APIs', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'Google', 'Cloud'), ('Google', 'Cloud', 'Platform'), ('Cloud', 'Platform', '('), ('Platform', '(', 'GCP'), ('(', 'GCP', ')'), ('GCP', ')', 'one'), (')', 'one', 'leaders'), ('one', 'leaders', 'among'), ('leaders', 'among', 'cloud'), ('among', 'cloud', 'Application'), ('cloud', 'Application', 'Programming'), ('Application', 'Programming', 'Interfaces'), ('Programming', 'Interfaces', '('), ('Interfaces', '(', 'APIs'), ('(', 'APIs', ')'), ('APIs', ')', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Google', 'NNP'), ('Cloud', 'NNP'), ('Platform', 'NNP'), ('(', '('), ('GCP', 'NNP'), (')', ')'), ('one', 'CD'), ('leaders', 'NNS'), ('among', 'IN'), ('cloud', 'JJ'), ('Application', 'NNP'), ('Programming', 'NNP'), ('Interfaces', 'NNP'), ('(', '('), ('APIs', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['• Google Cloud Platform', 'GCP', 'leaders', 'cloud Application Programming Interfaces', 'APIs']

>> Named Entities are: 
 [('PERSON', 'Google Cloud Platform'), ('ORGANIZATION', 'GCP'), ('ORGANIZATION', 'APIs')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('(', '('), ('GCP', 'gcp'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'applic'), ('Programming', 'program'), ('Interfaces', 'interfac'), ('(', '('), ('APIs', 'api'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('(', '('), ('GCP', 'gcp'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'applic'), ('Programming', 'program'), ('Interfaces', 'interfac'), ('(', '('), ('APIs', 'api'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Google', 'Google'), ('Cloud', 'Cloud'), ('Platform', 'Platform'), ('(', '('), ('GCP', 'GCP'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'Application'), ('Programming', 'Programming'), ('Interfaces', 'Interfaces'), ('(', '('), ('APIs', 'APIs'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Despite the fact that it was established a few years ago,

>> Tokens are: 
 ['Despite', 'fact', 'established', 'years', 'ago', ',']

>> Bigrams are: 
 [('Despite', 'fact'), ('fact', 'established'), ('established', 'years'), ('years', 'ago'), ('ago', ',')]

>> Trigrams are: 
 [('Despite', 'fact', 'established'), ('fact', 'established', 'years'), ('established', 'years', 'ago'), ('years', 'ago', ',')]

>> POS Tags are: 
 [('Despite', 'IN'), ('fact', 'NN'), ('established', 'VBN'), ('years', 'NNS'), ('ago', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['fact', 'years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Despite', 'despit'), ('fact', 'fact'), ('established', 'establish'), ('years', 'year'), ('ago', 'ago'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Despite', 'despit'), ('fact', 'fact'), ('established', 'establish'), ('years', 'year'), ('ago', 'ago'), (',', ',')]

>> Lemmatization: 
 [('Despite', 'Despite'), ('fact', 'fact'), ('established', 'established'), ('years', 'year'), ('ago', 'ago'), (',', ',')]



========================================== PARAGRAPH 865 ===========================================

GCP has realized a significant growth since it suits the public cloud services that are based  

------------------- Sentence 1 -------------------

GCP has realized a significant growth since it suits the public cloud services that are based

>> Tokens are: 
 ['GCP', 'realized', 'significant', 'growth', 'since', 'suits', 'public', 'cloud', 'services', 'based']

>> Bigrams are: 
 [('GCP', 'realized'), ('realized', 'significant'), ('significant', 'growth'), ('growth', 'since'), ('since', 'suits'), ('suits', 'public'), ('public', 'cloud'), ('cloud', 'services'), ('services', 'based')]

>> Trigrams are: 
 [('GCP', 'realized', 'significant'), ('realized', 'significant', 'growth'), ('significant', 'growth', 'since'), ('growth', 'since', 'suits'), ('since', 'suits', 'public'), ('suits', 'public', 'cloud'), ('public', 'cloud', 'services'), ('cloud', 'services', 'based')]

>> POS Tags are: 
 [('GCP', 'NNP'), ('realized', 'VBD'), ('significant', 'JJ'), ('growth', 'NN'), ('since', 'IN'), ('suits', 'NNS'), ('public', 'JJ'), ('cloud', 'NN'), ('services', 'NNS'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['GCP', 'significant growth', 'suits', 'public cloud services']

>> Named Entities are: 
 [('ORGANIZATION', 'GCP')] 

>> Stemming using Porter Stemmer: 
 [('GCP', 'gcp'), ('realized', 'realiz'), ('significant', 'signific'), ('growth', 'growth'), ('since', 'sinc'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'servic'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('GCP', 'gcp'), ('realized', 'realiz'), ('significant', 'signific'), ('growth', 'growth'), ('since', 'sinc'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'servic'), ('based', 'base')]

>> Lemmatization: 
 [('GCP', 'GCP'), ('realized', 'realized'), ('significant', 'significant'), ('growth', 'growth'), ('since', 'since'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'service'), ('based', 'based')]



========================================== PARAGRAPH 866 ===========================================

on massive, solid infrastructures. It gives the developer the ability to build a range of  

------------------- Sentence 1 -------------------

on massive, solid infrastructures.

>> Tokens are: 
 ['massive', ',', 'solid', 'infrastructures', '.']

>> Bigrams are: 
 [('massive', ','), (',', 'solid'), ('solid', 'infrastructures'), ('infrastructures', '.')]

>> Trigrams are: 
 [('massive', ',', 'solid'), (',', 'solid', 'infrastructures'), ('solid', 'infrastructures', '.')]

>> POS Tags are: 
 [('massive', 'JJ'), (',', ','), ('solid', 'JJ'), ('infrastructures', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['solid infrastructures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('massive', 'massiv'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('massive', 'massiv'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructur'), ('.', '.')]

>> Lemmatization: 
 [('massive', 'massive'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructure'), ('.', '.')]


------------------- Sentence 2 -------------------

It gives the developer the ability to build a range of

>> Tokens are: 
 ['It', 'gives', 'developer', 'ability', 'build', 'range']

>> Bigrams are: 
 [('It', 'gives'), ('gives', 'developer'), ('developer', 'ability'), ('ability', 'build'), ('build', 'range')]

>> Trigrams are: 
 [('It', 'gives', 'developer'), ('gives', 'developer', 'ability'), ('developer', 'ability', 'build'), ('ability', 'build', 'range')]

>> POS Tags are: 
 [('It', 'PRP'), ('gives', 'VBZ'), ('developer', 'JJ'), ('ability', 'NN'), ('build', 'NN'), ('range', 'NN')]

>> Noun Phrases are: 
 ['developer ability build range']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('gives', 'give'), ('developer', 'develop'), ('ability', 'abil'), ('build', 'build'), ('range', 'rang')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('gives', 'give'), ('developer', 'develop'), ('ability', 'abil'), ('build', 'build'), ('range', 'rang')]

>> Lemmatization: 
 [('It', 'It'), ('gives', 'give'), ('developer', 'developer'), ('ability', 'ability'), ('build', 'build'), ('range', 'range')]



========================================== PARAGRAPH 867 ===========================================

programs starting from simple websites to complex world-wide distributed applications.  

------------------- Sentence 1 -------------------

programs starting from simple websites to complex world-wide distributed applications.

>> Tokens are: 
 ['programs', 'starting', 'simple', 'websites', 'complex', 'world-wide', 'distributed', 'applications', '.']

>> Bigrams are: 
 [('programs', 'starting'), ('starting', 'simple'), ('simple', 'websites'), ('websites', 'complex'), ('complex', 'world-wide'), ('world-wide', 'distributed'), ('distributed', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('programs', 'starting', 'simple'), ('starting', 'simple', 'websites'), ('simple', 'websites', 'complex'), ('websites', 'complex', 'world-wide'), ('complex', 'world-wide', 'distributed'), ('world-wide', 'distributed', 'applications'), ('distributed', 'applications', '.')]

>> POS Tags are: 
 [('programs', 'NNS'), ('starting', 'VBG'), ('simple', 'JJ'), ('websites', 'NNS'), ('complex', 'JJ'), ('world-wide', 'JJ'), ('distributed', 'VBN'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['programs', 'simple websites', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('programs', 'program'), ('starting', 'start'), ('simple', 'simpl'), ('websites', 'websit'), ('complex', 'complex'), ('world-wide', 'world-wid'), ('distributed', 'distribut'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('programs', 'program'), ('starting', 'start'), ('simple', 'simpl'), ('websites', 'websit'), ('complex', 'complex'), ('world-wide', 'world-wid'), ('distributed', 'distribut'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('programs', 'program'), ('starting', 'starting'), ('simple', 'simple'), ('websites', 'website'), ('complex', 'complex'), ('world-wide', 'world-wide'), ('distributed', 'distributed'), ('applications', 'application'), ('.', '.')]



========================================== PARAGRAPH 868 ===========================================

GCP platform contains a set of physical assets (e.g.-, computers and hard disk drives) and  

------------------- Sentence 1 -------------------

GCP platform contains a set of physical assets (e.g.-, computers and hard disk drives) and

>> Tokens are: 
 ['GCP', 'platform', 'contains', 'set', 'physical', 'assets', '(', 'e.g.-', ',', 'computers', 'hard', 'disk', 'drives', ')']

>> Bigrams are: 
 [('GCP', 'platform'), ('platform', 'contains'), ('contains', 'set'), ('set', 'physical'), ('physical', 'assets'), ('assets', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'computers'), ('computers', 'hard'), ('hard', 'disk'), ('disk', 'drives'), ('drives', ')')]

>> Trigrams are: 
 [('GCP', 'platform', 'contains'), ('platform', 'contains', 'set'), ('contains', 'set', 'physical'), ('set', 'physical', 'assets'), ('physical', 'assets', '('), ('assets', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'computers'), (',', 'computers', 'hard'), ('computers', 'hard', 'disk'), ('hard', 'disk', 'drives'), ('disk', 'drives', ')')]

>> POS Tags are: 
 [('GCP', 'NNP'), ('platform', 'NN'), ('contains', 'VBZ'), ('set', 'VBN'), ('physical', 'JJ'), ('assets', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('computers', 'NNS'), ('hard', 'JJ'), ('disk', 'NN'), ('drives', 'NNS'), (')', ')')]

>> Noun Phrases are: 
 ['GCP platform', 'physical assets', 'computers', 'hard disk drives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('GCP', 'gcp'), ('platform', 'platform'), ('contains', 'contain'), ('set', 'set'), ('physical', 'physic'), ('assets', 'asset'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('computers', 'comput'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('GCP', 'gcp'), ('platform', 'platform'), ('contains', 'contain'), ('set', 'set'), ('physical', 'physic'), ('assets', 'asset'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('computers', 'comput'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')')]

>> Lemmatization: 
 [('GCP', 'GCP'), ('platform', 'platform'), ('contains', 'contains'), ('set', 'set'), ('physical', 'physical'), ('assets', 'asset'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('computers', 'computer'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')')]



========================================== PARAGRAPH 869 ===========================================

virtual resources (e.g.-, virtual machines, a.k.a. VMs) hosted in Google’s data centres  

------------------- Sentence 1 -------------------

virtual resources (e.g.-, virtual machines, a.k.a.

>> Tokens are: 
 ['virtual', 'resources', '(', 'e.g.-', ',', 'virtual', 'machines', ',', 'a.k.a', '.']

>> Bigrams are: 
 [('virtual', 'resources'), ('resources', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'virtual'), ('virtual', 'machines'), ('machines', ','), (',', 'a.k.a'), ('a.k.a', '.')]

>> Trigrams are: 
 [('virtual', 'resources', '('), ('resources', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'virtual'), (',', 'virtual', 'machines'), ('virtual', 'machines', ','), ('machines', ',', 'a.k.a'), (',', 'a.k.a', '.')]

>> POS Tags are: 
 [('virtual', 'JJ'), ('resources', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('virtual', 'JJ'), ('machines', 'NNS'), (',', ','), ('a.k.a', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['virtual resources', 'virtual machines', 'a.k.a']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('virtual', 'virtual'), ('resources', 'resourc'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machin'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('virtual', 'virtual'), ('resources', 'resourc'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machin'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]

>> Lemmatization: 
 [('virtual', 'virtual'), ('resources', 'resource'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machine'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]


------------------- Sentence 2 -------------------

VMs) hosted in Google’s data centres

>> Tokens are: 
 ['VMs', ')', 'hosted', 'Google', '’', 'data', 'centres']

>> Bigrams are: 
 [('VMs', ')'), (')', 'hosted'), ('hosted', 'Google'), ('Google', '’'), ('’', 'data'), ('data', 'centres')]

>> Trigrams are: 
 [('VMs', ')', 'hosted'), (')', 'hosted', 'Google'), ('hosted', 'Google', '’'), ('Google', '’', 'data'), ('’', 'data', 'centres')]

>> POS Tags are: 
 [('VMs', 'NNP'), (')', ')'), ('hosted', 'VBD'), ('Google', 'NNP'), ('’', 'NNP'), ('data', 'NN'), ('centres', 'NNS')]

>> Noun Phrases are: 
 ['VMs', 'Google ’ data centres']

>> Named Entities are: 
 [('PERSON', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('VMs', 'vm'), (')', ')'), ('hosted', 'host'), ('Google', 'googl'), ('’', '’'), ('data', 'data'), ('centres', 'centr')]

>> Stemming using Snowball Stemmer: 
 [('VMs', 'vms'), (')', ')'), ('hosted', 'host'), ('Google', 'googl'), ('’', '’'), ('data', 'data'), ('centres', 'centr')]

>> Lemmatization: 
 [('VMs', 'VMs'), (')', ')'), ('hosted', 'hosted'), ('Google', 'Google'), ('’', '’'), ('data', 'data'), ('centres', 'centre')]



========================================== PARAGRAPH 870 ===========================================

around the globe (Challita et al.,  2018 ).  

------------------- Sentence 1 -------------------

around the globe (Challita et al.,  2018 ).

>> Tokens are: 
 ['around', 'globe', '(', 'Challita', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('around', 'globe'), ('globe', '('), ('(', 'Challita'), ('Challita', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('around', 'globe', '('), ('globe', '(', 'Challita'), ('(', 'Challita', 'et'), ('Challita', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('around', 'IN'), ('globe', 'NN'), ('(', '('), ('Challita', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['globe', 'Challita']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'Challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 871 ===========================================

  


========================================== PARAGRAPH 872 ===========================================

• H2O is an open source framework offering parallel processing, analytics, math, and  machine learning libraries beside data pre-processing and assessment tools. Furthermore,  

------------------- Sentence 1 -------------------

• H2O is an open source framework offering parallel processing, analytics, math, and  machine learning libraries beside data pre-processing and assessment tools.

>> Tokens are: 
 ['•', 'H2O', 'open', 'source', 'framework', 'offering', 'parallel', 'processing', ',', 'analytics', ',', 'math', ',', 'machine', 'learning', 'libraries', 'beside', 'data', 'pre-processing', 'assessment', 'tools', '.']

>> Bigrams are: 
 [('•', 'H2O'), ('H2O', 'open'), ('open', 'source'), ('source', 'framework'), ('framework', 'offering'), ('offering', 'parallel'), ('parallel', 'processing'), ('processing', ','), (',', 'analytics'), ('analytics', ','), (',', 'math'), ('math', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'libraries'), ('libraries', 'beside'), ('beside', 'data'), ('data', 'pre-processing'), ('pre-processing', 'assessment'), ('assessment', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('•', 'H2O', 'open'), ('H2O', 'open', 'source'), ('open', 'source', 'framework'), ('source', 'framework', 'offering'), ('framework', 'offering', 'parallel'), ('offering', 'parallel', 'processing'), ('parallel', 'processing', ','), ('processing', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'math'), (',', 'math', ','), ('math', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'libraries'), ('learning', 'libraries', 'beside'), ('libraries', 'beside', 'data'), ('beside', 'data', 'pre-processing'), ('data', 'pre-processing', 'assessment'), ('pre-processing', 'assessment', 'tools'), ('assessment', 'tools', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('H2O', 'NNP'), ('open', 'JJ'), ('source', 'NN'), ('framework', 'NN'), ('offering', 'VBG'), ('parallel', 'JJ'), ('processing', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('math', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('libraries', 'NNS'), ('beside', 'IN'), ('data', 'NNS'), ('pre-processing', 'JJ'), ('assessment', 'NN'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['• H2O', 'open source framework', 'parallel processing', 'analytics', 'math', 'machine', 'libraries', 'data', 'pre-processing assessment tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('H2O', 'h2o'), ('open', 'open'), ('source', 'sourc'), ('framework', 'framework'), ('offering', 'offer'), ('parallel', 'parallel'), ('processing', 'process'), (',', ','), ('analytics', 'analyt'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('libraries', 'librari'), ('beside', 'besid'), ('data', 'data'), ('pre-processing', 'pre-process'), ('assessment', 'assess'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('H2O', 'h2o'), ('open', 'open'), ('source', 'sourc'), ('framework', 'framework'), ('offering', 'offer'), ('parallel', 'parallel'), ('processing', 'process'), (',', ','), ('analytics', 'analyt'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('libraries', 'librari'), ('beside', 'besid'), ('data', 'data'), ('pre-processing', 'pre-process'), ('assessment', 'assess'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('H2O', 'H2O'), ('open', 'open'), ('source', 'source'), ('framework', 'framework'), ('offering', 'offering'), ('parallel', 'parallel'), ('processing', 'processing'), (',', ','), ('analytics', 'analytics'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('libraries', 'library'), ('beside', 'beside'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('assessment', 'assessment'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

Furthermore,

>> Tokens are: 
 ['Furthermore', ',']

>> Bigrams are: 
 [('Furthermore', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ',')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ',')]



========================================== PARAGRAPH 873 ===========================================

it offers a web-based user interface that eases its use by analysts and statisticians who have  

------------------- Sentence 1 -------------------

it offers a web-based user interface that eases its use by analysts and statisticians who have

>> Tokens are: 
 ['offers', 'web-based', 'user', 'interface', 'eases', 'use', 'analysts', 'statisticians']

>> Bigrams are: 
 [('offers', 'web-based'), ('web-based', 'user'), ('user', 'interface'), ('interface', 'eases'), ('eases', 'use'), ('use', 'analysts'), ('analysts', 'statisticians')]

>> Trigrams are: 
 [('offers', 'web-based', 'user'), ('web-based', 'user', 'interface'), ('user', 'interface', 'eases'), ('interface', 'eases', 'use'), ('eases', 'use', 'analysts'), ('use', 'analysts', 'statisticians')]

>> POS Tags are: 
 [('offers', 'NNS'), ('web-based', 'JJ'), ('user', 'JJ'), ('interface', 'NN'), ('eases', 'NNS'), ('use', 'VBP'), ('analysts', 'NNS'), ('statisticians', 'NNS')]

>> Noun Phrases are: 
 ['offers', 'web-based user interface eases', 'analysts statisticians']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('offers', 'offer'), ('web-based', 'web-bas'), ('user', 'user'), ('interface', 'interfac'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician')]

>> Stemming using Snowball Stemmer: 
 [('offers', 'offer'), ('web-based', 'web-bas'), ('user', 'user'), ('interface', 'interfac'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician')]

>> Lemmatization: 
 [('offers', 'offer'), ('web-based', 'web-based'), ('user', 'user'), ('interface', 'interface'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician')]



========================================== PARAGRAPH 874 ===========================================

limited programming backgrounds. It also provides support for Java, R, Python, and Scala  

------------------- Sentence 1 -------------------

limited programming backgrounds.

>> Tokens are: 
 ['limited', 'programming', 'backgrounds', '.']

>> Bigrams are: 
 [('limited', 'programming'), ('programming', 'backgrounds'), ('backgrounds', '.')]

>> Trigrams are: 
 [('limited', 'programming', 'backgrounds'), ('programming', 'backgrounds', '.')]

>> POS Tags are: 
 [('limited', 'JJ'), ('programming', 'NN'), ('backgrounds', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['limited programming backgrounds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('limited', 'limit'), ('programming', 'program'), ('backgrounds', 'background'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('limited', 'limit'), ('programming', 'program'), ('backgrounds', 'background'), ('.', '.')]

>> Lemmatization: 
 [('limited', 'limited'), ('programming', 'programming'), ('backgrounds', 'background'), ('.', '.')]


------------------- Sentence 2 -------------------

It also provides support for Java, R, Python, and Scala

>> Tokens are: 
 ['It', 'also', 'provides', 'support', 'Java', ',', 'R', ',', 'Python', ',', 'Scala']

>> Bigrams are: 
 [('It', 'also'), ('also', 'provides'), ('provides', 'support'), ('support', 'Java'), ('Java', ','), (',', 'R'), ('R', ','), (',', 'Python'), ('Python', ','), (',', 'Scala')]

>> Trigrams are: 
 [('It', 'also', 'provides'), ('also', 'provides', 'support'), ('provides', 'support', 'Java'), ('support', 'Java', ','), ('Java', ',', 'R'), (',', 'R', ','), ('R', ',', 'Python'), (',', 'Python', ','), ('Python', ',', 'Scala')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('provides', 'VBZ'), ('support', 'NN'), ('Java', 'NNP'), (',', ','), ('R', 'NNP'), (',', ','), ('Python', 'NNP'), (',', ','), ('Scala', 'NNP')]

>> Noun Phrases are: 
 ['support Java', 'R', 'Python', 'Scala']

>> Named Entities are: 
 [('PERSON', 'Java'), ('GPE', 'R'), ('PERSON', 'Python'), ('PERSON', 'Scala')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('provides', 'provid'), ('support', 'support'), ('Java', 'java'), (',', ','), ('R', 'r'), (',', ','), ('Python', 'python'), (',', ','), ('Scala', 'scala')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('provides', 'provid'), ('support', 'support'), ('Java', 'java'), (',', ','), ('R', 'r'), (',', ','), ('Python', 'python'), (',', ','), ('Scala', 'scala')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('provides', 'provides'), ('support', 'support'), ('Java', 'Java'), (',', ','), ('R', 'R'), (',', ','), ('Python', 'Python'), (',', ','), ('Scala', 'Scala')]



========================================== PARAGRAPH 875 ===========================================

(Landset et al., 2015).  

------------------- Sentence 1 -------------------

(Landset et al., 2015).

>> Tokens are: 
 ['(', 'Landset', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('(', 'Landset'), ('Landset', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Landset', 'et'), ('Landset', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Landset', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Landset']

>> Named Entities are: 
 [('PERSON', 'Landset')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Landset', 'landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Landset', 'landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Landset', 'Landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 876 ===========================================

  


========================================== PARAGRAPH 877 ===========================================

• MicroStrategy provides an integrated big data analytics platform where the data is stored  in Hadoop clusters and the users are given permission to access the desktop computer and  

------------------- Sentence 1 -------------------

• MicroStrategy provides an integrated big data analytics platform where the data is stored  in Hadoop clusters and the users are given permission to access the desktop computer and

>> Tokens are: 
 ['•', 'MicroStrategy', 'provides', 'integrated', 'big', 'data', 'analytics', 'platform', 'data', 'stored', 'Hadoop', 'clusters', 'users', 'given', 'permission', 'access', 'desktop', 'computer']

>> Bigrams are: 
 [('•', 'MicroStrategy'), ('MicroStrategy', 'provides'), ('provides', 'integrated'), ('integrated', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'platform'), ('platform', 'data'), ('data', 'stored'), ('stored', 'Hadoop'), ('Hadoop', 'clusters'), ('clusters', 'users'), ('users', 'given'), ('given', 'permission'), ('permission', 'access'), ('access', 'desktop'), ('desktop', 'computer')]

>> Trigrams are: 
 [('•', 'MicroStrategy', 'provides'), ('MicroStrategy', 'provides', 'integrated'), ('provides', 'integrated', 'big'), ('integrated', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'platform'), ('analytics', 'platform', 'data'), ('platform', 'data', 'stored'), ('data', 'stored', 'Hadoop'), ('stored', 'Hadoop', 'clusters'), ('Hadoop', 'clusters', 'users'), ('clusters', 'users', 'given'), ('users', 'given', 'permission'), ('given', 'permission', 'access'), ('permission', 'access', 'desktop'), ('access', 'desktop', 'computer')]

>> POS Tags are: 
 [('•', 'JJ'), ('MicroStrategy', 'NNP'), ('provides', 'VBZ'), ('integrated', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('platform', 'NN'), ('data', 'NNS'), ('stored', 'VBD'), ('Hadoop', 'NNP'), ('clusters', 'NNS'), ('users', 'NNS'), ('given', 'VBN'), ('permission', 'NN'), ('access', 'NN'), ('desktop', 'NN'), ('computer', 'NN')]

>> Noun Phrases are: 
 ['• MicroStrategy', 'integrated big data analytics platform data', 'Hadoop clusters users', 'permission access desktop computer']

>> Named Entities are: 
 [('ORGANIZATION', 'MicroStrategy'), ('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('MicroStrategy', 'microstrategi'), ('provides', 'provid'), ('integrated', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('data', 'data'), ('stored', 'store'), ('Hadoop', 'hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permiss'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('MicroStrategy', 'microstrategi'), ('provides', 'provid'), ('integrated', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('data', 'data'), ('stored', 'store'), ('Hadoop', 'hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permiss'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'comput')]

>> Lemmatization: 
 [('•', '•'), ('MicroStrategy', 'MicroStrategy'), ('provides', 'provides'), ('integrated', 'integrated'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('platform', 'platform'), ('data', 'data'), ('stored', 'stored'), ('Hadoop', 'Hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permission'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'computer')]



========================================== PARAGRAPH 878 ===========================================

mobile devices. This tool offers real-time visualization and interactions to implement fast  

------------------- Sentence 1 -------------------

mobile devices.

>> Tokens are: 
 ['mobile', 'devices', '.']

>> Bigrams are: 
 [('mobile', 'devices'), ('devices', '.')]

>> Trigrams are: 
 [('mobile', 'devices', '.')]

>> POS Tags are: 
 [('mobile', 'JJ'), ('devices', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['mobile devices']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mobile', 'mobil'), ('devices', 'devic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('mobile', 'mobil'), ('devices', 'devic'), ('.', '.')]

>> Lemmatization: 
 [('mobile', 'mobile'), ('devices', 'device'), ('.', '.')]


------------------- Sentence 2 -------------------

This tool offers real-time visualization and interactions to implement fast

>> Tokens are: 
 ['This', 'tool', 'offers', 'real-time', 'visualization', 'interactions', 'implement', 'fast']

>> Bigrams are: 
 [('This', 'tool'), ('tool', 'offers'), ('offers', 'real-time'), ('real-time', 'visualization'), ('visualization', 'interactions'), ('interactions', 'implement'), ('implement', 'fast')]

>> Trigrams are: 
 [('This', 'tool', 'offers'), ('tool', 'offers', 'real-time'), ('offers', 'real-time', 'visualization'), ('real-time', 'visualization', 'interactions'), ('visualization', 'interactions', 'implement'), ('interactions', 'implement', 'fast')]

>> POS Tags are: 
 [('This', 'DT'), ('tool', 'NN'), ('offers', 'VBZ'), ('real-time', 'JJ'), ('visualization', 'NN'), ('interactions', 'NNS'), ('implement', 'VBP'), ('fast', 'RB')]

>> Noun Phrases are: 
 ['This tool', 'real-time visualization interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-tim'), ('visualization', 'visual'), ('interactions', 'interact'), ('implement', 'implement'), ('fast', 'fast')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-tim'), ('visualization', 'visual'), ('interactions', 'interact'), ('implement', 'implement'), ('fast', 'fast')]

>> Lemmatization: 
 [('This', 'This'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-time'), ('visualization', 'visualization'), ('interactions', 'interaction'), ('implement', 'implement'), ('fast', 'fast')]



========================================== PARAGRAPH 879 ===========================================

decisions (ur Rehman et al., 2016).  

------------------- Sentence 1 -------------------

decisions (ur Rehman et al., 2016).

>> Tokens are: 
 ['decisions', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('decisions', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('decisions', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('decisions', 'NNS'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['decisions', 'ur Rehman et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('decisions', 'decis'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('decisions', 'decis'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('decisions', 'decision'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 880 ===========================================

  


========================================== PARAGRAPH 881 ===========================================

• RapidMiner: is a programming-free data analysis platform. It provides the user with the  ability to "design data analysis processes in a plug-and-play fashion by wiring operators".  

------------------- Sentence 1 -------------------

• RapidMiner: is a programming-free data analysis platform.

>> Tokens are: 
 ['•', 'RapidMiner', ':', 'programming-free', 'data', 'analysis', 'platform', '.']

>> Bigrams are: 
 [('•', 'RapidMiner'), ('RapidMiner', ':'), (':', 'programming-free'), ('programming-free', 'data'), ('data', 'analysis'), ('analysis', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('•', 'RapidMiner', ':'), ('RapidMiner', ':', 'programming-free'), (':', 'programming-free', 'data'), ('programming-free', 'data', 'analysis'), ('data', 'analysis', 'platform'), ('analysis', 'platform', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('RapidMiner', 'NNP'), (':', ':'), ('programming-free', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('platform', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['• RapidMiner', 'programming-free data analysis platform']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('RapidMiner', 'rapidmin'), (':', ':'), ('programming-free', 'programming-fre'), ('data', 'data'), ('analysis', 'analysi'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('RapidMiner', 'rapidmin'), (':', ':'), ('programming-free', 'programming-fre'), ('data', 'data'), ('analysis', 'analysi'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('RapidMiner', 'RapidMiner'), (':', ':'), ('programming-free', 'programming-free'), ('data', 'data'), ('analysis', 'analysis'), ('platform', 'platform'), ('.', '.')]


------------------- Sentence 2 -------------------

It provides the user with the  ability to "design data analysis processes in a plug-and-play fashion by wiring operators".

>> Tokens are: 
 ['It', 'provides', 'user', 'ability', '``', 'design', 'data', 'analysis', 'processes', 'plug-and-play', 'fashion', 'wiring', 'operators', "''", '.']

>> Bigrams are: 
 [('It', 'provides'), ('provides', 'user'), ('user', 'ability'), ('ability', '``'), ('``', 'design'), ('design', 'data'), ('data', 'analysis'), ('analysis', 'processes'), ('processes', 'plug-and-play'), ('plug-and-play', 'fashion'), ('fashion', 'wiring'), ('wiring', 'operators'), ('operators', "''"), ("''", '.')]

>> Trigrams are: 
 [('It', 'provides', 'user'), ('provides', 'user', 'ability'), ('user', 'ability', '``'), ('ability', '``', 'design'), ('``', 'design', 'data'), ('design', 'data', 'analysis'), ('data', 'analysis', 'processes'), ('analysis', 'processes', 'plug-and-play'), ('processes', 'plug-and-play', 'fashion'), ('plug-and-play', 'fashion', 'wiring'), ('fashion', 'wiring', 'operators'), ('wiring', 'operators', "''"), ('operators', "''", '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('provides', 'VBZ'), ('user', 'JJ'), ('ability', 'NN'), ('``', '``'), ('design', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('processes', 'VBZ'), ('plug-and-play', 'JJ'), ('fashion', 'NN'), ('wiring', 'NN'), ('operators', 'NNS'), ("''", "''"), ('.', '.')]

>> Noun Phrases are: 
 ['user ability', 'design data analysis', 'plug-and-play fashion wiring operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('user', 'user'), ('ability', 'abil'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysi'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wire'), ('operators', 'oper'), ("''", "''"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('user', 'user'), ('ability', 'abil'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysi'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wire'), ('operators', 'oper'), ("''", "''"), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('provides', 'provides'), ('user', 'user'), ('ability', 'ability'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysis'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wiring'), ('operators', 'operator'), ("''", "''"), ('.', '.')]



========================================== PARAGRAPH 882 ===========================================

It allows importing operators for various data formats (e.g.-, Excel, CSV, XML). It prepares  

------------------- Sentence 1 -------------------

It allows importing operators for various data formats (e.g.-, Excel, CSV, XML).

>> Tokens are: 
 ['It', 'allows', 'importing', 'operators', 'various', 'data', 'formats', '(', 'e.g.-', ',', 'Excel', ',', 'CSV', ',', 'XML', ')', '.']

>> Bigrams are: 
 [('It', 'allows'), ('allows', 'importing'), ('importing', 'operators'), ('operators', 'various'), ('various', 'data'), ('data', 'formats'), ('formats', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'Excel'), ('Excel', ','), (',', 'CSV'), ('CSV', ','), (',', 'XML'), ('XML', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'allows', 'importing'), ('allows', 'importing', 'operators'), ('importing', 'operators', 'various'), ('operators', 'various', 'data'), ('various', 'data', 'formats'), ('data', 'formats', '('), ('formats', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'Excel'), (',', 'Excel', ','), ('Excel', ',', 'CSV'), (',', 'CSV', ','), ('CSV', ',', 'XML'), (',', 'XML', ')'), ('XML', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('allows', 'VBZ'), ('importing', 'VBG'), ('operators', 'NNS'), ('various', 'JJ'), ('data', 'NNS'), ('formats', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('Excel', 'NNP'), (',', ','), ('CSV', 'NNP'), (',', ','), ('XML', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['operators', 'various data formats', 'Excel', 'CSV', 'XML']

>> Named Entities are: 
 [('PERSON', 'Excel'), ('ORGANIZATION', 'CSV'), ('ORGANIZATION', 'XML')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('importing', 'import'), ('operators', 'oper'), ('various', 'variou'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('Excel', 'excel'), (',', ','), ('CSV', 'csv'), (',', ','), ('XML', 'xml'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('importing', 'import'), ('operators', 'oper'), ('various', 'various'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('Excel', 'excel'), (',', ','), ('CSV', 'csv'), (',', ','), ('XML', 'xml'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('allows', 'allows'), ('importing', 'importing'), ('operators', 'operator'), ('various', 'various'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('Excel', 'Excel'), (',', ','), ('CSV', 'CSV'), (',', ','), ('XML', 'XML'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

It prepares

>> Tokens are: 
 ['It', 'prepares']

>> Bigrams are: 
 [('It', 'prepares')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP'), ('prepares', 'VBZ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('prepares', 'prepar')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('prepares', 'prepar')]

>> Lemmatization: 
 [('It', 'It'), ('prepares', 'prepares')]



========================================== PARAGRAPH 883 ===========================================

a set of operators for massive datasets with further attributes from open data sources which  

------------------- Sentence 1 -------------------

a set of operators for massive datasets with further attributes from open data sources which

>> Tokens are: 
 ['set', 'operators', 'massive', 'datasets', 'attributes', 'open', 'data', 'sources']

>> Bigrams are: 
 [('set', 'operators'), ('operators', 'massive'), ('massive', 'datasets'), ('datasets', 'attributes'), ('attributes', 'open'), ('open', 'data'), ('data', 'sources')]

>> Trigrams are: 
 [('set', 'operators', 'massive'), ('operators', 'massive', 'datasets'), ('massive', 'datasets', 'attributes'), ('datasets', 'attributes', 'open'), ('attributes', 'open', 'data'), ('open', 'data', 'sources')]

>> POS Tags are: 
 [('set', 'NN'), ('operators', 'NNS'), ('massive', 'JJ'), ('datasets', 'NNS'), ('attributes', 'VBZ'), ('open', 'JJ'), ('data', 'NNS'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['set operators', 'massive datasets', 'open data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('set', 'set'), ('operators', 'oper'), ('massive', 'massiv'), ('datasets', 'dataset'), ('attributes', 'attribut'), ('open', 'open'), ('data', 'data'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('set', 'set'), ('operators', 'oper'), ('massive', 'massiv'), ('datasets', 'dataset'), ('attributes', 'attribut'), ('open', 'open'), ('data', 'data'), ('sources', 'sourc')]

>> Lemmatization: 
 [('set', 'set'), ('operators', 'operator'), ('massive', 'massive'), ('datasets', 'datasets'), ('attributes', 'attribute'), ('open', 'open'), ('data', 'data'), ('sources', 'source')]



========================================== PARAGRAPH 884 ===========================================

give an advantage of a better predictive and descriptive models (Ristoski et al., 2015).  

------------------- Sentence 1 -------------------

give an advantage of a better predictive and descriptive models (Ristoski et al., 2015).

>> Tokens are: 
 ['give', 'advantage', 'better', 'predictive', 'descriptive', 'models', '(', 'Ristoski', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('give', 'advantage'), ('advantage', 'better'), ('better', 'predictive'), ('predictive', 'descriptive'), ('descriptive', 'models'), ('models', '('), ('(', 'Ristoski'), ('Ristoski', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('give', 'advantage', 'better'), ('advantage', 'better', 'predictive'), ('better', 'predictive', 'descriptive'), ('predictive', 'descriptive', 'models'), ('descriptive', 'models', '('), ('models', '(', 'Ristoski'), ('(', 'Ristoski', 'et'), ('Ristoski', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('give', 'JJ'), ('advantage', 'NN'), ('better', 'RBR'), ('predictive', 'JJ'), ('descriptive', 'JJ'), ('models', 'NNS'), ('(', '('), ('Ristoski', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['give advantage', 'predictive descriptive models', 'Ristoski']

>> Named Entities are: 
 [('PERSON', 'Ristoski')] 

>> Stemming using Porter Stemmer: 
 [('give', 'give'), ('advantage', 'advantag'), ('better', 'better'), ('predictive', 'predict'), ('descriptive', 'descript'), ('models', 'model'), ('(', '('), ('Ristoski', 'ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('give', 'give'), ('advantage', 'advantag'), ('better', 'better'), ('predictive', 'predict'), ('descriptive', 'descript'), ('models', 'model'), ('(', '('), ('Ristoski', 'ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('give', 'give'), ('advantage', 'advantage'), ('better', 'better'), ('predictive', 'predictive'), ('descriptive', 'descriptive'), ('models', 'model'), ('(', '('), ('Ristoski', 'Ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 885 ===========================================

  


========================================== PARAGRAPH 886 ===========================================

• Datameer: Datameer Analytics Solution (DAS) is a business integration platform for  Hadoop. It contains data source integration, “an analytics mechanism with a spreadsheet  

------------------- Sentence 1 -------------------

• Datameer: Datameer Analytics Solution (DAS) is a business integration platform for  Hadoop.

>> Tokens are: 
 ['•', 'Datameer', ':', 'Datameer', 'Analytics', 'Solution', '(', 'DAS', ')', 'business', 'integration', 'platform', 'Hadoop', '.']

>> Bigrams are: 
 [('•', 'Datameer'), ('Datameer', ':'), (':', 'Datameer'), ('Datameer', 'Analytics'), ('Analytics', 'Solution'), ('Solution', '('), ('(', 'DAS'), ('DAS', ')'), (')', 'business'), ('business', 'integration'), ('integration', 'platform'), ('platform', 'Hadoop'), ('Hadoop', '.')]

>> Trigrams are: 
 [('•', 'Datameer', ':'), ('Datameer', ':', 'Datameer'), (':', 'Datameer', 'Analytics'), ('Datameer', 'Analytics', 'Solution'), ('Analytics', 'Solution', '('), ('Solution', '(', 'DAS'), ('(', 'DAS', ')'), ('DAS', ')', 'business'), (')', 'business', 'integration'), ('business', 'integration', 'platform'), ('integration', 'platform', 'Hadoop'), ('platform', 'Hadoop', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Datameer', 'NNP'), (':', ':'), ('Datameer', 'NNP'), ('Analytics', 'NNPS'), ('Solution', 'NNP'), ('(', '('), ('DAS', 'NNP'), (')', ')'), ('business', 'NN'), ('integration', 'NN'), ('platform', 'NN'), ('Hadoop', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['• Datameer', 'Datameer', 'Solution', 'DAS', 'business integration platform Hadoop']

>> Named Entities are: 
 [('ORGANIZATION', 'Datameer Analytics Solution'), ('ORGANIZATION', 'DAS'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Datameer', 'datam'), (':', ':'), ('Datameer', 'datam'), ('Analytics', 'analyt'), ('Solution', 'solut'), ('(', '('), ('DAS', 'da'), (')', ')'), ('business', 'busi'), ('integration', 'integr'), ('platform', 'platform'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Datameer', 'datam'), (':', ':'), ('Datameer', 'datam'), ('Analytics', 'analyt'), ('Solution', 'solut'), ('(', '('), ('DAS', 'das'), (')', ')'), ('business', 'busi'), ('integration', 'integr'), ('platform', 'platform'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Datameer', 'Datameer'), (':', ':'), ('Datameer', 'Datameer'), ('Analytics', 'Analytics'), ('Solution', 'Solution'), ('(', '('), ('DAS', 'DAS'), (')', ')'), ('business', 'business'), ('integration', 'integration'), ('platform', 'platform'), ('Hadoop', 'Hadoop'), ('.', '.')]


------------------- Sentence 2 -------------------

It contains data source integration, “an analytics mechanism with a spreadsheet

>> Tokens are: 
 ['It', 'contains', 'data', 'source', 'integration', ',', '“', 'analytics', 'mechanism', 'spreadsheet']

>> Bigrams are: 
 [('It', 'contains'), ('contains', 'data'), ('data', 'source'), ('source', 'integration'), ('integration', ','), (',', '“'), ('“', 'analytics'), ('analytics', 'mechanism'), ('mechanism', 'spreadsheet')]

>> Trigrams are: 
 [('It', 'contains', 'data'), ('contains', 'data', 'source'), ('data', 'source', 'integration'), ('source', 'integration', ','), ('integration', ',', '“'), (',', '“', 'analytics'), ('“', 'analytics', 'mechanism'), ('analytics', 'mechanism', 'spreadsheet')]

>> POS Tags are: 
 [('It', 'PRP'), ('contains', 'VBZ'), ('data', 'NNS'), ('source', 'NN'), ('integration', 'NN'), (',', ','), ('“', 'NNP'), ('analytics', 'NNS'), ('mechanism', 'NN'), ('spreadsheet', 'NN')]

>> Noun Phrases are: 
 ['data source integration', '“ analytics mechanism spreadsheet']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('data', 'data'), ('source', 'sourc'), ('integration', 'integr'), (',', ','), ('“', '“'), ('analytics', 'analyt'), ('mechanism', 'mechan'), ('spreadsheet', 'spreadsheet')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('data', 'data'), ('source', 'sourc'), ('integration', 'integr'), (',', ','), ('“', '“'), ('analytics', 'analyt'), ('mechanism', 'mechan'), ('spreadsheet', 'spreadsheet')]

>> Lemmatization: 
 [('It', 'It'), ('contains', 'contains'), ('data', 'data'), ('source', 'source'), ('integration', 'integration'), (',', ','), ('“', '“'), ('analytics', 'analytics'), ('mechanism', 'mechanism'), ('spreadsheet', 'spreadsheet')]



========================================== PARAGRAPH 887 ===========================================

interface”, designed with analytic functions and visualization to help business users in  

------------------- Sentence 1 -------------------

interface”, designed with analytic functions and visualization to help business users in

>> Tokens are: 
 ['interface', '”', ',', 'designed', 'analytic', 'functions', 'visualization', 'help', 'business', 'users']

>> Bigrams are: 
 [('interface', '”'), ('”', ','), (',', 'designed'), ('designed', 'analytic'), ('analytic', 'functions'), ('functions', 'visualization'), ('visualization', 'help'), ('help', 'business'), ('business', 'users')]

>> Trigrams are: 
 [('interface', '”', ','), ('”', ',', 'designed'), (',', 'designed', 'analytic'), ('designed', 'analytic', 'functions'), ('analytic', 'functions', 'visualization'), ('functions', 'visualization', 'help'), ('visualization', 'help', 'business'), ('help', 'business', 'users')]

>> POS Tags are: 
 [('interface', 'NN'), ('”', 'NNP'), (',', ','), ('designed', 'VBN'), ('analytic', 'JJ'), ('functions', 'NNS'), ('visualization', 'NN'), ('help', 'NN'), ('business', 'NN'), ('users', 'NNS')]

>> Noun Phrases are: 
 ['interface ”', 'analytic functions visualization help business users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interface', 'interfac'), ('”', '”'), (',', ','), ('designed', 'design'), ('analytic', 'analyt'), ('functions', 'function'), ('visualization', 'visual'), ('help', 'help'), ('business', 'busi'), ('users', 'user')]

>> Stemming using Snowball Stemmer: 
 [('interface', 'interfac'), ('”', '”'), (',', ','), ('designed', 'design'), ('analytic', 'analyt'), ('functions', 'function'), ('visualization', 'visual'), ('help', 'help'), ('business', 'busi'), ('users', 'user')]

>> Lemmatization: 
 [('interface', 'interface'), ('”', '”'), (',', ','), ('designed', 'designed'), ('analytic', 'analytic'), ('functions', 'function'), ('visualization', 'visualization'), ('help', 'help'), ('business', 'business'), ('users', 'user')]



========================================== PARAGRAPH 888 ===========================================

reports, charts and dashboards. Datameer can bring data from both structured such as  

------------------- Sentence 1 -------------------

reports, charts and dashboards.

>> Tokens are: 
 ['reports', ',', 'charts', 'dashboards', '.']

>> Bigrams are: 
 [('reports', ','), (',', 'charts'), ('charts', 'dashboards'), ('dashboards', '.')]

>> Trigrams are: 
 [('reports', ',', 'charts'), (',', 'charts', 'dashboards'), ('charts', 'dashboards', '.')]

>> POS Tags are: 
 [('reports', 'NNS'), (',', ','), ('charts', 'NNS'), ('dashboards', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['reports', 'charts dashboards']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]

>> Lemmatization: 
 [('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]


------------------- Sentence 2 -------------------

Datameer can bring data from both structured such as

>> Tokens are: 
 ['Datameer', 'bring', 'data', 'structured']

>> Bigrams are: 
 [('Datameer', 'bring'), ('bring', 'data'), ('data', 'structured')]

>> Trigrams are: 
 [('Datameer', 'bring', 'data'), ('bring', 'data', 'structured')]

>> POS Tags are: 
 [('Datameer', 'NNP'), ('bring', 'NN'), ('data', 'NNS'), ('structured', 'VBD')]

>> Noun Phrases are: 
 ['Datameer bring data']

>> Named Entities are: 
 [('GPE', 'Datameer')] 

>> Stemming using Porter Stemmer: 
 [('Datameer', 'datam'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('Datameer', 'datam'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structur')]

>> Lemmatization: 
 [('Datameer', 'Datameer'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structured')]



========================================== PARAGRAPH 889 ===========================================

Oracle, IBM DB2, and unstructured sources such as Twitter, Facebook, LinkedIn or e- 

------------------- Sentence 1 -------------------

Oracle, IBM DB2, and unstructured sources such as Twitter, Facebook, LinkedIn or e-

>> Tokens are: 
 ['Oracle', ',', 'IBM', 'DB2', ',', 'unstructured', 'sources', 'Twitter', ',', 'Facebook', ',', 'LinkedIn', 'e-']

>> Bigrams are: 
 [('Oracle', ','), (',', 'IBM'), ('IBM', 'DB2'), ('DB2', ','), (',', 'unstructured'), ('unstructured', 'sources'), ('sources', 'Twitter'), ('Twitter', ','), (',', 'Facebook'), ('Facebook', ','), (',', 'LinkedIn'), ('LinkedIn', 'e-')]

>> Trigrams are: 
 [('Oracle', ',', 'IBM'), (',', 'IBM', 'DB2'), ('IBM', 'DB2', ','), ('DB2', ',', 'unstructured'), (',', 'unstructured', 'sources'), ('unstructured', 'sources', 'Twitter'), ('sources', 'Twitter', ','), ('Twitter', ',', 'Facebook'), (',', 'Facebook', ','), ('Facebook', ',', 'LinkedIn'), (',', 'LinkedIn', 'e-')]

>> POS Tags are: 
 [('Oracle', 'NNP'), (',', ','), ('IBM', 'NNP'), ('DB2', 'NNP'), (',', ','), ('unstructured', 'JJ'), ('sources', 'NNS'), ('Twitter', 'NNP'), (',', ','), ('Facebook', 'NNP'), (',', ','), ('LinkedIn', 'NNP'), ('e-', 'NN')]

>> Noun Phrases are: 
 ['Oracle', 'IBM DB2', 'unstructured sources Twitter', 'Facebook', 'LinkedIn e-']

>> Named Entities are: 
 [('GPE', 'Oracle'), ('ORGANIZATION', 'IBM'), ('PERSON', 'Twitter'), ('GPE', 'Facebook'), ('ORGANIZATION', 'LinkedIn')] 

>> Stemming using Porter Stemmer: 
 [('Oracle', 'oracl'), (',', ','), ('IBM', 'ibm'), ('DB2', 'db2'), (',', ','), ('unstructured', 'unstructur'), ('sources', 'sourc'), ('Twitter', 'twitter'), (',', ','), ('Facebook', 'facebook'), (',', ','), ('LinkedIn', 'linkedin'), ('e-', 'e-')]

>> Stemming using Snowball Stemmer: 
 [('Oracle', 'oracl'), (',', ','), ('IBM', 'ibm'), ('DB2', 'db2'), (',', ','), ('unstructured', 'unstructur'), ('sources', 'sourc'), ('Twitter', 'twitter'), (',', ','), ('Facebook', 'facebook'), (',', ','), ('LinkedIn', 'linkedin'), ('e-', 'e-')]

>> Lemmatization: 
 [('Oracle', 'Oracle'), (',', ','), ('IBM', 'IBM'), ('DB2', 'DB2'), (',', ','), ('unstructured', 'unstructured'), ('sources', 'source'), ('Twitter', 'Twitter'), (',', ','), ('Facebook', 'Facebook'), (',', ','), ('LinkedIn', 'LinkedIn'), ('e-', 'e-')]



========================================== PARAGRAPH 890 ===========================================

mails (Di Martino et al., 2014).  

------------------- Sentence 1 -------------------

mails (Di Martino et al., 2014).

>> Tokens are: 
 ['mails', '(', 'Di', 'Martino', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('mails', '('), ('(', 'Di'), ('Di', 'Martino'), ('Martino', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('mails', '(', 'Di'), ('(', 'Di', 'Martino'), ('Di', 'Martino', 'et'), ('Martino', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('mails', 'NNS'), ('(', '('), ('Di', 'NNP'), ('Martino', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['mails', 'Di Martino', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mails', 'mail'), ('(', '('), ('Di', 'di'), ('Martino', 'martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('mails', 'mail'), ('(', '('), ('Di', 'di'), ('Martino', 'martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('mails', 'mail'), ('(', '('), ('Di', 'Di'), ('Martino', 'Martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 891 ===========================================

  


========================================== PARAGRAPH 892 ===========================================

• Microsoft: Microsoft platform provides predictive analytics capability called SSAS and  integrated in the SQL Server. This platform offers "efficiency in Azure’s cloud data  

------------------- Sentence 1 -------------------

• Microsoft: Microsoft platform provides predictive analytics capability called SSAS and  integrated in the SQL Server.

>> Tokens are: 
 ['•', 'Microsoft', ':', 'Microsoft', 'platform', 'provides', 'predictive', 'analytics', 'capability', 'called', 'SSAS', 'integrated', 'SQL', 'Server', '.']

>> Bigrams are: 
 [('•', 'Microsoft'), ('Microsoft', ':'), (':', 'Microsoft'), ('Microsoft', 'platform'), ('platform', 'provides'), ('provides', 'predictive'), ('predictive', 'analytics'), ('analytics', 'capability'), ('capability', 'called'), ('called', 'SSAS'), ('SSAS', 'integrated'), ('integrated', 'SQL'), ('SQL', 'Server'), ('Server', '.')]

>> Trigrams are: 
 [('•', 'Microsoft', ':'), ('Microsoft', ':', 'Microsoft'), (':', 'Microsoft', 'platform'), ('Microsoft', 'platform', 'provides'), ('platform', 'provides', 'predictive'), ('provides', 'predictive', 'analytics'), ('predictive', 'analytics', 'capability'), ('analytics', 'capability', 'called'), ('capability', 'called', 'SSAS'), ('called', 'SSAS', 'integrated'), ('SSAS', 'integrated', 'SQL'), ('integrated', 'SQL', 'Server'), ('SQL', 'Server', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Microsoft', 'NNP'), (':', ':'), ('Microsoft', 'JJ'), ('platform', 'NN'), ('provides', 'VBZ'), ('predictive', 'JJ'), ('analytics', 'NNS'), ('capability', 'NN'), ('called', 'VBN'), ('SSAS', 'NNP'), ('integrated', 'VBD'), ('SQL', 'NNP'), ('Server', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['• Microsoft', 'Microsoft platform', 'predictive analytics capability', 'SSAS', 'SQL Server']

>> Named Entities are: 
 [('PERSON', 'Microsoft'), ('PERSON', 'Microsoft'), ('ORGANIZATION', 'SSAS'), ('ORGANIZATION', 'SQL Server')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Microsoft', 'microsoft'), (':', ':'), ('Microsoft', 'microsoft'), ('platform', 'platform'), ('provides', 'provid'), ('predictive', 'predict'), ('analytics', 'analyt'), ('capability', 'capabl'), ('called', 'call'), ('SSAS', 'ssa'), ('integrated', 'integr'), ('SQL', 'sql'), ('Server', 'server'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Microsoft', 'microsoft'), (':', ':'), ('Microsoft', 'microsoft'), ('platform', 'platform'), ('provides', 'provid'), ('predictive', 'predict'), ('analytics', 'analyt'), ('capability', 'capabl'), ('called', 'call'), ('SSAS', 'ssas'), ('integrated', 'integr'), ('SQL', 'sql'), ('Server', 'server'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Microsoft', 'Microsoft'), (':', ':'), ('Microsoft', 'Microsoft'), ('platform', 'platform'), ('provides', 'provides'), ('predictive', 'predictive'), ('analytics', 'analytics'), ('capability', 'capability'), ('called', 'called'), ('SSAS', 'SSAS'), ('integrated', 'integrated'), ('SQL', 'SQL'), ('Server', 'Server'), ('.', '.')]


------------------- Sentence 2 -------------------

This platform offers "efficiency in Azure’s cloud data

>> Tokens are: 
 ['This', 'platform', 'offers', '``', 'efficiency', 'Azure', '’', 'cloud', 'data']

>> Bigrams are: 
 [('This', 'platform'), ('platform', 'offers'), ('offers', '``'), ('``', 'efficiency'), ('efficiency', 'Azure'), ('Azure', '’'), ('’', 'cloud'), ('cloud', 'data')]

>> Trigrams are: 
 [('This', 'platform', 'offers'), ('platform', 'offers', '``'), ('offers', '``', 'efficiency'), ('``', 'efficiency', 'Azure'), ('efficiency', 'Azure', '’'), ('Azure', '’', 'cloud'), ('’', 'cloud', 'data')]

>> POS Tags are: 
 [('This', 'DT'), ('platform', 'NN'), ('offers', 'VBZ'), ('``', '``'), ('efficiency', 'NN'), ('Azure', 'NNP'), ('’', 'NNP'), ('cloud', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['This platform', 'efficiency Azure ’ cloud data']

>> Named Entities are: 
 [('PERSON', 'Azure')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'effici'), ('Azure', 'azur'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'effici'), ('Azure', 'azur'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data')]

>> Lemmatization: 
 [('This', 'This'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'efficiency'), ('Azure', 'Azure'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data')]



========================================== PARAGRAPH 893 ===========================================

source’s integration and deployments as a web service" also, the simplicity of utilizing for  

------------------- Sentence 1 -------------------

source’s integration and deployments as a web service" also, the simplicity of utilizing for

>> Tokens are: 
 ['source', '’', 'integration', 'deployments', 'web', 'service', "''", 'also', ',', 'simplicity', 'utilizing']

>> Bigrams are: 
 [('source', '’'), ('’', 'integration'), ('integration', 'deployments'), ('deployments', 'web'), ('web', 'service'), ('service', "''"), ("''", 'also'), ('also', ','), (',', 'simplicity'), ('simplicity', 'utilizing')]

>> Trigrams are: 
 [('source', '’', 'integration'), ('’', 'integration', 'deployments'), ('integration', 'deployments', 'web'), ('deployments', 'web', 'service'), ('web', 'service', "''"), ('service', "''", 'also'), ("''", 'also', ','), ('also', ',', 'simplicity'), (',', 'simplicity', 'utilizing')]

>> POS Tags are: 
 [('source', 'NN'), ('’', 'CD'), ('integration', 'NN'), ('deployments', 'NNS'), ('web', 'VBP'), ('service', 'NN'), ("''", "''"), ('also', 'RB'), (',', ','), ('simplicity', 'NN'), ('utilizing', 'NN')]

>> Noun Phrases are: 
 ['source', 'integration deployments', 'service', 'simplicity utilizing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('source', 'sourc'), ('’', '’'), ('integration', 'integr'), ('deployments', 'deploy'), ('web', 'web'), ('service', 'servic'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplic'), ('utilizing', 'util')]

>> Stemming using Snowball Stemmer: 
 [('source', 'sourc'), ('’', '’'), ('integration', 'integr'), ('deployments', 'deploy'), ('web', 'web'), ('service', 'servic'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplic'), ('utilizing', 'util')]

>> Lemmatization: 
 [('source', 'source'), ('’', '’'), ('integration', 'integration'), ('deployments', 'deployment'), ('web', 'web'), ('service', 'service'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplicity'), ('utilizing', 'utilizing')]



========================================== PARAGRAPH 894 ===========================================

data scientists (ur Rehman et al., 2016).  

------------------- Sentence 1 -------------------

data scientists (ur Rehman et al., 2016).

>> Tokens are: 
 ['data', 'scientists', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('data', 'scientists'), ('scientists', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'scientists', '('), ('scientists', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('scientists', 'NNS'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data scientists', 'ur Rehman et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 895 ===========================================

 


========================================== PARAGRAPH 896 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 897 ===========================================

32  

------------------- Sentence 1 -------------------

32

>> Tokens are: 
 ['32']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('32', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('32', '32')]

>> Stemming using Snowball Stemmer: 
 [('32', '32')]

>> Lemmatization: 
 [('32', '32')]



========================================== PARAGRAPH 898 ===========================================

  


========================================== PARAGRAPH 899 ===========================================

Figure 19 is adopted  from (Raghupathi, W. and Raghupathi, V., 2014) and shows 1) data sources;  

------------------- Sentence 1 -------------------

Figure 19 is adopted  from (Raghupathi, W. and Raghupathi, V., 2014) and shows 1) data sources;

>> Tokens are: 
 ['Figure', '19', 'adopted', '(', 'Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', ')', 'shows', '1', ')', 'data', 'sources', ';']

>> Bigrams are: 
 [('Figure', '19'), ('19', 'adopted'), ('adopted', '('), ('(', 'Raghupathi'), ('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', ')'), (')', 'shows'), ('shows', '1'), ('1', ')'), (')', 'data'), ('data', 'sources'), ('sources', ';')]

>> Trigrams are: 
 [('Figure', '19', 'adopted'), ('19', 'adopted', '('), ('adopted', '(', 'Raghupathi'), ('(', 'Raghupathi', ','), ('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', ')'), ('2014', ')', 'shows'), (')', 'shows', '1'), ('shows', '1', ')'), ('1', ')', 'data'), (')', 'data', 'sources'), ('data', 'sources', ';')]

>> POS Tags are: 
 [('Figure', 'NN'), ('19', 'CD'), ('adopted', 'VBN'), ('(', '('), ('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('shows', 'VBZ'), ('1', 'CD'), (')', ')'), ('data', 'NN'), ('sources', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['Figure', 'Raghupathi', 'W. Raghupathi', 'V.', 'data sources']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('19', '19'), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'sourc'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('19', '19'), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'sourc'), (';', ';')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('19', '19'), ('adopted', 'adopted'), ('(', '('), ('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'source'), (';', ';')]



========================================== PARAGRAPH 900 ===========================================

2) the big data states that need to be processed and transformed; 3) big data tools and platforms  

------------------- Sentence 1 -------------------

2) the big data states that need to be processed and transformed; 3) big data tools and platforms

>> Tokens are: 
 ['2', ')', 'big', 'data', 'states', 'need', 'processed', 'transformed', ';', '3', ')', 'big', 'data', 'tools', 'platforms']

>> Bigrams are: 
 [('2', ')'), (')', 'big'), ('big', 'data'), ('data', 'states'), ('states', 'need'), ('need', 'processed'), ('processed', 'transformed'), ('transformed', ';'), (';', '3'), ('3', ')'), (')', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'platforms')]

>> Trigrams are: 
 [('2', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'states'), ('data', 'states', 'need'), ('states', 'need', 'processed'), ('need', 'processed', 'transformed'), ('processed', 'transformed', ';'), ('transformed', ';', '3'), (';', '3', ')'), ('3', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'platforms')]

>> POS Tags are: 
 [('2', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('states', 'NNS'), ('need', 'VBP'), ('processed', 'VBN'), ('transformed', 'VBD'), (';', ':'), ('3', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('platforms', 'NNS')]

>> Noun Phrases are: 
 ['big data states', 'big data tools platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'process'), ('transformed', 'transform'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'process'), ('transformed', 'transform'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform')]

>> Lemmatization: 
 [('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'processed'), ('transformed', 'transformed'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform')]



========================================== PARAGRAPH 901 ===========================================

wherein these decisions are made depending on the inputs, tool selection, and analytical models  

------------------- Sentence 1 -------------------

wherein these decisions are made depending on the inputs, tool selection, and analytical models

>> Tokens are: 
 ['wherein', 'decisions', 'made', 'depending', 'inputs', ',', 'tool', 'selection', ',', 'analytical', 'models']

>> Bigrams are: 
 [('wherein', 'decisions'), ('decisions', 'made'), ('made', 'depending'), ('depending', 'inputs'), ('inputs', ','), (',', 'tool'), ('tool', 'selection'), ('selection', ','), (',', 'analytical'), ('analytical', 'models')]

>> Trigrams are: 
 [('wherein', 'decisions', 'made'), ('decisions', 'made', 'depending'), ('made', 'depending', 'inputs'), ('depending', 'inputs', ','), ('inputs', ',', 'tool'), (',', 'tool', 'selection'), ('tool', 'selection', ','), ('selection', ',', 'analytical'), (',', 'analytical', 'models')]

>> POS Tags are: 
 [('wherein', 'NN'), ('decisions', 'NNS'), ('made', 'VBD'), ('depending', 'VBG'), ('inputs', 'NNS'), (',', ','), ('tool', 'NN'), ('selection', 'NN'), (',', ','), ('analytical', 'JJ'), ('models', 'NNS')]

>> Noun Phrases are: 
 ['wherein decisions', 'inputs', 'tool selection', 'analytical models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wherein', 'wherein'), ('decisions', 'decis'), ('made', 'made'), ('depending', 'depend'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'select'), (',', ','), ('analytical', 'analyt'), ('models', 'model')]

>> Stemming using Snowball Stemmer: 
 [('wherein', 'wherein'), ('decisions', 'decis'), ('made', 'made'), ('depending', 'depend'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'select'), (',', ','), ('analytical', 'analyt'), ('models', 'model')]

>> Lemmatization: 
 [('wherein', 'wherein'), ('decisions', 'decision'), ('made', 'made'), ('depending', 'depending'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'selection'), (',', ','), ('analytical', 'analytical'), ('models', 'model')]



========================================== PARAGRAPH 902 ===========================================

chosen; and  4) the big data analytics applications. Figure 20 shows the big data and AI Landscape  

------------------- Sentence 1 -------------------

chosen; and  4) the big data analytics applications.

>> Tokens are: 
 ['chosen', ';', '4', ')', 'big', 'data', 'analytics', 'applications', '.']

>> Bigrams are: 
 [('chosen', ';'), (';', '4'), ('4', ')'), (')', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('chosen', ';', '4'), (';', '4', ')'), ('4', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', '.')]

>> POS Tags are: 
 [('chosen', 'NN'), (';', ':'), ('4', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['chosen', 'big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

Figure 20 shows the big data and AI Landscape

>> Tokens are: 
 ['Figure', '20', 'shows', 'big', 'data', 'AI', 'Landscape']

>> Bigrams are: 
 [('Figure', '20'), ('20', 'shows'), ('shows', 'big'), ('big', 'data'), ('data', 'AI'), ('AI', 'Landscape')]

>> Trigrams are: 
 [('Figure', '20', 'shows'), ('20', 'shows', 'big'), ('shows', 'big', 'data'), ('big', 'data', 'AI'), ('data', 'AI', 'Landscape')]

>> POS Tags are: 
 [('Figure', 'NN'), ('20', 'CD'), ('shows', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('AI', 'NNP'), ('Landscape', 'NNP')]

>> Noun Phrases are: 
 ['Figure', 'big data AI Landscape']

>> Named Entities are: 
 [('ORGANIZATION', 'AI Landscape')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'AI'), ('Landscape', 'Landscape')]



========================================== PARAGRAPH 903 ===========================================

in 2018 which is adopted from (Goncharov, 2019).  

------------------- Sentence 1 -------------------

in 2018 which is adopted from (Goncharov, 2019).

>> Tokens are: 
 ['2018', 'adopted', '(', 'Goncharov', ',', '2019', ')', '.']

>> Bigrams are: 
 [('2018', 'adopted'), ('adopted', '('), ('(', 'Goncharov'), ('Goncharov', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('2018', 'adopted', '('), ('adopted', '(', 'Goncharov'), ('(', 'Goncharov', ','), ('Goncharov', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('2018', 'CD'), ('adopted', 'VBD'), ('(', '('), ('Goncharov', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Goncharov']

>> Named Entities are: 
 [('ORGANIZATION', 'Goncharov')] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('adopted', 'adopted'), ('(', '('), ('Goncharov', 'Goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 904 ===========================================

  


========================================== PARAGRAPH 905 ===========================================

  


========================================== PARAGRAPH 906 ===========================================

  


========================================== PARAGRAPH 907 ===========================================

Figure 19: An applied conceptual architecture of data analytics, adopted from (Raghupathi and  

------------------- Sentence 1 -------------------

Figure 19: An applied conceptual architecture of data analytics, adopted from (Raghupathi and

>> Tokens are: 
 ['Figure', '19', ':', 'An', 'applied', 'conceptual', 'architecture', 'data', 'analytics', ',', 'adopted', '(', 'Raghupathi']

>> Bigrams are: 
 [('Figure', '19'), ('19', ':'), (':', 'An'), ('An', 'applied'), ('applied', 'conceptual'), ('conceptual', 'architecture'), ('architecture', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Raghupathi')]

>> Trigrams are: 
 [('Figure', '19', ':'), ('19', ':', 'An'), (':', 'An', 'applied'), ('An', 'applied', 'conceptual'), ('applied', 'conceptual', 'architecture'), ('conceptual', 'architecture', 'data'), ('architecture', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Raghupathi')]

>> POS Tags are: 
 [('Figure', 'NN'), ('19', 'CD'), (':', ':'), ('An', 'DT'), ('applied', 'JJ'), ('conceptual', 'JJ'), ('architecture', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Raghupathi', 'NNP')]

>> Noun Phrases are: 
 ['Figure', 'An applied conceptual architecture data analytics', 'Raghupathi']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('19', '19'), (':', ':'), ('An', 'an'), ('applied', 'appli'), ('conceptual', 'conceptu'), ('architecture', 'architectur'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('19', '19'), (':', ':'), ('An', 'an'), ('applied', 'appli'), ('conceptual', 'conceptu'), ('architecture', 'architectur'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('19', '19'), (':', ':'), ('An', 'An'), ('applied', 'applied'), ('conceptual', 'conceptual'), ('architecture', 'architecture'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Raghupathi', 'Raghupathi')]



========================================== PARAGRAPH 908 ===========================================

Raghupathi, 2014).  

------------------- Sentence 1 -------------------

Raghupathi, 2014).

>> Tokens are: 
 ['Raghupathi', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Raghupathi', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Raghupathi', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Raghupathi']

>> Named Entities are: 
 [('GPE', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 909 ===========================================

  


========================================== PARAGRAPH 910 ===========================================

   


========================================== PARAGRAPH 911 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 912 ===========================================

33  

------------------- Sentence 1 -------------------

33

>> Tokens are: 
 ['33']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('33', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('33', '33')]

>> Stemming using Snowball Stemmer: 
 [('33', '33')]

>> Lemmatization: 
 [('33', '33')]



========================================== PARAGRAPH 913 ===========================================

  


========================================== PARAGRAPH 914 ===========================================

  


========================================== PARAGRAPH 915 ===========================================

  


========================================== PARAGRAPH 916 ===========================================

  


========================================== PARAGRAPH 917 ===========================================

Figure 20:  Big Data and AI Landscape in 2018, adopted from (Goncharov, 2019)  

------------------- Sentence 1 -------------------

Figure 20:  Big Data and AI Landscape in 2018, adopted from (Goncharov, 2019)

>> Tokens are: 
 ['Figure', '20', ':', 'Big', 'Data', 'AI', 'Landscape', '2018', ',', 'adopted', '(', 'Goncharov', ',', '2019', ')']

>> Bigrams are: 
 [('Figure', '20'), ('20', ':'), (':', 'Big'), ('Big', 'Data'), ('Data', 'AI'), ('AI', 'Landscape'), ('Landscape', '2018'), ('2018', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Goncharov'), ('Goncharov', ','), (',', '2019'), ('2019', ')')]

>> Trigrams are: 
 [('Figure', '20', ':'), ('20', ':', 'Big'), (':', 'Big', 'Data'), ('Big', 'Data', 'AI'), ('Data', 'AI', 'Landscape'), ('AI', 'Landscape', '2018'), ('Landscape', '2018', ','), ('2018', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Goncharov'), ('(', 'Goncharov', ','), ('Goncharov', ',', '2019'), (',', '2019', ')')]

>> POS Tags are: 
 [('Figure', 'NN'), ('20', 'CD'), (':', ':'), ('Big', 'JJ'), ('Data', 'NNS'), ('AI', 'NNP'), ('Landscape', 'NNP'), ('2018', 'CD'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Goncharov', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Figure', 'Big Data AI Landscape', 'Goncharov']

>> Named Entities are: 
 [('ORGANIZATION', 'AI'), ('ORGANIZATION', 'Goncharov')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('20', '20'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('20', '20'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('20', '20'), (':', ':'), ('Big', 'Big'), ('Data', 'Data'), ('AI', 'AI'), ('Landscape', 'Landscape'), ('2018', '2018'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Goncharov', 'Goncharov'), (',', ','), ('2019', '2019'), (')', ')')]



========================================== PARAGRAPH 918 ===========================================

  


========================================== PARAGRAPH 919 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 920 ===========================================

34  

------------------- Sentence 1 -------------------

34

>> Tokens are: 
 ['34']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('34', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('34', '34')]

>> Stemming using Snowball Stemmer: 
 [('34', '34')]

>> Lemmatization: 
 [('34', '34')]



========================================== PARAGRAPH 921 ===========================================

  


========================================== PARAGRAPH 922 ===========================================

  


========================================== PARAGRAPH 923 ===========================================

8. Big Data Analytics and Decision Making  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Analytics and Decision Making

>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Decision', 'Making']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Decision'), ('Decision', 'Making')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Decision'), ('Analytics', 'Decision', 'Making')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP')]

>> Noun Phrases are: 
 ['Big Data Analytics Decision Making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Decision', 'Decision'), ('Making', 'Making')]



========================================== PARAGRAPH 924 ===========================================

LaValle et al. (2011) examined big data analytics capability (BDAC) and defined it as the ability  

------------------- Sentence 1 -------------------

LaValle et al.

>> Tokens are: 
 ['LaValle', 'et', 'al', '.']

>> Bigrams are: 
 [('LaValle', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('LaValle', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('LaValle', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['LaValle', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'LaValle')] 

>> Stemming using Porter Stemmer: 
 [('LaValle', 'laval'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LaValle', 'lavall'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('LaValle', 'LaValle'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2011) examined big data analytics capability (BDAC) and defined it as the ability

>> Tokens are: 
 ['(', '2011', ')', 'examined', 'big', 'data', 'analytics', 'capability', '(', 'BDAC', ')', 'defined', 'ability']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', 'examined'), ('examined', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capability'), ('capability', '('), ('(', 'BDAC'), ('BDAC', ')'), (')', 'defined'), ('defined', 'ability')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', 'examined'), (')', 'examined', 'big'), ('examined', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capability'), ('analytics', 'capability', '('), ('capability', '(', 'BDAC'), ('(', 'BDAC', ')'), ('BDAC', ')', 'defined'), (')', 'defined', 'ability')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('examined', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capability', 'NN'), ('(', '('), ('BDAC', 'NNP'), (')', ')'), ('defined', 'VBD'), ('ability', 'NN')]

>> Noun Phrases are: 
 ['big data analytics capability', 'BDAC', 'ability']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examin'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('(', '('), ('BDAC', 'bdac'), (')', ')'), ('defined', 'defin'), ('ability', 'abil')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examin'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('(', '('), ('BDAC', 'bdac'), (')', ')'), ('defined', 'defin'), ('ability', 'abil')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examined'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capability', 'capability'), ('(', '('), ('BDAC', 'BDAC'), (')', ')'), ('defined', 'defined'), ('ability', 'ability')]



========================================== PARAGRAPH 925 ===========================================

to use big data in decision making. The study by Wixom et al. (2013) similarly focused on BDAC  

------------------- Sentence 1 -------------------

to use big data in decision making.

>> Tokens are: 
 ['use', 'big', 'data', 'decision', 'making', '.']

>> Bigrams are: 
 [('use', 'big'), ('big', 'data'), ('data', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('use', 'big', 'data'), ('big', 'data', 'decision'), ('data', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['use', 'big data decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]


------------------- Sentence 2 -------------------

The study by Wixom et al.

>> Tokens are: 
 ['The', 'study', 'Wixom', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', 'Wixom'), ('Wixom', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'study', 'Wixom'), ('study', 'Wixom', 'et'), ('Wixom', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('Wixom', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The study Wixom', 'al']

>> Named Entities are: 
 [('PERSON', 'Wixom')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('Wixom', 'wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('Wixom', 'wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('Wixom', 'Wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(2013) similarly focused on BDAC

>> Tokens are: 
 ['(', '2013', ')', 'similarly', 'focused', 'BDAC']

>> Bigrams are: 
 [('(', '2013'), ('2013', ')'), (')', 'similarly'), ('similarly', 'focused'), ('focused', 'BDAC')]

>> Trigrams are: 
 [('(', '2013', ')'), ('2013', ')', 'similarly'), (')', 'similarly', 'focused'), ('similarly', 'focused', 'BDAC')]

>> POS Tags are: 
 [('(', '('), ('2013', 'CD'), (')', ')'), ('similarly', 'RB'), ('focused', 'VBD'), ('BDAC', 'NNP')]

>> Noun Phrases are: 
 ['BDAC']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similarli'), ('focused', 'focus'), ('BDAC', 'bdac')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similar'), ('focused', 'focus'), ('BDAC', 'bdac')]

>> Lemmatization: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similarly'), ('focused', 'focused'), ('BDAC', 'BDAC')]



========================================== PARAGRAPH 926 ===========================================

in terms of driving business value, recognising the value of BDAC in terms of strategy, data  

------------------- Sentence 1 -------------------

in terms of driving business value, recognising the value of BDAC in terms of strategy, data

>> Tokens are: 
 ['terms', 'driving', 'business', 'value', ',', 'recognising', 'value', 'BDAC', 'terms', 'strategy', ',', 'data']

>> Bigrams are: 
 [('terms', 'driving'), ('driving', 'business'), ('business', 'value'), ('value', ','), (',', 'recognising'), ('recognising', 'value'), ('value', 'BDAC'), ('BDAC', 'terms'), ('terms', 'strategy'), ('strategy', ','), (',', 'data')]

>> Trigrams are: 
 [('terms', 'driving', 'business'), ('driving', 'business', 'value'), ('business', 'value', ','), ('value', ',', 'recognising'), (',', 'recognising', 'value'), ('recognising', 'value', 'BDAC'), ('value', 'BDAC', 'terms'), ('BDAC', 'terms', 'strategy'), ('terms', 'strategy', ','), ('strategy', ',', 'data')]

>> POS Tags are: 
 [('terms', 'NNS'), ('driving', 'VBG'), ('business', 'NN'), ('value', 'NN'), (',', ','), ('recognising', 'VBG'), ('value', 'NN'), ('BDAC', 'NNP'), ('terms', 'NNS'), ('strategy', 'NN'), (',', ','), ('data', 'NNS')]

>> Noun Phrases are: 
 ['terms', 'business value', 'value BDAC terms strategy', 'data']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('terms', 'term'), ('driving', 'drive'), ('business', 'busi'), ('value', 'valu'), (',', ','), ('recognising', 'recognis'), ('value', 'valu'), ('BDAC', 'bdac'), ('terms', 'term'), ('strategy', 'strategi'), (',', ','), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('terms', 'term'), ('driving', 'drive'), ('business', 'busi'), ('value', 'valu'), (',', ','), ('recognising', 'recognis'), ('value', 'valu'), ('BDAC', 'bdac'), ('terms', 'term'), ('strategy', 'strategi'), (',', ','), ('data', 'data')]

>> Lemmatization: 
 [('terms', 'term'), ('driving', 'driving'), ('business', 'business'), ('value', 'value'), (',', ','), ('recognising', 'recognising'), ('value', 'value'), ('BDAC', 'BDAC'), ('terms', 'term'), ('strategy', 'strategy'), (',', ','), ('data', 'data')]



========================================== PARAGRAPH 927 ===========================================

management, and human impact by conceptualising BDAC dimensions. That study showed that  

------------------- Sentence 1 -------------------

management, and human impact by conceptualising BDAC dimensions.

>> Tokens are: 
 ['management', ',', 'human', 'impact', 'conceptualising', 'BDAC', 'dimensions', '.']

>> Bigrams are: 
 [('management', ','), (',', 'human'), ('human', 'impact'), ('impact', 'conceptualising'), ('conceptualising', 'BDAC'), ('BDAC', 'dimensions'), ('dimensions', '.')]

>> Trigrams are: 
 [('management', ',', 'human'), (',', 'human', 'impact'), ('human', 'impact', 'conceptualising'), ('impact', 'conceptualising', 'BDAC'), ('conceptualising', 'BDAC', 'dimensions'), ('BDAC', 'dimensions', '.')]

>> POS Tags are: 
 [('management', 'NN'), (',', ','), ('human', 'JJ'), ('impact', 'NN'), ('conceptualising', 'VBG'), ('BDAC', 'NNP'), ('dimensions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['management', 'human impact', 'BDAC dimensions']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualis'), ('BDAC', 'bdac'), ('dimensions', 'dimens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualis'), ('BDAC', 'bdac'), ('dimensions', 'dimens'), ('.', '.')]

>> Lemmatization: 
 [('management', 'management'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualising'), ('BDAC', 'BDAC'), ('dimensions', 'dimension'), ('.', '.')]


------------------- Sentence 2 -------------------

That study showed that

>> Tokens are: 
 ['That', 'study', 'showed']

>> Bigrams are: 
 [('That', 'study'), ('study', 'showed')]

>> Trigrams are: 
 [('That', 'study', 'showed')]

>> POS Tags are: 
 [('That', 'DT'), ('study', 'NN'), ('showed', 'VBD')]

>> Noun Phrases are: 
 ['That study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('study', 'studi'), ('showed', 'show')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('study', 'studi'), ('showed', 'show')]

>> Lemmatization: 
 [('That', 'That'), ('study', 'study'), ('showed', 'showed')]



========================================== PARAGRAPH 928 ===========================================

establishing BDAC leads to maximising business value by increasing decision speed and allowing  

------------------- Sentence 1 -------------------

establishing BDAC leads to maximising business value by increasing decision speed and allowing

>> Tokens are: 
 ['establishing', 'BDAC', 'leads', 'maximising', 'business', 'value', 'increasing', 'decision', 'speed', 'allowing']

>> Bigrams are: 
 [('establishing', 'BDAC'), ('BDAC', 'leads'), ('leads', 'maximising'), ('maximising', 'business'), ('business', 'value'), ('value', 'increasing'), ('increasing', 'decision'), ('decision', 'speed'), ('speed', 'allowing')]

>> Trigrams are: 
 [('establishing', 'BDAC', 'leads'), ('BDAC', 'leads', 'maximising'), ('leads', 'maximising', 'business'), ('maximising', 'business', 'value'), ('business', 'value', 'increasing'), ('value', 'increasing', 'decision'), ('increasing', 'decision', 'speed'), ('decision', 'speed', 'allowing')]

>> POS Tags are: 
 [('establishing', 'VBG'), ('BDAC', 'NNP'), ('leads', 'VBZ'), ('maximising', 'VBG'), ('business', 'NN'), ('value', 'NN'), ('increasing', 'VBG'), ('decision', 'NN'), ('speed', 'NN'), ('allowing', 'VBG')]

>> Noun Phrases are: 
 ['BDAC', 'business value', 'decision speed']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('establishing', 'establish'), ('BDAC', 'bdac'), ('leads', 'lead'), ('maximising', 'maximis'), ('business', 'busi'), ('value', 'valu'), ('increasing', 'increas'), ('decision', 'decis'), ('speed', 'speed'), ('allowing', 'allow')]

>> Stemming using Snowball Stemmer: 
 [('establishing', 'establish'), ('BDAC', 'bdac'), ('leads', 'lead'), ('maximising', 'maximis'), ('business', 'busi'), ('value', 'valu'), ('increasing', 'increas'), ('decision', 'decis'), ('speed', 'speed'), ('allowing', 'allow')]

>> Lemmatization: 
 [('establishing', 'establishing'), ('BDAC', 'BDAC'), ('leads', 'lead'), ('maximising', 'maximising'), ('business', 'business'), ('value', 'value'), ('increasing', 'increasing'), ('decision', 'decision'), ('speed', 'speed'), ('allowing', 'allowing')]



========================================== PARAGRAPH 929 ===========================================

big data usage to spread more widely through an enterprise.  

------------------- Sentence 1 -------------------

big data usage to spread more widely through an enterprise.

>> Tokens are: 
 ['big', 'data', 'usage', 'spread', 'widely', 'enterprise', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'usage'), ('usage', 'spread'), ('spread', 'widely'), ('widely', 'enterprise'), ('enterprise', '.')]

>> Trigrams are: 
 [('big', 'data', 'usage'), ('data', 'usage', 'spread'), ('usage', 'spread', 'widely'), ('spread', 'widely', 'enterprise'), ('widely', 'enterprise', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('usage', 'NN'), ('spread', 'NN'), ('widely', 'RB'), ('enterprise', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data usage spread', 'enterprise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('usage', 'usag'), ('spread', 'spread'), ('widely', 'wide'), ('enterprise', 'enterpris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('usage', 'usag'), ('spread', 'spread'), ('widely', 'wide'), ('enterprise', 'enterpris'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('usage', 'usage'), ('spread', 'spread'), ('widely', 'widely'), ('enterprise', 'enterprise'), ('.', '.')]



========================================== PARAGRAPH 930 ===========================================

Chen et al. (2012) showed that business analytics and related technologies help organisations  

------------------- Sentence 1 -------------------

Chen et al.

>> Tokens are: 
 ['Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'al']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2012) showed that business analytics and related technologies help organisations

>> Tokens are: 
 ['(', '2012', ')', 'showed', 'business', 'analytics', 'related', 'technologies', 'help', 'organisations']

>> Bigrams are: 
 [('(', '2012'), ('2012', ')'), (')', 'showed'), ('showed', 'business'), ('business', 'analytics'), ('analytics', 'related'), ('related', 'technologies'), ('technologies', 'help'), ('help', 'organisations')]

>> Trigrams are: 
 [('(', '2012', ')'), ('2012', ')', 'showed'), (')', 'showed', 'business'), ('showed', 'business', 'analytics'), ('business', 'analytics', 'related'), ('analytics', 'related', 'technologies'), ('related', 'technologies', 'help'), ('technologies', 'help', 'organisations')]

>> POS Tags are: 
 [('(', '('), ('2012', 'CD'), (')', ')'), ('showed', 'VBD'), ('business', 'NN'), ('analytics', 'NNS'), ('related', 'JJ'), ('technologies', 'NNS'), ('help', 'VBP'), ('organisations', 'NNS')]

>> Noun Phrases are: 
 ['business analytics', 'related technologies', 'organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'show'), ('business', 'busi'), ('analytics', 'analyt'), ('related', 'relat'), ('technologies', 'technolog'), ('help', 'help'), ('organisations', 'organis')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'show'), ('business', 'busi'), ('analytics', 'analyt'), ('related', 'relat'), ('technologies', 'technolog'), ('help', 'help'), ('organisations', 'organis')]

>> Lemmatization: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'showed'), ('business', 'business'), ('analytics', 'analytics'), ('related', 'related'), ('technologies', 'technology'), ('help', 'help'), ('organisations', 'organisation')]



========================================== PARAGRAPH 931 ===========================================

develop better understanding of their own businesses and markets, while LaValle et al. (2011)  

------------------- Sentence 1 -------------------

develop better understanding of their own businesses and markets, while LaValle et al.

>> Tokens are: 
 ['develop', 'better', 'understanding', 'businesses', 'markets', ',', 'LaValle', 'et', 'al', '.']

>> Bigrams are: 
 [('develop', 'better'), ('better', 'understanding'), ('understanding', 'businesses'), ('businesses', 'markets'), ('markets', ','), (',', 'LaValle'), ('LaValle', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('develop', 'better', 'understanding'), ('better', 'understanding', 'businesses'), ('understanding', 'businesses', 'markets'), ('businesses', 'markets', ','), ('markets', ',', 'LaValle'), (',', 'LaValle', 'et'), ('LaValle', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('develop', 'VB'), ('better', 'RBR'), ('understanding', 'JJ'), ('businesses', 'NNS'), ('markets', 'NNS'), (',', ','), ('LaValle', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['understanding businesses markets', 'LaValle', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'LaValle')] 

>> Stemming using Porter Stemmer: 
 [('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('businesses', 'busi'), ('markets', 'market'), (',', ','), ('LaValle', 'laval'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('businesses', 'busi'), ('markets', 'market'), (',', ','), ('LaValle', 'lavall'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('develop', 'develop'), ('better', 'better'), ('understanding', 'understanding'), ('businesses', 'business'), ('markets', 'market'), (',', ','), ('LaValle', 'LaValle'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2011)

>> Tokens are: 
 ['(', '2011', ')']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')')]

>> Trigrams are: 
 [('(', '2011', ')')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')')]



========================================== PARAGRAPH 932 ===========================================

showed that “top-performing organisations make decisions based on rigorous analysis at more than  

------------------- Sentence 1 -------------------

showed that “top-performing organisations make decisions based on rigorous analysis at more than

>> Tokens are: 
 ['showed', '“', 'top-performing', 'organisations', 'make', 'decisions', 'based', 'rigorous', 'analysis']

>> Bigrams are: 
 [('showed', '“'), ('“', 'top-performing'), ('top-performing', 'organisations'), ('organisations', 'make'), ('make', 'decisions'), ('decisions', 'based'), ('based', 'rigorous'), ('rigorous', 'analysis')]

>> Trigrams are: 
 [('showed', '“', 'top-performing'), ('“', 'top-performing', 'organisations'), ('top-performing', 'organisations', 'make'), ('organisations', 'make', 'decisions'), ('make', 'decisions', 'based'), ('decisions', 'based', 'rigorous'), ('based', 'rigorous', 'analysis')]

>> POS Tags are: 
 [('showed', 'VBN'), ('“', 'JJ'), ('top-performing', 'JJ'), ('organisations', 'NNS'), ('make', 'VBP'), ('decisions', 'NNS'), ('based', 'VBN'), ('rigorous', 'JJ'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['“ top-performing organisations', 'decisions', 'rigorous analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('showed', 'show'), ('“', '“'), ('top-performing', 'top-perform'), ('organisations', 'organis'), ('make', 'make'), ('decisions', 'decis'), ('based', 'base'), ('rigorous', 'rigor'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('showed', 'show'), ('“', '“'), ('top-performing', 'top-perform'), ('organisations', 'organis'), ('make', 'make'), ('decisions', 'decis'), ('based', 'base'), ('rigorous', 'rigor'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('showed', 'showed'), ('“', '“'), ('top-performing', 'top-performing'), ('organisations', 'organisation'), ('make', 'make'), ('decisions', 'decision'), ('based', 'based'), ('rigorous', 'rigorous'), ('analysis', 'analysis')]



========================================== PARAGRAPH 933 ===========================================

double the rate of lower performing organisations” (Sharma et al., 2014). Similarly, according to  

------------------- Sentence 1 -------------------

double the rate of lower performing organisations” (Sharma et al., 2014).

>> Tokens are: 
 ['double', 'rate', 'lower', 'performing', 'organisations', '”', '(', 'Sharma', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('double', 'rate'), ('rate', 'lower'), ('lower', 'performing'), ('performing', 'organisations'), ('organisations', '”'), ('”', '('), ('(', 'Sharma'), ('Sharma', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('double', 'rate', 'lower'), ('rate', 'lower', 'performing'), ('lower', 'performing', 'organisations'), ('performing', 'organisations', '”'), ('organisations', '”', '('), ('”', '(', 'Sharma'), ('(', 'Sharma', 'et'), ('Sharma', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('double', 'JJ'), ('rate', 'NN'), ('lower', 'RBR'), ('performing', 'NN'), ('organisations', 'NNS'), ('”', 'VBP'), ('(', '('), ('Sharma', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['double rate', 'performing organisations', 'Sharma']

>> Named Entities are: 
 [('PERSON', 'Sharma')] 

>> Stemming using Porter Stemmer: 
 [('double', 'doubl'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'perform'), ('organisations', 'organis'), ('”', '”'), ('(', '('), ('Sharma', 'sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('double', 'doubl'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'perform'), ('organisations', 'organis'), ('”', '”'), ('(', '('), ('Sharma', 'sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('double', 'double'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'performing'), ('organisations', 'organisation'), ('”', '”'), ('(', '('), ('Sharma', 'Sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Similarly, according to

>> Tokens are: 
 ['Similarly', ',', 'according']

>> Bigrams are: 
 [('Similarly', ','), (',', 'according')]

>> Trigrams are: 
 [('Similarly', ',', 'according')]

>> POS Tags are: 
 [('Similarly', 'RB'), (',', ','), ('according', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Similarly', 'similarli'), (',', ','), ('according', 'accord')]

>> Stemming using Snowball Stemmer: 
 [('Similarly', 'similar'), (',', ','), ('according', 'accord')]

>> Lemmatization: 
 [('Similarly', 'Similarly'), (',', ','), ('according', 'according')]



========================================== PARAGRAPH 934 ===========================================

Kiron et al. (2014) BDAC is “the competence to provide business insights using data management,  

------------------- Sentence 1 -------------------

Kiron et al.

>> Tokens are: 
 ['Kiron', 'et', 'al', '.']

>> Bigrams are: 
 [('Kiron', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Kiron', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Kiron', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Kiron', 'al']

>> Named Entities are: 
 [('PERSON', 'Kiron')] 

>> Stemming using Porter Stemmer: 
 [('Kiron', 'kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kiron', 'kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Kiron', 'Kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2014) BDAC is “the competence to provide business insights using data management,

>> Tokens are: 
 ['(', '2014', ')', 'BDAC', '“', 'competence', 'provide', 'business', 'insights', 'using', 'data', 'management', ',']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'BDAC'), ('BDAC', '“'), ('“', 'competence'), ('competence', 'provide'), ('provide', 'business'), ('business', 'insights'), ('insights', 'using'), ('using', 'data'), ('data', 'management'), ('management', ',')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'BDAC'), (')', 'BDAC', '“'), ('BDAC', '“', 'competence'), ('“', 'competence', 'provide'), ('competence', 'provide', 'business'), ('provide', 'business', 'insights'), ('business', 'insights', 'using'), ('insights', 'using', 'data'), ('using', 'data', 'management'), ('data', 'management', ',')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('BDAC', 'NNP'), ('“', 'NNP'), ('competence', 'NN'), ('provide', 'NN'), ('business', 'NN'), ('insights', 'NNS'), ('using', 'VBG'), ('data', 'NNS'), ('management', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['BDAC “ competence provide business insights', 'data management']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'bdac'), ('“', '“'), ('competence', 'compet'), ('provide', 'provid'), ('business', 'busi'), ('insights', 'insight'), ('using', 'use'), ('data', 'data'), ('management', 'manag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'bdac'), ('“', '“'), ('competence', 'compet'), ('provide', 'provid'), ('business', 'busi'), ('insights', 'insight'), ('using', 'use'), ('data', 'data'), ('management', 'manag'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'BDAC'), ('“', '“'), ('competence', 'competence'), ('provide', 'provide'), ('business', 'business'), ('insights', 'insight'), ('using', 'using'), ('data', 'data'), ('management', 'management'), (',', ',')]



========================================== PARAGRAPH 935 ===========================================

infrastructure (technology) and talent (personnel) capability to transform business into a  

------------------- Sentence 1 -------------------

infrastructure (technology) and talent (personnel) capability to transform business into a

>> Tokens are: 
 ['infrastructure', '(', 'technology', ')', 'talent', '(', 'personnel', ')', 'capability', 'transform', 'business']

>> Bigrams are: 
 [('infrastructure', '('), ('(', 'technology'), ('technology', ')'), (')', 'talent'), ('talent', '('), ('(', 'personnel'), ('personnel', ')'), (')', 'capability'), ('capability', 'transform'), ('transform', 'business')]

>> Trigrams are: 
 [('infrastructure', '(', 'technology'), ('(', 'technology', ')'), ('technology', ')', 'talent'), (')', 'talent', '('), ('talent', '(', 'personnel'), ('(', 'personnel', ')'), ('personnel', ')', 'capability'), (')', 'capability', 'transform'), ('capability', 'transform', 'business')]

>> POS Tags are: 
 [('infrastructure', 'NN'), ('(', '('), ('technology', 'NN'), (')', ')'), ('talent', 'NN'), ('(', '('), ('personnel', 'NNS'), (')', ')'), ('capability', 'NN'), ('transform', 'NN'), ('business', 'NN')]

>> Noun Phrases are: 
 ['infrastructure', 'technology', 'talent', 'personnel', 'capability transform business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('infrastructure', 'infrastructur'), ('(', '('), ('technology', 'technolog'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capabl'), ('transform', 'transform'), ('business', 'busi')]

>> Stemming using Snowball Stemmer: 
 [('infrastructure', 'infrastructur'), ('(', '('), ('technology', 'technolog'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capabl'), ('transform', 'transform'), ('business', 'busi')]

>> Lemmatization: 
 [('infrastructure', 'infrastructure'), ('(', '('), ('technology', 'technology'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capability'), ('transform', 'transform'), ('business', 'business')]



========================================== PARAGRAPH 936 ===========================================

competitive force”.  

------------------- Sentence 1 -------------------

competitive force”.

>> Tokens are: 
 ['competitive', 'force', '”', '.']

>> Bigrams are: 
 [('competitive', 'force'), ('force', '”'), ('”', '.')]

>> Trigrams are: 
 [('competitive', 'force', '”'), ('force', '”', '.')]

>> POS Tags are: 
 [('competitive', 'JJ'), ('force', 'NN'), ('”', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['competitive force ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('competitive', 'competit'), ('force', 'forc'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('competitive', 'competit'), ('force', 'forc'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('competitive', 'competitive'), ('force', 'force'), ('”', '”'), ('.', '.')]



========================================== PARAGRAPH 937 ===========================================

Research by Akter et al. (2016) built a BDAC strategy based on previous studies which showed  

------------------- Sentence 1 -------------------

Research by Akter et al.

>> Tokens are: 
 ['Research', 'Akter', 'et', 'al', '.']

>> Bigrams are: 
 [('Research', 'Akter'), ('Akter', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Research', 'Akter', 'et'), ('Akter', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Research', 'NN'), ('Akter', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Research Akter', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Akter', 'akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Akter', 'akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Akter', 'Akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016) built a BDAC strategy based on previous studies which showed

>> Tokens are: 
 ['(', '2016', ')', 'built', 'BDAC', 'strategy', 'based', 'previous', 'studies', 'showed']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'built'), ('built', 'BDAC'), ('BDAC', 'strategy'), ('strategy', 'based'), ('based', 'previous'), ('previous', 'studies'), ('studies', 'showed')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'built'), (')', 'built', 'BDAC'), ('built', 'BDAC', 'strategy'), ('BDAC', 'strategy', 'based'), ('strategy', 'based', 'previous'), ('based', 'previous', 'studies'), ('previous', 'studies', 'showed')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('built', 'VBN'), ('BDAC', 'NNP'), ('strategy', 'NN'), ('based', 'VBN'), ('previous', 'JJ'), ('studies', 'NNS'), ('showed', 'VBD')]

>> Noun Phrases are: 
 ['BDAC strategy', 'previous studies']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'bdac'), ('strategy', 'strategi'), ('based', 'base'), ('previous', 'previou'), ('studies', 'studi'), ('showed', 'show')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'bdac'), ('strategy', 'strategi'), ('based', 'base'), ('previous', 'previous'), ('studies', 'studi'), ('showed', 'show')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'BDAC'), ('strategy', 'strategy'), ('based', 'based'), ('previous', 'previous'), ('studies', 'study'), ('showed', 'showed')]



========================================== PARAGRAPH 938 ===========================================

the importance of management and technology in the big data environment. This study proposed  

------------------- Sentence 1 -------------------

the importance of management and technology in the big data environment.

>> Tokens are: 
 ['importance', 'management', 'technology', 'big', 'data', 'environment', '.']

>> Bigrams are: 
 [('importance', 'management'), ('management', 'technology'), ('technology', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', '.')]

>> Trigrams are: 
 [('importance', 'management', 'technology'), ('management', 'technology', 'big'), ('technology', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', '.')]

>> POS Tags are: 
 [('importance', 'NN'), ('management', 'NN'), ('technology', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['importance management technology', 'big data environment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('importance', 'import'), ('management', 'manag'), ('technology', 'technolog'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('importance', 'import'), ('management', 'manag'), ('technology', 'technolog'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('importance', 'importance'), ('management', 'management'), ('technology', 'technology'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('.', '.')]


------------------- Sentence 2 -------------------

This study proposed

>> Tokens are: 
 ['This', 'study', 'proposed']

>> Bigrams are: 
 [('This', 'study'), ('study', 'proposed')]

>> Trigrams are: 
 [('This', 'study', 'proposed')]

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN'), ('proposed', 'VBD')]

>> Noun Phrases are: 
 ['This study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi'), ('proposed', 'propos')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi'), ('proposed', 'propos')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study'), ('proposed', 'proposed')]



========================================== PARAGRAPH 939 ===========================================

an integrated BDAC model and examined its impact. Elgendy (2013) further proposed a Big Data,  

------------------- Sentence 1 -------------------

an integrated BDAC model and examined its impact.

>> Tokens are: 
 ['integrated', 'BDAC', 'model', 'examined', 'impact', '.']

>> Bigrams are: 
 [('integrated', 'BDAC'), ('BDAC', 'model'), ('model', 'examined'), ('examined', 'impact'), ('impact', '.')]

>> Trigrams are: 
 [('integrated', 'BDAC', 'model'), ('BDAC', 'model', 'examined'), ('model', 'examined', 'impact'), ('examined', 'impact', '.')]

>> POS Tags are: 
 [('integrated', 'VBN'), ('BDAC', 'NNP'), ('model', 'NN'), ('examined', 'VBD'), ('impact', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['BDAC model', 'impact']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('integrated', 'integr'), ('BDAC', 'bdac'), ('model', 'model'), ('examined', 'examin'), ('impact', 'impact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('integrated', 'integr'), ('BDAC', 'bdac'), ('model', 'model'), ('examined', 'examin'), ('impact', 'impact'), ('.', '.')]

>> Lemmatization: 
 [('integrated', 'integrated'), ('BDAC', 'BDAC'), ('model', 'model'), ('examined', 'examined'), ('impact', 'impact'), ('.', '.')]


------------------- Sentence 2 -------------------

Elgendy (2013) further proposed a Big Data,

>> Tokens are: 
 ['Elgendy', '(', '2013', ')', 'proposed', 'Big', 'Data', ',']

>> Bigrams are: 
 [('Elgendy', '('), ('(', '2013'), ('2013', ')'), (')', 'proposed'), ('proposed', 'Big'), ('Big', 'Data'), ('Data', ',')]

>> Trigrams are: 
 [('Elgendy', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'proposed'), (')', 'proposed', 'Big'), ('proposed', 'Big', 'Data'), ('Big', 'Data', ',')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('proposed', 'VBD'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Elgendy', 'Big Data']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('Big', 'big'), ('Data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('Big', 'big'), ('Data', 'data'), (',', ',')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'proposed'), ('Big', 'Big'), ('Data', 'Data'), (',', ',')]



========================================== PARAGRAPH 940 ===========================================

Analytics, and Decisions (B-DAD) framework wherein big data analytics tools and methods are  

------------------- Sentence 1 -------------------

Analytics, and Decisions (B-DAD) framework wherein big data analytics tools and methods are

>> Tokens are: 
 ['Analytics', ',', 'Decisions', '(', 'B-DAD', ')', 'framework', 'wherein', 'big', 'data', 'analytics', 'tools', 'methods']

>> Bigrams are: 
 [('Analytics', ','), (',', 'Decisions'), ('Decisions', '('), ('(', 'B-DAD'), ('B-DAD', ')'), (')', 'framework'), ('framework', 'wherein'), ('wherein', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'methods')]

>> Trigrams are: 
 [('Analytics', ',', 'Decisions'), (',', 'Decisions', '('), ('Decisions', '(', 'B-DAD'), ('(', 'B-DAD', ')'), ('B-DAD', ')', 'framework'), (')', 'framework', 'wherein'), ('framework', 'wherein', 'big'), ('wherein', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'methods')]

>> POS Tags are: 
 [('Analytics', 'NNS'), (',', ','), ('Decisions', 'NNP'), ('(', '('), ('B-DAD', 'NNP'), (')', ')'), ('framework', 'NN'), ('wherein', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['Analytics', 'Decisions', 'B-DAD', 'framework', 'big data analytics tools methods']

>> Named Entities are: 
 [('GPE', 'Decisions')] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), (',', ','), ('Decisions', 'decis'), ('(', '('), ('B-DAD', 'b-dad'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), (',', ','), ('Decisions', 'decis'), ('(', '('), ('B-DAD', 'b-dad'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), (',', ','), ('Decisions', 'Decisions'), ('(', '('), ('B-DAD', 'B-DAD'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('methods', 'method')]



========================================== PARAGRAPH 941 ===========================================

combined in the decision-making process.   

------------------- Sentence 1 -------------------

combined in the decision-making process.

>> Tokens are: 
 ['combined', 'decision-making', 'process', '.']

>> Bigrams are: 
 [('combined', 'decision-making'), ('decision-making', 'process'), ('process', '.')]

>> Trigrams are: 
 [('combined', 'decision-making', 'process'), ('decision-making', 'process', '.')]

>> POS Tags are: 
 [('combined', 'VBN'), ('decision-making', 'JJ'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['decision-making process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('combined', 'combin'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('combined', 'combin'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('combined', 'combined'), ('decision-making', 'decision-making'), ('process', 'process'), ('.', '.')]



========================================== PARAGRAPH 942 ===========================================

In all of the models examined, the intelligence phase is the first phase of the decision-making  

------------------- Sentence 1 -------------------

In all of the models examined, the intelligence phase is the first phase of the decision-making

>> Tokens are: 
 ['In', 'models', 'examined', ',', 'intelligence', 'phase', 'first', 'phase', 'decision-making']

>> Bigrams are: 
 [('In', 'models'), ('models', 'examined'), ('examined', ','), (',', 'intelligence'), ('intelligence', 'phase'), ('phase', 'first'), ('first', 'phase'), ('phase', 'decision-making')]

>> Trigrams are: 
 [('In', 'models', 'examined'), ('models', 'examined', ','), ('examined', ',', 'intelligence'), (',', 'intelligence', 'phase'), ('intelligence', 'phase', 'first'), ('phase', 'first', 'phase'), ('first', 'phase', 'decision-making')]

>> POS Tags are: 
 [('In', 'IN'), ('models', 'NNS'), ('examined', 'VBN'), (',', ','), ('intelligence', 'NN'), ('phase', 'NN'), ('first', 'JJ'), ('phase', 'NN'), ('decision-making', 'NN')]

>> Noun Phrases are: 
 ['models', 'intelligence phase', 'first phase decision-making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('models', 'model'), ('examined', 'examin'), (',', ','), ('intelligence', 'intellig'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-mak')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('models', 'model'), ('examined', 'examin'), (',', ','), ('intelligence', 'intellig'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-mak')]

>> Lemmatization: 
 [('In', 'In'), ('models', 'model'), ('examined', 'examined'), (',', ','), ('intelligence', 'intelligence'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-making')]



========================================== PARAGRAPH 943 ===========================================

process. In this phase  

------------------- Sentence 1 -------------------

process.

>> Tokens are: 
 ['process', '.']

>> Bigrams are: 
 [('process', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('process', 'process'), ('.', '.')]


------------------- Sentence 2 -------------------

In this phase

>> Tokens are: 
 ['In', 'phase']

>> Bigrams are: 
 [('In', 'phase')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('phase', 'NN')]

>> Noun Phrases are: 
 ['phase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('phase', 'phase')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('phase', 'phase')]

>> Lemmatization: 
 [('In', 'In'), ('phase', 'phase')]



========================================== PARAGRAPH 944 ===========================================

• data collected from internal and external sources are used to identify problems and  opportunities;  

------------------- Sentence 1 -------------------

• data collected from internal and external sources are used to identify problems and  opportunities;

>> Tokens are: 
 ['•', 'data', 'collected', 'internal', 'external', 'sources', 'used', 'identify', 'problems', 'opportunities', ';']

>> Bigrams are: 
 [('•', 'data'), ('data', 'collected'), ('collected', 'internal'), ('internal', 'external'), ('external', 'sources'), ('sources', 'used'), ('used', 'identify'), ('identify', 'problems'), ('problems', 'opportunities'), ('opportunities', ';')]

>> Trigrams are: 
 [('•', 'data', 'collected'), ('data', 'collected', 'internal'), ('collected', 'internal', 'external'), ('internal', 'external', 'sources'), ('external', 'sources', 'used'), ('sources', 'used', 'identify'), ('used', 'identify', 'problems'), ('identify', 'problems', 'opportunities'), ('problems', 'opportunities', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('data', 'NNS'), ('collected', 'VBD'), ('internal', 'JJ'), ('external', 'JJ'), ('sources', 'NNS'), ('used', 'VBD'), ('identify', 'VB'), ('problems', 'NNS'), ('opportunities', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['• data', 'internal external sources', 'problems opportunities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('data', 'data'), ('collected', 'collect'), ('internal', 'intern'), ('external', 'extern'), ('sources', 'sourc'), ('used', 'use'), ('identify', 'identifi'), ('problems', 'problem'), ('opportunities', 'opportun'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('data', 'data'), ('collected', 'collect'), ('internal', 'intern'), ('external', 'extern'), ('sources', 'sourc'), ('used', 'use'), ('identify', 'identifi'), ('problems', 'problem'), ('opportunities', 'opportun'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('data', 'data'), ('collected', 'collected'), ('internal', 'internal'), ('external', 'external'), ('sources', 'source'), ('used', 'used'), ('identify', 'identify'), ('problems', 'problem'), ('opportunities', 'opportunity'), (';', ';')]



========================================== PARAGRAPH 945 ===========================================

• big data sources are clearly identified;  

------------------- Sentence 1 -------------------

• big data sources are clearly identified;

>> Tokens are: 
 ['•', 'big', 'data', 'sources', 'clearly', 'identified', ';']

>> Bigrams are: 
 [('•', 'big'), ('big', 'data'), ('data', 'sources'), ('sources', 'clearly'), ('clearly', 'identified'), ('identified', ';')]

>> Trigrams are: 
 [('•', 'big', 'data'), ('big', 'data', 'sources'), ('data', 'sources', 'clearly'), ('sources', 'clearly', 'identified'), ('clearly', 'identified', ';')]

>> POS Tags are: 
 [('•', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('clearly', 'RB'), ('identified', 'VBN'), (';', ':')]

>> Noun Phrases are: 
 ['big data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('clearly', 'clearli'), ('identified', 'identifi'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('clearly', 'clear'), ('identified', 'identifi'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'source'), ('clearly', 'clearly'), ('identified', 'identified'), (';', ';')]



========================================== PARAGRAPH 946 ===========================================

• further data are collected and gathered from different sources, being stored and sent to the  user;  

------------------- Sentence 1 -------------------

• further data are collected and gathered from different sources, being stored and sent to the  user;

>> Tokens are: 
 ['•', 'data', 'collected', 'gathered', 'different', 'sources', ',', 'stored', 'sent', 'user', ';']

>> Bigrams are: 
 [('•', 'data'), ('data', 'collected'), ('collected', 'gathered'), ('gathered', 'different'), ('different', 'sources'), ('sources', ','), (',', 'stored'), ('stored', 'sent'), ('sent', 'user'), ('user', ';')]

>> Trigrams are: 
 [('•', 'data', 'collected'), ('data', 'collected', 'gathered'), ('collected', 'gathered', 'different'), ('gathered', 'different', 'sources'), ('different', 'sources', ','), ('sources', ',', 'stored'), (',', 'stored', 'sent'), ('stored', 'sent', 'user'), ('sent', 'user', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('data', 'NNS'), ('collected', 'VBN'), ('gathered', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (',', ','), ('stored', 'VBD'), ('sent', 'VBN'), ('user', 'NN'), (';', ':')]

>> Noun Phrases are: 
 ['• data', 'gathered different sources', 'user']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('data', 'data'), ('collected', 'collect'), ('gathered', 'gather'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('stored', 'store'), ('sent', 'sent'), ('user', 'user'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('data', 'data'), ('collected', 'collect'), ('gathered', 'gather'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('stored', 'store'), ('sent', 'sent'), ('user', 'user'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('data', 'data'), ('collected', 'collected'), ('gathered', 'gathered'), ('different', 'different'), ('sources', 'source'), (',', ','), ('stored', 'stored'), ('sent', 'sent'), ('user', 'user'), (';', ';')]



========================================== PARAGRAPH 947 ===========================================

• after defining the data sources and types of the data required for the analysis, the data is  processed through big data storage and management tools;  

------------------- Sentence 1 -------------------

• after defining the data sources and types of the data required for the analysis, the data is  processed through big data storage and management tools;

>> Tokens are: 
 ['•', 'defining', 'data', 'sources', 'types', 'data', 'required', 'analysis', ',', 'data', 'processed', 'big', 'data', 'storage', 'management', 'tools', ';']

>> Bigrams are: 
 [('•', 'defining'), ('defining', 'data'), ('data', 'sources'), ('sources', 'types'), ('types', 'data'), ('data', 'required'), ('required', 'analysis'), ('analysis', ','), (',', 'data'), ('data', 'processed'), ('processed', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'management'), ('management', 'tools'), ('tools', ';')]

>> Trigrams are: 
 [('•', 'defining', 'data'), ('defining', 'data', 'sources'), ('data', 'sources', 'types'), ('sources', 'types', 'data'), ('types', 'data', 'required'), ('data', 'required', 'analysis'), ('required', 'analysis', ','), ('analysis', ',', 'data'), (',', 'data', 'processed'), ('data', 'processed', 'big'), ('processed', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'management'), ('storage', 'management', 'tools'), ('management', 'tools', ';')]

>> POS Tags are: 
 [('•', 'JJ'), ('defining', 'VBG'), ('data', 'NNS'), ('sources', 'NNS'), ('types', 'NNS'), ('data', 'NNS'), ('required', 'VBN'), ('analysis', 'NN'), (',', ','), ('data', 'NNS'), ('processed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN'), ('tools', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['data sources types data', 'analysis', 'data', 'big data storage management tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('defining', 'defin'), ('data', 'data'), ('sources', 'sourc'), ('types', 'type'), ('data', 'data'), ('required', 'requir'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('processed', 'process'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('tools', 'tool'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('defining', 'defin'), ('data', 'data'), ('sources', 'sourc'), ('types', 'type'), ('data', 'data'), ('required', 'requir'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('processed', 'process'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('tools', 'tool'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('defining', 'defining'), ('data', 'data'), ('sources', 'source'), ('types', 'type'), ('data', 'data'), ('required', 'required'), ('analysis', 'analysis'), (',', ','), ('data', 'data'), ('processed', 'processed'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management'), ('tools', 'tool'), (';', ';')]



========================================== PARAGRAPH 948 ===========================================

• organizing, preparing, and processing the big data is completed using either big data  processing tools or a high-speed network using Extract, Transform, Load or Extract, Load,  

------------------- Sentence 1 -------------------

• organizing, preparing, and processing the big data is completed using either big data  processing tools or a high-speed network using Extract, Transform, Load or Extract, Load,

>> Tokens are: 
 ['•', 'organizing', ',', 'preparing', ',', 'processing', 'big', 'data', 'completed', 'using', 'either', 'big', 'data', 'processing', 'tools', 'high-speed', 'network', 'using', 'Extract', ',', 'Transform', ',', 'Load', 'Extract', ',', 'Load', ',']

>> Bigrams are: 
 [('•', 'organizing'), ('organizing', ','), (',', 'preparing'), ('preparing', ','), (',', 'processing'), ('processing', 'big'), ('big', 'data'), ('data', 'completed'), ('completed', 'using'), ('using', 'either'), ('either', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', 'tools'), ('tools', 'high-speed'), ('high-speed', 'network'), ('network', 'using'), ('using', 'Extract'), ('Extract', ','), (',', 'Transform'), ('Transform', ','), (',', 'Load'), ('Load', 'Extract'), ('Extract', ','), (',', 'Load'), ('Load', ',')]

>> Trigrams are: 
 [('•', 'organizing', ','), ('organizing', ',', 'preparing'), (',', 'preparing', ','), ('preparing', ',', 'processing'), (',', 'processing', 'big'), ('processing', 'big', 'data'), ('big', 'data', 'completed'), ('data', 'completed', 'using'), ('completed', 'using', 'either'), ('using', 'either', 'big'), ('either', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', 'tools'), ('processing', 'tools', 'high-speed'), ('tools', 'high-speed', 'network'), ('high-speed', 'network', 'using'), ('network', 'using', 'Extract'), ('using', 'Extract', ','), ('Extract', ',', 'Transform'), (',', 'Transform', ','), ('Transform', ',', 'Load'), (',', 'Load', 'Extract'), ('Load', 'Extract', ','), ('Extract', ',', 'Load'), (',', 'Load', ',')]

>> POS Tags are: 
 [('•', 'NN'), ('organizing', 'NN'), (',', ','), ('preparing', 'VBG'), (',', ','), ('processing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('completed', 'VBD'), ('using', 'VBG'), ('either', 'CC'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('tools', 'NNS'), ('high-speed', 'JJ'), ('network', 'NN'), ('using', 'VBG'), ('Extract', 'NNP'), (',', ','), ('Transform', 'NNP'), (',', ','), ('Load', 'NNP'), ('Extract', 'NNP'), (',', ','), ('Load', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['• organizing', 'big data', 'big data processing tools', 'high-speed network', 'Extract', 'Transform', 'Load Extract', 'Load']

>> Named Entities are: 
 [('PERSON', 'Extract'), ('PERSON', 'Transform'), ('PERSON', 'Load Extract'), ('PERSON', 'Load')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('organizing', 'organ'), (',', ','), ('preparing', 'prepar'), (',', ','), ('processing', 'process'), ('big', 'big'), ('data', 'data'), ('completed', 'complet'), ('using', 'use'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('tools', 'tool'), ('high-speed', 'high-spe'), ('network', 'network'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('organizing', 'organ'), (',', ','), ('preparing', 'prepar'), (',', ','), ('processing', 'process'), ('big', 'big'), ('data', 'data'), ('completed', 'complet'), ('using', 'use'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('tools', 'tool'), ('high-speed', 'high-spe'), ('network', 'network'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ',')]

>> Lemmatization: 
 [('•', '•'), ('organizing', 'organizing'), (',', ','), ('preparing', 'preparing'), (',', ','), ('processing', 'processing'), ('big', 'big'), ('data', 'data'), ('completed', 'completed'), ('using', 'using'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('tools', 'tool'), ('high-speed', 'high-speed'), ('network', 'network'), ('using', 'using'), ('Extract', 'Extract'), (',', ','), ('Transform', 'Transform'), (',', ','), ('Load', 'Load'), ('Extract', 'Extract'), (',', ','), ('Load', 'Load'), (',', ',')]



========================================== PARAGRAPH 949 ===========================================

Transform (ETL/ELT) processes.   

------------------- Sentence 1 -------------------

Transform (ETL/ELT) processes.

>> Tokens are: 
 ['Transform', '(', 'ETL/ELT', ')', 'processes', '.']

>> Bigrams are: 
 [('Transform', '('), ('(', 'ETL/ELT'), ('ETL/ELT', ')'), (')', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('Transform', '(', 'ETL/ELT'), ('(', 'ETL/ELT', ')'), ('ETL/ELT', ')', 'processes'), (')', 'processes', '.')]

>> POS Tags are: 
 [('Transform', 'NNP'), ('(', '('), ('ETL/ELT', 'NNP'), (')', ')'), ('processes', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 ['Transform', 'ETL/ELT']

>> Named Entities are: 
 [('GPE', 'Transform')] 

>> Stemming using Porter Stemmer: 
 [('Transform', 'transform'), ('(', '('), ('ETL/ELT', 'etl/elt'), (')', ')'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Transform', 'transform'), ('(', '('), ('ETL/ELT', 'etl/elt'), (')', ')'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Transform', 'Transform'), ('(', '('), ('ETL/ELT', 'ETL/ELT'), (')', ')'), ('processes', 'process'), ('.', '.')]



========================================== PARAGRAPH 950 ===========================================

These phases are shown in detail in Figure 21.  

------------------- Sentence 1 -------------------

These phases are shown in detail in Figure 21.

>> Tokens are: 
 ['These', 'phases', 'shown', 'detail', 'Figure', '21', '.']

>> Bigrams are: 
 [('These', 'phases'), ('phases', 'shown'), ('shown', 'detail'), ('detail', 'Figure'), ('Figure', '21'), ('21', '.')]

>> Trigrams are: 
 [('These', 'phases', 'shown'), ('phases', 'shown', 'detail'), ('shown', 'detail', 'Figure'), ('detail', 'Figure', '21'), ('Figure', '21', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('phases', 'NNS'), ('shown', 'VBN'), ('detail', 'JJ'), ('Figure', 'NN'), ('21', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['These phases', 'detail Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'figur'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'figur'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'Figure'), ('21', '21'), ('.', '.')]



========================================== PARAGRAPH 951 ===========================================

The next phase is the design phase, in which developing and analysing the possible courses of  

------------------- Sentence 1 -------------------

The next phase is the design phase, in which developing and analysing the possible courses of

>> Tokens are: 
 ['The', 'next', 'phase', 'design', 'phase', ',', 'developing', 'analysing', 'possible', 'courses']

>> Bigrams are: 
 [('The', 'next'), ('next', 'phase'), ('phase', 'design'), ('design', 'phase'), ('phase', ','), (',', 'developing'), ('developing', 'analysing'), ('analysing', 'possible'), ('possible', 'courses')]

>> Trigrams are: 
 [('The', 'next', 'phase'), ('next', 'phase', 'design'), ('phase', 'design', 'phase'), ('design', 'phase', ','), ('phase', ',', 'developing'), (',', 'developing', 'analysing'), ('developing', 'analysing', 'possible'), ('analysing', 'possible', 'courses')]

>> POS Tags are: 
 [('The', 'DT'), ('next', 'JJ'), ('phase', 'NN'), ('design', 'NN'), ('phase', 'NN'), (',', ','), ('developing', 'VBG'), ('analysing', 'VBG'), ('possible', 'JJ'), ('courses', 'NNS')]

>> Noun Phrases are: 
 ['The next phase design phase', 'possible courses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'develop'), ('analysing', 'analys'), ('possible', 'possibl'), ('courses', 'cours')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'develop'), ('analysing', 'analys'), ('possible', 'possibl'), ('courses', 'cours')]

>> Lemmatization: 
 [('The', 'The'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'developing'), ('analysing', 'analysing'), ('possible', 'possible'), ('courses', 'course')]



========================================== PARAGRAPH 952 ===========================================

actions is done by means of conceptualization or developing a problem representative model. In  

------------------- Sentence 1 -------------------

actions is done by means of conceptualization or developing a problem representative model.

>> Tokens are: 
 ['actions', 'done', 'means', 'conceptualization', 'developing', 'problem', 'representative', 'model', '.']

>> Bigrams are: 
 [('actions', 'done'), ('done', 'means'), ('means', 'conceptualization'), ('conceptualization', 'developing'), ('developing', 'problem'), ('problem', 'representative'), ('representative', 'model'), ('model', '.')]

>> Trigrams are: 
 [('actions', 'done', 'means'), ('done', 'means', 'conceptualization'), ('means', 'conceptualization', 'developing'), ('conceptualization', 'developing', 'problem'), ('developing', 'problem', 'representative'), ('problem', 'representative', 'model'), ('representative', 'model', '.')]

>> POS Tags are: 
 [('actions', 'NNS'), ('done', 'VBN'), ('means', 'VBZ'), ('conceptualization', 'NN'), ('developing', 'VBG'), ('problem', 'NN'), ('representative', 'NN'), ('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['actions', 'conceptualization', 'problem representative model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptu'), ('developing', 'develop'), ('problem', 'problem'), ('representative', 'repres'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptu'), ('developing', 'develop'), ('problem', 'problem'), ('representative', 'repres'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptualization'), ('developing', 'developing'), ('problem', 'problem'), ('representative', 'representative'), ('model', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

In

>> Tokens are: 
 ['In']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in')]

>> Lemmatization: 
 [('In', 'In')]



========================================== PARAGRAPH 953 ===========================================

this phase, the framework divided into model planning, data analytics, and analysis. Where a data  

------------------- Sentence 1 -------------------

this phase, the framework divided into model planning, data analytics, and analysis.

>> Tokens are: 
 ['phase', ',', 'framework', 'divided', 'model', 'planning', ',', 'data', 'analytics', ',', 'analysis', '.']

>> Bigrams are: 
 [('phase', ','), (',', 'framework'), ('framework', 'divided'), ('divided', 'model'), ('model', 'planning'), ('planning', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('phase', ',', 'framework'), (',', 'framework', 'divided'), ('framework', 'divided', 'model'), ('divided', 'model', 'planning'), ('model', 'planning', ','), ('planning', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'analysis'), (',', 'analysis', '.')]

>> POS Tags are: 
 [('phase', 'NN'), (',', ','), ('framework', 'NN'), ('divided', 'VBD'), ('model', 'NN'), ('planning', 'NN'), (',', ','), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['phase', 'framework', 'model planning', 'data analytics', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divid'), ('model', 'model'), ('planning', 'plan'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divid'), ('model', 'model'), ('planning', 'plan'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divided'), ('model', 'model'), ('planning', 'planning'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Where a data

>> Tokens are: 
 ['Where', 'data']

>> Bigrams are: 
 [('Where', 'data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Where', 'WRB'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data', 'data')]

>> Lemmatization: 
 [('Where', 'Where'), ('data', 'data')]



========================================== PARAGRAPH 954 ===========================================

analytics model is selected, this is planned, applied, and then analysed.  

------------------- Sentence 1 -------------------

analytics model is selected, this is planned, applied, and then analysed.

>> Tokens are: 
 ['analytics', 'model', 'selected', ',', 'planned', ',', 'applied', ',', 'analysed', '.']

>> Bigrams are: 
 [('analytics', 'model'), ('model', 'selected'), ('selected', ','), (',', 'planned'), ('planned', ','), (',', 'applied'), ('applied', ','), (',', 'analysed'), ('analysed', '.')]

>> Trigrams are: 
 [('analytics', 'model', 'selected'), ('model', 'selected', ','), ('selected', ',', 'planned'), (',', 'planned', ','), ('planned', ',', 'applied'), (',', 'applied', ','), ('applied', ',', 'analysed'), (',', 'analysed', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('model', 'NN'), ('selected', 'VBN'), (',', ','), ('planned', 'VBN'), (',', ','), ('applied', 'VBN'), (',', ','), ('analysed', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('model', 'model'), ('selected', 'select'), (',', ','), ('planned', 'plan'), (',', ','), ('applied', 'appli'), (',', ','), ('analysed', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('model', 'model'), ('selected', 'select'), (',', ','), ('planned', 'plan'), (',', ','), ('applied', 'appli'), (',', ','), ('analysed', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('model', 'model'), ('selected', 'selected'), (',', ','), ('planned', 'planned'), (',', ','), ('applied', 'applied'), (',', ','), ('analysed', 'analysed'), ('.', '.')]



========================================== PARAGRAPH 955 ===========================================

The third phase of decision making is the choice phase, and in this phase, the proposed solution  

------------------- Sentence 1 -------------------

The third phase of decision making is the choice phase, and in this phase, the proposed solution

>> Tokens are: 
 ['The', 'third', 'phase', 'decision', 'making', 'choice', 'phase', ',', 'phase', ',', 'proposed', 'solution']

>> Bigrams are: 
 [('The', 'third'), ('third', 'phase'), ('phase', 'decision'), ('decision', 'making'), ('making', 'choice'), ('choice', 'phase'), ('phase', ','), (',', 'phase'), ('phase', ','), (',', 'proposed'), ('proposed', 'solution')]

>> Trigrams are: 
 [('The', 'third', 'phase'), ('third', 'phase', 'decision'), ('phase', 'decision', 'making'), ('decision', 'making', 'choice'), ('making', 'choice', 'phase'), ('choice', 'phase', ','), ('phase', ',', 'phase'), (',', 'phase', ','), ('phase', ',', 'proposed'), (',', 'proposed', 'solution')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('phase', 'NN'), ('decision', 'NN'), ('making', 'VBG'), ('choice', 'NN'), ('phase', 'NN'), (',', ','), ('phase', 'NN'), (',', ','), ('proposed', 'VBN'), ('solution', 'NN')]

>> Noun Phrases are: 
 ['The third phase decision', 'choice phase', 'phase', 'solution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('choice', 'choic'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('choice', 'choic'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decision'), ('making', 'making'), ('choice', 'choice'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'proposed'), ('solution', 'solution')]



========================================== PARAGRAPH 956 ===========================================

impact is evaluated. The final phase in decision making is the implementation phase; in this phase,  

------------------- Sentence 1 -------------------

impact is evaluated.

>> Tokens are: 
 ['impact', 'evaluated', '.']

>> Bigrams are: 
 [('impact', 'evaluated'), ('evaluated', '.')]

>> Trigrams are: 
 [('impact', 'evaluated', '.')]

>> POS Tags are: 
 [('impact', 'NN'), ('evaluated', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['impact']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('impact', 'impact'), ('evaluated', 'evalu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('impact', 'impact'), ('evaluated', 'evalu'), ('.', '.')]

>> Lemmatization: 
 [('impact', 'impact'), ('evaluated', 'evaluated'), ('.', '.')]


------------------- Sentence 2 -------------------

The final phase in decision making is the implementation phase; in this phase,

>> Tokens are: 
 ['The', 'final', 'phase', 'decision', 'making', 'implementation', 'phase', ';', 'phase', ',']

>> Bigrams are: 
 [('The', 'final'), ('final', 'phase'), ('phase', 'decision'), ('decision', 'making'), ('making', 'implementation'), ('implementation', 'phase'), ('phase', ';'), (';', 'phase'), ('phase', ',')]

>> Trigrams are: 
 [('The', 'final', 'phase'), ('final', 'phase', 'decision'), ('phase', 'decision', 'making'), ('decision', 'making', 'implementation'), ('making', 'implementation', 'phase'), ('implementation', 'phase', ';'), ('phase', ';', 'phase'), (';', 'phase', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('final', 'JJ'), ('phase', 'NN'), ('decision', 'NN'), ('making', 'VBG'), ('implementation', 'JJ'), ('phase', 'NN'), (';', ':'), ('phase', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['The final phase decision', 'implementation phase', 'phase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('implementation', 'implement'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('implementation', 'implement'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decision'), ('making', 'making'), ('implementation', 'implementation'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ',')]



========================================== PARAGRAPH 957 ===========================================

the proposed solution is implemented (Elgendy, N. and Elragal, A., 2016). 

------------------- Sentence 1 -------------------

the proposed solution is implemented (Elgendy, N. and Elragal, A., 2016).

>> Tokens are: 
 ['proposed', 'solution', 'implemented', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('proposed', 'solution'), ('solution', 'implemented'), ('implemented', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('proposed', 'solution', 'implemented'), ('solution', 'implemented', '('), ('implemented', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('proposed', 'VBN'), ('solution', 'NN'), ('implemented', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['solution', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('proposed', 'propos'), ('solution', 'solut'), ('implemented', 'implement'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('proposed', 'propos'), ('solution', 'solut'), ('implemented', 'implement'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('proposed', 'proposed'), ('solution', 'solution'), ('implemented', 'implemented'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 958 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 959 ===========================================

35  

------------------- Sentence 1 -------------------

35

>> Tokens are: 
 ['35']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('35', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35')]

>> Stemming using Snowball Stemmer: 
 [('35', '35')]

>> Lemmatization: 
 [('35', '35')]



========================================== PARAGRAPH 960 ===========================================

  


========================================== PARAGRAPH 961 ===========================================

   


========================================== PARAGRAPH 962 ===========================================

  


========================================== PARAGRAPH 963 ===========================================

  


========================================== PARAGRAPH 964 ===========================================

Figure 21: B-DAD framework, adopted from (Elgendy and Elragal, 2016).  

------------------- Sentence 1 -------------------

Figure 21: B-DAD framework, adopted from (Elgendy and Elragal, 2016).

>> Tokens are: 
 ['Figure', '21', ':', 'B-DAD', 'framework', ',', 'adopted', '(', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Figure', '21'), ('21', ':'), (':', 'B-DAD'), ('B-DAD', 'framework'), ('framework', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '21', ':'), ('21', ':', 'B-DAD'), (':', 'B-DAD', 'framework'), ('B-DAD', 'framework', ','), ('framework', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('21', 'CD'), (':', ':'), ('B-DAD', 'JJ'), ('framework', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'B-DAD framework', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('21', '21'), (':', ':'), ('B-DAD', 'b-dad'), ('framework', 'framework'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('21', '21'), (':', ':'), ('B-DAD', 'b-dad'), ('framework', 'framework'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('21', '21'), (':', ':'), ('B-DAD', 'B-DAD'), ('framework', 'framework'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 965 ===========================================

   


========================================== PARAGRAPH 966 ===========================================

 


========================================== PARAGRAPH 967 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 968 ===========================================

36  

------------------- Sentence 1 -------------------

36

>> Tokens are: 
 ['36']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('36', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('36', '36')]

>> Stemming using Snowball Stemmer: 
 [('36', '36')]

>> Lemmatization: 
 [('36', '36')]



========================================== PARAGRAPH 969 ===========================================

  


========================================== PARAGRAPH 970 ===========================================

Elgendy and Elragal (2016) shows the decision-making process and how big data analytics can be  

------------------- Sentence 1 -------------------

Elgendy and Elragal (2016) shows the decision-making process and how big data analytics can be

>> Tokens are: 
 ['Elgendy', 'Elragal', '(', '2016', ')', 'shows', 'decision-making', 'process', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('Elgendy', 'Elragal'), ('Elragal', '('), ('(', '2016'), ('2016', ')'), (')', 'shows'), ('shows', 'decision-making'), ('decision-making', 'process'), ('process', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Elgendy', 'Elragal', '('), ('Elragal', '(', '2016'), ('(', '2016', ')'), ('2016', ')', 'shows'), (')', 'shows', 'decision-making'), ('shows', 'decision-making', 'process'), ('decision-making', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), ('Elragal', 'NNP'), ('(', '('), ('2016', 'CD'), (')', ')'), ('shows', 'VBZ'), ('decision-making', 'JJ'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Elgendy Elragal', 'decision-making process', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Elgendy'), ('ORGANIZATION', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), ('Elragal', 'elrag'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-mak'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), ('Elragal', 'elrag'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-mak'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-making'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 971 ===========================================

integrated into it. Using the methodology of design science, the B-DAD can be used to map big  

------------------- Sentence 1 -------------------

integrated into it.

>> Tokens are: 
 ['integrated', '.']

>> Bigrams are: 
 [('integrated', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('integrated', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('integrated', 'integr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('integrated', 'integr'), ('.', '.')]

>> Lemmatization: 
 [('integrated', 'integrated'), ('.', '.')]


------------------- Sentence 2 -------------------

Using the methodology of design science, the B-DAD can be used to map big

>> Tokens are: 
 ['Using', 'methodology', 'design', 'science', ',', 'B-DAD', 'used', 'map', 'big']

>> Bigrams are: 
 [('Using', 'methodology'), ('methodology', 'design'), ('design', 'science'), ('science', ','), (',', 'B-DAD'), ('B-DAD', 'used'), ('used', 'map'), ('map', 'big')]

>> Trigrams are: 
 [('Using', 'methodology', 'design'), ('methodology', 'design', 'science'), ('design', 'science', ','), ('science', ',', 'B-DAD'), (',', 'B-DAD', 'used'), ('B-DAD', 'used', 'map'), ('used', 'map', 'big')]

>> POS Tags are: 
 [('Using', 'VBG'), ('methodology', 'NN'), ('design', 'NN'), ('science', 'NN'), (',', ','), ('B-DAD', 'NNP'), ('used', 'VBD'), ('map', 'NN'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['methodology design science', 'B-DAD', 'map']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('methodology', 'methodolog'), ('design', 'design'), ('science', 'scienc'), (',', ','), ('B-DAD', 'b-dad'), ('used', 'use'), ('map', 'map'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('methodology', 'methodolog'), ('design', 'design'), ('science', 'scienc'), (',', ','), ('B-DAD', 'b-dad'), ('used', 'use'), ('map', 'map'), ('big', 'big')]

>> Lemmatization: 
 [('Using', 'Using'), ('methodology', 'methodology'), ('design', 'design'), ('science', 'science'), (',', ','), ('B-DAD', 'B-DAD'), ('used', 'used'), ('map', 'map'), ('big', 'big')]



========================================== PARAGRAPH 972 ===========================================

data tools and analytics to various decision-making phases. As a result, the added value gained by  

------------------- Sentence 1 -------------------

data tools and analytics to various decision-making phases.

>> Tokens are: 
 ['data', 'tools', 'analytics', 'various', 'decision-making', 'phases', '.']

>> Bigrams are: 
 [('data', 'tools'), ('tools', 'analytics'), ('analytics', 'various'), ('various', 'decision-making'), ('decision-making', 'phases'), ('phases', '.')]

>> Trigrams are: 
 [('data', 'tools', 'analytics'), ('tools', 'analytics', 'various'), ('analytics', 'various', 'decision-making'), ('various', 'decision-making', 'phases'), ('decision-making', 'phases', '.')]

>> POS Tags are: 
 [('data', 'NN'), ('tools', 'NNS'), ('analytics', 'NNS'), ('various', 'JJ'), ('decision-making', 'JJ'), ('phases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data tools analytics', 'various decision-making phases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('tools', 'tool'), ('analytics', 'analyt'), ('various', 'variou'), ('decision-making', 'decision-mak'), ('phases', 'phase'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('tools', 'tool'), ('analytics', 'analyt'), ('various', 'various'), ('decision-making', 'decision-mak'), ('phases', 'phase'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('tools', 'tool'), ('analytics', 'analytics'), ('various', 'various'), ('decision-making', 'decision-making'), ('phases', 'phase'), ('.', '.')]


------------------- Sentence 2 -------------------

As a result, the added value gained by

>> Tokens are: 
 ['As', 'result', ',', 'added', 'value', 'gained']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'added'), ('added', 'value'), ('value', 'gained')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'added'), (',', 'added', 'value'), ('added', 'value', 'gained')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('added', 'VBD'), ('value', 'NN'), ('gained', 'VBN')]

>> Noun Phrases are: 
 ['result', 'value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('added', 'ad'), ('value', 'valu'), ('gained', 'gain')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('added', 'ad'), ('value', 'valu'), ('gained', 'gain')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('added', 'added'), ('value', 'value'), ('gained', 'gained')]



========================================== PARAGRAPH 973 ===========================================

integrating big data analytics into the decision-making process can be identified (Elgendy and  

------------------- Sentence 1 -------------------

integrating big data analytics into the decision-making process can be identified (Elgendy and

>> Tokens are: 
 ['integrating', 'big', 'data', 'analytics', 'decision-making', 'process', 'identified', '(', 'Elgendy']

>> Bigrams are: 
 [('integrating', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'decision-making'), ('decision-making', 'process'), ('process', 'identified'), ('identified', '('), ('(', 'Elgendy')]

>> Trigrams are: 
 [('integrating', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'decision-making'), ('analytics', 'decision-making', 'process'), ('decision-making', 'process', 'identified'), ('process', 'identified', '('), ('identified', '(', 'Elgendy')]

>> POS Tags are: 
 [('integrating', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('decision-making', 'JJ'), ('process', 'NN'), ('identified', 'VBN'), ('(', '('), ('Elgendy', 'NNP')]

>> Noun Phrases are: 
 ['big data analytics', 'decision-making process', 'Elgendy']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('integrating', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('decision-making', 'decision-mak'), ('process', 'process'), ('identified', 'identifi'), ('(', '('), ('Elgendy', 'elgendi')]

>> Stemming using Snowball Stemmer: 
 [('integrating', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('decision-making', 'decision-mak'), ('process', 'process'), ('identified', 'identifi'), ('(', '('), ('Elgendy', 'elgendi')]

>> Lemmatization: 
 [('integrating', 'integrating'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('decision-making', 'decision-making'), ('process', 'process'), ('identified', 'identified'), ('(', '('), ('Elgendy', 'Elgendy')]



========================================== PARAGRAPH 974 ===========================================

Elragal, 2014; Elgendy and Elragal, 2016).  

------------------- Sentence 1 -------------------

Elragal, 2014; Elgendy and Elragal, 2016).

>> Tokens are: 
 ['Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Elragal'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 975 ===========================================

Despite certain challenges, decision making is supported by advanced technologies and tools in  

------------------- Sentence 1 -------------------

Despite certain challenges, decision making is supported by advanced technologies and tools in

>> Tokens are: 
 ['Despite', 'certain', 'challenges', ',', 'decision', 'making', 'supported', 'advanced', 'technologies', 'tools']

>> Bigrams are: 
 [('Despite', 'certain'), ('certain', 'challenges'), ('challenges', ','), (',', 'decision'), ('decision', 'making'), ('making', 'supported'), ('supported', 'advanced'), ('advanced', 'technologies'), ('technologies', 'tools')]

>> Trigrams are: 
 [('Despite', 'certain', 'challenges'), ('certain', 'challenges', ','), ('challenges', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', 'supported'), ('making', 'supported', 'advanced'), ('supported', 'advanced', 'technologies'), ('advanced', 'technologies', 'tools')]

>> POS Tags are: 
 [('Despite', 'IN'), ('certain', 'JJ'), ('challenges', 'NNS'), (',', ','), ('decision', 'NN'), ('making', 'NN'), ('supported', 'VBD'), ('advanced', 'JJ'), ('technologies', 'NNS'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['certain challenges', 'decision making', 'advanced technologies tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Despite', 'despit'), ('certain', 'certain'), ('challenges', 'challeng'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('supported', 'support'), ('advanced', 'advanc'), ('technologies', 'technolog'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Despite', 'despit'), ('certain', 'certain'), ('challenges', 'challeng'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('supported', 'support'), ('advanced', 'advanc'), ('technologies', 'technolog'), ('tools', 'tool')]

>> Lemmatization: 
 [('Despite', 'Despite'), ('certain', 'certain'), ('challenges', 'challenge'), (',', ','), ('decision', 'decision'), ('making', 'making'), ('supported', 'supported'), ('advanced', 'advanced'), ('technologies', 'technology'), ('tools', 'tool')]



========================================== PARAGRAPH 976 ===========================================

each phase of processing and applying big data, and the use of big data now plays an important  

------------------- Sentence 1 -------------------

each phase of processing and applying big data, and the use of big data now plays an important

>> Tokens are: 
 ['phase', 'processing', 'applying', 'big', 'data', ',', 'use', 'big', 'data', 'plays', 'important']

>> Bigrams are: 
 [('phase', 'processing'), ('processing', 'applying'), ('applying', 'big'), ('big', 'data'), ('data', ','), (',', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'plays'), ('plays', 'important')]

>> Trigrams are: 
 [('phase', 'processing', 'applying'), ('processing', 'applying', 'big'), ('applying', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'use'), (',', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'plays'), ('data', 'plays', 'important')]

>> POS Tags are: 
 [('phase', 'NN'), ('processing', 'NN'), ('applying', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('plays', 'NNS'), ('important', 'JJ')]

>> Noun Phrases are: 
 ['phase processing', 'big data', 'use', 'big data plays']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('phase', 'phase'), ('processing', 'process'), ('applying', 'appli'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'import')]

>> Stemming using Snowball Stemmer: 
 [('phase', 'phase'), ('processing', 'process'), ('applying', 'appli'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'import')]

>> Lemmatization: 
 [('phase', 'phase'), ('processing', 'processing'), ('applying', 'applying'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'important')]



========================================== PARAGRAPH 977 ===========================================

role in many decisions making and forecasting domains such as healthcare, retail, tourism,  

------------------- Sentence 1 -------------------

role in many decisions making and forecasting domains such as healthcare, retail, tourism,

>> Tokens are: 
 ['role', 'many', 'decisions', 'making', 'forecasting', 'domains', 'healthcare', ',', 'retail', ',', 'tourism', ',']

>> Bigrams are: 
 [('role', 'many'), ('many', 'decisions'), ('decisions', 'making'), ('making', 'forecasting'), ('forecasting', 'domains'), ('domains', 'healthcare'), ('healthcare', ','), (',', 'retail'), ('retail', ','), (',', 'tourism'), ('tourism', ',')]

>> Trigrams are: 
 [('role', 'many', 'decisions'), ('many', 'decisions', 'making'), ('decisions', 'making', 'forecasting'), ('making', 'forecasting', 'domains'), ('forecasting', 'domains', 'healthcare'), ('domains', 'healthcare', ','), ('healthcare', ',', 'retail'), (',', 'retail', ','), ('retail', ',', 'tourism'), (',', 'tourism', ',')]

>> POS Tags are: 
 [('role', 'NN'), ('many', 'JJ'), ('decisions', 'NNS'), ('making', 'VBG'), ('forecasting', 'NN'), ('domains', 'NNS'), ('healthcare', 'NN'), (',', ','), ('retail', 'JJ'), (',', ','), ('tourism', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['role', 'many decisions', 'forecasting domains healthcare', 'tourism']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('role', 'role'), ('many', 'mani'), ('decisions', 'decis'), ('making', 'make'), ('forecasting', 'forecast'), ('domains', 'domain'), ('healthcare', 'healthcar'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('role', 'role'), ('many', 'mani'), ('decisions', 'decis'), ('making', 'make'), ('forecasting', 'forecast'), ('domains', 'domain'), ('healthcare', 'healthcar'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ',')]

>> Lemmatization: 
 [('role', 'role'), ('many', 'many'), ('decisions', 'decision'), ('making', 'making'), ('forecasting', 'forecasting'), ('domains', 'domain'), ('healthcare', 'healthcare'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ',')]



========================================== PARAGRAPH 978 ===========================================

marketing, the financial sector, and transportation (Elgendy and Elragal, 2014).  

------------------- Sentence 1 -------------------

marketing, the financial sector, and transportation (Elgendy and Elragal, 2014).

>> Tokens are: 
 ['marketing', ',', 'financial', 'sector', ',', 'transportation', '(', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('marketing', ','), (',', 'financial'), ('financial', 'sector'), ('sector', ','), (',', 'transportation'), ('transportation', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('marketing', ',', 'financial'), (',', 'financial', 'sector'), ('financial', 'sector', ','), ('sector', ',', 'transportation'), (',', 'transportation', '('), ('transportation', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('marketing', 'NN'), (',', ','), ('financial', 'JJ'), ('sector', 'NN'), (',', ','), ('transportation', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['marketing', 'financial sector', 'transportation', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('marketing', 'market'), (',', ','), ('financial', 'financi'), ('sector', 'sector'), (',', ','), ('transportation', 'transport'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('marketing', 'market'), (',', ','), ('financial', 'financi'), ('sector', 'sector'), (',', ','), ('transportation', 'transport'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('marketing', 'marketing'), (',', ','), ('financial', 'financial'), ('sector', 'sector'), (',', ','), ('transportation', 'transportation'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 979 ===========================================

Big data use requires decision support, however. The decision maker must identify the values  

------------------- Sentence 1 -------------------

Big data use requires decision support, however.

>> Tokens are: 
 ['Big', 'data', 'use', 'requires', 'decision', 'support', ',', 'however', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'use'), ('use', 'requires'), ('requires', 'decision'), ('decision', 'support'), ('support', ','), (',', 'however'), ('however', '.')]

>> Trigrams are: 
 [('Big', 'data', 'use'), ('data', 'use', 'requires'), ('use', 'requires', 'decision'), ('requires', 'decision', 'support'), ('decision', 'support', ','), ('support', ',', 'however'), (',', 'however', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('use', 'NN'), ('requires', 'VBZ'), ('decision', 'NN'), ('support', 'NN'), (',', ','), ('however', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data use', 'decision support']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('use', 'use'), ('requires', 'requir'), ('decision', 'decis'), ('support', 'support'), (',', ','), ('however', 'howev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('use', 'use'), ('requires', 'requir'), ('decision', 'decis'), ('support', 'support'), (',', ','), ('however', 'howev'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('use', 'use'), ('requires', 'requires'), ('decision', 'decision'), ('support', 'support'), (',', ','), ('however', 'however'), ('.', '.')]


------------------- Sentence 2 -------------------

The decision maker must identify the values

>> Tokens are: 
 ['The', 'decision', 'maker', 'must', 'identify', 'values']

>> Bigrams are: 
 [('The', 'decision'), ('decision', 'maker'), ('maker', 'must'), ('must', 'identify'), ('identify', 'values')]

>> Trigrams are: 
 [('The', 'decision', 'maker'), ('decision', 'maker', 'must'), ('maker', 'must', 'identify'), ('must', 'identify', 'values')]

>> POS Tags are: 
 [('The', 'DT'), ('decision', 'NN'), ('maker', 'NN'), ('must', 'MD'), ('identify', 'VB'), ('values', 'NNS')]

>> Noun Phrases are: 
 ['The decision maker', 'values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('decision', 'decis'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identifi'), ('values', 'valu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('decision', 'decis'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identifi'), ('values', 'valu')]

>> Lemmatization: 
 [('The', 'The'), ('decision', 'decision'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identify'), ('values', 'value')]



========================================== PARAGRAPH 980 ===========================================

required and focus on finding methodologies, technologies, and tools that allow them to select the  

------------------- Sentence 1 -------------------

required and focus on finding methodologies, technologies, and tools that allow them to select the

>> Tokens are: 
 ['required', 'focus', 'finding', 'methodologies', ',', 'technologies', ',', 'tools', 'allow', 'select']

>> Bigrams are: 
 [('required', 'focus'), ('focus', 'finding'), ('finding', 'methodologies'), ('methodologies', ','), (',', 'technologies'), ('technologies', ','), (',', 'tools'), ('tools', 'allow'), ('allow', 'select')]

>> Trigrams are: 
 [('required', 'focus', 'finding'), ('focus', 'finding', 'methodologies'), ('finding', 'methodologies', ','), ('methodologies', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'tools'), (',', 'tools', 'allow'), ('tools', 'allow', 'select')]

>> POS Tags are: 
 [('required', 'VBN'), ('focus', 'NN'), ('finding', 'VBG'), ('methodologies', 'NNS'), (',', ','), ('technologies', 'NNS'), (',', ','), ('tools', 'NNS'), ('allow', 'VBP'), ('select', 'NN')]

>> Noun Phrases are: 
 ['focus', 'methodologies', 'technologies', 'tools', 'select']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('required', 'requir'), ('focus', 'focu'), ('finding', 'find'), ('methodologies', 'methodolog'), (',', ','), ('technologies', 'technolog'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select')]

>> Stemming using Snowball Stemmer: 
 [('required', 'requir'), ('focus', 'focus'), ('finding', 'find'), ('methodologies', 'methodolog'), (',', ','), ('technologies', 'technolog'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select')]

>> Lemmatization: 
 [('required', 'required'), ('focus', 'focus'), ('finding', 'finding'), ('methodologies', 'methodology'), (',', ','), ('technologies', 'technology'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select')]



========================================== PARAGRAPH 981 ===========================================

best decision; this process thus relies on the assumption that the decision maker is sensible and  

------------------- Sentence 1 -------------------

best decision; this process thus relies on the assumption that the decision maker is sensible and

>> Tokens are: 
 ['best', 'decision', ';', 'process', 'thus', 'relies', 'assumption', 'decision', 'maker', 'sensible']

>> Bigrams are: 
 [('best', 'decision'), ('decision', ';'), (';', 'process'), ('process', 'thus'), ('thus', 'relies'), ('relies', 'assumption'), ('assumption', 'decision'), ('decision', 'maker'), ('maker', 'sensible')]

>> Trigrams are: 
 [('best', 'decision', ';'), ('decision', ';', 'process'), (';', 'process', 'thus'), ('process', 'thus', 'relies'), ('thus', 'relies', 'assumption'), ('relies', 'assumption', 'decision'), ('assumption', 'decision', 'maker'), ('decision', 'maker', 'sensible')]

>> POS Tags are: 
 [('best', 'JJS'), ('decision', 'NN'), (';', ':'), ('process', 'NN'), ('thus', 'RB'), ('relies', 'VBZ'), ('assumption', 'NN'), ('decision', 'NN'), ('maker', 'NN'), ('sensible', 'NN')]

>> Noun Phrases are: 
 ['decision', 'process', 'assumption decision maker sensible']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('best', 'best'), ('decision', 'decis'), (';', ';'), ('process', 'process'), ('thus', 'thu'), ('relies', 'reli'), ('assumption', 'assumpt'), ('decision', 'decis'), ('maker', 'maker'), ('sensible', 'sensibl')]

>> Stemming using Snowball Stemmer: 
 [('best', 'best'), ('decision', 'decis'), (';', ';'), ('process', 'process'), ('thus', 'thus'), ('relies', 'reli'), ('assumption', 'assumpt'), ('decision', 'decis'), ('maker', 'maker'), ('sensible', 'sensibl')]

>> Lemmatization: 
 [('best', 'best'), ('decision', 'decision'), (';', ';'), ('process', 'process'), ('thus', 'thus'), ('relies', 'relies'), ('assumption', 'assumption'), ('decision', 'decision'), ('maker', 'maker'), ('sensible', 'sensible')]



========================================== PARAGRAPH 982 ===========================================

reasonable (Wang et al., 2016).  

------------------- Sentence 1 -------------------

reasonable (Wang et al., 2016).

>> Tokens are: 
 ['reasonable', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('reasonable', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('reasonable', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('reasonable', 'JJ'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('reasonable', 'reason'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reasonable', 'reason'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('reasonable', 'reasonable'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 983 ===========================================

Generally, decision making occurs at the stage of each big data procedure, including data storage,  

------------------- Sentence 1 -------------------

Generally, decision making occurs at the stage of each big data procedure, including data storage,

>> Tokens are: 
 ['Generally', ',', 'decision', 'making', 'occurs', 'stage', 'big', 'data', 'procedure', ',', 'including', 'data', 'storage', ',']

>> Bigrams are: 
 [('Generally', ','), (',', 'decision'), ('decision', 'making'), ('making', 'occurs'), ('occurs', 'stage'), ('stage', 'big'), ('big', 'data'), ('data', 'procedure'), ('procedure', ','), (',', 'including'), ('including', 'data'), ('data', 'storage'), ('storage', ',')]

>> Trigrams are: 
 [('Generally', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', 'occurs'), ('making', 'occurs', 'stage'), ('occurs', 'stage', 'big'), ('stage', 'big', 'data'), ('big', 'data', 'procedure'), ('data', 'procedure', ','), ('procedure', ',', 'including'), (',', 'including', 'data'), ('including', 'data', 'storage'), ('data', 'storage', ',')]

>> POS Tags are: 
 [('Generally', 'RB'), (',', ','), ('decision', 'NN'), ('making', 'NN'), ('occurs', 'VBZ'), ('stage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('procedure', 'NN'), (',', ','), ('including', 'VBG'), ('data', 'NNS'), ('storage', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['decision making', 'stage', 'big data procedure', 'data storage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Generally', 'gener'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('occurs', 'occur'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedur'), (',', ','), ('including', 'includ'), ('data', 'data'), ('storage', 'storag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Generally', 'general'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('occurs', 'occur'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedur'), (',', ','), ('including', 'includ'), ('data', 'data'), ('storage', 'storag'), (',', ',')]

>> Lemmatization: 
 [('Generally', 'Generally'), (',', ','), ('decision', 'decision'), ('making', 'making'), ('occurs', 'occurs'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedure'), (',', ','), ('including', 'including'), ('data', 'data'), ('storage', 'storage'), (',', ',')]



========================================== PARAGRAPH 984 ===========================================

data cleaning, data analysis, data visualisation, and prediction. However, it is sometimes difficult  

------------------- Sentence 1 -------------------

data cleaning, data analysis, data visualisation, and prediction.

>> Tokens are: 
 ['data', 'cleaning', ',', 'data', 'analysis', ',', 'data', 'visualisation', ',', 'prediction', '.']

>> Bigrams are: 
 [('data', 'cleaning'), ('cleaning', ','), (',', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'data'), ('data', 'visualisation'), ('visualisation', ','), (',', 'prediction'), ('prediction', '.')]

>> Trigrams are: 
 [('data', 'cleaning', ','), ('cleaning', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'data'), (',', 'data', 'visualisation'), ('data', 'visualisation', ','), ('visualisation', ',', 'prediction'), (',', 'prediction', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('cleaning', 'NN'), (',', ','), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('data', 'NNS'), ('visualisation', 'NN'), (',', ','), ('prediction', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data cleaning', 'data analysis', 'data visualisation', 'prediction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('visualisation', 'visualis'), (',', ','), ('prediction', 'predict'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('visualisation', 'visualis'), (',', ','), ('prediction', 'predict'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('cleaning', 'cleaning'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('data', 'data'), ('visualisation', 'visualisation'), (',', ','), ('prediction', 'prediction'), ('.', '.')]


------------------- Sentence 2 -------------------

However, it is sometimes difficult

>> Tokens are: 
 ['However', ',', 'sometimes', 'difficult']

>> Bigrams are: 
 [('However', ','), (',', 'sometimes'), ('sometimes', 'difficult')]

>> Trigrams are: 
 [('However', ',', 'sometimes'), (',', 'sometimes', 'difficult')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('sometimes', 'RB'), ('difficult', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('sometimes', 'sometim'), ('difficult', 'difficult')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('sometimes', 'sometim'), ('difficult', 'difficult')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('sometimes', 'sometimes'), ('difficult', 'difficult')]



========================================== PARAGRAPH 985 ===========================================

to achieve a suitable solution for each procedure, and many technologies and techniques can be  

------------------- Sentence 1 -------------------

to achieve a suitable solution for each procedure, and many technologies and techniques can be

>> Tokens are: 
 ['achieve', 'suitable', 'solution', 'procedure', ',', 'many', 'technologies', 'techniques']

>> Bigrams are: 
 [('achieve', 'suitable'), ('suitable', 'solution'), ('solution', 'procedure'), ('procedure', ','), (',', 'many'), ('many', 'technologies'), ('technologies', 'techniques')]

>> Trigrams are: 
 [('achieve', 'suitable', 'solution'), ('suitable', 'solution', 'procedure'), ('solution', 'procedure', ','), ('procedure', ',', 'many'), (',', 'many', 'technologies'), ('many', 'technologies', 'techniques')]

>> POS Tags are: 
 [('achieve', 'RB'), ('suitable', 'JJ'), ('solution', 'NN'), ('procedure', 'NN'), (',', ','), ('many', 'JJ'), ('technologies', 'NNS'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['suitable solution procedure', 'many technologies techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('achieve', 'achiev'), ('suitable', 'suitabl'), ('solution', 'solut'), ('procedure', 'procedur'), (',', ','), ('many', 'mani'), ('technologies', 'technolog'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('achieve', 'achiev'), ('suitable', 'suitabl'), ('solution', 'solut'), ('procedure', 'procedur'), (',', ','), ('many', 'mani'), ('technologies', 'technolog'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('achieve', 'achieve'), ('suitable', 'suitable'), ('solution', 'solution'), ('procedure', 'procedure'), (',', ','), ('many', 'many'), ('technologies', 'technology'), ('techniques', 'technique')]



========================================== PARAGRAPH 986 ===========================================

used for decision making in big data work. Some decision making requires input from many  

------------------- Sentence 1 -------------------

used for decision making in big data work.

>> Tokens are: 
 ['used', 'decision', 'making', 'big', 'data', 'work', '.']

>> Bigrams are: 
 [('used', 'decision'), ('decision', 'making'), ('making', 'big'), ('big', 'data'), ('data', 'work'), ('work', '.')]

>> Trigrams are: 
 [('used', 'decision', 'making'), ('decision', 'making', 'big'), ('making', 'big', 'data'), ('big', 'data', 'work'), ('data', 'work', '.')]

>> POS Tags are: 
 [('used', 'VBN'), ('decision', 'NN'), ('making', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['decision', 'big data work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('used', 'used'), ('decision', 'decision'), ('making', 'making'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]


------------------- Sentence 2 -------------------

Some decision making requires input from many

>> Tokens are: 
 ['Some', 'decision', 'making', 'requires', 'input', 'many']

>> Bigrams are: 
 [('Some', 'decision'), ('decision', 'making'), ('making', 'requires'), ('requires', 'input'), ('input', 'many')]

>> Trigrams are: 
 [('Some', 'decision', 'making'), ('decision', 'making', 'requires'), ('making', 'requires', 'input'), ('requires', 'input', 'many')]

>> POS Tags are: 
 [('Some', 'DT'), ('decision', 'NN'), ('making', 'NN'), ('requires', 'VBZ'), ('input', 'VB'), ('many', 'JJ')]

>> Noun Phrases are: 
 ['Some decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('decision', 'decis'), ('making', 'make'), ('requires', 'requir'), ('input', 'input'), ('many', 'mani')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('decision', 'decis'), ('making', 'make'), ('requires', 'requir'), ('input', 'input'), ('many', 'mani')]

>> Lemmatization: 
 [('Some', 'Some'), ('decision', 'decision'), ('making', 'making'), ('requires', 'requires'), ('input', 'input'), ('many', 'many')]



========================================== PARAGRAPH 987 ===========================================

disciplines, including data mining, statistics, machine learning, visualisation, and social network  

------------------- Sentence 1 -------------------

disciplines, including data mining, statistics, machine learning, visualisation, and social network

>> Tokens are: 
 ['disciplines', ',', 'including', 'data', 'mining', ',', 'statistics', ',', 'machine', 'learning', ',', 'visualisation', ',', 'social', 'network']

>> Bigrams are: 
 [('disciplines', ','), (',', 'including'), ('including', 'data'), ('data', 'mining'), ('mining', ','), (',', 'statistics'), ('statistics', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'visualisation'), ('visualisation', ','), (',', 'social'), ('social', 'network')]

>> Trigrams are: 
 [('disciplines', ',', 'including'), (',', 'including', 'data'), ('including', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'statistics'), (',', 'statistics', ','), ('statistics', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'visualisation'), (',', 'visualisation', ','), ('visualisation', ',', 'social'), (',', 'social', 'network')]

>> POS Tags are: 
 [('disciplines', 'NNS'), (',', ','), ('including', 'VBG'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('statistics', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('visualisation', 'NN'), (',', ','), ('social', 'JJ'), ('network', 'NN')]

>> Noun Phrases are: 
 ['disciplines', 'data mining', 'statistics', 'machine learning', 'visualisation', 'social network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('statistics', 'statist'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('social', 'social'), ('network', 'network')]

>> Stemming using Snowball Stemmer: 
 [('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('statistics', 'statist'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('social', 'social'), ('network', 'network')]

>> Lemmatization: 
 [('disciplines', 'discipline'), (',', ','), ('including', 'including'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('statistics', 'statistic'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('visualisation', 'visualisation'), (',', ','), ('social', 'social'), ('network', 'network')]



========================================== PARAGRAPH 988 ===========================================

analysis. Specific big data tools come in three classifications types: batch processing, stream  

------------------- Sentence 1 -------------------

analysis.

>> Tokens are: 
 ['analysis', '.']

>> Bigrams are: 
 [('analysis', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Specific big data tools come in three classifications types: batch processing, stream

>> Tokens are: 
 ['Specific', 'big', 'data', 'tools', 'come', 'three', 'classifications', 'types', ':', 'batch', 'processing', ',', 'stream']

>> Bigrams are: 
 [('Specific', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'come'), ('come', 'three'), ('three', 'classifications'), ('classifications', 'types'), ('types', ':'), (':', 'batch'), ('batch', 'processing'), ('processing', ','), (',', 'stream')]

>> Trigrams are: 
 [('Specific', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'come'), ('tools', 'come', 'three'), ('come', 'three', 'classifications'), ('three', 'classifications', 'types'), ('classifications', 'types', ':'), ('types', ':', 'batch'), (':', 'batch', 'processing'), ('batch', 'processing', ','), ('processing', ',', 'stream')]

>> POS Tags are: 
 [('Specific', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('come', 'VBP'), ('three', 'CD'), ('classifications', 'NNS'), ('types', 'NNS'), (':', ':'), ('batch', 'NN'), ('processing', 'NN'), (',', ','), ('stream', 'NN')]

>> Noun Phrases are: 
 ['Specific big data tools', 'classifications types', 'batch processing', 'stream']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Specific', 'specif'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classif'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'process'), (',', ','), ('stream', 'stream')]

>> Stemming using Snowball Stemmer: 
 [('Specific', 'specif'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classif'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'process'), (',', ','), ('stream', 'stream')]

>> Lemmatization: 
 [('Specific', 'Specific'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classification'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'processing'), (',', ','), ('stream', 'stream')]



========================================== PARAGRAPH 989 ===========================================

processing, and hybrid processing tools (Wang, et al., 2016). The relationship between decision  

------------------- Sentence 1 -------------------

processing, and hybrid processing tools (Wang, et al., 2016).

>> Tokens are: 
 ['processing', ',', 'hybrid', 'processing', 'tools', '(', 'Wang', ',', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('processing', ','), (',', 'hybrid'), ('hybrid', 'processing'), ('processing', 'tools'), ('tools', '('), ('(', 'Wang'), ('Wang', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('processing', ',', 'hybrid'), (',', 'hybrid', 'processing'), ('hybrid', 'processing', 'tools'), ('processing', 'tools', '('), ('tools', '(', 'Wang'), ('(', 'Wang', ','), ('Wang', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('processing', 'NN'), (',', ','), ('hybrid', 'JJ'), ('processing', 'NN'), ('tools', 'NNS'), ('(', '('), ('Wang', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['processing', 'hybrid processing tools', 'Wang', 'al.']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('processing', 'process'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'process'), ('tools', 'tool'), ('(', '('), ('Wang', 'wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('processing', 'process'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'process'), ('tools', 'tool'), ('(', '('), ('Wang', 'wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('processing', 'processing'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'processing'), ('tools', 'tool'), ('(', '('), ('Wang', 'Wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The relationship between decision

>> Tokens are: 
 ['The', 'relationship', 'decision']

>> Bigrams are: 
 [('The', 'relationship'), ('relationship', 'decision')]

>> Trigrams are: 
 [('The', 'relationship', 'decision')]

>> POS Tags are: 
 [('The', 'DT'), ('relationship', 'NN'), ('decision', 'NN')]

>> Noun Phrases are: 
 ['The relationship decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('relationship', 'relationship'), ('decision', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('relationship', 'relationship'), ('decision', 'decis')]

>> Lemmatization: 
 [('The', 'The'), ('relationship', 'relationship'), ('decision', 'decision')]



========================================== PARAGRAPH 990 ===========================================

science and big data is clarified in Figure 22.  

------------------- Sentence 1 -------------------

science and big data is clarified in Figure 22.

>> Tokens are: 
 ['science', 'big', 'data', 'clarified', 'Figure', '22', '.']

>> Bigrams are: 
 [('science', 'big'), ('big', 'data'), ('data', 'clarified'), ('clarified', 'Figure'), ('Figure', '22'), ('22', '.')]

>> Trigrams are: 
 [('science', 'big', 'data'), ('big', 'data', 'clarified'), ('data', 'clarified', 'Figure'), ('clarified', 'Figure', '22'), ('Figure', '22', '.')]

>> POS Tags are: 
 [('science', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('clarified', 'VBD'), ('Figure', 'NNP'), ('22', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['science', 'big data', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('science', 'scienc'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarifi'), ('Figure', 'figur'), ('22', '22'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('science', 'scienc'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarifi'), ('Figure', 'figur'), ('22', '22'), ('.', '.')]

>> Lemmatization: 
 [('science', 'science'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarified'), ('Figure', 'Figure'), ('22', '22'), ('.', '.')]



========================================== PARAGRAPH 991 ===========================================

  


========================================== PARAGRAPH 992 ===========================================

  


========================================== PARAGRAPH 993 ===========================================

Figure 22: The relation between big data and decision sciences, adopted from (Wang et al., 2016)  

------------------- Sentence 1 -------------------

Figure 22: The relation between big data and decision sciences, adopted from (Wang et al., 2016)

>> Tokens are: 
 ['Figure', '22', ':', 'The', 'relation', 'big', 'data', 'decision', 'sciences', ',', 'adopted', '(', 'Wang', 'et', 'al.', ',', '2016', ')']

>> Bigrams are: 
 [('Figure', '22'), ('22', ':'), (':', 'The'), ('The', 'relation'), ('relation', 'big'), ('big', 'data'), ('data', 'decision'), ('decision', 'sciences'), ('sciences', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')')]

>> Trigrams are: 
 [('Figure', '22', ':'), ('22', ':', 'The'), (':', 'The', 'relation'), ('The', 'relation', 'big'), ('relation', 'big', 'data'), ('big', 'data', 'decision'), ('data', 'decision', 'sciences'), ('decision', 'sciences', ','), ('sciences', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')')]

>> POS Tags are: 
 [('Figure', 'NN'), ('22', 'CD'), (':', ':'), ('The', 'DT'), ('relation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('decision', 'NN'), ('sciences', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Figure', 'The relation', 'big data decision sciences', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('22', '22'), (':', ':'), ('The', 'the'), ('relation', 'relat'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('sciences', 'scienc'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('22', '22'), (':', ':'), ('The', 'the'), ('relation', 'relat'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('sciences', 'scienc'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('22', '22'), (':', ':'), ('The', 'The'), ('relation', 'relation'), ('big', 'big'), ('data', 'data'), ('decision', 'decision'), ('sciences', 'science'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')')]



========================================== PARAGRAPH 994 ===========================================

  


========================================== PARAGRAPH 995 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 996 ===========================================

37  

------------------- Sentence 1 -------------------

37

>> Tokens are: 
 ['37']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('37', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37', '37')]

>> Stemming using Snowball Stemmer: 
 [('37', '37')]

>> Lemmatization: 
 [('37', '37')]



========================================== PARAGRAPH 997 ===========================================

  


========================================== PARAGRAPH 998 ===========================================

9. Big data analytics challenges  

------------------- Sentence 1 -------------------

9.

>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics challenges

>> Tokens are: 
 ['Big', 'data', 'analytics', 'challenges']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'challenges')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'challenges')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge')]



========================================== PARAGRAPH 999 ===========================================

Many studies have focused on the use of analytics techniques such as data mining, visualisation,  

------------------- Sentence 1 -------------------

Many studies have focused on the use of analytics techniques such as data mining, visualisation,

>> Tokens are: 
 ['Many', 'studies', 'focused', 'use', 'analytics', 'techniques', 'data', 'mining', ',', 'visualisation', ',']

>> Bigrams are: 
 [('Many', 'studies'), ('studies', 'focused'), ('focused', 'use'), ('use', 'analytics'), ('analytics', 'techniques'), ('techniques', 'data'), ('data', 'mining'), ('mining', ','), (',', 'visualisation'), ('visualisation', ',')]

>> Trigrams are: 
 [('Many', 'studies', 'focused'), ('studies', 'focused', 'use'), ('focused', 'use', 'analytics'), ('use', 'analytics', 'techniques'), ('analytics', 'techniques', 'data'), ('techniques', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'visualisation'), (',', 'visualisation', ',')]

>> POS Tags are: 
 [('Many', 'JJ'), ('studies', 'NNS'), ('focused', 'VBD'), ('use', 'NN'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('visualisation', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Many studies', 'use analytics techniques data mining', 'visualisation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('use', 'use'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('visualisation', 'visualis'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('use', 'use'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('visualisation', 'visualis'), (',', ',')]

>> Lemmatization: 
 [('Many', 'Many'), ('studies', 'study'), ('focused', 'focused'), ('use', 'use'), ('analytics', 'analytics'), ('techniques', 'technique'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('visualisation', 'visualisation'), (',', ',')]



========================================== PARAGRAPH 1000 ===========================================

statistical analysis, and machine learning; however, there is a need to develop new analytic  

------------------- Sentence 1 -------------------

statistical analysis, and machine learning; however, there is a need to develop new analytic

>> Tokens are: 
 ['statistical', 'analysis', ',', 'machine', 'learning', ';', 'however', ',', 'need', 'develop', 'new', 'analytic']

>> Bigrams are: 
 [('statistical', 'analysis'), ('analysis', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ';'), (';', 'however'), ('however', ','), (',', 'need'), ('need', 'develop'), ('develop', 'new'), ('new', 'analytic')]

>> Trigrams are: 
 [('statistical', 'analysis', ','), ('analysis', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ';'), ('learning', ';', 'however'), (';', 'however', ','), ('however', ',', 'need'), (',', 'need', 'develop'), ('need', 'develop', 'new'), ('develop', 'new', 'analytic')]

>> POS Tags are: 
 [('statistical', 'JJ'), ('analysis', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (';', ':'), ('however', 'RB'), (',', ','), ('need', 'VBP'), ('develop', 'VB'), ('new', 'JJ'), ('analytic', 'JJ')]

>> Noun Phrases are: 
 ['statistical analysis', 'machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (';', ';'), ('however', 'howev'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (';', ';'), ('however', 'howev'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analyt')]

>> Lemmatization: 
 [('statistical', 'statistical'), ('analysis', 'analysis'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (';', ';'), ('however', 'however'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analytic')]



========================================== PARAGRAPH 1001 ===========================================

approaches in order to handle big data challenges such as the time required for processing when  

------------------- Sentence 1 -------------------

approaches in order to handle big data challenges such as the time required for processing when

>> Tokens are: 
 ['approaches', 'order', 'handle', 'big', 'data', 'challenges', 'time', 'required', 'processing']

>> Bigrams are: 
 [('approaches', 'order'), ('order', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'time'), ('time', 'required'), ('required', 'processing')]

>> Trigrams are: 
 [('approaches', 'order', 'handle'), ('order', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'time'), ('challenges', 'time', 'required'), ('time', 'required', 'processing')]

>> POS Tags are: 
 [('approaches', 'NNS'), ('order', 'NN'), ('handle', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('time', 'NN'), ('required', 'VBN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['approaches order', 'big data challenges time', 'processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approaches', 'approach'), ('order', 'order'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('time', 'time'), ('required', 'requir'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('approaches', 'approach'), ('order', 'order'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('time', 'time'), ('required', 'requir'), ('processing', 'process')]

>> Lemmatization: 
 [('approaches', 'approach'), ('order', 'order'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('time', 'time'), ('required', 'required'), ('processing', 'processing')]



========================================== PARAGRAPH 1002 ===========================================

the volume of the data is very large (Oussous et al., 2018). Oussous et al. thus presented the  

------------------- Sentence 1 -------------------

the volume of the data is very large (Oussous et al., 2018).

>> Tokens are: 
 ['volume', 'data', 'large', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('volume', 'data'), ('data', 'large'), ('large', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('volume', 'data', 'large'), ('data', 'large', '('), ('large', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('volume', 'NN'), ('data', 'NNS'), ('large', 'JJ'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['volume data', 'Oussous et al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('large', 'larg'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('large', 'larg'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('volume', 'volume'), ('data', 'data'), ('large', 'large'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Oussous et al.

>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

thus presented the

>> Tokens are: 
 ['thus', 'presented']

>> Bigrams are: 
 [('thus', 'presented')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('thus', 'RB'), ('presented', 'VBN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('thus', 'thu'), ('presented', 'present')]

>> Stemming using Snowball Stemmer: 
 [('thus', 'thus'), ('presented', 'present')]

>> Lemmatization: 
 [('thus', 'thus'), ('presented', 'presented')]



========================================== PARAGRAPH 1003 ===========================================

difficulties in applying current analytical solutions, including machine learning, deep learning,  

------------------- Sentence 1 -------------------

difficulties in applying current analytical solutions, including machine learning, deep learning,

>> Tokens are: 
 ['difficulties', 'applying', 'current', 'analytical', 'solutions', ',', 'including', 'machine', 'learning', ',', 'deep', 'learning', ',']

>> Bigrams are: 
 [('difficulties', 'applying'), ('applying', 'current'), ('current', 'analytical'), ('analytical', 'solutions'), ('solutions', ','), (',', 'including'), ('including', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'deep'), ('deep', 'learning'), ('learning', ',')]

>> Trigrams are: 
 [('difficulties', 'applying', 'current'), ('applying', 'current', 'analytical'), ('current', 'analytical', 'solutions'), ('analytical', 'solutions', ','), ('solutions', ',', 'including'), (',', 'including', 'machine'), ('including', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', ',')]

>> POS Tags are: 
 [('difficulties', 'NNS'), ('applying', 'VBG'), ('current', 'JJ'), ('analytical', 'JJ'), ('solutions', 'NNS'), (',', ','), ('including', 'VBG'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['difficulties', 'current analytical solutions', 'machine learning', 'deep learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('difficulties', 'difficulti'), ('applying', 'appli'), ('current', 'current'), ('analytical', 'analyt'), ('solutions', 'solut'), (',', ','), ('including', 'includ'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('difficulties', 'difficulti'), ('applying', 'appli'), ('current', 'current'), ('analytical', 'analyt'), ('solutions', 'solut'), (',', ','), ('including', 'includ'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ',')]

>> Lemmatization: 
 [('difficulties', 'difficulty'), ('applying', 'applying'), ('current', 'current'), ('analytical', 'analytical'), ('solutions', 'solution'), (',', ','), ('including', 'including'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), (',', ',')]



========================================== PARAGRAPH 1004 ===========================================

incremental approaches, and granular computing.  

------------------- Sentence 1 -------------------

incremental approaches, and granular computing.

>> Tokens are: 
 ['incremental', 'approaches', ',', 'granular', 'computing', '.']

>> Bigrams are: 
 [('incremental', 'approaches'), ('approaches', ','), (',', 'granular'), ('granular', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('incremental', 'approaches', ','), ('approaches', ',', 'granular'), (',', 'granular', 'computing'), ('granular', 'computing', '.')]

>> POS Tags are: 
 [('incremental', 'JJ'), ('approaches', 'NNS'), (',', ','), ('granular', 'JJ'), ('computing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['incremental approaches', 'granular computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('incremental', 'increment'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('incremental', 'increment'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('incremental', 'incremental'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'computing'), ('.', '.')]



========================================== PARAGRAPH 1005 ===========================================

Chen et al. (2014) similarly addressed big data applications, opportunities, and challenges, and  

------------------- Sentence 1 -------------------

Chen et al.

>> Tokens are: 
 ['Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'al']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2014) similarly addressed big data applications, opportunities, and challenges, and

>> Tokens are: 
 ['(', '2014', ')', 'similarly', 'addressed', 'big', 'data', 'applications', ',', 'opportunities', ',', 'challenges', ',']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'similarly'), ('similarly', 'addressed'), ('addressed', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'challenges'), ('challenges', ',')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'similarly'), (')', 'similarly', 'addressed'), ('similarly', 'addressed', 'big'), ('addressed', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', ','), ('applications', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'challenges'), (',', 'challenges', ',')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('similarly', 'RB'), ('addressed', 'VBD'), ('big', 'JJ'), ('data', 'NN'), ('applications', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('challenges', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['big data applications', 'opportunities', 'challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similarli'), ('addressed', 'address'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similar'), ('addressed', 'address'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similarly'), ('addressed', 'addressed'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('challenges', 'challenge'), (',', ',')]



========================================== PARAGRAPH 1006 ===========================================

examined several techniques to handle big data challenges, such as cloud computing and quantum  

------------------- Sentence 1 -------------------

examined several techniques to handle big data challenges, such as cloud computing and quantum

>> Tokens are: 
 ['examined', 'several', 'techniques', 'handle', 'big', 'data', 'challenges', ',', 'cloud', 'computing', 'quantum']

>> Bigrams are: 
 [('examined', 'several'), ('several', 'techniques'), ('techniques', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', ','), (',', 'cloud'), ('cloud', 'computing'), ('computing', 'quantum')]

>> Trigrams are: 
 [('examined', 'several', 'techniques'), ('several', 'techniques', 'handle'), ('techniques', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', ','), ('challenges', ',', 'cloud'), (',', 'cloud', 'computing'), ('cloud', 'computing', 'quantum')]

>> POS Tags are: 
 [('examined', 'VBN'), ('several', 'JJ'), ('techniques', 'NNS'), ('handle', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), (',', ','), ('cloud', 'NN'), ('computing', 'VBG'), ('quantum', 'NN')]

>> Noun Phrases are: 
 ['several techniques', 'big data challenges', 'cloud', 'quantum']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('examined', 'examin'), ('several', 'sever'), ('techniques', 'techniqu'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), (',', ','), ('cloud', 'cloud'), ('computing', 'comput'), ('quantum', 'quantum')]

>> Stemming using Snowball Stemmer: 
 [('examined', 'examin'), ('several', 'sever'), ('techniques', 'techniqu'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), (',', ','), ('cloud', 'cloud'), ('computing', 'comput'), ('quantum', 'quantum')]

>> Lemmatization: 
 [('examined', 'examined'), ('several', 'several'), ('techniques', 'technique'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), (',', ','), ('cloud', 'cloud'), ('computing', 'computing'), ('quantum', 'quantum')]



========================================== PARAGRAPH 1007 ===========================================

computing, to examine their efficacy. Wang.et al. (2016) presented a big data overview that  

------------------- Sentence 1 -------------------

computing, to examine their efficacy.

>> Tokens are: 
 ['computing', ',', 'examine', 'efficacy', '.']

>> Bigrams are: 
 [('computing', ','), (',', 'examine'), ('examine', 'efficacy'), ('efficacy', '.')]

>> Trigrams are: 
 [('computing', ',', 'examine'), (',', 'examine', 'efficacy'), ('examine', 'efficacy', '.')]

>> POS Tags are: 
 [('computing', 'NN'), (',', ','), ('examine', 'JJ'), ('efficacy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computing', 'examine efficacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computing', 'comput'), (',', ','), ('examine', 'examin'), ('efficacy', 'efficaci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computing', 'comput'), (',', ','), ('examine', 'examin'), ('efficacy', 'efficaci'), ('.', '.')]

>> Lemmatization: 
 [('computing', 'computing'), (',', ','), ('examine', 'examine'), ('efficacy', 'efficacy'), ('.', '.')]


------------------- Sentence 2 -------------------

Wang.et al.

>> Tokens are: 
 ['Wang.et', 'al', '.']

>> Bigrams are: 
 [('Wang.et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Wang.et', 'al', '.')]

>> POS Tags are: 
 [('Wang.et', 'NNP'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang.et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Wang.et', 'wang.et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang.et', 'wang.et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Wang.et', 'Wang.et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(2016) presented a big data overview that

>> Tokens are: 
 ['(', '2016', ')', 'presented', 'big', 'data', 'overview']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'overview')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'presented'), (')', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'overview')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('overview', 'NN')]

>> Noun Phrases are: 
 ['big data overview']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('overview', 'overview')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('overview', 'overview')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('overview', 'overview')]



========================================== PARAGRAPH 1008 ===========================================

included four categories: 1) concepts, big data characteristics, and processing paradigms; (2) state- 

------------------- Sentence 1 -------------------

included four categories: 1) concepts, big data characteristics, and processing paradigms; (2) state-

>> Tokens are: 
 ['included', 'four', 'categories', ':', '1', ')', 'concepts', ',', 'big', 'data', 'characteristics', ',', 'processing', 'paradigms', ';', '(', '2', ')', 'state-']

>> Bigrams are: 
 [('included', 'four'), ('four', 'categories'), ('categories', ':'), (':', '1'), ('1', ')'), (')', 'concepts'), ('concepts', ','), (',', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', ','), (',', 'processing'), ('processing', 'paradigms'), ('paradigms', ';'), (';', '('), ('(', '2'), ('2', ')'), (')', 'state-')]

>> Trigrams are: 
 [('included', 'four', 'categories'), ('four', 'categories', ':'), ('categories', ':', '1'), (':', '1', ')'), ('1', ')', 'concepts'), (')', 'concepts', ','), ('concepts', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', ','), ('characteristics', ',', 'processing'), (',', 'processing', 'paradigms'), ('processing', 'paradigms', ';'), ('paradigms', ';', '('), (';', '(', '2'), ('(', '2', ')'), ('2', ')', 'state-')]

>> POS Tags are: 
 [('included', 'VBD'), ('four', 'CD'), ('categories', 'NNS'), (':', ':'), ('1', 'CD'), (')', ')'), ('concepts', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('characteristics', 'NNS'), (',', ','), ('processing', 'VBG'), ('paradigms', 'NN'), (';', ':'), ('(', '('), ('2', 'CD'), (')', ')'), ('state-', 'NN')]

>> Noun Phrases are: 
 ['categories', 'concepts', 'big data characteristics', 'paradigms', 'state-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('included', 'includ'), ('four', 'four'), ('categories', 'categori'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('processing', 'process'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-')]

>> Stemming using Snowball Stemmer: 
 [('included', 'includ'), ('four', 'four'), ('categories', 'categori'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('processing', 'process'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-')]

>> Lemmatization: 
 [('included', 'included'), ('four', 'four'), ('categories', 'category'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), (',', ','), ('processing', 'processing'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-')]



========================================== PARAGRAPH 1009 ===========================================

of-the-art techniques for decision making in big data; (3) decision making applications of big data  

------------------- Sentence 1 -------------------

of-the-art techniques for decision making in big data; (3) decision making applications of big data

>> Tokens are: 
 ['of-the-art', 'techniques', 'decision', 'making', 'big', 'data', ';', '(', '3', ')', 'decision', 'making', 'applications', 'big', 'data']

>> Bigrams are: 
 [('of-the-art', 'techniques'), ('techniques', 'decision'), ('decision', 'making'), ('making', 'big'), ('big', 'data'), ('data', ';'), (';', '('), ('(', '3'), ('3', ')'), (')', 'decision'), ('decision', 'making'), ('making', 'applications'), ('applications', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('of-the-art', 'techniques', 'decision'), ('techniques', 'decision', 'making'), ('decision', 'making', 'big'), ('making', 'big', 'data'), ('big', 'data', ';'), ('data', ';', '('), (';', '(', '3'), ('(', '3', ')'), ('3', ')', 'decision'), (')', 'decision', 'making'), ('decision', 'making', 'applications'), ('making', 'applications', 'big'), ('applications', 'big', 'data')]

>> POS Tags are: 
 [('of-the-art', 'JJ'), ('techniques', 'NNS'), ('decision', 'NN'), ('making', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (';', ':'), ('(', '('), ('3', 'CD'), (')', ')'), ('decision', 'NN'), ('making', 'VBG'), ('applications', 'NNS'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['of-the-art techniques decision', 'big data', 'decision', 'applications', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('of-the-art', 'of-the-art'), ('techniques', 'techniqu'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decis'), ('making', 'make'), ('applications', 'applic'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('of-the-art', 'of-the-art'), ('techniques', 'techniqu'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decis'), ('making', 'make'), ('applications', 'applic'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('of-the-art', 'of-the-art'), ('techniques', 'technique'), ('decision', 'decision'), ('making', 'making'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decision'), ('making', 'making'), ('applications', 'application'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1010 ===========================================

in social science; and (4) big data’s current challenges and future directions.  

------------------- Sentence 1 -------------------

in social science; and (4) big data’s current challenges and future directions.

>> Tokens are: 
 ['social', 'science', ';', '(', '4', ')', 'big', 'data', '’', 'current', 'challenges', 'future', 'directions', '.']

>> Bigrams are: 
 [('social', 'science'), ('science', ';'), (';', '('), ('(', '4'), ('4', ')'), (')', 'big'), ('big', 'data'), ('data', '’'), ('’', 'current'), ('current', 'challenges'), ('challenges', 'future'), ('future', 'directions'), ('directions', '.')]

>> Trigrams are: 
 [('social', 'science', ';'), ('science', ';', '('), (';', '(', '4'), ('(', '4', ')'), ('4', ')', 'big'), (')', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'current'), ('’', 'current', 'challenges'), ('current', 'challenges', 'future'), ('challenges', 'future', 'directions'), ('future', 'directions', '.')]

>> POS Tags are: 
 [('social', 'JJ'), ('science', 'NN'), (';', ':'), ('(', '('), ('4', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'FW'), ('current', 'JJ'), ('challenges', 'NNS'), ('future', 'JJ'), ('directions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['social science', 'big data', 'current challenges', 'future directions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('social', 'social'), ('science', 'scienc'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challeng'), ('future', 'futur'), ('directions', 'direct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('social', 'social'), ('science', 'scienc'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challeng'), ('future', 'futur'), ('directions', 'direct'), ('.', '.')]

>> Lemmatization: 
 [('social', 'social'), ('science', 'science'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challenge'), ('future', 'future'), ('directions', 'direction'), ('.', '.')]



========================================== PARAGRAPH 1011 ===========================================

The work of Ali et al. (2016) explained big data’s potential and applications. It presented big data  

------------------- Sentence 1 -------------------

The work of Ali et al.

>> Tokens are: 
 ['The', 'work', 'Ali', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'work'), ('work', 'Ali'), ('Ali', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'work', 'Ali'), ('work', 'Ali', 'et'), ('Ali', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('work', 'NN'), ('Ali', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The work Ali', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('work', 'work'), ('Ali', 'ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('work', 'work'), ('Ali', 'ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('work', 'work'), ('Ali', 'Ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016) explained big data’s potential and applications.

>> Tokens are: 
 ['(', '2016', ')', 'explained', 'big', 'data', '’', 'potential', 'applications', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'explained'), ('explained', 'big'), ('big', 'data'), ('data', '’'), ('’', 'potential'), ('potential', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'explained'), (')', 'explained', 'big'), ('explained', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'potential'), ('’', 'potential', 'applications'), ('potential', 'applications', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('explained', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'VBP'), ('potential', 'JJ'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'potential applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explain'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explain'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explained'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potential'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 3 -------------------

It presented big data

>> Tokens are: 
 ['It', 'presented', 'big', 'data']

>> Bigrams are: 
 [('It', 'presented'), ('presented', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('It', 'presented', 'big'), ('presented', 'big', 'data')]

>> POS Tags are: 
 [('It', 'PRP'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('presented', 'present'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('presented', 'present'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('It', 'It'), ('presented', 'presented'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1012 ===========================================

techniques and offered some background to big data analytical approaches. The study highlighted  

------------------- Sentence 1 -------------------

techniques and offered some background to big data analytical approaches.

>> Tokens are: 
 ['techniques', 'offered', 'background', 'big', 'data', 'analytical', 'approaches', '.']

>> Bigrams are: 
 [('techniques', 'offered'), ('offered', 'background'), ('background', 'big'), ('big', 'data'), ('data', 'analytical'), ('analytical', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('techniques', 'offered', 'background'), ('offered', 'background', 'big'), ('background', 'big', 'data'), ('big', 'data', 'analytical'), ('data', 'analytical', 'approaches'), ('analytical', 'approaches', '.')]

>> POS Tags are: 
 [('techniques', 'NNS'), ('offered', 'VBN'), ('background', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytical', 'JJ'), ('approaches', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques', 'big data', 'analytical approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('offered', 'offer'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('offered', 'offer'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), ('offered', 'offered'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analytical'), ('approaches', 'approach'), ('.', '.')]


------------------- Sentence 2 -------------------

The study highlighted

>> Tokens are: 
 ['The', 'study', 'highlighted']

>> Bigrams are: 
 [('The', 'study'), ('study', 'highlighted')]

>> Trigrams are: 
 [('The', 'study', 'highlighted')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('highlighted', 'VBD')]

>> Noun Phrases are: 
 ['The study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('highlighted', 'highlight')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('highlighted', 'highlight')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('highlighted', 'highlighted')]



========================================== PARAGRAPH 1013 ===========================================

several big data technical challenges such as crowdsourcing, bias and polarization, technology  

------------------- Sentence 1 -------------------

several big data technical challenges such as crowdsourcing, bias and polarization, technology

>> Tokens are: 
 ['several', 'big', 'data', 'technical', 'challenges', 'crowdsourcing', ',', 'bias', 'polarization', ',', 'technology']

>> Bigrams are: 
 [('several', 'big'), ('big', 'data'), ('data', 'technical'), ('technical', 'challenges'), ('challenges', 'crowdsourcing'), ('crowdsourcing', ','), (',', 'bias'), ('bias', 'polarization'), ('polarization', ','), (',', 'technology')]

>> Trigrams are: 
 [('several', 'big', 'data'), ('big', 'data', 'technical'), ('data', 'technical', 'challenges'), ('technical', 'challenges', 'crowdsourcing'), ('challenges', 'crowdsourcing', ','), ('crowdsourcing', ',', 'bias'), (',', 'bias', 'polarization'), ('bias', 'polarization', ','), ('polarization', ',', 'technology')]

>> POS Tags are: 
 [('several', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('crowdsourcing', 'VBG'), (',', ','), ('bias', 'JJ'), ('polarization', 'NN'), (',', ','), ('technology', 'NN')]

>> Noun Phrases are: 
 ['several big data', 'technical challenges', 'bias polarization', 'technology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('several', 'sever'), ('big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('crowdsourcing', 'crowdsourc'), (',', ','), ('bias', 'bia'), ('polarization', 'polar'), (',', ','), ('technology', 'technolog')]

>> Stemming using Snowball Stemmer: 
 [('several', 'sever'), ('big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('crowdsourcing', 'crowdsourc'), (',', ','), ('bias', 'bias'), ('polarization', 'polar'), (',', ','), ('technology', 'technolog')]

>> Lemmatization: 
 [('several', 'several'), ('big', 'big'), ('data', 'data'), ('technical', 'technical'), ('challenges', 'challenge'), ('crowdsourcing', 'crowdsourcing'), (',', ','), ('bias', 'bias'), ('polarization', 'polarization'), (',', ','), ('technology', 'technology')]



========================================== PARAGRAPH 1014 ===========================================

usage, and scaling. New technologies and services such as cloud computing and hardware price  

------------------- Sentence 1 -------------------

usage, and scaling.

>> Tokens are: 
 ['usage', ',', 'scaling', '.']

>> Bigrams are: 
 [('usage', ','), (',', 'scaling'), ('scaling', '.')]

>> Trigrams are: 
 [('usage', ',', 'scaling'), (',', 'scaling', '.')]

>> POS Tags are: 
 [('usage', 'NN'), (',', ','), ('scaling', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['usage', 'scaling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('usage', 'usag'), (',', ','), ('scaling', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('usage', 'usag'), (',', ','), ('scaling', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('usage', 'usage'), (',', ','), ('scaling', 'scaling'), ('.', '.')]


------------------- Sentence 2 -------------------

New technologies and services such as cloud computing and hardware price

>> Tokens are: 
 ['New', 'technologies', 'services', 'cloud', 'computing', 'hardware', 'price']

>> Bigrams are: 
 [('New', 'technologies'), ('technologies', 'services'), ('services', 'cloud'), ('cloud', 'computing'), ('computing', 'hardware'), ('hardware', 'price')]

>> Trigrams are: 
 [('New', 'technologies', 'services'), ('technologies', 'services', 'cloud'), ('services', 'cloud', 'computing'), ('cloud', 'computing', 'hardware'), ('computing', 'hardware', 'price')]

>> POS Tags are: 
 [('New', 'NNP'), ('technologies', 'NNS'), ('services', 'NNS'), ('cloud', 'VBP'), ('computing', 'VBG'), ('hardware', 'NN'), ('price', 'NN')]

>> Noun Phrases are: 
 ['New technologies services', 'hardware price']

>> Named Entities are: 
 [('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('technologies', 'technolog'), ('services', 'servic'), ('cloud', 'cloud'), ('computing', 'comput'), ('hardware', 'hardwar'), ('price', 'price')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('technologies', 'technolog'), ('services', 'servic'), ('cloud', 'cloud'), ('computing', 'comput'), ('hardware', 'hardwar'), ('price', 'price')]

>> Lemmatization: 
 [('New', 'New'), ('technologies', 'technology'), ('services', 'service'), ('cloud', 'cloud'), ('computing', 'computing'), ('hardware', 'hardware'), ('price', 'price')]



========================================== PARAGRAPH 1015 ===========================================

reductions have also increased the information rates available from the Internet, representing a big  

------------------- Sentence 1 -------------------

reductions have also increased the information rates available from the Internet, representing a big

>> Tokens are: 
 ['reductions', 'also', 'increased', 'information', 'rates', 'available', 'Internet', ',', 'representing', 'big']

>> Bigrams are: 
 [('reductions', 'also'), ('also', 'increased'), ('increased', 'information'), ('information', 'rates'), ('rates', 'available'), ('available', 'Internet'), ('Internet', ','), (',', 'representing'), ('representing', 'big')]

>> Trigrams are: 
 [('reductions', 'also', 'increased'), ('also', 'increased', 'information'), ('increased', 'information', 'rates'), ('information', 'rates', 'available'), ('rates', 'available', 'Internet'), ('available', 'Internet', ','), ('Internet', ',', 'representing'), (',', 'representing', 'big')]

>> POS Tags are: 
 [('reductions', 'NNS'), ('also', 'RB'), ('increased', 'VBD'), ('information', 'NN'), ('rates', 'NNS'), ('available', 'JJ'), ('Internet', 'NNP'), (',', ','), ('representing', 'VBG'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['reductions', 'information rates', 'available Internet']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reductions', 'reduct'), ('also', 'also'), ('increased', 'increas'), ('information', 'inform'), ('rates', 'rate'), ('available', 'avail'), ('Internet', 'internet'), (',', ','), ('representing', 'repres'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('reductions', 'reduct'), ('also', 'also'), ('increased', 'increas'), ('information', 'inform'), ('rates', 'rate'), ('available', 'avail'), ('Internet', 'internet'), (',', ','), ('representing', 'repres'), ('big', 'big')]

>> Lemmatization: 
 [('reductions', 'reduction'), ('also', 'also'), ('increased', 'increased'), ('information', 'information'), ('rates', 'rate'), ('available', 'available'), ('Internet', 'Internet'), (',', ','), ('representing', 'representing'), ('big', 'big')]



========================================== PARAGRAPH 1016 ===========================================

challenge to the data analytics community.  

------------------- Sentence 1 -------------------

challenge to the data analytics community.

>> Tokens are: 
 ['challenge', 'data', 'analytics', 'community', '.']

>> Bigrams are: 
 [('challenge', 'data'), ('data', 'analytics'), ('analytics', 'community'), ('community', '.')]

>> Trigrams are: 
 [('challenge', 'data', 'analytics'), ('data', 'analytics', 'community'), ('analytics', 'community', '.')]

>> POS Tags are: 
 [('challenge', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('community', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['challenge data analytics community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenge', 'challeng'), ('data', 'data'), ('analytics', 'analyt'), ('community', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenge', 'challeng'), ('data', 'data'), ('analytics', 'analyt'), ('community', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('challenge', 'challenge'), ('data', 'data'), ('analytics', 'analytics'), ('community', 'community'), ('.', '.')]



========================================== PARAGRAPH 1017 ===========================================

  


========================================== PARAGRAPH 1018 ===========================================

The main challenges of using big data, which need to be resolved before it can be used  

------------------- Sentence 1 -------------------

The main challenges of using big data, which need to be resolved before it can be used

>> Tokens are: 
 ['The', 'main', 'challenges', 'using', 'big', 'data', ',', 'need', 'resolved', 'used']

>> Bigrams are: 
 [('The', 'main'), ('main', 'challenges'), ('challenges', 'using'), ('using', 'big'), ('big', 'data'), ('data', ','), (',', 'need'), ('need', 'resolved'), ('resolved', 'used')]

>> Trigrams are: 
 [('The', 'main', 'challenges'), ('main', 'challenges', 'using'), ('challenges', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'need'), (',', 'need', 'resolved'), ('need', 'resolved', 'used')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('challenges', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('need', 'VBP'), ('resolved', 'VBN'), ('used', 'JJ')]

>> Noun Phrases are: 
 ['The main challenges', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('challenges', 'challenge'), ('using', 'using'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolved'), ('used', 'used')]



========================================== PARAGRAPH 1019 ===========================================

effectively, include  

------------------- Sentence 1 -------------------

effectively, include

>> Tokens are: 
 ['effectively', ',', 'include']

>> Bigrams are: 
 [('effectively', ','), (',', 'include')]

>> Trigrams are: 
 [('effectively', ',', 'include')]

>> POS Tags are: 
 [('effectively', 'RB'), (',', ','), ('include', 'VBP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('effectively', 'effect'), (',', ','), ('include', 'includ')]

>> Stemming using Snowball Stemmer: 
 [('effectively', 'effect'), (',', ','), ('include', 'includ')]

>> Lemmatization: 
 [('effectively', 'effectively'), (',', ','), ('include', 'include')]



========================================== PARAGRAPH 1020 ===========================================

9.1.  Data Security issues  

------------------- Sentence 1 -------------------

9.1.

>> Tokens are: 
 ['9.1', '.']

>> Bigrams are: 
 [('9.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.1', '9.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.1', '9.1'), ('.', '.')]

>> Lemmatization: 
 [('9.1', '9.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Data Security issues

>> Tokens are: 
 ['Data', 'Security', 'issues']

>> Bigrams are: 
 [('Data', 'Security'), ('Security', 'issues')]

>> Trigrams are: 
 [('Data', 'Security', 'issues')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Security', 'NNP'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['Data Security issues']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu')]

>> Lemmatization: 
 [('Data', 'Data'), ('Security', 'Security'), ('issues', 'issue')]



========================================== PARAGRAPH 1021 ===========================================

In public affairs, privacy, internet access disparities, and legal and security issues are key concerns,  

------------------- Sentence 1 -------------------

In public affairs, privacy, internet access disparities, and legal and security issues are key concerns,

>> Tokens are: 
 ['In', 'public', 'affairs', ',', 'privacy', ',', 'internet', 'access', 'disparities', ',', 'legal', 'security', 'issues', 'key', 'concerns', ',']

>> Bigrams are: 
 [('In', 'public'), ('public', 'affairs'), ('affairs', ','), (',', 'privacy'), ('privacy', ','), (',', 'internet'), ('internet', 'access'), ('access', 'disparities'), ('disparities', ','), (',', 'legal'), ('legal', 'security'), ('security', 'issues'), ('issues', 'key'), ('key', 'concerns'), ('concerns', ',')]

>> Trigrams are: 
 [('In', 'public', 'affairs'), ('public', 'affairs', ','), ('affairs', ',', 'privacy'), (',', 'privacy', ','), ('privacy', ',', 'internet'), (',', 'internet', 'access'), ('internet', 'access', 'disparities'), ('access', 'disparities', ','), ('disparities', ',', 'legal'), (',', 'legal', 'security'), ('legal', 'security', 'issues'), ('security', 'issues', 'key'), ('issues', 'key', 'concerns'), ('key', 'concerns', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('public', 'JJ'), ('affairs', 'NNS'), (',', ','), ('privacy', 'NN'), (',', ','), ('internet', 'JJ'), ('access', 'NN'), ('disparities', 'NNS'), (',', ','), ('legal', 'JJ'), ('security', 'NN'), ('issues', 'NNS'), ('key', 'JJ'), ('concerns', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['public affairs', 'privacy', 'internet access disparities', 'legal security issues', 'key concerns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privaci'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'dispar'), (',', ','), ('legal', 'legal'), ('security', 'secur'), ('issues', 'issu'), ('key', 'key'), ('concerns', 'concern'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privaci'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'dispar'), (',', ','), ('legal', 'legal'), ('security', 'secur'), ('issues', 'issu'), ('key', 'key'), ('concerns', 'concern'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privacy'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'disparity'), (',', ','), ('legal', 'legal'), ('security', 'security'), ('issues', 'issue'), ('key', 'key'), ('concerns', 'concern'), (',', ',')]



========================================== PARAGRAPH 1022 ===========================================

and managers and policymakers in these areas should work to overcome these limitations. Public  

------------------- Sentence 1 -------------------

and managers and policymakers in these areas should work to overcome these limitations.

>> Tokens are: 
 ['managers', 'policymakers', 'areas', 'work', 'overcome', 'limitations', '.']

>> Bigrams are: 
 [('managers', 'policymakers'), ('policymakers', 'areas'), ('areas', 'work'), ('work', 'overcome'), ('overcome', 'limitations'), ('limitations', '.')]

>> Trigrams are: 
 [('managers', 'policymakers', 'areas'), ('policymakers', 'areas', 'work'), ('areas', 'work', 'overcome'), ('work', 'overcome', 'limitations'), ('overcome', 'limitations', '.')]

>> POS Tags are: 
 [('managers', 'NNS'), ('policymakers', 'NNS'), ('areas', 'NNS'), ('work', 'VBP'), ('overcome', 'JJ'), ('limitations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['managers policymakers areas', 'overcome limitations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('managers', 'manag'), ('policymakers', 'policymak'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcom'), ('limitations', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('managers', 'manag'), ('policymakers', 'policymak'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcom'), ('limitations', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('managers', 'manager'), ('policymakers', 'policymakers'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcome'), ('limitations', 'limitation'), ('.', '.')]


------------------- Sentence 2 -------------------

Public

>> Tokens are: 
 ['Public']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Public', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Public')] 

>> Stemming using Porter Stemmer: 
 [('Public', 'public')]

>> Stemming using Snowball Stemmer: 
 [('Public', 'public')]

>> Lemmatization: 
 [('Public', 'Public')]



========================================== PARAGRAPH 1023 ===========================================

managers and policymakers are also, however, generally working under the restrictions of a limited  

------------------- Sentence 1 -------------------

managers and policymakers are also, however, generally working under the restrictions of a limited

>> Tokens are: 
 ['managers', 'policymakers', 'also', ',', 'however', ',', 'generally', 'working', 'restrictions', 'limited']

>> Bigrams are: 
 [('managers', 'policymakers'), ('policymakers', 'also'), ('also', ','), (',', 'however'), ('however', ','), (',', 'generally'), ('generally', 'working'), ('working', 'restrictions'), ('restrictions', 'limited')]

>> Trigrams are: 
 [('managers', 'policymakers', 'also'), ('policymakers', 'also', ','), ('also', ',', 'however'), (',', 'however', ','), ('however', ',', 'generally'), (',', 'generally', 'working'), ('generally', 'working', 'restrictions'), ('working', 'restrictions', 'limited')]

>> POS Tags are: 
 [('managers', 'NNS'), ('policymakers', 'NNS'), ('also', 'RB'), (',', ','), ('however', 'RB'), (',', ','), ('generally', 'RB'), ('working', 'VBG'), ('restrictions', 'NNS'), ('limited', 'VBD')]

>> Noun Phrases are: 
 ['managers policymakers', 'restrictions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('managers', 'manag'), ('policymakers', 'policymak'), ('also', 'also'), (',', ','), ('however', 'howev'), (',', ','), ('generally', 'gener'), ('working', 'work'), ('restrictions', 'restrict'), ('limited', 'limit')]

>> Stemming using Snowball Stemmer: 
 [('managers', 'manag'), ('policymakers', 'policymak'), ('also', 'also'), (',', ','), ('however', 'howev'), (',', ','), ('generally', 'general'), ('working', 'work'), ('restrictions', 'restrict'), ('limited', 'limit')]

>> Lemmatization: 
 [('managers', 'manager'), ('policymakers', 'policymakers'), ('also', 'also'), (',', ','), ('however', 'however'), (',', ','), ('generally', 'generally'), ('working', 'working'), ('restrictions', 'restriction'), ('limited', 'limited')]



========================================== PARAGRAPH 1024 ===========================================

budget, multiple constituencies, and short time frames for extracting knowledge big data (Mergel,  

------------------- Sentence 1 -------------------

budget, multiple constituencies, and short time frames for extracting knowledge big data (Mergel,

>> Tokens are: 
 ['budget', ',', 'multiple', 'constituencies', ',', 'short', 'time', 'frames', 'extracting', 'knowledge', 'big', 'data', '(', 'Mergel', ',']

>> Bigrams are: 
 [('budget', ','), (',', 'multiple'), ('multiple', 'constituencies'), ('constituencies', ','), (',', 'short'), ('short', 'time'), ('time', 'frames'), ('frames', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'big'), ('big', 'data'), ('data', '('), ('(', 'Mergel'), ('Mergel', ',')]

>> Trigrams are: 
 [('budget', ',', 'multiple'), (',', 'multiple', 'constituencies'), ('multiple', 'constituencies', ','), ('constituencies', ',', 'short'), (',', 'short', 'time'), ('short', 'time', 'frames'), ('time', 'frames', 'extracting'), ('frames', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'big'), ('knowledge', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Mergel'), ('(', 'Mergel', ',')]

>> POS Tags are: 
 [('budget', 'NN'), (',', ','), ('multiple', 'JJ'), ('constituencies', 'NNS'), (',', ','), ('short', 'JJ'), ('time', 'NN'), ('frames', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Mergel', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['budget', 'multiple constituencies', 'short time frames', 'knowledge', 'big data', 'Mergel']

>> Named Entities are: 
 [('ORGANIZATION', 'Mergel')] 

>> Stemming using Porter Stemmer: 
 [('budget', 'budget'), (',', ','), ('multiple', 'multipl'), ('constituencies', 'constitu'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'mergel'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('budget', 'budget'), (',', ','), ('multiple', 'multipl'), ('constituencies', 'constitu'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'mergel'), (',', ',')]

>> Lemmatization: 
 [('budget', 'budget'), (',', ','), ('multiple', 'multiple'), ('constituencies', 'constituency'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'Mergel'), (',', ',')]



========================================== PARAGRAPH 1025 ===========================================

Rethemeyer, and Isett, 2016; Grover and Kar, 2017).   

------------------- Sentence 1 -------------------

Rethemeyer, and Isett, 2016; Grover and Kar, 2017).

>> Tokens are: 
 ['Rethemeyer', ',', 'Isett', ',', '2016', ';', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Rethemeyer', ','), (',', 'Isett'), ('Isett', ','), (',', '2016'), ('2016', ';'), (';', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Rethemeyer', ',', 'Isett'), (',', 'Isett', ','), ('Isett', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Grover'), (';', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Rethemeyer', 'NNP'), (',', ','), ('Isett', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Rethemeyer', 'Isett', 'Grover Kar']

>> Named Entities are: 
 [('GPE', 'Rethemeyer'), ('PERSON', 'Isett'), ('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Rethemeyer', 'rethemey'), (',', ','), ('Isett', 'isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rethemeyer', 'rethemey'), (',', ','), ('Isett', 'isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Rethemeyer', 'Rethemeyer'), (',', ','), ('Isett', 'Isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1026 ===========================================

Watson (2019) presented some security issues with big data and gave some suggestions for  

------------------- Sentence 1 -------------------

Watson (2019) presented some security issues with big data and gave some suggestions for

>> Tokens are: 
 ['Watson', '(', '2019', ')', 'presented', 'security', 'issues', 'big', 'data', 'gave', 'suggestions']

>> Bigrams are: 
 [('Watson', '('), ('(', '2019'), ('2019', ')'), (')', 'presented'), ('presented', 'security'), ('security', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'gave'), ('gave', 'suggestions')]

>> Trigrams are: 
 [('Watson', '(', '2019'), ('(', '2019', ')'), ('2019', ')', 'presented'), (')', 'presented', 'security'), ('presented', 'security', 'issues'), ('security', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'gave'), ('data', 'gave', 'suggestions')]

>> POS Tags are: 
 [('Watson', 'NNP'), ('(', '('), ('2019', 'CD'), (')', ')'), ('presented', 'VBD'), ('security', 'NN'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('gave', 'VBD'), ('suggestions', 'NNS')]

>> Noun Phrases are: 
 ['Watson', 'security issues', 'big data', 'suggestions']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'present'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggest')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'present'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggest')]

>> Lemmatization: 
 [('Watson', 'Watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'presented'), ('security', 'security'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggestion')]



========================================== PARAGRAPH 1027 ===========================================

avoiding big data security risks. The security concern inherent in big data include the fact that big  

------------------- Sentence 1 -------------------

avoiding big data security risks.

>> Tokens are: 
 ['avoiding', 'big', 'data', 'security', 'risks', '.']

>> Bigrams are: 
 [('avoiding', 'big'), ('big', 'data'), ('data', 'security'), ('security', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('avoiding', 'big', 'data'), ('big', 'data', 'security'), ('data', 'security', 'risks'), ('security', 'risks', '.')]

>> POS Tags are: 
 [('avoiding', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('security', 'NN'), ('risks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data security risks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('avoiding', 'avoid'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('avoiding', 'avoid'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('avoiding', 'avoiding'), ('big', 'big'), ('data', 'data'), ('security', 'security'), ('risks', 'risk'), ('.', '.')]


------------------- Sentence 2 -------------------

The security concern inherent in big data include the fact that big

>> Tokens are: 
 ['The', 'security', 'concern', 'inherent', 'big', 'data', 'include', 'fact', 'big']

>> Bigrams are: 
 [('The', 'security'), ('security', 'concern'), ('concern', 'inherent'), ('inherent', 'big'), ('big', 'data'), ('data', 'include'), ('include', 'fact'), ('fact', 'big')]

>> Trigrams are: 
 [('The', 'security', 'concern'), ('security', 'concern', 'inherent'), ('concern', 'inherent', 'big'), ('inherent', 'big', 'data'), ('big', 'data', 'include'), ('data', 'include', 'fact'), ('include', 'fact', 'big')]

>> POS Tags are: 
 [('The', 'DT'), ('security', 'NN'), ('concern', 'NN'), ('inherent', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('include', 'VBP'), ('fact', 'NN'), ('big', 'JJ')]

>> Noun Phrases are: 
 ['The security concern', 'inherent big data', 'fact']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('security', 'secur'), ('concern', 'concern'), ('inherent', 'inher'), ('big', 'big'), ('data', 'data'), ('include', 'includ'), ('fact', 'fact'), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('security', 'secur'), ('concern', 'concern'), ('inherent', 'inher'), ('big', 'big'), ('data', 'data'), ('include', 'includ'), ('fact', 'fact'), ('big', 'big')]

>> Lemmatization: 
 [('The', 'The'), ('security', 'security'), ('concern', 'concern'), ('inherent', 'inherent'), ('big', 'big'), ('data', 'data'), ('include', 'include'), ('fact', 'fact'), ('big', 'big')]



========================================== PARAGRAPH 1028 ===========================================

data comes from many different sources, some of which may have weak security as well as a  

------------------- Sentence 1 -------------------

data comes from many different sources, some of which may have weak security as well as a

>> Tokens are: 
 ['data', 'comes', 'many', 'different', 'sources', ',', 'may', 'weak', 'security', 'well']

>> Bigrams are: 
 [('data', 'comes'), ('comes', 'many'), ('many', 'different'), ('different', 'sources'), ('sources', ','), (',', 'may'), ('may', 'weak'), ('weak', 'security'), ('security', 'well')]

>> Trigrams are: 
 [('data', 'comes', 'many'), ('comes', 'many', 'different'), ('many', 'different', 'sources'), ('different', 'sources', ','), ('sources', ',', 'may'), (',', 'may', 'weak'), ('may', 'weak', 'security'), ('weak', 'security', 'well')]

>> POS Tags are: 
 [('data', 'NNS'), ('comes', 'VBZ'), ('many', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (',', ','), ('may', 'MD'), ('weak', 'JJ'), ('security', 'NN'), ('well', 'RB')]

>> Noun Phrases are: 
 ['data', 'many different sources', 'weak security']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'secur'), ('well', 'well')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'secur'), ('well', 'well')]

>> Lemmatization: 
 [('data', 'data'), ('comes', 'come'), ('many', 'many'), ('different', 'different'), ('sources', 'source'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'security'), ('well', 'well')]



========================================== PARAGRAPH 1029 ===========================================

variety of formats and large volumes. Any security breaches may thus affect multiple companies  

------------------- Sentence 1 -------------------

variety of formats and large volumes.

>> Tokens are: 
 ['variety', 'formats', 'large', 'volumes', '.']

>> Bigrams are: 
 [('variety', 'formats'), ('formats', 'large'), ('large', 'volumes'), ('volumes', '.')]

>> Trigrams are: 
 [('variety', 'formats', 'large'), ('formats', 'large', 'volumes'), ('large', 'volumes', '.')]

>> POS Tags are: 
 [('variety', 'NN'), ('formats', 'NNS'), ('large', 'JJ'), ('volumes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['variety formats', 'large volumes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variety', 'varieti'), ('formats', 'format'), ('large', 'larg'), ('volumes', 'volum'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('variety', 'varieti'), ('formats', 'format'), ('large', 'larg'), ('volumes', 'volum'), ('.', '.')]

>> Lemmatization: 
 [('variety', 'variety'), ('formats', 'format'), ('large', 'large'), ('volumes', 'volume'), ('.', '.')]


------------------- Sentence 2 -------------------

Any security breaches may thus affect multiple companies

>> Tokens are: 
 ['Any', 'security', 'breaches', 'may', 'thus', 'affect', 'multiple', 'companies']

>> Bigrams are: 
 [('Any', 'security'), ('security', 'breaches'), ('breaches', 'may'), ('may', 'thus'), ('thus', 'affect'), ('affect', 'multiple'), ('multiple', 'companies')]

>> Trigrams are: 
 [('Any', 'security', 'breaches'), ('security', 'breaches', 'may'), ('breaches', 'may', 'thus'), ('may', 'thus', 'affect'), ('thus', 'affect', 'multiple'), ('affect', 'multiple', 'companies')]

>> POS Tags are: 
 [('Any', 'DT'), ('security', 'NN'), ('breaches', 'NNS'), ('may', 'MD'), ('thus', 'RB'), ('affect', 'VB'), ('multiple', 'NN'), ('companies', 'NNS')]

>> Noun Phrases are: 
 ['Any security breaches', 'multiple companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Any', 'ani'), ('security', 'secur'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thu'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('Any', 'ani'), ('security', 'secur'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thus'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani')]

>> Lemmatization: 
 [('Any', 'Any'), ('security', 'security'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thus'), ('affect', 'affect'), ('multiple', 'multiple'), ('companies', 'company')]



========================================== PARAGRAPH 1030 ===========================================

and result in financial losses, and thus, appropriate actions should be taken to reduce such big data  

------------------- Sentence 1 -------------------

and result in financial losses, and thus, appropriate actions should be taken to reduce such big data

>> Tokens are: 
 ['result', 'financial', 'losses', ',', 'thus', ',', 'appropriate', 'actions', 'taken', 'reduce', 'big', 'data']

>> Bigrams are: 
 [('result', 'financial'), ('financial', 'losses'), ('losses', ','), (',', 'thus'), ('thus', ','), (',', 'appropriate'), ('appropriate', 'actions'), ('actions', 'taken'), ('taken', 'reduce'), ('reduce', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('result', 'financial', 'losses'), ('financial', 'losses', ','), ('losses', ',', 'thus'), (',', 'thus', ','), ('thus', ',', 'appropriate'), (',', 'appropriate', 'actions'), ('appropriate', 'actions', 'taken'), ('actions', 'taken', 'reduce'), ('taken', 'reduce', 'big'), ('reduce', 'big', 'data')]

>> POS Tags are: 
 [('result', 'NN'), ('financial', 'JJ'), ('losses', 'NNS'), (',', ','), ('thus', 'RB'), (',', ','), ('appropriate', 'JJ'), ('actions', 'NNS'), ('taken', 'VBN'), ('reduce', 'VB'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['result', 'financial losses', 'appropriate actions', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('result', 'result'), ('financial', 'financi'), ('losses', 'loss'), (',', ','), ('thus', 'thu'), (',', ','), ('appropriate', 'appropri'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduc'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('result', 'result'), ('financial', 'financi'), ('losses', 'loss'), (',', ','), ('thus', 'thus'), (',', ','), ('appropriate', 'appropri'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduc'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('result', 'result'), ('financial', 'financial'), ('losses', 'loss'), (',', ','), ('thus', 'thus'), (',', ','), ('appropriate', 'appropriate'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduce'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1031 ===========================================

security risks.  

------------------- Sentence 1 -------------------

security risks.

>> Tokens are: 
 ['security', 'risks', '.']

>> Bigrams are: 
 [('security', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('security', 'risks', '.')]

>> POS Tags are: 
 [('security', 'NN'), ('risks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['security risks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('security', 'security'), ('risks', 'risk'), ('.', '.')]



========================================== PARAGRAPH 1032 ===========================================

Data sources should be monitored by organisations, with end-to-end encryption used to prevent  

------------------- Sentence 1 -------------------

Data sources should be monitored by organisations, with end-to-end encryption used to prevent

>> Tokens are: 
 ['Data', 'sources', 'monitored', 'organisations', ',', 'end-to-end', 'encryption', 'used', 'prevent']

>> Bigrams are: 
 [('Data', 'sources'), ('sources', 'monitored'), ('monitored', 'organisations'), ('organisations', ','), (',', 'end-to-end'), ('end-to-end', 'encryption'), ('encryption', 'used'), ('used', 'prevent')]

>> Trigrams are: 
 [('Data', 'sources', 'monitored'), ('sources', 'monitored', 'organisations'), ('monitored', 'organisations', ','), ('organisations', ',', 'end-to-end'), (',', 'end-to-end', 'encryption'), ('end-to-end', 'encryption', 'used'), ('encryption', 'used', 'prevent')]

>> POS Tags are: 
 [('Data', 'NNP'), ('sources', 'NNS'), ('monitored', 'VBD'), ('organisations', 'NNS'), (',', ','), ('end-to-end', 'JJ'), ('encryption', 'NN'), ('used', 'VBN'), ('prevent', 'NN')]

>> Noun Phrases are: 
 ['Data sources', 'organisations', 'end-to-end encryption', 'prevent']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('sources', 'sourc'), ('monitored', 'monitor'), ('organisations', 'organis'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('sources', 'sourc'), ('monitored', 'monitor'), ('organisations', 'organis'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent')]

>> Lemmatization: 
 [('Data', 'Data'), ('sources', 'source'), ('monitored', 'monitored'), ('organisations', 'organisation'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encryption'), ('used', 'used'), ('prevent', 'prevent')]



========================================== PARAGRAPH 1033 ===========================================

anyone from accessing the data in transit. Companies should also check their cloud providers, as  

------------------- Sentence 1 -------------------

anyone from accessing the data in transit.

>> Tokens are: 
 ['anyone', 'accessing', 'data', 'transit', '.']

>> Bigrams are: 
 [('anyone', 'accessing'), ('accessing', 'data'), ('data', 'transit'), ('transit', '.')]

>> Trigrams are: 
 [('anyone', 'accessing', 'data'), ('accessing', 'data', 'transit'), ('data', 'transit', '.')]

>> POS Tags are: 
 [('anyone', 'NN'), ('accessing', 'VBG'), ('data', 'NNS'), ('transit', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['anyone', 'data transit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('anyone', 'anyon'), ('accessing', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('anyone', 'anyon'), ('accessing', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Lemmatization: 
 [('anyone', 'anyone'), ('accessing', 'accessing'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]


------------------- Sentence 2 -------------------

Companies should also check their cloud providers, as

>> Tokens are: 
 ['Companies', 'also', 'check', 'cloud', 'providers', ',']

>> Bigrams are: 
 [('Companies', 'also'), ('also', 'check'), ('check', 'cloud'), ('cloud', 'providers'), ('providers', ',')]

>> Trigrams are: 
 [('Companies', 'also', 'check'), ('also', 'check', 'cloud'), ('check', 'cloud', 'providers'), ('cloud', 'providers', ',')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('also', 'RB'), ('check', 'VBP'), ('cloud', 'JJ'), ('providers', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Companies', 'cloud providers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ',')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provider'), (',', ',')]



========================================== PARAGRAPH 1034 ===========================================

many cloud providers do not encrypt the data due to the quantity of data transferred at any given  

------------------- Sentence 1 -------------------

many cloud providers do not encrypt the data due to the quantity of data transferred at any given

>> Tokens are: 
 ['many', 'cloud', 'providers', 'encrypt', 'data', 'due', 'quantity', 'data', 'transferred', 'given']

>> Bigrams are: 
 [('many', 'cloud'), ('cloud', 'providers'), ('providers', 'encrypt'), ('encrypt', 'data'), ('data', 'due'), ('due', 'quantity'), ('quantity', 'data'), ('data', 'transferred'), ('transferred', 'given')]

>> Trigrams are: 
 [('many', 'cloud', 'providers'), ('cloud', 'providers', 'encrypt'), ('providers', 'encrypt', 'data'), ('encrypt', 'data', 'due'), ('data', 'due', 'quantity'), ('due', 'quantity', 'data'), ('quantity', 'data', 'transferred'), ('data', 'transferred', 'given')]

>> POS Tags are: 
 [('many', 'JJ'), ('cloud', 'NN'), ('providers', 'NNS'), ('encrypt', 'VBP'), ('data', 'NNS'), ('due', 'JJ'), ('quantity', 'NN'), ('data', 'NNS'), ('transferred', 'VBD'), ('given', 'VBN')]

>> Noun Phrases are: 
 ['many cloud providers', 'data', 'due quantity data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantiti'), ('data', 'data'), ('transferred', 'transfer'), ('given', 'given')]

>> Stemming using Snowball Stemmer: 
 [('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantiti'), ('data', 'data'), ('transferred', 'transfer'), ('given', 'given')]

>> Lemmatization: 
 [('many', 'many'), ('cloud', 'cloud'), ('providers', 'provider'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantity'), ('data', 'data'), ('transferred', 'transferred'), ('given', 'given')]



========================================== PARAGRAPH 1035 ===========================================

time, as encryption/decryption slows down the flow of data. 

------------------- Sentence 1 -------------------

time, as encryption/decryption slows down the flow of data.

>> Tokens are: 
 ['time', ',', 'encryption/decryption', 'slows', 'flow', 'data', '.']

>> Bigrams are: 
 [('time', ','), (',', 'encryption/decryption'), ('encryption/decryption', 'slows'), ('slows', 'flow'), ('flow', 'data'), ('data', '.')]

>> Trigrams are: 
 [('time', ',', 'encryption/decryption'), (',', 'encryption/decryption', 'slows'), ('encryption/decryption', 'slows', 'flow'), ('slows', 'flow', 'data'), ('flow', 'data', '.')]

>> POS Tags are: 
 [('time', 'NN'), (',', ','), ('encryption/decryption', 'NN'), ('slows', 'NNS'), ('flow', 'VBP'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['time', 'encryption/decryption slows', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decryption'), ('slows', 'slows'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 1036 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1037 ===========================================

38  

------------------- Sentence 1 -------------------

38

>> Tokens are: 
 ['38']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('38', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38', '38')]

>> Stemming using Snowball Stemmer: 
 [('38', '38')]

>> Lemmatization: 
 [('38', '38')]



========================================== PARAGRAPH 1038 ===========================================

  


========================================== PARAGRAPH 1039 ===========================================

Big data is defined by the 5V’s, and these charecteristics, especially the volume aspect, mean that  

------------------- Sentence 1 -------------------

Big data is defined by the 5V’s, and these charecteristics, especially the volume aspect, mean that

>> Tokens are: 
 ['Big', 'data', 'defined', '5V', '’', ',', 'charecteristics', ',', 'especially', 'volume', 'aspect', ',', 'mean']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'defined'), ('defined', '5V'), ('5V', '’'), ('’', ','), (',', 'charecteristics'), ('charecteristics', ','), (',', 'especially'), ('especially', 'volume'), ('volume', 'aspect'), ('aspect', ','), (',', 'mean')]

>> Trigrams are: 
 [('Big', 'data', 'defined'), ('data', 'defined', '5V'), ('defined', '5V', '’'), ('5V', '’', ','), ('’', ',', 'charecteristics'), (',', 'charecteristics', ','), ('charecteristics', ',', 'especially'), (',', 'especially', 'volume'), ('especially', 'volume', 'aspect'), ('volume', 'aspect', ','), ('aspect', ',', 'mean')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('defined', 'VBD'), ('5V', 'CD'), ('’', 'NN'), (',', ','), ('charecteristics', 'NNS'), (',', ','), ('especially', 'RB'), ('volume', 'NN'), ('aspect', 'NN'), (',', ','), ('mean', 'NN')]

>> Noun Phrases are: 
 ['Big data', '’', 'charecteristics', 'volume aspect', 'mean']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('defined', 'defin'), ('5V', '5v'), ('’', '’'), (',', ','), ('charecteristics', 'charecterist'), (',', ','), ('especially', 'especi'), ('volume', 'volum'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('defined', 'defin'), ('5V', '5v'), ('’', '’'), (',', ','), ('charecteristics', 'charecterist'), (',', ','), ('especially', 'especi'), ('volume', 'volum'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('defined', 'defined'), ('5V', '5V'), ('’', '’'), (',', ','), ('charecteristics', 'charecteristics'), (',', ','), ('especially', 'especially'), ('volume', 'volume'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean')]



========================================== PARAGRAPH 1040 ===========================================

it cannot be processed with traditional data analytic techniques.  Large amounts of complex data  

------------------- Sentence 1 -------------------

it cannot be processed with traditional data analytic techniques.

>> Tokens are: 
 ['processed', 'traditional', 'data', 'analytic', 'techniques', '.']

>> Bigrams are: 
 [('processed', 'traditional'), ('traditional', 'data'), ('data', 'analytic'), ('analytic', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('processed', 'traditional', 'data'), ('traditional', 'data', 'analytic'), ('data', 'analytic', 'techniques'), ('analytic', 'techniques', '.')]

>> POS Tags are: 
 [('processed', 'VBN'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional data', 'analytic techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('processed', 'process'), ('traditional', 'tradit'), ('data', 'data'), ('analytic', 'analyt'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('processed', 'process'), ('traditional', 'tradit'), ('data', 'data'), ('analytic', 'analyt'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('processed', 'processed'), ('traditional', 'traditional'), ('data', 'data'), ('analytic', 'analytic'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

Large amounts of complex data

>> Tokens are: 
 ['Large', 'amounts', 'complex', 'data']

>> Bigrams are: 
 [('Large', 'amounts'), ('amounts', 'complex'), ('complex', 'data')]

>> Trigrams are: 
 [('Large', 'amounts', 'complex'), ('amounts', 'complex', 'data')]

>> POS Tags are: 
 [('Large', 'JJ'), ('amounts', 'NNS'), ('complex', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Large amounts', 'complex data']

>> Named Entities are: 
 [('GPE', 'Large')] 

>> Stemming using Porter Stemmer: 
 [('Large', 'larg'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Large', 'larg'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data')]

>> Lemmatization: 
 [('Large', 'Large'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data')]



========================================== PARAGRAPH 1041 ===========================================

need time for analysis. Therefore, big data faces intrusion detection challenges, as the system busy  

------------------- Sentence 1 -------------------

need time for analysis.

>> Tokens are: 
 ['need', 'time', 'analysis', '.']

>> Bigrams are: 
 [('need', 'time'), ('time', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('need', 'time', 'analysis'), ('time', 'analysis', '.')]

>> POS Tags are: 
 [('need', 'NN'), ('time', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['need time analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('need', 'need'), ('time', 'time'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('need', 'need'), ('time', 'time'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('need', 'need'), ('time', 'time'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Therefore, big data faces intrusion detection challenges, as the system busy

>> Tokens are: 
 ['Therefore', ',', 'big', 'data', 'faces', 'intrusion', 'detection', 'challenges', ',', 'system', 'busy']

>> Bigrams are: 
 [('Therefore', ','), (',', 'big'), ('big', 'data'), ('data', 'faces'), ('faces', 'intrusion'), ('intrusion', 'detection'), ('detection', 'challenges'), ('challenges', ','), (',', 'system'), ('system', 'busy')]

>> Trigrams are: 
 [('Therefore', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'faces'), ('data', 'faces', 'intrusion'), ('faces', 'intrusion', 'detection'), ('intrusion', 'detection', 'challenges'), ('detection', 'challenges', ','), ('challenges', ',', 'system'), (',', 'system', 'busy')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('faces', 'VBZ'), ('intrusion', 'NN'), ('detection', 'NN'), ('challenges', 'NNS'), (',', ','), ('system', 'NN'), ('busy', 'JJ')]

>> Noun Phrases are: 
 ['big data', 'intrusion detection challenges', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrus'), ('detection', 'detect'), ('challenges', 'challeng'), (',', ','), ('system', 'system'), ('busy', 'busi')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrus'), ('detection', 'detect'), ('challenges', 'challeng'), (',', ','), ('system', 'system'), ('busy', 'busi')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('challenges', 'challenge'), (',', ','), ('system', 'system'), ('busy', 'busy')]



========================================== PARAGRAPH 1042 ===========================================

times are extended. Although many security monitoring systems have been developed to improve  

------------------- Sentence 1 -------------------

times are extended.

>> Tokens are: 
 ['times', 'extended', '.']

>> Bigrams are: 
 [('times', 'extended'), ('extended', '.')]

>> Trigrams are: 
 [('times', 'extended', '.')]

>> POS Tags are: 
 [('times', 'NNS'), ('extended', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('times', 'time'), ('extended', 'extend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('times', 'time'), ('extended', 'extend'), ('.', '.')]

>> Lemmatization: 
 [('times', 'time'), ('extended', 'extended'), ('.', '.')]


------------------- Sentence 2 -------------------

Although many security monitoring systems have been developed to improve

>> Tokens are: 
 ['Although', 'many', 'security', 'monitoring', 'systems', 'developed', 'improve']

>> Bigrams are: 
 [('Although', 'many'), ('many', 'security'), ('security', 'monitoring'), ('monitoring', 'systems'), ('systems', 'developed'), ('developed', 'improve')]

>> Trigrams are: 
 [('Although', 'many', 'security'), ('many', 'security', 'monitoring'), ('security', 'monitoring', 'systems'), ('monitoring', 'systems', 'developed'), ('systems', 'developed', 'improve')]

>> POS Tags are: 
 [('Although', 'IN'), ('many', 'JJ'), ('security', 'NN'), ('monitoring', 'VBG'), ('systems', 'NNS'), ('developed', 'VBN'), ('improve', 'VB')]

>> Noun Phrases are: 
 ['many security', 'systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('many', 'mani'), ('security', 'secur'), ('monitoring', 'monitor'), ('systems', 'system'), ('developed', 'develop'), ('improve', 'improv')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('many', 'mani'), ('security', 'secur'), ('monitoring', 'monitor'), ('systems', 'system'), ('developed', 'develop'), ('improve', 'improv')]

>> Lemmatization: 
 [('Although', 'Although'), ('many', 'many'), ('security', 'security'), ('monitoring', 'monitoring'), ('systems', 'system'), ('developed', 'developed'), ('improve', 'improve')]



========================================== PARAGRAPH 1043 ===========================================

data security, intrusion detection is still challenging, even for isolated systems. The issues include  

------------------- Sentence 1 -------------------

data security, intrusion detection is still challenging, even for isolated systems.

>> Tokens are: 
 ['data', 'security', ',', 'intrusion', 'detection', 'still', 'challenging', ',', 'even', 'isolated', 'systems', '.']

>> Bigrams are: 
 [('data', 'security'), ('security', ','), (',', 'intrusion'), ('intrusion', 'detection'), ('detection', 'still'), ('still', 'challenging'), ('challenging', ','), (',', 'even'), ('even', 'isolated'), ('isolated', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('data', 'security', ','), ('security', ',', 'intrusion'), (',', 'intrusion', 'detection'), ('intrusion', 'detection', 'still'), ('detection', 'still', 'challenging'), ('still', 'challenging', ','), ('challenging', ',', 'even'), (',', 'even', 'isolated'), ('even', 'isolated', 'systems'), ('isolated', 'systems', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('security', 'NN'), (',', ','), ('intrusion', 'NN'), ('detection', 'NN'), ('still', 'RB'), ('challenging', 'VBG'), (',', ','), ('even', 'RB'), ('isolated', 'JJ'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data security', 'intrusion detection', 'isolated systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('security', 'secur'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('still', 'still'), ('challenging', 'challeng'), (',', ','), ('even', 'even'), ('isolated', 'isol'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('security', 'secur'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('still', 'still'), ('challenging', 'challeng'), (',', ','), ('even', 'even'), ('isolated', 'isol'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('security', 'security'), (',', ','), ('intrusion', 'intrusion'), ('detection', 'detection'), ('still', 'still'), ('challenging', 'challenging'), (',', ','), ('even', 'even'), ('isolated', 'isolated'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

The issues include

>> Tokens are: 
 ['The', 'issues', 'include']

>> Bigrams are: 
 [('The', 'issues'), ('issues', 'include')]

>> Trigrams are: 
 [('The', 'issues', 'include')]

>> POS Tags are: 
 [('The', 'DT'), ('issues', 'NNS'), ('include', 'VBP')]

>> Noun Phrases are: 
 ['The issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('issues', 'issu'), ('include', 'includ')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('issues', 'issu'), ('include', 'includ')]

>> Lemmatization: 
 [('The', 'The'), ('issues', 'issue'), ('include', 'include')]



========================================== PARAGRAPH 1044 ===========================================

how to store large quantities of data safely, how to maintain security, and how to track data that  

------------------- Sentence 1 -------------------

how to store large quantities of data safely, how to maintain security, and how to track data that

>> Tokens are: 
 ['store', 'large', 'quantities', 'data', 'safely', ',', 'maintain', 'security', ',', 'track', 'data']

>> Bigrams are: 
 [('store', 'large'), ('large', 'quantities'), ('quantities', 'data'), ('data', 'safely'), ('safely', ','), (',', 'maintain'), ('maintain', 'security'), ('security', ','), (',', 'track'), ('track', 'data')]

>> Trigrams are: 
 [('store', 'large', 'quantities'), ('large', 'quantities', 'data'), ('quantities', 'data', 'safely'), ('data', 'safely', ','), ('safely', ',', 'maintain'), (',', 'maintain', 'security'), ('maintain', 'security', ','), ('security', ',', 'track'), (',', 'track', 'data')]

>> POS Tags are: 
 [('store', 'RB'), ('large', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), ('safely', 'RB'), (',', ','), ('maintain', 'VBP'), ('security', 'NN'), (',', ','), ('track', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['large quantities data', 'security', 'track data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('store', 'store'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('safely', 'safe'), (',', ','), ('maintain', 'maintain'), ('security', 'secur'), (',', ','), ('track', 'track'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('store', 'store'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('safely', 'safe'), (',', ','), ('maintain', 'maintain'), ('security', 'secur'), (',', ','), ('track', 'track'), ('data', 'data')]

>> Lemmatization: 
 [('store', 'store'), ('large', 'large'), ('quantities', 'quantity'), ('data', 'data'), ('safely', 'safely'), (',', ','), ('maintain', 'maintain'), ('security', 'security'), (',', ','), ('track', 'track'), ('data', 'data')]



========================================== PARAGRAPH 1045 ===========================================

flows quickly from different sources. Solution to these challenges include taking a more  

------------------- Sentence 1 -------------------

flows quickly from different sources.

>> Tokens are: 
 ['flows', 'quickly', 'different', 'sources', '.']

>> Bigrams are: 
 [('flows', 'quickly'), ('quickly', 'different'), ('different', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('flows', 'quickly', 'different'), ('quickly', 'different', 'sources'), ('different', 'sources', '.')]

>> POS Tags are: 
 [('flows', 'NNS'), ('quickly', 'RB'), ('different', 'JJ'), ('sources', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['flows', 'different sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('flows', 'flow'), ('quickly', 'quickli'), ('different', 'differ'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('flows', 'flow'), ('quickly', 'quick'), ('different', 'differ'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('flows', 'flow'), ('quickly', 'quickly'), ('different', 'different'), ('sources', 'source'), ('.', '.')]


------------------- Sentence 2 -------------------

Solution to these challenges include taking a more

>> Tokens are: 
 ['Solution', 'challenges', 'include', 'taking']

>> Bigrams are: 
 [('Solution', 'challenges'), ('challenges', 'include'), ('include', 'taking')]

>> Trigrams are: 
 [('Solution', 'challenges', 'include'), ('challenges', 'include', 'taking')]

>> POS Tags are: 
 [('Solution', 'NN'), ('challenges', 'NNS'), ('include', 'VBP'), ('taking', 'VBG')]

>> Noun Phrases are: 
 ['Solution challenges']

>> Named Entities are: 
 [('GPE', 'Solution')] 

>> Stemming using Porter Stemmer: 
 [('Solution', 'solut'), ('challenges', 'challeng'), ('include', 'includ'), ('taking', 'take')]

>> Stemming using Snowball Stemmer: 
 [('Solution', 'solut'), ('challenges', 'challeng'), ('include', 'includ'), ('taking', 'take')]

>> Lemmatization: 
 [('Solution', 'Solution'), ('challenges', 'challenge'), ('include', 'include'), ('taking', 'taking')]



========================================== PARAGRAPH 1046 ===========================================

comprehensive approach to monitoring the data that comes from different sources in order to  

------------------- Sentence 1 -------------------

comprehensive approach to monitoring the data that comes from different sources in order to

>> Tokens are: 
 ['comprehensive', 'approach', 'monitoring', 'data', 'comes', 'different', 'sources', 'order']

>> Bigrams are: 
 [('comprehensive', 'approach'), ('approach', 'monitoring'), ('monitoring', 'data'), ('data', 'comes'), ('comes', 'different'), ('different', 'sources'), ('sources', 'order')]

>> Trigrams are: 
 [('comprehensive', 'approach', 'monitoring'), ('approach', 'monitoring', 'data'), ('monitoring', 'data', 'comes'), ('data', 'comes', 'different'), ('comes', 'different', 'sources'), ('different', 'sources', 'order')]

>> POS Tags are: 
 [('comprehensive', 'JJ'), ('approach', 'NN'), ('monitoring', 'NN'), ('data', 'NNS'), ('comes', 'VBZ'), ('different', 'JJ'), ('sources', 'NNS'), ('order', 'NN')]

>> Noun Phrases are: 
 ['comprehensive approach monitoring data', 'different sources order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comprehensive', 'comprehens'), ('approach', 'approach'), ('monitoring', 'monitor'), ('data', 'data'), ('comes', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('order', 'order')]

>> Stemming using Snowball Stemmer: 
 [('comprehensive', 'comprehens'), ('approach', 'approach'), ('monitoring', 'monitor'), ('data', 'data'), ('comes', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('order', 'order')]

>> Lemmatization: 
 [('comprehensive', 'comprehensive'), ('approach', 'approach'), ('monitoring', 'monitoring'), ('data', 'data'), ('comes', 'come'), ('different', 'different'), ('sources', 'source'), ('order', 'order')]



========================================== PARAGRAPH 1047 ===========================================

develop better situational awareness of the threats in cyberspace. This helps minimise false alarms  

------------------- Sentence 1 -------------------

develop better situational awareness of the threats in cyberspace.

>> Tokens are: 
 ['develop', 'better', 'situational', 'awareness', 'threats', 'cyberspace', '.']

>> Bigrams are: 
 [('develop', 'better'), ('better', 'situational'), ('situational', 'awareness'), ('awareness', 'threats'), ('threats', 'cyberspace'), ('cyberspace', '.')]

>> Trigrams are: 
 [('develop', 'better', 'situational'), ('better', 'situational', 'awareness'), ('situational', 'awareness', 'threats'), ('awareness', 'threats', 'cyberspace'), ('threats', 'cyberspace', '.')]

>> POS Tags are: 
 [('develop', 'VB'), ('better', 'RBR'), ('situational', 'JJ'), ('awareness', 'NN'), ('threats', 'NNS'), ('cyberspace', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['situational awareness threats']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('develop', 'develop'), ('better', 'better'), ('situational', 'situat'), ('awareness', 'awar'), ('threats', 'threat'), ('cyberspace', 'cyberspac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('develop', 'develop'), ('better', 'better'), ('situational', 'situat'), ('awareness', 'awar'), ('threats', 'threat'), ('cyberspace', 'cyberspac'), ('.', '.')]

>> Lemmatization: 
 [('develop', 'develop'), ('better', 'better'), ('situational', 'situational'), ('awareness', 'awareness'), ('threats', 'threat'), ('cyberspace', 'cyberspace'), ('.', '.')]


------------------- Sentence 2 -------------------

This helps minimise false alarms

>> Tokens are: 
 ['This', 'helps', 'minimise', 'false', 'alarms']

>> Bigrams are: 
 [('This', 'helps'), ('helps', 'minimise'), ('minimise', 'false'), ('false', 'alarms')]

>> Trigrams are: 
 [('This', 'helps', 'minimise'), ('helps', 'minimise', 'false'), ('minimise', 'false', 'alarms')]

>> POS Tags are: 
 [('This', 'DT'), ('helps', 'VBZ'), ('minimise', 'VB'), ('false', 'JJ'), ('alarms', 'NNS')]

>> Noun Phrases are: 
 ['false alarms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('helps', 'help'), ('minimise', 'minimis'), ('false', 'fals'), ('alarms', 'alarm')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('helps', 'help'), ('minimise', 'minimis'), ('false', 'fals'), ('alarms', 'alarm')]

>> Lemmatization: 
 [('This', 'This'), ('helps', 'help'), ('minimise', 'minimise'), ('false', 'false'), ('alarms', 'alarm')]



========================================== PARAGRAPH 1048 ===========================================

and maximise intrusion detection. The big data challenges for intrusion detection can also be  

------------------- Sentence 1 -------------------

and maximise intrusion detection.

>> Tokens are: 
 ['maximise', 'intrusion', 'detection', '.']

>> Bigrams are: 
 [('maximise', 'intrusion'), ('intrusion', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('maximise', 'intrusion', 'detection'), ('intrusion', 'detection', '.')]

>> POS Tags are: 
 [('maximise', 'NN'), ('intrusion', 'NN'), ('detection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['maximise intrusion detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('maximise', 'maximis'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('maximise', 'maximis'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('maximise', 'maximise'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('.', '.')]


------------------- Sentence 2 -------------------

The big data challenges for intrusion detection can also be

>> Tokens are: 
 ['The', 'big', 'data', 'challenges', 'intrusion', 'detection', 'also']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'intrusion'), ('intrusion', 'detection'), ('detection', 'also')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'intrusion'), ('challenges', 'intrusion', 'detection'), ('intrusion', 'detection', 'also')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('intrusion', 'NN'), ('detection', 'NN'), ('also', 'RB')]

>> Noun Phrases are: 
 ['The big data challenges intrusion detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('intrusion', 'intrus'), ('detection', 'detect'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('intrusion', 'intrus'), ('detection', 'detect'), ('also', 'also')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('also', 'also')]



========================================== PARAGRAPH 1049 ===========================================

addressed by using traditional computing storage platforms such as Hadoop, an open source  

------------------- Sentence 1 -------------------

addressed by using traditional computing storage platforms such as Hadoop, an open source

>> Tokens are: 
 ['addressed', 'using', 'traditional', 'computing', 'storage', 'platforms', 'Hadoop', ',', 'open', 'source']

>> Bigrams are: 
 [('addressed', 'using'), ('using', 'traditional'), ('traditional', 'computing'), ('computing', 'storage'), ('storage', 'platforms'), ('platforms', 'Hadoop'), ('Hadoop', ','), (',', 'open'), ('open', 'source')]

>> Trigrams are: 
 [('addressed', 'using', 'traditional'), ('using', 'traditional', 'computing'), ('traditional', 'computing', 'storage'), ('computing', 'storage', 'platforms'), ('storage', 'platforms', 'Hadoop'), ('platforms', 'Hadoop', ','), ('Hadoop', ',', 'open'), (',', 'open', 'source')]

>> POS Tags are: 
 [('addressed', 'VBN'), ('using', 'VBG'), ('traditional', 'JJ'), ('computing', 'NN'), ('storage', 'NN'), ('platforms', 'NNS'), ('Hadoop', 'NNP'), (',', ','), ('open', 'JJ'), ('source', 'NN')]

>> Noun Phrases are: 
 ['traditional computing storage platforms Hadoop', 'open source']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('addressed', 'address'), ('using', 'use'), ('traditional', 'tradit'), ('computing', 'comput'), ('storage', 'storag'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('open', 'open'), ('source', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('addressed', 'address'), ('using', 'use'), ('traditional', 'tradit'), ('computing', 'comput'), ('storage', 'storag'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('open', 'open'), ('source', 'sourc')]

>> Lemmatization: 
 [('addressed', 'addressed'), ('using', 'using'), ('traditional', 'traditional'), ('computing', 'computing'), ('storage', 'storage'), ('platforms', 'platform'), ('Hadoop', 'Hadoop'), (',', ','), ('open', 'open'), ('source', 'source')]



========================================== PARAGRAPH 1050 ===========================================

distributed storage platform used for storing large amounts of data that flows quickly (Suthaharan,  

------------------- Sentence 1 -------------------

distributed storage platform used for storing large amounts of data that flows quickly (Suthaharan,

>> Tokens are: 
 ['distributed', 'storage', 'platform', 'used', 'storing', 'large', 'amounts', 'data', 'flows', 'quickly', '(', 'Suthaharan', ',']

>> Bigrams are: 
 [('distributed', 'storage'), ('storage', 'platform'), ('platform', 'used'), ('used', 'storing'), ('storing', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', 'flows'), ('flows', 'quickly'), ('quickly', '('), ('(', 'Suthaharan'), ('Suthaharan', ',')]

>> Trigrams are: 
 [('distributed', 'storage', 'platform'), ('storage', 'platform', 'used'), ('platform', 'used', 'storing'), ('used', 'storing', 'large'), ('storing', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', 'flows'), ('data', 'flows', 'quickly'), ('flows', 'quickly', '('), ('quickly', '(', 'Suthaharan'), ('(', 'Suthaharan', ',')]

>> POS Tags are: 
 [('distributed', 'VBN'), ('storage', 'NN'), ('platform', 'NN'), ('used', 'VBN'), ('storing', 'VBG'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('flows', 'NNS'), ('quickly', 'RB'), ('(', '('), ('Suthaharan', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['storage platform', 'large amounts data flows', 'Suthaharan']

>> Named Entities are: 
 [('ORGANIZATION', 'Suthaharan')] 

>> Stemming using Porter Stemmer: 
 [('distributed', 'distribut'), ('storage', 'storag'), ('platform', 'platform'), ('used', 'use'), ('storing', 'store'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickli'), ('(', '('), ('Suthaharan', 'suthaharan'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('distributed', 'distribut'), ('storage', 'storag'), ('platform', 'platform'), ('used', 'use'), ('storing', 'store'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quick'), ('(', '('), ('Suthaharan', 'suthaharan'), (',', ',')]

>> Lemmatization: 
 [('distributed', 'distributed'), ('storage', 'storage'), ('platform', 'platform'), ('used', 'used'), ('storing', 'storing'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickly'), ('(', '('), ('Suthaharan', 'Suthaharan'), (',', ',')]



========================================== PARAGRAPH 1051 ===========================================

2014; Zuech et al., 2015).  

------------------- Sentence 1 -------------------

2014; Zuech et al., 2015).

>> Tokens are: 
 ['2014', ';', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('2014', ';'), (';', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ';', 'Zuech'), (';', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('Zuech', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Zuech', 'al.']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1052 ===========================================

Suthaharan (2014) proposed using big data technologies such as Hadoop to address intrusion  

------------------- Sentence 1 -------------------

Suthaharan (2014) proposed using big data technologies such as Hadoop to address intrusion

>> Tokens are: 
 ['Suthaharan', '(', '2014', ')', 'proposed', 'using', 'big', 'data', 'technologies', 'Hadoop', 'address', 'intrusion']

>> Bigrams are: 
 [('Suthaharan', '('), ('(', '2014'), ('2014', ')'), (')', 'proposed'), ('proposed', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'technologies'), ('technologies', 'Hadoop'), ('Hadoop', 'address'), ('address', 'intrusion')]

>> Trigrams are: 
 [('Suthaharan', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'proposed'), (')', 'proposed', 'using'), ('proposed', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'technologies'), ('data', 'technologies', 'Hadoop'), ('technologies', 'Hadoop', 'address'), ('Hadoop', 'address', 'intrusion')]

>> POS Tags are: 
 [('Suthaharan', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('proposed', 'VBN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('technologies', 'NNS'), ('Hadoop', 'NNP'), ('address', 'NN'), ('intrusion', 'NN')]

>> Noun Phrases are: 
 ['Suthaharan', 'big data technologies Hadoop address intrusion']

>> Named Entities are: 
 [('GPE', 'Suthaharan'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Suthaharan', 'suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'propos'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('technologies', 'technolog'), ('Hadoop', 'hadoop'), ('address', 'address'), ('intrusion', 'intrus')]

>> Stemming using Snowball Stemmer: 
 [('Suthaharan', 'suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'propos'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('technologies', 'technolog'), ('Hadoop', 'hadoop'), ('address', 'address'), ('intrusion', 'intrus')]

>> Lemmatization: 
 [('Suthaharan', 'Suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'proposed'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('technologies', 'technology'), ('Hadoop', 'Hadoop'), ('address', 'address'), ('intrusion', 'intrusion')]



========================================== PARAGRAPH 1053 ===========================================

detection issues, and in addition, he proposed the 3Cs, Cardinality, Continuity, and Complexity,  

------------------- Sentence 1 -------------------

detection issues, and in addition, he proposed the 3Cs, Cardinality, Continuity, and Complexity,

>> Tokens are: 
 ['detection', 'issues', ',', 'addition', ',', 'proposed', '3Cs', ',', 'Cardinality', ',', 'Continuity', ',', 'Complexity', ',']

>> Bigrams are: 
 [('detection', 'issues'), ('issues', ','), (',', 'addition'), ('addition', ','), (',', 'proposed'), ('proposed', '3Cs'), ('3Cs', ','), (',', 'Cardinality'), ('Cardinality', ','), (',', 'Continuity'), ('Continuity', ','), (',', 'Complexity'), ('Complexity', ',')]

>> Trigrams are: 
 [('detection', 'issues', ','), ('issues', ',', 'addition'), (',', 'addition', ','), ('addition', ',', 'proposed'), (',', 'proposed', '3Cs'), ('proposed', '3Cs', ','), ('3Cs', ',', 'Cardinality'), (',', 'Cardinality', ','), ('Cardinality', ',', 'Continuity'), (',', 'Continuity', ','), ('Continuity', ',', 'Complexity'), (',', 'Complexity', ',')]

>> POS Tags are: 
 [('detection', 'NN'), ('issues', 'NNS'), (',', ','), ('addition', 'NN'), (',', ','), ('proposed', 'VBD'), ('3Cs', 'CD'), (',', ','), ('Cardinality', 'NNP'), (',', ','), ('Continuity', 'NNP'), (',', ','), ('Complexity', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['detection issues', 'addition', 'Cardinality', 'Continuity', 'Complexity']

>> Named Entities are: 
 [('GPE', 'Cardinality'), ('ORGANIZATION', 'Continuity'), ('ORGANIZATION', 'Complexity')] 

>> Stemming using Porter Stemmer: 
 [('detection', 'detect'), ('issues', 'issu'), (',', ','), ('addition', 'addit'), (',', ','), ('proposed', 'propos'), ('3Cs', '3c'), (',', ','), ('Cardinality', 'cardin'), (',', ','), ('Continuity', 'continu'), (',', ','), ('Complexity', 'complex'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('detection', 'detect'), ('issues', 'issu'), (',', ','), ('addition', 'addit'), (',', ','), ('proposed', 'propos'), ('3Cs', '3cs'), (',', ','), ('Cardinality', 'cardin'), (',', ','), ('Continuity', 'continu'), (',', ','), ('Complexity', 'complex'), (',', ',')]

>> Lemmatization: 
 [('detection', 'detection'), ('issues', 'issue'), (',', ','), ('addition', 'addition'), (',', ','), ('proposed', 'proposed'), ('3Cs', '3Cs'), (',', ','), ('Cardinality', 'Cardinality'), (',', ','), ('Continuity', 'Continuity'), (',', ','), ('Complexity', 'Complexity'), (',', ',')]



========================================== PARAGRAPH 1054 ===========================================

for use in developing mathematical and statistical tools. Here, Cardinality refers to the number of  

------------------- Sentence 1 -------------------

for use in developing mathematical and statistical tools.

>> Tokens are: 
 ['use', 'developing', 'mathematical', 'statistical', 'tools', '.']

>> Bigrams are: 
 [('use', 'developing'), ('developing', 'mathematical'), ('mathematical', 'statistical'), ('statistical', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('use', 'developing', 'mathematical'), ('developing', 'mathematical', 'statistical'), ('mathematical', 'statistical', 'tools'), ('statistical', 'tools', '.')]

>> POS Tags are: 
 [('use', 'NN'), ('developing', 'VBG'), ('mathematical', 'JJ'), ('statistical', 'JJ'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['use', 'mathematical statistical tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('use', 'use'), ('developing', 'develop'), ('mathematical', 'mathemat'), ('statistical', 'statist'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('use', 'use'), ('developing', 'develop'), ('mathematical', 'mathemat'), ('statistical', 'statist'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('use', 'use'), ('developing', 'developing'), ('mathematical', 'mathematical'), ('statistical', 'statistical'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

Here, Cardinality refers to the number of

>> Tokens are: 
 ['Here', ',', 'Cardinality', 'refers', 'number']

>> Bigrams are: 
 [('Here', ','), (',', 'Cardinality'), ('Cardinality', 'refers'), ('refers', 'number')]

>> Trigrams are: 
 [('Here', ',', 'Cardinality'), (',', 'Cardinality', 'refers'), ('Cardinality', 'refers', 'number')]

>> POS Tags are: 
 [('Here', 'RB'), (',', ','), ('Cardinality', 'NNP'), ('refers', 'VBZ'), ('number', 'NN')]

>> Noun Phrases are: 
 ['Cardinality', 'number']

>> Named Entities are: 
 [('GPE', 'Cardinality')] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), (',', ','), ('Cardinality', 'cardin'), ('refers', 'refer'), ('number', 'number')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), (',', ','), ('Cardinality', 'cardin'), ('refers', 'refer'), ('number', 'number')]

>> Lemmatization: 
 [('Here', 'Here'), (',', ','), ('Cardinality', 'Cardinality'), ('refers', 'refers'), ('number', 'number')]



========================================== PARAGRAPH 1055 ===========================================

records, Continuity refers to the data’s continuous growth over time, and Complexity refers to the  

------------------- Sentence 1 -------------------

records, Continuity refers to the data’s continuous growth over time, and Complexity refers to the

>> Tokens are: 
 ['records', ',', 'Continuity', 'refers', 'data', '’', 'continuous', 'growth', 'time', ',', 'Complexity', 'refers']

>> Bigrams are: 
 [('records', ','), (',', 'Continuity'), ('Continuity', 'refers'), ('refers', 'data'), ('data', '’'), ('’', 'continuous'), ('continuous', 'growth'), ('growth', 'time'), ('time', ','), (',', 'Complexity'), ('Complexity', 'refers')]

>> Trigrams are: 
 [('records', ',', 'Continuity'), (',', 'Continuity', 'refers'), ('Continuity', 'refers', 'data'), ('refers', 'data', '’'), ('data', '’', 'continuous'), ('’', 'continuous', 'growth'), ('continuous', 'growth', 'time'), ('growth', 'time', ','), ('time', ',', 'Complexity'), (',', 'Complexity', 'refers')]

>> POS Tags are: 
 [('records', 'NNS'), (',', ','), ('Continuity', 'NNP'), ('refers', 'VBZ'), ('data', 'NNS'), ('’', 'NNP'), ('continuous', 'JJ'), ('growth', 'NN'), ('time', 'NN'), (',', ','), ('Complexity', 'NNP'), ('refers', 'NNS')]

>> Noun Phrases are: 
 ['records', 'Continuity', 'data ’', 'continuous growth time', 'Complexity refers']

>> Named Entities are: 
 [('ORGANIZATION', 'Continuity'), ('ORGANIZATION', 'Complexity')] 

>> Stemming using Porter Stemmer: 
 [('records', 'record'), (',', ','), ('Continuity', 'continu'), ('refers', 'refer'), ('data', 'data'), ('’', '’'), ('continuous', 'continu'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'complex'), ('refers', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('records', 'record'), (',', ','), ('Continuity', 'continu'), ('refers', 'refer'), ('data', 'data'), ('’', '’'), ('continuous', 'continu'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'complex'), ('refers', 'refer')]

>> Lemmatization: 
 [('records', 'record'), (',', ','), ('Continuity', 'Continuity'), ('refers', 'refers'), ('data', 'data'), ('’', '’'), ('continuous', 'continuous'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'Complexity'), ('refers', 'refers')]



========================================== PARAGRAPH 1056 ===========================================

data type variety (Zuech et al., 2015). Learning from the data is executed by the User Interaction  

------------------- Sentence 1 -------------------

data type variety (Zuech et al., 2015).

>> Tokens are: 
 ['data', 'type', 'variety', '(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('data', 'type'), ('type', 'variety'), ('variety', '('), ('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'type', 'variety'), ('type', 'variety', '('), ('variety', '(', 'Zuech'), ('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('type', 'NN'), ('variety', 'NN'), ('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data type variety', 'Zuech']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('type', 'type'), ('variety', 'varieti'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('type', 'type'), ('variety', 'varieti'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('type', 'type'), ('variety', 'variety'), ('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Learning from the data is executed by the User Interaction

>> Tokens are: 
 ['Learning', 'data', 'executed', 'User', 'Interaction']

>> Bigrams are: 
 [('Learning', 'data'), ('data', 'executed'), ('executed', 'User'), ('User', 'Interaction')]

>> Trigrams are: 
 [('Learning', 'data', 'executed'), ('data', 'executed', 'User'), ('executed', 'User', 'Interaction')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('data', 'NNS'), ('executed', 'VBN'), ('User', 'NNP'), ('Interaction', 'NNP')]

>> Noun Phrases are: 
 ['data', 'User Interaction']

>> Named Entities are: 
 [('PERSON', 'User Interaction')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('data', 'data'), ('executed', 'execut'), ('User', 'user'), ('Interaction', 'interact')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('data', 'data'), ('executed', 'execut'), ('User', 'user'), ('Interaction', 'interact')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('data', 'data'), ('executed', 'executed'), ('User', 'User'), ('Interaction', 'Interaction')]



========================================== PARAGRAPH 1057 ===========================================

and Learning System (UILS) which gives the user permissions to interact with the system and  

------------------- Sentence 1 -------------------

and Learning System (UILS) which gives the user permissions to interact with the system and

>> Tokens are: 
 ['Learning', 'System', '(', 'UILS', ')', 'gives', 'user', 'permissions', 'interact', 'system']

>> Bigrams are: 
 [('Learning', 'System'), ('System', '('), ('(', 'UILS'), ('UILS', ')'), (')', 'gives'), ('gives', 'user'), ('user', 'permissions'), ('permissions', 'interact'), ('interact', 'system')]

>> Trigrams are: 
 [('Learning', 'System', '('), ('System', '(', 'UILS'), ('(', 'UILS', ')'), ('UILS', ')', 'gives'), (')', 'gives', 'user'), ('gives', 'user', 'permissions'), ('user', 'permissions', 'interact'), ('permissions', 'interact', 'system')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('System', 'NNP'), ('(', '('), ('UILS', 'NNP'), (')', ')'), ('gives', 'VBZ'), ('user', 'JJ'), ('permissions', 'NNS'), ('interact', 'NN'), ('system', 'NN')]

>> Noun Phrases are: 
 ['System', 'UILS', 'user permissions interact system']

>> Named Entities are: 
 [('GPE', 'System'), ('ORGANIZATION', 'UILS')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('System', 'system'), ('(', '('), ('UILS', 'uil'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permiss'), ('interact', 'interact'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('System', 'system'), ('(', '('), ('UILS', 'uil'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permiss'), ('interact', 'interact'), ('system', 'system')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('System', 'System'), ('(', '('), ('UILS', 'UILS'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permission'), ('interact', 'interact'), ('system', 'system')]



========================================== PARAGRAPH 1058 ===========================================

control the storage requirements. The network traffic is captured by a Network Traffic Recording  

------------------- Sentence 1 -------------------

control the storage requirements.

>> Tokens are: 
 ['control', 'storage', 'requirements', '.']

>> Bigrams are: 
 [('control', 'storage'), ('storage', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('control', 'storage', 'requirements'), ('storage', 'requirements', '.')]

>> POS Tags are: 
 [('control', 'NN'), ('storage', 'NN'), ('requirements', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['control storage requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('control', 'control'), ('storage', 'storag'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('control', 'control'), ('storage', 'storag'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('control', 'control'), ('storage', 'storage'), ('requirements', 'requirement'), ('.', '.')]


------------------- Sentence 2 -------------------

The network traffic is captured by a Network Traffic Recording

>> Tokens are: 
 ['The', 'network', 'traffic', 'captured', 'Network', 'Traffic', 'Recording']

>> Bigrams are: 
 [('The', 'network'), ('network', 'traffic'), ('traffic', 'captured'), ('captured', 'Network'), ('Network', 'Traffic'), ('Traffic', 'Recording')]

>> Trigrams are: 
 [('The', 'network', 'traffic'), ('network', 'traffic', 'captured'), ('traffic', 'captured', 'Network'), ('captured', 'Network', 'Traffic'), ('Network', 'Traffic', 'Recording')]

>> POS Tags are: 
 [('The', 'DT'), ('network', 'NN'), ('traffic', 'NN'), ('captured', 'VBD'), ('Network', 'NNP'), ('Traffic', 'NNP'), ('Recording', 'VBG')]

>> Noun Phrases are: 
 ['The network traffic', 'Network Traffic']

>> Named Entities are: 
 [('PERSON', 'Network Traffic')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captur'), ('Network', 'network'), ('Traffic', 'traffic'), ('Recording', 'record')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captur'), ('Network', 'network'), ('Traffic', 'traffic'), ('Recording', 'record')]

>> Lemmatization: 
 [('The', 'The'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captured'), ('Network', 'Network'), ('Traffic', 'Traffic'), ('Recording', 'Recording')]



========================================== PARAGRAPH 1059 ===========================================

System (NTRS), which stores it locally in the Hadoop Distributed File System (HDFS) or the  

------------------- Sentence 1 -------------------

System (NTRS), which stores it locally in the Hadoop Distributed File System (HDFS) or the

>> Tokens are: 
 ['System', '(', 'NTRS', ')', ',', 'stores', 'locally', 'Hadoop', 'Distributed', 'File', 'System', '(', 'HDFS', ')']

>> Bigrams are: 
 [('System', '('), ('(', 'NTRS'), ('NTRS', ')'), (')', ','), (',', 'stores'), ('stores', 'locally'), ('locally', 'Hadoop'), ('Hadoop', 'Distributed'), ('Distributed', 'File'), ('File', 'System'), ('System', '('), ('(', 'HDFS'), ('HDFS', ')')]

>> Trigrams are: 
 [('System', '(', 'NTRS'), ('(', 'NTRS', ')'), ('NTRS', ')', ','), (')', ',', 'stores'), (',', 'stores', 'locally'), ('stores', 'locally', 'Hadoop'), ('locally', 'Hadoop', 'Distributed'), ('Hadoop', 'Distributed', 'File'), ('Distributed', 'File', 'System'), ('File', 'System', '('), ('System', '(', 'HDFS'), ('(', 'HDFS', ')')]

>> POS Tags are: 
 [('System', 'NNP'), ('(', '('), ('NTRS', 'NNP'), (')', ')'), (',', ','), ('stores', 'NNS'), ('locally', 'RB'), ('Hadoop', 'NNP'), ('Distributed', 'NNP'), ('File', 'NNP'), ('System', 'NNP'), ('(', '('), ('HDFS', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['System', 'NTRS', 'stores', 'Hadoop Distributed File System', 'HDFS']

>> Named Entities are: 
 [('GPE', 'System'), ('ORGANIZATION', 'NTRS'), ('PERSON', 'Hadoop Distributed File System'), ('ORGANIZATION', 'HDFS')] 

>> Stemming using Porter Stemmer: 
 [('System', 'system'), ('(', '('), ('NTRS', 'ntr'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'local'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('System', 'system'), ('(', '('), ('NTRS', 'ntrs'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'local'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')')]

>> Lemmatization: 
 [('System', 'System'), ('(', '('), ('NTRS', 'NTRS'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'locally'), ('Hadoop', 'Hadoop'), ('Distributed', 'Distributed'), ('File', 'File'), ('System', 'System'), ('(', '('), ('HDFS', 'HDFS'), (')', ')')]



========================================== PARAGRAPH 1060 ===========================================

Cloud Computing Storage System (CCSS).  

------------------- Sentence 1 -------------------

Cloud Computing Storage System (CCSS).

>> Tokens are: 
 ['Cloud', 'Computing', 'Storage', 'System', '(', 'CCSS', ')', '.']

>> Bigrams are: 
 [('Cloud', 'Computing'), ('Computing', 'Storage'), ('Storage', 'System'), ('System', '('), ('(', 'CCSS'), ('CCSS', ')'), (')', '.')]

>> Trigrams are: 
 [('Cloud', 'Computing', 'Storage'), ('Computing', 'Storage', 'System'), ('Storage', 'System', '('), ('System', '(', 'CCSS'), ('(', 'CCSS', ')'), ('CCSS', ')', '.')]

>> POS Tags are: 
 [('Cloud', 'NNP'), ('Computing', 'NNP'), ('Storage', 'NNP'), ('System', 'NNP'), ('(', '('), ('CCSS', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Cloud Computing Storage System', 'CCSS']

>> Named Entities are: 
 [('PERSON', 'Cloud'), ('ORGANIZATION', 'CCSS')] 

>> Stemming using Porter Stemmer: 
 [('Cloud', 'cloud'), ('Computing', 'comput'), ('Storage', 'storag'), ('System', 'system'), ('(', '('), ('CCSS', 'ccss'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cloud', 'cloud'), ('Computing', 'comput'), ('Storage', 'storag'), ('System', 'system'), ('(', '('), ('CCSS', 'ccss'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Cloud', 'Cloud'), ('Computing', 'Computing'), ('Storage', 'Storage'), ('System', 'System'), ('(', '('), ('CCSS', 'CCSS'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1061 ===========================================

Based on Hadoop technology, Cheon and Choe (2013) proposed an intrusion detection system  

------------------- Sentence 1 -------------------

Based on Hadoop technology, Cheon and Choe (2013) proposed an intrusion detection system

>> Tokens are: 
 ['Based', 'Hadoop', 'technology', ',', 'Cheon', 'Choe', '(', '2013', ')', 'proposed', 'intrusion', 'detection', 'system']

>> Bigrams are: 
 [('Based', 'Hadoop'), ('Hadoop', 'technology'), ('technology', ','), (',', 'Cheon'), ('Cheon', 'Choe'), ('Choe', '('), ('(', '2013'), ('2013', ')'), (')', 'proposed'), ('proposed', 'intrusion'), ('intrusion', 'detection'), ('detection', 'system')]

>> Trigrams are: 
 [('Based', 'Hadoop', 'technology'), ('Hadoop', 'technology', ','), ('technology', ',', 'Cheon'), (',', 'Cheon', 'Choe'), ('Cheon', 'Choe', '('), ('Choe', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'proposed'), (')', 'proposed', 'intrusion'), ('proposed', 'intrusion', 'detection'), ('intrusion', 'detection', 'system')]

>> POS Tags are: 
 [('Based', 'VBN'), ('Hadoop', 'NNP'), ('technology', 'NN'), (',', ','), ('Cheon', 'NNP'), ('Choe', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('proposed', 'VBN'), ('intrusion', 'NN'), ('detection', 'NN'), ('system', 'NN')]

>> Noun Phrases are: 
 ['Hadoop technology', 'Cheon Choe', 'intrusion detection system']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Cheon Choe')] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('Hadoop', 'hadoop'), ('technology', 'technolog'), (',', ','), ('Cheon', 'cheon'), ('Choe', 'choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('intrusion', 'intrus'), ('detection', 'detect'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('Hadoop', 'hadoop'), ('technology', 'technolog'), (',', ','), ('Cheon', 'cheon'), ('Choe', 'choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('intrusion', 'intrus'), ('detection', 'detect'), ('system', 'system')]

>> Lemmatization: 
 [('Based', 'Based'), ('Hadoop', 'Hadoop'), ('technology', 'technology'), (',', ','), ('Cheon', 'Cheon'), ('Choe', 'Choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'proposed'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('system', 'system')]



========================================== PARAGRAPH 1062 ===========================================

architecture. They added additional Hadoop-based nodes to those used in analyses, varying from  

------------------- Sentence 1 -------------------

architecture.

>> Tokens are: 
 ['architecture', '.']

>> Bigrams are: 
 [('architecture', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('architecture', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('architecture', 'architectur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('architecture', 'architectur'), ('.', '.')]

>> Lemmatization: 
 [('architecture', 'architecture'), ('.', '.')]


------------------- Sentence 2 -------------------

They added additional Hadoop-based nodes to those used in analyses, varying from

>> Tokens are: 
 ['They', 'added', 'additional', 'Hadoop-based', 'nodes', 'used', 'analyses', ',', 'varying']

>> Bigrams are: 
 [('They', 'added'), ('added', 'additional'), ('additional', 'Hadoop-based'), ('Hadoop-based', 'nodes'), ('nodes', 'used'), ('used', 'analyses'), ('analyses', ','), (',', 'varying')]

>> Trigrams are: 
 [('They', 'added', 'additional'), ('added', 'additional', 'Hadoop-based'), ('additional', 'Hadoop-based', 'nodes'), ('Hadoop-based', 'nodes', 'used'), ('nodes', 'used', 'analyses'), ('used', 'analyses', ','), ('analyses', ',', 'varying')]

>> POS Tags are: 
 [('They', 'PRP'), ('added', 'VBD'), ('additional', 'JJ'), ('Hadoop-based', 'JJ'), ('nodes', 'NNS'), ('used', 'VBN'), ('analyses', 'NNS'), (',', ','), ('varying', 'VBG')]

>> Noun Phrases are: 
 ['additional Hadoop-based nodes', 'analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('added', 'ad'), ('additional', 'addit'), ('Hadoop-based', 'hadoop-bas'), ('nodes', 'node'), ('used', 'use'), ('analyses', 'analys'), (',', ','), ('varying', 'vari')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('added', 'ad'), ('additional', 'addit'), ('Hadoop-based', 'hadoop-bas'), ('nodes', 'node'), ('used', 'use'), ('analyses', 'analys'), (',', ','), ('varying', 'vari')]

>> Lemmatization: 
 [('They', 'They'), ('added', 'added'), ('additional', 'additional'), ('Hadoop-based', 'Hadoop-based'), ('nodes', 'node'), ('used', 'used'), ('analyses', 'analysis'), (',', ','), ('varying', 'varying')]



========================================== PARAGRAPH 1063 ===========================================

zero to eight replays of files; they then evaluated their efficiency. They found that the efficiency  

------------------- Sentence 1 -------------------

zero to eight replays of files; they then evaluated their efficiency.

>> Tokens are: 
 ['zero', 'eight', 'replays', 'files', ';', 'evaluated', 'efficiency', '.']

>> Bigrams are: 
 [('zero', 'eight'), ('eight', 'replays'), ('replays', 'files'), ('files', ';'), (';', 'evaluated'), ('evaluated', 'efficiency'), ('efficiency', '.')]

>> Trigrams are: 
 [('zero', 'eight', 'replays'), ('eight', 'replays', 'files'), ('replays', 'files', ';'), ('files', ';', 'evaluated'), (';', 'evaluated', 'efficiency'), ('evaluated', 'efficiency', '.')]

>> POS Tags are: 
 [('zero', 'CD'), ('eight', 'CD'), ('replays', 'NNS'), ('files', 'VBZ'), (';', ':'), ('evaluated', 'VBN'), ('efficiency', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['replays', 'efficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evalu'), ('efficiency', 'effici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evalu'), ('efficiency', 'effici'), ('.', '.')]

>> Lemmatization: 
 [('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evaluated'), ('efficiency', 'efficiency'), ('.', '.')]


------------------- Sentence 2 -------------------

They found that the efficiency

>> Tokens are: 
 ['They', 'found', 'efficiency']

>> Bigrams are: 
 [('They', 'found'), ('found', 'efficiency')]

>> Trigrams are: 
 [('They', 'found', 'efficiency')]

>> POS Tags are: 
 [('They', 'PRP'), ('found', 'VBD'), ('efficiency', 'NN')]

>> Noun Phrases are: 
 ['efficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('found', 'found'), ('efficiency', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('found', 'found'), ('efficiency', 'effici')]

>> Lemmatization: 
 [('They', 'They'), ('found', 'found'), ('efficiency', 'efficiency')]



========================================== PARAGRAPH 1064 ===========================================

of performance was increased, and that the system spent less time processing the datasets (Zuech,  

------------------- Sentence 1 -------------------

of performance was increased, and that the system spent less time processing the datasets (Zuech,

>> Tokens are: 
 ['performance', 'increased', ',', 'system', 'spent', 'less', 'time', 'processing', 'datasets', '(', 'Zuech', ',']

>> Bigrams are: 
 [('performance', 'increased'), ('increased', ','), (',', 'system'), ('system', 'spent'), ('spent', 'less'), ('less', 'time'), ('time', 'processing'), ('processing', 'datasets'), ('datasets', '('), ('(', 'Zuech'), ('Zuech', ',')]

>> Trigrams are: 
 [('performance', 'increased', ','), ('increased', ',', 'system'), (',', 'system', 'spent'), ('system', 'spent', 'less'), ('spent', 'less', 'time'), ('less', 'time', 'processing'), ('time', 'processing', 'datasets'), ('processing', 'datasets', '('), ('datasets', '(', 'Zuech'), ('(', 'Zuech', ',')]

>> POS Tags are: 
 [('performance', 'NN'), ('increased', 'VBD'), (',', ','), ('system', 'NN'), ('spent', 'VBD'), ('less', 'JJR'), ('time', 'NN'), ('processing', 'VBG'), ('datasets', 'NNS'), ('(', '('), ('Zuech', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['performance', 'system', 'time', 'datasets', 'Zuech']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('performance', 'perform'), ('increased', 'increas'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'less'), ('time', 'time'), ('processing', 'process'), ('datasets', 'dataset'), ('(', '('), ('Zuech', 'zuech'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('performance', 'perform'), ('increased', 'increas'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'less'), ('time', 'time'), ('processing', 'process'), ('datasets', 'dataset'), ('(', '('), ('Zuech', 'zuech'), (',', ',')]

>> Lemmatization: 
 [('performance', 'performance'), ('increased', 'increased'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'le'), ('time', 'time'), ('processing', 'processing'), ('datasets', 'datasets'), ('(', '('), ('Zuech', 'Zuech'), (',', ',')]



========================================== PARAGRAPH 1065 ===========================================

et al., 2015).  

------------------- Sentence 1 -------------------

et al., 2015).

>> Tokens are: 
 ['et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1066 ===========================================

Blazquez and Domenech (2018) proposed a big data architecture based on an analysis of economic  

------------------- Sentence 1 -------------------

Blazquez and Domenech (2018) proposed a big data architecture based on an analysis of economic

>> Tokens are: 
 ['Blazquez', 'Domenech', '(', '2018', ')', 'proposed', 'big', 'data', 'architecture', 'based', 'analysis', 'economic']

>> Bigrams are: 
 [('Blazquez', 'Domenech'), ('Domenech', '('), ('(', '2018'), ('2018', ')'), (')', 'proposed'), ('proposed', 'big'), ('big', 'data'), ('data', 'architecture'), ('architecture', 'based'), ('based', 'analysis'), ('analysis', 'economic')]

>> Trigrams are: 
 [('Blazquez', 'Domenech', '('), ('Domenech', '(', '2018'), ('(', '2018', ')'), ('2018', ')', 'proposed'), (')', 'proposed', 'big'), ('proposed', 'big', 'data'), ('big', 'data', 'architecture'), ('data', 'architecture', 'based'), ('architecture', 'based', 'analysis'), ('based', 'analysis', 'economic')]

>> POS Tags are: 
 [('Blazquez', 'NNP'), ('Domenech', 'NNP'), ('(', '('), ('2018', 'CD'), (')', ')'), ('proposed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('architecture', 'NN'), ('based', 'VBN'), ('analysis', 'NN'), ('economic', 'JJ')]

>> Noun Phrases are: 
 ['Blazquez Domenech', 'big data architecture', 'analysis']

>> Named Entities are: 
 [('PERSON', 'Blazquez'), ('ORGANIZATION', 'Domenech')] 

>> Stemming using Porter Stemmer: 
 [('Blazquez', 'blazquez'), ('Domenech', 'domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('based', 'base'), ('analysis', 'analysi'), ('economic', 'econom')]

>> Stemming using Snowball Stemmer: 
 [('Blazquez', 'blazquez'), ('Domenech', 'domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('based', 'base'), ('analysis', 'analysi'), ('economic', 'econom')]

>> Lemmatization: 
 [('Blazquez', 'Blazquez'), ('Domenech', 'Domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'proposed'), ('big', 'big'), ('data', 'data'), ('architecture', 'architecture'), ('based', 'based'), ('analysis', 'analysis'), ('economic', 'economic')]



========================================== PARAGRAPH 1067 ===========================================

and social behaviour in the digital era. This study addressed the issues raised by several economic  

------------------- Sentence 1 -------------------

and social behaviour in the digital era.

>> Tokens are: 
 ['social', 'behaviour', 'digital', 'era', '.']

>> Bigrams are: 
 [('social', 'behaviour'), ('behaviour', 'digital'), ('digital', 'era'), ('era', '.')]

>> Trigrams are: 
 [('social', 'behaviour', 'digital'), ('behaviour', 'digital', 'era'), ('digital', 'era', '.')]

>> POS Tags are: 
 [('social', 'JJ'), ('behaviour', 'NN'), ('digital', 'JJ'), ('era', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['social behaviour', 'digital era']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digit'), ('era', 'era'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digit'), ('era', 'era'), ('.', '.')]

>> Lemmatization: 
 [('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digital'), ('era', 'era'), ('.', '.')]


------------------- Sentence 2 -------------------

This study addressed the issues raised by several economic

>> Tokens are: 
 ['This', 'study', 'addressed', 'issues', 'raised', 'several', 'economic']

>> Bigrams are: 
 [('This', 'study'), ('study', 'addressed'), ('addressed', 'issues'), ('issues', 'raised'), ('raised', 'several'), ('several', 'economic')]

>> Trigrams are: 
 [('This', 'study', 'addressed'), ('study', 'addressed', 'issues'), ('addressed', 'issues', 'raised'), ('issues', 'raised', 'several'), ('raised', 'several', 'economic')]

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN'), ('addressed', 'VBD'), ('issues', 'NNS'), ('raised', 'VBD'), ('several', 'JJ'), ('economic', 'JJ')]

>> Noun Phrases are: 
 ['This study', 'issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi'), ('addressed', 'address'), ('issues', 'issu'), ('raised', 'rais'), ('several', 'sever'), ('economic', 'econom')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi'), ('addressed', 'address'), ('issues', 'issu'), ('raised', 'rais'), ('several', 'sever'), ('economic', 'econom')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study'), ('addressed', 'addressed'), ('issues', 'issue'), ('raised', 'raised'), ('several', 'several'), ('economic', 'economic')]



========================================== PARAGRAPH 1068 ===========================================

and social topics by presenting multiple data sources and proposing a taxonomy for classifying  

------------------- Sentence 1 -------------------

and social topics by presenting multiple data sources and proposing a taxonomy for classifying

>> Tokens are: 
 ['social', 'topics', 'presenting', 'multiple', 'data', 'sources', 'proposing', 'taxonomy', 'classifying']

>> Bigrams are: 
 [('social', 'topics'), ('topics', 'presenting'), ('presenting', 'multiple'), ('multiple', 'data'), ('data', 'sources'), ('sources', 'proposing'), ('proposing', 'taxonomy'), ('taxonomy', 'classifying')]

>> Trigrams are: 
 [('social', 'topics', 'presenting'), ('topics', 'presenting', 'multiple'), ('presenting', 'multiple', 'data'), ('multiple', 'data', 'sources'), ('data', 'sources', 'proposing'), ('sources', 'proposing', 'taxonomy'), ('proposing', 'taxonomy', 'classifying')]

>> POS Tags are: 
 [('social', 'JJ'), ('topics', 'NNS'), ('presenting', 'VBG'), ('multiple', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('proposing', 'VBG'), ('taxonomy', 'NN'), ('classifying', 'VBG')]

>> Noun Phrases are: 
 ['social topics', 'multiple data sources', 'taxonomy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('social', 'social'), ('topics', 'topic'), ('presenting', 'present'), ('multiple', 'multipl'), ('data', 'data'), ('sources', 'sourc'), ('proposing', 'propos'), ('taxonomy', 'taxonomi'), ('classifying', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('social', 'social'), ('topics', 'topic'), ('presenting', 'present'), ('multiple', 'multipl'), ('data', 'data'), ('sources', 'sourc'), ('proposing', 'propos'), ('taxonomy', 'taxonomi'), ('classifying', 'classifi')]

>> Lemmatization: 
 [('social', 'social'), ('topics', 'topic'), ('presenting', 'presenting'), ('multiple', 'multiple'), ('data', 'data'), ('sources', 'source'), ('proposing', 'proposing'), ('taxonomy', 'taxonomy'), ('classifying', 'classifying')]



========================================== PARAGRAPH 1069 ===========================================

these depending on the purpose of the agent used to generate the data.  

------------------- Sentence 1 -------------------

these depending on the purpose of the agent used to generate the data.

>> Tokens are: 
 ['depending', 'purpose', 'agent', 'used', 'generate', 'data', '.']

>> Bigrams are: 
 [('depending', 'purpose'), ('purpose', 'agent'), ('agent', 'used'), ('used', 'generate'), ('generate', 'data'), ('data', '.')]

>> Trigrams are: 
 [('depending', 'purpose', 'agent'), ('purpose', 'agent', 'used'), ('agent', 'used', 'generate'), ('used', 'generate', 'data'), ('generate', 'data', '.')]

>> POS Tags are: 
 [('depending', 'VBG'), ('purpose', 'JJ'), ('agent', 'NN'), ('used', 'VBN'), ('generate', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['purpose agent', 'generate data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('depending', 'depend'), ('purpose', 'purpos'), ('agent', 'agent'), ('used', 'use'), ('generate', 'gener'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('depending', 'depend'), ('purpose', 'purpos'), ('agent', 'agent'), ('used', 'use'), ('generate', 'generat'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('depending', 'depending'), ('purpose', 'purpose'), ('agent', 'agent'), ('used', 'used'), ('generate', 'generate'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 1070 ===========================================

Lan, et al. (2010) used data fusion across diverse heterogeneous sources to improve intrusion  

------------------- Sentence 1 -------------------

Lan, et al.

>> Tokens are: 
 ['Lan', ',', 'et', 'al', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Lan', ',', 'et'), (',', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Lan', 'al']

>> Named Entities are: 
 [('GPE', 'Lan')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2010) used data fusion across diverse heterogeneous sources to improve intrusion

>> Tokens are: 
 ['(', '2010', ')', 'used', 'data', 'fusion', 'across', 'diverse', 'heterogeneous', 'sources', 'improve', 'intrusion']

>> Bigrams are: 
 [('(', '2010'), ('2010', ')'), (')', 'used'), ('used', 'data'), ('data', 'fusion'), ('fusion', 'across'), ('across', 'diverse'), ('diverse', 'heterogeneous'), ('heterogeneous', 'sources'), ('sources', 'improve'), ('improve', 'intrusion')]

>> Trigrams are: 
 [('(', '2010', ')'), ('2010', ')', 'used'), (')', 'used', 'data'), ('used', 'data', 'fusion'), ('data', 'fusion', 'across'), ('fusion', 'across', 'diverse'), ('across', 'diverse', 'heterogeneous'), ('diverse', 'heterogeneous', 'sources'), ('heterogeneous', 'sources', 'improve'), ('sources', 'improve', 'intrusion')]

>> POS Tags are: 
 [('(', '('), ('2010', 'CD'), (')', ')'), ('used', 'VBN'), ('data', 'NNS'), ('fusion', 'NN'), ('across', 'IN'), ('diverse', 'JJ'), ('heterogeneous', 'JJ'), ('sources', 'NNS'), ('improve', 'VBP'), ('intrusion', 'NN')]

>> Noun Phrases are: 
 ['data fusion', 'diverse heterogeneous sources', 'intrusion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'use'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'divers'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('improve', 'improv'), ('intrusion', 'intrus')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'use'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'divers'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('improve', 'improv'), ('intrusion', 'intrus')]

>> Lemmatization: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'used'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'diverse'), ('heterogeneous', 'heterogeneous'), ('sources', 'source'), ('improve', 'improve'), ('intrusion', 'intrusion')]



========================================== PARAGRAPH 1071 ===========================================

detection. As a result, they found that traditional security products such as firewalls, intrusion  

------------------- Sentence 1 -------------------

detection.

>> Tokens are: 
 ['detection', '.']

>> Bigrams are: 
 [('detection', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('detection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('detection', 'detection'), ('.', '.')]


------------------- Sentence 2 -------------------

As a result, they found that traditional security products such as firewalls, intrusion

>> Tokens are: 
 ['As', 'result', ',', 'found', 'traditional', 'security', 'products', 'firewalls', ',', 'intrusion']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'found'), ('found', 'traditional'), ('traditional', 'security'), ('security', 'products'), ('products', 'firewalls'), ('firewalls', ','), (',', 'intrusion')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'found'), (',', 'found', 'traditional'), ('found', 'traditional', 'security'), ('traditional', 'security', 'products'), ('security', 'products', 'firewalls'), ('products', 'firewalls', ','), ('firewalls', ',', 'intrusion')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('found', 'VBD'), ('traditional', 'JJ'), ('security', 'NN'), ('products', 'NNS'), ('firewalls', 'NNS'), (',', ','), ('intrusion', 'NN')]

>> Noun Phrases are: 
 ['result', 'traditional security products firewalls', 'intrusion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'tradit'), ('security', 'secur'), ('products', 'product'), ('firewalls', 'firewal'), (',', ','), ('intrusion', 'intrus')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'tradit'), ('security', 'secur'), ('products', 'product'), ('firewalls', 'firewal'), (',', ','), ('intrusion', 'intrus')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'traditional'), ('security', 'security'), ('products', 'product'), ('firewalls', 'firewall'), (',', ','), ('intrusion', 'intrusion')]



========================================== PARAGRAPH 1072 ===========================================

detection systems, and security scanners do not work together, and thus protecting networks with  

------------------- Sentence 1 -------------------

detection systems, and security scanners do not work together, and thus protecting networks with

>> Tokens are: 
 ['detection', 'systems', ',', 'security', 'scanners', 'work', 'together', ',', 'thus', 'protecting', 'networks']

>> Bigrams are: 
 [('detection', 'systems'), ('systems', ','), (',', 'security'), ('security', 'scanners'), ('scanners', 'work'), ('work', 'together'), ('together', ','), (',', 'thus'), ('thus', 'protecting'), ('protecting', 'networks')]

>> Trigrams are: 
 [('detection', 'systems', ','), ('systems', ',', 'security'), (',', 'security', 'scanners'), ('security', 'scanners', 'work'), ('scanners', 'work', 'together'), ('work', 'together', ','), ('together', ',', 'thus'), (',', 'thus', 'protecting'), ('thus', 'protecting', 'networks')]

>> POS Tags are: 
 [('detection', 'NN'), ('systems', 'NNS'), (',', ','), ('security', 'NN'), ('scanners', 'NNS'), ('work', 'VBP'), ('together', 'RB'), (',', ','), ('thus', 'RB'), ('protecting', 'VBG'), ('networks', 'NNS')]

>> Noun Phrases are: 
 ['detection systems', 'security scanners', 'networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('detection', 'detect'), ('systems', 'system'), (',', ','), ('security', 'secur'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'togeth'), (',', ','), ('thus', 'thu'), ('protecting', 'protect'), ('networks', 'network')]

>> Stemming using Snowball Stemmer: 
 [('detection', 'detect'), ('systems', 'system'), (',', ','), ('security', 'secur'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'togeth'), (',', ','), ('thus', 'thus'), ('protecting', 'protect'), ('networks', 'network')]

>> Lemmatization: 
 [('detection', 'detection'), ('systems', 'system'), (',', ','), ('security', 'security'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'together'), (',', ','), ('thus', 'thus'), ('protecting', 'protecting'), ('networks', 'network')]



========================================== PARAGRAPH 1073 ===========================================

minimal network knowledge. The authors suggested utilising a form of data fusion known as  

------------------- Sentence 1 -------------------

minimal network knowledge.

>> Tokens are: 
 ['minimal', 'network', 'knowledge', '.']

>> Bigrams are: 
 [('minimal', 'network'), ('network', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('minimal', 'network', 'knowledge'), ('network', 'knowledge', '.')]

>> POS Tags are: 
 [('minimal', 'JJ'), ('network', 'NN'), ('knowledge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['minimal network knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('minimal', 'minim'), ('network', 'network'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('minimal', 'minim'), ('network', 'network'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('minimal', 'minimal'), ('network', 'network'), ('knowledge', 'knowledge'), ('.', '.')]


------------------- Sentence 2 -------------------

The authors suggested utilising a form of data fusion known as

>> Tokens are: 
 ['The', 'authors', 'suggested', 'utilising', 'form', 'data', 'fusion', 'known']

>> Bigrams are: 
 [('The', 'authors'), ('authors', 'suggested'), ('suggested', 'utilising'), ('utilising', 'form'), ('form', 'data'), ('data', 'fusion'), ('fusion', 'known')]

>> Trigrams are: 
 [('The', 'authors', 'suggested'), ('authors', 'suggested', 'utilising'), ('suggested', 'utilising', 'form'), ('utilising', 'form', 'data'), ('form', 'data', 'fusion'), ('data', 'fusion', 'known')]

>> POS Tags are: 
 [('The', 'DT'), ('authors', 'NNS'), ('suggested', 'VBD'), ('utilising', 'JJ'), ('form', 'NN'), ('data', 'NNS'), ('fusion', 'NN'), ('known', 'VBN')]

>> Noun Phrases are: 
 ['The authors', 'utilising form data fusion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('suggested', 'suggest'), ('utilising', 'utilis'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('suggested', 'suggest'), ('utilising', 'utilis'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known')]

>> Lemmatization: 
 [('The', 'The'), ('authors', 'author'), ('suggested', 'suggested'), ('utilising', 'utilising'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known')]



========================================== PARAGRAPH 1074 ===========================================

Dempster-Shafer (D-S) evidence theory in order to better understand heterogeneous sources  

------------------- Sentence 1 -------------------

Dempster-Shafer (D-S) evidence theory in order to better understand heterogeneous sources

>> Tokens are: 
 ['Dempster-Shafer', '(', 'D-S', ')', 'evidence', 'theory', 'order', 'better', 'understand', 'heterogeneous', 'sources']

>> Bigrams are: 
 [('Dempster-Shafer', '('), ('(', 'D-S'), ('D-S', ')'), (')', 'evidence'), ('evidence', 'theory'), ('theory', 'order'), ('order', 'better'), ('better', 'understand'), ('understand', 'heterogeneous'), ('heterogeneous', 'sources')]

>> Trigrams are: 
 [('Dempster-Shafer', '(', 'D-S'), ('(', 'D-S', ')'), ('D-S', ')', 'evidence'), (')', 'evidence', 'theory'), ('evidence', 'theory', 'order'), ('theory', 'order', 'better'), ('order', 'better', 'understand'), ('better', 'understand', 'heterogeneous'), ('understand', 'heterogeneous', 'sources')]

>> POS Tags are: 
 [('Dempster-Shafer', 'NNP'), ('(', '('), ('D-S', 'NNP'), (')', ')'), ('evidence', 'NN'), ('theory', 'NN'), ('order', 'NN'), ('better', 'RBR'), ('understand', 'VBP'), ('heterogeneous', 'JJ'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['Dempster-Shafer', 'D-S', 'evidence theory order', 'heterogeneous sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Dempster-Shafer', 'dempster-shaf'), ('(', '('), ('D-S', 'd-'), (')', ')'), ('evidence', 'evid'), ('theory', 'theori'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogen'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('Dempster-Shafer', 'dempster-shaf'), ('(', '('), ('D-S', 'd-s'), (')', ')'), ('evidence', 'evid'), ('theory', 'theori'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogen'), ('sources', 'sourc')]

>> Lemmatization: 
 [('Dempster-Shafer', 'Dempster-Shafer'), ('(', '('), ('D-S', 'D-S'), (')', ')'), ('evidence', 'evidence'), ('theory', 'theory'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogeneous'), ('sources', 'source')]



========================================== PARAGRAPH 1075 ===========================================

(Zuech et al., 2015). D-S evidence theory is a common data fusion technique used by researchers  

------------------- Sentence 1 -------------------

(Zuech et al., 2015).

>> Tokens are: 
 ['(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Zuech']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

D-S evidence theory is a common data fusion technique used by researchers

>> Tokens are: 
 ['D-S', 'evidence', 'theory', 'common', 'data', 'fusion', 'technique', 'used', 'researchers']

>> Bigrams are: 
 [('D-S', 'evidence'), ('evidence', 'theory'), ('theory', 'common'), ('common', 'data'), ('data', 'fusion'), ('fusion', 'technique'), ('technique', 'used'), ('used', 'researchers')]

>> Trigrams are: 
 [('D-S', 'evidence', 'theory'), ('evidence', 'theory', 'common'), ('theory', 'common', 'data'), ('common', 'data', 'fusion'), ('data', 'fusion', 'technique'), ('fusion', 'technique', 'used'), ('technique', 'used', 'researchers')]

>> POS Tags are: 
 [('D-S', 'JJ'), ('evidence', 'NN'), ('theory', 'NN'), ('common', 'JJ'), ('data', 'NNS'), ('fusion', 'NN'), ('technique', 'NN'), ('used', 'VBN'), ('researchers', 'NNS')]

>> Noun Phrases are: 
 ['D-S evidence theory', 'common data fusion technique', 'researchers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('D-S', 'd-'), ('evidence', 'evid'), ('theory', 'theori'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'techniqu'), ('used', 'use'), ('researchers', 'research')]

>> Stemming using Snowball Stemmer: 
 [('D-S', 'd-s'), ('evidence', 'evid'), ('theory', 'theori'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'techniqu'), ('used', 'use'), ('researchers', 'research')]

>> Lemmatization: 
 [('D-S', 'D-S'), ('evidence', 'evidence'), ('theory', 'theory'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'technique'), ('used', 'used'), ('researchers', 'researcher')]



========================================== PARAGRAPH 1076 ===========================================

within the Intrusion Detection domain, which applies probabilistic techniques to monitor the  

------------------- Sentence 1 -------------------

within the Intrusion Detection domain, which applies probabilistic techniques to monitor the

>> Tokens are: 
 ['within', 'Intrusion', 'Detection', 'domain', ',', 'applies', 'probabilistic', 'techniques', 'monitor']

>> Bigrams are: 
 [('within', 'Intrusion'), ('Intrusion', 'Detection'), ('Detection', 'domain'), ('domain', ','), (',', 'applies'), ('applies', 'probabilistic'), ('probabilistic', 'techniques'), ('techniques', 'monitor')]

>> Trigrams are: 
 [('within', 'Intrusion', 'Detection'), ('Intrusion', 'Detection', 'domain'), ('Detection', 'domain', ','), ('domain', ',', 'applies'), (',', 'applies', 'probabilistic'), ('applies', 'probabilistic', 'techniques'), ('probabilistic', 'techniques', 'monitor')]

>> POS Tags are: 
 [('within', 'IN'), ('Intrusion', 'NNP'), ('Detection', 'NNP'), ('domain', 'NN'), (',', ','), ('applies', 'VBZ'), ('probabilistic', 'JJ'), ('techniques', 'NNS'), ('monitor', 'VBP')]

>> Noun Phrases are: 
 ['Intrusion Detection domain', 'probabilistic techniques']

>> Named Entities are: 
 [('ORGANIZATION', 'Intrusion Detection')] 

>> Stemming using Porter Stemmer: 
 [('within', 'within'), ('Intrusion', 'intrus'), ('Detection', 'detect'), ('domain', 'domain'), (',', ','), ('applies', 'appli'), ('probabilistic', 'probabilist'), ('techniques', 'techniqu'), ('monitor', 'monitor')]

>> Stemming using Snowball Stemmer: 
 [('within', 'within'), ('Intrusion', 'intrus'), ('Detection', 'detect'), ('domain', 'domain'), (',', ','), ('applies', 'appli'), ('probabilistic', 'probabilist'), ('techniques', 'techniqu'), ('monitor', 'monitor')]

>> Lemmatization: 
 [('within', 'within'), ('Intrusion', 'Intrusion'), ('Detection', 'Detection'), ('domain', 'domain'), (',', ','), ('applies', 'applies'), ('probabilistic', 'probabilistic'), ('techniques', 'technique'), ('monitor', 'monitor')]



========================================== PARAGRAPH 1077 ===========================================

system.  

------------------- Sentence 1 -------------------

system.

>> Tokens are: 
 ['system', '.']

>> Bigrams are: 
 [('system', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('system', 'system'), ('.', '.')]



========================================== PARAGRAPH 1078 ===========================================

  


========================================== PARAGRAPH 1079 ===========================================

 


========================================== PARAGRAPH 1080 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1081 ===========================================

39  

------------------- Sentence 1 -------------------

39

>> Tokens are: 
 ['39']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('39', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('39', '39')]

>> Stemming using Snowball Stemmer: 
 [('39', '39')]

>> Lemmatization: 
 [('39', '39')]



========================================== PARAGRAPH 1082 ===========================================

  


========================================== PARAGRAPH 1083 ===========================================

9.2. Data privacy issues  

------------------- Sentence 1 -------------------

9.2.

>> Tokens are: 
 ['9.2', '.']

>> Bigrams are: 
 [('9.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.2', '9.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.2', '9.2'), ('.', '.')]

>> Lemmatization: 
 [('9.2', '9.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Data privacy issues

>> Tokens are: 
 ['Data', 'privacy', 'issues']

>> Bigrams are: 
 [('Data', 'privacy'), ('privacy', 'issues')]

>> Trigrams are: 
 [('Data', 'privacy', 'issues')]

>> POS Tags are: 
 [('Data', 'NNP'), ('privacy', 'NN'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['Data privacy issues']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu')]

>> Lemmatization: 
 [('Data', 'Data'), ('privacy', 'privacy'), ('issues', 'issue')]



========================================== PARAGRAPH 1084 ===========================================

Gathering data from users might lead to privacy challenges where the gathering process may cause  

------------------- Sentence 1 -------------------

Gathering data from users might lead to privacy challenges where the gathering process may cause

>> Tokens are: 
 ['Gathering', 'data', 'users', 'might', 'lead', 'privacy', 'challenges', 'gathering', 'process', 'may', 'cause']

>> Bigrams are: 
 [('Gathering', 'data'), ('data', 'users'), ('users', 'might'), ('might', 'lead'), ('lead', 'privacy'), ('privacy', 'challenges'), ('challenges', 'gathering'), ('gathering', 'process'), ('process', 'may'), ('may', 'cause')]

>> Trigrams are: 
 [('Gathering', 'data', 'users'), ('data', 'users', 'might'), ('users', 'might', 'lead'), ('might', 'lead', 'privacy'), ('lead', 'privacy', 'challenges'), ('privacy', 'challenges', 'gathering'), ('challenges', 'gathering', 'process'), ('gathering', 'process', 'may'), ('process', 'may', 'cause')]

>> POS Tags are: 
 [('Gathering', 'VBG'), ('data', 'NNS'), ('users', 'NNS'), ('might', 'MD'), ('lead', 'VB'), ('privacy', 'NN'), ('challenges', 'NNS'), ('gathering', 'VBG'), ('process', 'NN'), ('may', 'MD'), ('cause', 'VB')]

>> Noun Phrases are: 
 ['data users', 'privacy challenges', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Gathering', 'gather'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privaci'), ('challenges', 'challeng'), ('gathering', 'gather'), ('process', 'process'), ('may', 'may'), ('cause', 'caus')]

>> Stemming using Snowball Stemmer: 
 [('Gathering', 'gather'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privaci'), ('challenges', 'challeng'), ('gathering', 'gather'), ('process', 'process'), ('may', 'may'), ('cause', 'caus')]

>> Lemmatization: 
 [('Gathering', 'Gathering'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privacy'), ('challenges', 'challenge'), ('gathering', 'gathering'), ('process', 'process'), ('may', 'may'), ('cause', 'cause')]



========================================== PARAGRAPH 1085 ===========================================

the data context and semantics to be modified, leading to faulty and inefficient policies (Ali et al.,  

------------------- Sentence 1 -------------------

the data context and semantics to be modified, leading to faulty and inefficient policies (Ali et al.,

>> Tokens are: 
 ['data', 'context', 'semantics', 'modified', ',', 'leading', 'faulty', 'inefficient', 'policies', '(', 'Ali', 'et', 'al.', ',']

>> Bigrams are: 
 [('data', 'context'), ('context', 'semantics'), ('semantics', 'modified'), ('modified', ','), (',', 'leading'), ('leading', 'faulty'), ('faulty', 'inefficient'), ('inefficient', 'policies'), ('policies', '('), ('(', 'Ali'), ('Ali', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('data', 'context', 'semantics'), ('context', 'semantics', 'modified'), ('semantics', 'modified', ','), ('modified', ',', 'leading'), (',', 'leading', 'faulty'), ('leading', 'faulty', 'inefficient'), ('faulty', 'inefficient', 'policies'), ('inefficient', 'policies', '('), ('policies', '(', 'Ali'), ('(', 'Ali', 'et'), ('Ali', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('data', 'NNS'), ('context', 'NN'), ('semantics', 'NNS'), ('modified', 'VBD'), (',', ','), ('leading', 'VBG'), ('faulty', 'JJ'), ('inefficient', 'JJ'), ('policies', 'NNS'), ('(', '('), ('Ali', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['data context semantics', 'faulty inefficient policies', 'Ali']

>> Named Entities are: 
 [('PERSON', 'Ali')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('context', 'context'), ('semantics', 'semant'), ('modified', 'modifi'), (',', ','), ('leading', 'lead'), ('faulty', 'faulti'), ('inefficient', 'ineffici'), ('policies', 'polici'), ('(', '('), ('Ali', 'ali'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('context', 'context'), ('semantics', 'semant'), ('modified', 'modifi'), (',', ','), ('leading', 'lead'), ('faulty', 'faulti'), ('inefficient', 'ineffici'), ('policies', 'polici'), ('(', '('), ('Ali', 'ali'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('data', 'data'), ('context', 'context'), ('semantics', 'semantics'), ('modified', 'modified'), (',', ','), ('leading', 'leading'), ('faulty', 'faulty'), ('inefficient', 'inefficient'), ('policies', 'policy'), ('(', '('), ('Ali', 'Ali'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 1086 ===========================================

2016).  

------------------- Sentence 1 -------------------

2016).

>> Tokens are: 
 ['2016', ')', '.']

>> Bigrams are: 
 [('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1087 ===========================================

Lv et al. (2017) showed that one potential problem in big data is data security and privacy, as big  

------------------- Sentence 1 -------------------

Lv et al.

>> Tokens are: 
 ['Lv', 'et', 'al', '.']

>> Bigrams are: 
 [('Lv', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Lv', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Lv', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Lv', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Lv', 'lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lv', 'lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Lv', 'Lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2017) showed that one potential problem in big data is data security and privacy, as big

>> Tokens are: 
 ['(', '2017', ')', 'showed', 'one', 'potential', 'problem', 'big', 'data', 'data', 'security', 'privacy', ',', 'big']

>> Bigrams are: 
 [('(', '2017'), ('2017', ')'), (')', 'showed'), ('showed', 'one'), ('one', 'potential'), ('potential', 'problem'), ('problem', 'big'), ('big', 'data'), ('data', 'data'), ('data', 'security'), ('security', 'privacy'), ('privacy', ','), (',', 'big')]

>> Trigrams are: 
 [('(', '2017', ')'), ('2017', ')', 'showed'), (')', 'showed', 'one'), ('showed', 'one', 'potential'), ('one', 'potential', 'problem'), ('potential', 'problem', 'big'), ('problem', 'big', 'data'), ('big', 'data', 'data'), ('data', 'data', 'security'), ('data', 'security', 'privacy'), ('security', 'privacy', ','), ('privacy', ',', 'big')]

>> POS Tags are: 
 [('(', '('), ('2017', 'CD'), (')', ')'), ('showed', 'VBD'), ('one', 'CD'), ('potential', 'NN'), ('problem', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('data', 'NNS'), ('security', 'NN'), ('privacy', 'NN'), (',', ','), ('big', 'JJ')]

>> Noun Phrases are: 
 ['potential problem', 'big data data security privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'show'), ('one', 'one'), ('potential', 'potenti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), (',', ','), ('big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'show'), ('one', 'one'), ('potential', 'potenti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), (',', ','), ('big', 'big')]

>> Lemmatization: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'showed'), ('one', 'one'), ('potential', 'potential'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'security'), ('privacy', 'privacy'), (',', ','), ('big', 'big')]



========================================== PARAGRAPH 1088 ===========================================

data applications often contain sensitive information such as medical records and banking  

------------------- Sentence 1 -------------------

data applications often contain sensitive information such as medical records and banking

>> Tokens are: 
 ['data', 'applications', 'often', 'contain', 'sensitive', 'information', 'medical', 'records', 'banking']

>> Bigrams are: 
 [('data', 'applications'), ('applications', 'often'), ('often', 'contain'), ('contain', 'sensitive'), ('sensitive', 'information'), ('information', 'medical'), ('medical', 'records'), ('records', 'banking')]

>> Trigrams are: 
 [('data', 'applications', 'often'), ('applications', 'often', 'contain'), ('often', 'contain', 'sensitive'), ('contain', 'sensitive', 'information'), ('sensitive', 'information', 'medical'), ('information', 'medical', 'records'), ('medical', 'records', 'banking')]

>> POS Tags are: 
 [('data', 'NN'), ('applications', 'NNS'), ('often', 'RB'), ('contain', 'VBP'), ('sensitive', 'JJ'), ('information', 'NN'), ('medical', 'JJ'), ('records', 'NNS'), ('banking', 'NN')]

>> Noun Phrases are: 
 ['data applications', 'sensitive information', 'medical records banking']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('applications', 'applic'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensit'), ('information', 'inform'), ('medical', 'medic'), ('records', 'record'), ('banking', 'bank')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('applications', 'applic'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensit'), ('information', 'inform'), ('medical', 'medic'), ('records', 'record'), ('banking', 'bank')]

>> Lemmatization: 
 [('data', 'data'), ('applications', 'application'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensitive'), ('information', 'information'), ('medical', 'medical'), ('records', 'record'), ('banking', 'banking')]



========================================== PARAGRAPH 1089 ===========================================

transactions which is not appropriate for normal data transmission protocols. Data security and  

------------------- Sentence 1 -------------------

transactions which is not appropriate for normal data transmission protocols.

>> Tokens are: 
 ['transactions', 'appropriate', 'normal', 'data', 'transmission', 'protocols', '.']

>> Bigrams are: 
 [('transactions', 'appropriate'), ('appropriate', 'normal'), ('normal', 'data'), ('data', 'transmission'), ('transmission', 'protocols'), ('protocols', '.')]

>> Trigrams are: 
 [('transactions', 'appropriate', 'normal'), ('appropriate', 'normal', 'data'), ('normal', 'data', 'transmission'), ('data', 'transmission', 'protocols'), ('transmission', 'protocols', '.')]

>> POS Tags are: 
 [('transactions', 'NNS'), ('appropriate', 'VBP'), ('normal', 'JJ'), ('data', 'NNS'), ('transmission', 'NN'), ('protocols', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['transactions', 'normal data transmission protocols']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('transactions', 'transact'), ('appropriate', 'appropri'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmiss'), ('protocols', 'protocol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('transactions', 'transact'), ('appropriate', 'appropri'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmiss'), ('protocols', 'protocol'), ('.', '.')]

>> Lemmatization: 
 [('transactions', 'transaction'), ('appropriate', 'appropriate'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmission'), ('protocols', 'protocol'), ('.', '.')]


------------------- Sentence 2 -------------------

Data security and

>> Tokens are: 
 ['Data', 'security']

>> Bigrams are: 
 [('Data', 'security')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNP'), ('security', 'NN')]

>> Noun Phrases are: 
 ['Data security']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('security', 'secur')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('security', 'secur')]

>> Lemmatization: 
 [('Data', 'Data'), ('security', 'security')]



========================================== PARAGRAPH 1090 ===========================================

privacy must thus be considered before the adoption of any protocol for sharing information. The  

------------------- Sentence 1 -------------------

privacy must thus be considered before the adoption of any protocol for sharing information.

>> Tokens are: 
 ['privacy', 'must', 'thus', 'considered', 'adoption', 'protocol', 'sharing', 'information', '.']

>> Bigrams are: 
 [('privacy', 'must'), ('must', 'thus'), ('thus', 'considered'), ('considered', 'adoption'), ('adoption', 'protocol'), ('protocol', 'sharing'), ('sharing', 'information'), ('information', '.')]

>> Trigrams are: 
 [('privacy', 'must', 'thus'), ('must', 'thus', 'considered'), ('thus', 'considered', 'adoption'), ('considered', 'adoption', 'protocol'), ('adoption', 'protocol', 'sharing'), ('protocol', 'sharing', 'information'), ('sharing', 'information', '.')]

>> POS Tags are: 
 [('privacy', 'NN'), ('must', 'MD'), ('thus', 'RB'), ('considered', 'VBN'), ('adoption', 'NN'), ('protocol', 'NN'), ('sharing', 'VBG'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['privacy', 'adoption protocol', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('privacy', 'privaci'), ('must', 'must'), ('thus', 'thu'), ('considered', 'consid'), ('adoption', 'adopt'), ('protocol', 'protocol'), ('sharing', 'share'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('privacy', 'privaci'), ('must', 'must'), ('thus', 'thus'), ('considered', 'consid'), ('adoption', 'adopt'), ('protocol', 'protocol'), ('sharing', 'share'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('privacy', 'privacy'), ('must', 'must'), ('thus', 'thus'), ('considered', 'considered'), ('adoption', 'adoption'), ('protocol', 'protocol'), ('sharing', 'sharing'), ('information', 'information'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 1091 ===========================================

challenges caused by the inclusion of sensitive information and the requirements for access control  

------------------- Sentence 1 -------------------

challenges caused by the inclusion of sensitive information and the requirements for access control

>> Tokens are: 
 ['challenges', 'caused', 'inclusion', 'sensitive', 'information', 'requirements', 'access', 'control']

>> Bigrams are: 
 [('challenges', 'caused'), ('caused', 'inclusion'), ('inclusion', 'sensitive'), ('sensitive', 'information'), ('information', 'requirements'), ('requirements', 'access'), ('access', 'control')]

>> Trigrams are: 
 [('challenges', 'caused', 'inclusion'), ('caused', 'inclusion', 'sensitive'), ('inclusion', 'sensitive', 'information'), ('sensitive', 'information', 'requirements'), ('information', 'requirements', 'access'), ('requirements', 'access', 'control')]

>> POS Tags are: 
 [('challenges', 'NNS'), ('caused', 'VBN'), ('inclusion', 'NN'), ('sensitive', 'JJ'), ('information', 'NN'), ('requirements', 'NNS'), ('access', 'NN'), ('control', 'NN')]

>> Noun Phrases are: 
 ['challenges', 'inclusion', 'sensitive information requirements access control']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenges', 'challeng'), ('caused', 'caus'), ('inclusion', 'inclus'), ('sensitive', 'sensit'), ('information', 'inform'), ('requirements', 'requir'), ('access', 'access'), ('control', 'control')]

>> Stemming using Snowball Stemmer: 
 [('challenges', 'challeng'), ('caused', 'caus'), ('inclusion', 'inclus'), ('sensitive', 'sensit'), ('information', 'inform'), ('requirements', 'requir'), ('access', 'access'), ('control', 'control')]

>> Lemmatization: 
 [('challenges', 'challenge'), ('caused', 'caused'), ('inclusion', 'inclusion'), ('sensitive', 'sensitive'), ('information', 'information'), ('requirements', 'requirement'), ('access', 'access'), ('control', 'control')]



========================================== PARAGRAPH 1092 ===========================================

or certification are generally well known; however, secured certification mechanisms remain  

------------------- Sentence 1 -------------------

or certification are generally well known; however, secured certification mechanisms remain

>> Tokens are: 
 ['certification', 'generally', 'well', 'known', ';', 'however', ',', 'secured', 'certification', 'mechanisms', 'remain']

>> Bigrams are: 
 [('certification', 'generally'), ('generally', 'well'), ('well', 'known'), ('known', ';'), (';', 'however'), ('however', ','), (',', 'secured'), ('secured', 'certification'), ('certification', 'mechanisms'), ('mechanisms', 'remain')]

>> Trigrams are: 
 [('certification', 'generally', 'well'), ('generally', 'well', 'known'), ('well', 'known', ';'), ('known', ';', 'however'), (';', 'however', ','), ('however', ',', 'secured'), (',', 'secured', 'certification'), ('secured', 'certification', 'mechanisms'), ('certification', 'mechanisms', 'remain')]

>> POS Tags are: 
 [('certification', 'NN'), ('generally', 'RB'), ('well', 'RB'), ('known', 'VBN'), (';', ':'), ('however', 'RB'), (',', ','), ('secured', 'VBN'), ('certification', 'NN'), ('mechanisms', 'NNS'), ('remain', 'VBP')]

>> Noun Phrases are: 
 ['certification', 'certification mechanisms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('certification', 'certif'), ('generally', 'gener'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'howev'), (',', ','), ('secured', 'secur'), ('certification', 'certif'), ('mechanisms', 'mechan'), ('remain', 'remain')]

>> Stemming using Snowball Stemmer: 
 [('certification', 'certif'), ('generally', 'general'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'howev'), (',', ','), ('secured', 'secur'), ('certification', 'certif'), ('mechanisms', 'mechan'), ('remain', 'remain')]

>> Lemmatization: 
 [('certification', 'certification'), ('generally', 'generally'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'however'), (',', ','), ('secured', 'secured'), ('certification', 'certification'), ('mechanisms', 'mechanism'), ('remain', 'remain')]



========================================== PARAGRAPH 1093 ===========================================

challenging to implement, and anonymisation approaches decrease data confidence (Wang et al.,  

------------------- Sentence 1 -------------------

challenging to implement, and anonymisation approaches decrease data confidence (Wang et al.,

>> Tokens are: 
 ['challenging', 'implement', ',', 'anonymisation', 'approaches', 'decrease', 'data', 'confidence', '(', 'Wang', 'et', 'al.', ',']

>> Bigrams are: 
 [('challenging', 'implement'), ('implement', ','), (',', 'anonymisation'), ('anonymisation', 'approaches'), ('approaches', 'decrease'), ('decrease', 'data'), ('data', 'confidence'), ('confidence', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('challenging', 'implement', ','), ('implement', ',', 'anonymisation'), (',', 'anonymisation', 'approaches'), ('anonymisation', 'approaches', 'decrease'), ('approaches', 'decrease', 'data'), ('decrease', 'data', 'confidence'), ('data', 'confidence', '('), ('confidence', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('challenging', 'VBG'), ('implement', 'NN'), (',', ','), ('anonymisation', 'NN'), ('approaches', 'NNS'), ('decrease', 'VBP'), ('data', 'NNS'), ('confidence', 'NN'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['implement', 'anonymisation approaches', 'data confidence', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('challenging', 'challeng'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymis'), ('approaches', 'approach'), ('decrease', 'decreas'), ('data', 'data'), ('confidence', 'confid'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('challenging', 'challeng'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymis'), ('approaches', 'approach'), ('decrease', 'decreas'), ('data', 'data'), ('confidence', 'confid'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('challenging', 'challenging'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymisation'), ('approaches', 'approach'), ('decrease', 'decrease'), ('data', 'data'), ('confidence', 'confidence'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 1094 ===========================================

2016).  

------------------- Sentence 1 -------------------

2016).

>> Tokens are: 
 ['2016', ')', '.']

>> Bigrams are: 
 [('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('2016', ')', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1095 ===========================================

Big data privacy contains two aspects: the first is that the personal data privacy should be protected  

------------------- Sentence 1 -------------------

Big data privacy contains two aspects: the first is that the personal data privacy should be protected

>> Tokens are: 
 ['Big', 'data', 'privacy', 'contains', 'two', 'aspects', ':', 'first', 'personal', 'data', 'privacy', 'protected']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'privacy'), ('privacy', 'contains'), ('contains', 'two'), ('two', 'aspects'), ('aspects', ':'), (':', 'first'), ('first', 'personal'), ('personal', 'data'), ('data', 'privacy'), ('privacy', 'protected')]

>> Trigrams are: 
 [('Big', 'data', 'privacy'), ('data', 'privacy', 'contains'), ('privacy', 'contains', 'two'), ('contains', 'two', 'aspects'), ('two', 'aspects', ':'), ('aspects', ':', 'first'), (':', 'first', 'personal'), ('first', 'personal', 'data'), ('personal', 'data', 'privacy'), ('data', 'privacy', 'protected')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('privacy', 'NN'), ('contains', 'VBZ'), ('two', 'CD'), ('aspects', 'NNS'), (':', ':'), ('first', 'JJ'), ('personal', 'JJ'), ('data', 'NNS'), ('privacy', 'NN'), ('protected', 'VBD')]

>> Noun Phrases are: 
 ['Big data privacy', 'aspects', 'first personal data privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('contains', 'contain'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('protected', 'protect')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('contains', 'contain'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('protected', 'protect')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('privacy', 'privacy'), ('contains', 'contains'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'personal'), ('data', 'data'), ('privacy', 'privacy'), ('protected', 'protected')]



========================================== PARAGRAPH 1096 ===========================================

during data gaining such as personal interests, habits, and body properties, etc. of users who do  

------------------- Sentence 1 -------------------

during data gaining such as personal interests, habits, and body properties, etc.

>> Tokens are: 
 ['data', 'gaining', 'personal', 'interests', ',', 'habits', ',', 'body', 'properties', ',', 'etc', '.']

>> Bigrams are: 
 [('data', 'gaining'), ('gaining', 'personal'), ('personal', 'interests'), ('interests', ','), (',', 'habits'), ('habits', ','), (',', 'body'), ('body', 'properties'), ('properties', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('data', 'gaining', 'personal'), ('gaining', 'personal', 'interests'), ('personal', 'interests', ','), ('interests', ',', 'habits'), (',', 'habits', ','), ('habits', ',', 'body'), (',', 'body', 'properties'), ('body', 'properties', ','), ('properties', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('gaining', 'VBG'), ('personal', 'JJ'), ('interests', 'NNS'), (',', ','), ('habits', 'NNS'), (',', ','), ('body', 'NN'), ('properties', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'personal interests', 'habits', 'body properties']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('gaining', 'gain'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('gaining', 'gain'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('gaining', 'gaining'), ('personal', 'personal'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'body'), ('properties', 'property'), (',', ','), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

of users who do

>> Tokens are: 
 ['users']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('users', 'NNS')]

>> Noun Phrases are: 
 ['users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('users', 'user')]

>> Stemming using Snowball Stemmer: 
 [('users', 'user')]

>> Lemmatization: 
 [('users', 'user')]



========================================== PARAGRAPH 1097 ===========================================

not aware or easy to gain information from them. The second aspect is that the personal privacy  

------------------- Sentence 1 -------------------

not aware or easy to gain information from them.

>> Tokens are: 
 ['aware', 'easy', 'gain', 'information', '.']

>> Bigrams are: 
 [('aware', 'easy'), ('easy', 'gain'), ('gain', 'information'), ('information', '.')]

>> Trigrams are: 
 [('aware', 'easy', 'gain'), ('easy', 'gain', 'information'), ('gain', 'information', '.')]

>> POS Tags are: 
 [('aware', 'JJ'), ('easy', 'JJ'), ('gain', 'NN'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['aware easy gain information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('aware', 'aware'), ('easy', 'easy'), ('gain', 'gain'), ('information', 'information'), ('.', '.')]


------------------- Sentence 2 -------------------

The second aspect is that the personal privacy

>> Tokens are: 
 ['The', 'second', 'aspect', 'personal', 'privacy']

>> Bigrams are: 
 [('The', 'second'), ('second', 'aspect'), ('aspect', 'personal'), ('personal', 'privacy')]

>> Trigrams are: 
 [('The', 'second', 'aspect'), ('second', 'aspect', 'personal'), ('aspect', 'personal', 'privacy')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('aspect', 'JJ'), ('personal', 'JJ'), ('privacy', 'NN')]

>> Noun Phrases are: 
 ['The second aspect personal privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'person'), ('privacy', 'privaci')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'person'), ('privacy', 'privaci')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'personal'), ('privacy', 'privacy')]



========================================== PARAGRAPH 1098 ===========================================

data might discharge during storage, transmission, and usage, even if it gained with the user  

------------------- Sentence 1 -------------------

data might discharge during storage, transmission, and usage, even if it gained with the user

>> Tokens are: 
 ['data', 'might', 'discharge', 'storage', ',', 'transmission', ',', 'usage', ',', 'even', 'gained', 'user']

>> Bigrams are: 
 [('data', 'might'), ('might', 'discharge'), ('discharge', 'storage'), ('storage', ','), (',', 'transmission'), ('transmission', ','), (',', 'usage'), ('usage', ','), (',', 'even'), ('even', 'gained'), ('gained', 'user')]

>> Trigrams are: 
 [('data', 'might', 'discharge'), ('might', 'discharge', 'storage'), ('discharge', 'storage', ','), ('storage', ',', 'transmission'), (',', 'transmission', ','), ('transmission', ',', 'usage'), (',', 'usage', ','), ('usage', ',', 'even'), (',', 'even', 'gained'), ('even', 'gained', 'user')]

>> POS Tags are: 
 [('data', 'NNS'), ('might', 'MD'), ('discharge', 'VB'), ('storage', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('usage', 'NN'), (',', ','), ('even', 'RB'), ('gained', 'VBD'), ('user', 'RP')]

>> Noun Phrases are: 
 ['data', 'storage', 'transmission', 'usage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user')]

>> Lemmatization: 
 [('data', 'data'), ('might', 'might'), ('discharge', 'discharge'), ('storage', 'storage'), (',', ','), ('transmission', 'transmission'), (',', ','), ('usage', 'usage'), (',', ','), ('even', 'even'), ('gained', 'gained'), ('user', 'user')]



========================================== PARAGRAPH 1099 ===========================================

permission. For example, currently, Facebook is considered as a big data company with the most  

------------------- Sentence 1 -------------------

permission.

>> Tokens are: 
 ['permission', '.']

>> Bigrams are: 
 [('permission', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('permission', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['permission']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('permission', 'permiss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('permission', 'permiss'), ('.', '.')]

>> Lemmatization: 
 [('permission', 'permission'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, currently, Facebook is considered as a big data company with the most

>> Tokens are: 
 ['For', 'example', ',', 'currently', ',', 'Facebook', 'considered', 'big', 'data', 'company']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'currently'), ('currently', ','), (',', 'Facebook'), ('Facebook', 'considered'), ('considered', 'big'), ('big', 'data'), ('data', 'company')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'currently'), (',', 'currently', ','), ('currently', ',', 'Facebook'), (',', 'Facebook', 'considered'), ('Facebook', 'considered', 'big'), ('considered', 'big', 'data'), ('big', 'data', 'company')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('currently', 'RB'), (',', ','), ('Facebook', 'NNP'), ('considered', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('company', 'NN')]

>> Noun Phrases are: 
 ['example', 'Facebook', 'big data company']

>> Named Entities are: 
 [('PERSON', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('currently', 'current'), (',', ','), ('Facebook', 'facebook'), ('considered', 'consid'), ('big', 'big'), ('data', 'data'), ('company', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('currently', 'current'), (',', ','), ('Facebook', 'facebook'), ('considered', 'consid'), ('big', 'big'), ('data', 'data'), ('company', 'compani')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('currently', 'currently'), (',', ','), ('Facebook', 'Facebook'), ('considered', 'considered'), ('big', 'big'), ('data', 'data'), ('company', 'company')]



========================================== PARAGRAPH 1100 ===========================================

social networking service SNS data. Even though, some researchers gained data from public pages  

------------------- Sentence 1 -------------------

social networking service SNS data.

>> Tokens are: 
 ['social', 'networking', 'service', 'SNS', 'data', '.']

>> Bigrams are: 
 [('social', 'networking'), ('networking', 'service'), ('service', 'SNS'), ('SNS', 'data'), ('data', '.')]

>> Trigrams are: 
 [('social', 'networking', 'service'), ('networking', 'service', 'SNS'), ('service', 'SNS', 'data'), ('SNS', 'data', '.')]

>> POS Tags are: 
 [('social', 'JJ'), ('networking', 'NN'), ('service', 'NN'), ('SNS', 'NNP'), ('data', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['social networking service SNS data']

>> Named Entities are: 
 [('ORGANIZATION', 'SNS')] 

>> Stemming using Porter Stemmer: 
 [('social', 'social'), ('networking', 'network'), ('service', 'servic'), ('SNS', 'sn'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('social', 'social'), ('networking', 'network'), ('service', 'servic'), ('SNS', 'sns'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('social', 'social'), ('networking', 'networking'), ('service', 'service'), ('SNS', 'SNS'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Even though, some researchers gained data from public pages

>> Tokens are: 
 ['Even', 'though', ',', 'researchers', 'gained', 'data', 'public', 'pages']

>> Bigrams are: 
 [('Even', 'though'), ('though', ','), (',', 'researchers'), ('researchers', 'gained'), ('gained', 'data'), ('data', 'public'), ('public', 'pages')]

>> Trigrams are: 
 [('Even', 'though', ','), ('though', ',', 'researchers'), (',', 'researchers', 'gained'), ('researchers', 'gained', 'data'), ('gained', 'data', 'public'), ('data', 'public', 'pages')]

>> POS Tags are: 
 [('Even', 'RB'), ('though', 'IN'), (',', ','), ('researchers', 'NNS'), ('gained', 'VBD'), ('data', 'NNS'), ('public', 'JJ'), ('pages', 'NNS')]

>> Noun Phrases are: 
 ['researchers', 'data', 'public pages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Even', 'even'), ('though', 'though'), (',', ','), ('researchers', 'research'), ('gained', 'gain'), ('data', 'data'), ('public', 'public'), ('pages', 'page')]

>> Stemming using Snowball Stemmer: 
 [('Even', 'even'), ('though', 'though'), (',', ','), ('researchers', 'research'), ('gained', 'gain'), ('data', 'data'), ('public', 'public'), ('pages', 'page')]

>> Lemmatization: 
 [('Even', 'Even'), ('though', 'though'), (',', ','), ('researchers', 'researcher'), ('gained', 'gained'), ('data', 'data'), ('public', 'public'), ('pages', 'page')]



========================================== PARAGRAPH 1101 ===========================================

of Facebook users who did not change their privacy setting through an information-gaining tool  

------------------- Sentence 1 -------------------

of Facebook users who did not change their privacy setting through an information-gaining tool

>> Tokens are: 
 ['Facebook', 'users', 'change', 'privacy', 'setting', 'information-gaining', 'tool']

>> Bigrams are: 
 [('Facebook', 'users'), ('users', 'change'), ('change', 'privacy'), ('privacy', 'setting'), ('setting', 'information-gaining'), ('information-gaining', 'tool')]

>> Trigrams are: 
 [('Facebook', 'users', 'change'), ('users', 'change', 'privacy'), ('change', 'privacy', 'setting'), ('privacy', 'setting', 'information-gaining'), ('setting', 'information-gaining', 'tool')]

>> POS Tags are: 
 [('Facebook', 'NNP'), ('users', 'NNS'), ('change', 'VBP'), ('privacy', 'NN'), ('setting', 'VBG'), ('information-gaining', 'JJ'), ('tool', 'NN')]

>> Noun Phrases are: 
 ['Facebook users', 'privacy', 'information-gaining tool']

>> Named Entities are: 
 [('GPE', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('Facebook', 'facebook'), ('users', 'user'), ('change', 'chang'), ('privacy', 'privaci'), ('setting', 'set'), ('information-gaining', 'information-gain'), ('tool', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Facebook', 'facebook'), ('users', 'user'), ('change', 'chang'), ('privacy', 'privaci'), ('setting', 'set'), ('information-gaining', 'information-gain'), ('tool', 'tool')]

>> Lemmatization: 
 [('Facebook', 'Facebook'), ('users', 'user'), ('change', 'change'), ('privacy', 'privacy'), ('setting', 'setting'), ('information-gaining', 'information-gaining'), ('tool', 'tool')]



========================================== PARAGRAPH 1102 ===========================================

(Chen, M., Mao, S. and Liu, Y., 2014).  

------------------- Sentence 1 -------------------

(Chen, M., Mao, S. and Liu, Y., 2014).

>> Tokens are: 
 ['(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1103 ===========================================

9.3. Data storage, data capture and quality of data  

------------------- Sentence 1 -------------------

9.3.

>> Tokens are: 
 ['9.3', '.']

>> Bigrams are: 
 [('9.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Lemmatization: 
 [('9.3', '9.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Data storage, data capture and quality of data

>> Tokens are: 
 ['Data', 'storage', ',', 'data', 'capture', 'quality', 'data']

>> Bigrams are: 
 [('Data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'capture'), ('capture', 'quality'), ('quality', 'data')]

>> Trigrams are: 
 [('Data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'capture'), ('data', 'capture', 'quality'), ('capture', 'quality', 'data')]

>> POS Tags are: 
 [('Data', 'NNP'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('capture', 'VBP'), ('quality', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Data storage', 'data', 'quality data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data')]

>> Lemmatization: 
 [('Data', 'Data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('capture', 'capture'), ('quality', 'quality'), ('data', 'data')]



========================================== PARAGRAPH 1104 ===========================================

Capturing and storing data is not easy, especially as data sets are increasingly growing in size and  

------------------- Sentence 1 -------------------

Capturing and storing data is not easy, especially as data sets are increasingly growing in size and

>> Tokens are: 
 ['Capturing', 'storing', 'data', 'easy', ',', 'especially', 'data', 'sets', 'increasingly', 'growing', 'size']

>> Bigrams are: 
 [('Capturing', 'storing'), ('storing', 'data'), ('data', 'easy'), ('easy', ','), (',', 'especially'), ('especially', 'data'), ('data', 'sets'), ('sets', 'increasingly'), ('increasingly', 'growing'), ('growing', 'size')]

>> Trigrams are: 
 [('Capturing', 'storing', 'data'), ('storing', 'data', 'easy'), ('data', 'easy', ','), ('easy', ',', 'especially'), (',', 'especially', 'data'), ('especially', 'data', 'sets'), ('data', 'sets', 'increasingly'), ('sets', 'increasingly', 'growing'), ('increasingly', 'growing', 'size')]

>> POS Tags are: 
 [('Capturing', 'VBG'), ('storing', 'VBG'), ('data', 'NNS'), ('easy', 'RB'), (',', ','), ('especially', 'RB'), ('data', 'JJ'), ('sets', 'NNS'), ('increasingly', 'RB'), ('growing', 'VBG'), ('size', 'NN')]

>> Noun Phrases are: 
 ['data', 'data sets', 'size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Capturing', 'captur'), ('storing', 'store'), ('data', 'data'), ('easy', 'easi'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increasingli'), ('growing', 'grow'), ('size', 'size')]

>> Stemming using Snowball Stemmer: 
 [('Capturing', 'captur'), ('storing', 'store'), ('data', 'data'), ('easy', 'easi'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increas'), ('growing', 'grow'), ('size', 'size')]

>> Lemmatization: 
 [('Capturing', 'Capturing'), ('storing', 'storing'), ('data', 'data'), ('easy', 'easy'), (',', ','), ('especially', 'especially'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increasingly'), ('growing', 'growing'), ('size', 'size')]



========================================== PARAGRAPH 1105 ===========================================

complexity. There is often not enough space to store such big data, and many sectors and fields  

------------------- Sentence 1 -------------------

complexity.

>> Tokens are: 
 ['complexity', '.']

>> Bigrams are: 
 [('complexity', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('complexity', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['complexity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('complexity', 'complex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('complexity', 'complex'), ('.', '.')]

>> Lemmatization: 
 [('complexity', 'complexity'), ('.', '.')]


------------------- Sentence 2 -------------------

There is often not enough space to store such big data, and many sectors and fields

>> Tokens are: 
 ['There', 'often', 'enough', 'space', 'store', 'big', 'data', ',', 'many', 'sectors', 'fields']

>> Bigrams are: 
 [('There', 'often'), ('often', 'enough'), ('enough', 'space'), ('space', 'store'), ('store', 'big'), ('big', 'data'), ('data', ','), (',', 'many'), ('many', 'sectors'), ('sectors', 'fields')]

>> Trigrams are: 
 [('There', 'often', 'enough'), ('often', 'enough', 'space'), ('enough', 'space', 'store'), ('space', 'store', 'big'), ('store', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'many'), (',', 'many', 'sectors'), ('many', 'sectors', 'fields')]

>> POS Tags are: 
 [('There', 'EX'), ('often', 'RB'), ('enough', 'JJ'), ('space', 'NN'), ('store', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('many', 'JJ'), ('sectors', 'NNS'), ('fields', 'NNS')]

>> Noun Phrases are: 
 ['enough space store', 'big data', 'many sectors fields']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('sectors', 'sector'), ('fields', 'field')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('sectors', 'sector'), ('fields', 'field')]

>> Lemmatization: 
 [('There', 'There'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'many'), ('sectors', 'sector'), ('fields', 'field')]



========================================== PARAGRAPH 1106 ===========================================

such as the financial and medical areas are forced to delete data. Capturing and creating valuable  

------------------- Sentence 1 -------------------

such as the financial and medical areas are forced to delete data.

>> Tokens are: 
 ['financial', 'medical', 'areas', 'forced', 'delete', 'data', '.']

>> Bigrams are: 
 [('financial', 'medical'), ('medical', 'areas'), ('areas', 'forced'), ('forced', 'delete'), ('delete', 'data'), ('data', '.')]

>> Trigrams are: 
 [('financial', 'medical', 'areas'), ('medical', 'areas', 'forced'), ('areas', 'forced', 'delete'), ('forced', 'delete', 'data'), ('delete', 'data', '.')]

>> POS Tags are: 
 [('financial', 'JJ'), ('medical', 'JJ'), ('areas', 'NNS'), ('forced', 'VBD'), ('delete', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['financial medical areas', 'delete data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('financial', 'financi'), ('medical', 'medic'), ('areas', 'area'), ('forced', 'forc'), ('delete', 'delet'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('financial', 'financi'), ('medical', 'medic'), ('areas', 'area'), ('forced', 'forc'), ('delete', 'delet'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('financial', 'financial'), ('medical', 'medical'), ('areas', 'area'), ('forced', 'forced'), ('delete', 'delete'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Capturing and creating valuable

>> Tokens are: 
 ['Capturing', 'creating', 'valuable']

>> Bigrams are: 
 [('Capturing', 'creating'), ('creating', 'valuable')]

>> Trigrams are: 
 [('Capturing', 'creating', 'valuable')]

>> POS Tags are: 
 [('Capturing', 'VBG'), ('creating', 'VBG'), ('valuable', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Capturing', 'captur'), ('creating', 'creat'), ('valuable', 'valuabl')]

>> Stemming using Snowball Stemmer: 
 [('Capturing', 'captur'), ('creating', 'creat'), ('valuable', 'valuabl')]

>> Lemmatization: 
 [('Capturing', 'Capturing'), ('creating', 'creating'), ('valuable', 'valuable')]



========================================== PARAGRAPH 1107 ===========================================

data is only done at a high cost (Chen et al., 2014).  

------------------- Sentence 1 -------------------

data is only done at a high cost (Chen et al., 2014).

>> Tokens are: 
 ['data', 'done', 'high', 'cost', '(', 'Chen', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('data', 'done'), ('done', 'high'), ('high', 'cost'), ('cost', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('data', 'done', 'high'), ('done', 'high', 'cost'), ('high', 'cost', '('), ('cost', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('done', 'VBN'), ('high', 'JJ'), ('cost', 'NN'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'high cost', 'Chen']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1108 ===========================================

Oussous et al. (2018) discussed big data characteristics in terms of it being processed by many  

------------------- Sentence 1 -------------------

Oussous et al.

>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018) discussed big data characteristics in terms of it being processed by many

>> Tokens are: 
 ['(', '2018', ')', 'discussed', 'big', 'data', 'characteristics', 'terms', 'processed', 'many']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'discussed'), ('discussed', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', 'terms'), ('terms', 'processed'), ('processed', 'many')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'discussed'), (')', 'discussed', 'big'), ('discussed', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', 'terms'), ('characteristics', 'terms', 'processed'), ('terms', 'processed', 'many')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('discussed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), ('terms', 'NNS'), ('processed', 'VBD'), ('many', 'JJ')]

>> Noun Phrases are: 
 ['big data characteristics terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('terms', 'term'), ('processed', 'process'), ('many', 'mani')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('terms', 'term'), ('processed', 'process'), ('many', 'mani')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discussed'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), ('terms', 'term'), ('processed', 'processed'), ('many', 'many')]



========================================== PARAGRAPH 1109 ===========================================

analytics tools and visualisations. The big data platforms layer and its components and  

------------------- Sentence 1 -------------------

analytics tools and visualisations.

>> Tokens are: 
 ['analytics', 'tools', 'visualisations', '.']

>> Bigrams are: 
 [('analytics', 'tools'), ('tools', 'visualisations'), ('visualisations', '.')]

>> Trigrams are: 
 [('analytics', 'tools', 'visualisations'), ('tools', 'visualisations', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('tools', 'NNS'), ('visualisations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics tools visualisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('tools', 'tool'), ('visualisations', 'visualis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('tools', 'tool'), ('visualisations', 'visualis'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('tools', 'tool'), ('visualisations', 'visualisation'), ('.', '.')]


------------------- Sentence 2 -------------------

The big data platforms layer and its components and

>> Tokens are: 
 ['The', 'big', 'data', 'platforms', 'layer', 'components']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', 'layer'), ('layer', 'components')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', 'layer'), ('platforms', 'layer', 'components')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('layer', 'VBP'), ('components', 'NNS')]

>> Noun Phrases are: 
 ['The big data platforms', 'components']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'compon')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'compon')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'component')]



========================================== PARAGRAPH 1110 ===========================================

technologies were explained. In term of capabilities, different technologies were compared, and  

------------------- Sentence 1 -------------------

technologies were explained.

>> Tokens are: 
 ['technologies', 'explained', '.']

>> Bigrams are: 
 [('technologies', 'explained'), ('explained', '.')]

>> Trigrams are: 
 [('technologies', 'explained', '.')]

>> POS Tags are: 
 [('technologies', 'NNS'), ('explained', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('technologies', 'technolog'), ('explained', 'explain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('technologies', 'technolog'), ('explained', 'explain'), ('.', '.')]

>> Lemmatization: 
 [('technologies', 'technology'), ('explained', 'explained'), ('.', '.')]


------------------- Sentence 2 -------------------

In term of capabilities, different technologies were compared, and

>> Tokens are: 
 ['In', 'term', 'capabilities', ',', 'different', 'technologies', 'compared', ',']

>> Bigrams are: 
 [('In', 'term'), ('term', 'capabilities'), ('capabilities', ','), (',', 'different'), ('different', 'technologies'), ('technologies', 'compared'), ('compared', ',')]

>> Trigrams are: 
 [('In', 'term', 'capabilities'), ('term', 'capabilities', ','), ('capabilities', ',', 'different'), (',', 'different', 'technologies'), ('different', 'technologies', 'compared'), ('technologies', 'compared', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('term', 'NN'), ('capabilities', 'NNS'), (',', ','), ('different', 'JJ'), ('technologies', 'NNS'), ('compared', 'VBN'), (',', ',')]

>> Noun Phrases are: 
 ['term capabilities', 'different technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('term', 'term'), ('capabilities', 'capabl'), (',', ','), ('different', 'differ'), ('technologies', 'technolog'), ('compared', 'compar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('term', 'term'), ('capabilities', 'capabl'), (',', ','), ('different', 'differ'), ('technologies', 'technolog'), ('compared', 'compar'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('term', 'term'), ('capabilities', 'capability'), (',', ','), ('different', 'different'), ('technologies', 'technology'), ('compared', 'compared'), (',', ',')]



========================================== PARAGRAPH 1111 ===========================================

big data systems categorised according to their features and the services provided to users. They  

------------------- Sentence 1 -------------------

big data systems categorised according to their features and the services provided to users.

>> Tokens are: 
 ['big', 'data', 'systems', 'categorised', 'according', 'features', 'services', 'provided', 'users', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'systems'), ('systems', 'categorised'), ('categorised', 'according'), ('according', 'features'), ('features', 'services'), ('services', 'provided'), ('provided', 'users'), ('users', '.')]

>> Trigrams are: 
 [('big', 'data', 'systems'), ('data', 'systems', 'categorised'), ('systems', 'categorised', 'according'), ('categorised', 'according', 'features'), ('according', 'features', 'services'), ('features', 'services', 'provided'), ('services', 'provided', 'users'), ('provided', 'users', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('systems', 'NNS'), ('categorised', 'VBD'), ('according', 'VBG'), ('features', 'NNS'), ('services', 'NNS'), ('provided', 'VBD'), ('users', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data systems', 'features services', 'users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categoris'), ('according', 'accord'), ('features', 'featur'), ('services', 'servic'), ('provided', 'provid'), ('users', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categoris'), ('according', 'accord'), ('features', 'featur'), ('services', 'servic'), ('provided', 'provid'), ('users', 'user'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categorised'), ('according', 'according'), ('features', 'feature'), ('services', 'service'), ('provided', 'provided'), ('users', 'user'), ('.', '.')]


------------------- Sentence 2 -------------------

They

>> Tokens are: 
 ['They']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('They', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they')]

>> Lemmatization: 
 [('They', 'They')]



========================================== PARAGRAPH 1112 ===========================================

showed that big data use still has many technical issues that need to be studied. They also presented  

------------------- Sentence 1 -------------------

showed that big data use still has many technical issues that need to be studied.

>> Tokens are: 
 ['showed', 'big', 'data', 'use', 'still', 'many', 'technical', 'issues', 'need', 'studied', '.']

>> Bigrams are: 
 [('showed', 'big'), ('big', 'data'), ('data', 'use'), ('use', 'still'), ('still', 'many'), ('many', 'technical'), ('technical', 'issues'), ('issues', 'need'), ('need', 'studied'), ('studied', '.')]

>> Trigrams are: 
 [('showed', 'big', 'data'), ('big', 'data', 'use'), ('data', 'use', 'still'), ('use', 'still', 'many'), ('still', 'many', 'technical'), ('many', 'technical', 'issues'), ('technical', 'issues', 'need'), ('issues', 'need', 'studied'), ('need', 'studied', '.')]

>> POS Tags are: 
 [('showed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('use', 'NN'), ('still', 'RB'), ('many', 'JJ'), ('technical', 'JJ'), ('issues', 'NNS'), ('need', 'VBP'), ('studied', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data use', 'many technical issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('showed', 'show'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'mani'), ('technical', 'technic'), ('issues', 'issu'), ('need', 'need'), ('studied', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('showed', 'show'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'mani'), ('technical', 'technic'), ('issues', 'issu'), ('need', 'need'), ('studied', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('showed', 'showed'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'many'), ('technical', 'technical'), ('issues', 'issue'), ('need', 'need'), ('studied', 'studied'), ('.', '.')]


------------------- Sentence 2 -------------------

They also presented

>> Tokens are: 
 ['They', 'also', 'presented']

>> Bigrams are: 
 [('They', 'also'), ('also', 'presented')]

>> Trigrams are: 
 [('They', 'also', 'presented')]

>> POS Tags are: 
 [('They', 'PRP'), ('also', 'RB'), ('presented', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('also', 'also'), ('presented', 'present')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('also', 'also'), ('presented', 'present')]

>> Lemmatization: 
 [('They', 'They'), ('also', 'also'), ('presented', 'presented')]



========================================== PARAGRAPH 1113 ===========================================

big data computing systems’ challenges, examining difficulties on various different levels  

------------------- Sentence 1 -------------------

big data computing systems’ challenges, examining difficulties on various different levels

>> Tokens are: 
 ['big', 'data', 'computing', 'systems', '’', 'challenges', ',', 'examining', 'difficulties', 'various', 'different', 'levels']

>> Bigrams are: 
 [('big', 'data'), ('data', 'computing'), ('computing', 'systems'), ('systems', '’'), ('’', 'challenges'), ('challenges', ','), (',', 'examining'), ('examining', 'difficulties'), ('difficulties', 'various'), ('various', 'different'), ('different', 'levels')]

>> Trigrams are: 
 [('big', 'data', 'computing'), ('data', 'computing', 'systems'), ('computing', 'systems', '’'), ('systems', '’', 'challenges'), ('’', 'challenges', ','), ('challenges', ',', 'examining'), (',', 'examining', 'difficulties'), ('examining', 'difficulties', 'various'), ('difficulties', 'various', 'different'), ('various', 'different', 'levels')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('computing', 'VBG'), ('systems', 'NNS'), ('’', 'JJ'), ('challenges', 'NNS'), (',', ','), ('examining', 'VBG'), ('difficulties', 'NNS'), ('various', 'JJ'), ('different', 'JJ'), ('levels', 'NNS')]

>> Noun Phrases are: 
 ['big data', 'systems', '’ challenges', 'difficulties', 'various different levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('computing', 'comput'), ('systems', 'system'), ('’', '’'), ('challenges', 'challeng'), (',', ','), ('examining', 'examin'), ('difficulties', 'difficulti'), ('various', 'variou'), ('different', 'differ'), ('levels', 'level')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('computing', 'comput'), ('systems', 'system'), ('’', '’'), ('challenges', 'challeng'), (',', ','), ('examining', 'examin'), ('difficulties', 'difficulti'), ('various', 'various'), ('different', 'differ'), ('levels', 'level')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('computing', 'computing'), ('systems', 'system'), ('’', '’'), ('challenges', 'challenge'), (',', ','), ('examining', 'examining'), ('difficulties', 'difficulty'), ('various', 'various'), ('different', 'different'), ('levels', 'level')]



========================================== PARAGRAPH 1114 ===========================================

“including data capture, storage, searching, sharing, analysis, management and visualisation”. This  

------------------- Sentence 1 -------------------

“including data capture, storage, searching, sharing, analysis, management and visualisation”.

>> Tokens are: 
 ['“', 'including', 'data', 'capture', ',', 'storage', ',', 'searching', ',', 'sharing', ',', 'analysis', ',', 'management', 'visualisation', '”', '.']

>> Bigrams are: 
 [('“', 'including'), ('including', 'data'), ('data', 'capture'), ('capture', ','), (',', 'storage'), ('storage', ','), (',', 'searching'), ('searching', ','), (',', 'sharing'), ('sharing', ','), (',', 'analysis'), ('analysis', ','), (',', 'management'), ('management', 'visualisation'), ('visualisation', '”'), ('”', '.')]

>> Trigrams are: 
 [('“', 'including', 'data'), ('including', 'data', 'capture'), ('data', 'capture', ','), ('capture', ',', 'storage'), (',', 'storage', ','), ('storage', ',', 'searching'), (',', 'searching', ','), ('searching', ',', 'sharing'), (',', 'sharing', ','), ('sharing', ',', 'analysis'), (',', 'analysis', ','), ('analysis', ',', 'management'), (',', 'management', 'visualisation'), ('management', 'visualisation', '”'), ('visualisation', '”', '.')]

>> POS Tags are: 
 [('“', 'JJ'), ('including', 'VBG'), ('data', 'NNS'), ('capture', 'NN'), (',', ','), ('storage', 'NN'), (',', ','), ('searching', 'VBG'), (',', ','), ('sharing', 'VBG'), (',', ','), ('analysis', 'NN'), (',', ','), ('management', 'NN'), ('visualisation', 'NN'), ('”', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data capture', 'storage', 'analysis', 'management visualisation ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('including', 'includ'), ('data', 'data'), ('capture', 'captur'), (',', ','), ('storage', 'storag'), (',', ','), ('searching', 'search'), (',', ','), ('sharing', 'share'), (',', ','), ('analysis', 'analysi'), (',', ','), ('management', 'manag'), ('visualisation', 'visualis'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('including', 'includ'), ('data', 'data'), ('capture', 'captur'), (',', ','), ('storage', 'storag'), (',', ','), ('searching', 'search'), (',', ','), ('sharing', 'share'), (',', ','), ('analysis', 'analysi'), (',', ','), ('management', 'manag'), ('visualisation', 'visualis'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('including', 'including'), ('data', 'data'), ('capture', 'capture'), (',', ','), ('storage', 'storage'), (',', ','), ('searching', 'searching'), (',', ','), ('sharing', 'sharing'), (',', ','), ('analysis', 'analysis'), (',', ','), ('management', 'management'), ('visualisation', 'visualisation'), ('”', '”'), ('.', '.')]


------------------- Sentence 2 -------------------

This

>> Tokens are: 
 ['This']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('This', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this')]

>> Lemmatization: 
 [('This', 'This')]



========================================== PARAGRAPH 1115 ===========================================

included examining security and privacy issues. The size of big data is increasing exponentially,  

------------------- Sentence 1 -------------------

included examining security and privacy issues.

>> Tokens are: 
 ['included', 'examining', 'security', 'privacy', 'issues', '.']

>> Bigrams are: 
 [('included', 'examining'), ('examining', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('included', 'examining', 'security'), ('examining', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', '.')]

>> POS Tags are: 
 [('included', 'VBN'), ('examining', 'VBG'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['security privacy issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('included', 'includ'), ('examining', 'examin'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('included', 'includ'), ('examining', 'examin'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('included', 'included'), ('examining', 'examining'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), ('.', '.')]


------------------- Sentence 2 -------------------

The size of big data is increasing exponentially,

>> Tokens are: 
 ['The', 'size', 'big', 'data', 'increasing', 'exponentially', ',']

>> Bigrams are: 
 [('The', 'size'), ('size', 'big'), ('big', 'data'), ('data', 'increasing'), ('increasing', 'exponentially'), ('exponentially', ',')]

>> Trigrams are: 
 [('The', 'size', 'big'), ('size', 'big', 'data'), ('big', 'data', 'increasing'), ('data', 'increasing', 'exponentially'), ('increasing', 'exponentially', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('size', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('increasing', 'VBG'), ('exponentially', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['The size', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increas'), ('exponentially', 'exponenti'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increas'), ('exponentially', 'exponenti'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increasing'), ('exponentially', 'exponentially'), (',', ',')]



========================================== PARAGRAPH 1116 ===========================================

and this makes the current technology unable to handle such big datasets.   

------------------- Sentence 1 -------------------

and this makes the current technology unable to handle such big datasets.

>> Tokens are: 
 ['makes', 'current', 'technology', 'unable', 'handle', 'big', 'datasets', '.']

>> Bigrams are: 
 [('makes', 'current'), ('current', 'technology'), ('technology', 'unable'), ('unable', 'handle'), ('handle', 'big'), ('big', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('makes', 'current', 'technology'), ('current', 'technology', 'unable'), ('technology', 'unable', 'handle'), ('unable', 'handle', 'big'), ('handle', 'big', 'datasets'), ('big', 'datasets', '.')]

>> POS Tags are: 
 [('makes', 'VBZ'), ('current', 'JJ'), ('technology', 'NN'), ('unable', 'JJ'), ('handle', 'NN'), ('big', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['current technology', 'unable handle', 'big datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('makes', 'make'), ('current', 'current'), ('technology', 'technolog'), ('unable', 'unabl'), ('handle', 'handl'), ('big', 'big'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('makes', 'make'), ('current', 'current'), ('technology', 'technolog'), ('unable', 'unabl'), ('handle', 'handl'), ('big', 'big'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('makes', 'make'), ('current', 'current'), ('technology', 'technology'), ('unable', 'unable'), ('handle', 'handle'), ('big', 'big'), ('datasets', 'datasets'), ('.', '.')]



========================================== PARAGRAPH 1117 ===========================================

Modern big data challenges thus include big data management where the challenge lies in  

------------------- Sentence 1 -------------------

Modern big data challenges thus include big data management where the challenge lies in

>> Tokens are: 
 ['Modern', 'big', 'data', 'challenges', 'thus', 'include', 'big', 'data', 'management', 'challenge', 'lies']

>> Bigrams are: 
 [('Modern', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'thus'), ('thus', 'include'), ('include', 'big'), ('big', 'data'), ('data', 'management'), ('management', 'challenge'), ('challenge', 'lies')]

>> Trigrams are: 
 [('Modern', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'thus'), ('challenges', 'thus', 'include'), ('thus', 'include', 'big'), ('include', 'big', 'data'), ('big', 'data', 'management'), ('data', 'management', 'challenge'), ('management', 'challenge', 'lies')]

>> POS Tags are: 
 [('Modern', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('thus', 'RB'), ('include', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('challenge', 'NN'), ('lies', 'NNS')]

>> Noun Phrases are: 
 ['Modern', 'big data challenges', 'big data management challenge lies']

>> Named Entities are: 
 [('GPE', 'Modern')] 

>> Stemming using Porter Stemmer: 
 [('Modern', 'modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('thus', 'thu'), ('include', 'includ'), ('big', 'big'), ('data', 'data'), ('management', 'manag'), ('challenge', 'challeng'), ('lies', 'lie')]

>> Stemming using Snowball Stemmer: 
 [('Modern', 'modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('thus', 'thus'), ('include', 'includ'), ('big', 'big'), ('data', 'data'), ('management', 'manag'), ('challenge', 'challeng'), ('lies', 'lie')]

>> Lemmatization: 
 [('Modern', 'Modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('thus', 'thus'), ('include', 'include'), ('big', 'big'), ('data', 'data'), ('management', 'management'), ('challenge', 'challenge'), ('lies', 'lie')]



========================================== PARAGRAPH 1118 ===========================================

collecting, integrating, and storing data with minimal requirements (hardware and software). Big  

------------------- Sentence 1 -------------------

collecting, integrating, and storing data with minimal requirements (hardware and software).

>> Tokens are: 
 ['collecting', ',', 'integrating', ',', 'storing', 'data', 'minimal', 'requirements', '(', 'hardware', 'software', ')', '.']

>> Bigrams are: 
 [('collecting', ','), (',', 'integrating'), ('integrating', ','), (',', 'storing'), ('storing', 'data'), ('data', 'minimal'), ('minimal', 'requirements'), ('requirements', '('), ('(', 'hardware'), ('hardware', 'software'), ('software', ')'), (')', '.')]

>> Trigrams are: 
 [('collecting', ',', 'integrating'), (',', 'integrating', ','), ('integrating', ',', 'storing'), (',', 'storing', 'data'), ('storing', 'data', 'minimal'), ('data', 'minimal', 'requirements'), ('minimal', 'requirements', '('), ('requirements', '(', 'hardware'), ('(', 'hardware', 'software'), ('hardware', 'software', ')'), ('software', ')', '.')]

>> POS Tags are: 
 [('collecting', 'NN'), (',', ','), ('integrating', 'NN'), (',', ','), ('storing', 'VBG'), ('data', 'NNS'), ('minimal', 'JJ'), ('requirements', 'NNS'), ('(', '('), ('hardware', 'NN'), ('software', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['collecting', 'integrating', 'data', 'minimal requirements', 'hardware software']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('collecting', 'collect'), (',', ','), ('integrating', 'integr'), (',', ','), ('storing', 'store'), ('data', 'data'), ('minimal', 'minim'), ('requirements', 'requir'), ('(', '('), ('hardware', 'hardwar'), ('software', 'softwar'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('collecting', 'collect'), (',', ','), ('integrating', 'integr'), (',', ','), ('storing', 'store'), ('data', 'data'), ('minimal', 'minim'), ('requirements', 'requir'), ('(', '('), ('hardware', 'hardwar'), ('software', 'softwar'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('collecting', 'collecting'), (',', ','), ('integrating', 'integrating'), (',', ','), ('storing', 'storing'), ('data', 'data'), ('minimal', 'minimal'), ('requirements', 'requirement'), ('(', '('), ('hardware', 'hardware'), ('software', 'software'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Big

>> Tokens are: 
 ['Big']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big')]

>> Lemmatization: 
 [('Big', 'Big')]



========================================== PARAGRAPH 1119 ===========================================

data management also requires cleaning data for reliability then aggregating data from different  

------------------- Sentence 1 -------------------

data management also requires cleaning data for reliability then aggregating data from different

>> Tokens are: 
 ['data', 'management', 'also', 'requires', 'cleaning', 'data', 'reliability', 'aggregating', 'data', 'different']

>> Bigrams are: 
 [('data', 'management'), ('management', 'also'), ('also', 'requires'), ('requires', 'cleaning'), ('cleaning', 'data'), ('data', 'reliability'), ('reliability', 'aggregating'), ('aggregating', 'data'), ('data', 'different')]

>> Trigrams are: 
 [('data', 'management', 'also'), ('management', 'also', 'requires'), ('also', 'requires', 'cleaning'), ('requires', 'cleaning', 'data'), ('cleaning', 'data', 'reliability'), ('data', 'reliability', 'aggregating'), ('reliability', 'aggregating', 'data'), ('aggregating', 'data', 'different')]

>> POS Tags are: 
 [('data', 'NNS'), ('management', 'NN'), ('also', 'RB'), ('requires', 'VBZ'), ('cleaning', 'VBG'), ('data', 'NNS'), ('reliability', 'NN'), ('aggregating', 'VBG'), ('data', 'NNS'), ('different', 'JJ')]

>> Noun Phrases are: 
 ['data management', 'data reliability', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('management', 'manag'), ('also', 'also'), ('requires', 'requir'), ('cleaning', 'clean'), ('data', 'data'), ('reliability', 'reliabl'), ('aggregating', 'aggreg'), ('data', 'data'), ('different', 'differ')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('management', 'manag'), ('also', 'also'), ('requires', 'requir'), ('cleaning', 'clean'), ('data', 'data'), ('reliability', 'reliabl'), ('aggregating', 'aggreg'), ('data', 'data'), ('different', 'differ')]

>> Lemmatization: 
 [('data', 'data'), ('management', 'management'), ('also', 'also'), ('requires', 'requires'), ('cleaning', 'cleaning'), ('data', 'data'), ('reliability', 'reliability'), ('aggregating', 'aggregating'), ('data', 'data'), ('different', 'different')]



========================================== PARAGRAPH 1120 ===========================================

sources before encoding the data for security and privacy purposes (Chen et al., 2014; Najafabadi  

------------------- Sentence 1 -------------------

sources before encoding the data for security and privacy purposes (Chen et al., 2014; Najafabadi

>> Tokens are: 
 ['sources', 'encoding', 'data', 'security', 'privacy', 'purposes', '(', 'Chen', 'et', 'al.', ',', '2014', ';', 'Najafabadi']

>> Bigrams are: 
 [('sources', 'encoding'), ('encoding', 'data'), ('data', 'security'), ('security', 'privacy'), ('privacy', 'purposes'), ('purposes', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Najafabadi')]

>> Trigrams are: 
 [('sources', 'encoding', 'data'), ('encoding', 'data', 'security'), ('data', 'security', 'privacy'), ('security', 'privacy', 'purposes'), ('privacy', 'purposes', '('), ('purposes', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Najafabadi')]

>> POS Tags are: 
 [('sources', 'NNS'), ('encoding', 'VBG'), ('data', 'NNS'), ('security', 'NN'), ('privacy', 'NN'), ('purposes', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (';', ':'), ('Najafabadi', 'NNP')]

>> Noun Phrases are: 
 ['sources', 'data security privacy purposes', 'Chen', 'Najafabadi']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('sources', 'sourc'), ('encoding', 'encod'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('purposes', 'purpos'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'najafabadi')]

>> Stemming using Snowball Stemmer: 
 [('sources', 'sourc'), ('encoding', 'encod'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('purposes', 'purpos'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'najafabadi')]

>> Lemmatization: 
 [('sources', 'source'), ('encoding', 'encoding'), ('data', 'data'), ('security', 'security'), ('privacy', 'privacy'), ('purposes', 'purpose'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'Najafabadi')]



========================================== PARAGRAPH 1121 ===========================================

et al., 2015).  

------------------- Sentence 1 -------------------

et al., 2015).

>> Tokens are: 
 ['et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1122 ===========================================

Big data cleaning challenge lies in the data’s complexity: velocity, volume, and variety (Khan et  

------------------- Sentence 1 -------------------

Big data cleaning challenge lies in the data’s complexity: velocity, volume, and variety (Khan et

>> Tokens are: 
 ['Big', 'data', 'cleaning', 'challenge', 'lies', 'data', '’', 'complexity', ':', 'velocity', ',', 'volume', ',', 'variety', '(', 'Khan', 'et']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'cleaning'), ('cleaning', 'challenge'), ('challenge', 'lies'), ('lies', 'data'), ('data', '’'), ('’', 'complexity'), ('complexity', ':'), (':', 'velocity'), ('velocity', ','), (',', 'volume'), ('volume', ','), (',', 'variety'), ('variety', '('), ('(', 'Khan'), ('Khan', 'et')]

>> Trigrams are: 
 [('Big', 'data', 'cleaning'), ('data', 'cleaning', 'challenge'), ('cleaning', 'challenge', 'lies'), ('challenge', 'lies', 'data'), ('lies', 'data', '’'), ('data', '’', 'complexity'), ('’', 'complexity', ':'), ('complexity', ':', 'velocity'), (':', 'velocity', ','), ('velocity', ',', 'volume'), (',', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', '('), ('variety', '(', 'Khan'), ('(', 'Khan', 'et')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('cleaning', 'NN'), ('challenge', 'NN'), ('lies', 'VBZ'), ('data', 'NNS'), ('’', 'JJ'), ('complexity', 'NN'), (':', ':'), ('velocity', 'NN'), (',', ','), ('volume', 'NN'), (',', ','), ('variety', 'NN'), ('(', '('), ('Khan', 'NNP'), ('et', 'VBP')]

>> Noun Phrases are: 
 ['Big data cleaning challenge', 'data', '’ complexity', 'velocity', 'volume', 'variety', 'Khan']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('cleaning', 'clean'), ('challenge', 'challeng'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complex'), (':', ':'), ('velocity', 'veloc'), (',', ','), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), ('(', '('), ('Khan', 'khan'), ('et', 'et')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('cleaning', 'clean'), ('challenge', 'challeng'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complex'), (':', ':'), ('velocity', 'veloc'), (',', ','), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), ('(', '('), ('Khan', 'khan'), ('et', 'et')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('cleaning', 'cleaning'), ('challenge', 'challenge'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complexity'), (':', ':'), ('velocity', 'velocity'), (',', ','), ('volume', 'volume'), (',', ','), ('variety', 'variety'), ('(', '('), ('Khan', 'Khan'), ('et', 'et')]



========================================== PARAGRAPH 1123 ===========================================

al., 2014). Big data aggregation challenges are involved synchronising outside data sources and 

------------------- Sentence 1 -------------------

al., 2014).

>> Tokens are: 
 ['al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data aggregation challenges are involved synchronising outside data sources and

>> Tokens are: 
 ['Big', 'data', 'aggregation', 'challenges', 'involved', 'synchronising', 'outside', 'data', 'sources']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'aggregation'), ('aggregation', 'challenges'), ('challenges', 'involved'), ('involved', 'synchronising'), ('synchronising', 'outside'), ('outside', 'data'), ('data', 'sources')]

>> Trigrams are: 
 [('Big', 'data', 'aggregation'), ('data', 'aggregation', 'challenges'), ('aggregation', 'challenges', 'involved'), ('challenges', 'involved', 'synchronising'), ('involved', 'synchronising', 'outside'), ('synchronising', 'outside', 'data'), ('outside', 'data', 'sources')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('aggregation', 'NN'), ('challenges', 'NNS'), ('involved', 'VBN'), ('synchronising', 'VBG'), ('outside', 'JJ'), ('data', 'NNS'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['Big data aggregation challenges', 'outside data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('aggregation', 'aggreg'), ('challenges', 'challeng'), ('involved', 'involv'), ('synchronising', 'synchronis'), ('outside', 'outsid'), ('data', 'data'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('aggregation', 'aggreg'), ('challenges', 'challeng'), ('involved', 'involv'), ('synchronising', 'synchronis'), ('outside', 'outsid'), ('data', 'data'), ('sources', 'sourc')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('aggregation', 'aggregation'), ('challenges', 'challenge'), ('involved', 'involved'), ('synchronising', 'synchronising'), ('outside', 'outside'), ('data', 'data'), ('sources', 'source')]



========================================== PARAGRAPH 1124 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1125 ===========================================

40  

------------------- Sentence 1 -------------------

40

>> Tokens are: 
 ['40']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('40', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('40', '40')]

>> Stemming using Snowball Stemmer: 
 [('40', '40')]

>> Lemmatization: 
 [('40', '40')]



========================================== PARAGRAPH 1126 ===========================================

  


========================================== PARAGRAPH 1127 ===========================================

distributed big data platforms (including applications, repositories, sensors, networks, etc.) into a  

------------------- Sentence 1 -------------------

distributed big data platforms (including applications, repositories, sensors, networks, etc.)

>> Tokens are: 
 ['distributed', 'big', 'data', 'platforms', '(', 'including', 'applications', ',', 'repositories', ',', 'sensors', ',', 'networks', ',', 'etc', '.', ')']

>> Bigrams are: 
 [('distributed', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', '('), ('(', 'including'), ('including', 'applications'), ('applications', ','), (',', 'repositories'), ('repositories', ','), (',', 'sensors'), ('sensors', ','), (',', 'networks'), ('networks', ','), (',', 'etc'), ('etc', '.'), ('.', ')')]

>> Trigrams are: 
 [('distributed', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', '('), ('platforms', '(', 'including'), ('(', 'including', 'applications'), ('including', 'applications', ','), ('applications', ',', 'repositories'), (',', 'repositories', ','), ('repositories', ',', 'sensors'), (',', 'sensors', ','), ('sensors', ',', 'networks'), (',', 'networks', ','), ('networks', ',', 'etc'), (',', 'etc', '.'), ('etc', '.', ')')]

>> POS Tags are: 
 [('distributed', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('(', '('), ('including', 'VBG'), ('applications', 'NNS'), (',', ','), ('repositories', 'NNS'), (',', ','), ('sensors', 'NNS'), (',', ','), ('networks', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')]

>> Noun Phrases are: 
 ['big data platforms', 'applications', 'repositories', 'sensors', 'networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'includ'), ('applications', 'applic'), (',', ','), ('repositories', 'repositori'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'includ'), ('applications', 'applic'), (',', ','), ('repositories', 'repositori'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('distributed', 'distributed'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'including'), ('applications', 'application'), (',', ','), ('repositories', 'repository'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]


------------------- Sentence 2 -------------------

into a

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 1128 ===========================================

cohesive system (Oussous et al., 2018). Also, in imbalanced system capacities, the challenge lies  

------------------- Sentence 1 -------------------

cohesive system (Oussous et al., 2018).

>> Tokens are: 
 ['cohesive', 'system', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('cohesive', 'system'), ('system', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('cohesive', 'system', '('), ('system', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('cohesive', 'JJ'), ('system', 'NN'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['cohesive system', 'Oussous et al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('cohesive', 'cohes'), ('system', 'system'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cohesive', 'cohes'), ('system', 'system'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('cohesive', 'cohesive'), ('system', 'system'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Also, in imbalanced system capacities, the challenge lies

>> Tokens are: 
 ['Also', ',', 'imbalanced', 'system', 'capacities', ',', 'challenge', 'lies']

>> Bigrams are: 
 [('Also', ','), (',', 'imbalanced'), ('imbalanced', 'system'), ('system', 'capacities'), ('capacities', ','), (',', 'challenge'), ('challenge', 'lies')]

>> Trigrams are: 
 [('Also', ',', 'imbalanced'), (',', 'imbalanced', 'system'), ('imbalanced', 'system', 'capacities'), ('system', 'capacities', ','), ('capacities', ',', 'challenge'), (',', 'challenge', 'lies')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('imbalanced', 'JJ'), ('system', 'NN'), ('capacities', 'NNS'), (',', ','), ('challenge', 'NN'), ('lies', 'NNS')]

>> Noun Phrases are: 
 ['imbalanced system capacities', 'challenge lies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), (',', ','), ('challenge', 'challeng'), ('lies', 'lie')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), (',', ','), ('challenge', 'challeng'), ('lies', 'lie')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('imbalanced', 'imbalanced'), ('system', 'system'), ('capacities', 'capacity'), (',', ','), ('challenge', 'challenge'), ('lies', 'lie')]



========================================== PARAGRAPH 1129 ===========================================

in the computer architecture and capacity, as imbalanced system capacities might affect big data  

------------------- Sentence 1 -------------------

in the computer architecture and capacity, as imbalanced system capacities might affect big data

>> Tokens are: 
 ['computer', 'architecture', 'capacity', ',', 'imbalanced', 'system', 'capacities', 'might', 'affect', 'big', 'data']

>> Bigrams are: 
 [('computer', 'architecture'), ('architecture', 'capacity'), ('capacity', ','), (',', 'imbalanced'), ('imbalanced', 'system'), ('system', 'capacities'), ('capacities', 'might'), ('might', 'affect'), ('affect', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('computer', 'architecture', 'capacity'), ('architecture', 'capacity', ','), ('capacity', ',', 'imbalanced'), (',', 'imbalanced', 'system'), ('imbalanced', 'system', 'capacities'), ('system', 'capacities', 'might'), ('capacities', 'might', 'affect'), ('might', 'affect', 'big'), ('affect', 'big', 'data')]

>> POS Tags are: 
 [('computer', 'NN'), ('architecture', 'NN'), ('capacity', 'NN'), (',', ','), ('imbalanced', 'JJ'), ('system', 'NN'), ('capacities', 'NNS'), ('might', 'MD'), ('affect', 'VB'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['computer architecture capacity', 'imbalanced system capacities', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computer', 'comput'), ('architecture', 'architectur'), ('capacity', 'capac'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('computer', 'comput'), ('architecture', 'architectur'), ('capacity', 'capac'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('computer', 'computer'), ('architecture', 'architecture'), ('capacity', 'capacity'), (',', ','), ('imbalanced', 'imbalanced'), ('system', 'system'), ('capacities', 'capacity'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1130 ===========================================

application performance (Chen et al. 2014).  

------------------- Sentence 1 -------------------

application performance (Chen et al.

>> Tokens are: 
 ['application', 'performance', '(', 'Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('application', 'performance'), ('performance', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('application', 'performance', '('), ('performance', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('application', 'NN'), ('performance', 'NN'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['application performance', 'Chen', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('application', 'applic'), ('performance', 'perform'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('application', 'applic'), ('performance', 'perform'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('application', 'application'), ('performance', 'performance'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

2014).

>> Tokens are: 
 ['2014', ')', '.']

>> Bigrams are: 
 [('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1131 ===========================================

Furthermore, the challenge in imbalanced big data is how to classify imbalanced datasets, as  

------------------- Sentence 1 -------------------

Furthermore, the challenge in imbalanced big data is how to classify imbalanced datasets, as

>> Tokens are: 
 ['Furthermore', ',', 'challenge', 'imbalanced', 'big', 'data', 'classify', 'imbalanced', 'datasets', ',']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'challenge'), ('challenge', 'imbalanced'), ('imbalanced', 'big'), ('big', 'data'), ('data', 'classify'), ('classify', 'imbalanced'), ('imbalanced', 'datasets'), ('datasets', ',')]

>> Trigrams are: 
 [('Furthermore', ',', 'challenge'), (',', 'challenge', 'imbalanced'), ('challenge', 'imbalanced', 'big'), ('imbalanced', 'big', 'data'), ('big', 'data', 'classify'), ('data', 'classify', 'imbalanced'), ('classify', 'imbalanced', 'datasets'), ('imbalanced', 'datasets', ',')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('challenge', 'NN'), ('imbalanced', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('classify', 'NN'), ('imbalanced', 'JJ'), ('datasets', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['challenge', 'big data classify', 'imbalanced datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('challenge', 'challeng'), ('imbalanced', 'imbalanc'), ('big', 'big'), ('data', 'data'), ('classify', 'classifi'), ('imbalanced', 'imbalanc'), ('datasets', 'dataset'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('challenge', 'challeng'), ('imbalanced', 'imbalanc'), ('big', 'big'), ('data', 'data'), ('classify', 'classifi'), ('imbalanced', 'imbalanc'), ('datasets', 'dataset'), (',', ',')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('challenge', 'challenge'), ('imbalanced', 'imbalanced'), ('big', 'big'), ('data', 'data'), ('classify', 'classify'), ('imbalanced', 'imbalanced'), ('datasets', 'datasets'), (',', ',')]



========================================== PARAGRAPH 1132 ===========================================

“classical learning techniques are not adapted to imbalanced data sets” (Oussous et al., 2018). Big  

------------------- Sentence 1 -------------------

“classical learning techniques are not adapted to imbalanced data sets” (Oussous et al., 2018).

>> Tokens are: 
 ['“', 'classical', 'learning', 'techniques', 'adapted', 'imbalanced', 'data', 'sets', '”', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('“', 'classical'), ('classical', 'learning'), ('learning', 'techniques'), ('techniques', 'adapted'), ('adapted', 'imbalanced'), ('imbalanced', 'data'), ('data', 'sets'), ('sets', '”'), ('”', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('“', 'classical', 'learning'), ('classical', 'learning', 'techniques'), ('learning', 'techniques', 'adapted'), ('techniques', 'adapted', 'imbalanced'), ('adapted', 'imbalanced', 'data'), ('imbalanced', 'data', 'sets'), ('data', 'sets', '”'), ('sets', '”', '('), ('”', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('“', 'JJ'), ('classical', 'JJ'), ('learning', 'NN'), ('techniques', 'NNS'), ('adapted', 'VBN'), ('imbalanced', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('”', 'NNP'), ('(', '('), ('Oussous', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['“ classical learning techniques', 'imbalanced data sets ”', 'Oussous']

>> Named Entities are: 
 [('PERSON', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('classical', 'classic'), ('learning', 'learn'), ('techniques', 'techniqu'), ('adapted', 'adapt'), ('imbalanced', 'imbalanc'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('classical', 'classic'), ('learning', 'learn'), ('techniques', 'techniqu'), ('adapted', 'adapt'), ('imbalanced', 'imbalanc'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('classical', 'classical'), ('learning', 'learning'), ('techniques', 'technique'), ('adapted', 'adapted'), ('imbalanced', 'imbalanced'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Big

>> Tokens are: 
 ['Big']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big')]

>> Lemmatization: 
 [('Big', 'Big')]



========================================== PARAGRAPH 1133 ===========================================

data analytics challenges lie in the complex data analysis required to understand the relationships  

------------------- Sentence 1 -------------------

data analytics challenges lie in the complex data analysis required to understand the relationships

>> Tokens are: 
 ['data', 'analytics', 'challenges', 'lie', 'complex', 'data', 'analysis', 'required', 'understand', 'relationships']

>> Bigrams are: 
 [('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'lie'), ('lie', 'complex'), ('complex', 'data'), ('data', 'analysis'), ('analysis', 'required'), ('required', 'understand'), ('understand', 'relationships')]

>> Trigrams are: 
 [('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'lie'), ('challenges', 'lie', 'complex'), ('lie', 'complex', 'data'), ('complex', 'data', 'analysis'), ('data', 'analysis', 'required'), ('analysis', 'required', 'understand'), ('required', 'understand', 'relationships')]

>> POS Tags are: 
 [('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('lie', 'VBP'), ('complex', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('required', 'VBN'), ('understand', 'JJ'), ('relationships', 'NNS')]

>> Noun Phrases are: 
 ['data analytics challenges', 'complex data analysis', 'understand relationships']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysi'), ('required', 'requir'), ('understand', 'understand'), ('relationships', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysi'), ('required', 'requir'), ('understand', 'understand'), ('relationships', 'relationship')]

>> Lemmatization: 
 [('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysis'), ('required', 'required'), ('understand', 'understand'), ('relationships', 'relationship')]



========================================== PARAGRAPH 1134 ===========================================

among data features. Some data analysis requires real-time analysis, such as navigation, social  

------------------- Sentence 1 -------------------

among data features.

>> Tokens are: 
 ['among', 'data', 'features', '.']

>> Bigrams are: 
 [('among', 'data'), ('data', 'features'), ('features', '.')]

>> Trigrams are: 
 [('among', 'data', 'features'), ('data', 'features', '.')]

>> POS Tags are: 
 [('among', 'IN'), ('data', 'NNS'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('among', 'among'), ('data', 'data'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('among', 'among'), ('data', 'data'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('among', 'among'), ('data', 'data'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

Some data analysis requires real-time analysis, such as navigation, social

>> Tokens are: 
 ['Some', 'data', 'analysis', 'requires', 'real-time', 'analysis', ',', 'navigation', ',', 'social']

>> Bigrams are: 
 [('Some', 'data'), ('data', 'analysis'), ('analysis', 'requires'), ('requires', 'real-time'), ('real-time', 'analysis'), ('analysis', ','), (',', 'navigation'), ('navigation', ','), (',', 'social')]

>> Trigrams are: 
 [('Some', 'data', 'analysis'), ('data', 'analysis', 'requires'), ('analysis', 'requires', 'real-time'), ('requires', 'real-time', 'analysis'), ('real-time', 'analysis', ','), ('analysis', ',', 'navigation'), (',', 'navigation', ','), ('navigation', ',', 'social')]

>> POS Tags are: 
 [('Some', 'DT'), ('data', 'NNS'), ('analysis', 'NN'), ('requires', 'VBZ'), ('real-time', 'JJ'), ('analysis', 'NN'), (',', ','), ('navigation', 'NN'), (',', ','), ('social', 'JJ')]

>> Noun Phrases are: 
 ['Some data analysis', 'real-time analysis', 'navigation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('data', 'data'), ('analysis', 'analysi'), ('requires', 'requir'), ('real-time', 'real-tim'), ('analysis', 'analysi'), (',', ','), ('navigation', 'navig'), (',', ','), ('social', 'social')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('data', 'data'), ('analysis', 'analysi'), ('requires', 'requir'), ('real-time', 'real-tim'), ('analysis', 'analysi'), (',', ','), ('navigation', 'navig'), (',', ','), ('social', 'social')]

>> Lemmatization: 
 [('Some', 'Some'), ('data', 'data'), ('analysis', 'analysis'), ('requires', 'requires'), ('real-time', 'real-time'), ('analysis', 'analysis'), (',', ','), ('navigation', 'navigation'), (',', ','), ('social', 'social')]



========================================== PARAGRAPH 1135 ===========================================

networks, finance, biomedicine, astronomy, and intelligent transport systems, while other analyses  

------------------- Sentence 1 -------------------

networks, finance, biomedicine, astronomy, and intelligent transport systems, while other analyses

>> Tokens are: 
 ['networks', ',', 'finance', ',', 'biomedicine', ',', 'astronomy', ',', 'intelligent', 'transport', 'systems', ',', 'analyses']

>> Bigrams are: 
 [('networks', ','), (',', 'finance'), ('finance', ','), (',', 'biomedicine'), ('biomedicine', ','), (',', 'astronomy'), ('astronomy', ','), (',', 'intelligent'), ('intelligent', 'transport'), ('transport', 'systems'), ('systems', ','), (',', 'analyses')]

>> Trigrams are: 
 [('networks', ',', 'finance'), (',', 'finance', ','), ('finance', ',', 'biomedicine'), (',', 'biomedicine', ','), ('biomedicine', ',', 'astronomy'), (',', 'astronomy', ','), ('astronomy', ',', 'intelligent'), (',', 'intelligent', 'transport'), ('intelligent', 'transport', 'systems'), ('transport', 'systems', ','), ('systems', ',', 'analyses')]

>> POS Tags are: 
 [('networks', 'NNS'), (',', ','), ('finance', 'NN'), (',', ','), ('biomedicine', 'NN'), (',', ','), ('astronomy', 'NN'), (',', ','), ('intelligent', 'JJ'), ('transport', 'NN'), ('systems', 'NNS'), (',', ','), ('analyses', 'NNS')]

>> Noun Phrases are: 
 ['networks', 'finance', 'biomedicine', 'astronomy', 'intelligent transport systems', 'analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('networks', 'network'), (',', ','), ('finance', 'financ'), (',', ','), ('biomedicine', 'biomedicin'), (',', ','), ('astronomy', 'astronomi'), (',', ','), ('intelligent', 'intellig'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analys')]

>> Stemming using Snowball Stemmer: 
 [('networks', 'network'), (',', ','), ('finance', 'financ'), (',', ','), ('biomedicine', 'biomedicin'), (',', ','), ('astronomy', 'astronomi'), (',', ','), ('intelligent', 'intellig'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analys')]

>> Lemmatization: 
 [('networks', 'network'), (',', ','), ('finance', 'finance'), (',', ','), ('biomedicine', 'biomedicine'), (',', ','), ('astronomy', 'astronomy'), (',', ','), ('intelligent', 'intelligent'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analysis')]



========================================== PARAGRAPH 1136 ===========================================

require accurate result but not necessarily the same levels of speed. The challenge with big data  

------------------- Sentence 1 -------------------

require accurate result but not necessarily the same levels of speed.

>> Tokens are: 
 ['require', 'accurate', 'result', 'necessarily', 'levels', 'speed', '.']

>> Bigrams are: 
 [('require', 'accurate'), ('accurate', 'result'), ('result', 'necessarily'), ('necessarily', 'levels'), ('levels', 'speed'), ('speed', '.')]

>> Trigrams are: 
 [('require', 'accurate', 'result'), ('accurate', 'result', 'necessarily'), ('result', 'necessarily', 'levels'), ('necessarily', 'levels', 'speed'), ('levels', 'speed', '.')]

>> POS Tags are: 
 [('require', 'NN'), ('accurate', 'NN'), ('result', 'NN'), ('necessarily', 'RB'), ('levels', 'NNS'), ('speed', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['require accurate result', 'levels speed']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('require', 'requir'), ('accurate', 'accur'), ('result', 'result'), ('necessarily', 'necessarili'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('require', 'requir'), ('accurate', 'accur'), ('result', 'result'), ('necessarily', 'necessarili'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]

>> Lemmatization: 
 [('require', 'require'), ('accurate', 'accurate'), ('result', 'result'), ('necessarily', 'necessarily'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]


------------------- Sentence 2 -------------------

The challenge with big data

>> Tokens are: 
 ['The', 'challenge', 'big', 'data']

>> Bigrams are: 
 [('The', 'challenge'), ('challenge', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'challenge', 'big'), ('challenge', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('challenge', 'NN'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The challenge', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('challenge', 'challenge'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1137 ===========================================

analysis mainly arises due to the 5V’s and their effects on dataset performance (Qiu et al., 2016).  

------------------- Sentence 1 -------------------

analysis mainly arises due to the 5V’s and their effects on dataset performance (Qiu et al., 2016).

>> Tokens are: 
 ['analysis', 'mainly', 'arises', 'due', '5V', '’', 'effects', 'dataset', 'performance', '(', 'Qiu', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('analysis', 'mainly'), ('mainly', 'arises'), ('arises', 'due'), ('due', '5V'), ('5V', '’'), ('’', 'effects'), ('effects', 'dataset'), ('dataset', 'performance'), ('performance', '('), ('(', 'Qiu'), ('Qiu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('analysis', 'mainly', 'arises'), ('mainly', 'arises', 'due'), ('arises', 'due', '5V'), ('due', '5V', '’'), ('5V', '’', 'effects'), ('’', 'effects', 'dataset'), ('effects', 'dataset', 'performance'), ('dataset', 'performance', '('), ('performance', '(', 'Qiu'), ('(', 'Qiu', 'et'), ('Qiu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('analysis', 'NN'), ('mainly', 'RB'), ('arises', 'VBZ'), ('due', 'JJ'), ('5V', 'CD'), ('’', 'JJ'), ('effects', 'NNS'), ('dataset', 'VBN'), ('performance', 'NN'), ('(', '('), ('Qiu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis', '’ effects', 'performance', 'Qiu']

>> Named Entities are: 
 [('ORGANIZATION', 'Qiu')] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('mainly', 'mainli'), ('arises', 'aris'), ('due', 'due'), ('5V', '5v'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'perform'), ('(', '('), ('Qiu', 'qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('mainly', 'main'), ('arises', 'aris'), ('due', 'due'), ('5V', '5v'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'perform'), ('(', '('), ('Qiu', 'qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('mainly', 'mainly'), ('arises', 'arises'), ('due', 'due'), ('5V', '5V'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'performance'), ('(', '('), ('Qiu', 'Qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1138 ===========================================

One solution for the storage challenge is using Hadoop (Apache platform), which is an open-source  

------------------- Sentence 1 -------------------

One solution for the storage challenge is using Hadoop (Apache platform), which is an open-source

>> Tokens are: 
 ['One', 'solution', 'storage', 'challenge', 'using', 'Hadoop', '(', 'Apache', 'platform', ')', ',', 'open-source']

>> Bigrams are: 
 [('One', 'solution'), ('solution', 'storage'), ('storage', 'challenge'), ('challenge', 'using'), ('using', 'Hadoop'), ('Hadoop', '('), ('(', 'Apache'), ('Apache', 'platform'), ('platform', ')'), (')', ','), (',', 'open-source')]

>> Trigrams are: 
 [('One', 'solution', 'storage'), ('solution', 'storage', 'challenge'), ('storage', 'challenge', 'using'), ('challenge', 'using', 'Hadoop'), ('using', 'Hadoop', '('), ('Hadoop', '(', 'Apache'), ('(', 'Apache', 'platform'), ('Apache', 'platform', ')'), ('platform', ')', ','), (')', ',', 'open-source')]

>> POS Tags are: 
 [('One', 'CD'), ('solution', 'NN'), ('storage', 'NN'), ('challenge', 'NN'), ('using', 'VBG'), ('Hadoop', 'NNP'), ('(', '('), ('Apache', 'NNP'), ('platform', 'NN'), (')', ')'), (',', ','), ('open-source', 'JJ')]

>> Noun Phrases are: 
 ['solution storage challenge', 'Hadoop', 'Apache platform']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'Apache')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('using', 'use'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-sourc')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('using', 'use'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-sourc')]

>> Lemmatization: 
 [('One', 'One'), ('solution', 'solution'), ('storage', 'storage'), ('challenge', 'challenge'), ('using', 'using'), ('Hadoop', 'Hadoop'), ('(', '('), ('Apache', 'Apache'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-source')]



========================================== PARAGRAPH 1139 ===========================================

distributed data processing platform with the power to process extremely large amounts of data. It  

------------------- Sentence 1 -------------------

distributed data processing platform with the power to process extremely large amounts of data.

>> Tokens are: 
 ['distributed', 'data', 'processing', 'platform', 'power', 'process', 'extremely', 'large', 'amounts', 'data', '.']

>> Bigrams are: 
 [('distributed', 'data'), ('data', 'processing'), ('processing', 'platform'), ('platform', 'power'), ('power', 'process'), ('process', 'extremely'), ('extremely', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', '.')]

>> Trigrams are: 
 [('distributed', 'data', 'processing'), ('data', 'processing', 'platform'), ('processing', 'platform', 'power'), ('platform', 'power', 'process'), ('power', 'process', 'extremely'), ('process', 'extremely', 'large'), ('extremely', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', '.')]

>> POS Tags are: 
 [('distributed', 'VBN'), ('data', 'NNS'), ('processing', 'VBG'), ('platform', 'NN'), ('power', 'NN'), ('process', 'NN'), ('extremely', 'RB'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'platform power process', 'large amounts data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('distributed', 'distribut'), ('data', 'data'), ('processing', 'process'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('distributed', 'distribut'), ('data', 'data'), ('processing', 'process'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('distributed', 'distributed'), ('data', 'data'), ('processing', 'processing'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extremely'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

It

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 1140 ===========================================

does this by dividing the data into smaller parts then specifying some parts of the datasets to  

------------------- Sentence 1 -------------------

does this by dividing the data into smaller parts then specifying some parts of the datasets to

>> Tokens are: 
 ['dividing', 'data', 'smaller', 'parts', 'specifying', 'parts', 'datasets']

>> Bigrams are: 
 [('dividing', 'data'), ('data', 'smaller'), ('smaller', 'parts'), ('parts', 'specifying'), ('specifying', 'parts'), ('parts', 'datasets')]

>> Trigrams are: 
 [('dividing', 'data', 'smaller'), ('data', 'smaller', 'parts'), ('smaller', 'parts', 'specifying'), ('parts', 'specifying', 'parts'), ('specifying', 'parts', 'datasets')]

>> POS Tags are: 
 [('dividing', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('parts', 'NNS'), ('specifying', 'VBG'), ('parts', 'NNS'), ('datasets', 'NNS')]

>> Noun Phrases are: 
 ['data', 'parts', 'parts datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifi'), ('parts', 'part'), ('datasets', 'dataset')]

>> Stemming using Snowball Stemmer: 
 [('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifi'), ('parts', 'part'), ('datasets', 'dataset')]

>> Lemmatization: 
 [('dividing', 'dividing'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifying'), ('parts', 'part'), ('datasets', 'datasets')]



========================================== PARAGRAPH 1141 ===========================================

separate servers (nodes) (Raghupathi, W. and Raghupathi, V., 2014)  

------------------- Sentence 1 -------------------

separate servers (nodes) (Raghupathi, W. and Raghupathi, V., 2014)

>> Tokens are: 
 ['separate', 'servers', '(', 'nodes', ')', '(', 'Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', ')']

>> Bigrams are: 
 [('separate', 'servers'), ('servers', '('), ('(', 'nodes'), ('nodes', ')'), (')', '('), ('(', 'Raghupathi'), ('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', ')')]

>> Trigrams are: 
 [('separate', 'servers', '('), ('servers', '(', 'nodes'), ('(', 'nodes', ')'), ('nodes', ')', '('), (')', '(', 'Raghupathi'), ('(', 'Raghupathi', ','), ('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', ')')]

>> POS Tags are: 
 [('separate', 'JJ'), ('servers', 'NNS'), ('(', '('), ('nodes', 'NNS'), (')', ')'), ('(', '('), ('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['separate servers', 'nodes', 'Raghupathi', 'W. Raghupathi', 'V.']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')')]

>> Lemmatization: 
 [('separate', 'separate'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), (')', ')')]



========================================== PARAGRAPH 1142 ===========================================

  


========================================== PARAGRAPH 1143 ===========================================

9.4. Challenges in data analysis and visualisation  

------------------- Sentence 1 -------------------

9.4.

>> Tokens are: 
 ['9.4', '.']

>> Bigrams are: 
 [('9.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.4', '9.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.4', '9.4'), ('.', '.')]

>> Lemmatization: 
 [('9.4', '9.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Challenges in data analysis and visualisation

>> Tokens are: 
 ['Challenges', 'data', 'analysis', 'visualisation']

>> Bigrams are: 
 [('Challenges', 'data'), ('data', 'analysis'), ('analysis', 'visualisation')]

>> Trigrams are: 
 [('Challenges', 'data', 'analysis'), ('data', 'analysis', 'visualisation')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('visualisation', 'NN')]

>> Noun Phrases are: 
 ['Challenges data analysis visualisation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('data', 'data'), ('analysis', 'analysis'), ('visualisation', 'visualisation')]



========================================== PARAGRAPH 1144 ===========================================

Data analysis challenges arise from data complexity, which in turn comes from the data’s complex  

------------------- Sentence 1 -------------------

Data analysis challenges arise from data complexity, which in turn comes from the data’s complex

>> Tokens are: 
 ['Data', 'analysis', 'challenges', 'arise', 'data', 'complexity', ',', 'turn', 'comes', 'data', '’', 'complex']

>> Bigrams are: 
 [('Data', 'analysis'), ('analysis', 'challenges'), ('challenges', 'arise'), ('arise', 'data'), ('data', 'complexity'), ('complexity', ','), (',', 'turn'), ('turn', 'comes'), ('comes', 'data'), ('data', '’'), ('’', 'complex')]

>> Trigrams are: 
 [('Data', 'analysis', 'challenges'), ('analysis', 'challenges', 'arise'), ('challenges', 'arise', 'data'), ('arise', 'data', 'complexity'), ('data', 'complexity', ','), ('complexity', ',', 'turn'), (',', 'turn', 'comes'), ('turn', 'comes', 'data'), ('comes', 'data', '’'), ('data', '’', 'complex')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analysis', 'NN'), ('challenges', 'NNS'), ('arise', 'VBP'), ('data', 'NN'), ('complexity', 'NN'), (',', ','), ('turn', 'VBP'), ('comes', 'VBZ'), ('data', 'NNS'), ('’', 'NN'), ('complex', 'NN')]

>> Noun Phrases are: 
 ['Data analysis challenges', 'data complexity', 'data ’ complex']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('challenges', 'challeng'), ('arise', 'aris'), ('data', 'data'), ('complexity', 'complex'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('challenges', 'challeng'), ('arise', 'aris'), ('data', 'data'), ('complexity', 'complex'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex')]

>> Lemmatization: 
 [('Data', 'Data'), ('analysis', 'analysis'), ('challenges', 'challenge'), ('arise', 'arise'), ('data', 'data'), ('complexity', 'complexity'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex')]



========================================== PARAGRAPH 1145 ===========================================

types and structures. Standard data analysis techniques face difficulties in handling such big data  

------------------- Sentence 1 -------------------

types and structures.

>> Tokens are: 
 ['types', 'structures', '.']

>> Bigrams are: 
 [('types', 'structures'), ('structures', '.')]

>> Trigrams are: 
 [('types', 'structures', '.')]

>> POS Tags are: 
 [('types', 'NNS'), ('structures', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['types structures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('types', 'type'), ('structures', 'structur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('types', 'type'), ('structures', 'structur'), ('.', '.')]

>> Lemmatization: 
 [('types', 'type'), ('structures', 'structure'), ('.', '.')]


------------------- Sentence 2 -------------------

Standard data analysis techniques face difficulties in handling such big data

>> Tokens are: 
 ['Standard', 'data', 'analysis', 'techniques', 'face', 'difficulties', 'handling', 'big', 'data']

>> Bigrams are: 
 [('Standard', 'data'), ('data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'face'), ('face', 'difficulties'), ('difficulties', 'handling'), ('handling', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Standard', 'data', 'analysis'), ('data', 'analysis', 'techniques'), ('analysis', 'techniques', 'face'), ('techniques', 'face', 'difficulties'), ('face', 'difficulties', 'handling'), ('difficulties', 'handling', 'big'), ('handling', 'big', 'data')]

>> POS Tags are: 
 [('Standard', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('face', 'VBP'), ('difficulties', 'NNS'), ('handling', 'VBG'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Standard data analysis techniques', 'difficulties', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Standard', 'standard'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('face', 'face'), ('difficulties', 'difficulti'), ('handling', 'handl'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Standard', 'standard'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('face', 'face'), ('difficulties', 'difficulti'), ('handling', 'handl'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Standard', 'Standard'), ('data', 'data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('face', 'face'), ('difficulties', 'difficulty'), ('handling', 'handling'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1146 ===========================================

as it is more difficult to understand the distribution laws of big data (Wang et al., 2016).  

------------------- Sentence 1 -------------------

as it is more difficult to understand the distribution laws of big data (Wang et al., 2016).

>> Tokens are: 
 ['difficult', 'understand', 'distribution', 'laws', 'big', 'data', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('difficult', 'understand'), ('understand', 'distribution'), ('distribution', 'laws'), ('laws', 'big'), ('big', 'data'), ('data', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('difficult', 'understand', 'distribution'), ('understand', 'distribution', 'laws'), ('distribution', 'laws', 'big'), ('laws', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('difficult', 'JJ'), ('understand', 'JJ'), ('distribution', 'NN'), ('laws', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['difficult understand distribution laws', 'big data', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribut'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribut'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribution'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1147 ===========================================

Big data visualisation challenges come from the data’s high dimensions and size. The main goal  

------------------- Sentence 1 -------------------

Big data visualisation challenges come from the data’s high dimensions and size.

>> Tokens are: 
 ['Big', 'data', 'visualisation', 'challenges', 'come', 'data', '’', 'high', 'dimensions', 'size', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'visualisation'), ('visualisation', 'challenges'), ('challenges', 'come'), ('come', 'data'), ('data', '’'), ('’', 'high'), ('high', 'dimensions'), ('dimensions', 'size'), ('size', '.')]

>> Trigrams are: 
 [('Big', 'data', 'visualisation'), ('data', 'visualisation', 'challenges'), ('visualisation', 'challenges', 'come'), ('challenges', 'come', 'data'), ('come', 'data', '’'), ('data', '’', 'high'), ('’', 'high', 'dimensions'), ('high', 'dimensions', 'size'), ('dimensions', 'size', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('visualisation', 'NN'), ('challenges', 'VBZ'), ('come', 'VBN'), ('data', 'NNS'), ('’', 'RB'), ('high', 'JJ'), ('dimensions', 'NNS'), ('size', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data visualisation', 'data', 'high dimensions size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('visualisation', 'visualis'), ('challenges', 'challeng'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimens'), ('size', 'size'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('visualisation', 'visualis'), ('challenges', 'challeng'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimens'), ('size', 'size'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('visualisation', 'visualisation'), ('challenges', 'challenge'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimension'), ('size', 'size'), ('.', '.')]


------------------- Sentence 2 -------------------

The main goal

>> Tokens are: 
 ['The', 'main', 'goal']

>> Bigrams are: 
 [('The', 'main'), ('main', 'goal')]

>> Trigrams are: 
 [('The', 'main', 'goal')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('goal', 'NN')]

>> Noun Phrases are: 
 ['The main goal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('goal', 'goal')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('goal', 'goal')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('goal', 'goal')]



========================================== PARAGRAPH 1148 ===========================================

of data visualisation is to explain knowledge effectively by using diagrams; in order to transfer  

------------------- Sentence 1 -------------------

of data visualisation is to explain knowledge effectively by using diagrams; in order to transfer

>> Tokens are: 
 ['data', 'visualisation', 'explain', 'knowledge', 'effectively', 'using', 'diagrams', ';', 'order', 'transfer']

>> Bigrams are: 
 [('data', 'visualisation'), ('visualisation', 'explain'), ('explain', 'knowledge'), ('knowledge', 'effectively'), ('effectively', 'using'), ('using', 'diagrams'), ('diagrams', ';'), (';', 'order'), ('order', 'transfer')]

>> Trigrams are: 
 [('data', 'visualisation', 'explain'), ('visualisation', 'explain', 'knowledge'), ('explain', 'knowledge', 'effectively'), ('knowledge', 'effectively', 'using'), ('effectively', 'using', 'diagrams'), ('using', 'diagrams', ';'), ('diagrams', ';', 'order'), (';', 'order', 'transfer')]

>> POS Tags are: 
 [('data', 'NNS'), ('visualisation', 'NN'), ('explain', 'VBP'), ('knowledge', 'NN'), ('effectively', 'RB'), ('using', 'VBG'), ('diagrams', 'NNS'), (';', ':'), ('order', 'NN'), ('transfer', 'NN')]

>> Noun Phrases are: 
 ['data visualisation', 'knowledge', 'diagrams', 'order transfer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('visualisation', 'visualis'), ('explain', 'explain'), ('knowledge', 'knowledg'), ('effectively', 'effect'), ('using', 'use'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('visualisation', 'visualis'), ('explain', 'explain'), ('knowledge', 'knowledg'), ('effectively', 'effect'), ('using', 'use'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer')]

>> Lemmatization: 
 [('data', 'data'), ('visualisation', 'visualisation'), ('explain', 'explain'), ('knowledge', 'knowledge'), ('effectively', 'effectively'), ('using', 'using'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer')]



========================================== PARAGRAPH 1149 ===========================================

information easily to the user, hidden knowledge in the complex and large-scale data sets is  

------------------- Sentence 1 -------------------

information easily to the user, hidden knowledge in the complex and large-scale data sets is

>> Tokens are: 
 ['information', 'easily', 'user', ',', 'hidden', 'knowledge', 'complex', 'large-scale', 'data', 'sets']

>> Bigrams are: 
 [('information', 'easily'), ('easily', 'user'), ('user', ','), (',', 'hidden'), ('hidden', 'knowledge'), ('knowledge', 'complex'), ('complex', 'large-scale'), ('large-scale', 'data'), ('data', 'sets')]

>> Trigrams are: 
 [('information', 'easily', 'user'), ('easily', 'user', ','), ('user', ',', 'hidden'), (',', 'hidden', 'knowledge'), ('hidden', 'knowledge', 'complex'), ('knowledge', 'complex', 'large-scale'), ('complex', 'large-scale', 'data'), ('large-scale', 'data', 'sets')]

>> POS Tags are: 
 [('information', 'NN'), ('easily', 'RB'), ('user', 'RB'), (',', ','), ('hidden', 'JJ'), ('knowledge', 'NN'), ('complex', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('sets', 'NNS')]

>> Noun Phrases are: 
 ['information', 'hidden knowledge', 'complex large-scale data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('easily', 'easili'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('complex', 'complex'), ('large-scale', 'large-scal'), ('data', 'data'), ('sets', 'set')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('easily', 'easili'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('complex', 'complex'), ('large-scale', 'large-scal'), ('data', 'data'), ('sets', 'set')]

>> Lemmatization: 
 [('information', 'information'), ('easily', 'easily'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledge'), ('complex', 'complex'), ('large-scale', 'large-scale'), ('data', 'data'), ('sets', 'set')]



========================================== PARAGRAPH 1150 ===========================================

rendered visible. For more accurate data analysis, however, abstracting information in schematic  

------------------- Sentence 1 -------------------

rendered visible.

>> Tokens are: 
 ['rendered', 'visible', '.']

>> Bigrams are: 
 [('rendered', 'visible'), ('visible', '.')]

>> Trigrams are: 
 [('rendered', 'visible', '.')]

>> POS Tags are: 
 [('rendered', 'VBN'), ('visible', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rendered', 'render'), ('visible', 'visibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rendered', 'render'), ('visible', 'visibl'), ('.', '.')]

>> Lemmatization: 
 [('rendered', 'rendered'), ('visible', 'visible'), ('.', '.')]


------------------- Sentence 2 -------------------

For more accurate data analysis, however, abstracting information in schematic

>> Tokens are: 
 ['For', 'accurate', 'data', 'analysis', ',', 'however', ',', 'abstracting', 'information', 'schematic']

>> Bigrams are: 
 [('For', 'accurate'), ('accurate', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'however'), ('however', ','), (',', 'abstracting'), ('abstracting', 'information'), ('information', 'schematic')]

>> Trigrams are: 
 [('For', 'accurate', 'data'), ('accurate', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'however'), (',', 'however', ','), ('however', ',', 'abstracting'), (',', 'abstracting', 'information'), ('abstracting', 'information', 'schematic')]

>> POS Tags are: 
 [('For', 'IN'), ('accurate', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('abstracting', 'VBG'), ('information', 'NN'), ('schematic', 'NN')]

>> Noun Phrases are: 
 ['accurate data analysis', 'information schematic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('accurate', 'accur'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('however', 'howev'), (',', ','), ('abstracting', 'abstract'), ('information', 'inform'), ('schematic', 'schemat')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('accurate', 'accur'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('however', 'howev'), (',', ','), ('abstracting', 'abstract'), ('information', 'inform'), ('schematic', 'schemat')]

>> Lemmatization: 
 [('For', 'For'), ('accurate', 'accurate'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('however', 'however'), (',', ','), ('abstracting', 'abstracting'), ('information', 'information'), ('schematic', 'schematic')]



========================================== PARAGRAPH 1151 ===========================================

formats, including features or variables representing units of information is valuable. Nevertheless,  

------------------- Sentence 1 -------------------

formats, including features or variables representing units of information is valuable.

>> Tokens are: 
 ['formats', ',', 'including', 'features', 'variables', 'representing', 'units', 'information', 'valuable', '.']

>> Bigrams are: 
 [('formats', ','), (',', 'including'), ('including', 'features'), ('features', 'variables'), ('variables', 'representing'), ('representing', 'units'), ('units', 'information'), ('information', 'valuable'), ('valuable', '.')]

>> Trigrams are: 
 [('formats', ',', 'including'), (',', 'including', 'features'), ('including', 'features', 'variables'), ('features', 'variables', 'representing'), ('variables', 'representing', 'units'), ('representing', 'units', 'information'), ('units', 'information', 'valuable'), ('information', 'valuable', '.')]

>> POS Tags are: 
 [('formats', 'NNS'), (',', ','), ('including', 'VBG'), ('features', 'NNS'), ('variables', 'NNS'), ('representing', 'VBG'), ('units', 'NNS'), ('information', 'NN'), ('valuable', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['formats', 'features variables', 'units information valuable']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('formats', 'format'), (',', ','), ('including', 'includ'), ('features', 'featur'), ('variables', 'variabl'), ('representing', 'repres'), ('units', 'unit'), ('information', 'inform'), ('valuable', 'valuabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('formats', 'format'), (',', ','), ('including', 'includ'), ('features', 'featur'), ('variables', 'variabl'), ('representing', 'repres'), ('units', 'unit'), ('information', 'inform'), ('valuable', 'valuabl'), ('.', '.')]

>> Lemmatization: 
 [('formats', 'format'), (',', ','), ('including', 'including'), ('features', 'feature'), ('variables', 'variable'), ('representing', 'representing'), ('units', 'unit'), ('information', 'information'), ('valuable', 'valuable'), ('.', '.')]


------------------- Sentence 2 -------------------

Nevertheless,

>> Tokens are: 
 ['Nevertheless', ',']

>> Bigrams are: 
 [('Nevertheless', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Nevertheless', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ',')]

>> Lemmatization: 
 [('Nevertheless', 'Nevertheless'), (',', ',')]



========================================== PARAGRAPH 1152 ===========================================

because of the large size and high dimensions of big data, it can also be difficult to manage data  

------------------- Sentence 1 -------------------

because of the large size and high dimensions of big data, it can also be difficult to manage data

>> Tokens are: 
 ['large', 'size', 'high', 'dimensions', 'big', 'data', ',', 'also', 'difficult', 'manage', 'data']

>> Bigrams are: 
 [('large', 'size'), ('size', 'high'), ('high', 'dimensions'), ('dimensions', 'big'), ('big', 'data'), ('data', ','), (',', 'also'), ('also', 'difficult'), ('difficult', 'manage'), ('manage', 'data')]

>> Trigrams are: 
 [('large', 'size', 'high'), ('size', 'high', 'dimensions'), ('high', 'dimensions', 'big'), ('dimensions', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'also'), (',', 'also', 'difficult'), ('also', 'difficult', 'manage'), ('difficult', 'manage', 'data')]

>> POS Tags are: 
 [('large', 'JJ'), ('size', 'NN'), ('high', 'JJ'), ('dimensions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('also', 'RB'), ('difficult', 'JJ'), ('manage', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['large size', 'high dimensions', 'big data', 'difficult manage data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('large', 'larg'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimens'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manag'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('large', 'larg'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimens'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manag'), ('data', 'data')]

>> Lemmatization: 
 [('large', 'large'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimension'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manage'), ('data', 'data')]



========================================== PARAGRAPH 1153 ===========================================

visualisation in big data applications (Chen C.P et al., 2014; Wang et al., 2016).  

------------------- Sentence 1 -------------------

visualisation in big data applications (Chen C.P et al., 2014; Wang et al., 2016).

>> Tokens are: 
 ['visualisation', 'big', 'data', 'applications', '(', 'Chen', 'C.P', 'et', 'al.', ',', '2014', ';', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('visualisation', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', '('), ('(', 'Chen'), ('Chen', 'C.P'), ('C.P', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('visualisation', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', '('), ('applications', '(', 'Chen'), ('(', 'Chen', 'C.P'), ('Chen', 'C.P', 'et'), ('C.P', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Wang'), (';', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('visualisation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('C.P', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Wang', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['visualisation', 'big data applications', 'Chen C.P', 'al.', 'Wang', 'al.']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('visualisation', 'visualis'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('(', '('), ('Chen', 'chen'), ('C.P', 'c.p'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('visualisation', 'visualis'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('(', '('), ('Chen', 'chen'), ('C.P', 'c.p'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('visualisation', 'visualisation'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('(', '('), ('Chen', 'Chen'), ('C.P', 'C.P'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1154 ===========================================

Oussous et al. (2018) discussed the value of data mining methods in several domains. Data mining  

------------------- Sentence 1 -------------------

Oussous et al.

>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018) discussed the value of data mining methods in several domains.

>> Tokens are: 
 ['(', '2018', ')', 'discussed', 'value', 'data', 'mining', 'methods', 'several', 'domains', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'discussed'), ('discussed', 'value'), ('value', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'several'), ('several', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'discussed'), (')', 'discussed', 'value'), ('discussed', 'value', 'data'), ('value', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'several'), ('methods', 'several', 'domains'), ('several', 'domains', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('discussed', 'VBD'), ('value', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), ('several', 'JJ'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['value data mining methods', 'several domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('value', 'valu'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('several', 'sever'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('value', 'valu'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('several', 'sever'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discussed'), ('value', 'value'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('several', 'several'), ('domains', 'domain'), ('.', '.')]


------------------- Sentence 3 -------------------

Data mining

>> Tokens are: 
 ['Data', 'mining']

>> Bigrams are: 
 [('Data', 'mining')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['Data mining']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining')]



========================================== PARAGRAPH 1155 ===========================================

methods are significant when used for discovering patterns and extracting value hidden across  

------------------- Sentence 1 -------------------

methods are significant when used for discovering patterns and extracting value hidden across

>> Tokens are: 
 ['methods', 'significant', 'used', 'discovering', 'patterns', 'extracting', 'value', 'hidden', 'across']

>> Bigrams are: 
 [('methods', 'significant'), ('significant', 'used'), ('used', 'discovering'), ('discovering', 'patterns'), ('patterns', 'extracting'), ('extracting', 'value'), ('value', 'hidden'), ('hidden', 'across')]

>> Trigrams are: 
 [('methods', 'significant', 'used'), ('significant', 'used', 'discovering'), ('used', 'discovering', 'patterns'), ('discovering', 'patterns', 'extracting'), ('patterns', 'extracting', 'value'), ('extracting', 'value', 'hidden'), ('value', 'hidden', 'across')]

>> POS Tags are: 
 [('methods', 'NNS'), ('significant', 'JJ'), ('used', 'VBD'), ('discovering', 'VBG'), ('patterns', 'NNS'), ('extracting', 'VBG'), ('value', 'NN'), ('hidden', 'VBN'), ('across', 'IN')]

>> Noun Phrases are: 
 ['methods', 'patterns', 'value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('methods', 'method'), ('significant', 'signific'), ('used', 'use'), ('discovering', 'discov'), ('patterns', 'pattern'), ('extracting', 'extract'), ('value', 'valu'), ('hidden', 'hidden'), ('across', 'across')]

>> Stemming using Snowball Stemmer: 
 [('methods', 'method'), ('significant', 'signific'), ('used', 'use'), ('discovering', 'discov'), ('patterns', 'pattern'), ('extracting', 'extract'), ('value', 'valu'), ('hidden', 'hidden'), ('across', 'across')]

>> Lemmatization: 
 [('methods', 'method'), ('significant', 'significant'), ('used', 'used'), ('discovering', 'discovering'), ('patterns', 'pattern'), ('extracting', 'extracting'), ('value', 'value'), ('hidden', 'hidden'), ('across', 'across')]



========================================== PARAGRAPH 1156 ===========================================

massive datasets. Applying traditional data mining techniques, such as association mining,  

------------------- Sentence 1 -------------------

massive datasets.

>> Tokens are: 
 ['massive', 'datasets', '.']

>> Bigrams are: 
 [('massive', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('massive', 'datasets', '.')]

>> POS Tags are: 
 [('massive', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['massive datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('massive', 'massiv'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('massive', 'massiv'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('massive', 'massive'), ('datasets', 'datasets'), ('.', '.')]


------------------- Sentence 2 -------------------

Applying traditional data mining techniques, such as association mining,

>> Tokens are: 
 ['Applying', 'traditional', 'data', 'mining', 'techniques', ',', 'association', 'mining', ',']

>> Bigrams are: 
 [('Applying', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'techniques'), ('techniques', ','), (',', 'association'), ('association', 'mining'), ('mining', ',')]

>> Trigrams are: 
 [('Applying', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'techniques'), ('mining', 'techniques', ','), ('techniques', ',', 'association'), (',', 'association', 'mining'), ('association', 'mining', ',')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('techniques', 'NNS'), (',', ','), ('association', 'NN'), ('mining', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['traditional data mining techniques', 'association mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), (',', ','), ('association', 'associ'), ('mining', 'mine'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), (',', ','), ('association', 'associ'), ('mining', 'mine'), (',', ',')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('techniques', 'technique'), (',', ','), ('association', 'association'), ('mining', 'mining'), (',', ',')]



========================================== PARAGRAPH 1157 ===========================================

clustering, and classification, to big data is, however, inefficient and inaccurate. The volume,  

------------------- Sentence 1 -------------------

clustering, and classification, to big data is, however, inefficient and inaccurate.

>> Tokens are: 
 ['clustering', ',', 'classification', ',', 'big', 'data', ',', 'however', ',', 'inefficient', 'inaccurate', '.']

>> Bigrams are: 
 [('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'however'), ('however', ','), (',', 'inefficient'), ('inefficient', 'inaccurate'), ('inaccurate', '.')]

>> Trigrams are: 
 [('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'however'), (',', 'however', ','), ('however', ',', 'inefficient'), (',', 'inefficient', 'inaccurate'), ('inefficient', 'inaccurate', '.')]

>> POS Tags are: 
 [('clustering', 'NN'), (',', ','), ('classification', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('inefficient', 'JJ'), ('inaccurate', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['clustering', 'classification', 'big data', 'inefficient inaccurate']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('inefficient', 'ineffici'), ('inaccurate', 'inaccur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('inefficient', 'ineffici'), ('inaccurate', 'inaccur'), ('.', '.')]

>> Lemmatization: 
 [('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'however'), (',', ','), ('inefficient', 'inefficient'), ('inaccurate', 'inaccurate'), ('.', '.')]


------------------- Sentence 2 -------------------

The volume,

>> Tokens are: 
 ['The', 'volume', ',']

>> Bigrams are: 
 [('The', 'volume'), ('volume', ',')]

>> Trigrams are: 
 [('The', 'volume', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('volume', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['The volume']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('volume', 'volum'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('volume', 'volum'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('volume', 'volume'), (',', ',')]



========================================== PARAGRAPH 1158 ===========================================

speed, and variability of such data makes it unsuitable for long-term storage and analysis. Several  

------------------- Sentence 1 -------------------

speed, and variability of such data makes it unsuitable for long-term storage and analysis.

>> Tokens are: 
 ['speed', ',', 'variability', 'data', 'makes', 'unsuitable', 'long-term', 'storage', 'analysis', '.']

>> Bigrams are: 
 [('speed', ','), (',', 'variability'), ('variability', 'data'), ('data', 'makes'), ('makes', 'unsuitable'), ('unsuitable', 'long-term'), ('long-term', 'storage'), ('storage', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('speed', ',', 'variability'), (',', 'variability', 'data'), ('variability', 'data', 'makes'), ('data', 'makes', 'unsuitable'), ('makes', 'unsuitable', 'long-term'), ('unsuitable', 'long-term', 'storage'), ('long-term', 'storage', 'analysis'), ('storage', 'analysis', '.')]

>> POS Tags are: 
 [('speed', 'NN'), (',', ','), ('variability', 'NN'), ('data', 'NNS'), ('makes', 'VBZ'), ('unsuitable', 'JJ'), ('long-term', 'JJ'), ('storage', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['speed', 'variability data', 'unsuitable long-term storage analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('speed', 'speed'), (',', ','), ('variability', 'variabl'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuit'), ('long-term', 'long-term'), ('storage', 'storag'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('speed', 'speed'), (',', ','), ('variability', 'variabl'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuit'), ('long-term', 'long-term'), ('storage', 'storag'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('speed', 'speed'), (',', ','), ('variability', 'variability'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuitable'), ('long-term', 'long-term'), ('storage', 'storage'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Several

>> Tokens are: 
 ['Several']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Several', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever')]

>> Lemmatization: 
 [('Several', 'Several')]



========================================== PARAGRAPH 1159 ===========================================

data mining methods have thus been adapted to contain detecting techniques to take the data  

------------------- Sentence 1 -------------------

data mining methods have thus been adapted to contain detecting techniques to take the data

>> Tokens are: 
 ['data', 'mining', 'methods', 'thus', 'adapted', 'contain', 'detecting', 'techniques', 'take', 'data']

>> Bigrams are: 
 [('data', 'mining'), ('mining', 'methods'), ('methods', 'thus'), ('thus', 'adapted'), ('adapted', 'contain'), ('contain', 'detecting'), ('detecting', 'techniques'), ('techniques', 'take'), ('take', 'data')]

>> Trigrams are: 
 [('data', 'mining', 'methods'), ('mining', 'methods', 'thus'), ('methods', 'thus', 'adapted'), ('thus', 'adapted', 'contain'), ('adapted', 'contain', 'detecting'), ('contain', 'detecting', 'techniques'), ('detecting', 'techniques', 'take'), ('techniques', 'take', 'data')]

>> POS Tags are: 
 [('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), ('thus', 'RB'), ('adapted', 'VBD'), ('contain', 'NN'), ('detecting', 'VBG'), ('techniques', 'NNS'), ('take', 'VBP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['data mining methods', 'contain', 'techniques', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('thus', 'thu'), ('adapted', 'adapt'), ('contain', 'contain'), ('detecting', 'detect'), ('techniques', 'techniqu'), ('take', 'take'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('thus', 'thus'), ('adapted', 'adapt'), ('contain', 'contain'), ('detecting', 'detect'), ('techniques', 'techniqu'), ('take', 'take'), ('data', 'data')]

>> Lemmatization: 
 [('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('thus', 'thus'), ('adapted', 'adapted'), ('contain', 'contain'), ('detecting', 'detecting'), ('techniques', 'technique'), ('take', 'take'), ('data', 'data')]



========================================== PARAGRAPH 1160 ===========================================

environment into account.  

------------------- Sentence 1 -------------------

environment into account.

>> Tokens are: 
 ['environment', 'account', '.']

>> Bigrams are: 
 [('environment', 'account'), ('account', '.')]

>> Trigrams are: 
 [('environment', 'account', '.')]

>> POS Tags are: 
 [('environment', 'NN'), ('account', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['environment account']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('environment', 'environ'), ('account', 'account'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('environment', 'environ'), ('account', 'account'), ('.', '.')]

>> Lemmatization: 
 [('environment', 'environment'), ('account', 'account'), ('.', '.')]



========================================== PARAGRAPH 1161 ===========================================

Günther et al. (2017) noted that some empirical studies and some old ideas have characterised  

------------------- Sentence 1 -------------------

Günther et al.

>> Tokens are: 
 ['Günther', 'et', 'al', '.']

>> Bigrams are: 
 [('Günther', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Günther', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Günther', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Günther', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Günther', 'Günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2017) noted that some empirical studies and some old ideas have characterised

>> Tokens are: 
 ['(', '2017', ')', 'noted', 'empirical', 'studies', 'old', 'ideas', 'characterised']

>> Bigrams are: 
 [('(', '2017'), ('2017', ')'), (')', 'noted'), ('noted', 'empirical'), ('empirical', 'studies'), ('studies', 'old'), ('old', 'ideas'), ('ideas', 'characterised')]

>> Trigrams are: 
 [('(', '2017', ')'), ('2017', ')', 'noted'), (')', 'noted', 'empirical'), ('noted', 'empirical', 'studies'), ('empirical', 'studies', 'old'), ('studies', 'old', 'ideas'), ('old', 'ideas', 'characterised')]

>> POS Tags are: 
 [('(', '('), ('2017', 'CD'), (')', ')'), ('noted', 'VBD'), ('empirical', 'JJ'), ('studies', 'NNS'), ('old', 'JJ'), ('ideas', 'NNS'), ('characterised', 'VBD')]

>> Noun Phrases are: 
 ['empirical studies', 'old ideas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'note'), ('empirical', 'empir'), ('studies', 'studi'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characteris')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'note'), ('empirical', 'empir'), ('studies', 'studi'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characteris')]

>> Lemmatization: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'noted'), ('empirical', 'empirical'), ('studies', 'study'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characterised')]



========================================== PARAGRAPH 1162 ===========================================

much big data value realisation; the study examined six debates identified in terms of “how  

------------------- Sentence 1 -------------------

much big data value realisation; the study examined six debates identified in terms of “how

>> Tokens are: 
 ['much', 'big', 'data', 'value', 'realisation', ';', 'study', 'examined', 'six', 'debates', 'identified', 'terms', '“']

>> Bigrams are: 
 [('much', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', ';'), (';', 'study'), ('study', 'examined'), ('examined', 'six'), ('six', 'debates'), ('debates', 'identified'), ('identified', 'terms'), ('terms', '“')]

>> Trigrams are: 
 [('much', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', ';'), ('realisation', ';', 'study'), (';', 'study', 'examined'), ('study', 'examined', 'six'), ('examined', 'six', 'debates'), ('six', 'debates', 'identified'), ('debates', 'identified', 'terms'), ('identified', 'terms', '“')]

>> POS Tags are: 
 [('much', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), (';', ':'), ('study', 'NN'), ('examined', 'VBD'), ('six', 'CD'), ('debates', 'NNS'), ('identified', 'VBN'), ('terms', 'NNS'), ('“', 'VBP')]

>> Noun Phrases are: 
 ['much big data value realisation', 'study', 'debates', 'terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (';', ';'), ('study', 'studi'), ('examined', 'examin'), ('six', 'six'), ('debates', 'debat'), ('identified', 'identifi'), ('terms', 'term'), ('“', '“')]

>> Stemming using Snowball Stemmer: 
 [('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (';', ';'), ('study', 'studi'), ('examined', 'examin'), ('six', 'six'), ('debates', 'debat'), ('identified', 'identifi'), ('terms', 'term'), ('“', '“')]

>> Lemmatization: 
 [('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), (';', ';'), ('study', 'study'), ('examined', 'examined'), ('six', 'six'), ('debates', 'debate'), ('identified', 'identified'), ('terms', 'term'), ('“', '“')]



========================================== PARAGRAPH 1163 ===========================================

organisations realize social and economic value from big data that require attention from future  

------------------- Sentence 1 -------------------

organisations realize social and economic value from big data that require attention from future

>> Tokens are: 
 ['organisations', 'realize', 'social', 'economic', 'value', 'big', 'data', 'require', 'attention', 'future']

>> Bigrams are: 
 [('organisations', 'realize'), ('realize', 'social'), ('social', 'economic'), ('economic', 'value'), ('value', 'big'), ('big', 'data'), ('data', 'require'), ('require', 'attention'), ('attention', 'future')]

>> Trigrams are: 
 [('organisations', 'realize', 'social'), ('realize', 'social', 'economic'), ('social', 'economic', 'value'), ('economic', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', 'require'), ('data', 'require', 'attention'), ('require', 'attention', 'future')]

>> POS Tags are: 
 [('organisations', 'NNS'), ('realize', 'VBP'), ('social', 'JJ'), ('economic', 'JJ'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('require', 'VBP'), ('attention', 'NN'), ('future', 'NN')]

>> Noun Phrases are: 
 ['organisations', 'social economic value', 'big data', 'attention future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organisations', 'organis'), ('realize', 'realiz'), ('social', 'social'), ('economic', 'econom'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('attention', 'attent'), ('future', 'futur')]

>> Stemming using Snowball Stemmer: 
 [('organisations', 'organis'), ('realize', 'realiz'), ('social', 'social'), ('economic', 'econom'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('attention', 'attent'), ('future', 'futur')]

>> Lemmatization: 
 [('organisations', 'organisation'), ('realize', 'realize'), ('social', 'social'), ('economic', 'economic'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('require', 'require'), ('attention', 'attention'), ('future', 'future')]



========================================== PARAGRAPH 1164 ===========================================

research”. Two additional features of big data were also identified, portability and  

------------------- Sentence 1 -------------------

research”.

>> Tokens are: 
 ['research', '”', '.']

>> Bigrams are: 
 [('research', '”'), ('”', '.')]

>> Trigrams are: 
 [('research', '”', '.')]

>> POS Tags are: 
 [('research', 'NN'), ('”', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['research ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('research', 'research'), ('”', '”'), ('.', '.')]


------------------- Sentence 2 -------------------

Two additional features of big data were also identified, portability and

>> Tokens are: 
 ['Two', 'additional', 'features', 'big', 'data', 'also', 'identified', ',', 'portability']

>> Bigrams are: 
 [('Two', 'additional'), ('additional', 'features'), ('features', 'big'), ('big', 'data'), ('data', 'also'), ('also', 'identified'), ('identified', ','), (',', 'portability')]

>> Trigrams are: 
 [('Two', 'additional', 'features'), ('additional', 'features', 'big'), ('features', 'big', 'data'), ('big', 'data', 'also'), ('data', 'also', 'identified'), ('also', 'identified', ','), ('identified', ',', 'portability')]

>> POS Tags are: 
 [('Two', 'CD'), ('additional', 'JJ'), ('features', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('also', 'RB'), ('identified', 'VBN'), (',', ','), ('portability', 'NN')]

>> Noun Phrases are: 
 ['additional features', 'big data', 'portability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Two', 'two'), ('additional', 'addit'), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identifi'), (',', ','), ('portability', 'portabl')]

>> Stemming using Snowball Stemmer: 
 [('Two', 'two'), ('additional', 'addit'), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identifi'), (',', ','), ('portability', 'portabl')]

>> Lemmatization: 
 [('Two', 'Two'), ('additional', 'additional'), ('features', 'feature'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identified'), (',', ','), ('portability', 'portability')]



========================================== PARAGRAPH 1165 ===========================================

interconnectivity, and those features were utilised to show the effect of big data value realisation  

------------------- Sentence 1 -------------------

interconnectivity, and those features were utilised to show the effect of big data value realisation

>> Tokens are: 
 ['interconnectivity', ',', 'features', 'utilised', 'show', 'effect', 'big', 'data', 'value', 'realisation']

>> Bigrams are: 
 [('interconnectivity', ','), (',', 'features'), ('features', 'utilised'), ('utilised', 'show'), ('show', 'effect'), ('effect', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation')]

>> Trigrams are: 
 [('interconnectivity', ',', 'features'), (',', 'features', 'utilised'), ('features', 'utilised', 'show'), ('utilised', 'show', 'effect'), ('show', 'effect', 'big'), ('effect', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation')]

>> POS Tags are: 
 [('interconnectivity', 'NN'), (',', ','), ('features', 'NNS'), ('utilised', 'VBD'), ('show', 'NN'), ('effect', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN')]

>> Noun Phrases are: 
 ['interconnectivity', 'features', 'show effect', 'big data value realisation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interconnectivity', 'interconnect'), (',', ','), ('features', 'featur'), ('utilised', 'utilis'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis')]

>> Stemming using Snowball Stemmer: 
 [('interconnectivity', 'interconnect'), (',', ','), ('features', 'featur'), ('utilised', 'utilis'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis')]

>> Lemmatization: 
 [('interconnectivity', 'interconnectivity'), (',', ','), ('features', 'feature'), ('utilised', 'utilised'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation')]



========================================== PARAGRAPH 1166 ===========================================

in organisations. At the end of the study, the authors argued that the continuous interactions  

------------------- Sentence 1 -------------------

in organisations.

>> Tokens are: 
 ['organisations', '.']

>> Bigrams are: 
 [('organisations', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('organisations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organisations', 'organis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('organisations', 'organis'), ('.', '.')]

>> Lemmatization: 
 [('organisations', 'organisation'), ('.', '.')]


------------------- Sentence 2 -------------------

At the end of the study, the authors argued that the continuous interactions

>> Tokens are: 
 ['At', 'end', 'study', ',', 'authors', 'argued', 'continuous', 'interactions']

>> Bigrams are: 
 [('At', 'end'), ('end', 'study'), ('study', ','), (',', 'authors'), ('authors', 'argued'), ('argued', 'continuous'), ('continuous', 'interactions')]

>> Trigrams are: 
 [('At', 'end', 'study'), ('end', 'study', ','), ('study', ',', 'authors'), (',', 'authors', 'argued'), ('authors', 'argued', 'continuous'), ('argued', 'continuous', 'interactions')]

>> POS Tags are: 
 [('At', 'IN'), ('end', 'NN'), ('study', 'NN'), (',', ','), ('authors', 'NNS'), ('argued', 'VBD'), ('continuous', 'JJ'), ('interactions', 'NNS')]

>> Noun Phrases are: 
 ['end study', 'authors', 'continuous interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('end', 'end'), ('study', 'studi'), (',', ','), ('authors', 'author'), ('argued', 'argu'), ('continuous', 'continu'), ('interactions', 'interact')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('end', 'end'), ('study', 'studi'), (',', ','), ('authors', 'author'), ('argued', 'argu'), ('continuous', 'continu'), ('interactions', 'interact')]

>> Lemmatization: 
 [('At', 'At'), ('end', 'end'), ('study', 'study'), (',', ','), ('authors', 'author'), ('argued', 'argued'), ('continuous', 'continuous'), ('interactions', 'interaction')]



========================================== PARAGRAPH 1167 ===========================================

between work practices, organisational models, and stakeholder interests prompted calls for  

------------------- Sentence 1 -------------------

between work practices, organisational models, and stakeholder interests prompted calls for

>> Tokens are: 
 ['work', 'practices', ',', 'organisational', 'models', ',', 'stakeholder', 'interests', 'prompted', 'calls']

>> Bigrams are: 
 [('work', 'practices'), ('practices', ','), (',', 'organisational'), ('organisational', 'models'), ('models', ','), (',', 'stakeholder'), ('stakeholder', 'interests'), ('interests', 'prompted'), ('prompted', 'calls')]

>> Trigrams are: 
 [('work', 'practices', ','), ('practices', ',', 'organisational'), (',', 'organisational', 'models'), ('organisational', 'models', ','), ('models', ',', 'stakeholder'), (',', 'stakeholder', 'interests'), ('stakeholder', 'interests', 'prompted'), ('interests', 'prompted', 'calls')]

>> POS Tags are: 
 [('work', 'NN'), ('practices', 'NNS'), (',', ','), ('organisational', 'JJ'), ('models', 'NNS'), (',', ','), ('stakeholder', 'NN'), ('interests', 'NNS'), ('prompted', 'VBD'), ('calls', 'NNS')]

>> Noun Phrases are: 
 ['work practices', 'organisational models', 'stakeholder interests', 'calls']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('work', 'work'), ('practices', 'practic'), (',', ','), ('organisational', 'organis'), ('models', 'model'), (',', ','), ('stakeholder', 'stakehold'), ('interests', 'interest'), ('prompted', 'prompt'), ('calls', 'call')]

>> Stemming using Snowball Stemmer: 
 [('work', 'work'), ('practices', 'practic'), (',', ','), ('organisational', 'organis'), ('models', 'model'), (',', ','), ('stakeholder', 'stakehold'), ('interests', 'interest'), ('prompted', 'prompt'), ('calls', 'call')]

>> Lemmatization: 
 [('work', 'work'), ('practices', 'practice'), (',', ','), ('organisational', 'organisational'), ('models', 'model'), (',', ','), ('stakeholder', 'stakeholder'), ('interests', 'interest'), ('prompted', 'prompted'), ('calls', 'call')]



========================================== PARAGRAPH 1168 ===========================================

empirical research on cross-level interactions and alignment results from realising big data value,  

------------------- Sentence 1 -------------------

empirical research on cross-level interactions and alignment results from realising big data value,

>> Tokens are: 
 ['empirical', 'research', 'cross-level', 'interactions', 'alignment', 'results', 'realising', 'big', 'data', 'value', ',']

>> Bigrams are: 
 [('empirical', 'research'), ('research', 'cross-level'), ('cross-level', 'interactions'), ('interactions', 'alignment'), ('alignment', 'results'), ('results', 'realising'), ('realising', 'big'), ('big', 'data'), ('data', 'value'), ('value', ',')]

>> Trigrams are: 
 [('empirical', 'research', 'cross-level'), ('research', 'cross-level', 'interactions'), ('cross-level', 'interactions', 'alignment'), ('interactions', 'alignment', 'results'), ('alignment', 'results', 'realising'), ('results', 'realising', 'big'), ('realising', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', ',')]

>> POS Tags are: 
 [('empirical', 'JJ'), ('research', 'NN'), ('cross-level', 'JJ'), ('interactions', 'NNS'), ('alignment', 'JJ'), ('results', 'NNS'), ('realising', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['empirical research', 'cross-level interactions', 'alignment results', 'big data value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('empirical', 'empir'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interact'), ('alignment', 'align'), ('results', 'result'), ('realising', 'realis'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('empirical', 'empir'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interact'), ('alignment', 'align'), ('results', 'result'), ('realising', 'realis'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), (',', ',')]

>> Lemmatization: 
 [('empirical', 'empirical'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interaction'), ('alignment', 'alignment'), ('results', 'result'), ('realising', 'realising'), ('big', 'big'), ('data', 'data'), ('value', 'value'), (',', ',')]



========================================== PARAGRAPH 1169 ===========================================

as shown in Figure 23. Several suggestions for further study were also presented: 

------------------- Sentence 1 -------------------

as shown in Figure 23.

>> Tokens are: 
 ['shown', 'Figure', '23', '.']

>> Bigrams are: 
 [('shown', 'Figure'), ('Figure', '23'), ('23', '.')]

>> Trigrams are: 
 [('shown', 'Figure', '23'), ('Figure', '23', '.')]

>> POS Tags are: 
 [('shown', 'VBN'), ('Figure', 'NN'), ('23', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('Figure', 'figur'), ('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('shown', 'shown'), ('Figure', 'Figure'), ('23', '23'), ('.', '.')]


------------------- Sentence 2 -------------------

Several suggestions for further study were also presented:

>> Tokens are: 
 ['Several', 'suggestions', 'study', 'also', 'presented', ':']

>> Bigrams are: 
 [('Several', 'suggestions'), ('suggestions', 'study'), ('study', 'also'), ('also', 'presented'), ('presented', ':')]

>> Trigrams are: 
 [('Several', 'suggestions', 'study'), ('suggestions', 'study', 'also'), ('study', 'also', 'presented'), ('also', 'presented', ':')]

>> POS Tags are: 
 [('Several', 'JJ'), ('suggestions', 'NNS'), ('study', 'NN'), ('also', 'RB'), ('presented', 'VBD'), (':', ':')]

>> Noun Phrases are: 
 ['Several suggestions study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('suggestions', 'suggest'), ('study', 'studi'), ('also', 'also'), ('presented', 'present'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('suggestions', 'suggest'), ('study', 'studi'), ('also', 'also'), ('presented', 'present'), (':', ':')]

>> Lemmatization: 
 [('Several', 'Several'), ('suggestions', 'suggestion'), ('study', 'study'), ('also', 'also'), ('presented', 'presented'), (':', ':')]



========================================== PARAGRAPH 1170 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1171 ===========================================

41  

------------------- Sentence 1 -------------------

41

>> Tokens are: 
 ['41']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41', '41')]

>> Stemming using Snowball Stemmer: 
 [('41', '41')]

>> Lemmatization: 
 [('41', '41')]



========================================== PARAGRAPH 1172 ===========================================

  


========================================== PARAGRAPH 1173 ===========================================

• Work on improving big data business models and innovative approaches, such as the  development of a four-stage big data maturity model, allowing organisations to reach  

------------------- Sentence 1 -------------------

• Work on improving big data business models and innovative approaches, such as the  development of a four-stage big data maturity model, allowing organisations to reach

>> Tokens are: 
 ['•', 'Work', 'improving', 'big', 'data', 'business', 'models', 'innovative', 'approaches', ',', 'development', 'four-stage', 'big', 'data', 'maturity', 'model', ',', 'allowing', 'organisations', 'reach']

>> Bigrams are: 
 [('•', 'Work'), ('Work', 'improving'), ('improving', 'big'), ('big', 'data'), ('data', 'business'), ('business', 'models'), ('models', 'innovative'), ('innovative', 'approaches'), ('approaches', ','), (',', 'development'), ('development', 'four-stage'), ('four-stage', 'big'), ('big', 'data'), ('data', 'maturity'), ('maturity', 'model'), ('model', ','), (',', 'allowing'), ('allowing', 'organisations'), ('organisations', 'reach')]

>> Trigrams are: 
 [('•', 'Work', 'improving'), ('Work', 'improving', 'big'), ('improving', 'big', 'data'), ('big', 'data', 'business'), ('data', 'business', 'models'), ('business', 'models', 'innovative'), ('models', 'innovative', 'approaches'), ('innovative', 'approaches', ','), ('approaches', ',', 'development'), (',', 'development', 'four-stage'), ('development', 'four-stage', 'big'), ('four-stage', 'big', 'data'), ('big', 'data', 'maturity'), ('data', 'maturity', 'model'), ('maturity', 'model', ','), ('model', ',', 'allowing'), (',', 'allowing', 'organisations'), ('allowing', 'organisations', 'reach')]

>> POS Tags are: 
 [('•', 'JJ'), ('Work', 'NNP'), ('improving', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('business', 'NN'), ('models', 'NNS'), ('innovative', 'JJ'), ('approaches', 'NNS'), (',', ','), ('development', 'NN'), ('four-stage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('maturity', 'NN'), ('model', 'NN'), (',', ','), ('allowing', 'VBG'), ('organisations', 'NNS'), ('reach', 'VBP')]

>> Noun Phrases are: 
 ['• Work', 'big data business models', 'innovative approaches', 'development four-stage', 'big data maturity model', 'organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Work', 'work'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('models', 'model'), ('innovative', 'innov'), ('approaches', 'approach'), (',', ','), ('development', 'develop'), ('four-stage', 'four-stag'), ('big', 'big'), ('data', 'data'), ('maturity', 'matur'), ('model', 'model'), (',', ','), ('allowing', 'allow'), ('organisations', 'organis'), ('reach', 'reach')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Work', 'work'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('models', 'model'), ('innovative', 'innov'), ('approaches', 'approach'), (',', ','), ('development', 'develop'), ('four-stage', 'four-stag'), ('big', 'big'), ('data', 'data'), ('maturity', 'matur'), ('model', 'model'), (',', ','), ('allowing', 'allow'), ('organisations', 'organis'), ('reach', 'reach')]

>> Lemmatization: 
 [('•', '•'), ('Work', 'Work'), ('improving', 'improving'), ('big', 'big'), ('data', 'data'), ('business', 'business'), ('models', 'model'), ('innovative', 'innovative'), ('approaches', 'approach'), (',', ','), ('development', 'development'), ('four-stage', 'four-stage'), ('big', 'big'), ('data', 'data'), ('maturity', 'maturity'), ('model', 'model'), (',', ','), ('allowing', 'allowing'), ('organisations', 'organisation'), ('reach', 'reach')]



========================================== PARAGRAPH 1174 ===========================================

functional excellence despite the ability to develop business model transformation  

------------------- Sentence 1 -------------------

functional excellence despite the ability to develop business model transformation

>> Tokens are: 
 ['functional', 'excellence', 'despite', 'ability', 'develop', 'business', 'model', 'transformation']

>> Bigrams are: 
 [('functional', 'excellence'), ('excellence', 'despite'), ('despite', 'ability'), ('ability', 'develop'), ('develop', 'business'), ('business', 'model'), ('model', 'transformation')]

>> Trigrams are: 
 [('functional', 'excellence', 'despite'), ('excellence', 'despite', 'ability'), ('despite', 'ability', 'develop'), ('ability', 'develop', 'business'), ('develop', 'business', 'model'), ('business', 'model', 'transformation')]

>> POS Tags are: 
 [('functional', 'JJ'), ('excellence', 'NN'), ('despite', 'IN'), ('ability', 'NN'), ('develop', 'NN'), ('business', 'NN'), ('model', 'NN'), ('transformation', 'NN')]

>> Noun Phrases are: 
 ['functional excellence', 'ability develop business model transformation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('functional', 'function'), ('excellence', 'excel'), ('despite', 'despit'), ('ability', 'abil'), ('develop', 'develop'), ('business', 'busi'), ('model', 'model'), ('transformation', 'transform')]

>> Stemming using Snowball Stemmer: 
 [('functional', 'function'), ('excellence', 'excel'), ('despite', 'despit'), ('ability', 'abil'), ('develop', 'develop'), ('business', 'busi'), ('model', 'model'), ('transformation', 'transform')]

>> Lemmatization: 
 [('functional', 'functional'), ('excellence', 'excellence'), ('despite', 'despite'), ('ability', 'ability'), ('develop', 'develop'), ('business', 'business'), ('model', 'model'), ('transformation', 'transformation')]



========================================== PARAGRAPH 1175 ===========================================

occurring only in the last stage;  

------------------- Sentence 1 -------------------

occurring only in the last stage;

>> Tokens are: 
 ['occurring', 'last', 'stage', ';']

>> Bigrams are: 
 [('occurring', 'last'), ('last', 'stage'), ('stage', ';')]

>> Trigrams are: 
 [('occurring', 'last', 'stage'), ('last', 'stage', ';')]

>> POS Tags are: 
 [('occurring', 'VBG'), ('last', 'JJ'), ('stage', 'NN'), (';', ':')]

>> Noun Phrases are: 
 ['last stage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('occurring', 'occur'), ('last', 'last'), ('stage', 'stage'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('occurring', 'occur'), ('last', 'last'), ('stage', 'stage'), (';', ';')]

>> Lemmatization: 
 [('occurring', 'occurring'), ('last', 'last'), ('stage', 'stage'), (';', ';')]



========================================== PARAGRAPH 1176 ===========================================

• Relevant systems, such as Hadoop, which have the ability to work with both big data and  more traditional data being identified for various cases (Ekbia et al., 2015);  

------------------- Sentence 1 -------------------

• Relevant systems, such as Hadoop, which have the ability to work with both big data and  more traditional data being identified for various cases (Ekbia et al., 2015);

>> Tokens are: 
 ['•', 'Relevant', 'systems', ',', 'Hadoop', ',', 'ability', 'work', 'big', 'data', 'traditional', 'data', 'identified', 'various', 'cases', '(', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';']

>> Bigrams are: 
 [('•', 'Relevant'), ('Relevant', 'systems'), ('systems', ','), (',', 'Hadoop'), ('Hadoop', ','), (',', 'ability'), ('ability', 'work'), ('work', 'big'), ('big', 'data'), ('data', 'traditional'), ('traditional', 'data'), ('data', 'identified'), ('identified', 'various'), ('various', 'cases'), ('cases', '('), ('(', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';')]

>> Trigrams are: 
 [('•', 'Relevant', 'systems'), ('Relevant', 'systems', ','), ('systems', ',', 'Hadoop'), (',', 'Hadoop', ','), ('Hadoop', ',', 'ability'), (',', 'ability', 'work'), ('ability', 'work', 'big'), ('work', 'big', 'data'), ('big', 'data', 'traditional'), ('data', 'traditional', 'data'), ('traditional', 'data', 'identified'), ('data', 'identified', 'various'), ('identified', 'various', 'cases'), ('various', 'cases', '('), ('cases', '(', 'Ekbia'), ('(', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';')]

>> POS Tags are: 
 [('•', 'JJ'), ('Relevant', 'NNP'), ('systems', 'NNS'), (',', ','), ('Hadoop', 'NNP'), (',', ','), ('ability', 'NN'), ('work', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('identified', 'VBN'), ('various', 'JJ'), ('cases', 'NNS'), ('(', '('), ('Ekbia', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':')]

>> Noun Phrases are: 
 ['• Relevant systems', 'Hadoop', 'ability work', 'big data', 'traditional data', 'various cases', 'Ekbia']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('PERSON', 'Ekbia')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Relevant', 'relev'), ('systems', 'system'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('ability', 'abil'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('identified', 'identifi'), ('various', 'variou'), ('cases', 'case'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Relevant', 'relev'), ('systems', 'system'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('ability', 'abil'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('identified', 'identifi'), ('various', 'various'), ('cases', 'case'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('Relevant', 'Relevant'), ('systems', 'system'), (',', ','), ('Hadoop', 'Hadoop'), (',', ','), ('ability', 'ability'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'traditional'), ('data', 'data'), ('identified', 'identified'), ('various', 'various'), ('cases', 'case'), ('(', '('), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]



========================================== PARAGRAPH 1177 ===========================================

• Examining the dependency on size of organisations that can adopt big data (Ekbia et al.,  2015);  

------------------- Sentence 1 -------------------

• Examining the dependency on size of organisations that can adopt big data (Ekbia et al.,  2015);

>> Tokens are: 
 ['•', 'Examining', 'dependency', 'size', 'organisations', 'adopt', 'big', 'data', '(', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';']

>> Bigrams are: 
 [('•', 'Examining'), ('Examining', 'dependency'), ('dependency', 'size'), ('size', 'organisations'), ('organisations', 'adopt'), ('adopt', 'big'), ('big', 'data'), ('data', '('), ('(', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';')]

>> Trigrams are: 
 [('•', 'Examining', 'dependency'), ('Examining', 'dependency', 'size'), ('dependency', 'size', 'organisations'), ('size', 'organisations', 'adopt'), ('organisations', 'adopt', 'big'), ('adopt', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Ekbia'), ('(', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('Examining', 'NNP'), ('dependency', 'NN'), ('size', 'NN'), ('organisations', 'NNS'), ('adopt', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Ekbia', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':')]

>> Noun Phrases are: 
 ['• Examining dependency size organisations', 'big data', 'Ekbia']

>> Named Entities are: 
 [('PERSON', 'Ekbia')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Examining', 'examin'), ('dependency', 'depend'), ('size', 'size'), ('organisations', 'organis'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Examining', 'examin'), ('dependency', 'depend'), ('size', 'size'), ('organisations', 'organis'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('Examining', 'Examining'), ('dependency', 'dependency'), ('size', 'size'), ('organisations', 'organisation'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]



========================================== PARAGRAPH 1178 ===========================================

• Examining appropriate organisational models for creating and appropriating value from  big data (Karpovsky and Galliers, 2015; Ekbia et al., 2015);  

------------------- Sentence 1 -------------------

• Examining appropriate organisational models for creating and appropriating value from  big data (Karpovsky and Galliers, 2015; Ekbia et al., 2015);

>> Tokens are: 
 ['•', 'Examining', 'appropriate', 'organisational', 'models', 'creating', 'appropriating', 'value', 'big', 'data', '(', 'Karpovsky', 'Galliers', ',', '2015', ';', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';']

>> Bigrams are: 
 [('•', 'Examining'), ('Examining', 'appropriate'), ('appropriate', 'organisational'), ('organisational', 'models'), ('models', 'creating'), ('creating', 'appropriating'), ('appropriating', 'value'), ('value', 'big'), ('big', 'data'), ('data', '('), ('(', 'Karpovsky'), ('Karpovsky', 'Galliers'), ('Galliers', ','), (',', '2015'), ('2015', ';'), (';', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';')]

>> Trigrams are: 
 [('•', 'Examining', 'appropriate'), ('Examining', 'appropriate', 'organisational'), ('appropriate', 'organisational', 'models'), ('organisational', 'models', 'creating'), ('models', 'creating', 'appropriating'), ('creating', 'appropriating', 'value'), ('appropriating', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Karpovsky'), ('(', 'Karpovsky', 'Galliers'), ('Karpovsky', 'Galliers', ','), ('Galliers', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Ekbia'), (';', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('Examining', 'VBG'), ('appropriate', 'JJ'), ('organisational', 'JJ'), ('models', 'NNS'), ('creating', 'VBG'), ('appropriating', 'VBG'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Karpovsky', 'NNP'), ('Galliers', 'NNP'), (',', ','), ('2015', 'CD'), (';', ':'), ('Ekbia', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':')]

>> Noun Phrases are: 
 ['•', 'appropriate organisational models', 'value', 'big data', 'Karpovsky Galliers', 'Ekbia', 'al.']

>> Named Entities are: 
 [('PERSON', 'Karpovsky Galliers'), ('GPE', 'Ekbia')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Examining', 'examin'), ('appropriate', 'appropri'), ('organisational', 'organis'), ('models', 'model'), ('creating', 'creat'), ('appropriating', 'appropri'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'karpovski'), ('Galliers', 'gallier'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Examining', 'examin'), ('appropriate', 'appropri'), ('organisational', 'organis'), ('models', 'model'), ('creating', 'creat'), ('appropriating', 'appropri'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'karpovski'), ('Galliers', 'gallier'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('Examining', 'Examining'), ('appropriate', 'appropriate'), ('organisational', 'organisational'), ('models', 'model'), ('creating', 'creating'), ('appropriating', 'appropriating'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'Karpovsky'), ('Galliers', 'Galliers'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';')]



========================================== PARAGRAPH 1179 ===========================================

• Further investigation of two key issues: 1) controlled and open big data access when data  analytics can be considered a competitive advantage, as organisations may be opposed to  

------------------- Sentence 1 -------------------

• Further investigation of two key issues: 1) controlled and open big data access when data  analytics can be considered a competitive advantage, as organisations may be opposed to

>> Tokens are: 
 ['•', 'Further', 'investigation', 'two', 'key', 'issues', ':', '1', ')', 'controlled', 'open', 'big', 'data', 'access', 'data', 'analytics', 'considered', 'competitive', 'advantage', ',', 'organisations', 'may', 'opposed']

>> Bigrams are: 
 [('•', 'Further'), ('Further', 'investigation'), ('investigation', 'two'), ('two', 'key'), ('key', 'issues'), ('issues', ':'), (':', '1'), ('1', ')'), (')', 'controlled'), ('controlled', 'open'), ('open', 'big'), ('big', 'data'), ('data', 'access'), ('access', 'data'), ('data', 'analytics'), ('analytics', 'considered'), ('considered', 'competitive'), ('competitive', 'advantage'), ('advantage', ','), (',', 'organisations'), ('organisations', 'may'), ('may', 'opposed')]

>> Trigrams are: 
 [('•', 'Further', 'investigation'), ('Further', 'investigation', 'two'), ('investigation', 'two', 'key'), ('two', 'key', 'issues'), ('key', 'issues', ':'), ('issues', ':', '1'), (':', '1', ')'), ('1', ')', 'controlled'), (')', 'controlled', 'open'), ('controlled', 'open', 'big'), ('open', 'big', 'data'), ('big', 'data', 'access'), ('data', 'access', 'data'), ('access', 'data', 'analytics'), ('data', 'analytics', 'considered'), ('analytics', 'considered', 'competitive'), ('considered', 'competitive', 'advantage'), ('competitive', 'advantage', ','), ('advantage', ',', 'organisations'), (',', 'organisations', 'may'), ('organisations', 'may', 'opposed')]

>> POS Tags are: 
 [('•', 'VB'), ('Further', 'JJ'), ('investigation', 'NN'), ('two', 'CD'), ('key', 'JJ'), ('issues', 'NNS'), (':', ':'), ('1', 'CD'), (')', ')'), ('controlled', 'VBD'), ('open', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('access', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('considered', 'VBD'), ('competitive', 'JJ'), ('advantage', 'NN'), (',', ','), ('organisations', 'NNS'), ('may', 'MD'), ('opposed', 'VB')]

>> Noun Phrases are: 
 ['Further investigation', 'key issues', 'open big data access data analytics', 'competitive advantage', 'organisations']

>> Named Entities are: 
 [('PERSON', 'Further')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Further', 'further'), ('investigation', 'investig'), ('two', 'two'), ('key', 'key'), ('issues', 'issu'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'control'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analyt'), ('considered', 'consid'), ('competitive', 'competit'), ('advantage', 'advantag'), (',', ','), ('organisations', 'organis'), ('may', 'may'), ('opposed', 'oppos')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Further', 'further'), ('investigation', 'investig'), ('two', 'two'), ('key', 'key'), ('issues', 'issu'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'control'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analyt'), ('considered', 'consid'), ('competitive', 'competit'), ('advantage', 'advantag'), (',', ','), ('organisations', 'organis'), ('may', 'may'), ('opposed', 'oppos')]

>> Lemmatization: 
 [('•', '•'), ('Further', 'Further'), ('investigation', 'investigation'), ('two', 'two'), ('key', 'key'), ('issues', 'issue'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'controlled'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analytics'), ('considered', 'considered'), ('competitive', 'competitive'), ('advantage', 'advantage'), (',', ','), ('organisations', 'organisation'), ('may', 'may'), ('opposed', 'opposed')]



========================================== PARAGRAPH 1180 ===========================================

exchanging data with perceived competitors (Jagadish et al., 2014); and 2) minimising and  

------------------- Sentence 1 -------------------

exchanging data with perceived competitors (Jagadish et al., 2014); and 2) minimising and

>> Tokens are: 
 ['exchanging', 'data', 'perceived', 'competitors', '(', 'Jagadish', 'et', 'al.', ',', '2014', ')', ';', '2', ')', 'minimising']

>> Bigrams are: 
 [('exchanging', 'data'), ('data', 'perceived'), ('perceived', 'competitors'), ('competitors', '('), ('(', 'Jagadish'), ('Jagadish', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', ';'), (';', '2'), ('2', ')'), (')', 'minimising')]

>> Trigrams are: 
 [('exchanging', 'data', 'perceived'), ('data', 'perceived', 'competitors'), ('perceived', 'competitors', '('), ('competitors', '(', 'Jagadish'), ('(', 'Jagadish', 'et'), ('Jagadish', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ';'), (')', ';', '2'), (';', '2', ')'), ('2', ')', 'minimising')]

>> POS Tags are: 
 [('exchanging', 'VBG'), ('data', 'NNS'), ('perceived', 'VBN'), ('competitors', 'NNS'), ('(', '('), ('Jagadish', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), (';', ':'), ('2', 'CD'), (')', ')'), ('minimising', 'NN')]

>> Noun Phrases are: 
 ['data', 'competitors', 'Jagadish et al.', 'minimising']

>> Named Entities are: 
 [('GPE', 'Jagadish')] 

>> Stemming using Porter Stemmer: 
 [('exchanging', 'exchang'), ('data', 'data'), ('perceived', 'perceiv'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimis')]

>> Stemming using Snowball Stemmer: 
 [('exchanging', 'exchang'), ('data', 'data'), ('perceived', 'perceiv'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimis')]

>> Lemmatization: 
 [('exchanging', 'exchanging'), ('data', 'data'), ('perceived', 'perceived'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'Jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimising')]



========================================== PARAGRAPH 1181 ===========================================

countering the social risks of big data value realisation (Clarke, 2016).  

------------------- Sentence 1 -------------------

countering the social risks of big data value realisation (Clarke, 2016).

>> Tokens are: 
 ['countering', 'social', 'risks', 'big', 'data', 'value', 'realisation', '(', 'Clarke', ',', '2016', ')', '.']

>> Bigrams are: 
 [('countering', 'social'), ('social', 'risks'), ('risks', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', '('), ('(', 'Clarke'), ('Clarke', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('countering', 'social', 'risks'), ('social', 'risks', 'big'), ('risks', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', '('), ('realisation', '(', 'Clarke'), ('(', 'Clarke', ','), ('Clarke', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('countering', 'VBG'), ('social', 'JJ'), ('risks', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), ('(', '('), ('Clarke', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['social risks', 'big data value realisation', 'Clarke']

>> Named Entities are: 
 [('PERSON', 'Clarke')] 

>> Stemming using Porter Stemmer: 
 [('countering', 'counter'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('(', '('), ('Clarke', 'clark'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('countering', 'counter'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('(', '('), ('Clarke', 'clark'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('countering', 'countering'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), ('(', '('), ('Clarke', 'Clarke'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1182 ===========================================

  


========================================== PARAGRAPH 1183 ===========================================

  


========================================== PARAGRAPH 1184 ===========================================

  


========================================== PARAGRAPH 1185 ===========================================

Figure 23: Summary of debates related to big data value realisation, adopted from (Günther et  

------------------- Sentence 1 -------------------

Figure 23: Summary of debates related to big data value realisation, adopted from (Günther et

>> Tokens are: 
 ['Figure', '23', ':', 'Summary', 'debates', 'related', 'big', 'data', 'value', 'realisation', ',', 'adopted', '(', 'Günther', 'et']

>> Bigrams are: 
 [('Figure', '23'), ('23', ':'), (':', 'Summary'), ('Summary', 'debates'), ('debates', 'related'), ('related', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Günther'), ('Günther', 'et')]

>> Trigrams are: 
 [('Figure', '23', ':'), ('23', ':', 'Summary'), (':', 'Summary', 'debates'), ('Summary', 'debates', 'related'), ('debates', 'related', 'big'), ('related', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', ','), ('realisation', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Günther'), ('(', 'Günther', 'et')]

>> POS Tags are: 
 [('Figure', 'NN'), ('23', 'CD'), (':', ':'), ('Summary', 'JJ'), ('debates', 'NNS'), ('related', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Günther', 'NNP'), ('et', 'NN')]

>> Noun Phrases are: 
 ['Figure', 'Summary debates', 'big data value realisation', 'Günther et']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('23', '23'), (':', ':'), ('Summary', 'summari'), ('debates', 'debat'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Günther', 'günther'), ('et', 'et')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('23', '23'), (':', ':'), ('Summary', 'summari'), ('debates', 'debat'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Günther', 'günther'), ('et', 'et')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('23', '23'), (':', ':'), ('Summary', 'Summary'), ('debates', 'debate'), ('related', 'related'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Günther', 'Günther'), ('et', 'et')]



========================================== PARAGRAPH 1186 ===========================================

al., 2017).  

------------------- Sentence 1 -------------------

al., 2017).

>> Tokens are: 
 ['al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1187 ===========================================

 


========================================== PARAGRAPH 1188 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1189 ===========================================

42  

------------------- Sentence 1 -------------------

42

>> Tokens are: 
 ['42']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('42', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42', '42')]

>> Stemming using Snowball Stemmer: 
 [('42', '42')]

>> Lemmatization: 
 [('42', '42')]



========================================== PARAGRAPH 1190 ===========================================

  


========================================== PARAGRAPH 1191 ===========================================

10. Big data analytics applications  

------------------- Sentence 1 -------------------

10.

>> Tokens are: 
 ['10', '.']

>> Bigrams are: 
 [('10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics applications

>> Tokens are: 
 ['Big', 'data', 'analytics', 'applications']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applications')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applications')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application')]



========================================== PARAGRAPH 1192 ===========================================

A recent survey (Nashua, 2017) highlighted the growth in the use of big data analytics in  

------------------- Sentence 1 -------------------

A recent survey (Nashua, 2017) highlighted the growth in the use of big data analytics in

>> Tokens are: 
 ['A', 'recent', 'survey', '(', 'Nashua', ',', '2017', ')', 'highlighted', 'growth', 'use', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('A', 'recent'), ('recent', 'survey'), ('survey', '('), ('(', 'Nashua'), ('Nashua', ','), (',', '2017'), ('2017', ')'), (')', 'highlighted'), ('highlighted', 'growth'), ('growth', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('A', 'recent', 'survey'), ('recent', 'survey', '('), ('survey', '(', 'Nashua'), ('(', 'Nashua', ','), ('Nashua', ',', '2017'), (',', '2017', ')'), ('2017', ')', 'highlighted'), (')', 'highlighted', 'growth'), ('highlighted', 'growth', 'use'), ('growth', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('A', 'DT'), ('recent', 'JJ'), ('survey', 'NN'), ('(', '('), ('Nashua', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('highlighted', 'VBD'), ('growth', 'NN'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['A recent survey', 'Nashua', 'growth use', 'big data analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'Nashua')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlight'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlight'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('A', 'A'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'Nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlighted'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 1193 ===========================================

companies. The study examined companies’ use of big data compared to the previous year in 2015,  

------------------- Sentence 1 -------------------

companies.

>> Tokens are: 
 ['companies', '.']

>> Bigrams are: 
 [('companies', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('companies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('companies', 'compani'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('companies', 'compani'), ('.', '.')]

>> Lemmatization: 
 [('companies', 'company'), ('.', '.')]


------------------- Sentence 2 -------------------

The study examined companies’ use of big data compared to the previous year in 2015,

>> Tokens are: 
 ['The', 'study', 'examined', 'companies', '’', 'use', 'big', 'data', 'compared', 'previous', 'year', '2015', ',']

>> Bigrams are: 
 [('The', 'study'), ('study', 'examined'), ('examined', 'companies'), ('companies', '’'), ('’', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'compared'), ('compared', 'previous'), ('previous', 'year'), ('year', '2015'), ('2015', ',')]

>> Trigrams are: 
 [('The', 'study', 'examined'), ('study', 'examined', 'companies'), ('examined', 'companies', '’'), ('companies', '’', 'use'), ('’', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'compared'), ('data', 'compared', 'previous'), ('compared', 'previous', 'year'), ('previous', 'year', '2015'), ('year', '2015', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('examined', 'VBD'), ('companies', 'NNS'), ('’', 'NNP'), ('use', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('compared', 'VBN'), ('previous', 'JJ'), ('year', 'NN'), ('2015', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['The study', 'companies ’', 'big data', 'previous year']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('examined', 'examin'), ('companies', 'compani'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compar'), ('previous', 'previou'), ('year', 'year'), ('2015', '2015'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('examined', 'examin'), ('companies', 'compani'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compar'), ('previous', 'previous'), ('year', 'year'), ('2015', '2015'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('examined', 'examined'), ('companies', 'company'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compared'), ('previous', 'previous'), ('year', 'year'), ('2015', '2015'), (',', ',')]



========================================== PARAGRAPH 1194 ===========================================

2016, and 2017. The results indicated that over 50 percent of organisations were using big data by  

------------------- Sentence 1 -------------------

2016, and 2017.

>> Tokens are: 
 ['2016', ',', '2017', '.']

>> Bigrams are: 
 [('2016', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('2016', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('2016', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

The results indicated that over 50 percent of organisations were using big data by

>> Tokens are: 
 ['The', 'results', 'indicated', '50', 'percent', 'organisations', 'using', 'big', 'data']

>> Bigrams are: 
 [('The', 'results'), ('results', 'indicated'), ('indicated', '50'), ('50', 'percent'), ('percent', 'organisations'), ('organisations', 'using'), ('using', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'results', 'indicated'), ('results', 'indicated', '50'), ('indicated', '50', 'percent'), ('50', 'percent', 'organisations'), ('percent', 'organisations', 'using'), ('organisations', 'using', 'big'), ('using', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('results', 'NNS'), ('indicated', 'VBD'), ('50', 'CD'), ('percent', 'NN'), ('organisations', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The results', 'percent organisations', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('results', 'result'), ('indicated', 'indic'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organis'), ('using', 'use'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('results', 'result'), ('indicated', 'indic'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organis'), ('using', 'use'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('results', 'result'), ('indicated', 'indicated'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organisation'), ('using', 'using'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1195 ===========================================

2017 (Watson, 2019), as shown in Figure 24.  

------------------- Sentence 1 -------------------

2017 (Watson, 2019), as shown in Figure 24.

>> Tokens are: 
 ['2017', '(', 'Watson', ',', '2019', ')', ',', 'shown', 'Figure', '24', '.']

>> Bigrams are: 
 [('2017', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '24'), ('24', '.')]

>> Trigrams are: 
 [('2017', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '24'), ('Figure', '24', '.')]

>> POS Tags are: 
 [('2017', 'CD'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('24', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Watson', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('2017', '2017'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('24', '24'), ('.', '.')]



========================================== PARAGRAPH 1196 ===========================================

  


========================================== PARAGRAPH 1197 ===========================================

Figure 24: Adoption of Big Data from 2015 to 20173  

------------------- Sentence 1 -------------------

Figure 24: Adoption of Big Data from 2015 to 20173

>> Tokens are: 
 ['Figure', '24', ':', 'Adoption', 'Big', 'Data', '2015', '20173']

>> Bigrams are: 
 [('Figure', '24'), ('24', ':'), (':', 'Adoption'), ('Adoption', 'Big'), ('Big', 'Data'), ('Data', '2015'), ('2015', '20173')]

>> Trigrams are: 
 [('Figure', '24', ':'), ('24', ':', 'Adoption'), (':', 'Adoption', 'Big'), ('Adoption', 'Big', 'Data'), ('Big', 'Data', '2015'), ('Data', '2015', '20173')]

>> POS Tags are: 
 [('Figure', 'NN'), ('24', 'CD'), (':', ':'), ('Adoption', 'NN'), ('Big', 'NNP'), ('Data', 'NNP'), ('2015', 'CD'), ('20173', 'CD')]

>> Noun Phrases are: 
 ['Figure', 'Adoption Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('24', '24'), (':', ':'), ('Adoption', 'adopt'), ('Big', 'big'), ('Data', 'data'), ('2015', '2015'), ('20173', '20173')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('24', '24'), (':', ':'), ('Adoption', 'adopt'), ('Big', 'big'), ('Data', 'data'), ('2015', '2015'), ('20173', '20173')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('24', '24'), (':', ':'), ('Adoption', 'Adoption'), ('Big', 'Big'), ('Data', 'Data'), ('2015', '2015'), ('20173', '20173')]



========================================== PARAGRAPH 1198 ===========================================

The potential key resource of many organisations’ business models is thus big data where such  

------------------- Sentence 1 -------------------

The potential key resource of many organisations’ business models is thus big data where such

>> Tokens are: 
 ['The', 'potential', 'key', 'resource', 'many', 'organisations', '’', 'business', 'models', 'thus', 'big', 'data']

>> Bigrams are: 
 [('The', 'potential'), ('potential', 'key'), ('key', 'resource'), ('resource', 'many'), ('many', 'organisations'), ('organisations', '’'), ('’', 'business'), ('business', 'models'), ('models', 'thus'), ('thus', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'potential', 'key'), ('potential', 'key', 'resource'), ('key', 'resource', 'many'), ('resource', 'many', 'organisations'), ('many', 'organisations', '’'), ('organisations', '’', 'business'), ('’', 'business', 'models'), ('business', 'models', 'thus'), ('models', 'thus', 'big'), ('thus', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('potential', 'JJ'), ('key', 'NN'), ('resource', 'NN'), ('many', 'JJ'), ('organisations', 'NNS'), ('’', 'VBP'), ('business', 'NN'), ('models', 'NNS'), ('thus', 'RB'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The potential key resource', 'many organisations', 'business models', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('key', 'key'), ('resource', 'resourc'), ('many', 'mani'), ('organisations', 'organis'), ('’', '’'), ('business', 'busi'), ('models', 'model'), ('thus', 'thu'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('key', 'key'), ('resource', 'resourc'), ('many', 'mani'), ('organisations', 'organis'), ('’', '’'), ('business', 'busi'), ('models', 'model'), ('thus', 'thus'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('potential', 'potential'), ('key', 'key'), ('resource', 'resource'), ('many', 'many'), ('organisations', 'organisation'), ('’', '’'), ('business', 'business'), ('models', 'model'), ('thus', 'thus'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1199 ===========================================

“business models are reflections of the realized strategy” (Casadesus-Masanell et al., 2010;  

------------------- Sentence 1 -------------------

“business models are reflections of the realized strategy” (Casadesus-Masanell et al., 2010;

>> Tokens are: 
 ['“', 'business', 'models', 'reflections', 'realized', 'strategy', '”', '(', 'Casadesus-Masanell', 'et', 'al.', ',', '2010', ';']

>> Bigrams are: 
 [('“', 'business'), ('business', 'models'), ('models', 'reflections'), ('reflections', 'realized'), ('realized', 'strategy'), ('strategy', '”'), ('”', '('), ('(', 'Casadesus-Masanell'), ('Casadesus-Masanell', 'et'), ('et', 'al.'), ('al.', ','), (',', '2010'), ('2010', ';')]

>> Trigrams are: 
 [('“', 'business', 'models'), ('business', 'models', 'reflections'), ('models', 'reflections', 'realized'), ('reflections', 'realized', 'strategy'), ('realized', 'strategy', '”'), ('strategy', '”', '('), ('”', '(', 'Casadesus-Masanell'), ('(', 'Casadesus-Masanell', 'et'), ('Casadesus-Masanell', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2010'), (',', '2010', ';')]

>> POS Tags are: 
 [('“', 'NN'), ('business', 'NN'), ('models', 'NNS'), ('reflections', 'NNS'), ('realized', 'VBD'), ('strategy', 'NN'), ('”', 'NNP'), ('(', '('), ('Casadesus-Masanell', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2010', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['“ business models reflections', 'strategy ”', 'Casadesus-Masanell', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('business', 'busi'), ('models', 'model'), ('reflections', 'reflect'), ('realized', 'realiz'), ('strategy', 'strategi'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'casadesus-masanel'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('business', 'busi'), ('models', 'model'), ('reflections', 'reflect'), ('realized', 'realiz'), ('strategy', 'strategi'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'casadesus-masanel'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';')]

>> Lemmatization: 
 [('“', '“'), ('business', 'business'), ('models', 'model'), ('reflections', 'reflection'), ('realized', 'realized'), ('strategy', 'strategy'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'Casadesus-Masanell'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';')]



========================================== PARAGRAPH 1200 ===========================================

Günther et al., 2017). Business models represent the ability of the organisation to create and  

------------------- Sentence 1 -------------------

Günther et al., 2017).

>> Tokens are: 
 ['Günther', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Günther', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Günther', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Günther', 'NNP'), ('et', 'CC'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Günther', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Günther', 'Günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Business models represent the ability of the organisation to create and

>> Tokens are: 
 ['Business', 'models', 'represent', 'ability', 'organisation', 'create']

>> Bigrams are: 
 [('Business', 'models'), ('models', 'represent'), ('represent', 'ability'), ('ability', 'organisation'), ('organisation', 'create')]

>> Trigrams are: 
 [('Business', 'models', 'represent'), ('models', 'represent', 'ability'), ('represent', 'ability', 'organisation'), ('ability', 'organisation', 'create')]

>> POS Tags are: 
 [('Business', 'NN'), ('models', 'NNS'), ('represent', 'VBP'), ('ability', 'NN'), ('organisation', 'NN'), ('create', 'NN')]

>> Noun Phrases are: 
 ['Business models', 'ability organisation create']

>> Named Entities are: 
 [('GPE', 'Business')] 

>> Stemming using Porter Stemmer: 
 [('Business', 'busi'), ('models', 'model'), ('represent', 'repres'), ('ability', 'abil'), ('organisation', 'organis'), ('create', 'creat')]

>> Stemming using Snowball Stemmer: 
 [('Business', 'busi'), ('models', 'model'), ('represent', 'repres'), ('ability', 'abil'), ('organisation', 'organis'), ('create', 'creat')]

>> Lemmatization: 
 [('Business', 'Business'), ('models', 'model'), ('represent', 'represent'), ('ability', 'ability'), ('organisation', 'organisation'), ('create', 'create')]



========================================== PARAGRAPH 1201 ===========================================

appropriate value. Organisations must rethink their use of big data in relation to their business  

------------------- Sentence 1 -------------------

appropriate value.

>> Tokens are: 
 ['appropriate', 'value', '.']

>> Bigrams are: 
 [('appropriate', 'value'), ('value', '.')]

>> Trigrams are: 
 [('appropriate', 'value', '.')]

>> POS Tags are: 
 [('appropriate', 'JJ'), ('value', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['appropriate value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('appropriate', 'appropri'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('appropriate', 'appropri'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('appropriate', 'appropriate'), ('value', 'value'), ('.', '.')]


------------------- Sentence 2 -------------------

Organisations must rethink their use of big data in relation to their business

>> Tokens are: 
 ['Organisations', 'must', 'rethink', 'use', 'big', 'data', 'relation', 'business']

>> Bigrams are: 
 [('Organisations', 'must'), ('must', 'rethink'), ('rethink', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'relation'), ('relation', 'business')]

>> Trigrams are: 
 [('Organisations', 'must', 'rethink'), ('must', 'rethink', 'use'), ('rethink', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'relation'), ('data', 'relation', 'business')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('must', 'MD'), ('rethink', 'VB'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('relation', 'NN'), ('business', 'NN')]

>> Noun Phrases are: 
 ['Organisations', 'use', 'big data relation business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relat'), ('business', 'busi')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relat'), ('business', 'busi')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relation'), ('business', 'business')]



========================================== PARAGRAPH 1202 ===========================================

models, using analytics to develop access to new data sources and techniques to improve efficiency  

------------------- Sentence 1 -------------------

models, using analytics to develop access to new data sources and techniques to improve efficiency

>> Tokens are: 
 ['models', ',', 'using', 'analytics', 'develop', 'access', 'new', 'data', 'sources', 'techniques', 'improve', 'efficiency']

>> Bigrams are: 
 [('models', ','), (',', 'using'), ('using', 'analytics'), ('analytics', 'develop'), ('develop', 'access'), ('access', 'new'), ('new', 'data'), ('data', 'sources'), ('sources', 'techniques'), ('techniques', 'improve'), ('improve', 'efficiency')]

>> Trigrams are: 
 [('models', ',', 'using'), (',', 'using', 'analytics'), ('using', 'analytics', 'develop'), ('analytics', 'develop', 'access'), ('develop', 'access', 'new'), ('access', 'new', 'data'), ('new', 'data', 'sources'), ('data', 'sources', 'techniques'), ('sources', 'techniques', 'improve'), ('techniques', 'improve', 'efficiency')]

>> POS Tags are: 
 [('models', 'NNS'), (',', ','), ('using', 'VBG'), ('analytics', 'NNS'), ('develop', 'VB'), ('access', 'NN'), ('new', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('techniques', 'NNS'), ('improve', 'VBP'), ('efficiency', 'NN')]

>> Noun Phrases are: 
 ['models', 'analytics', 'access', 'new data sources techniques', 'efficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('models', 'model'), (',', ','), ('using', 'use'), ('analytics', 'analyt'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'sourc'), ('techniques', 'techniqu'), ('improve', 'improv'), ('efficiency', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('models', 'model'), (',', ','), ('using', 'use'), ('analytics', 'analyt'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'sourc'), ('techniques', 'techniqu'), ('improve', 'improv'), ('efficiency', 'effici')]

>> Lemmatization: 
 [('models', 'model'), (',', ','), ('using', 'using'), ('analytics', 'analytics'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'source'), ('techniques', 'technique'), ('improve', 'improve'), ('efficiency', 'efficiency')]



========================================== PARAGRAPH 1203 ===========================================

and effectiveness (Woerner et al., 2015).  

------------------- Sentence 1 -------------------

and effectiveness (Woerner et al., 2015).

>> Tokens are: 
 ['effectiveness', '(', 'Woerner', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('effectiveness', '('), ('(', 'Woerner'), ('Woerner', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('effectiveness', '(', 'Woerner'), ('(', 'Woerner', 'et'), ('Woerner', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('effectiveness', 'NN'), ('(', '('), ('Woerner', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['effectiveness', 'Woerner']

>> Named Entities are: 
 [('PERSON', 'Woerner')] 

>> Stemming using Porter Stemmer: 
 [('effectiveness', 'effect'), ('(', '('), ('Woerner', 'woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('effectiveness', 'effect'), ('(', '('), ('Woerner', 'woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('effectiveness', 'effectiveness'), ('(', '('), ('Woerner', 'Woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1204 ===========================================

Grover et al. (2018) argued that to achieve strategic business value from big data, significant  

------------------- Sentence 1 -------------------

Grover et al.

>> Tokens are: 
 ['Grover', 'et', 'al', '.']

>> Bigrams are: 
 [('Grover', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Grover', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Grover', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2018) argued that to achieve strategic business value from big data, significant

>> Tokens are: 
 ['(', '2018', ')', 'argued', 'achieve', 'strategic', 'business', 'value', 'big', 'data', ',', 'significant']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'argued'), ('argued', 'achieve'), ('achieve', 'strategic'), ('strategic', 'business'), ('business', 'value'), ('value', 'big'), ('big', 'data'), ('data', ','), (',', 'significant')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'argued'), (')', 'argued', 'achieve'), ('argued', 'achieve', 'strategic'), ('achieve', 'strategic', 'business'), ('strategic', 'business', 'value'), ('business', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'significant')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('argued', 'VBD'), ('achieve', 'JJ'), ('strategic', 'JJ'), ('business', 'NN'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('significant', 'JJ')]

>> Noun Phrases are: 
 ['achieve strategic business value', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('achieve', 'achiev'), ('strategic', 'strateg'), ('business', 'busi'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'signific')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('achieve', 'achiev'), ('strategic', 'strateg'), ('business', 'busi'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'signific')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argued'), ('achieve', 'achieve'), ('strategic', 'strategic'), ('business', 'business'), ('value', 'value'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'significant')]



========================================== PARAGRAPH 1205 ===========================================

investment in both infrastructure and analytic technologies are required to enable skilled analysis  

------------------- Sentence 1 -------------------

investment in both infrastructure and analytic technologies are required to enable skilled analysis

>> Tokens are: 
 ['investment', 'infrastructure', 'analytic', 'technologies', 'required', 'enable', 'skilled', 'analysis']

>> Bigrams are: 
 [('investment', 'infrastructure'), ('infrastructure', 'analytic'), ('analytic', 'technologies'), ('technologies', 'required'), ('required', 'enable'), ('enable', 'skilled'), ('skilled', 'analysis')]

>> Trigrams are: 
 [('investment', 'infrastructure', 'analytic'), ('infrastructure', 'analytic', 'technologies'), ('analytic', 'technologies', 'required'), ('technologies', 'required', 'enable'), ('required', 'enable', 'skilled'), ('enable', 'skilled', 'analysis')]

>> POS Tags are: 
 [('investment', 'NN'), ('infrastructure', 'NN'), ('analytic', 'JJ'), ('technologies', 'NNS'), ('required', 'VBN'), ('enable', 'JJ'), ('skilled', 'JJ'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['investment infrastructure', 'analytic technologies', 'enable skilled analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('investment', 'invest'), ('infrastructure', 'infrastructur'), ('analytic', 'analyt'), ('technologies', 'technolog'), ('required', 'requir'), ('enable', 'enabl'), ('skilled', 'skill'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('investment', 'invest'), ('infrastructure', 'infrastructur'), ('analytic', 'analyt'), ('technologies', 'technolog'), ('required', 'requir'), ('enable', 'enabl'), ('skilled', 'skill'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('investment', 'investment'), ('infrastructure', 'infrastructure'), ('analytic', 'analytic'), ('technologies', 'technology'), ('required', 'required'), ('enable', 'enable'), ('skilled', 'skilled'), ('analysis', 'analysis')]



========================================== PARAGRAPH 1206 ===========================================

and strategic positioning. Businesses thus need to access cutting edge tools and hire data-savvy  

------------------- Sentence 1 -------------------

and strategic positioning.

>> Tokens are: 
 ['strategic', 'positioning', '.']

>> Bigrams are: 
 [('strategic', 'positioning'), ('positioning', '.')]

>> Trigrams are: 
 [('strategic', 'positioning', '.')]

>> POS Tags are: 
 [('strategic', 'JJ'), ('positioning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['strategic positioning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('strategic', 'strateg'), ('positioning', 'posit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('strategic', 'strateg'), ('positioning', 'posit'), ('.', '.')]

>> Lemmatization: 
 [('strategic', 'strategic'), ('positioning', 'positioning'), ('.', '.')]


------------------- Sentence 2 -------------------

Businesses thus need to access cutting edge tools and hire data-savvy

>> Tokens are: 
 ['Businesses', 'thus', 'need', 'access', 'cutting', 'edge', 'tools', 'hire', 'data-savvy']

>> Bigrams are: 
 [('Businesses', 'thus'), ('thus', 'need'), ('need', 'access'), ('access', 'cutting'), ('cutting', 'edge'), ('edge', 'tools'), ('tools', 'hire'), ('hire', 'data-savvy')]

>> Trigrams are: 
 [('Businesses', 'thus', 'need'), ('thus', 'need', 'access'), ('need', 'access', 'cutting'), ('access', 'cutting', 'edge'), ('cutting', 'edge', 'tools'), ('edge', 'tools', 'hire'), ('tools', 'hire', 'data-savvy')]

>> POS Tags are: 
 [('Businesses', 'NNS'), ('thus', 'RB'), ('need', 'VBP'), ('access', 'NN'), ('cutting', 'VBG'), ('edge', 'NN'), ('tools', 'NNS'), ('hire', 'VBP'), ('data-savvy', 'NN')]

>> Noun Phrases are: 
 ['Businesses', 'access', 'edge tools', 'data-savvy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Businesses', 'busi'), ('thus', 'thu'), ('need', 'need'), ('access', 'access'), ('cutting', 'cut'), ('edge', 'edg'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvi')]

>> Stemming using Snowball Stemmer: 
 [('Businesses', 'busi'), ('thus', 'thus'), ('need', 'need'), ('access', 'access'), ('cutting', 'cut'), ('edge', 'edg'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvi')]

>> Lemmatization: 
 [('Businesses', 'Businesses'), ('thus', 'thus'), ('need', 'need'), ('access', 'access'), ('cutting', 'cutting'), ('edge', 'edge'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvy')]



========================================== PARAGRAPH 1207 ===========================================

people who understand the relevant technologies.  

------------------- Sentence 1 -------------------

people who understand the relevant technologies.

>> Tokens are: 
 ['people', 'understand', 'relevant', 'technologies', '.']

>> Bigrams are: 
 [('people', 'understand'), ('understand', 'relevant'), ('relevant', 'technologies'), ('technologies', '.')]

>> Trigrams are: 
 [('people', 'understand', 'relevant'), ('understand', 'relevant', 'technologies'), ('relevant', 'technologies', '.')]

>> POS Tags are: 
 [('people', 'NNS'), ('understand', 'VBP'), ('relevant', 'JJ'), ('technologies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['people', 'relevant technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('people', 'peopl'), ('understand', 'understand'), ('relevant', 'relev'), ('technologies', 'technolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('people', 'peopl'), ('understand', 'understand'), ('relevant', 'relev'), ('technologies', 'technolog'), ('.', '.')]

>> Lemmatization: 
 [('people', 'people'), ('understand', 'understand'), ('relevant', 'relevant'), ('technologies', 'technology'), ('.', '.')]



========================================== PARAGRAPH 1208 ===========================================

Watson (2014) wrote a paper about big data analytics which was published by the association for  

------------------- Sentence 1 -------------------

Watson (2014) wrote a paper about big data analytics which was published by the association for

>> Tokens are: 
 ['Watson', '(', '2014', ')', 'wrote', 'paper', 'big', 'data', 'analytics', 'published', 'association']

>> Bigrams are: 
 [('Watson', '('), ('(', '2014'), ('2014', ')'), (')', 'wrote'), ('wrote', 'paper'), ('paper', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'published'), ('published', 'association')]

>> Trigrams are: 
 [('Watson', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'wrote'), (')', 'wrote', 'paper'), ('wrote', 'paper', 'big'), ('paper', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'published'), ('analytics', 'published', 'association')]

>> POS Tags are: 
 [('Watson', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('wrote', 'VBD'), ('paper', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('published', 'VBN'), ('association', 'NN')]

>> Noun Phrases are: 
 ['Watson', 'paper', 'big data analytics', 'association']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('published', 'publish'), ('association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('published', 'publish'), ('association', 'associ')]

>> Lemmatization: 
 [('Watson', 'Watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('published', 'published'), ('association', 'association')]



========================================== PARAGRAPH 1209 ===========================================

information systems (CAIS). That paper showed the advances in technologies, applications, and  

------------------- Sentence 1 -------------------

information systems (CAIS).

>> Tokens are: 
 ['information', 'systems', '(', 'CAIS', ')', '.']

>> Bigrams are: 
 [('information', 'systems'), ('systems', '('), ('(', 'CAIS'), ('CAIS', ')'), (')', '.')]

>> Trigrams are: 
 [('information', 'systems', '('), ('systems', '(', 'CAIS'), ('(', 'CAIS', ')'), ('CAIS', ')', '.')]

>> POS Tags are: 
 [('information', 'NN'), ('systems', 'NNS'), ('(', '('), ('CAIS', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['information systems', 'CAIS']

>> Named Entities are: 
 [('ORGANIZATION', 'CAIS')] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('systems', 'system'), ('(', '('), ('CAIS', 'cai'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('systems', 'system'), ('(', '('), ('CAIS', 'cai'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), ('systems', 'system'), ('(', '('), ('CAIS', 'CAIS'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

That paper showed the advances in technologies, applications, and

>> Tokens are: 
 ['That', 'paper', 'showed', 'advances', 'technologies', ',', 'applications', ',']

>> Bigrams are: 
 [('That', 'paper'), ('paper', 'showed'), ('showed', 'advances'), ('advances', 'technologies'), ('technologies', ','), (',', 'applications'), ('applications', ',')]

>> Trigrams are: 
 [('That', 'paper', 'showed'), ('paper', 'showed', 'advances'), ('showed', 'advances', 'technologies'), ('advances', 'technologies', ','), ('technologies', ',', 'applications'), (',', 'applications', ',')]

>> POS Tags are: 
 [('That', 'DT'), ('paper', 'NN'), ('showed', 'VBD'), ('advances', 'NNS'), ('technologies', 'NNS'), (',', ','), ('applications', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['That paper', 'advances technologies', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('paper', 'paper'), ('showed', 'show'), ('advances', 'advanc'), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('paper', 'paper'), ('showed', 'show'), ('advances', 'advanc'), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), (',', ',')]

>> Lemmatization: 
 [('That', 'That'), ('paper', 'paper'), ('showed', 'showed'), ('advances', 'advance'), ('technologies', 'technology'), (',', ','), ('applications', 'application'), (',', ',')]



========================================== PARAGRAPH 1210 ===========================================

the impact of big data analytics at that time. In 2019, the same researcher (Watson, 2019)  

------------------- Sentence 1 -------------------

the impact of big data analytics at that time.

>> Tokens are: 
 ['impact', 'big', 'data', 'analytics', 'time', '.']

>> Bigrams are: 
 [('impact', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'time'), ('time', '.')]

>> Trigrams are: 
 [('impact', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'time'), ('analytics', 'time', '.')]

>> POS Tags are: 
 [('impact', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['impact', 'big data analytics time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('time', 'time'), ('.', '.')]


------------------- Sentence 2 -------------------

In 2019, the same researcher (Watson, 2019)

>> Tokens are: 
 ['In', '2019', ',', 'researcher', '(', 'Watson', ',', '2019', ')']

>> Bigrams are: 
 [('In', '2019'), ('2019', ','), (',', 'researcher'), ('researcher', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')')]

>> Trigrams are: 
 [('In', '2019', ','), ('2019', ',', 'researcher'), (',', 'researcher', '('), ('researcher', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')')]

>> POS Tags are: 
 [('In', 'IN'), ('2019', 'CD'), (',', ','), ('researcher', 'NN'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['researcher', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('2019', '2019'), (',', ','), ('researcher', 'research'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('2019', '2019'), (',', ','), ('researcher', 'research'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')')]

>> Lemmatization: 
 [('In', 'In'), ('2019', '2019'), (',', ','), ('researcher', 'researcher'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')')]



========================================== PARAGRAPH 1211 ===========================================

highlighted several important recent developments in big data analytics including   

------------------- Sentence 1 -------------------

highlighted several important recent developments in big data analytics including

>> Tokens are: 
 ['highlighted', 'several', 'important', 'recent', 'developments', 'big', 'data', 'analytics', 'including']

>> Bigrams are: 
 [('highlighted', 'several'), ('several', 'important'), ('important', 'recent'), ('recent', 'developments'), ('developments', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'including')]

>> Trigrams are: 
 [('highlighted', 'several', 'important'), ('several', 'important', 'recent'), ('important', 'recent', 'developments'), ('recent', 'developments', 'big'), ('developments', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'including')]

>> POS Tags are: 
 [('highlighted', 'VBN'), ('several', 'JJ'), ('important', 'JJ'), ('recent', 'JJ'), ('developments', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('including', 'VBG')]

>> Noun Phrases are: 
 ['several important recent developments', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('highlighted', 'highlight'), ('several', 'sever'), ('important', 'import'), ('recent', 'recent'), ('developments', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('including', 'includ')]

>> Stemming using Snowball Stemmer: 
 [('highlighted', 'highlight'), ('several', 'sever'), ('important', 'import'), ('recent', 'recent'), ('developments', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('including', 'includ')]

>> Lemmatization: 
 [('highlighted', 'highlighted'), ('several', 'several'), ('important', 'important'), ('recent', 'recent'), ('developments', 'development'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('including', 'including')]



========================================== PARAGRAPH 1212 ===========================================

                                                  3 Adopted from (Dresner Advisory Services, 2017; Nashua, 2017; Watson, 2019 

------------------- Sentence 1 -------------------

                                                  3 Adopted from (Dresner Advisory Services, 2017; Nashua, 2017; Watson, 2019

>> Tokens are: 
 ['3', 'Adopted', '(', 'Dresner', 'Advisory', 'Services', ',', '2017', ';', 'Nashua', ',', '2017', ';', 'Watson', ',', '2019']

>> Bigrams are: 
 [('3', 'Adopted'), ('Adopted', '('), ('(', 'Dresner'), ('Dresner', 'Advisory'), ('Advisory', 'Services'), ('Services', ','), (',', '2017'), ('2017', ';'), (';', 'Nashua'), ('Nashua', ','), (',', '2017'), ('2017', ';'), (';', 'Watson'), ('Watson', ','), (',', '2019')]

>> Trigrams are: 
 [('3', 'Adopted', '('), ('Adopted', '(', 'Dresner'), ('(', 'Dresner', 'Advisory'), ('Dresner', 'Advisory', 'Services'), ('Advisory', 'Services', ','), ('Services', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Nashua'), (';', 'Nashua', ','), ('Nashua', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Watson'), (';', 'Watson', ','), ('Watson', ',', '2019')]

>> POS Tags are: 
 [('3', 'CD'), ('Adopted', 'NNP'), ('(', '('), ('Dresner', 'NNP'), ('Advisory', 'NNP'), ('Services', 'NNPS'), (',', ','), ('2017', 'CD'), (';', ':'), ('Nashua', 'NNP'), (',', ','), ('2017', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ','), ('2019', 'CD')]

>> Noun Phrases are: 
 ['Adopted', 'Dresner Advisory', 'Nashua', 'Watson']

>> Named Entities are: 
 [('GPE', 'Adopted'), ('ORGANIZATION', 'Dresner Advisory Services'), ('GPE', 'Nashua'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('Adopted', 'adopt'), ('(', '('), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('Adopted', 'adopt'), ('(', '('), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019')]

>> Lemmatization: 
 [('3', '3'), ('Adopted', 'Adopted'), ('(', '('), ('Dresner', 'Dresner'), ('Advisory', 'Advisory'), ('Services', 'Services'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'Nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'Watson'), (',', ','), ('2019', '2019')]



========================================== PARAGRAPH 1213 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1214 ===========================================

43  

------------------- Sentence 1 -------------------

43

>> Tokens are: 
 ['43']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('43', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('43', '43')]

>> Stemming using Snowball Stemmer: 
 [('43', '43')]

>> Lemmatization: 
 [('43', '43')]



========================================== PARAGRAPH 1215 ===========================================

  


========================================== PARAGRAPH 1216 ===========================================

➢ Continued adoption of the big data analytics,  ➢ Growth in the number of big data applications,  ➢ Development of the Hadoop ecosystem technology,  ➢ Data lakes,  ➢ Advanced analytics models, and  ➢ Algorithmic transparency principles.  

------------------- Sentence 1 -------------------

➢ Continued adoption of the big data analytics,  ➢ Growth in the number of big data applications,  ➢ Development of the Hadoop ecosystem technology,  ➢ Data lakes,  ➢ Advanced analytics models, and  ➢ Algorithmic transparency principles.

>> Tokens are: 
 ['➢', 'Continued', 'adoption', 'big', 'data', 'analytics', ',', '➢', 'Growth', 'number', 'big', 'data', 'applications', ',', '➢', 'Development', 'Hadoop', 'ecosystem', 'technology', ',', '➢', 'Data', 'lakes', ',', '➢', 'Advanced', 'analytics', 'models', ',', '➢', 'Algorithmic', 'transparency', 'principles', '.']

>> Bigrams are: 
 [('➢', 'Continued'), ('Continued', 'adoption'), ('adoption', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', '➢'), ('➢', 'Growth'), ('Growth', 'number'), ('number', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', ','), (',', '➢'), ('➢', 'Development'), ('Development', 'Hadoop'), ('Hadoop', 'ecosystem'), ('ecosystem', 'technology'), ('technology', ','), (',', '➢'), ('➢', 'Data'), ('Data', 'lakes'), ('lakes', ','), (',', '➢'), ('➢', 'Advanced'), ('Advanced', 'analytics'), ('analytics', 'models'), ('models', ','), (',', '➢'), ('➢', 'Algorithmic'), ('Algorithmic', 'transparency'), ('transparency', 'principles'), ('principles', '.')]

>> Trigrams are: 
 [('➢', 'Continued', 'adoption'), ('Continued', 'adoption', 'big'), ('adoption', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', '➢'), (',', '➢', 'Growth'), ('➢', 'Growth', 'number'), ('Growth', 'number', 'big'), ('number', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', ','), ('applications', ',', '➢'), (',', '➢', 'Development'), ('➢', 'Development', 'Hadoop'), ('Development', 'Hadoop', 'ecosystem'), ('Hadoop', 'ecosystem', 'technology'), ('ecosystem', 'technology', ','), ('technology', ',', '➢'), (',', '➢', 'Data'), ('➢', 'Data', 'lakes'), ('Data', 'lakes', ','), ('lakes', ',', '➢'), (',', '➢', 'Advanced'), ('➢', 'Advanced', 'analytics'), ('Advanced', 'analytics', 'models'), ('analytics', 'models', ','), ('models', ',', '➢'), (',', '➢', 'Algorithmic'), ('➢', 'Algorithmic', 'transparency'), ('Algorithmic', 'transparency', 'principles'), ('transparency', 'principles', '.')]

>> POS Tags are: 
 [('➢', 'JJ'), ('Continued', 'NNP'), ('adoption', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('➢', 'NNP'), ('Growth', 'NNP'), ('number', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), (',', ','), ('➢', 'NNP'), ('Development', 'NNP'), ('Hadoop', 'NNP'), ('ecosystem', 'NN'), ('technology', 'NN'), (',', ','), ('➢', 'NNP'), ('Data', 'NNP'), ('lakes', 'NNS'), (',', ','), ('➢', 'NNP'), ('Advanced', 'NNP'), ('analytics', 'NNS'), ('models', 'NNS'), (',', ','), ('➢', 'JJ'), ('Algorithmic', 'NNP'), ('transparency', 'NN'), ('principles', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['➢ Continued adoption', 'big data analytics', '➢ Growth number', 'big data applications', '➢ Development Hadoop ecosystem technology', '➢ Data lakes', '➢ Advanced analytics models', '➢ Algorithmic transparency principles']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('Continued', 'continu'), ('adoption', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('➢', '➢'), ('Growth', 'growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('➢', '➢'), ('Development', 'develop'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technolog'), (',', ','), ('➢', '➢'), ('Data', 'data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'advanc'), ('analytics', 'analyt'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'algorithm'), ('transparency', 'transpar'), ('principles', 'principl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('Continued', 'continu'), ('adoption', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('➢', '➢'), ('Growth', 'growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('➢', '➢'), ('Development', 'develop'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technolog'), (',', ','), ('➢', '➢'), ('Data', 'data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'advanc'), ('analytics', 'analyt'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'algorithm'), ('transparency', 'transpar'), ('principles', 'principl'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('Continued', 'Continued'), ('adoption', 'adoption'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('➢', '➢'), ('Growth', 'Growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), (',', ','), ('➢', '➢'), ('Development', 'Development'), ('Hadoop', 'Hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technology'), (',', ','), ('➢', '➢'), ('Data', 'Data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'Advanced'), ('analytics', 'analytics'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'Algorithmic'), ('transparency', 'transparency'), ('principles', 'principle'), ('.', '.')]



========================================== PARAGRAPH 1217 ===========================================

Big data analytics has the potential to be applied to demand forecasting, analysing potential needs  

------------------- Sentence 1 -------------------

Big data analytics has the potential to be applied to demand forecasting, analysing potential needs

>> Tokens are: 
 ['Big', 'data', 'analytics', 'potential', 'applied', 'demand', 'forecasting', ',', 'analysing', 'potential', 'needs']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'potential'), ('potential', 'applied'), ('applied', 'demand'), ('demand', 'forecasting'), ('forecasting', ','), (',', 'analysing'), ('analysing', 'potential'), ('potential', 'needs')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'potential'), ('analytics', 'potential', 'applied'), ('potential', 'applied', 'demand'), ('applied', 'demand', 'forecasting'), ('demand', 'forecasting', ','), ('forecasting', ',', 'analysing'), (',', 'analysing', 'potential'), ('analysing', 'potential', 'needs')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('potential', 'JJ'), ('applied', 'JJ'), ('demand', 'NN'), ('forecasting', 'NN'), (',', ','), ('analysing', 'VBG'), ('potential', 'JJ'), ('needs', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics', 'potential applied demand forecasting', 'potential needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('applied', 'appli'), ('demand', 'demand'), ('forecasting', 'forecast'), (',', ','), ('analysing', 'analys'), ('potential', 'potenti'), ('needs', 'need')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('applied', 'appli'), ('demand', 'demand'), ('forecasting', 'forecast'), (',', ','), ('analysing', 'analys'), ('potential', 'potenti'), ('needs', 'need')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('potential', 'potential'), ('applied', 'applied'), ('demand', 'demand'), ('forecasting', 'forecasting'), (',', ','), ('analysing', 'analysing'), ('potential', 'potential'), ('needs', 'need')]



========================================== PARAGRAPH 1218 ===========================================

based on previous work used to classify analytics techniques (Hofmann et al., 2018).  

------------------- Sentence 1 -------------------

based on previous work used to classify analytics techniques (Hofmann et al., 2018).

>> Tokens are: 
 ['based', 'previous', 'work', 'used', 'classify', 'analytics', 'techniques', '(', 'Hofmann', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('based', 'previous'), ('previous', 'work'), ('work', 'used'), ('used', 'classify'), ('classify', 'analytics'), ('analytics', 'techniques'), ('techniques', '('), ('(', 'Hofmann'), ('Hofmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('based', 'previous', 'work'), ('previous', 'work', 'used'), ('work', 'used', 'classify'), ('used', 'classify', 'analytics'), ('classify', 'analytics', 'techniques'), ('analytics', 'techniques', '('), ('techniques', '(', 'Hofmann'), ('(', 'Hofmann', 'et'), ('Hofmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('based', 'VBN'), ('previous', 'JJ'), ('work', 'NN'), ('used', 'VBN'), ('classify', 'VB'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('(', '('), ('Hofmann', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['previous work', 'analytics techniques', 'Hofmann']

>> Named Entities are: 
 [('PERSON', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('based', 'base'), ('previous', 'previou'), ('work', 'work'), ('used', 'use'), ('classify', 'classifi'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('based', 'base'), ('previous', 'previous'), ('work', 'work'), ('used', 'use'), ('classify', 'classifi'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('based', 'based'), ('previous', 'previous'), ('work', 'work'), ('used', 'used'), ('classify', 'classify'), ('analytics', 'analytics'), ('techniques', 'technique'), ('(', '('), ('Hofmann', 'Hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1219 ===========================================

Big data analytics have also been applied in many areas, serving different sectors.   

------------------- Sentence 1 -------------------

Big data analytics have also been applied in many areas, serving different sectors.

>> Tokens are: 
 ['Big', 'data', 'analytics', 'also', 'applied', 'many', 'areas', ',', 'serving', 'different', 'sectors', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'applied'), ('applied', 'many'), ('many', 'areas'), ('areas', ','), (',', 'serving'), ('serving', 'different'), ('different', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'applied'), ('also', 'applied', 'many'), ('applied', 'many', 'areas'), ('many', 'areas', ','), ('areas', ',', 'serving'), (',', 'serving', 'different'), ('serving', 'different', 'sectors'), ('different', 'sectors', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('applied', 'VBD'), ('many', 'JJ'), ('areas', 'NNS'), (',', ','), ('serving', 'VBG'), ('different', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics', 'many areas', 'different sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('applied', 'appli'), ('many', 'mani'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('applied', 'appli'), ('many', 'mani'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('applied', 'applied'), ('many', 'many'), ('areas', 'area'), (',', ','), ('serving', 'serving'), ('different', 'different'), ('sectors', 'sector'), ('.', '.')]



========================================== PARAGRAPH 1220 ===========================================

  


========================================== PARAGRAPH 1221 ===========================================

Some big data analytics applications:  

------------------- Sentence 1 -------------------

Some big data analytics applications:

>> Tokens are: 
 ['Some', 'big', 'data', 'analytics', 'applications', ':']

>> Bigrams are: 
 [('Some', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', ':')]

>> Trigrams are: 
 [('Some', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', ':')]

>> POS Tags are: 
 [('Some', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['Some big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), (':', ':')]

>> Lemmatization: 
 [('Some', 'Some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), (':', ':')]



========================================== PARAGRAPH 1222 ===========================================

10.1. Healthcare   

------------------- Sentence 1 -------------------

10.1.

>> Tokens are: 
 ['10.1', '.']

>> Bigrams are: 
 [('10.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.1', '10.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.1', '10.1'), ('.', '.')]

>> Lemmatization: 
 [('10.1', '10.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Healthcare

>> Tokens are: 
 ['Healthcare']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Healthcare', 'NN')]

>> Noun Phrases are: 
 ['Healthcare']

>> Named Entities are: 
 [('GPE', 'Healthcare')] 

>> Stemming using Porter Stemmer: 
 [('Healthcare', 'healthcar')]

>> Stemming using Snowball Stemmer: 
 [('Healthcare', 'healthcar')]

>> Lemmatization: 
 [('Healthcare', 'Healthcare')]



========================================== PARAGRAPH 1223 ===========================================

Research by Manyika (2011) showed that big data might help in reducing waste and improving  

------------------- Sentence 1 -------------------

Research by Manyika (2011) showed that big data might help in reducing waste and improving

>> Tokens are: 
 ['Research', 'Manyika', '(', '2011', ')', 'showed', 'big', 'data', 'might', 'help', 'reducing', 'waste', 'improving']

>> Bigrams are: 
 [('Research', 'Manyika'), ('Manyika', '('), ('(', '2011'), ('2011', ')'), (')', 'showed'), ('showed', 'big'), ('big', 'data'), ('data', 'might'), ('might', 'help'), ('help', 'reducing'), ('reducing', 'waste'), ('waste', 'improving')]

>> Trigrams are: 
 [('Research', 'Manyika', '('), ('Manyika', '(', '2011'), ('(', '2011', ')'), ('2011', ')', 'showed'), (')', 'showed', 'big'), ('showed', 'big', 'data'), ('big', 'data', 'might'), ('data', 'might', 'help'), ('might', 'help', 'reducing'), ('help', 'reducing', 'waste'), ('reducing', 'waste', 'improving')]

>> POS Tags are: 
 [('Research', 'NN'), ('Manyika', 'NNP'), ('(', '('), ('2011', 'CD'), (')', ')'), ('showed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('might', 'MD'), ('help', 'VB'), ('reducing', 'VBG'), ('waste', 'NN'), ('improving', 'VBG')]

>> Noun Phrases are: 
 ['Research Manyika', 'big data', 'waste']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Manyika', 'manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reduc'), ('waste', 'wast'), ('improving', 'improv')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Manyika', 'manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reduc'), ('waste', 'wast'), ('improving', 'improv')]

>> Lemmatization: 
 [('Research', 'Research'), ('Manyika', 'Manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'showed'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reducing'), ('waste', 'waste'), ('improving', 'improving')]



========================================== PARAGRAPH 1224 ===========================================

efficiency in clinical operations, research and development, and public health by means of  

------------------- Sentence 1 -------------------

efficiency in clinical operations, research and development, and public health by means of

>> Tokens are: 
 ['efficiency', 'clinical', 'operations', ',', 'research', 'development', ',', 'public', 'health', 'means']

>> Bigrams are: 
 [('efficiency', 'clinical'), ('clinical', 'operations'), ('operations', ','), (',', 'research'), ('research', 'development'), ('development', ','), (',', 'public'), ('public', 'health'), ('health', 'means')]

>> Trigrams are: 
 [('efficiency', 'clinical', 'operations'), ('clinical', 'operations', ','), ('operations', ',', 'research'), (',', 'research', 'development'), ('research', 'development', ','), ('development', ',', 'public'), (',', 'public', 'health'), ('public', 'health', 'means')]

>> POS Tags are: 
 [('efficiency', 'NN'), ('clinical', 'JJ'), ('operations', 'NNS'), (',', ','), ('research', 'NN'), ('development', 'NN'), (',', ','), ('public', 'JJ'), ('health', 'NN'), ('means', 'NNS')]

>> Noun Phrases are: 
 ['efficiency', 'clinical operations', 'research development', 'public health means']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('efficiency', 'effici'), ('clinical', 'clinic'), ('operations', 'oper'), (',', ','), ('research', 'research'), ('development', 'develop'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean')]

>> Stemming using Snowball Stemmer: 
 [('efficiency', 'effici'), ('clinical', 'clinic'), ('operations', 'oper'), (',', ','), ('research', 'research'), ('development', 'develop'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean')]

>> Lemmatization: 
 [('efficiency', 'efficiency'), ('clinical', 'clinical'), ('operations', 'operation'), (',', ','), ('research', 'research'), ('development', 'development'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean')]



========================================== PARAGRAPH 1225 ===========================================

• statistical tools and algorithms;  

------------------- Sentence 1 -------------------

• statistical tools and algorithms;

>> Tokens are: 
 ['•', 'statistical', 'tools', 'algorithms', ';']

>> Bigrams are: 
 [('•', 'statistical'), ('statistical', 'tools'), ('tools', 'algorithms'), ('algorithms', ';')]

>> Trigrams are: 
 [('•', 'statistical', 'tools'), ('statistical', 'tools', 'algorithms'), ('tools', 'algorithms', ';')]

>> POS Tags are: 
 [('•', 'JJ'), ('statistical', 'JJ'), ('tools', 'NNS'), ('algorithms', 'VBP'), (';', ':')]

>> Noun Phrases are: 
 ['• statistical tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('statistical', 'statist'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('statistical', 'statist'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('statistical', 'statistical'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';')]



========================================== PARAGRAPH 1226 ===========================================

• predictive modelling to produce new drugs and devices more quickly;  

------------------- Sentence 1 -------------------

• predictive modelling to produce new drugs and devices more quickly;

>> Tokens are: 
 ['•', 'predictive', 'modelling', 'produce', 'new', 'drugs', 'devices', 'quickly', ';']

>> Bigrams are: 
 [('•', 'predictive'), ('predictive', 'modelling'), ('modelling', 'produce'), ('produce', 'new'), ('new', 'drugs'), ('drugs', 'devices'), ('devices', 'quickly'), ('quickly', ';')]

>> Trigrams are: 
 [('•', 'predictive', 'modelling'), ('predictive', 'modelling', 'produce'), ('modelling', 'produce', 'new'), ('produce', 'new', 'drugs'), ('new', 'drugs', 'devices'), ('drugs', 'devices', 'quickly'), ('devices', 'quickly', ';')]

>> POS Tags are: 
 [('•', 'RB'), ('predictive', 'JJ'), ('modelling', 'VBG'), ('produce', 'VBP'), ('new', 'JJ'), ('drugs', 'NNS'), ('devices', 'NNS'), ('quickly', 'RB'), (';', ':')]

>> Noun Phrases are: 
 ['new drugs devices']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('predictive', 'predict'), ('modelling', 'model'), ('produce', 'produc'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'devic'), ('quickly', 'quickli'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('predictive', 'predict'), ('modelling', 'model'), ('produce', 'produc'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'devic'), ('quickly', 'quick'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('predictive', 'predictive'), ('modelling', 'modelling'), ('produce', 'produce'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'device'), ('quickly', 'quickly'), (';', ';')]



========================================== PARAGRAPH 1227 ===========================================

• analysing records of diseases to improve epidemiology (Elgendy, N. and Elragal, A.,  2014);  

------------------- Sentence 1 -------------------

• analysing records of diseases to improve epidemiology (Elgendy, N. and Elragal, A.,  2014);

>> Tokens are: 
 ['•', 'analysing', 'records', 'diseases', 'improve', 'epidemiology', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', ';']

>> Bigrams are: 
 [('•', 'analysing'), ('analysing', 'records'), ('records', 'diseases'), ('diseases', 'improve'), ('improve', 'epidemiology'), ('epidemiology', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', ';')]

>> Trigrams are: 
 [('•', 'analysing', 'records'), ('analysing', 'records', 'diseases'), ('records', 'diseases', 'improve'), ('diseases', 'improve', 'epidemiology'), ('improve', 'epidemiology', '('), ('epidemiology', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ';')]

>> POS Tags are: 
 [('•', 'NNS'), ('analysing', 'VBG'), ('records', 'NNS'), ('diseases', 'NNS'), ('improve', 'VBP'), ('epidemiology', 'NN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), (';', ':')]

>> Noun Phrases are: 
 ['•', 'records diseases', 'epidemiology', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('analysing', 'analys'), ('records', 'record'), ('diseases', 'diseas'), ('improve', 'improv'), ('epidemiology', 'epidemiolog'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('analysing', 'analys'), ('records', 'record'), ('diseases', 'diseas'), ('improve', 'improv'), ('epidemiology', 'epidemiolog'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('analysing', 'analysing'), ('records', 'record'), ('diseases', 'disease'), ('improve', 'improve'), ('epidemiology', 'epidemiology'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';')]



========================================== PARAGRAPH 1228 ===========================================

• allowing faster development of vaccines; and  

------------------- Sentence 1 -------------------

• allowing faster development of vaccines; and

>> Tokens are: 
 ['•', 'allowing', 'faster', 'development', 'vaccines', ';']

>> Bigrams are: 
 [('•', 'allowing'), ('allowing', 'faster'), ('faster', 'development'), ('development', 'vaccines'), ('vaccines', ';')]

>> Trigrams are: 
 [('•', 'allowing', 'faster'), ('allowing', 'faster', 'development'), ('faster', 'development', 'vaccines'), ('development', 'vaccines', ';')]

>> POS Tags are: 
 [('•', 'NN'), ('allowing', 'VBG'), ('faster', 'RBR'), ('development', 'NN'), ('vaccines', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['•', 'development vaccines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('allowing', 'allow'), ('faster', 'faster'), ('development', 'develop'), ('vaccines', 'vaccin'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('allowing', 'allow'), ('faster', 'faster'), ('development', 'develop'), ('vaccines', 'vaccin'), (';', ';')]

>> Lemmatization: 
 [('•', '•'), ('allowing', 'allowing'), ('faster', 'faster'), ('development', 'development'), ('vaccines', 'vaccine'), (';', ';')]



========================================== PARAGRAPH 1229 ===========================================

• identifying the data relevant to provide services and prevent crises.  

------------------- Sentence 1 -------------------

• identifying the data relevant to provide services and prevent crises.

>> Tokens are: 
 ['•', 'identifying', 'data', 'relevant', 'provide', 'services', 'prevent', 'crises', '.']

>> Bigrams are: 
 [('•', 'identifying'), ('identifying', 'data'), ('data', 'relevant'), ('relevant', 'provide'), ('provide', 'services'), ('services', 'prevent'), ('prevent', 'crises'), ('crises', '.')]

>> Trigrams are: 
 [('•', 'identifying', 'data'), ('identifying', 'data', 'relevant'), ('data', 'relevant', 'provide'), ('relevant', 'provide', 'services'), ('provide', 'services', 'prevent'), ('services', 'prevent', 'crises'), ('prevent', 'crises', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('identifying', 'VBG'), ('data', 'NNS'), ('relevant', 'NN'), ('provide', 'NN'), ('services', 'NNS'), ('prevent', 'NN'), ('crises', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data relevant provide services prevent crises']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('identifying', 'identifi'), ('data', 'data'), ('relevant', 'relev'), ('provide', 'provid'), ('services', 'servic'), ('prevent', 'prevent'), ('crises', 'crise'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('identifying', 'identifi'), ('data', 'data'), ('relevant', 'relev'), ('provide', 'provid'), ('services', 'servic'), ('prevent', 'prevent'), ('crises', 'crise'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('identifying', 'identifying'), ('data', 'data'), ('relevant', 'relevant'), ('provide', 'provide'), ('services', 'service'), ('prevent', 'prevent'), ('crises', 'crisis'), ('.', '.')]



========================================== PARAGRAPH 1230 ===========================================

Raghupathi and Raghupathi (2014) described big data analytics in healthcare and identified several  

------------------- Sentence 1 -------------------

Raghupathi and Raghupathi (2014) described big data analytics in healthcare and identified several

>> Tokens are: 
 ['Raghupathi', 'Raghupathi', '(', '2014', ')', 'described', 'big', 'data', 'analytics', 'healthcare', 'identified', 'several']

>> Bigrams are: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', '('), ('(', '2014'), ('2014', ')'), (')', 'described'), ('described', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'healthcare'), ('healthcare', 'identified'), ('identified', 'several')]

>> Trigrams are: 
 [('Raghupathi', 'Raghupathi', '('), ('Raghupathi', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'described'), (')', 'described', 'big'), ('described', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'healthcare'), ('analytics', 'healthcare', 'identified'), ('healthcare', 'identified', 'several')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('described', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('healthcare', 'VBP'), ('identified', 'VBN'), ('several', 'JJ')]

>> Noun Phrases are: 
 ['Raghupathi Raghupathi', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Raghupathi'), ('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'describ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), ('identified', 'identifi'), ('several', 'sever')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'describ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), ('identified', 'identifi'), ('several', 'sever')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'described'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('healthcare', 'healthcare'), ('identified', 'identified'), ('several', 'several')]



========================================== PARAGRAPH 1231 ===========================================

remaining challenges; big data analytics has the power to develop care, save lives, and minimise  

------------------- Sentence 1 -------------------

remaining challenges; big data analytics has the power to develop care, save lives, and minimise

>> Tokens are: 
 ['remaining', 'challenges', ';', 'big', 'data', 'analytics', 'power', 'develop', 'care', ',', 'save', 'lives', ',', 'minimise']

>> Bigrams are: 
 [('remaining', 'challenges'), ('challenges', ';'), (';', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'power'), ('power', 'develop'), ('develop', 'care'), ('care', ','), (',', 'save'), ('save', 'lives'), ('lives', ','), (',', 'minimise')]

>> Trigrams are: 
 [('remaining', 'challenges', ';'), ('challenges', ';', 'big'), (';', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'power'), ('analytics', 'power', 'develop'), ('power', 'develop', 'care'), ('develop', 'care', ','), ('care', ',', 'save'), (',', 'save', 'lives'), ('save', 'lives', ','), ('lives', ',', 'minimise')]

>> POS Tags are: 
 [('remaining', 'VBG'), ('challenges', 'NNS'), (';', ':'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('power', 'NN'), ('develop', 'NN'), ('care', 'NN'), (',', ','), ('save', 'VBP'), ('lives', 'NNS'), (',', ','), ('minimise', 'NN')]

>> Noun Phrases are: 
 ['challenges', 'big data analytics power develop care', 'lives', 'minimise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('remaining', 'remain'), ('challenges', 'challeng'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('minimise', 'minimis')]

>> Stemming using Snowball Stemmer: 
 [('remaining', 'remain'), ('challenges', 'challeng'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('minimise', 'minimis')]

>> Lemmatization: 
 [('remaining', 'remaining'), ('challenges', 'challenge'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'life'), (',', ','), ('minimise', 'minimise')]



========================================== PARAGRAPH 1232 ===========================================

the costs, using the recent data explosion to extract insights in order to allow healthcare providers  

------------------- Sentence 1 -------------------

the costs, using the recent data explosion to extract insights in order to allow healthcare providers

>> Tokens are: 
 ['costs', ',', 'using', 'recent', 'data', 'explosion', 'extract', 'insights', 'order', 'allow', 'healthcare', 'providers']

>> Bigrams are: 
 [('costs', ','), (',', 'using'), ('using', 'recent'), ('recent', 'data'), ('data', 'explosion'), ('explosion', 'extract'), ('extract', 'insights'), ('insights', 'order'), ('order', 'allow'), ('allow', 'healthcare'), ('healthcare', 'providers')]

>> Trigrams are: 
 [('costs', ',', 'using'), (',', 'using', 'recent'), ('using', 'recent', 'data'), ('recent', 'data', 'explosion'), ('data', 'explosion', 'extract'), ('explosion', 'extract', 'insights'), ('extract', 'insights', 'order'), ('insights', 'order', 'allow'), ('order', 'allow', 'healthcare'), ('allow', 'healthcare', 'providers')]

>> POS Tags are: 
 [('costs', 'NNS'), (',', ','), ('using', 'VBG'), ('recent', 'JJ'), ('data', 'NNS'), ('explosion', 'NN'), ('extract', 'NN'), ('insights', 'NNS'), ('order', 'NN'), ('allow', 'IN'), ('healthcare', 'NN'), ('providers', 'NNS')]

>> Noun Phrases are: 
 ['costs', 'recent data explosion extract insights order', 'healthcare providers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('costs', 'cost'), (',', ','), ('using', 'use'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explos'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcar'), ('providers', 'provid')]

>> Stemming using Snowball Stemmer: 
 [('costs', 'cost'), (',', ','), ('using', 'use'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explos'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcar'), ('providers', 'provid')]

>> Lemmatization: 
 [('costs', 'cost'), (',', ','), ('using', 'using'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explosion'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcare'), ('providers', 'provider')]



========================================== PARAGRAPH 1233 ===========================================

to make better decisions. The potential benefits gained from using big data in healthcare include,  

------------------- Sentence 1 -------------------

to make better decisions.

>> Tokens are: 
 ['make', 'better', 'decisions', '.']

>> Bigrams are: 
 [('make', 'better'), ('better', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('make', 'better', 'decisions'), ('better', 'decisions', '.')]

>> POS Tags are: 
 [('make', 'VB'), ('better', 'JJR'), ('decisions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('make', 'make'), ('better', 'better'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('make', 'make'), ('better', 'better'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('make', 'make'), ('better', 'better'), ('decisions', 'decision'), ('.', '.')]


------------------- Sentence 2 -------------------

The potential benefits gained from using big data in healthcare include,

>> Tokens are: 
 ['The', 'potential', 'benefits', 'gained', 'using', 'big', 'data', 'healthcare', 'include', ',']

>> Bigrams are: 
 [('The', 'potential'), ('potential', 'benefits'), ('benefits', 'gained'), ('gained', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'healthcare'), ('healthcare', 'include'), ('include', ',')]

>> Trigrams are: 
 [('The', 'potential', 'benefits'), ('potential', 'benefits', 'gained'), ('benefits', 'gained', 'using'), ('gained', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'healthcare'), ('data', 'healthcare', 'include'), ('healthcare', 'include', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('potential', 'JJ'), ('benefits', 'NNS'), ('gained', 'VBN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('healthcare', 'NN'), ('include', 'VBP'), (',', ',')]

>> Noun Phrases are: 
 ['The potential benefits', 'big data healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('benefits', 'benefit'), ('gained', 'gain'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcar'), ('include', 'includ'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('benefits', 'benefit'), ('gained', 'gain'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcar'), ('include', 'includ'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('potential', 'potential'), ('benefits', 'benefit'), ('gained', 'gained'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcare'), ('include', 'include'), (',', ',')]



========================================== PARAGRAPH 1234 ===========================================

but are not limited to, discovering diseases quickly, thus making treatment easier and more  

------------------- Sentence 1 -------------------

but are not limited to, discovering diseases quickly, thus making treatment easier and more

>> Tokens are: 
 ['limited', ',', 'discovering', 'diseases', 'quickly', ',', 'thus', 'making', 'treatment', 'easier']

>> Bigrams are: 
 [('limited', ','), (',', 'discovering'), ('discovering', 'diseases'), ('diseases', 'quickly'), ('quickly', ','), (',', 'thus'), ('thus', 'making'), ('making', 'treatment'), ('treatment', 'easier')]

>> Trigrams are: 
 [('limited', ',', 'discovering'), (',', 'discovering', 'diseases'), ('discovering', 'diseases', 'quickly'), ('diseases', 'quickly', ','), ('quickly', ',', 'thus'), (',', 'thus', 'making'), ('thus', 'making', 'treatment'), ('making', 'treatment', 'easier')]

>> POS Tags are: 
 [('limited', 'JJ'), (',', ','), ('discovering', 'VBG'), ('diseases', 'NNS'), ('quickly', 'RB'), (',', ','), ('thus', 'RB'), ('making', 'VBG'), ('treatment', 'NN'), ('easier', 'JJR')]

>> Noun Phrases are: 
 ['diseases', 'treatment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('limited', 'limit'), (',', ','), ('discovering', 'discov'), ('diseases', 'diseas'), ('quickly', 'quickli'), (',', ','), ('thus', 'thu'), ('making', 'make'), ('treatment', 'treatment'), ('easier', 'easier')]

>> Stemming using Snowball Stemmer: 
 [('limited', 'limit'), (',', ','), ('discovering', 'discov'), ('diseases', 'diseas'), ('quickly', 'quick'), (',', ','), ('thus', 'thus'), ('making', 'make'), ('treatment', 'treatment'), ('easier', 'easier')]

>> Lemmatization: 
 [('limited', 'limited'), (',', ','), ('discovering', 'discovering'), ('diseases', 'disease'), ('quickly', 'quickly'), (',', ','), ('thus', 'thus'), ('making', 'making'), ('treatment', 'treatment'), ('easier', 'easier')]



========================================== PARAGRAPH 1235 ===========================================

effective; identifying healthcare fraud quickly in order to manage specific individuals; and  

------------------- Sentence 1 -------------------

effective; identifying healthcare fraud quickly in order to manage specific individuals; and

>> Tokens are: 
 ['effective', ';', 'identifying', 'healthcare', 'fraud', 'quickly', 'order', 'manage', 'specific', 'individuals', ';']

>> Bigrams are: 
 [('effective', ';'), (';', 'identifying'), ('identifying', 'healthcare'), ('healthcare', 'fraud'), ('fraud', 'quickly'), ('quickly', 'order'), ('order', 'manage'), ('manage', 'specific'), ('specific', 'individuals'), ('individuals', ';')]

>> Trigrams are: 
 [('effective', ';', 'identifying'), (';', 'identifying', 'healthcare'), ('identifying', 'healthcare', 'fraud'), ('healthcare', 'fraud', 'quickly'), ('fraud', 'quickly', 'order'), ('quickly', 'order', 'manage'), ('order', 'manage', 'specific'), ('manage', 'specific', 'individuals'), ('specific', 'individuals', ';')]

>> POS Tags are: 
 [('effective', 'JJ'), (';', ':'), ('identifying', 'VBG'), ('healthcare', 'NN'), ('fraud', 'NN'), ('quickly', 'RB'), ('order', 'NN'), ('manage', 'NN'), ('specific', 'JJ'), ('individuals', 'NNS'), (';', ':')]

>> Noun Phrases are: 
 ['healthcare fraud', 'order manage', 'specific individuals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('effective', 'effect'), (';', ';'), ('identifying', 'identifi'), ('healthcare', 'healthcar'), ('fraud', 'fraud'), ('quickly', 'quickli'), ('order', 'order'), ('manage', 'manag'), ('specific', 'specif'), ('individuals', 'individu'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('effective', 'effect'), (';', ';'), ('identifying', 'identifi'), ('healthcare', 'healthcar'), ('fraud', 'fraud'), ('quickly', 'quick'), ('order', 'order'), ('manage', 'manag'), ('specific', 'specif'), ('individuals', 'individu'), (';', ';')]

>> Lemmatization: 
 [('effective', 'effective'), (';', ';'), ('identifying', 'identifying'), ('healthcare', 'healthcare'), ('fraud', 'fraud'), ('quickly', 'quickly'), ('order', 'order'), ('manage', 'manage'), ('specific', 'specific'), ('individuals', 'individual'), (';', ';')]



========================================== PARAGRAPH 1236 ===========================================

improving population health.  

------------------- Sentence 1 -------------------

improving population health.

>> Tokens are: 
 ['improving', 'population', 'health', '.']

>> Bigrams are: 
 [('improving', 'population'), ('population', 'health'), ('health', '.')]

>> Trigrams are: 
 [('improving', 'population', 'health'), ('population', 'health', '.')]

>> POS Tags are: 
 [('improving', 'VBG'), ('population', 'NN'), ('health', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['population health']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('improving', 'improv'), ('population', 'popul'), ('health', 'health'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('improving', 'improv'), ('population', 'popul'), ('health', 'health'), ('.', '.')]

>> Lemmatization: 
 [('improving', 'improving'), ('population', 'population'), ('health', 'health'), ('.', '.')]



========================================== PARAGRAPH 1237 ===========================================

Furthermore, Zhong et al. (2016) presented big data applications in healthcare and showed how  

------------------- Sentence 1 -------------------

Furthermore, Zhong et al.

>> Tokens are: 
 ['Furthermore', ',', 'Zhong', 'et', 'al', '.']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'Zhong'), ('Zhong', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Furthermore', ',', 'Zhong'), (',', 'Zhong', 'et'), ('Zhong', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('Zhong', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhong', 'al']

>> Named Entities are: 
 [('GPE', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('Zhong', 'zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('Zhong', 'zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('Zhong', 'Zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016) presented big data applications in healthcare and showed how

>> Tokens are: 
 ['(', '2016', ')', 'presented', 'big', 'data', 'applications', 'healthcare', 'showed']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', 'healthcare'), ('healthcare', 'showed')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'presented'), (')', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', 'healthcare'), ('applications', 'healthcare', 'showed')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), ('healthcare', 'NN'), ('showed', 'VBD')]

>> Noun Phrases are: 
 ['big data applications healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('healthcare', 'healthcar'), ('showed', 'show')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('healthcare', 'healthcar'), ('showed', 'show')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('healthcare', 'healthcare'), ('showed', 'showed')]



========================================== PARAGRAPH 1238 ===========================================

big data can be embedded into daily life to offer the ability to examine experiences of illness and  

------------------- Sentence 1 -------------------

big data can be embedded into daily life to offer the ability to examine experiences of illness and

>> Tokens are: 
 ['big', 'data', 'embedded', 'daily', 'life', 'offer', 'ability', 'examine', 'experiences', 'illness']

>> Bigrams are: 
 [('big', 'data'), ('data', 'embedded'), ('embedded', 'daily'), ('daily', 'life'), ('life', 'offer'), ('offer', 'ability'), ('ability', 'examine'), ('examine', 'experiences'), ('experiences', 'illness')]

>> Trigrams are: 
 [('big', 'data', 'embedded'), ('data', 'embedded', 'daily'), ('embedded', 'daily', 'life'), ('daily', 'life', 'offer'), ('life', 'offer', 'ability'), ('offer', 'ability', 'examine'), ('ability', 'examine', 'experiences'), ('examine', 'experiences', 'illness')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('embedded', 'VBD'), ('daily', 'JJ'), ('life', 'NN'), ('offer', 'NN'), ('ability', 'NN'), ('examine', 'NN'), ('experiences', 'NNS'), ('illness', 'NN')]

>> Noun Phrases are: 
 ['big data', 'daily life offer ability examine experiences illness']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('embedded', 'embed'), ('daily', 'daili'), ('life', 'life'), ('offer', 'offer'), ('ability', 'abil'), ('examine', 'examin'), ('experiences', 'experi'), ('illness', 'ill')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('embedded', 'embed'), ('daily', 'daili'), ('life', 'life'), ('offer', 'offer'), ('ability', 'abil'), ('examine', 'examin'), ('experiences', 'experi'), ('illness', 'ill')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('embedded', 'embedded'), ('daily', 'daily'), ('life', 'life'), ('offer', 'offer'), ('ability', 'ability'), ('examine', 'examine'), ('experiences', 'experience'), ('illness', 'illness')]



========================================== PARAGRAPH 1239 ===========================================

healthcare. Big data analytics thus have a large impact on the healthcare sector, reducing  

------------------- Sentence 1 -------------------

healthcare.

>> Tokens are: 
 ['healthcare', '.']

>> Bigrams are: 
 [('healthcare', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('healthcare', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('healthcare', 'healthcar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('healthcare', 'healthcar'), ('.', '.')]

>> Lemmatization: 
 [('healthcare', 'healthcare'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics thus have a large impact on the healthcare sector, reducing

>> Tokens are: 
 ['Big', 'data', 'analytics', 'thus', 'large', 'impact', 'healthcare', 'sector', ',', 'reducing']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'large'), ('large', 'impact'), ('impact', 'healthcare'), ('healthcare', 'sector'), ('sector', ','), (',', 'reducing')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'large'), ('thus', 'large', 'impact'), ('large', 'impact', 'healthcare'), ('impact', 'healthcare', 'sector'), ('healthcare', 'sector', ','), ('sector', ',', 'reducing')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('large', 'JJ'), ('impact', 'NN'), ('healthcare', 'NN'), ('sector', 'NN'), (',', ','), ('reducing', 'VBG')]

>> Noun Phrases are: 
 ['Big data analytics', 'large impact healthcare sector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('large', 'larg'), ('impact', 'impact'), ('healthcare', 'healthcar'), ('sector', 'sector'), (',', ','), ('reducing', 'reduc')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('large', 'larg'), ('impact', 'impact'), ('healthcare', 'healthcar'), ('sector', 'sector'), (',', ','), ('reducing', 'reduc')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('large', 'large'), ('impact', 'impact'), ('healthcare', 'healthcare'), ('sector', 'sector'), (',', ','), ('reducing', 'reducing')]



========================================== PARAGRAPH 1240 ===========================================

operational costs and improving patients’ quality of life (Elgendy and Elragal, 2014; Wamba et  

------------------- Sentence 1 -------------------

operational costs and improving patients’ quality of life (Elgendy and Elragal, 2014; Wamba et

>> Tokens are: 
 ['operational', 'costs', 'improving', 'patients', '’', 'quality', 'life', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Wamba', 'et']

>> Bigrams are: 
 [('operational', 'costs'), ('costs', 'improving'), ('improving', 'patients'), ('patients', '’'), ('’', 'quality'), ('quality', 'life'), ('life', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Wamba'), ('Wamba', 'et')]

>> Trigrams are: 
 [('operational', 'costs', 'improving'), ('costs', 'improving', 'patients'), ('improving', 'patients', '’'), ('patients', '’', 'quality'), ('’', 'quality', 'life'), ('quality', 'life', '('), ('life', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Wamba'), (';', 'Wamba', 'et')]

>> POS Tags are: 
 [('operational', 'JJ'), ('costs', 'NNS'), ('improving', 'VBG'), ('patients', 'NNS'), ('’', 'JJ'), ('quality', 'JJ'), ('life', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Wamba', 'NNP'), ('et', 'FW')]

>> Noun Phrases are: 
 ['operational costs', 'patients', '’ quality life', 'Elgendy Elragal', 'Wamba']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Wamba')] 

>> Stemming using Porter Stemmer: 
 [('operational', 'oper'), ('costs', 'cost'), ('improving', 'improv'), ('patients', 'patient'), ('’', '’'), ('quality', 'qualiti'), ('life', 'life'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'wamba'), ('et', 'et')]

>> Stemming using Snowball Stemmer: 
 [('operational', 'oper'), ('costs', 'cost'), ('improving', 'improv'), ('patients', 'patient'), ('’', '’'), ('quality', 'qualiti'), ('life', 'life'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'wamba'), ('et', 'et')]

>> Lemmatization: 
 [('operational', 'operational'), ('costs', 'cost'), ('improving', 'improving'), ('patients', 'patient'), ('’', '’'), ('quality', 'quality'), ('life', 'life'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'Wamba'), ('et', 'et')]



========================================== PARAGRAPH 1241 ===========================================

al., 2017).  

------------------- Sentence 1 -------------------

al., 2017).

>> Tokens are: 
 ['al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1242 ===========================================

10.2. Banking  

------------------- Sentence 1 -------------------

10.2.

>> Tokens are: 
 ['10.2', '.']

>> Bigrams are: 
 [('10.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Lemmatization: 
 [('10.2', '10.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Banking

>> Tokens are: 
 ['Banking']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Banking', 'NN')]

>> Noun Phrases are: 
 ['Banking']

>> Named Entities are: 
 [('GPE', 'Banking')] 

>> Stemming using Porter Stemmer: 
 [('Banking', 'bank')]

>> Stemming using Snowball Stemmer: 
 [('Banking', 'bank')]

>> Lemmatization: 
 [('Banking', 'Banking')]



========================================== PARAGRAPH 1243 ===========================================

Handling massive volumes of data of many different types is not easy. Big data analytics offers  

------------------- Sentence 1 -------------------

Handling massive volumes of data of many different types is not easy.

>> Tokens are: 
 ['Handling', 'massive', 'volumes', 'data', 'many', 'different', 'types', 'easy', '.']

>> Bigrams are: 
 [('Handling', 'massive'), ('massive', 'volumes'), ('volumes', 'data'), ('data', 'many'), ('many', 'different'), ('different', 'types'), ('types', 'easy'), ('easy', '.')]

>> Trigrams are: 
 [('Handling', 'massive', 'volumes'), ('massive', 'volumes', 'data'), ('volumes', 'data', 'many'), ('data', 'many', 'different'), ('many', 'different', 'types'), ('different', 'types', 'easy'), ('types', 'easy', '.')]

>> POS Tags are: 
 [('Handling', 'VBG'), ('massive', 'JJ'), ('volumes', 'NNS'), ('data', 'VBP'), ('many', 'JJ'), ('different', 'JJ'), ('types', 'NNS'), ('easy', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['massive volumes', 'many different types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Handling', 'handl'), ('massive', 'massiv'), ('volumes', 'volum'), ('data', 'data'), ('many', 'mani'), ('different', 'differ'), ('types', 'type'), ('easy', 'easi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Handling', 'handl'), ('massive', 'massiv'), ('volumes', 'volum'), ('data', 'data'), ('many', 'mani'), ('different', 'differ'), ('types', 'type'), ('easy', 'easi'), ('.', '.')]

>> Lemmatization: 
 [('Handling', 'Handling'), ('massive', 'massive'), ('volumes', 'volume'), ('data', 'data'), ('many', 'many'), ('different', 'different'), ('types', 'type'), ('easy', 'easy'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics offers

>> Tokens are: 
 ['Big', 'data', 'analytics', 'offers']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'offers')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'offers')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('offers', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics offers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('offers', 'offer')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('offers', 'offer')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('offers', 'offer')]



========================================== PARAGRAPH 1244 ===========================================

potential benefits to industries such as banking by allowing analysis of customer log files and the  

------------------- Sentence 1 -------------------

potential benefits to industries such as banking by allowing analysis of customer log files and the

>> Tokens are: 
 ['potential', 'benefits', 'industries', 'banking', 'allowing', 'analysis', 'customer', 'log', 'files']

>> Bigrams are: 
 [('potential', 'benefits'), ('benefits', 'industries'), ('industries', 'banking'), ('banking', 'allowing'), ('allowing', 'analysis'), ('analysis', 'customer'), ('customer', 'log'), ('log', 'files')]

>> Trigrams are: 
 [('potential', 'benefits', 'industries'), ('benefits', 'industries', 'banking'), ('industries', 'banking', 'allowing'), ('banking', 'allowing', 'analysis'), ('allowing', 'analysis', 'customer'), ('analysis', 'customer', 'log'), ('customer', 'log', 'files')]

>> POS Tags are: 
 [('potential', 'JJ'), ('benefits', 'NNS'), ('industries', 'NNS'), ('banking', 'VBG'), ('allowing', 'VBG'), ('analysis', 'NN'), ('customer', 'NN'), ('log', 'NN'), ('files', 'NNS')]

>> Noun Phrases are: 
 ['potential benefits industries', 'analysis customer log files']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('potential', 'potenti'), ('benefits', 'benefit'), ('industries', 'industri'), ('banking', 'bank'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file')]

>> Stemming using Snowball Stemmer: 
 [('potential', 'potenti'), ('benefits', 'benefit'), ('industries', 'industri'), ('banking', 'bank'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file')]

>> Lemmatization: 
 [('potential', 'potential'), ('benefits', 'benefit'), ('industries', 'industry'), ('banking', 'banking'), ('allowing', 'allowing'), ('analysis', 'analysis'), ('customer', 'customer'), ('log', 'log'), ('files', 'file')]



========================================== PARAGRAPH 1245 ===========================================

handling of customer interactions. Combining structured and unstructured data types in this way  

------------------- Sentence 1 -------------------

handling of customer interactions.

>> Tokens are: 
 ['handling', 'customer', 'interactions', '.']

>> Bigrams are: 
 [('handling', 'customer'), ('customer', 'interactions'), ('interactions', '.')]

>> Trigrams are: 
 [('handling', 'customer', 'interactions'), ('customer', 'interactions', '.')]

>> POS Tags are: 
 [('handling', 'VBG'), ('customer', 'NN'), ('interactions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['customer interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('handling', 'handl'), ('customer', 'custom'), ('interactions', 'interact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('handling', 'handl'), ('customer', 'custom'), ('interactions', 'interact'), ('.', '.')]

>> Lemmatization: 
 [('handling', 'handling'), ('customer', 'customer'), ('interactions', 'interaction'), ('.', '.')]


------------------- Sentence 2 -------------------

Combining structured and unstructured data types in this way

>> Tokens are: 
 ['Combining', 'structured', 'unstructured', 'data', 'types', 'way']

>> Bigrams are: 
 [('Combining', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'types'), ('types', 'way')]

>> Trigrams are: 
 [('Combining', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', 'types'), ('data', 'types', 'way')]

>> POS Tags are: 
 [('Combining', 'VBG'), ('structured', 'VBN'), ('unstructured', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), ('way', 'NN')]

>> Noun Phrases are: 
 ['unstructured data types way']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Combining', 'combin'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('way', 'way')]

>> Stemming using Snowball Stemmer: 
 [('Combining', 'combin'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('way', 'way')]

>> Lemmatization: 
 [('Combining', 'Combining'), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('types', 'type'), ('way', 'way')]



========================================== PARAGRAPH 1246 ===========================================

can give companies a better view of both their customers and operations (Davenport, T.H. and  

------------------- Sentence 1 -------------------

can give companies a better view of both their customers and operations (Davenport, T.H.

>> Tokens are: 
 ['give', 'companies', 'better', 'view', 'customers', 'operations', '(', 'Davenport', ',', 'T.H', '.']

>> Bigrams are: 
 [('give', 'companies'), ('companies', 'better'), ('better', 'view'), ('view', 'customers'), ('customers', 'operations'), ('operations', '('), ('(', 'Davenport'), ('Davenport', ','), (',', 'T.H'), ('T.H', '.')]

>> Trigrams are: 
 [('give', 'companies', 'better'), ('companies', 'better', 'view'), ('better', 'view', 'customers'), ('view', 'customers', 'operations'), ('customers', 'operations', '('), ('operations', '(', 'Davenport'), ('(', 'Davenport', ','), ('Davenport', ',', 'T.H'), (',', 'T.H', '.')]

>> POS Tags are: 
 [('give', 'NN'), ('companies', 'NNS'), ('better', 'RBR'), ('view', 'NN'), ('customers', 'NNS'), ('operations', 'NNS'), ('(', '('), ('Davenport', 'NNP'), (',', ','), ('T.H', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['give companies', 'view customers operations', 'Davenport', 'T.H']

>> Named Entities are: 
 [('ORGANIZATION', 'Davenport')] 

>> Stemming using Porter Stemmer: 
 [('give', 'give'), ('companies', 'compani'), ('better', 'better'), ('view', 'view'), ('customers', 'custom'), ('operations', 'oper'), ('(', '('), ('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('give', 'give'), ('companies', 'compani'), ('better', 'better'), ('view', 'view'), ('customers', 'custom'), ('operations', 'oper'), ('(', '('), ('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Lemmatization: 
 [('give', 'give'), ('companies', 'company'), ('better', 'better'), ('view', 'view'), ('customers', 'customer'), ('operations', 'operation'), ('(', '('), ('Davenport', 'Davenport'), (',', ','), ('T.H', 'T.H'), ('.', '.')]


------------------- Sentence 2 -------------------

and

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 1247 ===========================================

Dyché, J., 2013). 

------------------- Sentence 1 -------------------

Dyché, J., 2013).

>> Tokens are: 
 ['Dyché', ',', 'J.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Dyché', ','), (',', 'J.'), ('J.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Dyché', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Dyché', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Dyché', 'J.']

>> Named Entities are: 
 [('GPE', 'Dyché')] 

>> Stemming using Porter Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Dyché', 'Dyché'), (',', ','), ('J.', 'J.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1248 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1249 ===========================================

44  

------------------- Sentence 1 -------------------

44

>> Tokens are: 
 ['44']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('44', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('44', '44')]

>> Stemming using Snowball Stemmer: 
 [('44', '44')]

>> Lemmatization: 
 [('44', '44')]



========================================== PARAGRAPH 1250 ===========================================

  


========================================== PARAGRAPH 1251 ===========================================

Analytics offers banks the ability to segment customers depending on their risk profiles, credit  

------------------- Sentence 1 -------------------

Analytics offers banks the ability to segment customers depending on their risk profiles, credit

>> Tokens are: 
 ['Analytics', 'offers', 'banks', 'ability', 'segment', 'customers', 'depending', 'risk', 'profiles', ',', 'credit']

>> Bigrams are: 
 [('Analytics', 'offers'), ('offers', 'banks'), ('banks', 'ability'), ('ability', 'segment'), ('segment', 'customers'), ('customers', 'depending'), ('depending', 'risk'), ('risk', 'profiles'), ('profiles', ','), (',', 'credit')]

>> Trigrams are: 
 [('Analytics', 'offers', 'banks'), ('offers', 'banks', 'ability'), ('banks', 'ability', 'segment'), ('ability', 'segment', 'customers'), ('segment', 'customers', 'depending'), ('customers', 'depending', 'risk'), ('depending', 'risk', 'profiles'), ('risk', 'profiles', ','), ('profiles', ',', 'credit')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('offers', 'NNS'), ('banks', 'NNS'), ('ability', 'NN'), ('segment', 'NN'), ('customers', 'NNS'), ('depending', 'VBG'), ('risk', 'NN'), ('profiles', 'NNS'), (',', ','), ('credit', 'NN')]

>> Noun Phrases are: 
 ['Analytics offers banks ability segment customers', 'risk profiles', 'credit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'abil'), ('segment', 'segment'), ('customers', 'custom'), ('depending', 'depend'), ('risk', 'risk'), ('profiles', 'profil'), (',', ','), ('credit', 'credit')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'abil'), ('segment', 'segment'), ('customers', 'custom'), ('depending', 'depend'), ('risk', 'risk'), ('profiles', 'profil'), (',', ','), ('credit', 'credit')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'ability'), ('segment', 'segment'), ('customers', 'customer'), ('depending', 'depending'), ('risk', 'risk'), ('profiles', 'profile'), (',', ','), ('credit', 'credit')]



========================================== PARAGRAPH 1252 ===========================================

usage, and similar markers, offering products tailored to their needs and ability to handle  

------------------- Sentence 1 -------------------

usage, and similar markers, offering products tailored to their needs and ability to handle

>> Tokens are: 
 ['usage', ',', 'similar', 'markers', ',', 'offering', 'products', 'tailored', 'needs', 'ability', 'handle']

>> Bigrams are: 
 [('usage', ','), (',', 'similar'), ('similar', 'markers'), ('markers', ','), (',', 'offering'), ('offering', 'products'), ('products', 'tailored'), ('tailored', 'needs'), ('needs', 'ability'), ('ability', 'handle')]

>> Trigrams are: 
 [('usage', ',', 'similar'), (',', 'similar', 'markers'), ('similar', 'markers', ','), ('markers', ',', 'offering'), (',', 'offering', 'products'), ('offering', 'products', 'tailored'), ('products', 'tailored', 'needs'), ('tailored', 'needs', 'ability'), ('needs', 'ability', 'handle')]

>> POS Tags are: 
 [('usage', 'NN'), (',', ','), ('similar', 'JJ'), ('markers', 'NNS'), (',', ','), ('offering', 'VBG'), ('products', 'NNS'), ('tailored', 'VBN'), ('needs', 'NNS'), ('ability', 'NN'), ('handle', 'NN')]

>> Noun Phrases are: 
 ['usage', 'similar markers', 'products', 'needs ability handle']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('usage', 'usag'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offer'), ('products', 'product'), ('tailored', 'tailor'), ('needs', 'need'), ('ability', 'abil'), ('handle', 'handl')]

>> Stemming using Snowball Stemmer: 
 [('usage', 'usag'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offer'), ('products', 'product'), ('tailored', 'tailor'), ('needs', 'need'), ('ability', 'abil'), ('handle', 'handl')]

>> Lemmatization: 
 [('usage', 'usage'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offering'), ('products', 'product'), ('tailored', 'tailored'), ('needs', 'need'), ('ability', 'ability'), ('handle', 'handle')]



========================================== PARAGRAPH 1253 ===========================================

money. Analytics are utilized throughout the industry, such as in retail banking operations, where  every customer transaction is tracked and matched to the customer. Banks have adopted new  

------------------- Sentence 1 -------------------

money.

>> Tokens are: 
 ['money', '.']

>> Bigrams are: 
 [('money', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('money', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['money']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('money', 'money'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('money', 'money'), ('.', '.')]

>> Lemmatization: 
 [('money', 'money'), ('.', '.')]


------------------- Sentence 2 -------------------

Analytics are utilized throughout the industry, such as in retail banking operations, where  every customer transaction is tracked and matched to the customer.

>> Tokens are: 
 ['Analytics', 'utilized', 'throughout', 'industry', ',', 'retail', 'banking', 'operations', ',', 'every', 'customer', 'transaction', 'tracked', 'matched', 'customer', '.']

>> Bigrams are: 
 [('Analytics', 'utilized'), ('utilized', 'throughout'), ('throughout', 'industry'), ('industry', ','), (',', 'retail'), ('retail', 'banking'), ('banking', 'operations'), ('operations', ','), (',', 'every'), ('every', 'customer'), ('customer', 'transaction'), ('transaction', 'tracked'), ('tracked', 'matched'), ('matched', 'customer'), ('customer', '.')]

>> Trigrams are: 
 [('Analytics', 'utilized', 'throughout'), ('utilized', 'throughout', 'industry'), ('throughout', 'industry', ','), ('industry', ',', 'retail'), (',', 'retail', 'banking'), ('retail', 'banking', 'operations'), ('banking', 'operations', ','), ('operations', ',', 'every'), (',', 'every', 'customer'), ('every', 'customer', 'transaction'), ('customer', 'transaction', 'tracked'), ('transaction', 'tracked', 'matched'), ('tracked', 'matched', 'customer'), ('matched', 'customer', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('utilized', 'JJ'), ('throughout', 'IN'), ('industry', 'NN'), (',', ','), ('retail', 'JJ'), ('banking', 'NN'), ('operations', 'NNS'), (',', ','), ('every', 'DT'), ('customer', 'NN'), ('transaction', 'NN'), ('tracked', 'VBD'), ('matched', 'JJ'), ('customer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Analytics', 'industry', 'retail banking operations', 'every customer transaction', 'matched customer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('utilized', 'util'), ('throughout', 'throughout'), ('industry', 'industri'), (',', ','), ('retail', 'retail'), ('banking', 'bank'), ('operations', 'oper'), (',', ','), ('every', 'everi'), ('customer', 'custom'), ('transaction', 'transact'), ('tracked', 'track'), ('matched', 'match'), ('customer', 'custom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('utilized', 'util'), ('throughout', 'throughout'), ('industry', 'industri'), (',', ','), ('retail', 'retail'), ('banking', 'bank'), ('operations', 'oper'), (',', ','), ('every', 'everi'), ('customer', 'custom'), ('transaction', 'transact'), ('tracked', 'track'), ('matched', 'match'), ('customer', 'custom'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('utilized', 'utilized'), ('throughout', 'throughout'), ('industry', 'industry'), (',', ','), ('retail', 'retail'), ('banking', 'banking'), ('operations', 'operation'), (',', ','), ('every', 'every'), ('customer', 'customer'), ('transaction', 'transaction'), ('tracked', 'tracked'), ('matched', 'matched'), ('customer', 'customer'), ('.', '.')]


------------------- Sentence 3 -------------------

Banks have adopted new

>> Tokens are: 
 ['Banks', 'adopted', 'new']

>> Bigrams are: 
 [('Banks', 'adopted'), ('adopted', 'new')]

>> Trigrams are: 
 [('Banks', 'adopted', 'new')]

>> POS Tags are: 
 [('Banks', 'NNS'), ('adopted', 'VBD'), ('new', 'JJ')]

>> Noun Phrases are: 
 ['Banks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Banks', 'bank'), ('adopted', 'adopt'), ('new', 'new')]

>> Stemming using Snowball Stemmer: 
 [('Banks', 'bank'), ('adopted', 'adopt'), ('new', 'new')]

>> Lemmatization: 
 [('Banks', 'Banks'), ('adopted', 'adopted'), ('new', 'new')]



========================================== PARAGRAPH 1254 ===========================================

requirements for data science (analytics) in a wise manner to avoid reduced performance, and data  

------------------- Sentence 1 -------------------

requirements for data science (analytics) in a wise manner to avoid reduced performance, and data

>> Tokens are: 
 ['requirements', 'data', 'science', '(', 'analytics', ')', 'wise', 'manner', 'avoid', 'reduced', 'performance', ',', 'data']

>> Bigrams are: 
 [('requirements', 'data'), ('data', 'science'), ('science', '('), ('(', 'analytics'), ('analytics', ')'), (')', 'wise'), ('wise', 'manner'), ('manner', 'avoid'), ('avoid', 'reduced'), ('reduced', 'performance'), ('performance', ','), (',', 'data')]

>> Trigrams are: 
 [('requirements', 'data', 'science'), ('data', 'science', '('), ('science', '(', 'analytics'), ('(', 'analytics', ')'), ('analytics', ')', 'wise'), (')', 'wise', 'manner'), ('wise', 'manner', 'avoid'), ('manner', 'avoid', 'reduced'), ('avoid', 'reduced', 'performance'), ('reduced', 'performance', ','), ('performance', ',', 'data')]

>> POS Tags are: 
 [('requirements', 'NNS'), ('data', 'NNS'), ('science', 'NN'), ('(', '('), ('analytics', 'NNS'), (')', ')'), ('wise', 'VBP'), ('manner', 'NN'), ('avoid', 'NN'), ('reduced', 'VBD'), ('performance', 'NN'), (',', ','), ('data', 'NNS')]

>> Noun Phrases are: 
 ['requirements data science', 'analytics', 'manner avoid', 'performance', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('requirements', 'requir'), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduc'), ('performance', 'perform'), (',', ','), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('requirements', 'requir'), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduc'), ('performance', 'perform'), (',', ','), ('data', 'data')]

>> Lemmatization: 
 [('requirements', 'requirement'), ('data', 'data'), ('science', 'science'), ('(', '('), ('analytics', 'analytics'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduced'), ('performance', 'performance'), (',', ','), ('data', 'data')]



========================================== PARAGRAPH 1255 ===========================================

science (analytics) offers them a resolution to next generation business problems (Banerjee et al.,  

------------------- Sentence 1 -------------------

science (analytics) offers them a resolution to next generation business problems (Banerjee et al.,

>> Tokens are: 
 ['science', '(', 'analytics', ')', 'offers', 'resolution', 'next', 'generation', 'business', 'problems', '(', 'Banerjee', 'et', 'al.', ',']

>> Bigrams are: 
 [('science', '('), ('(', 'analytics'), ('analytics', ')'), (')', 'offers'), ('offers', 'resolution'), ('resolution', 'next'), ('next', 'generation'), ('generation', 'business'), ('business', 'problems'), ('problems', '('), ('(', 'Banerjee'), ('Banerjee', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('science', '(', 'analytics'), ('(', 'analytics', ')'), ('analytics', ')', 'offers'), (')', 'offers', 'resolution'), ('offers', 'resolution', 'next'), ('resolution', 'next', 'generation'), ('next', 'generation', 'business'), ('generation', 'business', 'problems'), ('business', 'problems', '('), ('problems', '(', 'Banerjee'), ('(', 'Banerjee', 'et'), ('Banerjee', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('science', 'NN'), ('(', '('), ('analytics', 'NNS'), (')', ')'), ('offers', 'VBZ'), ('resolution', 'NN'), ('next', 'JJ'), ('generation', 'NN'), ('business', 'NN'), ('problems', 'NNS'), ('(', '('), ('Banerjee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['science', 'analytics', 'resolution', 'next generation business problems', 'Banerjee']

>> Named Entities are: 
 [('ORGANIZATION', 'Banerjee')] 

>> Stemming using Porter Stemmer: 
 [('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolut'), ('next', 'next'), ('generation', 'gener'), ('business', 'busi'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolut'), ('next', 'next'), ('generation', 'generat'), ('business', 'busi'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('science', 'science'), ('(', '('), ('analytics', 'analytics'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolution'), ('next', 'next'), ('generation', 'generation'), ('business', 'business'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'Banerjee'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 1256 ===========================================

2013).  

------------------- Sentence 1 -------------------

2013).

>> Tokens are: 
 ['2013', ')', '.']

>> Bigrams are: 
 [('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('2013', ')', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1257 ===========================================

Due to the massive number of transactions and activities in financial institutions such as banks,  

------------------- Sentence 1 -------------------

Due to the massive number of transactions and activities in financial institutions such as banks,

>> Tokens are: 
 ['Due', 'massive', 'number', 'transactions', 'activities', 'financial', 'institutions', 'banks', ',']

>> Bigrams are: 
 [('Due', 'massive'), ('massive', 'number'), ('number', 'transactions'), ('transactions', 'activities'), ('activities', 'financial'), ('financial', 'institutions'), ('institutions', 'banks'), ('banks', ',')]

>> Trigrams are: 
 [('Due', 'massive', 'number'), ('massive', 'number', 'transactions'), ('number', 'transactions', 'activities'), ('transactions', 'activities', 'financial'), ('activities', 'financial', 'institutions'), ('financial', 'institutions', 'banks'), ('institutions', 'banks', ',')]

>> POS Tags are: 
 [('Due', 'JJ'), ('massive', 'JJ'), ('number', 'NN'), ('transactions', 'NNS'), ('activities', 'NNS'), ('financial', 'JJ'), ('institutions', 'NNS'), ('banks', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Due massive number transactions activities', 'financial institutions banks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('massive', 'massiv'), ('number', 'number'), ('transactions', 'transact'), ('activities', 'activ'), ('financial', 'financi'), ('institutions', 'institut'), ('banks', 'bank'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('massive', 'massiv'), ('number', 'number'), ('transactions', 'transact'), ('activities', 'activ'), ('financial', 'financi'), ('institutions', 'institut'), ('banks', 'bank'), (',', ',')]

>> Lemmatization: 
 [('Due', 'Due'), ('massive', 'massive'), ('number', 'number'), ('transactions', 'transaction'), ('activities', 'activity'), ('financial', 'financial'), ('institutions', 'institution'), ('banks', 'bank'), (',', ',')]



========================================== PARAGRAPH 1258 ===========================================

big data development is inevitable, and this directly impacts on the management of scarce  

------------------- Sentence 1 -------------------

big data development is inevitable, and this directly impacts on the management of scarce

>> Tokens are: 
 ['big', 'data', 'development', 'inevitable', ',', 'directly', 'impacts', 'management', 'scarce']

>> Bigrams are: 
 [('big', 'data'), ('data', 'development'), ('development', 'inevitable'), ('inevitable', ','), (',', 'directly'), ('directly', 'impacts'), ('impacts', 'management'), ('management', 'scarce')]

>> Trigrams are: 
 [('big', 'data', 'development'), ('data', 'development', 'inevitable'), ('development', 'inevitable', ','), ('inevitable', ',', 'directly'), (',', 'directly', 'impacts'), ('directly', 'impacts', 'management'), ('impacts', 'management', 'scarce')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('development', 'NN'), ('inevitable', 'JJ'), (',', ','), ('directly', 'RB'), ('impacts', 'VBZ'), ('management', 'NN'), ('scarce', 'NN')]

>> Noun Phrases are: 
 ['big data development', 'management scarce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('development', 'develop'), ('inevitable', 'inevit'), (',', ','), ('directly', 'directli'), ('impacts', 'impact'), ('management', 'manag'), ('scarce', 'scarc')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('development', 'develop'), ('inevitable', 'inevit'), (',', ','), ('directly', 'direct'), ('impacts', 'impact'), ('management', 'manag'), ('scarce', 'scarc')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('development', 'development'), ('inevitable', 'inevitable'), (',', ','), ('directly', 'directly'), ('impacts', 'impact'), ('management', 'management'), ('scarce', 'scarce')]



========================================== PARAGRAPH 1259 ===========================================

resources by individuals, groups, and organisations. Big data analytics is thus used by the financial  

------------------- Sentence 1 -------------------

resources by individuals, groups, and organisations.

>> Tokens are: 
 ['resources', 'individuals', ',', 'groups', ',', 'organisations', '.']

>> Bigrams are: 
 [('resources', 'individuals'), ('individuals', ','), (',', 'groups'), ('groups', ','), (',', 'organisations'), ('organisations', '.')]

>> Trigrams are: 
 [('resources', 'individuals', ','), ('individuals', ',', 'groups'), (',', 'groups', ','), ('groups', ',', 'organisations'), (',', 'organisations', '.')]

>> POS Tags are: 
 [('resources', 'NNS'), ('individuals', 'NNS'), (',', ','), ('groups', 'NNS'), (',', ','), ('organisations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['resources individuals', 'groups', 'organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('resources', 'resourc'), ('individuals', 'individu'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('resources', 'resourc'), ('individuals', 'individu'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organis'), ('.', '.')]

>> Lemmatization: 
 [('resources', 'resource'), ('individuals', 'individual'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organisation'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics is thus used by the financial

>> Tokens are: 
 ['Big', 'data', 'analytics', 'thus', 'used', 'financial']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'used'), ('used', 'financial')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'used'), ('thus', 'used', 'financial')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('used', 'VBN'), ('financial', 'JJ')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('used', 'use'), ('financial', 'financi')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('used', 'use'), ('financial', 'financi')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('used', 'used'), ('financial', 'financial')]



========================================== PARAGRAPH 1260 ===========================================

service sector to predict client behaviours and to gain advantages based on understanding  

------------------- Sentence 1 -------------------

service sector to predict client behaviours and to gain advantages based on understanding

>> Tokens are: 
 ['service', 'sector', 'predict', 'client', 'behaviours', 'gain', 'advantages', 'based', 'understanding']

>> Bigrams are: 
 [('service', 'sector'), ('sector', 'predict'), ('predict', 'client'), ('client', 'behaviours'), ('behaviours', 'gain'), ('gain', 'advantages'), ('advantages', 'based'), ('based', 'understanding')]

>> Trigrams are: 
 [('service', 'sector', 'predict'), ('sector', 'predict', 'client'), ('predict', 'client', 'behaviours'), ('client', 'behaviours', 'gain'), ('behaviours', 'gain', 'advantages'), ('gain', 'advantages', 'based'), ('advantages', 'based', 'understanding')]

>> POS Tags are: 
 [('service', 'NN'), ('sector', 'NN'), ('predict', 'VBP'), ('client', 'NN'), ('behaviours', 'NNS'), ('gain', 'VBP'), ('advantages', 'NNS'), ('based', 'VBN'), ('understanding', 'NN')]

>> Noun Phrases are: 
 ['service sector', 'client behaviours', 'advantages', 'understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('service', 'servic'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantag'), ('based', 'base'), ('understanding', 'understand')]

>> Stemming using Snowball Stemmer: 
 [('service', 'servic'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantag'), ('based', 'base'), ('understanding', 'understand')]

>> Lemmatization: 
 [('service', 'service'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantage'), ('based', 'based'), ('understanding', 'understanding')]



========================================== PARAGRAPH 1261 ===========================================

customers and employees (Zhong et al., 2016; Breed and Verster, 2019; Rana, 2019).  

------------------- Sentence 1 -------------------

customers and employees (Zhong et al., 2016; Breed and Verster, 2019; Rana, 2019).

>> Tokens are: 
 ['customers', 'employees', '(', 'Zhong', 'et', 'al.', ',', '2016', ';', 'Breed', 'Verster', ',', '2019', ';', 'Rana', ',', '2019', ')', '.']

>> Bigrams are: 
 [('customers', 'employees'), ('employees', '('), ('(', 'Zhong'), ('Zhong', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ';'), (';', 'Rana'), ('Rana', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('customers', 'employees', '('), ('employees', '(', 'Zhong'), ('(', 'Zhong', 'et'), ('Zhong', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ';'), ('2019', ';', 'Rana'), (';', 'Rana', ','), ('Rana', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('customers', 'NNS'), ('employees', 'NNS'), ('(', '('), ('Zhong', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (';', ':'), ('Rana', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['customers employees', 'Zhong', 'Breed Verster', 'Rana']

>> Named Entities are: 
 [('PERSON', 'Zhong'), ('PERSON', 'Breed Verster'), ('GPE', 'Rana')] 

>> Stemming using Porter Stemmer: 
 [('customers', 'custom'), ('employees', 'employe'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('customers', 'custom'), ('employees', 'employe'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('customers', 'customer'), ('employees', 'employee'), ('(', '('), ('Zhong', 'Zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'Rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1262 ===========================================

Big data analytics is used widely in the field: McKinsey & Company, a global management  

------------------- Sentence 1 -------------------

Big data analytics is used widely in the field: McKinsey & Company, a global management

>> Tokens are: 
 ['Big', 'data', 'analytics', 'used', 'widely', 'field', ':', 'McKinsey', '&', 'Company', ',', 'global', 'management']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'widely'), ('widely', 'field'), ('field', ':'), (':', 'McKinsey'), ('McKinsey', '&'), ('&', 'Company'), ('Company', ','), (',', 'global'), ('global', 'management')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'widely'), ('used', 'widely', 'field'), ('widely', 'field', ':'), ('field', ':', 'McKinsey'), (':', 'McKinsey', '&'), ('McKinsey', '&', 'Company'), ('&', 'Company', ','), ('Company', ',', 'global'), (',', 'global', 'management')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('widely', 'RB'), ('field', 'NN'), (':', ':'), ('McKinsey', 'NNP'), ('&', 'CC'), ('Company', 'NNP'), (',', ','), ('global', 'JJ'), ('management', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics', 'field', 'McKinsey', 'Company', 'global management']

>> Named Entities are: 
 [('ORGANIZATION', 'McKinsey'), ('ORGANIZATION', 'Company')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('widely', 'wide'), ('field', 'field'), (':', ':'), ('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), (',', ','), ('global', 'global'), ('management', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('widely', 'wide'), ('field', 'field'), (':', ':'), ('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), (',', ','), ('global', 'global'), ('management', 'manag')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('widely', 'widely'), ('field', 'field'), (':', ':'), ('McKinsey', 'McKinsey'), ('&', '&'), ('Company', 'Company'), (',', ','), ('global', 'global'), ('management', 'management')]



========================================== PARAGRAPH 1263 ===========================================

consulting company, uses big data analytics to develop its services and to improve service  

------------------- Sentence 1 -------------------

consulting company, uses big data analytics to develop its services and to improve service

>> Tokens are: 
 ['consulting', 'company', ',', 'uses', 'big', 'data', 'analytics', 'develop', 'services', 'improve', 'service']

>> Bigrams are: 
 [('consulting', 'company'), ('company', ','), (',', 'uses'), ('uses', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'develop'), ('develop', 'services'), ('services', 'improve'), ('improve', 'service')]

>> Trigrams are: 
 [('consulting', 'company', ','), ('company', ',', 'uses'), (',', 'uses', 'big'), ('uses', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'develop'), ('analytics', 'develop', 'services'), ('develop', 'services', 'improve'), ('services', 'improve', 'service')]

>> POS Tags are: 
 [('consulting', 'VBG'), ('company', 'NN'), (',', ','), ('uses', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('develop', 'VB'), ('services', 'NNS'), ('improve', 'VB'), ('service', 'NN')]

>> Noun Phrases are: 
 ['company', 'big data analytics', 'services', 'service']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('consulting', 'consult'), ('company', 'compani'), (',', ','), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('develop', 'develop'), ('services', 'servic'), ('improve', 'improv'), ('service', 'servic')]

>> Stemming using Snowball Stemmer: 
 [('consulting', 'consult'), ('company', 'compani'), (',', ','), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('develop', 'develop'), ('services', 'servic'), ('improve', 'improv'), ('service', 'servic')]

>> Lemmatization: 
 [('consulting', 'consulting'), ('company', 'company'), (',', ','), ('uses', 'us'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('develop', 'develop'), ('services', 'service'), ('improve', 'improve'), ('service', 'service')]



========================================== PARAGRAPH 1264 ===========================================

performance. This company uses big data analytics to analyse consumer behaviours to upgrade  

------------------- Sentence 1 -------------------

performance.

>> Tokens are: 
 ['performance', '.']

>> Bigrams are: 
 [('performance', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('performance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('performance', 'performance'), ('.', '.')]


------------------- Sentence 2 -------------------

This company uses big data analytics to analyse consumer behaviours to upgrade

>> Tokens are: 
 ['This', 'company', 'uses', 'big', 'data', 'analytics', 'analyse', 'consumer', 'behaviours', 'upgrade']

>> Bigrams are: 
 [('This', 'company'), ('company', 'uses'), ('uses', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'analyse'), ('analyse', 'consumer'), ('consumer', 'behaviours'), ('behaviours', 'upgrade')]

>> Trigrams are: 
 [('This', 'company', 'uses'), ('company', 'uses', 'big'), ('uses', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'analyse'), ('analytics', 'analyse', 'consumer'), ('analyse', 'consumer', 'behaviours'), ('consumer', 'behaviours', 'upgrade')]

>> POS Tags are: 
 [('This', 'DT'), ('company', 'NN'), ('uses', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('analyse', 'JJ'), ('consumer', 'NN'), ('behaviours', 'NNS'), ('upgrade', 'VBP')]

>> Noun Phrases are: 
 ['This company', 'big data analytics', 'analyse consumer behaviours']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('company', 'compani'), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('consumer', 'consum'), ('behaviours', 'behaviour'), ('upgrade', 'upgrad')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('company', 'compani'), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('consumer', 'consum'), ('behaviours', 'behaviour'), ('upgrade', 'upgrad')]

>> Lemmatization: 
 [('This', 'This'), ('company', 'company'), ('uses', 'us'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('analyse', 'analyse'), ('consumer', 'consumer'), ('behaviours', 'behaviour'), ('upgrade', 'upgrade')]



========================================== PARAGRAPH 1265 ===========================================

services and to forecast customer behaviours, to allow fraud detection, and to determine financial  

------------------- Sentence 1 -------------------

services and to forecast customer behaviours, to allow fraud detection, and to determine financial

>> Tokens are: 
 ['services', 'forecast', 'customer', 'behaviours', ',', 'allow', 'fraud', 'detection', ',', 'determine', 'financial']

>> Bigrams are: 
 [('services', 'forecast'), ('forecast', 'customer'), ('customer', 'behaviours'), ('behaviours', ','), (',', 'allow'), ('allow', 'fraud'), ('fraud', 'detection'), ('detection', ','), (',', 'determine'), ('determine', 'financial')]

>> Trigrams are: 
 [('services', 'forecast', 'customer'), ('forecast', 'customer', 'behaviours'), ('customer', 'behaviours', ','), ('behaviours', ',', 'allow'), (',', 'allow', 'fraud'), ('allow', 'fraud', 'detection'), ('fraud', 'detection', ','), ('detection', ',', 'determine'), (',', 'determine', 'financial')]

>> POS Tags are: 
 [('services', 'NNS'), ('forecast', 'VBP'), ('customer', 'NN'), ('behaviours', 'NN'), (',', ','), ('allow', 'VB'), ('fraud', 'NN'), ('detection', 'NN'), (',', ','), ('determine', 'VBP'), ('financial', 'JJ')]

>> Noun Phrases are: 
 ['services', 'customer behaviours', 'fraud detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('services', 'servic'), ('forecast', 'forecast'), ('customer', 'custom'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detect'), (',', ','), ('determine', 'determin'), ('financial', 'financi')]

>> Stemming using Snowball Stemmer: 
 [('services', 'servic'), ('forecast', 'forecast'), ('customer', 'custom'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detect'), (',', ','), ('determine', 'determin'), ('financial', 'financi')]

>> Lemmatization: 
 [('services', 'service'), ('forecast', 'forecast'), ('customer', 'customer'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detection'), (',', ','), ('determine', 'determine'), ('financial', 'financial')]



========================================== PARAGRAPH 1266 ===========================================

risk assessments (Zhong et al., 2016).  

------------------- Sentence 1 -------------------

risk assessments (Zhong et al., 2016).

>> Tokens are: 
 ['risk', 'assessments', '(', 'Zhong', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('risk', 'assessments'), ('assessments', '('), ('(', 'Zhong'), ('Zhong', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('risk', 'assessments', '('), ('assessments', '(', 'Zhong'), ('(', 'Zhong', 'et'), ('Zhong', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('risk', 'NN'), ('assessments', 'NNS'), ('(', '('), ('Zhong', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['risk assessments', 'Zhong']

>> Named Entities are: 
 [('PERSON', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('risk', 'risk'), ('assessments', 'assess'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('risk', 'risk'), ('assessments', 'assess'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('risk', 'risk'), ('assessments', 'assessment'), ('(', '('), ('Zhong', 'Zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1267 ===========================================

10.3. Retail  

------------------- Sentence 1 -------------------

10.3.

>> Tokens are: 
 ['10.3', '.']

>> Bigrams are: 
 [('10.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Lemmatization: 
 [('10.3', '10.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Retail

>> Tokens are: 
 ['Retail']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Retail', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Retail')] 

>> Stemming using Porter Stemmer: 
 [('Retail', 'retail')]

>> Stemming using Snowball Stemmer: 
 [('Retail', 'retail')]

>> Lemmatization: 
 [('Retail', 'Retail')]



========================================== PARAGRAPH 1268 ===========================================

Big data analytics has a massive impact on retail industries, improving the customer experience  

------------------- Sentence 1 -------------------

Big data analytics has a massive impact on retail industries, improving the customer experience

>> Tokens are: 
 ['Big', 'data', 'analytics', 'massive', 'impact', 'retail', 'industries', ',', 'improving', 'customer', 'experience']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'massive'), ('massive', 'impact'), ('impact', 'retail'), ('retail', 'industries'), ('industries', ','), (',', 'improving'), ('improving', 'customer'), ('customer', 'experience')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'massive'), ('analytics', 'massive', 'impact'), ('massive', 'impact', 'retail'), ('impact', 'retail', 'industries'), ('retail', 'industries', ','), ('industries', ',', 'improving'), (',', 'improving', 'customer'), ('improving', 'customer', 'experience')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('massive', 'JJ'), ('impact', 'NN'), ('retail', 'JJ'), ('industries', 'NNS'), (',', ','), ('improving', 'VBG'), ('customer', 'NN'), ('experience', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics', 'massive impact', 'retail industries', 'customer experience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('massive', 'massiv'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industri'), (',', ','), ('improving', 'improv'), ('customer', 'custom'), ('experience', 'experi')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('massive', 'massiv'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industri'), (',', ','), ('improving', 'improv'), ('customer', 'custom'), ('experience', 'experi')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('massive', 'massive'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industry'), (',', ','), ('improving', 'improving'), ('customer', 'customer'), ('experience', 'experience')]



========================================== PARAGRAPH 1269 ===========================================

and reducing fraud (Wamba et al., 2017).  

------------------- Sentence 1 -------------------

and reducing fraud (Wamba et al., 2017).

>> Tokens are: 
 ['reducing', 'fraud', '(', 'Wamba', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('reducing', 'fraud'), ('fraud', '('), ('(', 'Wamba'), ('Wamba', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('reducing', 'fraud', '('), ('fraud', '(', 'Wamba'), ('(', 'Wamba', 'et'), ('Wamba', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('reducing', 'VBG'), ('fraud', 'NN'), ('(', '('), ('Wamba', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['fraud', 'Wamba']

>> Named Entities are: 
 [('PERSON', 'Wamba')] 

>> Stemming using Porter Stemmer: 
 [('reducing', 'reduc'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reducing', 'reduc'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('reducing', 'reducing'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'Wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1270 ===========================================

The retail sector is of major importance in modern society, as almost everyone nowadays musy  

------------------- Sentence 1 -------------------

The retail sector is of major importance in modern society, as almost everyone nowadays musy

>> Tokens are: 
 ['The', 'retail', 'sector', 'major', 'importance', 'modern', 'society', ',', 'almost', 'everyone', 'nowadays', 'musy']

>> Bigrams are: 
 [('The', 'retail'), ('retail', 'sector'), ('sector', 'major'), ('major', 'importance'), ('importance', 'modern'), ('modern', 'society'), ('society', ','), (',', 'almost'), ('almost', 'everyone'), ('everyone', 'nowadays'), ('nowadays', 'musy')]

>> Trigrams are: 
 [('The', 'retail', 'sector'), ('retail', 'sector', 'major'), ('sector', 'major', 'importance'), ('major', 'importance', 'modern'), ('importance', 'modern', 'society'), ('modern', 'society', ','), ('society', ',', 'almost'), (',', 'almost', 'everyone'), ('almost', 'everyone', 'nowadays'), ('everyone', 'nowadays', 'musy')]

>> POS Tags are: 
 [('The', 'DT'), ('retail', 'JJ'), ('sector', 'NN'), ('major', 'JJ'), ('importance', 'NN'), ('modern', 'JJ'), ('society', 'NN'), (',', ','), ('almost', 'RB'), ('everyone', 'NN'), ('nowadays', 'JJ'), ('musy', 'NN')]

>> Noun Phrases are: 
 ['The retail sector', 'major importance', 'modern society', 'everyone', 'nowadays musy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'import'), ('modern', 'modern'), ('society', 'societi'), (',', ','), ('almost', 'almost'), ('everyone', 'everyon'), ('nowadays', 'nowaday'), ('musy', 'musi')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'import'), ('modern', 'modern'), ('society', 'societi'), (',', ','), ('almost', 'almost'), ('everyone', 'everyon'), ('nowadays', 'nowaday'), ('musy', 'musi')]

>> Lemmatization: 
 [('The', 'The'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'importance'), ('modern', 'modern'), ('society', 'society'), (',', ','), ('almost', 'almost'), ('everyone', 'everyone'), ('nowadays', 'nowadays'), ('musy', 'musy')]



========================================== PARAGRAPH 1271 ===========================================

buy their basic needs. Predicting demand for items allows retailers to offer better services to  

------------------- Sentence 1 -------------------

buy their basic needs.

>> Tokens are: 
 ['buy', 'basic', 'needs', '.']

>> Bigrams are: 
 [('buy', 'basic'), ('basic', 'needs'), ('needs', '.')]

>> Trigrams are: 
 [('buy', 'basic', 'needs'), ('basic', 'needs', '.')]

>> POS Tags are: 
 [('buy', 'VB'), ('basic', 'JJ'), ('needs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['basic needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]

>> Lemmatization: 
 [('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]


------------------- Sentence 2 -------------------

Predicting demand for items allows retailers to offer better services to

>> Tokens are: 
 ['Predicting', 'demand', 'items', 'allows', 'retailers', 'offer', 'better', 'services']

>> Bigrams are: 
 [('Predicting', 'demand'), ('demand', 'items'), ('items', 'allows'), ('allows', 'retailers'), ('retailers', 'offer'), ('offer', 'better'), ('better', 'services')]

>> Trigrams are: 
 [('Predicting', 'demand', 'items'), ('demand', 'items', 'allows'), ('items', 'allows', 'retailers'), ('allows', 'retailers', 'offer'), ('retailers', 'offer', 'better'), ('offer', 'better', 'services')]

>> POS Tags are: 
 [('Predicting', 'VBG'), ('demand', 'NN'), ('items', 'NNS'), ('allows', 'VBZ'), ('retailers', 'NNS'), ('offer', 'VBP'), ('better', 'JJR'), ('services', 'NNS')]

>> Noun Phrases are: 
 ['demand items', 'retailers', 'services']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predicting', 'predict'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allow'), ('retailers', 'retail'), ('offer', 'offer'), ('better', 'better'), ('services', 'servic')]

>> Stemming using Snowball Stemmer: 
 [('Predicting', 'predict'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allow'), ('retailers', 'retail'), ('offer', 'offer'), ('better', 'better'), ('services', 'servic')]

>> Lemmatization: 
 [('Predicting', 'Predicting'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allows'), ('retailers', 'retailer'), ('offer', 'offer'), ('better', 'better'), ('services', 'service')]



========================================== PARAGRAPH 1272 ===========================================

customers (Singh et al., 2015; Lekhwar et al., 2019), and retailers can use customers’ billing data  

------------------- Sentence 1 -------------------

customers (Singh et al., 2015; Lekhwar et al., 2019), and retailers can use customers’ billing data

>> Tokens are: 
 ['customers', '(', 'Singh', 'et', 'al.', ',', '2015', ';', 'Lekhwar', 'et', 'al.', ',', '2019', ')', ',', 'retailers', 'use', 'customers', '’', 'billing', 'data']

>> Bigrams are: 
 [('customers', '('), ('(', 'Singh'), ('Singh', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Lekhwar'), ('Lekhwar', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'retailers'), ('retailers', 'use'), ('use', 'customers'), ('customers', '’'), ('’', 'billing'), ('billing', 'data')]

>> Trigrams are: 
 [('customers', '(', 'Singh'), ('(', 'Singh', 'et'), ('Singh', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Lekhwar'), (';', 'Lekhwar', 'et'), ('Lekhwar', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'retailers'), (',', 'retailers', 'use'), ('retailers', 'use', 'customers'), ('use', 'customers', '’'), ('customers', '’', 'billing'), ('’', 'billing', 'data')]

>> POS Tags are: 
 [('customers', 'NNS'), ('(', '('), ('Singh', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (';', ':'), ('Lekhwar', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('retailers', 'NNS'), ('use', 'VBP'), ('customers', 'NNS'), ('’', 'VBP'), ('billing', 'VBG'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['customers', 'Singh', 'Lekhwar', 'al.', 'retailers', 'customers', 'data']

>> Named Entities are: 
 [('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('customers', 'custom'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retail'), ('use', 'use'), ('customers', 'custom'), ('’', '’'), ('billing', 'bill'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('customers', 'custom'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retail'), ('use', 'use'), ('customers', 'custom'), ('’', '’'), ('billing', 'bill'), ('data', 'data')]

>> Lemmatization: 
 [('customers', 'customer'), ('(', '('), ('Singh', 'Singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'Lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retailer'), ('use', 'use'), ('customers', 'customer'), ('’', '’'), ('billing', 'billing'), ('data', 'data')]



========================================== PARAGRAPH 1273 ===========================================

to gather information for business intelligence. A Hadoop distributed file system (HDFS) tool is  

------------------- Sentence 1 -------------------

to gather information for business intelligence.

>> Tokens are: 
 ['gather', 'information', 'business', 'intelligence', '.']

>> Bigrams are: 
 [('gather', 'information'), ('information', 'business'), ('business', 'intelligence'), ('intelligence', '.')]

>> Trigrams are: 
 [('gather', 'information', 'business'), ('information', 'business', 'intelligence'), ('business', 'intelligence', '.')]

>> POS Tags are: 
 [('gather', 'NN'), ('information', 'NN'), ('business', 'NN'), ('intelligence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['gather information business intelligence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('gather', 'gather'), ('information', 'inform'), ('business', 'busi'), ('intelligence', 'intellig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('gather', 'gather'), ('information', 'inform'), ('business', 'busi'), ('intelligence', 'intellig'), ('.', '.')]

>> Lemmatization: 
 [('gather', 'gather'), ('information', 'information'), ('business', 'business'), ('intelligence', 'intelligence'), ('.', '.')]


------------------- Sentence 2 -------------------

A Hadoop distributed file system (HDFS) tool is

>> Tokens are: 
 ['A', 'Hadoop', 'distributed', 'file', 'system', '(', 'HDFS', ')', 'tool']

>> Bigrams are: 
 [('A', 'Hadoop'), ('Hadoop', 'distributed'), ('distributed', 'file'), ('file', 'system'), ('system', '('), ('(', 'HDFS'), ('HDFS', ')'), (')', 'tool')]

>> Trigrams are: 
 [('A', 'Hadoop', 'distributed'), ('Hadoop', 'distributed', 'file'), ('distributed', 'file', 'system'), ('file', 'system', '('), ('system', '(', 'HDFS'), ('(', 'HDFS', ')'), ('HDFS', ')', 'tool')]

>> POS Tags are: 
 [('A', 'DT'), ('Hadoop', 'NNP'), ('distributed', 'VBN'), ('file', 'NN'), ('system', 'NN'), ('(', '('), ('HDFS', 'NNP'), (')', ')'), ('tool', 'NN')]

>> Noun Phrases are: 
 ['A Hadoop', 'file system', 'HDFS', 'tool']

>> Named Entities are: 
 [('ORGANIZATION', 'HDFS')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Hadoop', 'hadoop'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')'), ('tool', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Hadoop', 'hadoop'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')'), ('tool', 'tool')]

>> Lemmatization: 
 [('A', 'A'), ('Hadoop', 'Hadoop'), ('distributed', 'distributed'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'HDFS'), (')', ')'), ('tool', 'tool')]



========================================== PARAGRAPH 1274 ===========================================

using to store, process, and analyse such data to allow the extraction of more information (Singh  

------------------- Sentence 1 -------------------

using to store, process, and analyse such data to allow the extraction of more information (Singh

>> Tokens are: 
 ['using', 'store', ',', 'process', ',', 'analyse', 'data', 'allow', 'extraction', 'information', '(', 'Singh']

>> Bigrams are: 
 [('using', 'store'), ('store', ','), (',', 'process'), ('process', ','), (',', 'analyse'), ('analyse', 'data'), ('data', 'allow'), ('allow', 'extraction'), ('extraction', 'information'), ('information', '('), ('(', 'Singh')]

>> Trigrams are: 
 [('using', 'store', ','), ('store', ',', 'process'), (',', 'process', ','), ('process', ',', 'analyse'), (',', 'analyse', 'data'), ('analyse', 'data', 'allow'), ('data', 'allow', 'extraction'), ('allow', 'extraction', 'information'), ('extraction', 'information', '('), ('information', '(', 'Singh')]

>> POS Tags are: 
 [('using', 'VBG'), ('store', 'NN'), (',', ','), ('process', 'NN'), (',', ','), ('analyse', 'NN'), ('data', 'NNS'), ('allow', 'VBP'), ('extraction', 'NN'), ('information', 'NN'), ('(', '('), ('Singh', 'NNP')]

>> Noun Phrases are: 
 ['store', 'process', 'analyse data', 'extraction information', 'Singh']

>> Named Entities are: 
 [('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analys'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extract'), ('information', 'inform'), ('(', '('), ('Singh', 'singh')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analys'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extract'), ('information', 'inform'), ('(', '('), ('Singh', 'singh')]

>> Lemmatization: 
 [('using', 'using'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analyse'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extraction'), ('information', 'information'), ('(', '('), ('Singh', 'Singh')]



========================================== PARAGRAPH 1275 ===========================================

et al., 2015).  

------------------- Sentence 1 -------------------

et al., 2015).

>> Tokens are: 
 ['et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1276 ===========================================

Big data analytics provides these organisations with more information on market decisions and  

------------------- Sentence 1 -------------------

Big data analytics provides these organisations with more information on market decisions and

>> Tokens are: 
 ['Big', 'data', 'analytics', 'provides', 'organisations', 'information', 'market', 'decisions']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'provides'), ('provides', 'organisations'), ('organisations', 'information'), ('information', 'market'), ('market', 'decisions')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'provides'), ('analytics', 'provides', 'organisations'), ('provides', 'organisations', 'information'), ('organisations', 'information', 'market'), ('information', 'market', 'decisions')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('provides', 'VBZ'), ('organisations', 'NNS'), ('information', 'NN'), ('market', 'NN'), ('decisions', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics', 'organisations information market decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('provides', 'provid'), ('organisations', 'organis'), ('information', 'inform'), ('market', 'market'), ('decisions', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('provides', 'provid'), ('organisations', 'organis'), ('information', 'inform'), ('market', 'market'), ('decisions', 'decis')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('provides', 'provides'), ('organisations', 'organisation'), ('information', 'information'), ('market', 'market'), ('decisions', 'decision')]



========================================== PARAGRAPH 1277 ===========================================

help in segmenting customer based on their characteristics. Social media analytics can also be used  

------------------- Sentence 1 -------------------

help in segmenting customer based on their characteristics.

>> Tokens are: 
 ['help', 'segmenting', 'customer', 'based', 'characteristics', '.']

>> Bigrams are: 
 [('help', 'segmenting'), ('segmenting', 'customer'), ('customer', 'based'), ('based', 'characteristics'), ('characteristics', '.')]

>> Trigrams are: 
 [('help', 'segmenting', 'customer'), ('segmenting', 'customer', 'based'), ('customer', 'based', 'characteristics'), ('based', 'characteristics', '.')]

>> POS Tags are: 
 [('help', 'NN'), ('segmenting', 'VBG'), ('customer', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['help', 'customer', 'characteristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('help', 'help'), ('segmenting', 'segment'), ('customer', 'custom'), ('based', 'base'), ('characteristics', 'characterist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('help', 'help'), ('segmenting', 'segment'), ('customer', 'custom'), ('based', 'base'), ('characteristics', 'characterist'), ('.', '.')]

>> Lemmatization: 
 [('help', 'help'), ('segmenting', 'segmenting'), ('customer', 'customer'), ('based', 'based'), ('characteristics', 'characteristic'), ('.', '.')]


------------------- Sentence 2 -------------------

Social media analytics can also be used

>> Tokens are: 
 ['Social', 'media', 'analytics', 'also', 'used']

>> Bigrams are: 
 [('Social', 'media'), ('media', 'analytics'), ('analytics', 'also'), ('also', 'used')]

>> Trigrams are: 
 [('Social', 'media', 'analytics'), ('media', 'analytics', 'also'), ('analytics', 'also', 'used')]

>> POS Tags are: 
 [('Social', 'JJ'), ('media', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Social media analytics']

>> Named Entities are: 
 [('GPE', 'Social')] 

>> Stemming using Porter Stemmer: 
 [('Social', 'social'), ('media', 'media'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Social', 'social'), ('media', 'media'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Lemmatization: 
 [('Social', 'Social'), ('media', 'medium'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used')]



========================================== PARAGRAPH 1278 ===========================================

to inform companies about what their customers prefer. Applying sentiment analysis to such data  

------------------- Sentence 1 -------------------

to inform companies about what their customers prefer.

>> Tokens are: 
 ['inform', 'companies', 'customers', 'prefer', '.']

>> Bigrams are: 
 [('inform', 'companies'), ('companies', 'customers'), ('customers', 'prefer'), ('prefer', '.')]

>> Trigrams are: 
 [('inform', 'companies', 'customers'), ('companies', 'customers', 'prefer'), ('customers', 'prefer', '.')]

>> POS Tags are: 
 [('inform', 'NN'), ('companies', 'NNS'), ('customers', 'NNS'), ('prefer', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['inform companies customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('inform', 'inform'), ('companies', 'compani'), ('customers', 'custom'), ('prefer', 'prefer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('inform', 'inform'), ('companies', 'compani'), ('customers', 'custom'), ('prefer', 'prefer'), ('.', '.')]

>> Lemmatization: 
 [('inform', 'inform'), ('companies', 'company'), ('customers', 'customer'), ('prefer', 'prefer'), ('.', '.')]


------------------- Sentence 2 -------------------

Applying sentiment analysis to such data

>> Tokens are: 
 ['Applying', 'sentiment', 'analysis', 'data']

>> Bigrams are: 
 [('Applying', 'sentiment'), ('sentiment', 'analysis'), ('analysis', 'data')]

>> Trigrams are: 
 [('Applying', 'sentiment', 'analysis'), ('sentiment', 'analysis', 'data')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('sentiment', 'NN'), ('analysis', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['sentiment analysis data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('data', 'data')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('data', 'data')]



========================================== PARAGRAPH 1279 ===========================================

provides the organisation with early warnings when the customer turns to different products,  

------------------- Sentence 1 -------------------

provides the organisation with early warnings when the customer turns to different products,

>> Tokens are: 
 ['provides', 'organisation', 'early', 'warnings', 'customer', 'turns', 'different', 'products', ',']

>> Bigrams are: 
 [('provides', 'organisation'), ('organisation', 'early'), ('early', 'warnings'), ('warnings', 'customer'), ('customer', 'turns'), ('turns', 'different'), ('different', 'products'), ('products', ',')]

>> Trigrams are: 
 [('provides', 'organisation', 'early'), ('organisation', 'early', 'warnings'), ('early', 'warnings', 'customer'), ('warnings', 'customer', 'turns'), ('customer', 'turns', 'different'), ('turns', 'different', 'products'), ('different', 'products', ',')]

>> POS Tags are: 
 [('provides', 'VBZ'), ('organisation', 'NN'), ('early', 'JJ'), ('warnings', 'NNS'), ('customer', 'NN'), ('turns', 'VBZ'), ('different', 'JJ'), ('products', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['organisation', 'early warnings customer', 'different products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provides', 'provid'), ('organisation', 'organis'), ('early', 'earli'), ('warnings', 'warn'), ('customer', 'custom'), ('turns', 'turn'), ('different', 'differ'), ('products', 'product'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('provides', 'provid'), ('organisation', 'organis'), ('early', 'earli'), ('warnings', 'warn'), ('customer', 'custom'), ('turns', 'turn'), ('different', 'differ'), ('products', 'product'), (',', ',')]

>> Lemmatization: 
 [('provides', 'provides'), ('organisation', 'organisation'), ('early', 'early'), ('warnings', 'warning'), ('customer', 'customer'), ('turns', 'turn'), ('different', 'different'), ('products', 'product'), (',', ',')]



========================================== PARAGRAPH 1280 ===========================================

allowing action to be taken by the organisation (Elgendy, N. and Elragal, A., 2014).  

------------------- Sentence 1 -------------------

allowing action to be taken by the organisation (Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['allowing', 'action', 'taken', 'organisation', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('allowing', 'action'), ('action', 'taken'), ('taken', 'organisation'), ('organisation', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('allowing', 'action', 'taken'), ('action', 'taken', 'organisation'), ('taken', 'organisation', '('), ('organisation', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('allowing', 'VBG'), ('action', 'NN'), ('taken', 'VBN'), ('organisation', 'NN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['action', 'organisation', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('allowing', 'allow'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organis'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('allowing', 'allow'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organis'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('allowing', 'allowing'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organisation'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1281 ===========================================

Organisations have used segmentation of customers for many years, but this is now assisted by  

------------------- Sentence 1 -------------------

Organisations have used segmentation of customers for many years, but this is now assisted by

>> Tokens are: 
 ['Organisations', 'used', 'segmentation', 'customers', 'many', 'years', ',', 'assisted']

>> Bigrams are: 
 [('Organisations', 'used'), ('used', 'segmentation'), ('segmentation', 'customers'), ('customers', 'many'), ('many', 'years'), ('years', ','), (',', 'assisted')]

>> Trigrams are: 
 [('Organisations', 'used', 'segmentation'), ('used', 'segmentation', 'customers'), ('segmentation', 'customers', 'many'), ('customers', 'many', 'years'), ('many', 'years', ','), ('years', ',', 'assisted')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('used', 'VBN'), ('segmentation', 'NN'), ('customers', 'NNS'), ('many', 'JJ'), ('years', 'NNS'), (',', ','), ('assisted', 'VBD')]

>> Noun Phrases are: 
 ['Organisations', 'segmentation customers', 'many years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('used', 'use'), ('segmentation', 'segment'), ('customers', 'custom'), ('many', 'mani'), ('years', 'year'), (',', ','), ('assisted', 'assist')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('used', 'use'), ('segmentation', 'segment'), ('customers', 'custom'), ('many', 'mani'), ('years', 'year'), (',', ','), ('assisted', 'assist')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('used', 'used'), ('segmentation', 'segmentation'), ('customers', 'customer'), ('many', 'many'), ('years', 'year'), (',', ','), ('assisted', 'assisted')]



========================================== PARAGRAPH 1282 ===========================================

complex big data techniques such as real-time micro-segmentation which offers better-targeted  

------------------- Sentence 1 -------------------

complex big data techniques such as real-time micro-segmentation which offers better-targeted

>> Tokens are: 
 ['complex', 'big', 'data', 'techniques', 'real-time', 'micro-segmentation', 'offers', 'better-targeted']

>> Bigrams are: 
 [('complex', 'big'), ('big', 'data'), ('data', 'techniques'), ('techniques', 'real-time'), ('real-time', 'micro-segmentation'), ('micro-segmentation', 'offers'), ('offers', 'better-targeted')]

>> Trigrams are: 
 [('complex', 'big', 'data'), ('big', 'data', 'techniques'), ('data', 'techniques', 'real-time'), ('techniques', 'real-time', 'micro-segmentation'), ('real-time', 'micro-segmentation', 'offers'), ('micro-segmentation', 'offers', 'better-targeted')]

>> POS Tags are: 
 [('complex', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('techniques', 'NNS'), ('real-time', 'JJ'), ('micro-segmentation', 'NN'), ('offers', 'NNS'), ('better-targeted', 'JJ')]

>> Noun Phrases are: 
 ['complex big data techniques', 'real-time micro-segmentation offers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('real-time', 'real-tim'), ('micro-segmentation', 'micro-segment'), ('offers', 'offer'), ('better-targeted', 'better-target')]

>> Stemming using Snowball Stemmer: 
 [('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('real-time', 'real-tim'), ('micro-segmentation', 'micro-segment'), ('offers', 'offer'), ('better-targeted', 'better-target')]

>> Lemmatization: 
 [('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'technique'), ('real-time', 'real-time'), ('micro-segmentation', 'micro-segmentation'), ('offers', 'offer'), ('better-targeted', 'better-targeted')]



========================================== PARAGRAPH 1283 ===========================================

advertising (Manyika et al., 2011; Elgendy and Elragal, 2014). Organisations can also gain better  

------------------- Sentence 1 -------------------

advertising (Manyika et al., 2011; Elgendy and Elragal, 2014).

>> Tokens are: 
 ['advertising', '(', 'Manyika', 'et', 'al.', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('advertising', '('), ('(', 'Manyika'), ('Manyika', 'et'), ('et', 'al.'), ('al.', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('advertising', '(', 'Manyika'), ('(', 'Manyika', 'et'), ('Manyika', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('advertising', 'NN'), ('(', '('), ('Manyika', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['advertising', 'Manyika', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Manyika'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('advertising', 'advertis'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('advertising', 'advertis'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('advertising', 'advertising'), ('(', '('), ('Manyika', 'Manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Organisations can also gain better

>> Tokens are: 
 ['Organisations', 'also', 'gain', 'better']

>> Bigrams are: 
 [('Organisations', 'also'), ('also', 'gain'), ('gain', 'better')]

>> Trigrams are: 
 [('Organisations', 'also', 'gain'), ('also', 'gain', 'better')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('also', 'RB'), ('gain', 'VBP'), ('better', 'JJR')]

>> Noun Phrases are: 
 ['Organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('also', 'also'), ('gain', 'gain'), ('better', 'better')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('also', 'also'), ('gain', 'gain'), ('better', 'better')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('also', 'also'), ('gain', 'gain'), ('better', 'better')]



========================================== PARAGRAPH 1284 ===========================================

targets for social marketing by understanding customer behaviors and predicting market sentiment  

------------------- Sentence 1 -------------------

targets for social marketing by understanding customer behaviors and predicting market sentiment

>> Tokens are: 
 ['targets', 'social', 'marketing', 'understanding', 'customer', 'behaviors', 'predicting', 'market', 'sentiment']

>> Bigrams are: 
 [('targets', 'social'), ('social', 'marketing'), ('marketing', 'understanding'), ('understanding', 'customer'), ('customer', 'behaviors'), ('behaviors', 'predicting'), ('predicting', 'market'), ('market', 'sentiment')]

>> Trigrams are: 
 [('targets', 'social', 'marketing'), ('social', 'marketing', 'understanding'), ('marketing', 'understanding', 'customer'), ('understanding', 'customer', 'behaviors'), ('customer', 'behaviors', 'predicting'), ('behaviors', 'predicting', 'market'), ('predicting', 'market', 'sentiment')]

>> POS Tags are: 
 [('targets', 'NNS'), ('social', 'JJ'), ('marketing', 'NN'), ('understanding', 'VBG'), ('customer', 'NN'), ('behaviors', 'NNS'), ('predicting', 'VBG'), ('market', 'NN'), ('sentiment', 'NN')]

>> Noun Phrases are: 
 ['targets', 'social marketing', 'customer behaviors', 'market sentiment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('targets', 'target'), ('social', 'social'), ('marketing', 'market'), ('understanding', 'understand'), ('customer', 'custom'), ('behaviors', 'behavior'), ('predicting', 'predict'), ('market', 'market'), ('sentiment', 'sentiment')]

>> Stemming using Snowball Stemmer: 
 [('targets', 'target'), ('social', 'social'), ('marketing', 'market'), ('understanding', 'understand'), ('customer', 'custom'), ('behaviors', 'behavior'), ('predicting', 'predict'), ('market', 'market'), ('sentiment', 'sentiment')]

>> Lemmatization: 
 [('targets', 'target'), ('social', 'social'), ('marketing', 'marketing'), ('understanding', 'understanding'), ('customer', 'customer'), ('behaviors', 'behavior'), ('predicting', 'predicting'), ('market', 'market'), ('sentiment', 'sentiment')]



========================================== PARAGRAPH 1285 ===========================================

trends (Russom, 2011; Elgendy and Elragal, 2014).   

------------------- Sentence 1 -------------------

trends (Russom, 2011; Elgendy and Elragal, 2014).

>> Tokens are: 
 ['trends', '(', 'Russom', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('trends', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('trends', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('trends', 'NNS'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['trends', 'Russom', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Russom'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('trends', 'trend'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('trends', 'trend'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('trends', 'trend'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1286 ===========================================

Retailers are thus using data analytics in order to address new challenges and find opportunities  

------------------- Sentence 1 -------------------

Retailers are thus using data analytics in order to address new challenges and find opportunities

>> Tokens are: 
 ['Retailers', 'thus', 'using', 'data', 'analytics', 'order', 'address', 'new', 'challenges', 'find', 'opportunities']

>> Bigrams are: 
 [('Retailers', 'thus'), ('thus', 'using'), ('using', 'data'), ('data', 'analytics'), ('analytics', 'order'), ('order', 'address'), ('address', 'new'), ('new', 'challenges'), ('challenges', 'find'), ('find', 'opportunities')]

>> Trigrams are: 
 [('Retailers', 'thus', 'using'), ('thus', 'using', 'data'), ('using', 'data', 'analytics'), ('data', 'analytics', 'order'), ('analytics', 'order', 'address'), ('order', 'address', 'new'), ('address', 'new', 'challenges'), ('new', 'challenges', 'find'), ('challenges', 'find', 'opportunities')]

>> POS Tags are: 
 [('Retailers', 'NNS'), ('thus', 'RB'), ('using', 'VBG'), ('data', 'NNS'), ('analytics', 'NNS'), ('order', 'NN'), ('address', 'IN'), ('new', 'JJ'), ('challenges', 'NNS'), ('find', 'VBP'), ('opportunities', 'NNS')]

>> Noun Phrases are: 
 ['Retailers', 'data analytics order', 'new challenges', 'opportunities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Retailers', 'retail'), ('thus', 'thu'), ('using', 'use'), ('data', 'data'), ('analytics', 'analyt'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challeng'), ('find', 'find'), ('opportunities', 'opportun')]

>> Stemming using Snowball Stemmer: 
 [('Retailers', 'retail'), ('thus', 'thus'), ('using', 'use'), ('data', 'data'), ('analytics', 'analyt'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challeng'), ('find', 'find'), ('opportunities', 'opportun')]

>> Lemmatization: 
 [('Retailers', 'Retailers'), ('thus', 'thus'), ('using', 'using'), ('data', 'data'), ('analytics', 'analytics'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challenge'), ('find', 'find'), ('opportunities', 'opportunity')]



========================================== PARAGRAPH 1287 ===========================================

based on increases in market expectations, competition, and volatility. In many companies,  

------------------- Sentence 1 -------------------

based on increases in market expectations, competition, and volatility.

>> Tokens are: 
 ['based', 'increases', 'market', 'expectations', ',', 'competition', ',', 'volatility', '.']

>> Bigrams are: 
 [('based', 'increases'), ('increases', 'market'), ('market', 'expectations'), ('expectations', ','), (',', 'competition'), ('competition', ','), (',', 'volatility'), ('volatility', '.')]

>> Trigrams are: 
 [('based', 'increases', 'market'), ('increases', 'market', 'expectations'), ('market', 'expectations', ','), ('expectations', ',', 'competition'), (',', 'competition', ','), ('competition', ',', 'volatility'), (',', 'volatility', '.')]

>> POS Tags are: 
 [('based', 'VBN'), ('increases', 'NNS'), ('market', 'NN'), ('expectations', 'NNS'), (',', ','), ('competition', 'NN'), (',', ','), ('volatility', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['increases market expectations', 'competition', 'volatility']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('based', 'base'), ('increases', 'increas'), ('market', 'market'), ('expectations', 'expect'), (',', ','), ('competition', 'competit'), (',', ','), ('volatility', 'volatil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('based', 'base'), ('increases', 'increas'), ('market', 'market'), ('expectations', 'expect'), (',', ','), ('competition', 'competit'), (',', ','), ('volatility', 'volatil'), ('.', '.')]

>> Lemmatization: 
 [('based', 'based'), ('increases', 'increase'), ('market', 'market'), ('expectations', 'expectation'), (',', ','), ('competition', 'competition'), (',', ','), ('volatility', 'volatility'), ('.', '.')]


------------------- Sentence 2 -------------------

In many companies,

>> Tokens are: 
 ['In', 'many', 'companies', ',']

>> Bigrams are: 
 [('In', 'many'), ('many', 'companies'), ('companies', ',')]

>> Trigrams are: 
 [('In', 'many', 'companies'), ('many', 'companies', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('many', 'JJ'), ('companies', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['many companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('companies', 'compani'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('companies', 'compani'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('many', 'many'), ('companies', 'company'), (',', ',')]



========================================== PARAGRAPH 1288 ===========================================

additional accuracy, clarity, and insight can be provided by the adoption of data analytics  

------------------- Sentence 1 -------------------

additional accuracy, clarity, and insight can be provided by the adoption of data analytics

>> Tokens are: 
 ['additional', 'accuracy', ',', 'clarity', ',', 'insight', 'provided', 'adoption', 'data', 'analytics']

>> Bigrams are: 
 [('additional', 'accuracy'), ('accuracy', ','), (',', 'clarity'), ('clarity', ','), (',', 'insight'), ('insight', 'provided'), ('provided', 'adoption'), ('adoption', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('additional', 'accuracy', ','), ('accuracy', ',', 'clarity'), (',', 'clarity', ','), ('clarity', ',', 'insight'), (',', 'insight', 'provided'), ('insight', 'provided', 'adoption'), ('provided', 'adoption', 'data'), ('adoption', 'data', 'analytics')]

>> POS Tags are: 
 [('additional', 'JJ'), ('accuracy', 'NN'), (',', ','), ('clarity', 'NN'), (',', ','), ('insight', 'NN'), ('provided', 'VBD'), ('adoption', 'NN'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['additional accuracy', 'clarity', 'insight', 'adoption data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('additional', 'addit'), ('accuracy', 'accuraci'), (',', ','), ('clarity', 'clariti'), (',', ','), ('insight', 'insight'), ('provided', 'provid'), ('adoption', 'adopt'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('additional', 'addit'), ('accuracy', 'accuraci'), (',', ','), ('clarity', 'clariti'), (',', ','), ('insight', 'insight'), ('provided', 'provid'), ('adoption', 'adopt'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('additional', 'additional'), ('accuracy', 'accuracy'), (',', ','), ('clarity', 'clarity'), (',', ','), ('insight', 'insight'), ('provided', 'provided'), ('adoption', 'adoption'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 1289 ===========================================

techniques, and such intelligence can be extended toward industry supply chains (Hofmann et al.,  

------------------- Sentence 1 -------------------

techniques, and such intelligence can be extended toward industry supply chains (Hofmann et al.,

>> Tokens are: 
 ['techniques', ',', 'intelligence', 'extended', 'toward', 'industry', 'supply', 'chains', '(', 'Hofmann', 'et', 'al.', ',']

>> Bigrams are: 
 [('techniques', ','), (',', 'intelligence'), ('intelligence', 'extended'), ('extended', 'toward'), ('toward', 'industry'), ('industry', 'supply'), ('supply', 'chains'), ('chains', '('), ('(', 'Hofmann'), ('Hofmann', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('techniques', ',', 'intelligence'), (',', 'intelligence', 'extended'), ('intelligence', 'extended', 'toward'), ('extended', 'toward', 'industry'), ('toward', 'industry', 'supply'), ('industry', 'supply', 'chains'), ('supply', 'chains', '('), ('chains', '(', 'Hofmann'), ('(', 'Hofmann', 'et'), ('Hofmann', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('techniques', 'NNS'), (',', ','), ('intelligence', 'NN'), ('extended', 'VBD'), ('toward', 'IN'), ('industry', 'NN'), ('supply', 'NN'), ('chains', 'NNS'), ('(', '('), ('Hofmann', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['techniques', 'intelligence', 'industry supply chains', 'Hofmann']

>> Named Entities are: 
 [('PERSON', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), (',', ','), ('intelligence', 'intellig'), ('extended', 'extend'), ('toward', 'toward'), ('industry', 'industri'), ('supply', 'suppli'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), (',', ','), ('intelligence', 'intellig'), ('extended', 'extend'), ('toward', 'toward'), ('industry', 'industri'), ('supply', 'suppli'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('techniques', 'technique'), (',', ','), ('intelligence', 'intelligence'), ('extended', 'extended'), ('toward', 'toward'), ('industry', 'industry'), ('supply', 'supply'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'Hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 1290 ===========================================

2018). 

------------------- Sentence 1 -------------------

2018).

>> Tokens are: 
 ['2018', ')', '.']

>> Bigrams are: 
 [('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('2018', ')', '.')]

>> POS Tags are: 
 [('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1291 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1292 ===========================================

45  

------------------- Sentence 1 -------------------

45

>> Tokens are: 
 ['45']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('45', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('45', '45')]

>> Stemming using Snowball Stemmer: 
 [('45', '45')]

>> Lemmatization: 
 [('45', '45')]



========================================== PARAGRAPH 1293 ===========================================

  


========================================== PARAGRAPH 1294 ===========================================

  


========================================== PARAGRAPH 1295 ===========================================

10.4. Telecommunications  

------------------- Sentence 1 -------------------

10.4.

>> Tokens are: 
 ['10.4', '.']

>> Bigrams are: 
 [('10.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.4', '10.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.4', '10.4'), ('.', '.')]

>> Lemmatization: 
 [('10.4', '10.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Telecommunications

>> Tokens are: 
 ['Telecommunications']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Telecommunications', 'NNS')]

>> Noun Phrases are: 
 ['Telecommunications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Telecommunications', 'telecommun')]

>> Stemming using Snowball Stemmer: 
 [('Telecommunications', 'telecommun')]

>> Lemmatization: 
 [('Telecommunications', 'Telecommunications')]



========================================== PARAGRAPH 1296 ===========================================

Big data analytics can improve the quality of management in telecommunications by making use  

------------------- Sentence 1 -------------------

Big data analytics can improve the quality of management in telecommunications by making use

>> Tokens are: 
 ['Big', 'data', 'analytics', 'improve', 'quality', 'management', 'telecommunications', 'making', 'use']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'improve'), ('improve', 'quality'), ('quality', 'management'), ('management', 'telecommunications'), ('telecommunications', 'making'), ('making', 'use')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'improve'), ('analytics', 'improve', 'quality'), ('improve', 'quality', 'management'), ('quality', 'management', 'telecommunications'), ('management', 'telecommunications', 'making'), ('telecommunications', 'making', 'use')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('improve', 'VBP'), ('quality', 'NN'), ('management', 'NN'), ('telecommunications', 'NNS'), ('making', 'VBG'), ('use', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics', 'quality management telecommunications', 'use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('quality', 'qualiti'), ('management', 'manag'), ('telecommunications', 'telecommun'), ('making', 'make'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('quality', 'qualiti'), ('management', 'manag'), ('telecommunications', 'telecommun'), ('making', 'make'), ('use', 'use')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('improve', 'improve'), ('quality', 'quality'), ('management', 'management'), ('telecommunications', 'telecommunication'), ('making', 'making'), ('use', 'use')]



========================================== PARAGRAPH 1297 ===========================================

of real-time data analyses and monitoring machine logs. Predictive analytics can also be used to  

------------------- Sentence 1 -------------------

of real-time data analyses and monitoring machine logs.

>> Tokens are: 
 ['real-time', 'data', 'analyses', 'monitoring', 'machine', 'logs', '.']

>> Bigrams are: 
 [('real-time', 'data'), ('data', 'analyses'), ('analyses', 'monitoring'), ('monitoring', 'machine'), ('machine', 'logs'), ('logs', '.')]

>> Trigrams are: 
 [('real-time', 'data', 'analyses'), ('data', 'analyses', 'monitoring'), ('analyses', 'monitoring', 'machine'), ('monitoring', 'machine', 'logs'), ('machine', 'logs', '.')]

>> POS Tags are: 
 [('real-time', 'JJ'), ('data', 'NNS'), ('analyses', 'NNS'), ('monitoring', 'VBG'), ('machine', 'NN'), ('logs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['real-time data analyses', 'machine logs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('real-time', 'real-tim'), ('data', 'data'), ('analyses', 'analys'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('real-time', 'real-tim'), ('data', 'data'), ('analyses', 'analys'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('.', '.')]

>> Lemmatization: 
 [('real-time', 'real-time'), ('data', 'data'), ('analyses', 'analysis'), ('monitoring', 'monitoring'), ('machine', 'machine'), ('logs', 'log'), ('.', '.')]


------------------- Sentence 2 -------------------

Predictive analytics can also be used to

>> Tokens are: 
 ['Predictive', 'analytics', 'also', 'used']

>> Bigrams are: 
 [('Predictive', 'analytics'), ('analytics', 'also'), ('also', 'used')]

>> Trigrams are: 
 [('Predictive', 'analytics', 'also'), ('analytics', 'also', 'used')]

>> POS Tags are: 
 [('Predictive', 'JJ'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Predictive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Lemmatization: 
 [('Predictive', 'Predictive'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used')]



========================================== PARAGRAPH 1298 ===========================================

minimise performance variability and to prevent quality issues by providing early warning alerts  

------------------- Sentence 1 -------------------

minimise performance variability and to prevent quality issues by providing early warning alerts

>> Tokens are: 
 ['minimise', 'performance', 'variability', 'prevent', 'quality', 'issues', 'providing', 'early', 'warning', 'alerts']

>> Bigrams are: 
 [('minimise', 'performance'), ('performance', 'variability'), ('variability', 'prevent'), ('prevent', 'quality'), ('quality', 'issues'), ('issues', 'providing'), ('providing', 'early'), ('early', 'warning'), ('warning', 'alerts')]

>> Trigrams are: 
 [('minimise', 'performance', 'variability'), ('performance', 'variability', 'prevent'), ('variability', 'prevent', 'quality'), ('prevent', 'quality', 'issues'), ('quality', 'issues', 'providing'), ('issues', 'providing', 'early'), ('providing', 'early', 'warning'), ('early', 'warning', 'alerts')]

>> POS Tags are: 
 [('minimise', 'NN'), ('performance', 'NN'), ('variability', 'NN'), ('prevent', 'VBP'), ('quality', 'NN'), ('issues', 'NNS'), ('providing', 'VBG'), ('early', 'JJ'), ('warning', 'NN'), ('alerts', 'NNS')]

>> Noun Phrases are: 
 ['minimise performance variability', 'quality issues', 'early warning alerts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('minimise', 'minimis'), ('performance', 'perform'), ('variability', 'variabl'), ('prevent', 'prevent'), ('quality', 'qualiti'), ('issues', 'issu'), ('providing', 'provid'), ('early', 'earli'), ('warning', 'warn'), ('alerts', 'alert')]

>> Stemming using Snowball Stemmer: 
 [('minimise', 'minimis'), ('performance', 'perform'), ('variability', 'variabl'), ('prevent', 'prevent'), ('quality', 'qualiti'), ('issues', 'issu'), ('providing', 'provid'), ('early', 'earli'), ('warning', 'warn'), ('alerts', 'alert')]

>> Lemmatization: 
 [('minimise', 'minimise'), ('performance', 'performance'), ('variability', 'variability'), ('prevent', 'prevent'), ('quality', 'quality'), ('issues', 'issue'), ('providing', 'providing'), ('early', 'early'), ('warning', 'warning'), ('alerts', 'alert')]



========================================== PARAGRAPH 1299 ===========================================

(Elgendy, N. and Elragal, A., 2014).  

------------------- Sentence 1 -------------------

(Elgendy, N. and Elragal, A., 2014).

>> Tokens are: 
 ['(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1300 ===========================================

Big data analytics platforms used in the telecommunication field face the major challenge of how  

------------------- Sentence 1 -------------------

Big data analytics platforms used in the telecommunication field face the major challenge of how

>> Tokens are: 
 ['Big', 'data', 'analytics', 'platforms', 'used', 'telecommunication', 'field', 'face', 'major', 'challenge']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'platforms'), ('platforms', 'used'), ('used', 'telecommunication'), ('telecommunication', 'field'), ('field', 'face'), ('face', 'major'), ('major', 'challenge')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'platforms'), ('analytics', 'platforms', 'used'), ('platforms', 'used', 'telecommunication'), ('used', 'telecommunication', 'field'), ('telecommunication', 'field', 'face'), ('field', 'face', 'major'), ('face', 'major', 'challenge')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('platforms', 'NNS'), ('used', 'VBN'), ('telecommunication', 'NN'), ('field', 'NN'), ('face', 'NN'), ('major', 'JJ'), ('challenge', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics platforms', 'telecommunication field face', 'major challenge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('used', 'use'), ('telecommunication', 'telecommun'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challeng')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('used', 'use'), ('telecommunication', 'telecommun'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challeng')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('platforms', 'platform'), ('used', 'used'), ('telecommunication', 'telecommunication'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challenge')]



========================================== PARAGRAPH 1301 ===========================================

to store and process big data; traditional analysis techniques are too expensive in many cases. Big  

------------------- Sentence 1 -------------------

to store and process big data; traditional analysis techniques are too expensive in many cases.

>> Tokens are: 
 ['store', 'process', 'big', 'data', ';', 'traditional', 'analysis', 'techniques', 'expensive', 'many', 'cases', '.']

>> Bigrams are: 
 [('store', 'process'), ('process', 'big'), ('big', 'data'), ('data', ';'), (';', 'traditional'), ('traditional', 'analysis'), ('analysis', 'techniques'), ('techniques', 'expensive'), ('expensive', 'many'), ('many', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('store', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', ';'), ('data', ';', 'traditional'), (';', 'traditional', 'analysis'), ('traditional', 'analysis', 'techniques'), ('analysis', 'techniques', 'expensive'), ('techniques', 'expensive', 'many'), ('expensive', 'many', 'cases'), ('many', 'cases', '.')]

>> POS Tags are: 
 [('store', 'NN'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (';', ':'), ('traditional', 'JJ'), ('analysis', 'NN'), ('techniques', 'NNS'), ('expensive', 'VBP'), ('many', 'JJ'), ('cases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['store process', 'big data', 'traditional analysis techniques', 'many cases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'tradit'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('expensive', 'expens'), ('many', 'mani'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'tradit'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('expensive', 'expens'), ('many', 'mani'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'traditional'), ('analysis', 'analysis'), ('techniques', 'technique'), ('expensive', 'expensive'), ('many', 'many'), ('cases', 'case'), ('.', '.')]


------------------- Sentence 2 -------------------

Big

>> Tokens are: 
 ['Big']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big')]

>> Lemmatization: 
 [('Big', 'Big')]



========================================== PARAGRAPH 1302 ===========================================

data techniques such as Hadoop can help in reducing the storage costs, particularly where storage  

------------------- Sentence 1 -------------------

data techniques such as Hadoop can help in reducing the storage costs, particularly where storage

>> Tokens are: 
 ['data', 'techniques', 'Hadoop', 'help', 'reducing', 'storage', 'costs', ',', 'particularly', 'storage']

>> Bigrams are: 
 [('data', 'techniques'), ('techniques', 'Hadoop'), ('Hadoop', 'help'), ('help', 'reducing'), ('reducing', 'storage'), ('storage', 'costs'), ('costs', ','), (',', 'particularly'), ('particularly', 'storage')]

>> Trigrams are: 
 [('data', 'techniques', 'Hadoop'), ('techniques', 'Hadoop', 'help'), ('Hadoop', 'help', 'reducing'), ('help', 'reducing', 'storage'), ('reducing', 'storage', 'costs'), ('storage', 'costs', ','), ('costs', ',', 'particularly'), (',', 'particularly', 'storage')]

>> POS Tags are: 
 [('data', 'NNS'), ('techniques', 'NNS'), ('Hadoop', 'NNP'), ('help', 'NN'), ('reducing', 'VBG'), ('storage', 'NN'), ('costs', 'NNS'), (',', ','), ('particularly', 'RB'), ('storage', 'NN')]

>> Noun Phrases are: 
 ['data techniques Hadoop help', 'storage costs', 'storage']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('techniques', 'techniqu'), ('Hadoop', 'hadoop'), ('help', 'help'), ('reducing', 'reduc'), ('storage', 'storag'), ('costs', 'cost'), (',', ','), ('particularly', 'particularli'), ('storage', 'storag')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('techniques', 'techniqu'), ('Hadoop', 'hadoop'), ('help', 'help'), ('reducing', 'reduc'), ('storage', 'storag'), ('costs', 'cost'), (',', ','), ('particularly', 'particular'), ('storage', 'storag')]

>> Lemmatization: 
 [('data', 'data'), ('techniques', 'technique'), ('Hadoop', 'Hadoop'), ('help', 'help'), ('reducing', 'reducing'), ('storage', 'storage'), ('costs', 'cost'), (',', ','), ('particularly', 'particularly'), ('storage', 'storage')]



========================================== PARAGRAPH 1303 ===========================================

modules such as the Hadoop Distributed File System (HDFS) and computation modules such  

------------------- Sentence 1 -------------------

modules such as the Hadoop Distributed File System (HDFS) and computation modules such

>> Tokens are: 
 ['modules', 'Hadoop', 'Distributed', 'File', 'System', '(', 'HDFS', ')', 'computation', 'modules']

>> Bigrams are: 
 [('modules', 'Hadoop'), ('Hadoop', 'Distributed'), ('Distributed', 'File'), ('File', 'System'), ('System', '('), ('(', 'HDFS'), ('HDFS', ')'), (')', 'computation'), ('computation', 'modules')]

>> Trigrams are: 
 [('modules', 'Hadoop', 'Distributed'), ('Hadoop', 'Distributed', 'File'), ('Distributed', 'File', 'System'), ('File', 'System', '('), ('System', '(', 'HDFS'), ('(', 'HDFS', ')'), ('HDFS', ')', 'computation'), (')', 'computation', 'modules')]

>> POS Tags are: 
 [('modules', 'NNS'), ('Hadoop', 'NNP'), ('Distributed', 'NNP'), ('File', 'NNP'), ('System', 'NNP'), ('(', '('), ('HDFS', 'NNP'), (')', ')'), ('computation', 'NN'), ('modules', 'NNS')]

>> Noun Phrases are: 
 ['modules Hadoop Distributed File System', 'HDFS', 'computation modules']

>> Named Entities are: 
 [('PERSON', 'Hadoop Distributed File System'), ('ORGANIZATION', 'HDFS')] 

>> Stemming using Porter Stemmer: 
 [('modules', 'modul'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')'), ('computation', 'comput'), ('modules', 'modul')]

>> Stemming using Snowball Stemmer: 
 [('modules', 'modul'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')'), ('computation', 'comput'), ('modules', 'modul')]

>> Lemmatization: 
 [('modules', 'module'), ('Hadoop', 'Hadoop'), ('Distributed', 'Distributed'), ('File', 'File'), ('System', 'System'), ('(', '('), ('HDFS', 'HDFS'), (')', ')'), ('computation', 'computation'), ('modules', 'module')]



========================================== PARAGRAPH 1304 ===========================================

as MapReduce are included (Çelebi, 2013).  

------------------- Sentence 1 -------------------

as MapReduce are included (Çelebi, 2013).

>> Tokens are: 
 ['MapReduce', 'included', '(', 'Çelebi', ',', '2013', ')', '.']

>> Bigrams are: 
 [('MapReduce', 'included'), ('included', '('), ('(', 'Çelebi'), ('Çelebi', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('MapReduce', 'included', '('), ('included', '(', 'Çelebi'), ('(', 'Çelebi', ','), ('Çelebi', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('MapReduce', 'NNP'), ('included', 'VBD'), ('(', '('), ('Çelebi', 'CD'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['MapReduce']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('MapReduce', 'mapreduc'), ('included', 'includ'), ('(', '('), ('Çelebi', 'çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MapReduce', 'mapreduc'), ('included', 'includ'), ('(', '('), ('Çelebi', 'çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('MapReduce', 'MapReduce'), ('included', 'included'), ('(', '('), ('Çelebi', 'Çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1305 ===========================================

Big data analytics has the power to extract more information than traditional data analytics, which  

------------------- Sentence 1 -------------------

Big data analytics has the power to extract more information than traditional data analytics, which

>> Tokens are: 
 ['Big', 'data', 'analytics', 'power', 'extract', 'information', 'traditional', 'data', 'analytics', ',']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'power'), ('power', 'extract'), ('extract', 'information'), ('information', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', ',')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'power'), ('analytics', 'power', 'extract'), ('power', 'extract', 'information'), ('extract', 'information', 'traditional'), ('information', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', ',')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('power', 'NN'), ('extract', 'JJ'), ('information', 'NN'), ('traditional', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Big data analytics power', 'extract information', 'traditional data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('extract', 'extract'), ('information', 'inform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('extract', 'extract'), ('information', 'inform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ',')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('power', 'power'), ('extract', 'extract'), ('information', 'information'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), (',', ',')]



========================================== PARAGRAPH 1306 ===========================================

can help in improving mobile cellular networks. Such mobile cellular networks generate and carry  

------------------- Sentence 1 -------------------

can help in improving mobile cellular networks.

>> Tokens are: 
 ['help', 'improving', 'mobile', 'cellular', 'networks', '.']

>> Bigrams are: 
 [('help', 'improving'), ('improving', 'mobile'), ('mobile', 'cellular'), ('cellular', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('help', 'improving', 'mobile'), ('improving', 'mobile', 'cellular'), ('mobile', 'cellular', 'networks'), ('cellular', 'networks', '.')]

>> POS Tags are: 
 [('help', 'NN'), ('improving', 'VBG'), ('mobile', 'JJ'), ('cellular', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['help', 'mobile cellular networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('help', 'help'), ('improving', 'improv'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('help', 'help'), ('improving', 'improv'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('help', 'help'), ('improving', 'improving'), ('mobile', 'mobile'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

Such mobile cellular networks generate and carry

>> Tokens are: 
 ['Such', 'mobile', 'cellular', 'networks', 'generate', 'carry']

>> Bigrams are: 
 [('Such', 'mobile'), ('mobile', 'cellular'), ('cellular', 'networks'), ('networks', 'generate'), ('generate', 'carry')]

>> Trigrams are: 
 [('Such', 'mobile', 'cellular'), ('mobile', 'cellular', 'networks'), ('cellular', 'networks', 'generate'), ('networks', 'generate', 'carry')]

>> POS Tags are: 
 [('Such', 'JJ'), ('mobile', 'JJ'), ('cellular', 'JJ'), ('networks', 'NNS'), ('generate', 'VBP'), ('carry', 'NN')]

>> Noun Phrases are: 
 ['Such mobile cellular networks', 'carry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'gener'), ('carry', 'carri')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'generat'), ('carry', 'carri')]

>> Lemmatization: 
 [('Such', 'Such'), ('mobile', 'mobile'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'generate'), ('carry', 'carry')]



========================================== PARAGRAPH 1307 ===========================================

massive amounts of data such as calls and mobile application activities that consist of both  

------------------- Sentence 1 -------------------

massive amounts of data such as calls and mobile application activities that consist of both

>> Tokens are: 
 ['massive', 'amounts', 'data', 'calls', 'mobile', 'application', 'activities', 'consist']

>> Bigrams are: 
 [('massive', 'amounts'), ('amounts', 'data'), ('data', 'calls'), ('calls', 'mobile'), ('mobile', 'application'), ('application', 'activities'), ('activities', 'consist')]

>> Trigrams are: 
 [('massive', 'amounts', 'data'), ('amounts', 'data', 'calls'), ('data', 'calls', 'mobile'), ('calls', 'mobile', 'application'), ('mobile', 'application', 'activities'), ('application', 'activities', 'consist')]

>> POS Tags are: 
 [('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('calls', 'NNS'), ('mobile', 'JJ'), ('application', 'NN'), ('activities', 'NNS'), ('consist', 'VBP')]

>> Noun Phrases are: 
 ['massive amounts data calls', 'mobile application activities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobil'), ('application', 'applic'), ('activities', 'activ'), ('consist', 'consist')]

>> Stemming using Snowball Stemmer: 
 [('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobil'), ('application', 'applic'), ('activities', 'activ'), ('consist', 'consist')]

>> Lemmatization: 
 [('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobile'), ('application', 'application'), ('activities', 'activity'), ('consist', 'consist')]



========================================== PARAGRAPH 1308 ===========================================

structured and unstructured data types. Traditional data analytics deals only with structured data,  

------------------- Sentence 1 -------------------

structured and unstructured data types.

>> Tokens are: 
 ['structured', 'unstructured', 'data', 'types', '.']

>> Bigrams are: 
 [('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'types'), ('types', '.')]

>> Trigrams are: 
 [('structured', 'unstructured', 'data'), ('unstructured', 'data', 'types'), ('data', 'types', '.')]

>> POS Tags are: 
 [('structured', 'VBN'), ('unstructured', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['unstructured data types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('.', '.')]

>> Lemmatization: 
 [('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('types', 'type'), ('.', '.')]


------------------- Sentence 2 -------------------

Traditional data analytics deals only with structured data,

>> Tokens are: 
 ['Traditional', 'data', 'analytics', 'deals', 'structured', 'data', ',']

>> Bigrams are: 
 [('Traditional', 'data'), ('data', 'analytics'), ('analytics', 'deals'), ('deals', 'structured'), ('structured', 'data'), ('data', ',')]

>> Trigrams are: 
 [('Traditional', 'data', 'analytics'), ('data', 'analytics', 'deals'), ('analytics', 'deals', 'structured'), ('deals', 'structured', 'data'), ('structured', 'data', ',')]

>> POS Tags are: 
 [('Traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('deals', 'NNS'), ('structured', 'VBD'), ('data', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Traditional data analytics deals', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('deals', 'deal'), ('structured', 'structur'), ('data', 'data'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('deals', 'deal'), ('structured', 'structur'), ('data', 'data'), (',', ',')]

>> Lemmatization: 
 [('Traditional', 'Traditional'), ('data', 'data'), ('analytics', 'analytics'), ('deals', 'deal'), ('structured', 'structured'), ('data', 'data'), (',', ',')]



========================================== PARAGRAPH 1309 ===========================================

and thus it is almost impossible to handle that data with traditional data analytics (He et al., 2016).  

------------------- Sentence 1 -------------------

and thus it is almost impossible to handle that data with traditional data analytics (He et al., 2016).

>> Tokens are: 
 ['thus', 'almost', 'impossible', 'handle', 'data', 'traditional', 'data', 'analytics', '(', 'He', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('thus', 'almost'), ('almost', 'impossible'), ('impossible', 'handle'), ('handle', 'data'), ('data', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'He'), ('He', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('thus', 'almost', 'impossible'), ('almost', 'impossible', 'handle'), ('impossible', 'handle', 'data'), ('handle', 'data', 'traditional'), ('data', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'He'), ('(', 'He', 'et'), ('He', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('thus', 'RB'), ('almost', 'RB'), ('impossible', 'JJ'), ('handle', 'JJ'), ('data', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('He', 'PRP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['impossible handle data', 'traditional data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('thus', 'thu'), ('almost', 'almost'), ('impossible', 'imposs'), ('handle', 'handl'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('He', 'he'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('thus', 'thus'), ('almost', 'almost'), ('impossible', 'imposs'), ('handle', 'handl'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('He', 'he'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('thus', 'thus'), ('almost', 'almost'), ('impossible', 'impossible'), ('handle', 'handle'), ('data', 'data'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('He', 'He'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1310 ===========================================

  


========================================== PARAGRAPH 1311 ===========================================

11. Implications of research   

------------------- Sentence 1 -------------------

11.

>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]


------------------- Sentence 2 -------------------

Implications of research

>> Tokens are: 
 ['Implications', 'research']

>> Bigrams are: 
 [('Implications', 'research')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Implications', 'NNS'), ('research', 'NN')]

>> Noun Phrases are: 
 ['Implications research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Implications', 'implic'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('Implications', 'implic'), ('research', 'research')]

>> Lemmatization: 
 [('Implications', 'Implications'), ('research', 'research')]



========================================== PARAGRAPH 1312 ===========================================

Big data has the power to change research and education. Improving the students’ results by  

------------------- Sentence 1 -------------------

Big data has the power to change research and education.

>> Tokens are: 
 ['Big', 'data', 'power', 'change', 'research', 'education', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'power'), ('power', 'change'), ('change', 'research'), ('research', 'education'), ('education', '.')]

>> Trigrams are: 
 [('Big', 'data', 'power'), ('data', 'power', 'change'), ('power', 'change', 'research'), ('change', 'research', 'education'), ('research', 'education', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('power', 'NN'), ('change', 'NN'), ('research', 'NN'), ('education', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data power change research education']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('power', 'power'), ('change', 'chang'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('power', 'power'), ('change', 'chang'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('power', 'power'), ('change', 'change'), ('research', 'research'), ('education', 'education'), ('.', '.')]


------------------- Sentence 2 -------------------

Improving the students’ results by

>> Tokens are: 
 ['Improving', 'students', '’', 'results']

>> Bigrams are: 
 [('Improving', 'students'), ('students', '’'), ('’', 'results')]

>> Trigrams are: 
 [('Improving', 'students', '’'), ('students', '’', 'results')]

>> POS Tags are: 
 [('Improving', 'VBG'), ('students', 'NNS'), ('’', 'JJ'), ('results', 'NNS')]

>> Noun Phrases are: 
 ['students', '’ results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Improving', 'improv'), ('students', 'student'), ('’', '’'), ('results', 'result')]

>> Stemming using Snowball Stemmer: 
 [('Improving', 'improv'), ('students', 'student'), ('’', '’'), ('results', 'result')]

>> Lemmatization: 
 [('Improving', 'Improving'), ('students', 'student'), ('’', '’'), ('results', 'result')]



========================================== PARAGRAPH 1313 ===========================================

refining the student’s performance during courses and understanding their behaviours can be done  

------------------- Sentence 1 -------------------

refining the student’s performance during courses and understanding their behaviours can be done

>> Tokens are: 
 ['refining', 'student', '’', 'performance', 'courses', 'understanding', 'behaviours', 'done']

>> Bigrams are: 
 [('refining', 'student'), ('student', '’'), ('’', 'performance'), ('performance', 'courses'), ('courses', 'understanding'), ('understanding', 'behaviours'), ('behaviours', 'done')]

>> Trigrams are: 
 [('refining', 'student', '’'), ('student', '’', 'performance'), ('’', 'performance', 'courses'), ('performance', 'courses', 'understanding'), ('courses', 'understanding', 'behaviours'), ('understanding', 'behaviours', 'done')]

>> POS Tags are: 
 [('refining', 'VBG'), ('student', 'NN'), ('’', 'NN'), ('performance', 'NN'), ('courses', 'NNS'), ('understanding', 'JJ'), ('behaviours', 'NNS'), ('done', 'VBN')]

>> Noun Phrases are: 
 ['student ’ performance courses', 'understanding behaviours']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('refining', 'refin'), ('student', 'student'), ('’', '’'), ('performance', 'perform'), ('courses', 'cours'), ('understanding', 'understand'), ('behaviours', 'behaviour'), ('done', 'done')]

>> Stemming using Snowball Stemmer: 
 [('refining', 'refin'), ('student', 'student'), ('’', '’'), ('performance', 'perform'), ('courses', 'cours'), ('understanding', 'understand'), ('behaviours', 'behaviour'), ('done', 'done')]

>> Lemmatization: 
 [('refining', 'refining'), ('student', 'student'), ('’', '’'), ('performance', 'performance'), ('courses', 'course'), ('understanding', 'understanding'), ('behaviours', 'behaviour'), ('done', 'done')]



========================================== PARAGRAPH 1314 ===========================================

using big data analytics. Also, big data analytics gives students the ability to matching their  

------------------- Sentence 1 -------------------

using big data analytics.

>> Tokens are: 
 ['using', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

Also, big data analytics gives students the ability to matching their

>> Tokens are: 
 ['Also', ',', 'big', 'data', 'analytics', 'gives', 'students', 'ability', 'matching']

>> Bigrams are: 
 [('Also', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'gives'), ('gives', 'students'), ('students', 'ability'), ('ability', 'matching')]

>> Trigrams are: 
 [('Also', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'gives'), ('analytics', 'gives', 'students'), ('gives', 'students', 'ability'), ('students', 'ability', 'matching')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('gives', 'VBZ'), ('students', 'NNS'), ('ability', 'NN'), ('matching', 'VBG')]

>> Noun Phrases are: 
 ['big data analytics', 'students ability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gives', 'give'), ('students', 'student'), ('ability', 'abil'), ('matching', 'match')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gives', 'give'), ('students', 'student'), ('ability', 'abil'), ('matching', 'match')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('gives', 'give'), ('students', 'student'), ('ability', 'ability'), ('matching', 'matching')]



========================================== PARAGRAPH 1315 ===========================================

interests to the available programs; thus, can choose the best school or educational program. On  

------------------- Sentence 1 -------------------

interests to the available programs; thus, can choose the best school or educational program.

>> Tokens are: 
 ['interests', 'available', 'programs', ';', 'thus', ',', 'choose', 'best', 'school', 'educational', 'program', '.']

>> Bigrams are: 
 [('interests', 'available'), ('available', 'programs'), ('programs', ';'), (';', 'thus'), ('thus', ','), (',', 'choose'), ('choose', 'best'), ('best', 'school'), ('school', 'educational'), ('educational', 'program'), ('program', '.')]

>> Trigrams are: 
 [('interests', 'available', 'programs'), ('available', 'programs', ';'), ('programs', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'choose'), (',', 'choose', 'best'), ('choose', 'best', 'school'), ('best', 'school', 'educational'), ('school', 'educational', 'program'), ('educational', 'program', '.')]

>> POS Tags are: 
 [('interests', 'NNS'), ('available', 'JJ'), ('programs', 'NNS'), (';', ':'), ('thus', 'RB'), (',', ','), ('choose', 'JJ'), ('best', 'JJS'), ('school', 'NN'), ('educational', 'JJ'), ('program', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['interests', 'available programs', 'school', 'educational program']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interests', 'interest'), ('available', 'avail'), ('programs', 'program'), (';', ';'), ('thus', 'thu'), (',', ','), ('choose', 'choos'), ('best', 'best'), ('school', 'school'), ('educational', 'educ'), ('program', 'program'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('interests', 'interest'), ('available', 'avail'), ('programs', 'program'), (';', ';'), ('thus', 'thus'), (',', ','), ('choose', 'choos'), ('best', 'best'), ('school', 'school'), ('educational', 'educ'), ('program', 'program'), ('.', '.')]

>> Lemmatization: 
 [('interests', 'interest'), ('available', 'available'), ('programs', 'program'), (';', ';'), ('thus', 'thus'), (',', ','), ('choose', 'choose'), ('best', 'best'), ('school', 'school'), ('educational', 'educational'), ('program', 'program'), ('.', '.')]


------------------- Sentence 2 -------------------

On

>> Tokens are: 
 ['On']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('On', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on')]

>> Lemmatization: 
 [('On', 'On')]



========================================== PARAGRAPH 1316 ===========================================

the other hand, big data helps teachers to understand the knowledge level of each student and tune  

------------------- Sentence 1 -------------------

the other hand, big data helps teachers to understand the knowledge level of each student and tune

>> Tokens are: 
 ['hand', ',', 'big', 'data', 'helps', 'teachers', 'understand', 'knowledge', 'level', 'student', 'tune']

>> Bigrams are: 
 [('hand', ','), (',', 'big'), ('big', 'data'), ('data', 'helps'), ('helps', 'teachers'), ('teachers', 'understand'), ('understand', 'knowledge'), ('knowledge', 'level'), ('level', 'student'), ('student', 'tune')]

>> Trigrams are: 
 [('hand', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'helps'), ('data', 'helps', 'teachers'), ('helps', 'teachers', 'understand'), ('teachers', 'understand', 'knowledge'), ('understand', 'knowledge', 'level'), ('knowledge', 'level', 'student'), ('level', 'student', 'tune')]

>> POS Tags are: 
 [('hand', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('helps', 'VBZ'), ('teachers', 'NNS'), ('understand', 'VBP'), ('knowledge', 'NN'), ('level', 'NN'), ('student', 'NN'), ('tune', 'NN')]

>> Noun Phrases are: 
 ['hand', 'big data', 'teachers', 'knowledge level student tune']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledg'), ('level', 'level'), ('student', 'student'), ('tune', 'tune')]

>> Stemming using Snowball Stemmer: 
 [('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledg'), ('level', 'level'), ('student', 'student'), ('tune', 'tune')]

>> Lemmatization: 
 [('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledge'), ('level', 'level'), ('student', 'student'), ('tune', 'tune')]



========================================== PARAGRAPH 1317 ===========================================

the teaching technique with the most valuable effect on an individual basis. Consequently, using  

------------------- Sentence 1 -------------------

the teaching technique with the most valuable effect on an individual basis.

>> Tokens are: 
 ['teaching', 'technique', 'valuable', 'effect', 'individual', 'basis', '.']

>> Bigrams are: 
 [('teaching', 'technique'), ('technique', 'valuable'), ('valuable', 'effect'), ('effect', 'individual'), ('individual', 'basis'), ('basis', '.')]

>> Trigrams are: 
 [('teaching', 'technique', 'valuable'), ('technique', 'valuable', 'effect'), ('valuable', 'effect', 'individual'), ('effect', 'individual', 'basis'), ('individual', 'basis', '.')]

>> POS Tags are: 
 [('teaching', 'VBG'), ('technique', 'NN'), ('valuable', 'JJ'), ('effect', 'NN'), ('individual', 'JJ'), ('basis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['technique', 'valuable effect', 'individual basis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('teaching', 'teach'), ('technique', 'techniqu'), ('valuable', 'valuabl'), ('effect', 'effect'), ('individual', 'individu'), ('basis', 'basi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('teaching', 'teach'), ('technique', 'techniqu'), ('valuable', 'valuabl'), ('effect', 'effect'), ('individual', 'individu'), ('basis', 'basi'), ('.', '.')]

>> Lemmatization: 
 [('teaching', 'teaching'), ('technique', 'technique'), ('valuable', 'valuable'), ('effect', 'effect'), ('individual', 'individual'), ('basis', 'basis'), ('.', '.')]


------------------- Sentence 2 -------------------

Consequently, using

>> Tokens are: 
 ['Consequently', ',', 'using']

>> Bigrams are: 
 [('Consequently', ','), (',', 'using')]

>> Trigrams are: 
 [('Consequently', ',', 'using')]

>> POS Tags are: 
 [('Consequently', 'RB'), (',', ','), ('using', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Consequently', 'consequ'), (',', ','), ('using', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Consequently', 'consequ'), (',', ','), ('using', 'use')]

>> Lemmatization: 
 [('Consequently', 'Consequently'), (',', ','), ('using', 'using')]



========================================== PARAGRAPH 1318 ===========================================

big data for guiding instructions in academia has a significant role in enhancing the educational  

------------------- Sentence 1 -------------------

big data for guiding instructions in academia has a significant role in enhancing the educational

>> Tokens are: 
 ['big', 'data', 'guiding', 'instructions', 'academia', 'significant', 'role', 'enhancing', 'educational']

>> Bigrams are: 
 [('big', 'data'), ('data', 'guiding'), ('guiding', 'instructions'), ('instructions', 'academia'), ('academia', 'significant'), ('significant', 'role'), ('role', 'enhancing'), ('enhancing', 'educational')]

>> Trigrams are: 
 [('big', 'data', 'guiding'), ('data', 'guiding', 'instructions'), ('guiding', 'instructions', 'academia'), ('instructions', 'academia', 'significant'), ('academia', 'significant', 'role'), ('significant', 'role', 'enhancing'), ('role', 'enhancing', 'educational')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('guiding', 'VBG'), ('instructions', 'NNS'), ('academia', 'VBP'), ('significant', 'JJ'), ('role', 'NN'), ('enhancing', 'VBG'), ('educational', 'JJ')]

>> Noun Phrases are: 
 ['big data', 'instructions', 'significant role']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('guiding', 'guid'), ('instructions', 'instruct'), ('academia', 'academia'), ('significant', 'signific'), ('role', 'role'), ('enhancing', 'enhanc'), ('educational', 'educ')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('guiding', 'guid'), ('instructions', 'instruct'), ('academia', 'academia'), ('significant', 'signific'), ('role', 'role'), ('enhancing', 'enhanc'), ('educational', 'educ')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('guiding', 'guiding'), ('instructions', 'instruction'), ('academia', 'academia'), ('significant', 'significant'), ('role', 'role'), ('enhancing', 'enhancing'), ('educational', 'educational')]



========================================== PARAGRAPH 1319 ===========================================

services by allowing students to access online instructors and communities at low-cost content.   

------------------- Sentence 1 -------------------

services by allowing students to access online instructors and communities at low-cost content.

>> Tokens are: 
 ['services', 'allowing', 'students', 'access', 'online', 'instructors', 'communities', 'low-cost', 'content', '.']

>> Bigrams are: 
 [('services', 'allowing'), ('allowing', 'students'), ('students', 'access'), ('access', 'online'), ('online', 'instructors'), ('instructors', 'communities'), ('communities', 'low-cost'), ('low-cost', 'content'), ('content', '.')]

>> Trigrams are: 
 [('services', 'allowing', 'students'), ('allowing', 'students', 'access'), ('students', 'access', 'online'), ('access', 'online', 'instructors'), ('online', 'instructors', 'communities'), ('instructors', 'communities', 'low-cost'), ('communities', 'low-cost', 'content'), ('low-cost', 'content', '.')]

>> POS Tags are: 
 [('services', 'NNS'), ('allowing', 'VBG'), ('students', 'NNS'), ('access', 'NN'), ('online', 'JJ'), ('instructors', 'NNS'), ('communities', 'NNS'), ('low-cost', 'JJ'), ('content', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['services', 'students access', 'online instructors communities', 'low-cost content']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('services', 'servic'), ('allowing', 'allow'), ('students', 'student'), ('access', 'access'), ('online', 'onlin'), ('instructors', 'instructor'), ('communities', 'commun'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('services', 'servic'), ('allowing', 'allow'), ('students', 'student'), ('access', 'access'), ('online', 'onlin'), ('instructors', 'instructor'), ('communities', 'communiti'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]

>> Lemmatization: 
 [('services', 'service'), ('allowing', 'allowing'), ('students', 'student'), ('access', 'access'), ('online', 'online'), ('instructors', 'instructor'), ('communities', 'community'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]



========================================== PARAGRAPH 1320 ===========================================

Technologies for controlling and analysing data are broadly available. Companies take advantage  

------------------- Sentence 1 -------------------

Technologies for controlling and analysing data are broadly available.

>> Tokens are: 
 ['Technologies', 'controlling', 'analysing', 'data', 'broadly', 'available', '.']

>> Bigrams are: 
 [('Technologies', 'controlling'), ('controlling', 'analysing'), ('analysing', 'data'), ('data', 'broadly'), ('broadly', 'available'), ('available', '.')]

>> Trigrams are: 
 [('Technologies', 'controlling', 'analysing'), ('controlling', 'analysing', 'data'), ('analysing', 'data', 'broadly'), ('data', 'broadly', 'available'), ('broadly', 'available', '.')]

>> POS Tags are: 
 [('Technologies', 'NNS'), ('controlling', 'VBG'), ('analysing', 'VBG'), ('data', 'NNS'), ('broadly', 'RB'), ('available', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Technologies', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Technologies', 'technolog'), ('controlling', 'control'), ('analysing', 'analys'), ('data', 'data'), ('broadly', 'broadli'), ('available', 'avail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technologies', 'technolog'), ('controlling', 'control'), ('analysing', 'analys'), ('data', 'data'), ('broadly', 'broad'), ('available', 'avail'), ('.', '.')]

>> Lemmatization: 
 [('Technologies', 'Technologies'), ('controlling', 'controlling'), ('analysing', 'analysing'), ('data', 'data'), ('broadly', 'broadly'), ('available', 'available'), ('.', '.')]


------------------- Sentence 2 -------------------

Companies take advantage

>> Tokens are: 
 ['Companies', 'take', 'advantage']

>> Bigrams are: 
 [('Companies', 'take'), ('take', 'advantage')]

>> Trigrams are: 
 [('Companies', 'take', 'advantage')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('take', 'VBP'), ('advantage', 'NN')]

>> Noun Phrases are: 
 ['Companies', 'advantage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('take', 'take'), ('advantage', 'advantag')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('take', 'take'), ('advantage', 'advantag')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('take', 'take'), ('advantage', 'advantage')]



========================================== PARAGRAPH 1321 ===========================================

of capturing the data to support accurate and stable business experimentation that direct decision  

------------------- Sentence 1 -------------------

of capturing the data to support accurate and stable business experimentation that direct decision

>> Tokens are: 
 ['capturing', 'data', 'support', 'accurate', 'stable', 'business', 'experimentation', 'direct', 'decision']

>> Bigrams are: 
 [('capturing', 'data'), ('data', 'support'), ('support', 'accurate'), ('accurate', 'stable'), ('stable', 'business'), ('business', 'experimentation'), ('experimentation', 'direct'), ('direct', 'decision')]

>> Trigrams are: 
 [('capturing', 'data', 'support'), ('data', 'support', 'accurate'), ('support', 'accurate', 'stable'), ('accurate', 'stable', 'business'), ('stable', 'business', 'experimentation'), ('business', 'experimentation', 'direct'), ('experimentation', 'direct', 'decision')]

>> POS Tags are: 
 [('capturing', 'VBG'), ('data', 'NNS'), ('support', 'NN'), ('accurate', 'NN'), ('stable', 'JJ'), ('business', 'NN'), ('experimentation', 'NN'), ('direct', 'JJ'), ('decision', 'NN')]

>> Noun Phrases are: 
 ['data support accurate', 'stable business experimentation', 'direct decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('capturing', 'captur'), ('data', 'data'), ('support', 'support'), ('accurate', 'accur'), ('stable', 'stabl'), ('business', 'busi'), ('experimentation', 'experiment'), ('direct', 'direct'), ('decision', 'decis')]

>> Stemming using Snowball Stemmer: 
 [('capturing', 'captur'), ('data', 'data'), ('support', 'support'), ('accurate', 'accur'), ('stable', 'stabl'), ('business', 'busi'), ('experimentation', 'experiment'), ('direct', 'direct'), ('decision', 'decis')]

>> Lemmatization: 
 [('capturing', 'capturing'), ('data', 'data'), ('support', 'support'), ('accurate', 'accurate'), ('stable', 'stable'), ('business', 'business'), ('experimentation', 'experimentation'), ('direct', 'direct'), ('decision', 'decision')]



========================================== PARAGRAPH 1322 ===========================================

makers. It might also evaluate outputs, business models, and restoration in customer experience.  

------------------- Sentence 1 -------------------

makers.

>> Tokens are: 
 ['makers', '.']

>> Bigrams are: 
 [('makers', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('makers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['makers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('makers', 'maker'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('makers', 'maker'), ('.', '.')]

>> Lemmatization: 
 [('makers', 'maker'), ('.', '.')]


------------------- Sentence 2 -------------------

It might also evaluate outputs, business models, and restoration in customer experience.

>> Tokens are: 
 ['It', 'might', 'also', 'evaluate', 'outputs', ',', 'business', 'models', ',', 'restoration', 'customer', 'experience', '.']

>> Bigrams are: 
 [('It', 'might'), ('might', 'also'), ('also', 'evaluate'), ('evaluate', 'outputs'), ('outputs', ','), (',', 'business'), ('business', 'models'), ('models', ','), (',', 'restoration'), ('restoration', 'customer'), ('customer', 'experience'), ('experience', '.')]

>> Trigrams are: 
 [('It', 'might', 'also'), ('might', 'also', 'evaluate'), ('also', 'evaluate', 'outputs'), ('evaluate', 'outputs', ','), ('outputs', ',', 'business'), (',', 'business', 'models'), ('business', 'models', ','), ('models', ',', 'restoration'), (',', 'restoration', 'customer'), ('restoration', 'customer', 'experience'), ('customer', 'experience', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('might', 'MD'), ('also', 'RB'), ('evaluate', 'VB'), ('outputs', 'NNS'), (',', ','), ('business', 'NN'), ('models', 'NNS'), (',', ','), ('restoration', 'NN'), ('customer', 'NN'), ('experience', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['outputs', 'business models', 'restoration customer experience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evalu'), ('outputs', 'output'), (',', ','), ('business', 'busi'), ('models', 'model'), (',', ','), ('restoration', 'restor'), ('customer', 'custom'), ('experience', 'experi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evalu'), ('outputs', 'output'), (',', ','), ('business', 'busi'), ('models', 'model'), (',', ','), ('restoration', 'restor'), ('customer', 'custom'), ('experience', 'experi'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evaluate'), ('outputs', 'output'), (',', ','), ('business', 'business'), ('models', 'model'), (',', ','), ('restoration', 'restoration'), ('customer', 'customer'), ('experience', 'experience'), ('.', '.')]



========================================== PARAGRAPH 1323 ===========================================

Trends allow directing a revolutionary transformation in research, invention, and business  

------------------- Sentence 1 -------------------

Trends allow directing a revolutionary transformation in research, invention, and business

>> Tokens are: 
 ['Trends', 'allow', 'directing', 'revolutionary', 'transformation', 'research', ',', 'invention', ',', 'business']

>> Bigrams are: 
 [('Trends', 'allow'), ('allow', 'directing'), ('directing', 'revolutionary'), ('revolutionary', 'transformation'), ('transformation', 'research'), ('research', ','), (',', 'invention'), ('invention', ','), (',', 'business')]

>> Trigrams are: 
 [('Trends', 'allow', 'directing'), ('allow', 'directing', 'revolutionary'), ('directing', 'revolutionary', 'transformation'), ('revolutionary', 'transformation', 'research'), ('transformation', 'research', ','), ('research', ',', 'invention'), (',', 'invention', ','), ('invention', ',', 'business')]

>> POS Tags are: 
 [('Trends', 'NNS'), ('allow', 'VBP'), ('directing', 'VBG'), ('revolutionary', 'JJ'), ('transformation', 'NN'), ('research', 'NN'), (',', ','), ('invention', 'NN'), (',', ','), ('business', 'NN')]

>> Noun Phrases are: 
 ['Trends', 'revolutionary transformation research', 'invention', 'business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Trends', 'trend'), ('allow', 'allow'), ('directing', 'direct'), ('revolutionary', 'revolutionari'), ('transformation', 'transform'), ('research', 'research'), (',', ','), ('invention', 'invent'), (',', ','), ('business', 'busi')]

>> Stemming using Snowball Stemmer: 
 [('Trends', 'trend'), ('allow', 'allow'), ('directing', 'direct'), ('revolutionary', 'revolutionari'), ('transformation', 'transform'), ('research', 'research'), (',', ','), ('invention', 'invent'), (',', ','), ('business', 'busi')]

>> Lemmatization: 
 [('Trends', 'Trends'), ('allow', 'allow'), ('directing', 'directing'), ('revolutionary', 'revolutionary'), ('transformation', 'transformation'), ('research', 'research'), (',', ','), ('invention', 'invention'), (',', ','), ('business', 'business')]



========================================== PARAGRAPH 1324 ===========================================

marketing.  Some firms like Amazon, Google, and eBay analyse elements that control performance  

------------------- Sentence 1 -------------------

marketing.

>> Tokens are: 
 ['marketing', '.']

>> Bigrams are: 
 [('marketing', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('marketing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['marketing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('marketing', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('marketing', 'market'), ('.', '.')]

>> Lemmatization: 
 [('marketing', 'marketing'), ('.', '.')]


------------------- Sentence 2 -------------------

Some firms like Amazon, Google, and eBay analyse elements that control performance

>> Tokens are: 
 ['Some', 'firms', 'like', 'Amazon', ',', 'Google', ',', 'eBay', 'analyse', 'elements', 'control', 'performance']

>> Bigrams are: 
 [('Some', 'firms'), ('firms', 'like'), ('like', 'Amazon'), ('Amazon', ','), (',', 'Google'), ('Google', ','), (',', 'eBay'), ('eBay', 'analyse'), ('analyse', 'elements'), ('elements', 'control'), ('control', 'performance')]

>> Trigrams are: 
 [('Some', 'firms', 'like'), ('firms', 'like', 'Amazon'), ('like', 'Amazon', ','), ('Amazon', ',', 'Google'), (',', 'Google', ','), ('Google', ',', 'eBay'), (',', 'eBay', 'analyse'), ('eBay', 'analyse', 'elements'), ('analyse', 'elements', 'control'), ('elements', 'control', 'performance')]

>> POS Tags are: 
 [('Some', 'DT'), ('firms', 'NNS'), ('like', 'IN'), ('Amazon', 'NNP'), (',', ','), ('Google', 'NNP'), (',', ','), ('eBay', 'NN'), ('analyse', 'JJ'), ('elements', 'NNS'), ('control', 'NN'), ('performance', 'NN')]

>> Noun Phrases are: 
 ['Some firms', 'Amazon', 'Google', 'eBay', 'analyse elements control performance']

>> Named Entities are: 
 [('PERSON', 'Amazon'), ('GPE', 'Google'), ('ORGANIZATION', 'eBay')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'amazon'), (',', ','), ('Google', 'googl'), (',', ','), ('eBay', 'ebay'), ('analyse', 'analys'), ('elements', 'element'), ('control', 'control'), ('performance', 'perform')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'amazon'), (',', ','), ('Google', 'googl'), (',', ','), ('eBay', 'ebay'), ('analyse', 'analys'), ('elements', 'element'), ('control', 'control'), ('performance', 'perform')]

>> Lemmatization: 
 [('Some', 'Some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'Amazon'), (',', ','), ('Google', 'Google'), (',', ','), ('eBay', 'eBay'), ('analyse', 'analyse'), ('elements', 'element'), ('control', 'control'), ('performance', 'performance')]



========================================== PARAGRAPH 1325 ===========================================

to determine factors that raise sales income and track the activity of users (Bughin et al., 2010).   

------------------- Sentence 1 -------------------

to determine factors that raise sales income and track the activity of users (Bughin et al., 2010).

>> Tokens are: 
 ['determine', 'factors', 'raise', 'sales', 'income', 'track', 'activity', 'users', '(', 'Bughin', 'et', 'al.', ',', '2010', ')', '.']

>> Bigrams are: 
 [('determine', 'factors'), ('factors', 'raise'), ('raise', 'sales'), ('sales', 'income'), ('income', 'track'), ('track', 'activity'), ('activity', 'users'), ('users', '('), ('(', 'Bughin'), ('Bughin', 'et'), ('et', 'al.'), ('al.', ','), (',', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('determine', 'factors', 'raise'), ('factors', 'raise', 'sales'), ('raise', 'sales', 'income'), ('sales', 'income', 'track'), ('income', 'track', 'activity'), ('track', 'activity', 'users'), ('activity', 'users', '('), ('users', '(', 'Bughin'), ('(', 'Bughin', 'et'), ('Bughin', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2010'), (',', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('determine', 'NN'), ('factors', 'NNS'), ('raise', 'VBP'), ('sales', 'NNS'), ('income', 'NN'), ('track', 'NN'), ('activity', 'NN'), ('users', 'NNS'), ('(', '('), ('Bughin', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['determine factors', 'sales income track activity users', 'Bughin']

>> Named Entities are: 
 [('PERSON', 'Bughin')] 

>> Stemming using Porter Stemmer: 
 [('determine', 'determin'), ('factors', 'factor'), ('raise', 'rais'), ('sales', 'sale'), ('income', 'incom'), ('track', 'track'), ('activity', 'activ'), ('users', 'user'), ('(', '('), ('Bughin', 'bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('determine', 'determin'), ('factors', 'factor'), ('raise', 'rais'), ('sales', 'sale'), ('income', 'incom'), ('track', 'track'), ('activity', 'activ'), ('users', 'user'), ('(', '('), ('Bughin', 'bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('determine', 'determine'), ('factors', 'factor'), ('raise', 'raise'), ('sales', 'sale'), ('income', 'income'), ('track', 'track'), ('activity', 'activity'), ('users', 'user'), ('(', '('), ('Bughin', 'Bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1326 ===========================================

Big data has an essential impact on financial institutions as they keep modifying their methods for  

------------------- Sentence 1 -------------------

Big data has an essential impact on financial institutions as they keep modifying their methods for

>> Tokens are: 
 ['Big', 'data', 'essential', 'impact', 'financial', 'institutions', 'keep', 'modifying', 'methods']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'essential'), ('essential', 'impact'), ('impact', 'financial'), ('financial', 'institutions'), ('institutions', 'keep'), ('keep', 'modifying'), ('modifying', 'methods')]

>> Trigrams are: 
 [('Big', 'data', 'essential'), ('data', 'essential', 'impact'), ('essential', 'impact', 'financial'), ('impact', 'financial', 'institutions'), ('financial', 'institutions', 'keep'), ('institutions', 'keep', 'modifying'), ('keep', 'modifying', 'methods')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('essential', 'JJ'), ('impact', 'NN'), ('financial', 'JJ'), ('institutions', 'NNS'), ('keep', 'VB'), ('modifying', 'VBG'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['Big data', 'essential impact', 'financial institutions', 'methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('essential', 'essenti'), ('impact', 'impact'), ('financial', 'financi'), ('institutions', 'institut'), ('keep', 'keep'), ('modifying', 'modifi'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('essential', 'essenti'), ('impact', 'impact'), ('financial', 'financi'), ('institutions', 'institut'), ('keep', 'keep'), ('modifying', 'modifi'), ('methods', 'method')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('essential', 'essential'), ('impact', 'impact'), ('financial', 'financial'), ('institutions', 'institution'), ('keep', 'keep'), ('modifying', 'modifying'), ('methods', 'method')]



========================================== PARAGRAPH 1327 ===========================================

segment credit card customers. Companies such as Brick and Mortar are utilizing big data to test  

------------------- Sentence 1 -------------------

segment credit card customers.

>> Tokens are: 
 ['segment', 'credit', 'card', 'customers', '.']

>> Bigrams are: 
 [('segment', 'credit'), ('credit', 'card'), ('card', 'customers'), ('customers', '.')]

>> Trigrams are: 
 [('segment', 'credit', 'card'), ('credit', 'card', 'customers'), ('card', 'customers', '.')]

>> POS Tags are: 
 [('segment', 'NN'), ('credit', 'NN'), ('card', 'NN'), ('customers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['segment credit card customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'custom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'custom'), ('.', '.')]

>> Lemmatization: 
 [('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'customer'), ('.', '.')]


------------------- Sentence 2 -------------------

Companies such as Brick and Mortar are utilizing big data to test

>> Tokens are: 
 ['Companies', 'Brick', 'Mortar', 'utilizing', 'big', 'data', 'test']

>> Bigrams are: 
 [('Companies', 'Brick'), ('Brick', 'Mortar'), ('Mortar', 'utilizing'), ('utilizing', 'big'), ('big', 'data'), ('data', 'test')]

>> Trigrams are: 
 [('Companies', 'Brick', 'Mortar'), ('Brick', 'Mortar', 'utilizing'), ('Mortar', 'utilizing', 'big'), ('utilizing', 'big', 'data'), ('big', 'data', 'test')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('Brick', 'NNP'), ('Mortar', 'NNP'), ('utilizing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('test', 'NN')]

>> Noun Phrases are: 
 ['Companies Brick Mortar', 'big data test']

>> Named Entities are: 
 [('PERSON', 'Brick Mortar')] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('Brick', 'brick'), ('Mortar', 'mortar'), ('utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('test', 'test')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('Brick', 'brick'), ('Mortar', 'mortar'), ('utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('test', 'test')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('Brick', 'Brick'), ('Mortar', 'Mortar'), ('utilizing', 'utilizing'), ('big', 'big'), ('data', 'data'), ('test', 'test')]



========================================== PARAGRAPH 1328 ===========================================

the ability to guide customer data by collecting transactional information from millions of  

------------------- Sentence 1 -------------------

the ability to guide customer data by collecting transactional information from millions of

>> Tokens are: 
 ['ability', 'guide', 'customer', 'data', 'collecting', 'transactional', 'information', 'millions']

>> Bigrams are: 
 [('ability', 'guide'), ('guide', 'customer'), ('customer', 'data'), ('data', 'collecting'), ('collecting', 'transactional'), ('transactional', 'information'), ('information', 'millions')]

>> Trigrams are: 
 [('ability', 'guide', 'customer'), ('guide', 'customer', 'data'), ('customer', 'data', 'collecting'), ('data', 'collecting', 'transactional'), ('collecting', 'transactional', 'information'), ('transactional', 'information', 'millions')]

>> POS Tags are: 
 [('ability', 'NN'), ('guide', 'VBP'), ('customer', 'NN'), ('data', 'NNS'), ('collecting', 'VBG'), ('transactional', 'JJ'), ('information', 'NN'), ('millions', 'NNS')]

>> Noun Phrases are: 
 ['ability', 'customer data', 'transactional information millions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ability', 'abil'), ('guide', 'guid'), ('customer', 'custom'), ('data', 'data'), ('collecting', 'collect'), ('transactional', 'transact'), ('information', 'inform'), ('millions', 'million')]

>> Stemming using Snowball Stemmer: 
 [('ability', 'abil'), ('guide', 'guid'), ('customer', 'custom'), ('data', 'data'), ('collecting', 'collect'), ('transactional', 'transact'), ('information', 'inform'), ('millions', 'million')]

>> Lemmatization: 
 [('ability', 'ability'), ('guide', 'guide'), ('customer', 'customer'), ('data', 'data'), ('collecting', 'collecting'), ('transactional', 'transactional'), ('information', 'information'), ('millions', 'million')]



========================================== PARAGRAPH 1329 ===========================================

customers, then use the collected information in analysing new opportunities such as optimizing  

------------------- Sentence 1 -------------------

customers, then use the collected information in analysing new opportunities such as optimizing

>> Tokens are: 
 ['customers', ',', 'use', 'collected', 'information', 'analysing', 'new', 'opportunities', 'optimizing']

>> Bigrams are: 
 [('customers', ','), (',', 'use'), ('use', 'collected'), ('collected', 'information'), ('information', 'analysing'), ('analysing', 'new'), ('new', 'opportunities'), ('opportunities', 'optimizing')]

>> Trigrams are: 
 [('customers', ',', 'use'), (',', 'use', 'collected'), ('use', 'collected', 'information'), ('collected', 'information', 'analysing'), ('information', 'analysing', 'new'), ('analysing', 'new', 'opportunities'), ('new', 'opportunities', 'optimizing')]

>> POS Tags are: 
 [('customers', 'NNS'), (',', ','), ('use', 'RB'), ('collected', 'VBN'), ('information', 'NN'), ('analysing', 'VBG'), ('new', 'JJ'), ('opportunities', 'NNS'), ('optimizing', 'VBG')]

>> Noun Phrases are: 
 ['customers', 'information', 'new opportunities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('customers', 'custom'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('information', 'inform'), ('analysing', 'analys'), ('new', 'new'), ('opportunities', 'opportun'), ('optimizing', 'optim')]

>> Stemming using Snowball Stemmer: 
 [('customers', 'custom'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('information', 'inform'), ('analysing', 'analys'), ('new', 'new'), ('opportunities', 'opportun'), ('optimizing', 'optim')]

>> Lemmatization: 
 [('customers', 'customer'), (',', ','), ('use', 'use'), ('collected', 'collected'), ('information', 'information'), ('analysing', 'analysing'), ('new', 'new'), ('opportunities', 'opportunity'), ('optimizing', 'optimizing')]



========================================== PARAGRAPH 1330 ===========================================

the most effective promotions. Other companies use data mining to gather information from social  

------------------- Sentence 1 -------------------

the most effective promotions.

>> Tokens are: 
 ['effective', 'promotions', '.']

>> Bigrams are: 
 [('effective', 'promotions'), ('promotions', '.')]

>> Trigrams are: 
 [('effective', 'promotions', '.')]

>> POS Tags are: 
 [('effective', 'JJ'), ('promotions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['effective promotions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('effective', 'effect'), ('promotions', 'promot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('effective', 'effect'), ('promotions', 'promot'), ('.', '.')]

>> Lemmatization: 
 [('effective', 'effective'), ('promotions', 'promotion'), ('.', '.')]


------------------- Sentence 2 -------------------

Other companies use data mining to gather information from social

>> Tokens are: 
 ['Other', 'companies', 'use', 'data', 'mining', 'gather', 'information', 'social']

>> Bigrams are: 
 [('Other', 'companies'), ('companies', 'use'), ('use', 'data'), ('data', 'mining'), ('mining', 'gather'), ('gather', 'information'), ('information', 'social')]

>> Trigrams are: 
 [('Other', 'companies', 'use'), ('companies', 'use', 'data'), ('use', 'data', 'mining'), ('data', 'mining', 'gather'), ('mining', 'gather', 'information'), ('gather', 'information', 'social')]

>> POS Tags are: 
 [('Other', 'JJ'), ('companies', 'NNS'), ('use', 'VBP'), ('data', 'NNS'), ('mining', 'NN'), ('gather', 'NN'), ('information', 'NN'), ('social', 'JJ')]

>> Noun Phrases are: 
 ['Other companies', 'data mining gather information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('companies', 'compani'), ('use', 'use'), ('data', 'data'), ('mining', 'mine'), ('gather', 'gather'), ('information', 'inform'), ('social', 'social')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('companies', 'compani'), ('use', 'use'), ('data', 'data'), ('mining', 'mine'), ('gather', 'gather'), ('information', 'inform'), ('social', 'social')]

>> Lemmatization: 
 [('Other', 'Other'), ('companies', 'company'), ('use', 'use'), ('data', 'data'), ('mining', 'mining'), ('gather', 'gather'), ('information', 'information'), ('social', 'social')]



========================================== PARAGRAPH 1331 ===========================================

media. Southwest Airlines, Ford motor, and Pepsico analyse consumer posts on social media like  

------------------- Sentence 1 -------------------

media.

>> Tokens are: 
 ['media', '.']

>> Bigrams are: 
 [('media', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('media', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['media']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('media', 'media'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('media', 'media'), ('.', '.')]

>> Lemmatization: 
 [('media', 'medium'), ('.', '.')]


------------------- Sentence 2 -------------------

Southwest Airlines, Ford motor, and Pepsico analyse consumer posts on social media like

>> Tokens are: 
 ['Southwest', 'Airlines', ',', 'Ford', 'motor', ',', 'Pepsico', 'analyse', 'consumer', 'posts', 'social', 'media', 'like']

>> Bigrams are: 
 [('Southwest', 'Airlines'), ('Airlines', ','), (',', 'Ford'), ('Ford', 'motor'), ('motor', ','), (',', 'Pepsico'), ('Pepsico', 'analyse'), ('analyse', 'consumer'), ('consumer', 'posts'), ('posts', 'social'), ('social', 'media'), ('media', 'like')]

>> Trigrams are: 
 [('Southwest', 'Airlines', ','), ('Airlines', ',', 'Ford'), (',', 'Ford', 'motor'), ('Ford', 'motor', ','), ('motor', ',', 'Pepsico'), (',', 'Pepsico', 'analyse'), ('Pepsico', 'analyse', 'consumer'), ('analyse', 'consumer', 'posts'), ('consumer', 'posts', 'social'), ('posts', 'social', 'media'), ('social', 'media', 'like')]

>> POS Tags are: 
 [('Southwest', 'NNP'), ('Airlines', 'NNPS'), (',', ','), ('Ford', 'NNP'), ('motor', 'NN'), (',', ','), ('Pepsico', 'NNP'), ('analyse', 'VBZ'), ('consumer', 'NN'), ('posts', 'NNS'), ('social', 'JJ'), ('media', 'NNS'), ('like', 'IN')]

>> Noun Phrases are: 
 ['Southwest', 'Ford motor', 'Pepsico', 'consumer posts', 'social media']

>> Named Entities are: 
 [('GPE', 'Southwest'), ('ORGANIZATION', 'Airlines'), ('ORGANIZATION', 'Ford'), ('PERSON', 'Pepsico')] 

>> Stemming using Porter Stemmer: 
 [('Southwest', 'southwest'), ('Airlines', 'airlin'), (',', ','), ('Ford', 'ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'pepsico'), ('analyse', 'analys'), ('consumer', 'consum'), ('posts', 'post'), ('social', 'social'), ('media', 'media'), ('like', 'like')]

>> Stemming using Snowball Stemmer: 
 [('Southwest', 'southwest'), ('Airlines', 'airlin'), (',', ','), ('Ford', 'ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'pepsico'), ('analyse', 'analys'), ('consumer', 'consum'), ('posts', 'post'), ('social', 'social'), ('media', 'media'), ('like', 'like')]

>> Lemmatization: 
 [('Southwest', 'Southwest'), ('Airlines', 'Airlines'), (',', ','), ('Ford', 'Ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'Pepsico'), ('analyse', 'analyse'), ('consumer', 'consumer'), ('posts', 'post'), ('social', 'social'), ('media', 'medium'), ('like', 'like')]



========================================== PARAGRAPH 1332 ===========================================

Facebook and Twitter to standard the immediate influence on a movement and track the consumer  

------------------- Sentence 1 -------------------

Facebook and Twitter to standard the immediate influence on a movement and track the consumer

>> Tokens are: 
 ['Facebook', 'Twitter', 'standard', 'immediate', 'influence', 'movement', 'track', 'consumer']

>> Bigrams are: 
 [('Facebook', 'Twitter'), ('Twitter', 'standard'), ('standard', 'immediate'), ('immediate', 'influence'), ('influence', 'movement'), ('movement', 'track'), ('track', 'consumer')]

>> Trigrams are: 
 [('Facebook', 'Twitter', 'standard'), ('Twitter', 'standard', 'immediate'), ('standard', 'immediate', 'influence'), ('immediate', 'influence', 'movement'), ('influence', 'movement', 'track'), ('movement', 'track', 'consumer')]

>> POS Tags are: 
 [('Facebook', 'NNP'), ('Twitter', 'NNP'), ('standard', 'NN'), ('immediate', 'JJ'), ('influence', 'NN'), ('movement', 'NN'), ('track', 'NN'), ('consumer', 'NN')]

>> Noun Phrases are: 
 ['Facebook Twitter standard', 'immediate influence movement track consumer']

>> Named Entities are: 
 [('PERSON', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('Facebook', 'facebook'), ('Twitter', 'twitter'), ('standard', 'standard'), ('immediate', 'immedi'), ('influence', 'influenc'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consum')]

>> Stemming using Snowball Stemmer: 
 [('Facebook', 'facebook'), ('Twitter', 'twitter'), ('standard', 'standard'), ('immediate', 'immedi'), ('influence', 'influenc'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consum')]

>> Lemmatization: 
 [('Facebook', 'Facebook'), ('Twitter', 'Twitter'), ('standard', 'standard'), ('immediate', 'immediate'), ('influence', 'influence'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consumer')]



========================================== PARAGRAPH 1333 ===========================================

opinions about their products. 

------------------- Sentence 1 -------------------

opinions about their products.

>> Tokens are: 
 ['opinions', 'products', '.']

>> Bigrams are: 
 [('opinions', 'products'), ('products', '.')]

>> Trigrams are: 
 [('opinions', 'products', '.')]

>> POS Tags are: 
 [('opinions', 'NNS'), ('products', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['opinions products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('opinions', 'opinion'), ('products', 'product'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('opinions', 'opinion'), ('products', 'product'), ('.', '.')]

>> Lemmatization: 
 [('opinions', 'opinion'), ('products', 'product'), ('.', '.')]



========================================== PARAGRAPH 1334 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1335 ===========================================

46  

------------------- Sentence 1 -------------------

46

>> Tokens are: 
 ['46']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('46', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('46', '46')]

>> Stemming using Snowball Stemmer: 
 [('46', '46')]

>> Lemmatization: 
 [('46', '46')]



========================================== PARAGRAPH 1336 ===========================================

  


========================================== PARAGRAPH 1337 ===========================================

Big data has an impact on many aspects of society resulting in societal benefits. On the medical  

------------------- Sentence 1 -------------------

Big data has an impact on many aspects of society resulting in societal benefits.

>> Tokens are: 
 ['Big', 'data', 'impact', 'many', 'aspects', 'society', 'resulting', 'societal', 'benefits', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'impact'), ('impact', 'many'), ('many', 'aspects'), ('aspects', 'society'), ('society', 'resulting'), ('resulting', 'societal'), ('societal', 'benefits'), ('benefits', '.')]

>> Trigrams are: 
 [('Big', 'data', 'impact'), ('data', 'impact', 'many'), ('impact', 'many', 'aspects'), ('many', 'aspects', 'society'), ('aspects', 'society', 'resulting'), ('society', 'resulting', 'societal'), ('resulting', 'societal', 'benefits'), ('societal', 'benefits', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('impact', 'NN'), ('many', 'JJ'), ('aspects', 'NNS'), ('society', 'NN'), ('resulting', 'VBG'), ('societal', 'JJ'), ('benefits', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data impact', 'many aspects society', 'societal benefits']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('impact', 'impact'), ('many', 'mani'), ('aspects', 'aspect'), ('society', 'societi'), ('resulting', 'result'), ('societal', 'societ'), ('benefits', 'benefit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('impact', 'impact'), ('many', 'mani'), ('aspects', 'aspect'), ('society', 'societi'), ('resulting', 'result'), ('societal', 'societ'), ('benefits', 'benefit'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('impact', 'impact'), ('many', 'many'), ('aspects', 'aspect'), ('society', 'society'), ('resulting', 'resulting'), ('societal', 'societal'), ('benefits', 'benefit'), ('.', '.')]


------------------- Sentence 2 -------------------

On the medical

>> Tokens are: 
 ['On', 'medical']

>> Bigrams are: 
 [('On', 'medical')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('On', 'IN'), ('medical', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('medical', 'medic')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('medical', 'medic')]

>> Lemmatization: 
 [('On', 'On'), ('medical', 'medical')]



========================================== PARAGRAPH 1338 ===========================================

system, for example, it gives benefits of saving lives, as using big data enables the doctors to decide  

------------------- Sentence 1 -------------------

system, for example, it gives benefits of saving lives, as using big data enables the doctors to decide

>> Tokens are: 
 ['system', ',', 'example', ',', 'gives', 'benefits', 'saving', 'lives', ',', 'using', 'big', 'data', 'enables', 'doctors', 'decide']

>> Bigrams are: 
 [('system', ','), (',', 'example'), ('example', ','), (',', 'gives'), ('gives', 'benefits'), ('benefits', 'saving'), ('saving', 'lives'), ('lives', ','), (',', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'enables'), ('enables', 'doctors'), ('doctors', 'decide')]

>> Trigrams are: 
 [('system', ',', 'example'), (',', 'example', ','), ('example', ',', 'gives'), (',', 'gives', 'benefits'), ('gives', 'benefits', 'saving'), ('benefits', 'saving', 'lives'), ('saving', 'lives', ','), ('lives', ',', 'using'), (',', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'enables'), ('data', 'enables', 'doctors'), ('enables', 'doctors', 'decide')]

>> POS Tags are: 
 [('system', 'NN'), (',', ','), ('example', 'NN'), (',', ','), ('gives', 'VBZ'), ('benefits', 'NNS'), ('saving', 'VBG'), ('lives', 'NNS'), (',', ','), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('enables', 'NNS'), ('doctors', 'NNS'), ('decide', 'VBP')]

>> Noun Phrases are: 
 ['system', 'example', 'benefits', 'lives', 'big data enables doctors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('system', 'system'), (',', ','), ('example', 'exampl'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'save'), ('lives', 'live'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('enables', 'enabl'), ('doctors', 'doctor'), ('decide', 'decid')]

>> Stemming using Snowball Stemmer: 
 [('system', 'system'), (',', ','), ('example', 'exampl'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'save'), ('lives', 'live'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('enables', 'enabl'), ('doctors', 'doctor'), ('decide', 'decid')]

>> Lemmatization: 
 [('system', 'system'), (',', ','), ('example', 'example'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'saving'), ('lives', 'life'), (',', ','), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('enables', 'enables'), ('doctors', 'doctor'), ('decide', 'decide')]



========================================== PARAGRAPH 1339 ===========================================

which medication is the best to a patient. The patient does not need to wait long times, get severe  

------------------- Sentence 1 -------------------

which medication is the best to a patient.

>> Tokens are: 
 ['medication', 'best', 'patient', '.']

>> Bigrams are: 
 [('medication', 'best'), ('best', 'patient'), ('patient', '.')]

>> Trigrams are: 
 [('medication', 'best', 'patient'), ('best', 'patient', '.')]

>> POS Tags are: 
 [('medication', 'NN'), ('best', 'RBS'), ('patient', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['medication', 'patient']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('medication', 'medic'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('medication', 'medic'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]

>> Lemmatization: 
 [('medication', 'medication'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]


------------------- Sentence 2 -------------------

The patient does not need to wait long times, get severe

>> Tokens are: 
 ['The', 'patient', 'need', 'wait', 'long', 'times', ',', 'get', 'severe']

>> Bigrams are: 
 [('The', 'patient'), ('patient', 'need'), ('need', 'wait'), ('wait', 'long'), ('long', 'times'), ('times', ','), (',', 'get'), ('get', 'severe')]

>> Trigrams are: 
 [('The', 'patient', 'need'), ('patient', 'need', 'wait'), ('need', 'wait', 'long'), ('wait', 'long', 'times'), ('long', 'times', ','), ('times', ',', 'get'), (',', 'get', 'severe')]

>> POS Tags are: 
 [('The', 'DT'), ('patient', 'NN'), ('need', 'MD'), ('wait', 'VB'), ('long', 'JJ'), ('times', 'NNS'), (',', ','), ('get', 'VB'), ('severe', 'JJ')]

>> Noun Phrases are: 
 ['The patient', 'long times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'sever')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'sever')]

>> Lemmatization: 
 [('The', 'The'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'severe')]



========================================== PARAGRAPH 1340 ===========================================

reactions, or dying from using medicines that do not fit with their case.  

------------------- Sentence 1 -------------------

reactions, or dying from using medicines that do not fit with their case.

>> Tokens are: 
 ['reactions', ',', 'dying', 'using', 'medicines', 'fit', 'case', '.']

>> Bigrams are: 
 [('reactions', ','), (',', 'dying'), ('dying', 'using'), ('using', 'medicines'), ('medicines', 'fit'), ('fit', 'case'), ('case', '.')]

>> Trigrams are: 
 [('reactions', ',', 'dying'), (',', 'dying', 'using'), ('dying', 'using', 'medicines'), ('using', 'medicines', 'fit'), ('medicines', 'fit', 'case'), ('fit', 'case', '.')]

>> POS Tags are: 
 [('reactions', 'NNS'), (',', ','), ('dying', 'VBG'), ('using', 'VBG'), ('medicines', 'NNS'), ('fit', 'JJ'), ('case', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['reactions', 'medicines', 'fit case']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reactions', 'reaction'), (',', ','), ('dying', 'die'), ('using', 'use'), ('medicines', 'medicin'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reactions', 'reaction'), (',', ','), ('dying', 'die'), ('using', 'use'), ('medicines', 'medicin'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]

>> Lemmatization: 
 [('reactions', 'reaction'), (',', ','), ('dying', 'dying'), ('using', 'using'), ('medicines', 'medicine'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]



========================================== PARAGRAPH 1341 ===========================================

  


========================================== PARAGRAPH 1342 ===========================================

12. Conclusion and Future Research  

------------------- Sentence 1 -------------------

12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]


------------------- Sentence 2 -------------------

Conclusion and Future Research

>> Tokens are: 
 ['Conclusion', 'Future', 'Research']

>> Bigrams are: 
 [('Conclusion', 'Future'), ('Future', 'Research')]

>> Trigrams are: 
 [('Conclusion', 'Future', 'Research')]

>> POS Tags are: 
 [('Conclusion', 'NNP'), ('Future', 'NNP'), ('Research', 'NNP')]

>> Noun Phrases are: 
 ['Conclusion Future Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research')]

>> Lemmatization: 
 [('Conclusion', 'Conclusion'), ('Future', 'Future'), ('Research', 'Research')]



========================================== PARAGRAPH 1343 ===========================================

The purpose of this study was to offer a literature review on the topic of big data analytics. This  

------------------- Sentence 1 -------------------

The purpose of this study was to offer a literature review on the topic of big data analytics.

>> Tokens are: 
 ['The', 'purpose', 'study', 'offer', 'literature', 'review', 'topic', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'purpose'), ('purpose', 'study'), ('study', 'offer'), ('offer', 'literature'), ('literature', 'review'), ('review', 'topic'), ('topic', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'purpose', 'study'), ('purpose', 'study', 'offer'), ('study', 'offer', 'literature'), ('offer', 'literature', 'review'), ('literature', 'review', 'topic'), ('review', 'topic', 'big'), ('topic', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('purpose', 'NN'), ('study', 'NN'), ('offer', 'VBP'), ('literature', 'NN'), ('review', 'NN'), ('topic', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The purpose study', 'literature review topic', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('study', 'studi'), ('offer', 'offer'), ('literature', 'literatur'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('study', 'studi'), ('offer', 'offer'), ('literature', 'literatur'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('purpose', 'purpose'), ('study', 'study'), ('offer', 'offer'), ('literature', 'literature'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

This

>> Tokens are: 
 ['This']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('This', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this')]

>> Lemmatization: 
 [('This', 'This')]



========================================== PARAGRAPH 1344 ===========================================

began with the presentation of a general background to the topic, including big data definitions  

------------------- Sentence 1 -------------------

began with the presentation of a general background to the topic, including big data definitions

>> Tokens are: 
 ['began', 'presentation', 'general', 'background', 'topic', ',', 'including', 'big', 'data', 'definitions']

>> Bigrams are: 
 [('began', 'presentation'), ('presentation', 'general'), ('general', 'background'), ('background', 'topic'), ('topic', ','), (',', 'including'), ('including', 'big'), ('big', 'data'), ('data', 'definitions')]

>> Trigrams are: 
 [('began', 'presentation', 'general'), ('presentation', 'general', 'background'), ('general', 'background', 'topic'), ('background', 'topic', ','), ('topic', ',', 'including'), (',', 'including', 'big'), ('including', 'big', 'data'), ('big', 'data', 'definitions')]

>> POS Tags are: 
 [('began', 'VBD'), ('presentation', 'JJ'), ('general', 'JJ'), ('background', 'NN'), ('topic', 'NN'), (',', ','), ('including', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS')]

>> Noun Phrases are: 
 ['presentation general background topic', 'big data definitions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('began', 'began'), ('presentation', 'present'), ('general', 'gener'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'includ'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit')]

>> Stemming using Snowball Stemmer: 
 [('began', 'began'), ('presentation', 'present'), ('general', 'general'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'includ'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit')]

>> Lemmatization: 
 [('began', 'began'), ('presentation', 'presentation'), ('general', 'general'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'including'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition')]



========================================== PARAGRAPH 1345 ===========================================

and characteristics, followed by a review of big data analytics tools and methods.  

------------------- Sentence 1 -------------------

and characteristics, followed by a review of big data analytics tools and methods.

>> Tokens are: 
 ['characteristics', ',', 'followed', 'review', 'big', 'data', 'analytics', 'tools', 'methods', '.']

>> Bigrams are: 
 [('characteristics', ','), (',', 'followed'), ('followed', 'review'), ('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('characteristics', ',', 'followed'), (',', 'followed', 'review'), ('followed', 'review', 'big'), ('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'methods'), ('tools', 'methods', '.')]

>> POS Tags are: 
 [('characteristics', 'NNS'), (',', ','), ('followed', 'VBD'), ('review', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['characteristics', 'review', 'big data analytics tools methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('characteristics', 'characterist'), (',', ','), ('followed', 'follow'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('characteristics', 'characterist'), (',', ','), ('followed', 'follow'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('characteristics', 'characteristic'), (',', ','), ('followed', 'followed'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]



========================================== PARAGRAPH 1346 ===========================================

  


========================================== PARAGRAPH 1347 ===========================================

This thesis presented data analysis techniques characterised in four sections: supervised,  

------------------- Sentence 1 -------------------

This thesis presented data analysis techniques characterised in four sections: supervised,

>> Tokens are: 
 ['This', 'thesis', 'presented', 'data', 'analysis', 'techniques', 'characterised', 'four', 'sections', ':', 'supervised', ',']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'presented'), ('presented', 'data'), ('data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'characterised'), ('characterised', 'four'), ('four', 'sections'), ('sections', ':'), (':', 'supervised'), ('supervised', ',')]

>> Trigrams are: 
 [('This', 'thesis', 'presented'), ('thesis', 'presented', 'data'), ('presented', 'data', 'analysis'), ('data', 'analysis', 'techniques'), ('analysis', 'techniques', 'characterised'), ('techniques', 'characterised', 'four'), ('characterised', 'four', 'sections'), ('four', 'sections', ':'), ('sections', ':', 'supervised'), (':', 'supervised', ',')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('presented', 'VBD'), ('data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('characterised', 'VBD'), ('four', 'CD'), ('sections', 'NNS'), (':', ':'), ('supervised', 'VBN'), (',', ',')]

>> Noun Phrases are: 
 ['This thesis', 'data analysis techniques', 'sections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('presented', 'present'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervis'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('presented', 'present'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervis'), (',', ',')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('presented', 'presented'), ('data', 'data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('characterised', 'characterised'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervised'), (',', ',')]



========================================== PARAGRAPH 1348 ===========================================

unsupervised, semi-supervised, and reinforcement learning. Some analytics techniques were also  

------------------- Sentence 1 -------------------

unsupervised, semi-supervised, and reinforcement learning.

>> Tokens are: 
 ['unsupervised', ',', 'semi-supervised', ',', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('unsupervised', ','), (',', 'semi-supervised'), ('semi-supervised', ','), (',', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('unsupervised', ',', 'semi-supervised'), (',', 'semi-supervised', ','), ('semi-supervised', ',', 'reinforcement'), (',', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('unsupervised', 'JJ'), (',', ','), ('semi-supervised', 'JJ'), (',', ','), ('reinforcement', 'JJ'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unsupervised', 'unsupervis'), (',', ','), ('semi-supervised', 'semi-supervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unsupervised', 'unsupervis'), (',', ','), ('semi-supervised', 'semi-supervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('unsupervised', 'unsupervised'), (',', ','), ('semi-supervised', 'semi-supervised'), (',', ','), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Some analytics techniques were also

>> Tokens are: 
 ['Some', 'analytics', 'techniques', 'also']

>> Bigrams are: 
 [('Some', 'analytics'), ('analytics', 'techniques'), ('techniques', 'also')]

>> Trigrams are: 
 [('Some', 'analytics', 'techniques'), ('analytics', 'techniques', 'also')]

>> POS Tags are: 
 [('Some', 'DT'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('also', 'RB')]

>> Noun Phrases are: 
 ['Some analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('also', 'also')]

>> Lemmatization: 
 [('Some', 'Some'), ('analytics', 'analytics'), ('techniques', 'technique'), ('also', 'also')]



========================================== PARAGRAPH 1349 ===========================================

presented, such as clustering, correlation, regression, and factor analytics, and some big data tools  

------------------- Sentence 1 -------------------

presented, such as clustering, correlation, regression, and factor analytics, and some big data tools

>> Tokens are: 
 ['presented', ',', 'clustering', ',', 'correlation', ',', 'regression', ',', 'factor', 'analytics', ',', 'big', 'data', 'tools']

>> Bigrams are: 
 [('presented', ','), (',', 'clustering'), ('clustering', ','), (',', 'correlation'), ('correlation', ','), (',', 'regression'), ('regression', ','), (',', 'factor'), ('factor', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', 'tools')]

>> Trigrams are: 
 [('presented', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'correlation'), (',', 'correlation', ','), ('correlation', ',', 'regression'), (',', 'regression', ','), ('regression', ',', 'factor'), (',', 'factor', 'analytics'), ('factor', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'tools')]

>> POS Tags are: 
 [('presented', 'VBN'), (',', ','), ('clustering', 'VBG'), (',', ','), ('correlation', 'NN'), (',', ','), ('regression', 'NN'), (',', ','), ('factor', 'NN'), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['correlation', 'regression', 'factor analytics', 'big data tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('presented', 'present'), (',', ','), ('clustering', 'cluster'), (',', ','), ('correlation', 'correl'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('presented', 'present'), (',', ','), ('clustering', 'cluster'), (',', ','), ('correlation', 'correl'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool')]

>> Lemmatization: 
 [('presented', 'presented'), (',', ','), ('clustering', 'clustering'), (',', ','), ('correlation', 'correlation'), (',', ','), ('regression', 'regression'), (',', ','), ('factor', 'factor'), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool')]



========================================== PARAGRAPH 1350 ===========================================

and platforms such as Hadoop, Apache Mahout, and R were explained in relation to these. Big  

------------------- Sentence 1 -------------------

and platforms such as Hadoop, Apache Mahout, and R were explained in relation to these.

>> Tokens are: 
 ['platforms', 'Hadoop', ',', 'Apache', 'Mahout', ',', 'R', 'explained', 'relation', '.']

>> Bigrams are: 
 [('platforms', 'Hadoop'), ('Hadoop', ','), (',', 'Apache'), ('Apache', 'Mahout'), ('Mahout', ','), (',', 'R'), ('R', 'explained'), ('explained', 'relation'), ('relation', '.')]

>> Trigrams are: 
 [('platforms', 'Hadoop', ','), ('Hadoop', ',', 'Apache'), (',', 'Apache', 'Mahout'), ('Apache', 'Mahout', ','), ('Mahout', ',', 'R'), (',', 'R', 'explained'), ('R', 'explained', 'relation'), ('explained', 'relation', '.')]

>> POS Tags are: 
 [('platforms', 'NNS'), ('Hadoop', 'NNP'), (',', ','), ('Apache', 'NNP'), ('Mahout', 'NNP'), (',', ','), ('R', 'NNP'), ('explained', 'VBD'), ('relation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['platforms Hadoop', 'Apache Mahout', 'R', 'relation']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Apache Mahout'), ('PERSON', 'R')] 

>> Stemming using Porter Stemmer: 
 [('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('R', 'r'), ('explained', 'explain'), ('relation', 'relat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('R', 'r'), ('explained', 'explain'), ('relation', 'relat'), ('.', '.')]

>> Lemmatization: 
 [('platforms', 'platform'), ('Hadoop', 'Hadoop'), (',', ','), ('Apache', 'Apache'), ('Mahout', 'Mahout'), (',', ','), ('R', 'R'), ('explained', 'explained'), ('relation', 'relation'), ('.', '.')]


------------------- Sentence 2 -------------------

Big

>> Tokens are: 
 ['Big']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big')]

>> Lemmatization: 
 [('Big', 'Big')]



========================================== PARAGRAPH 1351 ===========================================

data storage, management, and analytics processing were also discussed, and some emergent  

------------------- Sentence 1 -------------------

data storage, management, and analytics processing were also discussed, and some emergent

>> Tokens are: 
 ['data', 'storage', ',', 'management', ',', 'analytics', 'processing', 'also', 'discussed', ',', 'emergent']

>> Bigrams are: 
 [('data', 'storage'), ('storage', ','), (',', 'management'), ('management', ','), (',', 'analytics'), ('analytics', 'processing'), ('processing', 'also'), ('also', 'discussed'), ('discussed', ','), (',', 'emergent')]

>> Trigrams are: 
 [('data', 'storage', ','), ('storage', ',', 'management'), (',', 'management', ','), ('management', ',', 'analytics'), (',', 'analytics', 'processing'), ('analytics', 'processing', 'also'), ('processing', 'also', 'discussed'), ('also', 'discussed', ','), ('discussed', ',', 'emergent')]

>> POS Tags are: 
 [('data', 'NNS'), ('storage', 'NN'), (',', ','), ('management', 'NN'), (',', ','), ('analytics', 'NNS'), ('processing', 'NN'), ('also', 'RB'), ('discussed', 'VBD'), (',', ','), ('emergent', 'NN')]

>> Noun Phrases are: 
 ['data storage', 'management', 'analytics processing', 'emergent']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('analytics', 'analyt'), ('processing', 'process'), ('also', 'also'), ('discussed', 'discuss'), (',', ','), ('emergent', 'emerg')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('analytics', 'analyt'), ('processing', 'process'), ('also', 'also'), ('discussed', 'discuss'), (',', ','), ('emergent', 'emerg')]

>> Lemmatization: 
 [('data', 'data'), ('storage', 'storage'), (',', ','), ('management', 'management'), (',', ','), ('analytics', 'analytics'), ('processing', 'processing'), ('also', 'also'), ('discussed', 'discussed'), (',', ','), ('emergent', 'emergent')]



========================================== PARAGRAPH 1352 ===========================================

advanced data analytics techniques further examined.  

------------------- Sentence 1 -------------------

advanced data analytics techniques further examined.

>> Tokens are: 
 ['advanced', 'data', 'analytics', 'techniques', 'examined', '.']

>> Bigrams are: 
 [('advanced', 'data'), ('data', 'analytics'), ('analytics', 'techniques'), ('techniques', 'examined'), ('examined', '.')]

>> Trigrams are: 
 [('advanced', 'data', 'analytics'), ('data', 'analytics', 'techniques'), ('analytics', 'techniques', 'examined'), ('techniques', 'examined', '.')]

>> POS Tags are: 
 [('advanced', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('examined', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['advanced data analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('advanced', 'advanc'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('examined', 'examin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('advanced', 'advanc'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('examined', 'examin'), ('.', '.')]

>> Lemmatization: 
 [('advanced', 'advanced'), ('data', 'data'), ('analytics', 'analytics'), ('techniques', 'technique'), ('examined', 'examined'), ('.', '.')]



========================================== PARAGRAPH 1353 ===========================================

Various big data tools, methods, and technologies have been discussed in this research, offering  

------------------- Sentence 1 -------------------

Various big data tools, methods, and technologies have been discussed in this research, offering

>> Tokens are: 
 ['Various', 'big', 'data', 'tools', ',', 'methods', ',', 'technologies', 'discussed', 'research', ',', 'offering']

>> Bigrams are: 
 [('Various', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', ','), (',', 'methods'), ('methods', ','), (',', 'technologies'), ('technologies', 'discussed'), ('discussed', 'research'), ('research', ','), (',', 'offering')]

>> Trigrams are: 
 [('Various', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', ','), ('tools', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'technologies'), (',', 'technologies', 'discussed'), ('technologies', 'discussed', 'research'), ('discussed', 'research', ','), ('research', ',', 'offering')]

>> POS Tags are: 
 [('Various', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('technologies', 'NNS'), ('discussed', 'VBD'), ('research', 'NN'), (',', ','), ('offering', 'VBG')]

>> Noun Phrases are: 
 ['Various big data tools', 'methods', 'technologies', 'research']

>> Named Entities are: 
 [('GPE', 'Various')] 

>> Stemming using Porter Stemmer: 
 [('Various', 'variou'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technolog'), ('discussed', 'discuss'), ('research', 'research'), (',', ','), ('offering', 'offer')]

>> Stemming using Snowball Stemmer: 
 [('Various', 'various'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technolog'), ('discussed', 'discuss'), ('research', 'research'), (',', ','), ('offering', 'offer')]

>> Lemmatization: 
 [('Various', 'Various'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technology'), ('discussed', 'discussed'), ('research', 'research'), (',', ','), ('offering', 'offering')]



========================================== PARAGRAPH 1354 ===========================================

readers examples of the necessary technologies, and prompting developers to come up with ideas  

------------------- Sentence 1 -------------------

readers examples of the necessary technologies, and prompting developers to come up with ideas

>> Tokens are: 
 ['readers', 'examples', 'necessary', 'technologies', ',', 'prompting', 'developers', 'come', 'ideas']

>> Bigrams are: 
 [('readers', 'examples'), ('examples', 'necessary'), ('necessary', 'technologies'), ('technologies', ','), (',', 'prompting'), ('prompting', 'developers'), ('developers', 'come'), ('come', 'ideas')]

>> Trigrams are: 
 [('readers', 'examples', 'necessary'), ('examples', 'necessary', 'technologies'), ('necessary', 'technologies', ','), ('technologies', ',', 'prompting'), (',', 'prompting', 'developers'), ('prompting', 'developers', 'come'), ('developers', 'come', 'ideas')]

>> POS Tags are: 
 [('readers', 'NNS'), ('examples', 'NNS'), ('necessary', 'JJ'), ('technologies', 'NNS'), (',', ','), ('prompting', 'VBG'), ('developers', 'NNS'), ('come', 'VBP'), ('ideas', 'NNS')]

>> Noun Phrases are: 
 ['readers examples', 'necessary technologies', 'developers', 'ideas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('readers', 'reader'), ('examples', 'exampl'), ('necessary', 'necessari'), ('technologies', 'technolog'), (',', ','), ('prompting', 'prompt'), ('developers', 'develop'), ('come', 'come'), ('ideas', 'idea')]

>> Stemming using Snowball Stemmer: 
 [('readers', 'reader'), ('examples', 'exampl'), ('necessary', 'necessari'), ('technologies', 'technolog'), (',', ','), ('prompting', 'prompt'), ('developers', 'develop'), ('come', 'come'), ('ideas', 'idea')]

>> Lemmatization: 
 [('readers', 'reader'), ('examples', 'example'), ('necessary', 'necessary'), ('technologies', 'technology'), (',', ','), ('prompting', 'prompting'), ('developers', 'developer'), ('come', 'come'), ('ideas', 'idea')]



========================================== PARAGRAPH 1355 ===========================================

about how to provide additional big data analytics solutions to help in decision making.  

------------------- Sentence 1 -------------------

about how to provide additional big data analytics solutions to help in decision making.

>> Tokens are: 
 ['provide', 'additional', 'big', 'data', 'analytics', 'solutions', 'help', 'decision', 'making', '.']

>> Bigrams are: 
 [('provide', 'additional'), ('additional', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'solutions'), ('solutions', 'help'), ('help', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('provide', 'additional', 'big'), ('additional', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'solutions'), ('analytics', 'solutions', 'help'), ('solutions', 'help', 'decision'), ('help', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('provide', 'IN'), ('additional', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('solutions', 'NNS'), ('help', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['additional big data analytics solutions', 'decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provide', 'provid'), ('additional', 'addit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('solutions', 'solut'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('provide', 'provid'), ('additional', 'addit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('solutions', 'solut'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('provide', 'provide'), ('additional', 'additional'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('solutions', 'solution'), ('help', 'help'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



========================================== PARAGRAPH 1356 ===========================================

  


========================================== PARAGRAPH 1357 ===========================================

Big data analytics has been applied in various areas, serving many different sectors. Big data  

------------------- Sentence 1 -------------------

Big data analytics has been applied in various areas, serving many different sectors.

>> Tokens are: 
 ['Big', 'data', 'analytics', 'applied', 'various', 'areas', ',', 'serving', 'many', 'different', 'sectors', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applied'), ('applied', 'various'), ('various', 'areas'), ('areas', ','), (',', 'serving'), ('serving', 'many'), ('many', 'different'), ('different', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applied'), ('analytics', 'applied', 'various'), ('applied', 'various', 'areas'), ('various', 'areas', ','), ('areas', ',', 'serving'), (',', 'serving', 'many'), ('serving', 'many', 'different'), ('many', 'different', 'sectors'), ('different', 'sectors', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applied', 'VBD'), ('various', 'JJ'), ('areas', 'NNS'), (',', ','), ('serving', 'VBG'), ('many', 'JJ'), ('different', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics', 'various areas', 'many different sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applied', 'appli'), ('various', 'variou'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('many', 'mani'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applied', 'appli'), ('various', 'various'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('many', 'mani'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applied', 'applied'), ('various', 'various'), ('areas', 'area'), (',', ','), ('serving', 'serving'), ('many', 'many'), ('different', 'different'), ('sectors', 'sector'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data

>> Tokens are: 
 ['Big', 'data']

>> Bigrams are: 
 [('Big', 'data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data')]



========================================== PARAGRAPH 1358 ===========================================

analytics has the potential to improve care, save lives, and reduce costs in the healthcare sector. It  

------------------- Sentence 1 -------------------

analytics has the potential to improve care, save lives, and reduce costs in the healthcare sector.

>> Tokens are: 
 ['analytics', 'potential', 'improve', 'care', ',', 'save', 'lives', ',', 'reduce', 'costs', 'healthcare', 'sector', '.']

>> Bigrams are: 
 [('analytics', 'potential'), ('potential', 'improve'), ('improve', 'care'), ('care', ','), (',', 'save'), ('save', 'lives'), ('lives', ','), (',', 'reduce'), ('reduce', 'costs'), ('costs', 'healthcare'), ('healthcare', 'sector'), ('sector', '.')]

>> Trigrams are: 
 [('analytics', 'potential', 'improve'), ('potential', 'improve', 'care'), ('improve', 'care', ','), ('care', ',', 'save'), (',', 'save', 'lives'), ('save', 'lives', ','), ('lives', ',', 'reduce'), (',', 'reduce', 'costs'), ('reduce', 'costs', 'healthcare'), ('costs', 'healthcare', 'sector'), ('healthcare', 'sector', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('potential', 'JJ'), ('improve', 'NN'), ('care', 'NN'), (',', ','), ('save', 'VBP'), ('lives', 'NNS'), (',', ','), ('reduce', 'VB'), ('costs', 'NNS'), ('healthcare', 'NN'), ('sector', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics', 'potential improve care', 'lives', 'costs healthcare sector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('potential', 'potenti'), ('improve', 'improv'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('reduce', 'reduc'), ('costs', 'cost'), ('healthcare', 'healthcar'), ('sector', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('potential', 'potenti'), ('improve', 'improv'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('reduce', 'reduc'), ('costs', 'cost'), ('healthcare', 'healthcar'), ('sector', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('potential', 'potential'), ('improve', 'improve'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'life'), (',', ','), ('reduce', 'reduce'), ('costs', 'cost'), ('healthcare', 'healthcare'), ('sector', 'sector'), ('.', '.')]


------------------- Sentence 2 -------------------

It

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 1359 ===========================================

also benefits industries such as financial institutions by allowing analysis of customer log files to  

------------------- Sentence 1 -------------------

also benefits industries such as financial institutions by allowing analysis of customer log files to

>> Tokens are: 
 ['also', 'benefits', 'industries', 'financial', 'institutions', 'allowing', 'analysis', 'customer', 'log', 'files']

>> Bigrams are: 
 [('also', 'benefits'), ('benefits', 'industries'), ('industries', 'financial'), ('financial', 'institutions'), ('institutions', 'allowing'), ('allowing', 'analysis'), ('analysis', 'customer'), ('customer', 'log'), ('log', 'files')]

>> Trigrams are: 
 [('also', 'benefits', 'industries'), ('benefits', 'industries', 'financial'), ('industries', 'financial', 'institutions'), ('financial', 'institutions', 'allowing'), ('institutions', 'allowing', 'analysis'), ('allowing', 'analysis', 'customer'), ('analysis', 'customer', 'log'), ('customer', 'log', 'files')]

>> POS Tags are: 
 [('also', 'RB'), ('benefits', 'NNS'), ('industries', 'NNS'), ('financial', 'JJ'), ('institutions', 'NNS'), ('allowing', 'VBG'), ('analysis', 'NN'), ('customer', 'NN'), ('log', 'NN'), ('files', 'NNS')]

>> Noun Phrases are: 
 ['benefits industries', 'financial institutions', 'analysis customer log files']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('benefits', 'benefit'), ('industries', 'industri'), ('financial', 'financi'), ('institutions', 'institut'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('benefits', 'benefit'), ('industries', 'industri'), ('financial', 'financi'), ('institutions', 'institut'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file')]

>> Lemmatization: 
 [('also', 'also'), ('benefits', 'benefit'), ('industries', 'industry'), ('financial', 'financial'), ('institutions', 'institution'), ('allowing', 'allowing'), ('analysis', 'analysis'), ('customer', 'customer'), ('log', 'log'), ('files', 'file')]



========================================== PARAGRAPH 1360 ===========================================

help develop a better understanding of customer needs. The retail sector has a significant impact  

------------------- Sentence 1 -------------------

help develop a better understanding of customer needs.

>> Tokens are: 
 ['help', 'develop', 'better', 'understanding', 'customer', 'needs', '.']

>> Bigrams are: 
 [('help', 'develop'), ('develop', 'better'), ('better', 'understanding'), ('understanding', 'customer'), ('customer', 'needs'), ('needs', '.')]

>> Trigrams are: 
 [('help', 'develop', 'better'), ('develop', 'better', 'understanding'), ('better', 'understanding', 'customer'), ('understanding', 'customer', 'needs'), ('customer', 'needs', '.')]

>> POS Tags are: 
 [('help', 'NN'), ('develop', 'VB'), ('better', 'RBR'), ('understanding', 'VBG'), ('customer', 'NN'), ('needs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['help', 'customer needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('customer', 'custom'), ('needs', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('customer', 'custom'), ('needs', 'need'), ('.', '.')]

>> Lemmatization: 
 [('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understanding'), ('customer', 'customer'), ('needs', 'need'), ('.', '.')]


------------------- Sentence 2 -------------------

The retail sector has a significant impact

>> Tokens are: 
 ['The', 'retail', 'sector', 'significant', 'impact']

>> Bigrams are: 
 [('The', 'retail'), ('retail', 'sector'), ('sector', 'significant'), ('significant', 'impact')]

>> Trigrams are: 
 [('The', 'retail', 'sector'), ('retail', 'sector', 'significant'), ('sector', 'significant', 'impact')]

>> POS Tags are: 
 [('The', 'DT'), ('retail', 'JJ'), ('sector', 'NN'), ('significant', 'JJ'), ('impact', 'NN')]

>> Noun Phrases are: 
 ['The retail sector', 'significant impact']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'signific'), ('impact', 'impact')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'signific'), ('impact', 'impact')]

>> Lemmatization: 
 [('The', 'The'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'significant'), ('impact', 'impact')]



========================================== PARAGRAPH 1361 ===========================================

on society and using big data analytics in this sector can again help managers to better understand  

------------------- Sentence 1 -------------------

on society and using big data analytics in this sector can again help managers to better understand

>> Tokens are: 
 ['society', 'using', 'big', 'data', 'analytics', 'sector', 'help', 'managers', 'better', 'understand']

>> Bigrams are: 
 [('society', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'sector'), ('sector', 'help'), ('help', 'managers'), ('managers', 'better'), ('better', 'understand')]

>> Trigrams are: 
 [('society', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'sector'), ('analytics', 'sector', 'help'), ('sector', 'help', 'managers'), ('help', 'managers', 'better'), ('managers', 'better', 'understand')]

>> POS Tags are: 
 [('society', 'NN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('sector', 'NN'), ('help', 'NN'), ('managers', 'NNS'), ('better', 'RBR'), ('understand', 'VBP')]

>> Noun Phrases are: 
 ['society', 'big data analytics sector help managers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('society', 'societi'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manag'), ('better', 'better'), ('understand', 'understand')]

>> Stemming using Snowball Stemmer: 
 [('society', 'societi'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manag'), ('better', 'better'), ('understand', 'understand')]

>> Lemmatization: 
 [('society', 'society'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manager'), ('better', 'better'), ('understand', 'understand')]



========================================== PARAGRAPH 1362 ===========================================

people’s needs, thus prompting the development of better services. Big data analytics are also used  

------------------- Sentence 1 -------------------

people’s needs, thus prompting the development of better services.

>> Tokens are: 
 ['people', '’', 'needs', ',', 'thus', 'prompting', 'development', 'better', 'services', '.']

>> Bigrams are: 
 [('people', '’'), ('’', 'needs'), ('needs', ','), (',', 'thus'), ('thus', 'prompting'), ('prompting', 'development'), ('development', 'better'), ('better', 'services'), ('services', '.')]

>> Trigrams are: 
 [('people', '’', 'needs'), ('’', 'needs', ','), ('needs', ',', 'thus'), (',', 'thus', 'prompting'), ('thus', 'prompting', 'development'), ('prompting', 'development', 'better'), ('development', 'better', 'services'), ('better', 'services', '.')]

>> POS Tags are: 
 [('people', 'NNS'), ('’', 'VBP'), ('needs', 'NNS'), (',', ','), ('thus', 'RB'), ('prompting', 'VBG'), ('development', 'NN'), ('better', 'NN'), ('services', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['people', 'needs', 'development better services']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('people', 'peopl'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thu'), ('prompting', 'prompt'), ('development', 'develop'), ('better', 'better'), ('services', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('people', 'peopl'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thus'), ('prompting', 'prompt'), ('development', 'develop'), ('better', 'better'), ('services', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('people', 'people'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thus'), ('prompting', 'prompting'), ('development', 'development'), ('better', 'better'), ('services', 'service'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics are also used

>> Tokens are: 
 ['Big', 'data', 'analytics', 'also', 'used']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'used')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'used')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used')]



========================================== PARAGRAPH 1363 ===========================================

in the telecommunications sector, where they help in monitoring machine logs and addressing  

------------------- Sentence 1 -------------------

in the telecommunications sector, where they help in monitoring machine logs and addressing

>> Tokens are: 
 ['telecommunications', 'sector', ',', 'help', 'monitoring', 'machine', 'logs', 'addressing']

>> Bigrams are: 
 [('telecommunications', 'sector'), ('sector', ','), (',', 'help'), ('help', 'monitoring'), ('monitoring', 'machine'), ('machine', 'logs'), ('logs', 'addressing')]

>> Trigrams are: 
 [('telecommunications', 'sector', ','), ('sector', ',', 'help'), (',', 'help', 'monitoring'), ('help', 'monitoring', 'machine'), ('monitoring', 'machine', 'logs'), ('machine', 'logs', 'addressing')]

>> POS Tags are: 
 [('telecommunications', 'NNS'), ('sector', 'NN'), (',', ','), ('help', 'VB'), ('monitoring', 'NN'), ('machine', 'NN'), ('logs', 'NNS'), ('addressing', 'VBG')]

>> Noun Phrases are: 
 ['telecommunications sector', 'monitoring machine logs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('telecommunications', 'telecommun'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('addressing', 'address')]

>> Stemming using Snowball Stemmer: 
 [('telecommunications', 'telecommun'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('addressing', 'address')]

>> Lemmatization: 
 [('telecommunications', 'telecommunication'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitoring'), ('machine', 'machine'), ('logs', 'log'), ('addressing', 'addressing')]



========================================== PARAGRAPH 1364 ===========================================

quality issues.   

------------------- Sentence 1 -------------------

quality issues.

>> Tokens are: 
 ['quality', 'issues', '.']

>> Bigrams are: 
 [('quality', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('quality', 'issues', '.')]

>> POS Tags are: 
 [('quality', 'NN'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['quality issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('quality', 'qualiti'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('quality', 'qualiti'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('quality', 'quality'), ('issues', 'issue'), ('.', '.')]



========================================== PARAGRAPH 1365 ===========================================

  


========================================== PARAGRAPH 1366 ===========================================

Some big data analytics challenges were discussed in this work, particularly with regard to security  

------------------- Sentence 1 -------------------

Some big data analytics challenges were discussed in this work, particularly with regard to security

>> Tokens are: 
 ['Some', 'big', 'data', 'analytics', 'challenges', 'discussed', 'work', ',', 'particularly', 'regard', 'security']

>> Bigrams are: 
 [('Some', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'discussed'), ('discussed', 'work'), ('work', ','), (',', 'particularly'), ('particularly', 'regard'), ('regard', 'security')]

>> Trigrams are: 
 [('Some', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'discussed'), ('challenges', 'discussed', 'work'), ('discussed', 'work', ','), ('work', ',', 'particularly'), (',', 'particularly', 'regard'), ('particularly', 'regard', 'security')]

>> POS Tags are: 
 [('Some', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('discussed', 'VBN'), ('work', 'NN'), (',', ','), ('particularly', 'RB'), ('regard', 'JJ'), ('security', 'NN')]

>> Noun Phrases are: 
 ['Some big data analytics challenges', 'work', 'regard security']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('discussed', 'discuss'), ('work', 'work'), (',', ','), ('particularly', 'particularli'), ('regard', 'regard'), ('security', 'secur')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('discussed', 'discuss'), ('work', 'work'), (',', ','), ('particularly', 'particular'), ('regard', 'regard'), ('security', 'secur')]

>> Lemmatization: 
 [('Some', 'Some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('discussed', 'discussed'), ('work', 'work'), (',', ','), ('particularly', 'particularly'), ('regard', 'regard'), ('security', 'security')]



========================================== PARAGRAPH 1367 ===========================================

and privacy. Some examples of how big data analytics can be used to handle issues such as  

------------------- Sentence 1 -------------------

and privacy.

>> Tokens are: 
 ['privacy', '.']

>> Bigrams are: 
 [('privacy', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('privacy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('privacy', 'privaci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('privacy', 'privaci'), ('.', '.')]

>> Lemmatization: 
 [('privacy', 'privacy'), ('.', '.')]


------------------- Sentence 2 -------------------

Some examples of how big data analytics can be used to handle issues such as

>> Tokens are: 
 ['Some', 'examples', 'big', 'data', 'analytics', 'used', 'handle', 'issues']

>> Bigrams are: 
 [('Some', 'examples'), ('examples', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'handle'), ('handle', 'issues')]

>> Trigrams are: 
 [('Some', 'examples', 'big'), ('examples', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'handle'), ('used', 'handle', 'issues')]

>> POS Tags are: 
 [('Some', 'DT'), ('examples', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('handle', 'JJ'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['Some examples', 'big data analytics', 'handle issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('examples', 'exampl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('handle', 'handl'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('examples', 'exampl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('handle', 'handl'), ('issues', 'issu')]

>> Lemmatization: 
 [('Some', 'Some'), ('examples', 'example'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('handle', 'handle'), ('issues', 'issue')]



========================================== PARAGRAPH 1368 ===========================================

intrusion detection and big data characteristics such as size, velocity, variety, value and external  

------------------- Sentence 1 -------------------

intrusion detection and big data characteristics such as size, velocity, variety, value and external

>> Tokens are: 
 ['intrusion', 'detection', 'big', 'data', 'characteristics', 'size', ',', 'velocity', ',', 'variety', ',', 'value', 'external']

>> Bigrams are: 
 [('intrusion', 'detection'), ('detection', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', 'size'), ('size', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', ','), (',', 'value'), ('value', 'external')]

>> Trigrams are: 
 [('intrusion', 'detection', 'big'), ('detection', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', 'size'), ('characteristics', 'size', ','), ('size', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'value'), (',', 'value', 'external')]

>> POS Tags are: 
 [('intrusion', 'NN'), ('detection', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), ('size', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('value', 'NN'), ('external', 'NN')]

>> Noun Phrases are: 
 ['intrusion detection', 'big data characteristics size', 'velocity', 'variety', 'value external']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('size', 'size'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('value', 'valu'), ('external', 'extern')]

>> Stemming using Snowball Stemmer: 
 [('intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('size', 'size'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('value', 'valu'), ('external', 'extern')]

>> Lemmatization: 
 [('intrusion', 'intrusion'), ('detection', 'detection'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), ('size', 'size'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (',', ','), ('value', 'value'), ('external', 'external')]



========================================== PARAGRAPH 1369 ===========================================

sources were also given. Finally, some real-world big data analytics applications were introduced.  

------------------- Sentence 1 -------------------

sources were also given.

>> Tokens are: 
 ['sources', 'also', 'given', '.']

>> Bigrams are: 
 [('sources', 'also'), ('also', 'given'), ('given', '.')]

>> Trigrams are: 
 [('sources', 'also', 'given'), ('also', 'given', '.')]

>> POS Tags are: 
 [('sources', 'NNS'), ('also', 'RB'), ('given', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sources', 'sourc'), ('also', 'also'), ('given', 'given'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sources', 'sourc'), ('also', 'also'), ('given', 'given'), ('.', '.')]

>> Lemmatization: 
 [('sources', 'source'), ('also', 'also'), ('given', 'given'), ('.', '.')]


------------------- Sentence 2 -------------------

Finally, some real-world big data analytics applications were introduced.

>> Tokens are: 
 ['Finally', ',', 'real-world', 'big', 'data', 'analytics', 'applications', 'introduced', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'real-world'), ('real-world', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', 'introduced'), ('introduced', '.')]

>> Trigrams are: 
 [('Finally', ',', 'real-world'), (',', 'real-world', 'big'), ('real-world', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', 'introduced'), ('applications', 'introduced', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('real-world', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('introduced', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['real-world big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('introduced', 'introduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('introduced', 'introduc'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('introduced', 'introduced'), ('.', '.')]



========================================== PARAGRAPH 1370 ===========================================

  


========================================== PARAGRAPH 1371 ===========================================

Big data is a significant area which offers many potential benefits and innovations. It is a  

------------------- Sentence 1 -------------------

Big data is a significant area which offers many potential benefits and innovations.

>> Tokens are: 
 ['Big', 'data', 'significant', 'area', 'offers', 'many', 'potential', 'benefits', 'innovations', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'significant'), ('significant', 'area'), ('area', 'offers'), ('offers', 'many'), ('many', 'potential'), ('potential', 'benefits'), ('benefits', 'innovations'), ('innovations', '.')]

>> Trigrams are: 
 [('Big', 'data', 'significant'), ('data', 'significant', 'area'), ('significant', 'area', 'offers'), ('area', 'offers', 'many'), ('offers', 'many', 'potential'), ('many', 'potential', 'benefits'), ('potential', 'benefits', 'innovations'), ('benefits', 'innovations', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('significant', 'JJ'), ('area', 'NN'), ('offers', 'NNS'), ('many', 'JJ'), ('potential', 'JJ'), ('benefits', 'NNS'), ('innovations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'significant area offers', 'many potential benefits innovations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('significant', 'signific'), ('area', 'area'), ('offers', 'offer'), ('many', 'mani'), ('potential', 'potenti'), ('benefits', 'benefit'), ('innovations', 'innov'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('significant', 'signific'), ('area', 'area'), ('offers', 'offer'), ('many', 'mani'), ('potential', 'potenti'), ('benefits', 'benefit'), ('innovations', 'innov'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('significant', 'significant'), ('area', 'area'), ('offers', 'offer'), ('many', 'many'), ('potential', 'potential'), ('benefits', 'benefit'), ('innovations', 'innovation'), ('.', '.')]


------------------- Sentence 2 -------------------

It is a

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 1372 ===========================================

remarkable domain with a promising future, if approached correctly. The difficulty with big data  

------------------- Sentence 1 -------------------

remarkable domain with a promising future, if approached correctly.

>> Tokens are: 
 ['remarkable', 'domain', 'promising', 'future', ',', 'approached', 'correctly', '.']

>> Bigrams are: 
 [('remarkable', 'domain'), ('domain', 'promising'), ('promising', 'future'), ('future', ','), (',', 'approached'), ('approached', 'correctly'), ('correctly', '.')]

>> Trigrams are: 
 [('remarkable', 'domain', 'promising'), ('domain', 'promising', 'future'), ('promising', 'future', ','), ('future', ',', 'approached'), (',', 'approached', 'correctly'), ('approached', 'correctly', '.')]

>> POS Tags are: 
 [('remarkable', 'JJ'), ('domain', 'NN'), ('promising', 'JJ'), ('future', 'NN'), (',', ','), ('approached', 'VBN'), ('correctly', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['remarkable domain', 'promising future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('remarkable', 'remark'), ('domain', 'domain'), ('promising', 'promis'), ('future', 'futur'), (',', ','), ('approached', 'approach'), ('correctly', 'correctli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('remarkable', 'remark'), ('domain', 'domain'), ('promising', 'promis'), ('future', 'futur'), (',', ','), ('approached', 'approach'), ('correctly', 'correct'), ('.', '.')]

>> Lemmatization: 
 [('remarkable', 'remarkable'), ('domain', 'domain'), ('promising', 'promising'), ('future', 'future'), (',', ','), ('approached', 'approached'), ('correctly', 'correctly'), ('.', '.')]


------------------- Sentence 2 -------------------

The difficulty with big data

>> Tokens are: 
 ['The', 'difficulty', 'big', 'data']

>> Bigrams are: 
 [('The', 'difficulty'), ('difficulty', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('The', 'difficulty', 'big'), ('difficulty', 'big', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('difficulty', 'NN'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The difficulty', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('difficulty', 'difficulti'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('difficulty', 'difficulti'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('difficulty', 'difficulty'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1373 ===========================================

comes mainly from its size, which requires proper storage, management, integration, cleansing,  

------------------- Sentence 1 -------------------

comes mainly from its size, which requires proper storage, management, integration, cleansing,

>> Tokens are: 
 ['comes', 'mainly', 'size', ',', 'requires', 'proper', 'storage', ',', 'management', ',', 'integration', ',', 'cleansing', ',']

>> Bigrams are: 
 [('comes', 'mainly'), ('mainly', 'size'), ('size', ','), (',', 'requires'), ('requires', 'proper'), ('proper', 'storage'), ('storage', ','), (',', 'management'), ('management', ','), (',', 'integration'), ('integration', ','), (',', 'cleansing'), ('cleansing', ',')]

>> Trigrams are: 
 [('comes', 'mainly', 'size'), ('mainly', 'size', ','), ('size', ',', 'requires'), (',', 'requires', 'proper'), ('requires', 'proper', 'storage'), ('proper', 'storage', ','), ('storage', ',', 'management'), (',', 'management', ','), ('management', ',', 'integration'), (',', 'integration', ','), ('integration', ',', 'cleansing'), (',', 'cleansing', ',')]

>> POS Tags are: 
 [('comes', 'VBZ'), ('mainly', 'RB'), ('size', 'NN'), (',', ','), ('requires', 'VBZ'), ('proper', 'JJ'), ('storage', 'NN'), (',', ','), ('management', 'NN'), (',', ','), ('integration', 'NN'), (',', ','), ('cleansing', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['size', 'proper storage', 'management', 'integration', 'cleansing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comes', 'come'), ('mainly', 'mainli'), ('size', 'size'), (',', ','), ('requires', 'requir'), ('proper', 'proper'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('integration', 'integr'), (',', ','), ('cleansing', 'cleans'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('comes', 'come'), ('mainly', 'main'), ('size', 'size'), (',', ','), ('requires', 'requir'), ('proper', 'proper'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('integration', 'integr'), (',', ','), ('cleansing', 'cleans'), (',', ',')]

>> Lemmatization: 
 [('comes', 'come'), ('mainly', 'mainly'), ('size', 'size'), (',', ','), ('requires', 'requires'), ('proper', 'proper'), ('storage', 'storage'), (',', ','), ('management', 'management'), (',', ','), ('integration', 'integration'), (',', ','), ('cleansing', 'cleansing'), (',', ',')]



========================================== PARAGRAPH 1374 ===========================================

processing, and analysis. The sheer volume, velocity, speed, and variety of data increases the  

------------------- Sentence 1 -------------------

processing, and analysis.

>> Tokens are: 
 ['processing', ',', 'analysis', '.']

>> Bigrams are: 
 [('processing', ','), (',', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('processing', ',', 'analysis'), (',', 'analysis', '.')]

>> POS Tags are: 
 [('processing', 'NN'), (',', ','), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['processing', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('processing', 'process'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('processing', 'process'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('processing', 'processing'), (',', ','), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

The sheer volume, velocity, speed, and variety of data increases the

>> Tokens are: 
 ['The', 'sheer', 'volume', ',', 'velocity', ',', 'speed', ',', 'variety', 'data', 'increases']

>> Bigrams are: 
 [('The', 'sheer'), ('sheer', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'speed'), ('speed', ','), (',', 'variety'), ('variety', 'data'), ('data', 'increases')]

>> Trigrams are: 
 [('The', 'sheer', 'volume'), ('sheer', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'speed'), (',', 'speed', ','), ('speed', ',', 'variety'), (',', 'variety', 'data'), ('variety', 'data', 'increases')]

>> POS Tags are: 
 [('The', 'DT'), ('sheer', 'NN'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('speed', 'NN'), (',', ','), ('variety', 'NN'), ('data', 'NNS'), ('increases', 'NNS')]

>> Noun Phrases are: 
 ['The sheer volume', 'velocity', 'speed', 'variety data increases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('sheer', 'sheer'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'varieti'), ('data', 'data'), ('increases', 'increas')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('sheer', 'sheer'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'varieti'), ('data', 'data'), ('increases', 'increas')]

>> Lemmatization: 
 [('The', 'The'), ('sheer', 'sheer'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'variety'), ('data', 'data'), ('increases', 'increase')]



========================================== PARAGRAPH 1375 ===========================================

difficulty of dealing with it in terms of traditional data management, creating a need to study and  

------------------- Sentence 1 -------------------

difficulty of dealing with it in terms of traditional data management, creating a need to study and

>> Tokens are: 
 ['difficulty', 'dealing', 'terms', 'traditional', 'data', 'management', ',', 'creating', 'need', 'study']

>> Bigrams are: 
 [('difficulty', 'dealing'), ('dealing', 'terms'), ('terms', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', ','), (',', 'creating'), ('creating', 'need'), ('need', 'study')]

>> Trigrams are: 
 [('difficulty', 'dealing', 'terms'), ('dealing', 'terms', 'traditional'), ('terms', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'creating'), (',', 'creating', 'need'), ('creating', 'need', 'study')]

>> POS Tags are: 
 [('difficulty', 'NN'), ('dealing', 'VBG'), ('terms', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('creating', 'VBG'), ('need', 'NN'), ('study', 'NN')]

>> Noun Phrases are: 
 ['difficulty', 'terms', 'traditional data management', 'need study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('difficulty', 'difficulti'), ('dealing', 'deal'), ('terms', 'term'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), (',', ','), ('creating', 'creat'), ('need', 'need'), ('study', 'studi')]

>> Stemming using Snowball Stemmer: 
 [('difficulty', 'difficulti'), ('dealing', 'deal'), ('terms', 'term'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), (',', ','), ('creating', 'creat'), ('need', 'need'), ('study', 'studi')]

>> Lemmatization: 
 [('difficulty', 'difficulty'), ('dealing', 'dealing'), ('terms', 'term'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), (',', ','), ('creating', 'creating'), ('need', 'need'), ('study', 'study')]



========================================== PARAGRAPH 1376 ===========================================

explore new analytics methods which might help in overcoming such difficulties to promote the  

------------------- Sentence 1 -------------------

explore new analytics methods which might help in overcoming such difficulties to promote the

>> Tokens are: 
 ['explore', 'new', 'analytics', 'methods', 'might', 'help', 'overcoming', 'difficulties', 'promote']

>> Bigrams are: 
 [('explore', 'new'), ('new', 'analytics'), ('analytics', 'methods'), ('methods', 'might'), ('might', 'help'), ('help', 'overcoming'), ('overcoming', 'difficulties'), ('difficulties', 'promote')]

>> Trigrams are: 
 [('explore', 'new', 'analytics'), ('new', 'analytics', 'methods'), ('analytics', 'methods', 'might'), ('methods', 'might', 'help'), ('might', 'help', 'overcoming'), ('help', 'overcoming', 'difficulties'), ('overcoming', 'difficulties', 'promote')]

>> POS Tags are: 
 [('explore', 'RB'), ('new', 'JJ'), ('analytics', 'NNS'), ('methods', 'NNS'), ('might', 'MD'), ('help', 'VB'), ('overcoming', 'VBG'), ('difficulties', 'NNS'), ('promote', 'VBP')]

>> Noun Phrases are: 
 ['new analytics methods', 'difficulties']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('explore', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcom'), ('difficulties', 'difficulti'), ('promote', 'promot')]

>> Stemming using Snowball Stemmer: 
 [('explore', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcom'), ('difficulties', 'difficulti'), ('promote', 'promot')]

>> Lemmatization: 
 [('explore', 'explore'), ('new', 'new'), ('analytics', 'analytics'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcoming'), ('difficulties', 'difficulty'), ('promote', 'promote')]



========================================== PARAGRAPH 1377 ===========================================

positive role of big data analytics to as many sectors as possible. Future research could thus  

------------------- Sentence 1 -------------------

positive role of big data analytics to as many sectors as possible.

>> Tokens are: 
 ['positive', 'role', 'big', 'data', 'analytics', 'many', 'sectors', 'possible', '.']

>> Bigrams are: 
 [('positive', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'many'), ('many', 'sectors'), ('sectors', 'possible'), ('possible', '.')]

>> Trigrams are: 
 [('positive', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'many'), ('analytics', 'many', 'sectors'), ('many', 'sectors', 'possible'), ('sectors', 'possible', '.')]

>> POS Tags are: 
 [('positive', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('many', 'JJ'), ('sectors', 'NNS'), ('possible', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['positive role', 'big data analytics', 'many sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('possible', 'possibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('possible', 'possibl'), ('.', '.')]

>> Lemmatization: 
 [('positive', 'positive'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('many', 'many'), ('sectors', 'sector'), ('possible', 'possible'), ('.', '.')]


------------------- Sentence 2 -------------------

Future research could thus

>> Tokens are: 
 ['Future', 'research', 'could', 'thus']

>> Bigrams are: 
 [('Future', 'research'), ('research', 'could'), ('could', 'thus')]

>> Trigrams are: 
 [('Future', 'research', 'could'), ('research', 'could', 'thus')]

>> POS Tags are: 
 [('Future', 'NNP'), ('research', 'NN'), ('could', 'MD'), ('thus', 'RB')]

>> Noun Phrases are: 
 ['Future research']

>> Named Entities are: 
 [('GPE', 'Future')] 

>> Stemming using Porter Stemmer: 
 [('Future', 'futur'), ('research', 'research'), ('could', 'could'), ('thus', 'thu')]

>> Stemming using Snowball Stemmer: 
 [('Future', 'futur'), ('research', 'research'), ('could', 'could'), ('thus', 'thus')]

>> Lemmatization: 
 [('Future', 'Future'), ('research', 'research'), ('could', 'could'), ('thus', 'thus')]



========================================== PARAGRAPH 1378 ===========================================

usefully focus on big data analytics challenges with regard to security and privacy issues, based 

------------------- Sentence 1 -------------------

usefully focus on big data analytics challenges with regard to security and privacy issues, based

>> Tokens are: 
 ['usefully', 'focus', 'big', 'data', 'analytics', 'challenges', 'regard', 'security', 'privacy', 'issues', ',', 'based']

>> Bigrams are: 
 [('usefully', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'regard'), ('regard', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', ','), (',', 'based')]

>> Trigrams are: 
 [('usefully', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'regard'), ('challenges', 'regard', 'security'), ('regard', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', ','), ('issues', ',', 'based')]

>> POS Tags are: 
 [('usefully', 'RB'), ('focus', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('regard', 'VBP'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), (',', ','), ('based', 'VBN')]

>> Noun Phrases are: 
 ['big data analytics challenges', 'security privacy issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('usefully', 'use'), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('usefully', 'use'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('based', 'base')]

>> Lemmatization: 
 [('usefully', 'usefully'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('regard', 'regard'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), (',', ','), ('based', 'based')]



========================================== PARAGRAPH 1379 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1380 ===========================================

47  

------------------- Sentence 1 -------------------

47

>> Tokens are: 
 ['47']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('47', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('47', '47')]

>> Stemming using Snowball Stemmer: 
 [('47', '47')]

>> Lemmatization: 
 [('47', '47')]



========================================== PARAGRAPH 1381 ===========================================

  


========================================== PARAGRAPH 1382 ===========================================

on big data’s weakness in coming from many different sources; a focus on cloud providers and  

------------------- Sentence 1 -------------------

on big data’s weakness in coming from many different sources; a focus on cloud providers and

>> Tokens are: 
 ['big', 'data', '’', 'weakness', 'coming', 'many', 'different', 'sources', ';', 'focus', 'cloud', 'providers']

>> Bigrams are: 
 [('big', 'data'), ('data', '’'), ('’', 'weakness'), ('weakness', 'coming'), ('coming', 'many'), ('many', 'different'), ('different', 'sources'), ('sources', ';'), (';', 'focus'), ('focus', 'cloud'), ('cloud', 'providers')]

>> Trigrams are: 
 [('big', 'data', '’'), ('data', '’', 'weakness'), ('’', 'weakness', 'coming'), ('weakness', 'coming', 'many'), ('coming', 'many', 'different'), ('many', 'different', 'sources'), ('different', 'sources', ';'), ('sources', ';', 'focus'), (';', 'focus', 'cloud'), ('focus', 'cloud', 'providers')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('’', 'NNS'), ('weakness', 'NN'), ('coming', 'VBG'), ('many', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (';', ':'), ('focus', 'VB'), ('cloud', 'NN'), ('providers', 'NNS')]

>> Noun Phrases are: 
 ['big data ’ weakness', 'many different sources', 'cloud providers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weak'), ('coming', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (';', ';'), ('focus', 'focu'), ('cloud', 'cloud'), ('providers', 'provid')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weak'), ('coming', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (';', ';'), ('focus', 'focus'), ('cloud', 'cloud'), ('providers', 'provid')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weakness'), ('coming', 'coming'), ('many', 'many'), ('different', 'different'), ('sources', 'source'), (';', ';'), ('focus', 'focus'), ('cloud', 'cloud'), ('providers', 'provider')]



========================================== PARAGRAPH 1383 ===========================================

security breaches which affect multiple companies would also be advised.  

------------------- Sentence 1 -------------------

security breaches which affect multiple companies would also be advised.

>> Tokens are: 
 ['security', 'breaches', 'affect', 'multiple', 'companies', 'would', 'also', 'advised', '.']

>> Bigrams are: 
 [('security', 'breaches'), ('breaches', 'affect'), ('affect', 'multiple'), ('multiple', 'companies'), ('companies', 'would'), ('would', 'also'), ('also', 'advised'), ('advised', '.')]

>> Trigrams are: 
 [('security', 'breaches', 'affect'), ('breaches', 'affect', 'multiple'), ('affect', 'multiple', 'companies'), ('multiple', 'companies', 'would'), ('companies', 'would', 'also'), ('would', 'also', 'advised'), ('also', 'advised', '.')]

>> POS Tags are: 
 [('security', 'NN'), ('breaches', 'NNS'), ('affect', 'VBP'), ('multiple', 'JJ'), ('companies', 'NNS'), ('would', 'MD'), ('also', 'RB'), ('advised', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['security breaches', 'multiple companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('security', 'secur'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('would', 'would'), ('also', 'also'), ('advised', 'advis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('security', 'secur'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('would', 'would'), ('also', 'also'), ('advised', 'advis'), ('.', '.')]

>> Lemmatization: 
 [('security', 'security'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multiple'), ('companies', 'company'), ('would', 'would'), ('also', 'also'), ('advised', 'advised'), ('.', '.')]



========================================== PARAGRAPH 1384 ===========================================

  


========================================== PARAGRAPH 1385 ===========================================

  


========================================== PARAGRAPH 1386 ===========================================

  


========================================== PARAGRAPH 1387 ===========================================

13. References  

------------------- Sentence 1 -------------------

13.

>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]


------------------- Sentence 2 -------------------

References

>> Tokens are: 
 ['References']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('References', 'NNS')]

>> Noun Phrases are: 
 ['References']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('References', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('References', 'refer')]

>> Lemmatization: 
 [('References', 'References')]



========================================== PARAGRAPH 1388 ===========================================

Acharjya, D.P. and Ahmed, K., 2016. A survey on big data analytics: challenges, open research  

------------------- Sentence 1 -------------------

Acharjya, D.P.

>> Tokens are: 
 ['Acharjya', ',', 'D.P', '.']

>> Bigrams are: 
 [('Acharjya', ','), (',', 'D.P'), ('D.P', '.')]

>> Trigrams are: 
 [('Acharjya', ',', 'D.P'), (',', 'D.P', '.')]

>> POS Tags are: 
 [('Acharjya', 'NNP'), (',', ','), ('D.P', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Acharjya', 'D.P']

>> Named Entities are: 
 [('GPE', 'Acharjya')] 

>> Stemming using Porter Stemmer: 
 [('Acharjya', 'acharjya'), (',', ','), ('D.P', 'd.p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Acharjya', 'acharjya'), (',', ','), ('D.P', 'd.p'), ('.', '.')]

>> Lemmatization: 
 [('Acharjya', 'Acharjya'), (',', ','), ('D.P', 'D.P'), ('.', '.')]


------------------- Sentence 2 -------------------

and Ahmed, K., 2016.

>> Tokens are: 
 ['Ahmed', ',', 'K.', ',', '2016', '.']

>> Bigrams are: 
 [('Ahmed', ','), (',', 'K.'), ('K.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Ahmed', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Ahmed', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ahmed', 'K.']

>> Named Entities are: 
 [('GPE', 'Ahmed')] 

>> Stemming using Porter Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Ahmed', 'Ahmed'), (',', ','), ('K.', 'K.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 3 -------------------

A survey on big data analytics: challenges, open research

>> Tokens are: 
 ['A', 'survey', 'big', 'data', 'analytics', ':', 'challenges', ',', 'open', 'research']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'challenges'), ('challenges', ','), (',', 'open'), ('open', 'research')]

>> Trigrams are: 
 [('A', 'survey', 'big'), ('survey', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'challenges'), (':', 'challenges', ','), ('challenges', ',', 'open'), (',', 'open', 'research')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('challenges', 'NNS'), (',', ','), ('open', 'JJ'), ('research', 'NN')]

>> Noun Phrases are: 
 ['A survey', 'big data analytics', 'challenges', 'open research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('open', 'open'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('open', 'open'), ('research', 'research')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('challenges', 'challenge'), (',', ','), ('open', 'open'), ('research', 'research')]



========================================== PARAGRAPH 1389 ===========================================

issues and tools. International Journal of Advanced Computer Science and Applications, pp. 511- 

------------------- Sentence 1 -------------------

issues and tools.

>> Tokens are: 
 ['issues', 'tools', '.']

>> Bigrams are: 
 [('issues', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('issues', 'tools', '.')]

>> POS Tags are: 
 [('issues', 'NNS'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['issues tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('issues', 'issu'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('issues', 'issu'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('issues', 'issue'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

International Journal of Advanced Computer Science and Applications, pp.

>> Tokens are: 
 ['International', 'Journal', 'Advanced', 'Computer', 'Science', 'Applications', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Advanced'), ('Advanced', 'Computer'), ('Computer', 'Science'), ('Science', 'Applications'), ('Applications', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Advanced'), ('Journal', 'Advanced', 'Computer'), ('Advanced', 'Computer', 'Science'), ('Computer', 'Science', 'Applications'), ('Science', 'Applications', ','), ('Applications', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Advanced', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Applications', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['International Journal Advanced Computer Science Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Advanced Computer Science Applications')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Advanced', 'advanc'), ('Computer', 'comput'), ('Science', 'scienc'), ('Applications', 'applic'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Advanced', 'advanc'), ('Computer', 'comput'), ('Science', 'scienc'), ('Applications', 'applic'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Advanced', 'Advanced'), ('Computer', 'Computer'), ('Science', 'Science'), ('Applications', 'Applications'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

511-

>> Tokens are: 
 ['511-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('511-', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('511-', '511-')]

>> Stemming using Snowball Stemmer: 
 [('511-', '511-')]

>> Lemmatization: 
 [('511-', '511-')]



========================================== PARAGRAPH 1390 ===========================================

518.  

------------------- Sentence 1 -------------------

518.

>> Tokens are: 
 ['518', '.']

>> Bigrams are: 
 [('518', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('518', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('518', '518'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('518', '518'), ('.', '.')]

>> Lemmatization: 
 [('518', '518'), ('.', '.')]



========================================== PARAGRAPH 1391 ===========================================

Addo-Tenkorang, R. and Helo, P.T., 2016. Big data applications in operations/supply-chain  

------------------- Sentence 1 -------------------

Addo-Tenkorang, R. and Helo, P.T., 2016.

>> Tokens are: 
 ['Addo-Tenkorang', ',', 'R.', 'Helo', ',', 'P.T.', ',', '2016', '.']

>> Bigrams are: 
 [('Addo-Tenkorang', ','), (',', 'R.'), ('R.', 'Helo'), ('Helo', ','), (',', 'P.T.'), ('P.T.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Addo-Tenkorang', ',', 'R.'), (',', 'R.', 'Helo'), ('R.', 'Helo', ','), ('Helo', ',', 'P.T.'), (',', 'P.T.', ','), ('P.T.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Addo-Tenkorang', 'NNP'), (',', ','), ('R.', 'NNP'), ('Helo', 'NNP'), (',', ','), ('P.T.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Addo-Tenkorang', 'R. Helo', 'P.T.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Addo-Tenkorang', 'addo-tenkorang'), (',', ','), ('R.', 'r.'), ('Helo', 'helo'), (',', ','), ('P.T.', 'p.t.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Addo-Tenkorang', 'addo-tenkorang'), (',', ','), ('R.', 'r.'), ('Helo', 'helo'), (',', ','), ('P.T.', 'p.t.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Addo-Tenkorang', 'Addo-Tenkorang'), (',', ','), ('R.', 'R.'), ('Helo', 'Helo'), (',', ','), ('P.T.', 'P.T.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data applications in operations/supply-chain

>> Tokens are: 
 ['Big', 'data', 'applications', 'operations/supply-chain']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'applications'), ('applications', 'operations/supply-chain')]

>> Trigrams are: 
 [('Big', 'data', 'applications'), ('data', 'applications', 'operations/supply-chain')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('applications', 'NNS'), ('operations/supply-chain', 'VBP')]

>> Noun Phrases are: 
 ['Big data applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('applications', 'applic'), ('operations/supply-chain', 'operations/supply-chain')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('applications', 'applic'), ('operations/supply-chain', 'operations/supply-chain')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('applications', 'application'), ('operations/supply-chain', 'operations/supply-chain')]



========================================== PARAGRAPH 1392 ===========================================

management: A literature review. Computers & Industrial Engineering journal, Volume 101, pp.  

------------------- Sentence 1 -------------------

management: A literature review.

>> Tokens are: 
 ['management', ':', 'A', 'literature', 'review', '.']

>> Bigrams are: 
 [('management', ':'), (':', 'A'), ('A', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('management', ':', 'A'), (':', 'A', 'literature'), ('A', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('management', 'NN'), (':', ':'), ('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['management', 'A literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('management', 'management'), (':', ':'), ('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]


------------------- Sentence 2 -------------------

Computers & Industrial Engineering journal, Volume 101, pp.

>> Tokens are: 
 ['Computers', '&', 'Industrial', 'Engineering', 'journal', ',', 'Volume', '101', ',', 'pp', '.']

>> Bigrams are: 
 [('Computers', '&'), ('&', 'Industrial'), ('Industrial', 'Engineering'), ('Engineering', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '101'), ('101', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Computers', '&', 'Industrial'), ('&', 'Industrial', 'Engineering'), ('Industrial', 'Engineering', 'journal'), ('Engineering', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '101'), ('Volume', '101', ','), ('101', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Computers', 'NNP'), ('&', 'CC'), ('Industrial', 'NNP'), ('Engineering', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('101', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Computers', 'Industrial Engineering journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computers'), ('ORGANIZATION', 'Industrial'), ('ORGANIZATION', 'Volume 101')] 

>> Stemming using Porter Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Computers', 'Computers'), ('&', '&'), ('Industrial', 'Industrial'), ('Engineering', 'Engineering'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]



========================================== PARAGRAPH 1393 ===========================================

528-543.  

------------------- Sentence 1 -------------------

528-543.

>> Tokens are: 
 ['528-543', '.']

>> Bigrams are: 
 [('528-543', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('528-543', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('528-543', '528-543'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('528-543', '528-543'), ('.', '.')]

>> Lemmatization: 
 [('528-543', '528-543'), ('.', '.')]



========================================== PARAGRAPH 1394 ===========================================

Agarwal, R. and Dhar, V., 2014. Big data, data science, and analytics: The opportunity and  

------------------- Sentence 1 -------------------

Agarwal, R. and Dhar, V., 2014.

>> Tokens are: 
 ['Agarwal', ',', 'R.', 'Dhar', ',', 'V.', ',', '2014', '.']

>> Bigrams are: 
 [('Agarwal', ','), (',', 'R.'), ('R.', 'Dhar'), ('Dhar', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Agarwal', ',', 'R.'), (',', 'R.', 'Dhar'), ('R.', 'Dhar', ','), ('Dhar', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Agarwal', 'NNP'), (',', ','), ('R.', 'NNP'), ('Dhar', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Agarwal', 'R. Dhar', 'V.']

>> Named Entities are: 
 [('GPE', 'Agarwal')] 

>> Stemming using Porter Stemmer: 
 [('Agarwal', 'agarw'), (',', ','), ('R.', 'r.'), ('Dhar', 'dhar'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Agarwal', 'agarw'), (',', ','), ('R.', 'r.'), ('Dhar', 'dhar'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Agarwal', 'Agarwal'), (',', ','), ('R.', 'R.'), ('Dhar', 'Dhar'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data, data science, and analytics: The opportunity and

>> Tokens are: 
 ['Big', 'data', ',', 'data', 'science', ',', 'analytics', ':', 'The', 'opportunity']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'data'), ('data', 'science'), ('science', ','), (',', 'analytics'), ('analytics', ':'), (':', 'The'), ('The', 'opportunity')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'data'), (',', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'analytics'), (',', 'analytics', ':'), ('analytics', ':', 'The'), (':', 'The', 'opportunity')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('science', 'NN'), (',', ','), ('analytics', 'NNS'), (':', ':'), ('The', 'DT'), ('opportunity', 'NN')]

>> Noun Phrases are: 
 ['Big data', 'data science', 'analytics', 'The opportunity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (':', ':'), ('The', 'the'), ('opportunity', 'opportun')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (':', ':'), ('The', 'the'), ('opportunity', 'opportun')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'science'), (',', ','), ('analytics', 'analytics'), (':', ':'), ('The', 'The'), ('opportunity', 'opportunity')]



========================================== PARAGRAPH 1395 ===========================================

challenge for IS research. IS research Journal.  

------------------- Sentence 1 -------------------

challenge for IS research.

>> Tokens are: 
 ['challenge', 'IS', 'research', '.']

>> Bigrams are: 
 [('challenge', 'IS'), ('IS', 'research'), ('research', '.')]

>> Trigrams are: 
 [('challenge', 'IS', 'research'), ('IS', 'research', '.')]

>> POS Tags are: 
 [('challenge', 'NN'), ('IS', 'NNP'), ('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['challenge IS research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenge', 'challeng'), ('IS', 'is'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenge', 'challeng'), ('IS', 'is'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('challenge', 'challenge'), ('IS', 'IS'), ('research', 'research'), ('.', '.')]


------------------- Sentence 2 -------------------

IS research Journal.

>> Tokens are: 
 ['IS', 'research', 'Journal', '.']

>> Bigrams are: 
 [('IS', 'research'), ('research', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('IS', 'research', 'Journal'), ('research', 'Journal', '.')]

>> POS Tags are: 
 [('IS', 'VBZ'), ('research', 'NN'), ('Journal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['research Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IS', 'is'), ('research', 'research'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IS', 'is'), ('research', 'research'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('IS', 'IS'), ('research', 'research'), ('Journal', 'Journal'), ('.', '.')]



========================================== PARAGRAPH 1396 ===========================================

Akter, S., Wamba, S.F., Gunasekaran, A., Dubey, R. and Childe, S.J., 2016. How to improve firm  

------------------- Sentence 1 -------------------

Akter, S., Wamba, S.F., Gunasekaran, A., Dubey, R. and Childe, S.J., 2016.

>> Tokens are: 
 ['Akter', ',', 'S.', ',', 'Wamba', ',', 'S.F.', ',', 'Gunasekaran', ',', 'A.', ',', 'Dubey', ',', 'R.', 'Childe', ',', 'S.J.', ',', '2016', '.']

>> Bigrams are: 
 [('Akter', ','), (',', 'S.'), ('S.', ','), (',', 'Wamba'), ('Wamba', ','), (',', 'S.F.'), ('S.F.', ','), (',', 'Gunasekaran'), ('Gunasekaran', ','), (',', 'A.'), ('A.', ','), (',', 'Dubey'), ('Dubey', ','), (',', 'R.'), ('R.', 'Childe'), ('Childe', ','), (',', 'S.J.'), ('S.J.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Akter', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Wamba'), (',', 'Wamba', ','), ('Wamba', ',', 'S.F.'), (',', 'S.F.', ','), ('S.F.', ',', 'Gunasekaran'), (',', 'Gunasekaran', ','), ('Gunasekaran', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Dubey'), (',', 'Dubey', ','), ('Dubey', ',', 'R.'), (',', 'R.', 'Childe'), ('R.', 'Childe', ','), ('Childe', ',', 'S.J.'), (',', 'S.J.', ','), ('S.J.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Akter', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Wamba', 'NNP'), (',', ','), ('S.F.', 'NNP'), (',', ','), ('Gunasekaran', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Dubey', 'NNP'), (',', ','), ('R.', 'NNP'), ('Childe', 'NNP'), (',', ','), ('S.J.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Akter', 'S.', 'Wamba', 'S.F.', 'Gunasekaran', 'A.', 'Dubey', 'R. Childe', 'S.J.']

>> Named Entities are: 
 [('PERSON', 'Akter'), ('PERSON', 'Wamba'), ('GPE', 'Gunasekaran'), ('PERSON', 'Dubey')] 

>> Stemming using Porter Stemmer: 
 [('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Akter', 'Akter'), (',', ','), ('S.', 'S.'), (',', ','), ('Wamba', 'Wamba'), (',', ','), ('S.F.', 'S.F.'), (',', ','), ('Gunasekaran', 'Gunasekaran'), (',', ','), ('A.', 'A.'), (',', ','), ('Dubey', 'Dubey'), (',', ','), ('R.', 'R.'), ('Childe', 'Childe'), (',', ','), ('S.J.', 'S.J.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

How to improve firm

>> Tokens are: 
 ['How', 'improve', 'firm']

>> Bigrams are: 
 [('How', 'improve'), ('improve', 'firm')]

>> Trigrams are: 
 [('How', 'improve', 'firm')]

>> POS Tags are: 
 [('How', 'WRB'), ('improve', 'JJ'), ('firm', 'NN')]

>> Noun Phrases are: 
 ['improve firm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('improve', 'improv'), ('firm', 'firm')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('improve', 'improv'), ('firm', 'firm')]

>> Lemmatization: 
 [('How', 'How'), ('improve', 'improve'), ('firm', 'firm')]



========================================== PARAGRAPH 1397 ===========================================

performance using big data analytics capability and business strategy alignment?. International  

------------------- Sentence 1 -------------------

performance using big data analytics capability and business strategy alignment?.

>> Tokens are: 
 ['performance', 'using', 'big', 'data', 'analytics', 'capability', 'business', 'strategy', 'alignment', '?', '.']

>> Bigrams are: 
 [('performance', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capability'), ('capability', 'business'), ('business', 'strategy'), ('strategy', 'alignment'), ('alignment', '?'), ('?', '.')]

>> Trigrams are: 
 [('performance', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capability'), ('analytics', 'capability', 'business'), ('capability', 'business', 'strategy'), ('business', 'strategy', 'alignment'), ('strategy', 'alignment', '?'), ('alignment', '?', '.')]

>> POS Tags are: 
 [('performance', 'NN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capability', 'NN'), ('business', 'NN'), ('strategy', 'NN'), ('alignment', 'NN'), ('?', '.'), ('.', '.')]

>> Noun Phrases are: 
 ['performance', 'big data analytics capability business strategy alignment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('performance', 'perform'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('business', 'busi'), ('strategy', 'strategi'), ('alignment', 'align'), ('?', '?'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('performance', 'perform'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('business', 'busi'), ('strategy', 'strategi'), ('alignment', 'align'), ('?', '?'), ('.', '.')]

>> Lemmatization: 
 [('performance', 'performance'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capability', 'capability'), ('business', 'business'), ('strategy', 'strategy'), ('alignment', 'alignment'), ('?', '?'), ('.', '.')]


------------------- Sentence 2 -------------------

International

>> Tokens are: 
 ['International']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('International', 'NNP')]

>> Noun Phrases are: 
 ['International']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern')]

>> Lemmatization: 
 [('International', 'International')]



========================================== PARAGRAPH 1398 ===========================================

Journal of Production Economics, pp. 113-131.  

------------------- Sentence 1 -------------------

Journal of Production Economics, pp.

>> Tokens are: 
 ['Journal', 'Production', 'Economics', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Production'), ('Production', 'Economics'), ('Economics', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Production', 'Economics'), ('Production', 'Economics', ','), ('Economics', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Production', 'NNP'), ('Economics', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Production Economics', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Production', 'product'), ('Economics', 'econom'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Production', 'product'), ('Economics', 'econom'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Production', 'Production'), ('Economics', 'Economics'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

113-131.

>> Tokens are: 
 ['113-131', '.']

>> Bigrams are: 
 [('113-131', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('113-131', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('113-131', '113-131'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('113-131', '113-131'), ('.', '.')]

>> Lemmatization: 
 [('113-131', '113-131'), ('.', '.')]



========================================== PARAGRAPH 1399 ===========================================

Al-Barashdi, H. and Al-Karousi, R., 2019. Big Data in academic libraries: literature review and  

------------------- Sentence 1 -------------------

Al-Barashdi, H. and Al-Karousi, R., 2019.

>> Tokens are: 
 ['Al-Barashdi', ',', 'H.', 'Al-Karousi', ',', 'R.', ',', '2019', '.']

>> Bigrams are: 
 [('Al-Barashdi', ','), (',', 'H.'), ('H.', 'Al-Karousi'), ('Al-Karousi', ','), (',', 'R.'), ('R.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Al-Barashdi', ',', 'H.'), (',', 'H.', 'Al-Karousi'), ('H.', 'Al-Karousi', ','), ('Al-Karousi', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Al-Barashdi', 'NNP'), (',', ','), ('H.', 'NNP'), ('Al-Karousi', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Al-Barashdi', 'H. Al-Karousi', 'R.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Al-Barashdi', 'al-barashdi'), (',', ','), ('H.', 'h.'), ('Al-Karousi', 'al-karousi'), (',', ','), ('R.', 'r.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Al-Barashdi', 'al-barashdi'), (',', ','), ('H.', 'h.'), ('Al-Karousi', 'al-karousi'), (',', ','), ('R.', 'r.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Al-Barashdi', 'Al-Barashdi'), (',', ','), ('H.', 'H.'), ('Al-Karousi', 'Al-Karousi'), (',', ','), ('R.', 'R.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data in academic libraries: literature review and

>> Tokens are: 
 ['Big', 'Data', 'academic', 'libraries', ':', 'literature', 'review']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'academic'), ('academic', 'libraries'), ('libraries', ':'), (':', 'literature'), ('literature', 'review')]

>> Trigrams are: 
 [('Big', 'Data', 'academic'), ('Data', 'academic', 'libraries'), ('academic', 'libraries', ':'), ('libraries', ':', 'literature'), (':', 'literature', 'review')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('academic', 'JJ'), ('libraries', 'NNS'), (':', ':'), ('literature', 'NN'), ('review', 'NN')]

>> Noun Phrases are: 
 ['Big Data', 'academic libraries', 'literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('academic', 'academ'), ('libraries', 'librari'), (':', ':'), ('literature', 'literatur'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('academic', 'academ'), ('libraries', 'librari'), (':', ':'), ('literature', 'literatur'), ('review', 'review')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('academic', 'academic'), ('libraries', 'library'), (':', ':'), ('literature', 'literature'), ('review', 'review')]



========================================== PARAGRAPH 1400 ===========================================

future research directions.. Journal of Information Studies and Technology, p. 13.  

------------------- Sentence 1 -------------------

future research directions.. Journal of Information Studies and Technology, p. 13.

>> Tokens are: 
 ['future', 'research', 'directions', '..', 'Journal', 'Information', 'Studies', 'Technology', ',', 'p.', '13', '.']

>> Bigrams are: 
 [('future', 'research'), ('research', 'directions'), ('directions', '..'), ('..', 'Journal'), ('Journal', 'Information'), ('Information', 'Studies'), ('Studies', 'Technology'), ('Technology', ','), (',', 'p.'), ('p.', '13'), ('13', '.')]

>> Trigrams are: 
 [('future', 'research', 'directions'), ('research', 'directions', '..'), ('directions', '..', 'Journal'), ('..', 'Journal', 'Information'), ('Journal', 'Information', 'Studies'), ('Information', 'Studies', 'Technology'), ('Studies', 'Technology', ','), ('Technology', ',', 'p.'), (',', 'p.', '13'), ('p.', '13', '.')]

>> POS Tags are: 
 [('future', 'JJ'), ('research', 'NN'), ('directions', 'NNS'), ('..', 'VBP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Studies', 'NNP'), ('Technology', 'NNP'), (',', ','), ('p.', 'VBD'), ('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['future research directions', 'Journal Information Studies Technology']

>> Named Entities are: 
 [('PERSON', 'Journal Information Studies Technology')] 

>> Stemming using Porter Stemmer: 
 [('future', 'futur'), ('research', 'research'), ('directions', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Studies', 'studi'), ('Technology', 'technolog'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('future', 'futur'), ('research', 'research'), ('directions', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Studies', 'studi'), ('Technology', 'technolog'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('future', 'future'), ('research', 'research'), ('directions', 'direction'), ('..', '..'), ('Journal', 'Journal'), ('Information', 'Information'), ('Studies', 'Studies'), ('Technology', 'Technology'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]



========================================== PARAGRAPH 1401 ===========================================

Ali, A., Qadir, J., ur Rasool, R., Sathiaseelan, A., Zwitter, A. and Crowcroft, J., 2016. Big data for  

------------------- Sentence 1 -------------------

Ali, A., Qadir, J., ur Rasool, R., Sathiaseelan, A., Zwitter, A. and Crowcroft, J., 2016.

>> Tokens are: 
 ['Ali', ',', 'A.', ',', 'Qadir', ',', 'J.', ',', 'ur', 'Rasool', ',', 'R.', ',', 'Sathiaseelan', ',', 'A.', ',', 'Zwitter', ',', 'A.', 'Crowcroft', ',', 'J.', ',', '2016', '.']

>> Bigrams are: 
 [('Ali', ','), (',', 'A.'), ('A.', ','), (',', 'Qadir'), ('Qadir', ','), (',', 'J.'), ('J.', ','), (',', 'ur'), ('ur', 'Rasool'), ('Rasool', ','), (',', 'R.'), ('R.', ','), (',', 'Sathiaseelan'), ('Sathiaseelan', ','), (',', 'A.'), ('A.', ','), (',', 'Zwitter'), ('Zwitter', ','), (',', 'A.'), ('A.', 'Crowcroft'), ('Crowcroft', ','), (',', 'J.'), ('J.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Ali', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Qadir'), (',', 'Qadir', ','), ('Qadir', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'ur'), (',', 'ur', 'Rasool'), ('ur', 'Rasool', ','), ('Rasool', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Sathiaseelan'), (',', 'Sathiaseelan', ','), ('Sathiaseelan', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Zwitter'), (',', 'Zwitter', ','), ('Zwitter', ',', 'A.'), (',', 'A.', 'Crowcroft'), ('A.', 'Crowcroft', ','), ('Crowcroft', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Ali', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Qadir', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('ur', 'JJ'), ('Rasool', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Sathiaseelan', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Zwitter', 'NNP'), (',', ','), ('A.', 'NNP'), ('Crowcroft', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ali', 'A.', 'Qadir', 'J.', 'ur Rasool', 'R.', 'Sathiaseelan', 'A.', 'Zwitter', 'A. Crowcroft', 'J.']

>> Named Entities are: 
 [('GPE', 'Ali'), ('PERSON', 'Qadir'), ('GPE', 'Rasool'), ('GPE', 'Sathiaseelan'), ('PERSON', 'Zwitter')] 

>> Stemming using Porter Stemmer: 
 [('Ali', 'ali'), (',', ','), ('A.', 'a.'), (',', ','), ('Qadir', 'qadir'), (',', ','), ('J.', 'j.'), (',', ','), ('ur', 'ur'), ('Rasool', 'rasool'), (',', ','), ('R.', 'r.'), (',', ','), ('Sathiaseelan', 'sathiaseelan'), (',', ','), ('A.', 'a.'), (',', ','), ('Zwitter', 'zwitter'), (',', ','), ('A.', 'a.'), ('Crowcroft', 'crowcroft'), (',', ','), ('J.', 'j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ali', 'ali'), (',', ','), ('A.', 'a.'), (',', ','), ('Qadir', 'qadir'), (',', ','), ('J.', 'j.'), (',', ','), ('ur', 'ur'), ('Rasool', 'rasool'), (',', ','), ('R.', 'r.'), (',', ','), ('Sathiaseelan', 'sathiaseelan'), (',', ','), ('A.', 'a.'), (',', ','), ('Zwitter', 'zwitter'), (',', ','), ('A.', 'a.'), ('Crowcroft', 'crowcroft'), (',', ','), ('J.', 'j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Ali', 'Ali'), (',', ','), ('A.', 'A.'), (',', ','), ('Qadir', 'Qadir'), (',', ','), ('J.', 'J.'), (',', ','), ('ur', 'ur'), ('Rasool', 'Rasool'), (',', ','), ('R.', 'R.'), (',', ','), ('Sathiaseelan', 'Sathiaseelan'), (',', ','), ('A.', 'A.'), (',', ','), ('Zwitter', 'Zwitter'), (',', ','), ('A.', 'A.'), ('Crowcroft', 'Crowcroft'), (',', ','), ('J.', 'J.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data for

>> Tokens are: 
 ['Big', 'data']

>> Bigrams are: 
 [('Big', 'data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data')]



========================================== PARAGRAPH 1402 ===========================================

development: applications and techniques.. Big Data Analytics journal, Volume 1, p. 2.  

------------------- Sentence 1 -------------------

development: applications and techniques.. Big Data Analytics journal, Volume 1, p. 2.

>> Tokens are: 
 ['development', ':', 'applications', 'techniques', '..', 'Big', 'Data', 'Analytics', 'journal', ',', 'Volume', '1', ',', 'p.', '2', '.']

>> Bigrams are: 
 [('development', ':'), (':', 'applications'), ('applications', 'techniques'), ('techniques', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '1'), ('1', ','), (',', 'p.'), ('p.', '2'), ('2', '.')]

>> Trigrams are: 
 [('development', ':', 'applications'), (':', 'applications', 'techniques'), ('applications', 'techniques', '..'), ('techniques', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'journal'), ('Analytics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '1'), ('Volume', '1', ','), ('1', ',', 'p.'), (',', 'p.', '2'), ('p.', '2', '.')]

>> POS Tags are: 
 [('development', 'NN'), (':', ':'), ('applications', 'NNS'), ('techniques', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('1', 'CD'), (',', ','), ('p.', 'RB'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['development', 'applications techniques', 'Big Data Analytics journal', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('development', 'develop'), (':', ':'), ('applications', 'applic'), ('techniques', 'techniqu'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('development', 'develop'), (':', ':'), ('applications', 'applic'), ('techniques', 'techniqu'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('development', 'development'), (':', ':'), ('applications', 'application'), ('techniques', 'technique'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]



========================================== PARAGRAPH 1403 ===========================================

Arunachalam, D., Kumar, N. and Kawalek, J.P., 2018. Arunachalam, D., Kumar, N.  

------------------- Sentence 1 -------------------

Arunachalam, D., Kumar, N. and Kawalek, J.P., 2018.

>> Tokens are: 
 ['Arunachalam', ',', 'D.', ',', 'Kumar', ',', 'N.', 'Kawalek', ',', 'J.P.', ',', '2018', '.']

>> Bigrams are: 
 [('Arunachalam', ','), (',', 'D.'), ('D.', ','), (',', 'Kumar'), ('Kumar', ','), (',', 'N.'), ('N.', 'Kawalek'), ('Kawalek', ','), (',', 'J.P.'), ('J.P.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Arunachalam', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Kumar'), (',', 'Kumar', ','), ('Kumar', ',', 'N.'), (',', 'N.', 'Kawalek'), ('N.', 'Kawalek', ','), ('Kawalek', ',', 'J.P.'), (',', 'J.P.', ','), ('J.P.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Kumar', 'NNP'), (',', ','), ('N.', 'NNP'), ('Kawalek', 'NNP'), (',', ','), ('J.P.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Arunachalam', 'D.', 'Kumar', 'N. Kawalek', 'J.P.']

>> Named Entities are: 
 [('GPE', 'Arunachalam'), ('PERSON', 'Kumar')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('Kawalek', 'kawalek'), (',', ','), ('J.P.', 'j.p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('Kawalek', 'kawalek'), (',', ','), ('J.P.', 'j.p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), (',', ','), ('D.', 'D.'), (',', ','), ('Kumar', 'Kumar'), (',', ','), ('N.', 'N.'), ('Kawalek', 'Kawalek'), (',', ','), ('J.P.', 'J.P.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Arunachalam, D., Kumar, N.

>> Tokens are: 
 ['Arunachalam', ',', 'D.', ',', 'Kumar', ',', 'N', '.']

>> Bigrams are: 
 [('Arunachalam', ','), (',', 'D.'), ('D.', ','), (',', 'Kumar'), ('Kumar', ','), (',', 'N'), ('N', '.')]

>> Trigrams are: 
 [('Arunachalam', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Kumar'), (',', 'Kumar', ','), ('Kumar', ',', 'N'), (',', 'N', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Kumar', 'NNP'), (',', ','), ('N', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Arunachalam', 'D.', 'Kumar', 'N']

>> Named Entities are: 
 [('GPE', 'Arunachalam'), ('PERSON', 'Kumar')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N', 'n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N', 'n'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), (',', ','), ('D.', 'D.'), (',', ','), ('Kumar', 'Kumar'), (',', ','), ('N', 'N'), ('.', '.')]



========================================== PARAGRAPH 1404 ===========================================

anUnderstanding big data analytics capabilities in supply chain management: Unravelling the  

------------------- Sentence 1 -------------------

anUnderstanding big data analytics capabilities in supply chain management: Unravelling the

>> Tokens are: 
 ['anUnderstanding', 'big', 'data', 'analytics', 'capabilities', 'supply', 'chain', 'management', ':', 'Unravelling']

>> Bigrams are: 
 [('anUnderstanding', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capabilities'), ('capabilities', 'supply'), ('supply', 'chain'), ('chain', 'management'), ('management', ':'), (':', 'Unravelling')]

>> Trigrams are: 
 [('anUnderstanding', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capabilities'), ('analytics', 'capabilities', 'supply'), ('capabilities', 'supply', 'chain'), ('supply', 'chain', 'management'), ('chain', 'management', ':'), ('management', ':', 'Unravelling')]

>> POS Tags are: 
 [('anUnderstanding', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capabilities', 'NNS'), ('supply', 'VBP'), ('chain', 'NN'), ('management', 'NN'), (':', ':'), ('Unravelling', 'NN')]

>> Noun Phrases are: 
 ['big data analytics capabilities', 'chain management', 'Unravelling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('anUnderstanding', 'anunderstand'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), (':', ':'), ('Unravelling', 'unravel')]

>> Stemming using Snowball Stemmer: 
 [('anUnderstanding', 'anunderstand'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), (':', ':'), ('Unravelling', 'unravel')]

>> Lemmatization: 
 [('anUnderstanding', 'anUnderstanding'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capabilities', 'capability'), ('supply', 'supply'), ('chain', 'chain'), ('management', 'management'), (':', ':'), ('Unravelling', 'Unravelling')]



========================================== PARAGRAPH 1405 ===========================================

issues, challenges and implications for practice.. Transportation Research Part E: Logistics and  

------------------- Sentence 1 -------------------

issues, challenges and implications for practice.. Transportation Research Part E: Logistics and

>> Tokens are: 
 ['issues', ',', 'challenges', 'implications', 'practice', '..', 'Transportation', 'Research', 'Part', 'E', ':', 'Logistics']

>> Bigrams are: 
 [('issues', ','), (',', 'challenges'), ('challenges', 'implications'), ('implications', 'practice'), ('practice', '..'), ('..', 'Transportation'), ('Transportation', 'Research'), ('Research', 'Part'), ('Part', 'E'), ('E', ':'), (':', 'Logistics')]

>> Trigrams are: 
 [('issues', ',', 'challenges'), (',', 'challenges', 'implications'), ('challenges', 'implications', 'practice'), ('implications', 'practice', '..'), ('practice', '..', 'Transportation'), ('..', 'Transportation', 'Research'), ('Transportation', 'Research', 'Part'), ('Research', 'Part', 'E'), ('Part', 'E', ':'), ('E', ':', 'Logistics')]

>> POS Tags are: 
 [('issues', 'NNS'), (',', ','), ('challenges', 'NNS'), ('implications', 'NNS'), ('practice', 'NN'), ('..', 'CD'), ('Transportation', 'NNP'), ('Research', 'NNP'), ('Part', 'NNP'), ('E', 'NNP'), (':', ':'), ('Logistics', 'NNS')]

>> Noun Phrases are: 
 ['issues', 'challenges implications practice', 'Transportation Research Part E', 'Logistics']

>> Named Entities are: 
 [('ORGANIZATION', 'Transportation Research Part')] 

>> Stemming using Porter Stemmer: 
 [('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('implications', 'implic'), ('practice', 'practic'), ('..', '..'), ('Transportation', 'transport'), ('Research', 'research'), ('Part', 'part'), ('E', 'e'), (':', ':'), ('Logistics', 'logist')]

>> Stemming using Snowball Stemmer: 
 [('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('implications', 'implic'), ('practice', 'practic'), ('..', '..'), ('Transportation', 'transport'), ('Research', 'research'), ('Part', 'part'), ('E', 'e'), (':', ':'), ('Logistics', 'logist')]

>> Lemmatization: 
 [('issues', 'issue'), (',', ','), ('challenges', 'challenge'), ('implications', 'implication'), ('practice', 'practice'), ('..', '..'), ('Transportation', 'Transportation'), ('Research', 'Research'), ('Part', 'Part'), ('E', 'E'), (':', ':'), ('Logistics', 'Logistics')]



========================================== PARAGRAPH 1406 ===========================================

Transportation Review journal, Volume 114, pp. 416--436.  

------------------- Sentence 1 -------------------

Transportation Review journal, Volume 114, pp.

>> Tokens are: 
 ['Transportation', 'Review', 'journal', ',', 'Volume', '114', ',', 'pp', '.']

>> Bigrams are: 
 [('Transportation', 'Review'), ('Review', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '114'), ('114', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Transportation', 'Review', 'journal'), ('Review', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '114'), ('Volume', '114', ','), ('114', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Transportation', 'NNP'), ('Review', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('114', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Transportation Review journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 114')] 

>> Stemming using Porter Stemmer: 
 [('Transportation', 'transport'), ('Review', 'review'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Transportation', 'transport'), ('Review', 'review'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Transportation', 'Transportation'), ('Review', 'Review'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

416--436.

>> Tokens are: 
 ['416', '--', '436', '.']

>> Bigrams are: 
 [('416', '--'), ('--', '436'), ('436', '.')]

>> Trigrams are: 
 [('416', '--', '436'), ('--', '436', '.')]

>> POS Tags are: 
 [('416', 'CD'), ('--', ':'), ('436', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]

>> Lemmatization: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]



========================================== PARAGRAPH 1407 ===========================================

Bakshi, K., 2012. Considerations for big data: Architecture and approach conference. s.l., IEEE,  

------------------- Sentence 1 -------------------

Bakshi, K., 2012.

>> Tokens are: 
 ['Bakshi', ',', 'K.', ',', '2012', '.']

>> Bigrams are: 
 [('Bakshi', ','), (',', 'K.'), ('K.', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Bakshi', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('Bakshi', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Bakshi', 'K.']

>> Named Entities are: 
 [('GPE', 'Bakshi')] 

>> Stemming using Porter Stemmer: 
 [('Bakshi', 'bakshi'), (',', ','), ('K.', 'k.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bakshi', 'bakshi'), (',', ','), ('K.', 'k.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Bakshi', 'Bakshi'), (',', ','), ('K.', 'K.'), (',', ','), ('2012', '2012'), ('.', '.')]


------------------- Sentence 2 -------------------

Considerations for big data: Architecture and approach conference.

>> Tokens are: 
 ['Considerations', 'big', 'data', ':', 'Architecture', 'approach', 'conference', '.']

>> Bigrams are: 
 [('Considerations', 'big'), ('big', 'data'), ('data', ':'), (':', 'Architecture'), ('Architecture', 'approach'), ('approach', 'conference'), ('conference', '.')]

>> Trigrams are: 
 [('Considerations', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'Architecture'), (':', 'Architecture', 'approach'), ('Architecture', 'approach', 'conference'), ('approach', 'conference', '.')]

>> POS Tags are: 
 [('Considerations', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('Architecture', 'NNP'), ('approach', 'NN'), ('conference', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Considerations', 'big data', 'Architecture approach conference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Considerations', 'consider'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'architectur'), ('approach', 'approach'), ('conference', 'confer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Considerations', 'consider'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'architectur'), ('approach', 'approach'), ('conference', 'confer'), ('.', '.')]

>> Lemmatization: 
 [('Considerations', 'Considerations'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'Architecture'), ('approach', 'approach'), ('conference', 'conference'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., IEEE,

>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ',')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ',')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ',')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ',')]



========================================== PARAGRAPH 1408 ===========================================

pp. (1-7).  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

(1-7).

>> Tokens are: 
 ['(', '1-7', ')', '.']

>> Bigrams are: 
 [('(', '1-7'), ('1-7', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1-7', ')'), ('1-7', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1-7', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1409 ===========================================

Banerjee, A., Bandyopadhyay, T. and Acharya, P., 2013. Data analytics: Hyped up aspirations or  

------------------- Sentence 1 -------------------

Banerjee, A., Bandyopadhyay, T. and Acharya, P., 2013.

>> Tokens are: 
 ['Banerjee', ',', 'A.', ',', 'Bandyopadhyay', ',', 'T.', 'Acharya', ',', 'P.', ',', '2013', '.']

>> Bigrams are: 
 [('Banerjee', ','), (',', 'A.'), ('A.', ','), (',', 'Bandyopadhyay'), ('Bandyopadhyay', ','), (',', 'T.'), ('T.', 'Acharya'), ('Acharya', ','), (',', 'P.'), ('P.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Banerjee', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Bandyopadhyay'), (',', 'Bandyopadhyay', ','), ('Bandyopadhyay', ',', 'T.'), (',', 'T.', 'Acharya'), ('T.', 'Acharya', ','), ('Acharya', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Banerjee', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Bandyopadhyay', 'NNP'), (',', ','), ('T.', 'NNP'), ('Acharya', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Banerjee', 'A.', 'Bandyopadhyay', 'T. Acharya', 'P.']

>> Named Entities are: 
 [('GPE', 'Banerjee'), ('GPE', 'Bandyopadhyay')] 

>> Stemming using Porter Stemmer: 
 [('Banerjee', 'banerje'), (',', ','), ('A.', 'a.'), (',', ','), ('Bandyopadhyay', 'bandyopadhyay'), (',', ','), ('T.', 't.'), ('Acharya', 'acharya'), (',', ','), ('P.', 'p.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Banerjee', 'banerje'), (',', ','), ('A.', 'a.'), (',', ','), ('Bandyopadhyay', 'bandyopadhyay'), (',', ','), ('T.', 't.'), ('Acharya', 'acharya'), (',', ','), ('P.', 'p.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Banerjee', 'Banerjee'), (',', ','), ('A.', 'A.'), (',', ','), ('Bandyopadhyay', 'Bandyopadhyay'), (',', ','), ('T.', 'T.'), ('Acharya', 'Acharya'), (',', ','), ('P.', 'P.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Data analytics: Hyped up aspirations or

>> Tokens are: 
 ['Data', 'analytics', ':', 'Hyped', 'aspirations']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', ':'), (':', 'Hyped'), ('Hyped', 'aspirations')]

>> Trigrams are: 
 [('Data', 'analytics', ':'), ('analytics', ':', 'Hyped'), (':', 'Hyped', 'aspirations')]

>> POS Tags are: 
 [('Data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('Hyped', 'VBD'), ('aspirations', 'NNS')]

>> Noun Phrases are: 
 ['Data analytics', 'aspirations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Hyped', 'hype'), ('aspirations', 'aspir')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Hyped', 'hype'), ('aspirations', 'aspir')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), (':', ':'), ('Hyped', 'Hyped'), ('aspirations', 'aspiration')]



========================================== PARAGRAPH 1410 ===========================================

true potential?. Vikalpa journal, Volume 38, pp. 1-12.  

------------------- Sentence 1 -------------------

true potential?.

>> Tokens are: 
 ['true', 'potential', '?', '.']

>> Bigrams are: 
 [('true', 'potential'), ('potential', '?'), ('?', '.')]

>> Trigrams are: 
 [('true', 'potential', '?'), ('potential', '?', '.')]

>> POS Tags are: 
 [('true', 'JJ'), ('potential', 'NN'), ('?', '.'), ('.', '.')]

>> Noun Phrases are: 
 ['true potential']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('true', 'true'), ('potential', 'potenti'), ('?', '?'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('true', 'true'), ('potential', 'potenti'), ('?', '?'), ('.', '.')]

>> Lemmatization: 
 [('true', 'true'), ('potential', 'potential'), ('?', '?'), ('.', '.')]


------------------- Sentence 2 -------------------

Vikalpa journal, Volume 38, pp.

>> Tokens are: 
 ['Vikalpa', 'journal', ',', 'Volume', '38', ',', 'pp', '.']

>> Bigrams are: 
 [('Vikalpa', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '38'), ('38', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Vikalpa', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '38'), ('Volume', '38', ','), ('38', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Vikalpa', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('38', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Vikalpa journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Vikalpa'), ('ORGANIZATION', 'Volume 38')] 

>> Stemming using Porter Stemmer: 
 [('Vikalpa', 'vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vikalpa', 'vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Vikalpa', 'Vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1-12.

>> Tokens are: 
 ['1-12', '.']

>> Bigrams are: 
 [('1-12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1-12', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-12', '1-12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-12', '1-12'), ('.', '.')]

>> Lemmatization: 
 [('1-12', '1-12'), ('.', '.')]



========================================== PARAGRAPH 1411 ===========================================

Blazquez, D. and Domenech, J., 2018. Big Data sources and methods for social and economic  

------------------- Sentence 1 -------------------

Blazquez, D. and Domenech, J., 2018.

>> Tokens are: 
 ['Blazquez', ',', 'D.', 'Domenech', ',', 'J.', ',', '2018', '.']

>> Bigrams are: 
 [('Blazquez', ','), (',', 'D.'), ('D.', 'Domenech'), ('Domenech', ','), (',', 'J.'), ('J.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Blazquez', ',', 'D.'), (',', 'D.', 'Domenech'), ('D.', 'Domenech', ','), ('Domenech', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Blazquez', 'NNP'), (',', ','), ('D.', 'NNP'), ('Domenech', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Blazquez', 'D. Domenech', 'J.']

>> Named Entities are: 
 [('GPE', 'Blazquez')] 

>> Stemming using Porter Stemmer: 
 [('Blazquez', 'blazquez'), (',', ','), ('D.', 'd.'), ('Domenech', 'domenech'), (',', ','), ('J.', 'j.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Blazquez', 'blazquez'), (',', ','), ('D.', 'd.'), ('Domenech', 'domenech'), (',', ','), ('J.', 'j.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Blazquez', 'Blazquez'), (',', ','), ('D.', 'D.'), ('Domenech', 'Domenech'), (',', ','), ('J.', 'J.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data sources and methods for social and economic

>> Tokens are: 
 ['Big', 'Data', 'sources', 'methods', 'social', 'economic']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'sources'), ('sources', 'methods'), ('methods', 'social'), ('social', 'economic')]

>> Trigrams are: 
 [('Big', 'Data', 'sources'), ('Data', 'sources', 'methods'), ('sources', 'methods', 'social'), ('methods', 'social', 'economic')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('sources', 'NNS'), ('methods', 'VBD'), ('social', 'JJ'), ('economic', 'JJ')]

>> Noun Phrases are: 
 ['Big Data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('sources', 'sourc'), ('methods', 'method'), ('social', 'social'), ('economic', 'econom')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('sources', 'sourc'), ('methods', 'method'), ('social', 'social'), ('economic', 'econom')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('sources', 'source'), ('methods', 'method'), ('social', 'social'), ('economic', 'economic')]



========================================== PARAGRAPH 1412 ===========================================

analyses. Technological Forecasting and Social Change journal, Volume 130, pp. 99--113.  

------------------- Sentence 1 -------------------

analyses.

>> Tokens are: 
 ['analyses', '.']

>> Bigrams are: 
 [('analyses', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('analyses', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyses', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analyses', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('analyses', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Technological Forecasting and Social Change journal, Volume 130, pp.

>> Tokens are: 
 ['Technological', 'Forecasting', 'Social', 'Change', 'journal', ',', 'Volume', '130', ',', 'pp', '.']

>> Bigrams are: 
 [('Technological', 'Forecasting'), ('Forecasting', 'Social'), ('Social', 'Change'), ('Change', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '130'), ('130', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Technological', 'Forecasting', 'Social'), ('Forecasting', 'Social', 'Change'), ('Social', 'Change', 'journal'), ('Change', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '130'), ('Volume', '130', ','), ('130', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Technological', 'JJ'), ('Forecasting', 'NNP'), ('Social', 'NNP'), ('Change', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('130', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Technological Forecasting Social Change journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 130')] 

>> Stemming using Porter Stemmer: 
 [('Technological', 'technolog'), ('Forecasting', 'forecast'), ('Social', 'social'), ('Change', 'chang'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technological', 'technolog'), ('Forecasting', 'forecast'), ('Social', 'social'), ('Change', 'chang'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Technological', 'Technological'), ('Forecasting', 'Forecasting'), ('Social', 'Social'), ('Change', 'Change'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

99--113.

>> Tokens are: 
 ['99', '--', '113', '.']

>> Bigrams are: 
 [('99', '--'), ('--', '113'), ('113', '.')]

>> Trigrams are: 
 [('99', '--', '113'), ('--', '113', '.')]

>> POS Tags are: 
 [('99', 'CD'), ('--', ':'), ('113', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]

>> Lemmatization: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]



========================================== PARAGRAPH 1413 ===========================================

Boyd-Graber, J., Mimno, D. and Newman, D., 2014. Care and feeding of topic models: Problems,  

------------------- Sentence 1 -------------------

Boyd-Graber, J., Mimno, D. and Newman, D., 2014.

>> Tokens are: 
 ['Boyd-Graber', ',', 'J.', ',', 'Mimno', ',', 'D.', 'Newman', ',', 'D.', ',', '2014', '.']

>> Bigrams are: 
 [('Boyd-Graber', ','), (',', 'J.'), ('J.', ','), (',', 'Mimno'), ('Mimno', ','), (',', 'D.'), ('D.', 'Newman'), ('Newman', ','), (',', 'D.'), ('D.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Boyd-Graber', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Mimno'), (',', 'Mimno', ','), ('Mimno', ',', 'D.'), (',', 'D.', 'Newman'), ('D.', 'Newman', ','), ('Newman', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Boyd-Graber', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Mimno', 'NNP'), (',', ','), ('D.', 'NNP'), ('Newman', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Boyd-Graber', 'J.', 'Mimno', 'D. Newman', 'D.']

>> Named Entities are: 
 [('PERSON', 'Mimno')] 

>> Stemming using Porter Stemmer: 
 [('Boyd-Graber', 'boyd-grab'), (',', ','), ('J.', 'j.'), (',', ','), ('Mimno', 'mimno'), (',', ','), ('D.', 'd.'), ('Newman', 'newman'), (',', ','), ('D.', 'd.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boyd-Graber', 'boyd-grab'), (',', ','), ('J.', 'j.'), (',', ','), ('Mimno', 'mimno'), (',', ','), ('D.', 'd.'), ('Newman', 'newman'), (',', ','), ('D.', 'd.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Boyd-Graber', 'Boyd-Graber'), (',', ','), ('J.', 'J.'), (',', ','), ('Mimno', 'Mimno'), (',', ','), ('D.', 'D.'), ('Newman', 'Newman'), (',', ','), ('D.', 'D.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Care and feeding of topic models: Problems,

>> Tokens are: 
 ['Care', 'feeding', 'topic', 'models', ':', 'Problems', ',']

>> Bigrams are: 
 [('Care', 'feeding'), ('feeding', 'topic'), ('topic', 'models'), ('models', ':'), (':', 'Problems'), ('Problems', ',')]

>> Trigrams are: 
 [('Care', 'feeding', 'topic'), ('feeding', 'topic', 'models'), ('topic', 'models', ':'), ('models', ':', 'Problems'), (':', 'Problems', ',')]

>> POS Tags are: 
 [('Care', 'NNP'), ('feeding', 'VBG'), ('topic', 'NN'), ('models', 'NNS'), (':', ':'), ('Problems', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Care', 'topic models', 'Problems']

>> Named Entities are: 
 [('GPE', 'Care')] 

>> Stemming using Porter Stemmer: 
 [('Care', 'care'), ('feeding', 'feed'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'problem'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Care', 'care'), ('feeding', 'feed'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'problem'), (',', ',')]

>> Lemmatization: 
 [('Care', 'Care'), ('feeding', 'feeding'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'Problems'), (',', ',')]



========================================== PARAGRAPH 1414 ===========================================

diagnostics, and improvements.. Handbook of mixed membership models and their applications  

------------------- Sentence 1 -------------------

diagnostics, and improvements.. Handbook of mixed membership models and their applications

>> Tokens are: 
 ['diagnostics', ',', 'improvements', '..', 'Handbook', 'mixed', 'membership', 'models', 'applications']

>> Bigrams are: 
 [('diagnostics', ','), (',', 'improvements'), ('improvements', '..'), ('..', 'Handbook'), ('Handbook', 'mixed'), ('mixed', 'membership'), ('membership', 'models'), ('models', 'applications')]

>> Trigrams are: 
 [('diagnostics', ',', 'improvements'), (',', 'improvements', '..'), ('improvements', '..', 'Handbook'), ('..', 'Handbook', 'mixed'), ('Handbook', 'mixed', 'membership'), ('mixed', 'membership', 'models'), ('membership', 'models', 'applications')]

>> POS Tags are: 
 [('diagnostics', 'NNS'), (',', ','), ('improvements', 'NNS'), ('..', 'VBP'), ('Handbook', 'NNP'), ('mixed', 'JJ'), ('membership', 'NN'), ('models', 'NNS'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['diagnostics', 'improvements', 'Handbook', 'mixed membership models applications']

>> Named Entities are: 
 [('PERSON', 'Handbook')] 

>> Stemming using Porter Stemmer: 
 [('diagnostics', 'diagnost'), (',', ','), ('improvements', 'improv'), ('..', '..'), ('Handbook', 'handbook'), ('mixed', 'mix'), ('membership', 'membership'), ('models', 'model'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('diagnostics', 'diagnost'), (',', ','), ('improvements', 'improv'), ('..', '..'), ('Handbook', 'handbook'), ('mixed', 'mix'), ('membership', 'membership'), ('models', 'model'), ('applications', 'applic')]

>> Lemmatization: 
 [('diagnostics', 'diagnostics'), (',', ','), ('improvements', 'improvement'), ('..', '..'), ('Handbook', 'Handbook'), ('mixed', 'mixed'), ('membership', 'membership'), ('models', 'model'), ('applications', 'application')]



========================================== PARAGRAPH 1415 ===========================================

Journal , Volume 225255.  

------------------- Sentence 1 -------------------

Journal , Volume 225255.

>> Tokens are: 
 ['Journal', ',', 'Volume', '225255', '.']

>> Bigrams are: 
 [('Journal', ','), (',', 'Volume'), ('Volume', '225255'), ('225255', '.')]

>> Trigrams are: 
 [('Journal', ',', 'Volume'), (',', 'Volume', '225255'), ('Volume', '225255', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('225255', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Journal'), ('ORGANIZATION', 'Volume 225255')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('225255', '225255'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('225255', '225255'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('225255', '225255'), ('.', '.')]



========================================== PARAGRAPH 1416 ===========================================

Bradlow, E.T., Gangwar, M., Kopalle, P. and Voleti, S., 2017. The role of big data and predictive  

------------------- Sentence 1 -------------------

Bradlow, E.T., Gangwar, M., Kopalle, P. and Voleti, S., 2017.

>> Tokens are: 
 ['Bradlow', ',', 'E.T.', ',', 'Gangwar', ',', 'M.', ',', 'Kopalle', ',', 'P.', 'Voleti', ',', 'S.', ',', '2017', '.']

>> Bigrams are: 
 [('Bradlow', ','), (',', 'E.T.'), ('E.T.', ','), (',', 'Gangwar'), ('Gangwar', ','), (',', 'M.'), ('M.', ','), (',', 'Kopalle'), ('Kopalle', ','), (',', 'P.'), ('P.', 'Voleti'), ('Voleti', ','), (',', 'S.'), ('S.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Bradlow', ',', 'E.T.'), (',', 'E.T.', ','), ('E.T.', ',', 'Gangwar'), (',', 'Gangwar', ','), ('Gangwar', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kopalle'), (',', 'Kopalle', ','), ('Kopalle', ',', 'P.'), (',', 'P.', 'Voleti'), ('P.', 'Voleti', ','), ('Voleti', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Bradlow', 'NNP'), (',', ','), ('E.T.', 'NNP'), (',', ','), ('Gangwar', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kopalle', 'NNP'), (',', ','), ('P.', 'NNP'), ('Voleti', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Bradlow', 'E.T.', 'Gangwar', 'M.', 'Kopalle', 'P. Voleti', 'S.']

>> Named Entities are: 
 [('GPE', 'Bradlow'), ('PERSON', 'Gangwar'), ('GPE', 'Kopalle')] 

>> Stemming using Porter Stemmer: 
 [('Bradlow', 'bradlow'), (',', ','), ('E.T.', 'e.t.'), (',', ','), ('Gangwar', 'gangwar'), (',', ','), ('M.', 'm.'), (',', ','), ('Kopalle', 'kopal'), (',', ','), ('P.', 'p.'), ('Voleti', 'voleti'), (',', ','), ('S.', 's.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bradlow', 'bradlow'), (',', ','), ('E.T.', 'e.t.'), (',', ','), ('Gangwar', 'gangwar'), (',', ','), ('M.', 'm.'), (',', ','), ('Kopalle', 'kopall'), (',', ','), ('P.', 'p.'), ('Voleti', 'voleti'), (',', ','), ('S.', 's.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Bradlow', 'Bradlow'), (',', ','), ('E.T.', 'E.T.'), (',', ','), ('Gangwar', 'Gangwar'), (',', ','), ('M.', 'M.'), (',', ','), ('Kopalle', 'Kopalle'), (',', ','), ('P.', 'P.'), ('Voleti', 'Voleti'), (',', ','), ('S.', 'S.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

The role of big data and predictive

>> Tokens are: 
 ['The', 'role', 'big', 'data', 'predictive']

>> Bigrams are: 
 [('The', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'predictive')]

>> Trigrams are: 
 [('The', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'predictive')]

>> POS Tags are: 
 [('The', 'DT'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('predictive', 'NN')]

>> Noun Phrases are: 
 ['The role', 'big data predictive']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predict')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predict')]

>> Lemmatization: 
 [('The', 'The'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predictive')]



========================================== PARAGRAPH 1417 ===========================================

analytics in retailing. Journal of Retailing, pp. 79-95. 

------------------- Sentence 1 -------------------

analytics in retailing.

>> Tokens are: 
 ['analytics', 'retailing', '.']

>> Bigrams are: 
 [('analytics', 'retailing'), ('retailing', '.')]

>> Trigrams are: 
 [('analytics', 'retailing', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('retailing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics retailing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('retailing', 'retail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('retailing', 'retail'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('retailing', 'retailing'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Retailing, pp.

>> Tokens are: 
 ['Journal', 'Retailing', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Retailing'), ('Retailing', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Retailing', ','), ('Retailing', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Retailing', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Retailing', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal Retailing')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Retailing', 'retail'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Retailing', 'retail'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Retailing', 'Retailing'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

79-95.

>> Tokens are: 
 ['79-95', '.']

>> Bigrams are: 
 [('79-95', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('79-95', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('79-95', '79-95'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('79-95', '79-95'), ('.', '.')]

>> Lemmatization: 
 [('79-95', '79-95'), ('.', '.')]



========================================== PARAGRAPH 1418 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1419 ===========================================

48  

------------------- Sentence 1 -------------------

48

>> Tokens are: 
 ['48']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('48', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('48', '48')]

>> Stemming using Snowball Stemmer: 
 [('48', '48')]

>> Lemmatization: 
 [('48', '48')]



========================================== PARAGRAPH 1420 ===========================================

  


========================================== PARAGRAPH 1421 ===========================================

Breed, D.G. and Verster, T., 2019. An empirical investigation of alternative semi-supervised  

------------------- Sentence 1 -------------------

Breed, D.G.

>> Tokens are: 
 ['Breed', ',', 'D.G', '.']

>> Bigrams are: 
 [('Breed', ','), (',', 'D.G'), ('D.G', '.')]

>> Trigrams are: 
 [('Breed', ',', 'D.G'), (',', 'D.G', '.')]

>> POS Tags are: 
 [('Breed', 'NNP'), (',', ','), ('D.G', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Breed', 'D.G']

>> Named Entities are: 
 [('GPE', 'Breed')] 

>> Stemming using Porter Stemmer: 
 [('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Lemmatization: 
 [('Breed', 'Breed'), (',', ','), ('D.G', 'D.G'), ('.', '.')]


------------------- Sentence 2 -------------------

and Verster, T., 2019.

>> Tokens are: 
 ['Verster', ',', 'T.', ',', '2019', '.']

>> Bigrams are: 
 [('Verster', ','), (',', 'T.'), ('T.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Verster', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Verster', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Verster', 'T.']

>> Named Entities are: 
 [('PERSON', 'Verster')] 

>> Stemming using Porter Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Verster', 'Verster'), (',', ','), ('T.', 'T.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 3 -------------------

An empirical investigation of alternative semi-supervised

>> Tokens are: 
 ['An', 'empirical', 'investigation', 'alternative', 'semi-supervised']

>> Bigrams are: 
 [('An', 'empirical'), ('empirical', 'investigation'), ('investigation', 'alternative'), ('alternative', 'semi-supervised')]

>> Trigrams are: 
 [('An', 'empirical', 'investigation'), ('empirical', 'investigation', 'alternative'), ('investigation', 'alternative', 'semi-supervised')]

>> POS Tags are: 
 [('An', 'DT'), ('empirical', 'JJ'), ('investigation', 'NN'), ('alternative', 'JJ'), ('semi-supervised', 'JJ')]

>> Noun Phrases are: 
 ['An empirical investigation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('empirical', 'empir'), ('investigation', 'investig'), ('alternative', 'altern'), ('semi-supervised', 'semi-supervis')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('empirical', 'empir'), ('investigation', 'investig'), ('alternative', 'altern'), ('semi-supervised', 'semi-supervis')]

>> Lemmatization: 
 [('An', 'An'), ('empirical', 'empirical'), ('investigation', 'investigation'), ('alternative', 'alternative'), ('semi-supervised', 'semi-supervised')]



========================================== PARAGRAPH 1422 ===========================================

segmentation methodologies. South African Journal of Science, Volume 115, pp. pp.92-98.  

------------------- Sentence 1 -------------------

segmentation methodologies.

>> Tokens are: 
 ['segmentation', 'methodologies', '.']

>> Bigrams are: 
 [('segmentation', 'methodologies'), ('methodologies', '.')]

>> Trigrams are: 
 [('segmentation', 'methodologies', '.')]

>> POS Tags are: 
 [('segmentation', 'NN'), ('methodologies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['segmentation methodologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('segmentation', 'segment'), ('methodologies', 'methodolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('segmentation', 'segment'), ('methodologies', 'methodolog'), ('.', '.')]

>> Lemmatization: 
 [('segmentation', 'segmentation'), ('methodologies', 'methodology'), ('.', '.')]


------------------- Sentence 2 -------------------

South African Journal of Science, Volume 115, pp.

>> Tokens are: 
 ['South', 'African', 'Journal', 'Science', ',', 'Volume', '115', ',', 'pp', '.']

>> Bigrams are: 
 [('South', 'African'), ('African', 'Journal'), ('Journal', 'Science'), ('Science', ','), (',', 'Volume'), ('Volume', '115'), ('115', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('South', 'African', 'Journal'), ('African', 'Journal', 'Science'), ('Journal', 'Science', ','), ('Science', ',', 'Volume'), (',', 'Volume', '115'), ('Volume', '115', ','), ('115', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('South', 'JJ'), ('African', 'JJ'), ('Journal', 'NNP'), ('Science', 'NNP'), (',', ','), ('Volume', 'NN'), ('115', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['South African Journal Science', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'South'), ('ORGANIZATION', 'African Journal Science'), ('ORGANIZATION', 'Volume 115')] 

>> Stemming using Porter Stemmer: 
 [('South', 'south'), ('African', 'african'), ('Journal', 'journal'), ('Science', 'scienc'), (',', ','), ('Volume', 'volum'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('South', 'south'), ('African', 'african'), ('Journal', 'journal'), ('Science', 'scienc'), (',', ','), ('Volume', 'volum'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('South', 'South'), ('African', 'African'), ('Journal', 'Journal'), ('Science', 'Science'), (',', ','), ('Volume', 'Volume'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

pp.92-98.

>> Tokens are: 
 ['pp.92-98', '.']

>> Bigrams are: 
 [('pp.92-98', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp.92-98', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp.92-98']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]

>> Lemmatization: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]



========================================== PARAGRAPH 1423 ===========================================

Bughin, J., Chui, M. and Manyika, J., 2010. Clouds, big data, and smart assets: Ten tech-enabled  

------------------- Sentence 1 -------------------

Bughin, J., Chui, M. and Manyika, J., 2010.

>> Tokens are: 
 ['Bughin', ',', 'J.', ',', 'Chui', ',', 'M.', 'Manyika', ',', 'J.', ',', '2010', '.']

>> Bigrams are: 
 [('Bughin', ','), (',', 'J.'), ('J.', ','), (',', 'Chui'), ('Chui', ','), (',', 'M.'), ('M.', 'Manyika'), ('Manyika', ','), (',', 'J.'), ('J.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Bughin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Chui'), (',', 'Chui', ','), ('Chui', ',', 'M.'), (',', 'M.', 'Manyika'), ('M.', 'Manyika', ','), ('Manyika', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Bughin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Chui', 'NNP'), (',', ','), ('M.', 'NNP'), ('Manyika', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Bughin', 'J.', 'Chui', 'M. Manyika', 'J.']

>> Named Entities are: 
 [('GPE', 'Bughin'), ('PERSON', 'Chui')] 

>> Stemming using Porter Stemmer: 
 [('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), ('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), ('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Bughin', 'Bughin'), (',', ','), ('J.', 'J.'), (',', ','), ('Chui', 'Chui'), (',', ','), ('M.', 'M.'), ('Manyika', 'Manyika'), (',', ','), ('J.', 'J.'), (',', ','), ('2010', '2010'), ('.', '.')]


------------------- Sentence 2 -------------------

Clouds, big data, and smart assets: Ten tech-enabled

>> Tokens are: 
 ['Clouds', ',', 'big', 'data', ',', 'smart', 'assets', ':', 'Ten', 'tech-enabled']

>> Bigrams are: 
 [('Clouds', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'smart'), ('smart', 'assets'), ('assets', ':'), (':', 'Ten'), ('Ten', 'tech-enabled')]

>> Trigrams are: 
 [('Clouds', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'smart'), (',', 'smart', 'assets'), ('smart', 'assets', ':'), ('assets', ':', 'Ten'), (':', 'Ten', 'tech-enabled')]

>> POS Tags are: 
 [('Clouds', 'NNP'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('smart', 'JJ'), ('assets', 'NNS'), (':', ':'), ('Ten', 'CD'), ('tech-enabled', 'JJ')]

>> Noun Phrases are: 
 ['Clouds', 'big data', 'smart assets']

>> Named Entities are: 
 [('GPE', 'Clouds')] 

>> Stemming using Porter Stemmer: 
 [('Clouds', 'cloud'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'ten'), ('tech-enabled', 'tech-en')]

>> Stemming using Snowball Stemmer: 
 [('Clouds', 'cloud'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'ten'), ('tech-enabled', 'tech-en')]

>> Lemmatization: 
 [('Clouds', 'Clouds'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'Ten'), ('tech-enabled', 'tech-enabled')]



========================================== PARAGRAPH 1424 ===========================================

business trends to watch.. McKinsey quarterly, Volume 56, pp. 75-86.  

------------------- Sentence 1 -------------------

business trends to watch.. McKinsey quarterly, Volume 56, pp.

>> Tokens are: 
 ['business', 'trends', 'watch', '..', 'McKinsey', 'quarterly', ',', 'Volume', '56', ',', 'pp', '.']

>> Bigrams are: 
 [('business', 'trends'), ('trends', 'watch'), ('watch', '..'), ('..', 'McKinsey'), ('McKinsey', 'quarterly'), ('quarterly', ','), (',', 'Volume'), ('Volume', '56'), ('56', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('business', 'trends', 'watch'), ('trends', 'watch', '..'), ('watch', '..', 'McKinsey'), ('..', 'McKinsey', 'quarterly'), ('McKinsey', 'quarterly', ','), ('quarterly', ',', 'Volume'), (',', 'Volume', '56'), ('Volume', '56', ','), ('56', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('business', 'NN'), ('trends', 'NNS'), ('watch', 'VBP'), ('..', 'NNP'), ('McKinsey', 'NNP'), ('quarterly', 'RB'), (',', ','), ('Volume', 'NN'), ('56', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['business trends', '.. McKinsey', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 56')] 

>> Stemming using Porter Stemmer: 
 [('business', 'busi'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'mckinsey'), ('quarterly', 'quarterli'), (',', ','), ('Volume', 'volum'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('business', 'busi'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'mckinsey'), ('quarterly', 'quarter'), (',', ','), ('Volume', 'volum'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('business', 'business'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'McKinsey'), ('quarterly', 'quarterly'), (',', ','), ('Volume', 'Volume'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

75-86.

>> Tokens are: 
 ['75-86', '.']

>> Bigrams are: 
 [('75-86', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('75-86', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('75-86', '75-86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('75-86', '75-86'), ('.', '.')]

>> Lemmatization: 
 [('75-86', '75-86'), ('.', '.')]



========================================== PARAGRAPH 1425 ===========================================

Casadesus-Masanell, R. and Ricart, J.E, 2010. From strategy to business models and onto tactics.  

------------------- Sentence 1 -------------------

Casadesus-Masanell, R. and Ricart, J.E, 2010.

>> Tokens are: 
 ['Casadesus-Masanell', ',', 'R.', 'Ricart', ',', 'J.E', ',', '2010', '.']

>> Bigrams are: 
 [('Casadesus-Masanell', ','), (',', 'R.'), ('R.', 'Ricart'), ('Ricart', ','), (',', 'J.E'), ('J.E', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Casadesus-Masanell', ',', 'R.'), (',', 'R.', 'Ricart'), ('R.', 'Ricart', ','), ('Ricart', ',', 'J.E'), (',', 'J.E', ','), ('J.E', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Casadesus-Masanell', 'NNP'), (',', ','), ('R.', 'NNP'), ('Ricart', 'NNP'), (',', ','), ('J.E', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Casadesus-Masanell', 'R. Ricart', 'J.E']

>> Named Entities are: 
 [('PERSON', 'Ricart')] 

>> Stemming using Porter Stemmer: 
 [('Casadesus-Masanell', 'casadesus-masanel'), (',', ','), ('R.', 'r.'), ('Ricart', 'ricart'), (',', ','), ('J.E', 'j.e'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Casadesus-Masanell', 'casadesus-masanel'), (',', ','), ('R.', 'r.'), ('Ricart', 'ricart'), (',', ','), ('J.E', 'j.e'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Casadesus-Masanell', 'Casadesus-Masanell'), (',', ','), ('R.', 'R.'), ('Ricart', 'Ricart'), (',', ','), ('J.E', 'J.E'), (',', ','), ('2010', '2010'), ('.', '.')]


------------------- Sentence 2 -------------------

From strategy to business models and onto tactics.

>> Tokens are: 
 ['From', 'strategy', 'business', 'models', 'onto', 'tactics', '.']

>> Bigrams are: 
 [('From', 'strategy'), ('strategy', 'business'), ('business', 'models'), ('models', 'onto'), ('onto', 'tactics'), ('tactics', '.')]

>> Trigrams are: 
 [('From', 'strategy', 'business'), ('strategy', 'business', 'models'), ('business', 'models', 'onto'), ('models', 'onto', 'tactics'), ('onto', 'tactics', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('strategy', 'NN'), ('business', 'NN'), ('models', 'NNS'), ('onto', 'IN'), ('tactics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['strategy business models', 'tactics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('strategy', 'strategi'), ('business', 'busi'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('strategy', 'strategi'), ('business', 'busi'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('strategy', 'strategy'), ('business', 'business'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]



========================================== PARAGRAPH 1426 ===========================================

Long range planning journal, Volume 43, pp. 195-215.  

------------------- Sentence 1 -------------------

Long range planning journal, Volume 43, pp.

>> Tokens are: 
 ['Long', 'range', 'planning', 'journal', ',', 'Volume', '43', ',', 'pp', '.']

>> Bigrams are: 
 [('Long', 'range'), ('range', 'planning'), ('planning', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '43'), ('43', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Long', 'range', 'planning'), ('range', 'planning', 'journal'), ('planning', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '43'), ('Volume', '43', ','), ('43', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Long', 'JJ'), ('range', 'NN'), ('planning', 'NN'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('43', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Long range planning journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Long'), ('ORGANIZATION', 'Volume 43')] 

>> Stemming using Porter Stemmer: 
 [('Long', 'long'), ('range', 'rang'), ('planning', 'plan'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Long', 'long'), ('range', 'rang'), ('planning', 'plan'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Long', 'Long'), ('range', 'range'), ('planning', 'planning'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

195-215.

>> Tokens are: 
 ['195-215', '.']

>> Bigrams are: 
 [('195-215', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('195-215', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('195-215', '195-215'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('195-215', '195-215'), ('.', '.')]

>> Lemmatization: 
 [('195-215', '195-215'), ('.', '.')]



========================================== PARAGRAPH 1427 ===========================================

Çelebi, Ö.F., Zeydan, E., Kurt, Ö.F., Dedeoğlu, Ö., İieri, Ö., AykutSungur, B., Akan, A. and Ergüt,  

------------------- Sentence 1 -------------------

Çelebi, Ö.F., Zeydan, E., Kurt, Ö.F., Dedeoğlu, Ö., İieri, Ö., AykutSungur, B., Akan, A. and Ergüt,

>> Tokens are: 
 ['Çelebi', ',', 'Ö.F.', ',', 'Zeydan', ',', 'E.', ',', 'Kurt', ',', 'Ö.F.', ',', 'Dedeoğlu', ',', 'Ö.', ',', 'İieri', ',', 'Ö.', ',', 'AykutSungur', ',', 'B.', ',', 'Akan', ',', 'A.', 'Ergüt', ',']

>> Bigrams are: 
 [('Çelebi', ','), (',', 'Ö.F.'), ('Ö.F.', ','), (',', 'Zeydan'), ('Zeydan', ','), (',', 'E.'), ('E.', ','), (',', 'Kurt'), ('Kurt', ','), (',', 'Ö.F.'), ('Ö.F.', ','), (',', 'Dedeoğlu'), ('Dedeoğlu', ','), (',', 'Ö.'), ('Ö.', ','), (',', 'İieri'), ('İieri', ','), (',', 'Ö.'), ('Ö.', ','), (',', 'AykutSungur'), ('AykutSungur', ','), (',', 'B.'), ('B.', ','), (',', 'Akan'), ('Akan', ','), (',', 'A.'), ('A.', 'Ergüt'), ('Ergüt', ',')]

>> Trigrams are: 
 [('Çelebi', ',', 'Ö.F.'), (',', 'Ö.F.', ','), ('Ö.F.', ',', 'Zeydan'), (',', 'Zeydan', ','), ('Zeydan', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Kurt'), (',', 'Kurt', ','), ('Kurt', ',', 'Ö.F.'), (',', 'Ö.F.', ','), ('Ö.F.', ',', 'Dedeoğlu'), (',', 'Dedeoğlu', ','), ('Dedeoğlu', ',', 'Ö.'), (',', 'Ö.', ','), ('Ö.', ',', 'İieri'), (',', 'İieri', ','), ('İieri', ',', 'Ö.'), (',', 'Ö.', ','), ('Ö.', ',', 'AykutSungur'), (',', 'AykutSungur', ','), ('AykutSungur', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Akan'), (',', 'Akan', ','), ('Akan', ',', 'A.'), (',', 'A.', 'Ergüt'), ('A.', 'Ergüt', ',')]

>> POS Tags are: 
 [('Çelebi', 'NN'), (',', ','), ('Ö.F.', 'NNP'), (',', ','), ('Zeydan', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Kurt', 'NNP'), (',', ','), ('Ö.F.', 'NNP'), (',', ','), ('Dedeoğlu', 'NNP'), (',', ','), ('Ö.', 'NNP'), (',', ','), ('İieri', 'NNP'), (',', ','), ('Ö.', 'NNP'), (',', ','), ('AykutSungur', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Akan', 'NNP'), (',', ','), ('A.', 'NNP'), ('Ergüt', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Çelebi', 'Ö.F.', 'Zeydan', 'E.', 'Kurt', 'Ö.F.', 'Dedeoğlu', 'Ö.', 'İieri', 'Ö.', 'AykutSungur', 'B.', 'Akan', 'A. Ergüt']

>> Named Entities are: 
 [('GPE', 'Çelebi'), ('GPE', 'Zeydan'), ('PERSON', 'Kurt'), ('GPE', 'Dedeoğlu'), ('PERSON', 'İieri'), ('ORGANIZATION', 'AykutSungur'), ('PERSON', 'Akan')] 

>> Stemming using Porter Stemmer: 
 [('Çelebi', 'çelebi'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Zeydan', 'zeydan'), (',', ','), ('E.', 'e.'), (',', ','), ('Kurt', 'kurt'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Dedeoğlu', 'dedeoğlu'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('İieri', 'i̇ieri'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('AykutSungur', 'aykutsungur'), (',', ','), ('B.', 'b.'), (',', ','), ('Akan', 'akan'), (',', ','), ('A.', 'a.'), ('Ergüt', 'ergüt'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Çelebi', 'çelebi'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Zeydan', 'zeydan'), (',', ','), ('E.', 'e.'), (',', ','), ('Kurt', 'kurt'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Dedeoğlu', 'dedeoğlu'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('İieri', 'i̇ieri'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('AykutSungur', 'aykutsungur'), (',', ','), ('B.', 'b.'), (',', ','), ('Akan', 'akan'), (',', ','), ('A.', 'a.'), ('Ergüt', 'ergüt'), (',', ',')]

>> Lemmatization: 
 [('Çelebi', 'Çelebi'), (',', ','), ('Ö.F.', 'Ö.F.'), (',', ','), ('Zeydan', 'Zeydan'), (',', ','), ('E.', 'E.'), (',', ','), ('Kurt', 'Kurt'), (',', ','), ('Ö.F.', 'Ö.F.'), (',', ','), ('Dedeoğlu', 'Dedeoğlu'), (',', ','), ('Ö.', 'Ö.'), (',', ','), ('İieri', 'İieri'), (',', ','), ('Ö.', 'Ö.'), (',', ','), ('AykutSungur', 'AykutSungur'), (',', ','), ('B.', 'B.'), (',', ','), ('Akan', 'Akan'), (',', ','), ('A.', 'A.'), ('Ergüt', 'Ergüt'), (',', ',')]



========================================== PARAGRAPH 1428 ===========================================

S., 2013. On use of big data for enhancing network coverage analysis. In ICT 2013 IEEE journal,  

------------------- Sentence 1 -------------------

S., 2013.

>> Tokens are: 
 ['S.', ',', '2013', '.']

>> Bigrams are: 
 [('S.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('S.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('S.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['S.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S.', 's.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('S.', 's.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('S.', 'S.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

On use of big data for enhancing network coverage analysis.

>> Tokens are: 
 ['On', 'use', 'big', 'data', 'enhancing', 'network', 'coverage', 'analysis', '.']

>> Bigrams are: 
 [('On', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'enhancing'), ('enhancing', 'network'), ('network', 'coverage'), ('coverage', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('On', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'enhancing'), ('data', 'enhancing', 'network'), ('enhancing', 'network', 'coverage'), ('network', 'coverage', 'analysis'), ('coverage', 'analysis', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('enhancing', 'VBG'), ('network', 'NN'), ('coverage', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['use', 'big data', 'network coverage analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhanc'), ('network', 'network'), ('coverage', 'coverag'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhanc'), ('network', 'network'), ('coverage', 'coverag'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhancing'), ('network', 'network'), ('coverage', 'coverage'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 3 -------------------

In ICT 2013 IEEE journal,

>> Tokens are: 
 ['In', 'ICT', '2013', 'IEEE', 'journal', ',']

>> Bigrams are: 
 [('In', 'ICT'), ('ICT', '2013'), ('2013', 'IEEE'), ('IEEE', 'journal'), ('journal', ',')]

>> Trigrams are: 
 [('In', 'ICT', '2013'), ('ICT', '2013', 'IEEE'), ('2013', 'IEEE', 'journal'), ('IEEE', 'journal', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('ICT', 'NNP'), ('2013', 'CD'), ('IEEE', 'NNP'), ('journal', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['ICT', 'IEEE journal']

>> Named Entities are: 
 [('ORGANIZATION', 'ICT'), ('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('ICT', 'ict'), ('2013', '2013'), ('IEEE', 'ieee'), ('journal', 'journal'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('ICT', 'ict'), ('2013', '2013'), ('IEEE', 'ieee'), ('journal', 'journal'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('ICT', 'ICT'), ('2013', '2013'), ('IEEE', 'IEEE'), ('journal', 'journal'), (',', ',')]



========================================== PARAGRAPH 1429 ===========================================

pp. 1-5.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1-5.

>> Tokens are: 
 ['1-5', '.']

>> Bigrams are: 
 [('1-5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1-5', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-5', '1-5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-5', '1-5'), ('.', '.')]

>> Lemmatization: 
 [('1-5', '1-5'), ('.', '.')]



========================================== PARAGRAPH 1430 ===========================================

Challita, S., Zalila, F., Gourdin, C. and Merle, P., 2018 . A Precise Model for Google Cloud  

------------------- Sentence 1 -------------------

Challita, S., Zalila, F., Gourdin, C. and Merle, P., 2018 .

>> Tokens are: 
 ['Challita', ',', 'S.', ',', 'Zalila', ',', 'F.', ',', 'Gourdin', ',', 'C.', 'Merle', ',', 'P.', ',', '2018', '.']

>> Bigrams are: 
 [('Challita', ','), (',', 'S.'), ('S.', ','), (',', 'Zalila'), ('Zalila', ','), (',', 'F.'), ('F.', ','), (',', 'Gourdin'), ('Gourdin', ','), (',', 'C.'), ('C.', 'Merle'), ('Merle', ','), (',', 'P.'), ('P.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Challita', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zalila'), (',', 'Zalila', ','), ('Zalila', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Gourdin'), (',', 'Gourdin', ','), ('Gourdin', ',', 'C.'), (',', 'C.', 'Merle'), ('C.', 'Merle', ','), ('Merle', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Challita', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zalila', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Gourdin', 'NNP'), (',', ','), ('C.', 'NNP'), ('Merle', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Challita', 'S.', 'Zalila', 'F.', 'Gourdin', 'C. Merle', 'P.']

>> Named Entities are: 
 [('GPE', 'Challita'), ('PERSON', 'Zalila'), ('PERSON', 'Gourdin')] 

>> Stemming using Porter Stemmer: 
 [('Challita', 'challita'), (',', ','), ('S.', 's.'), (',', ','), ('Zalila', 'zalila'), (',', ','), ('F.', 'f.'), (',', ','), ('Gourdin', 'gourdin'), (',', ','), ('C.', 'c.'), ('Merle', 'merl'), (',', ','), ('P.', 'p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challita', 'challita'), (',', ','), ('S.', 's.'), (',', ','), ('Zalila', 'zalila'), (',', ','), ('F.', 'f.'), (',', ','), ('Gourdin', 'gourdin'), (',', ','), ('C.', 'c.'), ('Merle', 'merl'), (',', ','), ('P.', 'p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Challita', 'Challita'), (',', ','), ('S.', 'S.'), (',', ','), ('Zalila', 'Zalila'), (',', ','), ('F.', 'F.'), (',', ','), ('Gourdin', 'Gourdin'), (',', ','), ('C.', 'C.'), ('Merle', 'Merle'), (',', ','), ('P.', 'P.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

A Precise Model for Google Cloud

>> Tokens are: 
 ['A', 'Precise', 'Model', 'Google', 'Cloud']

>> Bigrams are: 
 [('A', 'Precise'), ('Precise', 'Model'), ('Model', 'Google'), ('Google', 'Cloud')]

>> Trigrams are: 
 [('A', 'Precise', 'Model'), ('Precise', 'Model', 'Google'), ('Model', 'Google', 'Cloud')]

>> POS Tags are: 
 [('A', 'DT'), ('Precise', 'NNP'), ('Model', 'NNP'), ('Google', 'NNP'), ('Cloud', 'NNP')]

>> Noun Phrases are: 
 ['A Precise Model Google Cloud']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Precise', 'precis'), ('Model', 'model'), ('Google', 'googl'), ('Cloud', 'cloud')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Precise', 'precis'), ('Model', 'model'), ('Google', 'googl'), ('Cloud', 'cloud')]

>> Lemmatization: 
 [('A', 'A'), ('Precise', 'Precise'), ('Model', 'Model'), ('Google', 'Google'), ('Cloud', 'Cloud')]



========================================== PARAGRAPH 1431 ===========================================

Platform.. s.l., IEEE, pp. 177-183.  

------------------- Sentence 1 -------------------

Platform..

>> Tokens are: 
 ['Platform', '..']

>> Bigrams are: 
 [('Platform', '..')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Platform', 'NNP'), ('..', 'NN')]

>> Noun Phrases are: 
 ['Platform ..']

>> Named Entities are: 
 [('GPE', 'Platform')] 

>> Stemming using Porter Stemmer: 
 [('Platform', 'platform'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Platform', 'platform'), ('..', '..')]

>> Lemmatization: 
 [('Platform', 'Platform'), ('..', '..')]


------------------- Sentence 2 -------------------

s.l., IEEE, pp.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

177-183.

>> Tokens are: 
 ['177-183', '.']

>> Bigrams are: 
 [('177-183', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('177-183', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('177-183', '177-183'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('177-183', '177-183'), ('.', '.')]

>> Lemmatization: 
 [('177-183', '177-183'), ('.', '.')]



========================================== PARAGRAPH 1432 ===========================================

Chen G, Guo X., 2016. Big data commerce. Inf Manag. Journal.  

------------------- Sentence 1 -------------------

Chen G, Guo X., 2016.

>> Tokens are: 
 ['Chen', 'G', ',', 'Guo', 'X.', ',', '2016', '.']

>> Bigrams are: 
 [('Chen', 'G'), ('G', ','), (',', 'Guo'), ('Guo', 'X.'), ('X.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Chen', 'G', ','), ('G', ',', 'Guo'), (',', 'Guo', 'X.'), ('Guo', 'X.', ','), ('X.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('G', 'NNP'), (',', ','), ('Guo', 'NNP'), ('X.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen G', 'Guo X.']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('ORGANIZATION', 'G'), ('PERSON', 'Guo X.')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('G', 'g'), (',', ','), ('Guo', 'guo'), ('X.', 'x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('G', 'g'), (',', ','), ('Guo', 'guo'), ('X.', 'x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('G', 'G'), (',', ','), ('Guo', 'Guo'), ('X.', 'X.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data commerce.

>> Tokens are: 
 ['Big', 'data', 'commerce', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'commerce'), ('commerce', '.')]

>> Trigrams are: 
 [('Big', 'data', 'commerce'), ('data', 'commerce', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('commerce', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data commerce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('commerce', 'commerc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('commerce', 'commerc'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('commerce', 'commerce'), ('.', '.')]


------------------- Sentence 3 -------------------

Inf Manag.

>> Tokens are: 
 ['Inf', 'Manag', '.']

>> Bigrams are: 
 [('Inf', 'Manag'), ('Manag', '.')]

>> Trigrams are: 
 [('Inf', 'Manag', '.')]

>> POS Tags are: 
 [('Inf', 'NNP'), ('Manag', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Inf Manag']

>> Named Entities are: 
 [('PERSON', 'Inf'), ('ORGANIZATION', 'Manag')] 

>> Stemming using Porter Stemmer: 
 [('Inf', 'inf'), ('Manag', 'manag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inf', 'inf'), ('Manag', 'manag'), ('.', '.')]

>> Lemmatization: 
 [('Inf', 'Inf'), ('Manag', 'Manag'), ('.', '.')]


------------------- Sentence 4 -------------------

Journal.

>> Tokens are: 
 ['Journal', '.']

>> Bigrams are: 
 [('Journal', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Journal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal']

>> Named Entities are: 
 [('GPE', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('.', '.')]



========================================== PARAGRAPH 1433 ===========================================

Chen, C.P and Zhang, Chun-Yang, 2014. Data-intensive applications, challenges, techniques and  

------------------- Sentence 1 -------------------

Chen, C.P and Zhang, Chun-Yang, 2014.

>> Tokens are: 
 ['Chen', ',', 'C.P', 'Zhang', ',', 'Chun-Yang', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'C.P'), ('C.P', 'Zhang'), ('Zhang', ','), (',', 'Chun-Yang'), ('Chun-Yang', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'C.P'), (',', 'C.P', 'Zhang'), ('C.P', 'Zhang', ','), ('Zhang', ',', 'Chun-Yang'), (',', 'Chun-Yang', ','), ('Chun-Yang', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('C.P', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('Chun-Yang', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'C.P Zhang', 'Chun-Yang']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Zhang'), ('PERSON', 'Chun-Yang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('C.P', 'c.p'), ('Zhang', 'zhang'), (',', ','), ('Chun-Yang', 'chun-yang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('C.P', 'c.p'), ('Zhang', 'zhang'), (',', ','), ('Chun-Yang', 'chun-yang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('C.P', 'C.P'), ('Zhang', 'Zhang'), (',', ','), ('Chun-Yang', 'Chun-Yang'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Data-intensive applications, challenges, techniques and

>> Tokens are: 
 ['Data-intensive', 'applications', ',', 'challenges', ',', 'techniques']

>> Bigrams are: 
 [('Data-intensive', 'applications'), ('applications', ','), (',', 'challenges'), ('challenges', ','), (',', 'techniques')]

>> Trigrams are: 
 [('Data-intensive', 'applications', ','), ('applications', ',', 'challenges'), (',', 'challenges', ','), ('challenges', ',', 'techniques')]

>> POS Tags are: 
 [('Data-intensive', 'JJ'), ('applications', 'NNS'), (',', ','), ('challenges', 'NNS'), (',', ','), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Data-intensive applications', 'challenges', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data-intensive', 'data-intens'), ('applications', 'applic'), (',', ','), ('challenges', 'challeng'), (',', ','), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Data-intensive', 'data-intens'), ('applications', 'applic'), (',', ','), ('challenges', 'challeng'), (',', ','), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Data-intensive', 'Data-intensive'), ('applications', 'application'), (',', ','), ('challenges', 'challenge'), (',', ','), ('techniques', 'technique')]



========================================== PARAGRAPH 1434 ===========================================

technologies: A survey on Big Data. Information sciences Journal, Volume 275, p. 314–347.  

------------------- Sentence 1 -------------------

technologies: A survey on Big Data.

>> Tokens are: 
 ['technologies', ':', 'A', 'survey', 'Big', 'Data', '.']

>> Bigrams are: 
 [('technologies', ':'), (':', 'A'), ('A', 'survey'), ('survey', 'Big'), ('Big', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('technologies', ':', 'A'), (':', 'A', 'survey'), ('A', 'survey', 'Big'), ('survey', 'Big', 'Data'), ('Big', 'Data', '.')]

>> POS Tags are: 
 [('technologies', 'NNS'), (':', ':'), ('A', 'DT'), ('survey', 'NN'), ('Big', 'NNP'), ('Data', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['technologies', 'A survey Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('technologies', 'technology'), (':', ':'), ('A', 'A'), ('survey', 'survey'), ('Big', 'Big'), ('Data', 'Data'), ('.', '.')]


------------------- Sentence 2 -------------------

Information sciences Journal, Volume 275, p. 314–347.

>> Tokens are: 
 ['Information', 'sciences', 'Journal', ',', 'Volume', '275', ',', 'p.', '314–347', '.']

>> Bigrams are: 
 [('Information', 'sciences'), ('sciences', 'Journal'), ('Journal', ','), (',', 'Volume'), ('Volume', '275'), ('275', ','), (',', 'p.'), ('p.', '314–347'), ('314–347', '.')]

>> Trigrams are: 
 [('Information', 'sciences', 'Journal'), ('sciences', 'Journal', ','), ('Journal', ',', 'Volume'), (',', 'Volume', '275'), ('Volume', '275', ','), ('275', ',', 'p.'), (',', 'p.', '314–347'), ('p.', '314–347', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('sciences', 'NNS'), ('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('275', 'CD'), (',', ','), ('p.', 'RB'), ('314–347', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Information sciences Journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Information'), ('ORGANIZATION', 'Volume 275')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('sciences', 'scienc'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('sciences', 'scienc'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('sciences', 'science'), ('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]



========================================== PARAGRAPH 1435 ===========================================

Chen, H., Chiang, R.H. and Storey, V.C., 2012. Business intelligence and analytics: from big data  

------------------- Sentence 1 -------------------

Chen, H., Chiang, R.H. and Storey, V.C., 2012. Business intelligence and analytics: from big data

>> Tokens are: 
 ['Chen', ',', 'H.', ',', 'Chiang', ',', 'R.H.', 'Storey', ',', 'V.C.', ',', '2012.', 'Business', 'intelligence', 'analytics', ':', 'big', 'data']

>> Bigrams are: 
 [('Chen', ','), (',', 'H.'), ('H.', ','), (',', 'Chiang'), ('Chiang', ','), (',', 'R.H.'), ('R.H.', 'Storey'), ('Storey', ','), (',', 'V.C.'), ('V.C.', ','), (',', '2012.'), ('2012.', 'Business'), ('Business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', ':'), (':', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Chen', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Chiang'), (',', 'Chiang', ','), ('Chiang', ',', 'R.H.'), (',', 'R.H.', 'Storey'), ('R.H.', 'Storey', ','), ('Storey', ',', 'V.C.'), (',', 'V.C.', ','), ('V.C.', ',', '2012.'), (',', '2012.', 'Business'), ('2012.', 'Business', 'intelligence'), ('Business', 'intelligence', 'analytics'), ('intelligence', 'analytics', ':'), ('analytics', ':', 'big'), (':', 'big', 'data')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Chiang', 'NNP'), (',', ','), ('R.H.', 'NNP'), ('Storey', 'NNP'), (',', ','), ('V.C.', 'NNP'), (',', ','), ('2012.', 'CD'), ('Business', 'NNP'), ('intelligence', 'NN'), ('analytics', 'NNS'), (':', ':'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Chen', 'H.', 'Chiang', 'R.H. Storey', 'V.C.', 'Business intelligence analytics', 'big data']

>> Named Entities are: 
 [('GPE', 'Chen'), ('GPE', 'Chiang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('H.', 'h.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), ('Storey', 'storey'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2012.', '2012.'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('H.', 'h.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), ('Storey', 'storey'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2012.', '2012.'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('H.', 'H.'), (',', ','), ('Chiang', 'Chiang'), (',', ','), ('R.H.', 'R.H.'), ('Storey', 'Storey'), (',', ','), ('V.C.', 'V.C.'), (',', ','), ('2012.', '2012.'), ('Business', 'Business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), (':', ':'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1436 ===========================================

to big impact.. MIS quarterly, pp. 1165-1188.  

------------------- Sentence 1 -------------------

to big impact.. MIS quarterly, pp.

>> Tokens are: 
 ['big', 'impact', '..', 'MIS', 'quarterly', ',', 'pp', '.']

>> Bigrams are: 
 [('big', 'impact'), ('impact', '..'), ('..', 'MIS'), ('MIS', 'quarterly'), ('quarterly', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('big', 'impact', '..'), ('impact', '..', 'MIS'), ('..', 'MIS', 'quarterly'), ('MIS', 'quarterly', ','), ('quarterly', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('impact', 'NN'), ('..', 'NNP'), ('MIS', 'NNP'), ('quarterly', 'RB'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big impact .. MIS', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'mi'), ('quarterly', 'quarterli'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'mis'), ('quarterly', 'quarter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'MIS'), ('quarterly', 'quarterly'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1165-1188.

>> Tokens are: 
 ['1165-1188', '.']

>> Bigrams are: 
 [('1165-1188', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1165-1188', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1165-1188', '1165-1188'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1165-1188', '1165-1188'), ('.', '.')]

>> Lemmatization: 
 [('1165-1188', '1165-1188'), ('.', '.')]



========================================== PARAGRAPH 1437 ===========================================

Chen, M., Mao, S. and Liu, Y., 2014. Big data: A survey.. Journal of mobile networks and  

------------------- Sentence 1 -------------------

Chen, M., Mao, S. and Liu, Y., 2014.

>> Tokens are: 
 ['Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: A survey.. Journal of mobile networks and

>> Tokens are: 
 ['Big', 'data', ':', 'A', 'survey', '..', 'Journal', 'mobile', 'networks']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'A'), ('A', 'survey'), ('survey', '..'), ('..', 'Journal'), ('Journal', 'mobile'), ('mobile', 'networks')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'A'), (':', 'A', 'survey'), ('A', 'survey', '..'), ('survey', '..', 'Journal'), ('..', 'Journal', 'mobile'), ('Journal', 'mobile', 'networks')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT'), ('survey', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('mobile', 'NN'), ('networks', 'NNS')]

>> Noun Phrases are: 
 ['Big data', 'A survey .. Journal mobile networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('mobile', 'mobil'), ('networks', 'network')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('mobile', 'mobil'), ('networks', 'network')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('A', 'A'), ('survey', 'survey'), ('..', '..'), ('Journal', 'Journal'), ('mobile', 'mobile'), ('networks', 'network')]



========================================== PARAGRAPH 1438 ===========================================

applications, Volume 19, pp. 171-209.  

------------------- Sentence 1 -------------------

applications, Volume 19, pp.

>> Tokens are: 
 ['applications', ',', 'Volume', '19', ',', 'pp', '.']

>> Bigrams are: 
 [('applications', ','), (',', 'Volume'), ('Volume', '19'), ('19', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('applications', ',', 'Volume'), (',', 'Volume', '19'), ('Volume', '19', ','), ('19', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), (',', ','), ('Volume', 'NN'), ('19', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['applications', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 19')] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), (',', ','), ('Volume', 'volum'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), (',', ','), ('Volume', 'volum'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), (',', ','), ('Volume', 'Volume'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

171-209.

>> Tokens are: 
 ['171-209', '.']

>> Bigrams are: 
 [('171-209', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('171-209', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('171-209', '171-209'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('171-209', '171-209'), ('.', '.')]

>> Lemmatization: 
 [('171-209', '171-209'), ('.', '.')]



========================================== PARAGRAPH 1439 ===========================================

Chen, M., Mao, S., Zhang, Y. and Leung, V.C., 2014. Big data: related technologies, challenges  

------------------- Sentence 1 -------------------

Chen, M., Mao, S., Zhang, Y. and Leung, V.C., 2014.

>> Tokens are: 
 ['Chen', ',', 'M.', ',', 'Mao', ',', 'S.', ',', 'Zhang', ',', 'Y.', 'Leung', ',', 'V.C.', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', 'Leung'), ('Leung', ','), (',', 'V.C.'), ('V.C.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', 'Leung'), ('Y.', 'Leung', ','), ('Leung', ',', 'V.C.'), (',', 'V.C.', ','), ('V.C.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Leung', 'NNP'), (',', ','), ('V.C.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen', 'M.', 'Mao', 'S.', 'Zhang', 'Y. Leung', 'V.C.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Leung', 'leung'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Leung', 'leung'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), ('Leung', 'Leung'), (',', ','), ('V.C.', 'V.C.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: related technologies, challenges

>> Tokens are: 
 ['Big', 'data', ':', 'related', 'technologies', ',', 'challenges']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'related'), ('related', 'technologies'), ('technologies', ','), (',', 'challenges')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'related'), (':', 'related', 'technologies'), ('related', 'technologies', ','), ('technologies', ',', 'challenges')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('related', 'JJ'), ('technologies', 'NNS'), (',', ','), ('challenges', 'NNS')]

>> Noun Phrases are: 
 ['Big data', 'related technologies', 'challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('related', 'relat'), ('technologies', 'technolog'), (',', ','), ('challenges', 'challeng')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('related', 'relat'), ('technologies', 'technolog'), (',', ','), ('challenges', 'challeng')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('related', 'related'), ('technologies', 'technology'), (',', ','), ('challenges', 'challenge')]



========================================== PARAGRAPH 1440 ===========================================

and future prospects. s.l.:Springer.  

------------------- Sentence 1 -------------------

and future prospects.

>> Tokens are: 
 ['future', 'prospects', '.']

>> Bigrams are: 
 [('future', 'prospects'), ('prospects', '.')]

>> Trigrams are: 
 [('future', 'prospects', '.')]

>> POS Tags are: 
 [('future', 'JJ'), ('prospects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['future prospects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('future', 'futur'), ('prospects', 'prospect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('future', 'futur'), ('prospects', 'prospect'), ('.', '.')]

>> Lemmatization: 
 [('future', 'future'), ('prospects', 'prospect'), ('.', '.')]


------------------- Sentence 2 -------------------

s.l.

>> Tokens are: 
 ['s.l', '.']

>> Bigrams are: 
 [('s.l', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('s.l', 's.l'), ('.', '.')]


------------------- Sentence 3 -------------------

:Springer.

>> Tokens are: 
 [':', 'Springer', '.']

>> Bigrams are: 
 [(':', 'Springer'), ('Springer', '.')]

>> Trigrams are: 
 [(':', 'Springer', '.')]

>> POS Tags are: 
 [(':', ':'), ('Springer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Springer', 'springer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Springer', 'springer'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Springer', 'Springer'), ('.', '.')]



========================================== PARAGRAPH 1441 ===========================================

Cheon, J. and Choe, T.Y., 2013. Distributed processing of snort alert log using hadoop..  

------------------- Sentence 1 -------------------

Cheon, J. and Choe, T.Y., 2013.

>> Tokens are: 
 ['Cheon', ',', 'J.', 'Choe', ',', 'T.Y.', ',', '2013', '.']

>> Bigrams are: 
 [('Cheon', ','), (',', 'J.'), ('J.', 'Choe'), ('Choe', ','), (',', 'T.Y.'), ('T.Y.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Cheon', ',', 'J.'), (',', 'J.', 'Choe'), ('J.', 'Choe', ','), ('Choe', ',', 'T.Y.'), (',', 'T.Y.', ','), ('T.Y.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Cheon', 'NNP'), (',', ','), ('J.', 'NNP'), ('Choe', 'NNP'), (',', ','), ('T.Y.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Cheon', 'J. Choe', 'T.Y.']

>> Named Entities are: 
 [('GPE', 'Cheon'), ('PERSON', 'J. Choe')] 

>> Stemming using Porter Stemmer: 
 [('Cheon', 'cheon'), (',', ','), ('J.', 'j.'), ('Choe', 'choe'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheon', 'cheon'), (',', ','), ('J.', 'j.'), ('Choe', 'choe'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Cheon', 'Cheon'), (',', ','), ('J.', 'J.'), ('Choe', 'Choe'), (',', ','), ('T.Y.', 'T.Y.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Distributed processing of snort alert log using hadoop..

>> Tokens are: 
 ['Distributed', 'processing', 'snort', 'alert', 'log', 'using', 'hadoop', '..']

>> Bigrams are: 
 [('Distributed', 'processing'), ('processing', 'snort'), ('snort', 'alert'), ('alert', 'log'), ('log', 'using'), ('using', 'hadoop'), ('hadoop', '..')]

>> Trigrams are: 
 [('Distributed', 'processing', 'snort'), ('processing', 'snort', 'alert'), ('snort', 'alert', 'log'), ('alert', 'log', 'using'), ('log', 'using', 'hadoop'), ('using', 'hadoop', '..')]

>> POS Tags are: 
 [('Distributed', 'VBN'), ('processing', 'VBG'), ('snort', 'NN'), ('alert', 'NN'), ('log', 'NN'), ('using', 'VBG'), ('hadoop', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['snort alert log', 'hadoop ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Distributed', 'distribut'), ('processing', 'process'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'use'), ('hadoop', 'hadoop'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Distributed', 'distribut'), ('processing', 'process'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'use'), ('hadoop', 'hadoop'), ('..', '..')]

>> Lemmatization: 
 [('Distributed', 'Distributed'), ('processing', 'processing'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'using'), ('hadoop', 'hadoop'), ('..', '..')]



========================================== PARAGRAPH 1442 ===========================================

International Journal of Engineering and Technology IJET, Volume 5, pp. 2685-2690.  

------------------- Sentence 1 -------------------

International Journal of Engineering and Technology IJET, Volume 5, pp.

>> Tokens are: 
 ['International', 'Journal', 'Engineering', 'Technology', 'IJET', ',', 'Volume', '5', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Engineering'), ('Engineering', 'Technology'), ('Technology', 'IJET'), ('IJET', ','), (',', 'Volume'), ('Volume', '5'), ('5', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Engineering'), ('Journal', 'Engineering', 'Technology'), ('Engineering', 'Technology', 'IJET'), ('Technology', 'IJET', ','), ('IJET', ',', 'Volume'), (',', 'Volume', '5'), ('Volume', '5', ','), ('5', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Engineering', 'NNP'), ('Technology', 'NNP'), ('IJET', 'NNP'), (',', ','), ('Volume', 'NN'), ('5', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['International Journal Engineering Technology IJET', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal'), ('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Engineering', 'engin'), ('Technology', 'technolog'), ('IJET', 'ijet'), (',', ','), ('Volume', 'volum'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Engineering', 'engin'), ('Technology', 'technolog'), ('IJET', 'ijet'), (',', ','), ('Volume', 'volum'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Engineering', 'Engineering'), ('Technology', 'Technology'), ('IJET', 'IJET'), (',', ','), ('Volume', 'Volume'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

2685-2690.

>> Tokens are: 
 ['2685-2690', '.']

>> Bigrams are: 
 [('2685-2690', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2685-2690', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2685-2690', '2685-2690'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2685-2690', '2685-2690'), ('.', '.')]

>> Lemmatization: 
 [('2685-2690', '2685-2690'), ('.', '.')]



========================================== PARAGRAPH 1443 ===========================================

Clarke, R., 2016. Big data, big risks. Information Systems Journal, Volume 26, pp. 77-90.  

------------------- Sentence 1 -------------------

Clarke, R., 2016.

>> Tokens are: 
 ['Clarke', ',', 'R.', ',', '2016', '.']

>> Bigrams are: 
 [('Clarke', ','), (',', 'R.'), ('R.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Clarke', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Clarke', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Clarke', 'R.']

>> Named Entities are: 
 [('GPE', 'Clarke')] 

>> Stemming using Porter Stemmer: 
 [('Clarke', 'clark'), (',', ','), ('R.', 'r.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clarke', 'clark'), (',', ','), ('R.', 'r.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Clarke', 'Clarke'), (',', ','), ('R.', 'R.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data, big risks.

>> Tokens are: 
 ['Big', 'data', ',', 'big', 'risks', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'big'), ('big', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'risks'), ('big', 'risks', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('risks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'big risks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]


------------------- Sentence 3 -------------------

Information Systems Journal, Volume 26, pp.

>> Tokens are: 
 ['Information', 'Systems', 'Journal', ',', 'Volume', '26', ',', 'pp', '.']

>> Bigrams are: 
 [('Information', 'Systems'), ('Systems', 'Journal'), ('Journal', ','), (',', 'Volume'), ('Volume', '26'), ('26', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Information', 'Systems', 'Journal'), ('Systems', 'Journal', ','), ('Journal', ',', 'Volume'), (',', 'Volume', '26'), ('Volume', '26', ','), ('26', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Systems', 'NNP'), ('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('26', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Systems Journal', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Systems Journal'), ('ORGANIZATION', 'Volume 26')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Systems', 'Systems'), ('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

77-90.

>> Tokens are: 
 ['77-90', '.']

>> Bigrams are: 
 [('77-90', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77-90', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77-90', '77-90'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77-90', '77-90'), ('.', '.')]

>> Lemmatization: 
 [('77-90', '77-90'), ('.', '.')]



========================================== PARAGRAPH 1444 ===========================================

Constantiou, I.D. and Kallinikos, J., 2015. New games, new rules: big data and the changing  

------------------- Sentence 1 -------------------

Constantiou, I.D.

>> Tokens are: 
 ['Constantiou', ',', 'I.D', '.']

>> Bigrams are: 
 [('Constantiou', ','), (',', 'I.D'), ('I.D', '.')]

>> Trigrams are: 
 [('Constantiou', ',', 'I.D'), (',', 'I.D', '.')]

>> POS Tags are: 
 [('Constantiou', 'NNP'), (',', ','), ('I.D', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Constantiou', 'I.D']

>> Named Entities are: 
 [('GSP', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('Constantiou', 'constanti'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Constantiou', 'constantiou'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Lemmatization: 
 [('Constantiou', 'Constantiou'), (',', ','), ('I.D', 'I.D'), ('.', '.')]


------------------- Sentence 2 -------------------

and Kallinikos, J., 2015.

>> Tokens are: 
 ['Kallinikos', ',', 'J.', ',', '2015', '.']

>> Bigrams are: 
 [('Kallinikos', ','), (',', 'J.'), ('J.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Kallinikos', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Kallinikos', 'J.']

>> Named Entities are: 
 [('GPE', 'Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('J.', 'J.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 3 -------------------

New games, new rules: big data and the changing

>> Tokens are: 
 ['New', 'games', ',', 'new', 'rules', ':', 'big', 'data', 'changing']

>> Bigrams are: 
 [('New', 'games'), ('games', ','), (',', 'new'), ('new', 'rules'), ('rules', ':'), (':', 'big'), ('big', 'data'), ('data', 'changing')]

>> Trigrams are: 
 [('New', 'games', ','), ('games', ',', 'new'), (',', 'new', 'rules'), ('new', 'rules', ':'), ('rules', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'changing')]

>> POS Tags are: 
 [('New', 'NNP'), ('games', 'NNS'), (',', ','), ('new', 'JJ'), ('rules', 'NNS'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('changing', 'VBG')]

>> Noun Phrases are: 
 ['New games', 'new rules', 'big data']

>> Named Entities are: 
 [('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'chang')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'chang')]

>> Lemmatization: 
 [('New', 'New'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'changing')]



========================================== PARAGRAPH 1445 ===========================================

context of strategy. Journal of Information Technology, Volume 30, pp. 44-57.  

------------------- Sentence 1 -------------------

context of strategy.

>> Tokens are: 
 ['context', 'strategy', '.']

>> Bigrams are: 
 [('context', 'strategy'), ('strategy', '.')]

>> Trigrams are: 
 [('context', 'strategy', '.')]

>> POS Tags are: 
 [('context', 'NN'), ('strategy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['context strategy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('context', 'context'), ('strategy', 'strategi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('context', 'context'), ('strategy', 'strategi'), ('.', '.')]

>> Lemmatization: 
 [('context', 'context'), ('strategy', 'strategy'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Information Technology, Volume 30, pp.

>> Tokens are: 
 ['Journal', 'Information', 'Technology', ',', 'Volume', '30', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '30'), ('30', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '30'), ('Volume', '30', ','), ('30', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('30', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Information Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Information Technology'), ('ORGANIZATION', 'Volume 30')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

44-57.

>> Tokens are: 
 ['44-57', '.']

>> Bigrams are: 
 [('44-57', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('44-57', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('44-57', '44-57'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('44-57', '44-57'), ('.', '.')]

>> Lemmatization: 
 [('44-57', '44-57'), ('.', '.')]



========================================== PARAGRAPH 1446 ===========================================

Cronin, P., Ryan, F. and Coughlan, M., 2008. Undertaking a literature review: a step-by-step  

------------------- Sentence 1 -------------------

Cronin, P., Ryan, F. and Coughlan, M., 2008.

>> Tokens are: 
 ['Cronin', ',', 'P.', ',', 'Ryan', ',', 'F.', 'Coughlan', ',', 'M.', ',', '2008', '.']

>> Bigrams are: 
 [('Cronin', ','), (',', 'P.'), ('P.', ','), (',', 'Ryan'), ('Ryan', ','), (',', 'F.'), ('F.', 'Coughlan'), ('Coughlan', ','), (',', 'M.'), ('M.', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('Cronin', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Ryan'), (',', 'Ryan', ','), ('Ryan', ',', 'F.'), (',', 'F.', 'Coughlan'), ('F.', 'Coughlan', ','), ('Coughlan', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('Cronin', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Ryan', 'NNP'), (',', ','), ('F.', 'NNP'), ('Coughlan', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2008', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Cronin', 'P.', 'Ryan', 'F. Coughlan', 'M.']

>> Named Entities are: 
 [('GPE', 'Cronin'), ('PERSON', 'Ryan')] 

>> Stemming using Porter Stemmer: 
 [('Cronin', 'cronin'), (',', ','), ('P.', 'p.'), (',', ','), ('Ryan', 'ryan'), (',', ','), ('F.', 'f.'), ('Coughlan', 'coughlan'), (',', ','), ('M.', 'm.'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cronin', 'cronin'), (',', ','), ('P.', 'p.'), (',', ','), ('Ryan', 'ryan'), (',', ','), ('F.', 'f.'), ('Coughlan', 'coughlan'), (',', ','), ('M.', 'm.'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('Cronin', 'Cronin'), (',', ','), ('P.', 'P.'), (',', ','), ('Ryan', 'Ryan'), (',', ','), ('F.', 'F.'), ('Coughlan', 'Coughlan'), (',', ','), ('M.', 'M.'), (',', ','), ('2008', '2008'), ('.', '.')]


------------------- Sentence 2 -------------------

Undertaking a literature review: a step-by-step

>> Tokens are: 
 ['Undertaking', 'literature', 'review', ':', 'step-by-step']

>> Bigrams are: 
 [('Undertaking', 'literature'), ('literature', 'review'), ('review', ':'), (':', 'step-by-step')]

>> Trigrams are: 
 [('Undertaking', 'literature', 'review'), ('literature', 'review', ':'), ('review', ':', 'step-by-step')]

>> POS Tags are: 
 [('Undertaking', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (':', ':'), ('step-by-step', 'NN')]

>> Noun Phrases are: 
 ['literature review', 'step-by-step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Undertaking', 'undertak'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step')]

>> Stemming using Snowball Stemmer: 
 [('Undertaking', 'undertak'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step')]

>> Lemmatization: 
 [('Undertaking', 'Undertaking'), ('literature', 'literature'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step')]



========================================== PARAGRAPH 1447 ===========================================

approach.. British journal of nursing, pp. 38-43.  

------------------- Sentence 1 -------------------

approach.. British journal of nursing, pp.

>> Tokens are: 
 ['approach', '..', 'British', 'journal', 'nursing', ',', 'pp', '.']

>> Bigrams are: 
 [('approach', '..'), ('..', 'British'), ('British', 'journal'), ('journal', 'nursing'), ('nursing', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('approach', '..', 'British'), ('..', 'British', 'journal'), ('British', 'journal', 'nursing'), ('journal', 'nursing', ','), ('nursing', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('approach', 'NN'), ('..', 'CD'), ('British', 'JJ'), ('journal', 'NN'), ('nursing', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach', 'British journal nursing', 'pp']

>> Named Entities are: 
 [('GPE', 'British')] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('..', '..'), ('British', 'british'), ('journal', 'journal'), ('nursing', 'nurs'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('..', '..'), ('British', 'british'), ('journal', 'journal'), ('nursing', 'nurs'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('..', '..'), ('British', 'British'), ('journal', 'journal'), ('nursing', 'nursing'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

38-43.

>> Tokens are: 
 ['38-43', '.']

>> Bigrams are: 
 [('38-43', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('38-43', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38-43', '38-43'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38-43', '38-43'), ('.', '.')]

>> Lemmatization: 
 [('38-43', '38-43'), ('.', '.')]



========================================== PARAGRAPH 1448 ===========================================

Cui, Q., Gong, Z., Ni, W., Hou, Y., Chen, X., Tao, X. and Zhang, P., 2019. Stochastic Online  

------------------- Sentence 1 -------------------

Cui, Q., Gong, Z., Ni, W., Hou, Y., Chen, X., Tao, X. and Zhang, P., 2019.

>> Tokens are: 
 ['Cui', ',', 'Q.', ',', 'Gong', ',', 'Z.', ',', 'Ni', ',', 'W.', ',', 'Hou', ',', 'Y.', ',', 'Chen', ',', 'X.', ',', 'Tao', ',', 'X.', 'Zhang', ',', 'P.', ',', '2019', '.']

>> Bigrams are: 
 [('Cui', ','), (',', 'Q.'), ('Q.', ','), (',', 'Gong'), ('Gong', ','), (',', 'Z.'), ('Z.', ','), (',', 'Ni'), ('Ni', ','), (',', 'W.'), ('W.', ','), (',', 'Hou'), ('Hou', ','), (',', 'Y.'), ('Y.', ','), (',', 'Chen'), ('Chen', ','), (',', 'X.'), ('X.', ','), (',', 'Tao'), ('Tao', ','), (',', 'X.'), ('X.', 'Zhang'), ('Zhang', ','), (',', 'P.'), ('P.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Cui', ',', 'Q.'), (',', 'Q.', ','), ('Q.', ',', 'Gong'), (',', 'Gong', ','), ('Gong', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Ni'), (',', 'Ni', ','), ('Ni', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Hou'), (',', 'Hou', ','), ('Hou', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Chen'), (',', 'Chen', ','), ('Chen', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Tao'), (',', 'Tao', ','), ('Tao', ',', 'X.'), (',', 'X.', 'Zhang'), ('X.', 'Zhang', ','), ('Zhang', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Cui', 'NNP'), (',', ','), ('Q.', 'NNP'), (',', ','), ('Gong', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Ni', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Hou', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Chen', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Tao', 'NNP'), (',', ','), ('X.', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Cui', 'Q.', 'Gong', 'Z.', 'Ni', 'W.', 'Hou', 'Y.', 'Chen', 'X.', 'Tao', 'X. Zhang', 'P.']

>> Named Entities are: 
 [('GPE', 'Cui'), ('GPE', 'Gong'), ('GPE', 'Ni'), ('PERSON', 'Hou'), ('GPE', 'Chen'), ('PERSON', 'Tao'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Cui', 'cui'), (',', ','), ('Q.', 'q.'), (',', ','), ('Gong', 'gong'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ni', 'ni'), (',', ','), ('W.', 'w.'), (',', ','), ('Hou', 'hou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Chen', 'chen'), (',', ','), ('X.', 'x.'), (',', ','), ('Tao', 'tao'), (',', ','), ('X.', 'x.'), ('Zhang', 'zhang'), (',', ','), ('P.', 'p.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cui', 'cui'), (',', ','), ('Q.', 'q.'), (',', ','), ('Gong', 'gong'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ni', 'ni'), (',', ','), ('W.', 'w.'), (',', ','), ('Hou', 'hou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Chen', 'chen'), (',', ','), ('X.', 'x.'), (',', ','), ('Tao', 'tao'), (',', ','), ('X.', 'x.'), ('Zhang', 'zhang'), (',', ','), ('P.', 'p.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Cui', 'Cui'), (',', ','), ('Q.', 'Q.'), (',', ','), ('Gong', 'Gong'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Ni', 'Ni'), (',', ','), ('W.', 'W.'), (',', ','), ('Hou', 'Hou'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Chen', 'Chen'), (',', ','), ('X.', 'X.'), (',', ','), ('Tao', 'Tao'), (',', ','), ('X.', 'X.'), ('Zhang', 'Zhang'), (',', ','), ('P.', 'P.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Stochastic Online

>> Tokens are: 
 ['Stochastic', 'Online']

>> Bigrams are: 
 [('Stochastic', 'Online')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Stochastic', 'JJ'), ('Online', 'NN')]

>> Noun Phrases are: 
 ['Stochastic Online']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Stochastic', 'stochast'), ('Online', 'onlin')]

>> Stemming using Snowball Stemmer: 
 [('Stochastic', 'stochast'), ('Online', 'onlin')]

>> Lemmatization: 
 [('Stochastic', 'Stochastic'), ('Online', 'Online')]



========================================== PARAGRAPH 1449 ===========================================

Learning for Mobile Edge Computing: Learning from Changes.. IEEE Communications Magazine  

------------------- Sentence 1 -------------------

Learning for Mobile Edge Computing: Learning from Changes.. IEEE Communications Magazine

>> Tokens are: 
 ['Learning', 'Mobile', 'Edge', 'Computing', ':', 'Learning', 'Changes', '..', 'IEEE', 'Communications', 'Magazine']

>> Bigrams are: 
 [('Learning', 'Mobile'), ('Mobile', 'Edge'), ('Edge', 'Computing'), ('Computing', ':'), (':', 'Learning'), ('Learning', 'Changes'), ('Changes', '..'), ('..', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Magazine')]

>> Trigrams are: 
 [('Learning', 'Mobile', 'Edge'), ('Mobile', 'Edge', 'Computing'), ('Edge', 'Computing', ':'), ('Computing', ':', 'Learning'), (':', 'Learning', 'Changes'), ('Learning', 'Changes', '..'), ('Changes', '..', 'IEEE'), ('..', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Magazine')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('Mobile', 'NNP'), ('Edge', 'NNP'), ('Computing', 'NNP'), (':', ':'), ('Learning', 'NNP'), ('Changes', 'NNP'), ('..', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Magazine', 'NNP')]

>> Noun Phrases are: 
 ['Mobile Edge Computing', 'Learning Changes .. IEEE Communications Magazine']

>> Named Entities are: 
 [('PERSON', 'Mobile Edge'), ('ORGANIZATION', 'IEEE Communications Magazine')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('Mobile', 'mobil'), ('Edge', 'edg'), ('Computing', 'comput'), (':', ':'), ('Learning', 'learn'), ('Changes', 'chang'), ('..', '..'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Magazine', 'magazin')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('Mobile', 'mobil'), ('Edge', 'edg'), ('Computing', 'comput'), (':', ':'), ('Learning', 'learn'), ('Changes', 'chang'), ('..', '..'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Magazine', 'magazin')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('Mobile', 'Mobile'), ('Edge', 'Edge'), ('Computing', 'Computing'), (':', ':'), ('Learning', 'Learning'), ('Changes', 'Changes'), ('..', '..'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Magazine', 'Magazine')]



========================================== PARAGRAPH 1450 ===========================================

journal, Volume 57, pp. 63-69.  

------------------- Sentence 1 -------------------

journal, Volume 57, pp.

>> Tokens are: 
 ['journal', ',', 'Volume', '57', ',', 'pp', '.']

>> Bigrams are: 
 [('journal', ','), (',', 'Volume'), ('Volume', '57'), ('57', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('journal', ',', 'Volume'), (',', 'Volume', '57'), ('Volume', '57', ','), ('57', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('57', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 57')] 

>> Stemming using Porter Stemmer: 
 [('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

63-69.

>> Tokens are: 
 ['63-69', '.']

>> Bigrams are: 
 [('63-69', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63-69', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63-69', '63-69'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63-69', '63-69'), ('.', '.')]

>> Lemmatization: 
 [('63-69', '63-69'), ('.', '.')]



========================================== PARAGRAPH 1451 ===========================================

Data, D.B., 2012. A Practical Guide to Transforming the Business of Government.. TechAmerica  

------------------- Sentence 1 -------------------

Data, D.B., 2012.

>> Tokens are: 
 ['Data', ',', 'D.B.', ',', '2012', '.']

>> Bigrams are: 
 [('Data', ','), (',', 'D.B.'), ('D.B.', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Data', ',', 'D.B.'), (',', 'D.B.', ','), ('D.B.', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), (',', ','), ('D.B.', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Data', 'D.B.']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), (',', ','), ('D.B.', 'D.B.'), (',', ','), ('2012', '2012'), ('.', '.')]


------------------- Sentence 2 -------------------

A Practical Guide to Transforming the Business of Government.. TechAmerica

>> Tokens are: 
 ['A', 'Practical', 'Guide', 'Transforming', 'Business', 'Government', '..', 'TechAmerica']

>> Bigrams are: 
 [('A', 'Practical'), ('Practical', 'Guide'), ('Guide', 'Transforming'), ('Transforming', 'Business'), ('Business', 'Government'), ('Government', '..'), ('..', 'TechAmerica')]

>> Trigrams are: 
 [('A', 'Practical', 'Guide'), ('Practical', 'Guide', 'Transforming'), ('Guide', 'Transforming', 'Business'), ('Transforming', 'Business', 'Government'), ('Business', 'Government', '..'), ('Government', '..', 'TechAmerica')]

>> POS Tags are: 
 [('A', 'DT'), ('Practical', 'NNP'), ('Guide', 'NNP'), ('Transforming', 'NNP'), ('Business', 'NNP'), ('Government', 'NNP'), ('..', 'NNP'), ('TechAmerica', 'NNP')]

>> Noun Phrases are: 
 ['A Practical Guide Transforming Business Government .. TechAmerica']

>> Named Entities are: 
 [('ORGANIZATION', 'Practical Guide')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Transforming', 'transform'), ('Business', 'busi'), ('Government', 'govern'), ('..', '..'), ('TechAmerica', 'techamerica')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Transforming', 'transform'), ('Business', 'busi'), ('Government', 'govern'), ('..', '..'), ('TechAmerica', 'techamerica')]

>> Lemmatization: 
 [('A', 'A'), ('Practical', 'Practical'), ('Guide', 'Guide'), ('Transforming', 'Transforming'), ('Business', 'Business'), ('Government', 'Government'), ('..', '..'), ('TechAmerica', 'TechAmerica')]



========================================== PARAGRAPH 1452 ===========================================

Foundation‟ s Federal Big Data Commission Journal.  

------------------- Sentence 1 -------------------

Foundation‟ s Federal Big Data Commission Journal.

>> Tokens are: 
 ['Foundation‟', 'Federal', 'Big', 'Data', 'Commission', 'Journal', '.']

>> Bigrams are: 
 [('Foundation‟', 'Federal'), ('Federal', 'Big'), ('Big', 'Data'), ('Data', 'Commission'), ('Commission', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('Foundation‟', 'Federal', 'Big'), ('Federal', 'Big', 'Data'), ('Big', 'Data', 'Commission'), ('Data', 'Commission', 'Journal'), ('Commission', 'Journal', '.')]

>> POS Tags are: 
 [('Foundation‟', 'NNP'), ('Federal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Commission', 'NNP'), ('Journal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Foundation‟ Federal Big Data Commission Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Foundation‟', 'foundation‟'), ('Federal', 'feder'), ('Big', 'big'), ('Data', 'data'), ('Commission', 'commiss'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Foundation‟', 'foundation‟'), ('Federal', 'feder'), ('Big', 'big'), ('Data', 'data'), ('Commission', 'commiss'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('Foundation‟', 'Foundation‟'), ('Federal', 'Federal'), ('Big', 'Big'), ('Data', 'Data'), ('Commission', 'Commission'), ('Journal', 'Journal'), ('.', '.')]



========================================== PARAGRAPH 1453 ===========================================

Davenport, T.H. and Dyché, J., 2013. Big data in big companies. International Institute for  

------------------- Sentence 1 -------------------

Davenport, T.H.

>> Tokens are: 
 ['Davenport', ',', 'T.H', '.']

>> Bigrams are: 
 [('Davenport', ','), (',', 'T.H'), ('T.H', '.')]

>> Trigrams are: 
 [('Davenport', ',', 'T.H'), (',', 'T.H', '.')]

>> POS Tags are: 
 [('Davenport', 'NNP'), (',', ','), ('T.H', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Davenport', 'T.H']

>> Named Entities are: 
 [('GPE', 'Davenport')] 

>> Stemming using Porter Stemmer: 
 [('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Lemmatization: 
 [('Davenport', 'Davenport'), (',', ','), ('T.H', 'T.H'), ('.', '.')]


------------------- Sentence 2 -------------------

and Dyché, J., 2013.

>> Tokens are: 
 ['Dyché', ',', 'J.', ',', '2013', '.']

>> Bigrams are: 
 [('Dyché', ','), (',', 'J.'), ('J.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Dyché', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Dyché', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Dyché', 'J.']

>> Named Entities are: 
 [('GPE', 'Dyché')] 

>> Stemming using Porter Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Dyché', 'Dyché'), (',', ','), ('J.', 'J.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data in big companies.

>> Tokens are: 
 ['Big', 'data', 'big', 'companies', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'big'), ('big', 'companies'), ('companies', '.')]

>> Trigrams are: 
 [('Big', 'data', 'big'), ('data', 'big', 'companies'), ('big', 'companies', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('big', 'JJ'), ('companies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'big companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('big', 'big'), ('companies', 'compani'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('big', 'big'), ('companies', 'compani'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('big', 'big'), ('companies', 'company'), ('.', '.')]


------------------- Sentence 4 -------------------

International Institute for

>> Tokens are: 
 ['International', 'Institute']

>> Bigrams are: 
 [('International', 'Institute')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('International', 'NNP'), ('Institute', 'NNP')]

>> Noun Phrases are: 
 ['International Institute']

>> Named Entities are: 
 [('ORGANIZATION', 'International Institute')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Institute', 'institut')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Institute', 'institut')]

>> Lemmatization: 
 [('International', 'International'), ('Institute', 'Institute')]



========================================== PARAGRAPH 1454 ===========================================

Analytics.  

------------------- Sentence 1 -------------------

Analytics.

>> Tokens are: 
 ['Analytics', '.']

>> Bigrams are: 
 [('Analytics', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('.', '.')]



========================================== PARAGRAPH 1455 ===========================================

Di Martino, B., Aversa, R., Cretella, G., Esposito, A. and Kołodziej, J., 2014. Big data (lost) in the  

------------------- Sentence 1 -------------------

Di Martino, B., Aversa, R., Cretella, G., Esposito, A. and Kołodziej, J., 2014.

>> Tokens are: 
 ['Di', 'Martino', ',', 'B.', ',', 'Aversa', ',', 'R.', ',', 'Cretella', ',', 'G.', ',', 'Esposito', ',', 'A.', 'Kołodziej', ',', 'J.', ',', '2014', '.']

>> Bigrams are: 
 [('Di', 'Martino'), ('Martino', ','), (',', 'B.'), ('B.', ','), (',', 'Aversa'), ('Aversa', ','), (',', 'R.'), ('R.', ','), (',', 'Cretella'), ('Cretella', ','), (',', 'G.'), ('G.', ','), (',', 'Esposito'), ('Esposito', ','), (',', 'A.'), ('A.', 'Kołodziej'), ('Kołodziej', ','), (',', 'J.'), ('J.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Di', 'Martino', ','), ('Martino', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Aversa'), (',', 'Aversa', ','), ('Aversa', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Cretella'), (',', 'Cretella', ','), ('Cretella', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Esposito'), (',', 'Esposito', ','), ('Esposito', ',', 'A.'), (',', 'A.', 'Kołodziej'), ('A.', 'Kołodziej', ','), ('Kołodziej', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Di', 'NNP'), ('Martino', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Aversa', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Cretella', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Esposito', 'NNP'), (',', ','), ('A.', 'NNP'), ('Kołodziej', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Di Martino', 'B.', 'Aversa', 'R.', 'Cretella', 'G.', 'Esposito', 'A. Kołodziej', 'J.']

>> Named Entities are: 
 [('PERSON', 'Martino'), ('GPE', 'Aversa'), ('GPE', 'Cretella'), ('GPE', 'Esposito')] 

>> Stemming using Porter Stemmer: 
 [('Di', 'di'), ('Martino', 'martino'), (',', ','), ('B.', 'b.'), (',', ','), ('Aversa', 'aversa'), (',', ','), ('R.', 'r.'), (',', ','), ('Cretella', 'cretella'), (',', ','), ('G.', 'g.'), (',', ','), ('Esposito', 'esposito'), (',', ','), ('A.', 'a.'), ('Kołodziej', 'kołodziej'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Di', 'di'), ('Martino', 'martino'), (',', ','), ('B.', 'b.'), (',', ','), ('Aversa', 'aversa'), (',', ','), ('R.', 'r.'), (',', ','), ('Cretella', 'cretella'), (',', ','), ('G.', 'g.'), (',', ','), ('Esposito', 'esposito'), (',', ','), ('A.', 'a.'), ('Kołodziej', 'kołodziej'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Di', 'Di'), ('Martino', 'Martino'), (',', ','), ('B.', 'B.'), (',', ','), ('Aversa', 'Aversa'), (',', ','), ('R.', 'R.'), (',', ','), ('Cretella', 'Cretella'), (',', ','), ('G.', 'G.'), (',', ','), ('Esposito', 'Esposito'), (',', ','), ('A.', 'A.'), ('Kołodziej', 'Kołodziej'), (',', ','), ('J.', 'J.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data (lost) in the

>> Tokens are: 
 ['Big', 'data', '(', 'lost', ')']

>> Bigrams are: 
 [('Big', 'data'), ('data', '('), ('(', 'lost'), ('lost', ')')]

>> Trigrams are: 
 [('Big', 'data', '('), ('data', '(', 'lost'), ('(', 'lost', ')')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), ('(', '('), ('lost', 'VBN'), (')', ')')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')')]



========================================== PARAGRAPH 1456 ===========================================

cloud.. International Journal of Big Data Intelligence, Volume 1, pp. 3-17. 

------------------- Sentence 1 -------------------

cloud.. International Journal of Big Data Intelligence, Volume 1, pp.

>> Tokens are: 
 ['cloud', '..', 'International', 'Journal', 'Big', 'Data', 'Intelligence', ',', 'Volume', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('cloud', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', 'Intelligence'), ('Intelligence', ','), (',', 'Volume'), ('Volume', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('cloud', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', 'Intelligence'), ('Data', 'Intelligence', ','), ('Intelligence', ',', 'Volume'), (',', 'Volume', '1'), ('Volume', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('cloud', 'NN'), ('..', 'NNP'), ('International', 'NNP'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Intelligence', 'NNP'), (',', ','), ('Volume', 'NN'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['cloud .. International Journal Big Data Intelligence', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('cloud', 'cloud'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('Intelligence', 'intellig'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cloud', 'cloud'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('Intelligence', 'intellig'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('cloud', 'cloud'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('Intelligence', 'Intelligence'), (',', ','), ('Volume', 'Volume'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

3-17.

>> Tokens are: 
 ['3-17', '.']

>> Bigrams are: 
 [('3-17', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3-17', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-17', '3-17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-17', '3-17'), ('.', '.')]

>> Lemmatization: 
 [('3-17', '3-17'), ('.', '.')]



========================================== PARAGRAPH 1457 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1458 ===========================================

49  

------------------- Sentence 1 -------------------

49

>> Tokens are: 
 ['49']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('49', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('49', '49')]

>> Stemming using Snowball Stemmer: 
 [('49', '49')]

>> Lemmatization: 
 [('49', '49')]



========================================== PARAGRAPH 1459 ===========================================

  


========================================== PARAGRAPH 1460 ===========================================

Ekbia, H., Mattioli, M., Kouper, I., Arave, G., Ghazinejad, A., Bowman, T., Suri, V.R., Tsou, A.,  

------------------- Sentence 1 -------------------

Ekbia, H., Mattioli, M., Kouper, I., Arave, G., Ghazinejad, A., Bowman, T., Suri, V.R., Tsou, A.,

>> Tokens are: 
 ['Ekbia', ',', 'H.', ',', 'Mattioli', ',', 'M.', ',', 'Kouper', ',', 'I.', ',', 'Arave', ',', 'G.', ',', 'Ghazinejad', ',', 'A.', ',', 'Bowman', ',', 'T.', ',', 'Suri', ',', 'V.R.', ',', 'Tsou', ',', 'A.', ',']

>> Bigrams are: 
 [('Ekbia', ','), (',', 'H.'), ('H.', ','), (',', 'Mattioli'), ('Mattioli', ','), (',', 'M.'), ('M.', ','), (',', 'Kouper'), ('Kouper', ','), (',', 'I.'), ('I.', ','), (',', 'Arave'), ('Arave', ','), (',', 'G.'), ('G.', ','), (',', 'Ghazinejad'), ('Ghazinejad', ','), (',', 'A.'), ('A.', ','), (',', 'Bowman'), ('Bowman', ','), (',', 'T.'), ('T.', ','), (',', 'Suri'), ('Suri', ','), (',', 'V.R.'), ('V.R.', ','), (',', 'Tsou'), ('Tsou', ','), (',', 'A.'), ('A.', ',')]

>> Trigrams are: 
 [('Ekbia', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Mattioli'), (',', 'Mattioli', ','), ('Mattioli', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kouper'), (',', 'Kouper', ','), ('Kouper', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Arave'), (',', 'Arave', ','), ('Arave', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Ghazinejad'), (',', 'Ghazinejad', ','), ('Ghazinejad', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Bowman'), (',', 'Bowman', ','), ('Bowman', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Suri'), (',', 'Suri', ','), ('Suri', ',', 'V.R.'), (',', 'V.R.', ','), ('V.R.', ',', 'Tsou'), (',', 'Tsou', ','), ('Tsou', ',', 'A.'), (',', 'A.', ',')]

>> POS Tags are: 
 [('Ekbia', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Mattioli', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kouper', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Arave', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Ghazinejad', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Bowman', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Suri', 'NNP'), (',', ','), ('V.R.', 'NNP'), (',', ','), ('Tsou', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Ekbia', 'H.', 'Mattioli', 'M.', 'Kouper', 'I.', 'Arave', 'G.', 'Ghazinejad', 'A.', 'Bowman', 'T.', 'Suri', 'V.R.', 'Tsou', 'A.']

>> Named Entities are: 
 [('GPE', 'Ekbia'), ('PERSON', 'Mattioli'), ('GPE', 'Kouper'), ('PERSON', 'Arave'), ('PERSON', 'Ghazinejad'), ('PERSON', 'Bowman'), ('PERSON', 'Suri'), ('PERSON', 'Tsou')] 

>> Stemming using Porter Stemmer: 
 [('Ekbia', 'ekbia'), (',', ','), ('H.', 'h.'), (',', ','), ('Mattioli', 'mattioli'), (',', ','), ('M.', 'm.'), (',', ','), ('Kouper', 'kouper'), (',', ','), ('I.', 'i.'), (',', ','), ('Arave', 'arav'), (',', ','), ('G.', 'g.'), (',', ','), ('Ghazinejad', 'ghazinejad'), (',', ','), ('A.', 'a.'), (',', ','), ('Bowman', 'bowman'), (',', ','), ('T.', 't.'), (',', ','), ('Suri', 'suri'), (',', ','), ('V.R.', 'v.r.'), (',', ','), ('Tsou', 'tsou'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Ekbia', 'ekbia'), (',', ','), ('H.', 'h.'), (',', ','), ('Mattioli', 'mattioli'), (',', ','), ('M.', 'm.'), (',', ','), ('Kouper', 'kouper'), (',', ','), ('I.', 'i.'), (',', ','), ('Arave', 'arav'), (',', ','), ('G.', 'g.'), (',', ','), ('Ghazinejad', 'ghazinejad'), (',', ','), ('A.', 'a.'), (',', ','), ('Bowman', 'bowman'), (',', ','), ('T.', 't.'), (',', ','), ('Suri', 'suri'), (',', ','), ('V.R.', 'v.r.'), (',', ','), ('Tsou', 'tsou'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Lemmatization: 
 [('Ekbia', 'Ekbia'), (',', ','), ('H.', 'H.'), (',', ','), ('Mattioli', 'Mattioli'), (',', ','), ('M.', 'M.'), (',', ','), ('Kouper', 'Kouper'), (',', ','), ('I.', 'I.'), (',', ','), ('Arave', 'Arave'), (',', ','), ('G.', 'G.'), (',', ','), ('Ghazinejad', 'Ghazinejad'), (',', ','), ('A.', 'A.'), (',', ','), ('Bowman', 'Bowman'), (',', ','), ('T.', 'T.'), (',', ','), ('Suri', 'Suri'), (',', ','), ('V.R.', 'V.R.'), (',', ','), ('Tsou', 'Tsou'), (',', ','), ('A.', 'A.'), (',', ',')]



========================================== PARAGRAPH 1461 ===========================================

Weingart, S. and Sugimoto, C.R., 2015. Big data, bigger dilemmas: A critical review. Journal of  

------------------- Sentence 1 -------------------

Weingart, S. and Sugimoto, C.R., 2015.

>> Tokens are: 
 ['Weingart', ',', 'S.', 'Sugimoto', ',', 'C.R.', ',', '2015', '.']

>> Bigrams are: 
 [('Weingart', ','), (',', 'S.'), ('S.', 'Sugimoto'), ('Sugimoto', ','), (',', 'C.R.'), ('C.R.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Weingart', ',', 'S.'), (',', 'S.', 'Sugimoto'), ('S.', 'Sugimoto', ','), ('Sugimoto', ',', 'C.R.'), (',', 'C.R.', ','), ('C.R.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Weingart', 'NNP'), (',', ','), ('S.', 'NNP'), ('Sugimoto', 'NNP'), (',', ','), ('C.R.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Weingart', 'S. Sugimoto', 'C.R.']

>> Named Entities are: 
 [('GPE', 'Weingart')] 

>> Stemming using Porter Stemmer: 
 [('Weingart', 'weingart'), (',', ','), ('S.', 's.'), ('Sugimoto', 'sugimoto'), (',', ','), ('C.R.', 'c.r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Weingart', 'weingart'), (',', ','), ('S.', 's.'), ('Sugimoto', 'sugimoto'), (',', ','), ('C.R.', 'c.r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Weingart', 'Weingart'), (',', ','), ('S.', 'S.'), ('Sugimoto', 'Sugimoto'), (',', ','), ('C.R.', 'C.R.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data, bigger dilemmas: A critical review.

>> Tokens are: 
 ['Big', 'data', ',', 'bigger', 'dilemmas', ':', 'A', 'critical', 'review', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'bigger'), ('bigger', 'dilemmas'), ('dilemmas', ':'), (':', 'A'), ('A', 'critical'), ('critical', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'bigger'), (',', 'bigger', 'dilemmas'), ('bigger', 'dilemmas', ':'), ('dilemmas', ':', 'A'), (':', 'A', 'critical'), ('A', 'critical', 'review'), ('critical', 'review', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('bigger', 'JJR'), ('dilemmas', 'NN'), (':', ':'), ('A', 'DT'), ('critical', 'JJ'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'dilemmas', 'A critical review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'a'), ('critical', 'critic'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'a'), ('critical', 'critic'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'A'), ('critical', 'critical'), ('review', 'review'), ('.', '.')]


------------------- Sentence 3 -------------------

Journal of

>> Tokens are: 
 ['Journal']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Journal', 'NNP')]

>> Noun Phrases are: 
 ['Journal']

>> Named Entities are: 
 [('GPE', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal')]

>> Lemmatization: 
 [('Journal', 'Journal')]



========================================== PARAGRAPH 1462 ===========================================

the Association for Information Science and Technology, Volume 66, pp. 1523-1545.  

------------------- Sentence 1 -------------------

the Association for Information Science and Technology, Volume 66, pp.

>> Tokens are: 
 ['Association', 'Information', 'Science', 'Technology', ',', 'Volume', '66', ',', 'pp', '.']

>> Bigrams are: 
 [('Association', 'Information'), ('Information', 'Science'), ('Science', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '66'), ('66', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Association', 'Information', 'Science'), ('Information', 'Science', 'Technology'), ('Science', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '66'), ('Volume', '66', ','), ('66', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Information', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('66', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Information Science Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 66')] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Information', 'inform'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Information', 'inform'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Information', 'Information'), ('Science', 'Science'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1523-1545.

>> Tokens are: 
 ['1523-1545', '.']

>> Bigrams are: 
 [('1523-1545', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1523-1545', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1523-1545', '1523-1545'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1523-1545', '1523-1545'), ('.', '.')]

>> Lemmatization: 
 [('1523-1545', '1523-1545'), ('.', '.')]



========================================== PARAGRAPH 1463 ===========================================

Eldawy, A. and Mokbel, M.F., 2015. Spatialhadoop: A mapreduce framework for spatial data.  

------------------- Sentence 1 -------------------

Eldawy, A. and Mokbel, M.F., 2015.

>> Tokens are: 
 ['Eldawy', ',', 'A.', 'Mokbel', ',', 'M.F.', ',', '2015', '.']

>> Bigrams are: 
 [('Eldawy', ','), (',', 'A.'), ('A.', 'Mokbel'), ('Mokbel', ','), (',', 'M.F.'), ('M.F.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Eldawy', ',', 'A.'), (',', 'A.', 'Mokbel'), ('A.', 'Mokbel', ','), ('Mokbel', ',', 'M.F.'), (',', 'M.F.', ','), ('M.F.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Eldawy', 'NNP'), (',', ','), ('A.', 'NNP'), ('Mokbel', 'NNP'), (',', ','), ('M.F.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Eldawy', 'A. Mokbel', 'M.F.']

>> Named Entities are: 
 [('GPE', 'Eldawy')] 

>> Stemming using Porter Stemmer: 
 [('Eldawy', 'eldawi'), (',', ','), ('A.', 'a.'), ('Mokbel', 'mokbel'), (',', ','), ('M.F.', 'm.f.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Eldawy', 'eldawi'), (',', ','), ('A.', 'a.'), ('Mokbel', 'mokbel'), (',', ','), ('M.F.', 'm.f.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Eldawy', 'Eldawy'), (',', ','), ('A.', 'A.'), ('Mokbel', 'Mokbel'), (',', ','), ('M.F.', 'M.F.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Spatialhadoop: A mapreduce framework for spatial data.

>> Tokens are: 
 ['Spatialhadoop', ':', 'A', 'mapreduce', 'framework', 'spatial', 'data', '.']

>> Bigrams are: 
 [('Spatialhadoop', ':'), (':', 'A'), ('A', 'mapreduce'), ('mapreduce', 'framework'), ('framework', 'spatial'), ('spatial', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Spatialhadoop', ':', 'A'), (':', 'A', 'mapreduce'), ('A', 'mapreduce', 'framework'), ('mapreduce', 'framework', 'spatial'), ('framework', 'spatial', 'data'), ('spatial', 'data', '.')]

>> POS Tags are: 
 [('Spatialhadoop', 'NN'), (':', ':'), ('A', 'DT'), ('mapreduce', 'NN'), ('framework', 'NN'), ('spatial', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Spatialhadoop', 'A mapreduce framework', 'spatial data']

>> Named Entities are: 
 [('GPE', 'Spatialhadoop')] 

>> Stemming using Porter Stemmer: 
 [('Spatialhadoop', 'spatialhadoop'), (':', ':'), ('A', 'a'), ('mapreduce', 'mapreduc'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spatialhadoop', 'spatialhadoop'), (':', ':'), ('A', 'a'), ('mapreduce', 'mapreduc'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Spatialhadoop', 'Spatialhadoop'), (':', ':'), ('A', 'A'), ('mapreduce', 'mapreduce'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 1464 ===========================================

s.l., IEEE.  

------------------- Sentence 1 -------------------

s.l., IEEE.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 1465 ===========================================

Elgendy, N. and Elragal, A., 2014. Big data analytics: a literature review paper. s.l., Springer,  

------------------- Sentence 1 -------------------

Elgendy, N. and Elragal, A., 2014.

>> Tokens are: 
 ['Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics: a literature review paper.

>> Tokens are: 
 ['Big', 'data', 'analytics', ':', 'literature', 'review', 'paper', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'literature'), ('literature', 'review'), ('review', 'paper'), ('paper', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'literature'), (':', 'literature', 'review'), ('literature', 'review', 'paper'), ('review', 'paper', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('literature', 'NN'), ('review', 'NN'), ('paper', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics', 'literature review paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('literature', 'literature'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., Springer,

>> Tokens are: 
 ['s.l.', ',', 'Springer', ',']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Springer'), ('Springer', ',')]

>> Trigrams are: 
 [('s.l.', ',', 'Springer'), (',', 'Springer', ',')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Springer', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['s.l.', 'Springer']

>> Named Entities are: 
 [('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'springer'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'springer'), (',', ',')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'Springer'), (',', ',')]



========================================== PARAGRAPH 1466 ===========================================

cham, pp. 214-227.  

------------------- Sentence 1 -------------------

cham, pp.

>> Tokens are: 
 ['cham', ',', 'pp', '.']

>> Bigrams are: 
 [('cham', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('cham', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('cham', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['cham', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

214-227.

>> Tokens are: 
 ['214-227', '.']

>> Bigrams are: 
 [('214-227', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('214-227', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('214-227', '214-227'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('214-227', '214-227'), ('.', '.')]

>> Lemmatization: 
 [('214-227', '214-227'), ('.', '.')]



========================================== PARAGRAPH 1467 ===========================================

Elgendy, N. and Elragal, A., 2016. Big Data Analytics in Support of the Decision Making Process.  

------------------- Sentence 1 -------------------

Elgendy, N. and Elragal, A., 2016.

>> Tokens are: 
 ['Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2016', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Analytics in Support of the Decision Making Process.

>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Support', 'Decision', 'Making', 'Process', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Support'), ('Support', 'Decision'), ('Decision', 'Making'), ('Making', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Support'), ('Analytics', 'Support', 'Decision'), ('Support', 'Decision', 'Making'), ('Decision', 'Making', 'Process'), ('Making', 'Process', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Support', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('Process', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data Analytics Support Decision Making Process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Support', 'Support'), ('Decision', 'Decision'), ('Making', 'Making'), ('Process', 'Process'), ('.', '.')]



========================================== PARAGRAPH 1468 ===========================================

s.l., Elsevier.  

------------------- Sentence 1 -------------------

s.l., Elsevier.

>> Tokens are: 
 ['s.l.', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'Elsevier']

>> Named Entities are: 
 [('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



========================================== PARAGRAPH 1469 ===========================================

Elgendy, N., 2013. Big Data Analytics in Support of the Decision Making Process. MSc Thesis.  

------------------- Sentence 1 -------------------

Elgendy, N., 2013.

>> Tokens are: 
 ['Elgendy', ',', 'N.', ',', '2013', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Elgendy', 'N.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Analytics in Support of the Decision Making Process.

>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Support', 'Decision', 'Making', 'Process', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Support'), ('Support', 'Decision'), ('Decision', 'Making'), ('Making', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Support'), ('Analytics', 'Support', 'Decision'), ('Support', 'Decision', 'Making'), ('Decision', 'Making', 'Process'), ('Making', 'Process', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Support', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('Process', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data Analytics Support Decision Making Process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Support', 'Support'), ('Decision', 'Decision'), ('Making', 'Making'), ('Process', 'Process'), ('.', '.')]


------------------- Sentence 3 -------------------

MSc Thesis.

>> Tokens are: 
 ['MSc', 'Thesis', '.']

>> Bigrams are: 
 [('MSc', 'Thesis'), ('Thesis', '.')]

>> Trigrams are: 
 [('MSc', 'Thesis', '.')]

>> POS Tags are: 
 [('MSc', 'NNP'), ('Thesis', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['MSc Thesis']

>> Named Entities are: 
 [('ORGANIZATION', 'MSc')] 

>> Stemming using Porter Stemmer: 
 [('MSc', 'msc'), ('Thesis', 'thesi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MSc', 'msc'), ('Thesis', 'thesi'), ('.', '.')]

>> Lemmatization: 
 [('MSc', 'MSc'), ('Thesis', 'Thesis'), ('.', '.')]



========================================== PARAGRAPH 1470 ===========================================

p. 164.  

------------------- Sentence 1 -------------------

p. 164.

>> Tokens are: 
 ['p.', '164', '.']

>> Bigrams are: 
 [('p.', '164'), ('164', '.')]

>> Trigrams are: 
 [('p.', '164', '.')]

>> POS Tags are: 
 [('p.', 'NN'), ('164', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['p.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]

>> Lemmatization: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]



========================================== PARAGRAPH 1471 ===========================================

Elragal, A. and Klischewski, R., 2017. Theory-driven or process-driven prediction?  

------------------- Sentence 1 -------------------

Elragal, A. and Klischewski, R., 2017.

>> Tokens are: 
 ['Elragal', ',', 'A.', 'Klischewski', ',', 'R.', ',', '2017', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', 'A.'), ('A.', 'Klischewski'), ('Klischewski', ','), (',', 'R.'), ('R.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Elragal', ',', 'A.'), (',', 'A.', 'Klischewski'), ('A.', 'Klischewski', ','), ('Klischewski', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'A. Klischewski', 'R.']

>> Named Entities are: 
 [('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Klischewski', 'klischewski'), (',', ','), ('R.', 'r.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Klischewski', 'klischewski'), (',', ','), ('R.', 'r.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), ('Klischewski', 'Klischewski'), (',', ','), ('R.', 'R.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

Theory-driven or process-driven prediction?

>> Tokens are: 
 ['Theory-driven', 'process-driven', 'prediction', '?']

>> Bigrams are: 
 [('Theory-driven', 'process-driven'), ('process-driven', 'prediction'), ('prediction', '?')]

>> Trigrams are: 
 [('Theory-driven', 'process-driven', 'prediction'), ('process-driven', 'prediction', '?')]

>> POS Tags are: 
 [('Theory-driven', 'JJ'), ('process-driven', 'JJ'), ('prediction', 'NN'), ('?', '.')]

>> Noun Phrases are: 
 ['Theory-driven process-driven prediction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('?', '?')]

>> Lemmatization: 
 [('Theory-driven', 'Theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'prediction'), ('?', '?')]



========================================== PARAGRAPH 1472 ===========================================

Epistemological challenges of big data analytics. Journal of Big Data, p. 19.  

------------------- Sentence 1 -------------------

Epistemological challenges of big data analytics.

>> Tokens are: 
 ['Epistemological', 'challenges', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Epistemological', 'challenges'), ('challenges', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Epistemological', 'challenges', 'big'), ('challenges', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Epistemological', 'JJ'), ('challenges', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Epistemological challenges', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Epistemological')] 

>> Stemming using Porter Stemmer: 
 [('Epistemological', 'epistemolog'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Epistemological', 'epistemolog'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Epistemological', 'Epistemological'), ('challenges', 'challenge'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data, p. 19.

>> Tokens are: 
 ['Journal', 'Big', 'Data', ',', 'p.', '19', '.']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p.'), ('p.', '19'), ('19', '.')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p.'), (',', 'p.', '19'), ('p.', '19', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p.', 'NN'), ('19', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Big Data', 'p.']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]



========================================== PARAGRAPH 1473 ===========================================

Elragal, A, 2014. ERP and big data: the inept couple. s.l., Elsevier, pp. 242-249.  

------------------- Sentence 1 -------------------

Elragal, A, 2014.

>> Tokens are: 
 ['Elragal', ',', 'A', ',', '2014', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Elragal', 'A']

>> Named Entities are: 
 [('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

ERP and big data: the inept couple.

>> Tokens are: 
 ['ERP', 'big', 'data', ':', 'inept', 'couple', '.']

>> Bigrams are: 
 [('ERP', 'big'), ('big', 'data'), ('data', ':'), (':', 'inept'), ('inept', 'couple'), ('couple', '.')]

>> Trigrams are: 
 [('ERP', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'inept'), (':', 'inept', 'couple'), ('inept', 'couple', '.')]

>> POS Tags are: 
 [('ERP', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('inept', 'JJ'), ('couple', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ERP', 'big data', 'inept couple']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ERP', 'erp'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'coupl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ERP', 'erp'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'coupl'), ('.', '.')]

>> Lemmatization: 
 [('ERP', 'ERP'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'couple'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., Elsevier, pp.

>> Tokens are: 
 ['s.l.', ',', 'Elsevier', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Elsevier'), ('Elsevier', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'Elsevier'), (',', 'Elsevier', ','), ('Elsevier', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Elsevier', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'Elsevier', 'pp']

>> Named Entities are: 
 [('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'Elsevier'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

242-249.

>> Tokens are: 
 ['242-249', '.']

>> Bigrams are: 
 [('242-249', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('242-249', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('242-249', '242-249'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('242-249', '242-249'), ('.', '.')]

>> Lemmatization: 
 [('242-249', '242-249'), ('.', '.')]



========================================== PARAGRAPH 1474 ===========================================

Fan, J., Han, F. and Liu, H., 2014. Challenges of big data analysis. National science review,  

------------------- Sentence 1 -------------------

Fan, J., Han, F. and Liu, H., 2014.

>> Tokens are: 
 ['Fan', ',', 'J.', ',', 'Han', ',', 'F.', 'Liu', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Fan', ','), (',', 'J.'), ('J.', ','), (',', 'Han'), ('Han', ','), (',', 'F.'), ('F.', 'Liu'), ('Liu', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Fan', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Han'), (',', 'Han', ','), ('Han', ',', 'F.'), (',', 'F.', 'Liu'), ('F.', 'Liu', ','), ('Liu', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Fan', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Han', 'NNP'), (',', ','), ('F.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Fan', 'J.', 'Han', 'F. Liu', 'H.']

>> Named Entities are: 
 [('GPE', 'Fan'), ('PERSON', 'Han')] 

>> Stemming using Porter Stemmer: 
 [('Fan', 'fan'), (',', ','), ('J.', 'j.'), (',', ','), ('Han', 'han'), (',', ','), ('F.', 'f.'), ('Liu', 'liu'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fan', 'fan'), (',', ','), ('J.', 'j.'), (',', ','), ('Han', 'han'), (',', ','), ('F.', 'f.'), ('Liu', 'liu'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Fan', 'Fan'), (',', ','), ('J.', 'J.'), (',', ','), ('Han', 'Han'), (',', ','), ('F.', 'F.'), ('Liu', 'Liu'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Challenges of big data analysis.

>> Tokens are: 
 ['Challenges', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Challenges', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Challenges', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Challenges', 'big data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 3 -------------------

National science review,

>> Tokens are: 
 ['National', 'science', 'review', ',']

>> Bigrams are: 
 [('National', 'science'), ('science', 'review'), ('review', ',')]

>> Trigrams are: 
 [('National', 'science', 'review'), ('science', 'review', ',')]

>> POS Tags are: 
 [('National', 'NNP'), ('science', 'NN'), ('review', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['National science review']

>> Named Entities are: 
 [('GPE', 'National')] 

>> Stemming using Porter Stemmer: 
 [('National', 'nation'), ('science', 'scienc'), ('review', 'review'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('National', 'nation'), ('science', 'scienc'), ('review', 'review'), (',', ',')]

>> Lemmatization: 
 [('National', 'National'), ('science', 'science'), ('review', 'review'), (',', ',')]



========================================== PARAGRAPH 1475 ===========================================

Volume 1, pp. 293-314.  

------------------- Sentence 1 -------------------

Volume 1, pp.

>> Tokens are: 
 ['Volume', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('Volume', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Volume', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Volume', 'NN'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Volume', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Volume', 'Volume'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

293-314.

>> Tokens are: 
 ['293-314', '.']

>> Bigrams are: 
 [('293-314', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('293-314', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('293-314', '293-314'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('293-314', '293-314'), ('.', '.')]

>> Lemmatization: 
 [('293-314', '293-314'), ('.', '.')]



========================================== PARAGRAPH 1476 ===========================================

Gandomi, A. and Haider, M., 2015. Beyond the hype: Big data concepts, methods, and analytics.  

------------------- Sentence 1 -------------------

Gandomi, A. and Haider, M., 2015.

>> Tokens are: 
 ['Gandomi', ',', 'A.', 'Haider', ',', 'M.', ',', '2015', '.']

>> Bigrams are: 
 [('Gandomi', ','), (',', 'A.'), ('A.', 'Haider'), ('Haider', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Gandomi', ',', 'A.'), (',', 'A.', 'Haider'), ('A.', 'Haider', ','), ('Haider', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Gandomi', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haider', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Gandomi', 'A. Haider', 'M.']

>> Named Entities are: 
 [('GPE', 'Gandomi')] 

>> Stemming using Porter Stemmer: 
 [('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Gandomi', 'Gandomi'), (',', ','), ('A.', 'A.'), ('Haider', 'Haider'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Beyond the hype: Big data concepts, methods, and analytics.

>> Tokens are: 
 ['Beyond', 'hype', ':', 'Big', 'data', 'concepts', ',', 'methods', ',', 'analytics', '.']

>> Bigrams are: 
 [('Beyond', 'hype'), ('hype', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'concepts'), ('concepts', ','), (',', 'methods'), ('methods', ','), (',', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Beyond', 'hype', ':'), ('hype', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'concepts'), ('data', 'concepts', ','), ('concepts', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'analytics'), (',', 'analytics', '.')]

>> POS Tags are: 
 [('Beyond', 'IN'), ('hype', 'NN'), (':', ':'), ('Big', 'NNP'), ('data', 'NNS'), ('concepts', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['hype', 'Big data concepts', 'methods', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Beyond', 'beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Beyond', 'beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Beyond', 'Beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 1477 ===========================================

International Journal of Information Management, Volume 35, pp. 137-144.  

------------------- Sentence 1 -------------------

International Journal of Information Management, Volume 35, pp.

>> Tokens are: 
 ['International', 'Journal', 'Information', 'Management', ',', 'Volume', '35', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '35'), ('35', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '35'), ('Volume', '35', ','), ('35', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('35', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['International Journal Information Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Information Management'), ('ORGANIZATION', 'Volume 35')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

137-144.

>> Tokens are: 
 ['137-144', '.']

>> Bigrams are: 
 [('137-144', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('137-144', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('137-144', '137-144'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('137-144', '137-144'), ('.', '.')]

>> Lemmatization: 
 [('137-144', '137-144'), ('.', '.')]



========================================== PARAGRAPH 1478 ===========================================

García, S., Ramírez-Gallego, S., Luengo, J., Benítez, J.M. and Herrera, F., 2016. Big data  

------------------- Sentence 1 -------------------

García, S., Ramírez-Gallego, S., Luengo, J., Benítez, J.M.

>> Tokens are: 
 ['García', ',', 'S.', ',', 'Ramírez-Gallego', ',', 'S.', ',', 'Luengo', ',', 'J.', ',', 'Benítez', ',', 'J.M', '.']

>> Bigrams are: 
 [('García', ','), (',', 'S.'), ('S.', ','), (',', 'Ramírez-Gallego'), ('Ramírez-Gallego', ','), (',', 'S.'), ('S.', ','), (',', 'Luengo'), ('Luengo', ','), (',', 'J.'), ('J.', ','), (',', 'Benítez'), ('Benítez', ','), (',', 'J.M'), ('J.M', '.')]

>> Trigrams are: 
 [('García', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ramírez-Gallego'), (',', 'Ramírez-Gallego', ','), ('Ramírez-Gallego', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Luengo'), (',', 'Luengo', ','), ('Luengo', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Benítez'), (',', 'Benítez', ','), ('Benítez', ',', 'J.M'), (',', 'J.M', '.')]

>> POS Tags are: 
 [('García', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ramírez-Gallego', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Luengo', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Benítez', 'NNP'), (',', ','), ('J.M', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['García', 'S.', 'Ramírez-Gallego', 'S.', 'Luengo', 'J.', 'Benítez', 'J.M']

>> Named Entities are: 
 [('GPE', 'García'), ('GPE', 'Luengo'), ('PERSON', 'Benítez')] 

>> Stemming using Porter Stemmer: 
 [('García', 'garcía'), (',', ','), ('S.', 's.'), (',', ','), ('Ramírez-Gallego', 'ramírez-gallego'), (',', ','), ('S.', 's.'), (',', ','), ('Luengo', 'luengo'), (',', ','), ('J.', 'j.'), (',', ','), ('Benítez', 'benítez'), (',', ','), ('J.M', 'j.m'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('García', 'garcía'), (',', ','), ('S.', 's.'), (',', ','), ('Ramírez-Gallego', 'ramírez-gallego'), (',', ','), ('S.', 's.'), (',', ','), ('Luengo', 'luengo'), (',', ','), ('J.', 'j.'), (',', ','), ('Benítez', 'benítez'), (',', ','), ('J.M', 'j.m'), ('.', '.')]

>> Lemmatization: 
 [('García', 'García'), (',', ','), ('S.', 'S.'), (',', ','), ('Ramírez-Gallego', 'Ramírez-Gallego'), (',', ','), ('S.', 'S.'), (',', ','), ('Luengo', 'Luengo'), (',', ','), ('J.', 'J.'), (',', ','), ('Benítez', 'Benítez'), (',', ','), ('J.M', 'J.M'), ('.', '.')]


------------------- Sentence 2 -------------------

and Herrera, F., 2016.

>> Tokens are: 
 ['Herrera', ',', 'F.', ',', '2016', '.']

>> Bigrams are: 
 [('Herrera', ','), (',', 'F.'), ('F.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Herrera', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Herrera', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Herrera', 'F.']

>> Named Entities are: 
 [('GPE', 'Herrera')] 

>> Stemming using Porter Stemmer: 
 [('Herrera', 'herrera'), (',', ','), ('F.', 'f.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Herrera', 'herrera'), (',', ','), ('F.', 'f.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Herrera', 'Herrera'), (',', ','), ('F.', 'F.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data

>> Tokens are: 
 ['Big', 'data']

>> Bigrams are: 
 [('Big', 'data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data')]



========================================== PARAGRAPH 1479 ===========================================

preprocessing: methods and prospects.. Big Data Analytics Journal, p. 9.  

------------------- Sentence 1 -------------------

preprocessing: methods and prospects.. Big Data Analytics Journal, p. 9.

>> Tokens are: 
 ['preprocessing', ':', 'methods', 'prospects', '..', 'Big', 'Data', 'Analytics', 'Journal', ',', 'p.', '9', '.']

>> Bigrams are: 
 [('preprocessing', ':'), (':', 'methods'), ('methods', 'prospects'), ('prospects', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Journal'), ('Journal', ','), (',', 'p.'), ('p.', '9'), ('9', '.')]

>> Trigrams are: 
 [('preprocessing', ':', 'methods'), (':', 'methods', 'prospects'), ('methods', 'prospects', '..'), ('prospects', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Journal'), ('Analytics', 'Journal', ','), ('Journal', ',', 'p.'), (',', 'p.', '9'), ('p.', '9', '.')]

>> POS Tags are: 
 [('preprocessing', 'NN'), (':', ':'), ('methods', 'NNS'), ('prospects', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['preprocessing', 'methods prospects', 'Big Data Analytics Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('preprocessing', 'preprocess'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('preprocessing', 'preprocess'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('preprocessing', 'preprocessing'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]



========================================== PARAGRAPH 1480 ===========================================

Goncharov, I., 2019. Big Data and AI Landscape in 2018 , s.l.: Four Megatrends in Big Data in  

------------------- Sentence 1 -------------------

Goncharov, I., 2019.

>> Tokens are: 
 ['Goncharov', ',', 'I.', ',', '2019', '.']

>> Bigrams are: 
 [('Goncharov', ','), (',', 'I.'), ('I.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Goncharov', ',', 'I.'), (',', 'I.', ','), ('I.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Goncharov', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Goncharov', 'I.']

>> Named Entities are: 
 [('GPE', 'Goncharov')] 

>> Stemming using Porter Stemmer: 
 [('Goncharov', 'goncharov'), (',', ','), ('I.', 'i.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Goncharov', 'goncharov'), (',', ','), ('I.', 'i.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Goncharov', 'Goncharov'), (',', ','), ('I.', 'I.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data and AI Landscape in 2018 , s.l.

>> Tokens are: 
 ['Big', 'Data', 'AI', 'Landscape', '2018', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'AI'), ('AI', 'Landscape'), ('Landscape', '2018'), ('2018', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'AI'), ('Data', 'AI', 'Landscape'), ('AI', 'Landscape', '2018'), ('Landscape', '2018', ','), ('2018', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('AI', 'NNP'), ('Landscape', 'NNP'), ('2018', 'CD'), (',', ','), ('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data AI Landscape', 's.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('AI', 'AI'), ('Landscape', 'Landscape'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]


------------------- Sentence 3 -------------------

: Four Megatrends in Big Data in

>> Tokens are: 
 [':', 'Four', 'Megatrends', 'Big', 'Data']

>> Bigrams are: 
 [(':', 'Four'), ('Four', 'Megatrends'), ('Megatrends', 'Big'), ('Big', 'Data')]

>> Trigrams are: 
 [(':', 'Four', 'Megatrends'), ('Four', 'Megatrends', 'Big'), ('Megatrends', 'Big', 'Data')]

>> POS Tags are: 
 [(':', ':'), ('Four', 'CD'), ('Megatrends', 'NNS'), ('Big', 'NNP'), ('Data', 'NNS')]

>> Noun Phrases are: 
 ['Megatrends Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Four', 'four'), ('Megatrends', 'megatrend'), ('Big', 'big'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Four', 'four'), ('Megatrends', 'megatrend'), ('Big', 'big'), ('Data', 'data')]

>> Lemmatization: 
 [(':', ':'), ('Four', 'Four'), ('Megatrends', 'Megatrends'), ('Big', 'Big'), ('Data', 'Data')]



========================================== PARAGRAPH 1481 ===========================================

2019 and Beyond .  

------------------- Sentence 1 -------------------

2019 and Beyond .

>> Tokens are: 
 ['2019', 'Beyond', '.']

>> Bigrams are: 
 [('2019', 'Beyond'), ('Beyond', '.')]

>> Trigrams are: 
 [('2019', 'Beyond', '.')]

>> POS Tags are: 
 [('2019', 'CD'), ('Beyond', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Beyond']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2019', '2019'), ('Beyond', 'beyond'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2019', '2019'), ('Beyond', 'beyond'), ('.', '.')]

>> Lemmatization: 
 [('2019', '2019'), ('Beyond', 'Beyond'), ('.', '.')]



========================================== PARAGRAPH 1482 ===========================================

Grover, P. and Kar, A.K., 2017. Big data analytics: a review on theoretical contributions and tools  

------------------- Sentence 1 -------------------

Grover, P. and Kar, A.K., 2017.

>> Tokens are: 
 ['Grover', ',', 'P.', 'Kar', ',', 'A.K.', ',', '2017', '.']

>> Bigrams are: 
 [('Grover', ','), (',', 'P.'), ('P.', 'Kar'), ('Kar', ','), (',', 'A.K.'), ('A.K.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Grover', ',', 'P.'), (',', 'P.', 'Kar'), ('P.', 'Kar', ','), ('Kar', ',', 'A.K.'), (',', 'A.K.', ','), ('A.K.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), (',', ','), ('P.', 'NNP'), ('Kar', 'NNP'), (',', ','), ('A.K.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Grover', 'P. Kar', 'A.K.']

>> Named Entities are: 
 [('GPE', 'Grover')] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), (',', ','), ('P.', 'p.'), ('Kar', 'kar'), (',', ','), ('A.K.', 'a.k.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), (',', ','), ('P.', 'p.'), ('Kar', 'kar'), (',', ','), ('A.K.', 'a.k.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), (',', ','), ('P.', 'P.'), ('Kar', 'Kar'), (',', ','), ('A.K.', 'A.K.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics: a review on theoretical contributions and tools

>> Tokens are: 
 ['Big', 'data', 'analytics', ':', 'review', 'theoretical', 'contributions', 'tools']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'review'), ('review', 'theoretical'), ('theoretical', 'contributions'), ('contributions', 'tools')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'review'), (':', 'review', 'theoretical'), ('review', 'theoretical', 'contributions'), ('theoretical', 'contributions', 'tools')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('review', 'VB'), ('theoretical', 'JJ'), ('contributions', 'NNS'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['Big data analytics', 'theoretical contributions tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('review', 'review'), ('theoretical', 'theoret'), ('contributions', 'contribut'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('review', 'review'), ('theoretical', 'theoret'), ('contributions', 'contribut'), ('tools', 'tool')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('review', 'review'), ('theoretical', 'theoretical'), ('contributions', 'contribution'), ('tools', 'tool')]



========================================== PARAGRAPH 1483 ===========================================

used in literature.. Global Journal of Flexible Systems Management, 18(3), pp. 203-229.  

------------------- Sentence 1 -------------------

used in literature..

>> Tokens are: 
 ['used', 'literature', '..']

>> Bigrams are: 
 [('used', 'literature'), ('literature', '..')]

>> Trigrams are: 
 [('used', 'literature', '..')]

>> POS Tags are: 
 [('used', 'VBN'), ('literature', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['literature ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('literature', 'literatur'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('literature', 'literatur'), ('..', '..')]

>> Lemmatization: 
 [('used', 'used'), ('literature', 'literature'), ('..', '..')]


------------------- Sentence 2 -------------------

Global Journal of Flexible Systems Management, 18(3), pp.

>> Tokens are: 
 ['Global', 'Journal', 'Flexible', 'Systems', 'Management', ',', '18', '(', '3', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Global', 'Journal'), ('Journal', 'Flexible'), ('Flexible', 'Systems'), ('Systems', 'Management'), ('Management', ','), (',', '18'), ('18', '('), ('(', '3'), ('3', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Global', 'Journal', 'Flexible'), ('Journal', 'Flexible', 'Systems'), ('Flexible', 'Systems', 'Management'), ('Systems', 'Management', ','), ('Management', ',', '18'), (',', '18', '('), ('18', '(', '3'), ('(', '3', ')'), ('3', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Global', 'JJ'), ('Journal', 'NNP'), ('Flexible', 'NNP'), ('Systems', 'NNPS'), ('Management', 'NNP'), (',', ','), ('18', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Global Journal Flexible', 'Management', 'pp']

>> Named Entities are: 
 [('PERSON', 'Global'), ('ORGANIZATION', 'Journal Flexible Systems Management')] 

>> Stemming using Porter Stemmer: 
 [('Global', 'global'), ('Journal', 'journal'), ('Flexible', 'flexibl'), ('Systems', 'system'), ('Management', 'manag'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Global', 'global'), ('Journal', 'journal'), ('Flexible', 'flexibl'), ('Systems', 'system'), ('Management', 'manag'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Global', 'Global'), ('Journal', 'Journal'), ('Flexible', 'Flexible'), ('Systems', 'Systems'), ('Management', 'Management'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

203-229.

>> Tokens are: 
 ['203-229', '.']

>> Bigrams are: 
 [('203-229', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('203-229', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('203-229', '203-229'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('203-229', '203-229'), ('.', '.')]

>> Lemmatization: 
 [('203-229', '203-229'), ('.', '.')]



========================================== PARAGRAPH 1484 ===========================================

Grover, V., Chiang, R.H., Liang, T.P. and Zhang, D., 2018. Creating Strategic Business Value  

------------------- Sentence 1 -------------------

Grover, V., Chiang, R.H., Liang, T.P.

>> Tokens are: 
 ['Grover', ',', 'V.', ',', 'Chiang', ',', 'R.H.', ',', 'Liang', ',', 'T.P', '.']

>> Bigrams are: 
 [('Grover', ','), (',', 'V.'), ('V.', ','), (',', 'Chiang'), ('Chiang', ','), (',', 'R.H.'), ('R.H.', ','), (',', 'Liang'), ('Liang', ','), (',', 'T.P'), ('T.P', '.')]

>> Trigrams are: 
 [('Grover', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Chiang'), (',', 'Chiang', ','), ('Chiang', ',', 'R.H.'), (',', 'R.H.', ','), ('R.H.', ',', 'Liang'), (',', 'Liang', ','), ('Liang', ',', 'T.P'), (',', 'T.P', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Chiang', 'NNP'), (',', ','), ('R.H.', 'NNP'), (',', ','), ('Liang', 'NNP'), (',', ','), ('T.P', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Grover', 'V.', 'Chiang', 'R.H.', 'Liang', 'T.P']

>> Named Entities are: 
 [('GPE', 'Grover'), ('GPE', 'Chiang'), ('PERSON', 'Liang')] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), (',', ','), ('V.', 'v.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), (',', ','), ('Liang', 'liang'), (',', ','), ('T.P', 't.p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), (',', ','), ('V.', 'v.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), (',', ','), ('Liang', 'liang'), (',', ','), ('T.P', 't.p'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), (',', ','), ('V.', 'V.'), (',', ','), ('Chiang', 'Chiang'), (',', ','), ('R.H.', 'R.H.'), (',', ','), ('Liang', 'Liang'), (',', ','), ('T.P', 'T.P'), ('.', '.')]


------------------- Sentence 2 -------------------

and Zhang, D., 2018.

>> Tokens are: 
 ['Zhang', ',', 'D.', ',', '2018', '.']

>> Bigrams are: 
 [('Zhang', ','), (',', 'D.'), ('D.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Zhang', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang', 'D.']

>> Named Entities are: 
 [('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), (',', ','), ('D.', 'd.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), (',', ','), ('D.', 'd.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), (',', ','), ('D.', 'D.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 3 -------------------

Creating Strategic Business Value

>> Tokens are: 
 ['Creating', 'Strategic', 'Business', 'Value']

>> Bigrams are: 
 [('Creating', 'Strategic'), ('Strategic', 'Business'), ('Business', 'Value')]

>> Trigrams are: 
 [('Creating', 'Strategic', 'Business'), ('Strategic', 'Business', 'Value')]

>> POS Tags are: 
 [('Creating', 'VBG'), ('Strategic', 'NNP'), ('Business', 'NNP'), ('Value', 'NNP')]

>> Noun Phrases are: 
 ['Strategic Business Value']

>> Named Entities are: 
 [('PERSON', 'Strategic Business Value')] 

>> Stemming using Porter Stemmer: 
 [('Creating', 'creat'), ('Strategic', 'strateg'), ('Business', 'busi'), ('Value', 'valu')]

>> Stemming using Snowball Stemmer: 
 [('Creating', 'creat'), ('Strategic', 'strateg'), ('Business', 'busi'), ('Value', 'valu')]

>> Lemmatization: 
 [('Creating', 'Creating'), ('Strategic', 'Strategic'), ('Business', 'Business'), ('Value', 'Value')]



========================================== PARAGRAPH 1485 ===========================================

from Big Data Analytics: A Research Framework.. Journal of Management Information Systems,  

------------------- Sentence 1 -------------------

from Big Data Analytics: A Research Framework.. Journal of Management Information Systems,

>> Tokens are: 
 ['Big', 'Data', 'Analytics', ':', 'A', 'Research', 'Framework', '..', 'Journal', 'Management', 'Information', 'Systems', ',']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'A'), ('A', 'Research'), ('Research', 'Framework'), ('Framework', '..'), ('..', 'Journal'), ('Journal', 'Management'), ('Management', 'Information'), ('Information', 'Systems'), ('Systems', ',')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'A'), (':', 'A', 'Research'), ('A', 'Research', 'Framework'), ('Research', 'Framework', '..'), ('Framework', '..', 'Journal'), ('..', 'Journal', 'Management'), ('Journal', 'Management', 'Information'), ('Management', 'Information', 'Systems'), ('Information', 'Systems', ',')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('A', 'DT'), ('Research', 'NNP'), ('Framework', 'NNP'), ('..', 'NNP'), ('Journal', 'NNP'), ('Management', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Big Data Analytics', 'A Research Framework .. Journal Management Information Systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Research', 'research'), ('Framework', 'framework'), ('..', '..'), ('Journal', 'journal'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Research', 'research'), ('Framework', 'framework'), ('..', '..'), ('Journal', 'journal'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), (',', ',')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('A', 'A'), ('Research', 'Research'), ('Framework', 'Framework'), ('..', '..'), ('Journal', 'Journal'), ('Management', 'Management'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ',')]



========================================== PARAGRAPH 1486 ===========================================

pp. 388-423.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

388-423.

>> Tokens are: 
 ['388-423', '.']

>> Bigrams are: 
 [('388-423', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('388-423', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('388-423', '388-423'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('388-423', '388-423'), ('.', '.')]

>> Lemmatization: 
 [('388-423', '388-423'), ('.', '.')]



========================================== PARAGRAPH 1487 ===========================================

Günther, W.A., Mehrizi, M.H.R., Huysman, M. and Feldberg, F., 2017. Debating big data: A  

------------------- Sentence 1 -------------------

Günther, W.A., Mehrizi, M.H.R., Huysman, M. and Feldberg, F., 2017.

>> Tokens are: 
 ['Günther', ',', 'W.A.', ',', 'Mehrizi', ',', 'M.H.R.', ',', 'Huysman', ',', 'M.', 'Feldberg', ',', 'F.', ',', '2017', '.']

>> Bigrams are: 
 [('Günther', ','), (',', 'W.A.'), ('W.A.', ','), (',', 'Mehrizi'), ('Mehrizi', ','), (',', 'M.H.R.'), ('M.H.R.', ','), (',', 'Huysman'), ('Huysman', ','), (',', 'M.'), ('M.', 'Feldberg'), ('Feldberg', ','), (',', 'F.'), ('F.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Günther', ',', 'W.A.'), (',', 'W.A.', ','), ('W.A.', ',', 'Mehrizi'), (',', 'Mehrizi', ','), ('Mehrizi', ',', 'M.H.R.'), (',', 'M.H.R.', ','), ('M.H.R.', ',', 'Huysman'), (',', 'Huysman', ','), ('Huysman', ',', 'M.'), (',', 'M.', 'Feldberg'), ('M.', 'Feldberg', ','), ('Feldberg', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Günther', 'NNP'), (',', ','), ('W.A.', 'NNP'), (',', ','), ('Mehrizi', 'NNP'), (',', ','), ('M.H.R.', 'NNP'), (',', ','), ('Huysman', 'NNP'), (',', ','), ('M.', 'NNP'), ('Feldberg', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Günther', 'W.A.', 'Mehrizi', 'M.H.R.', 'Huysman', 'M. Feldberg', 'F.']

>> Named Entities are: 
 [('GPE', 'Günther'), ('ORGANIZATION', 'W.A.'), ('PERSON', 'Mehrizi'), ('PERSON', 'Huysman')] 

>> Stemming using Porter Stemmer: 
 [('Günther', 'günther'), (',', ','), ('W.A.', 'w.a.'), (',', ','), ('Mehrizi', 'mehrizi'), (',', ','), ('M.H.R.', 'm.h.r.'), (',', ','), ('Huysman', 'huysman'), (',', ','), ('M.', 'm.'), ('Feldberg', 'feldberg'), (',', ','), ('F.', 'f.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Günther', 'günther'), (',', ','), ('W.A.', 'w.a.'), (',', ','), ('Mehrizi', 'mehrizi'), (',', ','), ('M.H.R.', 'm.h.r.'), (',', ','), ('Huysman', 'huysman'), (',', ','), ('M.', 'm.'), ('Feldberg', 'feldberg'), (',', ','), ('F.', 'f.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Günther', 'Günther'), (',', ','), ('W.A.', 'W.A.'), (',', ','), ('Mehrizi', 'Mehrizi'), (',', ','), ('M.H.R.', 'M.H.R.'), (',', ','), ('Huysman', 'Huysman'), (',', ','), ('M.', 'M.'), ('Feldberg', 'Feldberg'), (',', ','), ('F.', 'F.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

Debating big data: A

>> Tokens are: 
 ['Debating', 'big', 'data', ':', 'A']

>> Bigrams are: 
 [('Debating', 'big'), ('big', 'data'), ('data', ':'), (':', 'A')]

>> Trigrams are: 
 [('Debating', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'A')]

>> POS Tags are: 
 [('Debating', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT')]

>> Noun Phrases are: 
 ['big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Debating', 'debat'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('Debating', 'debat'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a')]

>> Lemmatization: 
 [('Debating', 'Debating'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'A')]



========================================== PARAGRAPH 1488 ===========================================

literature review on realizing value from big data. The Journal of Strategic Information Systems,  

------------------- Sentence 1 -------------------

literature review on realizing value from big data.

>> Tokens are: 
 ['literature', 'review', 'realizing', 'value', 'big', 'data', '.']

>> Bigrams are: 
 [('literature', 'review'), ('review', 'realizing'), ('realizing', 'value'), ('value', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('literature', 'review', 'realizing'), ('review', 'realizing', 'value'), ('realizing', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('literature', 'NN'), ('review', 'NN'), ('realizing', 'VBG'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['literature review', 'value', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('realizing', 'realiz'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('realizing', 'realiz'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('literature', 'literature'), ('review', 'review'), ('realizing', 'realizing'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The Journal of Strategic Information Systems,

>> Tokens are: 
 ['The', 'Journal', 'Strategic', 'Information', 'Systems', ',']

>> Bigrams are: 
 [('The', 'Journal'), ('Journal', 'Strategic'), ('Strategic', 'Information'), ('Information', 'Systems'), ('Systems', ',')]

>> Trigrams are: 
 [('The', 'Journal', 'Strategic'), ('Journal', 'Strategic', 'Information'), ('Strategic', 'Information', 'Systems'), ('Information', 'Systems', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('Journal', 'NNP'), ('Strategic', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['The Journal Strategic Information Systems']

>> Named Entities are: 
 [('ORGANIZATION', 'Journal Strategic Information Systems')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Journal', 'journal'), ('Strategic', 'strateg'), ('Information', 'inform'), ('Systems', 'system'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Journal', 'journal'), ('Strategic', 'strateg'), ('Information', 'inform'), ('Systems', 'system'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('Journal', 'Journal'), ('Strategic', 'Strategic'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ',')]



========================================== PARAGRAPH 1489 ===========================================

Volume 26, pp. 191-209.  

------------------- Sentence 1 -------------------

Volume 26, pp.

>> Tokens are: 
 ['Volume', '26', ',', 'pp', '.']

>> Bigrams are: 
 [('Volume', '26'), ('26', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Volume', '26', ','), ('26', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Volume', 'NN'), ('26', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Volume', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Volume', 'Volume'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

191-209.

>> Tokens are: 
 ['191-209', '.']

>> Bigrams are: 
 [('191-209', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('191-209', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('191-209', '191-209'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('191-209', '191-209'), ('.', '.')]

>> Lemmatization: 
 [('191-209', '191-209'), ('.', '.')]



========================================== PARAGRAPH 1490 ===========================================

H. Eszter, 2015. Is bigger always better? Potential biases of big data derived from social network  

------------------- Sentence 1 -------------------

H. Eszter, 2015.

>> Tokens are: 
 ['H.', 'Eszter', ',', '2015', '.']

>> Bigrams are: 
 [('H.', 'Eszter'), ('Eszter', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('H.', 'Eszter', ','), ('Eszter', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('H.', 'NNP'), ('Eszter', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['H. Eszter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('H.', 'H.'), ('Eszter', 'Eszter'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Is bigger always better?

>> Tokens are: 
 ['Is', 'bigger', 'always', 'better', '?']

>> Bigrams are: 
 [('Is', 'bigger'), ('bigger', 'always'), ('always', 'better'), ('better', '?')]

>> Trigrams are: 
 [('Is', 'bigger', 'always'), ('bigger', 'always', 'better'), ('always', 'better', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('bigger', 'JJR'), ('always', 'RB'), ('better', 'RBR'), ('?', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('bigger', 'bigger'), ('always', 'alway'), ('better', 'better'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('bigger', 'bigger'), ('always', 'alway'), ('better', 'better'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('bigger', 'bigger'), ('always', 'always'), ('better', 'better'), ('?', '?')]


------------------- Sentence 3 -------------------

Potential biases of big data derived from social network

>> Tokens are: 
 ['Potential', 'biases', 'big', 'data', 'derived', 'social', 'network']

>> Bigrams are: 
 [('Potential', 'biases'), ('biases', 'big'), ('big', 'data'), ('data', 'derived'), ('derived', 'social'), ('social', 'network')]

>> Trigrams are: 
 [('Potential', 'biases', 'big'), ('biases', 'big', 'data'), ('big', 'data', 'derived'), ('data', 'derived', 'social'), ('derived', 'social', 'network')]

>> POS Tags are: 
 [('Potential', 'JJ'), ('biases', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('derived', 'VBD'), ('social', 'JJ'), ('network', 'NN')]

>> Noun Phrases are: 
 ['Potential biases', 'big data', 'social network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Potential', 'potenti'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'deriv'), ('social', 'social'), ('network', 'network')]

>> Stemming using Snowball Stemmer: 
 [('Potential', 'potenti'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'deriv'), ('social', 'social'), ('network', 'network')]

>> Lemmatization: 
 [('Potential', 'Potential'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'derived'), ('social', 'social'), ('network', 'network')]



========================================== PARAGRAPH 1491 ===========================================

sites. The ANNALS of the American Academy of Political and Social Science journal, Volume 659,  

------------------- Sentence 1 -------------------

sites.

>> Tokens are: 
 ['sites', '.']

>> Bigrams are: 
 [('sites', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('sites', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['sites']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sites', 'site'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sites', 'site'), ('.', '.')]

>> Lemmatization: 
 [('sites', 'site'), ('.', '.')]


------------------- Sentence 2 -------------------

The ANNALS of the American Academy of Political and Social Science journal, Volume 659,

>> Tokens are: 
 ['The', 'ANNALS', 'American', 'Academy', 'Political', 'Social', 'Science', 'journal', ',', 'Volume', '659', ',']

>> Bigrams are: 
 [('The', 'ANNALS'), ('ANNALS', 'American'), ('American', 'Academy'), ('Academy', 'Political'), ('Political', 'Social'), ('Social', 'Science'), ('Science', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '659'), ('659', ',')]

>> Trigrams are: 
 [('The', 'ANNALS', 'American'), ('ANNALS', 'American', 'Academy'), ('American', 'Academy', 'Political'), ('Academy', 'Political', 'Social'), ('Political', 'Social', 'Science'), ('Social', 'Science', 'journal'), ('Science', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '659'), ('Volume', '659', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('ANNALS', 'NNP'), ('American', 'NNP'), ('Academy', 'NNP'), ('Political', 'NNP'), ('Social', 'NNP'), ('Science', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('659', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['The ANNALS American Academy Political Social Science journal', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'ANNALS American Academy'), ('ORGANIZATION', 'Volume 659')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ANNALS', 'annal'), ('American', 'american'), ('Academy', 'academi'), ('Political', 'polit'), ('Social', 'social'), ('Science', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('659', '659'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ANNALS', 'annal'), ('American', 'american'), ('Academy', 'academi'), ('Political', 'polit'), ('Social', 'social'), ('Science', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('659', '659'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('ANNALS', 'ANNALS'), ('American', 'American'), ('Academy', 'Academy'), ('Political', 'Political'), ('Social', 'Social'), ('Science', 'Science'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('659', '659'), (',', ',')]



========================================== PARAGRAPH 1492 ===========================================

pp. 63-76.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

63-76.

>> Tokens are: 
 ['63-76', '.']

>> Bigrams are: 
 [('63-76', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63-76', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63-76', '63-76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63-76', '63-76'), ('.', '.')]

>> Lemmatization: 
 [('63-76', '63-76'), ('.', '.')]



========================================== PARAGRAPH 1493 ===========================================

Hart, C., 2018. Doing a literature review: Releasing the research imagination.. s.l.:Sage.  

------------------- Sentence 1 -------------------

Hart, C., 2018.

>> Tokens are: 
 ['Hart', ',', 'C.', ',', '2018', '.']

>> Bigrams are: 
 [('Hart', ','), (',', 'C.'), ('C.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Hart', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Hart', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hart', 'C.']

>> Named Entities are: 
 [('GPE', 'Hart')] 

>> Stemming using Porter Stemmer: 
 [('Hart', 'hart'), (',', ','), ('C.', 'c.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hart', 'hart'), (',', ','), ('C.', 'c.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Hart', 'Hart'), (',', ','), ('C.', 'C.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Doing a literature review: Releasing the research imagination..

>> Tokens are: 
 ['Doing', 'literature', 'review', ':', 'Releasing', 'research', 'imagination', '..']

>> Bigrams are: 
 [('Doing', 'literature'), ('literature', 'review'), ('review', ':'), (':', 'Releasing'), ('Releasing', 'research'), ('research', 'imagination'), ('imagination', '..')]

>> Trigrams are: 
 [('Doing', 'literature', 'review'), ('literature', 'review', ':'), ('review', ':', 'Releasing'), (':', 'Releasing', 'research'), ('Releasing', 'research', 'imagination'), ('research', 'imagination', '..')]

>> POS Tags are: 
 [('Doing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (':', ':'), ('Releasing', 'NNP'), ('research', 'NN'), ('imagination', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['literature review', 'Releasing research imagination ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Doing', 'do'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('Releasing', 'releas'), ('research', 'research'), ('imagination', 'imagin'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Doing', 'do'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('Releasing', 'releas'), ('research', 'research'), ('imagination', 'imagin'), ('..', '..')]

>> Lemmatization: 
 [('Doing', 'Doing'), ('literature', 'literature'), ('review', 'review'), (':', ':'), ('Releasing', 'Releasing'), ('research', 'research'), ('imagination', 'imagination'), ('..', '..')]


------------------- Sentence 3 -------------------

s.l.

>> Tokens are: 
 ['s.l', '.']

>> Bigrams are: 
 [('s.l', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('s.l', 's.l'), ('.', '.')]


------------------- Sentence 4 -------------------

:Sage.

>> Tokens are: 
 [':', 'Sage', '.']

>> Bigrams are: 
 [(':', 'Sage'), ('Sage', '.')]

>> Trigrams are: 
 [(':', 'Sage', '.')]

>> POS Tags are: 
 [(':', ':'), ('Sage', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Sage', 'sage'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Sage', 'sage'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Sage', 'Sage'), ('.', '.')]



========================================== PARAGRAPH 1494 ===========================================

Hartmann, T., Fouquet, F., Moawad, A., Rouvoy, R. and Le Traon, Y., 2019. GreyCat: Efficient  

------------------- Sentence 1 -------------------

Hartmann, T., Fouquet, F., Moawad, A., Rouvoy, R. and Le Traon, Y., 2019.

>> Tokens are: 
 ['Hartmann', ',', 'T.', ',', 'Fouquet', ',', 'F.', ',', 'Moawad', ',', 'A.', ',', 'Rouvoy', ',', 'R.', 'Le', 'Traon', ',', 'Y.', ',', '2019', '.']

>> Bigrams are: 
 [('Hartmann', ','), (',', 'T.'), ('T.', ','), (',', 'Fouquet'), ('Fouquet', ','), (',', 'F.'), ('F.', ','), (',', 'Moawad'), ('Moawad', ','), (',', 'A.'), ('A.', ','), (',', 'Rouvoy'), ('Rouvoy', ','), (',', 'R.'), ('R.', 'Le'), ('Le', 'Traon'), ('Traon', ','), (',', 'Y.'), ('Y.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Hartmann', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Fouquet'), (',', 'Fouquet', ','), ('Fouquet', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Moawad'), (',', 'Moawad', ','), ('Moawad', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Rouvoy'), (',', 'Rouvoy', ','), ('Rouvoy', ',', 'R.'), (',', 'R.', 'Le'), ('R.', 'Le', 'Traon'), ('Le', 'Traon', ','), ('Traon', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Fouquet', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Moawad', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Rouvoy', 'NNP'), (',', ','), ('R.', 'NNP'), ('Le', 'NNP'), ('Traon', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hartmann', 'T.', 'Fouquet', 'F.', 'Moawad', 'A.', 'Rouvoy', 'R. Le Traon', 'Y.']

>> Named Entities are: 
 [('GPE', 'Hartmann'), ('PERSON', 'Fouquet'), ('GPE', 'Moawad'), ('GPE', 'Rouvoy')] 

>> Stemming using Porter Stemmer: 
 [('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), (',', ','), ('Fouquet', 'fouquet'), (',', ','), ('F.', 'f.'), (',', ','), ('Moawad', 'moawad'), (',', ','), ('A.', 'a.'), (',', ','), ('Rouvoy', 'rouvoy'), (',', ','), ('R.', 'r.'), ('Le', 'le'), ('Traon', 'traon'), (',', ','), ('Y.', 'y.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), (',', ','), ('Fouquet', 'fouquet'), (',', ','), ('F.', 'f.'), (',', ','), ('Moawad', 'moawad'), (',', ','), ('A.', 'a.'), (',', ','), ('Rouvoy', 'rouvoy'), (',', ','), ('R.', 'r.'), ('Le', 'le'), ('Traon', 'traon'), (',', ','), ('Y.', 'y.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), (',', ','), ('Fouquet', 'Fouquet'), (',', ','), ('F.', 'F.'), (',', ','), ('Moawad', 'Moawad'), (',', ','), ('A.', 'A.'), (',', ','), ('Rouvoy', 'Rouvoy'), (',', ','), ('R.', 'R.'), ('Le', 'Le'), ('Traon', 'Traon'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

GreyCat: Efficient

>> Tokens are: 
 ['GreyCat', ':', 'Efficient']

>> Bigrams are: 
 [('GreyCat', ':'), (':', 'Efficient')]

>> Trigrams are: 
 [('GreyCat', ':', 'Efficient')]

>> POS Tags are: 
 [('GreyCat', 'NN'), (':', ':'), ('Efficient', 'NN')]

>> Noun Phrases are: 
 ['GreyCat', 'Efficient']

>> Named Entities are: 
 [('GPE', 'GreyCat')] 

>> Stemming using Porter Stemmer: 
 [('GreyCat', 'greycat'), (':', ':'), ('Efficient', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('GreyCat', 'greycat'), (':', ':'), ('Efficient', 'effici')]

>> Lemmatization: 
 [('GreyCat', 'GreyCat'), (':', ':'), ('Efficient', 'Efficient')]



========================================== PARAGRAPH 1495 ===========================================

what-if analytics for data in motion at scale.. Information Systems journal.  

------------------- Sentence 1 -------------------

what-if analytics for data in motion at scale.. Information Systems journal.

>> Tokens are: 
 ['what-if', 'analytics', 'data', 'motion', 'scale', '..', 'Information', 'Systems', 'journal', '.']

>> Bigrams are: 
 [('what-if', 'analytics'), ('analytics', 'data'), ('data', 'motion'), ('motion', 'scale'), ('scale', '..'), ('..', 'Information'), ('Information', 'Systems'), ('Systems', 'journal'), ('journal', '.')]

>> Trigrams are: 
 [('what-if', 'analytics', 'data'), ('analytics', 'data', 'motion'), ('data', 'motion', 'scale'), ('motion', 'scale', '..'), ('scale', '..', 'Information'), ('..', 'Information', 'Systems'), ('Information', 'Systems', 'journal'), ('Systems', 'journal', '.')]

>> POS Tags are: 
 [('what-if', 'JJ'), ('analytics', 'NNS'), ('data', 'NNS'), ('motion', 'NN'), ('scale', 'NN'), ('..', 'JJ'), ('Information', 'NNP'), ('Systems', 'NNP'), ('journal', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['what-if analytics data motion scale', '.. Information Systems journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('what-if', 'what-if'), ('analytics', 'analyt'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'inform'), ('Systems', 'system'), ('journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('what-if', 'what-if'), ('analytics', 'analyt'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'inform'), ('Systems', 'system'), ('journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('what-if', 'what-if'), ('analytics', 'analytics'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'Information'), ('Systems', 'Systems'), ('journal', 'journal'), ('.', '.')]



========================================== PARAGRAPH 1496 ===========================================

Hasselt, H.V., 2010. Double Q-learning. s.l., s.n., pp. 2613-2621. 

------------------- Sentence 1 -------------------

Hasselt, H.V., 2010.

>> Tokens are: 
 ['Hasselt', ',', 'H.V.', ',', '2010', '.']

>> Bigrams are: 
 [('Hasselt', ','), (',', 'H.V.'), ('H.V.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Hasselt', ',', 'H.V.'), (',', 'H.V.', ','), ('H.V.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Hasselt', 'NNP'), (',', ','), ('H.V.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hasselt', 'H.V.']

>> Named Entities are: 
 [('GPE', 'Hasselt')] 

>> Stemming using Porter Stemmer: 
 [('Hasselt', 'hasselt'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasselt', 'hasselt'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Hasselt', 'Hasselt'), (',', ','), ('H.V.', 'H.V.'), (',', ','), ('2010', '2010'), ('.', '.')]


------------------- Sentence 2 -------------------

Double Q-learning.

>> Tokens are: 
 ['Double', 'Q-learning', '.']

>> Bigrams are: 
 [('Double', 'Q-learning'), ('Q-learning', '.')]

>> Trigrams are: 
 [('Double', 'Q-learning', '.')]

>> POS Tags are: 
 [('Double', 'JJ'), ('Q-learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Double Q-learning']

>> Named Entities are: 
 [('GPE', 'Double')] 

>> Stemming using Porter Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('.', '.')]

>> Lemmatization: 
 [('Double', 'Double'), ('Q-learning', 'Q-learning'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., s.n., pp.

>> Tokens are: 
 ['s.l.', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 's.n.', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

2613-2621.

>> Tokens are: 
 ['2613-2621', '.']

>> Bigrams are: 
 [('2613-2621', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2613-2621', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2613-2621', '2613-2621'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2613-2621', '2613-2621'), ('.', '.')]

>> Lemmatization: 
 [('2613-2621', '2613-2621'), ('.', '.')]



========================================== PARAGRAPH 1497 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1498 ===========================================

50  

------------------- Sentence 1 -------------------

50

>> Tokens are: 
 ['50']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('50', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('50', '50')]

>> Stemming using Snowball Stemmer: 
 [('50', '50')]

>> Lemmatization: 
 [('50', '50')]



========================================== PARAGRAPH 1499 ===========================================

  


========================================== PARAGRAPH 1500 ===========================================

He, Y., Lee, R., Huai, Y., Shao, Z., Jain, N., Zhang, X. and Xu, Z., 2011. RCFile: A fast and space- 

------------------- Sentence 1 -------------------

He, Y., Lee, R., Huai, Y., Shao, Z., Jain, N., Zhang, X. and Xu, Z., 2011.

>> Tokens are: 
 ['He', ',', 'Y.', ',', 'Lee', ',', 'R.', ',', 'Huai', ',', 'Y.', ',', 'Shao', ',', 'Z.', ',', 'Jain', ',', 'N.', ',', 'Zhang', ',', 'X.', 'Xu', ',', 'Z.', ',', '2011', '.']

>> Bigrams are: 
 [('He', ','), (',', 'Y.'), ('Y.', ','), (',', 'Lee'), ('Lee', ','), (',', 'R.'), ('R.', ','), (',', 'Huai'), ('Huai', ','), (',', 'Y.'), ('Y.', ','), (',', 'Shao'), ('Shao', ','), (',', 'Z.'), ('Z.', ','), (',', 'Jain'), ('Jain', ','), (',', 'N.'), ('N.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'X.'), ('X.', 'Xu'), ('Xu', ','), (',', 'Z.'), ('Z.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('He', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Lee'), (',', 'Lee', ','), ('Lee', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Huai'), (',', 'Huai', ','), ('Huai', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Shao'), (',', 'Shao', ','), ('Shao', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Jain'), (',', 'Jain', ','), ('Jain', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'X.'), (',', 'X.', 'Xu'), ('X.', 'Xu', ','), ('Xu', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('He', 'PRP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Lee', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Huai', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Shao', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Jain', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('X.', 'NNP'), ('Xu', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Y.', 'Lee', 'R.', 'Huai', 'Y.', 'Shao', 'Z.', 'Jain', 'N.', 'Zhang', 'X. Xu', 'Z.']

>> Named Entities are: 
 [('PERSON', 'Lee'), ('PERSON', 'Huai'), ('PERSON', 'Shao'), ('GPE', 'Jain'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('R.', 'r.'), (',', ','), ('Huai', 'huai'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shao', 'shao'), (',', ','), ('Z.', 'z.'), (',', ','), ('Jain', 'jain'), (',', ','), ('N.', 'n.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('X.', 'x.'), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('R.', 'r.'), (',', ','), ('Huai', 'huai'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shao', 'shao'), (',', ','), ('Z.', 'z.'), (',', ','), ('Jain', 'jain'), (',', ','), ('N.', 'n.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('X.', 'x.'), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('He', 'He'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Lee', 'Lee'), (',', ','), ('R.', 'R.'), (',', ','), ('Huai', 'Huai'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Shao', 'Shao'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Jain', 'Jain'), (',', ','), ('N.', 'N.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('X.', 'X.'), ('Xu', 'Xu'), (',', ','), ('Z.', 'Z.'), (',', ','), ('2011', '2011'), ('.', '.')]


------------------- Sentence 2 -------------------

RCFile: A fast and space-

>> Tokens are: 
 ['RCFile', ':', 'A', 'fast', 'space-']

>> Bigrams are: 
 [('RCFile', ':'), (':', 'A'), ('A', 'fast'), ('fast', 'space-')]

>> Trigrams are: 
 [('RCFile', ':', 'A'), (':', 'A', 'fast'), ('A', 'fast', 'space-')]

>> POS Tags are: 
 [('RCFile', 'NN'), (':', ':'), ('A', 'DT'), ('fast', 'JJ'), ('space-', 'NN')]

>> Noun Phrases are: 
 ['RCFile', 'A fast space-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('RCFile', 'rcfile'), (':', ':'), ('A', 'a'), ('fast', 'fast'), ('space-', 'space-')]

>> Stemming using Snowball Stemmer: 
 [('RCFile', 'rcfile'), (':', ':'), ('A', 'a'), ('fast', 'fast'), ('space-', 'space-')]

>> Lemmatization: 
 [('RCFile', 'RCFile'), (':', ':'), ('A', 'A'), ('fast', 'fast'), ('space-', 'space-')]



========================================== PARAGRAPH 1501 ===========================================

efficient data placement structure in MapReduce-based warehouse systems. s.l., IEEE, pp. 1199- 

------------------- Sentence 1 -------------------

efficient data placement structure in MapReduce-based warehouse systems.

>> Tokens are: 
 ['efficient', 'data', 'placement', 'structure', 'MapReduce-based', 'warehouse', 'systems', '.']

>> Bigrams are: 
 [('efficient', 'data'), ('data', 'placement'), ('placement', 'structure'), ('structure', 'MapReduce-based'), ('MapReduce-based', 'warehouse'), ('warehouse', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('efficient', 'data', 'placement'), ('data', 'placement', 'structure'), ('placement', 'structure', 'MapReduce-based'), ('structure', 'MapReduce-based', 'warehouse'), ('MapReduce-based', 'warehouse', 'systems'), ('warehouse', 'systems', '.')]

>> POS Tags are: 
 [('efficient', 'JJ'), ('data', 'NNS'), ('placement', 'NN'), ('structure', 'NN'), ('MapReduce-based', 'JJ'), ('warehouse', 'NN'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['efficient data placement structure', 'MapReduce-based warehouse systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('efficient', 'effici'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('MapReduce-based', 'mapreduce-bas'), ('warehouse', 'warehous'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('efficient', 'effici'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('MapReduce-based', 'mapreduce-bas'), ('warehouse', 'warehous'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('efficient', 'efficient'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structure'), ('MapReduce-based', 'MapReduce-based'), ('warehouse', 'warehouse'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

s.l., IEEE, pp.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1199-

>> Tokens are: 
 ['1199-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1199-', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1199-', '1199-')]

>> Stemming using Snowball Stemmer: 
 [('1199-', '1199-')]

>> Lemmatization: 
 [('1199-', '1199-')]



========================================== PARAGRAPH 1502 ===========================================

12.  

------------------- Sentence 1 -------------------

12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]



========================================== PARAGRAPH 1503 ===========================================

He, Y., Yu, F.R., Zhao, N., Yin, H., Yao, H. and Qiu, R.C., 2016. Big data analytics in mobile  

------------------- Sentence 1 -------------------

He, Y., Yu, F.R., Zhao, N., Yin, H., Yao, H. and Qiu, R.C., 2016.

>> Tokens are: 
 ['He', ',', 'Y.', ',', 'Yu', ',', 'F.R.', ',', 'Zhao', ',', 'N.', ',', 'Yin', ',', 'H.', ',', 'Yao', ',', 'H.', 'Qiu', ',', 'R.C.', ',', '2016', '.']

>> Bigrams are: 
 [('He', ','), (',', 'Y.'), ('Y.', ','), (',', 'Yu'), ('Yu', ','), (',', 'F.R.'), ('F.R.', ','), (',', 'Zhao'), ('Zhao', ','), (',', 'N.'), ('N.', ','), (',', 'Yin'), ('Yin', ','), (',', 'H.'), ('H.', ','), (',', 'Yao'), ('Yao', ','), (',', 'H.'), ('H.', 'Qiu'), ('Qiu', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('He', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Yu'), (',', 'Yu', ','), ('Yu', ',', 'F.R.'), (',', 'F.R.', ','), ('F.R.', ',', 'Zhao'), (',', 'Zhao', ','), ('Zhao', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Yin'), (',', 'Yin', ','), ('Yin', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Yao'), (',', 'Yao', ','), ('Yao', ',', 'H.'), (',', 'H.', 'Qiu'), ('H.', 'Qiu', ','), ('Qiu', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('He', 'PRP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Yu', 'NNP'), (',', ','), ('F.R.', 'NNP'), (',', ','), ('Zhao', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Yin', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Yao', 'NNP'), (',', ','), ('H.', 'NNP'), ('Qiu', 'NNP'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Y.', 'Yu', 'F.R.', 'Zhao', 'N.', 'Yin', 'H.', 'Yao', 'H. Qiu', 'R.C.']

>> Named Entities are: 
 [('GPE', 'Yu'), ('PERSON', 'Zhao'), ('PERSON', 'Yin'), ('PERSON', 'Yao')] 

>> Stemming using Porter Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yu', 'yu'), (',', ','), ('F.R.', 'f.r.'), (',', ','), ('Zhao', 'zhao'), (',', ','), ('N.', 'n.'), (',', ','), ('Yin', 'yin'), (',', ','), ('H.', 'h.'), (',', ','), ('Yao', 'yao'), (',', ','), ('H.', 'h.'), ('Qiu', 'qiu'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yu', 'yu'), (',', ','), ('F.R.', 'f.r.'), (',', ','), ('Zhao', 'zhao'), (',', ','), ('N.', 'n.'), (',', ','), ('Yin', 'yin'), (',', ','), ('H.', 'h.'), (',', ','), ('Yao', 'yao'), (',', ','), ('H.', 'h.'), ('Qiu', 'qiu'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('He', 'He'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Yu', 'Yu'), (',', ','), ('F.R.', 'F.R.'), (',', ','), ('Zhao', 'Zhao'), (',', ','), ('N.', 'N.'), (',', ','), ('Yin', 'Yin'), (',', ','), ('H.', 'H.'), (',', ','), ('Yao', 'Yao'), (',', ','), ('H.', 'H.'), ('Qiu', 'Qiu'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics in mobile

>> Tokens are: 
 ['Big', 'data', 'analytics', 'mobile']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'mobile')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'mobile')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('mobile', 'JJ')]

>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('mobile', 'mobil')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('mobile', 'mobil')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('mobile', 'mobile')]



========================================== PARAGRAPH 1504 ===========================================

cellular networks. IEEE access, Volume 4, pp. 1985-1996.  

------------------- Sentence 1 -------------------

cellular networks.

>> Tokens are: 
 ['cellular', 'networks', '.']

>> Bigrams are: 
 [('cellular', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('cellular', 'networks', '.')]

>> POS Tags are: 
 [('cellular', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['cellular networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE access, Volume 4, pp.

>> Tokens are: 
 ['IEEE', 'access', ',', 'Volume', '4', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'access'), ('access', ','), (',', 'Volume'), ('Volume', '4'), ('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'access', ','), ('access', ',', 'Volume'), (',', 'Volume', '4'), ('Volume', '4', ','), ('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('access', 'NN'), (',', ','), ('Volume', 'NN'), ('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE access', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('access', 'access'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('access', 'access'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('access', 'access'), (',', ','), ('Volume', 'Volume'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1985-1996.

>> Tokens are: 
 ['1985-1996', '.']

>> Bigrams are: 
 [('1985-1996', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1985-1996', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1985-1996', '1985-1996'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1985-1996', '1985-1996'), ('.', '.')]

>> Lemmatization: 
 [('1985-1996', '1985-1996'), ('.', '.')]



========================================== PARAGRAPH 1505 ===========================================

Hester, T., Vecerik, M., Pietquin, O., Lanctot, M., Schaul, T., Piot, B., Horgan, D., Quan, J.,  

------------------- Sentence 1 -------------------

Hester, T., Vecerik, M., Pietquin, O., Lanctot, M., Schaul, T., Piot, B., Horgan, D., Quan, J.,

>> Tokens are: 
 ['Hester', ',', 'T.', ',', 'Vecerik', ',', 'M.', ',', 'Pietquin', ',', 'O.', ',', 'Lanctot', ',', 'M.', ',', 'Schaul', ',', 'T.', ',', 'Piot', ',', 'B.', ',', 'Horgan', ',', 'D.', ',', 'Quan', ',', 'J.', ',']

>> Bigrams are: 
 [('Hester', ','), (',', 'T.'), ('T.', ','), (',', 'Vecerik'), ('Vecerik', ','), (',', 'M.'), ('M.', ','), (',', 'Pietquin'), ('Pietquin', ','), (',', 'O.'), ('O.', ','), (',', 'Lanctot'), ('Lanctot', ','), (',', 'M.'), ('M.', ','), (',', 'Schaul'), ('Schaul', ','), (',', 'T.'), ('T.', ','), (',', 'Piot'), ('Piot', ','), (',', 'B.'), ('B.', ','), (',', 'Horgan'), ('Horgan', ','), (',', 'D.'), ('D.', ','), (',', 'Quan'), ('Quan', ','), (',', 'J.'), ('J.', ',')]

>> Trigrams are: 
 [('Hester', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Vecerik'), (',', 'Vecerik', ','), ('Vecerik', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Pietquin'), (',', 'Pietquin', ','), ('Pietquin', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Lanctot'), (',', 'Lanctot', ','), ('Lanctot', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Schaul'), (',', 'Schaul', ','), ('Schaul', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Piot'), (',', 'Piot', ','), ('Piot', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Horgan'), (',', 'Horgan', ','), ('Horgan', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Quan'), (',', 'Quan', ','), ('Quan', ',', 'J.'), (',', 'J.', ',')]

>> POS Tags are: 
 [('Hester', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Vecerik', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Pietquin', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Lanctot', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Schaul', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Piot', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Horgan', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Quan', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Hester', 'T.', 'Vecerik', 'M.', 'Pietquin', 'O.', 'Lanctot', 'M.', 'Schaul', 'T.', 'Piot', 'B.', 'Horgan', 'D.', 'Quan', 'J.']

>> Named Entities are: 
 [('GPE', 'Hester'), ('PERSON', 'Vecerik'), ('GPE', 'Pietquin'), ('PERSON', 'Lanctot'), ('PERSON', 'Schaul'), ('GPE', 'Piot'), ('GPE', 'Horgan'), ('PERSON', 'Quan')] 

>> Stemming using Porter Stemmer: 
 [('Hester', 'hester'), (',', ','), ('T.', 't.'), (',', ','), ('Vecerik', 'vecerik'), (',', ','), ('M.', 'm.'), (',', ','), ('Pietquin', 'pietquin'), (',', ','), ('O.', 'o.'), (',', ','), ('Lanctot', 'lanctot'), (',', ','), ('M.', 'm.'), (',', ','), ('Schaul', 'schaul'), (',', ','), ('T.', 't.'), (',', ','), ('Piot', 'piot'), (',', ','), ('B.', 'b.'), (',', ','), ('Horgan', 'horgan'), (',', ','), ('D.', 'd.'), (',', ','), ('Quan', 'quan'), (',', ','), ('J.', 'j.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Hester', 'hester'), (',', ','), ('T.', 't.'), (',', ','), ('Vecerik', 'vecerik'), (',', ','), ('M.', 'm.'), (',', ','), ('Pietquin', 'pietquin'), (',', ','), ('O.', 'o.'), (',', ','), ('Lanctot', 'lanctot'), (',', ','), ('M.', 'm.'), (',', ','), ('Schaul', 'schaul'), (',', ','), ('T.', 't.'), (',', ','), ('Piot', 'piot'), (',', ','), ('B.', 'b.'), (',', ','), ('Horgan', 'horgan'), (',', ','), ('D.', 'd.'), (',', ','), ('Quan', 'quan'), (',', ','), ('J.', 'j.'), (',', ',')]

>> Lemmatization: 
 [('Hester', 'Hester'), (',', ','), ('T.', 'T.'), (',', ','), ('Vecerik', 'Vecerik'), (',', ','), ('M.', 'M.'), (',', ','), ('Pietquin', 'Pietquin'), (',', ','), ('O.', 'O.'), (',', ','), ('Lanctot', 'Lanctot'), (',', ','), ('M.', 'M.'), (',', ','), ('Schaul', 'Schaul'), (',', ','), ('T.', 'T.'), (',', ','), ('Piot', 'Piot'), (',', ','), ('B.', 'B.'), (',', ','), ('Horgan', 'Horgan'), (',', ','), ('D.', 'D.'), (',', ','), ('Quan', 'Quan'), (',', ','), ('J.', 'J.'), (',', ',')]



========================================== PARAGRAPH 1506 ===========================================

Sendonaris, A., Osband, I. and Dulac-Arnold, G., 2018. Deep q-learning from demonstrations. s.l.,  

------------------- Sentence 1 -------------------

Sendonaris, A., Osband, I. and Dulac-Arnold, G., 2018.

>> Tokens are: 
 ['Sendonaris', ',', 'A.', ',', 'Osband', ',', 'I.', 'Dulac-Arnold', ',', 'G.', ',', '2018', '.']

>> Bigrams are: 
 [('Sendonaris', ','), (',', 'A.'), ('A.', ','), (',', 'Osband'), ('Osband', ','), (',', 'I.'), ('I.', 'Dulac-Arnold'), ('Dulac-Arnold', ','), (',', 'G.'), ('G.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Sendonaris', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Osband'), (',', 'Osband', ','), ('Osband', ',', 'I.'), (',', 'I.', 'Dulac-Arnold'), ('I.', 'Dulac-Arnold', ','), ('Dulac-Arnold', ',', 'G.'), (',', 'G.', ','), ('G.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Sendonaris', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Osband', 'NNP'), (',', ','), ('I.', 'NNP'), ('Dulac-Arnold', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Sendonaris', 'A.', 'Osband', 'I. Dulac-Arnold', 'G.']

>> Named Entities are: 
 [('GPE', 'Sendonaris'), ('GPE', 'Osband')] 

>> Stemming using Porter Stemmer: 
 [('Sendonaris', 'sendonari'), (',', ','), ('A.', 'a.'), (',', ','), ('Osband', 'osband'), (',', ','), ('I.', 'i.'), ('Dulac-Arnold', 'dulac-arnold'), (',', ','), ('G.', 'g.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sendonaris', 'sendonari'), (',', ','), ('A.', 'a.'), (',', ','), ('Osband', 'osband'), (',', ','), ('I.', 'i.'), ('Dulac-Arnold', 'dulac-arnold'), (',', ','), ('G.', 'g.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Sendonaris', 'Sendonaris'), (',', ','), ('A.', 'A.'), (',', ','), ('Osband', 'Osband'), (',', ','), ('I.', 'I.'), ('Dulac-Arnold', 'Dulac-Arnold'), (',', ','), ('G.', 'G.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep q-learning from demonstrations.

>> Tokens are: 
 ['Deep', 'q-learning', 'demonstrations', '.']

>> Bigrams are: 
 [('Deep', 'q-learning'), ('q-learning', 'demonstrations'), ('demonstrations', '.')]

>> Trigrams are: 
 [('Deep', 'q-learning', 'demonstrations'), ('q-learning', 'demonstrations', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('q-learning', 'JJ'), ('demonstrations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep q-learning demonstrations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('q-learning', 'q-learn'), ('demonstrations', 'demonstr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('q-learning', 'q-learn'), ('demonstrations', 'demonstr'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('q-learning', 'q-learning'), ('demonstrations', 'demonstration'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l.,

>> Tokens are: 
 ['s.l.', ',']

>> Bigrams are: 
 [('s.l.', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['s.l.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ',')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ',')]



========================================== PARAGRAPH 1507 ===========================================

s.n.  

------------------- Sentence 1 -------------------

s.n.

>> Tokens are: 
 ['s.n', '.']

>> Bigrams are: 
 [('s.n', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('s.n', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.n', 's.n'), ('.', '.')]



========================================== PARAGRAPH 1508 ===========================================

Hofmann, E. and Rutschmann, E., 2018. Big data analytics and demand forecasting in supply  

------------------- Sentence 1 -------------------

Hofmann, E. and Rutschmann, E., 2018.

>> Tokens are: 
 ['Hofmann', ',', 'E.', 'Rutschmann', ',', 'E.', ',', '2018', '.']

>> Bigrams are: 
 [('Hofmann', ','), (',', 'E.'), ('E.', 'Rutschmann'), ('Rutschmann', ','), (',', 'E.'), ('E.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Hofmann', ',', 'E.'), (',', 'E.', 'Rutschmann'), ('E.', 'Rutschmann', ','), ('Rutschmann', ',', 'E.'), (',', 'E.', ','), ('E.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Hofmann', 'NNP'), (',', ','), ('E.', 'NNP'), ('Rutschmann', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hofmann', 'E. Rutschmann', 'E.']

>> Named Entities are: 
 [('GPE', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('Hofmann', 'hofmann'), (',', ','), ('E.', 'e.'), ('Rutschmann', 'rutschmann'), (',', ','), ('E.', 'e.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hofmann', 'hofmann'), (',', ','), ('E.', 'e.'), ('Rutschmann', 'rutschmann'), (',', ','), ('E.', 'e.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Hofmann', 'Hofmann'), (',', ','), ('E.', 'E.'), ('Rutschmann', 'Rutschmann'), (',', ','), ('E.', 'E.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics and demand forecasting in supply

>> Tokens are: 
 ['Big', 'data', 'analytics', 'demand', 'forecasting', 'supply']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'demand'), ('demand', 'forecasting'), ('forecasting', 'supply')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'demand'), ('analytics', 'demand', 'forecasting'), ('demand', 'forecasting', 'supply')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('demand', 'VBP'), ('forecasting', 'VBG'), ('supply', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics', 'supply']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('demand', 'demand'), ('forecasting', 'forecast'), ('supply', 'suppli')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('demand', 'demand'), ('forecasting', 'forecast'), ('supply', 'suppli')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('demand', 'demand'), ('forecasting', 'forecasting'), ('supply', 'supply')]



========================================== PARAGRAPH 1509 ===========================================

chains: a conceptual analysis.. The International Journal of Logistics Management, Volume 29,  

------------------- Sentence 1 -------------------

chains: a conceptual analysis..

>> Tokens are: 
 ['chains', ':', 'conceptual', 'analysis', '..']

>> Bigrams are: 
 [('chains', ':'), (':', 'conceptual'), ('conceptual', 'analysis'), ('analysis', '..')]

>> Trigrams are: 
 [('chains', ':', 'conceptual'), (':', 'conceptual', 'analysis'), ('conceptual', 'analysis', '..')]

>> POS Tags are: 
 [('chains', 'NNS'), (':', ':'), ('conceptual', 'JJ'), ('analysis', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['chains', 'conceptual analysis ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('chains', 'chain'), (':', ':'), ('conceptual', 'conceptu'), ('analysis', 'analysi'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('chains', 'chain'), (':', ':'), ('conceptual', 'conceptu'), ('analysis', 'analysi'), ('..', '..')]

>> Lemmatization: 
 [('chains', 'chain'), (':', ':'), ('conceptual', 'conceptual'), ('analysis', 'analysis'), ('..', '..')]


------------------- Sentence 2 -------------------

The International Journal of Logistics Management, Volume 29,

>> Tokens are: 
 ['The', 'International', 'Journal', 'Logistics', 'Management', ',', 'Volume', '29', ',']

>> Bigrams are: 
 [('The', 'International'), ('International', 'Journal'), ('Journal', 'Logistics'), ('Logistics', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '29'), ('29', ',')]

>> Trigrams are: 
 [('The', 'International', 'Journal'), ('International', 'Journal', 'Logistics'), ('Journal', 'Logistics', 'Management'), ('Logistics', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '29'), ('Volume', '29', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('International', 'NNP'), ('Journal', 'NNP'), ('Logistics', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('29', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['The International Journal Logistics Management', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Logistics Management'), ('ORGANIZATION', 'Volume 29')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('International', 'intern'), ('Journal', 'journal'), ('Logistics', 'logist'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('29', '29'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('International', 'intern'), ('Journal', 'journal'), ('Logistics', 'logist'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('29', '29'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('International', 'International'), ('Journal', 'Journal'), ('Logistics', 'Logistics'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('29', '29'), (',', ',')]



========================================== PARAGRAPH 1510 ===========================================

pp. 739-766.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

739-766.

>> Tokens are: 
 ['739-766', '.']

>> Bigrams are: 
 [('739-766', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('739-766', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('739-766', '739-766'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('739-766', '739-766'), ('.', '.')]

>> Lemmatization: 
 [('739-766', '739-766'), ('.', '.')]



========================================== PARAGRAPH 1511 ===========================================

Jagadish, H.V., Gehrke, J., Labrinidis, A., Papakonstantinou, Y., Patel, J.M., Ramakrishnan, R.  

------------------- Sentence 1 -------------------

Jagadish, H.V., Gehrke, J., Labrinidis, A., Papakonstantinou, Y., Patel, J.M., Ramakrishnan, R.

>> Tokens are: 
 ['Jagadish', ',', 'H.V.', ',', 'Gehrke', ',', 'J.', ',', 'Labrinidis', ',', 'A.', ',', 'Papakonstantinou', ',', 'Y.', ',', 'Patel', ',', 'J.M.', ',', 'Ramakrishnan', ',', 'R', '.']

>> Bigrams are: 
 [('Jagadish', ','), (',', 'H.V.'), ('H.V.', ','), (',', 'Gehrke'), ('Gehrke', ','), (',', 'J.'), ('J.', ','), (',', 'Labrinidis'), ('Labrinidis', ','), (',', 'A.'), ('A.', ','), (',', 'Papakonstantinou'), ('Papakonstantinou', ','), (',', 'Y.'), ('Y.', ','), (',', 'Patel'), ('Patel', ','), (',', 'J.M.'), ('J.M.', ','), (',', 'Ramakrishnan'), ('Ramakrishnan', ','), (',', 'R'), ('R', '.')]

>> Trigrams are: 
 [('Jagadish', ',', 'H.V.'), (',', 'H.V.', ','), ('H.V.', ',', 'Gehrke'), (',', 'Gehrke', ','), ('Gehrke', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Labrinidis'), (',', 'Labrinidis', ','), ('Labrinidis', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Papakonstantinou'), (',', 'Papakonstantinou', ','), ('Papakonstantinou', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Patel'), (',', 'Patel', ','), ('Patel', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', 'Ramakrishnan'), (',', 'Ramakrishnan', ','), ('Ramakrishnan', ',', 'R'), (',', 'R', '.')]

>> POS Tags are: 
 [('Jagadish', 'JJ'), (',', ','), ('H.V.', 'NNP'), (',', ','), ('Gehrke', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Labrinidis', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Papakonstantinou', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Patel', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('Ramakrishnan', 'NNP'), (',', ','), ('R', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['H.V.', 'Gehrke', 'J.', 'Labrinidis', 'A.', 'Papakonstantinou', 'Y.', 'Patel', 'J.M.', 'Ramakrishnan', 'R']

>> Named Entities are: 
 [('GPE', 'Jagadish'), ('GPE', 'Gehrke'), ('ORGANIZATION', 'Labrinidis'), ('PERSON', 'Papakonstantinou'), ('PERSON', 'Patel'), ('PERSON', 'Ramakrishnan')] 

>> Stemming using Porter Stemmer: 
 [('Jagadish', 'jagadish'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('Gehrke', 'gehrk'), (',', ','), ('J.', 'j.'), (',', ','), ('Labrinidis', 'labrinidi'), (',', ','), ('A.', 'a.'), (',', ','), ('Papakonstantinou', 'papakonstantin'), (',', ','), ('Y.', 'y.'), (',', ','), ('Patel', 'patel'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), (',', ','), ('R', 'r'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jagadish', 'jagadish'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('Gehrke', 'gehrk'), (',', ','), ('J.', 'j.'), (',', ','), ('Labrinidis', 'labrinidi'), (',', ','), ('A.', 'a.'), (',', ','), ('Papakonstantinou', 'papakonstantinou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Patel', 'patel'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), (',', ','), ('R', 'r'), ('.', '.')]

>> Lemmatization: 
 [('Jagadish', 'Jagadish'), (',', ','), ('H.V.', 'H.V.'), (',', ','), ('Gehrke', 'Gehrke'), (',', ','), ('J.', 'J.'), (',', ','), ('Labrinidis', 'Labrinidis'), (',', ','), ('A.', 'A.'), (',', ','), ('Papakonstantinou', 'Papakonstantinou'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Patel', 'Patel'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('Ramakrishnan', 'Ramakrishnan'), (',', ','), ('R', 'R'), ('.', '.')]



========================================== PARAGRAPH 1512 ===========================================

and Shahabi, C., 2014. Big data and its technical challenges. Communications of the ACM, Volume  

------------------- Sentence 1 -------------------

and Shahabi, C., 2014.

>> Tokens are: 
 ['Shahabi', ',', 'C.', ',', '2014', '.']

>> Bigrams are: 
 [('Shahabi', ','), (',', 'C.'), ('C.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Shahabi', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Shahabi', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Shahabi', 'C.']

>> Named Entities are: 
 [('GPE', 'Shahabi')] 

>> Stemming using Porter Stemmer: 
 [('Shahabi', 'shahabi'), (',', ','), ('C.', 'c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Shahabi', 'shahabi'), (',', ','), ('C.', 'c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Shahabi', 'Shahabi'), (',', ','), ('C.', 'C.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data and its technical challenges.

>> Tokens are: 
 ['Big', 'data', 'technical', 'challenges', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'technical'), ('technical', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('Big', 'data', 'technical'), ('data', 'technical', 'challenges'), ('technical', 'challenges', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'technical challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('technical', 'technical'), ('challenges', 'challenge'), ('.', '.')]


------------------- Sentence 3 -------------------

Communications of the ACM, Volume

>> Tokens are: 
 ['Communications', 'ACM', ',', 'Volume']

>> Bigrams are: 
 [('Communications', 'ACM'), ('ACM', ','), (',', 'Volume')]

>> Trigrams are: 
 [('Communications', 'ACM', ','), ('ACM', ',', 'Volume')]

>> POS Tags are: 
 [('Communications', 'NNS'), ('ACM', 'NNP'), (',', ','), ('Volume', 'NN')]

>> Noun Phrases are: 
 ['Communications ACM', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('PERSON', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Communications', 'commun'), ('ACM', 'acm'), (',', ','), ('Volume', 'volum')]

>> Stemming using Snowball Stemmer: 
 [('Communications', 'communic'), ('ACM', 'acm'), (',', ','), ('Volume', 'volum')]

>> Lemmatization: 
 [('Communications', 'Communications'), ('ACM', 'ACM'), (',', ','), ('Volume', 'Volume')]



========================================== PARAGRAPH 1513 ===========================================

57, pp. 86-94.  

------------------- Sentence 1 -------------------

57, pp.

>> Tokens are: 
 ['57', ',', 'pp', '.']

>> Bigrams are: 
 [('57', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('57', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('57', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

86-94.

>> Tokens are: 
 ['86-94', '.']

>> Bigrams are: 
 [('86-94', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('86-94', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('86-94', '86-94'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('86-94', '86-94'), ('.', '.')]

>> Lemmatization: 
 [('86-94', '86-94'), ('.', '.')]



========================================== PARAGRAPH 1514 ===========================================

Jiang, C., Zhang, H., Ren, Y., Han, Z., Chen, K.C. and Hanzo, L., 2017. Machine learning  

------------------- Sentence 1 -------------------

Jiang, C., Zhang, H., Ren, Y., Han, Z., Chen, K.C.

>> Tokens are: 
 ['Jiang', ',', 'C.', ',', 'Zhang', ',', 'H.', ',', 'Ren', ',', 'Y.', ',', 'Han', ',', 'Z.', ',', 'Chen', ',', 'K.C', '.']

>> Bigrams are: 
 [('Jiang', ','), (',', 'C.'), ('C.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'H.'), ('H.', ','), (',', 'Ren'), ('Ren', ','), (',', 'Y.'), ('Y.', ','), (',', 'Han'), ('Han', ','), (',', 'Z.'), ('Z.', ','), (',', 'Chen'), ('Chen', ','), (',', 'K.C'), ('K.C', '.')]

>> Trigrams are: 
 [('Jiang', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Ren'), (',', 'Ren', ','), ('Ren', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Han'), (',', 'Han', ','), ('Han', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Chen'), (',', 'Chen', ','), ('Chen', ',', 'K.C'), (',', 'K.C', '.')]

>> POS Tags are: 
 [('Jiang', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Ren', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Han', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Chen', 'NNP'), (',', ','), ('K.C', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Jiang', 'C.', 'Zhang', 'H.', 'Ren', 'Y.', 'Han', 'Z.', 'Chen', 'K.C']

>> Named Entities are: 
 [('PERSON', 'Jiang'), ('PERSON', 'Zhang'), ('PERSON', 'Ren'), ('PERSON', 'Han'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Jiang', 'jiang'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.', 'h.'), (',', ','), ('Ren', 'ren'), (',', ','), ('Y.', 'y.'), (',', ','), ('Han', 'han'), (',', ','), ('Z.', 'z.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.C', 'k.c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jiang', 'jiang'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.', 'h.'), (',', ','), ('Ren', 'ren'), (',', ','), ('Y.', 'y.'), (',', ','), ('Han', 'han'), (',', ','), ('Z.', 'z.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.C', 'k.c'), ('.', '.')]

>> Lemmatization: 
 [('Jiang', 'Jiang'), (',', ','), ('C.', 'C.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('H.', 'H.'), (',', ','), ('Ren', 'Ren'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Han', 'Han'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Chen', 'Chen'), (',', ','), ('K.C', 'K.C'), ('.', '.')]


------------------- Sentence 2 -------------------

and Hanzo, L., 2017.

>> Tokens are: 
 ['Hanzo', ',', 'L.', ',', '2017', '.']

>> Bigrams are: 
 [('Hanzo', ','), (',', 'L.'), ('L.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Hanzo', ',', 'L.'), (',', 'L.', ','), ('L.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Hanzo', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hanzo', 'L.']

>> Named Entities are: 
 [('GPE', 'Hanzo')] 

>> Stemming using Porter Stemmer: 
 [('Hanzo', 'hanzo'), (',', ','), ('L.', 'l.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hanzo', 'hanzo'), (',', ','), ('L.', 'l.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Hanzo', 'Hanzo'), (',', ','), ('L.', 'L.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 3 -------------------

Machine learning

>> Tokens are: 
 ['Machine', 'learning']

>> Bigrams are: 
 [('Machine', 'learning')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Machine learning']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning')]



========================================== PARAGRAPH 1515 ===========================================

paradigms for next-generation wireless networks.. IEEE Wireless Communications journal,  

------------------- Sentence 1 -------------------

paradigms for next-generation wireless networks.. IEEE Wireless Communications journal,

>> Tokens are: 
 ['paradigms', 'next-generation', 'wireless', 'networks', '..', 'IEEE', 'Wireless', 'Communications', 'journal', ',']

>> Bigrams are: 
 [('paradigms', 'next-generation'), ('next-generation', 'wireless'), ('wireless', 'networks'), ('networks', '..'), ('..', 'IEEE'), ('IEEE', 'Wireless'), ('Wireless', 'Communications'), ('Communications', 'journal'), ('journal', ',')]

>> Trigrams are: 
 [('paradigms', 'next-generation', 'wireless'), ('next-generation', 'wireless', 'networks'), ('wireless', 'networks', '..'), ('networks', '..', 'IEEE'), ('..', 'IEEE', 'Wireless'), ('IEEE', 'Wireless', 'Communications'), ('Wireless', 'Communications', 'journal'), ('Communications', 'journal', ',')]

>> POS Tags are: 
 [('paradigms', 'JJ'), ('next-generation', 'NN'), ('wireless', 'NN'), ('networks', 'NNS'), ('..', 'VBP'), ('IEEE', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), ('journal', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['paradigms next-generation wireless networks', 'IEEE Wireless Communications journal']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Wireless Communications')] 

>> Stemming using Porter Stemmer: 
 [('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'commun'), ('journal', 'journal'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'communic'), ('journal', 'journal'), (',', ',')]

>> Lemmatization: 
 [('paradigms', 'paradigm'), ('next-generation', 'next-generation'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'IEEE'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), ('journal', 'journal'), (',', ',')]



========================================== PARAGRAPH 1516 ===========================================

Volume 24, pp. 98-105.  

------------------- Sentence 1 -------------------

Volume 24, pp.

>> Tokens are: 
 ['Volume', '24', ',', 'pp', '.']

>> Bigrams are: 
 [('Volume', '24'), ('24', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Volume', '24', ','), ('24', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Volume', 'NN'), ('24', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Volume', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Volume', 'volum'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Volume', 'volum'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Volume', 'Volume'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

98-105.

>> Tokens are: 
 ['98-105', '.']

>> Bigrams are: 
 [('98-105', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('98-105', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98-105', '98-105'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98-105', '98-105'), ('.', '.')]

>> Lemmatization: 
 [('98-105', '98-105'), ('.', '.')]



========================================== PARAGRAPH 1517 ===========================================

Karpovsky, A. and Galliers, R.D., 2015. Aligning in practice: from current cases to a new agenda.  

------------------- Sentence 1 -------------------

Karpovsky, A. and Galliers, R.D., 2015.

>> Tokens are: 
 ['Karpovsky', ',', 'A.', 'Galliers', ',', 'R.D.', ',', '2015', '.']

>> Bigrams are: 
 [('Karpovsky', ','), (',', 'A.'), ('A.', 'Galliers'), ('Galliers', ','), (',', 'R.D.'), ('R.D.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Karpovsky', ',', 'A.'), (',', 'A.', 'Galliers'), ('A.', 'Galliers', ','), ('Galliers', ',', 'R.D.'), (',', 'R.D.', ','), ('R.D.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Karpovsky', 'NNP'), (',', ','), ('A.', 'NNP'), ('Galliers', 'NNP'), (',', ','), ('R.D.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Karpovsky', 'A. Galliers', 'R.D.']

>> Named Entities are: 
 [('GPE', 'Karpovsky')] 

>> Stemming using Porter Stemmer: 
 [('Karpovsky', 'karpovski'), (',', ','), ('A.', 'a.'), ('Galliers', 'gallier'), (',', ','), ('R.D.', 'r.d.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Karpovsky', 'karpovski'), (',', ','), ('A.', 'a.'), ('Galliers', 'gallier'), (',', ','), ('R.D.', 'r.d.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Karpovsky', 'Karpovsky'), (',', ','), ('A.', 'A.'), ('Galliers', 'Galliers'), (',', ','), ('R.D.', 'R.D.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Aligning in practice: from current cases to a new agenda.

>> Tokens are: 
 ['Aligning', 'practice', ':', 'current', 'cases', 'new', 'agenda', '.']

>> Bigrams are: 
 [('Aligning', 'practice'), ('practice', ':'), (':', 'current'), ('current', 'cases'), ('cases', 'new'), ('new', 'agenda'), ('agenda', '.')]

>> Trigrams are: 
 [('Aligning', 'practice', ':'), ('practice', ':', 'current'), (':', 'current', 'cases'), ('current', 'cases', 'new'), ('cases', 'new', 'agenda'), ('new', 'agenda', '.')]

>> POS Tags are: 
 [('Aligning', 'VBG'), ('practice', 'NN'), (':', ':'), ('current', 'JJ'), ('cases', 'NNS'), ('new', 'JJ'), ('agenda', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['practice', 'current cases', 'new agenda']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Aligning', 'align'), ('practice', 'practic'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aligning', 'align'), ('practice', 'practic'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]

>> Lemmatization: 
 [('Aligning', 'Aligning'), ('practice', 'practice'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]



========================================== PARAGRAPH 1518 ===========================================

Journal of Information Technology, pp. 136-160.  

------------------- Sentence 1 -------------------

Journal of Information Technology, pp.

>> Tokens are: 
 ['Journal', 'Information', 'Technology', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Information Technology', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Information Technology')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

136-160.

>> Tokens are: 
 ['136-160', '.']

>> Bigrams are: 
 [('136-160', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('136-160', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('136-160', '136-160'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('136-160', '136-160'), ('.', '.')]

>> Lemmatization: 
 [('136-160', '136-160'), ('.', '.')]



========================================== PARAGRAPH 1519 ===========================================

Khan, N., Yaqoob, I., Hashem, I.A.T., Inayat, Z., Ali, M., Kamaleldin, W., Alam, M., Shiraz, M.  

------------------- Sentence 1 -------------------

Khan, N., Yaqoob, I., Hashem, I.A.T., Inayat, Z., Ali, M., Kamaleldin, W., Alam, M., Shiraz, M.

>> Tokens are: 
 ['Khan', ',', 'N.', ',', 'Yaqoob', ',', 'I.', ',', 'Hashem', ',', 'I.A.T.', ',', 'Inayat', ',', 'Z.', ',', 'Ali', ',', 'M.', ',', 'Kamaleldin', ',', 'W.', ',', 'Alam', ',', 'M.', ',', 'Shiraz', ',', 'M', '.']

>> Bigrams are: 
 [('Khan', ','), (',', 'N.'), ('N.', ','), (',', 'Yaqoob'), ('Yaqoob', ','), (',', 'I.'), ('I.', ','), (',', 'Hashem'), ('Hashem', ','), (',', 'I.A.T.'), ('I.A.T.', ','), (',', 'Inayat'), ('Inayat', ','), (',', 'Z.'), ('Z.', ','), (',', 'Ali'), ('Ali', ','), (',', 'M.'), ('M.', ','), (',', 'Kamaleldin'), ('Kamaleldin', ','), (',', 'W.'), ('W.', ','), (',', 'Alam'), ('Alam', ','), (',', 'M.'), ('M.', ','), (',', 'Shiraz'), ('Shiraz', ','), (',', 'M'), ('M', '.')]

>> Trigrams are: 
 [('Khan', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Yaqoob'), (',', 'Yaqoob', ','), ('Yaqoob', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Hashem'), (',', 'Hashem', ','), ('Hashem', ',', 'I.A.T.'), (',', 'I.A.T.', ','), ('I.A.T.', ',', 'Inayat'), (',', 'Inayat', ','), ('Inayat', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Ali'), (',', 'Ali', ','), ('Ali', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kamaleldin'), (',', 'Kamaleldin', ','), ('Kamaleldin', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Alam'), (',', 'Alam', ','), ('Alam', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Shiraz'), (',', 'Shiraz', ','), ('Shiraz', ',', 'M'), (',', 'M', '.')]

>> POS Tags are: 
 [('Khan', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Yaqoob', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Hashem', 'NNP'), (',', ','), ('I.A.T.', 'NNP'), (',', ','), ('Inayat', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Ali', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kamaleldin', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Alam', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Shiraz', 'NNP'), (',', ','), ('M', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Khan', 'N.', 'Yaqoob', 'I.', 'Hashem', 'I.A.T.', 'Inayat', 'Z.', 'Ali', 'M.', 'Kamaleldin', 'W.', 'Alam', 'M.', 'Shiraz', 'M']

>> Named Entities are: 
 [('GPE', 'Khan'), ('GPE', 'Yaqoob'), ('GPE', 'Hashem'), ('GPE', 'Inayat'), ('PERSON', 'Ali'), ('PERSON', 'Kamaleldin'), ('PERSON', 'Alam'), ('GPE', 'Shiraz')] 

>> Stemming using Porter Stemmer: 
 [('Khan', 'khan'), (',', ','), ('N.', 'n.'), (',', ','), ('Yaqoob', 'yaqoob'), (',', ','), ('I.', 'i.'), (',', ','), ('Hashem', 'hashem'), (',', ','), ('I.A.T.', 'i.a.t.'), (',', ','), ('Inayat', 'inayat'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ali', 'ali'), (',', ','), ('M.', 'm.'), (',', ','), ('Kamaleldin', 'kamaleldin'), (',', ','), ('W.', 'w.'), (',', ','), ('Alam', 'alam'), (',', ','), ('M.', 'm.'), (',', ','), ('Shiraz', 'shiraz'), (',', ','), ('M', 'm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Khan', 'khan'), (',', ','), ('N.', 'n.'), (',', ','), ('Yaqoob', 'yaqoob'), (',', ','), ('I.', 'i.'), (',', ','), ('Hashem', 'hashem'), (',', ','), ('I.A.T.', 'i.a.t.'), (',', ','), ('Inayat', 'inayat'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ali', 'ali'), (',', ','), ('M.', 'm.'), (',', ','), ('Kamaleldin', 'kamaleldin'), (',', ','), ('W.', 'w.'), (',', ','), ('Alam', 'alam'), (',', ','), ('M.', 'm.'), (',', ','), ('Shiraz', 'shiraz'), (',', ','), ('M', 'm'), ('.', '.')]

>> Lemmatization: 
 [('Khan', 'Khan'), (',', ','), ('N.', 'N.'), (',', ','), ('Yaqoob', 'Yaqoob'), (',', ','), ('I.', 'I.'), (',', ','), ('Hashem', 'Hashem'), (',', ','), ('I.A.T.', 'I.A.T.'), (',', ','), ('Inayat', 'Inayat'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Ali', 'Ali'), (',', ','), ('M.', 'M.'), (',', ','), ('Kamaleldin', 'Kamaleldin'), (',', ','), ('W.', 'W.'), (',', ','), ('Alam', 'Alam'), (',', ','), ('M.', 'M.'), (',', ','), ('Shiraz', 'Shiraz'), (',', ','), ('M', 'M'), ('.', '.')]



========================================== PARAGRAPH 1520 ===========================================

and Gani, A., 2014 . Big data: survey, technologies, opportunities, and challenges. The Scientific  

------------------- Sentence 1 -------------------

and Gani, A., 2014 .

>> Tokens are: 
 ['Gani', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Gani', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Gani', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Gani', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Gani', 'A.']

>> Named Entities are: 
 [('GPE', 'Gani')] 

>> Stemming using Porter Stemmer: 
 [('Gani', 'gani'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gani', 'gani'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Gani', 'Gani'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: survey, technologies, opportunities, and challenges.

>> Tokens are: 
 ['Big', 'data', ':', 'survey', ',', 'technologies', ',', 'opportunities', ',', 'challenges', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'survey'), ('survey', ','), (',', 'technologies'), ('technologies', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'survey'), (':', 'survey', ','), ('survey', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'challenges'), (',', 'challenges', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('survey', 'NN'), (',', ','), ('technologies', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('challenges', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'survey', 'technologies', 'opportunities', 'challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technolog'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technolog'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technology'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('challenges', 'challenge'), ('.', '.')]


------------------- Sentence 3 -------------------

The Scientific

>> Tokens are: 
 ['The', 'Scientific']

>> Bigrams are: 
 [('The', 'Scientific')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('Scientific', 'NNP')]

>> Noun Phrases are: 
 ['The Scientific']

>> Named Entities are: 
 [('ORGANIZATION', 'Scientific')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Scientific', 'scientif')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Scientific', 'scientif')]

>> Lemmatization: 
 [('The', 'The'), ('Scientific', 'Scientific')]



========================================== PARAGRAPH 1521 ===========================================

World Journal.  

------------------- Sentence 1 -------------------

World Journal.

>> Tokens are: 
 ['World', 'Journal', '.']

>> Bigrams are: 
 [('World', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('World', 'Journal', '.')]

>> POS Tags are: 
 [('World', 'NNP'), ('Journal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['World Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('World', 'world'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('World', 'world'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('World', 'World'), ('Journal', 'Journal'), ('.', '.')]



========================================== PARAGRAPH 1522 ===========================================

Kiron, D., Prentice, P.K. and Ferguson, R.B., 2014. The analytics mandate. MIT Sloan  

------------------- Sentence 1 -------------------

Kiron, D., Prentice, P.K.

>> Tokens are: 
 ['Kiron', ',', 'D.', ',', 'Prentice', ',', 'P.K', '.']

>> Bigrams are: 
 [('Kiron', ','), (',', 'D.'), ('D.', ','), (',', 'Prentice'), ('Prentice', ','), (',', 'P.K'), ('P.K', '.')]

>> Trigrams are: 
 [('Kiron', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Prentice'), (',', 'Prentice', ','), ('Prentice', ',', 'P.K'), (',', 'P.K', '.')]

>> POS Tags are: 
 [('Kiron', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Prentice', 'NNP'), (',', ','), ('P.K', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Kiron', 'D.', 'Prentice', 'P.K']

>> Named Entities are: 
 [('GPE', 'Kiron')] 

>> Stemming using Porter Stemmer: 
 [('Kiron', 'kiron'), (',', ','), ('D.', 'd.'), (',', ','), ('Prentice', 'prentic'), (',', ','), ('P.K', 'p.k'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kiron', 'kiron'), (',', ','), ('D.', 'd.'), (',', ','), ('Prentice', 'prentic'), (',', ','), ('P.K', 'p.k'), ('.', '.')]

>> Lemmatization: 
 [('Kiron', 'Kiron'), (',', ','), ('D.', 'D.'), (',', ','), ('Prentice', 'Prentice'), (',', ','), ('P.K', 'P.K'), ('.', '.')]


------------------- Sentence 2 -------------------

and Ferguson, R.B., 2014.

>> Tokens are: 
 ['Ferguson', ',', 'R.B.', ',', '2014', '.']

>> Bigrams are: 
 [('Ferguson', ','), (',', 'R.B.'), ('R.B.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Ferguson', ',', 'R.B.'), (',', 'R.B.', ','), ('R.B.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Ferguson', 'NNP'), (',', ','), ('R.B.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ferguson', 'R.B.']

>> Named Entities are: 
 [('GPE', 'Ferguson')] 

>> Stemming using Porter Stemmer: 
 [('Ferguson', 'ferguson'), (',', ','), ('R.B.', 'r.b.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ferguson', 'ferguson'), (',', ','), ('R.B.', 'r.b.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Ferguson', 'Ferguson'), (',', ','), ('R.B.', 'R.B.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 3 -------------------

The analytics mandate.

>> Tokens are: 
 ['The', 'analytics', 'mandate', '.']

>> Bigrams are: 
 [('The', 'analytics'), ('analytics', 'mandate'), ('mandate', '.')]

>> Trigrams are: 
 [('The', 'analytics', 'mandate'), ('analytics', 'mandate', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('analytics', 'NNS'), ('mandate', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The analytics mandate']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('analytics', 'analyt'), ('mandate', 'mandat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('analytics', 'analyt'), ('mandate', 'mandat'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('analytics', 'analytics'), ('mandate', 'mandate'), ('.', '.')]


------------------- Sentence 4 -------------------

MIT Sloan

>> Tokens are: 
 ['MIT', 'Sloan']

>> Bigrams are: 
 [('MIT', 'Sloan')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('MIT', 'NNP'), ('Sloan', 'NNP')]

>> Noun Phrases are: 
 ['MIT Sloan']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT Sloan')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('Sloan', 'sloan')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('Sloan', 'sloan')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('Sloan', 'Sloan')]



========================================== PARAGRAPH 1523 ===========================================

management review, p. 1.  

------------------- Sentence 1 -------------------

management review, p. 1.

>> Tokens are: 
 ['management', 'review', ',', 'p.', '1', '.']

>> Bigrams are: 
 [('management', 'review'), ('review', ','), (',', 'p.'), ('p.', '1'), ('1', '.')]

>> Trigrams are: 
 [('management', 'review', ','), ('review', ',', 'p.'), (',', 'p.', '1'), ('p.', '1', '.')]

>> POS Tags are: 
 [('management', 'NN'), ('review', 'NN'), (',', ','), ('p.', 'JJ'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['management review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('management', 'management'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]



========================================== PARAGRAPH 1524 ===========================================

Kitchin, R., 2014. Big Data, new epistemologies and paradigm shifts.. Big Data & Society Journal,  

------------------- Sentence 1 -------------------

Kitchin, R., 2014.

>> Tokens are: 
 ['Kitchin', ',', 'R.', ',', '2014', '.']

>> Bigrams are: 
 [('Kitchin', ','), (',', 'R.'), ('R.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Kitchin', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Kitchin', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Kitchin', 'R.']

>> Named Entities are: 
 [('GPE', 'Kitchin')] 

>> Stemming using Porter Stemmer: 
 [('Kitchin', 'kitchin'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kitchin', 'kitchin'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Kitchin', 'Kitchin'), (',', ','), ('R.', 'R.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data, new epistemologies and paradigm shifts.. Big Data & Society Journal,

>> Tokens are: 
 ['Big', 'Data', ',', 'new', 'epistemologies', 'paradigm', 'shifts', '..', 'Big', 'Data', '&', 'Society', 'Journal', ',']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', ','), (',', 'new'), ('new', 'epistemologies'), ('epistemologies', 'paradigm'), ('paradigm', 'shifts'), ('shifts', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', '&'), ('&', 'Society'), ('Society', 'Journal'), ('Journal', ',')]

>> Trigrams are: 
 [('Big', 'Data', ','), ('Data', ',', 'new'), (',', 'new', 'epistemologies'), ('new', 'epistemologies', 'paradigm'), ('epistemologies', 'paradigm', 'shifts'), ('paradigm', 'shifts', '..'), ('shifts', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', '&'), ('Data', '&', 'Society'), ('&', 'Society', 'Journal'), ('Society', 'Journal', ',')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('new', 'JJ'), ('epistemologies', 'NNS'), ('paradigm', 'VBP'), ('shifts', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('&', 'CC'), ('Society', 'NNP'), ('Journal', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Big Data', 'new epistemologies', 'shifts', 'Big Data', 'Society Journal']

>> Named Entities are: 
 [('PERSON', 'Society Journal')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemolog'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('&', '&'), ('Society', 'societi'), ('Journal', 'journal'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemolog'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('&', '&'), ('Society', 'societi'), ('Journal', 'journal'), (',', ',')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemology'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('&', '&'), ('Society', 'Society'), ('Journal', 'Journal'), (',', ',')]



========================================== PARAGRAPH 1525 ===========================================

p. 2053951714528481.  

------------------- Sentence 1 -------------------

p. 2053951714528481.

>> Tokens are: 
 ['p.', '2053951714528481', '.']

>> Bigrams are: 
 [('p.', '2053951714528481'), ('2053951714528481', '.')]

>> Trigrams are: 
 [('p.', '2053951714528481', '.')]

>> POS Tags are: 
 [('p.', 'NN'), ('2053951714528481', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['p.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]

>> Lemmatization: 
 [('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]



========================================== PARAGRAPH 1526 ===========================================

Kotsiantis, Sotiris B and Zaharakis, I and Pintelas, P, 2007. Supervised machine learning: A review  

------------------- Sentence 1 -------------------

Kotsiantis, Sotiris B and Zaharakis, I and Pintelas, P, 2007.

>> Tokens are: 
 ['Kotsiantis', ',', 'Sotiris', 'B', 'Zaharakis', ',', 'I', 'Pintelas', ',', 'P', ',', '2007', '.']

>> Bigrams are: 
 [('Kotsiantis', ','), (',', 'Sotiris'), ('Sotiris', 'B'), ('B', 'Zaharakis'), ('Zaharakis', ','), (',', 'I'), ('I', 'Pintelas'), ('Pintelas', ','), (',', 'P'), ('P', ','), (',', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('Kotsiantis', ',', 'Sotiris'), (',', 'Sotiris', 'B'), ('Sotiris', 'B', 'Zaharakis'), ('B', 'Zaharakis', ','), ('Zaharakis', ',', 'I'), (',', 'I', 'Pintelas'), ('I', 'Pintelas', ','), ('Pintelas', ',', 'P'), (',', 'P', ','), ('P', ',', '2007'), (',', '2007', '.')]

>> POS Tags are: 
 [('Kotsiantis', 'NNP'), (',', ','), ('Sotiris', 'NNP'), ('B', 'NNP'), ('Zaharakis', 'NNP'), (',', ','), ('I', 'PRP'), ('Pintelas', 'VBP'), (',', ','), ('P', 'NNP'), (',', ','), ('2007', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Kotsiantis', 'Sotiris B Zaharakis', 'P']

>> Named Entities are: 
 [('GPE', 'Kotsiantis'), ('PERSON', 'Sotiris B Zaharakis'), ('PERSON', 'P')] 

>> Stemming using Porter Stemmer: 
 [('Kotsiantis', 'kotsianti'), (',', ','), ('Sotiris', 'sotiri'), ('B', 'b'), ('Zaharakis', 'zaharaki'), (',', ','), ('I', 'i'), ('Pintelas', 'pintela'), (',', ','), ('P', 'p'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kotsiantis', 'kotsianti'), (',', ','), ('Sotiris', 'sotiri'), ('B', 'b'), ('Zaharakis', 'zaharaki'), (',', ','), ('I', 'i'), ('Pintelas', 'pintela'), (',', ','), ('P', 'p'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('Kotsiantis', 'Kotsiantis'), (',', ','), ('Sotiris', 'Sotiris'), ('B', 'B'), ('Zaharakis', 'Zaharakis'), (',', ','), ('I', 'I'), ('Pintelas', 'Pintelas'), (',', ','), ('P', 'P'), (',', ','), ('2007', '2007'), ('.', '.')]


------------------- Sentence 2 -------------------

Supervised machine learning: A review

>> Tokens are: 
 ['Supervised', 'machine', 'learning', ':', 'A', 'review']

>> Bigrams are: 
 [('Supervised', 'machine'), ('machine', 'learning'), ('learning', ':'), (':', 'A'), ('A', 'review')]

>> Trigrams are: 
 [('Supervised', 'machine', 'learning'), ('machine', 'learning', ':'), ('learning', ':', 'A'), (':', 'A', 'review')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('machine', 'NN'), ('learning', 'NN'), (':', ':'), ('A', 'DT'), ('review', 'NN')]

>> Noun Phrases are: 
 ['machine learning', 'A review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('A', 'a'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('A', 'a'), ('review', 'review')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('machine', 'machine'), ('learning', 'learning'), (':', ':'), ('A', 'A'), ('review', 'review')]



========================================== PARAGRAPH 1527 ===========================================

of classification techniques. Emerging artificial intelligence applications in computer engineering  

------------------- Sentence 1 -------------------

of classification techniques.

>> Tokens are: 
 ['classification', 'techniques', '.']

>> Bigrams are: 
 [('classification', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('classification', 'techniques', '.')]

>> POS Tags are: 
 [('classification', 'NN'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('classification', 'classification'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

Emerging artificial intelligence applications in computer engineering

>> Tokens are: 
 ['Emerging', 'artificial', 'intelligence', 'applications', 'computer', 'engineering']

>> Bigrams are: 
 [('Emerging', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'applications'), ('applications', 'computer'), ('computer', 'engineering')]

>> Trigrams are: 
 [('Emerging', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'applications'), ('intelligence', 'applications', 'computer'), ('applications', 'computer', 'engineering')]

>> POS Tags are: 
 [('Emerging', 'VBG'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('applications', 'NNS'), ('computer', 'NN'), ('engineering', 'NN')]

>> Noun Phrases are: 
 ['artificial intelligence applications computer engineering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Emerging', 'emerg'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('applications', 'applic'), ('computer', 'comput'), ('engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Emerging', 'emerg'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('applications', 'applic'), ('computer', 'comput'), ('engineering', 'engin')]

>> Lemmatization: 
 [('Emerging', 'Emerging'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('applications', 'application'), ('computer', 'computer'), ('engineering', 'engineering')]



========================================== PARAGRAPH 1528 ===========================================

journal, 160(2), pp. 3--24.  

------------------- Sentence 1 -------------------

journal, 160(2), pp.

>> Tokens are: 
 ['journal', ',', '160', '(', '2', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('journal', ','), (',', '160'), ('160', '('), ('(', '2'), ('2', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('journal', ',', '160'), (',', '160', '('), ('160', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('journal', 'NN'), (',', ','), ('160', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['journal', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

3--24.

>> Tokens are: 
 ['3', '--', '24', '.']

>> Bigrams are: 
 [('3', '--'), ('--', '24'), ('24', '.')]

>> Trigrams are: 
 [('3', '--', '24'), ('--', '24', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('--', ':'), ('24', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]



========================================== PARAGRAPH 1529 ===========================================

Lan, F., Chunlei, W. and Guoqing, M., 2010. A framework for network security situation  

------------------- Sentence 1 -------------------

Lan, F., Chunlei, W. and Guoqing, M., 2010.

>> Tokens are: 
 ['Lan', ',', 'F.', ',', 'Chunlei', ',', 'W.', 'Guoqing', ',', 'M.', ',', '2010', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'F.'), ('F.', ','), (',', 'Chunlei'), ('Chunlei', ','), (',', 'W.'), ('W.', 'Guoqing'), ('Guoqing', ','), (',', 'M.'), ('M.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Lan', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Chunlei'), (',', 'Chunlei', ','), ('Chunlei', ',', 'W.'), (',', 'W.', 'Guoqing'), ('W.', 'Guoqing', ','), ('Guoqing', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Chunlei', 'NNP'), (',', ','), ('W.', 'NNP'), ('Guoqing', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lan', 'F.', 'Chunlei', 'W. Guoqing', 'M.']

>> Named Entities are: 
 [('GPE', 'Lan'), ('PERSON', 'Chunlei')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('F.', 'f.'), (',', ','), ('Chunlei', 'chunlei'), (',', ','), ('W.', 'w.'), ('Guoqing', 'guoq'), (',', ','), ('M.', 'm.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('F.', 'f.'), (',', ','), ('Chunlei', 'chunlei'), (',', ','), ('W.', 'w.'), ('Guoqing', 'guoq'), (',', ','), ('M.', 'm.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('F.', 'F.'), (',', ','), ('Chunlei', 'Chunlei'), (',', ','), ('W.', 'W.'), ('Guoqing', 'Guoqing'), (',', ','), ('M.', 'M.'), (',', ','), ('2010', '2010'), ('.', '.')]


------------------- Sentence 2 -------------------

A framework for network security situation

>> Tokens are: 
 ['A', 'framework', 'network', 'security', 'situation']

>> Bigrams are: 
 [('A', 'framework'), ('framework', 'network'), ('network', 'security'), ('security', 'situation')]

>> Trigrams are: 
 [('A', 'framework', 'network'), ('framework', 'network', 'security'), ('network', 'security', 'situation')]

>> POS Tags are: 
 [('A', 'DT'), ('framework', 'NN'), ('network', 'NN'), ('security', 'NN'), ('situation', 'NN')]

>> Noun Phrases are: 
 ['A framework network security situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('framework', 'framework'), ('network', 'network'), ('security', 'secur'), ('situation', 'situat')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('framework', 'framework'), ('network', 'network'), ('security', 'secur'), ('situation', 'situat')]

>> Lemmatization: 
 [('A', 'A'), ('framework', 'framework'), ('network', 'network'), ('security', 'security'), ('situation', 'situation')]



========================================== PARAGRAPH 1530 ===========================================

awareness based on knowledge discovery. s.l., IEEE, pp. V1-226.  

------------------- Sentence 1 -------------------

awareness based on knowledge discovery.

>> Tokens are: 
 ['awareness', 'based', 'knowledge', 'discovery', '.']

>> Bigrams are: 
 [('awareness', 'based'), ('based', 'knowledge'), ('knowledge', 'discovery'), ('discovery', '.')]

>> Trigrams are: 
 [('awareness', 'based', 'knowledge'), ('based', 'knowledge', 'discovery'), ('knowledge', 'discovery', '.')]

>> POS Tags are: 
 [('awareness', 'NN'), ('based', 'VBN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['awareness', 'knowledge discovery']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('awareness', 'awar'), ('based', 'base'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('awareness', 'awar'), ('based', 'base'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('.', '.')]

>> Lemmatization: 
 [('awareness', 'awareness'), ('based', 'based'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('.', '.')]


------------------- Sentence 2 -------------------

s.l., IEEE, pp.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

V1-226.

>> Tokens are: 
 ['V1-226', '.']

>> Bigrams are: 
 [('V1-226', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('V1-226', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['V1-226']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('V1-226', 'v1-226'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('V1-226', 'v1-226'), ('.', '.')]

>> Lemmatization: 
 [('V1-226', 'V1-226'), ('.', '.')]



========================================== PARAGRAPH 1531 ===========================================

Landset, S., Khoshgoftaar, T.M., Richter, A.N. and Hasanin, T., 2015. A survey of open source  

------------------- Sentence 1 -------------------

Landset, S., Khoshgoftaar, T.M., Richter, A.N.

>> Tokens are: 
 ['Landset', ',', 'S.', ',', 'Khoshgoftaar', ',', 'T.M.', ',', 'Richter', ',', 'A.N', '.']

>> Bigrams are: 
 [('Landset', ','), (',', 'S.'), ('S.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M.'), ('T.M.', ','), (',', 'Richter'), ('Richter', ','), (',', 'A.N'), ('A.N', '.')]

>> Trigrams are: 
 [('Landset', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M.'), (',', 'T.M.', ','), ('T.M.', ',', 'Richter'), (',', 'Richter', ','), ('Richter', ',', 'A.N'), (',', 'A.N', '.')]

>> POS Tags are: 
 [('Landset', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M.', 'NNP'), (',', ','), ('Richter', 'NNP'), (',', ','), ('A.N', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Landset', 'S.', 'Khoshgoftaar', 'T.M.', 'Richter', 'A.N']

>> Named Entities are: 
 [('GPE', 'Landset'), ('GPE', 'Khoshgoftaar'), ('PERSON', 'Richter')] 

>> Stemming using Porter Stemmer: 
 [('Landset', 'landset'), (',', ','), ('S.', 's.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Richter', 'richter'), (',', ','), ('A.N', 'a.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Landset', 'landset'), (',', ','), ('S.', 's.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Richter', 'richter'), (',', ','), ('A.N', 'a.n'), ('.', '.')]

>> Lemmatization: 
 [('Landset', 'Landset'), (',', ','), ('S.', 'S.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M.', 'T.M.'), (',', ','), ('Richter', 'Richter'), (',', ','), ('A.N', 'A.N'), ('.', '.')]


------------------- Sentence 2 -------------------

and Hasanin, T., 2015.

>> Tokens are: 
 ['Hasanin', ',', 'T.', ',', '2015', '.']

>> Bigrams are: 
 [('Hasanin', ','), (',', 'T.'), ('T.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Hasanin', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Hasanin', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hasanin', 'T.']

>> Named Entities are: 
 [('GPE', 'Hasanin')] 

>> Stemming using Porter Stemmer: 
 [('Hasanin', 'hasanin'), (',', ','), ('T.', 't.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasanin', 'hasanin'), (',', ','), ('T.', 't.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Hasanin', 'Hasanin'), (',', ','), ('T.', 'T.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 3 -------------------

A survey of open source

>> Tokens are: 
 ['A', 'survey', 'open', 'source']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'open'), ('open', 'source')]

>> Trigrams are: 
 [('A', 'survey', 'open'), ('survey', 'open', 'source')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('open', 'JJ'), ('source', 'NN')]

>> Noun Phrases are: 
 ['A survey', 'open source']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('open', 'open'), ('source', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('open', 'open'), ('source', 'sourc')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('open', 'open'), ('source', 'source')]



========================================== PARAGRAPH 1532 ===========================================

tools for machine learning with big data in the Hadoop ecosystem.. Journal of Big Data, Volume  

------------------- Sentence 1 -------------------

tools for machine learning with big data in the Hadoop ecosystem.. Journal of Big Data, Volume

>> Tokens are: 
 ['tools', 'machine', 'learning', 'big', 'data', 'Hadoop', 'ecosystem', '..', 'Journal', 'Big', 'Data', ',', 'Volume']

>> Bigrams are: 
 [('tools', 'machine'), ('machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'Hadoop'), ('Hadoop', 'ecosystem'), ('ecosystem', '..'), ('..', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'Volume')]

>> Trigrams are: 
 [('tools', 'machine', 'learning'), ('machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'Hadoop'), ('data', 'Hadoop', 'ecosystem'), ('Hadoop', 'ecosystem', '..'), ('ecosystem', '..', 'Journal'), ('..', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'Volume')]

>> POS Tags are: 
 [('tools', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('Hadoop', 'NNP'), ('ecosystem', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('Volume', 'NN')]

>> Noun Phrases are: 
 ['tools machine', 'big data Hadoop ecosystem .. Journal Big Data', 'Volume']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Volume', 'volum')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Volume', 'volum')]

>> Lemmatization: 
 [('tools', 'tool'), ('machine', 'machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'Hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('Volume', 'Volume')]



========================================== PARAGRAPH 1533 ===========================================

2, p. 24.  

------------------- Sentence 1 -------------------

2, p. 24.

>> Tokens are: 
 ['2', ',', 'p.', '24', '.']

>> Bigrams are: 
 [('2', ','), (',', 'p.'), ('p.', '24'), ('24', '.')]

>> Trigrams are: 
 [('2', ',', 'p.'), (',', 'p.', '24'), ('p.', '24', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('p.', 'RB'), ('24', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]



========================================== PARAGRAPH 1534 ===========================================

Laney, D., 2001. 3D data management: Controlling data volume, velocity and variety.. META  

------------------- Sentence 1 -------------------

Laney, D., 2001.

>> Tokens are: 
 ['Laney', ',', 'D.', ',', '2001', '.']

>> Bigrams are: 
 [('Laney', ','), (',', 'D.'), ('D.', ','), (',', '2001'), ('2001', '.')]

>> Trigrams are: 
 [('Laney', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2001'), (',', '2001', '.')]

>> POS Tags are: 
 [('Laney', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2001', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Laney', 'D.']

>> Named Entities are: 
 [('GPE', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('Laney', 'laney'), (',', ','), ('D.', 'd.'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Laney', 'laney'), (',', ','), ('D.', 'd.'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Lemmatization: 
 [('Laney', 'Laney'), (',', ','), ('D.', 'D.'), (',', ','), ('2001', '2001'), ('.', '.')]


------------------- Sentence 2 -------------------

3D data management: Controlling data volume, velocity and variety.. META

>> Tokens are: 
 ['3D', 'data', 'management', ':', 'Controlling', 'data', 'volume', ',', 'velocity', 'variety', '..', 'META']

>> Bigrams are: 
 [('3D', 'data'), ('data', 'management'), ('management', ':'), (':', 'Controlling'), ('Controlling', 'data'), ('data', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', 'variety'), ('variety', '..'), ('..', 'META')]

>> Trigrams are: 
 [('3D', 'data', 'management'), ('data', 'management', ':'), ('management', ':', 'Controlling'), (':', 'Controlling', 'data'), ('Controlling', 'data', 'volume'), ('data', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', 'variety'), ('velocity', 'variety', '..'), ('variety', '..', 'META')]

>> POS Tags are: 
 [('3D', 'CD'), ('data', 'NNS'), ('management', 'NN'), (':', ':'), ('Controlling', 'NNP'), ('data', 'NN'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), ('variety', 'NN'), ('..', 'NNP'), ('META', 'NNP')]

>> Noun Phrases are: 
 ['data management', 'Controlling data volume', 'velocity variety .. META']

>> Named Entities are: 
 [('ORGANIZATION', 'META')] 

>> Stemming using Porter Stemmer: 
 [('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('Controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('variety', 'varieti'), ('..', '..'), ('META', 'meta')]

>> Stemming using Snowball Stemmer: 
 [('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('Controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('variety', 'varieti'), ('..', '..'), ('META', 'meta')]

>> Lemmatization: 
 [('3D', '3D'), ('data', 'data'), ('management', 'management'), (':', ':'), ('Controlling', 'Controlling'), ('data', 'data'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), ('variety', 'variety'), ('..', '..'), ('META', 'META')]



========================================== PARAGRAPH 1535 ===========================================

group research note, Volume 6, p. 1.  

------------------- Sentence 1 -------------------

group research note, Volume 6, p. 1.

>> Tokens are: 
 ['group', 'research', 'note', ',', 'Volume', '6', ',', 'p.', '1', '.']

>> Bigrams are: 
 [('group', 'research'), ('research', 'note'), ('note', ','), (',', 'Volume'), ('Volume', '6'), ('6', ','), (',', 'p.'), ('p.', '1'), ('1', '.')]

>> Trigrams are: 
 [('group', 'research', 'note'), ('research', 'note', ','), ('note', ',', 'Volume'), (',', 'Volume', '6'), ('Volume', '6', ','), ('6', ',', 'p.'), (',', 'p.', '1'), ('p.', '1', '.')]

>> POS Tags are: 
 [('group', 'NN'), ('research', 'NN'), ('note', 'NN'), (',', ','), ('Volume', 'NN'), ('6', 'CD'), (',', ','), ('p.', 'RB'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['group research note', 'Volume']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'volum'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'volum'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'Volume'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]



========================================== PARAGRAPH 1536 ===========================================

LaValle, S., Lesser, E., Shockley, R., Hopkins, M.S. and Kruschwitz, N., 2011. Big data, analytics  

------------------- Sentence 1 -------------------

LaValle, S., Lesser, E., Shockley, R., Hopkins, M.S.

>> Tokens are: 
 ['LaValle', ',', 'S.', ',', 'Lesser', ',', 'E.', ',', 'Shockley', ',', 'R.', ',', 'Hopkins', ',', 'M.S', '.']

>> Bigrams are: 
 [('LaValle', ','), (',', 'S.'), ('S.', ','), (',', 'Lesser'), ('Lesser', ','), (',', 'E.'), ('E.', ','), (',', 'Shockley'), ('Shockley', ','), (',', 'R.'), ('R.', ','), (',', 'Hopkins'), ('Hopkins', ','), (',', 'M.S'), ('M.S', '.')]

>> Trigrams are: 
 [('LaValle', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Lesser'), (',', 'Lesser', ','), ('Lesser', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Shockley'), (',', 'Shockley', ','), ('Shockley', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Hopkins'), (',', 'Hopkins', ','), ('Hopkins', ',', 'M.S'), (',', 'M.S', '.')]

>> POS Tags are: 
 [('LaValle', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Lesser', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Shockley', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Hopkins', 'NNP'), (',', ','), ('M.S', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['LaValle', 'S.', 'Lesser', 'E.', 'Shockley', 'R.', 'Hopkins', 'M.S']

>> Named Entities are: 
 [('GPE', 'LaValle'), ('PERSON', 'Lesser'), ('GPE', 'Shockley'), ('PERSON', 'Hopkins')] 

>> Stemming using Porter Stemmer: 
 [('LaValle', 'laval'), (',', ','), ('S.', 's.'), (',', ','), ('Lesser', 'lesser'), (',', ','), ('E.', 'e.'), (',', ','), ('Shockley', 'shockley'), (',', ','), ('R.', 'r.'), (',', ','), ('Hopkins', 'hopkin'), (',', ','), ('M.S', 'm.'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LaValle', 'lavall'), (',', ','), ('S.', 's.'), (',', ','), ('Lesser', 'lesser'), (',', ','), ('E.', 'e.'), (',', ','), ('Shockley', 'shockley'), (',', ','), ('R.', 'r.'), (',', ','), ('Hopkins', 'hopkin'), (',', ','), ('M.S', 'm.s'), ('.', '.')]

>> Lemmatization: 
 [('LaValle', 'LaValle'), (',', ','), ('S.', 'S.'), (',', ','), ('Lesser', 'Lesser'), (',', ','), ('E.', 'E.'), (',', ','), ('Shockley', 'Shockley'), (',', ','), ('R.', 'R.'), (',', ','), ('Hopkins', 'Hopkins'), (',', ','), ('M.S', 'M.S'), ('.', '.')]


------------------- Sentence 2 -------------------

and Kruschwitz, N., 2011.

>> Tokens are: 
 ['Kruschwitz', ',', 'N.', ',', '2011', '.']

>> Bigrams are: 
 [('Kruschwitz', ','), (',', 'N.'), ('N.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Kruschwitz', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Kruschwitz', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Kruschwitz', 'N.']

>> Named Entities are: 
 [('GPE', 'Kruschwitz')] 

>> Stemming using Porter Stemmer: 
 [('Kruschwitz', 'kruschwitz'), (',', ','), ('N.', 'n.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kruschwitz', 'kruschwitz'), (',', ','), ('N.', 'n.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Kruschwitz', 'Kruschwitz'), (',', ','), ('N.', 'N.'), (',', ','), ('2011', '2011'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data, analytics

>> Tokens are: 
 ['Big', 'data', ',', 'analytics']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'analytics')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'analytics')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Big data', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('analytics', 'analytics')]



========================================== PARAGRAPH 1537 ===========================================

and the path from insights to value. MIT sloan management review, p. 21. 

------------------- Sentence 1 -------------------

and the path from insights to value.

>> Tokens are: 
 ['path', 'insights', 'value', '.']

>> Bigrams are: 
 [('path', 'insights'), ('insights', 'value'), ('value', '.')]

>> Trigrams are: 
 [('path', 'insights', 'value'), ('insights', 'value', '.')]

>> POS Tags are: 
 [('path', 'NN'), ('insights', 'NNS'), ('value', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['path insights value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('path', 'path'), ('insights', 'insight'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('path', 'path'), ('insights', 'insight'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('path', 'path'), ('insights', 'insight'), ('value', 'value'), ('.', '.')]


------------------- Sentence 2 -------------------

MIT sloan management review, p. 21.

>> Tokens are: 
 ['MIT', 'sloan', 'management', 'review', ',', 'p.', '21', '.']

>> Bigrams are: 
 [('MIT', 'sloan'), ('sloan', 'management'), ('management', 'review'), ('review', ','), (',', 'p.'), ('p.', '21'), ('21', '.')]

>> Trigrams are: 
 [('MIT', 'sloan', 'management'), ('sloan', 'management', 'review'), ('management', 'review', ','), ('review', ',', 'p.'), (',', 'p.', '21'), ('p.', '21', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('sloan', 'VBD'), ('management', 'NN'), ('review', 'NN'), (',', ','), ('p.', 'JJ'), ('21', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['MIT', 'management review']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('sloan', 'sloan'), ('management', 'management'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]



========================================== PARAGRAPH 1538 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1539 ===========================================

51  

------------------- Sentence 1 -------------------

51

>> Tokens are: 
 ['51']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('51', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('51', '51')]

>> Stemming using Snowball Stemmer: 
 [('51', '51')]

>> Lemmatization: 
 [('51', '51')]



========================================== PARAGRAPH 1540 ===========================================

  


========================================== PARAGRAPH 1541 ===========================================

Lee, J., Kao, H.A. and Yang, S., 2014. Service innovation and smart analytics for industry 4.0 and  

------------------- Sentence 1 -------------------

Lee, J., Kao, H.A.

>> Tokens are: 
 ['Lee', ',', 'J.', ',', 'Kao', ',', 'H.A', '.']

>> Bigrams are: 
 [('Lee', ','), (',', 'J.'), ('J.', ','), (',', 'Kao'), ('Kao', ','), (',', 'H.A'), ('H.A', '.')]

>> Trigrams are: 
 [('Lee', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Kao'), (',', 'Kao', ','), ('Kao', ',', 'H.A'), (',', 'H.A', '.')]

>> POS Tags are: 
 [('Lee', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Kao', 'NNP'), (',', ','), ('H.A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lee', 'J.', 'Kao', 'H.A']

>> Named Entities are: 
 [('PERSON', 'Lee'), ('PERSON', 'Kao')] 

>> Stemming using Porter Stemmer: 
 [('Lee', 'lee'), (',', ','), ('J.', 'j.'), (',', ','), ('Kao', 'kao'), (',', ','), ('H.A', 'h.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lee', 'lee'), (',', ','), ('J.', 'j.'), (',', ','), ('Kao', 'kao'), (',', ','), ('H.A', 'h.a'), ('.', '.')]

>> Lemmatization: 
 [('Lee', 'Lee'), (',', ','), ('J.', 'J.'), (',', ','), ('Kao', 'Kao'), (',', ','), ('H.A', 'H.A'), ('.', '.')]


------------------- Sentence 2 -------------------

and Yang, S., 2014.

>> Tokens are: 
 ['Yang', ',', 'S.', ',', '2014', '.']

>> Bigrams are: 
 [('Yang', ','), (',', 'S.'), ('S.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Yang', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Yang', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Yang', 'S.']

>> Named Entities are: 
 [('GPE', 'Yang')] 

>> Stemming using Porter Stemmer: 
 [('Yang', 'yang'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yang', 'yang'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Yang', 'Yang'), (',', ','), ('S.', 'S.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 3 -------------------

Service innovation and smart analytics for industry 4.0 and

>> Tokens are: 
 ['Service', 'innovation', 'smart', 'analytics', 'industry', '4.0']

>> Bigrams are: 
 [('Service', 'innovation'), ('innovation', 'smart'), ('smart', 'analytics'), ('analytics', 'industry'), ('industry', '4.0')]

>> Trigrams are: 
 [('Service', 'innovation', 'smart'), ('innovation', 'smart', 'analytics'), ('smart', 'analytics', 'industry'), ('analytics', 'industry', '4.0')]

>> POS Tags are: 
 [('Service', 'NNP'), ('innovation', 'NN'), ('smart', 'JJ'), ('analytics', 'NNS'), ('industry', 'NN'), ('4.0', 'CD')]

>> Noun Phrases are: 
 ['Service innovation', 'smart analytics industry']

>> Named Entities are: 
 [('GPE', 'Service')] 

>> Stemming using Porter Stemmer: 
 [('Service', 'servic'), ('innovation', 'innov'), ('smart', 'smart'), ('analytics', 'analyt'), ('industry', 'industri'), ('4.0', '4.0')]

>> Stemming using Snowball Stemmer: 
 [('Service', 'servic'), ('innovation', 'innov'), ('smart', 'smart'), ('analytics', 'analyt'), ('industry', 'industri'), ('4.0', '4.0')]

>> Lemmatization: 
 [('Service', 'Service'), ('innovation', 'innovation'), ('smart', 'smart'), ('analytics', 'analytics'), ('industry', 'industry'), ('4.0', '4.0')]



========================================== PARAGRAPH 1542 ===========================================

big data environment.. Procedia Cirp Journal, pp. 3-8.  

------------------- Sentence 1 -------------------

big data environment.. Procedia Cirp Journal, pp.

>> Tokens are: 
 ['big', 'data', 'environment', '..', 'Procedia', 'Cirp', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'environment'), ('environment', '..'), ('..', 'Procedia'), ('Procedia', 'Cirp'), ('Cirp', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('big', 'data', 'environment'), ('data', 'environment', '..'), ('environment', '..', 'Procedia'), ('..', 'Procedia', 'Cirp'), ('Procedia', 'Cirp', 'Journal'), ('Cirp', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('..', 'IN'), ('Procedia', 'NNP'), ('Cirp', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data environment', 'Procedia Cirp Journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Procedia Cirp Journal')] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('..', '..'), ('Procedia', 'procedia'), ('Cirp', 'cirp'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('..', '..'), ('Procedia', 'procedia'), ('Cirp', 'cirp'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('..', '..'), ('Procedia', 'Procedia'), ('Cirp', 'Cirp'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

3-8.

>> Tokens are: 
 ['3-8', '.']

>> Bigrams are: 
 [('3-8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3-8', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-8', '3-8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-8', '3-8'), ('.', '.')]

>> Lemmatization: 
 [('3-8', '3-8'), ('.', '.')]



========================================== PARAGRAPH 1543 ===========================================

Lei, Y., Jia, F., Lin, J., Xing, S. and Ding, S.X., 2016. An intelligent fault diagnosis method using  

------------------- Sentence 1 -------------------

Lei, Y., Jia, F., Lin, J., Xing, S. and Ding, S.X., 2016.

>> Tokens are: 
 ['Lei', ',', 'Y.', ',', 'Jia', ',', 'F.', ',', 'Lin', ',', 'J.', ',', 'Xing', ',', 'S.', 'Ding', ',', 'S.X.', ',', '2016', '.']

>> Bigrams are: 
 [('Lei', ','), (',', 'Y.'), ('Y.', ','), (',', 'Jia'), ('Jia', ','), (',', 'F.'), ('F.', ','), (',', 'Lin'), ('Lin', ','), (',', 'J.'), ('J.', ','), (',', 'Xing'), ('Xing', ','), (',', 'S.'), ('S.', 'Ding'), ('Ding', ','), (',', 'S.X.'), ('S.X.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Lei', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Jia'), (',', 'Jia', ','), ('Jia', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Lin'), (',', 'Lin', ','), ('Lin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Xing'), (',', 'Xing', ','), ('Xing', ',', 'S.'), (',', 'S.', 'Ding'), ('S.', 'Ding', ','), ('Ding', ',', 'S.X.'), (',', 'S.X.', ','), ('S.X.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Lei', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Jia', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Lin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Xing', 'NNP'), (',', ','), ('S.', 'NNP'), ('Ding', 'NNP'), (',', ','), ('S.X.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lei', 'Y.', 'Jia', 'F.', 'Lin', 'J.', 'Xing', 'S. Ding', 'S.X.']

>> Named Entities are: 
 [('GPE', 'Lei'), ('PERSON', 'Jia'), ('PERSON', 'Lin'), ('GPE', 'Xing')] 

>> Stemming using Porter Stemmer: 
 [('Lei', 'lei'), (',', ','), ('Y.', 'y.'), (',', ','), ('Jia', 'jia'), (',', ','), ('F.', 'f.'), (',', ','), ('Lin', 'lin'), (',', ','), ('J.', 'j.'), (',', ','), ('Xing', 'xing'), (',', ','), ('S.', 's.'), ('Ding', 'ding'), (',', ','), ('S.X.', 's.x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lei', 'lei'), (',', ','), ('Y.', 'y.'), (',', ','), ('Jia', 'jia'), (',', ','), ('F.', 'f.'), (',', ','), ('Lin', 'lin'), (',', ','), ('J.', 'j.'), (',', ','), ('Xing', 'xing'), (',', ','), ('S.', 's.'), ('Ding', 'ding'), (',', ','), ('S.X.', 's.x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Lei', 'Lei'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Jia', 'Jia'), (',', ','), ('F.', 'F.'), (',', ','), ('Lin', 'Lin'), (',', ','), ('J.', 'J.'), (',', ','), ('Xing', 'Xing'), (',', ','), ('S.', 'S.'), ('Ding', 'Ding'), (',', ','), ('S.X.', 'S.X.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

An intelligent fault diagnosis method using

>> Tokens are: 
 ['An', 'intelligent', 'fault', 'diagnosis', 'method', 'using']

>> Bigrams are: 
 [('An', 'intelligent'), ('intelligent', 'fault'), ('fault', 'diagnosis'), ('diagnosis', 'method'), ('method', 'using')]

>> Trigrams are: 
 [('An', 'intelligent', 'fault'), ('intelligent', 'fault', 'diagnosis'), ('fault', 'diagnosis', 'method'), ('diagnosis', 'method', 'using')]

>> POS Tags are: 
 [('An', 'DT'), ('intelligent', 'JJ'), ('fault', 'NN'), ('diagnosis', 'NN'), ('method', 'NN'), ('using', 'VBG')]

>> Noun Phrases are: 
 ['An intelligent fault diagnosis method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('intelligent', 'intellig'), ('fault', 'fault'), ('diagnosis', 'diagnosi'), ('method', 'method'), ('using', 'use')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('intelligent', 'intellig'), ('fault', 'fault'), ('diagnosis', 'diagnosi'), ('method', 'method'), ('using', 'use')]

>> Lemmatization: 
 [('An', 'An'), ('intelligent', 'intelligent'), ('fault', 'fault'), ('diagnosis', 'diagnosis'), ('method', 'method'), ('using', 'using')]



========================================== PARAGRAPH 1544 ===========================================

unsupervised feature learning towards mechanical big data.. IEEE Transactions on Industrial  

------------------- Sentence 1 -------------------

unsupervised feature learning towards mechanical big data.. IEEE Transactions on Industrial

>> Tokens are: 
 ['unsupervised', 'feature', 'learning', 'towards', 'mechanical', 'big', 'data', '..', 'IEEE', 'Transactions', 'Industrial']

>> Bigrams are: 
 [('unsupervised', 'feature'), ('feature', 'learning'), ('learning', 'towards'), ('towards', 'mechanical'), ('mechanical', 'big'), ('big', 'data'), ('data', '..'), ('..', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Industrial')]

>> Trigrams are: 
 [('unsupervised', 'feature', 'learning'), ('feature', 'learning', 'towards'), ('learning', 'towards', 'mechanical'), ('towards', 'mechanical', 'big'), ('mechanical', 'big', 'data'), ('big', 'data', '..'), ('data', '..', 'IEEE'), ('..', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Industrial')]

>> POS Tags are: 
 [('unsupervised', 'JJ'), ('feature', 'NN'), ('learning', 'VBG'), ('towards', 'NNS'), ('mechanical', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('..', 'NNS'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Industrial', 'NNP')]

>> Noun Phrases are: 
 ['unsupervised feature', 'towards', 'mechanical big data .. IEEE Transactions Industrial']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions Industrial')] 

>> Stemming using Porter Stemmer: 
 [('unsupervised', 'unsupervis'), ('feature', 'featur'), ('learning', 'learn'), ('towards', 'toward'), ('mechanical', 'mechan'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('unsupervised', 'unsupervis'), ('feature', 'featur'), ('learning', 'learn'), ('towards', 'toward'), ('mechanical', 'mechan'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri')]

>> Lemmatization: 
 [('unsupervised', 'unsupervised'), ('feature', 'feature'), ('learning', 'learning'), ('towards', 'towards'), ('mechanical', 'mechanical'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Industrial', 'Industrial')]



========================================== PARAGRAPH 1545 ===========================================

Electronics journal, Volume 36, pp. 3137-3147.  

------------------- Sentence 1 -------------------

Electronics journal, Volume 36, pp.

>> Tokens are: 
 ['Electronics', 'journal', ',', 'Volume', '36', ',', 'pp', '.']

>> Bigrams are: 
 [('Electronics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '36'), ('36', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Electronics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '36'), ('Volume', '36', ','), ('36', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Electronics', 'NNS'), ('journal', 'JJ'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Electronics', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 36')] 

>> Stemming using Porter Stemmer: 
 [('Electronics', 'electron'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Electronics', 'electron'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Electronics', 'Electronics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

3137-3147.

>> Tokens are: 
 ['3137-3147', '.']

>> Bigrams are: 
 [('3137-3147', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3137-3147', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3137-3147', '3137-3147'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3137-3147', '3137-3147'), ('.', '.')]

>> Lemmatization: 
 [('3137-3147', '3137-3147'), ('.', '.')]



========================================== PARAGRAPH 1546 ===========================================

Lekhwar, S., Yadav, S. and Singh, A., 2019. Lekhwar, S., Yadav, S. and Singh, A., 2019. Big Data  

------------------- Sentence 1 -------------------

Lekhwar, S., Yadav, S. and Singh, A., 2019.

>> Tokens are: 
 ['Lekhwar', ',', 'S.', ',', 'Yadav', ',', 'S.', 'Singh', ',', 'A.', ',', '2019', '.']

>> Bigrams are: 
 [('Lekhwar', ','), (',', 'S.'), ('S.', ','), (',', 'Yadav'), ('Yadav', ','), (',', 'S.'), ('S.', 'Singh'), ('Singh', ','), (',', 'A.'), ('A.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Lekhwar', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Yadav'), (',', 'Yadav', ','), ('Yadav', ',', 'S.'), (',', 'S.', 'Singh'), ('S.', 'Singh', ','), ('Singh', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Lekhwar', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Yadav', 'NNP'), (',', ','), ('S.', 'NNP'), ('Singh', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lekhwar', 'S.', 'Yadav', 'S. Singh', 'A.']

>> Named Entities are: 
 [('GPE', 'Lekhwar'), ('PERSON', 'Yadav'), ('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Lekhwar', 'Lekhwar'), (',', ','), ('S.', 'S.'), (',', ','), ('Yadav', 'Yadav'), (',', ','), ('S.', 'S.'), ('Singh', 'Singh'), (',', ','), ('A.', 'A.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Lekhwar, S., Yadav, S. and Singh, A., 2019.

>> Tokens are: 
 ['Lekhwar', ',', 'S.', ',', 'Yadav', ',', 'S.', 'Singh', ',', 'A.', ',', '2019', '.']

>> Bigrams are: 
 [('Lekhwar', ','), (',', 'S.'), ('S.', ','), (',', 'Yadav'), ('Yadav', ','), (',', 'S.'), ('S.', 'Singh'), ('Singh', ','), (',', 'A.'), ('A.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Lekhwar', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Yadav'), (',', 'Yadav', ','), ('Yadav', ',', 'S.'), (',', 'S.', 'Singh'), ('S.', 'Singh', ','), ('Singh', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Lekhwar', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Yadav', 'NNP'), (',', ','), ('S.', 'NNP'), ('Singh', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lekhwar', 'S.', 'Yadav', 'S. Singh', 'A.']

>> Named Entities are: 
 [('GPE', 'Lekhwar'), ('PERSON', 'Yadav'), ('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Lekhwar', 'Lekhwar'), (',', ','), ('S.', 'S.'), (',', ','), ('Yadav', 'Yadav'), (',', ','), ('S.', 'S.'), ('Singh', 'Singh'), (',', ','), ('A.', 'A.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 3 -------------------

Big Data

>> Tokens are: 
 ['Big', 'Data']

>> Bigrams are: 
 [('Big', 'Data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNS')]

>> Noun Phrases are: 
 ['Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data')]



========================================== PARAGRAPH 1547 ===========================================

Analytics in Retail. Singapore, Springer, pp. 469-477.  

------------------- Sentence 1 -------------------

Analytics in Retail.

>> Tokens are: 
 ['Analytics', 'Retail', '.']

>> Bigrams are: 
 [('Analytics', 'Retail'), ('Retail', '.')]

>> Trigrams are: 
 [('Analytics', 'Retail', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('Retail', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Analytics Retail']

>> Named Entities are: 
 [('PERSON', 'Retail')] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('Retail', 'retail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('Retail', 'retail'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('Retail', 'Retail'), ('.', '.')]


------------------- Sentence 2 -------------------

Singapore, Springer, pp.

>> Tokens are: 
 ['Singapore', ',', 'Springer', ',', 'pp', '.']

>> Bigrams are: 
 [('Singapore', ','), (',', 'Springer'), ('Springer', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Singapore', ',', 'Springer'), (',', 'Springer', ','), ('Springer', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Singapore', 'NNP'), (',', ','), ('Springer', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Singapore', 'Springer', 'pp']

>> Named Entities are: 
 [('GPE', 'Singapore'), ('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Singapore', 'singapor'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Singapore', 'singapor'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Singapore', 'Singapore'), (',', ','), ('Springer', 'Springer'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

469-477.

>> Tokens are: 
 ['469-477', '.']

>> Bigrams are: 
 [('469-477', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('469-477', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('469-477', '469-477'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('469-477', '469-477'), ('.', '.')]

>> Lemmatization: 
 [('469-477', '469-477'), ('.', '.')]



========================================== PARAGRAPH 1548 ===========================================

Levy, Y. and Ellis, T.J., 2006. A systems approach to conduct an effective literature review in  

------------------- Sentence 1 -------------------

Levy, Y. and Ellis, T.J., 2006.

>> Tokens are: 
 ['Levy', ',', 'Y.', 'Ellis', ',', 'T.J.', ',', '2006', '.']

>> Bigrams are: 
 [('Levy', ','), (',', 'Y.'), ('Y.', 'Ellis'), ('Ellis', ','), (',', 'T.J.'), ('T.J.', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('Levy', ',', 'Y.'), (',', 'Y.', 'Ellis'), ('Y.', 'Ellis', ','), ('Ellis', ',', 'T.J.'), (',', 'T.J.', ','), ('T.J.', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('Levy', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('T.J.', 'NNP'), (',', ','), ('2006', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Levy', 'Y. Ellis', 'T.J.']

>> Named Entities are: 
 [('GPE', 'Levy')] 

>> Stemming using Porter Stemmer: 
 [('Levy', 'levi'), (',', ','), ('Y.', 'y.'), ('Ellis', 'elli'), (',', ','), ('T.J.', 't.j.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Levy', 'levi'), (',', ','), ('Y.', 'y.'), ('Ellis', 'elli'), (',', ','), ('T.J.', 't.j.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('Levy', 'Levy'), (',', ','), ('Y.', 'Y.'), ('Ellis', 'Ellis'), (',', ','), ('T.J.', 'T.J.'), (',', ','), ('2006', '2006'), ('.', '.')]


------------------- Sentence 2 -------------------

A systems approach to conduct an effective literature review in

>> Tokens are: 
 ['A', 'systems', 'approach', 'conduct', 'effective', 'literature', 'review']

>> Bigrams are: 
 [('A', 'systems'), ('systems', 'approach'), ('approach', 'conduct'), ('conduct', 'effective'), ('effective', 'literature'), ('literature', 'review')]

>> Trigrams are: 
 [('A', 'systems', 'approach'), ('systems', 'approach', 'conduct'), ('approach', 'conduct', 'effective'), ('conduct', 'effective', 'literature'), ('effective', 'literature', 'review')]

>> POS Tags are: 
 [('A', 'DT'), ('systems', 'NNS'), ('approach', 'NN'), ('conduct', 'VBP'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'NN')]

>> Noun Phrases are: 
 ['A systems approach', 'effective literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review')]

>> Lemmatization: 
 [('A', 'A'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review')]



========================================== PARAGRAPH 1549 ===========================================

support of information systems research.. Informing Science Journal, p. 9.  

------------------- Sentence 1 -------------------

support of information systems research.. Informing Science Journal, p. 9.

>> Tokens are: 
 ['support', 'information', 'systems', 'research', '..', 'Informing', 'Science', 'Journal', ',', 'p.', '9', '.']

>> Bigrams are: 
 [('support', 'information'), ('information', 'systems'), ('systems', 'research'), ('research', '..'), ('..', 'Informing'), ('Informing', 'Science'), ('Science', 'Journal'), ('Journal', ','), (',', 'p.'), ('p.', '9'), ('9', '.')]

>> Trigrams are: 
 [('support', 'information', 'systems'), ('information', 'systems', 'research'), ('systems', 'research', '..'), ('research', '..', 'Informing'), ('..', 'Informing', 'Science'), ('Informing', 'Science', 'Journal'), ('Science', 'Journal', ','), ('Journal', ',', 'p.'), (',', 'p.', '9'), ('p.', '9', '.')]

>> POS Tags are: 
 [('support', 'NN'), ('information', 'NN'), ('systems', 'NNS'), ('research', 'NN'), ('..', 'VBP'), ('Informing', 'VBG'), ('Science', 'NNP'), ('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['support information systems research', 'Science Journal']

>> Named Entities are: 
 [('PERSON', 'Science Journal')] 

>> Stemming using Porter Stemmer: 
 [('support', 'support'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'inform'), ('Science', 'scienc'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('support', 'support'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'inform'), ('Science', 'scienc'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('support', 'support'), ('information', 'information'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'Informing'), ('Science', 'Science'), ('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]



========================================== PARAGRAPH 1550 ===========================================

Li, Y. and Schuurmans, D., 2011. MapReduce for parallel reinforcement learning. Berlin,  

------------------- Sentence 1 -------------------

Li, Y. and Schuurmans, D., 2011.

>> Tokens are: 
 ['Li', ',', 'Y.', 'Schuurmans', ',', 'D.', ',', '2011', '.']

>> Bigrams are: 
 [('Li', ','), (',', 'Y.'), ('Y.', 'Schuurmans'), ('Schuurmans', ','), (',', 'D.'), ('D.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Li', ',', 'Y.'), (',', 'Y.', 'Schuurmans'), ('Y.', 'Schuurmans', ','), ('Schuurmans', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Li', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Schuurmans', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Li', 'Y. Schuurmans', 'D.']

>> Named Entities are: 
 [('GPE', 'Li')] 

>> Stemming using Porter Stemmer: 
 [('Li', 'li'), (',', ','), ('Y.', 'y.'), ('Schuurmans', 'schuurman'), (',', ','), ('D.', 'd.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Li', 'li'), (',', ','), ('Y.', 'y.'), ('Schuurmans', 'schuurman'), (',', ','), ('D.', 'd.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Li', 'Li'), (',', ','), ('Y.', 'Y.'), ('Schuurmans', 'Schuurmans'), (',', ','), ('D.', 'D.'), (',', ','), ('2011', '2011'), ('.', '.')]


------------------- Sentence 2 -------------------

MapReduce for parallel reinforcement learning.

>> Tokens are: 
 ['MapReduce', 'parallel', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('MapReduce', 'parallel'), ('parallel', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('MapReduce', 'parallel', 'reinforcement'), ('parallel', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('MapReduce', 'NNP'), ('parallel', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['MapReduce', 'parallel reinforcement learning']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('MapReduce', 'mapreduc'), ('parallel', 'parallel'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MapReduce', 'mapreduc'), ('parallel', 'parallel'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('MapReduce', 'MapReduce'), ('parallel', 'parallel'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 3 -------------------

Berlin,

>> Tokens are: 
 ['Berlin', ',']

>> Bigrams are: 
 [('Berlin', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Berlin', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Berlin']

>> Named Entities are: 
 [('GPE', 'Berlin')] 

>> Stemming using Porter Stemmer: 
 [('Berlin', 'berlin'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Berlin', 'berlin'), (',', ',')]

>> Lemmatization: 
 [('Berlin', 'Berlin'), (',', ',')]



========================================== PARAGRAPH 1551 ===========================================

Heidelberg, Springer, pp. 309-320.  

------------------- Sentence 1 -------------------

Heidelberg, Springer, pp.

>> Tokens are: 
 ['Heidelberg', ',', 'Springer', ',', 'pp', '.']

>> Bigrams are: 
 [('Heidelberg', ','), (',', 'Springer'), ('Springer', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Heidelberg', ',', 'Springer'), (',', 'Springer', ','), ('Springer', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Heidelberg', 'NNP'), (',', ','), ('Springer', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Heidelberg', 'Springer', 'pp']

>> Named Entities are: 
 [('GPE', 'Heidelberg'), ('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Heidelberg', 'heidelberg'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Heidelberg', 'heidelberg'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Heidelberg', 'Heidelberg'), (',', ','), ('Springer', 'Springer'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

309-320.

>> Tokens are: 
 ['309-320', '.']

>> Bigrams are: 
 [('309-320', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('309-320', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('309-320', '309-320'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('309-320', '309-320'), ('.', '.')]

>> Lemmatization: 
 [('309-320', '309-320'), ('.', '.')]



========================================== PARAGRAPH 1552 ===========================================

Lomotey, R. K., & Deters, R., 2014. Towards knowledge discovery in Big Data. s.l., IEEE  

------------------- Sentence 1 -------------------

Lomotey, R. K., & Deters, R., 2014.

>> Tokens are: 
 ['Lomotey', ',', 'R.', 'K.', ',', '&', 'Deters', ',', 'R.', ',', '2014', '.']

>> Bigrams are: 
 [('Lomotey', ','), (',', 'R.'), ('R.', 'K.'), ('K.', ','), (',', '&'), ('&', 'Deters'), ('Deters', ','), (',', 'R.'), ('R.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Lomotey', ',', 'R.'), (',', 'R.', 'K.'), ('R.', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Deters'), ('&', 'Deters', ','), ('Deters', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Lomotey', 'NNP'), (',', ','), ('R.', 'NNP'), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Deters', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lomotey', 'R. K.', 'Deters', 'R.']

>> Named Entities are: 
 [('GPE', 'Lomotey'), ('GPE', 'Deters')] 

>> Stemming using Porter Stemmer: 
 [('Lomotey', 'lomotey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Deters', 'deter'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lomotey', 'lomotey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Deters', 'deter'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Lomotey', 'Lomotey'), (',', ','), ('R.', 'R.'), ('K.', 'K.'), (',', ','), ('&', '&'), ('Deters', 'Deters'), (',', ','), ('R.', 'R.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Towards knowledge discovery in Big Data.

>> Tokens are: 
 ['Towards', 'knowledge', 'discovery', 'Big', 'Data', '.']

>> Bigrams are: 
 [('Towards', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'Big'), ('Big', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('Towards', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'Big'), ('discovery', 'Big', 'Data'), ('Big', 'Data', '.')]

>> POS Tags are: 
 [('Towards', 'NNS'), ('knowledge', 'VBP'), ('discovery', 'RB'), ('Big', 'NNP'), ('Data', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Towards', 'Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Towards', 'toward'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Towards', 'toward'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Towards', 'Towards'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('Big', 'Big'), ('Data', 'Data'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., IEEE

>> Tokens are: 
 ['s.l.', ',', 'IEEE']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE')]



========================================== PARAGRAPH 1553 ===========================================

Computer Society, p. 181–191.  

------------------- Sentence 1 -------------------

Computer Society, p. 181–191.

>> Tokens are: 
 ['Computer', 'Society', ',', 'p.', '181–191', '.']

>> Bigrams are: 
 [('Computer', 'Society'), ('Society', ','), (',', 'p.'), ('p.', '181–191'), ('181–191', '.')]

>> Trigrams are: 
 [('Computer', 'Society', ','), ('Society', ',', 'p.'), (',', 'p.', '181–191'), ('p.', '181–191', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Society', 'NNP'), (',', ','), ('p.', 'RB'), ('181–191', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Society']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Society')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Society', 'societi'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Society', 'societi'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Society', 'Society'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]



========================================== PARAGRAPH 1554 ===========================================

Lv, Z., Song, H., Basanta-Val, P., Steed, A. and Jo, M., 2017. IEEE Transactions on Industrial  

------------------- Sentence 1 -------------------

Lv, Z., Song, H., Basanta-Val, P., Steed, A. and Jo, M., 2017.

>> Tokens are: 
 ['Lv', ',', 'Z.', ',', 'Song', ',', 'H.', ',', 'Basanta-Val', ',', 'P.', ',', 'Steed', ',', 'A.', 'Jo', ',', 'M.', ',', '2017', '.']

>> Bigrams are: 
 [('Lv', ','), (',', 'Z.'), ('Z.', ','), (',', 'Song'), ('Song', ','), (',', 'H.'), ('H.', ','), (',', 'Basanta-Val'), ('Basanta-Val', ','), (',', 'P.'), ('P.', ','), (',', 'Steed'), ('Steed', ','), (',', 'A.'), ('A.', 'Jo'), ('Jo', ','), (',', 'M.'), ('M.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Lv', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Song'), (',', 'Song', ','), ('Song', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Basanta-Val'), (',', 'Basanta-Val', ','), ('Basanta-Val', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Steed'), (',', 'Steed', ','), ('Steed', ',', 'A.'), (',', 'A.', 'Jo'), ('A.', 'Jo', ','), ('Jo', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Lv', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Song', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Basanta-Val', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Steed', 'NNP'), (',', ','), ('A.', 'NNP'), ('Jo', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lv', 'Z.', 'Song', 'H.', 'Basanta-Val', 'P.', 'Steed', 'A. Jo', 'M.']

>> Named Entities are: 
 [('GPE', 'Lv'), ('GPE', 'Song'), ('PERSON', 'Steed')] 

>> Stemming using Porter Stemmer: 
 [('Lv', 'lv'), (',', ','), ('Z.', 'z.'), (',', ','), ('Song', 'song'), (',', ','), ('H.', 'h.'), (',', ','), ('Basanta-Val', 'basanta-v'), (',', ','), ('P.', 'p.'), (',', ','), ('Steed', 'steed'), (',', ','), ('A.', 'a.'), ('Jo', 'jo'), (',', ','), ('M.', 'm.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lv', 'lv'), (',', ','), ('Z.', 'z.'), (',', ','), ('Song', 'song'), (',', ','), ('H.', 'h.'), (',', ','), ('Basanta-Val', 'basanta-v'), (',', ','), ('P.', 'p.'), (',', ','), ('Steed', 'steed'), (',', ','), ('A.', 'a.'), ('Jo', 'jo'), (',', ','), ('M.', 'm.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Lv', 'Lv'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Song', 'Song'), (',', ','), ('H.', 'H.'), (',', ','), ('Basanta-Val', 'Basanta-Val'), (',', ','), ('P.', 'P.'), (',', ','), ('Steed', 'Steed'), (',', ','), ('A.', 'A.'), ('Jo', 'Jo'), (',', ','), ('M.', 'M.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Transactions on Industrial

>> Tokens are: 
 ['IEEE', 'Transactions', 'Industrial']

>> Bigrams are: 
 [('IEEE', 'Transactions'), ('Transactions', 'Industrial')]

>> Trigrams are: 
 [('IEEE', 'Transactions', 'Industrial')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Industrial', 'NNP')]

>> Noun Phrases are: 
 ['IEEE Transactions Industrial']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions Industrial')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Industrial', 'Industrial')]



========================================== PARAGRAPH 1555 ===========================================

Informatics journal, Volume 13, pp. 1891-1899.  

------------------- Sentence 1 -------------------

Informatics journal, Volume 13, pp.

>> Tokens are: 
 ['Informatics', 'journal', ',', 'Volume', '13', ',', 'pp', '.']

>> Bigrams are: 
 [('Informatics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '13'), ('13', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Informatics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '13'), ('Volume', '13', ','), ('13', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Informatics', 'NNS'), ('journal', 'JJ'), (',', ','), ('Volume', 'NN'), ('13', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Informatics', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 13')] 

>> Stemming using Porter Stemmer: 
 [('Informatics', 'informat'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Informatics', 'informat'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Informatics', 'Informatics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1891-1899.

>> Tokens are: 
 ['1891-1899', '.']

>> Bigrams are: 
 [('1891-1899', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1891-1899', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1891-1899', '1891-1899'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1891-1899', '1891-1899'), ('.', '.')]

>> Lemmatization: 
 [('1891-1899', '1891-1899'), ('.', '.')]



========================================== PARAGRAPH 1556 ===========================================

Ma, C., Zhang, H.H. and Wang, 2014. Machine learning for big data analytics in plants.. XTrends  

------------------- Sentence 1 -------------------

Ma, C., Zhang, H.H.

>> Tokens are: 
 ['Ma', ',', 'C.', ',', 'Zhang', ',', 'H.H', '.']

>> Bigrams are: 
 [('Ma', ','), (',', 'C.'), ('C.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'H.H'), ('H.H', '.')]

>> Trigrams are: 
 [('Ma', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'H.H'), (',', 'H.H', '.')]

>> POS Tags are: 
 [('Ma', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('H.H', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ma', 'C.', 'Zhang', 'H.H']

>> Named Entities are: 
 [('GPE', 'Ma'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Ma', 'ma'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.H', 'h.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ma', 'ma'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.H', 'h.h'), ('.', '.')]

>> Lemmatization: 
 [('Ma', 'Ma'), (',', ','), ('C.', 'C.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('H.H', 'H.H'), ('.', '.')]


------------------- Sentence 2 -------------------

and Wang, 2014.

>> Tokens are: 
 ['Wang', ',', '2014', '.']

>> Bigrams are: 
 [('Wang', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Wang', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Wang', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Wang', 'wang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang', 'wang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Wang', 'Wang'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 3 -------------------

Machine learning for big data analytics in plants.. XTrends

>> Tokens are: 
 ['Machine', 'learning', 'big', 'data', 'analytics', 'plants', '..', 'XTrends']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'plants'), ('plants', '..'), ('..', 'XTrends')]

>> Trigrams are: 
 [('Machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'plants'), ('analytics', 'plants', '..'), ('plants', '..', 'XTrends')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('plants', 'NNS'), ('..', 'VBP'), ('XTrends', 'NNS')]

>> Noun Phrases are: 
 ['Machine', 'big data analytics plants', 'XTrends']

>> Named Entities are: 
 [('GPE', 'Machine'), ('ORGANIZATION', 'XTrends')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'xtrend')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'xtrend')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'XTrends')]



========================================== PARAGRAPH 1557 ===========================================

in plant science Journal, pp. 798-808.  

------------------- Sentence 1 -------------------

in plant science Journal, pp.

>> Tokens are: 
 ['plant', 'science', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('plant', 'science'), ('science', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('plant', 'science', 'Journal'), ('science', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('plant', 'NN'), ('science', 'NN'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['plant science Journal', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('plant', 'plant'), ('science', 'scienc'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('plant', 'plant'), ('science', 'scienc'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('plant', 'plant'), ('science', 'science'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

798-808.

>> Tokens are: 
 ['798-808', '.']

>> Bigrams are: 
 [('798-808', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('798-808', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('798-808', '798-808'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('798-808', '798-808'), ('.', '.')]

>> Lemmatization: 
 [('798-808', '798-808'), ('.', '.')]



========================================== PARAGRAPH 1558 ===========================================

Manyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C. and Byers, A.H., 2011.  

------------------- Sentence 1 -------------------

Manyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C. and Byers, A.H., 2011.

>> Tokens are: 
 ['Manyika', ',', 'J.', ',', 'Chui', ',', 'M.', ',', 'Brown', ',', 'B.', ',', 'Bughin', ',', 'J.', ',', 'Dobbs', ',', 'R.', ',', 'Roxburgh', ',', 'C.', 'Byers', ',', 'A.H.', ',', '2011', '.']

>> Bigrams are: 
 [('Manyika', ','), (',', 'J.'), ('J.', ','), (',', 'Chui'), ('Chui', ','), (',', 'M.'), ('M.', ','), (',', 'Brown'), ('Brown', ','), (',', 'B.'), ('B.', ','), (',', 'Bughin'), ('Bughin', ','), (',', 'J.'), ('J.', ','), (',', 'Dobbs'), ('Dobbs', ','), (',', 'R.'), ('R.', ','), (',', 'Roxburgh'), ('Roxburgh', ','), (',', 'C.'), ('C.', 'Byers'), ('Byers', ','), (',', 'A.H.'), ('A.H.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Manyika', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Chui'), (',', 'Chui', ','), ('Chui', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Brown'), (',', 'Brown', ','), ('Brown', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Bughin'), (',', 'Bughin', ','), ('Bughin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Dobbs'), (',', 'Dobbs', ','), ('Dobbs', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Roxburgh'), (',', 'Roxburgh', ','), ('Roxburgh', ',', 'C.'), (',', 'C.', 'Byers'), ('C.', 'Byers', ','), ('Byers', ',', 'A.H.'), (',', 'A.H.', ','), ('A.H.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Manyika', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Chui', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Brown', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Bughin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Dobbs', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Roxburgh', 'NNP'), (',', ','), ('C.', 'NNP'), ('Byers', 'NNP'), (',', ','), ('A.H.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Manyika', 'J.', 'Chui', 'M.', 'Brown', 'B.', 'Bughin', 'J.', 'Dobbs', 'R.', 'Roxburgh', 'C. Byers', 'A.H.']

>> Named Entities are: 
 [('GPE', 'Manyika'), ('PERSON', 'Chui'), ('PERSON', 'Brown'), ('PERSON', 'Bughin'), ('PERSON', 'Dobbs'), ('GPE', 'Roxburgh')] 

>> Stemming using Porter Stemmer: 
 [('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), (',', ','), ('Brown', 'brown'), (',', ','), ('B.', 'b.'), (',', ','), ('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Dobbs', 'dobb'), (',', ','), ('R.', 'r.'), (',', ','), ('Roxburgh', 'roxburgh'), (',', ','), ('C.', 'c.'), ('Byers', 'byer'), (',', ','), ('A.H.', 'a.h.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), (',', ','), ('Brown', 'brown'), (',', ','), ('B.', 'b.'), (',', ','), ('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Dobbs', 'dobb'), (',', ','), ('R.', 'r.'), (',', ','), ('Roxburgh', 'roxburgh'), (',', ','), ('C.', 'c.'), ('Byers', 'byer'), (',', ','), ('A.H.', 'a.h.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Manyika', 'Manyika'), (',', ','), ('J.', 'J.'), (',', ','), ('Chui', 'Chui'), (',', ','), ('M.', 'M.'), (',', ','), ('Brown', 'Brown'), (',', ','), ('B.', 'B.'), (',', ','), ('Bughin', 'Bughin'), (',', ','), ('J.', 'J.'), (',', ','), ('Dobbs', 'Dobbs'), (',', ','), ('R.', 'R.'), (',', ','), ('Roxburgh', 'Roxburgh'), (',', ','), ('C.', 'C.'), ('Byers', 'Byers'), (',', ','), ('A.H.', 'A.H.'), (',', ','), ('2011', '2011'), ('.', '.')]



========================================== PARAGRAPH 1559 ===========================================

Big data: The next frontier for innovation, competition, and productivity..   

------------------- Sentence 1 -------------------

Big data: The next frontier for innovation, competition, and productivity..

>> Tokens are: 
 ['Big', 'data', ':', 'The', 'next', 'frontier', 'innovation', ',', 'competition', ',', 'productivity', '..']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'The'), ('The', 'next'), ('next', 'frontier'), ('frontier', 'innovation'), ('innovation', ','), (',', 'competition'), ('competition', ','), (',', 'productivity'), ('productivity', '..')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'The'), (':', 'The', 'next'), ('The', 'next', 'frontier'), ('next', 'frontier', 'innovation'), ('frontier', 'innovation', ','), ('innovation', ',', 'competition'), (',', 'competition', ','), ('competition', ',', 'productivity'), (',', 'productivity', '..')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('The', 'DT'), ('next', 'JJ'), ('frontier', 'NN'), ('innovation', 'NN'), (',', ','), ('competition', 'NN'), (',', ','), ('productivity', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['Big data', 'The next frontier innovation', 'competition', 'productivity ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('The', 'the'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innov'), (',', ','), ('competition', 'competit'), (',', ','), ('productivity', 'product'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('The', 'the'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innov'), (',', ','), ('competition', 'competit'), (',', ','), ('productivity', 'product'), ('..', '..')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('The', 'The'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innovation'), (',', ','), ('competition', 'competition'), (',', ','), ('productivity', 'productivity'), ('..', '..')]



========================================== PARAGRAPH 1560 ===========================================

Mayer-Schonberger, V. and Padova, Y., 2015. Regime Change: Enabling Big Data through  

------------------- Sentence 1 -------------------

Mayer-Schonberger, V. and Padova, Y., 2015.

>> Tokens are: 
 ['Mayer-Schonberger', ',', 'V.', 'Padova', ',', 'Y.', ',', '2015', '.']

>> Bigrams are: 
 [('Mayer-Schonberger', ','), (',', 'V.'), ('V.', 'Padova'), ('Padova', ','), (',', 'Y.'), ('Y.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Mayer-Schonberger', ',', 'V.'), (',', 'V.', 'Padova'), ('V.', 'Padova', ','), ('Padova', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Mayer-Schonberger', 'NNP'), (',', ','), ('V.', 'NNP'), ('Padova', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Mayer-Schonberger', 'V. Padova', 'Y.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mayer-Schonberger', 'mayer-schonberg'), (',', ','), ('V.', 'v.'), ('Padova', 'padova'), (',', ','), ('Y.', 'y.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mayer-Schonberger', 'mayer-schonberg'), (',', ','), ('V.', 'v.'), ('Padova', 'padova'), (',', ','), ('Y.', 'y.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Mayer-Schonberger', 'Mayer-Schonberger'), (',', ','), ('V.', 'V.'), ('Padova', 'Padova'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Regime Change: Enabling Big Data through

>> Tokens are: 
 ['Regime', 'Change', ':', 'Enabling', 'Big', 'Data']

>> Bigrams are: 
 [('Regime', 'Change'), ('Change', ':'), (':', 'Enabling'), ('Enabling', 'Big'), ('Big', 'Data')]

>> Trigrams are: 
 [('Regime', 'Change', ':'), ('Change', ':', 'Enabling'), (':', 'Enabling', 'Big'), ('Enabling', 'Big', 'Data')]

>> POS Tags are: 
 [('Regime', 'JJ'), ('Change', 'NN'), (':', ':'), ('Enabling', 'NN'), ('Big', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['Regime Change', 'Enabling Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Regime', 'regim'), ('Change', 'chang'), (':', ':'), ('Enabling', 'enabl'), ('Big', 'big'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Regime', 'regim'), ('Change', 'chang'), (':', ':'), ('Enabling', 'enabl'), ('Big', 'big'), ('Data', 'data')]

>> Lemmatization: 
 [('Regime', 'Regime'), ('Change', 'Change'), (':', ':'), ('Enabling', 'Enabling'), ('Big', 'Big'), ('Data', 'Data')]



========================================== PARAGRAPH 1561 ===========================================

Europe's New Data Protection Regulation.. Colum. Sci. & Tech. L. Rev. Journal, p. 315.  

------------------- Sentence 1 -------------------

Europe's New Data Protection Regulation.. Colum.

>> Tokens are: 
 ['Europe', "'s", 'New', 'Data', 'Protection', 'Regulation', '..', 'Colum', '.']

>> Bigrams are: 
 [('Europe', "'s"), ("'s", 'New'), ('New', 'Data'), ('Data', 'Protection'), ('Protection', 'Regulation'), ('Regulation', '..'), ('..', 'Colum'), ('Colum', '.')]

>> Trigrams are: 
 [('Europe', "'s", 'New'), ("'s", 'New', 'Data'), ('New', 'Data', 'Protection'), ('Data', 'Protection', 'Regulation'), ('Protection', 'Regulation', '..'), ('Regulation', '..', 'Colum'), ('..', 'Colum', '.')]

>> POS Tags are: 
 [('Europe', 'NNP'), ("'s", 'POS'), ('New', 'NNP'), ('Data', 'NNP'), ('Protection', 'NNP'), ('Regulation', 'NNP'), ('..', 'NNP'), ('Colum', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Europe', 'New Data Protection Regulation .. Colum']

>> Named Entities are: 
 [('GPE', 'Europe'), ('ORGANIZATION', 'New Data Protection Regulation')] 

>> Stemming using Porter Stemmer: 
 [('Europe', 'europ'), ("'s", "'s"), ('New', 'new'), ('Data', 'data'), ('Protection', 'protect'), ('Regulation', 'regul'), ('..', '..'), ('Colum', 'colum'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Europe', 'europ'), ("'s", "'s"), ('New', 'new'), ('Data', 'data'), ('Protection', 'protect'), ('Regulation', 'regul'), ('..', '..'), ('Colum', 'colum'), ('.', '.')]

>> Lemmatization: 
 [('Europe', 'Europe'), ("'s", "'s"), ('New', 'New'), ('Data', 'Data'), ('Protection', 'Protection'), ('Regulation', 'Regulation'), ('..', '..'), ('Colum', 'Colum'), ('.', '.')]


------------------- Sentence 2 -------------------

Sci.

>> Tokens are: 
 ['Sci', '.']

>> Bigrams are: 
 [('Sci', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sci', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sci']

>> Named Entities are: 
 [('GPE', 'Sci')] 

>> Stemming using Porter Stemmer: 
 [('Sci', 'sci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sci', 'sci'), ('.', '.')]

>> Lemmatization: 
 [('Sci', 'Sci'), ('.', '.')]


------------------- Sentence 3 -------------------

& Tech.

>> Tokens are: 
 ['&', 'Tech', '.']

>> Bigrams are: 
 [('&', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('&', 'Tech', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tech']

>> Named Entities are: 
 [('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

L. Rev.

>> Tokens are: 
 ['L.', 'Rev', '.']

>> Bigrams are: 
 [('L.', 'Rev'), ('Rev', '.')]

>> Trigrams are: 
 [('L.', 'Rev', '.')]

>> POS Tags are: 
 [('L.', 'NNP'), ('Rev', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['L. Rev']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('L.', 'l.'), ('Rev', 'rev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('L.', 'l.'), ('Rev', 'rev'), ('.', '.')]

>> Lemmatization: 
 [('L.', 'L.'), ('Rev', 'Rev'), ('.', '.')]


------------------- Sentence 5 -------------------

Journal, p. 315.

>> Tokens are: 
 ['Journal', ',', 'p.', '315', '.']

>> Bigrams are: 
 [('Journal', ','), (',', 'p.'), ('p.', '315'), ('315', '.')]

>> Trigrams are: 
 [('Journal', ',', 'p.'), (',', 'p.', '315'), ('p.', '315', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('315', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal']

>> Named Entities are: 
 [('GPE', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]



========================================== PARAGRAPH 1562 ===========================================

Mergel, I., Rethemeyer, R. K., & Isett, K., 2016. Big data in public affairs. Public Administration  

------------------- Sentence 1 -------------------

Mergel, I., Rethemeyer, R. K., & Isett, K., 2016.

>> Tokens are: 
 ['Mergel', ',', 'I.', ',', 'Rethemeyer', ',', 'R.', 'K.', ',', '&', 'Isett', ',', 'K.', ',', '2016', '.']

>> Bigrams are: 
 [('Mergel', ','), (',', 'I.'), ('I.', ','), (',', 'Rethemeyer'), ('Rethemeyer', ','), (',', 'R.'), ('R.', 'K.'), ('K.', ','), (',', '&'), ('&', 'Isett'), ('Isett', ','), (',', 'K.'), ('K.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Mergel', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Rethemeyer'), (',', 'Rethemeyer', ','), ('Rethemeyer', ',', 'R.'), (',', 'R.', 'K.'), ('R.', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Isett'), ('&', 'Isett', ','), ('Isett', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Mergel', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Rethemeyer', 'NNP'), (',', ','), ('R.', 'NNP'), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Isett', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Mergel', 'I.', 'Rethemeyer', 'R. K.', 'Isett', 'K.']

>> Named Entities are: 
 [('GPE', 'Mergel'), ('GPE', 'Rethemeyer'), ('PERSON', 'Isett')] 

>> Stemming using Porter Stemmer: 
 [('Mergel', 'mergel'), (',', ','), ('I.', 'i.'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Isett', 'isett'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mergel', 'mergel'), (',', ','), ('I.', 'i.'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Isett', 'isett'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Mergel', 'Mergel'), (',', ','), ('I.', 'I.'), (',', ','), ('Rethemeyer', 'Rethemeyer'), (',', ','), ('R.', 'R.'), ('K.', 'K.'), (',', ','), ('&', '&'), ('Isett', 'Isett'), (',', ','), ('K.', 'K.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data in public affairs.

>> Tokens are: 
 ['Big', 'data', 'public', 'affairs', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'public'), ('public', 'affairs'), ('affairs', '.')]

>> Trigrams are: 
 [('Big', 'data', 'public'), ('data', 'public', 'affairs'), ('public', 'affairs', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('public', 'JJ'), ('affairs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'public affairs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]


------------------- Sentence 3 -------------------

Public Administration

>> Tokens are: 
 ['Public', 'Administration']

>> Bigrams are: 
 [('Public', 'Administration')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Public', 'NNP'), ('Administration', 'NNP')]

>> Noun Phrases are: 
 ['Public Administration']

>> Named Entities are: 
 [('PERSON', 'Public'), ('ORGANIZATION', 'Administration')] 

>> Stemming using Porter Stemmer: 
 [('Public', 'public'), ('Administration', 'administr')]

>> Stemming using Snowball Stemmer: 
 [('Public', 'public'), ('Administration', 'administr')]

>> Lemmatization: 
 [('Public', 'Public'), ('Administration', 'Administration')]



========================================== PARAGRAPH 1563 ===========================================

Review Journal, pp. 928-937.  

------------------- Sentence 1 -------------------

Review Journal, pp.

>> Tokens are: 
 ['Review', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Review', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Review', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Review', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Review Journal', 'pp']

>> Named Entities are: 
 [('PERSON', 'Review'), ('ORGANIZATION', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Review', 'review'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Review', 'review'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Review', 'Review'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

928-937.

>> Tokens are: 
 ['928-937', '.']

>> Bigrams are: 
 [('928-937', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('928-937', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('928-937', '928-937'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('928-937', '928-937'), ('.', '.')]

>> Lemmatization: 
 [('928-937', '928-937'), ('.', '.')]



========================================== PARAGRAPH 1564 ===========================================

Mikalef, P., Pappas, I.O., Krogstie, J. and Giannakos, M., 2018. Big data analytics capabilities: a  

------------------- Sentence 1 -------------------

Mikalef, P., Pappas, I.O., Krogstie, J. and Giannakos, M., 2018.

>> Tokens are: 
 ['Mikalef', ',', 'P.', ',', 'Pappas', ',', 'I.O.', ',', 'Krogstie', ',', 'J.', 'Giannakos', ',', 'M.', ',', '2018', '.']

>> Bigrams are: 
 [('Mikalef', ','), (',', 'P.'), ('P.', ','), (',', 'Pappas'), ('Pappas', ','), (',', 'I.O.'), ('I.O.', ','), (',', 'Krogstie'), ('Krogstie', ','), (',', 'J.'), ('J.', 'Giannakos'), ('Giannakos', ','), (',', 'M.'), ('M.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Mikalef', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Pappas'), (',', 'Pappas', ','), ('Pappas', ',', 'I.O.'), (',', 'I.O.', ','), ('I.O.', ',', 'Krogstie'), (',', 'Krogstie', ','), ('Krogstie', ',', 'J.'), (',', 'J.', 'Giannakos'), ('J.', 'Giannakos', ','), ('Giannakos', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Mikalef', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Pappas', 'NNP'), (',', ','), ('I.O.', 'NNP'), (',', ','), ('Krogstie', 'NNP'), (',', ','), ('J.', 'NNP'), ('Giannakos', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Mikalef', 'P.', 'Pappas', 'I.O.', 'Krogstie', 'J. Giannakos', 'M.']

>> Named Entities are: 
 [('GPE', 'Mikalef'), ('PERSON', 'Pappas'), ('GPE', 'Krogstie'), ('PERSON', 'J. Giannakos')] 

>> Stemming using Porter Stemmer: 
 [('Mikalef', 'mikalef'), (',', ','), ('P.', 'p.'), (',', ','), ('Pappas', 'pappa'), (',', ','), ('I.O.', 'i.o.'), (',', ','), ('Krogstie', 'krogsti'), (',', ','), ('J.', 'j.'), ('Giannakos', 'giannako'), (',', ','), ('M.', 'm.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikalef', 'mikalef'), (',', ','), ('P.', 'p.'), (',', ','), ('Pappas', 'pappa'), (',', ','), ('I.O.', 'i.o.'), (',', ','), ('Krogstie', 'krogsti'), (',', ','), ('J.', 'j.'), ('Giannakos', 'giannako'), (',', ','), ('M.', 'm.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Mikalef', 'Mikalef'), (',', ','), ('P.', 'P.'), (',', ','), ('Pappas', 'Pappas'), (',', ','), ('I.O.', 'I.O.'), (',', ','), ('Krogstie', 'Krogstie'), (',', ','), ('J.', 'J.'), ('Giannakos', 'Giannakos'), (',', ','), ('M.', 'M.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics capabilities: a

>> Tokens are: 
 ['Big', 'data', 'analytics', 'capabilities', ':']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'capabilities'), ('capabilities', ':')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'capabilities'), ('analytics', 'capabilities', ':')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('capabilities', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['Big data analytics capabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), (':', ':')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('capabilities', 'capability'), (':', ':')]



========================================== PARAGRAPH 1565 ===========================================

systematic literature review and research agenda.. Journal of Information Systems and e-Business  

------------------- Sentence 1 -------------------

systematic literature review and research agenda.. Journal of Information Systems and e-Business

>> Tokens are: 
 ['systematic', 'literature', 'review', 'research', 'agenda', '..', 'Journal', 'Information', 'Systems', 'e-Business']

>> Bigrams are: 
 [('systematic', 'literature'), ('literature', 'review'), ('review', 'research'), ('research', 'agenda'), ('agenda', '..'), ('..', 'Journal'), ('Journal', 'Information'), ('Information', 'Systems'), ('Systems', 'e-Business')]

>> Trigrams are: 
 [('systematic', 'literature', 'review'), ('literature', 'review', 'research'), ('review', 'research', 'agenda'), ('research', 'agenda', '..'), ('agenda', '..', 'Journal'), ('..', 'Journal', 'Information'), ('Journal', 'Information', 'Systems'), ('Information', 'Systems', 'e-Business')]

>> POS Tags are: 
 [('systematic', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('research', 'NN'), ('agenda', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), ('e-Business', 'NN')]

>> Noun Phrases are: 
 ['systematic literature review research agenda .. Journal Information Systems e-Business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('systematic', 'systemat'), ('literature', 'literatur'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), ('e-Business', 'e-busi')]

>> Stemming using Snowball Stemmer: 
 [('systematic', 'systemat'), ('literature', 'literatur'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), ('e-Business', 'e-busi')]

>> Lemmatization: 
 [('systematic', 'systematic'), ('literature', 'literature'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'Journal'), ('Information', 'Information'), ('Systems', 'Systems'), ('e-Business', 'e-Business')]



========================================== PARAGRAPH 1566 ===========================================

Management, Volume 3, pp. 547-578.  

------------------- Sentence 1 -------------------

Management, Volume 3, pp.

>> Tokens are: 
 ['Management', ',', 'Volume', '3', ',', 'pp', '.']

>> Bigrams are: 
 [('Management', ','), (',', 'Volume'), ('Volume', '3'), ('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Management', ',', 'Volume'), (',', 'Volume', '3'), ('Volume', '3', ','), ('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Management', 'NN'), (',', ','), ('Volume', 'NN'), ('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Management', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Management'), ('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

547-578.

>> Tokens are: 
 ['547-578', '.']

>> Bigrams are: 
 [('547-578', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('547-578', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('547-578', '547-578'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('547-578', '547-578'), ('.', '.')]

>> Lemmatization: 
 [('547-578', '547-578'), ('.', '.')]



========================================== PARAGRAPH 1567 ===========================================

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D. and Riedmiller,  

------------------- Sentence 1 -------------------

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D. and Riedmiller,

>> Tokens are: 
 ['Mnih', ',', 'V.', ',', 'Kavukcuoglu', ',', 'K.', ',', 'Silver', ',', 'D.', ',', 'Graves', ',', 'A.', ',', 'Antonoglou', ',', 'I.', ',', 'Wierstra', ',', 'D.', 'Riedmiller', ',']

>> Bigrams are: 
 [('Mnih', ','), (',', 'V.'), ('V.', ','), (',', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'K.'), ('K.', ','), (',', 'Silver'), ('Silver', ','), (',', 'D.'), ('D.', ','), (',', 'Graves'), ('Graves', ','), (',', 'A.'), ('A.', ','), (',', 'Antonoglou'), ('Antonoglou', ','), (',', 'I.'), ('I.', ','), (',', 'Wierstra'), ('Wierstra', ','), (',', 'D.'), ('D.', 'Riedmiller'), ('Riedmiller', ',')]

>> Trigrams are: 
 [('Mnih', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Kavukcuoglu'), (',', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Silver'), (',', 'Silver', ','), ('Silver', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Graves'), (',', 'Graves', ','), ('Graves', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Antonoglou'), (',', 'Antonoglou', ','), ('Antonoglou', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Wierstra'), (',', 'Wierstra', ','), ('Wierstra', ',', 'D.'), (',', 'D.', 'Riedmiller'), ('D.', 'Riedmiller', ',')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Kavukcuoglu', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Silver', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Graves', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Antonoglou', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Wierstra', 'NNP'), (',', ','), ('D.', 'NNP'), ('Riedmiller', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Mnih', 'V.', 'Kavukcuoglu', 'K.', 'Silver', 'D.', 'Graves', 'A.', 'Antonoglou', 'I.', 'Wierstra', 'D. Riedmiller']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('GPE', 'Kavukcuoglu'), ('GPE', 'Silver'), ('GPE', 'Graves'), ('PERSON', 'Antonoglou'), ('GPE', 'Wierstra')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Antonoglou', 'antonogl'), (',', ','), ('I.', 'i.'), (',', ','), ('Wierstra', 'wierstra'), (',', ','), ('D.', 'd.'), ('Riedmiller', 'riedmil'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Antonoglou', 'antonoglou'), (',', ','), ('I.', 'i.'), (',', ','), ('Wierstra', 'wierstra'), (',', ','), ('D.', 'd.'), ('Riedmiller', 'riedmil'), (',', ',')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('V.', 'V.'), (',', ','), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('K.', 'K.'), (',', ','), ('Silver', 'Silver'), (',', ','), ('D.', 'D.'), (',', ','), ('Graves', 'Graves'), (',', ','), ('A.', 'A.'), (',', ','), ('Antonoglou', 'Antonoglou'), (',', ','), ('I.', 'I.'), (',', ','), ('Wierstra', 'Wierstra'), (',', ','), ('D.', 'D.'), ('Riedmiller', 'Riedmiller'), (',', ',')]



========================================== PARAGRAPH 1568 ===========================================

M., 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.  

------------------- Sentence 1 -------------------

M., 2013.

>> Tokens are: 
 ['M.', ',', '2013', '.']

>> Bigrams are: 
 [('M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['M.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('M.', 'M.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Playing atari with deep reinforcement learning.

>> Tokens are: 
 ['Playing', 'atari', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Playing', 'atari'), ('atari', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Playing', 'atari', 'deep'), ('atari', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Playing', 'VBG'), ('atari', 'JJ'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['atari deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Playing', 'play'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Playing', 'play'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Playing', 'Playing'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 3 -------------------

arXiv preprint arXiv:1312.5602.

>> Tokens are: 
 ['arXiv', 'preprint', 'arXiv:1312.5602', '.']

>> Bigrams are: 
 [('arXiv', 'preprint'), ('preprint', 'arXiv:1312.5602'), ('arXiv:1312.5602', '.')]

>> Trigrams are: 
 [('arXiv', 'preprint', 'arXiv:1312.5602'), ('preprint', 'arXiv:1312.5602', '.')]

>> POS Tags are: 
 [('arXiv', 'JJ'), ('preprint', 'NN'), ('arXiv:1312.5602', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['arXiv preprint arXiv:1312.5602']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arxiv:1312.5602'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arxiv:1312.5602'), ('.', '.')]

>> Lemmatization: 
 [('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arXiv:1312.5602'), ('.', '.')]



========================================== PARAGRAPH 1569 ===========================================

Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and  

------------------- Sentence 1 -------------------

Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and

>> Tokens are: 
 ['Mnih', ',', 'Volodymyr', 'Badia', ',', 'Adria', 'Puigdomenech', 'Mirza', ',', 'Mehdi', 'Graves', ',', 'Alex']

>> Bigrams are: 
 [('Mnih', ','), (',', 'Volodymyr'), ('Volodymyr', 'Badia'), ('Badia', ','), (',', 'Adria'), ('Adria', 'Puigdomenech'), ('Puigdomenech', 'Mirza'), ('Mirza', ','), (',', 'Mehdi'), ('Mehdi', 'Graves'), ('Graves', ','), (',', 'Alex')]

>> Trigrams are: 
 [('Mnih', ',', 'Volodymyr'), (',', 'Volodymyr', 'Badia'), ('Volodymyr', 'Badia', ','), ('Badia', ',', 'Adria'), (',', 'Adria', 'Puigdomenech'), ('Adria', 'Puigdomenech', 'Mirza'), ('Puigdomenech', 'Mirza', ','), ('Mirza', ',', 'Mehdi'), (',', 'Mehdi', 'Graves'), ('Mehdi', 'Graves', ','), ('Graves', ',', 'Alex')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('Volodymyr', 'NNP'), ('Badia', 'NNP'), (',', ','), ('Adria', 'NNP'), ('Puigdomenech', 'NNP'), ('Mirza', 'NNP'), (',', ','), ('Mehdi', 'NNP'), ('Graves', 'NNP'), (',', ','), ('Alex', 'NNP')]

>> Noun Phrases are: 
 ['Mnih', 'Volodymyr Badia', 'Adria Puigdomenech Mirza', 'Mehdi Graves', 'Alex']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('PERSON', 'Volodymyr Badia'), ('PERSON', 'Adria Puigdomenech Mirza'), ('PERSON', 'Mehdi Graves'), ('PERSON', 'Alex')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Badia', 'badia'), (',', ','), ('Adria', 'adria'), ('Puigdomenech', 'puigdomenech'), ('Mirza', 'mirza'), (',', ','), ('Mehdi', 'mehdi'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Badia', 'badia'), (',', ','), ('Adria', 'adria'), ('Puigdomenech', 'puigdomenech'), ('Mirza', 'mirza'), (',', ','), ('Mehdi', 'mehdi'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('Volodymyr', 'Volodymyr'), ('Badia', 'Badia'), (',', ','), ('Adria', 'Adria'), ('Puigdomenech', 'Puigdomenech'), ('Mirza', 'Mirza'), (',', ','), ('Mehdi', 'Mehdi'), ('Graves', 'Graves'), (',', ','), ('Alex', 'Alex')]



========================================== PARAGRAPH 1570 ===========================================

Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray, 2016.  

------------------- Sentence 1 -------------------

Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray, 2016.

>> Tokens are: 
 ['Lillicrap', ',', 'Timothy', 'Harley', ',', 'Tim', 'Silver', ',', 'David', 'Kavukcuoglu', ',', 'Koray', ',', '2016', '.']

>> Bigrams are: 
 [('Lillicrap', ','), (',', 'Timothy'), ('Timothy', 'Harley'), ('Harley', ','), (',', 'Tim'), ('Tim', 'Silver'), ('Silver', ','), (',', 'David'), ('David', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'Koray'), ('Koray', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Lillicrap', ',', 'Timothy'), (',', 'Timothy', 'Harley'), ('Timothy', 'Harley', ','), ('Harley', ',', 'Tim'), (',', 'Tim', 'Silver'), ('Tim', 'Silver', ','), ('Silver', ',', 'David'), (',', 'David', 'Kavukcuoglu'), ('David', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'Koray'), (',', 'Koray', ','), ('Koray', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Lillicrap', 'NNP'), (',', ','), ('Timothy', 'NNP'), ('Harley', 'NNP'), (',', ','), ('Tim', 'NNP'), ('Silver', 'NNP'), (',', ','), ('David', 'NNP'), ('Kavukcuoglu', 'NNP'), (',', ','), ('Koray', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lillicrap', 'Timothy Harley', 'Tim Silver', 'David Kavukcuoglu', 'Koray']

>> Named Entities are: 
 [('GPE', 'Lillicrap'), ('PERSON', 'Timothy Harley'), ('PERSON', 'Tim Silver'), ('PERSON', 'David Kavukcuoglu'), ('GPE', 'Koray')] 

>> Stemming using Porter Stemmer: 
 [('Lillicrap', 'lillicrap'), (',', ','), ('Timothy', 'timothi'), ('Harley', 'harley'), (',', ','), ('Tim', 'tim'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lillicrap', 'lillicrap'), (',', ','), ('Timothy', 'timothi'), ('Harley', 'harley'), (',', ','), ('Tim', 'tim'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Lillicrap', 'Lillicrap'), (',', ','), ('Timothy', 'Timothy'), ('Harley', 'Harley'), (',', ','), ('Tim', 'Tim'), ('Silver', 'Silver'), (',', ','), ('David', 'David'), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('Koray', 'Koray'), (',', ','), ('2016', '2016'), ('.', '.')]



========================================== PARAGRAPH 1571 ===========================================

Asynchronous methods for deep reinforcement learning. New York, NY, US, s.n., pp. 1928--1937.  

------------------- Sentence 1 -------------------

Asynchronous methods for deep reinforcement learning.

>> Tokens are: 
 ['Asynchronous', 'methods', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Asynchronous', 'methods'), ('methods', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Asynchronous', 'methods', 'deep'), ('methods', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Asynchronous', 'JJ'), ('methods', 'NNS'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Asynchronous methods', 'deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Asynchronous', 'asynchron'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Asynchronous', 'asynchron'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Asynchronous', 'Asynchronous'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

New York, NY, US, s.n., pp.

>> Tokens are: 
 ['New', 'York', ',', 'NY', ',', 'US', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('New', 'York'), ('York', ','), (',', 'NY'), ('NY', ','), (',', 'US'), ('US', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('New', 'York', ','), ('York', ',', 'NY'), (',', 'NY', ','), ('NY', ',', 'US'), (',', 'US', ','), ('US', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('New', 'NNP'), ('York', 'NNP'), (',', ','), ('NY', 'NNP'), (',', ','), ('US', 'NNP'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['New York', 'NY', 'US', 's.n.', 'pp']

>> Named Entities are: 
 [('GPE', 'New York'), ('ORGANIZATION', 'NY'), ('GSP', 'US')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('York', 'york'), (',', ','), ('NY', 'ny'), (',', ','), ('US', 'us'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('York', 'york'), (',', ','), ('NY', 'ny'), (',', ','), ('US', 'us'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('New', 'New'), ('York', 'York'), (',', ','), ('NY', 'NY'), (',', ','), ('US', 'US'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1928--1937.

>> Tokens are: 
 ['1928', '--', '1937', '.']

>> Bigrams are: 
 [('1928', '--'), ('--', '1937'), ('1937', '.')]

>> Trigrams are: 
 [('1928', '--', '1937'), ('--', '1937', '.')]

>> POS Tags are: 
 [('1928', 'CD'), ('--', ':'), ('1937', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]

>> Lemmatization: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]



========================================== PARAGRAPH 1572 ===========================================

Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness,  

------------------- Sentence 1 -------------------

Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness,

>> Tokens are: 
 ['Mnih', ',', 'Volodymyr', 'Kavukcuoglu', ',', 'Koray', 'Silver', ',', 'David', 'Rusu', ',', 'Andrei', 'A', 'Veness', ',']

>> Bigrams are: 
 [('Mnih', ','), (',', 'Volodymyr'), ('Volodymyr', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'Koray'), ('Koray', 'Silver'), ('Silver', ','), (',', 'David'), ('David', 'Rusu'), ('Rusu', ','), (',', 'Andrei'), ('Andrei', 'A'), ('A', 'Veness'), ('Veness', ',')]

>> Trigrams are: 
 [('Mnih', ',', 'Volodymyr'), (',', 'Volodymyr', 'Kavukcuoglu'), ('Volodymyr', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'Koray'), (',', 'Koray', 'Silver'), ('Koray', 'Silver', ','), ('Silver', ',', 'David'), (',', 'David', 'Rusu'), ('David', 'Rusu', ','), ('Rusu', ',', 'Andrei'), (',', 'Andrei', 'A'), ('Andrei', 'A', 'Veness'), ('A', 'Veness', ',')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('Volodymyr', 'NNP'), ('Kavukcuoglu', 'NNP'), (',', ','), ('Koray', 'NNP'), ('Silver', 'NNP'), (',', ','), ('David', 'NNP'), ('Rusu', 'NNP'), (',', ','), ('Andrei', 'NNP'), ('A', 'NNP'), ('Veness', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Mnih', 'Volodymyr Kavukcuoglu', 'Koray Silver', 'David Rusu', 'Andrei A Veness']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('PERSON', 'Volodymyr Kavukcuoglu'), ('PERSON', 'Koray Silver'), ('PERSON', 'David Rusu'), ('PERSON', 'Andrei A Veness')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Rusu', 'rusu'), (',', ','), ('Andrei', 'andrei'), ('A', 'a'), ('Veness', 'veness'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Rusu', 'rusu'), (',', ','), ('Andrei', 'andrei'), ('A', 'a'), ('Veness', 'veness'), (',', ',')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('Volodymyr', 'Volodymyr'), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('Koray', 'Koray'), ('Silver', 'Silver'), (',', ','), ('David', 'David'), ('Rusu', 'Rusu'), (',', ','), ('Andrei', 'Andrei'), ('A', 'A'), ('Veness', 'Veness'), (',', ',')]



========================================== PARAGRAPH 1573 ===========================================

Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K  

------------------- Sentence 1 -------------------

Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K

>> Tokens are: 
 ['Joel', 'Bellemare', ',', 'Marc', 'G', 'Graves', ',', 'Alex', 'Riedmiller', ',', 'Martin', 'Fidjeland', ',', 'Andreas', 'K']

>> Bigrams are: 
 [('Joel', 'Bellemare'), ('Bellemare', ','), (',', 'Marc'), ('Marc', 'G'), ('G', 'Graves'), ('Graves', ','), (',', 'Alex'), ('Alex', 'Riedmiller'), ('Riedmiller', ','), (',', 'Martin'), ('Martin', 'Fidjeland'), ('Fidjeland', ','), (',', 'Andreas'), ('Andreas', 'K')]

>> Trigrams are: 
 [('Joel', 'Bellemare', ','), ('Bellemare', ',', 'Marc'), (',', 'Marc', 'G'), ('Marc', 'G', 'Graves'), ('G', 'Graves', ','), ('Graves', ',', 'Alex'), (',', 'Alex', 'Riedmiller'), ('Alex', 'Riedmiller', ','), ('Riedmiller', ',', 'Martin'), (',', 'Martin', 'Fidjeland'), ('Martin', 'Fidjeland', ','), ('Fidjeland', ',', 'Andreas'), (',', 'Andreas', 'K')]

>> POS Tags are: 
 [('Joel', 'NNP'), ('Bellemare', 'NNP'), (',', ','), ('Marc', 'NNP'), ('G', 'NNP'), ('Graves', 'NNP'), (',', ','), ('Alex', 'NNP'), ('Riedmiller', 'NNP'), (',', ','), ('Martin', 'NNP'), ('Fidjeland', 'NNP'), (',', ','), ('Andreas', 'NNP'), ('K', 'NNP')]

>> Noun Phrases are: 
 ['Joel Bellemare', 'Marc G Graves', 'Alex Riedmiller', 'Martin Fidjeland', 'Andreas K']

>> Named Entities are: 
 [('PERSON', 'Joel Bellemare'), ('PERSON', 'Marc G Graves'), ('PERSON', 'Alex Riedmiller'), ('PERSON', 'Martin Fidjeland'), ('PERSON', 'Andreas K')] 

>> Stemming using Porter Stemmer: 
 [('Joel', 'joel'), ('Bellemare', 'bellemar'), (',', ','), ('Marc', 'marc'), ('G', 'g'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Riedmiller', 'riedmil'), (',', ','), ('Martin', 'martin'), ('Fidjeland', 'fidjeland'), (',', ','), ('Andreas', 'andrea'), ('K', 'k')]

>> Stemming using Snowball Stemmer: 
 [('Joel', 'joel'), ('Bellemare', 'bellemar'), (',', ','), ('Marc', 'marc'), ('G', 'g'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Riedmiller', 'riedmil'), (',', ','), ('Martin', 'martin'), ('Fidjeland', 'fidjeland'), (',', ','), ('Andreas', 'andrea'), ('K', 'k')]

>> Lemmatization: 
 [('Joel', 'Joel'), ('Bellemare', 'Bellemare'), (',', ','), ('Marc', 'Marc'), ('G', 'G'), ('Graves', 'Graves'), (',', ','), ('Alex', 'Alex'), ('Riedmiller', 'Riedmiller'), (',', ','), ('Martin', 'Martin'), ('Fidjeland', 'Fidjeland'), (',', ','), ('Andreas', 'Andreas'), ('K', 'K')]



========================================== PARAGRAPH 1574 ===========================================

and Ostrovski, Georg and others, 2015. Human-level control through deep reinforcement learning.  

------------------- Sentence 1 -------------------

and Ostrovski, Georg and others, 2015.

>> Tokens are: 
 ['Ostrovski', ',', 'Georg', 'others', ',', '2015', '.']

>> Bigrams are: 
 [('Ostrovski', ','), (',', 'Georg'), ('Georg', 'others'), ('others', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Ostrovski', ',', 'Georg'), (',', 'Georg', 'others'), ('Georg', 'others', ','), ('others', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Ostrovski', 'NNP'), (',', ','), ('Georg', 'NNP'), ('others', 'NNS'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ostrovski', 'Georg others']

>> Named Entities are: 
 [('GPE', 'Ostrovski'), ('GPE', 'Georg')] 

>> Stemming using Porter Stemmer: 
 [('Ostrovski', 'ostrovski'), (',', ','), ('Georg', 'georg'), ('others', 'other'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ostrovski', 'ostrovski'), (',', ','), ('Georg', 'georg'), ('others', 'other'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Ostrovski', 'Ostrovski'), (',', ','), ('Georg', 'Georg'), ('others', 'others'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Human-level control through deep reinforcement learning.

>> Tokens are: 
 ['Human-level', 'control', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Human-level', 'control'), ('control', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Human-level', 'control', 'deep'), ('control', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Human-level', 'NNP'), ('control', 'NN'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human-level control', 'deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Human-level', 'Human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



========================================== PARAGRAPH 1575 ===========================================

Nature journal, Volume 518, p. 529.  

------------------- Sentence 1 -------------------

Nature journal, Volume 518, p. 529.

>> Tokens are: 
 ['Nature', 'journal', ',', 'Volume', '518', ',', 'p.', '529', '.']

>> Bigrams are: 
 [('Nature', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '518'), ('518', ','), (',', 'p.'), ('p.', '529'), ('529', '.')]

>> Trigrams are: 
 [('Nature', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '518'), ('Volume', '518', ','), ('518', ',', 'p.'), (',', 'p.', '529'), ('p.', '529', '.')]

>> POS Tags are: 
 [('Nature', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('518', 'CD'), (',', ','), ('p.', 'RB'), ('529', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Nature journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Nature'), ('ORGANIZATION', 'Volume 518')] 

>> Stemming using Porter Stemmer: 
 [('Nature', 'natur'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nature', 'natur'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]

>> Lemmatization: 
 [('Nature', 'Nature'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]



========================================== PARAGRAPH 1576 ===========================================

Mouthami, K., Devi, K.N. and Bhaskaran, V.M., 2013. Sentiment analysis and classification based  

------------------- Sentence 1 -------------------

Mouthami, K., Devi, K.N.

>> Tokens are: 
 ['Mouthami', ',', 'K.', ',', 'Devi', ',', 'K.N', '.']

>> Bigrams are: 
 [('Mouthami', ','), (',', 'K.'), ('K.', ','), (',', 'Devi'), ('Devi', ','), (',', 'K.N'), ('K.N', '.')]

>> Trigrams are: 
 [('Mouthami', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Devi'), (',', 'Devi', ','), ('Devi', ',', 'K.N'), (',', 'K.N', '.')]

>> POS Tags are: 
 [('Mouthami', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Devi', 'NNP'), (',', ','), ('K.N', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mouthami', 'K.', 'Devi', 'K.N']

>> Named Entities are: 
 [('GPE', 'Mouthami'), ('PERSON', 'Devi')] 

>> Stemming using Porter Stemmer: 
 [('Mouthami', 'mouthami'), (',', ','), ('K.', 'k.'), (',', ','), ('Devi', 'devi'), (',', ','), ('K.N', 'k.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mouthami', 'mouthami'), (',', ','), ('K.', 'k.'), (',', ','), ('Devi', 'devi'), (',', ','), ('K.N', 'k.n'), ('.', '.')]

>> Lemmatization: 
 [('Mouthami', 'Mouthami'), (',', ','), ('K.', 'K.'), (',', ','), ('Devi', 'Devi'), (',', ','), ('K.N', 'K.N'), ('.', '.')]


------------------- Sentence 2 -------------------

and Bhaskaran, V.M., 2013.

>> Tokens are: 
 ['Bhaskaran', ',', 'V.M.', ',', '2013', '.']

>> Bigrams are: 
 [('Bhaskaran', ','), (',', 'V.M.'), ('V.M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Bhaskaran', ',', 'V.M.'), (',', 'V.M.', ','), ('V.M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Bhaskaran', 'NNP'), (',', ','), ('V.M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Bhaskaran', 'V.M.']

>> Named Entities are: 
 [('GPE', 'Bhaskaran')] 

>> Stemming using Porter Stemmer: 
 [('Bhaskaran', 'bhaskaran'), (',', ','), ('V.M.', 'v.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bhaskaran', 'bhaskaran'), (',', ','), ('V.M.', 'v.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Bhaskaran', 'Bhaskaran'), (',', ','), ('V.M.', 'V.M.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 3 -------------------

Sentiment analysis and classification based

>> Tokens are: 
 ['Sentiment', 'analysis', 'classification', 'based']

>> Bigrams are: 
 [('Sentiment', 'analysis'), ('analysis', 'classification'), ('classification', 'based')]

>> Trigrams are: 
 [('Sentiment', 'analysis', 'classification'), ('analysis', 'classification', 'based')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('analysis', 'NN'), ('classification', 'NN'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['Sentiment analysis classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('classification', 'classif'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('classification', 'classif'), ('based', 'base')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analysis', 'analysis'), ('classification', 'classification'), ('based', 'based')]



========================================== PARAGRAPH 1577 ===========================================

on textual reviews.. s.l., IEEE. 

------------------- Sentence 1 -------------------

on textual reviews..

>> Tokens are: 
 ['textual', 'reviews', '..']

>> Bigrams are: 
 [('textual', 'reviews'), ('reviews', '..')]

>> Trigrams are: 
 [('textual', 'reviews', '..')]

>> POS Tags are: 
 [('textual', 'JJ'), ('reviews', 'NNS'), ('..', 'VBP')]

>> Noun Phrases are: 
 ['textual reviews']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('textual', 'textual'), ('reviews', 'review'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('textual', 'textual'), ('reviews', 'review'), ('..', '..')]

>> Lemmatization: 
 [('textual', 'textual'), ('reviews', 'review'), ('..', '..')]


------------------- Sentence 2 -------------------

s.l., IEEE.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 1578 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1579 ===========================================

52  

------------------- Sentence 1 -------------------

52

>> Tokens are: 
 ['52']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('52', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('52', '52')]

>> Stemming using Snowball Stemmer: 
 [('52', '52')]

>> Lemmatization: 
 [('52', '52')]



========================================== PARAGRAPH 1580 ===========================================

  


========================================== PARAGRAPH 1581 ===========================================

Müller, O., Junglas, I., Brocke, J.V. and Debortoli, S., 2016. Utilizing big data analytics for  

------------------- Sentence 1 -------------------

Müller, O., Junglas, I., Brocke, J.V.

>> Tokens are: 
 ['Müller', ',', 'O.', ',', 'Junglas', ',', 'I.', ',', 'Brocke', ',', 'J.V', '.']

>> Bigrams are: 
 [('Müller', ','), (',', 'O.'), ('O.', ','), (',', 'Junglas'), ('Junglas', ','), (',', 'I.'), ('I.', ','), (',', 'Brocke'), ('Brocke', ','), (',', 'J.V'), ('J.V', '.')]

>> Trigrams are: 
 [('Müller', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Junglas'), (',', 'Junglas', ','), ('Junglas', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Brocke'), (',', 'Brocke', ','), ('Brocke', ',', 'J.V'), (',', 'J.V', '.')]

>> POS Tags are: 
 [('Müller', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Junglas', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Brocke', 'NNP'), (',', ','), ('J.V', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Müller', 'O.', 'Junglas', 'I.', 'Brocke', 'J.V']

>> Named Entities are: 
 [('GPE', 'Müller'), ('PERSON', 'Junglas'), ('GPE', 'Brocke')] 

>> Stemming using Porter Stemmer: 
 [('Müller', 'müller'), (',', ','), ('O.', 'o.'), (',', ','), ('Junglas', 'jungla'), (',', ','), ('I.', 'i.'), (',', ','), ('Brocke', 'brock'), (',', ','), ('J.V', 'j.v'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Müller', 'müller'), (',', ','), ('O.', 'o.'), (',', ','), ('Junglas', 'jungla'), (',', ','), ('I.', 'i.'), (',', ','), ('Brocke', 'brock'), (',', ','), ('J.V', 'j.v'), ('.', '.')]

>> Lemmatization: 
 [('Müller', 'Müller'), (',', ','), ('O.', 'O.'), (',', ','), ('Junglas', 'Junglas'), (',', ','), ('I.', 'I.'), (',', ','), ('Brocke', 'Brocke'), (',', ','), ('J.V', 'J.V'), ('.', '.')]


------------------- Sentence 2 -------------------

and Debortoli, S., 2016.

>> Tokens are: 
 ['Debortoli', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Debortoli', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Debortoli', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Debortoli', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Debortoli', 'S.']

>> Named Entities are: 
 [('GPE', 'Debortoli')] 

>> Stemming using Porter Stemmer: 
 [('Debortoli', 'debortoli'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Debortoli', 'debortoli'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Debortoli', 'Debortoli'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 3 -------------------

Utilizing big data analytics for

>> Tokens are: 
 ['Utilizing', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('Utilizing', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Utilizing', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('Utilizing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Utilizing', 'Utilizing'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 1582 ===========================================

information systems research: challenges, promises and guidelines. European Journal of  

------------------- Sentence 1 -------------------

information systems research: challenges, promises and guidelines.

>> Tokens are: 
 ['information', 'systems', 'research', ':', 'challenges', ',', 'promises', 'guidelines', '.']

>> Bigrams are: 
 [('information', 'systems'), ('systems', 'research'), ('research', ':'), (':', 'challenges'), ('challenges', ','), (',', 'promises'), ('promises', 'guidelines'), ('guidelines', '.')]

>> Trigrams are: 
 [('information', 'systems', 'research'), ('systems', 'research', ':'), ('research', ':', 'challenges'), (':', 'challenges', ','), ('challenges', ',', 'promises'), (',', 'promises', 'guidelines'), ('promises', 'guidelines', '.')]

>> POS Tags are: 
 [('information', 'NN'), ('systems', 'NNS'), ('research', 'NN'), (':', ':'), ('challenges', 'NNS'), (',', ','), ('promises', 'NNS'), ('guidelines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['information systems research', 'challenges', 'promises guidelines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('promises', 'promis'), ('guidelines', 'guidelin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('promises', 'promis'), ('guidelines', 'guidelin'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challenge'), (',', ','), ('promises', 'promise'), ('guidelines', 'guideline'), ('.', '.')]


------------------- Sentence 2 -------------------

European Journal of

>> Tokens are: 
 ['European', 'Journal']

>> Bigrams are: 
 [('European', 'Journal')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('European', 'JJ'), ('Journal', 'NNP')]

>> Noun Phrases are: 
 ['European Journal']

>> Named Entities are: 
 [('GPE', 'European'), ('ORGANIZATION', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('European', 'european'), ('Journal', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('European', 'european'), ('Journal', 'journal')]

>> Lemmatization: 
 [('European', 'European'), ('Journal', 'Journal')]



========================================== PARAGRAPH 1583 ===========================================

Information Systems, pp. 289-302.  

------------------- Sentence 1 -------------------

Information Systems, pp.

>> Tokens are: 
 ['Information', 'Systems', ',', 'pp', '.']

>> Bigrams are: 
 [('Information', 'Systems'), ('Systems', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Information', 'Systems', ','), ('Systems', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Systems', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Systems', 'pp']

>> Named Entities are: 
 [('PERSON', 'Systems')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

289-302.

>> Tokens are: 
 ['289-302', '.']

>> Bigrams are: 
 [('289-302', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('289-302', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('289-302', '289-302'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('289-302', '289-302'), ('.', '.')]

>> Lemmatization: 
 [('289-302', '289-302'), ('.', '.')]



========================================== PARAGRAPH 1584 ===========================================

Nafus, D. and Sherman, J., 2014. Big data, big questions| this one does not go up to 11: the  

------------------- Sentence 1 -------------------

Nafus, D. and Sherman, J., 2014.

>> Tokens are: 
 ['Nafus', ',', 'D.', 'Sherman', ',', 'J.', ',', '2014', '.']

>> Bigrams are: 
 [('Nafus', ','), (',', 'D.'), ('D.', 'Sherman'), ('Sherman', ','), (',', 'J.'), ('J.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Nafus', ',', 'D.'), (',', 'D.', 'Sherman'), ('D.', 'Sherman', ','), ('Sherman', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Nafus', 'NNP'), (',', ','), ('D.', 'NNP'), ('Sherman', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Nafus', 'D. Sherman', 'J.']

>> Named Entities are: 
 [('GPE', 'Nafus')] 

>> Stemming using Porter Stemmer: 
 [('Nafus', 'nafu'), (',', ','), ('D.', 'd.'), ('Sherman', 'sherman'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nafus', 'nafus'), (',', ','), ('D.', 'd.'), ('Sherman', 'sherman'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Nafus', 'Nafus'), (',', ','), ('D.', 'D.'), ('Sherman', 'Sherman'), (',', ','), ('J.', 'J.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data, big questions| this one does not go up to 11: the

>> Tokens are: 
 ['Big', 'data', ',', 'big', 'questions|', 'one', 'go', '11', ':']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'big'), ('big', 'questions|'), ('questions|', 'one'), ('one', 'go'), ('go', '11'), ('11', ':')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'questions|'), ('big', 'questions|', 'one'), ('questions|', 'one', 'go'), ('one', 'go', '11'), ('go', '11', ':')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('questions|', 'NN'), ('one', 'CD'), ('go', 'NN'), ('11', 'CD'), (':', ':')]

>> Noun Phrases are: 
 ['Big data', 'big questions|', 'go']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':')]



========================================== PARAGRAPH 1585 ===========================================

quantified self movement as an alternative big data practice.. International journal of  

------------------- Sentence 1 -------------------

quantified self movement as an alternative big data practice.. International journal of

>> Tokens are: 
 ['quantified', 'self', 'movement', 'alternative', 'big', 'data', 'practice', '..', 'International', 'journal']

>> Bigrams are: 
 [('quantified', 'self'), ('self', 'movement'), ('movement', 'alternative'), ('alternative', 'big'), ('big', 'data'), ('data', 'practice'), ('practice', '..'), ('..', 'International'), ('International', 'journal')]

>> Trigrams are: 
 [('quantified', 'self', 'movement'), ('self', 'movement', 'alternative'), ('movement', 'alternative', 'big'), ('alternative', 'big', 'data'), ('big', 'data', 'practice'), ('data', 'practice', '..'), ('practice', '..', 'International'), ('..', 'International', 'journal')]

>> POS Tags are: 
 [('quantified', 'VBN'), ('self', 'PRP'), ('movement', 'NN'), ('alternative', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('practice', 'NN'), ('..', 'NNP'), ('International', 'NNP'), ('journal', 'NN')]

>> Noun Phrases are: 
 ['movement', 'alternative big data practice .. International journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('quantified', 'quantifi'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'altern'), ('big', 'big'), ('data', 'data'), ('practice', 'practic'), ('..', '..'), ('International', 'intern'), ('journal', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('quantified', 'quantifi'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'altern'), ('big', 'big'), ('data', 'data'), ('practice', 'practic'), ('..', '..'), ('International', 'intern'), ('journal', 'journal')]

>> Lemmatization: 
 [('quantified', 'quantified'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'alternative'), ('big', 'big'), ('data', 'data'), ('practice', 'practice'), ('..', '..'), ('International', 'International'), ('journal', 'journal')]



========================================== PARAGRAPH 1586 ===========================================

communication, p. 11.  

------------------- Sentence 1 -------------------

communication, p. 11.

>> Tokens are: 
 ['communication', ',', 'p.', '11', '.']

>> Bigrams are: 
 [('communication', ','), (',', 'p.'), ('p.', '11'), ('11', '.')]

>> Trigrams are: 
 [('communication', ',', 'p.'), (',', 'p.', '11'), ('p.', '11', '.')]

>> POS Tags are: 
 [('communication', 'NN'), (',', ','), ('p.', 'JJ'), ('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['communication']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('communication', 'commun'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('communication', 'communic'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('communication', 'communication'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]



========================================== PARAGRAPH 1587 ===========================================

Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R. and Muharemagic,  

------------------- Sentence 1 -------------------

Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R. and Muharemagic,

>> Tokens are: 
 ['Najafabadi', ',', 'M.M.', ',', 'Villanustre', ',', 'F.', ',', 'Khoshgoftaar', ',', 'T.M.', ',', 'Seliya', ',', 'N.', ',', 'Wald', ',', 'R.', 'Muharemagic', ',']

>> Bigrams are: 
 [('Najafabadi', ','), (',', 'M.M.'), ('M.M.', ','), (',', 'Villanustre'), ('Villanustre', ','), (',', 'F.'), ('F.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M.'), ('T.M.', ','), (',', 'Seliya'), ('Seliya', ','), (',', 'N.'), ('N.', ','), (',', 'Wald'), ('Wald', ','), (',', 'R.'), ('R.', 'Muharemagic'), ('Muharemagic', ',')]

>> Trigrams are: 
 [('Najafabadi', ',', 'M.M.'), (',', 'M.M.', ','), ('M.M.', ',', 'Villanustre'), (',', 'Villanustre', ','), ('Villanustre', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M.'), (',', 'T.M.', ','), ('T.M.', ',', 'Seliya'), (',', 'Seliya', ','), ('Seliya', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Wald'), (',', 'Wald', ','), ('Wald', ',', 'R.'), (',', 'R.', 'Muharemagic'), ('R.', 'Muharemagic', ',')]

>> POS Tags are: 
 [('Najafabadi', 'NNP'), (',', ','), ('M.M.', 'NNP'), (',', ','), ('Villanustre', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M.', 'NNP'), (',', ','), ('Seliya', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Wald', 'NNP'), (',', ','), ('R.', 'NNP'), ('Muharemagic', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Najafabadi', 'M.M.', 'Villanustre', 'F.', 'Khoshgoftaar', 'T.M.', 'Seliya', 'N.', 'Wald', 'R. Muharemagic']

>> Named Entities are: 
 [('GPE', 'Najafabadi'), ('GPE', 'Villanustre'), ('GPE', 'Khoshgoftaar'), ('GPE', 'Seliya'), ('PERSON', 'Wald')] 

>> Stemming using Porter Stemmer: 
 [('Najafabadi', 'najafabadi'), (',', ','), ('M.M.', 'm.m.'), (',', ','), ('Villanustre', 'villanustr'), (',', ','), ('F.', 'f.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Seliya', 'seliya'), (',', ','), ('N.', 'n.'), (',', ','), ('Wald', 'wald'), (',', ','), ('R.', 'r.'), ('Muharemagic', 'muharemag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Najafabadi', 'najafabadi'), (',', ','), ('M.M.', 'm.m.'), (',', ','), ('Villanustre', 'villanustr'), (',', ','), ('F.', 'f.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Seliya', 'seliya'), (',', ','), ('N.', 'n.'), (',', ','), ('Wald', 'wald'), (',', ','), ('R.', 'r.'), ('Muharemagic', 'muharemag'), (',', ',')]

>> Lemmatization: 
 [('Najafabadi', 'Najafabadi'), (',', ','), ('M.M.', 'M.M.'), (',', ','), ('Villanustre', 'Villanustre'), (',', ','), ('F.', 'F.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M.', 'T.M.'), (',', ','), ('Seliya', 'Seliya'), (',', ','), ('N.', 'N.'), (',', ','), ('Wald', 'Wald'), (',', ','), ('R.', 'R.'), ('Muharemagic', 'Muharemagic'), (',', ',')]



========================================== PARAGRAPH 1588 ===========================================

E., 2015. Deep learning applications and challenges in big data analytics. Journal of Big Data, p.  

------------------- Sentence 1 -------------------

E., 2015.

>> Tokens are: 
 ['E.', ',', '2015', '.']

>> Bigrams are: 
 [('E.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('E.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('E.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['E.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.', 'e.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.', 'e.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('E.', 'E.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep learning applications and challenges in big data analytics.

>> Tokens are: 
 ['Deep', 'learning', 'applications', 'challenges', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'applications'), ('applications', 'challenges'), ('challenges', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'applications'), ('learning', 'applications', 'challenges'), ('applications', 'challenges', 'big'), ('challenges', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('applications', 'NNS'), ('challenges', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep learning applications', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('applications', 'applic'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('applications', 'applic'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('applications', 'application'), ('challenges', 'challenge'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

Journal of Big Data, p.

>> Tokens are: 
 ['Journal', 'Big', 'Data', ',', 'p', '.']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p'), ('p', '.')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p'), (',', 'p', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Big Data', 'p']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p', 'p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p', 'p'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p', 'p'), ('.', '.')]



========================================== PARAGRAPH 1589 ===========================================

1.  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



========================================== PARAGRAPH 1590 ===========================================

Nashua, N., 2017. Big Data Analytics Market Study, s.l.: Dresner Advisory Services.  

------------------- Sentence 1 -------------------

Nashua, N., 2017.

>> Tokens are: 
 ['Nashua', ',', 'N.', ',', '2017', '.']

>> Bigrams are: 
 [('Nashua', ','), (',', 'N.'), ('N.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Nashua', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Nashua', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Nashua', 'N.']

>> Named Entities are: 
 [('GPE', 'Nashua')] 

>> Stemming using Porter Stemmer: 
 [('Nashua', 'nashua'), (',', ','), ('N.', 'n.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nashua', 'nashua'), (',', ','), ('N.', 'n.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Nashua', 'Nashua'), (',', ','), ('N.', 'N.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Analytics Market Study, s.l.

>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Market', 'Study', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Market'), ('Market', 'Study'), ('Study', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Market'), ('Analytics', 'Market', 'Study'), ('Market', 'Study', ','), ('Study', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Market', 'NNP'), ('Study', 'NNP'), (',', ','), ('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data Analytics Market Study', 's.l']

>> Named Entities are: 
 [('PERSON', 'Market Study')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Market', 'market'), ('Study', 'studi'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Market', 'market'), ('Study', 'studi'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Market', 'Market'), ('Study', 'Study'), (',', ','), ('s.l', 's.l'), ('.', '.')]


------------------- Sentence 3 -------------------

: Dresner Advisory Services.

>> Tokens are: 
 [':', 'Dresner', 'Advisory', 'Services', '.']

>> Bigrams are: 
 [(':', 'Dresner'), ('Dresner', 'Advisory'), ('Advisory', 'Services'), ('Services', '.')]

>> Trigrams are: 
 [(':', 'Dresner', 'Advisory'), ('Dresner', 'Advisory', 'Services'), ('Advisory', 'Services', '.')]

>> POS Tags are: 
 [(':', ':'), ('Dresner', 'NN'), ('Advisory', 'NNP'), ('Services', 'NNPS'), ('.', '.')]

>> Noun Phrases are: 
 ['Dresner Advisory']

>> Named Entities are: 
 [('PERSON', 'Dresner Advisory Services')] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Dresner', 'Dresner'), ('Advisory', 'Advisory'), ('Services', 'Services'), ('.', '.')]



========================================== PARAGRAPH 1591 ===========================================

Orange-Roglá, Sergio; Chalmeta, Ricardo, 2019. Framework for implementing a big data  

------------------- Sentence 1 -------------------

Orange-Roglá, Sergio; Chalmeta, Ricardo, 2019.

>> Tokens are: 
 ['Orange-Roglá', ',', 'Sergio', ';', 'Chalmeta', ',', 'Ricardo', ',', '2019', '.']

>> Bigrams are: 
 [('Orange-Roglá', ','), (',', 'Sergio'), ('Sergio', ';'), (';', 'Chalmeta'), ('Chalmeta', ','), (',', 'Ricardo'), ('Ricardo', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Orange-Roglá', ',', 'Sergio'), (',', 'Sergio', ';'), ('Sergio', ';', 'Chalmeta'), (';', 'Chalmeta', ','), ('Chalmeta', ',', 'Ricardo'), (',', 'Ricardo', ','), ('Ricardo', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Orange-Roglá', 'NNP'), (',', ','), ('Sergio', 'NNP'), (';', ':'), ('Chalmeta', 'NNP'), (',', ','), ('Ricardo', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Orange-Roglá', 'Sergio', 'Chalmeta', 'Ricardo']

>> Named Entities are: 
 [('GPE', 'Sergio'), ('PERSON', 'Chalmeta'), ('PERSON', 'Ricardo')] 

>> Stemming using Porter Stemmer: 
 [('Orange-Roglá', 'orange-roglá'), (',', ','), ('Sergio', 'sergio'), (';', ';'), ('Chalmeta', 'chalmeta'), (',', ','), ('Ricardo', 'ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Orange-Roglá', 'orange-roglá'), (',', ','), ('Sergio', 'sergio'), (';', ';'), ('Chalmeta', 'chalmeta'), (',', ','), ('Ricardo', 'ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Orange-Roglá', 'Orange-Roglá'), (',', ','), ('Sergio', 'Sergio'), (';', ';'), ('Chalmeta', 'Chalmeta'), (',', ','), ('Ricardo', 'Ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Framework for implementing a big data

>> Tokens are: 
 ['Framework', 'implementing', 'big', 'data']

>> Bigrams are: 
 [('Framework', 'implementing'), ('implementing', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Framework', 'implementing', 'big'), ('implementing', 'big', 'data')]

>> POS Tags are: 
 [('Framework', 'NNP'), ('implementing', 'VBG'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Framework', 'big data']

>> Named Entities are: 
 [('GPE', 'Framework')] 

>> Stemming using Porter Stemmer: 
 [('Framework', 'framework'), ('implementing', 'implement'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Framework', 'framework'), ('implementing', 'implement'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Framework', 'Framework'), ('implementing', 'implementing'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1592 ===========================================

ecosystem in organizations.. Communications of the ACM Journal, 62(1).  

------------------- Sentence 1 -------------------

ecosystem in organizations.. Communications of the ACM Journal, 62(1).

>> Tokens are: 
 ['ecosystem', 'organizations', '..', 'Communications', 'ACM', 'Journal', ',', '62', '(', '1', ')', '.']

>> Bigrams are: 
 [('ecosystem', 'organizations'), ('organizations', '..'), ('..', 'Communications'), ('Communications', 'ACM'), ('ACM', 'Journal'), ('Journal', ','), (',', '62'), ('62', '('), ('(', '1'), ('1', ')'), (')', '.')]

>> Trigrams are: 
 [('ecosystem', 'organizations', '..'), ('organizations', '..', 'Communications'), ('..', 'Communications', 'ACM'), ('Communications', 'ACM', 'Journal'), ('ACM', 'Journal', ','), ('Journal', ',', '62'), (',', '62', '('), ('62', '(', '1'), ('(', '1', ')'), ('1', ')', '.')]

>> POS Tags are: 
 [('ecosystem', 'NN'), ('organizations', 'NNS'), ('..', 'VBP'), ('Communications', 'NNP'), ('ACM', 'NNP'), ('Journal', 'NNP'), (',', ','), ('62', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['ecosystem organizations', 'Communications ACM Journal']

>> Named Entities are: 
 [('ORGANIZATION', 'Communications')] 

>> Stemming using Porter Stemmer: 
 [('ecosystem', 'ecosystem'), ('organizations', 'organ'), ('..', '..'), ('Communications', 'commun'), ('ACM', 'acm'), ('Journal', 'journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ecosystem', 'ecosystem'), ('organizations', 'organ'), ('..', '..'), ('Communications', 'communic'), ('ACM', 'acm'), ('Journal', 'journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('ecosystem', 'ecosystem'), ('organizations', 'organization'), ('..', '..'), ('Communications', 'Communications'), ('ACM', 'ACM'), ('Journal', 'Journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 1593 ===========================================

Oussous, A., Benjelloun, F.Z., Lahcen, A.A. and Belfkih, S., 2018. Big Data technologies: A  

------------------- Sentence 1 -------------------

Oussous, A., Benjelloun, F.Z., Lahcen, A.A. and Belfkih, S., 2018.

>> Tokens are: 
 ['Oussous', ',', 'A.', ',', 'Benjelloun', ',', 'F.Z.', ',', 'Lahcen', ',', 'A.A.', 'Belfkih', ',', 'S.', ',', '2018', '.']

>> Bigrams are: 
 [('Oussous', ','), (',', 'A.'), ('A.', ','), (',', 'Benjelloun'), ('Benjelloun', ','), (',', 'F.Z.'), ('F.Z.', ','), (',', 'Lahcen'), ('Lahcen', ','), (',', 'A.A.'), ('A.A.', 'Belfkih'), ('Belfkih', ','), (',', 'S.'), ('S.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Oussous', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Benjelloun'), (',', 'Benjelloun', ','), ('Benjelloun', ',', 'F.Z.'), (',', 'F.Z.', ','), ('F.Z.', ',', 'Lahcen'), (',', 'Lahcen', ','), ('Lahcen', ',', 'A.A.'), (',', 'A.A.', 'Belfkih'), ('A.A.', 'Belfkih', ','), ('Belfkih', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Oussous', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Benjelloun', 'NNP'), (',', ','), ('F.Z.', 'NNP'), (',', ','), ('Lahcen', 'NNP'), (',', ','), ('A.A.', 'NNP'), ('Belfkih', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Oussous', 'A.', 'Benjelloun', 'F.Z.', 'Lahcen', 'A.A. Belfkih', 'S.']

>> Named Entities are: 
 [('GPE', 'Oussous'), ('PERSON', 'Benjelloun'), ('GPE', 'Lahcen'), ('ORGANIZATION', 'A.A. Belfkih')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), (',', ','), ('A.', 'a.'), (',', ','), ('Benjelloun', 'benjelloun'), (',', ','), ('F.Z.', 'f.z.'), (',', ','), ('Lahcen', 'lahcen'), (',', ','), ('A.A.', 'a.a.'), ('Belfkih', 'belfkih'), (',', ','), ('S.', 's.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), (',', ','), ('A.', 'a.'), (',', ','), ('Benjelloun', 'benjelloun'), (',', ','), ('F.Z.', 'f.z.'), (',', ','), ('Lahcen', 'lahcen'), (',', ','), ('A.A.', 'a.a.'), ('Belfkih', 'belfkih'), (',', ','), ('S.', 's.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), (',', ','), ('A.', 'A.'), (',', ','), ('Benjelloun', 'Benjelloun'), (',', ','), ('F.Z.', 'F.Z.'), (',', ','), ('Lahcen', 'Lahcen'), (',', ','), ('A.A.', 'A.A.'), ('Belfkih', 'Belfkih'), (',', ','), ('S.', 'S.'), (',', ','), ('2018', '2018'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data technologies: A

>> Tokens are: 
 ['Big', 'Data', 'technologies', ':', 'A']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'technologies'), ('technologies', ':'), (':', 'A')]

>> Trigrams are: 
 [('Big', 'Data', 'technologies'), ('Data', 'technologies', ':'), ('technologies', ':', 'A')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('technologies', 'NNS'), (':', ':'), ('A', 'DT')]

>> Noun Phrases are: 
 ['Big Data technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('technologies', 'technolog'), (':', ':'), ('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('technologies', 'technolog'), (':', ':'), ('A', 'a')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('technologies', 'technology'), (':', ':'), ('A', 'A')]



========================================== PARAGRAPH 1594 ===========================================

survey. Journal of King Saud University-Computer and Information Sciences, pp. 431-448.  

------------------- Sentence 1 -------------------

survey.

>> Tokens are: 
 ['survey', '.']

>> Bigrams are: 
 [('survey', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('survey', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['survey']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('survey', 'survey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('survey', 'survey'), ('.', '.')]

>> Lemmatization: 
 [('survey', 'survey'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of King Saud University-Computer and Information Sciences, pp.

>> Tokens are: 
 ['Journal', 'King', 'Saud', 'University-Computer', 'Information', 'Sciences', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'King'), ('King', 'Saud'), ('Saud', 'University-Computer'), ('University-Computer', 'Information'), ('Information', 'Sciences'), ('Sciences', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'King', 'Saud'), ('King', 'Saud', 'University-Computer'), ('Saud', 'University-Computer', 'Information'), ('University-Computer', 'Information', 'Sciences'), ('Information', 'Sciences', ','), ('Sciences', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('King', 'NNP'), ('Saud', 'NNP'), ('University-Computer', 'NNP'), ('Information', 'NNP'), ('Sciences', 'NNPS'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal King Saud University-Computer Information', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('King', 'king'), ('Saud', 'saud'), ('University-Computer', 'university-comput'), ('Information', 'inform'), ('Sciences', 'scienc'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('King', 'king'), ('Saud', 'saud'), ('University-Computer', 'university-comput'), ('Information', 'inform'), ('Sciences', 'scienc'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('King', 'King'), ('Saud', 'Saud'), ('University-Computer', 'University-Computer'), ('Information', 'Information'), ('Sciences', 'Sciences'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

431-448.

>> Tokens are: 
 ['431-448', '.']

>> Bigrams are: 
 [('431-448', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('431-448', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('431-448', '431-448'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('431-448', '431-448'), ('.', '.')]

>> Lemmatization: 
 [('431-448', '431-448'), ('.', '.')]



========================================== PARAGRAPH 1595 ===========================================

Provost, F. and Fawcett, T., 2013. Data science and its relationship to big data and data-driven  

------------------- Sentence 1 -------------------

Provost, F. and Fawcett, T., 2013.

>> Tokens are: 
 ['Provost', ',', 'F.', 'Fawcett', ',', 'T.', ',', '2013', '.']

>> Bigrams are: 
 [('Provost', ','), (',', 'F.'), ('F.', 'Fawcett'), ('Fawcett', ','), (',', 'T.'), ('T.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Provost', ',', 'F.'), (',', 'F.', 'Fawcett'), ('F.', 'Fawcett', ','), ('Fawcett', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Provost', 'NNP'), (',', ','), ('F.', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Provost', 'F. Fawcett', 'T.']

>> Named Entities are: 
 [('GPE', 'Provost'), ('PERSON', 'Fawcett')] 

>> Stemming using Porter Stemmer: 
 [('Provost', 'provost'), (',', ','), ('F.', 'f.'), ('Fawcett', 'fawcett'), (',', ','), ('T.', 't.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Provost', 'provost'), (',', ','), ('F.', 'f.'), ('Fawcett', 'fawcett'), (',', ','), ('T.', 't.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Provost', 'Provost'), (',', ','), ('F.', 'F.'), ('Fawcett', 'Fawcett'), (',', ','), ('T.', 'T.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Data science and its relationship to big data and data-driven

>> Tokens are: 
 ['Data', 'science', 'relationship', 'big', 'data', 'data-driven']

>> Bigrams are: 
 [('Data', 'science'), ('science', 'relationship'), ('relationship', 'big'), ('big', 'data'), ('data', 'data-driven')]

>> Trigrams are: 
 [('Data', 'science', 'relationship'), ('science', 'relationship', 'big'), ('relationship', 'big', 'data'), ('big', 'data', 'data-driven')]

>> POS Tags are: 
 [('Data', 'NNP'), ('science', 'NN'), ('relationship', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('data-driven', 'RB')]

>> Noun Phrases are: 
 ['Data science relationship', 'big data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven')]

>> Lemmatization: 
 [('Data', 'Data'), ('science', 'science'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven')]



========================================== PARAGRAPH 1596 ===========================================

decision making. Big Data Journal, pp. 51-59.  

------------------- Sentence 1 -------------------

decision making.

>> Tokens are: 
 ['decision', 'making', '.']

>> Bigrams are: 
 [('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('decision', 'making', '.')]

>> POS Tags are: 
 [('decision', 'NN'), ('making', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('decision', 'decision'), ('making', 'making'), ('.', '.')]


------------------- Sentence 2 -------------------

Big Data Journal, pp.

>> Tokens are: 
 ['Big', 'Data', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Journal'), ('Data', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('Data', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data Journal', 'pp']

>> Named Entities are: 
 [('PERSON', 'Data Journal')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

51-59.

>> Tokens are: 
 ['51-59', '.']

>> Bigrams are: 
 [('51-59', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('51-59', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('51-59', '51-59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('51-59', '51-59'), ('.', '.')]

>> Lemmatization: 
 [('51-59', '51-59'), ('.', '.')]



========================================== PARAGRAPH 1597 ===========================================

Qiu, J., Wu, Q., Ding, G., Xu, Y. and Feng, S., 2016. A survey of machine learning for big data  

------------------- Sentence 1 -------------------

Qiu, J., Wu, Q., Ding, G., Xu, Y. and Feng, S., 2016.

>> Tokens are: 
 ['Qiu', ',', 'J.', ',', 'Wu', ',', 'Q.', ',', 'Ding', ',', 'G.', ',', 'Xu', ',', 'Y.', 'Feng', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Qiu', ','), (',', 'J.'), ('J.', ','), (',', 'Wu'), ('Wu', ','), (',', 'Q.'), ('Q.', ','), (',', 'Ding'), ('Ding', ','), (',', 'G.'), ('G.', ','), (',', 'Xu'), ('Xu', ','), (',', 'Y.'), ('Y.', 'Feng'), ('Feng', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Qiu', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Wu'), (',', 'Wu', ','), ('Wu', ',', 'Q.'), (',', 'Q.', ','), ('Q.', ',', 'Ding'), (',', 'Ding', ','), ('Ding', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Xu'), (',', 'Xu', ','), ('Xu', ',', 'Y.'), (',', 'Y.', 'Feng'), ('Y.', 'Feng', ','), ('Feng', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Qiu', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Wu', 'NNP'), (',', ','), ('Q.', 'NNP'), (',', ','), ('Ding', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Xu', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Feng', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Qiu', 'J.', 'Wu', 'Q.', 'Ding', 'G.', 'Xu', 'Y. Feng', 'S.']

>> Named Entities are: 
 [('GPE', 'Qiu'), ('GPE', 'Wu'), ('GPE', 'Ding'), ('GPE', 'Xu')] 

>> Stemming using Porter Stemmer: 
 [('Qiu', 'qiu'), (',', ','), ('J.', 'j.'), (',', ','), ('Wu', 'wu'), (',', ','), ('Q.', 'q.'), (',', ','), ('Ding', 'ding'), (',', ','), ('G.', 'g.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Y.', 'y.'), ('Feng', 'feng'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Qiu', 'qiu'), (',', ','), ('J.', 'j.'), (',', ','), ('Wu', 'wu'), (',', ','), ('Q.', 'q.'), (',', ','), ('Ding', 'ding'), (',', ','), ('G.', 'g.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Y.', 'y.'), ('Feng', 'feng'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Qiu', 'Qiu'), (',', ','), ('J.', 'J.'), (',', ','), ('Wu', 'Wu'), (',', ','), ('Q.', 'Q.'), (',', ','), ('Ding', 'Ding'), (',', ','), ('G.', 'G.'), (',', ','), ('Xu', 'Xu'), (',', ','), ('Y.', 'Y.'), ('Feng', 'Feng'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

A survey of machine learning for big data

>> Tokens are: 
 ['A', 'survey', 'machine', 'learning', 'big', 'data']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'machine'), ('machine', 'learning'), ('learning', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('A', 'survey', 'machine'), ('survey', 'machine', 'learning'), ('machine', 'learning', 'big'), ('learning', 'big', 'data')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['A survey machine', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('machine', 'machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 1598 ===========================================

processing. EURASIP Journal on Advances in Signal Processing, p. 67.  

------------------- Sentence 1 -------------------

processing.

>> Tokens are: 
 ['processing', '.']

>> Bigrams are: 
 [('processing', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('processing', 'processing'), ('.', '.')]


------------------- Sentence 2 -------------------

EURASIP Journal on Advances in Signal Processing, p. 67.

>> Tokens are: 
 ['EURASIP', 'Journal', 'Advances', 'Signal', 'Processing', ',', 'p.', '67', '.']

>> Bigrams are: 
 [('EURASIP', 'Journal'), ('Journal', 'Advances'), ('Advances', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'p.'), ('p.', '67'), ('67', '.')]

>> Trigrams are: 
 [('EURASIP', 'Journal', 'Advances'), ('Journal', 'Advances', 'Signal'), ('Advances', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'p.'), (',', 'p.', '67'), ('p.', '67', '.')]

>> POS Tags are: 
 [('EURASIP', 'NNP'), ('Journal', 'NNP'), ('Advances', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('p.', 'VBD'), ('67', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['EURASIP Journal Advances Signal Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'EURASIP Journal Advances Signal')] 

>> Stemming using Porter Stemmer: 
 [('EURASIP', 'eurasip'), ('Journal', 'journal'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('EURASIP', 'eurasip'), ('Journal', 'journal'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]

>> Lemmatization: 
 [('EURASIP', 'EURASIP'), ('Journal', 'Journal'), ('Advances', 'Advances'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]



========================================== PARAGRAPH 1599 ===========================================

Raghupathi, W. and Raghupathi, V., 2014. Big data analytics in healthcare: promise and potential.  

------------------- Sentence 1 -------------------

Raghupathi, W. and Raghupathi, V., 2014.

>> Tokens are: 
 ['Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', '.']

>> Bigrams are: 
 [('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Raghupathi', 'W. Raghupathi', 'V.']

>> Named Entities are: 
 [('GPE', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics in healthcare: promise and potential.

>> Tokens are: 
 ['Big', 'data', 'analytics', 'healthcare', ':', 'promise', 'potential', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'healthcare'), ('healthcare', ':'), (':', 'promise'), ('promise', 'potential'), ('potential', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'healthcare'), ('analytics', 'healthcare', ':'), ('healthcare', ':', 'promise'), (':', 'promise', 'potential'), ('promise', 'potential', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('healthcare', 'NN'), (':', ':'), ('promise', 'NN'), ('potential', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics healthcare', 'promise potential']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), (':', ':'), ('promise', 'promis'), ('potential', 'potenti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), (':', ':'), ('promise', 'promis'), ('potential', 'potenti'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('healthcare', 'healthcare'), (':', ':'), ('promise', 'promise'), ('potential', 'potential'), ('.', '.')]



========================================== PARAGRAPH 1600 ===========================================

Health information science and systems, p. 3.  

------------------- Sentence 1 -------------------

Health information science and systems, p. 3.

>> Tokens are: 
 ['Health', 'information', 'science', 'systems', ',', 'p.', '3', '.']

>> Bigrams are: 
 [('Health', 'information'), ('information', 'science'), ('science', 'systems'), ('systems', ','), (',', 'p.'), ('p.', '3'), ('3', '.')]

>> Trigrams are: 
 [('Health', 'information', 'science'), ('information', 'science', 'systems'), ('science', 'systems', ','), ('systems', ',', 'p.'), (',', 'p.', '3'), ('p.', '3', '.')]

>> POS Tags are: 
 [('Health', 'NNP'), ('information', 'NN'), ('science', 'NN'), ('systems', 'NNS'), (',', ','), ('p.', 'JJ'), ('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Health information science systems']

>> Named Entities are: 
 [('GPE', 'Health')] 

>> Stemming using Porter Stemmer: 
 [('Health', 'health'), ('information', 'inform'), ('science', 'scienc'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Health', 'health'), ('information', 'inform'), ('science', 'scienc'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Health', 'Health'), ('information', 'information'), ('science', 'science'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]



========================================== PARAGRAPH 1601 ===========================================

Rana, S., 2019. Moving in the Realm of Big Data: Using Analytics in Management Research and  

------------------- Sentence 1 -------------------

Rana, S., 2019.

>> Tokens are: 
 ['Rana', ',', 'S.', ',', '2019', '.']

>> Bigrams are: 
 [('Rana', ','), (',', 'S.'), ('S.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Rana', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Rana', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rana', 'S.']

>> Named Entities are: 
 [('GPE', 'Rana')] 

>> Stemming using Porter Stemmer: 
 [('Rana', 'rana'), (',', ','), ('S.', 's.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rana', 'rana'), (',', ','), ('S.', 's.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Rana', 'Rana'), (',', ','), ('S.', 'S.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Moving in the Realm of Big Data: Using Analytics in Management Research and

>> Tokens are: 
 ['Moving', 'Realm', 'Big', 'Data', ':', 'Using', 'Analytics', 'Management', 'Research']

>> Bigrams are: 
 [('Moving', 'Realm'), ('Realm', 'Big'), ('Big', 'Data'), ('Data', ':'), (':', 'Using'), ('Using', 'Analytics'), ('Analytics', 'Management'), ('Management', 'Research')]

>> Trigrams are: 
 [('Moving', 'Realm', 'Big'), ('Realm', 'Big', 'Data'), ('Big', 'Data', ':'), ('Data', ':', 'Using'), (':', 'Using', 'Analytics'), ('Using', 'Analytics', 'Management'), ('Analytics', 'Management', 'Research')]

>> POS Tags are: 
 [('Moving', 'VBG'), ('Realm', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (':', ':'), ('Using', 'NN'), ('Analytics', 'NNP'), ('Management', 'NNP'), ('Research', 'NNP')]

>> Noun Phrases are: 
 ['Realm Big Data', 'Using Analytics Management Research']

>> Named Entities are: 
 [('PERSON', 'Realm Big Data'), ('PERSON', 'Analytics Management Research')] 

>> Stemming using Porter Stemmer: 
 [('Moving', 'move'), ('Realm', 'realm'), ('Big', 'big'), ('Data', 'data'), (':', ':'), ('Using', 'use'), ('Analytics', 'analyt'), ('Management', 'manag'), ('Research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('Moving', 'move'), ('Realm', 'realm'), ('Big', 'big'), ('Data', 'data'), (':', ':'), ('Using', 'use'), ('Analytics', 'analyt'), ('Management', 'manag'), ('Research', 'research')]

>> Lemmatization: 
 [('Moving', 'Moving'), ('Realm', 'Realm'), ('Big', 'Big'), ('Data', 'Data'), (':', ':'), ('Using', 'Using'), ('Analytics', 'Analytics'), ('Management', 'Management'), ('Research', 'Research')]



========================================== PARAGRAPH 1602 ===========================================

Practices.. SAGE journal, 8(1), pp. 7-8.  

------------------- Sentence 1 -------------------

Practices.. SAGE journal, 8(1), pp.

>> Tokens are: 
 ['Practices', '..', 'SAGE', 'journal', ',', '8', '(', '1', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Practices', '..'), ('..', 'SAGE'), ('SAGE', 'journal'), ('journal', ','), (',', '8'), ('8', '('), ('(', '1'), ('1', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Practices', '..', 'SAGE'), ('..', 'SAGE', 'journal'), ('SAGE', 'journal', ','), ('journal', ',', '8'), (',', '8', '('), ('8', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Practices', 'NNS'), ('..', 'VBP'), ('SAGE', 'NNP'), ('journal', 'NN'), (',', ','), ('8', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Practices', 'SAGE journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'SAGE')] 

>> Stemming using Porter Stemmer: 
 [('Practices', 'practic'), ('..', '..'), ('SAGE', 'sage'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Practices', 'practic'), ('..', '..'), ('SAGE', 'sage'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Practices', 'Practices'), ('..', '..'), ('SAGE', 'SAGE'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

7-8.

>> Tokens are: 
 ['7-8', '.']

>> Bigrams are: 
 [('7-8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7-8', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7-8', '7-8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7-8', '7-8'), ('.', '.')]

>> Lemmatization: 
 [('7-8', '7-8'), ('.', '.')]



========================================== PARAGRAPH 1603 ===========================================

Ren, S., Zhang, Y., Liu, Y., Sakao, T., Huisingh, D., Almeida, C. M. V. B, 2019. A comprehensive  

------------------- Sentence 1 -------------------

Ren, S., Zhang, Y., Liu, Y., Sakao, T., Huisingh, D., Almeida, C. M. V. B, 2019.

>> Tokens are: 
 ['Ren', ',', 'S.', ',', 'Zhang', ',', 'Y.', ',', 'Liu', ',', 'Y.', ',', 'Sakao', ',', 'T.', ',', 'Huisingh', ',', 'D.', ',', 'Almeida', ',', 'C.', 'M.', 'V.', 'B', ',', '2019', '.']

>> Bigrams are: 
 [('Ren', ','), (',', 'S.'), ('S.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', ','), (',', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', 'Sakao'), ('Sakao', ','), (',', 'T.'), ('T.', ','), (',', 'Huisingh'), ('Huisingh', ','), (',', 'D.'), ('D.', ','), (',', 'Almeida'), ('Almeida', ','), (',', 'C.'), ('C.', 'M.'), ('M.', 'V.'), ('V.', 'B'), ('B', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Ren', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Sakao'), (',', 'Sakao', ','), ('Sakao', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Huisingh'), (',', 'Huisingh', ','), ('Huisingh', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Almeida'), (',', 'Almeida', ','), ('Almeida', ',', 'C.'), (',', 'C.', 'M.'), ('C.', 'M.', 'V.'), ('M.', 'V.', 'B'), ('V.', 'B', ','), ('B', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Ren', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Sakao', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Huisingh', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Almeida', 'NNP'), (',', ','), ('C.', 'NNP'), ('M.', 'NNP'), ('V.', 'NNP'), ('B', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ren', 'S.', 'Zhang', 'Y.', 'Liu', 'Y.', 'Sakao', 'T.', 'Huisingh', 'D.', 'Almeida', 'C. M. V. B']

>> Named Entities are: 
 [('PERSON', 'Ren'), ('PERSON', 'Zhang'), ('PERSON', 'Liu'), ('PERSON', 'Sakao'), ('PERSON', 'Huisingh'), ('GPE', 'Almeida')] 

>> Stemming using Porter Stemmer: 
 [('Ren', 'ren'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('Sakao', 'sakao'), (',', ','), ('T.', 't.'), (',', ','), ('Huisingh', 'huisingh'), (',', ','), ('D.', 'd.'), (',', ','), ('Almeida', 'almeida'), (',', ','), ('C.', 'c.'), ('M.', 'm.'), ('V.', 'v.'), ('B', 'b'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ren', 'ren'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('Sakao', 'sakao'), (',', ','), ('T.', 't.'), (',', ','), ('Huisingh', 'huisingh'), (',', ','), ('D.', 'd.'), (',', ','), ('Almeida', 'almeida'), (',', ','), ('C.', 'c.'), ('M.', 'm.'), ('V.', 'v.'), ('B', 'b'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Ren', 'Ren'), (',', ','), ('S.', 'S.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Sakao', 'Sakao'), (',', ','), ('T.', 'T.'), (',', ','), ('Huisingh', 'Huisingh'), (',', ','), ('D.', 'D.'), (',', ','), ('Almeida', 'Almeida'), (',', ','), ('C.', 'C.'), ('M.', 'M.'), ('V.', 'V.'), ('B', 'B'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

A comprehensive

>> Tokens are: 
 ['A', 'comprehensive']

>> Bigrams are: 
 [('A', 'comprehensive')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('comprehensive', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('comprehensive', 'comprehens')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('comprehensive', 'comprehens')]

>> Lemmatization: 
 [('A', 'A'), ('comprehensive', 'comprehensive')]



========================================== PARAGRAPH 1604 ===========================================

review of big data analytics throughout product lifecycle to support sustainable smart  

------------------- Sentence 1 -------------------

review of big data analytics throughout product lifecycle to support sustainable smart

>> Tokens are: 
 ['review', 'big', 'data', 'analytics', 'throughout', 'product', 'lifecycle', 'support', 'sustainable', 'smart']

>> Bigrams are: 
 [('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'throughout'), ('throughout', 'product'), ('product', 'lifecycle'), ('lifecycle', 'support'), ('support', 'sustainable'), ('sustainable', 'smart')]

>> Trigrams are: 
 [('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'throughout'), ('analytics', 'throughout', 'product'), ('throughout', 'product', 'lifecycle'), ('product', 'lifecycle', 'support'), ('lifecycle', 'support', 'sustainable'), ('support', 'sustainable', 'smart')]

>> POS Tags are: 
 [('review', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('throughout', 'IN'), ('product', 'NN'), ('lifecycle', 'NN'), ('support', 'NN'), ('sustainable', 'JJ'), ('smart', 'NN')]

>> Noun Phrases are: 
 ['review', 'big data analytics', 'product lifecycle support', 'sustainable smart']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycl'), ('support', 'support'), ('sustainable', 'sustain'), ('smart', 'smart')]

>> Stemming using Snowball Stemmer: 
 [('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycl'), ('support', 'support'), ('sustainable', 'sustain'), ('smart', 'smart')]

>> Lemmatization: 
 [('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycle'), ('support', 'support'), ('sustainable', 'sustainable'), ('smart', 'smart')]



========================================== PARAGRAPH 1605 ===========================================

manufacturing: A framework, challenges and future research direction.. Journal of Cleaner  

------------------- Sentence 1 -------------------

manufacturing: A framework, challenges and future research direction.. Journal of Cleaner

>> Tokens are: 
 ['manufacturing', ':', 'A', 'framework', ',', 'challenges', 'future', 'research', 'direction', '..', 'Journal', 'Cleaner']

>> Bigrams are: 
 [('manufacturing', ':'), (':', 'A'), ('A', 'framework'), ('framework', ','), (',', 'challenges'), ('challenges', 'future'), ('future', 'research'), ('research', 'direction'), ('direction', '..'), ('..', 'Journal'), ('Journal', 'Cleaner')]

>> Trigrams are: 
 [('manufacturing', ':', 'A'), (':', 'A', 'framework'), ('A', 'framework', ','), ('framework', ',', 'challenges'), (',', 'challenges', 'future'), ('challenges', 'future', 'research'), ('future', 'research', 'direction'), ('research', 'direction', '..'), ('direction', '..', 'Journal'), ('..', 'Journal', 'Cleaner')]

>> POS Tags are: 
 [('manufacturing', 'NN'), (':', ':'), ('A', 'DT'), ('framework', 'NN'), (',', ','), ('challenges', 'VBZ'), ('future', 'JJ'), ('research', 'NN'), ('direction', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Cleaner', 'NNP')]

>> Noun Phrases are: 
 ['manufacturing', 'A framework', 'future research direction .. Journal Cleaner']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('manufacturing', 'manufactur'), (':', ':'), ('A', 'a'), ('framework', 'framework'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('research', 'research'), ('direction', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Cleaner', 'cleaner')]

>> Stemming using Snowball Stemmer: 
 [('manufacturing', 'manufactur'), (':', ':'), ('A', 'a'), ('framework', 'framework'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('research', 'research'), ('direction', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Cleaner', 'cleaner')]

>> Lemmatization: 
 [('manufacturing', 'manufacturing'), (':', ':'), ('A', 'A'), ('framework', 'framework'), (',', ','), ('challenges', 'challenge'), ('future', 'future'), ('research', 'research'), ('direction', 'direction'), ('..', '..'), ('Journal', 'Journal'), ('Cleaner', 'Cleaner')]



========================================== PARAGRAPH 1606 ===========================================

Production, Volume 210, pp. 1343-1365.  

------------------- Sentence 1 -------------------

Production, Volume 210, pp.

>> Tokens are: 
 ['Production', ',', 'Volume', '210', ',', 'pp', '.']

>> Bigrams are: 
 [('Production', ','), (',', 'Volume'), ('Volume', '210'), ('210', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Production', ',', 'Volume'), (',', 'Volume', '210'), ('Volume', '210', ','), ('210', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Production', 'NN'), (',', ','), ('Volume', 'NN'), ('210', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Production', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 210')] 

>> Stemming using Porter Stemmer: 
 [('Production', 'product'), (',', ','), ('Volume', 'volum'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Production', 'product'), (',', ','), ('Volume', 'volum'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Production', 'Production'), (',', ','), ('Volume', 'Volume'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1343-1365.

>> Tokens are: 
 ['1343-1365', '.']

>> Bigrams are: 
 [('1343-1365', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1343-1365', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1343-1365', '1343-1365'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1343-1365', '1343-1365'), ('.', '.')]

>> Lemmatization: 
 [('1343-1365', '1343-1365'), ('.', '.')]



========================================== PARAGRAPH 1607 ===========================================

Ristoski, P., Bizer, C. and Paulheim, H., 2015. Mining the web of linked data with rapidminer..  

------------------- Sentence 1 -------------------

Ristoski, P., Bizer, C. and Paulheim, H., 2015.

>> Tokens are: 
 ['Ristoski', ',', 'P.', ',', 'Bizer', ',', 'C.', 'Paulheim', ',', 'H.', ',', '2015', '.']

>> Bigrams are: 
 [('Ristoski', ','), (',', 'P.'), ('P.', ','), (',', 'Bizer'), ('Bizer', ','), (',', 'C.'), ('C.', 'Paulheim'), ('Paulheim', ','), (',', 'H.'), ('H.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Ristoski', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Bizer'), (',', 'Bizer', ','), ('Bizer', ',', 'C.'), (',', 'C.', 'Paulheim'), ('C.', 'Paulheim', ','), ('Paulheim', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Ristoski', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Bizer', 'NNP'), (',', ','), ('C.', 'NNP'), ('Paulheim', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ristoski', 'P.', 'Bizer', 'C. Paulheim', 'H.']

>> Named Entities are: 
 [('GPE', 'Ristoski'), ('PERSON', 'Bizer')] 

>> Stemming using Porter Stemmer: 
 [('Ristoski', 'ristoski'), (',', ','), ('P.', 'p.'), (',', ','), ('Bizer', 'bizer'), (',', ','), ('C.', 'c.'), ('Paulheim', 'paulheim'), (',', ','), ('H.', 'h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ristoski', 'ristoski'), (',', ','), ('P.', 'p.'), (',', ','), ('Bizer', 'bizer'), (',', ','), ('C.', 'c.'), ('Paulheim', 'paulheim'), (',', ','), ('H.', 'h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Ristoski', 'Ristoski'), (',', ','), ('P.', 'P.'), (',', ','), ('Bizer', 'Bizer'), (',', ','), ('C.', 'C.'), ('Paulheim', 'Paulheim'), (',', ','), ('H.', 'H.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Mining the web of linked data with rapidminer..

>> Tokens are: 
 ['Mining', 'web', 'linked', 'data', 'rapidminer', '..']

>> Bigrams are: 
 [('Mining', 'web'), ('web', 'linked'), ('linked', 'data'), ('data', 'rapidminer'), ('rapidminer', '..')]

>> Trigrams are: 
 [('Mining', 'web', 'linked'), ('web', 'linked', 'data'), ('linked', 'data', 'rapidminer'), ('data', 'rapidminer', '..')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('web', 'NN'), ('linked', 'VBN'), ('data', 'NNS'), ('rapidminer', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['web', 'data rapidminer ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('web', 'web'), ('linked', 'link'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('web', 'web'), ('linked', 'link'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('..', '..')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('web', 'web'), ('linked', 'linked'), ('data', 'data'), ('rapidminer', 'rapidminer'), ('..', '..')]



========================================== PARAGRAPH 1608 ===========================================

Web Semantics: Science, Services and Agents on the World Wide Web, Volume 35, pp. 142-151.  

------------------- Sentence 1 -------------------

Web Semantics: Science, Services and Agents on the World Wide Web, Volume 35, pp.

>> Tokens are: 
 ['Web', 'Semantics', ':', 'Science', ',', 'Services', 'Agents', 'World', 'Wide', 'Web', ',', 'Volume', '35', ',', 'pp', '.']

>> Bigrams are: 
 [('Web', 'Semantics'), ('Semantics', ':'), (':', 'Science'), ('Science', ','), (',', 'Services'), ('Services', 'Agents'), ('Agents', 'World'), ('World', 'Wide'), ('Wide', 'Web'), ('Web', ','), (',', 'Volume'), ('Volume', '35'), ('35', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Web', 'Semantics', ':'), ('Semantics', ':', 'Science'), (':', 'Science', ','), ('Science', ',', 'Services'), (',', 'Services', 'Agents'), ('Services', 'Agents', 'World'), ('Agents', 'World', 'Wide'), ('World', 'Wide', 'Web'), ('Wide', 'Web', ','), ('Web', ',', 'Volume'), (',', 'Volume', '35'), ('Volume', '35', ','), ('35', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Web', 'JJ'), ('Semantics', 'NNS'), (':', ':'), ('Science', 'NN'), (',', ','), ('Services', 'NNPS'), ('Agents', 'NNP'), ('World', 'NNP'), ('Wide', 'NNP'), ('Web', 'NNP'), (',', ','), ('Volume', 'NN'), ('35', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Web Semantics', 'Science', 'Agents World Wide Web', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Services Agents'), ('ORGANIZATION', 'Volume 35')] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('Semantics', 'Semantics'), (':', ':'), ('Science', 'Science'), (',', ','), ('Services', 'Services'), ('Agents', 'Agents'), ('World', 'World'), ('Wide', 'Wide'), ('Web', 'Web'), (',', ','), ('Volume', 'Volume'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

142-151.

>> Tokens are: 
 ['142-151', '.']

>> Bigrams are: 
 [('142-151', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('142-151', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('142-151', '142-151'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('142-151', '142-151'), ('.', '.')]

>> Lemmatization: 
 [('142-151', '142-151'), ('.', '.')]



========================================== PARAGRAPH 1609 ===========================================

Russom, P., 2011. Big data analytics, s.l.: TDWI best practices report, fourth quarter.  

------------------- Sentence 1 -------------------

Russom, P., 2011.

>> Tokens are: 
 ['Russom', ',', 'P.', ',', '2011', '.']

>> Bigrams are: 
 [('Russom', ','), (',', 'P.'), ('P.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Russom', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Russom', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Russom', 'P.']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('Russom', 'russom'), (',', ','), ('P.', 'p.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Russom', 'russom'), (',', ','), ('P.', 'p.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Russom', 'Russom'), (',', ','), ('P.', 'P.'), (',', ','), ('2011', '2011'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data analytics, s.l.

>> Tokens are: 
 ['Big', 'data', 'analytics', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics', 's.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('s.l', 's.l'), ('.', '.')]


------------------- Sentence 3 -------------------

: TDWI best practices report, fourth quarter.

>> Tokens are: 
 [':', 'TDWI', 'best', 'practices', 'report', ',', 'fourth', 'quarter', '.']

>> Bigrams are: 
 [(':', 'TDWI'), ('TDWI', 'best'), ('best', 'practices'), ('practices', 'report'), ('report', ','), (',', 'fourth'), ('fourth', 'quarter'), ('quarter', '.')]

>> Trigrams are: 
 [(':', 'TDWI', 'best'), ('TDWI', 'best', 'practices'), ('best', 'practices', 'report'), ('practices', 'report', ','), ('report', ',', 'fourth'), (',', 'fourth', 'quarter'), ('fourth', 'quarter', '.')]

>> POS Tags are: 
 [(':', ':'), ('TDWI', 'NN'), ('best', 'JJS'), ('practices', 'NNS'), ('report', 'NN'), (',', ','), ('fourth', 'JJ'), ('quarter', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['TDWI', 'practices report', 'fourth quarter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('TDWI', 'tdwi'), ('best', 'best'), ('practices', 'practic'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('TDWI', 'tdwi'), ('best', 'best'), ('practices', 'practic'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('TDWI', 'TDWI'), ('best', 'best'), ('practices', 'practice'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]



========================================== PARAGRAPH 1610 ===========================================

Sagiroglu, S. and Sinanc, D., 2013. Big data: A review. s.l., IEEE, pp. 42-47.  

------------------- Sentence 1 -------------------

Sagiroglu, S. and Sinanc, D., 2013.

>> Tokens are: 
 ['Sagiroglu', ',', 'S.', 'Sinanc', ',', 'D.', ',', '2013', '.']

>> Bigrams are: 
 [('Sagiroglu', ','), (',', 'S.'), ('S.', 'Sinanc'), ('Sinanc', ','), (',', 'D.'), ('D.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Sagiroglu', ',', 'S.'), (',', 'S.', 'Sinanc'), ('S.', 'Sinanc', ','), ('Sinanc', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), (',', ','), ('S.', 'NNP'), ('Sinanc', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Sagiroglu', 'S. Sinanc', 'D.']

>> Named Entities are: 
 [('GPE', 'Sagiroglu')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), (',', ','), ('S.', 's.'), ('Sinanc', 'sinanc'), (',', ','), ('D.', 'd.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), (',', ','), ('S.', 's.'), ('Sinanc', 'sinanc'), (',', ','), ('D.', 'd.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), (',', ','), ('S.', 'S.'), ('Sinanc', 'Sinanc'), (',', ','), ('D.', 'D.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: A review.

>> Tokens are: 
 ['Big', 'data', ':', 'A', 'review', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'A'), ('A', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'A'), (':', 'A', 'review'), ('A', 'review', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'A review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('A', 'A'), ('review', 'review'), ('.', '.')]


------------------- Sentence 3 -------------------

s.l., IEEE, pp.

>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

42-47.

>> Tokens are: 
 ['42-47', '.']

>> Bigrams are: 
 [('42-47', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('42-47', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42-47', '42-47'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('42-47', '42-47'), ('.', '.')]

>> Lemmatization: 
 [('42-47', '42-47'), ('.', '.')]



========================================== PARAGRAPH 1611 ===========================================

Schelén, O., Elragal, A. and Haddara, M., 2015. A roadmap for big-data research and education.,  

------------------- Sentence 1 -------------------

Schelén, O., Elragal, A. and Haddara, M., 2015.

>> Tokens are: 
 ['Schelén', ',', 'O.', ',', 'Elragal', ',', 'A.', 'Haddara', ',', 'M.', ',', '2015', '.']

>> Bigrams are: 
 [('Schelén', ','), (',', 'O.'), ('O.', ','), (',', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', 'Haddara'), ('Haddara', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Schelén', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Elragal'), (',', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', 'Haddara'), ('A.', 'Haddara', ','), ('Haddara', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Schelén', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haddara', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Schelén', 'O.', 'Elragal', 'A. Haddara', 'M.']

>> Named Entities are: 
 [('GPE', 'Schelén'), ('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Schelén', 'schelén'), (',', ','), ('O.', 'o.'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Haddara', 'haddara'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schelén', 'schelén'), (',', ','), ('O.', 'o.'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Haddara', 'haddara'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Schelén', 'Schelén'), (',', ','), ('O.', 'O.'), (',', ','), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), ('Haddara', 'Haddara'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

A roadmap for big-data research and education.,

>> Tokens are: 
 ['A', 'roadmap', 'big-data', 'research', 'education.', ',']

>> Bigrams are: 
 [('A', 'roadmap'), ('roadmap', 'big-data'), ('big-data', 'research'), ('research', 'education.'), ('education.', ',')]

>> Trigrams are: 
 [('A', 'roadmap', 'big-data'), ('roadmap', 'big-data', 'research'), ('big-data', 'research', 'education.'), ('research', 'education.', ',')]

>> POS Tags are: 
 [('A', 'DT'), ('roadmap', 'JJ'), ('big-data', 'JJ'), ('research', 'NN'), ('education.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['A roadmap big-data research education.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ',')]

>> Lemmatization: 
 [('A', 'A'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ',')]



========================================== PARAGRAPH 1612 ===========================================

s.l.: Luleå tekniska universitet.  

------------------- Sentence 1 -------------------

s.l.

>> Tokens are: 
 ['s.l', '.']

>> Bigrams are: 
 [('s.l', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('s.l', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('s.l', 's.l'), ('.', '.')]


------------------- Sentence 2 -------------------

: Luleå tekniska universitet.

>> Tokens are: 
 [':', 'Luleå', 'tekniska', 'universitet', '.']

>> Bigrams are: 
 [(':', 'Luleå'), ('Luleå', 'tekniska'), ('tekniska', 'universitet'), ('universitet', '.')]

>> Trigrams are: 
 [(':', 'Luleå', 'tekniska'), ('Luleå', 'tekniska', 'universitet'), ('tekniska', 'universitet', '.')]

>> POS Tags are: 
 [(':', ':'), ('Luleå', 'NN'), ('tekniska', 'NN'), ('universitet', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Luleå tekniska universitet']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Luleå', 'luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Luleå', 'luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Luleå', 'Luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]



========================================== PARAGRAPH 1613 ===========================================

Schulman, J., Levine, S., Abbeel, P., Jordan, M. and Moritz, P., 2015. Trust region policy  

------------------- Sentence 1 -------------------

Schulman, J., Levine, S., Abbeel, P., Jordan, M. and Moritz, P., 2015.

>> Tokens are: 
 ['Schulman', ',', 'J.', ',', 'Levine', ',', 'S.', ',', 'Abbeel', ',', 'P.', ',', 'Jordan', ',', 'M.', 'Moritz', ',', 'P.', ',', '2015', '.']

>> Bigrams are: 
 [('Schulman', ','), (',', 'J.'), ('J.', ','), (',', 'Levine'), ('Levine', ','), (',', 'S.'), ('S.', ','), (',', 'Abbeel'), ('Abbeel', ','), (',', 'P.'), ('P.', ','), (',', 'Jordan'), ('Jordan', ','), (',', 'M.'), ('M.', 'Moritz'), ('Moritz', ','), (',', 'P.'), ('P.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Schulman', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Levine'), (',', 'Levine', ','), ('Levine', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Abbeel'), (',', 'Abbeel', ','), ('Abbeel', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Jordan'), (',', 'Jordan', ','), ('Jordan', ',', 'M.'), (',', 'M.', 'Moritz'), ('M.', 'Moritz', ','), ('Moritz', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Schulman', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Levine', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Abbeel', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Jordan', 'NNP'), (',', ','), ('M.', 'NNP'), ('Moritz', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Schulman', 'J.', 'Levine', 'S.', 'Abbeel', 'P.', 'Jordan', 'M. Moritz', 'P.']

>> Named Entities are: 
 [('GPE', 'Schulman'), ('GPE', 'Levine'), ('GPE', 'Abbeel'), ('GPE', 'Jordan')] 

>> Stemming using Porter Stemmer: 
 [('Schulman', 'schulman'), (',', ','), ('J.', 'j.'), (',', ','), ('Levine', 'levin'), (',', ','), ('S.', 's.'), (',', ','), ('Abbeel', 'abbeel'), (',', ','), ('P.', 'p.'), (',', ','), ('Jordan', 'jordan'), (',', ','), ('M.', 'm.'), ('Moritz', 'moritz'), (',', ','), ('P.', 'p.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schulman', 'schulman'), (',', ','), ('J.', 'j.'), (',', ','), ('Levine', 'levin'), (',', ','), ('S.', 's.'), (',', ','), ('Abbeel', 'abbeel'), (',', ','), ('P.', 'p.'), (',', ','), ('Jordan', 'jordan'), (',', ','), ('M.', 'm.'), ('Moritz', 'moritz'), (',', ','), ('P.', 'p.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Schulman', 'Schulman'), (',', ','), ('J.', 'J.'), (',', ','), ('Levine', 'Levine'), (',', ','), ('S.', 'S.'), (',', ','), ('Abbeel', 'Abbeel'), (',', ','), ('P.', 'P.'), (',', ','), ('Jordan', 'Jordan'), (',', ','), ('M.', 'M.'), ('Moritz', 'Moritz'), (',', ','), ('P.', 'P.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Trust region policy

>> Tokens are: 
 ['Trust', 'region', 'policy']

>> Bigrams are: 
 [('Trust', 'region'), ('region', 'policy')]

>> Trigrams are: 
 [('Trust', 'region', 'policy')]

>> POS Tags are: 
 [('Trust', 'NNP'), ('region', 'NN'), ('policy', 'NN')]

>> Noun Phrases are: 
 ['Trust region policy']

>> Named Entities are: 
 [('GPE', 'Trust')] 

>> Stemming using Porter Stemmer: 
 [('Trust', 'trust'), ('region', 'region'), ('policy', 'polici')]

>> Stemming using Snowball Stemmer: 
 [('Trust', 'trust'), ('region', 'region'), ('policy', 'polici')]

>> Lemmatization: 
 [('Trust', 'Trust'), ('region', 'region'), ('policy', 'policy')]



========================================== PARAGRAPH 1614 ===========================================

optimization. s.l., s.n., pp. 1889-1897.  

------------------- Sentence 1 -------------------

optimization.

>> Tokens are: 
 ['optimization', '.']

>> Bigrams are: 
 [('optimization', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('optimization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['optimization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('optimization', 'optim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('optimization', 'optim'), ('.', '.')]

>> Lemmatization: 
 [('optimization', 'optimization'), ('.', '.')]


------------------- Sentence 2 -------------------

s.l., s.n., pp.

>> Tokens are: 
 ['s.l.', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 's.n.', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1889-1897.

>> Tokens are: 
 ['1889-1897', '.']

>> Bigrams are: 
 [('1889-1897', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1889-1897', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1889-1897', '1889-1897'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1889-1897', '1889-1897'), ('.', '.')]

>> Lemmatization: 
 [('1889-1897', '1889-1897'), ('.', '.')]



========================================== PARAGRAPH 1615 ===========================================

Sharma, R., Mithas, S. and Kankanhalli, A., 2014. Transforming decision-making processes: a  

------------------- Sentence 1 -------------------

Sharma, R., Mithas, S. and Kankanhalli, A., 2014.

>> Tokens are: 
 ['Sharma', ',', 'R.', ',', 'Mithas', ',', 'S.', 'Kankanhalli', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Sharma', ','), (',', 'R.'), ('R.', ','), (',', 'Mithas'), ('Mithas', ','), (',', 'S.'), ('S.', 'Kankanhalli'), ('Kankanhalli', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Sharma', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Mithas'), (',', 'Mithas', ','), ('Mithas', ',', 'S.'), (',', 'S.', 'Kankanhalli'), ('S.', 'Kankanhalli', ','), ('Kankanhalli', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Sharma', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Mithas', 'NNP'), (',', ','), ('S.', 'NNP'), ('Kankanhalli', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Sharma', 'R.', 'Mithas', 'S. Kankanhalli', 'A.']

>> Named Entities are: 
 [('GPE', 'Sharma'), ('GPE', 'Mithas')] 

>> Stemming using Porter Stemmer: 
 [('Sharma', 'sharma'), (',', ','), ('R.', 'r.'), (',', ','), ('Mithas', 'mitha'), (',', ','), ('S.', 's.'), ('Kankanhalli', 'kankanh'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sharma', 'sharma'), (',', ','), ('R.', 'r.'), (',', ','), ('Mithas', 'mitha'), (',', ','), ('S.', 's.'), ('Kankanhalli', 'kankanh'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Sharma', 'Sharma'), (',', ','), ('R.', 'R.'), (',', ','), ('Mithas', 'Mithas'), (',', ','), ('S.', 'S.'), ('Kankanhalli', 'Kankanhalli'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Transforming decision-making processes: a

>> Tokens are: 
 ['Transforming', 'decision-making', 'processes', ':']

>> Bigrams are: 
 [('Transforming', 'decision-making'), ('decision-making', 'processes'), ('processes', ':')]

>> Trigrams are: 
 [('Transforming', 'decision-making', 'processes'), ('decision-making', 'processes', ':')]

>> POS Tags are: 
 [('Transforming', 'VBG'), ('decision-making', 'JJ'), ('processes', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['decision-making processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Transforming', 'transform'), ('decision-making', 'decision-mak'), ('processes', 'process'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Transforming', 'transform'), ('decision-making', 'decision-mak'), ('processes', 'process'), (':', ':')]

>> Lemmatization: 
 [('Transforming', 'Transforming'), ('decision-making', 'decision-making'), ('processes', 'process'), (':', ':')]



========================================== PARAGRAPH 1616 ===========================================

research agenda for understanding the impact of business analytics on organisations.. European  

------------------- Sentence 1 -------------------

research agenda for understanding the impact of business analytics on organisations.. European

>> Tokens are: 
 ['research', 'agenda', 'understanding', 'impact', 'business', 'analytics', 'organisations', '..', 'European']

>> Bigrams are: 
 [('research', 'agenda'), ('agenda', 'understanding'), ('understanding', 'impact'), ('impact', 'business'), ('business', 'analytics'), ('analytics', 'organisations'), ('organisations', '..'), ('..', 'European')]

>> Trigrams are: 
 [('research', 'agenda', 'understanding'), ('agenda', 'understanding', 'impact'), ('understanding', 'impact', 'business'), ('impact', 'business', 'analytics'), ('business', 'analytics', 'organisations'), ('analytics', 'organisations', '..'), ('organisations', '..', 'European')]

>> POS Tags are: 
 [('research', 'NN'), ('agenda', 'NN'), ('understanding', 'JJ'), ('impact', 'NN'), ('business', 'NN'), ('analytics', 'NNS'), ('organisations', 'NNS'), ('..', 'VBP'), ('European', 'JJ')]

>> Noun Phrases are: 
 ['research agenda', 'understanding impact business analytics organisations']

>> Named Entities are: 
 [('GPE', 'European')] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understand'), ('impact', 'impact'), ('business', 'busi'), ('analytics', 'analyt'), ('organisations', 'organis'), ('..', '..'), ('European', 'european')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understand'), ('impact', 'impact'), ('business', 'busi'), ('analytics', 'analyt'), ('organisations', 'organis'), ('..', '..'), ('European', 'european')]

>> Lemmatization: 
 [('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understanding'), ('impact', 'impact'), ('business', 'business'), ('analytics', 'analytics'), ('organisations', 'organisation'), ('..', '..'), ('European', 'European')]



========================================== PARAGRAPH 1617 ===========================================

Journal of Information Systems, Volume 23. 

------------------- Sentence 1 -------------------

Journal of Information Systems, Volume 23.

>> Tokens are: 
 ['Journal', 'Information', 'Systems', ',', 'Volume', '23', '.']

>> Bigrams are: 
 [('Journal', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Volume'), ('Volume', '23'), ('23', '.')]

>> Trigrams are: 
 [('Journal', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Volume'), (',', 'Volume', '23'), ('Volume', '23', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Volume', 'NN'), ('23', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Information Systems', 'Volume']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Information Systems'), ('ORGANIZATION', 'Volume 23')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Volume', 'Volume'), ('23', '23'), ('.', '.')]



========================================== PARAGRAPH 1618 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1619 ===========================================

53  

------------------- Sentence 1 -------------------

53

>> Tokens are: 
 ['53']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('53', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('53', '53')]

>> Stemming using Snowball Stemmer: 
 [('53', '53')]

>> Lemmatization: 
 [('53', '53')]



========================================== PARAGRAPH 1620 ===========================================

  


========================================== PARAGRAPH 1621 ===========================================

Singh, J. and Singla, V., 2015. Big data: tools and technologies in big data.. International Journal  

------------------- Sentence 1 -------------------

Singh, J. and Singla, V., 2015.

>> Tokens are: 
 ['Singh', ',', 'J.', 'Singla', ',', 'V.', ',', '2015', '.']

>> Bigrams are: 
 [('Singh', ','), (',', 'J.'), ('J.', 'Singla'), ('Singla', ','), (',', 'V.'), ('V.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Singh', ',', 'J.'), (',', 'J.', 'Singla'), ('J.', 'Singla', ','), ('Singla', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Singh', 'NNP'), (',', ','), ('J.', 'NNP'), ('Singla', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Singh', 'J. Singla', 'V.']

>> Named Entities are: 
 [('GPE', 'Singh'), ('PERSON', 'J. Singla')] 

>> Stemming using Porter Stemmer: 
 [('Singh', 'singh'), (',', ','), ('J.', 'j.'), ('Singla', 'singla'), (',', ','), ('V.', 'v.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Singh', 'singh'), (',', ','), ('J.', 'j.'), ('Singla', 'singla'), (',', ','), ('V.', 'v.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Singh', 'Singh'), (',', ','), ('J.', 'J.'), ('Singla', 'Singla'), (',', ','), ('V.', 'V.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: tools and technologies in big data.. International Journal

>> Tokens are: 
 ['Big', 'data', ':', 'tools', 'technologies', 'big', 'data', '..', 'International', 'Journal']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'tools'), ('tools', 'technologies'), ('technologies', 'big'), ('big', 'data'), ('data', '..'), ('..', 'International'), ('International', 'Journal')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'tools'), (':', 'tools', 'technologies'), ('tools', 'technologies', 'big'), ('technologies', 'big', 'data'), ('big', 'data', '..'), ('data', '..', 'International'), ('..', 'International', 'Journal')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('tools', 'NNS'), ('technologies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('..', 'VBP'), ('International', 'NNP'), ('Journal', 'NNP')]

>> Noun Phrases are: 
 ['Big data', 'tools technologies', 'big data', 'International Journal']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technolog'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technolog'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technology'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal')]



========================================== PARAGRAPH 1622 ===========================================

of Computer Applications., Volume 112.  

------------------- Sentence 1 -------------------

of Computer Applications., Volume 112.

>> Tokens are: 
 ['Computer', 'Applications.', ',', 'Volume', '112', '.']

>> Bigrams are: 
 [('Computer', 'Applications.'), ('Applications.', ','), (',', 'Volume'), ('Volume', '112'), ('112', '.')]

>> Trigrams are: 
 [('Computer', 'Applications.', ','), ('Applications.', ',', 'Volume'), (',', 'Volume', '112'), ('Volume', '112', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Applications.', 'NNP'), (',', ','), ('Volume', 'NN'), ('112', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Applications.', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer'), ('ORGANIZATION', 'Volume 112')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Applications.', 'applications.'), (',', ','), ('Volume', 'volum'), ('112', '112'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Applications.', 'applications.'), (',', ','), ('Volume', 'volum'), ('112', '112'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Applications.', 'Applications.'), (',', ','), ('Volume', 'Volume'), ('112', '112'), ('.', '.')]



========================================== PARAGRAPH 1623 ===========================================

Suthaharan, S., 2014. Big data classification: Problems and challenges in network intrusion  

------------------- Sentence 1 -------------------

Suthaharan, S., 2014.

>> Tokens are: 
 ['Suthaharan', ',', 'S.', ',', '2014', '.']

>> Bigrams are: 
 [('Suthaharan', ','), (',', 'S.'), ('S.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Suthaharan', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Suthaharan', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Suthaharan', 'S.']

>> Named Entities are: 
 [('GPE', 'Suthaharan')] 

>> Stemming using Porter Stemmer: 
 [('Suthaharan', 'suthaharan'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Suthaharan', 'suthaharan'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Suthaharan', 'Suthaharan'), (',', ','), ('S.', 'S.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data classification: Problems and challenges in network intrusion

>> Tokens are: 
 ['Big', 'data', 'classification', ':', 'Problems', 'challenges', 'network', 'intrusion']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'classification'), ('classification', ':'), (':', 'Problems'), ('Problems', 'challenges'), ('challenges', 'network'), ('network', 'intrusion')]

>> Trigrams are: 
 [('Big', 'data', 'classification'), ('data', 'classification', ':'), ('classification', ':', 'Problems'), (':', 'Problems', 'challenges'), ('Problems', 'challenges', 'network'), ('challenges', 'network', 'intrusion')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('classification', 'NN'), (':', ':'), ('Problems', 'NNP'), ('challenges', 'VBZ'), ('network', 'NN'), ('intrusion', 'NN')]

>> Noun Phrases are: 
 ['Big data classification', 'Problems', 'network intrusion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('classification', 'classif'), (':', ':'), ('Problems', 'problem'), ('challenges', 'challeng'), ('network', 'network'), ('intrusion', 'intrus')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('classification', 'classif'), (':', ':'), ('Problems', 'problem'), ('challenges', 'challeng'), ('network', 'network'), ('intrusion', 'intrus')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('classification', 'classification'), (':', ':'), ('Problems', 'Problems'), ('challenges', 'challenge'), ('network', 'network'), ('intrusion', 'intrusion')]



========================================== PARAGRAPH 1624 ===========================================

prediction with machine learning.. ACM SIGMETRICS Performance Evaluation Review, Volume  

------------------- Sentence 1 -------------------

prediction with machine learning.. ACM SIGMETRICS Performance Evaluation Review, Volume

>> Tokens are: 
 ['prediction', 'machine', 'learning', '..', 'ACM', 'SIGMETRICS', 'Performance', 'Evaluation', 'Review', ',', 'Volume']

>> Bigrams are: 
 [('prediction', 'machine'), ('machine', 'learning'), ('learning', '..'), ('..', 'ACM'), ('ACM', 'SIGMETRICS'), ('SIGMETRICS', 'Performance'), ('Performance', 'Evaluation'), ('Evaluation', 'Review'), ('Review', ','), (',', 'Volume')]

>> Trigrams are: 
 [('prediction', 'machine', 'learning'), ('machine', 'learning', '..'), ('learning', '..', 'ACM'), ('..', 'ACM', 'SIGMETRICS'), ('ACM', 'SIGMETRICS', 'Performance'), ('SIGMETRICS', 'Performance', 'Evaluation'), ('Performance', 'Evaluation', 'Review'), ('Evaluation', 'Review', ','), ('Review', ',', 'Volume')]

>> POS Tags are: 
 [('prediction', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('..', 'JJ'), ('ACM', 'NNP'), ('SIGMETRICS', 'NNP'), ('Performance', 'NNP'), ('Evaluation', 'NNP'), ('Review', 'NNP'), (',', ','), ('Volume', 'NN')]

>> Noun Phrases are: 
 ['prediction machine', '.. ACM SIGMETRICS Performance Evaluation Review', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('PERSON', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('prediction', 'predict'), ('machine', 'machin'), ('learning', 'learn'), ('..', '..'), ('ACM', 'acm'), ('SIGMETRICS', 'sigmetr'), ('Performance', 'perform'), ('Evaluation', 'evalu'), ('Review', 'review'), (',', ','), ('Volume', 'volum')]

>> Stemming using Snowball Stemmer: 
 [('prediction', 'predict'), ('machine', 'machin'), ('learning', 'learn'), ('..', '..'), ('ACM', 'acm'), ('SIGMETRICS', 'sigmetr'), ('Performance', 'perform'), ('Evaluation', 'evalu'), ('Review', 'review'), (',', ','), ('Volume', 'volum')]

>> Lemmatization: 
 [('prediction', 'prediction'), ('machine', 'machine'), ('learning', 'learning'), ('..', '..'), ('ACM', 'ACM'), ('SIGMETRICS', 'SIGMETRICS'), ('Performance', 'Performance'), ('Evaluation', 'Evaluation'), ('Review', 'Review'), (',', ','), ('Volume', 'Volume')]



========================================== PARAGRAPH 1625 ===========================================

4, pp. 70-73.  

------------------- Sentence 1 -------------------

4, pp.

>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

70-73.

>> Tokens are: 
 ['70-73', '.']

>> Bigrams are: 
 [('70-73', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('70-73', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('70-73', '70-73'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('70-73', '70-73'), ('.', '.')]

>> Lemmatization: 
 [('70-73', '70-73'), ('.', '.')]



========================================== PARAGRAPH 1626 ===========================================

Team, R.C., 2000. R language definition.. R foundation for statistical computing.  

------------------- Sentence 1 -------------------

Team, R.C., 2000.

>> Tokens are: 
 ['Team', ',', 'R.C.', ',', '2000', '.']

>> Bigrams are: 
 [('Team', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2000'), ('2000', '.')]

>> Trigrams are: 
 [('Team', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2000'), (',', '2000', '.')]

>> POS Tags are: 
 [('Team', 'NN'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2000', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Team', 'R.C.']

>> Named Entities are: 
 [('GPE', 'Team')] 

>> Stemming using Porter Stemmer: 
 [('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Lemmatization: 
 [('Team', 'Team'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2000', '2000'), ('.', '.')]


------------------- Sentence 2 -------------------

R language definition.. R foundation for statistical computing.

>> Tokens are: 
 ['R', 'language', 'definition', '..', 'R', 'foundation', 'statistical', 'computing', '.']

>> Bigrams are: 
 [('R', 'language'), ('language', 'definition'), ('definition', '..'), ('..', 'R'), ('R', 'foundation'), ('foundation', 'statistical'), ('statistical', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('R', 'language', 'definition'), ('language', 'definition', '..'), ('definition', '..', 'R'), ('..', 'R', 'foundation'), ('R', 'foundation', 'statistical'), ('foundation', 'statistical', 'computing'), ('statistical', 'computing', '.')]

>> POS Tags are: 
 [('R', 'NNP'), ('language', 'NN'), ('definition', 'NN'), ('..', 'NNP'), ('R', 'NNP'), ('foundation', 'NN'), ('statistical', 'JJ'), ('computing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['R language definition .. R foundation', 'statistical computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('language', 'languag'), ('definition', 'definit'), ('..', '..'), ('R', 'r'), ('foundation', 'foundat'), ('statistical', 'statist'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('language', 'languag'), ('definition', 'definit'), ('..', '..'), ('R', 'r'), ('foundation', 'foundat'), ('statistical', 'statist'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('R', 'R'), ('language', 'language'), ('definition', 'definition'), ('..', '..'), ('R', 'R'), ('foundation', 'foundation'), ('statistical', 'statistical'), ('computing', 'computing'), ('.', '.')]



========================================== PARAGRAPH 1627 ===========================================

Tien, J.M., 2013. Big data: Unleashing information.. Journal of Systems Science and Systems  

------------------- Sentence 1 -------------------

Tien, J.M., 2013.

>> Tokens are: 
 ['Tien', ',', 'J.M.', ',', '2013', '.']

>> Bigrams are: 
 [('Tien', ','), (',', 'J.M.'), ('J.M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Tien', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Tien', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Tien', 'J.M.']

>> Named Entities are: 
 [('GPE', 'Tien')] 

>> Stemming using Porter Stemmer: 
 [('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Tien', 'Tien'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: Unleashing information.. Journal of Systems Science and Systems

>> Tokens are: 
 ['Big', 'data', ':', 'Unleashing', 'information', '..', 'Journal', 'Systems', 'Science', 'Systems']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'Unleashing'), ('Unleashing', 'information'), ('information', '..'), ('..', 'Journal'), ('Journal', 'Systems'), ('Systems', 'Science'), ('Science', 'Systems')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'Unleashing'), (':', 'Unleashing', 'information'), ('Unleashing', 'information', '..'), ('information', '..', 'Journal'), ('..', 'Journal', 'Systems'), ('Journal', 'Systems', 'Science'), ('Systems', 'Science', 'Systems')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('Unleashing', 'VBG'), ('information', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Systems', 'NNPS'), ('Science', 'NNP'), ('Systems', 'NNPS')]

>> Noun Phrases are: 
 ['Big data', 'information .. Journal', 'Science']

>> Named Entities are: 
 [('ORGANIZATION', 'Science Systems')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('Unleashing', 'unleash'), ('information', 'inform'), ('..', '..'), ('Journal', 'journal'), ('Systems', 'system'), ('Science', 'scienc'), ('Systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('Unleashing', 'unleash'), ('information', 'inform'), ('..', '..'), ('Journal', 'journal'), ('Systems', 'system'), ('Science', 'scienc'), ('Systems', 'system')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('Unleashing', 'Unleashing'), ('information', 'information'), ('..', '..'), ('Journal', 'Journal'), ('Systems', 'Systems'), ('Science', 'Science'), ('Systems', 'Systems')]



========================================== PARAGRAPH 1628 ===========================================

Engineering, 22(2), pp. 127-151.  

------------------- Sentence 1 -------------------

Engineering, 22(2), pp.

>> Tokens are: 
 ['Engineering', ',', '22', '(', '2', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Engineering', ','), (',', '22'), ('22', '('), ('(', '2'), ('2', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Engineering', ',', '22'), (',', '22', '('), ('22', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Engineering', 'NNP'), (',', ','), ('22', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Engineering', 'pp']

>> Named Entities are: 
 [('GPE', 'Engineering')] 

>> Stemming using Porter Stemmer: 
 [('Engineering', 'engin'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Engineering', 'engin'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Engineering', 'Engineering'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

127-151.

>> Tokens are: 
 ['127-151', '.']

>> Bigrams are: 
 [('127-151', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('127-151', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('127-151', '127-151'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('127-151', '127-151'), ('.', '.')]

>> Lemmatization: 
 [('127-151', '127-151'), ('.', '.')]



========================================== PARAGRAPH 1629 ===========================================

ur Rehman, M.H., Chang, V., Batool, A. and Wah, T.Y., 2016. Big data reduction framework for  

------------------- Sentence 1 -------------------

ur Rehman, M.H., Chang, V., Batool, A. and Wah, T.Y., 2016.

>> Tokens are: 
 ['ur', 'Rehman', ',', 'M.H.', ',', 'Chang', ',', 'V.', ',', 'Batool', ',', 'A.', 'Wah', ',', 'T.Y.', ',', '2016', '.']

>> Bigrams are: 
 [('ur', 'Rehman'), ('Rehman', ','), (',', 'M.H.'), ('M.H.', ','), (',', 'Chang'), ('Chang', ','), (',', 'V.'), ('V.', ','), (',', 'Batool'), ('Batool', ','), (',', 'A.'), ('A.', 'Wah'), ('Wah', ','), (',', 'T.Y.'), ('T.Y.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('ur', 'Rehman', ','), ('Rehman', ',', 'M.H.'), (',', 'M.H.', ','), ('M.H.', ',', 'Chang'), (',', 'Chang', ','), ('Chang', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Batool'), (',', 'Batool', ','), ('Batool', ',', 'A.'), (',', 'A.', 'Wah'), ('A.', 'Wah', ','), ('Wah', ',', 'T.Y.'), (',', 'T.Y.', ','), ('T.Y.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('ur', 'JJ'), ('Rehman', 'NNP'), (',', ','), ('M.H.', 'NNP'), (',', ','), ('Chang', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Batool', 'NNP'), (',', ','), ('A.', 'NNP'), ('Wah', 'NNP'), (',', ','), ('T.Y.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['ur Rehman', 'M.H.', 'Chang', 'V.', 'Batool', 'A. Wah', 'T.Y.']

>> Named Entities are: 
 [('PERSON', 'Rehman'), ('PERSON', 'Chang'), ('GPE', 'Batool')] 

>> Stemming using Porter Stemmer: 
 [('ur', 'ur'), ('Rehman', 'rehman'), (',', ','), ('M.H.', 'm.h.'), (',', ','), ('Chang', 'chang'), (',', ','), ('V.', 'v.'), (',', ','), ('Batool', 'batool'), (',', ','), ('A.', 'a.'), ('Wah', 'wah'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ur', 'ur'), ('Rehman', 'rehman'), (',', ','), ('M.H.', 'm.h.'), (',', ','), ('Chang', 'chang'), (',', ','), ('V.', 'v.'), (',', ','), ('Batool', 'batool'), (',', ','), ('A.', 'a.'), ('Wah', 'wah'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('ur', 'ur'), ('Rehman', 'Rehman'), (',', ','), ('M.H.', 'M.H.'), (',', ','), ('Chang', 'Chang'), (',', ','), ('V.', 'V.'), (',', ','), ('Batool', 'Batool'), (',', ','), ('A.', 'A.'), ('Wah', 'Wah'), (',', ','), ('T.Y.', 'T.Y.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data reduction framework for

>> Tokens are: 
 ['Big', 'data', 'reduction', 'framework']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'reduction'), ('reduction', 'framework')]

>> Trigrams are: 
 [('Big', 'data', 'reduction'), ('data', 'reduction', 'framework')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('reduction', 'NN'), ('framework', 'NN')]

>> Noun Phrases are: 
 ['Big data reduction framework']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('reduction', 'reduct'), ('framework', 'framework')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('reduction', 'reduct'), ('framework', 'framework')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('reduction', 'reduction'), ('framework', 'framework')]



========================================== PARAGRAPH 1630 ===========================================

value creation in sustainable enterprises. International Journal of Information Management, 36(6),  

------------------- Sentence 1 -------------------

value creation in sustainable enterprises.

>> Tokens are: 
 ['value', 'creation', 'sustainable', 'enterprises', '.']

>> Bigrams are: 
 [('value', 'creation'), ('creation', 'sustainable'), ('sustainable', 'enterprises'), ('enterprises', '.')]

>> Trigrams are: 
 [('value', 'creation', 'sustainable'), ('creation', 'sustainable', 'enterprises'), ('sustainable', 'enterprises', '.')]

>> POS Tags are: 
 [('value', 'NN'), ('creation', 'NN'), ('sustainable', 'JJ'), ('enterprises', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['value creation', 'sustainable enterprises']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('value', 'valu'), ('creation', 'creation'), ('sustainable', 'sustain'), ('enterprises', 'enterpris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('value', 'valu'), ('creation', 'creation'), ('sustainable', 'sustain'), ('enterprises', 'enterpris'), ('.', '.')]

>> Lemmatization: 
 [('value', 'value'), ('creation', 'creation'), ('sustainable', 'sustainable'), ('enterprises', 'enterprise'), ('.', '.')]


------------------- Sentence 2 -------------------

International Journal of Information Management, 36(6),

>> Tokens are: 
 ['International', 'Journal', 'Information', 'Management', ',', '36', '(', '6', ')', ',']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', '36'), ('36', '('), ('(', '6'), ('6', ')'), (')', ',')]

>> Trigrams are: 
 [('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', '36'), (',', '36', '('), ('36', '(', '6'), ('(', '6', ')'), ('6', ')', ',')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('36', 'CD'), ('(', '('), ('6', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['International Journal Information Management']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Information Management')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 1631 ===========================================

pp.917-928.. International Journal of Information Management, Volume 36, pp. 917-928.  

------------------- Sentence 1 -------------------

pp.917-928.. International Journal of Information Management, Volume 36, pp.

>> Tokens are: 
 ['pp.917-928', '..', 'International', 'Journal', 'Information', 'Management', ',', 'Volume', '36', ',', 'pp', '.']

>> Bigrams are: 
 [('pp.917-928', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '36'), ('36', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('pp.917-928', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '36'), ('Volume', '36', ','), ('36', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('pp.917-928', 'JJ'), ('..', 'NNP'), ('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp.917-928 .. International Journal Information Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 36')] 

>> Stemming using Porter Stemmer: 
 [('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

917-928.

>> Tokens are: 
 ['917-928', '.']

>> Bigrams are: 
 [('917-928', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('917-928', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('917-928', '917-928'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('917-928', '917-928'), ('.', '.')]

>> Lemmatization: 
 [('917-928', '917-928'), ('.', '.')]



========================================== PARAGRAPH 1632 ===========================================

Van Hasselt, H., Guez, A. and Silver, D., 2016. Deep reinforcement learning with double q- 

------------------- Sentence 1 -------------------

Van Hasselt, H., Guez, A. and Silver, D., 2016.

>> Tokens are: 
 ['Van', 'Hasselt', ',', 'H.', ',', 'Guez', ',', 'A.', 'Silver', ',', 'D.', ',', '2016', '.']

>> Bigrams are: 
 [('Van', 'Hasselt'), ('Hasselt', ','), (',', 'H.'), ('H.', ','), (',', 'Guez'), ('Guez', ','), (',', 'A.'), ('A.', 'Silver'), ('Silver', ','), (',', 'D.'), ('D.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Van', 'Hasselt', ','), ('Hasselt', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Guez'), (',', 'Guez', ','), ('Guez', ',', 'A.'), (',', 'A.', 'Silver'), ('A.', 'Silver', ','), ('Silver', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Van', 'NNP'), ('Hasselt', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Guez', 'NNP'), (',', ','), ('A.', 'NNP'), ('Silver', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Van Hasselt', 'H.', 'Guez', 'A. Silver', 'D.']

>> Named Entities are: 
 [('PERSON', 'Van Hasselt'), ('GPE', 'Guez')] 

>> Stemming using Porter Stemmer: 
 [('Van', 'van'), ('Hasselt', 'hasselt'), (',', ','), ('H.', 'h.'), (',', ','), ('Guez', 'guez'), (',', ','), ('A.', 'a.'), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Van', 'van'), ('Hasselt', 'hasselt'), (',', ','), ('H.', 'h.'), (',', ','), ('Guez', 'guez'), (',', ','), ('A.', 'a.'), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Van', 'Van'), ('Hasselt', 'Hasselt'), (',', ','), ('H.', 'H.'), (',', ','), ('Guez', 'Guez'), (',', ','), ('A.', 'A.'), ('Silver', 'Silver'), (',', ','), ('D.', 'D.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep reinforcement learning with double q-

>> Tokens are: 
 ['Deep', 'reinforcement', 'learning', 'double', 'q-']

>> Bigrams are: 
 [('Deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'double'), ('double', 'q-')]

>> Trigrams are: 
 [('Deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'double'), ('learning', 'double', 'q-')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('double', 'JJ'), ('q-', 'JJ')]

>> Noun Phrases are: 
 ['Deep reinforcement']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('double', 'doubl'), ('q-', 'q-')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('double', 'doubl'), ('q-', 'q-')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('double', 'double'), ('q-', 'q-')]



========================================== PARAGRAPH 1633 ===========================================

learning. s.l., s.n.  

------------------- Sentence 1 -------------------

learning.

>> Tokens are: 
 ['learning', '.']

>> Bigrams are: 
 [('learning', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

s.l., s.n.

>> Tokens are: 
 ['s.l.', ',', 's.n', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n'), ('s.n', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n'), (',', 's.n', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 's.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]



========================================== PARAGRAPH 1634 ===========================================

Vom Brocke, J., Simons, A., Niehaves, B., Riemer, K., Plattfaut, R. and Cleven, A., 2009.  

------------------- Sentence 1 -------------------

Vom Brocke, J., Simons, A., Niehaves, B., Riemer, K., Plattfaut, R. and Cleven, A., 2009.

>> Tokens are: 
 ['Vom', 'Brocke', ',', 'J.', ',', 'Simons', ',', 'A.', ',', 'Niehaves', ',', 'B.', ',', 'Riemer', ',', 'K.', ',', 'Plattfaut', ',', 'R.', 'Cleven', ',', 'A.', ',', '2009', '.']

>> Bigrams are: 
 [('Vom', 'Brocke'), ('Brocke', ','), (',', 'J.'), ('J.', ','), (',', 'Simons'), ('Simons', ','), (',', 'A.'), ('A.', ','), (',', 'Niehaves'), ('Niehaves', ','), (',', 'B.'), ('B.', ','), (',', 'Riemer'), ('Riemer', ','), (',', 'K.'), ('K.', ','), (',', 'Plattfaut'), ('Plattfaut', ','), (',', 'R.'), ('R.', 'Cleven'), ('Cleven', ','), (',', 'A.'), ('A.', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('Vom', 'Brocke', ','), ('Brocke', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Simons'), (',', 'Simons', ','), ('Simons', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Niehaves'), (',', 'Niehaves', ','), ('Niehaves', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Riemer'), (',', 'Riemer', ','), ('Riemer', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Plattfaut'), (',', 'Plattfaut', ','), ('Plattfaut', ',', 'R.'), (',', 'R.', 'Cleven'), ('R.', 'Cleven', ','), ('Cleven', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('Vom', 'NNP'), ('Brocke', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Simons', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Niehaves', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Riemer', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Plattfaut', 'NNP'), (',', ','), ('R.', 'NNP'), ('Cleven', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2009', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Vom Brocke', 'J.', 'Simons', 'A.', 'Niehaves', 'B.', 'Riemer', 'K.', 'Plattfaut', 'R. Cleven', 'A.']

>> Named Entities are: 
 [('PERSON', 'Vom'), ('ORGANIZATION', 'Brocke'), ('GPE', 'Simons'), ('GPE', 'Niehaves'), ('GPE', 'Riemer'), ('PERSON', 'Plattfaut')] 

>> Stemming using Porter Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), (',', ','), ('Simons', 'simon'), (',', ','), ('A.', 'a.'), (',', ','), ('Niehaves', 'niehav'), (',', ','), ('B.', 'b.'), (',', ','), ('Riemer', 'riemer'), (',', ','), ('K.', 'k.'), (',', ','), ('Plattfaut', 'plattfaut'), (',', ','), ('R.', 'r.'), ('Cleven', 'cleven'), (',', ','), ('A.', 'a.'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), (',', ','), ('Simons', 'simon'), (',', ','), ('A.', 'a.'), (',', ','), ('Niehaves', 'niehav'), (',', ','), ('B.', 'b.'), (',', ','), ('Riemer', 'riemer'), (',', ','), ('K.', 'k.'), (',', ','), ('Plattfaut', 'plattfaut'), (',', ','), ('R.', 'r.'), ('Cleven', 'cleven'), (',', ','), ('A.', 'a.'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('Vom', 'Vom'), ('Brocke', 'Brocke'), (',', ','), ('J.', 'J.'), (',', ','), ('Simons', 'Simons'), (',', ','), ('A.', 'A.'), (',', ','), ('Niehaves', 'Niehaves'), (',', ','), ('B.', 'B.'), (',', ','), ('Riemer', 'Riemer'), (',', ','), ('K.', 'K.'), (',', ','), ('Plattfaut', 'Plattfaut'), (',', ','), ('R.', 'R.'), ('Cleven', 'Cleven'), (',', ','), ('A.', 'A.'), (',', ','), ('2009', '2009'), ('.', '.')]



========================================== PARAGRAPH 1635 ===========================================

Reconstructing the giant: On the importance of rigour in documenting the literature search  

------------------- Sentence 1 -------------------

Reconstructing the giant: On the importance of rigour in documenting the literature search

>> Tokens are: 
 ['Reconstructing', 'giant', ':', 'On', 'importance', 'rigour', 'documenting', 'literature', 'search']

>> Bigrams are: 
 [('Reconstructing', 'giant'), ('giant', ':'), (':', 'On'), ('On', 'importance'), ('importance', 'rigour'), ('rigour', 'documenting'), ('documenting', 'literature'), ('literature', 'search')]

>> Trigrams are: 
 [('Reconstructing', 'giant', ':'), ('giant', ':', 'On'), (':', 'On', 'importance'), ('On', 'importance', 'rigour'), ('importance', 'rigour', 'documenting'), ('rigour', 'documenting', 'literature'), ('documenting', 'literature', 'search')]

>> POS Tags are: 
 [('Reconstructing', 'VBG'), ('giant', 'NN'), (':', ':'), ('On', 'IN'), ('importance', 'NN'), ('rigour', 'NN'), ('documenting', 'VBG'), ('literature', 'NN'), ('search', 'NN')]

>> Noun Phrases are: 
 ['giant', 'importance rigour', 'literature search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reconstructing', 'reconstruct'), ('giant', 'giant'), (':', ':'), ('On', 'on'), ('importance', 'import'), ('rigour', 'rigour'), ('documenting', 'document'), ('literature', 'literatur'), ('search', 'search')]

>> Stemming using Snowball Stemmer: 
 [('Reconstructing', 'reconstruct'), ('giant', 'giant'), (':', ':'), ('On', 'on'), ('importance', 'import'), ('rigour', 'rigour'), ('documenting', 'document'), ('literature', 'literatur'), ('search', 'search')]

>> Lemmatization: 
 [('Reconstructing', 'Reconstructing'), ('giant', 'giant'), (':', ':'), ('On', 'On'), ('importance', 'importance'), ('rigour', 'rigour'), ('documenting', 'documenting'), ('literature', 'literature'), ('search', 'search')]



========================================== PARAGRAPH 1636 ===========================================

process.. s.l., s.n.  

------------------- Sentence 1 -------------------

process..

>> Tokens are: 
 ['process', '..']

>> Bigrams are: 
 [('process', '..')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('process', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['process ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('..', '..')]

>> Lemmatization: 
 [('process', 'process'), ('..', '..')]


------------------- Sentence 2 -------------------

s.l., s.n.

>> Tokens are: 
 ['s.l.', ',', 's.n', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n'), ('s.n', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n'), (',', 's.n', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['s.l.', 's.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]



========================================== PARAGRAPH 1637 ===========================================

Waller, M.A. and Fawcett, S.E., 2013. Data science, predictive analytics, and big data: a revolution  

------------------- Sentence 1 -------------------

Waller, M.A.

>> Tokens are: 
 ['Waller', ',', 'M.A', '.']

>> Bigrams are: 
 [('Waller', ','), (',', 'M.A'), ('M.A', '.')]

>> Trigrams are: 
 [('Waller', ',', 'M.A'), (',', 'M.A', '.')]

>> POS Tags are: 
 [('Waller', 'NNP'), (',', ','), ('M.A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Waller', 'M.A']

>> Named Entities are: 
 [('GPE', 'Waller')] 

>> Stemming using Porter Stemmer: 
 [('Waller', 'waller'), (',', ','), ('M.A', 'm.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Waller', 'waller'), (',', ','), ('M.A', 'm.a'), ('.', '.')]

>> Lemmatization: 
 [('Waller', 'Waller'), (',', ','), ('M.A', 'M.A'), ('.', '.')]


------------------- Sentence 2 -------------------

and Fawcett, S.E., 2013.

>> Tokens are: 
 ['Fawcett', ',', 'S.E.', ',', '2013', '.']

>> Bigrams are: 
 [('Fawcett', ','), (',', 'S.E.'), ('S.E.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Fawcett', ',', 'S.E.'), (',', 'S.E.', ','), ('S.E.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Fawcett', 'NNP'), (',', ','), ('S.E.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Fawcett', 'S.E.']

>> Named Entities are: 
 [('GPE', 'Fawcett')] 

>> Stemming using Porter Stemmer: 
 [('Fawcett', 'fawcett'), (',', ','), ('S.E.', 's.e.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fawcett', 'fawcett'), (',', ','), ('S.E.', 's.e.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Fawcett', 'Fawcett'), (',', ','), ('S.E.', 'S.E.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 3 -------------------

Data science, predictive analytics, and big data: a revolution

>> Tokens are: 
 ['Data', 'science', ',', 'predictive', 'analytics', ',', 'big', 'data', ':', 'revolution']

>> Bigrams are: 
 [('Data', 'science'), ('science', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', ':'), (':', 'revolution')]

>> Trigrams are: 
 [('Data', 'science', ','), ('science', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'revolution')]

>> POS Tags are: 
 [('Data', 'NNP'), ('science', 'NN'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('revolution', 'NN')]

>> Noun Phrases are: 
 ['Data science', 'predictive analytics', 'big data', 'revolution']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut')]

>> Lemmatization: 
 [('Data', 'Data'), ('science', 'science'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolution')]



========================================== PARAGRAPH 1638 ===========================================

that will transform supply chain design and management.. Journal of Business Logistics, Volume  

------------------- Sentence 1 -------------------

that will transform supply chain design and management.. Journal of Business Logistics, Volume

>> Tokens are: 
 ['transform', 'supply', 'chain', 'design', 'management', '..', 'Journal', 'Business', 'Logistics', ',', 'Volume']

>> Bigrams are: 
 [('transform', 'supply'), ('supply', 'chain'), ('chain', 'design'), ('design', 'management'), ('management', '..'), ('..', 'Journal'), ('Journal', 'Business'), ('Business', 'Logistics'), ('Logistics', ','), (',', 'Volume')]

>> Trigrams are: 
 [('transform', 'supply', 'chain'), ('supply', 'chain', 'design'), ('chain', 'design', 'management'), ('design', 'management', '..'), ('management', '..', 'Journal'), ('..', 'Journal', 'Business'), ('Journal', 'Business', 'Logistics'), ('Business', 'Logistics', ','), ('Logistics', ',', 'Volume')]

>> POS Tags are: 
 [('transform', 'NN'), ('supply', 'NN'), ('chain', 'NN'), ('design', 'NN'), ('management', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Business', 'NNP'), ('Logistics', 'NNP'), (',', ','), ('Volume', 'NN')]

>> Noun Phrases are: 
 ['transform supply chain design management .. Journal Business Logistics', 'Volume']

>> Named Entities are: 
 [('PERSON', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('transform', 'transform'), ('supply', 'suppli'), ('chain', 'chain'), ('design', 'design'), ('management', 'manag'), ('..', '..'), ('Journal', 'journal'), ('Business', 'busi'), ('Logistics', 'logist'), (',', ','), ('Volume', 'volum')]

>> Stemming using Snowball Stemmer: 
 [('transform', 'transform'), ('supply', 'suppli'), ('chain', 'chain'), ('design', 'design'), ('management', 'manag'), ('..', '..'), ('Journal', 'journal'), ('Business', 'busi'), ('Logistics', 'logist'), (',', ','), ('Volume', 'volum')]

>> Lemmatization: 
 [('transform', 'transform'), ('supply', 'supply'), ('chain', 'chain'), ('design', 'design'), ('management', 'management'), ('..', '..'), ('Journal', 'Journal'), ('Business', 'Business'), ('Logistics', 'Logistics'), (',', ','), ('Volume', 'Volume')]



========================================== PARAGRAPH 1639 ===========================================

34, pp. 77-84.  

------------------- Sentence 1 -------------------

34, pp.

>> Tokens are: 
 ['34', ',', 'pp', '.']

>> Bigrams are: 
 [('34', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('34', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('34', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

77-84.

>> Tokens are: 
 ['77-84', '.']

>> Bigrams are: 
 [('77-84', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77-84', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77-84', '77-84'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77-84', '77-84'), ('.', '.')]

>> Lemmatization: 
 [('77-84', '77-84'), ('.', '.')]



========================================== PARAGRAPH 1640 ===========================================

Wamba, S.F., Gunasekaran, A., Akter, S., Ren, S.J.F., Dubey, R. and Childe, S.J., 2017. Big data  

------------------- Sentence 1 -------------------

Wamba, S.F., Gunasekaran, A., Akter, S., Ren, S.J.F., Dubey, R. and Childe, S.J., 2017.

>> Tokens are: 
 ['Wamba', ',', 'S.F.', ',', 'Gunasekaran', ',', 'A.', ',', 'Akter', ',', 'S.', ',', 'Ren', ',', 'S.J.F.', ',', 'Dubey', ',', 'R.', 'Childe', ',', 'S.J.', ',', '2017', '.']

>> Bigrams are: 
 [('Wamba', ','), (',', 'S.F.'), ('S.F.', ','), (',', 'Gunasekaran'), ('Gunasekaran', ','), (',', 'A.'), ('A.', ','), (',', 'Akter'), ('Akter', ','), (',', 'S.'), ('S.', ','), (',', 'Ren'), ('Ren', ','), (',', 'S.J.F.'), ('S.J.F.', ','), (',', 'Dubey'), ('Dubey', ','), (',', 'R.'), ('R.', 'Childe'), ('Childe', ','), (',', 'S.J.'), ('S.J.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Wamba', ',', 'S.F.'), (',', 'S.F.', ','), ('S.F.', ',', 'Gunasekaran'), (',', 'Gunasekaran', ','), ('Gunasekaran', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Akter'), (',', 'Akter', ','), ('Akter', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ren'), (',', 'Ren', ','), ('Ren', ',', 'S.J.F.'), (',', 'S.J.F.', ','), ('S.J.F.', ',', 'Dubey'), (',', 'Dubey', ','), ('Dubey', ',', 'R.'), (',', 'R.', 'Childe'), ('R.', 'Childe', ','), ('Childe', ',', 'S.J.'), (',', 'S.J.', ','), ('S.J.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Wamba', 'NNP'), (',', ','), ('S.F.', 'NNP'), (',', ','), ('Gunasekaran', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Akter', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ren', 'NNP'), (',', ','), ('S.J.F.', 'NNP'), (',', ','), ('Dubey', 'NNP'), (',', ','), ('R.', 'NNP'), ('Childe', 'NNP'), (',', ','), ('S.J.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wamba', 'S.F.', 'Gunasekaran', 'A.', 'Akter', 'S.', 'Ren', 'S.J.F.', 'Dubey', 'R. Childe', 'S.J.']

>> Named Entities are: 
 [('GPE', 'Wamba'), ('GPE', 'Gunasekaran'), ('PERSON', 'Akter'), ('PERSON', 'Ren'), ('PERSON', 'Dubey')] 

>> Stemming using Porter Stemmer: 
 [('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Ren', 'ren'), (',', ','), ('S.J.F.', 's.j.f.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Ren', 'ren'), (',', ','), ('S.J.F.', 's.j.f.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Wamba', 'Wamba'), (',', ','), ('S.F.', 'S.F.'), (',', ','), ('Gunasekaran', 'Gunasekaran'), (',', ','), ('A.', 'A.'), (',', ','), ('Akter', 'Akter'), (',', ','), ('S.', 'S.'), (',', ','), ('Ren', 'Ren'), (',', ','), ('S.J.F.', 'S.J.F.'), (',', ','), ('Dubey', 'Dubey'), (',', ','), ('R.', 'R.'), ('Childe', 'Childe'), (',', ','), ('S.J.', 'S.J.'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data

>> Tokens are: 
 ['Big', 'data']

>> Bigrams are: 
 [('Big', 'data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data')]



========================================== PARAGRAPH 1641 ===========================================

analytics and firm performance: Effects of dynamic capabilities. Journal of Business Research,  

------------------- Sentence 1 -------------------

analytics and firm performance: Effects of dynamic capabilities.

>> Tokens are: 
 ['analytics', 'firm', 'performance', ':', 'Effects', 'dynamic', 'capabilities', '.']

>> Bigrams are: 
 [('analytics', 'firm'), ('firm', 'performance'), ('performance', ':'), (':', 'Effects'), ('Effects', 'dynamic'), ('dynamic', 'capabilities'), ('capabilities', '.')]

>> Trigrams are: 
 [('analytics', 'firm', 'performance'), ('firm', 'performance', ':'), ('performance', ':', 'Effects'), (':', 'Effects', 'dynamic'), ('Effects', 'dynamic', 'capabilities'), ('dynamic', 'capabilities', '.')]

>> POS Tags are: 
 [('analytics', 'NNS'), ('firm', 'JJ'), ('performance', 'NN'), (':', ':'), ('Effects', 'NNS'), ('dynamic', 'JJ'), ('capabilities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['analytics', 'firm performance', 'Effects', 'dynamic capabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytics', 'analyt'), ('firm', 'firm'), ('performance', 'perform'), (':', ':'), ('Effects', 'effect'), ('dynamic', 'dynam'), ('capabilities', 'capabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytics', 'analyt'), ('firm', 'firm'), ('performance', 'perform'), (':', ':'), ('Effects', 'effect'), ('dynamic', 'dynam'), ('capabilities', 'capabl'), ('.', '.')]

>> Lemmatization: 
 [('analytics', 'analytics'), ('firm', 'firm'), ('performance', 'performance'), (':', ':'), ('Effects', 'Effects'), ('dynamic', 'dynamic'), ('capabilities', 'capability'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Business Research,

>> Tokens are: 
 ['Journal', 'Business', 'Research', ',']

>> Bigrams are: 
 [('Journal', 'Business'), ('Business', 'Research'), ('Research', ',')]

>> Trigrams are: 
 [('Journal', 'Business', 'Research'), ('Business', 'Research', ',')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Business', 'NNP'), ('Research', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Journal Business Research']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Business Research')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Business', 'busi'), ('Research', 'research'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Business', 'busi'), ('Research', 'research'), (',', ',')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Business', 'Business'), ('Research', 'Research'), (',', ',')]



========================================== PARAGRAPH 1642 ===========================================

pp. 356-365.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

356-365.

>> Tokens are: 
 ['356-365', '.']

>> Bigrams are: 
 [('356-365', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('356-365', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('356-365', '356-365'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('356-365', '356-365'), ('.', '.')]

>> Lemmatization: 
 [('356-365', '356-365'), ('.', '.')]



========================================== PARAGRAPH 1643 ===========================================

Wang, H., Xu, Z., Fujita, H. and Liu, S., 2016. Towards felicitous decision making: An overview  

------------------- Sentence 1 -------------------

Wang, H., Xu, Z., Fujita, H. and Liu, S., 2016.

>> Tokens are: 
 ['Wang', ',', 'H.', ',', 'Xu', ',', 'Z.', ',', 'Fujita', ',', 'H.', 'Liu', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Wang', ','), (',', 'H.'), ('H.', ','), (',', 'Xu'), ('Xu', ','), (',', 'Z.'), ('Z.', ','), (',', 'Fujita'), ('Fujita', ','), (',', 'H.'), ('H.', 'Liu'), ('Liu', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Wang', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Xu'), (',', 'Xu', ','), ('Xu', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Fujita'), (',', 'Fujita', ','), ('Fujita', ',', 'H.'), (',', 'H.', 'Liu'), ('H.', 'Liu', ','), ('Liu', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Wang', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Xu', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Fujita', 'NNP'), (',', ','), ('H.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang', 'H.', 'Xu', 'Z.', 'Fujita', 'H. Liu', 'S.']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('GPE', 'Xu'), ('GPE', 'Fujita')] 

>> Stemming using Porter Stemmer: 
 [('Wang', 'wang'), (',', ','), ('H.', 'h.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('Fujita', 'fujita'), (',', ','), ('H.', 'h.'), ('Liu', 'liu'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang', 'wang'), (',', ','), ('H.', 'h.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('Fujita', 'fujita'), (',', ','), ('H.', 'h.'), ('Liu', 'liu'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Wang', 'Wang'), (',', ','), ('H.', 'H.'), (',', ','), ('Xu', 'Xu'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Fujita', 'Fujita'), (',', ','), ('H.', 'H.'), ('Liu', 'Liu'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 2 -------------------

Towards felicitous decision making: An overview

>> Tokens are: 
 ['Towards', 'felicitous', 'decision', 'making', ':', 'An', 'overview']

>> Bigrams are: 
 [('Towards', 'felicitous'), ('felicitous', 'decision'), ('decision', 'making'), ('making', ':'), (':', 'An'), ('An', 'overview')]

>> Trigrams are: 
 [('Towards', 'felicitous', 'decision'), ('felicitous', 'decision', 'making'), ('decision', 'making', ':'), ('making', ':', 'An'), (':', 'An', 'overview')]

>> POS Tags are: 
 [('Towards', 'NNS'), ('felicitous', 'JJ'), ('decision', 'NN'), ('making', 'NN'), (':', ':'), ('An', 'DT'), ('overview', 'NN')]

>> Noun Phrases are: 
 ['Towards', 'felicitous decision making', 'An overview']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Towards', 'toward'), ('felicitous', 'felicit'), ('decision', 'decis'), ('making', 'make'), (':', ':'), ('An', 'an'), ('overview', 'overview')]

>> Stemming using Snowball Stemmer: 
 [('Towards', 'toward'), ('felicitous', 'felicit'), ('decision', 'decis'), ('making', 'make'), (':', ':'), ('An', 'an'), ('overview', 'overview')]

>> Lemmatization: 
 [('Towards', 'Towards'), ('felicitous', 'felicitous'), ('decision', 'decision'), ('making', 'making'), (':', ':'), ('An', 'An'), ('overview', 'overview')]



========================================== PARAGRAPH 1644 ===========================================

on challenges and trends of Big Data.. Information Sciences journal, Volume 367, pp. 747-765.  

------------------- Sentence 1 -------------------

on challenges and trends of Big Data.. Information Sciences journal, Volume 367, pp.

>> Tokens are: 
 ['challenges', 'trends', 'Big', 'Data', '..', 'Information', 'Sciences', 'journal', ',', 'Volume', '367', ',', 'pp', '.']

>> Bigrams are: 
 [('challenges', 'trends'), ('trends', 'Big'), ('Big', 'Data'), ('Data', '..'), ('..', 'Information'), ('Information', 'Sciences'), ('Sciences', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '367'), ('367', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('challenges', 'trends', 'Big'), ('trends', 'Big', 'Data'), ('Big', 'Data', '..'), ('Data', '..', 'Information'), ('..', 'Information', 'Sciences'), ('Information', 'Sciences', 'journal'), ('Sciences', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '367'), ('Volume', '367', ','), ('367', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('challenges', 'NNS'), ('trends', 'VBP'), ('Big', 'JJ'), ('Data', 'NNP'), ('..', 'NN'), ('Information', 'NNP'), ('Sciences', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('367', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['challenges', 'Big Data .. Information Sciences journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Information Sciences'), ('ORGANIZATION', 'Volume 367')] 

>> Stemming using Porter Stemmer: 
 [('challenges', 'challeng'), ('trends', 'trend'), ('Big', 'big'), ('Data', 'data'), ('..', '..'), ('Information', 'inform'), ('Sciences', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenges', 'challeng'), ('trends', 'trend'), ('Big', 'big'), ('Data', 'data'), ('..', '..'), ('Information', 'inform'), ('Sciences', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('challenges', 'challenge'), ('trends', 'trend'), ('Big', 'Big'), ('Data', 'Data'), ('..', '..'), ('Information', 'Information'), ('Sciences', 'Sciences'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

747-765.

>> Tokens are: 
 ['747-765', '.']

>> Bigrams are: 
 [('747-765', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('747-765', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('747-765', '747-765'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('747-765', '747-765'), ('.', '.')]

>> Lemmatization: 
 [('747-765', '747-765'), ('.', '.')]



========================================== PARAGRAPH 1645 ===========================================

Watson, H., 2014. Tutorial: Big data analytics: Concepts, technologies, and applications..  

------------------- Sentence 1 -------------------

Watson, H., 2014.

>> Tokens are: 
 ['Watson', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Watson', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Watson', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Watson', 'H.']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Tutorial: Big data analytics: Concepts, technologies, and applications..

>> Tokens are: 
 ['Tutorial', ':', 'Big', 'data', 'analytics', ':', 'Concepts', ',', 'technologies', ',', 'applications', '..']

>> Bigrams are: 
 [('Tutorial', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'Concepts'), ('Concepts', ','), (',', 'technologies'), ('technologies', ','), (',', 'applications'), ('applications', '..')]

>> Trigrams are: 
 [('Tutorial', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'Concepts'), (':', 'Concepts', ','), ('Concepts', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'applications'), (',', 'applications', '..')]

>> POS Tags are: 
 [('Tutorial', 'NN'), (':', ':'), ('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('Concepts', 'NNP'), (',', ','), ('technologies', 'NNS'), (',', ','), ('applications', 'NNS'), ('..', 'VBP')]

>> Noun Phrases are: 
 ['Tutorial', 'Big data analytics', 'Concepts', 'technologies', 'applications']

>> Named Entities are: 
 [('GPE', 'Tutorial')] 

>> Stemming using Porter Stemmer: 
 [('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), ('..', '..')]

>> Lemmatization: 
 [('Tutorial', 'Tutorial'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('Concepts', 'Concepts'), (',', ','), ('technologies', 'technology'), (',', ','), ('applications', 'application'), ('..', '..')]



========================================== PARAGRAPH 1646 ===========================================

Communications of the Association for Information Systems CAIS, Volume 34, p. p.65.  

------------------- Sentence 1 -------------------

Communications of the Association for Information Systems CAIS, Volume 34, p. p.65.

>> Tokens are: 
 ['Communications', 'Association', 'Information', 'Systems', 'CAIS', ',', 'Volume', '34', ',', 'p.', 'p.65', '.']

>> Bigrams are: 
 [('Communications', 'Association'), ('Association', 'Information'), ('Information', 'Systems'), ('Systems', 'CAIS'), ('CAIS', ','), (',', 'Volume'), ('Volume', '34'), ('34', ','), (',', 'p.'), ('p.', 'p.65'), ('p.65', '.')]

>> Trigrams are: 
 [('Communications', 'Association', 'Information'), ('Association', 'Information', 'Systems'), ('Information', 'Systems', 'CAIS'), ('Systems', 'CAIS', ','), ('CAIS', ',', 'Volume'), (',', 'Volume', '34'), ('Volume', '34', ','), ('34', ',', 'p.'), (',', 'p.', 'p.65'), ('p.', 'p.65', '.')]

>> POS Tags are: 
 [('Communications', 'NNP'), ('Association', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), ('CAIS', 'NNP'), (',', ','), ('Volume', 'NN'), ('34', 'CD'), (',', ','), ('p.', 'NN'), ('p.65', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Communications Association Information Systems CAIS', 'Volume', 'p. p.65']

>> Named Entities are: 
 [('ORGANIZATION', 'Communications Association Information Systems'), ('ORGANIZATION', 'Volume 34')] 

>> Stemming using Porter Stemmer: 
 [('Communications', 'commun'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), ('CAIS', 'cai'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Communications', 'communic'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), ('CAIS', 'cai'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]

>> Lemmatization: 
 [('Communications', 'Communications'), ('Association', 'Association'), ('Information', 'Information'), ('Systems', 'Systems'), ('CAIS', 'CAIS'), (',', ','), ('Volume', 'Volume'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]



========================================== PARAGRAPH 1647 ===========================================

Watson, H., 2019. Update Tutorial: Big Data Analytics: Concepts, Technology, and Applications..  

------------------- Sentence 1 -------------------

Watson, H., 2019.

>> Tokens are: 
 ['Watson', ',', 'H.', ',', '2019', '.']

>> Bigrams are: 
 [('Watson', ','), (',', 'H.'), ('H.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Watson', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Watson', 'H.']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), (',', ','), ('H.', 'H.'), (',', ','), ('2019', '2019'), ('.', '.')]


------------------- Sentence 2 -------------------

Update Tutorial: Big Data Analytics: Concepts, Technology, and Applications..

>> Tokens are: 
 ['Update', 'Tutorial', ':', 'Big', 'Data', 'Analytics', ':', 'Concepts', ',', 'Technology', ',', 'Applications', '..']

>> Bigrams are: 
 [('Update', 'Tutorial'), ('Tutorial', ':'), (':', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'Concepts'), ('Concepts', ','), (',', 'Technology'), ('Technology', ','), (',', 'Applications'), ('Applications', '..')]

>> Trigrams are: 
 [('Update', 'Tutorial', ':'), ('Tutorial', ':', 'Big'), (':', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'Concepts'), (':', 'Concepts', ','), ('Concepts', ',', 'Technology'), (',', 'Technology', ','), ('Technology', ',', 'Applications'), (',', 'Applications', '..')]

>> POS Tags are: 
 [('Update', 'JJ'), ('Tutorial', 'NNP'), (':', ':'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('Concepts', 'NNP'), (',', ','), ('Technology', 'NNP'), (',', ','), ('Applications', 'NNP'), ('..', 'VBP')]

>> Noun Phrases are: 
 ['Update Tutorial', 'Big Data Analytics', 'Concepts', 'Technology', 'Applications']

>> Named Entities are: 
 [('GPE', 'Technology'), ('GSP', 'Applications')] 

>> Stemming using Porter Stemmer: 
 [('Update', 'updat'), ('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('Technology', 'technolog'), (',', ','), ('Applications', 'applic'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Update', 'updat'), ('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('Technology', 'technolog'), (',', ','), ('Applications', 'applic'), ('..', '..')]

>> Lemmatization: 
 [('Update', 'Update'), ('Tutorial', 'Tutorial'), (':', ':'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('Concepts', 'Concepts'), (',', ','), ('Technology', 'Technology'), (',', ','), ('Applications', 'Applications'), ('..', '..')]



========================================== PARAGRAPH 1648 ===========================================

Communications of the Association for Information Systems, Volume 44, p. 21.  

------------------- Sentence 1 -------------------

Communications of the Association for Information Systems, Volume 44, p. 21.

>> Tokens are: 
 ['Communications', 'Association', 'Information', 'Systems', ',', 'Volume', '44', ',', 'p.', '21', '.']

>> Bigrams are: 
 [('Communications', 'Association'), ('Association', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Volume'), ('Volume', '44'), ('44', ','), (',', 'p.'), ('p.', '21'), ('21', '.')]

>> Trigrams are: 
 [('Communications', 'Association', 'Information'), ('Association', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Volume'), (',', 'Volume', '44'), ('Volume', '44', ','), ('44', ',', 'p.'), (',', 'p.', '21'), ('p.', '21', '.')]

>> POS Tags are: 
 [('Communications', 'NNP'), ('Association', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Volume', 'NN'), ('44', 'CD'), (',', ','), ('p.', 'RB'), ('21', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Communications Association Information Systems', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'Communications Association Information Systems'), ('ORGANIZATION', 'Volume 44')] 

>> Stemming using Porter Stemmer: 
 [('Communications', 'commun'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Communications', 'communic'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('Communications', 'Communications'), ('Association', 'Association'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Volume', 'Volume'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]



========================================== PARAGRAPH 1649 ===========================================

Webster, J. and Watson, R.T., 2002. Analyzing the past to prepare for the future: Writing a  

------------------- Sentence 1 -------------------

Webster, J. and Watson, R.T., 2002.

>> Tokens are: 
 ['Webster', ',', 'J.', 'Watson', ',', 'R.T.', ',', '2002', '.']

>> Bigrams are: 
 [('Webster', ','), (',', 'J.'), ('J.', 'Watson'), ('Watson', ','), (',', 'R.T.'), ('R.T.', ','), (',', '2002'), ('2002', '.')]

>> Trigrams are: 
 [('Webster', ',', 'J.'), (',', 'J.', 'Watson'), ('J.', 'Watson', ','), ('Watson', ',', 'R.T.'), (',', 'R.T.', ','), ('R.T.', ',', '2002'), (',', '2002', '.')]

>> POS Tags are: 
 [('Webster', 'NNP'), (',', ','), ('J.', 'NNP'), ('Watson', 'NNP'), (',', ','), ('R.T.', 'NNP'), (',', ','), ('2002', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Webster', 'J. Watson', 'R.T.']

>> Named Entities are: 
 [('PERSON', 'J. Watson')] 

>> Stemming using Porter Stemmer: 
 [('Webster', 'webster'), (',', ','), ('J.', 'j.'), ('Watson', 'watson'), (',', ','), ('R.T.', 'r.t.'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Webster', 'webster'), (',', ','), ('J.', 'j.'), ('Watson', 'watson'), (',', ','), ('R.T.', 'r.t.'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('Webster', 'Webster'), (',', ','), ('J.', 'J.'), ('Watson', 'Watson'), (',', ','), ('R.T.', 'R.T.'), (',', ','), ('2002', '2002'), ('.', '.')]


------------------- Sentence 2 -------------------

Analyzing the past to prepare for the future: Writing a

>> Tokens are: 
 ['Analyzing', 'past', 'prepare', 'future', ':', 'Writing']

>> Bigrams are: 
 [('Analyzing', 'past'), ('past', 'prepare'), ('prepare', 'future'), ('future', ':'), (':', 'Writing')]

>> Trigrams are: 
 [('Analyzing', 'past', 'prepare'), ('past', 'prepare', 'future'), ('prepare', 'future', ':'), ('future', ':', 'Writing')]

>> POS Tags are: 
 [('Analyzing', 'VBG'), ('past', 'JJ'), ('prepare', 'JJ'), ('future', 'NN'), (':', ':'), ('Writing', 'NN')]

>> Noun Phrases are: 
 ['past prepare future', 'Writing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analyzing', 'analyz'), ('past', 'past'), ('prepare', 'prepar'), ('future', 'futur'), (':', ':'), ('Writing', 'write')]

>> Stemming using Snowball Stemmer: 
 [('Analyzing', 'analyz'), ('past', 'past'), ('prepare', 'prepar'), ('future', 'futur'), (':', ':'), ('Writing', 'write')]

>> Lemmatization: 
 [('Analyzing', 'Analyzing'), ('past', 'past'), ('prepare', 'prepare'), ('future', 'future'), (':', ':'), ('Writing', 'Writing')]



========================================== PARAGRAPH 1650 ===========================================

literature review. MIS quarterly, pp. xiii-xxiii.  

------------------- Sentence 1 -------------------

literature review.

>> Tokens are: 
 ['literature', 'review', '.']

>> Bigrams are: 
 [('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('literature', 'review', '.')]

>> POS Tags are: 
 [('literature', 'NN'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('literature', 'literature'), ('review', 'review'), ('.', '.')]


------------------- Sentence 2 -------------------

MIS quarterly, pp.

>> Tokens are: 
 ['MIS', 'quarterly', ',', 'pp', '.']

>> Bigrams are: 
 [('MIS', 'quarterly'), ('quarterly', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('MIS', 'quarterly', ','), ('quarterly', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('MIS', 'NNP'), ('quarterly', 'RB'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['MIS', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('MIS', 'mi'), ('quarterly', 'quarterli'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIS', 'mis'), ('quarterly', 'quarter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('MIS', 'MIS'), ('quarterly', 'quarterly'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

xiii-xxiii.

>> Tokens are: 
 ['xiii-xxiii', '.']

>> Bigrams are: 
 [('xiii-xxiii', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('xiii-xxiii', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['xiii-xxiii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]

>> Lemmatization: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]



========================================== PARAGRAPH 1651 ===========================================

Wixom, B.H., Yen, B. and Relich, M., 2013. Maximizing Value from Business Analytics. MIS  

------------------- Sentence 1 -------------------

Wixom, B.H., Yen, B. and Relich, M., 2013.

>> Tokens are: 
 ['Wixom', ',', 'B.H.', ',', 'Yen', ',', 'B.', 'Relich', ',', 'M.', ',', '2013', '.']

>> Bigrams are: 
 [('Wixom', ','), (',', 'B.H.'), ('B.H.', ','), (',', 'Yen'), ('Yen', ','), (',', 'B.'), ('B.', 'Relich'), ('Relich', ','), (',', 'M.'), ('M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Wixom', ',', 'B.H.'), (',', 'B.H.', ','), ('B.H.', ',', 'Yen'), (',', 'Yen', ','), ('Yen', ',', 'B.'), (',', 'B.', 'Relich'), ('B.', 'Relich', ','), ('Relich', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Wixom', 'NNP'), (',', ','), ('B.H.', 'NNP'), (',', ','), ('Yen', 'NNP'), (',', ','), ('B.', 'NNP'), ('Relich', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wixom', 'B.H.', 'Yen', 'B. Relich', 'M.']

>> Named Entities are: 
 [('GPE', 'Wixom'), ('PERSON', 'Yen'), ('PERSON', 'Relich')] 

>> Stemming using Porter Stemmer: 
 [('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('Yen', 'yen'), (',', ','), ('B.', 'b.'), ('Relich', 'relich'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('Yen', 'yen'), (',', ','), ('B.', 'b.'), ('Relich', 'relich'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Wixom', 'Wixom'), (',', ','), ('B.H.', 'B.H.'), (',', ','), ('Yen', 'Yen'), (',', ','), ('B.', 'B.'), ('Relich', 'Relich'), (',', ','), ('M.', 'M.'), (',', ','), ('2013', '2013'), ('.', '.')]


------------------- Sentence 2 -------------------

Maximizing Value from Business Analytics.

>> Tokens are: 
 ['Maximizing', 'Value', 'Business', 'Analytics', '.']

>> Bigrams are: 
 [('Maximizing', 'Value'), ('Value', 'Business'), ('Business', 'Analytics'), ('Analytics', '.')]

>> Trigrams are: 
 [('Maximizing', 'Value', 'Business'), ('Value', 'Business', 'Analytics'), ('Business', 'Analytics', '.')]

>> POS Tags are: 
 [('Maximizing', 'VBG'), ('Value', 'NNP'), ('Business', 'NNP'), ('Analytics', 'NNPS'), ('.', '.')]

>> Noun Phrases are: 
 ['Value Business']

>> Named Entities are: 
 [('PERSON', 'Value Business')] 

>> Stemming using Porter Stemmer: 
 [('Maximizing', 'maxim'), ('Value', 'valu'), ('Business', 'busi'), ('Analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Maximizing', 'maxim'), ('Value', 'valu'), ('Business', 'busi'), ('Analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Maximizing', 'Maximizing'), ('Value', 'Value'), ('Business', 'Business'), ('Analytics', 'Analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

MIS

>> Tokens are: 
 ['MIS']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('MIS', 'NN')]

>> Noun Phrases are: 
 ['MIS']

>> Named Entities are: 
 [('ORGANIZATION', 'MIS')] 

>> Stemming using Porter Stemmer: 
 [('MIS', 'mi')]

>> Stemming using Snowball Stemmer: 
 [('MIS', 'mis')]

>> Lemmatization: 
 [('MIS', 'MIS')]



========================================== PARAGRAPH 1652 ===========================================

Quarterly Executive.  

------------------- Sentence 1 -------------------

Quarterly Executive.

>> Tokens are: 
 ['Quarterly', 'Executive', '.']

>> Bigrams are: 
 [('Quarterly', 'Executive'), ('Executive', '.')]

>> Trigrams are: 
 [('Quarterly', 'Executive', '.')]

>> POS Tags are: 
 [('Quarterly', 'JJ'), ('Executive', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Quarterly Executive']

>> Named Entities are: 
 [('GPE', 'Quarterly'), ('ORGANIZATION', 'Executive')] 

>> Stemming using Porter Stemmer: 
 [('Quarterly', 'quarterli'), ('Executive', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Quarterly', 'quarter'), ('Executive', 'execut'), ('.', '.')]

>> Lemmatization: 
 [('Quarterly', 'Quarterly'), ('Executive', 'Executive'), ('.', '.')]



========================================== PARAGRAPH 1653 ===========================================

Woerner, S.L., Wixom, B.H., 2015. Big data: extending the business strategy toolbox.. Journal of  

------------------- Sentence 1 -------------------

Woerner, S.L., Wixom, B.H., 2015.

>> Tokens are: 
 ['Woerner', ',', 'S.L.', ',', 'Wixom', ',', 'B.H.', ',', '2015', '.']

>> Bigrams are: 
 [('Woerner', ','), (',', 'S.L.'), ('S.L.', ','), (',', 'Wixom'), ('Wixom', ','), (',', 'B.H.'), ('B.H.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Woerner', ',', 'S.L.'), (',', 'S.L.', ','), ('S.L.', ',', 'Wixom'), (',', 'Wixom', ','), ('Wixom', ',', 'B.H.'), (',', 'B.H.', ','), ('B.H.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Woerner', 'NNP'), (',', ','), ('S.L.', 'NNP'), (',', ','), ('Wixom', 'NNP'), (',', ','), ('B.H.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Woerner', 'S.L.', 'Wixom', 'B.H.']

>> Named Entities are: 
 [('GPE', 'Woerner'), ('PERSON', 'Wixom')] 

>> Stemming using Porter Stemmer: 
 [('Woerner', 'woerner'), (',', ','), ('S.L.', 's.l.'), (',', ','), ('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Woerner', 'woerner'), (',', ','), ('S.L.', 's.l.'), (',', ','), ('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Woerner', 'Woerner'), (',', ','), ('S.L.', 'S.L.'), (',', ','), ('Wixom', 'Wixom'), (',', ','), ('B.H.', 'B.H.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data: extending the business strategy toolbox.. Journal of

>> Tokens are: 
 ['Big', 'data', ':', 'extending', 'business', 'strategy', 'toolbox', '..', 'Journal']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'extending'), ('extending', 'business'), ('business', 'strategy'), ('strategy', 'toolbox'), ('toolbox', '..'), ('..', 'Journal')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'extending'), (':', 'extending', 'business'), ('extending', 'business', 'strategy'), ('business', 'strategy', 'toolbox'), ('strategy', 'toolbox', '..'), ('toolbox', '..', 'Journal')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('extending', 'NN'), ('business', 'NN'), ('strategy', 'NN'), ('toolbox', 'NN'), ('..', 'NNP'), ('Journal', 'NNP')]

>> Noun Phrases are: 
 ['Big data', 'extending business strategy toolbox .. Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('extending', 'extend'), ('business', 'busi'), ('strategy', 'strategi'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'journal')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('extending', 'extend'), ('business', 'busi'), ('strategy', 'strategi'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'journal')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('extending', 'extending'), ('business', 'business'), ('strategy', 'strategy'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'Journal')]



========================================== PARAGRAPH 1654 ===========================================

Information Technology, Volume 30, pp. 60-62.  

------------------- Sentence 1 -------------------

Information Technology, Volume 30, pp.

>> Tokens are: 
 ['Information', 'Technology', ',', 'Volume', '30', ',', 'pp', '.']

>> Bigrams are: 
 [('Information', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '30'), ('30', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Information', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '30'), ('Volume', '30', ','), ('30', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('30', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 30')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

60-62.

>> Tokens are: 
 ['60-62', '.']

>> Bigrams are: 
 [('60-62', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('60-62', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('60-62', '60-62'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('60-62', '60-62'), ('.', '.')]

>> Lemmatization: 
 [('60-62', '60-62'), ('.', '.')]



========================================== PARAGRAPH 1655 ===========================================

Wu, Celimuge and Yoshinaga, Tsutomu and Chen, Xianfu and Zhang, Lin and Ji, Yusheng, 2018.  

------------------- Sentence 1 -------------------

Wu, Celimuge and Yoshinaga, Tsutomu and Chen, Xianfu and Zhang, Lin and Ji, Yusheng, 2018.

>> Tokens are: 
 ['Wu', ',', 'Celimuge', 'Yoshinaga', ',', 'Tsutomu', 'Chen', ',', 'Xianfu', 'Zhang', ',', 'Lin', 'Ji', ',', 'Yusheng', ',', '2018', '.']

>> Bigrams are: 
 [('Wu', ','), (',', 'Celimuge'), ('Celimuge', 'Yoshinaga'), ('Yoshinaga', ','), (',', 'Tsutomu'), ('Tsutomu', 'Chen'), ('Chen', ','), (',', 'Xianfu'), ('Xianfu', 'Zhang'), ('Zhang', ','), (',', 'Lin'), ('Lin', 'Ji'), ('Ji', ','), (',', 'Yusheng'), ('Yusheng', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Wu', ',', 'Celimuge'), (',', 'Celimuge', 'Yoshinaga'), ('Celimuge', 'Yoshinaga', ','), ('Yoshinaga', ',', 'Tsutomu'), (',', 'Tsutomu', 'Chen'), ('Tsutomu', 'Chen', ','), ('Chen', ',', 'Xianfu'), (',', 'Xianfu', 'Zhang'), ('Xianfu', 'Zhang', ','), ('Zhang', ',', 'Lin'), (',', 'Lin', 'Ji'), ('Lin', 'Ji', ','), ('Ji', ',', 'Yusheng'), (',', 'Yusheng', ','), ('Yusheng', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Wu', 'NNP'), (',', ','), ('Celimuge', 'NNP'), ('Yoshinaga', 'NNP'), (',', ','), ('Tsutomu', 'NNP'), ('Chen', 'NNP'), (',', ','), ('Xianfu', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('Lin', 'NNP'), ('Ji', 'NNP'), (',', ','), ('Yusheng', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wu', 'Celimuge Yoshinaga', 'Tsutomu Chen', 'Xianfu Zhang', 'Lin Ji', 'Yusheng']

>> Named Entities are: 
 [('GPE', 'Wu'), ('PERSON', 'Celimuge Yoshinaga'), ('PERSON', 'Tsutomu Chen'), ('PERSON', 'Xianfu Zhang'), ('PERSON', 'Lin Ji'), ('PERSON', 'Yusheng')] 

>> Stemming using Porter Stemmer: 
 [('Wu', 'wu'), (',', ','), ('Celimuge', 'celimug'), ('Yoshinaga', 'yoshinaga'), (',', ','), ('Tsutomu', 'tsutomu'), ('Chen', 'chen'), (',', ','), ('Xianfu', 'xianfu'), ('Zhang', 'zhang'), (',', ','), ('Lin', 'lin'), ('Ji', 'ji'), (',', ','), ('Yusheng', 'yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wu', 'wu'), (',', ','), ('Celimuge', 'celimug'), ('Yoshinaga', 'yoshinaga'), (',', ','), ('Tsutomu', 'tsutomu'), ('Chen', 'chen'), (',', ','), ('Xianfu', 'xianfu'), ('Zhang', 'zhang'), (',', ','), ('Lin', 'lin'), ('Ji', 'ji'), (',', ','), ('Yusheng', 'yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Wu', 'Wu'), (',', ','), ('Celimuge', 'Celimuge'), ('Yoshinaga', 'Yoshinaga'), (',', ','), ('Tsutomu', 'Tsutomu'), ('Chen', 'Chen'), (',', ','), ('Xianfu', 'Xianfu'), ('Zhang', 'Zhang'), (',', ','), ('Lin', 'Lin'), ('Ji', 'Ji'), (',', ','), ('Yusheng', 'Yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]



========================================== PARAGRAPH 1656 ===========================================

Cluster-based content distribution integrating LTE and IEEE 802.11 p with fuzzy logic and Q- 

------------------- Sentence 1 -------------------

Cluster-based content distribution integrating LTE and IEEE 802.11 p with fuzzy logic and Q-

>> Tokens are: 
 ['Cluster-based', 'content', 'distribution', 'integrating', 'LTE', 'IEEE', '802.11', 'p', 'fuzzy', 'logic', 'Q-']

>> Bigrams are: 
 [('Cluster-based', 'content'), ('content', 'distribution'), ('distribution', 'integrating'), ('integrating', 'LTE'), ('LTE', 'IEEE'), ('IEEE', '802.11'), ('802.11', 'p'), ('p', 'fuzzy'), ('fuzzy', 'logic'), ('logic', 'Q-')]

>> Trigrams are: 
 [('Cluster-based', 'content', 'distribution'), ('content', 'distribution', 'integrating'), ('distribution', 'integrating', 'LTE'), ('integrating', 'LTE', 'IEEE'), ('LTE', 'IEEE', '802.11'), ('IEEE', '802.11', 'p'), ('802.11', 'p', 'fuzzy'), ('p', 'fuzzy', 'logic'), ('fuzzy', 'logic', 'Q-')]

>> POS Tags are: 
 [('Cluster-based', 'JJ'), ('content', 'NN'), ('distribution', 'NN'), ('integrating', 'VBG'), ('LTE', 'NNP'), ('IEEE', 'NNP'), ('802.11', 'CD'), ('p', 'NN'), ('fuzzy', 'JJ'), ('logic', 'JJ'), ('Q-', 'NN')]

>> Noun Phrases are: 
 ['Cluster-based content distribution', 'LTE IEEE', 'p', 'fuzzy logic Q-']

>> Named Entities are: 
 [('ORGANIZATION', 'LTE')] 

>> Stemming using Porter Stemmer: 
 [('Cluster-based', 'cluster-bas'), ('content', 'content'), ('distribution', 'distribut'), ('integrating', 'integr'), ('LTE', 'lte'), ('IEEE', 'ieee'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzi'), ('logic', 'logic'), ('Q-', 'q-')]

>> Stemming using Snowball Stemmer: 
 [('Cluster-based', 'cluster-bas'), ('content', 'content'), ('distribution', 'distribut'), ('integrating', 'integr'), ('LTE', 'lte'), ('IEEE', 'ieee'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzi'), ('logic', 'logic'), ('Q-', 'q-')]

>> Lemmatization: 
 [('Cluster-based', 'Cluster-based'), ('content', 'content'), ('distribution', 'distribution'), ('integrating', 'integrating'), ('LTE', 'LTE'), ('IEEE', 'IEEE'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzy'), ('logic', 'logic'), ('Q-', 'Q-')]



========================================== PARAGRAPH 1657 ===========================================

learning. ieee Computational intelligenCe magazine journal, pp. 41-50. 

------------------- Sentence 1 -------------------

learning.

>> Tokens are: 
 ['learning', '.']

>> Bigrams are: 
 [('learning', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

ieee Computational intelligenCe magazine journal, pp.

>> Tokens are: 
 ['ieee', 'Computational', 'intelligenCe', 'magazine', 'journal', ',', 'pp', '.']

>> Bigrams are: 
 [('ieee', 'Computational'), ('Computational', 'intelligenCe'), ('intelligenCe', 'magazine'), ('magazine', 'journal'), ('journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('ieee', 'Computational', 'intelligenCe'), ('Computational', 'intelligenCe', 'magazine'), ('intelligenCe', 'magazine', 'journal'), ('magazine', 'journal', ','), ('journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('ieee', 'JJ'), ('Computational', 'NNP'), ('intelligenCe', 'NN'), ('magazine', 'NN'), ('journal', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ieee Computational intelligenCe magazine journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computational'), ('ORGANIZATION', 'intelligenCe')] 

>> Stemming using Porter Stemmer: 
 [('ieee', 'ieee'), ('Computational', 'comput'), ('intelligenCe', 'intellig'), ('magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ieee', 'ieee'), ('Computational', 'comput'), ('intelligenCe', 'intellig'), ('magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('ieee', 'ieee'), ('Computational', 'Computational'), ('intelligenCe', 'intelligenCe'), ('magazine', 'magazine'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

41-50.

>> Tokens are: 
 ['41-50', '.']

>> Bigrams are: 
 [('41-50', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41-50', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41-50', '41-50'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41-50', '41-50'), ('.', '.')]

>> Lemmatization: 
 [('41-50', '41-50'), ('.', '.')]



========================================== PARAGRAPH 1658 ===========================================

Sarah Al-Shiakhli  

------------------- Sentence 1 -------------------

Sarah Al-Shiakhli

>> Tokens are: 
 ['Sarah', 'Al-Shiakhli']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP')]

>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli')]



========================================== PARAGRAPH 1659 ===========================================

54  

------------------- Sentence 1 -------------------

54

>> Tokens are: 
 ['54']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('54', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('54', '54')]

>> Stemming using Snowball Stemmer: 
 [('54', '54')]

>> Lemmatization: 
 [('54', '54')]



========================================== PARAGRAPH 1660 ===========================================

  


========================================== PARAGRAPH 1661 ===========================================

Yi, X., Liu, F., Liu, J. and Jin, H., 2014. Building a network highway for big data: architecture and  

------------------- Sentence 1 -------------------

Yi, X., Liu, F., Liu, J. and Jin, H., 2014.

>> Tokens are: 
 ['Yi', ',', 'X.', ',', 'Liu', ',', 'F.', ',', 'Liu', ',', 'J.', 'Jin', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Yi', ','), (',', 'X.'), ('X.', ','), (',', 'Liu'), ('Liu', ','), (',', 'F.'), ('F.', ','), (',', 'Liu'), ('Liu', ','), (',', 'J.'), ('J.', 'Jin'), ('Jin', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Yi', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'J.'), (',', 'J.', 'Jin'), ('J.', 'Jin', ','), ('Jin', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Yi', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('J.', 'NNP'), ('Jin', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Yi', 'X.', 'Liu', 'F.', 'Liu', 'J. Jin', 'H.']

>> Named Entities are: 
 [('GPE', 'Yi'), ('PERSON', 'Liu'), ('PERSON', 'Liu'), ('PERSON', 'J. Jin')] 

>> Stemming using Porter Stemmer: 
 [('Yi', 'yi'), (',', ','), ('X.', 'x.'), (',', ','), ('Liu', 'liu'), (',', ','), ('F.', 'f.'), (',', ','), ('Liu', 'liu'), (',', ','), ('J.', 'j.'), ('Jin', 'jin'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yi', 'yi'), (',', ','), ('X.', 'x.'), (',', ','), ('Liu', 'liu'), (',', ','), ('F.', 'f.'), (',', ','), ('Liu', 'liu'), (',', ','), ('J.', 'j.'), ('Jin', 'jin'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Yi', 'Yi'), (',', ','), ('X.', 'X.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('F.', 'F.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('J.', 'J.'), ('Jin', 'Jin'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Building a network highway for big data: architecture and

>> Tokens are: 
 ['Building', 'network', 'highway', 'big', 'data', ':', 'architecture']

>> Bigrams are: 
 [('Building', 'network'), ('network', 'highway'), ('highway', 'big'), ('big', 'data'), ('data', ':'), (':', 'architecture')]

>> Trigrams are: 
 [('Building', 'network', 'highway'), ('network', 'highway', 'big'), ('highway', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'architecture')]

>> POS Tags are: 
 [('Building', 'NN'), ('network', 'NN'), ('highway', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('architecture', 'NN')]

>> Noun Phrases are: 
 ['Building network highway', 'big data', 'architecture']

>> Named Entities are: 
 [('GPE', 'Building')] 

>> Stemming using Porter Stemmer: 
 [('Building', 'build'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('Building', 'build'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architectur')]

>> Lemmatization: 
 [('Building', 'Building'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architecture')]



========================================== PARAGRAPH 1662 ===========================================

challenges. IEEE Network journal, Volume 28, pp. 5-13.  

------------------- Sentence 1 -------------------

challenges.

>> Tokens are: 
 ['challenges', '.']

>> Bigrams are: 
 [('challenges', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('challenges', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('challenges', 'challenge'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Network journal, Volume 28, pp.

>> Tokens are: 
 ['IEEE', 'Network', 'journal', ',', 'Volume', '28', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'Network'), ('Network', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '28'), ('28', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'Network', 'journal'), ('Network', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '28'), ('Volume', '28', ','), ('28', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Network', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('28', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Network journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Network'), ('ORGANIZATION', 'Volume 28')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Network', 'network'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Network', 'network'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Network', 'Network'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

5-13.

>> Tokens are: 
 ['5-13', '.']

>> Bigrams are: 
 [('5-13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5-13', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5-13', '5-13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5-13', '5-13'), ('.', '.')]

>> Lemmatization: 
 [('5-13', '5-13'), ('.', '.')]



========================================== PARAGRAPH 1663 ===========================================

Zhong, R.Y., Newman, S.T., Huang, G.Q. and Lan, S., 2016. Big Data for supply chain  

------------------- Sentence 1 -------------------

Zhong, R.Y., Newman, S.T., Huang, G.Q.

>> Tokens are: 
 ['Zhong', ',', 'R.Y.', ',', 'Newman', ',', 'S.T.', ',', 'Huang', ',', 'G.Q', '.']

>> Bigrams are: 
 [('Zhong', ','), (',', 'R.Y.'), ('R.Y.', ','), (',', 'Newman'), ('Newman', ','), (',', 'S.T.'), ('S.T.', ','), (',', 'Huang'), ('Huang', ','), (',', 'G.Q'), ('G.Q', '.')]

>> Trigrams are: 
 [('Zhong', ',', 'R.Y.'), (',', 'R.Y.', ','), ('R.Y.', ',', 'Newman'), (',', 'Newman', ','), ('Newman', ',', 'S.T.'), (',', 'S.T.', ','), ('S.T.', ',', 'Huang'), (',', 'Huang', ','), ('Huang', ',', 'G.Q'), (',', 'G.Q', '.')]

>> POS Tags are: 
 [('Zhong', 'NNP'), (',', ','), ('R.Y.', 'NNP'), (',', ','), ('Newman', 'NNP'), (',', ','), ('S.T.', 'NNP'), (',', ','), ('Huang', 'NNP'), (',', ','), ('G.Q', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhong', 'R.Y.', 'Newman', 'S.T.', 'Huang', 'G.Q']

>> Named Entities are: 
 [('GPE', 'Zhong'), ('GPE', 'Newman'), ('PERSON', 'Huang')] 

>> Stemming using Porter Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('R.Y.', 'r.y.'), (',', ','), ('Newman', 'newman'), (',', ','), ('S.T.', 's.t.'), (',', ','), ('Huang', 'huang'), (',', ','), ('G.Q', 'g.q'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('R.Y.', 'r.y.'), (',', ','), ('Newman', 'newman'), (',', ','), ('S.T.', 's.t.'), (',', ','), ('Huang', 'huang'), (',', ','), ('G.Q', 'g.q'), ('.', '.')]

>> Lemmatization: 
 [('Zhong', 'Zhong'), (',', ','), ('R.Y.', 'R.Y.'), (',', ','), ('Newman', 'Newman'), (',', ','), ('S.T.', 'S.T.'), (',', ','), ('Huang', 'Huang'), (',', ','), ('G.Q', 'G.Q'), ('.', '.')]


------------------- Sentence 2 -------------------

and Lan, S., 2016.

>> Tokens are: 
 ['Lan', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Lan', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Lan', 'S.']

>> Named Entities are: 
 [('GPE', 'Lan')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]


------------------- Sentence 3 -------------------

Big Data for supply chain

>> Tokens are: 
 ['Big', 'Data', 'supply', 'chain']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'supply'), ('supply', 'chain')]

>> Trigrams are: 
 [('Big', 'Data', 'supply'), ('Data', 'supply', 'chain')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('supply', 'NN'), ('chain', 'NN')]

>> Noun Phrases are: 
 ['Big Data supply chain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('supply', 'suppli'), ('chain', 'chain')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('supply', 'suppli'), ('chain', 'chain')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('supply', 'supply'), ('chain', 'chain')]



========================================== PARAGRAPH 1664 ===========================================

management in the service and manufacturing sectors: Challenges, opportunities, and future  

------------------- Sentence 1 -------------------

management in the service and manufacturing sectors: Challenges, opportunities, and future

>> Tokens are: 
 ['management', 'service', 'manufacturing', 'sectors', ':', 'Challenges', ',', 'opportunities', ',', 'future']

>> Bigrams are: 
 [('management', 'service'), ('service', 'manufacturing'), ('manufacturing', 'sectors'), ('sectors', ':'), (':', 'Challenges'), ('Challenges', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'future')]

>> Trigrams are: 
 [('management', 'service', 'manufacturing'), ('service', 'manufacturing', 'sectors'), ('manufacturing', 'sectors', ':'), ('sectors', ':', 'Challenges'), (':', 'Challenges', ','), ('Challenges', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'future')]

>> POS Tags are: 
 [('management', 'NN'), ('service', 'NN'), ('manufacturing', 'VBG'), ('sectors', 'NNS'), (':', ':'), ('Challenges', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('future', 'NN')]

>> Noun Phrases are: 
 ['management service', 'sectors', 'Challenges', 'opportunities', 'future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), ('service', 'servic'), ('manufacturing', 'manufactur'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'challeng'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('future', 'futur')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), ('service', 'servic'), ('manufacturing', 'manufactur'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'challeng'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('future', 'futur')]

>> Lemmatization: 
 [('management', 'management'), ('service', 'service'), ('manufacturing', 'manufacturing'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'Challenges'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('future', 'future')]



========================================== PARAGRAPH 1665 ===========================================

perspectives. Computers & Industrial Engineering journal, pp. 572-591.  

------------------- Sentence 1 -------------------

perspectives.

>> Tokens are: 
 ['perspectives', '.']

>> Bigrams are: 
 [('perspectives', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('perspectives', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['perspectives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('perspectives', 'perspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('perspectives', 'perspect'), ('.', '.')]

>> Lemmatization: 
 [('perspectives', 'perspective'), ('.', '.')]


------------------- Sentence 2 -------------------

Computers & Industrial Engineering journal, pp.

>> Tokens are: 
 ['Computers', '&', 'Industrial', 'Engineering', 'journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Computers', '&'), ('&', 'Industrial'), ('Industrial', 'Engineering'), ('Engineering', 'journal'), ('journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Computers', '&', 'Industrial'), ('&', 'Industrial', 'Engineering'), ('Industrial', 'Engineering', 'journal'), ('Engineering', 'journal', ','), ('journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Computers', 'NNP'), ('&', 'CC'), ('Industrial', 'NNP'), ('Engineering', 'NNP'), ('journal', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Computers', 'Industrial Engineering journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computers'), ('ORGANIZATION', 'Industrial')] 

>> Stemming using Porter Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Computers', 'Computers'), ('&', '&'), ('Industrial', 'Industrial'), ('Engineering', 'Engineering'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

572-591.

>> Tokens are: 
 ['572-591', '.']

>> Bigrams are: 
 [('572-591', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('572-591', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('572-591', '572-591'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('572-591', '572-591'), ('.', '.')]

>> Lemmatization: 
 [('572-591', '572-591'), ('.', '.')]



========================================== PARAGRAPH 1666 ===========================================

Zuech, R., Khoshgoftaar, T.M. and Wald, R., 2015. Intrusion detection and big heterogeneous  

------------------- Sentence 1 -------------------

Zuech, R., Khoshgoftaar, T.M.

>> Tokens are: 
 ['Zuech', ',', 'R.', ',', 'Khoshgoftaar', ',', 'T.M', '.']

>> Bigrams are: 
 [('Zuech', ','), (',', 'R.'), ('R.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M'), ('T.M', '.')]

>> Trigrams are: 
 [('Zuech', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M'), (',', 'T.M', '.')]

>> POS Tags are: 
 [('Zuech', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zuech', 'R.', 'Khoshgoftaar', 'T.M']

>> Named Entities are: 
 [('GPE', 'Zuech'), ('GPE', 'Khoshgoftaar')] 

>> Stemming using Porter Stemmer: 
 [('Zuech', 'zuech'), (',', ','), ('R.', 'r.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M', 't.m'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zuech', 'zuech'), (',', ','), ('R.', 'r.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M', 't.m'), ('.', '.')]

>> Lemmatization: 
 [('Zuech', 'Zuech'), (',', ','), ('R.', 'R.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M', 'T.M'), ('.', '.')]


------------------- Sentence 2 -------------------

and Wald, R., 2015.

>> Tokens are: 
 ['Wald', ',', 'R.', ',', '2015', '.']

>> Bigrams are: 
 [('Wald', ','), (',', 'R.'), ('R.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Wald', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Wald', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wald', 'R.']

>> Named Entities are: 
 [('GPE', 'Wald')] 

>> Stemming using Porter Stemmer: 
 [('Wald', 'wald'), (',', ','), ('R.', 'r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wald', 'wald'), (',', ','), ('R.', 'r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Wald', 'Wald'), (',', ','), ('R.', 'R.'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 3 -------------------

Intrusion detection and big heterogeneous

>> Tokens are: 
 ['Intrusion', 'detection', 'big', 'heterogeneous']

>> Bigrams are: 
 [('Intrusion', 'detection'), ('detection', 'big'), ('big', 'heterogeneous')]

>> Trigrams are: 
 [('Intrusion', 'detection', 'big'), ('detection', 'big', 'heterogeneous')]

>> POS Tags are: 
 [('Intrusion', 'NNP'), ('detection', 'NN'), ('big', 'JJ'), ('heterogeneous', 'JJ')]

>> Noun Phrases are: 
 ['Intrusion detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('heterogeneous', 'heterogen')]

>> Stemming using Snowball Stemmer: 
 [('Intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('heterogeneous', 'heterogen')]

>> Lemmatization: 
 [('Intrusion', 'Intrusion'), ('detection', 'detection'), ('big', 'big'), ('heterogeneous', 'heterogeneous')]



========================================== PARAGRAPH 1667 ===========================================

data: a survey.. Journal of Big Data, p. 3.  

------------------- Sentence 1 -------------------

data: a survey.. Journal of Big Data, p. 3.

>> Tokens are: 
 ['data', ':', 'survey', '..', 'Journal', 'Big', 'Data', ',', 'p.', '3', '.']

>> Bigrams are: 
 [('data', ':'), (':', 'survey'), ('survey', '..'), ('..', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p.'), ('p.', '3'), ('3', '.')]

>> Trigrams are: 
 [('data', ':', 'survey'), (':', 'survey', '..'), ('survey', '..', 'Journal'), ('..', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p.'), (',', 'p.', '3'), ('p.', '3', '.')]

>> POS Tags are: 
 [('data', 'NNS'), (':', ':'), ('survey', 'NN'), ('..', 'VBZ'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p.', 'NN'), ('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'survey', 'Journal Big Data', 'p.']

>> Named Entities are: 
 [('PERSON', 'Journal Big Data')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]



========================================== PARAGRAPH 1668 ===========================================

 
