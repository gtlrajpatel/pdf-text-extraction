				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

International Journal of Recent Technology and Engineering (IJRTE)  

------------------- Sentence 1 -------------------

International Journal of Recent Technology and Engineering (IJRTE)

>> Tokens are: 
 ['International', 'Journal', 'Recent', 'Technology', 'Engineering', '(', 'IJRTE', ')']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Recent'), ('Recent', 'Technology'), ('Technology', 'Engineering'), ('Engineering', '('), ('(', 'IJRTE'), ('IJRTE', ')')]

>> Trigrams are: 
 [('International', 'Journal', 'Recent'), ('Journal', 'Recent', 'Technology'), ('Recent', 'Technology', 'Engineering'), ('Technology', 'Engineering', '('), ('Engineering', '(', 'IJRTE'), ('(', 'IJRTE', ')')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Recent', 'NNP'), ('Technology', 'NNP'), ('Engineering', 'NNP'), ('(', '('), ('IJRTE', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['International Journal Recent Technology Engineering', 'IJRTE']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal'), ('ORGANIZATION', 'IJRTE')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Recent', 'recent'), ('Technology', 'technolog'), ('Engineering', 'engin'), ('(', '('), ('IJRTE', 'ijrt'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Recent', 'recent'), ('Technology', 'technolog'), ('Engineering', 'engin'), ('(', '('), ('IJRTE', 'ijrt'), (')', ')')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Recent', 'Recent'), ('Technology', 'Technology'), ('Engineering', 'Engineering'), ('(', '('), ('IJRTE', 'IJRTE'), (')', ')')]



========================================== PARAGRAPH 2 ===========================================

ISSN: 2277-3878, Volume-7, Issue-5C, February 2019     

------------------- Sentence 1 -------------------

ISSN: 2277-3878, Volume-7, Issue-5C, February 2019

>> Tokens are: 
 ['ISSN', ':', '2277-3878', ',', 'Volume-7', ',', 'Issue-5C', ',', 'February', '2019']

>> Bigrams are: 
 [('ISSN', ':'), (':', '2277-3878'), ('2277-3878', ','), (',', 'Volume-7'), ('Volume-7', ','), (',', 'Issue-5C'), ('Issue-5C', ','), (',', 'February'), ('February', '2019')]

>> Trigrams are: 
 [('ISSN', ':', '2277-3878'), (':', '2277-3878', ','), ('2277-3878', ',', 'Volume-7'), (',', 'Volume-7', ','), ('Volume-7', ',', 'Issue-5C'), (',', 'Issue-5C', ','), ('Issue-5C', ',', 'February'), (',', 'February', '2019')]

>> POS Tags are: 
 [('ISSN', 'NN'), (':', ':'), ('2277-3878', 'JJ'), (',', ','), ('Volume-7', 'NNP'), (',', ','), ('Issue-5C', 'NNP'), (',', ','), ('February', 'NNP'), ('2019', 'CD')]

>> Noun Phrases are: 
 ['ISSN', 'Volume-7', 'Issue-5C', 'February']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'volume-7'), (',', ','), ('Issue-5C', 'issue-5c'), (',', ','), ('February', 'februari'), ('2019', '2019')]

>> Stemming using Snowball Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'volume-7'), (',', ','), ('Issue-5C', 'issue-5c'), (',', ','), ('February', 'februari'), ('2019', '2019')]

>> Lemmatization: 
 [('ISSN', 'ISSN'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'Volume-7'), (',', ','), ('Issue-5C', 'Issue-5C'), (',', ','), ('February', 'February'), ('2019', '2019')]



========================================== PARAGRAPH 3 ===========================================

  


========================================== PARAGRAPH 4 ===========================================

199  

------------------- Sentence 1 -------------------

199

>> Tokens are: 
 ['199']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('199', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('199', '199')]

>> Stemming using Snowball Stemmer: 
 [('199', '199')]

>> Lemmatization: 
 [('199', '199')]



========================================== PARAGRAPH 5 ===========================================

  


========================================== PARAGRAPH 6 ===========================================

Published By:  Blue Eyes Intelligence Engineering  

------------------- Sentence 1 -------------------

Published By:  Blue Eyes Intelligence Engineering

>> Tokens are: 
 ['Published', 'By', ':', 'Blue', 'Eyes', 'Intelligence', 'Engineering']

>> Bigrams are: 
 [('Published', 'By'), ('By', ':'), (':', 'Blue'), ('Blue', 'Eyes'), ('Eyes', 'Intelligence'), ('Intelligence', 'Engineering')]

>> Trigrams are: 
 [('Published', 'By', ':'), ('By', ':', 'Blue'), (':', 'Blue', 'Eyes'), ('Blue', 'Eyes', 'Intelligence'), ('Eyes', 'Intelligence', 'Engineering')]

>> POS Tags are: 
 [('Published', 'VBN'), ('By', 'IN'), (':', ':'), ('Blue', 'JJ'), ('Eyes', 'NNS'), ('Intelligence', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['Blue Eyes Intelligence Engineering']

>> Named Entities are: 
 [('ORGANIZATION', 'Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('Published', 'Published'), ('By', 'By'), (':', ':'), ('Blue', 'Blue'), ('Eyes', 'Eyes'), ('Intelligence', 'Intelligence'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 7 ===========================================

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP  

------------------- Sentence 1 -------------------

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP

>> Tokens are: 
 ['&', 'Sciences', 'Publication', 'Retrieval', 'Number', ':', 'E10480275C19/19©BEIESP']

>> Bigrams are: 
 [('&', 'Sciences'), ('Sciences', 'Publication'), ('Publication', 'Retrieval'), ('Retrieval', 'Number'), ('Number', ':'), (':', 'E10480275C19/19©BEIESP')]

>> Trigrams are: 
 [('&', 'Sciences', 'Publication'), ('Sciences', 'Publication', 'Retrieval'), ('Publication', 'Retrieval', 'Number'), ('Retrieval', 'Number', ':'), ('Number', ':', 'E10480275C19/19©BEIESP')]

>> POS Tags are: 
 [('&', 'CC'), ('Sciences', 'NNPS'), ('Publication', 'NNP'), ('Retrieval', 'NNP'), ('Number', 'NNP'), (':', ':'), ('E10480275C19/19©BEIESP', 'NN')]

>> Noun Phrases are: 
 ['Publication Retrieval Number', 'E10480275C19/19©BEIESP']

>> Named Entities are: 
 [('ORGANIZATION', 'Sciences Publication Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Lemmatization: 
 [('&', '&'), ('Sciences', 'Sciences'), ('Publication', 'Publication'), ('Retrieval', 'Retrieval'), ('Number', 'Number'), (':', ':'), ('E10480275C19/19©BEIESP', 'E10480275C19/19©BEIESP')]



========================================== PARAGRAPH 8 ===========================================

Abstract--- Natural Language Processing (NLP) is a  

------------------- Sentence 1 -------------------

Abstract--- Natural Language Processing (NLP) is a

>> Tokens are: 
 ['Abstract', '--', '-', 'Natural', 'Language', 'Processing', '(', 'NLP', ')']

>> Bigrams are: 
 [('Abstract', '--'), ('--', '-'), ('-', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '('), ('(', 'NLP'), ('NLP', ')')]

>> Trigrams are: 
 [('Abstract', '--', '-'), ('--', '-', 'Natural'), ('-', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '('), ('Processing', '(', 'NLP'), ('(', 'NLP', ')')]

>> POS Tags are: 
 [('Abstract', 'NNP'), ('--', ':'), ('-', ':'), ('Natural', 'JJ'), ('Language', 'NN'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['Abstract', 'Natural Language Processing', 'NLP']

>> Named Entities are: 
 [('GPE', 'Abstract'), ('GPE', 'Natural'), ('ORGANIZATION', 'Language Processing'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract'), ('--', '--'), ('-', '-'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract'), ('--', '--'), ('-', '-'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')')]

>> Lemmatization: 
 [('Abstract', 'Abstract'), ('--', '--'), ('-', '-'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('NLP', 'NLP'), (')', ')')]



========================================== PARAGRAPH 9 ===========================================

subfield of Artificial Intelligence and getting lot of focus on  

------------------- Sentence 1 -------------------

subfield of Artificial Intelligence and getting lot of focus on

>> Tokens are: 
 ['subfield', 'Artificial', 'Intelligence', 'getting', 'lot', 'focus']

>> Bigrams are: 
 [('subfield', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'getting'), ('getting', 'lot'), ('lot', 'focus')]

>> Trigrams are: 
 [('subfield', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'getting'), ('Intelligence', 'getting', 'lot'), ('getting', 'lot', 'focus')]

>> POS Tags are: 
 [('subfield', 'VBN'), ('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('getting', 'VBG'), ('lot', 'NN'), ('focus', 'NN')]

>> Noun Phrases are: 
 ['Artificial Intelligence', 'lot focus']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('subfield', 'subfield'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('getting', 'get'), ('lot', 'lot'), ('focus', 'focu')]

>> Stemming using Snowball Stemmer: 
 [('subfield', 'subfield'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('getting', 'get'), ('lot', 'lot'), ('focus', 'focus')]

>> Lemmatization: 
 [('subfield', 'subfield'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('getting', 'getting'), ('lot', 'lot'), ('focus', 'focus')]



========================================== PARAGRAPH 10 ===========================================

research and development due to emergence of its  

------------------- Sentence 1 -------------------

research and development due to emergence of its

>> Tokens are: 
 ['research', 'development', 'due', 'emergence']

>> Bigrams are: 
 [('research', 'development'), ('development', 'due'), ('due', 'emergence')]

>> Trigrams are: 
 [('research', 'development', 'due'), ('development', 'due', 'emergence')]

>> POS Tags are: 
 [('research', 'NN'), ('development', 'NN'), ('due', 'JJ'), ('emergence', 'NN')]

>> Noun Phrases are: 
 ['research development', 'due emergence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('development', 'develop'), ('due', 'due'), ('emergence', 'emerg')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('development', 'develop'), ('due', 'due'), ('emergence', 'emerg')]

>> Lemmatization: 
 [('research', 'research'), ('development', 'development'), ('due', 'due'), ('emergence', 'emergence')]



========================================== PARAGRAPH 11 ===========================================

applications. The research areas in focus are conversation  

------------------- Sentence 1 -------------------

applications.

>> Tokens are: 
 ['applications', '.']

>> Bigrams are: 
 [('applications', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

The research areas in focus are conversation

>> Tokens are: 
 ['The', 'research', 'areas', 'focus', 'conversation']

>> Bigrams are: 
 [('The', 'research'), ('research', 'areas'), ('areas', 'focus'), ('focus', 'conversation')]

>> Trigrams are: 
 [('The', 'research', 'areas'), ('research', 'areas', 'focus'), ('areas', 'focus', 'conversation')]

>> POS Tags are: 
 [('The', 'DT'), ('research', 'NN'), ('areas', 'NNS'), ('focus', 'VBP'), ('conversation', 'NN')]

>> Noun Phrases are: 
 ['The research areas', 'conversation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('research', 'research'), ('areas', 'area'), ('focus', 'focu'), ('conversation', 'convers')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('research', 'research'), ('areas', 'area'), ('focus', 'focus'), ('conversation', 'convers')]

>> Lemmatization: 
 [('The', 'The'), ('research', 'research'), ('areas', 'area'), ('focus', 'focus'), ('conversation', 'conversation')]



========================================== PARAGRAPH 12 ===========================================

systems, Language processing, Machine Translation, Deep  

------------------- Sentence 1 -------------------

systems, Language processing, Machine Translation, Deep

>> Tokens are: 
 ['systems', ',', 'Language', 'processing', ',', 'Machine', 'Translation', ',', 'Deep']

>> Bigrams are: 
 [('systems', ','), (',', 'Language'), ('Language', 'processing'), ('processing', ','), (',', 'Machine'), ('Machine', 'Translation'), ('Translation', ','), (',', 'Deep')]

>> Trigrams are: 
 [('systems', ',', 'Language'), (',', 'Language', 'processing'), ('Language', 'processing', ','), ('processing', ',', 'Machine'), (',', 'Machine', 'Translation'), ('Machine', 'Translation', ','), ('Translation', ',', 'Deep')]

>> POS Tags are: 
 [('systems', 'NNS'), (',', ','), ('Language', 'NNP'), ('processing', 'NN'), (',', ','), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ','), ('Deep', 'NNP')]

>> Noun Phrases are: 
 ['systems', 'Language processing', 'Machine Translation', 'Deep']

>> Named Entities are: 
 [('GPE', 'Language'), ('PERSON', 'Machine Translation'), ('PERSON', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('systems', 'system'), (',', ','), ('Language', 'languag'), ('processing', 'process'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Deep', 'deep')]

>> Stemming using Snowball Stemmer: 
 [('systems', 'system'), (',', ','), ('Language', 'languag'), ('processing', 'process'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Deep', 'deep')]

>> Lemmatization: 
 [('systems', 'system'), (',', ','), ('Language', 'Language'), ('processing', 'processing'), (',', ','), ('Machine', 'Machine'), ('Translation', 'Translation'), (',', ','), ('Deep', 'Deep')]



========================================== PARAGRAPH 13 ===========================================

learning. The researches in these areas lead to development of  

------------------- Sentence 1 -------------------

learning.

>> Tokens are: 
 ['learning', '.']

>> Bigrams are: 
 [('learning', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

The researches in these areas lead to development of

>> Tokens are: 
 ['The', 'researches', 'areas', 'lead', 'development']

>> Bigrams are: 
 [('The', 'researches'), ('researches', 'areas'), ('areas', 'lead'), ('lead', 'development')]

>> Trigrams are: 
 [('The', 'researches', 'areas'), ('researches', 'areas', 'lead'), ('areas', 'lead', 'development')]

>> POS Tags are: 
 [('The', 'DT'), ('researches', 'NNS'), ('areas', 'NNS'), ('lead', 'VBP'), ('development', 'NN')]

>> Noun Phrases are: 
 ['The researches areas', 'development']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('researches', 'research'), ('areas', 'area'), ('lead', 'lead'), ('development', 'develop')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('researches', 'research'), ('areas', 'area'), ('lead', 'lead'), ('development', 'develop')]

>> Lemmatization: 
 [('The', 'The'), ('researches', 'research'), ('areas', 'area'), ('lead', 'lead'), ('development', 'development')]



========================================== PARAGRAPH 14 ===========================================

many tools to build industrial applications. Combining Deep  

------------------- Sentence 1 -------------------

many tools to build industrial applications.

>> Tokens are: 
 ['many', 'tools', 'build', 'industrial', 'applications', '.']

>> Bigrams are: 
 [('many', 'tools'), ('tools', 'build'), ('build', 'industrial'), ('industrial', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('many', 'tools', 'build'), ('tools', 'build', 'industrial'), ('build', 'industrial', 'applications'), ('industrial', 'applications', '.')]

>> POS Tags are: 
 [('many', 'JJ'), ('tools', 'NNS'), ('build', 'VBP'), ('industrial', 'JJ'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['many tools', 'industrial applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('many', 'mani'), ('tools', 'tool'), ('build', 'build'), ('industrial', 'industri'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('many', 'mani'), ('tools', 'tool'), ('build', 'build'), ('industrial', 'industri'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('many', 'many'), ('tools', 'tool'), ('build', 'build'), ('industrial', 'industrial'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

Combining Deep

>> Tokens are: 
 ['Combining', 'Deep']

>> Bigrams are: 
 [('Combining', 'Deep')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Combining', 'VBG'), ('Deep', 'NNP')]

>> Noun Phrases are: 
 ['Deep']

>> Named Entities are: 
 [('PERSON', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Combining', 'combin'), ('Deep', 'deep')]

>> Stemming using Snowball Stemmer: 
 [('Combining', 'combin'), ('Deep', 'deep')]

>> Lemmatization: 
 [('Combining', 'Combining'), ('Deep', 'Deep')]



========================================== PARAGRAPH 15 ===========================================

Learning techniques with Natural Language Processing is  

------------------- Sentence 1 -------------------

Learning techniques with Natural Language Processing is

>> Tokens are: 
 ['Learning', 'techniques', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('Learning', 'techniques'), ('techniques', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('Learning', 'techniques', 'Natural'), ('techniques', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('techniques', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['techniques Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('techniques', 'techniqu'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('techniques', 'techniqu'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('techniques', 'technique'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 16 ===========================================

finding lot of applications in domains such as Healthcare,  

------------------- Sentence 1 -------------------

finding lot of applications in domains such as Healthcare,

>> Tokens are: 
 ['finding', 'lot', 'applications', 'domains', 'Healthcare', ',']

>> Bigrams are: 
 [('finding', 'lot'), ('lot', 'applications'), ('applications', 'domains'), ('domains', 'Healthcare'), ('Healthcare', ',')]

>> Trigrams are: 
 [('finding', 'lot', 'applications'), ('lot', 'applications', 'domains'), ('applications', 'domains', 'Healthcare'), ('domains', 'Healthcare', ',')]

>> POS Tags are: 
 [('finding', 'VBG'), ('lot', 'NN'), ('applications', 'NNS'), ('domains', 'NNS'), ('Healthcare', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['lot applications domains Healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('finding', 'find'), ('lot', 'lot'), ('applications', 'applic'), ('domains', 'domain'), ('Healthcare', 'healthcar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('finding', 'find'), ('lot', 'lot'), ('applications', 'applic'), ('domains', 'domain'), ('Healthcare', 'healthcar'), (',', ',')]

>> Lemmatization: 
 [('finding', 'finding'), ('lot', 'lot'), ('applications', 'application'), ('domains', 'domain'), ('Healthcare', 'Healthcare'), (',', ',')]



========================================== PARAGRAPH 17 ===========================================

Finance, Manufacturing, Education, Retail and customer  

------------------- Sentence 1 -------------------

Finance, Manufacturing, Education, Retail and customer

>> Tokens are: 
 ['Finance', ',', 'Manufacturing', ',', 'Education', ',', 'Retail', 'customer']

>> Bigrams are: 
 [('Finance', ','), (',', 'Manufacturing'), ('Manufacturing', ','), (',', 'Education'), ('Education', ','), (',', 'Retail'), ('Retail', 'customer')]

>> Trigrams are: 
 [('Finance', ',', 'Manufacturing'), (',', 'Manufacturing', ','), ('Manufacturing', ',', 'Education'), (',', 'Education', ','), ('Education', ',', 'Retail'), (',', 'Retail', 'customer')]

>> POS Tags are: 
 [('Finance', 'NN'), (',', ','), ('Manufacturing', 'NNP'), (',', ','), ('Education', 'NNP'), (',', ','), ('Retail', 'NNP'), ('customer', 'NN')]

>> Noun Phrases are: 
 ['Finance', 'Manufacturing', 'Education', 'Retail customer']

>> Named Entities are: 
 [('GPE', 'Finance'), ('GPE', 'Manufacturing'), ('PERSON', 'Education'), ('GPE', 'Retail')] 

>> Stemming using Porter Stemmer: 
 [('Finance', 'financ'), (',', ','), ('Manufacturing', 'manufactur'), (',', ','), ('Education', 'educ'), (',', ','), ('Retail', 'retail'), ('customer', 'custom')]

>> Stemming using Snowball Stemmer: 
 [('Finance', 'financ'), (',', ','), ('Manufacturing', 'manufactur'), (',', ','), ('Education', 'educ'), (',', ','), ('Retail', 'retail'), ('customer', 'custom')]

>> Lemmatization: 
 [('Finance', 'Finance'), (',', ','), ('Manufacturing', 'Manufacturing'), (',', ','), ('Education', 'Education'), (',', ','), ('Retail', 'Retail'), ('customer', 'customer')]



========================================== PARAGRAPH 18 ===========================================

service. This paper provides bird’s view of advancement in  

------------------- Sentence 1 -------------------

service.

>> Tokens are: 
 ['service', '.']

>> Bigrams are: 
 [('service', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('service', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['service']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('service', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('service', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('service', 'service'), ('.', '.')]


------------------- Sentence 2 -------------------

This paper provides bird’s view of advancement in

>> Tokens are: 
 ['This', 'paper', 'provides', 'bird', '’', 'view', 'advancement']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'provides'), ('provides', 'bird'), ('bird', '’'), ('’', 'view'), ('view', 'advancement')]

>> Trigrams are: 
 [('This', 'paper', 'provides'), ('paper', 'provides', 'bird'), ('provides', 'bird', '’'), ('bird', '’', 'view'), ('’', 'view', 'advancement')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('provides', 'VBZ'), ('bird', 'JJ'), ('’', 'NNP'), ('view', 'NN'), ('advancement', 'NN')]

>> Noun Phrases are: 
 ['This paper', 'bird ’ view advancement']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('provides', 'provid'), ('bird', 'bird'), ('’', '’'), ('view', 'view'), ('advancement', 'advanc')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('provides', 'provid'), ('bird', 'bird'), ('’', '’'), ('view', 'view'), ('advancement', 'advanc')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('provides', 'provides'), ('bird', 'bird'), ('’', '’'), ('view', 'view'), ('advancement', 'advancement')]



========================================== PARAGRAPH 19 ===========================================

research, development and application areas of Natural  

------------------- Sentence 1 -------------------

research, development and application areas of Natural

>> Tokens are: 
 ['research', ',', 'development', 'application', 'areas', 'Natural']

>> Bigrams are: 
 [('research', ','), (',', 'development'), ('development', 'application'), ('application', 'areas'), ('areas', 'Natural')]

>> Trigrams are: 
 [('research', ',', 'development'), (',', 'development', 'application'), ('development', 'application', 'areas'), ('application', 'areas', 'Natural')]

>> POS Tags are: 
 [('research', 'NN'), (',', ','), ('development', 'NN'), ('application', 'NN'), ('areas', 'NNS'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['research', 'development application areas Natural']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), (',', ','), ('development', 'develop'), ('application', 'applic'), ('areas', 'area'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), (',', ','), ('development', 'develop'), ('application', 'applic'), ('areas', 'area'), ('Natural', 'natur')]

>> Lemmatization: 
 [('research', 'research'), (',', ','), ('development', 'development'), ('application', 'application'), ('areas', 'area'), ('Natural', 'Natural')]



========================================== PARAGRAPH 20 ===========================================

Language Processing. This paper captures21research focus  

------------------- Sentence 1 -------------------

Language Processing.

>> Tokens are: 
 ['Language', 'Processing', '.']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', '.')]

>> Trigrams are: 
 [('Language', 'Processing', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Processing']

>> Named Entities are: 
 [('GPE', 'Language'), ('ORGANIZATION', 'Processing')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('.', '.')]


------------------- Sentence 2 -------------------

This paper captures21research focus

>> Tokens are: 
 ['This', 'paper', 'captures21research', 'focus']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'captures21research'), ('captures21research', 'focus')]

>> Trigrams are: 
 [('This', 'paper', 'captures21research'), ('paper', 'captures21research', 'focus')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('captures21research', 'NN'), ('focus', 'NN')]

>> Noun Phrases are: 
 ['This paper captures21research focus']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('captures21research', 'captures21research'), ('focus', 'focu')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('captures21research', 'captures21research'), ('focus', 'focus')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('captures21research', 'captures21research'), ('focus', 'focus')]



========================================== PARAGRAPH 21 ===========================================

areas, 22 development tools and 6 domains where Natural  

------------------- Sentence 1 -------------------

areas, 22 development tools and 6 domains where Natural

>> Tokens are: 
 ['areas', ',', '22', 'development', 'tools', '6', 'domains', 'Natural']

>> Bigrams are: 
 [('areas', ','), (',', '22'), ('22', 'development'), ('development', 'tools'), ('tools', '6'), ('6', 'domains'), ('domains', 'Natural')]

>> Trigrams are: 
 [('areas', ',', '22'), (',', '22', 'development'), ('22', 'development', 'tools'), ('development', 'tools', '6'), ('tools', '6', 'domains'), ('6', 'domains', 'Natural')]

>> POS Tags are: 
 [('areas', 'NNS'), (',', ','), ('22', 'CD'), ('development', 'NN'), ('tools', 'NNS'), ('6', 'CD'), ('domains', 'NNS'), ('Natural', 'JJ')]

>> Noun Phrases are: 
 ['areas', 'development tools', 'domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('areas', 'area'), (',', ','), ('22', '22'), ('development', 'develop'), ('tools', 'tool'), ('6', '6'), ('domains', 'domain'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('areas', 'area'), (',', ','), ('22', '22'), ('development', 'develop'), ('tools', 'tool'), ('6', '6'), ('domains', 'domain'), ('Natural', 'natur')]

>> Lemmatization: 
 [('areas', 'area'), (',', ','), ('22', '22'), ('development', 'development'), ('tools', 'tool'), ('6', '6'), ('domains', 'domain'), ('Natural', 'Natural')]



========================================== PARAGRAPH 22 ===========================================

Language Processing are making rapid advancements.  

------------------- Sentence 1 -------------------

Language Processing are making rapid advancements.

>> Tokens are: 
 ['Language', 'Processing', 'making', 'rapid', 'advancements', '.']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', 'making'), ('making', 'rapid'), ('rapid', 'advancements'), ('advancements', '.')]

>> Trigrams are: 
 [('Language', 'Processing', 'making'), ('Processing', 'making', 'rapid'), ('making', 'rapid', 'advancements'), ('rapid', 'advancements', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'VBG'), ('making', 'VBG'), ('rapid', 'JJ'), ('advancements', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Language', 'rapid advancements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('making', 'make'), ('rapid', 'rapid'), ('advancements', 'advanc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('making', 'make'), ('rapid', 'rapid'), ('advancements', 'advanc'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('making', 'making'), ('rapid', 'rapid'), ('advancements', 'advancement'), ('.', '.')]



========================================== PARAGRAPH 23 ===========================================

Key terms used in this text: NLP, Natural Language  

------------------- Sentence 1 -------------------

Key terms used in this text: NLP, Natural Language

>> Tokens are: 
 ['Key', 'terms', 'used', 'text', ':', 'NLP', ',', 'Natural', 'Language']

>> Bigrams are: 
 [('Key', 'terms'), ('terms', 'used'), ('used', 'text'), ('text', ':'), (':', 'NLP'), ('NLP', ','), (',', 'Natural'), ('Natural', 'Language')]

>> Trigrams are: 
 [('Key', 'terms', 'used'), ('terms', 'used', 'text'), ('used', 'text', ':'), ('text', ':', 'NLP'), (':', 'NLP', ','), ('NLP', ',', 'Natural'), (',', 'Natural', 'Language')]

>> POS Tags are: 
 [('Key', 'JJ'), ('terms', 'NNS'), ('used', 'VBN'), ('text', 'NN'), (':', ':'), ('NLP', 'NNP'), (',', ','), ('Natural', 'NNP'), ('Language', 'NNP')]

>> Noun Phrases are: 
 ['Key terms', 'text', 'NLP', 'Natural Language']

>> Named Entities are: 
 [('GPE', 'Key'), ('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Key', 'key'), ('terms', 'term'), ('used', 'use'), ('text', 'text'), (':', ':'), ('NLP', 'nlp'), (',', ','), ('Natural', 'natur'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Key', 'key'), ('terms', 'term'), ('used', 'use'), ('text', 'text'), (':', ':'), ('NLP', 'nlp'), (',', ','), ('Natural', 'natur'), ('Language', 'languag')]

>> Lemmatization: 
 [('Key', 'Key'), ('terms', 'term'), ('used', 'used'), ('text', 'text'), (':', ':'), ('NLP', 'NLP'), (',', ','), ('Natural', 'Natural'), ('Language', 'Language')]



========================================== PARAGRAPH 24 ===========================================

Processing, Deep Learning, Sentiment Analysis, Question  

------------------- Sentence 1 -------------------

Processing, Deep Learning, Sentiment Analysis, Question

>> Tokens are: 
 ['Processing', ',', 'Deep', 'Learning', ',', 'Sentiment', 'Analysis', ',', 'Question']

>> Bigrams are: 
 [('Processing', ','), (',', 'Deep'), ('Deep', 'Learning'), ('Learning', ','), (',', 'Sentiment'), ('Sentiment', 'Analysis'), ('Analysis', ','), (',', 'Question')]

>> Trigrams are: 
 [('Processing', ',', 'Deep'), (',', 'Deep', 'Learning'), ('Deep', 'Learning', ','), ('Learning', ',', 'Sentiment'), (',', 'Sentiment', 'Analysis'), ('Sentiment', 'Analysis', ','), ('Analysis', ',', 'Question')]

>> POS Tags are: 
 [('Processing', 'NN'), (',', ','), ('Deep', 'NNP'), ('Learning', 'NNP'), (',', ','), ('Sentiment', 'NNP'), ('Analysis', 'NNP'), (',', ','), ('Question', 'NN')]

>> Noun Phrases are: 
 ['Processing', 'Deep Learning', 'Sentiment Analysis', 'Question']

>> Named Entities are: 
 [('PERSON', 'Deep Learning'), ('ORGANIZATION', 'Sentiment Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), (',', ','), ('Deep', 'deep'), ('Learning', 'learn'), (',', ','), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (',', ','), ('Question', 'question')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), (',', ','), ('Deep', 'deep'), ('Learning', 'learn'), (',', ','), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (',', ','), ('Question', 'question')]

>> Lemmatization: 
 [('Processing', 'Processing'), (',', ','), ('Deep', 'Deep'), ('Learning', 'Learning'), (',', ','), ('Sentiment', 'Sentiment'), ('Analysis', 'Analysis'), (',', ','), ('Question', 'Question')]



========================================== PARAGRAPH 25 ===========================================

Answering, Dialogue Systems, Parsing, Named-Entity  

------------------- Sentence 1 -------------------

Answering, Dialogue Systems, Parsing, Named-Entity

>> Tokens are: 
 ['Answering', ',', 'Dialogue', 'Systems', ',', 'Parsing', ',', 'Named-Entity']

>> Bigrams are: 
 [('Answering', ','), (',', 'Dialogue'), ('Dialogue', 'Systems'), ('Systems', ','), (',', 'Parsing'), ('Parsing', ','), (',', 'Named-Entity')]

>> Trigrams are: 
 [('Answering', ',', 'Dialogue'), (',', 'Dialogue', 'Systems'), ('Dialogue', 'Systems', ','), ('Systems', ',', 'Parsing'), (',', 'Parsing', ','), ('Parsing', ',', 'Named-Entity')]

>> POS Tags are: 
 [('Answering', 'NNP'), (',', ','), ('Dialogue', 'NNP'), ('Systems', 'NNPS'), (',', ','), ('Parsing', 'NNP'), (',', ','), ('Named-Entity', 'NNP')]

>> Noun Phrases are: 
 ['Answering', 'Dialogue', 'Parsing', 'Named-Entity']

>> Named Entities are: 
 [('GPE', 'Answering'), ('ORGANIZATION', 'Dialogue Systems'), ('GPE', 'Parsing')] 

>> Stemming using Porter Stemmer: 
 [('Answering', 'answer'), (',', ','), ('Dialogue', 'dialogu'), ('Systems', 'system'), (',', ','), ('Parsing', 'pars'), (',', ','), ('Named-Entity', 'named-ent')]

>> Stemming using Snowball Stemmer: 
 [('Answering', 'answer'), (',', ','), ('Dialogue', 'dialogu'), ('Systems', 'system'), (',', ','), ('Parsing', 'pars'), (',', ','), ('Named-Entity', 'named-ent')]

>> Lemmatization: 
 [('Answering', 'Answering'), (',', ','), ('Dialogue', 'Dialogue'), ('Systems', 'Systems'), (',', ','), ('Parsing', 'Parsing'), (',', ','), ('Named-Entity', 'Named-Entity')]



========================================== PARAGRAPH 26 ===========================================

Recognition, POS Tagging, Chatbots, Human-Computer- 

------------------- Sentence 1 -------------------

Recognition, POS Tagging, Chatbots, Human-Computer-

>> Tokens are: 
 ['Recognition', ',', 'POS', 'Tagging', ',', 'Chatbots', ',', 'Human-Computer-']

>> Bigrams are: 
 [('Recognition', ','), (',', 'POS'), ('POS', 'Tagging'), ('Tagging', ','), (',', 'Chatbots'), ('Chatbots', ','), (',', 'Human-Computer-')]

>> Trigrams are: 
 [('Recognition', ',', 'POS'), (',', 'POS', 'Tagging'), ('POS', 'Tagging', ','), ('Tagging', ',', 'Chatbots'), (',', 'Chatbots', ','), ('Chatbots', ',', 'Human-Computer-')]

>> POS Tags are: 
 [('Recognition', 'NN'), (',', ','), ('POS', 'NNP'), ('Tagging', 'NNP'), (',', ','), ('Chatbots', 'NNP'), (',', ','), ('Human-Computer-', 'NNP')]

>> Noun Phrases are: 
 ['Recognition', 'POS Tagging', 'Chatbots', 'Human-Computer-']

>> Named Entities are: 
 [('GPE', 'Recognition'), ('ORGANIZATION', 'POS Tagging'), ('PERSON', 'Chatbots')] 

>> Stemming using Porter Stemmer: 
 [('Recognition', 'recognit'), (',', ','), ('POS', 'po'), ('Tagging', 'tag'), (',', ','), ('Chatbots', 'chatbot'), (',', ','), ('Human-Computer-', 'human-computer-')]

>> Stemming using Snowball Stemmer: 
 [('Recognition', 'recognit'), (',', ','), ('POS', 'pos'), ('Tagging', 'tag'), (',', ','), ('Chatbots', 'chatbot'), (',', ','), ('Human-Computer-', 'human-computer-')]

>> Lemmatization: 
 [('Recognition', 'Recognition'), (',', ','), ('POS', 'POS'), ('Tagging', 'Tagging'), (',', ','), ('Chatbots', 'Chatbots'), (',', ','), ('Human-Computer-', 'Human-Computer-')]



========================================== PARAGRAPH 27 ===========================================

Interface.  

------------------- Sentence 1 -------------------

Interface.

>> Tokens are: 
 ['Interface', '.']

>> Bigrams are: 
 [('Interface', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Interface', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Interface']

>> Named Entities are: 
 [('GPE', 'Interface')] 

>> Stemming using Porter Stemmer: 
 [('Interface', 'interfac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Interface', 'interfac'), ('.', '.')]

>> Lemmatization: 
 [('Interface', 'Interface'), ('.', '.')]



========================================== PARAGRAPH 28 ===========================================

I. INTRODUCTION  

------------------- Sentence 1 -------------------

I.

>> Tokens are: 
 ['I', '.']

>> Bigrams are: 
 [('I', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), ('.', '.')]


------------------- Sentence 2 -------------------

INTRODUCTION

>> Tokens are: 
 ['INTRODUCTION']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('INTRODUCTION', 'NN')]

>> Noun Phrases are: 
 ['INTRODUCTION']

>> Named Entities are: 
 [('ORGANIZATION', 'INTRODUCTION')] 

>> Stemming using Porter Stemmer: 
 [('INTRODUCTION', 'introduct')]

>> Stemming using Snowball Stemmer: 
 [('INTRODUCTION', 'introduct')]

>> Lemmatization: 
 [('INTRODUCTION', 'INTRODUCTION')]



========================================== PARAGRAPH 29 ===========================================

Natural Language processing (NLP) is a subfield of  

------------------- Sentence 1 -------------------

Natural Language processing (NLP) is a subfield of

>> Tokens are: 
 ['Natural', 'Language', 'processing', '(', 'NLP', ')', 'subfield']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'processing'), ('processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'subfield')]

>> Trigrams are: 
 [('Natural', 'Language', 'processing'), ('Language', 'processing', '('), ('processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'subfield')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('subfield', 'VBD')]

>> Noun Phrases are: 
 ['Natural Language processing', 'NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('subfield', 'subfield')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('subfield', 'subfield')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('processing', 'processing'), ('(', '('), ('NLP', 'NLP'), (')', ')'), ('subfield', 'subfield')]



========================================== PARAGRAPH 30 ===========================================

artificial intelligence dealing with computational  

------------------- Sentence 1 -------------------

artificial intelligence dealing with computational

>> Tokens are: 
 ['artificial', 'intelligence', 'dealing', 'computational']

>> Bigrams are: 
 [('artificial', 'intelligence'), ('intelligence', 'dealing'), ('dealing', 'computational')]

>> Trigrams are: 
 [('artificial', 'intelligence', 'dealing'), ('intelligence', 'dealing', 'computational')]

>> POS Tags are: 
 [('artificial', 'JJ'), ('intelligence', 'NN'), ('dealing', 'VBG'), ('computational', 'JJ')]

>> Noun Phrases are: 
 ['artificial intelligence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('dealing', 'deal'), ('computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('artificial', 'artifici'), ('intelligence', 'intellig'), ('dealing', 'deal'), ('computational', 'comput')]

>> Lemmatization: 
 [('artificial', 'artificial'), ('intelligence', 'intelligence'), ('dealing', 'dealing'), ('computational', 'computational')]



========================================== PARAGRAPH 31 ===========================================

algorithms to automatically represent and process various  

------------------- Sentence 1 -------------------

algorithms to automatically represent and process various

>> Tokens are: 
 ['algorithms', 'automatically', 'represent', 'process', 'various']

>> Bigrams are: 
 [('algorithms', 'automatically'), ('automatically', 'represent'), ('represent', 'process'), ('process', 'various')]

>> Trigrams are: 
 [('algorithms', 'automatically', 'represent'), ('automatically', 'represent', 'process'), ('represent', 'process', 'various')]

>> POS Tags are: 
 [('algorithms', 'NNS'), ('automatically', 'RB'), ('represent', 'VBP'), ('process', 'NN'), ('various', 'JJ')]

>> Noun Phrases are: 
 ['algorithms', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('automatically', 'automat'), ('represent', 'repres'), ('process', 'process'), ('various', 'variou')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('automatically', 'automat'), ('represent', 'repres'), ('process', 'process'), ('various', 'various')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('automatically', 'automatically'), ('represent', 'represent'), ('process', 'process'), ('various', 'various')]



========================================== PARAGRAPH 32 ===========================================

forms of human (natural) language inputs and  

------------------- Sentence 1 -------------------

forms of human (natural) language inputs and

>> Tokens are: 
 ['forms', 'human', '(', 'natural', ')', 'language', 'inputs']

>> Bigrams are: 
 [('forms', 'human'), ('human', '('), ('(', 'natural'), ('natural', ')'), (')', 'language'), ('language', 'inputs')]

>> Trigrams are: 
 [('forms', 'human', '('), ('human', '(', 'natural'), ('(', 'natural', ')'), ('natural', ')', 'language'), (')', 'language', 'inputs')]

>> POS Tags are: 
 [('forms', 'NNS'), ('human', 'VBP'), ('(', '('), ('natural', 'JJ'), (')', ')'), ('language', 'NN'), ('inputs', 'NNS')]

>> Noun Phrases are: 
 ['forms', 'language inputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('forms', 'form'), ('human', 'human'), ('(', '('), ('natural', 'natur'), (')', ')'), ('language', 'languag'), ('inputs', 'input')]

>> Stemming using Snowball Stemmer: 
 [('forms', 'form'), ('human', 'human'), ('(', '('), ('natural', 'natur'), (')', ')'), ('language', 'languag'), ('inputs', 'input')]

>> Lemmatization: 
 [('forms', 'form'), ('human', 'human'), ('(', '('), ('natural', 'natural'), (')', ')'), ('language', 'language'), ('inputs', 'input')]



========================================== PARAGRAPH 33 ===========================================

communicate with Human-Computer-Interface (HCI). It  

------------------- Sentence 1 -------------------

communicate with Human-Computer-Interface (HCI).

>> Tokens are: 
 ['communicate', 'Human-Computer-Interface', '(', 'HCI', ')', '.']

>> Bigrams are: 
 [('communicate', 'Human-Computer-Interface'), ('Human-Computer-Interface', '('), ('(', 'HCI'), ('HCI', ')'), (')', '.')]

>> Trigrams are: 
 [('communicate', 'Human-Computer-Interface', '('), ('Human-Computer-Interface', '(', 'HCI'), ('(', 'HCI', ')'), ('HCI', ')', '.')]

>> POS Tags are: 
 [('communicate', 'NN'), ('Human-Computer-Interface', 'NNP'), ('(', '('), ('HCI', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['communicate Human-Computer-Interface', 'HCI']

>> Named Entities are: 
 [('ORGANIZATION', 'HCI')] 

>> Stemming using Porter Stemmer: 
 [('communicate', 'commun'), ('Human-Computer-Interface', 'human-computer-interfac'), ('(', '('), ('HCI', 'hci'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('communicate', 'communic'), ('Human-Computer-Interface', 'human-computer-interfac'), ('(', '('), ('HCI', 'hci'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('communicate', 'communicate'), ('Human-Computer-Interface', 'Human-Computer-Interface'), ('(', '('), ('HCI', 'HCI'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

It

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 34 ===========================================

is also known by a name “Computational Linguistics”.  

------------------- Sentence 1 -------------------

is also known by a name “Computational Linguistics”.

>> Tokens are: 
 ['also', 'known', 'name', '“', 'Computational', 'Linguistics', '”', '.']

>> Bigrams are: 
 [('also', 'known'), ('known', 'name'), ('name', '“'), ('“', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '”'), ('”', '.')]

>> Trigrams are: 
 [('also', 'known', 'name'), ('known', 'name', '“'), ('name', '“', 'Computational'), ('“', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '”'), ('Linguistics', '”', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('known', 'VBN'), ('name', 'NN'), ('“', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('”', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['name “ Computational Linguistics ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('known', 'known'), ('name', 'name'), ('“', '“'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('known', 'known'), ('name', 'name'), ('“', '“'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('known', 'known'), ('name', 'name'), ('“', '“'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('”', '”'), ('.', '.')]



========================================== PARAGRAPH 35 ===========================================

Natural Language Processing involves following  

------------------- Sentence 1 -------------------

Natural Language Processing involves following

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'involves', 'following']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'involves'), ('involves', 'following')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'involves'), ('Processing', 'involves', 'following')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('involves', 'VBZ'), ('following', 'VBG')]

>> Noun Phrases are: 
 ['Natural Language Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('involves', 'involv'), ('following', 'follow')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('involves', 'involv'), ('following', 'follow')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('involves', 'involves'), ('following', 'following')]



========================================== PARAGRAPH 36 ===========================================

stages of processing namely, lexical (structure) analysis,  

------------------- Sentence 1 -------------------

stages of processing namely, lexical (structure) analysis,

>> Tokens are: 
 ['stages', 'processing', 'namely', ',', 'lexical', '(', 'structure', ')', 'analysis', ',']

>> Bigrams are: 
 [('stages', 'processing'), ('processing', 'namely'), ('namely', ','), (',', 'lexical'), ('lexical', '('), ('(', 'structure'), ('structure', ')'), (')', 'analysis'), ('analysis', ',')]

>> Trigrams are: 
 [('stages', 'processing', 'namely'), ('processing', 'namely', ','), ('namely', ',', 'lexical'), (',', 'lexical', '('), ('lexical', '(', 'structure'), ('(', 'structure', ')'), ('structure', ')', 'analysis'), (')', 'analysis', ',')]

>> POS Tags are: 
 [('stages', 'NNS'), ('processing', 'VBG'), ('namely', 'RB'), (',', ','), ('lexical', 'JJ'), ('(', '('), ('structure', 'NN'), (')', ')'), ('analysis', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['stages', 'structure', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('stages', 'stage'), ('processing', 'process'), ('namely', 'name'), (',', ','), ('lexical', 'lexic'), ('(', '('), ('structure', 'structur'), (')', ')'), ('analysis', 'analysi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('stages', 'stage'), ('processing', 'process'), ('namely', 'name'), (',', ','), ('lexical', 'lexic'), ('(', '('), ('structure', 'structur'), (')', ')'), ('analysis', 'analysi'), (',', ',')]

>> Lemmatization: 
 [('stages', 'stage'), ('processing', 'processing'), ('namely', 'namely'), (',', ','), ('lexical', 'lexical'), ('(', '('), ('structure', 'structure'), (')', ')'), ('analysis', 'analysis'), (',', ',')]



========================================== PARAGRAPH 37 ===========================================

parsing, semantic analysis, discourse integration, and  

------------------- Sentence 1 -------------------

parsing, semantic analysis, discourse integration, and

>> Tokens are: 
 ['parsing', ',', 'semantic', 'analysis', ',', 'discourse', 'integration', ',']

>> Bigrams are: 
 [('parsing', ','), (',', 'semantic'), ('semantic', 'analysis'), ('analysis', ','), (',', 'discourse'), ('discourse', 'integration'), ('integration', ',')]

>> Trigrams are: 
 [('parsing', ',', 'semantic'), (',', 'semantic', 'analysis'), ('semantic', 'analysis', ','), ('analysis', ',', 'discourse'), (',', 'discourse', 'integration'), ('discourse', 'integration', ',')]

>> POS Tags are: 
 [('parsing', 'NN'), (',', ','), ('semantic', 'JJ'), ('analysis', 'NN'), (',', ','), ('discourse', 'JJ'), ('integration', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['parsing', 'semantic analysis', 'discourse integration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parsing', 'pars'), (',', ','), ('semantic', 'semant'), ('analysis', 'analysi'), (',', ','), ('discourse', 'discours'), ('integration', 'integr'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('parsing', 'pars'), (',', ','), ('semantic', 'semant'), ('analysis', 'analysi'), (',', ','), ('discourse', 'discours'), ('integration', 'integr'), (',', ',')]

>> Lemmatization: 
 [('parsing', 'parsing'), (',', ','), ('semantic', 'semantic'), ('analysis', 'analysis'), (',', ','), ('discourse', 'discourse'), ('integration', 'integration'), (',', ',')]



========================================== PARAGRAPH 38 ===========================================

pragmatic analysis. Some well-known application areas  

------------------- Sentence 1 -------------------

pragmatic analysis.

>> Tokens are: 
 ['pragmatic', 'analysis', '.']

>> Bigrams are: 
 [('pragmatic', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('pragmatic', 'analysis', '.')]

>> POS Tags are: 
 [('pragmatic', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pragmatic analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pragmatic', 'pragmat'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pragmatic', 'pragmat'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('pragmatic', 'pragmatic'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Some well-known application areas

>> Tokens are: 
 ['Some', 'well-known', 'application', 'areas']

>> Bigrams are: 
 [('Some', 'well-known'), ('well-known', 'application'), ('application', 'areas')]

>> Trigrams are: 
 [('Some', 'well-known', 'application'), ('well-known', 'application', 'areas')]

>> POS Tags are: 
 [('Some', 'DT'), ('well-known', 'JJ'), ('application', 'NN'), ('areas', 'NNS')]

>> Noun Phrases are: 
 ['Some well-known application areas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('well-known', 'well-known'), ('application', 'applic'), ('areas', 'area')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('well-known', 'well-known'), ('application', 'applic'), ('areas', 'area')]

>> Lemmatization: 
 [('Some', 'Some'), ('well-known', 'well-known'), ('application', 'application'), ('areas', 'area')]



========================================== PARAGRAPH 39 ===========================================

of NLP are Speech Recognition, Optical Character  

------------------- Sentence 1 -------------------

of NLP are Speech Recognition, Optical Character

>> Tokens are: 
 ['NLP', 'Speech', 'Recognition', ',', 'Optical', 'Character']

>> Bigrams are: 
 [('NLP', 'Speech'), ('Speech', 'Recognition'), ('Recognition', ','), (',', 'Optical'), ('Optical', 'Character')]

>> Trigrams are: 
 [('NLP', 'Speech', 'Recognition'), ('Speech', 'Recognition', ','), ('Recognition', ',', 'Optical'), (',', 'Optical', 'Character')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('Speech', 'NNP'), ('Recognition', 'NNP'), (',', ','), ('Optical', 'NNP'), ('Character', 'NNP')]

>> Noun Phrases are: 
 ['NLP Speech Recognition', 'Optical Character']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('PERSON', 'Speech Recognition'), ('PERSON', 'Optical Character')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('Speech', 'speech'), ('Recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('Character', 'charact')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('Speech', 'speech'), ('Recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('Character', 'charact')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('Speech', 'Speech'), ('Recognition', 'Recognition'), (',', ','), ('Optical', 'Optical'), ('Character', 'Character')]



========================================== PARAGRAPH 40 ===========================================

Recognition (OCR), Machine Translation, and Chatbots.  

------------------- Sentence 1 -------------------

Recognition (OCR), Machine Translation, and Chatbots.

>> Tokens are: 
 ['Recognition', '(', 'OCR', ')', ',', 'Machine', 'Translation', ',', 'Chatbots', '.']

>> Bigrams are: 
 [('Recognition', '('), ('(', 'OCR'), ('OCR', ')'), (')', ','), (',', 'Machine'), ('Machine', 'Translation'), ('Translation', ','), (',', 'Chatbots'), ('Chatbots', '.')]

>> Trigrams are: 
 [('Recognition', '(', 'OCR'), ('(', 'OCR', ')'), ('OCR', ')', ','), (')', ',', 'Machine'), (',', 'Machine', 'Translation'), ('Machine', 'Translation', ','), ('Translation', ',', 'Chatbots'), (',', 'Chatbots', '.')]

>> POS Tags are: 
 [('Recognition', 'NNP'), ('(', '('), ('OCR', 'NNP'), (')', ')'), (',', ','), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ','), ('Chatbots', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Recognition', 'OCR', 'Machine Translation', 'Chatbots']

>> Named Entities are: 
 [('GPE', 'Recognition'), ('ORGANIZATION', 'OCR'), ('PERSON', 'Machine Translation'), ('PERSON', 'Chatbots')] 

>> Stemming using Porter Stemmer: 
 [('Recognition', 'recognit'), ('(', '('), ('OCR', 'ocr'), (')', ')'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Chatbots', 'chatbot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recognition', 'recognit'), ('(', '('), ('OCR', 'ocr'), (')', ')'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Chatbots', 'chatbot'), ('.', '.')]

>> Lemmatization: 
 [('Recognition', 'Recognition'), ('(', '('), ('OCR', 'OCR'), (')', ')'), (',', ','), ('Machine', 'Machine'), ('Translation', 'Translation'), (',', ','), ('Chatbots', 'Chatbots'), ('.', '.')]



========================================== PARAGRAPH 41 ===========================================

Recently, Machine Learning algorithms are used to  

------------------- Sentence 1 -------------------

Recently, Machine Learning algorithms are used to

>> Tokens are: 
 ['Recently', ',', 'Machine', 'Learning', 'algorithms', 'used']

>> Bigrams are: 
 [('Recently', ','), (',', 'Machine'), ('Machine', 'Learning'), ('Learning', 'algorithms'), ('algorithms', 'used')]

>> Trigrams are: 
 [('Recently', ',', 'Machine'), (',', 'Machine', 'Learning'), ('Machine', 'Learning', 'algorithms'), ('Learning', 'algorithms', 'used')]

>> POS Tags are: 
 [('Recently', 'RB'), (',', ','), ('Machine', 'NNP'), ('Learning', 'NNP'), ('algorithms', 'NN'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['Machine Learning algorithms']

>> Named Entities are: 
 [('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use')]

>> Lemmatization: 
 [('Recently', 'Recently'), (',', ','), ('Machine', 'Machine'), ('Learning', 'Learning'), ('algorithms', 'algorithm'), ('used', 'used')]



========================================== PARAGRAPH 42 ===========================================

process Natural Language input by studying millions of  

------------------- Sentence 1 -------------------

process Natural Language input by studying millions of

>> Tokens are: 
 ['process', 'Natural', 'Language', 'input', 'studying', 'millions']

>> Bigrams are: 
 [('process', 'Natural'), ('Natural', 'Language'), ('Language', 'input'), ('input', 'studying'), ('studying', 'millions')]

>> Trigrams are: 
 [('process', 'Natural', 'Language'), ('Natural', 'Language', 'input'), ('Language', 'input', 'studying'), ('input', 'studying', 'millions')]

>> POS Tags are: 
 [('process', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('input', 'VBD'), ('studying', 'VBG'), ('millions', 'NNS')]

>> Noun Phrases are: 
 ['process Natural Language', 'millions']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('Natural', 'natur'), ('Language', 'languag'), ('input', 'input'), ('studying', 'studi'), ('millions', 'million')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('Natural', 'natur'), ('Language', 'languag'), ('input', 'input'), ('studying', 'studi'), ('millions', 'million')]

>> Lemmatization: 
 [('process', 'process'), ('Natural', 'Natural'), ('Language', 'Language'), ('input', 'input'), ('studying', 'studying'), ('millions', 'million')]



========================================== PARAGRAPH 43 ===========================================

examples of text — words, sentences, and paragraphs —  

------------------- Sentence 1 -------------------

examples of text — words, sentences, and paragraphs —

>> Tokens are: 
 ['examples', 'text', '—', 'words', ',', 'sentences', ',', 'paragraphs', '—']

>> Bigrams are: 
 [('examples', 'text'), ('text', '—'), ('—', 'words'), ('words', ','), (',', 'sentences'), ('sentences', ','), (',', 'paragraphs'), ('paragraphs', '—')]

>> Trigrams are: 
 [('examples', 'text', '—'), ('text', '—', 'words'), ('—', 'words', ','), ('words', ',', 'sentences'), (',', 'sentences', ','), ('sentences', ',', 'paragraphs'), (',', 'paragraphs', '—')]

>> POS Tags are: 
 [('examples', 'NNS'), ('text', 'VBP'), ('—', 'JJ'), ('words', 'NNS'), (',', ','), ('sentences', 'NNS'), (',', ','), ('paragraphs', 'NN'), ('—', 'NN')]

>> Noun Phrases are: 
 ['examples', '— words', 'sentences', 'paragraphs —']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('examples', 'exampl'), ('text', 'text'), ('—', '—'), ('words', 'word'), (',', ','), ('sentences', 'sentenc'), (',', ','), ('paragraphs', 'paragraph'), ('—', '—')]

>> Stemming using Snowball Stemmer: 
 [('examples', 'exampl'), ('text', 'text'), ('—', '—'), ('words', 'word'), (',', ','), ('sentences', 'sentenc'), (',', ','), ('paragraphs', 'paragraph'), ('—', '—')]

>> Lemmatization: 
 [('examples', 'example'), ('text', 'text'), ('—', '—'), ('words', 'word'), (',', ','), ('sentences', 'sentence'), (',', ','), ('paragraphs', 'paragraph'), ('—', '—')]



========================================== PARAGRAPH 44 ===========================================

written by humans. By studying these samples, training  

------------------- Sentence 1 -------------------

written by humans.

>> Tokens are: 
 ['written', 'humans', '.']

>> Bigrams are: 
 [('written', 'humans'), ('humans', '.')]

>> Trigrams are: 
 [('written', 'humans', '.')]

>> POS Tags are: 
 [('written', 'VBN'), ('humans', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['humans']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('written', 'written'), ('humans', 'human'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('written', 'written'), ('humans', 'human'), ('.', '.')]

>> Lemmatization: 
 [('written', 'written'), ('humans', 'human'), ('.', '.')]


------------------- Sentence 2 -------------------

By studying these samples, training

>> Tokens are: 
 ['By', 'studying', 'samples', ',', 'training']

>> Bigrams are: 
 [('By', 'studying'), ('studying', 'samples'), ('samples', ','), (',', 'training')]

>> Trigrams are: 
 [('By', 'studying', 'samples'), ('studying', 'samples', ','), ('samples', ',', 'training')]

>> POS Tags are: 
 [('By', 'IN'), ('studying', 'VBG'), ('samples', 'NNS'), (',', ','), ('training', 'VBG')]

>> Noun Phrases are: 
 ['samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('studying', 'studi'), ('samples', 'sampl'), (',', ','), ('training', 'train')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('studying', 'studi'), ('samples', 'sampl'), (',', ','), ('training', 'train')]

>> Lemmatization: 
 [('By', 'By'), ('studying', 'studying'), ('samples', 'sample'), (',', ','), ('training', 'training')]



========================================== PARAGRAPH 45 ===========================================

algorithms gain an understanding of the “context” of  

------------------- Sentence 1 -------------------

algorithms gain an understanding of the “context” of

>> Tokens are: 
 ['algorithms', 'gain', 'understanding', '“', 'context', '”']

>> Bigrams are: 
 [('algorithms', 'gain'), ('gain', 'understanding'), ('understanding', '“'), ('“', 'context'), ('context', '”')]

>> Trigrams are: 
 [('algorithms', 'gain', 'understanding'), ('gain', 'understanding', '“'), ('understanding', '“', 'context'), ('“', 'context', '”')]

>> POS Tags are: 
 [('algorithms', 'RB'), ('gain', 'NN'), ('understanding', 'JJ'), ('“', 'NNP'), ('context', 'NN'), ('”', 'NN')]

>> Noun Phrases are: 
 ['gain', 'understanding “ context ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('gain', 'gain'), ('understanding', 'understand'), ('“', '“'), ('context', 'context'), ('”', '”')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('gain', 'gain'), ('understanding', 'understand'), ('“', '“'), ('context', 'context'), ('”', '”')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('gain', 'gain'), ('understanding', 'understanding'), ('“', '“'), ('context', 'context'), ('”', '”')]



========================================== PARAGRAPH 46 ===========================================

human speech, writing, and other modes of  

------------------- Sentence 1 -------------------

human speech, writing, and other modes of

>> Tokens are: 
 ['human', 'speech', ',', 'writing', ',', 'modes']

>> Bigrams are: 
 [('human', 'speech'), ('speech', ','), (',', 'writing'), ('writing', ','), (',', 'modes')]

>> Trigrams are: 
 [('human', 'speech', ','), ('speech', ',', 'writing'), (',', 'writing', ','), ('writing', ',', 'modes')]

>> POS Tags are: 
 [('human', 'JJ'), ('speech', 'NN'), (',', ','), ('writing', 'VBG'), (',', ','), ('modes', 'NNS')]

>> Noun Phrases are: 
 ['human speech', 'modes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('human', 'human'), ('speech', 'speech'), (',', ','), ('writing', 'write'), (',', ','), ('modes', 'mode')]

>> Stemming using Snowball Stemmer: 
 [('human', 'human'), ('speech', 'speech'), (',', ','), ('writing', 'write'), (',', ','), ('modes', 'mode')]

>> Lemmatization: 
 [('human', 'human'), ('speech', 'speech'), (',', ','), ('writing', 'writing'), (',', ','), ('modes', 'mode')]



========================================== PARAGRAPH 47 ===========================================

                                                            Revised Version Manuscript Received on 22 February, 2019  

------------------- Sentence 1 -------------------

                                                            Revised Version Manuscript Received on 22 February, 2019

>> Tokens are: 
 ['Revised', 'Version', 'Manuscript', 'Received', '22', 'February', ',', '2019']

>> Bigrams are: 
 [('Revised', 'Version'), ('Version', 'Manuscript'), ('Manuscript', 'Received'), ('Received', '22'), ('22', 'February'), ('February', ','), (',', '2019')]

>> Trigrams are: 
 [('Revised', 'Version', 'Manuscript'), ('Version', 'Manuscript', 'Received'), ('Manuscript', 'Received', '22'), ('Received', '22', 'February'), ('22', 'February', ','), ('February', ',', '2019')]

>> POS Tags are: 
 [('Revised', 'VBN'), ('Version', 'NNP'), ('Manuscript', 'NNP'), ('Received', 'VBD'), ('22', 'CD'), ('February', 'NNP'), (',', ','), ('2019', 'CD')]

>> Noun Phrases are: 
 ['Version Manuscript', 'February']

>> Named Entities are: 
 [('PERSON', 'Version Manuscript')] 

>> Stemming using Porter Stemmer: 
 [('Revised', 'revis'), ('Version', 'version'), ('Manuscript', 'manuscript'), ('Received', 'receiv'), ('22', '22'), ('February', 'februari'), (',', ','), ('2019', '2019')]

>> Stemming using Snowball Stemmer: 
 [('Revised', 'revis'), ('Version', 'version'), ('Manuscript', 'manuscript'), ('Received', 'receiv'), ('22', '22'), ('February', 'februari'), (',', ','), ('2019', '2019')]

>> Lemmatization: 
 [('Revised', 'Revised'), ('Version', 'Version'), ('Manuscript', 'Manuscript'), ('Received', 'Received'), ('22', '22'), ('February', 'February'), (',', ','), ('2019', '2019')]



========================================== PARAGRAPH 48 ===========================================

Krishna Prakash Kalyanathaya, M.Phil, Research Scholar,  

------------------- Sentence 1 -------------------

Krishna Prakash Kalyanathaya, M.Phil, Research Scholar,

>> Tokens are: 
 ['Krishna', 'Prakash', 'Kalyanathaya', ',', 'M.Phil', ',', 'Research', 'Scholar', ',']

>> Bigrams are: 
 [('Krishna', 'Prakash'), ('Prakash', 'Kalyanathaya'), ('Kalyanathaya', ','), (',', 'M.Phil'), ('M.Phil', ','), (',', 'Research'), ('Research', 'Scholar'), ('Scholar', ',')]

>> Trigrams are: 
 [('Krishna', 'Prakash', 'Kalyanathaya'), ('Prakash', 'Kalyanathaya', ','), ('Kalyanathaya', ',', 'M.Phil'), (',', 'M.Phil', ','), ('M.Phil', ',', 'Research'), (',', 'Research', 'Scholar'), ('Research', 'Scholar', ',')]

>> POS Tags are: 
 [('Krishna', 'NNP'), ('Prakash', 'NNP'), ('Kalyanathaya', 'NNP'), (',', ','), ('M.Phil', 'NNP'), (',', ','), ('Research', 'NNP'), ('Scholar', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Krishna Prakash Kalyanathaya', 'M.Phil', 'Research Scholar']

>> Named Entities are: 
 [('PERSON', 'Krishna'), ('PERSON', 'Prakash Kalyanathaya'), ('PERSON', 'Research Scholar')] 

>> Stemming using Porter Stemmer: 
 [('Krishna', 'krishna'), ('Prakash', 'prakash'), ('Kalyanathaya', 'kalyanathaya'), (',', ','), ('M.Phil', 'm.phil'), (',', ','), ('Research', 'research'), ('Scholar', 'scholar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Krishna', 'krishna'), ('Prakash', 'prakash'), ('Kalyanathaya', 'kalyanathaya'), (',', ','), ('M.Phil', 'm.phil'), (',', ','), ('Research', 'research'), ('Scholar', 'scholar'), (',', ',')]

>> Lemmatization: 
 [('Krishna', 'Krishna'), ('Prakash', 'Prakash'), ('Kalyanathaya', 'Kalyanathaya'), (',', ','), ('M.Phil', 'M.Phil'), (',', ','), ('Research', 'Research'), ('Scholar', 'Scholar'), (',', ',')]



========================================== PARAGRAPH 49 ===========================================

Department of Computer Science, VELS Institute of Science,  Technology & Advanced Studies, Chennai, Tamilnadu, India.                           

------------------- Sentence 1 -------------------

Department of Computer Science, VELS Institute of Science,  Technology & Advanced Studies, Chennai, Tamilnadu, India.

>> Tokens are: 
 ['Department', 'Computer', 'Science', ',', 'VELS', 'Institute', 'Science', ',', 'Technology', '&', 'Advanced', 'Studies', ',', 'Chennai', ',', 'Tamilnadu', ',', 'India', '.']

>> Bigrams are: 
 [('Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'VELS'), ('VELS', 'Institute'), ('Institute', 'Science'), ('Science', ','), (',', 'Technology'), ('Technology', '&'), ('&', 'Advanced'), ('Advanced', 'Studies'), ('Studies', ','), (',', 'Chennai'), ('Chennai', ','), (',', 'Tamilnadu'), ('Tamilnadu', ','), (',', 'India'), ('India', '.')]

>> Trigrams are: 
 [('Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'VELS'), (',', 'VELS', 'Institute'), ('VELS', 'Institute', 'Science'), ('Institute', 'Science', ','), ('Science', ',', 'Technology'), (',', 'Technology', '&'), ('Technology', '&', 'Advanced'), ('&', 'Advanced', 'Studies'), ('Advanced', 'Studies', ','), ('Studies', ',', 'Chennai'), (',', 'Chennai', ','), ('Chennai', ',', 'Tamilnadu'), (',', 'Tamilnadu', ','), ('Tamilnadu', ',', 'India'), (',', 'India', '.')]

>> POS Tags are: 
 [('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('VELS', 'NNP'), ('Institute', 'NNP'), ('Science', 'NNP'), (',', ','), ('Technology', 'NNP'), ('&', 'CC'), ('Advanced', 'NNP'), ('Studies', 'NNPS'), (',', ','), ('Chennai', 'NNP'), (',', ','), ('Tamilnadu', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Department Computer Science', 'VELS Institute Science', 'Technology', 'Advanced', 'Chennai', 'Tamilnadu', 'India']

>> Named Entities are: 
 [('ORGANIZATION', 'VELS Institute Science'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Advanced Studies'), ('GPE', 'Chennai'), ('PERSON', 'Tamilnadu'), ('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ','), ('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ','), ('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Lemmatization: 
 [('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('VELS', 'VELS'), ('Institute', 'Institute'), ('Science', 'Science'), (',', ','), ('Technology', 'Technology'), ('&', '&'), ('Advanced', 'Advanced'), ('Studies', 'Studies'), (',', ','), ('Chennai', 'Chennai'), (',', ','), ('Tamilnadu', 'Tamilnadu'), (',', ','), ('India', 'India'), ('.', '.')]



========================================== PARAGRAPH 50 ===========================================

(e-mail:krishna.prakash.kk@ gmail.com)  

------------------- Sentence 1 -------------------

(e-mail:krishna.prakash.kk@ gmail.com)

>> Tokens are: 
 ['(', 'e-mail', ':', 'krishna.prakash.kk', '@', 'gmail.com', ')']

>> Bigrams are: 
 [('(', 'e-mail'), ('e-mail', ':'), (':', 'krishna.prakash.kk'), ('krishna.prakash.kk', '@'), ('@', 'gmail.com'), ('gmail.com', ')')]

>> Trigrams are: 
 [('(', 'e-mail', ':'), ('e-mail', ':', 'krishna.prakash.kk'), (':', 'krishna.prakash.kk', '@'), ('krishna.prakash.kk', '@', 'gmail.com'), ('@', 'gmail.com', ')')]

>> POS Tags are: 
 [('(', '('), ('e-mail', 'NN'), (':', ':'), ('krishna.prakash.kk', 'NN'), ('@', 'NNP'), ('gmail.com', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['e-mail', 'krishna.prakash.kk @ gmail.com']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('krishna.prakash.kk', 'krishna.prakash.kk'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('krishna.prakash.kk', 'krishna.prakash.kk'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]

>> Lemmatization: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('krishna.prakash.kk', 'krishna.prakash.kk'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]



========================================== PARAGRAPH 51 ===========================================

D. Akila, Associate Professor, Department of Information  Technology, School of Computing Sciences, VELS Institute of Science,  

------------------- Sentence 1 -------------------

D. Akila, Associate Professor, Department of Information  Technology, School of Computing Sciences, VELS Institute of Science,

>> Tokens are: 
 ['D.', 'Akila', ',', 'Associate', 'Professor', ',', 'Department', 'Information', 'Technology', ',', 'School', 'Computing', 'Sciences', ',', 'VELS', 'Institute', 'Science', ',']

>> Bigrams are: 
 [('D.', 'Akila'), ('Akila', ','), (',', 'Associate'), ('Associate', 'Professor'), ('Professor', ','), (',', 'Department'), ('Department', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'School'), ('School', 'Computing'), ('Computing', 'Sciences'), ('Sciences', ','), (',', 'VELS'), ('VELS', 'Institute'), ('Institute', 'Science'), ('Science', ',')]

>> Trigrams are: 
 [('D.', 'Akila', ','), ('Akila', ',', 'Associate'), (',', 'Associate', 'Professor'), ('Associate', 'Professor', ','), ('Professor', ',', 'Department'), (',', 'Department', 'Information'), ('Department', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'School'), (',', 'School', 'Computing'), ('School', 'Computing', 'Sciences'), ('Computing', 'Sciences', ','), ('Sciences', ',', 'VELS'), (',', 'VELS', 'Institute'), ('VELS', 'Institute', 'Science'), ('Institute', 'Science', ',')]

>> POS Tags are: 
 [('D.', 'NNP'), ('Akila', 'NNP'), (',', ','), ('Associate', 'NNP'), ('Professor', 'NNP'), (',', ','), ('Department', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('School', 'NNP'), ('Computing', 'NNP'), ('Sciences', 'NNPS'), (',', ','), ('VELS', 'NNP'), ('Institute', 'NNP'), ('Science', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['D. Akila', 'Associate Professor', 'Department Information Technology', 'School Computing', 'VELS Institute Science']

>> Named Entities are: 
 [('ORGANIZATION', 'Associate Professor'), ('ORGANIZATION', 'Department Information Technology'), ('PERSON', 'School Computing Sciences'), ('ORGANIZATION', 'VELS Institute Science')] 

>> Stemming using Porter Stemmer: 
 [('D.', 'd.'), ('Akila', 'akila'), (',', ','), ('Associate', 'associ'), ('Professor', 'professor'), (',', ','), ('Department', 'depart'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('School', 'school'), ('Computing', 'comput'), ('Sciences', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('D.', 'd.'), ('Akila', 'akila'), (',', ','), ('Associate', 'associ'), ('Professor', 'professor'), (',', ','), ('Department', 'depart'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('School', 'school'), ('Computing', 'comput'), ('Sciences', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ',')]

>> Lemmatization: 
 [('D.', 'D.'), ('Akila', 'Akila'), (',', ','), ('Associate', 'Associate'), ('Professor', 'Professor'), (',', ','), ('Department', 'Department'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('School', 'School'), ('Computing', 'Computing'), ('Sciences', 'Sciences'), (',', ','), ('VELS', 'VELS'), ('Institute', 'Institute'), ('Science', 'Science'), (',', ',')]



========================================== PARAGRAPH 52 ===========================================

Technology & Advanced Studies, Chennai, Tamilnadu, India.                      

------------------- Sentence 1 -------------------

Technology & Advanced Studies, Chennai, Tamilnadu, India.

>> Tokens are: 
 ['Technology', '&', 'Advanced', 'Studies', ',', 'Chennai', ',', 'Tamilnadu', ',', 'India', '.']

>> Bigrams are: 
 [('Technology', '&'), ('&', 'Advanced'), ('Advanced', 'Studies'), ('Studies', ','), (',', 'Chennai'), ('Chennai', ','), (',', 'Tamilnadu'), ('Tamilnadu', ','), (',', 'India'), ('India', '.')]

>> Trigrams are: 
 [('Technology', '&', 'Advanced'), ('&', 'Advanced', 'Studies'), ('Advanced', 'Studies', ','), ('Studies', ',', 'Chennai'), (',', 'Chennai', ','), ('Chennai', ',', 'Tamilnadu'), (',', 'Tamilnadu', ','), ('Tamilnadu', ',', 'India'), (',', 'India', '.')]

>> POS Tags are: 
 [('Technology', 'NNP'), ('&', 'CC'), ('Advanced', 'NNP'), ('Studies', 'NNPS'), (',', ','), ('Chennai', 'NNP'), (',', ','), ('Tamilnadu', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Technology', 'Advanced', 'Chennai', 'Tamilnadu', 'India']

>> Named Entities are: 
 [('ORGANIZATION', 'Advanced Studies'), ('GPE', 'Chennai'), ('PERSON', 'Tamilnadu'), ('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Lemmatization: 
 [('Technology', 'Technology'), ('&', '&'), ('Advanced', 'Advanced'), ('Studies', 'Studies'), (',', ','), ('Chennai', 'Chennai'), (',', ','), ('Tamilnadu', 'Tamilnadu'), (',', ','), ('India', 'India'), ('.', '.')]



========================================== PARAGRAPH 53 ===========================================

(e-mail:akiindia@yahoo.com)  P. Rajesh, Assistant Professor, Department of Information  

------------------- Sentence 1 -------------------

(e-mail:akiindia@yahoo.com)  P. Rajesh, Assistant Professor, Department of Information

>> Tokens are: 
 ['(', 'e-mail', ':', 'akiindia', '@', 'yahoo.com', ')', 'P.', 'Rajesh', ',', 'Assistant', 'Professor', ',', 'Department', 'Information']

>> Bigrams are: 
 [('(', 'e-mail'), ('e-mail', ':'), (':', 'akiindia'), ('akiindia', '@'), ('@', 'yahoo.com'), ('yahoo.com', ')'), (')', 'P.'), ('P.', 'Rajesh'), ('Rajesh', ','), (',', 'Assistant'), ('Assistant', 'Professor'), ('Professor', ','), (',', 'Department'), ('Department', 'Information')]

>> Trigrams are: 
 [('(', 'e-mail', ':'), ('e-mail', ':', 'akiindia'), (':', 'akiindia', '@'), ('akiindia', '@', 'yahoo.com'), ('@', 'yahoo.com', ')'), ('yahoo.com', ')', 'P.'), (')', 'P.', 'Rajesh'), ('P.', 'Rajesh', ','), ('Rajesh', ',', 'Assistant'), (',', 'Assistant', 'Professor'), ('Assistant', 'Professor', ','), ('Professor', ',', 'Department'), (',', 'Department', 'Information')]

>> POS Tags are: 
 [('(', '('), ('e-mail', 'NN'), (':', ':'), ('akiindia', 'NN'), ('@', 'NNP'), ('yahoo.com', 'NN'), (')', ')'), ('P.', 'NNP'), ('Rajesh', 'NNP'), (',', ','), ('Assistant', 'NNP'), ('Professor', 'NNP'), (',', ','), ('Department', 'NNP'), ('Information', 'NN')]

>> Noun Phrases are: 
 ['e-mail', 'akiindia @ yahoo.com', 'P. Rajesh', 'Assistant Professor', 'Department Information']

>> Named Entities are: 
 [('ORGANIZATION', 'Assistant Professor'), ('ORGANIZATION', 'Department Information')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('akiindia', 'akiindia'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (')', ')'), ('P.', 'p.'), ('Rajesh', 'rajesh'), (',', ','), ('Assistant', 'assist'), ('Professor', 'professor'), (',', ','), ('Department', 'depart'), ('Information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('akiindia', 'akiindia'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (')', ')'), ('P.', 'p.'), ('Rajesh', 'rajesh'), (',', ','), ('Assistant', 'assist'), ('Professor', 'professor'), (',', ','), ('Department', 'depart'), ('Information', 'inform')]

>> Lemmatization: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('akiindia', 'akiindia'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (')', ')'), ('P.', 'P.'), ('Rajesh', 'Rajesh'), (',', ','), ('Assistant', 'Assistant'), ('Professor', 'Professor'), (',', ','), ('Department', 'Department'), ('Information', 'Information')]



========================================== PARAGRAPH 54 ===========================================

Technology, School of Computing Sciences, VELS Institute of Science,  

------------------- Sentence 1 -------------------

Technology, School of Computing Sciences, VELS Institute of Science,

>> Tokens are: 
 ['Technology', ',', 'School', 'Computing', 'Sciences', ',', 'VELS', 'Institute', 'Science', ',']

>> Bigrams are: 
 [('Technology', ','), (',', 'School'), ('School', 'Computing'), ('Computing', 'Sciences'), ('Sciences', ','), (',', 'VELS'), ('VELS', 'Institute'), ('Institute', 'Science'), ('Science', ',')]

>> Trigrams are: 
 [('Technology', ',', 'School'), (',', 'School', 'Computing'), ('School', 'Computing', 'Sciences'), ('Computing', 'Sciences', ','), ('Sciences', ',', 'VELS'), (',', 'VELS', 'Institute'), ('VELS', 'Institute', 'Science'), ('Institute', 'Science', ',')]

>> POS Tags are: 
 [('Technology', 'NN'), (',', ','), ('School', 'NNP'), ('Computing', 'NNP'), ('Sciences', 'NNPS'), (',', ','), ('VELS', 'NNP'), ('Institute', 'NNP'), ('Science', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Technology', 'School Computing', 'VELS Institute Science']

>> Named Entities are: 
 [('GPE', 'Technology'), ('PERSON', 'School Computing Sciences'), ('ORGANIZATION', 'VELS Institute Science')] 

>> Stemming using Porter Stemmer: 
 [('Technology', 'technolog'), (',', ','), ('School', 'school'), ('Computing', 'comput'), ('Sciences', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Technology', 'technolog'), (',', ','), ('School', 'school'), ('Computing', 'comput'), ('Sciences', 'scienc'), (',', ','), ('VELS', 'vel'), ('Institute', 'institut'), ('Science', 'scienc'), (',', ',')]

>> Lemmatization: 
 [('Technology', 'Technology'), (',', ','), ('School', 'School'), ('Computing', 'Computing'), ('Sciences', 'Sciences'), (',', ','), ('VELS', 'VELS'), ('Institute', 'Institute'), ('Science', 'Science'), (',', ',')]



========================================== PARAGRAPH 55 ===========================================

Technology & Advanced Studies, Chennai, Tamilnadu, India.                       (e-mail:itsrajesh91@gmail.com)  

------------------- Sentence 1 -------------------

Technology & Advanced Studies, Chennai, Tamilnadu, India.

>> Tokens are: 
 ['Technology', '&', 'Advanced', 'Studies', ',', 'Chennai', ',', 'Tamilnadu', ',', 'India', '.']

>> Bigrams are: 
 [('Technology', '&'), ('&', 'Advanced'), ('Advanced', 'Studies'), ('Studies', ','), (',', 'Chennai'), ('Chennai', ','), (',', 'Tamilnadu'), ('Tamilnadu', ','), (',', 'India'), ('India', '.')]

>> Trigrams are: 
 [('Technology', '&', 'Advanced'), ('&', 'Advanced', 'Studies'), ('Advanced', 'Studies', ','), ('Studies', ',', 'Chennai'), (',', 'Chennai', ','), ('Chennai', ',', 'Tamilnadu'), (',', 'Tamilnadu', ','), ('Tamilnadu', ',', 'India'), (',', 'India', '.')]

>> POS Tags are: 
 [('Technology', 'NNP'), ('&', 'CC'), ('Advanced', 'NNP'), ('Studies', 'NNPS'), (',', ','), ('Chennai', 'NNP'), (',', ','), ('Tamilnadu', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Technology', 'Advanced', 'Chennai', 'Tamilnadu', 'India']

>> Named Entities are: 
 [('ORGANIZATION', 'Advanced Studies'), ('GPE', 'Chennai'), ('PERSON', 'Tamilnadu'), ('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technology', 'technolog'), ('&', '&'), ('Advanced', 'advanc'), ('Studies', 'studi'), (',', ','), ('Chennai', 'chennai'), (',', ','), ('Tamilnadu', 'tamilnadu'), (',', ','), ('India', 'india'), ('.', '.')]

>> Lemmatization: 
 [('Technology', 'Technology'), ('&', '&'), ('Advanced', 'Advanced'), ('Studies', 'Studies'), (',', ','), ('Chennai', 'Chennai'), (',', ','), ('Tamilnadu', 'Tamilnadu'), (',', ','), ('India', 'India'), ('.', '.')]


------------------- Sentence 2 -------------------

(e-mail:itsrajesh91@gmail.com)

>> Tokens are: 
 ['(', 'e-mail', ':', 'itsrajesh91', '@', 'gmail.com', ')']

>> Bigrams are: 
 [('(', 'e-mail'), ('e-mail', ':'), (':', 'itsrajesh91'), ('itsrajesh91', '@'), ('@', 'gmail.com'), ('gmail.com', ')')]

>> Trigrams are: 
 [('(', 'e-mail', ':'), ('e-mail', ':', 'itsrajesh91'), (':', 'itsrajesh91', '@'), ('itsrajesh91', '@', 'gmail.com'), ('@', 'gmail.com', ')')]

>> POS Tags are: 
 [('(', '('), ('e-mail', 'NN'), (':', ':'), ('itsrajesh91', 'NN'), ('@', 'NNP'), ('gmail.com', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['e-mail', 'itsrajesh91 @ gmail.com']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('itsrajesh91', 'itsrajesh91'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('itsrajesh91', 'itsrajesh91'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]

>> Lemmatization: 
 [('(', '('), ('e-mail', 'e-mail'), (':', ':'), ('itsrajesh91', 'itsrajesh91'), ('@', '@'), ('gmail.com', 'gmail.com'), (')', ')')]



========================================== PARAGRAPH 56 ===========================================

communication. The machine learning and deep learning  

------------------- Sentence 1 -------------------

communication.

>> Tokens are: 
 ['communication', '.']

>> Bigrams are: 
 [('communication', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('communication', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['communication']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('communication', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('communication', 'communic'), ('.', '.')]

>> Lemmatization: 
 [('communication', 'communication'), ('.', '.')]


------------------- Sentence 2 -------------------

The machine learning and deep learning

>> Tokens are: 
 ['The', 'machine', 'learning', 'deep', 'learning']

>> Bigrams are: 
 [('The', 'machine'), ('machine', 'learning'), ('learning', 'deep'), ('deep', 'learning')]

>> Trigrams are: 
 [('The', 'machine', 'learning'), ('machine', 'learning', 'deep'), ('learning', 'deep', 'learning')]

>> POS Tags are: 
 [('The', 'DT'), ('machine', 'NN'), ('learning', 'VBG'), ('deep', 'JJ'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['The machine', 'deep learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('learning', 'learn'), ('deep', 'deep'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('learning', 'learn'), ('deep', 'deep'), ('learning', 'learn')]

>> Lemmatization: 
 [('The', 'The'), ('machine', 'machine'), ('learning', 'learning'), ('deep', 'deep'), ('learning', 'learning')]



========================================== PARAGRAPH 57 ===========================================

algorithms are widely is used to develop frameworks for  

------------------- Sentence 1 -------------------

algorithms are widely is used to develop frameworks for

>> Tokens are: 
 ['algorithms', 'widely', 'used', 'develop', 'frameworks']

>> Bigrams are: 
 [('algorithms', 'widely'), ('widely', 'used'), ('used', 'develop'), ('develop', 'frameworks')]

>> Trigrams are: 
 [('algorithms', 'widely', 'used'), ('widely', 'used', 'develop'), ('used', 'develop', 'frameworks')]

>> POS Tags are: 
 [('algorithms', 'NN'), ('widely', 'RB'), ('used', 'VBD'), ('develop', 'VB'), ('frameworks', 'NNS')]

>> Noun Phrases are: 
 ['algorithms', 'frameworks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('widely', 'wide'), ('used', 'use'), ('develop', 'develop'), ('frameworks', 'framework')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('widely', 'wide'), ('used', 'use'), ('develop', 'develop'), ('frameworks', 'framework')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('widely', 'widely'), ('used', 'used'), ('develop', 'develop'), ('frameworks', 'framework')]



========================================== PARAGRAPH 58 ===========================================

NLP and efficiently perform common NLP tasks.  

------------------- Sentence 1 -------------------

NLP and efficiently perform common NLP tasks.

>> Tokens are: 
 ['NLP', 'efficiently', 'perform', 'common', 'NLP', 'tasks', '.']

>> Bigrams are: 
 [('NLP', 'efficiently'), ('efficiently', 'perform'), ('perform', 'common'), ('common', 'NLP'), ('NLP', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('NLP', 'efficiently', 'perform'), ('efficiently', 'perform', 'common'), ('perform', 'common', 'NLP'), ('common', 'NLP', 'tasks'), ('NLP', 'tasks', '.')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('efficiently', 'RB'), ('perform', 'VBP'), ('common', 'JJ'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP', 'common NLP tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('efficiently', 'effici'), ('perform', 'perform'), ('common', 'common'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('efficiently', 'effici'), ('perform', 'perform'), ('common', 'common'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('efficiently', 'efficiently'), ('perform', 'perform'), ('common', 'common'), ('NLP', 'NLP'), ('tasks', 'task'), ('.', '.')]



========================================== PARAGRAPH 59 ===========================================

II. BRIEF HISTORY  

------------------- Sentence 1 -------------------

II.

>> Tokens are: 
 ['II', '.']

>> Bigrams are: 
 [('II', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('II', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['II']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Lemmatization: 
 [('II', 'II'), ('.', '.')]


------------------- Sentence 2 -------------------

BRIEF HISTORY

>> Tokens are: 
 ['BRIEF', 'HISTORY']

>> Bigrams are: 
 [('BRIEF', 'HISTORY')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('BRIEF', 'JJ'), ('HISTORY', 'NNP')]

>> Noun Phrases are: 
 ['BRIEF HISTORY']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('BRIEF', 'brief'), ('HISTORY', 'histori')]

>> Stemming using Snowball Stemmer: 
 [('BRIEF', 'brief'), ('HISTORY', 'histori')]

>> Lemmatization: 
 [('BRIEF', 'BRIEF'), ('HISTORY', 'HISTORY')]



========================================== PARAGRAPH 60 ===========================================

Although the work on NLP dates back to around 1950  

------------------- Sentence 1 -------------------

Although the work on NLP dates back to around 1950

>> Tokens are: 
 ['Although', 'work', 'NLP', 'dates', 'back', 'around', '1950']

>> Bigrams are: 
 [('Although', 'work'), ('work', 'NLP'), ('NLP', 'dates'), ('dates', 'back'), ('back', 'around'), ('around', '1950')]

>> Trigrams are: 
 [('Although', 'work', 'NLP'), ('work', 'NLP', 'dates'), ('NLP', 'dates', 'back'), ('dates', 'back', 'around'), ('back', 'around', '1950')]

>> POS Tags are: 
 [('Although', 'IN'), ('work', 'NN'), ('NLP', 'NNP'), ('dates', 'VBZ'), ('back', 'RB'), ('around', 'IN'), ('1950', 'CD')]

>> Noun Phrases are: 
 ['work NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('work', 'work'), ('NLP', 'nlp'), ('dates', 'date'), ('back', 'back'), ('around', 'around'), ('1950', '1950')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('work', 'work'), ('NLP', 'nlp'), ('dates', 'date'), ('back', 'back'), ('around', 'around'), ('1950', '1950')]

>> Lemmatization: 
 [('Although', 'Although'), ('work', 'work'), ('NLP', 'NLP'), ('dates', 'date'), ('back', 'back'), ('around', 'around'), ('1950', '1950')]



========================================== PARAGRAPH 61 ===========================================

with the development of what is called as “Turing Test”  

------------------- Sentence 1 -------------------

with the development of what is called as “Turing Test”

>> Tokens are: 
 ['development', 'called', '“', 'Turing', 'Test', '”']

>> Bigrams are: 
 [('development', 'called'), ('called', '“'), ('“', 'Turing'), ('Turing', 'Test'), ('Test', '”')]

>> Trigrams are: 
 [('development', 'called', '“'), ('called', '“', 'Turing'), ('“', 'Turing', 'Test'), ('Turing', 'Test', '”')]

>> POS Tags are: 
 [('development', 'NN'), ('called', 'VBN'), ('“', 'CD'), ('Turing', 'NNP'), ('Test', 'NNP'), ('”', 'NN')]

>> Noun Phrases are: 
 ['development', 'Turing Test ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('development', 'develop'), ('called', 'call'), ('“', '“'), ('Turing', 'ture'), ('Test', 'test'), ('”', '”')]

>> Stemming using Snowball Stemmer: 
 [('development', 'develop'), ('called', 'call'), ('“', '“'), ('Turing', 'ture'), ('Test', 'test'), ('”', '”')]

>> Lemmatization: 
 [('development', 'development'), ('called', 'called'), ('“', '“'), ('Turing', 'Turing'), ('Test', 'Test'), ('”', '”')]



========================================== PARAGRAPH 62 ===========================================

and in 1957 a rule based system of syntactic structures.  

------------------- Sentence 1 -------------------

and in 1957 a rule based system of syntactic structures.

>> Tokens are: 
 ['1957', 'rule', 'based', 'system', 'syntactic', 'structures', '.']

>> Bigrams are: 
 [('1957', 'rule'), ('rule', 'based'), ('based', 'system'), ('system', 'syntactic'), ('syntactic', 'structures'), ('structures', '.')]

>> Trigrams are: 
 [('1957', 'rule', 'based'), ('rule', 'based', 'system'), ('based', 'system', 'syntactic'), ('system', 'syntactic', 'structures'), ('syntactic', 'structures', '.')]

>> POS Tags are: 
 [('1957', 'CD'), ('rule', 'NN'), ('based', 'VBN'), ('system', 'NN'), ('syntactic', 'JJ'), ('structures', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['rule', 'system', 'syntactic structures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1957', '1957'), ('rule', 'rule'), ('based', 'base'), ('system', 'system'), ('syntactic', 'syntact'), ('structures', 'structur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1957', '1957'), ('rule', 'rule'), ('based', 'base'), ('system', 'system'), ('syntactic', 'syntact'), ('structures', 'structur'), ('.', '.')]

>> Lemmatization: 
 [('1957', '1957'), ('rule', 'rule'), ('based', 'based'), ('system', 'system'), ('syntactic', 'syntactic'), ('structures', 'structure'), ('.', '.')]



========================================== PARAGRAPH 63 ===========================================

The progress was slow until 1990 due to limited  

------------------- Sentence 1 -------------------

The progress was slow until 1990 due to limited

>> Tokens are: 
 ['The', 'progress', 'slow', '1990', 'due', 'limited']

>> Bigrams are: 
 [('The', 'progress'), ('progress', 'slow'), ('slow', '1990'), ('1990', 'due'), ('due', 'limited')]

>> Trigrams are: 
 [('The', 'progress', 'slow'), ('progress', 'slow', '1990'), ('slow', '1990', 'due'), ('1990', 'due', 'limited')]

>> POS Tags are: 
 [('The', 'DT'), ('progress', 'NN'), ('slow', 'JJ'), ('1990', 'CD'), ('due', 'JJ'), ('limited', 'VBD')]

>> Noun Phrases are: 
 ['The progress']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('progress', 'progress'), ('slow', 'slow'), ('1990', '1990'), ('due', 'due'), ('limited', 'limit')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('progress', 'progress'), ('slow', 'slow'), ('1990', '1990'), ('due', 'due'), ('limited', 'limit')]

>> Lemmatization: 
 [('The', 'The'), ('progress', 'progress'), ('slow', 'slow'), ('1990', '1990'), ('due', 'due'), ('limited', 'limited')]



========================================== PARAGRAPH 64 ===========================================

computational power and systems were based on  

------------------- Sentence 1 -------------------

computational power and systems were based on

>> Tokens are: 
 ['computational', 'power', 'systems', 'based']

>> Bigrams are: 
 [('computational', 'power'), ('power', 'systems'), ('systems', 'based')]

>> Trigrams are: 
 [('computational', 'power', 'systems'), ('power', 'systems', 'based')]

>> POS Tags are: 
 [('computational', 'JJ'), ('power', 'NN'), ('systems', 'NNS'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['computational power systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computational', 'comput'), ('power', 'power'), ('systems', 'system'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('computational', 'comput'), ('power', 'power'), ('systems', 'system'), ('based', 'base')]

>> Lemmatization: 
 [('computational', 'computational'), ('power', 'power'), ('systems', 'system'), ('based', 'based')]



========================================== PARAGRAPH 65 ===========================================

complex sets of hand written rules and limited  

------------------- Sentence 1 -------------------

complex sets of hand written rules and limited

>> Tokens are: 
 ['complex', 'sets', 'hand', 'written', 'rules', 'limited']

>> Bigrams are: 
 [('complex', 'sets'), ('sets', 'hand'), ('hand', 'written'), ('written', 'rules'), ('rules', 'limited')]

>> Trigrams are: 
 [('complex', 'sets', 'hand'), ('sets', 'hand', 'written'), ('hand', 'written', 'rules'), ('written', 'rules', 'limited')]

>> POS Tags are: 
 [('complex', 'JJ'), ('sets', 'NNS'), ('hand', 'NN'), ('written', 'VBN'), ('rules', 'NNS'), ('limited', 'VBD')]

>> Noun Phrases are: 
 ['complex sets hand', 'rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('complex', 'complex'), ('sets', 'set'), ('hand', 'hand'), ('written', 'written'), ('rules', 'rule'), ('limited', 'limit')]

>> Stemming using Snowball Stemmer: 
 [('complex', 'complex'), ('sets', 'set'), ('hand', 'hand'), ('written', 'written'), ('rules', 'rule'), ('limited', 'limit')]

>> Lemmatization: 
 [('complex', 'complex'), ('sets', 'set'), ('hand', 'hand'), ('written', 'written'), ('rules', 'rule'), ('limited', 'limited')]



========================================== PARAGRAPH 66 ===========================================

vocabulary. With the introduction of machine learning  

------------------- Sentence 1 -------------------

vocabulary.

>> Tokens are: 
 ['vocabulary', '.']

>> Bigrams are: 
 [('vocabulary', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('vocabulary', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['vocabulary']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('vocabulary', 'vocabulari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('vocabulary', 'vocabulari'), ('.', '.')]

>> Lemmatization: 
 [('vocabulary', 'vocabulary'), ('.', '.')]


------------------- Sentence 2 -------------------

With the introduction of machine learning

>> Tokens are: 
 ['With', 'introduction', 'machine', 'learning']

>> Bigrams are: 
 [('With', 'introduction'), ('introduction', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('With', 'introduction', 'machine'), ('introduction', 'machine', 'learning')]

>> POS Tags are: 
 [('With', 'IN'), ('introduction', 'NN'), ('machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['introduction machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('With', 'With'), ('introduction', 'introduction'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 67 ===========================================

and steady increase in computational power, recently  

------------------- Sentence 1 -------------------

and steady increase in computational power, recently

>> Tokens are: 
 ['steady', 'increase', 'computational', 'power', ',', 'recently']

>> Bigrams are: 
 [('steady', 'increase'), ('increase', 'computational'), ('computational', 'power'), ('power', ','), (',', 'recently')]

>> Trigrams are: 
 [('steady', 'increase', 'computational'), ('increase', 'computational', 'power'), ('computational', 'power', ','), ('power', ',', 'recently')]

>> POS Tags are: 
 [('steady', 'JJ'), ('increase', 'NN'), ('computational', 'JJ'), ('power', 'NN'), (',', ','), ('recently', 'RB')]

>> Noun Phrases are: 
 ['steady increase', 'computational power']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('steady', 'steadi'), ('increase', 'increas'), ('computational', 'comput'), ('power', 'power'), (',', ','), ('recently', 'recent')]

>> Stemming using Snowball Stemmer: 
 [('steady', 'steadi'), ('increase', 'increas'), ('computational', 'comput'), ('power', 'power'), (',', ','), ('recently', 'recent')]

>> Lemmatization: 
 [('steady', 'steady'), ('increase', 'increase'), ('computational', 'computational'), ('power', 'power'), (',', ','), ('recently', 'recently')]



========================================== PARAGRAPH 68 ===========================================

interest on research and applications are growing. The  

------------------- Sentence 1 -------------------

interest on research and applications are growing.

>> Tokens are: 
 ['interest', 'research', 'applications', 'growing', '.']

>> Bigrams are: 
 [('interest', 'research'), ('research', 'applications'), ('applications', 'growing'), ('growing', '.')]

>> Trigrams are: 
 [('interest', 'research', 'applications'), ('research', 'applications', 'growing'), ('applications', 'growing', '.')]

>> POS Tags are: 
 [('interest', 'NN'), ('research', 'NN'), ('applications', 'NNS'), ('growing', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['interest research applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interest', 'interest'), ('research', 'research'), ('applications', 'applic'), ('growing', 'grow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('interest', 'interest'), ('research', 'research'), ('applications', 'applic'), ('growing', 'grow'), ('.', '.')]

>> Lemmatization: 
 [('interest', 'interest'), ('research', 'research'), ('applications', 'application'), ('growing', 'growing'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 69 ===========================================

recent major breakthrough areas of NLP are: speech  

------------------- Sentence 1 -------------------

recent major breakthrough areas of NLP are: speech

>> Tokens are: 
 ['recent', 'major', 'breakthrough', 'areas', 'NLP', ':', 'speech']

>> Bigrams are: 
 [('recent', 'major'), ('major', 'breakthrough'), ('breakthrough', 'areas'), ('areas', 'NLP'), ('NLP', ':'), (':', 'speech')]

>> Trigrams are: 
 [('recent', 'major', 'breakthrough'), ('major', 'breakthrough', 'areas'), ('breakthrough', 'areas', 'NLP'), ('areas', 'NLP', ':'), ('NLP', ':', 'speech')]

>> POS Tags are: 
 [('recent', 'JJ'), ('major', 'JJ'), ('breakthrough', 'IN'), ('areas', 'NNS'), ('NLP', 'NNP'), (':', ':'), ('speech', 'NN')]

>> Noun Phrases are: 
 ['areas NLP', 'speech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('recent', 'recent'), ('major', 'major'), ('breakthrough', 'breakthrough'), ('areas', 'area'), ('NLP', 'nlp'), (':', ':'), ('speech', 'speech')]

>> Stemming using Snowball Stemmer: 
 [('recent', 'recent'), ('major', 'major'), ('breakthrough', 'breakthrough'), ('areas', 'area'), ('NLP', 'nlp'), (':', ':'), ('speech', 'speech')]

>> Lemmatization: 
 [('recent', 'recent'), ('major', 'major'), ('breakthrough', 'breakthrough'), ('areas', 'area'), ('NLP', 'NLP'), (':', ':'), ('speech', 'speech')]



========================================== PARAGRAPH 70 ===========================================

recognition, language processing, dialog systems and  

------------------- Sentence 1 -------------------

recognition, language processing, dialog systems and

>> Tokens are: 
 ['recognition', ',', 'language', 'processing', ',', 'dialog', 'systems']

>> Bigrams are: 
 [('recognition', ','), (',', 'language'), ('language', 'processing'), ('processing', ','), (',', 'dialog'), ('dialog', 'systems')]

>> Trigrams are: 
 [('recognition', ',', 'language'), (',', 'language', 'processing'), ('language', 'processing', ','), ('processing', ',', 'dialog'), (',', 'dialog', 'systems')]

>> POS Tags are: 
 [('recognition', 'NN'), (',', ','), ('language', 'NN'), ('processing', 'NN'), (',', ','), ('dialog', 'NN'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['recognition', 'language processing', 'dialog systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('recognition', 'recognit'), (',', ','), ('language', 'languag'), ('processing', 'process'), (',', ','), ('dialog', 'dialog'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('recognition', 'recognit'), (',', ','), ('language', 'languag'), ('processing', 'process'), (',', ','), ('dialog', 'dialog'), ('systems', 'system')]

>> Lemmatization: 
 [('recognition', 'recognition'), (',', ','), ('language', 'language'), ('processing', 'processing'), (',', ','), ('dialog', 'dialog'), ('systems', 'system')]



========================================== PARAGRAPH 71 ===========================================

applying deep learning techniques.  

------------------- Sentence 1 -------------------

applying deep learning techniques.

>> Tokens are: 
 ['applying', 'deep', 'learning', 'techniques', '.']

>> Bigrams are: 
 [('applying', 'deep'), ('deep', 'learning'), ('learning', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('applying', 'deep', 'learning'), ('deep', 'learning', 'techniques'), ('learning', 'techniques', '.')]

>> POS Tags are: 
 [('applying', 'VBG'), ('deep', 'JJ'), ('learning', 'NN'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep learning techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applying', 'appli'), ('deep', 'deep'), ('learning', 'learn'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applying', 'appli'), ('deep', 'deep'), ('learning', 'learn'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('applying', 'applying'), ('deep', 'deep'), ('learning', 'learning'), ('techniques', 'technique'), ('.', '.')]



========================================== PARAGRAPH 72 ===========================================

While NLP is still facing lot of challenges (like human  

------------------- Sentence 1 -------------------

While NLP is still facing lot of challenges (like human

>> Tokens are: 
 ['While', 'NLP', 'still', 'facing', 'lot', 'challenges', '(', 'like', 'human']

>> Bigrams are: 
 [('While', 'NLP'), ('NLP', 'still'), ('still', 'facing'), ('facing', 'lot'), ('lot', 'challenges'), ('challenges', '('), ('(', 'like'), ('like', 'human')]

>> Trigrams are: 
 [('While', 'NLP', 'still'), ('NLP', 'still', 'facing'), ('still', 'facing', 'lot'), ('facing', 'lot', 'challenges'), ('lot', 'challenges', '('), ('challenges', '(', 'like'), ('(', 'like', 'human')]

>> POS Tags are: 
 [('While', 'IN'), ('NLP', 'NNP'), ('still', 'RB'), ('facing', 'VBG'), ('lot', 'NN'), ('challenges', 'NNS'), ('(', '('), ('like', 'IN'), ('human', 'NN')]

>> Noun Phrases are: 
 ['NLP', 'lot challenges', 'human']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('NLP', 'nlp'), ('still', 'still'), ('facing', 'face'), ('lot', 'lot'), ('challenges', 'challeng'), ('(', '('), ('like', 'like'), ('human', 'human')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('NLP', 'nlp'), ('still', 'still'), ('facing', 'face'), ('lot', 'lot'), ('challenges', 'challeng'), ('(', '('), ('like', 'like'), ('human', 'human')]

>> Lemmatization: 
 [('While', 'While'), ('NLP', 'NLP'), ('still', 'still'), ('facing', 'facing'), ('lot', 'lot'), ('challenges', 'challenge'), ('(', '('), ('like', 'like'), ('human', 'human')]



========================================== PARAGRAPH 73 ===========================================

computer interfaces), there has been lot of research  

------------------- Sentence 1 -------------------

computer interfaces), there has been lot of research

>> Tokens are: 
 ['computer', 'interfaces', ')', ',', 'lot', 'research']

>> Bigrams are: 
 [('computer', 'interfaces'), ('interfaces', ')'), (')', ','), (',', 'lot'), ('lot', 'research')]

>> Trigrams are: 
 [('computer', 'interfaces', ')'), ('interfaces', ')', ','), (')', ',', 'lot'), (',', 'lot', 'research')]

>> POS Tags are: 
 [('computer', 'NN'), ('interfaces', 'NNS'), (')', ')'), (',', ','), ('lot', 'NN'), ('research', 'NN')]

>> Noun Phrases are: 
 ['computer interfaces', 'lot research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computer', 'comput'), ('interfaces', 'interfac'), (')', ')'), (',', ','), ('lot', 'lot'), ('research', 'research')]

>> Stemming using Snowball Stemmer: 
 [('computer', 'comput'), ('interfaces', 'interfac'), (')', ')'), (',', ','), ('lot', 'lot'), ('research', 'research')]

>> Lemmatization: 
 [('computer', 'computer'), ('interfaces', 'interface'), (')', ')'), (',', ','), ('lot', 'lot'), ('research', 'research')]



========================================== PARAGRAPH 74 ===========================================

interests and it has opened to many opportunities for  

------------------- Sentence 1 -------------------

interests and it has opened to many opportunities for

>> Tokens are: 
 ['interests', 'opened', 'many', 'opportunities']

>> Bigrams are: 
 [('interests', 'opened'), ('opened', 'many'), ('many', 'opportunities')]

>> Trigrams are: 
 [('interests', 'opened', 'many'), ('opened', 'many', 'opportunities')]

>> POS Tags are: 
 [('interests', 'NNS'), ('opened', 'VBD'), ('many', 'JJ'), ('opportunities', 'NNS')]

>> Noun Phrases are: 
 ['interests', 'many opportunities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interests', 'interest'), ('opened', 'open'), ('many', 'mani'), ('opportunities', 'opportun')]

>> Stemming using Snowball Stemmer: 
 [('interests', 'interest'), ('opened', 'open'), ('many', 'mani'), ('opportunities', 'opportun')]

>> Lemmatization: 
 [('interests', 'interest'), ('opened', 'opened'), ('many', 'many'), ('opportunities', 'opportunity')]



========================================== PARAGRAPH 75 ===========================================

using the techniques in robotics, automation and digital  

------------------- Sentence 1 -------------------

using the techniques in robotics, automation and digital

>> Tokens are: 
 ['using', 'techniques', 'robotics', ',', 'automation', 'digital']

>> Bigrams are: 
 [('using', 'techniques'), ('techniques', 'robotics'), ('robotics', ','), (',', 'automation'), ('automation', 'digital')]

>> Trigrams are: 
 [('using', 'techniques', 'robotics'), ('techniques', 'robotics', ','), ('robotics', ',', 'automation'), (',', 'automation', 'digital')]

>> POS Tags are: 
 [('using', 'VBG'), ('techniques', 'NNS'), ('robotics', 'NNS'), (',', ','), ('automation', 'NN'), ('digital', 'NN')]

>> Noun Phrases are: 
 ['techniques robotics', 'automation digital']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('techniques', 'techniqu'), ('robotics', 'robot'), (',', ','), ('automation', 'autom'), ('digital', 'digit')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('techniques', 'techniqu'), ('robotics', 'robot'), (',', ','), ('automation', 'autom'), ('digital', 'digit')]

>> Lemmatization: 
 [('using', 'using'), ('techniques', 'technique'), ('robotics', 'robotics'), (',', ','), ('automation', 'automation'), ('digital', 'digital')]



========================================== PARAGRAPH 76 ===========================================

transformation.  

------------------- Sentence 1 -------------------

transformation.

>> Tokens are: 
 ['transformation', '.']

>> Bigrams are: 
 [('transformation', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('transformation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['transformation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('transformation', 'transform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('transformation', 'transform'), ('.', '.')]

>> Lemmatization: 
 [('transformation', 'transformation'), ('.', '.')]



========================================== PARAGRAPH 77 ===========================================

III. RESEARCH WORKS ON NLP  

------------------- Sentence 1 -------------------

III.

>> Tokens are: 
 ['III', '.']

>> Bigrams are: 
 [('III', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('III', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['III']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('III', 'iii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III', 'iii'), ('.', '.')]

>> Lemmatization: 
 [('III', 'III'), ('.', '.')]


------------------- Sentence 2 -------------------

RESEARCH WORKS ON NLP

>> Tokens are: 
 ['RESEARCH', 'WORKS', 'ON', 'NLP']

>> Bigrams are: 
 [('RESEARCH', 'WORKS'), ('WORKS', 'ON'), ('ON', 'NLP')]

>> Trigrams are: 
 [('RESEARCH', 'WORKS', 'ON'), ('WORKS', 'ON', 'NLP')]

>> POS Tags are: 
 [('RESEARCH', 'NNP'), ('WORKS', 'NNP'), ('ON', 'NNP'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['RESEARCH WORKS ON NLP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('RESEARCH', 'research'), ('WORKS', 'work'), ('ON', 'on'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('RESEARCH', 'research'), ('WORKS', 'work'), ('ON', 'on'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('RESEARCH', 'RESEARCH'), ('WORKS', 'WORKS'), ('ON', 'ON'), ('NLP', 'NLP')]



========================================== PARAGRAPH 78 ===========================================

Until 1990, most of the research work was done on the  

------------------- Sentence 1 -------------------

Until 1990, most of the research work was done on the

>> Tokens are: 
 ['Until', '1990', ',', 'research', 'work', 'done']

>> Bigrams are: 
 [('Until', '1990'), ('1990', ','), (',', 'research'), ('research', 'work'), ('work', 'done')]

>> Trigrams are: 
 [('Until', '1990', ','), ('1990', ',', 'research'), (',', 'research', 'work'), ('research', 'work', 'done')]

>> POS Tags are: 
 [('Until', 'IN'), ('1990', 'CD'), (',', ','), ('research', 'NN'), ('work', 'NN'), ('done', 'VBN')]

>> Noun Phrases are: 
 ['research work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Until', 'until'), ('1990', '1990'), (',', ','), ('research', 'research'), ('work', 'work'), ('done', 'done')]

>> Stemming using Snowball Stemmer: 
 [('Until', 'until'), ('1990', '1990'), (',', ','), ('research', 'research'), ('work', 'work'), ('done', 'done')]

>> Lemmatization: 
 [('Until', 'Until'), ('1990', '1990'), (',', ','), ('research', 'research'), ('work', 'work'), ('done', 'done')]



========================================== PARAGRAPH 79 ===========================================

NLP concepts and machine translation. Most recent  

------------------- Sentence 1 -------------------

NLP concepts and machine translation.

>> Tokens are: 
 ['NLP', 'concepts', 'machine', 'translation', '.']

>> Bigrams are: 
 [('NLP', 'concepts'), ('concepts', 'machine'), ('machine', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('NLP', 'concepts', 'machine'), ('concepts', 'machine', 'translation'), ('machine', 'translation', '.')]

>> POS Tags are: 
 [('NLP', 'JJ'), ('concepts', 'NNS'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP concepts machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('concepts', 'concept'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('concepts', 'concept'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('concepts', 'concept'), ('machine', 'machine'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

Most recent

>> Tokens are: 
 ['Most', 'recent']

>> Bigrams are: 
 [('Most', 'recent')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Most', 'JJS'), ('recent', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('recent', 'recent')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('recent', 'recent')]

>> Lemmatization: 
 [('Most', 'Most'), ('recent', 'recent')]



========================================== PARAGRAPH 80 ===========================================

research work on NLP have harnessed the power of  

------------------- Sentence 1 -------------------

research work on NLP have harnessed the power of

>> Tokens are: 
 ['research', 'work', 'NLP', 'harnessed', 'power']

>> Bigrams are: 
 [('research', 'work'), ('work', 'NLP'), ('NLP', 'harnessed'), ('harnessed', 'power')]

>> Trigrams are: 
 [('research', 'work', 'NLP'), ('work', 'NLP', 'harnessed'), ('NLP', 'harnessed', 'power')]

>> POS Tags are: 
 [('research', 'NN'), ('work', 'NN'), ('NLP', 'NNP'), ('harnessed', 'VBD'), ('power', 'NN')]

>> Noun Phrases are: 
 ['research work NLP', 'power']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), ('work', 'work'), ('NLP', 'nlp'), ('harnessed', 'har'), ('power', 'power')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), ('work', 'work'), ('NLP', 'nlp'), ('harnessed', 'har'), ('power', 'power')]

>> Lemmatization: 
 [('research', 'research'), ('work', 'work'), ('NLP', 'NLP'), ('harnessed', 'harnessed'), ('power', 'power')]



========================================== PARAGRAPH 81 ===========================================

statistical models, machine learning, Deep learning  

------------------- Sentence 1 -------------------

statistical models, machine learning, Deep learning

>> Tokens are: 
 ['statistical', 'models', ',', 'machine', 'learning', ',', 'Deep', 'learning']

>> Bigrams are: 
 [('statistical', 'models'), ('models', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'Deep'), ('Deep', 'learning')]

>> Trigrams are: 
 [('statistical', 'models', ','), ('models', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'Deep'), (',', 'Deep', 'learning')]

>> POS Tags are: 
 [('statistical', 'JJ'), ('models', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('Deep', 'NNP'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['statistical models', 'machine learning', 'Deep learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('statistical', 'statist'), ('models', 'model'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('Deep', 'deep'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('statistical', 'statist'), ('models', 'model'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('Deep', 'deep'), ('learning', 'learn')]

>> Lemmatization: 
 [('statistical', 'statistical'), ('models', 'model'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('Deep', 'Deep'), ('learning', 'learning')]



========================================== PARAGRAPH 82 ===========================================

technologies that are using data driven approach.  

------------------- Sentence 1 -------------------

technologies that are using data driven approach.

>> Tokens are: 
 ['technologies', 'using', 'data', 'driven', 'approach', '.']

>> Bigrams are: 
 [('technologies', 'using'), ('using', 'data'), ('data', 'driven'), ('driven', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('technologies', 'using', 'data'), ('using', 'data', 'driven'), ('data', 'driven', 'approach'), ('driven', 'approach', '.')]

>> POS Tags are: 
 [('technologies', 'NNS'), ('using', 'VBG'), ('data', 'NNS'), ('driven', 'RB'), ('approach', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['technologies', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('technologies', 'technolog'), ('using', 'use'), ('data', 'data'), ('driven', 'driven'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('technologies', 'technolog'), ('using', 'use'), ('data', 'data'), ('driven', 'driven'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('technologies', 'technology'), ('using', 'using'), ('data', 'data'), ('driven', 'driven'), ('approach', 'approach'), ('.', '.')]



========================================== PARAGRAPH 83 ===========================================

The research topics on Natural Language Processing  

------------------- Sentence 1 -------------------

The research topics on Natural Language Processing

>> Tokens are: 
 ['The', 'research', 'topics', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('The', 'research'), ('research', 'topics'), ('topics', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('The', 'research', 'topics'), ('research', 'topics', 'Natural'), ('topics', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('The', 'DT'), ('research', 'NN'), ('topics', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['The research topics Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('research', 'research'), ('topics', 'topic'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('research', 'research'), ('topics', 'topic'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('The', 'The'), ('research', 'research'), ('topics', 'topic'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 84 ===========================================

sometimes overlap with some artificial intelligence and  

------------------- Sentence 1 -------------------

sometimes overlap with some artificial intelligence and

>> Tokens are: 
 ['sometimes', 'overlap', 'artificial', 'intelligence']

>> Bigrams are: 
 [('sometimes', 'overlap'), ('overlap', 'artificial'), ('artificial', 'intelligence')]

>> Trigrams are: 
 [('sometimes', 'overlap', 'artificial'), ('overlap', 'artificial', 'intelligence')]

>> POS Tags are: 
 [('sometimes', 'RB'), ('overlap', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN')]

>> Noun Phrases are: 
 ['overlap artificial intelligence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sometimes', 'sometim'), ('overlap', 'overlap'), ('artificial', 'artifici'), ('intelligence', 'intellig')]

>> Stemming using Snowball Stemmer: 
 [('sometimes', 'sometim'), ('overlap', 'overlap'), ('artificial', 'artifici'), ('intelligence', 'intellig')]

>> Lemmatization: 
 [('sometimes', 'sometimes'), ('overlap', 'overlap'), ('artificial', 'artificial'), ('intelligence', 'intelligence')]



========================================== PARAGRAPH 85 ===========================================

Deep Learning topics. These approaches generally  

------------------- Sentence 1 -------------------

Deep Learning topics.

>> Tokens are: 
 ['Deep', 'Learning', 'topics', '.']

>> Bigrams are: 
 [('Deep', 'Learning'), ('Learning', 'topics'), ('topics', '.')]

>> Trigrams are: 
 [('Deep', 'Learning', 'topics'), ('Learning', 'topics', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('Learning', 'NNP'), ('topics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep Learning topics']

>> Named Entities are: 
 [('PERSON', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('Learning', 'learn'), ('topics', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('Learning', 'learn'), ('topics', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('Learning', 'Learning'), ('topics', 'topic'), ('.', '.')]


------------------- Sentence 2 -------------------

These approaches generally

>> Tokens are: 
 ['These', 'approaches', 'generally']

>> Bigrams are: 
 [('These', 'approaches'), ('approaches', 'generally')]

>> Trigrams are: 
 [('These', 'approaches', 'generally')]

>> POS Tags are: 
 [('These', 'DT'), ('approaches', 'NNS'), ('generally', 'RB')]

>> Noun Phrases are: 
 ['These approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('approaches', 'approach'), ('generally', 'gener')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('approaches', 'approach'), ('generally', 'general')]

>> Lemmatization: 
 [('These', 'These'), ('approaches', 'approach'), ('generally', 'generally')]



========================================== PARAGRAPH 86 ===========================================

adopted recently to perform NLP tasks in most efficient  

------------------- Sentence 1 -------------------

adopted recently to perform NLP tasks in most efficient

>> Tokens are: 
 ['adopted', 'recently', 'perform', 'NLP', 'tasks', 'efficient']

>> Bigrams are: 
 [('adopted', 'recently'), ('recently', 'perform'), ('perform', 'NLP'), ('NLP', 'tasks'), ('tasks', 'efficient')]

>> Trigrams are: 
 [('adopted', 'recently', 'perform'), ('recently', 'perform', 'NLP'), ('perform', 'NLP', 'tasks'), ('NLP', 'tasks', 'efficient')]

>> POS Tags are: 
 [('adopted', 'VBN'), ('recently', 'RB'), ('perform', 'VB'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('efficient', 'NN')]

>> Noun Phrases are: 
 ['NLP tasks efficient']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('adopted', 'adopt'), ('recently', 'recent'), ('perform', 'perform'), ('NLP', 'nlp'), ('tasks', 'task'), ('efficient', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('adopted', 'adopt'), ('recently', 'recent'), ('perform', 'perform'), ('NLP', 'nlp'), ('tasks', 'task'), ('efficient', 'effici')]

>> Lemmatization: 
 [('adopted', 'adopted'), ('recently', 'recently'), ('perform', 'perform'), ('NLP', 'NLP'), ('tasks', 'task'), ('efficient', 'efficient')]



========================================== PARAGRAPH 87 ===========================================

way. The ACL 2018 Main Conference invited papers in  

------------------- Sentence 1 -------------------

way.

>> Tokens are: 
 ['way', '.']

>> Bigrams are: 
 [('way', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('way', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['way']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('way', 'way'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('way', 'way'), ('.', '.')]

>> Lemmatization: 
 [('way', 'way'), ('.', '.')]


------------------- Sentence 2 -------------------

The ACL 2018 Main Conference invited papers in

>> Tokens are: 
 ['The', 'ACL', '2018', 'Main', 'Conference', 'invited', 'papers']

>> Bigrams are: 
 [('The', 'ACL'), ('ACL', '2018'), ('2018', 'Main'), ('Main', 'Conference'), ('Conference', 'invited'), ('invited', 'papers')]

>> Trigrams are: 
 [('The', 'ACL', '2018'), ('ACL', '2018', 'Main'), ('2018', 'Main', 'Conference'), ('Main', 'Conference', 'invited'), ('Conference', 'invited', 'papers')]

>> POS Tags are: 
 [('The', 'DT'), ('ACL', 'NNP'), ('2018', 'CD'), ('Main', 'NNP'), ('Conference', 'NNP'), ('invited', 'VBD'), ('papers', 'NNS')]

>> Noun Phrases are: 
 ['The ACL', 'Main Conference', 'papers']

>> Named Entities are: 
 [('ORGANIZATION', 'ACL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ACL', 'acl'), ('2018', '2018'), ('Main', 'main'), ('Conference', 'confer'), ('invited', 'invit'), ('papers', 'paper')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ACL', 'acl'), ('2018', '2018'), ('Main', 'main'), ('Conference', 'confer'), ('invited', 'invit'), ('papers', 'paper')]

>> Lemmatization: 
 [('The', 'The'), ('ACL', 'ACL'), ('2018', '2018'), ('Main', 'Main'), ('Conference', 'Conference'), ('invited', 'invited'), ('papers', 'paper')]



========================================== PARAGRAPH 88 ===========================================

21areas which are Dialogue and Interactive Systems,  

------------------- Sentence 1 -------------------

21areas which are Dialogue and Interactive Systems,

>> Tokens are: 
 ['21areas', 'Dialogue', 'Interactive', 'Systems', ',']

>> Bigrams are: 
 [('21areas', 'Dialogue'), ('Dialogue', 'Interactive'), ('Interactive', 'Systems'), ('Systems', ',')]

>> Trigrams are: 
 [('21areas', 'Dialogue', 'Interactive'), ('Dialogue', 'Interactive', 'Systems'), ('Interactive', 'Systems', ',')]

>> POS Tags are: 
 [('21areas', 'CD'), ('Dialogue', 'NNP'), ('Interactive', 'NNP'), ('Systems', 'NNPS'), (',', ',')]

>> Noun Phrases are: 
 ['Dialogue Interactive']

>> Named Entities are: 
 [('PERSON', 'Dialogue Interactive Systems')] 

>> Stemming using Porter Stemmer: 
 [('21areas', '21area'), ('Dialogue', 'dialogu'), ('Interactive', 'interact'), ('Systems', 'system'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('21areas', '21area'), ('Dialogue', 'dialogu'), ('Interactive', 'interact'), ('Systems', 'system'), (',', ',')]

>> Lemmatization: 
 [('21areas', '21areas'), ('Dialogue', 'Dialogue'), ('Interactive', 'Interactive'), ('Systems', 'Systems'), (',', ',')]



========================================== PARAGRAPH 89 ===========================================

Discourse and Pragmatics, Document Analysis,  

------------------- Sentence 1 -------------------

Discourse and Pragmatics, Document Analysis,

>> Tokens are: 
 ['Discourse', 'Pragmatics', ',', 'Document', 'Analysis', ',']

>> Bigrams are: 
 [('Discourse', 'Pragmatics'), ('Pragmatics', ','), (',', 'Document'), ('Document', 'Analysis'), ('Analysis', ',')]

>> Trigrams are: 
 [('Discourse', 'Pragmatics', ','), ('Pragmatics', ',', 'Document'), (',', 'Document', 'Analysis'), ('Document', 'Analysis', ',')]

>> POS Tags are: 
 [('Discourse', 'NNP'), ('Pragmatics', 'NNP'), (',', ','), ('Document', 'NNP'), ('Analysis', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Discourse Pragmatics', 'Document Analysis']

>> Named Entities are: 
 [('PERSON', 'Discourse'), ('ORGANIZATION', 'Pragmatics'), ('ORGANIZATION', 'Document Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Discourse', 'discours'), ('Pragmatics', 'pragmat'), (',', ','), ('Document', 'document'), ('Analysis', 'analysi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Discourse', 'discours'), ('Pragmatics', 'pragmat'), (',', ','), ('Document', 'document'), ('Analysis', 'analysi'), (',', ',')]

>> Lemmatization: 
 [('Discourse', 'Discourse'), ('Pragmatics', 'Pragmatics'), (',', ','), ('Document', 'Document'), ('Analysis', 'Analysis'), (',', ',')]



========================================== PARAGRAPH 90 ===========================================

Generation, Information Extraction and Text Mining,  

------------------- Sentence 1 -------------------

Generation, Information Extraction and Text Mining,

>> Tokens are: 
 ['Generation', ',', 'Information', 'Extraction', 'Text', 'Mining', ',']

>> Bigrams are: 
 [('Generation', ','), (',', 'Information'), ('Information', 'Extraction'), ('Extraction', 'Text'), ('Text', 'Mining'), ('Mining', ',')]

>> Trigrams are: 
 [('Generation', ',', 'Information'), (',', 'Information', 'Extraction'), ('Information', 'Extraction', 'Text'), ('Extraction', 'Text', 'Mining'), ('Text', 'Mining', ',')]

>> POS Tags are: 
 [('Generation', 'NNP'), (',', ','), ('Information', 'NNP'), ('Extraction', 'NNP'), ('Text', 'NNP'), ('Mining', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Generation', 'Information Extraction Text Mining']

>> Named Entities are: 
 [('GPE', 'Generation'), ('ORGANIZATION', 'Information Extraction Text Mining')] 

>> Stemming using Porter Stemmer: 
 [('Generation', 'gener'), (',', ','), ('Information', 'inform'), ('Extraction', 'extract'), ('Text', 'text'), ('Mining', 'mine'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Generation', 'generat'), (',', ','), ('Information', 'inform'), ('Extraction', 'extract'), ('Text', 'text'), ('Mining', 'mine'), (',', ',')]

>> Lemmatization: 
 [('Generation', 'Generation'), (',', ','), ('Information', 'Information'), ('Extraction', 'Extraction'), ('Text', 'Text'), ('Mining', 'Mining'), (',', ',')]



========================================== PARAGRAPH 91 ===========================================

Linguistic Theories, Cognitive Modeling and  

------------------- Sentence 1 -------------------

Linguistic Theories, Cognitive Modeling and

>> Tokens are: 
 ['Linguistic', 'Theories', ',', 'Cognitive', 'Modeling']

>> Bigrams are: 
 [('Linguistic', 'Theories'), ('Theories', ','), (',', 'Cognitive'), ('Cognitive', 'Modeling')]

>> Trigrams are: 
 [('Linguistic', 'Theories', ','), ('Theories', ',', 'Cognitive'), (',', 'Cognitive', 'Modeling')]

>> POS Tags are: 
 [('Linguistic', 'JJ'), ('Theories', 'NNS'), (',', ','), ('Cognitive', 'NNP'), ('Modeling', 'NNP')]

>> Noun Phrases are: 
 ['Linguistic Theories', 'Cognitive Modeling']

>> Named Entities are: 
 [('GPE', 'Linguistic'), ('PERSON', 'Cognitive Modeling')] 

>> Stemming using Porter Stemmer: 
 [('Linguistic', 'linguist'), ('Theories', 'theori'), (',', ','), ('Cognitive', 'cognit'), ('Modeling', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Linguistic', 'linguist'), ('Theories', 'theori'), (',', ','), ('Cognitive', 'cognit'), ('Modeling', 'model')]

>> Lemmatization: 
 [('Linguistic', 'Linguistic'), ('Theories', 'Theories'), (',', ','), ('Cognitive', 'Cognitive'), ('Modeling', 'Modeling')]



========================================== PARAGRAPH 92 ===========================================

Psycholinguistics, Machine Learning, Machine  

------------------- Sentence 1 -------------------

Psycholinguistics, Machine Learning, Machine

>> Tokens are: 
 ['Psycholinguistics', ',', 'Machine', 'Learning', ',', 'Machine']

>> Bigrams are: 
 [('Psycholinguistics', ','), (',', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', 'Machine')]

>> Trigrams are: 
 [('Psycholinguistics', ',', 'Machine'), (',', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', 'Machine')]

>> POS Tags are: 
 [('Psycholinguistics', 'NNS'), (',', ','), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('Machine', 'NNP')]

>> Noun Phrases are: 
 ['Psycholinguistics', 'Machine Learning', 'Machine']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Psycholinguistics', 'psycholinguist'), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('Psycholinguistics', 'psycholinguist'), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Machine', 'machin')]

>> Lemmatization: 
 [('Psycholinguistics', 'Psycholinguistics'), (',', ','), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('Machine', 'Machine')]



========================================== PARAGRAPH 93 ===========================================

Translation, Multidisciplinary, Multilinguality,  

------------------- Sentence 1 -------------------

Translation, Multidisciplinary, Multilinguality,

>> Tokens are: 
 ['Translation', ',', 'Multidisciplinary', ',', 'Multilinguality', ',']

>> Bigrams are: 
 [('Translation', ','), (',', 'Multidisciplinary'), ('Multidisciplinary', ','), (',', 'Multilinguality'), ('Multilinguality', ',')]

>> Trigrams are: 
 [('Translation', ',', 'Multidisciplinary'), (',', 'Multidisciplinary', ','), ('Multidisciplinary', ',', 'Multilinguality'), (',', 'Multilinguality', ',')]

>> POS Tags are: 
 [('Translation', 'NN'), (',', ','), ('Multidisciplinary', 'NNP'), (',', ','), ('Multilinguality', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Translation', 'Multidisciplinary', 'Multilinguality']

>> Named Entities are: 
 [('GPE', 'Translation'), ('GPE', 'Multidisciplinary'), ('GPE', 'Multilinguality')] 

>> Stemming using Porter Stemmer: 
 [('Translation', 'translat'), (',', ','), ('Multidisciplinary', 'multidisciplinari'), (',', ','), ('Multilinguality', 'multilingu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Translation', 'translat'), (',', ','), ('Multidisciplinary', 'multidisciplinari'), (',', ','), ('Multilinguality', 'multilingu'), (',', ',')]

>> Lemmatization: 
 [('Translation', 'Translation'), (',', ','), ('Multidisciplinary', 'Multidisciplinary'), (',', ','), ('Multilinguality', 'Multilinguality'), (',', ',')]



========================================== PARAGRAPH 94 ===========================================

Phonology, Morphology and Word Segmentation,  

------------------- Sentence 1 -------------------

Phonology, Morphology and Word Segmentation,

>> Tokens are: 
 ['Phonology', ',', 'Morphology', 'Word', 'Segmentation', ',']

>> Bigrams are: 
 [('Phonology', ','), (',', 'Morphology'), ('Morphology', 'Word'), ('Word', 'Segmentation'), ('Segmentation', ',')]

>> Trigrams are: 
 [('Phonology', ',', 'Morphology'), (',', 'Morphology', 'Word'), ('Morphology', 'Word', 'Segmentation'), ('Word', 'Segmentation', ',')]

>> POS Tags are: 
 [('Phonology', 'NNP'), (',', ','), ('Morphology', 'NNP'), ('Word', 'NNP'), ('Segmentation', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Phonology', 'Morphology Word Segmentation']

>> Named Entities are: 
 [('GPE', 'Phonology'), ('PERSON', 'Morphology Word Segmentation')] 

>> Stemming using Porter Stemmer: 
 [('Phonology', 'phonolog'), (',', ','), ('Morphology', 'morpholog'), ('Word', 'word'), ('Segmentation', 'segment'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Phonology', 'phonolog'), (',', ','), ('Morphology', 'morpholog'), ('Word', 'word'), ('Segmentation', 'segment'), (',', ',')]

>> Lemmatization: 
 [('Phonology', 'Phonology'), (',', ','), ('Morphology', 'Morphology'), ('Word', 'Word'), ('Segmentation', 'Segmentation'), (',', ',')]



========================================== PARAGRAPH 95 ===========================================

Question Answering, Resources and Evaluation,  

------------------- Sentence 1 -------------------

Question Answering, Resources and Evaluation,

>> Tokens are: 
 ['Question', 'Answering', ',', 'Resources', 'Evaluation', ',']

>> Bigrams are: 
 [('Question', 'Answering'), ('Answering', ','), (',', 'Resources'), ('Resources', 'Evaluation'), ('Evaluation', ',')]

>> Trigrams are: 
 [('Question', 'Answering', ','), ('Answering', ',', 'Resources'), (',', 'Resources', 'Evaluation'), ('Resources', 'Evaluation', ',')]

>> POS Tags are: 
 [('Question', 'NN'), ('Answering', 'NNP'), (',', ','), ('Resources', 'NNP'), ('Evaluation', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Question Answering', 'Resources Evaluation']

>> Named Entities are: 
 [('PERSON', 'Resources Evaluation')] 

>> Stemming using Porter Stemmer: 
 [('Question', 'question'), ('Answering', 'answer'), (',', ','), ('Resources', 'resourc'), ('Evaluation', 'evalu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Question', 'question'), ('Answering', 'answer'), (',', ','), ('Resources', 'resourc'), ('Evaluation', 'evalu'), (',', ',')]

>> Lemmatization: 
 [('Question', 'Question'), ('Answering', 'Answering'), (',', ','), ('Resources', 'Resources'), ('Evaluation', 'Evaluation'), (',', ',')]



========================================== PARAGRAPH 96 ===========================================

Sentence-level Semantics, Sentiment Analysis and  

------------------- Sentence 1 -------------------

Sentence-level Semantics, Sentiment Analysis and

>> Tokens are: 
 ['Sentence-level', 'Semantics', ',', 'Sentiment', 'Analysis']

>> Bigrams are: 
 [('Sentence-level', 'Semantics'), ('Semantics', ','), (',', 'Sentiment'), ('Sentiment', 'Analysis')]

>> Trigrams are: 
 [('Sentence-level', 'Semantics', ','), ('Semantics', ',', 'Sentiment'), (',', 'Sentiment', 'Analysis')]

>> POS Tags are: 
 [('Sentence-level', 'JJ'), ('Semantics', 'NNP'), (',', ','), ('Sentiment', 'NNP'), ('Analysis', 'NNP')]

>> Noun Phrases are: 
 ['Sentence-level Semantics', 'Sentiment Analysis']

>> Named Entities are: 
 [('ORGANIZATION', 'Sentiment Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Sentence-level', 'sentence-level'), ('Semantics', 'semant'), (',', ','), ('Sentiment', 'sentiment'), ('Analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Sentence-level', 'sentence-level'), ('Semantics', 'semant'), (',', ','), ('Sentiment', 'sentiment'), ('Analysis', 'analysi')]

>> Lemmatization: 
 [('Sentence-level', 'Sentence-level'), ('Semantics', 'Semantics'), (',', ','), ('Sentiment', 'Sentiment'), ('Analysis', 'Analysis')]



========================================== PARAGRAPH 97 ===========================================

Argument Mining, Social Media, Summarization,   

------------------- Sentence 1 -------------------

Argument Mining, Social Media, Summarization,

>> Tokens are: 
 ['Argument', 'Mining', ',', 'Social', 'Media', ',', 'Summarization', ',']

>> Bigrams are: 
 [('Argument', 'Mining'), ('Mining', ','), (',', 'Social'), ('Social', 'Media'), ('Media', ','), (',', 'Summarization'), ('Summarization', ',')]

>> Trigrams are: 
 [('Argument', 'Mining', ','), ('Mining', ',', 'Social'), (',', 'Social', 'Media'), ('Social', 'Media', ','), ('Media', ',', 'Summarization'), (',', 'Summarization', ',')]

>> POS Tags are: 
 [('Argument', 'NN'), ('Mining', 'NNP'), (',', ','), ('Social', 'NNP'), ('Media', 'NNP'), (',', ','), ('Summarization', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Argument Mining', 'Social Media', 'Summarization']

>> Named Entities are: 
 [('ORGANIZATION', 'Social Media'), ('GPE', 'Summarization')] 

>> Stemming using Porter Stemmer: 
 [('Argument', 'argument'), ('Mining', 'mine'), (',', ','), ('Social', 'social'), ('Media', 'media'), (',', ','), ('Summarization', 'summar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Argument', 'argument'), ('Mining', 'mine'), (',', ','), ('Social', 'social'), ('Media', 'media'), (',', ','), ('Summarization', 'summar'), (',', ',')]

>> Lemmatization: 
 [('Argument', 'Argument'), ('Mining', 'Mining'), (',', ','), ('Social', 'Social'), ('Media', 'Media'), (',', ','), ('Summarization', 'Summarization'), (',', ',')]



========================================== PARAGRAPH 98 ===========================================

  


========================================== PARAGRAPH 99 ===========================================

  


========================================== PARAGRAPH 100 ===========================================

Advances in Natural Language Processing –  

------------------- Sentence 1 -------------------

Advances in Natural Language Processing –

>> Tokens are: 
 ['Advances', 'Natural', 'Language', 'Processing', '–']

>> Bigrams are: 
 [('Advances', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '–')]

>> Trigrams are: 
 [('Advances', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '–')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('–', 'NN')]

>> Noun Phrases are: 
 ['Advances Natural Language Processing –']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('–', '–')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('–', '–')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('–', '–')]



========================================== PARAGRAPH 101 ===========================================

A Survey of Current Research Trends,  

------------------- Sentence 1 -------------------

A Survey of Current Research Trends,

>> Tokens are: 
 ['A', 'Survey', 'Current', 'Research', 'Trends', ',']

>> Bigrams are: 
 [('A', 'Survey'), ('Survey', 'Current'), ('Current', 'Research'), ('Research', 'Trends'), ('Trends', ',')]

>> Trigrams are: 
 [('A', 'Survey', 'Current'), ('Survey', 'Current', 'Research'), ('Current', 'Research', 'Trends'), ('Research', 'Trends', ',')]

>> POS Tags are: 
 [('A', 'DT'), ('Survey', 'NNP'), ('Current', 'NNP'), ('Research', 'NNP'), ('Trends', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['A Survey Current Research Trends']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Survey', 'survey'), ('Current', 'current'), ('Research', 'research'), ('Trends', 'trend'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Survey', 'survey'), ('Current', 'current'), ('Research', 'research'), ('Trends', 'trend'), (',', ',')]

>> Lemmatization: 
 [('A', 'A'), ('Survey', 'Survey'), ('Current', 'Current'), ('Research', 'Research'), ('Trends', 'Trends'), (',', ',')]



========================================== PARAGRAPH 102 ===========================================

Development Tools and Industry  

------------------- Sentence 1 -------------------

Development Tools and Industry

>> Tokens are: 
 ['Development', 'Tools', 'Industry']

>> Bigrams are: 
 [('Development', 'Tools'), ('Tools', 'Industry')]

>> Trigrams are: 
 [('Development', 'Tools', 'Industry')]

>> POS Tags are: 
 [('Development', 'NNP'), ('Tools', 'NNP'), ('Industry', 'NNP')]

>> Noun Phrases are: 
 ['Development Tools Industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Development', 'develop'), ('Tools', 'tool'), ('Industry', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('Development', 'develop'), ('Tools', 'tool'), ('Industry', 'industri')]

>> Lemmatization: 
 [('Development', 'Development'), ('Tools', 'Tools'), ('Industry', 'Industry')]



========================================== PARAGRAPH 103 ===========================================

Applications  Krishna Prakash Kalyanathaya, D. Akila and P. Rajesh  

------------------- Sentence 1 -------------------

Applications  Krishna Prakash Kalyanathaya, D. Akila and P. Rajesh 

>> Tokens are: 
 ['Applications', 'Krishna', 'Prakash', 'Kalyanathaya', ',', 'D.', 'Akila', 'P.', 'Rajesh', '\uf020']

>> Bigrams are: 
 [('Applications', 'Krishna'), ('Krishna', 'Prakash'), ('Prakash', 'Kalyanathaya'), ('Kalyanathaya', ','), (',', 'D.'), ('D.', 'Akila'), ('Akila', 'P.'), ('P.', 'Rajesh'), ('Rajesh', '\uf020')]

>> Trigrams are: 
 [('Applications', 'Krishna', 'Prakash'), ('Krishna', 'Prakash', 'Kalyanathaya'), ('Prakash', 'Kalyanathaya', ','), ('Kalyanathaya', ',', 'D.'), (',', 'D.', 'Akila'), ('D.', 'Akila', 'P.'), ('Akila', 'P.', 'Rajesh'), ('P.', 'Rajesh', '\uf020')]

>> POS Tags are: 
 [('Applications', 'NNS'), ('Krishna', 'NNP'), ('Prakash', 'NNP'), ('Kalyanathaya', 'NNP'), (',', ','), ('D.', 'NNP'), ('Akila', 'NNP'), ('P.', 'NNP'), ('Rajesh', 'NNP'), ('\uf020', 'NN')]

>> Noun Phrases are: 
 ['Applications Krishna Prakash Kalyanathaya', 'D. Akila P. Rajesh \uf020']

>> Named Entities are: 
 [('PERSON', 'Krishna Prakash Kalyanathaya'), ('PERSON', 'Akila P. Rajesh')] 

>> Stemming using Porter Stemmer: 
 [('Applications', 'applic'), ('Krishna', 'krishna'), ('Prakash', 'prakash'), ('Kalyanathaya', 'kalyanathaya'), (',', ','), ('D.', 'd.'), ('Akila', 'akila'), ('P.', 'p.'), ('Rajesh', 'rajesh'), ('\uf020', '\uf020')]

>> Stemming using Snowball Stemmer: 
 [('Applications', 'applic'), ('Krishna', 'krishna'), ('Prakash', 'prakash'), ('Kalyanathaya', 'kalyanathaya'), (',', ','), ('D.', 'd.'), ('Akila', 'akila'), ('P.', 'p.'), ('Rajesh', 'rajesh'), ('\uf020', '\uf020')]

>> Lemmatization: 
 [('Applications', 'Applications'), ('Krishna', 'Krishna'), ('Prakash', 'Prakash'), ('Kalyanathaya', 'Kalyanathaya'), (',', ','), ('D.', 'D.'), ('Akila', 'Akila'), ('P.', 'P.'), ('Rajesh', 'Rajesh'), ('\uf020', '\uf020')]



========================================== PARAGRAPH 104 ===========================================

International Conference on Advances in Signal Processing, Power, Embedded, Soft Computing, Communication and  

------------------- Sentence 1 -------------------

International Conference on Advances in Signal Processing, Power, Embedded, Soft Computing, Communication and

>> Tokens are: 
 ['International', 'Conference', 'Advances', 'Signal', 'Processing', ',', 'Power', ',', 'Embedded', ',', 'Soft', 'Computing', ',', 'Communication']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Advances'), ('Advances', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'Power'), ('Power', ','), (',', 'Embedded'), ('Embedded', ','), (',', 'Soft'), ('Soft', 'Computing'), ('Computing', ','), (',', 'Communication')]

>> Trigrams are: 
 [('International', 'Conference', 'Advances'), ('Conference', 'Advances', 'Signal'), ('Advances', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'Power'), (',', 'Power', ','), ('Power', ',', 'Embedded'), (',', 'Embedded', ','), ('Embedded', ',', 'Soft'), (',', 'Soft', 'Computing'), ('Soft', 'Computing', ','), ('Computing', ',', 'Communication')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Advances', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('Power', 'NNP'), (',', ','), ('Embedded', 'NNP'), (',', ','), ('Soft', 'NNP'), ('Computing', 'NNP'), (',', ','), ('Communication', 'NNP')]

>> Noun Phrases are: 
 ['International Conference Advances Signal Processing', 'Power', 'Embedded', 'Soft Computing', 'Communication']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Advances Signal'), ('PERSON', 'Power'), ('GPE', 'Embedded'), ('PERSON', 'Soft Computing'), ('ORGANIZATION', 'Communication')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('Power', 'power'), (',', ','), ('Embedded', 'embed'), (',', ','), ('Soft', 'soft'), ('Computing', 'comput'), (',', ','), ('Communication', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('Power', 'power'), (',', ','), ('Embedded', 'embed'), (',', ','), ('Soft', 'soft'), ('Computing', 'comput'), (',', ','), ('Communication', 'communic')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Advances', 'Advances'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('Power', 'Power'), (',', ','), ('Embedded', 'Embedded'), (',', ','), ('Soft', 'Soft'), ('Computing', 'Computing'), (',', ','), ('Communication', 'Communication')]



========================================== PARAGRAPH 105 ===========================================

Control Systems (ICSPECS-2019) | 11th & 12th January 2019 | GPREC, Kurnool, A.P. India  

------------------- Sentence 1 -------------------

Control Systems (ICSPECS-2019) | 11th & 12th January 2019 | GPREC, Kurnool, A.P.

>> Tokens are: 
 ['Control', 'Systems', '(', 'ICSPECS-2019', ')', '|', '11th', '&', '12th', 'January', '2019', '|', 'GPREC', ',', 'Kurnool', ',', 'A.P', '.']

>> Bigrams are: 
 [('Control', 'Systems'), ('Systems', '('), ('(', 'ICSPECS-2019'), ('ICSPECS-2019', ')'), (')', '|'), ('|', '11th'), ('11th', '&'), ('&', '12th'), ('12th', 'January'), ('January', '2019'), ('2019', '|'), ('|', 'GPREC'), ('GPREC', ','), (',', 'Kurnool'), ('Kurnool', ','), (',', 'A.P'), ('A.P', '.')]

>> Trigrams are: 
 [('Control', 'Systems', '('), ('Systems', '(', 'ICSPECS-2019'), ('(', 'ICSPECS-2019', ')'), ('ICSPECS-2019', ')', '|'), (')', '|', '11th'), ('|', '11th', '&'), ('11th', '&', '12th'), ('&', '12th', 'January'), ('12th', 'January', '2019'), ('January', '2019', '|'), ('2019', '|', 'GPREC'), ('|', 'GPREC', ','), ('GPREC', ',', 'Kurnool'), (',', 'Kurnool', ','), ('Kurnool', ',', 'A.P'), (',', 'A.P', '.')]

>> POS Tags are: 
 [('Control', 'NNP'), ('Systems', 'NNP'), ('(', '('), ('ICSPECS-2019', 'NNP'), (')', ')'), ('|', 'VBZ'), ('11th', 'CD'), ('&', 'CC'), ('12th', 'CD'), ('January', 'NNP'), ('2019', 'CD'), ('|', 'NNP'), ('GPREC', 'NNP'), (',', ','), ('Kurnool', 'NNP'), (',', ','), ('A.P', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Control Systems', 'ICSPECS-2019', 'January', '| GPREC', 'Kurnool', 'A.P']

>> Named Entities are: 
 [('PERSON', 'Control'), ('ORGANIZATION', 'Systems'), ('PERSON', 'Kurnool')] 

>> Stemming using Porter Stemmer: 
 [('Control', 'control'), ('Systems', 'system'), ('(', '('), ('ICSPECS-2019', 'icspecs-2019'), (')', ')'), ('|', '|'), ('11th', '11th'), ('&', '&'), ('12th', '12th'), ('January', 'januari'), ('2019', '2019'), ('|', '|'), ('GPREC', 'gprec'), (',', ','), ('Kurnool', 'kurnool'), (',', ','), ('A.P', 'a.p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Control', 'control'), ('Systems', 'system'), ('(', '('), ('ICSPECS-2019', 'icspecs-2019'), (')', ')'), ('|', '|'), ('11th', '11th'), ('&', '&'), ('12th', '12th'), ('January', 'januari'), ('2019', '2019'), ('|', '|'), ('GPREC', 'gprec'), (',', ','), ('Kurnool', 'kurnool'), (',', ','), ('A.P', 'a.p'), ('.', '.')]

>> Lemmatization: 
 [('Control', 'Control'), ('Systems', 'Systems'), ('(', '('), ('ICSPECS-2019', 'ICSPECS-2019'), (')', ')'), ('|', '|'), ('11th', '11th'), ('&', '&'), ('12th', '12th'), ('January', 'January'), ('2019', '2019'), ('|', '|'), ('GPREC', 'GPREC'), (',', ','), ('Kurnool', 'Kurnool'), (',', ','), ('A.P', 'A.P'), ('.', '.')]


------------------- Sentence 2 -------------------

India

>> Tokens are: 
 ['India']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('India', 'NNP')]

>> Noun Phrases are: 
 ['India']

>> Named Entities are: 
 [('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('India', 'india')]

>> Stemming using Snowball Stemmer: 
 [('India', 'india')]

>> Lemmatization: 
 [('India', 'India')]



========================================== PARAGRAPH 106 ===========================================

  


========================================== PARAGRAPH 107 ===========================================

200  

------------------- Sentence 1 -------------------

200

>> Tokens are: 
 ['200']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('200', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('200', '200')]

>> Stemming using Snowball Stemmer: 
 [('200', '200')]

>> Lemmatization: 
 [('200', '200')]



========================================== PARAGRAPH 108 ===========================================

Published By:  Blue Eyes Intelligence Engineering  

------------------- Sentence 1 -------------------

Published By:  Blue Eyes Intelligence Engineering

>> Tokens are: 
 ['Published', 'By', ':', 'Blue', 'Eyes', 'Intelligence', 'Engineering']

>> Bigrams are: 
 [('Published', 'By'), ('By', ':'), (':', 'Blue'), ('Blue', 'Eyes'), ('Eyes', 'Intelligence'), ('Intelligence', 'Engineering')]

>> Trigrams are: 
 [('Published', 'By', ':'), ('By', ':', 'Blue'), (':', 'Blue', 'Eyes'), ('Blue', 'Eyes', 'Intelligence'), ('Eyes', 'Intelligence', 'Engineering')]

>> POS Tags are: 
 [('Published', 'VBN'), ('By', 'IN'), (':', ':'), ('Blue', 'JJ'), ('Eyes', 'NNS'), ('Intelligence', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['Blue Eyes Intelligence Engineering']

>> Named Entities are: 
 [('ORGANIZATION', 'Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('Published', 'Published'), ('By', 'By'), (':', ':'), ('Blue', 'Blue'), ('Eyes', 'Eyes'), ('Intelligence', 'Intelligence'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 109 ===========================================

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP  

------------------- Sentence 1 -------------------

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP

>> Tokens are: 
 ['&', 'Sciences', 'Publication', 'Retrieval', 'Number', ':', 'E10480275C19/19©BEIESP']

>> Bigrams are: 
 [('&', 'Sciences'), ('Sciences', 'Publication'), ('Publication', 'Retrieval'), ('Retrieval', 'Number'), ('Number', ':'), (':', 'E10480275C19/19©BEIESP')]

>> Trigrams are: 
 [('&', 'Sciences', 'Publication'), ('Sciences', 'Publication', 'Retrieval'), ('Publication', 'Retrieval', 'Number'), ('Retrieval', 'Number', ':'), ('Number', ':', 'E10480275C19/19©BEIESP')]

>> POS Tags are: 
 [('&', 'CC'), ('Sciences', 'NNPS'), ('Publication', 'NNP'), ('Retrieval', 'NNP'), ('Number', 'NNP'), (':', ':'), ('E10480275C19/19©BEIESP', 'NN')]

>> Noun Phrases are: 
 ['Publication Retrieval Number', 'E10480275C19/19©BEIESP']

>> Named Entities are: 
 [('ORGANIZATION', 'Sciences Publication Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Lemmatization: 
 [('&', '&'), ('Sciences', 'Sciences'), ('Publication', 'Publication'), ('Retrieval', 'Retrieval'), ('Number', 'Number'), (':', ':'), ('E10480275C19/19©BEIESP', 'E10480275C19/19©BEIESP')]



========================================== PARAGRAPH 110 ===========================================

Tagging, Chunking, Syntax and Parsing, Textual  

------------------- Sentence 1 -------------------

Tagging, Chunking, Syntax and Parsing, Textual

>> Tokens are: 
 ['Tagging', ',', 'Chunking', ',', 'Syntax', 'Parsing', ',', 'Textual']

>> Bigrams are: 
 [('Tagging', ','), (',', 'Chunking'), ('Chunking', ','), (',', 'Syntax'), ('Syntax', 'Parsing'), ('Parsing', ','), (',', 'Textual')]

>> Trigrams are: 
 [('Tagging', ',', 'Chunking'), (',', 'Chunking', ','), ('Chunking', ',', 'Syntax'), (',', 'Syntax', 'Parsing'), ('Syntax', 'Parsing', ','), ('Parsing', ',', 'Textual')]

>> POS Tags are: 
 [('Tagging', 'NN'), (',', ','), ('Chunking', 'NNP'), (',', ','), ('Syntax', 'NNP'), ('Parsing', 'NNP'), (',', ','), ('Textual', 'NNP')]

>> Noun Phrases are: 
 ['Tagging', 'Chunking', 'Syntax Parsing', 'Textual']

>> Named Entities are: 
 [('GPE', 'Tagging'), ('GPE', 'Chunking'), ('PERSON', 'Syntax Parsing'), ('PERSON', 'Textual')] 

>> Stemming using Porter Stemmer: 
 [('Tagging', 'tag'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Syntax', 'syntax'), ('Parsing', 'pars'), (',', ','), ('Textual', 'textual')]

>> Stemming using Snowball Stemmer: 
 [('Tagging', 'tag'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Syntax', 'syntax'), ('Parsing', 'pars'), (',', ','), ('Textual', 'textual')]

>> Lemmatization: 
 [('Tagging', 'Tagging'), (',', ','), ('Chunking', 'Chunking'), (',', ','), ('Syntax', 'Syntax'), ('Parsing', 'Parsing'), (',', ','), ('Textual', 'Textual')]



========================================== PARAGRAPH 111 ===========================================

Inference and Other Areas of Semantics, Vision,  

------------------- Sentence 1 -------------------

Inference and Other Areas of Semantics, Vision,

>> Tokens are: 
 ['Inference', 'Other', 'Areas', 'Semantics', ',', 'Vision', ',']

>> Bigrams are: 
 [('Inference', 'Other'), ('Other', 'Areas'), ('Areas', 'Semantics'), ('Semantics', ','), (',', 'Vision'), ('Vision', ',')]

>> Trigrams are: 
 [('Inference', 'Other', 'Areas'), ('Other', 'Areas', 'Semantics'), ('Areas', 'Semantics', ','), ('Semantics', ',', 'Vision'), (',', 'Vision', ',')]

>> POS Tags are: 
 [('Inference', 'NNP'), ('Other', 'JJ'), ('Areas', 'NNP'), ('Semantics', 'NNP'), (',', ','), ('Vision', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Inference', 'Other Areas Semantics', 'Vision']

>> Named Entities are: 
 [('GPE', 'Inference'), ('PERSON', 'Areas Semantics'), ('GPE', 'Vision')] 

>> Stemming using Porter Stemmer: 
 [('Inference', 'infer'), ('Other', 'other'), ('Areas', 'area'), ('Semantics', 'semant'), (',', ','), ('Vision', 'vision'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Inference', 'infer'), ('Other', 'other'), ('Areas', 'area'), ('Semantics', 'semant'), (',', ','), ('Vision', 'vision'), (',', ',')]

>> Lemmatization: 
 [('Inference', 'Inference'), ('Other', 'Other'), ('Areas', 'Areas'), ('Semantics', 'Semantics'), (',', ','), ('Vision', 'Vision'), (',', ',')]



========================================== PARAGRAPH 112 ===========================================

Robotics, Multimodal, Grounding and Speech, Word- 

------------------- Sentence 1 -------------------

Robotics, Multimodal, Grounding and Speech, Word-

>> Tokens are: 
 ['Robotics', ',', 'Multimodal', ',', 'Grounding', 'Speech', ',', 'Word-']

>> Bigrams are: 
 [('Robotics', ','), (',', 'Multimodal'), ('Multimodal', ','), (',', 'Grounding'), ('Grounding', 'Speech'), ('Speech', ','), (',', 'Word-')]

>> Trigrams are: 
 [('Robotics', ',', 'Multimodal'), (',', 'Multimodal', ','), ('Multimodal', ',', 'Grounding'), (',', 'Grounding', 'Speech'), ('Grounding', 'Speech', ','), ('Speech', ',', 'Word-')]

>> POS Tags are: 
 [('Robotics', 'NNS'), (',', ','), ('Multimodal', 'NNP'), (',', ','), ('Grounding', 'NNP'), ('Speech', 'NNP'), (',', ','), ('Word-', 'NNP')]

>> Noun Phrases are: 
 ['Robotics', 'Multimodal', 'Grounding Speech', 'Word-']

>> Named Entities are: 
 [('PERSON', 'Multimodal')] 

>> Stemming using Porter Stemmer: 
 [('Robotics', 'robot'), (',', ','), ('Multimodal', 'multimod'), (',', ','), ('Grounding', 'ground'), ('Speech', 'speech'), (',', ','), ('Word-', 'word-')]

>> Stemming using Snowball Stemmer: 
 [('Robotics', 'robot'), (',', ','), ('Multimodal', 'multimod'), (',', ','), ('Grounding', 'ground'), ('Speech', 'speech'), (',', ','), ('Word-', 'word-')]

>> Lemmatization: 
 [('Robotics', 'Robotics'), (',', ','), ('Multimodal', 'Multimodal'), (',', ','), ('Grounding', 'Grounding'), ('Speech', 'Speech'), (',', ','), ('Word-', 'Word-')]



========================================== PARAGRAPH 113 ===========================================

level Semantics [3][4]. The conference accepted 258 long  

------------------- Sentence 1 -------------------

level Semantics [3][4].

>> Tokens are: 
 ['level', 'Semantics', '[', '3', ']', '[', '4', ']', '.']

>> Bigrams are: 
 [('level', 'Semantics'), ('Semantics', '['), ('[', '3'), ('3', ']'), (']', '['), ('[', '4'), ('4', ']'), (']', '.')]

>> Trigrams are: 
 [('level', 'Semantics', '['), ('Semantics', '[', '3'), ('[', '3', ']'), ('3', ']', '['), (']', '[', '4'), ('[', '4', ']'), ('4', ']', '.')]

>> POS Tags are: 
 [('level', 'NN'), ('Semantics', 'NNPS'), ('[', '$'), ('3', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('4', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['level', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('level', 'level'), ('Semantics', 'semant'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('level', 'level'), ('Semantics', 'semant'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('level', 'level'), ('Semantics', 'Semantics'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The conference accepted 258 long

>> Tokens are: 
 ['The', 'conference', 'accepted', '258', 'long']

>> Bigrams are: 
 [('The', 'conference'), ('conference', 'accepted'), ('accepted', '258'), ('258', 'long')]

>> Trigrams are: 
 [('The', 'conference', 'accepted'), ('conference', 'accepted', '258'), ('accepted', '258', 'long')]

>> POS Tags are: 
 [('The', 'DT'), ('conference', 'NN'), ('accepted', 'VBD'), ('258', 'CD'), ('long', 'JJ')]

>> Noun Phrases are: 
 ['The conference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('conference', 'confer'), ('accepted', 'accept'), ('258', '258'), ('long', 'long')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('conference', 'confer'), ('accepted', 'accept'), ('258', '258'), ('long', 'long')]

>> Lemmatization: 
 [('The', 'The'), ('conference', 'conference'), ('accepted', 'accepted'), ('258', '258'), ('long', 'long')]



========================================== PARAGRAPH 114 ===========================================

papers and 156 short papers on the above areas.  

------------------- Sentence 1 -------------------

papers and 156 short papers on the above areas.

>> Tokens are: 
 ['papers', '156', 'short', 'papers', 'areas', '.']

>> Bigrams are: 
 [('papers', '156'), ('156', 'short'), ('short', 'papers'), ('papers', 'areas'), ('areas', '.')]

>> Trigrams are: 
 [('papers', '156', 'short'), ('156', 'short', 'papers'), ('short', 'papers', 'areas'), ('papers', 'areas', '.')]

>> POS Tags are: 
 [('papers', 'NNS'), ('156', 'CD'), ('short', 'JJ'), ('papers', 'NNS'), ('areas', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['papers', 'short papers areas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('papers', 'paper'), ('156', '156'), ('short', 'short'), ('papers', 'paper'), ('areas', 'area'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('papers', 'paper'), ('156', '156'), ('short', 'short'), ('papers', 'paper'), ('areas', 'area'), ('.', '.')]

>> Lemmatization: 
 [('papers', 'paper'), ('156', '156'), ('short', 'short'), ('papers', 'paper'), ('areas', 'area'), ('.', '.')]



========================================== PARAGRAPH 115 ===========================================

IV. INDUSTRIAL APPLICATIONS OF  NLP  

------------------- Sentence 1 -------------------

IV.

>> Tokens are: 
 ['IV', '.']

>> Bigrams are: 
 [('IV', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IV', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IV']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Lemmatization: 
 [('IV', 'IV'), ('.', '.')]


------------------- Sentence 2 -------------------

INDUSTRIAL APPLICATIONS OF  NLP

>> Tokens are: 
 ['INDUSTRIAL', 'APPLICATIONS', 'OF', 'NLP']

>> Bigrams are: 
 [('INDUSTRIAL', 'APPLICATIONS'), ('APPLICATIONS', 'OF'), ('OF', 'NLP')]

>> Trigrams are: 
 [('INDUSTRIAL', 'APPLICATIONS', 'OF'), ('APPLICATIONS', 'OF', 'NLP')]

>> POS Tags are: 
 [('INDUSTRIAL', 'NNP'), ('APPLICATIONS', 'NNP'), ('OF', 'NNP'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['INDUSTRIAL APPLICATIONS OF NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'INDUSTRIAL'), ('ORGANIZATION', 'APPLICATIONS OF')] 

>> Stemming using Porter Stemmer: 
 [('INDUSTRIAL', 'industri'), ('APPLICATIONS', 'applic'), ('OF', 'of'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('INDUSTRIAL', 'industri'), ('APPLICATIONS', 'applic'), ('OF', 'of'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('INDUSTRIAL', 'INDUSTRIAL'), ('APPLICATIONS', 'APPLICATIONS'), ('OF', 'OF'), ('NLP', 'NLP')]



========================================== PARAGRAPH 116 ===========================================

NLP aims to dominate human-to-machine interaction  

------------------- Sentence 1 -------------------

NLP aims to dominate human-to-machine interaction

>> Tokens are: 
 ['NLP', 'aims', 'dominate', 'human-to-machine', 'interaction']

>> Bigrams are: 
 [('NLP', 'aims'), ('aims', 'dominate'), ('dominate', 'human-to-machine'), ('human-to-machine', 'interaction')]

>> Trigrams are: 
 [('NLP', 'aims', 'dominate'), ('aims', 'dominate', 'human-to-machine'), ('dominate', 'human-to-machine', 'interaction')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('aims', 'NNS'), ('dominate', 'VBP'), ('human-to-machine', 'JJ'), ('interaction', 'NN')]

>> Noun Phrases are: 
 ['NLP aims', 'human-to-machine interaction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('aims', 'aim'), ('dominate', 'domin'), ('human-to-machine', 'human-to-machin'), ('interaction', 'interact')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('aims', 'aim'), ('dominate', 'domin'), ('human-to-machine', 'human-to-machin'), ('interaction', 'interact')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('aims', 'aim'), ('dominate', 'dominate'), ('human-to-machine', 'human-to-machine'), ('interaction', 'interaction')]



========================================== PARAGRAPH 117 ===========================================

to the point where talking to a machine is as easy as  

------------------- Sentence 1 -------------------

to the point where talking to a machine is as easy as

>> Tokens are: 
 ['point', 'talking', 'machine', 'easy']

>> Bigrams are: 
 [('point', 'talking'), ('talking', 'machine'), ('machine', 'easy')]

>> Trigrams are: 
 [('point', 'talking', 'machine'), ('talking', 'machine', 'easy')]

>> POS Tags are: 
 [('point', 'NN'), ('talking', 'VBG'), ('machine', 'NN'), ('easy', 'NN')]

>> Noun Phrases are: 
 ['point', 'machine easy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('point', 'point'), ('talking', 'talk'), ('machine', 'machin'), ('easy', 'easi')]

>> Stemming using Snowball Stemmer: 
 [('point', 'point'), ('talking', 'talk'), ('machine', 'machin'), ('easy', 'easi')]

>> Lemmatization: 
 [('point', 'point'), ('talking', 'talking'), ('machine', 'machine'), ('easy', 'easy')]



========================================== PARAGRAPH 118 ===========================================

talking to a human. NLP still continues to harness  

------------------- Sentence 1 -------------------

talking to a human.

>> Tokens are: 
 ['talking', 'human', '.']

>> Bigrams are: 
 [('talking', 'human'), ('human', '.')]

>> Trigrams are: 
 [('talking', 'human', '.')]

>> POS Tags are: 
 [('talking', 'VBG'), ('human', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('talking', 'talk'), ('human', 'human'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('talking', 'talk'), ('human', 'human'), ('.', '.')]

>> Lemmatization: 
 [('talking', 'talking'), ('human', 'human'), ('.', '.')]


------------------- Sentence 2 -------------------

NLP still continues to harness

>> Tokens are: 
 ['NLP', 'still', 'continues', 'harness']

>> Bigrams are: 
 [('NLP', 'still'), ('still', 'continues'), ('continues', 'harness')]

>> Trigrams are: 
 [('NLP', 'still', 'continues'), ('still', 'continues', 'harness')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('still', 'RB'), ('continues', 'VBZ'), ('harness', 'NN')]

>> Noun Phrases are: 
 ['NLP', 'harness']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('still', 'still'), ('continues', 'continu'), ('harness', 'har')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('still', 'still'), ('continues', 'continu'), ('harness', 'har')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('still', 'still'), ('continues', 'continues'), ('harness', 'harness')]



========================================== PARAGRAPH 119 ===========================================

unstructured data and make it meaningful to a machine.  

------------------- Sentence 1 -------------------

unstructured data and make it meaningful to a machine.

>> Tokens are: 
 ['unstructured', 'data', 'make', 'meaningful', 'machine', '.']

>> Bigrams are: 
 [('unstructured', 'data'), ('data', 'make'), ('make', 'meaningful'), ('meaningful', 'machine'), ('machine', '.')]

>> Trigrams are: 
 [('unstructured', 'data', 'make'), ('data', 'make', 'meaningful'), ('make', 'meaningful', 'machine'), ('meaningful', 'machine', '.')]

>> POS Tags are: 
 [('unstructured', 'JJ'), ('data', 'NNS'), ('make', 'VBP'), ('meaningful', 'JJ'), ('machine', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['unstructured data', 'meaningful machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unstructured', 'unstructur'), ('data', 'data'), ('make', 'make'), ('meaningful', 'meaning'), ('machine', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unstructured', 'unstructur'), ('data', 'data'), ('make', 'make'), ('meaningful', 'meaning'), ('machine', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('unstructured', 'unstructured'), ('data', 'data'), ('make', 'make'), ('meaningful', 'meaningful'), ('machine', 'machine'), ('.', '.')]



========================================== PARAGRAPH 120 ===========================================

IDC recently forecasted that the quantity of analyzed data  

------------------- Sentence 1 -------------------

IDC recently forecasted that the quantity of analyzed data

>> Tokens are: 
 ['IDC', 'recently', 'forecasted', 'quantity', 'analyzed', 'data']

>> Bigrams are: 
 [('IDC', 'recently'), ('recently', 'forecasted'), ('forecasted', 'quantity'), ('quantity', 'analyzed'), ('analyzed', 'data')]

>> Trigrams are: 
 [('IDC', 'recently', 'forecasted'), ('recently', 'forecasted', 'quantity'), ('forecasted', 'quantity', 'analyzed'), ('quantity', 'analyzed', 'data')]

>> POS Tags are: 
 [('IDC', 'NNP'), ('recently', 'RB'), ('forecasted', 'VBD'), ('quantity', 'NN'), ('analyzed', 'VBN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['IDC', 'quantity', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IDC', 'idc'), ('recently', 'recent'), ('forecasted', 'forecast'), ('quantity', 'quantiti'), ('analyzed', 'analyz'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('IDC', 'idc'), ('recently', 'recent'), ('forecasted', 'forecast'), ('quantity', 'quantiti'), ('analyzed', 'analyz'), ('data', 'data')]

>> Lemmatization: 
 [('IDC', 'IDC'), ('recently', 'recently'), ('forecasted', 'forecasted'), ('quantity', 'quantity'), ('analyzed', 'analyzed'), ('data', 'data')]



========================================== PARAGRAPH 121 ===========================================

by cognitive systems will grow by a factor of 100 to 1.4  

------------------- Sentence 1 -------------------

by cognitive systems will grow by a factor of 100 to 1.4

>> Tokens are: 
 ['cognitive', 'systems', 'grow', 'factor', '100', '1.4']

>> Bigrams are: 
 [('cognitive', 'systems'), ('systems', 'grow'), ('grow', 'factor'), ('factor', '100'), ('100', '1.4')]

>> Trigrams are: 
 [('cognitive', 'systems', 'grow'), ('systems', 'grow', 'factor'), ('grow', 'factor', '100'), ('factor', '100', '1.4')]

>> POS Tags are: 
 [('cognitive', 'JJ'), ('systems', 'NNS'), ('grow', 'VBP'), ('factor', 'NN'), ('100', 'CD'), ('1.4', 'CD')]

>> Noun Phrases are: 
 ['cognitive systems', 'factor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cognitive', 'cognit'), ('systems', 'system'), ('grow', 'grow'), ('factor', 'factor'), ('100', '100'), ('1.4', '1.4')]

>> Stemming using Snowball Stemmer: 
 [('cognitive', 'cognit'), ('systems', 'system'), ('grow', 'grow'), ('factor', 'factor'), ('100', '100'), ('1.4', '1.4')]

>> Lemmatization: 
 [('cognitive', 'cognitive'), ('systems', 'system'), ('grow', 'grow'), ('factor', 'factor'), ('100', '100'), ('1.4', '1.4')]



========================================== PARAGRAPH 122 ===========================================

ZB by 2025 impacting thousands of industries and  

------------------- Sentence 1 -------------------

ZB by 2025 impacting thousands of industries and

>> Tokens are: 
 ['ZB', '2025', 'impacting', 'thousands', 'industries']

>> Bigrams are: 
 [('ZB', '2025'), ('2025', 'impacting'), ('impacting', 'thousands'), ('thousands', 'industries')]

>> Trigrams are: 
 [('ZB', '2025', 'impacting'), ('2025', 'impacting', 'thousands'), ('impacting', 'thousands', 'industries')]

>> POS Tags are: 
 [('ZB', 'JJ'), ('2025', 'CD'), ('impacting', 'VBG'), ('thousands', 'NNS'), ('industries', 'NNS')]

>> Noun Phrases are: 
 ['thousands industries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ZB', 'zb'), ('2025', '2025'), ('impacting', 'impact'), ('thousands', 'thousand'), ('industries', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('ZB', 'zb'), ('2025', '2025'), ('impacting', 'impact'), ('thousands', 'thousand'), ('industries', 'industri')]

>> Lemmatization: 
 [('ZB', 'ZB'), ('2025', '2025'), ('impacting', 'impacting'), ('thousands', 'thousand'), ('industries', 'industry')]



========================================== PARAGRAPH 123 ===========================================

companies around the globe [2]. Robotics, health care,  

------------------- Sentence 1 -------------------

companies around the globe [2].

>> Tokens are: 
 ['companies', 'around', 'globe', '[', '2', ']', '.']

>> Bigrams are: 
 [('companies', 'around'), ('around', 'globe'), ('globe', '['), ('[', '2'), ('2', ']'), (']', '.')]

>> Trigrams are: 
 [('companies', 'around', 'globe'), ('around', 'globe', '['), ('globe', '[', '2'), ('[', '2', ']'), ('2', ']', '.')]

>> POS Tags are: 
 [('companies', 'NNS'), ('around', 'IN'), ('globe', 'NN'), ('[', '$'), ('2', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['companies', 'globe', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('companies', 'compani'), ('around', 'around'), ('globe', 'globe'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('companies', 'compani'), ('around', 'around'), ('globe', 'globe'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('companies', 'company'), ('around', 'around'), ('globe', 'globe'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Robotics, health care,

>> Tokens are: 
 ['Robotics', ',', 'health', 'care', ',']

>> Bigrams are: 
 [('Robotics', ','), (',', 'health'), ('health', 'care'), ('care', ',')]

>> Trigrams are: 
 [('Robotics', ',', 'health'), (',', 'health', 'care'), ('health', 'care', ',')]

>> POS Tags are: 
 [('Robotics', 'NNS'), (',', ','), ('health', 'NN'), ('care', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Robotics', 'health care']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Robotics', 'robot'), (',', ','), ('health', 'health'), ('care', 'care'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Robotics', 'robot'), (',', ','), ('health', 'health'), ('care', 'care'), (',', ',')]

>> Lemmatization: 
 [('Robotics', 'Robotics'), (',', ','), ('health', 'health'), ('care', 'care'), (',', ',')]



========================================== PARAGRAPH 124 ===========================================

financial services, connected auto and smart homes are  

------------------- Sentence 1 -------------------

financial services, connected auto and smart homes are

>> Tokens are: 
 ['financial', 'services', ',', 'connected', 'auto', 'smart', 'homes']

>> Bigrams are: 
 [('financial', 'services'), ('services', ','), (',', 'connected'), ('connected', 'auto'), ('auto', 'smart'), ('smart', 'homes')]

>> Trigrams are: 
 [('financial', 'services', ','), ('services', ',', 'connected'), (',', 'connected', 'auto'), ('connected', 'auto', 'smart'), ('auto', 'smart', 'homes')]

>> POS Tags are: 
 [('financial', 'JJ'), ('services', 'NNS'), (',', ','), ('connected', 'JJ'), ('auto', 'NN'), ('smart', 'JJ'), ('homes', 'NNS')]

>> Noun Phrases are: 
 ['financial services', 'connected auto', 'smart homes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('financial', 'financi'), ('services', 'servic'), (',', ','), ('connected', 'connect'), ('auto', 'auto'), ('smart', 'smart'), ('homes', 'home')]

>> Stemming using Snowball Stemmer: 
 [('financial', 'financi'), ('services', 'servic'), (',', ','), ('connected', 'connect'), ('auto', 'auto'), ('smart', 'smart'), ('homes', 'home')]

>> Lemmatization: 
 [('financial', 'financial'), ('services', 'service'), (',', ','), ('connected', 'connected'), ('auto', 'auto'), ('smart', 'smart'), ('homes', 'home')]



========================================== PARAGRAPH 125 ===========================================

some of the sectors that will continue to be advanced by  

------------------- Sentence 1 -------------------

some of the sectors that will continue to be advanced by

>> Tokens are: 
 ['sectors', 'continue', 'advanced']

>> Bigrams are: 
 [('sectors', 'continue'), ('continue', 'advanced')]

>> Trigrams are: 
 [('sectors', 'continue', 'advanced')]

>> POS Tags are: 
 [('sectors', 'NNS'), ('continue', 'VBP'), ('advanced', 'VBD')]

>> Noun Phrases are: 
 ['sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sectors', 'sector'), ('continue', 'continu'), ('advanced', 'advanc')]

>> Stemming using Snowball Stemmer: 
 [('sectors', 'sector'), ('continue', 'continu'), ('advanced', 'advanc')]

>> Lemmatization: 
 [('sectors', 'sector'), ('continue', 'continue'), ('advanced', 'advanced')]



========================================== PARAGRAPH 126 ===========================================

NLP.   

------------------- Sentence 1 -------------------

NLP.

>> Tokens are: 
 ['NLP', '.']

>> Bigrams are: 
 [('NLP', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('NLP', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('.', '.')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('.', '.')]



========================================== PARAGRAPH 127 ===========================================

One of initial applications of NLP in early years of  

------------------- Sentence 1 -------------------

One of initial applications of NLP in early years of

>> Tokens are: 
 ['One', 'initial', 'applications', 'NLP', 'early', 'years']

>> Bigrams are: 
 [('One', 'initial'), ('initial', 'applications'), ('applications', 'NLP'), ('NLP', 'early'), ('early', 'years')]

>> Trigrams are: 
 [('One', 'initial', 'applications'), ('initial', 'applications', 'NLP'), ('applications', 'NLP', 'early'), ('NLP', 'early', 'years')]

>> POS Tags are: 
 [('One', 'CD'), ('initial', 'JJ'), ('applications', 'NNS'), ('NLP', 'NNP'), ('early', 'JJ'), ('years', 'NNS')]

>> Noun Phrases are: 
 ['initial applications NLP', 'early years']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('initial', 'initi'), ('applications', 'applic'), ('NLP', 'nlp'), ('early', 'earli'), ('years', 'year')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('initial', 'initi'), ('applications', 'applic'), ('NLP', 'nlp'), ('early', 'earli'), ('years', 'year')]

>> Lemmatization: 
 [('One', 'One'), ('initial', 'initial'), ('applications', 'application'), ('NLP', 'NLP'), ('early', 'early'), ('years', 'year')]



========================================== PARAGRAPH 128 ===========================================

2000 was on machine translation to work as translator  

------------------- Sentence 1 -------------------

2000 was on machine translation to work as translator

>> Tokens are: 
 ['2000', 'machine', 'translation', 'work', 'translator']

>> Bigrams are: 
 [('2000', 'machine'), ('machine', 'translation'), ('translation', 'work'), ('work', 'translator')]

>> Trigrams are: 
 [('2000', 'machine', 'translation'), ('machine', 'translation', 'work'), ('translation', 'work', 'translator')]

>> POS Tags are: 
 [('2000', 'CD'), ('machine', 'NN'), ('translation', 'NN'), ('work', 'NN'), ('translator', 'NN')]

>> Noun Phrases are: 
 ['machine translation work translator']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2000', '2000'), ('machine', 'machin'), ('translation', 'translat'), ('work', 'work'), ('translator', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('2000', '2000'), ('machine', 'machin'), ('translation', 'translat'), ('work', 'work'), ('translator', 'translat')]

>> Lemmatization: 
 [('2000', '2000'), ('machine', 'machine'), ('translation', 'translation'), ('work', 'work'), ('translator', 'translator')]



========================================== PARAGRAPH 129 ===========================================

from one human language to another. But it rapidly found  

------------------- Sentence 1 -------------------

from one human language to another.

>> Tokens are: 
 ['one', 'human', 'language', 'another', '.']

>> Bigrams are: 
 [('one', 'human'), ('human', 'language'), ('language', 'another'), ('another', '.')]

>> Trigrams are: 
 [('one', 'human', 'language'), ('human', 'language', 'another'), ('language', 'another', '.')]

>> POS Tags are: 
 [('one', 'CD'), ('human', 'JJ'), ('language', 'NN'), ('another', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 ['human language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('human', 'human'), ('language', 'languag'), ('another', 'anoth'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('human', 'human'), ('language', 'languag'), ('another', 'anoth'), ('.', '.')]

>> Lemmatization: 
 [('one', 'one'), ('human', 'human'), ('language', 'language'), ('another', 'another'), ('.', '.')]


------------------- Sentence 2 -------------------

But it rapidly found

>> Tokens are: 
 ['But', 'rapidly', 'found']

>> Bigrams are: 
 [('But', 'rapidly'), ('rapidly', 'found')]

>> Trigrams are: 
 [('But', 'rapidly', 'found')]

>> POS Tags are: 
 [('But', 'CC'), ('rapidly', 'RB'), ('found', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('rapidly', 'rapidli'), ('found', 'found')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('rapidly', 'rapid'), ('found', 'found')]

>> Lemmatization: 
 [('But', 'But'), ('rapidly', 'rapidly'), ('found', 'found')]



========================================== PARAGRAPH 130 ===========================================

its acceptance in customer service industry. Most popular  

------------------- Sentence 1 -------------------

its acceptance in customer service industry.

>> Tokens are: 
 ['acceptance', 'customer', 'service', 'industry', '.']

>> Bigrams are: 
 [('acceptance', 'customer'), ('customer', 'service'), ('service', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('acceptance', 'customer', 'service'), ('customer', 'service', 'industry'), ('service', 'industry', '.')]

>> POS Tags are: 
 [('acceptance', 'NN'), ('customer', 'NN'), ('service', 'NN'), ('industry', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['acceptance customer service industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('acceptance', 'accept'), ('customer', 'custom'), ('service', 'servic'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('acceptance', 'accept'), ('customer', 'custom'), ('service', 'servic'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('acceptance', 'acceptance'), ('customer', 'customer'), ('service', 'service'), ('industry', 'industry'), ('.', '.')]


------------------- Sentence 2 -------------------

Most popular

>> Tokens are: 
 ['Most', 'popular']

>> Bigrams are: 
 [('Most', 'popular')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Most', 'RBS'), ('popular', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('popular', 'popular')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('popular', 'popular')]

>> Lemmatization: 
 [('Most', 'Most'), ('popular', 'popular')]



========================================== PARAGRAPH 131 ===========================================

application of NLP in customer service is called as  

------------------- Sentence 1 -------------------

application of NLP in customer service is called as

>> Tokens are: 
 ['application', 'NLP', 'customer', 'service', 'called']

>> Bigrams are: 
 [('application', 'NLP'), ('NLP', 'customer'), ('customer', 'service'), ('service', 'called')]

>> Trigrams are: 
 [('application', 'NLP', 'customer'), ('NLP', 'customer', 'service'), ('customer', 'service', 'called')]

>> POS Tags are: 
 [('application', 'NN'), ('NLP', 'NNP'), ('customer', 'NN'), ('service', 'NN'), ('called', 'VBD')]

>> Noun Phrases are: 
 ['application NLP customer service']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('application', 'applic'), ('NLP', 'nlp'), ('customer', 'custom'), ('service', 'servic'), ('called', 'call')]

>> Stemming using Snowball Stemmer: 
 [('application', 'applic'), ('NLP', 'nlp'), ('customer', 'custom'), ('service', 'servic'), ('called', 'call')]

>> Lemmatization: 
 [('application', 'application'), ('NLP', 'NLP'), ('customer', 'customer'), ('service', 'service'), ('called', 'called')]



========================================== PARAGRAPH 132 ===========================================

“Chatbots” or Virtual assistant.   

------------------- Sentence 1 -------------------

“Chatbots” or Virtual assistant.

>> Tokens are: 
 ['“', 'Chatbots', '”', 'Virtual', 'assistant', '.']

>> Bigrams are: 
 [('“', 'Chatbots'), ('Chatbots', '”'), ('”', 'Virtual'), ('Virtual', 'assistant'), ('assistant', '.')]

>> Trigrams are: 
 [('“', 'Chatbots', '”'), ('Chatbots', '”', 'Virtual'), ('”', 'Virtual', 'assistant'), ('Virtual', 'assistant', '.')]

>> POS Tags are: 
 [('“', 'JJ'), ('Chatbots', 'NNP'), ('”', 'NNP'), ('Virtual', 'NNP'), ('assistant', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['“ Chatbots ” Virtual assistant']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('Chatbots', 'chatbot'), ('”', '”'), ('Virtual', 'virtual'), ('assistant', 'assist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('Chatbots', 'chatbot'), ('”', '”'), ('Virtual', 'virtual'), ('assistant', 'assist'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('Chatbots', 'Chatbots'), ('”', '”'), ('Virtual', 'Virtual'), ('assistant', 'assistant'), ('.', '.')]



========================================== PARAGRAPH 133 ===========================================

Industrial applications of NLP can be broadly  

------------------- Sentence 1 -------------------

Industrial applications of NLP can be broadly

>> Tokens are: 
 ['Industrial', 'applications', 'NLP', 'broadly']

>> Bigrams are: 
 [('Industrial', 'applications'), ('applications', 'NLP'), ('NLP', 'broadly')]

>> Trigrams are: 
 [('Industrial', 'applications', 'NLP'), ('applications', 'NLP', 'broadly')]

>> POS Tags are: 
 [('Industrial', 'NNP'), ('applications', 'NNS'), ('NLP', 'NNP'), ('broadly', 'RB')]

>> Noun Phrases are: 
 ['Industrial applications NLP']

>> Named Entities are: 
 [('GPE', 'Industrial'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Industrial', 'industri'), ('applications', 'applic'), ('NLP', 'nlp'), ('broadly', 'broadli')]

>> Stemming using Snowball Stemmer: 
 [('Industrial', 'industri'), ('applications', 'applic'), ('NLP', 'nlp'), ('broadly', 'broad')]

>> Lemmatization: 
 [('Industrial', 'Industrial'), ('applications', 'application'), ('NLP', 'NLP'), ('broadly', 'broadly')]



========================================== PARAGRAPH 134 ===========================================

classified into 3 categories:Conversational systems, Text  

------------------- Sentence 1 -------------------

classified into 3 categories:Conversational systems, Text

>> Tokens are: 
 ['classified', '3', 'categories', ':', 'Conversational', 'systems', ',', 'Text']

>> Bigrams are: 
 [('classified', '3'), ('3', 'categories'), ('categories', ':'), (':', 'Conversational'), ('Conversational', 'systems'), ('systems', ','), (',', 'Text')]

>> Trigrams are: 
 [('classified', '3', 'categories'), ('3', 'categories', ':'), ('categories', ':', 'Conversational'), (':', 'Conversational', 'systems'), ('Conversational', 'systems', ','), ('systems', ',', 'Text')]

>> POS Tags are: 
 [('classified', 'JJ'), ('3', 'CD'), ('categories', 'NNS'), (':', ':'), ('Conversational', 'JJ'), ('systems', 'NNS'), (',', ','), ('Text', 'NNP')]

>> Noun Phrases are: 
 ['categories', 'Conversational systems', 'Text']

>> Named Entities are: 
 [('PERSON', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('classified', 'classifi'), ('3', '3'), ('categories', 'categori'), (':', ':'), ('Conversational', 'convers'), ('systems', 'system'), (',', ','), ('Text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('classified', 'classifi'), ('3', '3'), ('categories', 'categori'), (':', ':'), ('Conversational', 'convers'), ('systems', 'system'), (',', ','), ('Text', 'text')]

>> Lemmatization: 
 [('classified', 'classified'), ('3', '3'), ('categories', 'category'), (':', ':'), ('Conversational', 'Conversational'), ('systems', 'system'), (',', ','), ('Text', 'Text')]



========================================== PARAGRAPH 135 ===========================================

Analytics, Machine translation  

------------------- Sentence 1 -------------------

Analytics, Machine translation

>> Tokens are: 
 ['Analytics', ',', 'Machine', 'translation']

>> Bigrams are: 
 [('Analytics', ','), (',', 'Machine'), ('Machine', 'translation')]

>> Trigrams are: 
 [('Analytics', ',', 'Machine'), (',', 'Machine', 'translation')]

>> POS Tags are: 
 [('Analytics', 'NNS'), (',', ','), ('Machine', 'NNP'), ('translation', 'NN')]

>> Noun Phrases are: 
 ['Analytics', 'Machine translation']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), (',', ','), ('Machine', 'machin'), ('translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), (',', ','), ('Machine', 'machin'), ('translation', 'translat')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), (',', ','), ('Machine', 'Machine'), ('translation', 'translation')]



========================================== PARAGRAPH 136 ===========================================

A. Conversational Systems  

------------------- Sentence 1 -------------------

A. Conversational Systems

>> Tokens are: 
 ['A.', 'Conversational', 'Systems']

>> Bigrams are: 
 [('A.', 'Conversational'), ('Conversational', 'Systems')]

>> Trigrams are: 
 [('A.', 'Conversational', 'Systems')]

>> POS Tags are: 
 [('A.', 'JJ'), ('Conversational', 'NNP'), ('Systems', 'NNPS')]

>> Noun Phrases are: 
 ['A. Conversational']

>> Named Entities are: 
 [('ORGANIZATION', 'Conversational Systems')] 

>> Stemming using Porter Stemmer: 
 [('A.', 'a.'), ('Conversational', 'convers'), ('Systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('A.', 'a.'), ('Conversational', 'convers'), ('Systems', 'system')]

>> Lemmatization: 
 [('A.', 'A.'), ('Conversational', 'Conversational'), ('Systems', 'Systems')]



========================================== PARAGRAPH 137 ===========================================

Conversational system allows us to make the  

------------------- Sentence 1 -------------------

Conversational system allows us to make the

>> Tokens are: 
 ['Conversational', 'system', 'allows', 'us', 'make']

>> Bigrams are: 
 [('Conversational', 'system'), ('system', 'allows'), ('allows', 'us'), ('us', 'make')]

>> Trigrams are: 
 [('Conversational', 'system', 'allows'), ('system', 'allows', 'us'), ('allows', 'us', 'make')]

>> POS Tags are: 
 [('Conversational', 'NNP'), ('system', 'NN'), ('allows', 'VBZ'), ('us', 'PRP'), ('make', 'VB')]

>> Noun Phrases are: 
 ['Conversational system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conversational', 'convers'), ('system', 'system'), ('allows', 'allow'), ('us', 'us'), ('make', 'make')]

>> Stemming using Snowball Stemmer: 
 [('Conversational', 'convers'), ('system', 'system'), ('allows', 'allow'), ('us', 'us'), ('make', 'make')]

>> Lemmatization: 
 [('Conversational', 'Conversational'), ('system', 'system'), ('allows', 'allows'), ('us', 'u'), ('make', 'make')]



========================================== PARAGRAPH 138 ===========================================

conversation with the automated system in a natural  

------------------- Sentence 1 -------------------

conversation with the automated system in a natural

>> Tokens are: 
 ['conversation', 'automated', 'system', 'natural']

>> Bigrams are: 
 [('conversation', 'automated'), ('automated', 'system'), ('system', 'natural')]

>> Trigrams are: 
 [('conversation', 'automated', 'system'), ('automated', 'system', 'natural')]

>> POS Tags are: 
 [('conversation', 'NN'), ('automated', 'VBD'), ('system', 'NN'), ('natural', 'JJ')]

>> Noun Phrases are: 
 ['conversation', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conversation', 'convers'), ('automated', 'autom'), ('system', 'system'), ('natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('conversation', 'convers'), ('automated', 'autom'), ('system', 'system'), ('natural', 'natur')]

>> Lemmatization: 
 [('conversation', 'conversation'), ('automated', 'automated'), ('system', 'system'), ('natural', 'natural')]



========================================== PARAGRAPH 139 ===========================================

language via voice or text interface. They help to  

------------------- Sentence 1 -------------------

language via voice or text interface.

>> Tokens are: 
 ['language', 'via', 'voice', 'text', 'interface', '.']

>> Bigrams are: 
 [('language', 'via'), ('via', 'voice'), ('voice', 'text'), ('text', 'interface'), ('interface', '.')]

>> Trigrams are: 
 [('language', 'via', 'voice'), ('via', 'voice', 'text'), ('voice', 'text', 'interface'), ('text', 'interface', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('via', 'IN'), ('voice', 'NN'), ('text', 'JJ'), ('interface', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language', 'voice', 'text interface']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('via', 'via'), ('voice', 'voic'), ('text', 'text'), ('interface', 'interfac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('via', 'via'), ('voice', 'voic'), ('text', 'text'), ('interface', 'interfac'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('via', 'via'), ('voice', 'voice'), ('text', 'text'), ('interface', 'interface'), ('.', '.')]


------------------- Sentence 2 -------------------

They help to

>> Tokens are: 
 ['They', 'help']

>> Bigrams are: 
 [('They', 'help')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('They', 'PRP'), ('help', 'VBP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('help', 'help')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('help', 'help')]

>> Lemmatization: 
 [('They', 'They'), ('help', 'help')]



========================================== PARAGRAPH 140 ===========================================

automate the complex workflows in an organization with  

------------------- Sentence 1 -------------------

automate the complex workflows in an organization with

>> Tokens are: 
 ['automate', 'complex', 'workflows', 'organization']

>> Bigrams are: 
 [('automate', 'complex'), ('complex', 'workflows'), ('workflows', 'organization')]

>> Trigrams are: 
 [('automate', 'complex', 'workflows'), ('complex', 'workflows', 'organization')]

>> POS Tags are: 
 [('automate', 'NN'), ('complex', 'NN'), ('workflows', 'VBZ'), ('organization', 'NN')]

>> Noun Phrases are: 
 ['automate complex', 'organization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automate', 'autom'), ('complex', 'complex'), ('workflows', 'workflow'), ('organization', 'organ')]

>> Stemming using Snowball Stemmer: 
 [('automate', 'autom'), ('complex', 'complex'), ('workflows', 'workflow'), ('organization', 'organ')]

>> Lemmatization: 
 [('automate', 'automate'), ('complex', 'complex'), ('workflows', 'workflow'), ('organization', 'organization')]



========================================== PARAGRAPH 141 ===========================================

24X7 support to its users.   

------------------- Sentence 1 -------------------

24X7 support to its users.

>> Tokens are: 
 ['24X7', 'support', 'users', '.']

>> Bigrams are: 
 [('24X7', 'support'), ('support', 'users'), ('users', '.')]

>> Trigrams are: 
 [('24X7', 'support', 'users'), ('support', 'users', '.')]

>> POS Tags are: 
 [('24X7', 'CD'), ('support', 'NN'), ('users', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['support users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('24X7', '24x7'), ('support', 'support'), ('users', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('24X7', '24x7'), ('support', 'support'), ('users', 'user'), ('.', '.')]

>> Lemmatization: 
 [('24X7', '24X7'), ('support', 'support'), ('users', 'user'), ('.', '.')]



========================================== PARAGRAPH 142 ===========================================

Most common type of conversation devices are  

------------------- Sentence 1 -------------------

Most common type of conversation devices are

>> Tokens are: 
 ['Most', 'common', 'type', 'conversation', 'devices']

>> Bigrams are: 
 [('Most', 'common'), ('common', 'type'), ('type', 'conversation'), ('conversation', 'devices')]

>> Trigrams are: 
 [('Most', 'common', 'type'), ('common', 'type', 'conversation'), ('type', 'conversation', 'devices')]

>> POS Tags are: 
 [('Most', 'JJS'), ('common', 'JJ'), ('type', 'NN'), ('conversation', 'NN'), ('devices', 'NNS')]

>> Noun Phrases are: 
 ['common type conversation devices']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('common', 'common'), ('type', 'type'), ('conversation', 'convers'), ('devices', 'devic')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('common', 'common'), ('type', 'type'), ('conversation', 'convers'), ('devices', 'devic')]

>> Lemmatization: 
 [('Most', 'Most'), ('common', 'common'), ('type', 'type'), ('conversation', 'conversation'), ('devices', 'device')]



========================================== PARAGRAPH 143 ===========================================

Chatbots and Virtual Assistants. Today, these two  

------------------- Sentence 1 -------------------

Chatbots and Virtual Assistants.

>> Tokens are: 
 ['Chatbots', 'Virtual', 'Assistants', '.']

>> Bigrams are: 
 [('Chatbots', 'Virtual'), ('Virtual', 'Assistants'), ('Assistants', '.')]

>> Trigrams are: 
 [('Chatbots', 'Virtual', 'Assistants'), ('Virtual', 'Assistants', '.')]

>> POS Tags are: 
 [('Chatbots', 'NNP'), ('Virtual', 'NNP'), ('Assistants', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Chatbots Virtual Assistants']

>> Named Entities are: 
 [('PERSON', 'Chatbots'), ('PERSON', 'Virtual Assistants')] 

>> Stemming using Porter Stemmer: 
 [('Chatbots', 'chatbot'), ('Virtual', 'virtual'), ('Assistants', 'assist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chatbots', 'chatbot'), ('Virtual', 'virtual'), ('Assistants', 'assist'), ('.', '.')]

>> Lemmatization: 
 [('Chatbots', 'Chatbots'), ('Virtual', 'Virtual'), ('Assistants', 'Assistants'), ('.', '.')]


------------------- Sentence 2 -------------------

Today, these two

>> Tokens are: 
 ['Today', ',', 'two']

>> Bigrams are: 
 [('Today', ','), (',', 'two')]

>> Trigrams are: 
 [('Today', ',', 'two')]

>> POS Tags are: 
 [('Today', 'NN'), (',', ','), ('two', 'CD')]

>> Noun Phrases are: 
 ['Today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Today', 'today'), (',', ','), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('Today', 'today'), (',', ','), ('two', 'two')]

>> Lemmatization: 
 [('Today', 'Today'), (',', ','), ('two', 'two')]



========================================== PARAGRAPH 144 ===========================================

devices are employed by banks, e-commerce, social  

------------------- Sentence 1 -------------------

devices are employed by banks, e-commerce, social

>> Tokens are: 
 ['devices', 'employed', 'banks', ',', 'e-commerce', ',', 'social']

>> Bigrams are: 
 [('devices', 'employed'), ('employed', 'banks'), ('banks', ','), (',', 'e-commerce'), ('e-commerce', ','), (',', 'social')]

>> Trigrams are: 
 [('devices', 'employed', 'banks'), ('employed', 'banks', ','), ('banks', ',', 'e-commerce'), (',', 'e-commerce', ','), ('e-commerce', ',', 'social')]

>> POS Tags are: 
 [('devices', 'NNS'), ('employed', 'VBD'), ('banks', 'NNS'), (',', ','), ('e-commerce', 'NN'), (',', ','), ('social', 'JJ')]

>> Noun Phrases are: 
 ['devices', 'banks', 'e-commerce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('devices', 'devic'), ('employed', 'employ'), ('banks', 'bank'), (',', ','), ('e-commerce', 'e-commerc'), (',', ','), ('social', 'social')]

>> Stemming using Snowball Stemmer: 
 [('devices', 'devic'), ('employed', 'employ'), ('banks', 'bank'), (',', ','), ('e-commerce', 'e-commerc'), (',', ','), ('social', 'social')]

>> Lemmatization: 
 [('devices', 'device'), ('employed', 'employed'), ('banks', 'bank'), (',', ','), ('e-commerce', 'e-commerce'), (',', ','), ('social', 'social')]



========================================== PARAGRAPH 145 ===========================================

media and other self service point of sales systems to  

------------------- Sentence 1 -------------------

media and other self service point of sales systems to

>> Tokens are: 
 ['media', 'self', 'service', 'point', 'sales', 'systems']

>> Bigrams are: 
 [('media', 'self'), ('self', 'service'), ('service', 'point'), ('point', 'sales'), ('sales', 'systems')]

>> Trigrams are: 
 [('media', 'self', 'service'), ('self', 'service', 'point'), ('service', 'point', 'sales'), ('point', 'sales', 'systems')]

>> POS Tags are: 
 [('media', 'NNS'), ('self', 'PRP'), ('service', 'NN'), ('point', 'NN'), ('sales', 'NNS'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['media', 'service point sales systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('media', 'media'), ('self', 'self'), ('service', 'servic'), ('point', 'point'), ('sales', 'sale'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('media', 'media'), ('self', 'self'), ('service', 'servic'), ('point', 'point'), ('sales', 'sale'), ('systems', 'system')]

>> Lemmatization: 
 [('media', 'medium'), ('self', 'self'), ('service', 'service'), ('point', 'point'), ('sales', 'sale'), ('systems', 'system')]



========================================== PARAGRAPH 146 ===========================================

provide various services to their customers.  

------------------- Sentence 1 -------------------

provide various services to their customers.

>> Tokens are: 
 ['provide', 'various', 'services', 'customers', '.']

>> Bigrams are: 
 [('provide', 'various'), ('various', 'services'), ('services', 'customers'), ('customers', '.')]

>> Trigrams are: 
 [('provide', 'various', 'services'), ('various', 'services', 'customers'), ('services', 'customers', '.')]

>> POS Tags are: 
 [('provide', 'RB'), ('various', 'JJ'), ('services', 'NNS'), ('customers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['various services customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provide', 'provid'), ('various', 'variou'), ('services', 'servic'), ('customers', 'custom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('provide', 'provid'), ('various', 'various'), ('services', 'servic'), ('customers', 'custom'), ('.', '.')]

>> Lemmatization: 
 [('provide', 'provide'), ('various', 'various'), ('services', 'service'), ('customers', 'customer'), ('.', '.')]



========================================== PARAGRAPH 147 ===========================================

B. Text Analytics  

------------------- Sentence 1 -------------------

B.

>> Tokens are: 
 ['B', '.']

>> Bigrams are: 
 [('B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('B', 'B'), ('.', '.')]


------------------- Sentence 2 -------------------

Text Analytics

>> Tokens are: 
 ['Text', 'Analytics']

>> Bigrams are: 
 [('Text', 'Analytics')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Text', 'NN'), ('Analytics', 'NNS')]

>> Noun Phrases are: 
 ['Text Analytics']

>> Named Entities are: 
 [('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('Analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('Analytics', 'analyt')]

>> Lemmatization: 
 [('Text', 'Text'), ('Analytics', 'Analytics')]



========================================== PARAGRAPH 148 ===========================================

Text Analytics also called as Text mining which aims  

------------------- Sentence 1 -------------------

Text Analytics also called as Text mining which aims

>> Tokens are: 
 ['Text', 'Analytics', 'also', 'called', 'Text', 'mining', 'aims']

>> Bigrams are: 
 [('Text', 'Analytics'), ('Analytics', 'also'), ('also', 'called'), ('called', 'Text'), ('Text', 'mining'), ('mining', 'aims')]

>> Trigrams are: 
 [('Text', 'Analytics', 'also'), ('Analytics', 'also', 'called'), ('also', 'called', 'Text'), ('called', 'Text', 'mining'), ('Text', 'mining', 'aims')]

>> POS Tags are: 
 [('Text', 'NN'), ('Analytics', 'NNS'), ('also', 'RB'), ('called', 'VBD'), ('Text', 'NNP'), ('mining', 'NN'), ('aims', 'NNS')]

>> Noun Phrases are: 
 ['Text Analytics', 'Text mining aims']

>> Named Entities are: 
 [('GPE', 'Text'), ('PERSON', 'Analytics'), ('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('Analytics', 'analyt'), ('also', 'also'), ('called', 'call'), ('Text', 'text'), ('mining', 'mine'), ('aims', 'aim')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('Analytics', 'analyt'), ('also', 'also'), ('called', 'call'), ('Text', 'text'), ('mining', 'mine'), ('aims', 'aim')]

>> Lemmatization: 
 [('Text', 'Text'), ('Analytics', 'Analytics'), ('also', 'also'), ('called', 'called'), ('Text', 'Text'), ('mining', 'mining'), ('aims', 'aim')]



========================================== PARAGRAPH 149 ===========================================

to extract meaningful content from text, either in  

------------------- Sentence 1 -------------------

to extract meaningful content from text, either in

>> Tokens are: 
 ['extract', 'meaningful', 'content', 'text', ',', 'either']

>> Bigrams are: 
 [('extract', 'meaningful'), ('meaningful', 'content'), ('content', 'text'), ('text', ','), (',', 'either')]

>> Trigrams are: 
 [('extract', 'meaningful', 'content'), ('meaningful', 'content', 'text'), ('content', 'text', ','), ('text', ',', 'either')]

>> POS Tags are: 
 [('extract', 'JJ'), ('meaningful', 'JJ'), ('content', 'NN'), ('text', 'NN'), (',', ','), ('either', 'CC')]

>> Noun Phrases are: 
 ['extract meaningful content text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extract', 'extract'), ('meaningful', 'meaning'), ('content', 'content'), ('text', 'text'), (',', ','), ('either', 'either')]

>> Stemming using Snowball Stemmer: 
 [('extract', 'extract'), ('meaningful', 'meaning'), ('content', 'content'), ('text', 'text'), (',', ','), ('either', 'either')]

>> Lemmatization: 
 [('extract', 'extract'), ('meaningful', 'meaningful'), ('content', 'content'), ('text', 'text'), (',', ','), ('either', 'either')]



========================================== PARAGRAPH 150 ===========================================

documents, emails or short-form communications such as  

------------------- Sentence 1 -------------------

documents, emails or short-form communications such as

>> Tokens are: 
 ['documents', ',', 'emails', 'short-form', 'communications']

>> Bigrams are: 
 [('documents', ','), (',', 'emails'), ('emails', 'short-form'), ('short-form', 'communications')]

>> Trigrams are: 
 [('documents', ',', 'emails'), (',', 'emails', 'short-form'), ('emails', 'short-form', 'communications')]

>> POS Tags are: 
 [('documents', 'NNS'), (',', ','), ('emails', 'VBZ'), ('short-form', 'NN'), ('communications', 'NNS')]

>> Noun Phrases are: 
 ['documents', 'short-form communications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('documents', 'document'), (',', ','), ('emails', 'email'), ('short-form', 'short-form'), ('communications', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('documents', 'document'), (',', ','), ('emails', 'email'), ('short-form', 'short-form'), ('communications', 'communic')]

>> Lemmatization: 
 [('documents', 'document'), (',', ','), ('emails', 'email'), ('short-form', 'short-form'), ('communications', 'communication')]



========================================== PARAGRAPH 151 ===========================================

tweets and SMS texts [2].  

------------------- Sentence 1 -------------------

tweets and SMS texts [2].

>> Tokens are: 
 ['tweets', 'SMS', 'texts', '[', '2', ']', '.']

>> Bigrams are: 
 [('tweets', 'SMS'), ('SMS', 'texts'), ('texts', '['), ('[', '2'), ('2', ']'), (']', '.')]

>> Trigrams are: 
 [('tweets', 'SMS', 'texts'), ('SMS', 'texts', '['), ('texts', '[', '2'), ('[', '2', ']'), ('2', ']', '.')]

>> POS Tags are: 
 [('tweets', 'NNS'), ('SMS', 'NNP'), ('texts', 'VBD'), ('[', '$'), ('2', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tweets SMS', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'SMS')] 

>> Stemming using Porter Stemmer: 
 [('tweets', 'tweet'), ('SMS', 'sm'), ('texts', 'text'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tweets', 'tweet'), ('SMS', 'sms'), ('texts', 'text'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('tweets', 'tweet'), ('SMS', 'SMS'), ('texts', 'text'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 152 ===========================================

 Most common use cases of text analytics on social  

------------------- Sentence 1 -------------------

 Most common use cases of text analytics on social

>> Tokens are: 
 ['Most', 'common', 'use', 'cases', 'text', 'analytics', 'social']

>> Bigrams are: 
 [('Most', 'common'), ('common', 'use'), ('use', 'cases'), ('cases', 'text'), ('text', 'analytics'), ('analytics', 'social')]

>> Trigrams are: 
 [('Most', 'common', 'use'), ('common', 'use', 'cases'), ('use', 'cases', 'text'), ('cases', 'text', 'analytics'), ('text', 'analytics', 'social')]

>> POS Tags are: 
 [('Most', 'JJS'), ('common', 'JJ'), ('use', 'NN'), ('cases', 'NNS'), ('text', 'VBP'), ('analytics', 'NNS'), ('social', 'JJ')]

>> Noun Phrases are: 
 ['common use cases', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('common', 'common'), ('use', 'use'), ('cases', 'case'), ('text', 'text'), ('analytics', 'analyt'), ('social', 'social')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('common', 'common'), ('use', 'use'), ('cases', 'case'), ('text', 'text'), ('analytics', 'analyt'), ('social', 'social')]

>> Lemmatization: 
 [('Most', 'Most'), ('common', 'common'), ('use', 'use'), ('cases', 'case'), ('text', 'text'), ('analytics', 'analytics'), ('social', 'social')]



========================================== PARAGRAPH 153 ===========================================

media analytics.  

------------------- Sentence 1 -------------------

media analytics.

>> Tokens are: 
 ['media', 'analytics', '.']

>> Bigrams are: 
 [('media', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('media', 'analytics', '.')]

>> POS Tags are: 
 [('media', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['media analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('media', 'media'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('media', 'media'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('media', 'medium'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 154 ===========================================

C. Machine Translation  

------------------- Sentence 1 -------------------

C. Machine Translation

>> Tokens are: 
 ['C.', 'Machine', 'Translation']

>> Bigrams are: 
 [('C.', 'Machine'), ('Machine', 'Translation')]

>> Trigrams are: 
 [('C.', 'Machine', 'Translation')]

>> POS Tags are: 
 [('C.', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP')]

>> Noun Phrases are: 
 ['C. Machine Translation']

>> Named Entities are: 
 [('PERSON', 'Machine Translation')] 

>> Stemming using Porter Stemmer: 
 [('C.', 'c.'), ('Machine', 'machin'), ('Translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('C.', 'c.'), ('Machine', 'machin'), ('Translation', 'translat')]

>> Lemmatization: 
 [('C.', 'C.'), ('Machine', 'Machine'), ('Translation', 'Translation')]



========================================== PARAGRAPH 155 ===========================================

Machine translation is the task of automatically  

------------------- Sentence 1 -------------------

Machine translation is the task of automatically

>> Tokens are: 
 ['Machine', 'translation', 'task', 'automatically']

>> Bigrams are: 
 [('Machine', 'translation'), ('translation', 'task'), ('task', 'automatically')]

>> Trigrams are: 
 [('Machine', 'translation', 'task'), ('translation', 'task', 'automatically')]

>> POS Tags are: 
 [('Machine', 'NN'), ('translation', 'NN'), ('task', 'NN'), ('automatically', 'RB')]

>> Noun Phrases are: 
 ['Machine translation task']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), ('task', 'task'), ('automatically', 'automat')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), ('task', 'task'), ('automatically', 'automat')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('translation', 'translation'), ('task', 'task'), ('automatically', 'automatically')]



========================================== PARAGRAPH 156 ===========================================

translating one natural language into another, preserving  

------------------- Sentence 1 -------------------

translating one natural language into another, preserving

>> Tokens are: 
 ['translating', 'one', 'natural', 'language', 'another', ',', 'preserving']

>> Bigrams are: 
 [('translating', 'one'), ('one', 'natural'), ('natural', 'language'), ('language', 'another'), ('another', ','), (',', 'preserving')]

>> Trigrams are: 
 [('translating', 'one', 'natural'), ('one', 'natural', 'language'), ('natural', 'language', 'another'), ('language', 'another', ','), ('another', ',', 'preserving')]

>> POS Tags are: 
 [('translating', 'VBG'), ('one', 'CD'), ('natural', 'JJ'), ('language', 'NN'), ('another', 'DT'), (',', ','), ('preserving', 'VBG')]

>> Noun Phrases are: 
 ['natural language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('translating', 'translat'), ('one', 'one'), ('natural', 'natur'), ('language', 'languag'), ('another', 'anoth'), (',', ','), ('preserving', 'preserv')]

>> Stemming using Snowball Stemmer: 
 [('translating', 'translat'), ('one', 'one'), ('natural', 'natur'), ('language', 'languag'), ('another', 'anoth'), (',', ','), ('preserving', 'preserv')]

>> Lemmatization: 
 [('translating', 'translating'), ('one', 'one'), ('natural', 'natural'), ('language', 'language'), ('another', 'another'), (',', ','), ('preserving', 'preserving')]



========================================== PARAGRAPH 157 ===========================================

the meaning of the input text [4].   

------------------- Sentence 1 -------------------

the meaning of the input text [4].

>> Tokens are: 
 ['meaning', 'input', 'text', '[', '4', ']', '.']

>> Bigrams are: 
 [('meaning', 'input'), ('input', 'text'), ('text', '['), ('[', '4'), ('4', ']'), (']', '.')]

>> Trigrams are: 
 [('meaning', 'input', 'text'), ('input', 'text', '['), ('text', '[', '4'), ('[', '4', ']'), ('4', ']', '.')]

>> POS Tags are: 
 [('meaning', 'VBG'), ('input', 'NN'), ('text', 'NN'), ('[', '$'), ('4', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['input text', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('meaning', 'mean'), ('input', 'input'), ('text', 'text'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('meaning', 'mean'), ('input', 'input'), ('text', 'text'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('meaning', 'meaning'), ('input', 'input'), ('text', 'text'), ('[', '['), ('4', '4'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 158 ===========================================

Most popular application of machine translation is  

------------------- Sentence 1 -------------------

Most popular application of machine translation is

>> Tokens are: 
 ['Most', 'popular', 'application', 'machine', 'translation']

>> Bigrams are: 
 [('Most', 'popular'), ('popular', 'application'), ('application', 'machine'), ('machine', 'translation')]

>> Trigrams are: 
 [('Most', 'popular', 'application'), ('popular', 'application', 'machine'), ('application', 'machine', 'translation')]

>> POS Tags are: 
 [('Most', 'RBS'), ('popular', 'JJ'), ('application', 'NN'), ('machine', 'NN'), ('translation', 'NN')]

>> Noun Phrases are: 
 ['popular application machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('application', 'applic'), ('machine', 'machin'), ('translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('application', 'applic'), ('machine', 'machin'), ('translation', 'translat')]

>> Lemmatization: 
 [('Most', 'Most'), ('popular', 'popular'), ('application', 'application'), ('machine', 'machine'), ('translation', 'translation')]



========================================== PARAGRAPH 159 ===========================================

Google translator.  Other machine translation software’s  

------------------- Sentence 1 -------------------

Google translator.

>> Tokens are: 
 ['Google', 'translator', '.']

>> Bigrams are: 
 [('Google', 'translator'), ('translator', '.')]

>> Trigrams are: 
 [('Google', 'translator', '.')]

>> POS Tags are: 
 [('Google', 'NNP'), ('translator', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Google translator']

>> Named Entities are: 
 [('GPE', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('Google', 'googl'), ('translator', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Google', 'googl'), ('translator', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('Google', 'Google'), ('translator', 'translator'), ('.', '.')]


------------------- Sentence 2 -------------------

Other machine translation software’s

>> Tokens are: 
 ['Other', 'machine', 'translation', 'software', '’']

>> Bigrams are: 
 [('Other', 'machine'), ('machine', 'translation'), ('translation', 'software'), ('software', '’')]

>> Trigrams are: 
 [('Other', 'machine', 'translation'), ('machine', 'translation', 'software'), ('translation', 'software', '’')]

>> POS Tags are: 
 [('Other', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('software', 'NN'), ('’', 'NN')]

>> Noun Phrases are: 
 ['Other machine translation software ’']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('machine', 'machin'), ('translation', 'translat'), ('software', 'softwar'), ('’', '’')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('machine', 'machin'), ('translation', 'translat'), ('software', 'softwar'), ('’', '’')]

>> Lemmatization: 
 [('Other', 'Other'), ('machine', 'machine'), ('translation', 'translation'), ('software', 'software'), ('’', '’')]



========================================== PARAGRAPH 160 ===========================================

are also used in speech translation and teaching.  

------------------- Sentence 1 -------------------

are also used in speech translation and teaching.

>> Tokens are: 
 ['also', 'used', 'speech', 'translation', 'teaching', '.']

>> Bigrams are: 
 [('also', 'used'), ('used', 'speech'), ('speech', 'translation'), ('translation', 'teaching'), ('teaching', '.')]

>> Trigrams are: 
 [('also', 'used', 'speech'), ('used', 'speech', 'translation'), ('speech', 'translation', 'teaching'), ('translation', 'teaching', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('used', 'VBN'), ('speech', 'NN'), ('translation', 'NN'), ('teaching', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['speech translation teaching']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('used', 'use'), ('speech', 'speech'), ('translation', 'translat'), ('teaching', 'teach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('used', 'use'), ('speech', 'speech'), ('translation', 'translat'), ('teaching', 'teach'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('used', 'used'), ('speech', 'speech'), ('translation', 'translation'), ('teaching', 'teaching'), ('.', '.')]



========================================== PARAGRAPH 161 ===========================================

Now, we will look at some industrial applications in  

------------------- Sentence 1 -------------------

Now, we will look at some industrial applications in

>> Tokens are: 
 ['Now', ',', 'look', 'industrial', 'applications']

>> Bigrams are: 
 [('Now', ','), (',', 'look'), ('look', 'industrial'), ('industrial', 'applications')]

>> Trigrams are: 
 [('Now', ',', 'look'), (',', 'look', 'industrial'), ('look', 'industrial', 'applications')]

>> POS Tags are: 
 [('Now', 'RB'), (',', ','), ('look', 'VBP'), ('industrial', 'JJ'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['industrial applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Now', 'now'), (',', ','), ('look', 'look'), ('industrial', 'industri'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('Now', 'now'), (',', ','), ('look', 'look'), ('industrial', 'industri'), ('applications', 'applic')]

>> Lemmatization: 
 [('Now', 'Now'), (',', ','), ('look', 'look'), ('industrial', 'industrial'), ('applications', 'application')]



========================================== PARAGRAPH 162 ===========================================

following domain areas: Healthcare, Automotive,  

------------------- Sentence 1 -------------------

following domain areas: Healthcare, Automotive,

>> Tokens are: 
 ['following', 'domain', 'areas', ':', 'Healthcare', ',', 'Automotive', ',']

>> Bigrams are: 
 [('following', 'domain'), ('domain', 'areas'), ('areas', ':'), (':', 'Healthcare'), ('Healthcare', ','), (',', 'Automotive'), ('Automotive', ',')]

>> Trigrams are: 
 [('following', 'domain', 'areas'), ('domain', 'areas', ':'), ('areas', ':', 'Healthcare'), (':', 'Healthcare', ','), ('Healthcare', ',', 'Automotive'), (',', 'Automotive', ',')]

>> POS Tags are: 
 [('following', 'VBG'), ('domain', 'NN'), ('areas', 'NNS'), (':', ':'), ('Healthcare', 'NNP'), (',', ','), ('Automotive', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['domain areas', 'Healthcare', 'Automotive']

>> Named Entities are: 
 [('GPE', 'Automotive')] 

>> Stemming using Porter Stemmer: 
 [('following', 'follow'), ('domain', 'domain'), ('areas', 'area'), (':', ':'), ('Healthcare', 'healthcar'), (',', ','), ('Automotive', 'automot'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('following', 'follow'), ('domain', 'domain'), ('areas', 'area'), (':', ':'), ('Healthcare', 'healthcar'), (',', ','), ('Automotive', 'automot'), (',', ',')]

>> Lemmatization: 
 [('following', 'following'), ('domain', 'domain'), ('areas', 'area'), (':', ':'), ('Healthcare', 'Healthcare'), (',', ','), ('Automotive', 'Automotive'), (',', ',')]



========================================== PARAGRAPH 163 ===========================================

Finance, Manufacturing, Retail, Education and customer  

------------------- Sentence 1 -------------------

Finance, Manufacturing, Retail, Education and customer

>> Tokens are: 
 ['Finance', ',', 'Manufacturing', ',', 'Retail', ',', 'Education', 'customer']

>> Bigrams are: 
 [('Finance', ','), (',', 'Manufacturing'), ('Manufacturing', ','), (',', 'Retail'), ('Retail', ','), (',', 'Education'), ('Education', 'customer')]

>> Trigrams are: 
 [('Finance', ',', 'Manufacturing'), (',', 'Manufacturing', ','), ('Manufacturing', ',', 'Retail'), (',', 'Retail', ','), ('Retail', ',', 'Education'), (',', 'Education', 'customer')]

>> POS Tags are: 
 [('Finance', 'NN'), (',', ','), ('Manufacturing', 'NNP'), (',', ','), ('Retail', 'NNP'), (',', ','), ('Education', 'NNP'), ('customer', 'NN')]

>> Noun Phrases are: 
 ['Finance', 'Manufacturing', 'Retail', 'Education customer']

>> Named Entities are: 
 [('GPE', 'Finance'), ('GPE', 'Manufacturing'), ('GPE', 'Retail'), ('PERSON', 'Education')] 

>> Stemming using Porter Stemmer: 
 [('Finance', 'financ'), (',', ','), ('Manufacturing', 'manufactur'), (',', ','), ('Retail', 'retail'), (',', ','), ('Education', 'educ'), ('customer', 'custom')]

>> Stemming using Snowball Stemmer: 
 [('Finance', 'financ'), (',', ','), ('Manufacturing', 'manufactur'), (',', ','), ('Retail', 'retail'), (',', ','), ('Education', 'educ'), ('customer', 'custom')]

>> Lemmatization: 
 [('Finance', 'Finance'), (',', ','), ('Manufacturing', 'Manufacturing'), (',', ','), ('Retail', 'Retail'), (',', ','), ('Education', 'Education'), ('customer', 'customer')]



========================================== PARAGRAPH 164 ===========================================

service.   

------------------- Sentence 1 -------------------

service.

>> Tokens are: 
 ['service', '.']

>> Bigrams are: 
 [('service', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('service', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['service']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('service', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('service', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('service', 'service'), ('.', '.')]



========================================== PARAGRAPH 165 ===========================================

D. Healthcare  

------------------- Sentence 1 -------------------

D. Healthcare

>> Tokens are: 
 ['D.', 'Healthcare']

>> Bigrams are: 
 [('D.', 'Healthcare')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D.', 'NNP'), ('Healthcare', 'NNP')]

>> Noun Phrases are: 
 ['D. Healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('D.', 'd.'), ('Healthcare', 'healthcar')]

>> Stemming using Snowball Stemmer: 
 [('D.', 'd.'), ('Healthcare', 'healthcar')]

>> Lemmatization: 
 [('D.', 'D.'), ('Healthcare', 'Healthcare')]



========================================== PARAGRAPH 166 ===========================================

Hospitals are deploying Virtual Assistants developed  

------------------- Sentence 1 -------------------

Hospitals are deploying Virtual Assistants developed

>> Tokens are: 
 ['Hospitals', 'deploying', 'Virtual', 'Assistants', 'developed']

>> Bigrams are: 
 [('Hospitals', 'deploying'), ('deploying', 'Virtual'), ('Virtual', 'Assistants'), ('Assistants', 'developed')]

>> Trigrams are: 
 [('Hospitals', 'deploying', 'Virtual'), ('deploying', 'Virtual', 'Assistants'), ('Virtual', 'Assistants', 'developed')]

>> POS Tags are: 
 [('Hospitals', 'NNS'), ('deploying', 'VBG'), ('Virtual', 'JJ'), ('Assistants', 'NNS'), ('developed', 'VBD')]

>> Noun Phrases are: 
 ['Hospitals', 'Virtual Assistants']

>> Named Entities are: 
 [('ORGANIZATION', 'Virtual Assistants')] 

>> Stemming using Porter Stemmer: 
 [('Hospitals', 'hospit'), ('deploying', 'deploy'), ('Virtual', 'virtual'), ('Assistants', 'assist'), ('developed', 'develop')]

>> Stemming using Snowball Stemmer: 
 [('Hospitals', 'hospit'), ('deploying', 'deploy'), ('Virtual', 'virtual'), ('Assistants', 'assist'), ('developed', 'develop')]

>> Lemmatization: 
 [('Hospitals', 'Hospitals'), ('deploying', 'deploying'), ('Virtual', 'Virtual'), ('Assistants', 'Assistants'), ('developed', 'developed')]



========================================== PARAGRAPH 167 ===========================================

with combination of Natural Language Processing,  

------------------- Sentence 1 -------------------

with combination of Natural Language Processing,

>> Tokens are: 
 ['combination', 'Natural', 'Language', 'Processing', ',']

>> Bigrams are: 
 [('combination', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', ',')]

>> Trigrams are: 
 [('combination', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', ',')]

>> POS Tags are: 
 [('combination', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['combination Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language Processing')] 

>> Stemming using Porter Stemmer: 
 [('combination', 'combin'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('combination', 'combin'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), (',', ',')]

>> Lemmatization: 
 [('combination', 'combination'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), (',', ',')]



========================================== PARAGRAPH 168 ===========================================

Computer Vision and Machine learning which will  

------------------- Sentence 1 -------------------

Computer Vision and Machine learning which will

>> Tokens are: 
 ['Computer', 'Vision', 'Machine', 'learning']

>> Bigrams are: 
 [('Computer', 'Vision'), ('Vision', 'Machine'), ('Machine', 'learning')]

>> Trigrams are: 
 [('Computer', 'Vision', 'Machine'), ('Vision', 'Machine', 'learning')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Vision', 'NNP'), ('Machine', 'NNP'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Computer Vision Machine learning']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Vision Machine')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Vision', 'vision'), ('Machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Vision', 'vision'), ('Machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Vision', 'Vision'), ('Machine', 'Machine'), ('learning', 'learning')]



========================================== PARAGRAPH 169 ===========================================

automatically create and retrieve patient history by  

------------------- Sentence 1 -------------------

automatically create and retrieve patient history by

>> Tokens are: 
 ['automatically', 'create', 'retrieve', 'patient', 'history']

>> Bigrams are: 
 [('automatically', 'create'), ('create', 'retrieve'), ('retrieve', 'patient'), ('patient', 'history')]

>> Trigrams are: 
 [('automatically', 'create', 'retrieve'), ('create', 'retrieve', 'patient'), ('retrieve', 'patient', 'history')]

>> POS Tags are: 
 [('automatically', 'RB'), ('create', 'JJ'), ('retrieve', 'JJ'), ('patient', 'NN'), ('history', 'NN')]

>> Noun Phrases are: 
 ['create retrieve patient history']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatically', 'automat'), ('create', 'creat'), ('retrieve', 'retriev'), ('patient', 'patient'), ('history', 'histori')]

>> Stemming using Snowball Stemmer: 
 [('automatically', 'automat'), ('create', 'creat'), ('retrieve', 'retriev'), ('patient', 'patient'), ('history', 'histori')]

>> Lemmatization: 
 [('automatically', 'automatically'), ('create', 'create'), ('retrieve', 'retrieve'), ('patient', 'patient'), ('history', 'history')]



========================================== PARAGRAPH 170 ===========================================

interacting with the Patients. Virtual Assistant handle  

------------------- Sentence 1 -------------------

interacting with the Patients.

>> Tokens are: 
 ['interacting', 'Patients', '.']

>> Bigrams are: 
 [('interacting', 'Patients'), ('Patients', '.')]

>> Trigrams are: 
 [('interacting', 'Patients', '.')]

>> POS Tags are: 
 [('interacting', 'VBG'), ('Patients', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Patients']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interacting', 'interact'), ('Patients', 'patient'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('interacting', 'interact'), ('Patients', 'patient'), ('.', '.')]

>> Lemmatization: 
 [('interacting', 'interacting'), ('Patients', 'Patients'), ('.', '.')]


------------------- Sentence 2 -------------------

Virtual Assistant handle

>> Tokens are: 
 ['Virtual', 'Assistant', 'handle']

>> Bigrams are: 
 [('Virtual', 'Assistant'), ('Assistant', 'handle')]

>> Trigrams are: 
 [('Virtual', 'Assistant', 'handle')]

>> POS Tags are: 
 [('Virtual', 'JJ'), ('Assistant', 'NNP'), ('handle', 'NN')]

>> Noun Phrases are: 
 ['Virtual Assistant handle']

>> Named Entities are: 
 [('PERSON', 'Virtual'), ('ORGANIZATION', 'Assistant')] 

>> Stemming using Porter Stemmer: 
 [('Virtual', 'virtual'), ('Assistant', 'assist'), ('handle', 'handl')]

>> Stemming using Snowball Stemmer: 
 [('Virtual', 'virtual'), ('Assistant', 'assist'), ('handle', 'handl')]

>> Lemmatization: 
 [('Virtual', 'Virtual'), ('Assistant', 'Assistant'), ('handle', 'handle')]



========================================== PARAGRAPH 171 ===========================================

routine tasks such as scheduling appointments and  

------------------- Sentence 1 -------------------

routine tasks such as scheduling appointments and

>> Tokens are: 
 ['routine', 'tasks', 'scheduling', 'appointments']

>> Bigrams are: 
 [('routine', 'tasks'), ('tasks', 'scheduling'), ('scheduling', 'appointments')]

>> Trigrams are: 
 [('routine', 'tasks', 'scheduling'), ('tasks', 'scheduling', 'appointments')]

>> POS Tags are: 
 [('routine', 'JJ'), ('tasks', 'NNS'), ('scheduling', 'VBG'), ('appointments', 'NNS')]

>> Noun Phrases are: 
 ['routine tasks', 'appointments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('routine', 'routin'), ('tasks', 'task'), ('scheduling', 'schedul'), ('appointments', 'appoint')]

>> Stemming using Snowball Stemmer: 
 [('routine', 'routin'), ('tasks', 'task'), ('scheduling', 'schedul'), ('appointments', 'appoint')]

>> Lemmatization: 
 [('routine', 'routine'), ('tasks', 'task'), ('scheduling', 'scheduling'), ('appointments', 'appointment')]



========================================== PARAGRAPH 172 ===========================================

registration of patients.  

------------------- Sentence 1 -------------------

registration of patients.

>> Tokens are: 
 ['registration', 'patients', '.']

>> Bigrams are: 
 [('registration', 'patients'), ('patients', '.')]

>> Trigrams are: 
 [('registration', 'patients', '.')]

>> POS Tags are: 
 [('registration', 'NN'), ('patients', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['registration patients']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('registration', 'registr'), ('patients', 'patient'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('registration', 'registr'), ('patients', 'patient'), ('.', '.')]

>> Lemmatization: 
 [('registration', 'registration'), ('patients', 'patient'), ('.', '.')]



========================================== PARAGRAPH 173 ===========================================

E. Automotive  

------------------- Sentence 1 -------------------

E. Automotive

>> Tokens are: 
 ['E.', 'Automotive']

>> Bigrams are: 
 [('E.', 'Automotive')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.', 'NNP'), ('Automotive', 'NNP')]

>> Noun Phrases are: 
 ['E. Automotive']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.', 'e.'), ('Automotive', 'automot')]

>> Stemming using Snowball Stemmer: 
 [('E.', 'e.'), ('Automotive', 'automot')]

>> Lemmatization: 
 [('E.', 'E.'), ('Automotive', 'Automotive')]



========================================== PARAGRAPH 174 ===========================================

Self driving cars are one of most significant  

------------------- Sentence 1 -------------------

Self driving cars are one of most significant

>> Tokens are: 
 ['Self', 'driving', 'cars', 'one', 'significant']

>> Bigrams are: 
 [('Self', 'driving'), ('driving', 'cars'), ('cars', 'one'), ('one', 'significant')]

>> Trigrams are: 
 [('Self', 'driving', 'cars'), ('driving', 'cars', 'one'), ('cars', 'one', 'significant')]

>> POS Tags are: 
 [('Self', 'NNP'), ('driving', 'VBG'), ('cars', 'NNS'), ('one', 'CD'), ('significant', 'JJ')]

>> Noun Phrases are: 
 ['Self', 'cars']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Self', 'self'), ('driving', 'drive'), ('cars', 'car'), ('one', 'one'), ('significant', 'signific')]

>> Stemming using Snowball Stemmer: 
 [('Self', 'self'), ('driving', 'drive'), ('cars', 'car'), ('one', 'one'), ('significant', 'signific')]

>> Lemmatization: 
 [('Self', 'Self'), ('driving', 'driving'), ('cars', 'car'), ('one', 'one'), ('significant', 'significant')]



========================================== PARAGRAPH 175 ===========================================

innovations in this field. NLP enables human computer  

------------------- Sentence 1 -------------------

innovations in this field.

>> Tokens are: 
 ['innovations', 'field', '.']

>> Bigrams are: 
 [('innovations', 'field'), ('field', '.')]

>> Trigrams are: 
 [('innovations', 'field', '.')]

>> POS Tags are: 
 [('innovations', 'NNS'), ('field', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['innovations field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('innovations', 'innov'), ('field', 'field'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('innovations', 'innov'), ('field', 'field'), ('.', '.')]

>> Lemmatization: 
 [('innovations', 'innovation'), ('field', 'field'), ('.', '.')]


------------------- Sentence 2 -------------------

NLP enables human computer

>> Tokens are: 
 ['NLP', 'enables', 'human', 'computer']

>> Bigrams are: 
 [('NLP', 'enables'), ('enables', 'human'), ('human', 'computer')]

>> Trigrams are: 
 [('NLP', 'enables', 'human'), ('enables', 'human', 'computer')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('enables', 'VBZ'), ('human', 'JJ'), ('computer', 'NN')]

>> Noun Phrases are: 
 ['NLP', 'human computer']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('enables', 'enabl'), ('human', 'human'), ('computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('enables', 'enabl'), ('human', 'human'), ('computer', 'comput')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('enables', 'enables'), ('human', 'human'), ('computer', 'computer')]



========================================== PARAGRAPH 176 ===========================================

interface in what is now called as “in-car assistants”  

------------------- Sentence 1 -------------------

interface in what is now called as “in-car assistants”

>> Tokens are: 
 ['interface', 'called', '“', 'in-car', 'assistants', '”']

>> Bigrams are: 
 [('interface', 'called'), ('called', '“'), ('“', 'in-car'), ('in-car', 'assistants'), ('assistants', '”')]

>> Trigrams are: 
 [('interface', 'called', '“'), ('called', '“', 'in-car'), ('“', 'in-car', 'assistants'), ('in-car', 'assistants', '”')]

>> POS Tags are: 
 [('interface', 'NN'), ('called', 'VBN'), ('“', 'CD'), ('in-car', 'JJ'), ('assistants', 'NNS'), ('”', 'VB')]

>> Noun Phrases are: 
 ['interface', 'in-car assistants']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interface', 'interfac'), ('called', 'call'), ('“', '“'), ('in-car', 'in-car'), ('assistants', 'assist'), ('”', '”')]

>> Stemming using Snowball Stemmer: 
 [('interface', 'interfac'), ('called', 'call'), ('“', '“'), ('in-car', 'in-car'), ('assistants', 'assist'), ('”', '”')]

>> Lemmatization: 
 [('interface', 'interface'), ('called', 'called'), ('“', '“'), ('in-car', 'in-car'), ('assistants', 'assistant'), ('”', '”')]



========================================== PARAGRAPH 177 ===========================================

which is gaining popularity in the industry.  

------------------- Sentence 1 -------------------

which is gaining popularity in the industry.

>> Tokens are: 
 ['gaining', 'popularity', 'industry', '.']

>> Bigrams are: 
 [('gaining', 'popularity'), ('popularity', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('gaining', 'popularity', 'industry'), ('popularity', 'industry', '.')]

>> POS Tags are: 
 [('gaining', 'VBG'), ('popularity', 'NN'), ('industry', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['popularity industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('gaining', 'gain'), ('popularity', 'popular'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('gaining', 'gain'), ('popularity', 'popular'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('gaining', 'gaining'), ('popularity', 'popularity'), ('industry', 'industry'), ('.', '.')]



========================================== PARAGRAPH 178 ===========================================

F. Finance  

------------------- Sentence 1 -------------------

F. Finance

>> Tokens are: 
 ['F.', 'Finance']

>> Bigrams are: 
 [('F.', 'Finance')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('F.', 'NNP'), ('Finance', 'NNP')]

>> Noun Phrases are: 
 ['F. Finance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('F.', 'f.'), ('Finance', 'financ')]

>> Stemming using Snowball Stemmer: 
 [('F.', 'f.'), ('Finance', 'financ')]

>> Lemmatization: 
 [('F.', 'F.'), ('Finance', 'Finance')]



========================================== PARAGRAPH 179 ===========================================

NLP based solutions are developed in applications  

------------------- Sentence 1 -------------------

NLP based solutions are developed in applications

>> Tokens are: 
 ['NLP', 'based', 'solutions', 'developed', 'applications']

>> Bigrams are: 
 [('NLP', 'based'), ('based', 'solutions'), ('solutions', 'developed'), ('developed', 'applications')]

>> Trigrams are: 
 [('NLP', 'based', 'solutions'), ('based', 'solutions', 'developed'), ('solutions', 'developed', 'applications')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('based', 'VBN'), ('solutions', 'NNS'), ('developed', 'VBD'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['NLP', 'solutions', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('based', 'base'), ('solutions', 'solut'), ('developed', 'develop'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('based', 'base'), ('solutions', 'solut'), ('developed', 'develop'), ('applications', 'applic')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('based', 'based'), ('solutions', 'solution'), ('developed', 'developed'), ('applications', 'application')]



========================================== PARAGRAPH 180 ===========================================

such as credit scoring, sentiment analysis and document  

------------------- Sentence 1 -------------------

such as credit scoring, sentiment analysis and document

>> Tokens are: 
 ['credit', 'scoring', ',', 'sentiment', 'analysis', 'document']

>> Bigrams are: 
 [('credit', 'scoring'), ('scoring', ','), (',', 'sentiment'), ('sentiment', 'analysis'), ('analysis', 'document')]

>> Trigrams are: 
 [('credit', 'scoring', ','), ('scoring', ',', 'sentiment'), (',', 'sentiment', 'analysis'), ('sentiment', 'analysis', 'document')]

>> POS Tags are: 
 [('credit', 'NN'), ('scoring', 'NN'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), ('document', 'NN')]

>> Noun Phrases are: 
 ['credit scoring', 'sentiment analysis document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('credit', 'credit'), ('scoring', 'score'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('document', 'document')]

>> Stemming using Snowball Stemmer: 
 [('credit', 'credit'), ('scoring', 'score'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('document', 'document')]

>> Lemmatization: 
 [('credit', 'credit'), ('scoring', 'scoring'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('document', 'document')]



========================================== PARAGRAPH 181 ===========================================

search. Credit scoring application help the banks and  

------------------- Sentence 1 -------------------

search.

>> Tokens are: 
 ['search', '.']

>> Bigrams are: 
 [('search', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('search', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('search', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('search', 'search'), ('.', '.')]

>> Lemmatization: 
 [('search', 'search'), ('.', '.')]


------------------- Sentence 2 -------------------

Credit scoring application help the banks and

>> Tokens are: 
 ['Credit', 'scoring', 'application', 'help', 'banks']

>> Bigrams are: 
 [('Credit', 'scoring'), ('scoring', 'application'), ('application', 'help'), ('help', 'banks')]

>> Trigrams are: 
 [('Credit', 'scoring', 'application'), ('scoring', 'application', 'help'), ('application', 'help', 'banks')]

>> POS Tags are: 
 [('Credit', 'NN'), ('scoring', 'VBG'), ('application', 'NN'), ('help', 'NN'), ('banks', 'NNS')]

>> Noun Phrases are: 
 ['Credit', 'application help banks']

>> Named Entities are: 
 [('GPE', 'Credit')] 

>> Stemming using Porter Stemmer: 
 [('Credit', 'credit'), ('scoring', 'score'), ('application', 'applic'), ('help', 'help'), ('banks', 'bank')]

>> Stemming using Snowball Stemmer: 
 [('Credit', 'credit'), ('scoring', 'score'), ('application', 'applic'), ('help', 'help'), ('banks', 'bank')]

>> Lemmatization: 
 [('Credit', 'Credit'), ('scoring', 'scoring'), ('application', 'application'), ('help', 'help'), ('banks', 'bank')]



========================================== PARAGRAPH 182 ===========================================

financial institutions assess an individual’s  

------------------- Sentence 1 -------------------

financial institutions assess an individual’s

>> Tokens are: 
 ['financial', 'institutions', 'assess', 'individual', '’']

>> Bigrams are: 
 [('financial', 'institutions'), ('institutions', 'assess'), ('assess', 'individual'), ('individual', '’')]

>> Trigrams are: 
 [('financial', 'institutions', 'assess'), ('institutions', 'assess', 'individual'), ('assess', 'individual', '’')]

>> POS Tags are: 
 [('financial', 'JJ'), ('institutions', 'NNS'), ('assess', 'IN'), ('individual', 'JJ'), ('’', 'NN')]

>> Noun Phrases are: 
 ['financial institutions', 'individual ’']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('financial', 'financi'), ('institutions', 'institut'), ('assess', 'assess'), ('individual', 'individu'), ('’', '’')]

>> Stemming using Snowball Stemmer: 
 [('financial', 'financi'), ('institutions', 'institut'), ('assess', 'assess'), ('individual', 'individu'), ('’', '’')]

>> Lemmatization: 
 [('financial', 'financial'), ('institutions', 'institution'), ('assess', 'ass'), ('individual', 'individual'), ('’', '’')]



========================================== PARAGRAPH 183 ===========================================

creditworthiness and provide credit score using NLP and  

------------------- Sentence 1 -------------------

creditworthiness and provide credit score using NLP and

>> Tokens are: 
 ['creditworthiness', 'provide', 'credit', 'score', 'using', 'NLP']

>> Bigrams are: 
 [('creditworthiness', 'provide'), ('provide', 'credit'), ('credit', 'score'), ('score', 'using'), ('using', 'NLP')]

>> Trigrams are: 
 [('creditworthiness', 'provide', 'credit'), ('provide', 'credit', 'score'), ('credit', 'score', 'using'), ('score', 'using', 'NLP')]

>> POS Tags are: 
 [('creditworthiness', 'NN'), ('provide', 'VB'), ('credit', 'NN'), ('score', 'NN'), ('using', 'VBG'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['creditworthiness', 'credit score', 'NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('creditworthiness', 'creditworthi'), ('provide', 'provid'), ('credit', 'credit'), ('score', 'score'), ('using', 'use'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('creditworthiness', 'creditworthi'), ('provide', 'provid'), ('credit', 'credit'), ('score', 'score'), ('using', 'use'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('creditworthiness', 'creditworthiness'), ('provide', 'provide'), ('credit', 'credit'), ('score', 'score'), ('using', 'using'), ('NLP', 'NLP')]



========================================== PARAGRAPH 184 ===========================================

machine learning.  In sentiment analysis applications  

------------------- Sentence 1 -------------------

machine learning.

>> Tokens are: 
 ['machine', 'learning', '.']

>> Bigrams are: 
 [('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('machine', 'learning', '.')]

>> POS Tags are: 
 [('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('machine', 'machine'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

In sentiment analysis applications

>> Tokens are: 
 ['In', 'sentiment', 'analysis', 'applications']

>> Bigrams are: 
 [('In', 'sentiment'), ('sentiment', 'analysis'), ('analysis', 'applications')]

>> Trigrams are: 
 [('In', 'sentiment', 'analysis'), ('sentiment', 'analysis', 'applications')]

>> POS Tags are: 
 [('In', 'IN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('applications', 'NNS')]

>> Noun Phrases are: 
 ['sentiment analysis applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('applications', 'applic')]

>> Lemmatization: 
 [('In', 'In'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('applications', 'application')]



========================================== PARAGRAPH 185 ===========================================

automate the tasks of text mining for real time  

------------------- Sentence 1 -------------------

automate the tasks of text mining for real time

>> Tokens are: 
 ['automate', 'tasks', 'text', 'mining', 'real', 'time']

>> Bigrams are: 
 [('automate', 'tasks'), ('tasks', 'text'), ('text', 'mining'), ('mining', 'real'), ('real', 'time')]

>> Trigrams are: 
 [('automate', 'tasks', 'text'), ('tasks', 'text', 'mining'), ('text', 'mining', 'real'), ('mining', 'real', 'time')]

>> POS Tags are: 
 [('automate', 'NN'), ('tasks', 'NNS'), ('text', 'IN'), ('mining', 'VBG'), ('real', 'JJ'), ('time', 'NN')]

>> Noun Phrases are: 
 ['automate tasks', 'real time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automate', 'autom'), ('tasks', 'task'), ('text', 'text'), ('mining', 'mine'), ('real', 'real'), ('time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('automate', 'autom'), ('tasks', 'task'), ('text', 'text'), ('mining', 'mine'), ('real', 'real'), ('time', 'time')]

>> Lemmatization: 
 [('automate', 'automate'), ('tasks', 'task'), ('text', 'text'), ('mining', 'mining'), ('real', 'real'), ('time', 'time')]



========================================== PARAGRAPH 186 ===========================================

information on market from news site and social media  

------------------- Sentence 1 -------------------

information on market from news site and social media

>> Tokens are: 
 ['information', 'market', 'news', 'site', 'social', 'media']

>> Bigrams are: 
 [('information', 'market'), ('market', 'news'), ('news', 'site'), ('site', 'social'), ('social', 'media')]

>> Trigrams are: 
 [('information', 'market', 'news'), ('market', 'news', 'site'), ('news', 'site', 'social'), ('site', 'social', 'media')]

>> POS Tags are: 
 [('information', 'NN'), ('market', 'NN'), ('news', 'NN'), ('site', 'NN'), ('social', 'JJ'), ('media', 'NNS')]

>> Noun Phrases are: 
 ['information market news site', 'social media']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('market', 'market'), ('news', 'news'), ('site', 'site'), ('social', 'social'), ('media', 'media')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('market', 'market'), ('news', 'news'), ('site', 'site'), ('social', 'social'), ('media', 'media')]

>> Lemmatization: 
 [('information', 'information'), ('market', 'market'), ('news', 'news'), ('site', 'site'), ('social', 'social'), ('media', 'medium')]



========================================== PARAGRAPH 187 ===========================================

and then perform document classification and named  

------------------- Sentence 1 -------------------

and then perform document classification and named

>> Tokens are: 
 ['perform', 'document', 'classification', 'named']

>> Bigrams are: 
 [('perform', 'document'), ('document', 'classification'), ('classification', 'named')]

>> Trigrams are: 
 [('perform', 'document', 'classification'), ('document', 'classification', 'named')]

>> POS Tags are: 
 [('perform', 'NN'), ('document', 'NN'), ('classification', 'NN'), ('named', 'VBN')]

>> Noun Phrases are: 
 ['perform document classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('perform', 'perform'), ('document', 'document'), ('classification', 'classif'), ('named', 'name')]

>> Stemming using Snowball Stemmer: 
 [('perform', 'perform'), ('document', 'document'), ('classification', 'classif'), ('named', 'name')]

>> Lemmatization: 
 [('perform', 'perform'), ('document', 'document'), ('classification', 'classification'), ('named', 'named')]



========================================== PARAGRAPH 188 ===========================================

entity recognition to filter out most relevant information  

------------------- Sentence 1 -------------------

entity recognition to filter out most relevant information

>> Tokens are: 
 ['entity', 'recognition', 'filter', 'relevant', 'information']

>> Bigrams are: 
 [('entity', 'recognition'), ('recognition', 'filter'), ('filter', 'relevant'), ('relevant', 'information')]

>> Trigrams are: 
 [('entity', 'recognition', 'filter'), ('recognition', 'filter', 'relevant'), ('filter', 'relevant', 'information')]

>> POS Tags are: 
 [('entity', 'NN'), ('recognition', 'NN'), ('filter', 'NN'), ('relevant', 'JJ'), ('information', 'NN')]

>> Noun Phrases are: 
 ['entity recognition filter', 'relevant information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('entity', 'entiti'), ('recognition', 'recognit'), ('filter', 'filter'), ('relevant', 'relev'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('entity', 'entiti'), ('recognition', 'recognit'), ('filter', 'filter'), ('relevant', 'relev'), ('information', 'inform')]

>> Lemmatization: 
 [('entity', 'entity'), ('recognition', 'recognition'), ('filter', 'filter'), ('relevant', 'relevant'), ('information', 'information')]



========================================== PARAGRAPH 189 ===========================================

to the investors needs.In document search applications,  

------------------- Sentence 1 -------------------

to the investors needs.In document search applications,

>> Tokens are: 
 ['investors', 'needs.In', 'document', 'search', 'applications', ',']

>> Bigrams are: 
 [('investors', 'needs.In'), ('needs.In', 'document'), ('document', 'search'), ('search', 'applications'), ('applications', ',')]

>> Trigrams are: 
 [('investors', 'needs.In', 'document'), ('needs.In', 'document', 'search'), ('document', 'search', 'applications'), ('search', 'applications', ',')]

>> POS Tags are: 
 [('investors', 'NNS'), ('needs.In', 'VBP'), ('document', 'JJ'), ('search', 'NN'), ('applications', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['investors', 'document search applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('investors', 'investor'), ('needs.In', 'needs.in'), ('document', 'document'), ('search', 'search'), ('applications', 'applic'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('investors', 'investor'), ('needs.In', 'needs.in'), ('document', 'document'), ('search', 'search'), ('applications', 'applic'), (',', ',')]

>> Lemmatization: 
 [('investors', 'investor'), ('needs.In', 'needs.In'), ('document', 'document'), ('search', 'search'), ('applications', 'application'), (',', ',')]



========================================== PARAGRAPH 190 ===========================================

the banks or financial institutions uses chatbot interface  

------------------- Sentence 1 -------------------

the banks or financial institutions uses chatbot interface

>> Tokens are: 
 ['banks', 'financial', 'institutions', 'uses', 'chatbot', 'interface']

>> Bigrams are: 
 [('banks', 'financial'), ('financial', 'institutions'), ('institutions', 'uses'), ('uses', 'chatbot'), ('chatbot', 'interface')]

>> Trigrams are: 
 [('banks', 'financial', 'institutions'), ('financial', 'institutions', 'uses'), ('institutions', 'uses', 'chatbot'), ('uses', 'chatbot', 'interface')]

>> POS Tags are: 
 [('banks', 'NNS'), ('financial', 'JJ'), ('institutions', 'NNS'), ('uses', 'VBZ'), ('chatbot', 'JJ'), ('interface', 'NN')]

>> Noun Phrases are: 
 ['banks', 'financial institutions', 'chatbot interface']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('banks', 'bank'), ('financial', 'financi'), ('institutions', 'institut'), ('uses', 'use'), ('chatbot', 'chatbot'), ('interface', 'interfac')]

>> Stemming using Snowball Stemmer: 
 [('banks', 'bank'), ('financial', 'financi'), ('institutions', 'institut'), ('uses', 'use'), ('chatbot', 'chatbot'), ('interface', 'interfac')]

>> Lemmatization: 
 [('banks', 'bank'), ('financial', 'financial'), ('institutions', 'institution'), ('uses', 'us'), ('chatbot', 'chatbot'), ('interface', 'interface')]



========================================== PARAGRAPH 191 ===========================================

that enables its customers to search for information and  

------------------- Sentence 1 -------------------

that enables its customers to search for information and

>> Tokens are: 
 ['enables', 'customers', 'search', 'information']

>> Bigrams are: 
 [('enables', 'customers'), ('customers', 'search'), ('search', 'information')]

>> Trigrams are: 
 [('enables', 'customers', 'search'), ('customers', 'search', 'information')]

>> POS Tags are: 
 [('enables', 'NNS'), ('customers', 'NNS'), ('search', 'VBP'), ('information', 'NN')]

>> Noun Phrases are: 
 ['enables customers', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('enables', 'enabl'), ('customers', 'custom'), ('search', 'search'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('enables', 'enabl'), ('customers', 'custom'), ('search', 'search'), ('information', 'inform')]

>> Lemmatization: 
 [('enables', 'enables'), ('customers', 'customer'), ('search', 'search'), ('information', 'information')]



========================================== PARAGRAPH 192 ===========================================

get answers to basic transactional queries.  

------------------- Sentence 1 -------------------

get answers to basic transactional queries.

>> Tokens are: 
 ['get', 'answers', 'basic', 'transactional', 'queries', '.']

>> Bigrams are: 
 [('get', 'answers'), ('answers', 'basic'), ('basic', 'transactional'), ('transactional', 'queries'), ('queries', '.')]

>> Trigrams are: 
 [('get', 'answers', 'basic'), ('answers', 'basic', 'transactional'), ('basic', 'transactional', 'queries'), ('transactional', 'queries', '.')]

>> POS Tags are: 
 [('get', 'NN'), ('answers', 'NNS'), ('basic', 'JJ'), ('transactional', 'JJ'), ('queries', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['get answers', 'basic transactional queries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('get', 'get'), ('answers', 'answer'), ('basic', 'basic'), ('transactional', 'transact'), ('queries', 'queri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('get', 'get'), ('answers', 'answer'), ('basic', 'basic'), ('transactional', 'transact'), ('queries', 'queri'), ('.', '.')]

>> Lemmatization: 
 [('get', 'get'), ('answers', 'answer'), ('basic', 'basic'), ('transactional', 'transactional'), ('queries', 'query'), ('.', '.')]



========================================== PARAGRAPH 193 ===========================================

G. Manufacturing   

------------------- Sentence 1 -------------------

G. Manufacturing

>> Tokens are: 
 ['G.', 'Manufacturing']

>> Bigrams are: 
 [('G.', 'Manufacturing')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('G.', 'NNP'), ('Manufacturing', 'NNP')]

>> Noun Phrases are: 
 ['G. Manufacturing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('G.', 'g.'), ('Manufacturing', 'manufactur')]

>> Stemming using Snowball Stemmer: 
 [('G.', 'g.'), ('Manufacturing', 'manufactur')]

>> Lemmatization: 
 [('G.', 'G.'), ('Manufacturing', 'Manufacturing')]



========================================== PARAGRAPH 194 ===========================================

Robotics and Process Automation are two very  

------------------- Sentence 1 -------------------

Robotics and Process Automation are two very

>> Tokens are: 
 ['Robotics', 'Process', 'Automation', 'two']

>> Bigrams are: 
 [('Robotics', 'Process'), ('Process', 'Automation'), ('Automation', 'two')]

>> Trigrams are: 
 [('Robotics', 'Process', 'Automation'), ('Process', 'Automation', 'two')]

>> POS Tags are: 
 [('Robotics', 'NNS'), ('Process', 'NNP'), ('Automation', 'NNP'), ('two', 'CD')]

>> Noun Phrases are: 
 ['Robotics Process Automation']

>> Named Entities are: 
 [('ORGANIZATION', 'Process')] 

>> Stemming using Porter Stemmer: 
 [('Robotics', 'robot'), ('Process', 'process'), ('Automation', 'autom'), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('Robotics', 'robot'), ('Process', 'process'), ('Automation', 'autom'), ('two', 'two')]

>> Lemmatization: 
 [('Robotics', 'Robotics'), ('Process', 'Process'), ('Automation', 'Automation'), ('two', 'two')]



========================================== PARAGRAPH 195 ===========================================

promising applications areas that will employ Natural  

------------------- Sentence 1 -------------------

promising applications areas that will employ Natural

>> Tokens are: 
 ['promising', 'applications', 'areas', 'employ', 'Natural']

>> Bigrams are: 
 [('promising', 'applications'), ('applications', 'areas'), ('areas', 'employ'), ('employ', 'Natural')]

>> Trigrams are: 
 [('promising', 'applications', 'areas'), ('applications', 'areas', 'employ'), ('areas', 'employ', 'Natural')]

>> POS Tags are: 
 [('promising', 'VBG'), ('applications', 'NNS'), ('areas', 'NNS'), ('employ', 'VBP'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['applications areas', 'Natural']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural')] 

>> Stemming using Porter Stemmer: 
 [('promising', 'promis'), ('applications', 'applic'), ('areas', 'area'), ('employ', 'employ'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('promising', 'promis'), ('applications', 'applic'), ('areas', 'area'), ('employ', 'employ'), ('Natural', 'natur')]

>> Lemmatization: 
 [('promising', 'promising'), ('applications', 'application'), ('areas', 'area'), ('employ', 'employ'), ('Natural', 'Natural')]



========================================== PARAGRAPH 196 ===========================================

Language Processing capabilities. Using NLP, Robot on  

------------------- Sentence 1 -------------------

Language Processing capabilities.

>> Tokens are: 
 ['Language', 'Processing', 'capabilities', '.']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', 'capabilities'), ('capabilities', '.')]

>> Trigrams are: 
 [('Language', 'Processing', 'capabilities'), ('Processing', 'capabilities', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'VBG'), ('capabilities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Language', 'capabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('capabilities', 'capabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('capabilities', 'capabl'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('capabilities', 'capability'), ('.', '.')]


------------------- Sentence 2 -------------------

Using NLP, Robot on

>> Tokens are: 
 ['Using', 'NLP', ',', 'Robot']

>> Bigrams are: 
 [('Using', 'NLP'), ('NLP', ','), (',', 'Robot')]

>> Trigrams are: 
 [('Using', 'NLP', ','), ('NLP', ',', 'Robot')]

>> POS Tags are: 
 [('Using', 'VBG'), ('NLP', 'NNP'), (',', ','), ('Robot', 'NNP')]

>> Noun Phrases are: 
 ['NLP', 'Robot']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('PERSON', 'Robot')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('NLP', 'nlp'), (',', ','), ('Robot', 'robot')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('NLP', 'nlp'), (',', ','), ('Robot', 'robot')]

>> Lemmatization: 
 [('Using', 'Using'), ('NLP', 'NLP'), (',', ','), ('Robot', 'Robot')]



========================================== PARAGRAPH 197 ===========================================

a manufacturing floor can interact with human operator at  

------------------- Sentence 1 -------------------

a manufacturing floor can interact with human operator at

>> Tokens are: 
 ['manufacturing', 'floor', 'interact', 'human', 'operator']

>> Bigrams are: 
 [('manufacturing', 'floor'), ('floor', 'interact'), ('interact', 'human'), ('human', 'operator')]

>> Trigrams are: 
 [('manufacturing', 'floor', 'interact'), ('floor', 'interact', 'human'), ('interact', 'human', 'operator')]

>> POS Tags are: 
 [('manufacturing', 'VBG'), ('floor', 'NN'), ('interact', 'JJ'), ('human', 'NN'), ('operator', 'NN')]

>> Noun Phrases are: 
 ['floor', 'interact human operator']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('manufacturing', 'manufactur'), ('floor', 'floor'), ('interact', 'interact'), ('human', 'human'), ('operator', 'oper')]

>> Stemming using Snowball Stemmer: 
 [('manufacturing', 'manufactur'), ('floor', 'floor'), ('interact', 'interact'), ('human', 'human'), ('operator', 'oper')]

>> Lemmatization: 
 [('manufacturing', 'manufacturing'), ('floor', 'floor'), ('interact', 'interact'), ('human', 'human'), ('operator', 'operator')]



========================================== PARAGRAPH 198 ===========================================

a remote place and process instructions for assembly and  

------------------- Sentence 1 -------------------

a remote place and process instructions for assembly and

>> Tokens are: 
 ['remote', 'place', 'process', 'instructions', 'assembly']

>> Bigrams are: 
 [('remote', 'place'), ('place', 'process'), ('process', 'instructions'), ('instructions', 'assembly')]

>> Trigrams are: 
 [('remote', 'place', 'process'), ('place', 'process', 'instructions'), ('process', 'instructions', 'assembly')]

>> POS Tags are: 
 [('remote', 'JJ'), ('place', 'NN'), ('process', 'NN'), ('instructions', 'NNS'), ('assembly', 'RB')]

>> Noun Phrases are: 
 ['remote place process instructions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('remote', 'remot'), ('place', 'place'), ('process', 'process'), ('instructions', 'instruct'), ('assembly', 'assembl')]

>> Stemming using Snowball Stemmer: 
 [('remote', 'remot'), ('place', 'place'), ('process', 'process'), ('instructions', 'instruct'), ('assembly', 'assembl')]

>> Lemmatization: 
 [('remote', 'remote'), ('place', 'place'), ('process', 'process'), ('instructions', 'instruction'), ('assembly', 'assembly')]



========================================== PARAGRAPH 199 ===========================================

movement of machines and products. The industries have  

------------------- Sentence 1 -------------------

movement of machines and products.

>> Tokens are: 
 ['movement', 'machines', 'products', '.']

>> Bigrams are: 
 [('movement', 'machines'), ('machines', 'products'), ('products', '.')]

>> Trigrams are: 
 [('movement', 'machines', 'products'), ('machines', 'products', '.')]

>> POS Tags are: 
 [('movement', 'NN'), ('machines', 'NNS'), ('products', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['movement machines products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('movement', 'movement'), ('machines', 'machin'), ('products', 'product'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('movement', 'movement'), ('machines', 'machin'), ('products', 'product'), ('.', '.')]

>> Lemmatization: 
 [('movement', 'movement'), ('machines', 'machine'), ('products', 'product'), ('.', '.')]


------------------- Sentence 2 -------------------

The industries have

>> Tokens are: 
 ['The', 'industries']

>> Bigrams are: 
 [('The', 'industries')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('industries', 'NNS')]

>> Noun Phrases are: 
 ['The industries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('industries', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('industries', 'industri')]

>> Lemmatization: 
 [('The', 'The'), ('industries', 'industry')]



========================================== PARAGRAPH 200 ===========================================

already begun to use NLP based solution to automate  

------------------- Sentence 1 -------------------

already begun to use NLP based solution to automate

>> Tokens are: 
 ['already', 'begun', 'use', 'NLP', 'based', 'solution', 'automate']

>> Bigrams are: 
 [('already', 'begun'), ('begun', 'use'), ('use', 'NLP'), ('NLP', 'based'), ('based', 'solution'), ('solution', 'automate')]

>> Trigrams are: 
 [('already', 'begun', 'use'), ('begun', 'use', 'NLP'), ('use', 'NLP', 'based'), ('NLP', 'based', 'solution'), ('based', 'solution', 'automate')]

>> POS Tags are: 
 [('already', 'RB'), ('begun', 'VBN'), ('use', 'NN'), ('NLP', 'NNP'), ('based', 'VBN'), ('solution', 'NN'), ('automate', 'NN')]

>> Noun Phrases are: 
 ['use NLP', 'solution automate']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('already', 'alreadi'), ('begun', 'begun'), ('use', 'use'), ('NLP', 'nlp'), ('based', 'base'), ('solution', 'solut'), ('automate', 'autom')]

>> Stemming using Snowball Stemmer: 
 [('already', 'alreadi'), ('begun', 'begun'), ('use', 'use'), ('NLP', 'nlp'), ('based', 'base'), ('solution', 'solut'), ('automate', 'autom')]

>> Lemmatization: 
 [('already', 'already'), ('begun', 'begun'), ('use', 'use'), ('NLP', 'NLP'), ('based', 'based'), ('solution', 'solution'), ('automate', 'automate')]



========================================== PARAGRAPH 201 ===========================================

their process workflow for improving efficiency of  

------------------- Sentence 1 -------------------

their process workflow for improving efficiency of

>> Tokens are: 
 ['process', 'workflow', 'improving', 'efficiency']

>> Bigrams are: 
 [('process', 'workflow'), ('workflow', 'improving'), ('improving', 'efficiency')]

>> Trigrams are: 
 [('process', 'workflow', 'improving'), ('workflow', 'improving', 'efficiency')]

>> POS Tags are: 
 [('process', 'NN'), ('workflow', 'IN'), ('improving', 'VBG'), ('efficiency', 'NN')]

>> Noun Phrases are: 
 ['process', 'efficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('workflow', 'workflow'), ('improving', 'improv'), ('efficiency', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('workflow', 'workflow'), ('improving', 'improv'), ('efficiency', 'effici')]

>> Lemmatization: 
 [('process', 'process'), ('workflow', 'workflow'), ('improving', 'improving'), ('efficiency', 'efficiency')]



========================================== PARAGRAPH 202 ===========================================

operations.   

------------------- Sentence 1 -------------------

operations.

>> Tokens are: 
 ['operations', '.']

>> Bigrams are: 
 [('operations', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('operations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['operations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('operations', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('operations', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('operations', 'operation'), ('.', '.')]



========================================== PARAGRAPH 203 ===========================================

H. Retail  

------------------- Sentence 1 -------------------

H. Retail

>> Tokens are: 
 ['H.', 'Retail']

>> Bigrams are: 
 [('H.', 'Retail')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('H.', 'NNP'), ('Retail', 'NNP')]

>> Noun Phrases are: 
 ['H. Retail']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('H.', 'h.'), ('Retail', 'retail')]

>> Stemming using Snowball Stemmer: 
 [('H.', 'h.'), ('Retail', 'retail')]

>> Lemmatization: 
 [('H.', 'H.'), ('Retail', 'Retail')]



========================================== PARAGRAPH 204 ===========================================

Using Natural Language, Computer Vision and  

------------------- Sentence 1 -------------------

Using Natural Language, Computer Vision and

>> Tokens are: 
 ['Using', 'Natural', 'Language', ',', 'Computer', 'Vision']

>> Bigrams are: 
 [('Using', 'Natural'), ('Natural', 'Language'), ('Language', ','), (',', 'Computer'), ('Computer', 'Vision')]

>> Trigrams are: 
 [('Using', 'Natural', 'Language'), ('Natural', 'Language', ','), ('Language', ',', 'Computer'), (',', 'Computer', 'Vision')]

>> POS Tags are: 
 [('Using', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), (',', ','), ('Computer', 'NNP'), ('Vision', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language', 'Computer Vision']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language'), ('ORGANIZATION', 'Computer Vision')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), (',', ','), ('Computer', 'comput'), ('Vision', 'vision')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), (',', ','), ('Computer', 'comput'), ('Vision', 'vision')]

>> Lemmatization: 
 [('Using', 'Using'), ('Natural', 'Natural'), ('Language', 'Language'), (',', ','), ('Computer', 'Computer'), ('Vision', 'Vision')]



========================================== PARAGRAPH 205 ===========================================

Machine learning technologies, a Virtual Assistant placed  

------------------- Sentence 1 -------------------

Machine learning technologies, a Virtual Assistant placed

>> Tokens are: 
 ['Machine', 'learning', 'technologies', ',', 'Virtual', 'Assistant', 'placed']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'technologies'), ('technologies', ','), (',', 'Virtual'), ('Virtual', 'Assistant'), ('Assistant', 'placed')]

>> Trigrams are: 
 [('Machine', 'learning', 'technologies'), ('learning', 'technologies', ','), ('technologies', ',', 'Virtual'), (',', 'Virtual', 'Assistant'), ('Virtual', 'Assistant', 'placed')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('technologies', 'NNS'), (',', ','), ('Virtual', 'NNP'), ('Assistant', 'NNP'), ('placed', 'VBD')]

>> Noun Phrases are: 
 ['Machine', 'technologies', 'Virtual Assistant']

>> Named Entities are: 
 [('GPE', 'Machine'), ('PERSON', 'Virtual Assistant')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('technologies', 'technolog'), (',', ','), ('Virtual', 'virtual'), ('Assistant', 'assist'), ('placed', 'place')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('technologies', 'technolog'), (',', ','), ('Virtual', 'virtual'), ('Assistant', 'assist'), ('placed', 'place')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('technologies', 'technology'), (',', ','), ('Virtual', 'Virtual'), ('Assistant', 'Assistant'), ('placed', 'placed')]



========================================== PARAGRAPH 206 ===========================================

in front of the Retail shop can identify and know what  

------------------- Sentence 1 -------------------

in front of the Retail shop can identify and know what

>> Tokens are: 
 ['front', 'Retail', 'shop', 'identify', 'know']

>> Bigrams are: 
 [('front', 'Retail'), ('Retail', 'shop'), ('shop', 'identify'), ('identify', 'know')]

>> Trigrams are: 
 [('front', 'Retail', 'shop'), ('Retail', 'shop', 'identify'), ('shop', 'identify', 'know')]

>> POS Tags are: 
 [('front', 'JJ'), ('Retail', 'NNP'), ('shop', 'NN'), ('identify', 'NN'), ('know', 'VBP')]

>> Noun Phrases are: 
 ['front Retail shop identify']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('front', 'front'), ('Retail', 'retail'), ('shop', 'shop'), ('identify', 'identifi'), ('know', 'know')]

>> Stemming using Snowball Stemmer: 
 [('front', 'front'), ('Retail', 'retail'), ('shop', 'shop'), ('identify', 'identifi'), ('know', 'know')]

>> Lemmatization: 
 [('front', 'front'), ('Retail', 'Retail'), ('shop', 'shop'), ('identify', 'identify'), ('know', 'know')]



========================================== PARAGRAPH 207 ===========================================

customer wants and provide them quick information and  

------------------- Sentence 1 -------------------

customer wants and provide them quick information and

>> Tokens are: 
 ['customer', 'wants', 'provide', 'quick', 'information']

>> Bigrams are: 
 [('customer', 'wants'), ('wants', 'provide'), ('provide', 'quick'), ('quick', 'information')]

>> Trigrams are: 
 [('customer', 'wants', 'provide'), ('wants', 'provide', 'quick'), ('provide', 'quick', 'information')]

>> POS Tags are: 
 [('customer', 'NN'), ('wants', 'VBZ'), ('provide', 'VB'), ('quick', 'JJ'), ('information', 'NN')]

>> Noun Phrases are: 
 ['customer', 'quick information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('customer', 'custom'), ('wants', 'want'), ('provide', 'provid'), ('quick', 'quick'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('customer', 'custom'), ('wants', 'want'), ('provide', 'provid'), ('quick', 'quick'), ('information', 'inform')]

>> Lemmatization: 
 [('customer', 'customer'), ('wants', 'want'), ('provide', 'provide'), ('quick', 'quick'), ('information', 'information')]



========================================== PARAGRAPH 208 ===========================================

promotional offers. The specialized virtual assistant also  

------------------- Sentence 1 -------------------

promotional offers.

>> Tokens are: 
 ['promotional', 'offers', '.']

>> Bigrams are: 
 [('promotional', 'offers'), ('offers', '.')]

>> Trigrams are: 
 [('promotional', 'offers', '.')]

>> POS Tags are: 
 [('promotional', 'JJ'), ('offers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['promotional offers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('promotional', 'promot'), ('offers', 'offer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('promotional', 'promot'), ('offers', 'offer'), ('.', '.')]

>> Lemmatization: 
 [('promotional', 'promotional'), ('offers', 'offer'), ('.', '.')]


------------------- Sentence 2 -------------------

The specialized virtual assistant also

>> Tokens are: 
 ['The', 'specialized', 'virtual', 'assistant', 'also']

>> Bigrams are: 
 [('The', 'specialized'), ('specialized', 'virtual'), ('virtual', 'assistant'), ('assistant', 'also')]

>> Trigrams are: 
 [('The', 'specialized', 'virtual'), ('specialized', 'virtual', 'assistant'), ('virtual', 'assistant', 'also')]

>> POS Tags are: 
 [('The', 'DT'), ('specialized', 'JJ'), ('virtual', 'JJ'), ('assistant', 'NN'), ('also', 'RB')]

>> Noun Phrases are: 
 ['The specialized virtual assistant']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('specialized', 'special'), ('virtual', 'virtual'), ('assistant', 'assist'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('specialized', 'special'), ('virtual', 'virtual'), ('assistant', 'assist'), ('also', 'also')]

>> Lemmatization: 
 [('The', 'The'), ('specialized', 'specialized'), ('virtual', 'virtual'), ('assistant', 'assistant'), ('also', 'also')]



========================================== PARAGRAPH 209 ===========================================

understand the shoppers comments and complaints  

------------------- Sentence 1 -------------------

understand the shoppers comments and complaints

>> Tokens are: 
 ['understand', 'shoppers', 'comments', 'complaints']

>> Bigrams are: 
 [('understand', 'shoppers'), ('shoppers', 'comments'), ('comments', 'complaints')]

>> Trigrams are: 
 [('understand', 'shoppers', 'comments'), ('shoppers', 'comments', 'complaints')]

>> POS Tags are: 
 [('understand', 'NN'), ('shoppers', 'NNS'), ('comments', 'NNS'), ('complaints', 'NNS')]

>> Noun Phrases are: 
 ['understand shoppers comments complaints']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understand', 'understand'), ('shoppers', 'shopper'), ('comments', 'comment'), ('complaints', 'complaint')]

>> Stemming using Snowball Stemmer: 
 [('understand', 'understand'), ('shoppers', 'shopper'), ('comments', 'comment'), ('complaints', 'complaint')]

>> Lemmatization: 
 [('understand', 'understand'), ('shoppers', 'shopper'), ('comments', 'comment'), ('complaints', 'complaint')]



========================================== PARAGRAPH 210 ===========================================

regarding the products and provide a quick direction for  

------------------- Sentence 1 -------------------

regarding the products and provide a quick direction for

>> Tokens are: 
 ['regarding', 'products', 'provide', 'quick', 'direction']

>> Bigrams are: 
 [('regarding', 'products'), ('products', 'provide'), ('provide', 'quick'), ('quick', 'direction')]

>> Trigrams are: 
 [('regarding', 'products', 'provide'), ('products', 'provide', 'quick'), ('provide', 'quick', 'direction')]

>> POS Tags are: 
 [('regarding', 'VBG'), ('products', 'NNS'), ('provide', 'VBP'), ('quick', 'JJ'), ('direction', 'NN')]

>> Noun Phrases are: 
 ['products', 'quick direction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('regarding', 'regard'), ('products', 'product'), ('provide', 'provid'), ('quick', 'quick'), ('direction', 'direct')]

>> Stemming using Snowball Stemmer: 
 [('regarding', 'regard'), ('products', 'product'), ('provide', 'provid'), ('quick', 'quick'), ('direction', 'direct')]

>> Lemmatization: 
 [('regarding', 'regarding'), ('products', 'product'), ('provide', 'provide'), ('quick', 'quick'), ('direction', 'direction')]



========================================== PARAGRAPH 211 ===========================================

resolution. Many e-commerce platforms are currently  

------------------- Sentence 1 -------------------

resolution.

>> Tokens are: 
 ['resolution', '.']

>> Bigrams are: 
 [('resolution', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('resolution', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['resolution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('resolution', 'resolut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('resolution', 'resolut'), ('.', '.')]

>> Lemmatization: 
 [('resolution', 'resolution'), ('.', '.')]


------------------- Sentence 2 -------------------

Many e-commerce platforms are currently

>> Tokens are: 
 ['Many', 'e-commerce', 'platforms', 'currently']

>> Bigrams are: 
 [('Many', 'e-commerce'), ('e-commerce', 'platforms'), ('platforms', 'currently')]

>> Trigrams are: 
 [('Many', 'e-commerce', 'platforms'), ('e-commerce', 'platforms', 'currently')]

>> POS Tags are: 
 [('Many', 'JJ'), ('e-commerce', 'JJ'), ('platforms', 'NNS'), ('currently', 'RB')]

>> Noun Phrases are: 
 ['Many e-commerce platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('e-commerce', 'e-commerc'), ('platforms', 'platform'), ('currently', 'current')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('e-commerce', 'e-commerc'), ('platforms', 'platform'), ('currently', 'current')]

>> Lemmatization: 
 [('Many', 'Many'), ('e-commerce', 'e-commerce'), ('platforms', 'platform'), ('currently', 'currently')]



========================================== PARAGRAPH 212 ===========================================

using conversational agents for customer support.  

------------------- Sentence 1 -------------------

using conversational agents for customer support.

>> Tokens are: 
 ['using', 'conversational', 'agents', 'customer', 'support', '.']

>> Bigrams are: 
 [('using', 'conversational'), ('conversational', 'agents'), ('agents', 'customer'), ('customer', 'support'), ('support', '.')]

>> Trigrams are: 
 [('using', 'conversational', 'agents'), ('conversational', 'agents', 'customer'), ('agents', 'customer', 'support'), ('customer', 'support', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('conversational', 'JJ'), ('agents', 'NNS'), ('customer', 'NN'), ('support', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['conversational agents customer support']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('conversational', 'convers'), ('agents', 'agent'), ('customer', 'custom'), ('support', 'support'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('conversational', 'convers'), ('agents', 'agent'), ('customer', 'custom'), ('support', 'support'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('conversational', 'conversational'), ('agents', 'agent'), ('customer', 'customer'), ('support', 'support'), ('.', '.')]



========================================== PARAGRAPH 213 ===========================================

I. Education  

------------------- Sentence 1 -------------------

I.

>> Tokens are: 
 ['I', '.']

>> Bigrams are: 
 [('I', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), ('.', '.')]


------------------- Sentence 2 -------------------

Education

>> Tokens are: 
 ['Education']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Education', 'NN')]

>> Noun Phrases are: 
 ['Education']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Education', 'educ')]

>> Stemming using Snowball Stemmer: 
 [('Education', 'educ')]

>> Lemmatization: 
 [('Education', 'Education')]



========================================== PARAGRAPH 214 ===========================================

A combination of Natural Language Processing and  

------------------- Sentence 1 -------------------

A combination of Natural Language Processing and

>> Tokens are: 
 ['A', 'combination', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('A', 'combination'), ('combination', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('A', 'combination', 'Natural'), ('combination', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('A', 'DT'), ('combination', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['A combination Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('combination', 'combin'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('combination', 'combin'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('A', 'A'), ('combination', 'combination'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 215 ===========================================

Computer vision enable a platform to deliver virtual  

------------------- Sentence 1 -------------------

Computer vision enable a platform to deliver virtual

>> Tokens are: 
 ['Computer', 'vision', 'enable', 'platform', 'deliver', 'virtual']

>> Bigrams are: 
 [('Computer', 'vision'), ('vision', 'enable'), ('enable', 'platform'), ('platform', 'deliver'), ('deliver', 'virtual')]

>> Trigrams are: 
 [('Computer', 'vision', 'enable'), ('vision', 'enable', 'platform'), ('enable', 'platform', 'deliver'), ('platform', 'deliver', 'virtual')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('vision', 'NN'), ('enable', 'JJ'), ('platform', 'NN'), ('deliver', 'NN'), ('virtual', 'JJ')]

>> Noun Phrases are: 
 ['Computer vision', 'enable platform deliver']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('vision', 'vision'), ('enable', 'enabl'), ('platform', 'platform'), ('deliver', 'deliv'), ('virtual', 'virtual')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('vision', 'vision'), ('enable', 'enabl'), ('platform', 'platform'), ('deliver', 'deliv'), ('virtual', 'virtual')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('vision', 'vision'), ('enable', 'enable'), ('platform', 'platform'), ('deliver', 'deliver'), ('virtual', 'virtual')]



========================================== PARAGRAPH 216 ===========================================

classroom for students. We have already seen the digital  

------------------- Sentence 1 -------------------

classroom for students.

>> Tokens are: 
 ['classroom', 'students', '.']

>> Bigrams are: 
 [('classroom', 'students'), ('students', '.')]

>> Trigrams are: 
 [('classroom', 'students', '.')]

>> POS Tags are: 
 [('classroom', 'NN'), ('students', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classroom students']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classroom', 'classroom'), ('students', 'student'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classroom', 'classroom'), ('students', 'student'), ('.', '.')]

>> Lemmatization: 
 [('classroom', 'classroom'), ('students', 'student'), ('.', '.')]


------------------- Sentence 2 -------------------

We have already seen the digital

>> Tokens are: 
 ['We', 'already', 'seen', 'digital']

>> Bigrams are: 
 [('We', 'already'), ('already', 'seen'), ('seen', 'digital')]

>> Trigrams are: 
 [('We', 'already', 'seen'), ('already', 'seen', 'digital')]

>> POS Tags are: 
 [('We', 'PRP'), ('already', 'RB'), ('seen', 'VBN'), ('digital', 'NN')]

>> Noun Phrases are: 
 ['digital']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('already', 'alreadi'), ('seen', 'seen'), ('digital', 'digit')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('already', 'alreadi'), ('seen', 'seen'), ('digital', 'digit')]

>> Lemmatization: 
 [('We', 'We'), ('already', 'already'), ('seen', 'seen'), ('digital', 'digital')]



========================================== PARAGRAPH 217 ===========================================

assistants helping students solving the problems from   

------------------- Sentence 1 -------------------

assistants helping students solving the problems from

>> Tokens are: 
 ['assistants', 'helping', 'students', 'solving', 'problems']

>> Bigrams are: 
 [('assistants', 'helping'), ('helping', 'students'), ('students', 'solving'), ('solving', 'problems')]

>> Trigrams are: 
 [('assistants', 'helping', 'students'), ('helping', 'students', 'solving'), ('students', 'solving', 'problems')]

>> POS Tags are: 
 [('assistants', 'NNS'), ('helping', 'VBG'), ('students', 'NNS'), ('solving', 'VBG'), ('problems', 'NNS')]

>> Noun Phrases are: 
 ['assistants', 'students', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('assistants', 'assist'), ('helping', 'help'), ('students', 'student'), ('solving', 'solv'), ('problems', 'problem')]

>> Stemming using Snowball Stemmer: 
 [('assistants', 'assist'), ('helping', 'help'), ('students', 'student'), ('solving', 'solv'), ('problems', 'problem')]

>> Lemmatization: 
 [('assistants', 'assistant'), ('helping', 'helping'), ('students', 'student'), ('solving', 'solving'), ('problems', 'problem')]



========================================== PARAGRAPH 218 ===========================================

  


========================================== PARAGRAPH 219 ===========================================

  


========================================== PARAGRAPH 220 ===========================================

 


========================================== PARAGRAPH 221 ===========================================

International Journal of Recent Technology and Engineering (IJRTE)  

------------------- Sentence 1 -------------------

International Journal of Recent Technology and Engineering (IJRTE)

>> Tokens are: 
 ['International', 'Journal', 'Recent', 'Technology', 'Engineering', '(', 'IJRTE', ')']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Recent'), ('Recent', 'Technology'), ('Technology', 'Engineering'), ('Engineering', '('), ('(', 'IJRTE'), ('IJRTE', ')')]

>> Trigrams are: 
 [('International', 'Journal', 'Recent'), ('Journal', 'Recent', 'Technology'), ('Recent', 'Technology', 'Engineering'), ('Technology', 'Engineering', '('), ('Engineering', '(', 'IJRTE'), ('(', 'IJRTE', ')')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Recent', 'NNP'), ('Technology', 'NNP'), ('Engineering', 'NNP'), ('(', '('), ('IJRTE', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['International Journal Recent Technology Engineering', 'IJRTE']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal'), ('ORGANIZATION', 'IJRTE')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Recent', 'recent'), ('Technology', 'technolog'), ('Engineering', 'engin'), ('(', '('), ('IJRTE', 'ijrt'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Recent', 'recent'), ('Technology', 'technolog'), ('Engineering', 'engin'), ('(', '('), ('IJRTE', 'ijrt'), (')', ')')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Recent', 'Recent'), ('Technology', 'Technology'), ('Engineering', 'Engineering'), ('(', '('), ('IJRTE', 'IJRTE'), (')', ')')]



========================================== PARAGRAPH 222 ===========================================

ISSN: 2277-3878, Volume-7, Issue-5C, February 2019     

------------------- Sentence 1 -------------------

ISSN: 2277-3878, Volume-7, Issue-5C, February 2019

>> Tokens are: 
 ['ISSN', ':', '2277-3878', ',', 'Volume-7', ',', 'Issue-5C', ',', 'February', '2019']

>> Bigrams are: 
 [('ISSN', ':'), (':', '2277-3878'), ('2277-3878', ','), (',', 'Volume-7'), ('Volume-7', ','), (',', 'Issue-5C'), ('Issue-5C', ','), (',', 'February'), ('February', '2019')]

>> Trigrams are: 
 [('ISSN', ':', '2277-3878'), (':', '2277-3878', ','), ('2277-3878', ',', 'Volume-7'), (',', 'Volume-7', ','), ('Volume-7', ',', 'Issue-5C'), (',', 'Issue-5C', ','), ('Issue-5C', ',', 'February'), (',', 'February', '2019')]

>> POS Tags are: 
 [('ISSN', 'NN'), (':', ':'), ('2277-3878', 'JJ'), (',', ','), ('Volume-7', 'NNP'), (',', ','), ('Issue-5C', 'NNP'), (',', ','), ('February', 'NNP'), ('2019', 'CD')]

>> Noun Phrases are: 
 ['ISSN', 'Volume-7', 'Issue-5C', 'February']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'volume-7'), (',', ','), ('Issue-5C', 'issue-5c'), (',', ','), ('February', 'februari'), ('2019', '2019')]

>> Stemming using Snowball Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'volume-7'), (',', ','), ('Issue-5C', 'issue-5c'), (',', ','), ('February', 'februari'), ('2019', '2019')]

>> Lemmatization: 
 [('ISSN', 'ISSN'), (':', ':'), ('2277-3878', '2277-3878'), (',', ','), ('Volume-7', 'Volume-7'), (',', ','), ('Issue-5C', 'Issue-5C'), (',', ','), ('February', 'February'), ('2019', '2019')]



========================================== PARAGRAPH 223 ===========================================

  


========================================== PARAGRAPH 224 ===========================================

201  

------------------- Sentence 1 -------------------

201

>> Tokens are: 
 ['201']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('201', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('201', '201')]

>> Stemming using Snowball Stemmer: 
 [('201', '201')]

>> Lemmatization: 
 [('201', '201')]



========================================== PARAGRAPH 225 ===========================================

  


========================================== PARAGRAPH 226 ===========================================

Published By:  Blue Eyes Intelligence Engineering  

------------------- Sentence 1 -------------------

Published By:  Blue Eyes Intelligence Engineering

>> Tokens are: 
 ['Published', 'By', ':', 'Blue', 'Eyes', 'Intelligence', 'Engineering']

>> Bigrams are: 
 [('Published', 'By'), ('By', ':'), (':', 'Blue'), ('Blue', 'Eyes'), ('Eyes', 'Intelligence'), ('Intelligence', 'Engineering')]

>> Trigrams are: 
 [('Published', 'By', ':'), ('By', ':', 'Blue'), (':', 'Blue', 'Eyes'), ('Blue', 'Eyes', 'Intelligence'), ('Eyes', 'Intelligence', 'Engineering')]

>> POS Tags are: 
 [('Published', 'VBN'), ('By', 'IN'), (':', ':'), ('Blue', 'JJ'), ('Eyes', 'NNS'), ('Intelligence', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['Blue Eyes Intelligence Engineering']

>> Named Entities are: 
 [('ORGANIZATION', 'Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Published', 'publish'), ('By', 'by'), (':', ':'), ('Blue', 'blue'), ('Eyes', 'eye'), ('Intelligence', 'intellig'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('Published', 'Published'), ('By', 'By'), (':', ':'), ('Blue', 'Blue'), ('Eyes', 'Eyes'), ('Intelligence', 'Intelligence'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 227 ===========================================

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP  

------------------- Sentence 1 -------------------

& Sciences Publication  Retrieval Number: E10480275C19/19©BEIESP

>> Tokens are: 
 ['&', 'Sciences', 'Publication', 'Retrieval', 'Number', ':', 'E10480275C19/19©BEIESP']

>> Bigrams are: 
 [('&', 'Sciences'), ('Sciences', 'Publication'), ('Publication', 'Retrieval'), ('Retrieval', 'Number'), ('Number', ':'), (':', 'E10480275C19/19©BEIESP')]

>> Trigrams are: 
 [('&', 'Sciences', 'Publication'), ('Sciences', 'Publication', 'Retrieval'), ('Publication', 'Retrieval', 'Number'), ('Retrieval', 'Number', ':'), ('Number', ':', 'E10480275C19/19©BEIESP')]

>> POS Tags are: 
 [('&', 'CC'), ('Sciences', 'NNPS'), ('Publication', 'NNP'), ('Retrieval', 'NNP'), ('Number', 'NNP'), (':', ':'), ('E10480275C19/19©BEIESP', 'NN')]

>> Noun Phrases are: 
 ['Publication Retrieval Number', 'E10480275C19/19©BEIESP']

>> Named Entities are: 
 [('ORGANIZATION', 'Sciences Publication Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Sciences', 'scienc'), ('Publication', 'public'), ('Retrieval', 'retriev'), ('Number', 'number'), (':', ':'), ('E10480275C19/19©BEIESP', 'e10480275c19/19©beiesp')]

>> Lemmatization: 
 [('&', '&'), ('Sciences', 'Sciences'), ('Publication', 'Publication'), ('Retrieval', 'Retrieval'), ('Number', 'Number'), (':', ':'), ('E10480275C19/19©BEIESP', 'E10480275C19/19©BEIESP')]



========================================== PARAGRAPH 228 ===========================================

expert knowledge available in digital libraries.  

------------------- Sentence 1 -------------------

expert knowledge available in digital libraries.

>> Tokens are: 
 ['expert', 'knowledge', 'available', 'digital', 'libraries', '.']

>> Bigrams are: 
 [('expert', 'knowledge'), ('knowledge', 'available'), ('available', 'digital'), ('digital', 'libraries'), ('libraries', '.')]

>> Trigrams are: 
 [('expert', 'knowledge', 'available'), ('knowledge', 'available', 'digital'), ('available', 'digital', 'libraries'), ('digital', 'libraries', '.')]

>> POS Tags are: 
 [('expert', 'NN'), ('knowledge', 'NN'), ('available', 'JJ'), ('digital', 'JJ'), ('libraries', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['expert knowledge', 'available digital libraries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('expert', 'expert'), ('knowledge', 'knowledg'), ('available', 'avail'), ('digital', 'digit'), ('libraries', 'librari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('expert', 'expert'), ('knowledge', 'knowledg'), ('available', 'avail'), ('digital', 'digit'), ('libraries', 'librari'), ('.', '.')]

>> Lemmatization: 
 [('expert', 'expert'), ('knowledge', 'knowledge'), ('available', 'available'), ('digital', 'digital'), ('libraries', 'library'), ('.', '.')]



========================================== PARAGRAPH 229 ===========================================

The top vendors delivering NLP solutions are IBM,  

------------------- Sentence 1 -------------------

The top vendors delivering NLP solutions are IBM,

>> Tokens are: 
 ['The', 'top', 'vendors', 'delivering', 'NLP', 'solutions', 'IBM', ',']

>> Bigrams are: 
 [('The', 'top'), ('top', 'vendors'), ('vendors', 'delivering'), ('delivering', 'NLP'), ('NLP', 'solutions'), ('solutions', 'IBM'), ('IBM', ',')]

>> Trigrams are: 
 [('The', 'top', 'vendors'), ('top', 'vendors', 'delivering'), ('vendors', 'delivering', 'NLP'), ('delivering', 'NLP', 'solutions'), ('NLP', 'solutions', 'IBM'), ('solutions', 'IBM', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('top', 'JJ'), ('vendors', 'NNS'), ('delivering', 'VBG'), ('NLP', 'NNP'), ('solutions', 'NNS'), ('IBM', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['The top vendors', 'NLP solutions IBM']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'IBM')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('top', 'top'), ('vendors', 'vendor'), ('delivering', 'deliv'), ('NLP', 'nlp'), ('solutions', 'solut'), ('IBM', 'ibm'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('top', 'top'), ('vendors', 'vendor'), ('delivering', 'deliv'), ('NLP', 'nlp'), ('solutions', 'solut'), ('IBM', 'ibm'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('top', 'top'), ('vendors', 'vendor'), ('delivering', 'delivering'), ('NLP', 'NLP'), ('solutions', 'solution'), ('IBM', 'IBM'), (',', ',')]



========================================== PARAGRAPH 230 ===========================================

Google, Amazon, Cerner, Nuance Communications and  

------------------- Sentence 1 -------------------

Google, Amazon, Cerner, Nuance Communications and

>> Tokens are: 
 ['Google', ',', 'Amazon', ',', 'Cerner', ',', 'Nuance', 'Communications']

>> Bigrams are: 
 [('Google', ','), (',', 'Amazon'), ('Amazon', ','), (',', 'Cerner'), ('Cerner', ','), (',', 'Nuance'), ('Nuance', 'Communications')]

>> Trigrams are: 
 [('Google', ',', 'Amazon'), (',', 'Amazon', ','), ('Amazon', ',', 'Cerner'), (',', 'Cerner', ','), ('Cerner', ',', 'Nuance'), (',', 'Nuance', 'Communications')]

>> POS Tags are: 
 [('Google', 'NNP'), (',', ','), ('Amazon', 'NNP'), (',', ','), ('Cerner', 'NNP'), (',', ','), ('Nuance', 'NNP'), ('Communications', 'NNP')]

>> Noun Phrases are: 
 ['Google', 'Amazon', 'Cerner', 'Nuance Communications']

>> Named Entities are: 
 [('GPE', 'Google'), ('GPE', 'Amazon'), ('PERSON', 'Cerner'), ('PERSON', 'Nuance Communications')] 

>> Stemming using Porter Stemmer: 
 [('Google', 'googl'), (',', ','), ('Amazon', 'amazon'), (',', ','), ('Cerner', 'cerner'), (',', ','), ('Nuance', 'nuanc'), ('Communications', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('Google', 'googl'), (',', ','), ('Amazon', 'amazon'), (',', ','), ('Cerner', 'cerner'), (',', ','), ('Nuance', 'nuanc'), ('Communications', 'communic')]

>> Lemmatization: 
 [('Google', 'Google'), (',', ','), ('Amazon', 'Amazon'), (',', ','), ('Cerner', 'Cerner'), (',', ','), ('Nuance', 'Nuance'), ('Communications', 'Communications')]



========================================== PARAGRAPH 231 ===========================================

Microsoft.  

------------------- Sentence 1 -------------------

Microsoft.

>> Tokens are: 
 ['Microsoft', '.']

>> Bigrams are: 
 [('Microsoft', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Microsoft', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Microsoft']

>> Named Entities are: 
 [('GPE', 'Microsoft')] 

>> Stemming using Porter Stemmer: 
 [('Microsoft', 'microsoft'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Microsoft', 'microsoft'), ('.', '.')]

>> Lemmatization: 
 [('Microsoft', 'Microsoft'), ('.', '.')]



========================================== PARAGRAPH 232 ===========================================

V. DEVELOPMENT FRAMEWORKS  AND TOOLS FOR NLP  

------------------- Sentence 1 -------------------

V. DEVELOPMENT FRAMEWORKS  AND TOOLS FOR NLP

>> Tokens are: 
 ['V.', 'DEVELOPMENT', 'FRAMEWORKS', 'AND', 'TOOLS', 'FOR', 'NLP']

>> Bigrams are: 
 [('V.', 'DEVELOPMENT'), ('DEVELOPMENT', 'FRAMEWORKS'), ('FRAMEWORKS', 'AND'), ('AND', 'TOOLS'), ('TOOLS', 'FOR'), ('FOR', 'NLP')]

>> Trigrams are: 
 [('V.', 'DEVELOPMENT', 'FRAMEWORKS'), ('DEVELOPMENT', 'FRAMEWORKS', 'AND'), ('FRAMEWORKS', 'AND', 'TOOLS'), ('AND', 'TOOLS', 'FOR'), ('TOOLS', 'FOR', 'NLP')]

>> POS Tags are: 
 [('V.', 'NNP'), ('DEVELOPMENT', 'NNP'), ('FRAMEWORKS', 'NNP'), ('AND', 'NNP'), ('TOOLS', 'NNP'), ('FOR', 'NNP'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['V. DEVELOPMENT FRAMEWORKS AND TOOLS FOR NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'FRAMEWORKS')] 

>> Stemming using Porter Stemmer: 
 [('V.', 'v.'), ('DEVELOPMENT', 'develop'), ('FRAMEWORKS', 'framework'), ('AND', 'and'), ('TOOLS', 'tool'), ('FOR', 'for'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('V.', 'v.'), ('DEVELOPMENT', 'develop'), ('FRAMEWORKS', 'framework'), ('AND', 'and'), ('TOOLS', 'tool'), ('FOR', 'for'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('V.', 'V.'), ('DEVELOPMENT', 'DEVELOPMENT'), ('FRAMEWORKS', 'FRAMEWORKS'), ('AND', 'AND'), ('TOOLS', 'TOOLS'), ('FOR', 'FOR'), ('NLP', 'NLP')]



========================================== PARAGRAPH 233 ===========================================

The development frameworks and tools will help to  

------------------- Sentence 1 -------------------

The development frameworks and tools will help to

>> Tokens are: 
 ['The', 'development', 'frameworks', 'tools', 'help']

>> Bigrams are: 
 [('The', 'development'), ('development', 'frameworks'), ('frameworks', 'tools'), ('tools', 'help')]

>> Trigrams are: 
 [('The', 'development', 'frameworks'), ('development', 'frameworks', 'tools'), ('frameworks', 'tools', 'help')]

>> POS Tags are: 
 [('The', 'DT'), ('development', 'NN'), ('frameworks', 'NN'), ('tools', 'NNS'), ('help', 'VBP')]

>> Noun Phrases are: 
 ['The development frameworks tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('development', 'develop'), ('frameworks', 'framework'), ('tools', 'tool'), ('help', 'help')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('development', 'develop'), ('frameworks', 'framework'), ('tools', 'tool'), ('help', 'help')]

>> Lemmatization: 
 [('The', 'The'), ('development', 'development'), ('frameworks', 'framework'), ('tools', 'tool'), ('help', 'help')]



========================================== PARAGRAPH 234 ===========================================

build industrial applications discussed in the previous  

------------------- Sentence 1 -------------------

build industrial applications discussed in the previous

>> Tokens are: 
 ['build', 'industrial', 'applications', 'discussed', 'previous']

>> Bigrams are: 
 [('build', 'industrial'), ('industrial', 'applications'), ('applications', 'discussed'), ('discussed', 'previous')]

>> Trigrams are: 
 [('build', 'industrial', 'applications'), ('industrial', 'applications', 'discussed'), ('applications', 'discussed', 'previous')]

>> POS Tags are: 
 [('build', 'VB'), ('industrial', 'JJ'), ('applications', 'NNS'), ('discussed', 'VBD'), ('previous', 'JJ')]

>> Noun Phrases are: 
 ['industrial applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('build', 'build'), ('industrial', 'industri'), ('applications', 'applic'), ('discussed', 'discuss'), ('previous', 'previou')]

>> Stemming using Snowball Stemmer: 
 [('build', 'build'), ('industrial', 'industri'), ('applications', 'applic'), ('discussed', 'discuss'), ('previous', 'previous')]

>> Lemmatization: 
 [('build', 'build'), ('industrial', 'industrial'), ('applications', 'application'), ('discussed', 'discussed'), ('previous', 'previous')]



========================================== PARAGRAPH 235 ===========================================

section. There has been numerous development tools  

------------------- Sentence 1 -------------------

section.

>> Tokens are: 
 ['section', '.']

>> Bigrams are: 
 [('section', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('section', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('section', 'section'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('section', 'section'), ('.', '.')]

>> Lemmatization: 
 [('section', 'section'), ('.', '.')]


------------------- Sentence 2 -------------------

There has been numerous development tools

>> Tokens are: 
 ['There', 'numerous', 'development', 'tools']

>> Bigrams are: 
 [('There', 'numerous'), ('numerous', 'development'), ('development', 'tools')]

>> Trigrams are: 
 [('There', 'numerous', 'development'), ('numerous', 'development', 'tools')]

>> POS Tags are: 
 [('There', 'EX'), ('numerous', 'JJ'), ('development', 'NN'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['numerous development tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('numerous', 'numer'), ('development', 'develop'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('numerous', 'numer'), ('development', 'develop'), ('tools', 'tool')]

>> Lemmatization: 
 [('There', 'There'), ('numerous', 'numerous'), ('development', 'development'), ('tools', 'tool')]



========================================== PARAGRAPH 236 ===========================================

available today due to significant interest shown by open  

------------------- Sentence 1 -------------------

available today due to significant interest shown by open

>> Tokens are: 
 ['available', 'today', 'due', 'significant', 'interest', 'shown', 'open']

>> Bigrams are: 
 [('available', 'today'), ('today', 'due'), ('due', 'significant'), ('significant', 'interest'), ('interest', 'shown'), ('shown', 'open')]

>> Trigrams are: 
 [('available', 'today', 'due'), ('today', 'due', 'significant'), ('due', 'significant', 'interest'), ('significant', 'interest', 'shown'), ('interest', 'shown', 'open')]

>> POS Tags are: 
 [('available', 'JJ'), ('today', 'NN'), ('due', 'JJ'), ('significant', 'JJ'), ('interest', 'NN'), ('shown', 'VBN'), ('open', 'JJ')]

>> Noun Phrases are: 
 ['available today', 'due significant interest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('available', 'avail'), ('today', 'today'), ('due', 'due'), ('significant', 'signific'), ('interest', 'interest'), ('shown', 'shown'), ('open', 'open')]

>> Stemming using Snowball Stemmer: 
 [('available', 'avail'), ('today', 'today'), ('due', 'due'), ('significant', 'signific'), ('interest', 'interest'), ('shown', 'shown'), ('open', 'open')]

>> Lemmatization: 
 [('available', 'available'), ('today', 'today'), ('due', 'due'), ('significant', 'significant'), ('interest', 'interest'), ('shown', 'shown'), ('open', 'open')]



========================================== PARAGRAPH 237 ===========================================

source communities around the world. These frameworks  

------------------- Sentence 1 -------------------

source communities around the world.

>> Tokens are: 
 ['source', 'communities', 'around', 'world', '.']

>> Bigrams are: 
 [('source', 'communities'), ('communities', 'around'), ('around', 'world'), ('world', '.')]

>> Trigrams are: 
 [('source', 'communities', 'around'), ('communities', 'around', 'world'), ('around', 'world', '.')]

>> POS Tags are: 
 [('source', 'NN'), ('communities', 'NNS'), ('around', 'IN'), ('world', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['source communities', 'world']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('source', 'sourc'), ('communities', 'commun'), ('around', 'around'), ('world', 'world'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('source', 'sourc'), ('communities', 'communiti'), ('around', 'around'), ('world', 'world'), ('.', '.')]

>> Lemmatization: 
 [('source', 'source'), ('communities', 'community'), ('around', 'around'), ('world', 'world'), ('.', '.')]


------------------- Sentence 2 -------------------

These frameworks

>> Tokens are: 
 ['These', 'frameworks']

>> Bigrams are: 
 [('These', 'frameworks')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('These', 'DT'), ('frameworks', 'NNS')]

>> Noun Phrases are: 
 ['These frameworks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('frameworks', 'framework')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('frameworks', 'framework')]

>> Lemmatization: 
 [('These', 'These'), ('frameworks', 'framework')]



========================================== PARAGRAPH 238 ===========================================

and tools provide built in libraries and also customizable  

------------------- Sentence 1 -------------------

and tools provide built in libraries and also customizable

>> Tokens are: 
 ['tools', 'provide', 'built', 'libraries', 'also', 'customizable']

>> Bigrams are: 
 [('tools', 'provide'), ('provide', 'built'), ('built', 'libraries'), ('libraries', 'also'), ('also', 'customizable')]

>> Trigrams are: 
 [('tools', 'provide', 'built'), ('provide', 'built', 'libraries'), ('built', 'libraries', 'also'), ('libraries', 'also', 'customizable')]

>> POS Tags are: 
 [('tools', 'NNS'), ('provide', 'VBP'), ('built', 'VBN'), ('libraries', 'NNS'), ('also', 'RB'), ('customizable', 'JJ')]

>> Noun Phrases are: 
 ['tools', 'libraries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), ('provide', 'provid'), ('built', 'built'), ('libraries', 'librari'), ('also', 'also'), ('customizable', 'customiz')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), ('provide', 'provid'), ('built', 'built'), ('libraries', 'librari'), ('also', 'also'), ('customizable', 'customiz')]

>> Lemmatization: 
 [('tools', 'tool'), ('provide', 'provide'), ('built', 'built'), ('libraries', 'library'), ('also', 'also'), ('customizable', 'customizable')]



========================================== PARAGRAPH 239 ===========================================

to adapt specific needs of the industry.   

------------------- Sentence 1 -------------------

to adapt specific needs of the industry.

>> Tokens are: 
 ['adapt', 'specific', 'needs', 'industry', '.']

>> Bigrams are: 
 [('adapt', 'specific'), ('specific', 'needs'), ('needs', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('adapt', 'specific', 'needs'), ('specific', 'needs', 'industry'), ('needs', 'industry', '.')]

>> POS Tags are: 
 [('adapt', 'NN'), ('specific', 'JJ'), ('needs', 'VBZ'), ('industry', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['adapt', 'industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('adapt', 'adapt'), ('specific', 'specif'), ('needs', 'need'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('adapt', 'adapt'), ('specific', 'specif'), ('needs', 'need'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('adapt', 'adapt'), ('specific', 'specific'), ('needs', 'need'), ('industry', 'industry'), ('.', '.')]



========================================== PARAGRAPH 240 ===========================================

  Fig 1: Block representation of stages in the  

------------------- Sentence 1 -------------------

  Fig 1: Block representation of stages in the

>> Tokens are: 
 ['Fig', '1', ':', 'Block', 'representation', 'stages']

>> Bigrams are: 
 [('Fig', '1'), ('1', ':'), (':', 'Block'), ('Block', 'representation'), ('representation', 'stages')]

>> Trigrams are: 
 [('Fig', '1', ':'), ('1', ':', 'Block'), (':', 'Block', 'representation'), ('Block', 'representation', 'stages')]

>> POS Tags are: 
 [('Fig', 'JJ'), ('1', 'CD'), (':', ':'), ('Block', 'NNP'), ('representation', 'NN'), ('stages', 'NNS')]

>> Noun Phrases are: 
 ['Block representation stages']

>> Named Entities are: 
 [('PERSON', 'Block')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('1', '1'), (':', ':'), ('Block', 'block'), ('representation', 'represent'), ('stages', 'stage')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('1', '1'), (':', ':'), ('Block', 'block'), ('representation', 'represent'), ('stages', 'stage')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('1', '1'), (':', ':'), ('Block', 'Block'), ('representation', 'representation'), ('stages', 'stage')]



========================================== PARAGRAPH 241 ===========================================

development of NLP tools  

------------------- Sentence 1 -------------------

development of NLP tools

>> Tokens are: 
 ['development', 'NLP', 'tools']

>> Bigrams are: 
 [('development', 'NLP'), ('NLP', 'tools')]

>> Trigrams are: 
 [('development', 'NLP', 'tools')]

>> POS Tags are: 
 [('development', 'NN'), ('NLP', 'NNP'), ('tools', 'NNS')]

>> Noun Phrases are: 
 ['development NLP tools']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('development', 'develop'), ('NLP', 'nlp'), ('tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('development', 'develop'), ('NLP', 'nlp'), ('tools', 'tool')]

>> Lemmatization: 
 [('development', 'development'), ('NLP', 'NLP'), ('tools', 'tool')]



========================================== PARAGRAPH 242 ===========================================

Fig 1 shows the block representation of various stages  

------------------- Sentence 1 -------------------

Fig 1 shows the block representation of various stages

>> Tokens are: 
 ['Fig', '1', 'shows', 'block', 'representation', 'various', 'stages']

>> Bigrams are: 
 [('Fig', '1'), ('1', 'shows'), ('shows', 'block'), ('block', 'representation'), ('representation', 'various'), ('various', 'stages')]

>> Trigrams are: 
 [('Fig', '1', 'shows'), ('1', 'shows', 'block'), ('shows', 'block', 'representation'), ('block', 'representation', 'various'), ('representation', 'various', 'stages')]

>> POS Tags are: 
 [('Fig', 'NNP'), ('1', 'CD'), ('shows', 'NNS'), ('block', 'VBP'), ('representation', 'NN'), ('various', 'JJ'), ('stages', 'NNS')]

>> Noun Phrases are: 
 ['Fig', 'shows', 'representation', 'various stages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('1', '1'), ('shows', 'show'), ('block', 'block'), ('representation', 'represent'), ('various', 'variou'), ('stages', 'stage')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('1', '1'), ('shows', 'show'), ('block', 'block'), ('representation', 'represent'), ('various', 'various'), ('stages', 'stage')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('1', '1'), ('shows', 'show'), ('block', 'block'), ('representation', 'representation'), ('various', 'various'), ('stages', 'stage')]



========================================== PARAGRAPH 243 ===========================================

in NLP application development. The Natural Language  

------------------- Sentence 1 -------------------

in NLP application development.

>> Tokens are: 
 ['NLP', 'application', 'development', '.']

>> Bigrams are: 
 [('NLP', 'application'), ('application', 'development'), ('development', '.')]

>> Trigrams are: 
 [('NLP', 'application', 'development'), ('application', 'development', '.')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('application', 'NN'), ('development', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP application development']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('application', 'applic'), ('development', 'develop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('application', 'applic'), ('development', 'develop'), ('.', '.')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('application', 'application'), ('development', 'development'), ('.', '.')]


------------------- Sentence 2 -------------------

The Natural Language

>> Tokens are: 
 ['The', 'Natural', 'Language']

>> Bigrams are: 
 [('The', 'Natural'), ('Natural', 'Language')]

>> Trigrams are: 
 [('The', 'Natural', 'Language')]

>> POS Tags are: 
 [('The', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP')]

>> Noun Phrases are: 
 ['The Natural Language']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Natural', 'natur'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Natural', 'natur'), ('Language', 'languag')]

>> Lemmatization: 
 [('The', 'The'), ('Natural', 'Natural'), ('Language', 'Language')]



========================================== PARAGRAPH 244 ===========================================

acquisition block built with speech processing, Computer  

------------------- Sentence 1 -------------------

acquisition block built with speech processing, Computer

>> Tokens are: 
 ['acquisition', 'block', 'built', 'speech', 'processing', ',', 'Computer']

>> Bigrams are: 
 [('acquisition', 'block'), ('block', 'built'), ('built', 'speech'), ('speech', 'processing'), ('processing', ','), (',', 'Computer')]

>> Trigrams are: 
 [('acquisition', 'block', 'built'), ('block', 'built', 'speech'), ('built', 'speech', 'processing'), ('speech', 'processing', ','), ('processing', ',', 'Computer')]

>> POS Tags are: 
 [('acquisition', 'NN'), ('block', 'NN'), ('built', 'VBN'), ('speech', 'NN'), ('processing', 'NN'), (',', ','), ('Computer', 'NNP')]

>> Noun Phrases are: 
 ['acquisition block', 'speech processing', 'Computer']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer')] 

>> Stemming using Porter Stemmer: 
 [('acquisition', 'acquisit'), ('block', 'block'), ('built', 'built'), ('speech', 'speech'), ('processing', 'process'), (',', ','), ('Computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('acquisition', 'acquisit'), ('block', 'block'), ('built', 'built'), ('speech', 'speech'), ('processing', 'process'), (',', ','), ('Computer', 'comput')]

>> Lemmatization: 
 [('acquisition', 'acquisition'), ('block', 'block'), ('built', 'built'), ('speech', 'speech'), ('processing', 'processing'), (',', ','), ('Computer', 'Computer')]



========================================== PARAGRAPH 245 ===========================================

vision or any data acquisition tools to inject Natural  

------------------- Sentence 1 -------------------

vision or any data acquisition tools to inject Natural

>> Tokens are: 
 ['vision', 'data', 'acquisition', 'tools', 'inject', 'Natural']

>> Bigrams are: 
 [('vision', 'data'), ('data', 'acquisition'), ('acquisition', 'tools'), ('tools', 'inject'), ('inject', 'Natural')]

>> Trigrams are: 
 [('vision', 'data', 'acquisition'), ('data', 'acquisition', 'tools'), ('acquisition', 'tools', 'inject'), ('tools', 'inject', 'Natural')]

>> POS Tags are: 
 [('vision', 'NN'), ('data', 'NNS'), ('acquisition', 'NN'), ('tools', 'NNS'), ('inject', 'VBP'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['vision data acquisition tools', 'Natural']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural')] 

>> Stemming using Porter Stemmer: 
 [('vision', 'vision'), ('data', 'data'), ('acquisition', 'acquisit'), ('tools', 'tool'), ('inject', 'inject'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('vision', 'vision'), ('data', 'data'), ('acquisition', 'acquisit'), ('tools', 'tool'), ('inject', 'inject'), ('Natural', 'natur')]

>> Lemmatization: 
 [('vision', 'vision'), ('data', 'data'), ('acquisition', 'acquisition'), ('tools', 'tool'), ('inject', 'inject'), ('Natural', 'Natural')]



========================================== PARAGRAPH 246 ===========================================

language text into the system.   

------------------- Sentence 1 -------------------

language text into the system.

>> Tokens are: 
 ['language', 'text', 'system', '.']

>> Bigrams are: 
 [('language', 'text'), ('text', 'system'), ('system', '.')]

>> Trigrams are: 
 [('language', 'text', 'system'), ('text', 'system', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('text', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language text system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('text', 'text'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('text', 'text'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('text', 'text'), ('system', 'system'), ('.', '.')]



========================================== PARAGRAPH 247 ===========================================

Table 1: Natural Language Processing Tools  

------------------- Sentence 1 -------------------

Table 1: Natural Language Processing Tools

>> Tokens are: 
 ['Table', '1', ':', 'Natural', 'Language', 'Processing', 'Tools']

>> Bigrams are: 
 [('Table', '1'), ('1', ':'), (':', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Tools')]

>> Trigrams are: 
 [('Table', '1', ':'), ('1', ':', 'Natural'), (':', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Tools')]

>> POS Tags are: 
 [('Table', 'JJ'), ('1', 'CD'), (':', ':'), ('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Tools', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing Tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Tools', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Tools', 'tool')]

>> Lemmatization: 
 [('Table', 'Table'), ('1', '1'), (':', ':'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Tools', 'Tools')]



========================================== PARAGRAPH 248 ===========================================

  Natural Language representation block uses structured,  

------------------- Sentence 1 -------------------

  Natural Language representation block uses structured,

>> Tokens are: 
 ['Natural', 'Language', 'representation', 'block', 'uses', 'structured', ',']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'representation'), ('representation', 'block'), ('block', 'uses'), ('uses', 'structured'), ('structured', ',')]

>> Trigrams are: 
 [('Natural', 'Language', 'representation'), ('Language', 'representation', 'block'), ('representation', 'block', 'uses'), ('block', 'uses', 'structured'), ('uses', 'structured', ',')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('representation', 'NN'), ('block', 'NN'), ('uses', 'NNS'), ('structured', 'VBD'), (',', ',')]

>> Noun Phrases are: 
 ['Natural Language representation block uses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('representation', 'represent'), ('block', 'block'), ('uses', 'use'), ('structured', 'structur'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('representation', 'represent'), ('block', 'block'), ('uses', 'use'), ('structured', 'structur'), (',', ',')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('representation', 'representation'), ('block', 'block'), ('uses', 'us'), ('structured', 'structured'), (',', ',')]



========================================== PARAGRAPH 249 ===========================================

tree or graph models to represent the Natural Language  

------------------- Sentence 1 -------------------

tree or graph models to represent the Natural Language

>> Tokens are: 
 ['tree', 'graph', 'models', 'represent', 'Natural', 'Language']

>> Bigrams are: 
 [('tree', 'graph'), ('graph', 'models'), ('models', 'represent'), ('represent', 'Natural'), ('Natural', 'Language')]

>> Trigrams are: 
 [('tree', 'graph', 'models'), ('graph', 'models', 'represent'), ('models', 'represent', 'Natural'), ('represent', 'Natural', 'Language')]

>> POS Tags are: 
 [('tree', 'JJ'), ('graph', 'NN'), ('models', 'NNS'), ('represent', 'VBP'), ('Natural', 'JJ'), ('Language', 'NN')]

>> Noun Phrases are: 
 ['tree graph models', 'Natural Language']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('tree', 'tree'), ('graph', 'graph'), ('models', 'model'), ('represent', 'repres'), ('Natural', 'natur'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('tree', 'tree'), ('graph', 'graph'), ('models', 'model'), ('represent', 'repres'), ('Natural', 'natur'), ('Language', 'languag')]

>> Lemmatization: 
 [('tree', 'tree'), ('graph', 'graph'), ('models', 'model'), ('represent', 'represent'), ('Natural', 'Natural'), ('Language', 'Language')]



========================================== PARAGRAPH 250 ===========================================

understanding. Natural Language database is a repository  

------------------- Sentence 1 -------------------

understanding.

>> Tokens are: 
 ['understanding', '.']

>> Bigrams are: 
 [('understanding', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('understanding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('understanding', 'understanding'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural Language database is a repository

>> Tokens are: 
 ['Natural', 'Language', 'database', 'repository']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'database'), ('database', 'repository')]

>> Trigrams are: 
 [('Natural', 'Language', 'database'), ('Language', 'database', 'repository')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('database', 'NN'), ('repository', 'NN')]

>> Noun Phrases are: 
 ['Natural Language database repository']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('database', 'databas'), ('repository', 'repositori')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('database', 'databas'), ('repository', 'repositori')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('database', 'database'), ('repository', 'repository')]



========================================== PARAGRAPH 251 ===========================================

of Natural Language data like MNIST or similar  

------------------- Sentence 1 -------------------

of Natural Language data like MNIST or similar

>> Tokens are: 
 ['Natural', 'Language', 'data', 'like', 'MNIST', 'similar']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'data'), ('data', 'like'), ('like', 'MNIST'), ('MNIST', 'similar')]

>> Trigrams are: 
 [('Natural', 'Language', 'data'), ('Language', 'data', 'like'), ('data', 'like', 'MNIST'), ('like', 'MNIST', 'similar')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('data', 'NNS'), ('like', 'IN'), ('MNIST', 'NNP'), ('similar', 'JJ')]

>> Noun Phrases are: 
 ['Natural Language data', 'MNIST']

>> Named Entities are: 
 [('ORGANIZATION', 'MNIST')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('data', 'data'), ('like', 'like'), ('MNIST', 'mnist'), ('similar', 'similar')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('data', 'data'), ('like', 'like'), ('MNIST', 'mnist'), ('similar', 'similar')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('data', 'data'), ('like', 'like'), ('MNIST', 'MNIST'), ('similar', 'similar')]



========================================== PARAGRAPH 252 ===========================================

databases which are then used by machine learning  

------------------- Sentence 1 -------------------

databases which are then used by machine learning

>> Tokens are: 
 ['databases', 'used', 'machine', 'learning']

>> Bigrams are: 
 [('databases', 'used'), ('used', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('databases', 'used', 'machine'), ('used', 'machine', 'learning')]

>> POS Tags are: 
 [('databases', 'NNS'), ('used', 'VBN'), ('machine', 'NN'), ('learning', 'VBG')]

>> Noun Phrases are: 
 ['databases', 'machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('databases', 'databas'), ('used', 'use'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('databases', 'databas'), ('used', 'use'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('databases', 'database'), ('used', 'used'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 253 ===========================================

algorithms to perform other NLP tasks.  

------------------- Sentence 1 -------------------

algorithms to perform other NLP tasks.

>> Tokens are: 
 ['algorithms', 'perform', 'NLP', 'tasks', '.']

>> Bigrams are: 
 [('algorithms', 'perform'), ('perform', 'NLP'), ('NLP', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('algorithms', 'perform', 'NLP'), ('perform', 'NLP', 'tasks'), ('NLP', 'tasks', '.')]

>> POS Tags are: 
 [('algorithms', 'RB'), ('perform', 'VB'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('perform', 'perform'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('perform', 'perform'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('perform', 'perform'), ('NLP', 'NLP'), ('tasks', 'task'), ('.', '.')]



========================================== PARAGRAPH 254 ===========================================

This database is accessed by representation and  

------------------- Sentence 1 -------------------

This database is accessed by representation and

>> Tokens are: 
 ['This', 'database', 'accessed', 'representation']

>> Bigrams are: 
 [('This', 'database'), ('database', 'accessed'), ('accessed', 'representation')]

>> Trigrams are: 
 [('This', 'database', 'accessed'), ('database', 'accessed', 'representation')]

>> POS Tags are: 
 [('This', 'DT'), ('database', 'NN'), ('accessed', 'VBD'), ('representation', 'NN')]

>> Noun Phrases are: 
 ['This database', 'representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('database', 'databas'), ('accessed', 'access'), ('representation', 'represent')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('database', 'databas'), ('accessed', 'access'), ('representation', 'represent')]

>> Lemmatization: 
 [('This', 'This'), ('database', 'database'), ('accessed', 'accessed'), ('representation', 'representation')]



========================================== PARAGRAPH 255 ===========================================

transformation blocks to perform their tasks. Natural  

------------------- Sentence 1 -------------------

transformation blocks to perform their tasks.

>> Tokens are: 
 ['transformation', 'blocks', 'perform', 'tasks', '.']

>> Bigrams are: 
 [('transformation', 'blocks'), ('blocks', 'perform'), ('perform', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('transformation', 'blocks', 'perform'), ('blocks', 'perform', 'tasks'), ('perform', 'tasks', '.')]

>> POS Tags are: 
 [('transformation', 'NN'), ('blocks', 'NNS'), ('perform', 'VBP'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['transformation blocks', 'tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('transformation', 'transform'), ('blocks', 'block'), ('perform', 'perform'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('transformation', 'transform'), ('blocks', 'block'), ('perform', 'perform'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('transformation', 'transformation'), ('blocks', 'block'), ('perform', 'perform'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural

>> Tokens are: 
 ['Natural']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Natural', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur')]

>> Lemmatization: 
 [('Natural', 'Natural')]



========================================== PARAGRAPH 256 ===========================================

Language transformation will consists of suite of various  

------------------- Sentence 1 -------------------

Language transformation will consists of suite of various

>> Tokens are: 
 ['Language', 'transformation', 'consists', 'suite', 'various']

>> Bigrams are: 
 [('Language', 'transformation'), ('transformation', 'consists'), ('consists', 'suite'), ('suite', 'various')]

>> Trigrams are: 
 [('Language', 'transformation', 'consists'), ('transformation', 'consists', 'suite'), ('consists', 'suite', 'various')]

>> POS Tags are: 
 [('Language', 'NNP'), ('transformation', 'NN'), ('consists', 'VBZ'), ('suite', 'RB'), ('various', 'JJ')]

>> Noun Phrases are: 
 ['Language transformation']

>> Named Entities are: 
 [('GPE', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('transformation', 'transform'), ('consists', 'consist'), ('suite', 'suit'), ('various', 'variou')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('transformation', 'transform'), ('consists', 'consist'), ('suite', 'suit'), ('various', 'various')]

>> Lemmatization: 
 [('Language', 'Language'), ('transformation', 'transformation'), ('consists', 'consists'), ('suite', 'suite'), ('various', 'various')]



========================================== PARAGRAPH 257 ===========================================

learning, extraction algorithms to extract meaningful  

------------------- Sentence 1 -------------------

learning, extraction algorithms to extract meaningful

>> Tokens are: 
 ['learning', ',', 'extraction', 'algorithms', 'extract', 'meaningful']

>> Bigrams are: 
 [('learning', ','), (',', 'extraction'), ('extraction', 'algorithms'), ('algorithms', 'extract'), ('extract', 'meaningful')]

>> Trigrams are: 
 [('learning', ',', 'extraction'), (',', 'extraction', 'algorithms'), ('extraction', 'algorithms', 'extract'), ('algorithms', 'extract', 'meaningful')]

>> POS Tags are: 
 [('learning', 'NN'), (',', ','), ('extraction', 'NN'), ('algorithms', 'NNS'), ('extract', 'VBP'), ('meaningful', 'JJ')]

>> Noun Phrases are: 
 ['learning', 'extraction algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), (',', ','), ('extraction', 'extract'), ('algorithms', 'algorithm'), ('extract', 'extract'), ('meaningful', 'meaning')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), (',', ','), ('extraction', 'extract'), ('algorithms', 'algorithm'), ('extract', 'extract'), ('meaningful', 'meaning')]

>> Lemmatization: 
 [('learning', 'learning'), (',', ','), ('extraction', 'extraction'), ('algorithms', 'algorithm'), ('extract', 'extract'), ('meaningful', 'meaningful')]



========================================== PARAGRAPH 258 ===========================================

actions from the NLP tasks. Natural Language  

------------------- Sentence 1 -------------------

actions from the NLP tasks.

>> Tokens are: 
 ['actions', 'NLP', 'tasks', '.']

>> Bigrams are: 
 [('actions', 'NLP'), ('NLP', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('actions', 'NLP', 'tasks'), ('NLP', 'tasks', '.')]

>> POS Tags are: 
 [('actions', 'NNS'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['actions NLP tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('actions', 'action'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actions', 'action'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('actions', 'action'), ('NLP', 'NLP'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural Language

>> Tokens are: 
 ['Natural', 'Language']

>> Bigrams are: 
 [('Natural', 'Language')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NN')]

>> Noun Phrases are: 
 ['Natural Language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language')]



========================================== PARAGRAPH 259 ===========================================

communication is a presentation of the desired actions as  

------------------- Sentence 1 -------------------

communication is a presentation of the desired actions as

>> Tokens are: 
 ['communication', 'presentation', 'desired', 'actions']

>> Bigrams are: 
 [('communication', 'presentation'), ('presentation', 'desired'), ('desired', 'actions')]

>> Trigrams are: 
 [('communication', 'presentation', 'desired'), ('presentation', 'desired', 'actions')]

>> POS Tags are: 
 [('communication', 'NN'), ('presentation', 'NN'), ('desired', 'VBD'), ('actions', 'NNS')]

>> Noun Phrases are: 
 ['communication presentation', 'actions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('communication', 'commun'), ('presentation', 'present'), ('desired', 'desir'), ('actions', 'action')]

>> Stemming using Snowball Stemmer: 
 [('communication', 'communic'), ('presentation', 'present'), ('desired', 'desir'), ('actions', 'action')]

>> Lemmatization: 
 [('communication', 'communication'), ('presentation', 'presentation'), ('desired', 'desired'), ('actions', 'action')]



========================================== PARAGRAPH 260 ===========================================

an outcome of the NLP tasks. The generated outcome  

------------------- Sentence 1 -------------------

an outcome of the NLP tasks.

>> Tokens are: 
 ['outcome', 'NLP', 'tasks', '.']

>> Bigrams are: 
 [('outcome', 'NLP'), ('NLP', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('outcome', 'NLP', 'tasks'), ('NLP', 'tasks', '.')]

>> POS Tags are: 
 [('outcome', 'NN'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['outcome NLP tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('outcome', 'outcom'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('outcome', 'outcom'), ('NLP', 'nlp'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('outcome', 'outcome'), ('NLP', 'NLP'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

The generated outcome

>> Tokens are: 
 ['The', 'generated', 'outcome']

>> Bigrams are: 
 [('The', 'generated'), ('generated', 'outcome')]

>> Trigrams are: 
 [('The', 'generated', 'outcome')]

>> POS Tags are: 
 [('The', 'DT'), ('generated', 'JJ'), ('outcome', 'NN')]

>> Noun Phrases are: 
 ['The generated outcome']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('generated', 'gener'), ('outcome', 'outcom')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('generated', 'generat'), ('outcome', 'outcom')]

>> Lemmatization: 
 [('The', 'The'), ('generated', 'generated'), ('outcome', 'outcome')]



========================================== PARAGRAPH 261 ===========================================

may be either in Natural Language or in the form of  

------------------- Sentence 1 -------------------

may be either in Natural Language or in the form of

>> Tokens are: 
 ['may', 'either', 'Natural', 'Language', 'form']

>> Bigrams are: 
 [('may', 'either'), ('either', 'Natural'), ('Natural', 'Language'), ('Language', 'form')]

>> Trigrams are: 
 [('may', 'either', 'Natural'), ('either', 'Natural', 'Language'), ('Natural', 'Language', 'form')]

>> POS Tags are: 
 [('may', 'MD'), ('either', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('form', 'NN')]

>> Noun Phrases are: 
 ['either Natural Language form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('may', 'may'), ('either', 'either'), ('Natural', 'natur'), ('Language', 'languag'), ('form', 'form')]

>> Stemming using Snowball Stemmer: 
 [('may', 'may'), ('either', 'either'), ('Natural', 'natur'), ('Language', 'languag'), ('form', 'form')]

>> Lemmatization: 
 [('may', 'may'), ('either', 'either'), ('Natural', 'Natural'), ('Language', 'Language'), ('form', 'form')]



========================================== PARAGRAPH 262 ===========================================

computer action such as robot arm movement.  

------------------- Sentence 1 -------------------

computer action such as robot arm movement.

>> Tokens are: 
 ['computer', 'action', 'robot', 'arm', 'movement', '.']

>> Bigrams are: 
 [('computer', 'action'), ('action', 'robot'), ('robot', 'arm'), ('arm', 'movement'), ('movement', '.')]

>> Trigrams are: 
 [('computer', 'action', 'robot'), ('action', 'robot', 'arm'), ('robot', 'arm', 'movement'), ('arm', 'movement', '.')]

>> POS Tags are: 
 [('computer', 'NN'), ('action', 'NN'), ('robot', 'NN'), ('arm', 'NN'), ('movement', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computer action robot arm movement']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computer', 'comput'), ('action', 'action'), ('robot', 'robot'), ('arm', 'arm'), ('movement', 'movement'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computer', 'comput'), ('action', 'action'), ('robot', 'robot'), ('arm', 'arm'), ('movement', 'movement'), ('.', '.')]

>> Lemmatization: 
 [('computer', 'computer'), ('action', 'action'), ('robot', 'robot'), ('arm', 'arm'), ('movement', 'movement'), ('.', '.')]



========================================== PARAGRAPH 263 ===========================================

The following table gives an overview of the popular  

------------------- Sentence 1 -------------------

The following table gives an overview of the popular

>> Tokens are: 
 ['The', 'following', 'table', 'gives', 'overview', 'popular']

>> Bigrams are: 
 [('The', 'following'), ('following', 'table'), ('table', 'gives'), ('gives', 'overview'), ('overview', 'popular')]

>> Trigrams are: 
 [('The', 'following', 'table'), ('following', 'table', 'gives'), ('table', 'gives', 'overview'), ('gives', 'overview', 'popular')]

>> POS Tags are: 
 [('The', 'DT'), ('following', 'VBG'), ('table', 'JJ'), ('gives', 'VBZ'), ('overview', 'VBP'), ('popular', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('following', 'follow'), ('table', 'tabl'), ('gives', 'give'), ('overview', 'overview'), ('popular', 'popular')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('following', 'follow'), ('table', 'tabl'), ('gives', 'give'), ('overview', 'overview'), ('popular', 'popular')]

>> Lemmatization: 
 [('The', 'The'), ('following', 'following'), ('table', 'table'), ('gives', 'give'), ('overview', 'overview'), ('popular', 'popular')]



========================================== PARAGRAPH 264 ===========================================

tools currently available in the market.  

------------------- Sentence 1 -------------------

tools currently available in the market.

>> Tokens are: 
 ['tools', 'currently', 'available', 'market', '.']

>> Bigrams are: 
 [('tools', 'currently'), ('currently', 'available'), ('available', 'market'), ('market', '.')]

>> Trigrams are: 
 [('tools', 'currently', 'available'), ('currently', 'available', 'market'), ('available', 'market', '.')]

>> POS Tags are: 
 [('tools', 'NNS'), ('currently', 'RB'), ('available', 'JJ'), ('market', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tools', 'available market']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), ('currently', 'current'), ('available', 'avail'), ('market', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), ('currently', 'current'), ('available', 'avail'), ('market', 'market'), ('.', '.')]

>> Lemmatization: 
 [('tools', 'tool'), ('currently', 'currently'), ('available', 'available'), ('market', 'market'), ('.', '.')]



========================================== PARAGRAPH 265 ===========================================

Abbreviations  1 Common NLP tasks: Lexical analysis, Parsing,  

------------------- Sentence 1 -------------------

Abbreviations  1 Common NLP tasks: Lexical analysis, Parsing,

>> Tokens are: 
 ['Abbreviations', '1', 'Common', 'NLP', 'tasks', ':', 'Lexical', 'analysis', ',', 'Parsing', ',']

>> Bigrams are: 
 [('Abbreviations', '1'), ('1', 'Common'), ('Common', 'NLP'), ('NLP', 'tasks'), ('tasks', ':'), (':', 'Lexical'), ('Lexical', 'analysis'), ('analysis', ','), (',', 'Parsing'), ('Parsing', ',')]

>> Trigrams are: 
 [('Abbreviations', '1', 'Common'), ('1', 'Common', 'NLP'), ('Common', 'NLP', 'tasks'), ('NLP', 'tasks', ':'), ('tasks', ':', 'Lexical'), (':', 'Lexical', 'analysis'), ('Lexical', 'analysis', ','), ('analysis', ',', 'Parsing'), (',', 'Parsing', ',')]

>> POS Tags are: 
 [('Abbreviations', 'NNS'), ('1', 'CD'), ('Common', 'NNP'), ('NLP', 'NNP'), ('tasks', 'NNS'), (':', ':'), ('Lexical', 'JJ'), ('analysis', 'NN'), (',', ','), ('Parsing', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Abbreviations', 'Common NLP tasks', 'Lexical analysis', 'Parsing']

>> Named Entities are: 
 [('ORGANIZATION', 'Common'), ('GPE', 'Parsing')] 

>> Stemming using Porter Stemmer: 
 [('Abbreviations', 'abbrevi'), ('1', '1'), ('Common', 'common'), ('NLP', 'nlp'), ('tasks', 'task'), (':', ':'), ('Lexical', 'lexic'), ('analysis', 'analysi'), (',', ','), ('Parsing', 'pars'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Abbreviations', 'abbrevi'), ('1', '1'), ('Common', 'common'), ('NLP', 'nlp'), ('tasks', 'task'), (':', ':'), ('Lexical', 'lexic'), ('analysis', 'analysi'), (',', ','), ('Parsing', 'pars'), (',', ',')]

>> Lemmatization: 
 [('Abbreviations', 'Abbreviations'), ('1', '1'), ('Common', 'Common'), ('NLP', 'NLP'), ('tasks', 'task'), (':', ':'), ('Lexical', 'Lexical'), ('analysis', 'analysis'), (',', ','), ('Parsing', 'Parsing'), (',', ',')]



========================================== PARAGRAPH 266 ===========================================

semantic analysis, POS tags, Chunking, Name Entity  

------------------- Sentence 1 -------------------

semantic analysis, POS tags, Chunking, Name Entity

>> Tokens are: 
 ['semantic', 'analysis', ',', 'POS', 'tags', ',', 'Chunking', ',', 'Name', 'Entity']

>> Bigrams are: 
 [('semantic', 'analysis'), ('analysis', ','), (',', 'POS'), ('POS', 'tags'), ('tags', ','), (',', 'Chunking'), ('Chunking', ','), (',', 'Name'), ('Name', 'Entity')]

>> Trigrams are: 
 [('semantic', 'analysis', ','), ('analysis', ',', 'POS'), (',', 'POS', 'tags'), ('POS', 'tags', ','), ('tags', ',', 'Chunking'), (',', 'Chunking', ','), ('Chunking', ',', 'Name'), (',', 'Name', 'Entity')]

>> POS Tags are: 
 [('semantic', 'JJ'), ('analysis', 'NN'), (',', ','), ('POS', 'NNP'), ('tags', 'NN'), (',', ','), ('Chunking', 'NNP'), (',', ','), ('Name', 'NNP'), ('Entity', 'NNP')]

>> Noun Phrases are: 
 ['semantic analysis', 'POS tags', 'Chunking', 'Name Entity']

>> Named Entities are: 
 [('ORGANIZATION', 'POS'), ('GPE', 'Chunking'), ('PERSON', 'Name Entity')] 

>> Stemming using Porter Stemmer: 
 [('semantic', 'semant'), ('analysis', 'analysi'), (',', ','), ('POS', 'po'), ('tags', 'tag'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Name', 'name'), ('Entity', 'entiti')]

>> Stemming using Snowball Stemmer: 
 [('semantic', 'semant'), ('analysis', 'analysi'), (',', ','), ('POS', 'pos'), ('tags', 'tag'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Name', 'name'), ('Entity', 'entiti')]

>> Lemmatization: 
 [('semantic', 'semantic'), ('analysis', 'analysis'), (',', ','), ('POS', 'POS'), ('tags', 'tag'), (',', ','), ('Chunking', 'Chunking'), (',', ','), ('Name', 'Name'), ('Entity', 'Entity')]



========================================== PARAGRAPH 267 ===========================================

Recognition (NER), Semantic Role Labeling  

------------------- Sentence 1 -------------------

Recognition (NER), Semantic Role Labeling

>> Tokens are: 
 ['Recognition', '(', 'NER', ')', ',', 'Semantic', 'Role', 'Labeling']

>> Bigrams are: 
 [('Recognition', '('), ('(', 'NER'), ('NER', ')'), (')', ','), (',', 'Semantic'), ('Semantic', 'Role'), ('Role', 'Labeling')]

>> Trigrams are: 
 [('Recognition', '(', 'NER'), ('(', 'NER', ')'), ('NER', ')', ','), (')', ',', 'Semantic'), (',', 'Semantic', 'Role'), ('Semantic', 'Role', 'Labeling')]

>> POS Tags are: 
 [('Recognition', 'NNP'), ('(', '('), ('NER', 'NNP'), (')', ')'), (',', ','), ('Semantic', 'JJ'), ('Role', 'NNP'), ('Labeling', 'NNP')]

>> Noun Phrases are: 
 ['Recognition', 'NER', 'Semantic Role Labeling']

>> Named Entities are: 
 [('GPE', 'Recognition'), ('ORGANIZATION', 'NER'), ('ORGANIZATION', 'Semantic Role')] 

>> Stemming using Porter Stemmer: 
 [('Recognition', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), (',', ','), ('Semantic', 'semant'), ('Role', 'role'), ('Labeling', 'label')]

>> Stemming using Snowball Stemmer: 
 [('Recognition', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), (',', ','), ('Semantic', 'semant'), ('Role', 'role'), ('Labeling', 'label')]

>> Lemmatization: 
 [('Recognition', 'Recognition'), ('(', '('), ('NER', 'NER'), (')', ')'), (',', ','), ('Semantic', 'Semantic'), ('Role', 'Role'), ('Labeling', 'Labeling')]



========================================== PARAGRAPH 268 ===========================================

(SRL)and Syntactic parsing.  2 NLTK: Natural Language Toolkit  

------------------- Sentence 1 -------------------

(SRL)and Syntactic parsing.

>> Tokens are: 
 ['(', 'SRL', ')', 'Syntactic', 'parsing', '.']

>> Bigrams are: 
 [('(', 'SRL'), ('SRL', ')'), (')', 'Syntactic'), ('Syntactic', 'parsing'), ('parsing', '.')]

>> Trigrams are: 
 [('(', 'SRL', ')'), ('SRL', ')', 'Syntactic'), (')', 'Syntactic', 'parsing'), ('Syntactic', 'parsing', '.')]

>> POS Tags are: 
 [('(', '('), ('SRL', 'NNP'), (')', ')'), ('Syntactic', 'NNP'), ('parsing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['SRL', 'Syntactic parsing']

>> Named Entities are: 
 [('ORGANIZATION', 'SRL'), ('ORGANIZATION', 'Syntactic')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('SRL', 'srl'), (')', ')'), ('Syntactic', 'syntact'), ('parsing', 'pars'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('SRL', 'srl'), (')', ')'), ('Syntactic', 'syntact'), ('parsing', 'pars'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('SRL', 'SRL'), (')', ')'), ('Syntactic', 'Syntactic'), ('parsing', 'parsing'), ('.', '.')]


------------------- Sentence 2 -------------------

2 NLTK: Natural Language Toolkit

>> Tokens are: 
 ['2', 'NLTK', ':', 'Natural', 'Language', 'Toolkit']

>> Bigrams are: 
 [('2', 'NLTK'), ('NLTK', ':'), (':', 'Natural'), ('Natural', 'Language'), ('Language', 'Toolkit')]

>> Trigrams are: 
 [('2', 'NLTK', ':'), ('NLTK', ':', 'Natural'), (':', 'Natural', 'Language'), ('Natural', 'Language', 'Toolkit')]

>> POS Tags are: 
 [('2', 'CD'), ('NLTK', 'NN'), (':', ':'), ('Natural', 'JJ'), ('Language', 'NNP'), ('Toolkit', 'NNP')]

>> Noun Phrases are: 
 ['NLTK', 'Natural Language Toolkit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('NLTK', 'nltk'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Toolkit', 'toolkit')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('NLTK', 'nltk'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Toolkit', 'toolkit')]

>> Lemmatization: 
 [('2', '2'), ('NLTK', 'NLTK'), (':', ':'), ('Natural', 'Natural'), ('Language', 'Language'), ('Toolkit', 'Toolkit')]



========================================== PARAGRAPH 269 ===========================================

3 UIMA: Unstructured Information Management  

------------------- Sentence 1 -------------------

3 UIMA: Unstructured Information Management

>> Tokens are: 
 ['3', 'UIMA', ':', 'Unstructured', 'Information', 'Management']

>> Bigrams are: 
 [('3', 'UIMA'), ('UIMA', ':'), (':', 'Unstructured'), ('Unstructured', 'Information'), ('Information', 'Management')]

>> Trigrams are: 
 [('3', 'UIMA', ':'), ('UIMA', ':', 'Unstructured'), (':', 'Unstructured', 'Information'), ('Unstructured', 'Information', 'Management')]

>> POS Tags are: 
 [('3', 'CD'), ('UIMA', 'NNS'), (':', ':'), ('Unstructured', 'VBN'), ('Information', 'NNP'), ('Management', 'NNP')]

>> Noun Phrases are: 
 ['UIMA', 'Information Management']

>> Named Entities are: 
 [('ORGANIZATION', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('UIMA', 'uima'), (':', ':'), ('Unstructured', 'unstructur'), ('Information', 'inform'), ('Management', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('UIMA', 'uima'), (':', ':'), ('Unstructured', 'unstructur'), ('Information', 'inform'), ('Management', 'manag')]

>> Lemmatization: 
 [('3', '3'), ('UIMA', 'UIMA'), (':', ':'), ('Unstructured', 'Unstructured'), ('Information', 'Information'), ('Management', 'Management')]



========================================== PARAGRAPH 270 ===========================================

Architecture  4 GATE: General Architecture for Text Processing  

------------------- Sentence 1 -------------------

Architecture  4 GATE: General Architecture for Text Processing

>> Tokens are: 
 ['Architecture', '4', 'GATE', ':', 'General', 'Architecture', 'Text', 'Processing']

>> Bigrams are: 
 [('Architecture', '4'), ('4', 'GATE'), ('GATE', ':'), (':', 'General'), ('General', 'Architecture'), ('Architecture', 'Text'), ('Text', 'Processing')]

>> Trigrams are: 
 [('Architecture', '4', 'GATE'), ('4', 'GATE', ':'), ('GATE', ':', 'General'), (':', 'General', 'Architecture'), ('General', 'Architecture', 'Text'), ('Architecture', 'Text', 'Processing')]

>> POS Tags are: 
 [('Architecture', 'NN'), ('4', 'CD'), ('GATE', 'NN'), (':', ':'), ('General', 'JJ'), ('Architecture', 'NNP'), ('Text', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['Architecture', 'GATE', 'General Architecture Text Processing']

>> Named Entities are: 
 [('PERSON', 'Architecture Text')] 

>> Stemming using Porter Stemmer: 
 [('Architecture', 'architectur'), ('4', '4'), ('GATE', 'gate'), (':', ':'), ('General', 'gener'), ('Architecture', 'architectur'), ('Text', 'text'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Architecture', 'architectur'), ('4', '4'), ('GATE', 'gate'), (':', ':'), ('General', 'general'), ('Architecture', 'architectur'), ('Text', 'text'), ('Processing', 'process')]

>> Lemmatization: 
 [('Architecture', 'Architecture'), ('4', '4'), ('GATE', 'GATE'), (':', ':'), ('General', 'General'), ('Architecture', 'Architecture'), ('Text', 'Text'), ('Processing', 'Processing')]



========================================== PARAGRAPH 271 ===========================================

5 GPL: General Public License  

------------------- Sentence 1 -------------------

5 GPL: General Public License

>> Tokens are: 
 ['5', 'GPL', ':', 'General', 'Public', 'License']

>> Bigrams are: 
 [('5', 'GPL'), ('GPL', ':'), (':', 'General'), ('General', 'Public'), ('Public', 'License')]

>> Trigrams are: 
 [('5', 'GPL', ':'), ('GPL', ':', 'General'), (':', 'General', 'Public'), ('General', 'Public', 'License')]

>> POS Tags are: 
 [('5', 'CD'), ('GPL', 'NNP'), (':', ':'), ('General', 'JJ'), ('Public', 'NNP'), ('License', 'NNP')]

>> Noun Phrases are: 
 ['GPL', 'General Public License']

>> Named Entities are: 
 [('PERSON', 'Public License')] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('GPL', 'gpl'), (':', ':'), ('General', 'gener'), ('Public', 'public'), ('License', 'licens')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('GPL', 'gpl'), (':', ':'), ('General', 'general'), ('Public', 'public'), ('License', 'licens')]

>> Lemmatization: 
 [('5', '5'), ('GPL', 'GPL'), (':', ':'), ('General', 'General'), ('Public', 'Public'), ('License', 'License')]



========================================== PARAGRAPH 272 ===========================================

6 Dynet: Dynamic Neural Network  

------------------- Sentence 1 -------------------

6 Dynet: Dynamic Neural Network

>> Tokens are: 
 ['6', 'Dynet', ':', 'Dynamic', 'Neural', 'Network']

>> Bigrams are: 
 [('6', 'Dynet'), ('Dynet', ':'), (':', 'Dynamic'), ('Dynamic', 'Neural'), ('Neural', 'Network')]

>> Trigrams are: 
 [('6', 'Dynet', ':'), ('Dynet', ':', 'Dynamic'), (':', 'Dynamic', 'Neural'), ('Dynamic', 'Neural', 'Network')]

>> POS Tags are: 
 [('6', 'CD'), ('Dynet', 'NN'), (':', ':'), ('Dynamic', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP')]

>> Noun Phrases are: 
 ['Dynet', 'Dynamic Neural Network']

>> Named Entities are: 
 [('PERSON', 'Dynamic Neural Network')] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('Dynet', 'dynet'), (':', ':'), ('Dynamic', 'dynam'), ('Neural', 'neural'), ('Network', 'network')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('Dynet', 'dynet'), (':', ':'), ('Dynamic', 'dynam'), ('Neural', 'neural'), ('Network', 'network')]

>> Lemmatization: 
 [('6', '6'), ('Dynet', 'Dynet'), (':', ':'), ('Dynamic', 'Dynamic'), ('Neural', 'Neural'), ('Network', 'Network')]



========================================== PARAGRAPH 273 ===========================================

7 MALLET: Machine learning for Language Toolkit  

------------------- Sentence 1 -------------------

7 MALLET: Machine learning for Language Toolkit

>> Tokens are: 
 ['7', 'MALLET', ':', 'Machine', 'learning', 'Language', 'Toolkit']

>> Bigrams are: 
 [('7', 'MALLET'), ('MALLET', ':'), (':', 'Machine'), ('Machine', 'learning'), ('learning', 'Language'), ('Language', 'Toolkit')]

>> Trigrams are: 
 [('7', 'MALLET', ':'), ('MALLET', ':', 'Machine'), (':', 'Machine', 'learning'), ('Machine', 'learning', 'Language'), ('learning', 'Language', 'Toolkit')]

>> POS Tags are: 
 [('7', 'CD'), ('MALLET', 'NNS'), (':', ':'), ('Machine', 'NNP'), ('learning', 'VBG'), ('Language', 'NNP'), ('Toolkit', 'NNP')]

>> Noun Phrases are: 
 ['MALLET', 'Machine', 'Language Toolkit']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('PERSON', 'Language Toolkit')] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('MALLET', 'mallet'), (':', ':'), ('Machine', 'machin'), ('learning', 'learn'), ('Language', 'languag'), ('Toolkit', 'toolkit')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('MALLET', 'mallet'), (':', ':'), ('Machine', 'machin'), ('learning', 'learn'), ('Language', 'languag'), ('Toolkit', 'toolkit')]

>> Lemmatization: 
 [('7', '7'), ('MALLET', 'MALLET'), (':', ':'), ('Machine', 'Machine'), ('learning', 'learning'), ('Language', 'Language'), ('Toolkit', 'Toolkit')]



========================================== PARAGRAPH 274 ===========================================

8 LUIS: Language Understanding Intelligent Service  

------------------- Sentence 1 -------------------

8 LUIS: Language Understanding Intelligent Service

>> Tokens are: 
 ['8', 'LUIS', ':', 'Language', 'Understanding', 'Intelligent', 'Service']

>> Bigrams are: 
 [('8', 'LUIS'), ('LUIS', ':'), (':', 'Language'), ('Language', 'Understanding'), ('Understanding', 'Intelligent'), ('Intelligent', 'Service')]

>> Trigrams are: 
 [('8', 'LUIS', ':'), ('LUIS', ':', 'Language'), (':', 'Language', 'Understanding'), ('Language', 'Understanding', 'Intelligent'), ('Understanding', 'Intelligent', 'Service')]

>> POS Tags are: 
 [('8', 'CD'), ('LUIS', 'NNP'), (':', ':'), ('Language', 'NN'), ('Understanding', 'NNP'), ('Intelligent', 'NNP'), ('Service', 'NNP')]

>> Noun Phrases are: 
 ['LUIS', 'Language Understanding Intelligent Service']

>> Named Entities are: 
 [('PERSON', 'Language Understanding')] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('LUIS', 'lui'), (':', ':'), ('Language', 'languag'), ('Understanding', 'understand'), ('Intelligent', 'intellig'), ('Service', 'servic')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('LUIS', 'lui'), (':', ':'), ('Language', 'languag'), ('Understanding', 'understand'), ('Intelligent', 'intellig'), ('Service', 'servic')]

>> Lemmatization: 
 [('8', '8'), ('LUIS', 'LUIS'), (':', ':'), ('Language', 'Language'), ('Understanding', 'Understanding'), ('Intelligent', 'Intelligent'), ('Service', 'Service')]



========================================== PARAGRAPH 275 ===========================================

REFERENCES  

------------------- Sentence 1 -------------------

REFERENCES

>> Tokens are: 
 ['REFERENCES']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REFERENCES', 'NNS')]

>> Noun Phrases are: 
 ['REFERENCES']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REFERENCES', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('REFERENCES', 'refer')]

>> Lemmatization: 
 [('REFERENCES', 'REFERENCES')]



========================================== PARAGRAPH 276 ===========================================

1. Daniel W. Otter, Julian R. Medina, and Jugal K. Kalita.  2018. A Survey of the Usages of Deep Learning inNatural  Language Processing. 1, 1 (July 2018), 35 pages.  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Daniel W. Otter, Julian R. Medina, and Jugal K. Kalita.

>> Tokens are: 
 ['Daniel', 'W.', 'Otter', ',', 'Julian', 'R.', 'Medina', ',', 'Jugal', 'K.', 'Kalita', '.']

>> Bigrams are: 
 [('Daniel', 'W.'), ('W.', 'Otter'), ('Otter', ','), (',', 'Julian'), ('Julian', 'R.'), ('R.', 'Medina'), ('Medina', ','), (',', 'Jugal'), ('Jugal', 'K.'), ('K.', 'Kalita'), ('Kalita', '.')]

>> Trigrams are: 
 [('Daniel', 'W.', 'Otter'), ('W.', 'Otter', ','), ('Otter', ',', 'Julian'), (',', 'Julian', 'R.'), ('Julian', 'R.', 'Medina'), ('R.', 'Medina', ','), ('Medina', ',', 'Jugal'), (',', 'Jugal', 'K.'), ('Jugal', 'K.', 'Kalita'), ('K.', 'Kalita', '.')]

>> POS Tags are: 
 [('Daniel', 'NNP'), ('W.', 'NNP'), ('Otter', 'NNP'), (',', ','), ('Julian', 'NNP'), ('R.', 'NNP'), ('Medina', 'NNP'), (',', ','), ('Jugal', 'NNP'), ('K.', 'NNP'), ('Kalita', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Daniel W. Otter', 'Julian R. Medina', 'Jugal K. Kalita']

>> Named Entities are: 
 [('PERSON', 'Daniel'), ('PERSON', 'Julian R. Medina'), ('PERSON', 'Jugal K. Kalita')] 

>> Stemming using Porter Stemmer: 
 [('Daniel', 'daniel'), ('W.', 'w.'), ('Otter', 'otter'), (',', ','), ('Julian', 'julian'), ('R.', 'r.'), ('Medina', 'medina'), (',', ','), ('Jugal', 'jugal'), ('K.', 'k.'), ('Kalita', 'kalita'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Daniel', 'daniel'), ('W.', 'w.'), ('Otter', 'otter'), (',', ','), ('Julian', 'julian'), ('R.', 'r.'), ('Medina', 'medina'), (',', ','), ('Jugal', 'jugal'), ('K.', 'k.'), ('Kalita', 'kalita'), ('.', '.')]

>> Lemmatization: 
 [('Daniel', 'Daniel'), ('W.', 'W.'), ('Otter', 'Otter'), (',', ','), ('Julian', 'Julian'), ('R.', 'R.'), ('Medina', 'Medina'), (',', ','), ('Jugal', 'Jugal'), ('K.', 'K.'), ('Kalita', 'Kalita'), ('.', '.')]


------------------- Sentence 3 -------------------

2018.

>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]


------------------- Sentence 4 -------------------

A Survey of the Usages of Deep Learning inNatural  Language Processing.

>> Tokens are: 
 ['A', 'Survey', 'Usages', 'Deep', 'Learning', 'inNatural', 'Language', 'Processing', '.']

>> Bigrams are: 
 [('A', 'Survey'), ('Survey', 'Usages'), ('Usages', 'Deep'), ('Deep', 'Learning'), ('Learning', 'inNatural'), ('inNatural', 'Language'), ('Language', 'Processing'), ('Processing', '.')]

>> Trigrams are: 
 [('A', 'Survey', 'Usages'), ('Survey', 'Usages', 'Deep'), ('Usages', 'Deep', 'Learning'), ('Deep', 'Learning', 'inNatural'), ('Learning', 'inNatural', 'Language'), ('inNatural', 'Language', 'Processing'), ('Language', 'Processing', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Survey', 'NNP'), ('Usages', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('inNatural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A Survey Usages Deep Learning', 'inNatural Language Processing']

>> Named Entities are: 
 [('PERSON', 'Usages Deep')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Survey', 'survey'), ('Usages', 'usag'), ('Deep', 'deep'), ('Learning', 'learn'), ('inNatural', 'innatur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Survey', 'survey'), ('Usages', 'usag'), ('Deep', 'deep'), ('Learning', 'learn'), ('inNatural', 'innatur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Survey', 'Survey'), ('Usages', 'Usages'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('inNatural', 'inNatural'), ('Language', 'Language'), ('Processing', 'Processing'), ('.', '.')]


------------------- Sentence 5 -------------------

1, 1 (July 2018), 35 pages.

>> Tokens are: 
 ['1', ',', '1', '(', 'July', '2018', ')', ',', '35', 'pages', '.']

>> Bigrams are: 
 [('1', ','), (',', '1'), ('1', '('), ('(', 'July'), ('July', '2018'), ('2018', ')'), (')', ','), (',', '35'), ('35', 'pages'), ('pages', '.')]

>> Trigrams are: 
 [('1', ',', '1'), (',', '1', '('), ('1', '(', 'July'), ('(', 'July', '2018'), ('July', '2018', ')'), ('2018', ')', ','), (')', ',', '35'), (',', '35', 'pages'), ('35', 'pages', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('1', 'CD'), ('(', '('), ('July', 'NNP'), ('2018', 'CD'), (')', ')'), (',', ','), ('35', 'CD'), ('pages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['July', 'pages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('1', '1'), ('(', '('), ('July', 'juli'), ('2018', '2018'), (')', ')'), (',', ','), ('35', '35'), ('pages', 'page'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('1', '1'), ('(', '('), ('July', 'juli'), ('2018', '2018'), (')', ')'), (',', ','), ('35', '35'), ('pages', 'page'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('1', '1'), ('(', '('), ('July', 'July'), ('2018', '2018'), (')', ')'), (',', ','), ('35', '35'), ('pages', 'page'), ('.', '.')]



========================================== PARAGRAPH 277 ===========================================

2. ROBERT DALE. "The commercial NLP Landscape in  2017", Article in Natural LanguageEngineering, July2017   

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

ROBERT DALE.

>> Tokens are: 
 ['ROBERT', 'DALE', '.']

>> Bigrams are: 
 [('ROBERT', 'DALE'), ('DALE', '.')]

>> Trigrams are: 
 [('ROBERT', 'DALE', '.')]

>> POS Tags are: 
 [('ROBERT', 'NNP'), ('DALE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ROBERT DALE']

>> Named Entities are: 
 [('PERSON', 'ROBERT'), ('GPE', 'DALE')] 

>> Stemming using Porter Stemmer: 
 [('ROBERT', 'robert'), ('DALE', 'dale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ROBERT', 'robert'), ('DALE', 'dale'), ('.', '.')]

>> Lemmatization: 
 [('ROBERT', 'ROBERT'), ('DALE', 'DALE'), ('.', '.')]


------------------- Sentence 3 -------------------

"The commercial NLP Landscape in  2017", Article in Natural LanguageEngineering, July2017

>> Tokens are: 
 ['``', 'The', 'commercial', 'NLP', 'Landscape', '2017', "''", ',', 'Article', 'Natural', 'LanguageEngineering', ',', 'July2017']

>> Bigrams are: 
 [('``', 'The'), ('The', 'commercial'), ('commercial', 'NLP'), ('NLP', 'Landscape'), ('Landscape', '2017'), ('2017', "''"), ("''", ','), (',', 'Article'), ('Article', 'Natural'), ('Natural', 'LanguageEngineering'), ('LanguageEngineering', ','), (',', 'July2017')]

>> Trigrams are: 
 [('``', 'The', 'commercial'), ('The', 'commercial', 'NLP'), ('commercial', 'NLP', 'Landscape'), ('NLP', 'Landscape', '2017'), ('Landscape', '2017', "''"), ('2017', "''", ','), ("''", ',', 'Article'), (',', 'Article', 'Natural'), ('Article', 'Natural', 'LanguageEngineering'), ('Natural', 'LanguageEngineering', ','), ('LanguageEngineering', ',', 'July2017')]

>> POS Tags are: 
 [('``', '``'), ('The', 'DT'), ('commercial', 'JJ'), ('NLP', 'NNP'), ('Landscape', 'NNP'), ('2017', 'CD'), ("''", "''"), (',', ','), ('Article', 'NNP'), ('Natural', 'NNP'), ('LanguageEngineering', 'NNP'), (',', ','), ('July2017', 'NNP')]

>> Noun Phrases are: 
 ['The commercial NLP Landscape', 'Article Natural LanguageEngineering', 'July2017']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('PERSON', 'Article Natural'), ('PERSON', 'July2017')] 

>> Stemming using Porter Stemmer: 
 [('``', '``'), ('The', 'the'), ('commercial', 'commerci'), ('NLP', 'nlp'), ('Landscape', 'landscap'), ('2017', '2017'), ("''", "''"), (',', ','), ('Article', 'articl'), ('Natural', 'natur'), ('LanguageEngineering', 'languageengin'), (',', ','), ('July2017', 'july2017')]

>> Stemming using Snowball Stemmer: 
 [('``', '``'), ('The', 'the'), ('commercial', 'commerci'), ('NLP', 'nlp'), ('Landscape', 'landscap'), ('2017', '2017'), ("''", "''"), (',', ','), ('Article', 'articl'), ('Natural', 'natur'), ('LanguageEngineering', 'languageengin'), (',', ','), ('July2017', 'july2017')]

>> Lemmatization: 
 [('``', '``'), ('The', 'The'), ('commercial', 'commercial'), ('NLP', 'NLP'), ('Landscape', 'Landscape'), ('2017', '2017'), ("''", "''"), (',', ','), ('Article', 'Article'), ('Natural', 'Natural'), ('LanguageEngineering', 'LanguageEngineering'), (',', ','), ('July2017', 'July2017')]



========================================== PARAGRAPH 278 ===========================================

3. ACL 2018: 56 th  Annual Meeting of Association for  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

ACL 2018: 56 th  Annual Meeting of Association for

>> Tokens are: 
 ['ACL', '2018', ':', '56', 'th', 'Annual', 'Meeting', 'Association']

>> Bigrams are: 
 [('ACL', '2018'), ('2018', ':'), (':', '56'), ('56', 'th'), ('th', 'Annual'), ('Annual', 'Meeting'), ('Meeting', 'Association')]

>> Trigrams are: 
 [('ACL', '2018', ':'), ('2018', ':', '56'), (':', '56', 'th'), ('56', 'th', 'Annual'), ('th', 'Annual', 'Meeting'), ('Annual', 'Meeting', 'Association')]

>> POS Tags are: 
 [('ACL', 'JJ'), ('2018', 'CD'), (':', ':'), ('56', 'CD'), ('th', 'NNS'), ('Annual', 'NNP'), ('Meeting', 'NNP'), ('Association', 'NNP')]

>> Noun Phrases are: 
 ['th Annual Meeting Association']

>> Named Entities are: 
 [('PERSON', 'Annual Meeting')] 

>> Stemming using Porter Stemmer: 
 [('ACL', 'acl'), ('2018', '2018'), (':', ':'), ('56', '56'), ('th', 'th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('ACL', 'acl'), ('2018', '2018'), (':', ':'), ('56', '56'), ('th', 'th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ')]

>> Lemmatization: 
 [('ACL', 'ACL'), ('2018', '2018'), (':', ':'), ('56', '56'), ('th', 'th'), ('Annual', 'Annual'), ('Meeting', 'Meeting'), ('Association', 'Association')]



========================================== PARAGRAPH 279 ===========================================

Computational Linguistics https://acl2018.org  

------------------- Sentence 1 -------------------

Computational Linguistics https://acl2018.org

>> Tokens are: 
 ['Computational', 'Linguistics', 'https', ':', '//acl2018.org']

>> Bigrams are: 
 [('Computational', 'Linguistics'), ('Linguistics', 'https'), ('https', ':'), (':', '//acl2018.org')]

>> Trigrams are: 
 [('Computational', 'Linguistics', 'https'), ('Linguistics', 'https', ':'), ('https', ':', '//acl2018.org')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('Linguistics', 'NNS'), ('https', 'NN'), (':', ':'), ('//acl2018.org', 'NN')]

>> Noun Phrases are: 
 ['Computational Linguistics https', '//acl2018.org']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('https', 'http'), (':', ':'), ('//acl2018.org', '//acl2018.org')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('https', 'https'), (':', ':'), ('//acl2018.org', '//acl2018.org')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('https', 'http'), (':', ':'), ('//acl2018.org', '//acl2018.org')]



========================================== PARAGRAPH 280 ===========================================

4. Predictive Analytics Today:  www.predictiveanalyticstoday.com[accessed in Dec 2018]  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Predictive Analytics Today:  www.predictiveanalyticstoday.com[accessed in Dec 2018]

>> Tokens are: 
 ['Predictive', 'Analytics', 'Today', ':', 'www.predictiveanalyticstoday.com', '[', 'accessed', 'Dec', '2018', ']']

>> Bigrams are: 
 [('Predictive', 'Analytics'), ('Analytics', 'Today'), ('Today', ':'), (':', 'www.predictiveanalyticstoday.com'), ('www.predictiveanalyticstoday.com', '['), ('[', 'accessed'), ('accessed', 'Dec'), ('Dec', '2018'), ('2018', ']')]

>> Trigrams are: 
 [('Predictive', 'Analytics', 'Today'), ('Analytics', 'Today', ':'), ('Today', ':', 'www.predictiveanalyticstoday.com'), (':', 'www.predictiveanalyticstoday.com', '['), ('www.predictiveanalyticstoday.com', '[', 'accessed'), ('[', 'accessed', 'Dec'), ('accessed', 'Dec', '2018'), ('Dec', '2018', ']')]

>> POS Tags are: 
 [('Predictive', 'JJ'), ('Analytics', 'NNS'), ('Today', 'NN'), (':', ':'), ('www.predictiveanalyticstoday.com', 'NN'), ('[', 'NN'), ('accessed', 'VBD'), ('Dec', 'NNP'), ('2018', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Predictive Analytics Today', 'www.predictiveanalyticstoday.com [', 'Dec', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predictive', 'predict'), ('Analytics', 'analyt'), ('Today', 'today'), (':', ':'), ('www.predictiveanalyticstoday.com', 'www.predictiveanalyticstoday.com'), ('[', '['), ('accessed', 'access'), ('Dec', 'dec'), ('2018', '2018'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Predictive', 'predict'), ('Analytics', 'analyt'), ('Today', 'today'), (':', ':'), ('www.predictiveanalyticstoday.com', 'www.predictiveanalyticstoday.com'), ('[', '['), ('accessed', 'access'), ('Dec', 'dec'), ('2018', '2018'), (']', ']')]

>> Lemmatization: 
 [('Predictive', 'Predictive'), ('Analytics', 'Analytics'), ('Today', 'Today'), (':', ':'), ('www.predictiveanalyticstoday.com', 'www.predictiveanalyticstoday.com'), ('[', '['), ('accessed', 'accessed'), ('Dec', 'Dec'), ('2018', '2018'), (']', ']')]



========================================== PARAGRAPH 281 ===========================================

5. Ali Shatnawi, Ghadeer Al-Bdour, Raffi Al-Qurran and  Mahmoud Al-Ayyoub 2018. A Comparative Study of Open  Source Deep Learning Frameworks. 2018 9th International  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

Ali Shatnawi, Ghadeer Al-Bdour, Raffi Al-Qurran and  Mahmoud Al-Ayyoub 2018.

>> Tokens are: 
 ['Ali', 'Shatnawi', ',', 'Ghadeer', 'Al-Bdour', ',', 'Raffi', 'Al-Qurran', 'Mahmoud', 'Al-Ayyoub', '2018', '.']

>> Bigrams are: 
 [('Ali', 'Shatnawi'), ('Shatnawi', ','), (',', 'Ghadeer'), ('Ghadeer', 'Al-Bdour'), ('Al-Bdour', ','), (',', 'Raffi'), ('Raffi', 'Al-Qurran'), ('Al-Qurran', 'Mahmoud'), ('Mahmoud', 'Al-Ayyoub'), ('Al-Ayyoub', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Ali', 'Shatnawi', ','), ('Shatnawi', ',', 'Ghadeer'), (',', 'Ghadeer', 'Al-Bdour'), ('Ghadeer', 'Al-Bdour', ','), ('Al-Bdour', ',', 'Raffi'), (',', 'Raffi', 'Al-Qurran'), ('Raffi', 'Al-Qurran', 'Mahmoud'), ('Al-Qurran', 'Mahmoud', 'Al-Ayyoub'), ('Mahmoud', 'Al-Ayyoub', '2018'), ('Al-Ayyoub', '2018', '.')]

>> POS Tags are: 
 [('Ali', 'NNP'), ('Shatnawi', 'NNP'), (',', ','), ('Ghadeer', 'NNP'), ('Al-Bdour', 'NNP'), (',', ','), ('Raffi', 'NNP'), ('Al-Qurran', 'NNP'), ('Mahmoud', 'NNP'), ('Al-Ayyoub', 'NNP'), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Ali Shatnawi', 'Ghadeer Al-Bdour', 'Raffi Al-Qurran Mahmoud Al-Ayyoub']

>> Named Entities are: 
 [('PERSON', 'Ali Shatnawi'), ('PERSON', 'Ghadeer Al-Bdour'), ('PERSON', 'Raffi'), ('PERSON', 'Mahmoud')] 

>> Stemming using Porter Stemmer: 
 [('Ali', 'ali'), ('Shatnawi', 'shatnawi'), (',', ','), ('Ghadeer', 'ghadeer'), ('Al-Bdour', 'al-bdour'), (',', ','), ('Raffi', 'raffi'), ('Al-Qurran', 'al-qurran'), ('Mahmoud', 'mahmoud'), ('Al-Ayyoub', 'al-ayyoub'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ali', 'ali'), ('Shatnawi', 'shatnawi'), (',', ','), ('Ghadeer', 'ghadeer'), ('Al-Bdour', 'al-bdour'), (',', ','), ('Raffi', 'raffi'), ('Al-Qurran', 'al-qurran'), ('Mahmoud', 'mahmoud'), ('Al-Ayyoub', 'al-ayyoub'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Ali', 'Ali'), ('Shatnawi', 'Shatnawi'), (',', ','), ('Ghadeer', 'Ghadeer'), ('Al-Bdour', 'Al-Bdour'), (',', ','), ('Raffi', 'Raffi'), ('Al-Qurran', 'Al-Qurran'), ('Mahmoud', 'Mahmoud'), ('Al-Ayyoub', 'Al-Ayyoub'), ('2018', '2018'), ('.', '.')]


------------------- Sentence 3 -------------------

A Comparative Study of Open  Source Deep Learning Frameworks.

>> Tokens are: 
 ['A', 'Comparative', 'Study', 'Open', 'Source', 'Deep', 'Learning', 'Frameworks', '.']

>> Bigrams are: 
 [('A', 'Comparative'), ('Comparative', 'Study'), ('Study', 'Open'), ('Open', 'Source'), ('Source', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Frameworks'), ('Frameworks', '.')]

>> Trigrams are: 
 [('A', 'Comparative', 'Study'), ('Comparative', 'Study', 'Open'), ('Study', 'Open', 'Source'), ('Open', 'Source', 'Deep'), ('Source', 'Deep', 'Learning'), ('Deep', 'Learning', 'Frameworks'), ('Learning', 'Frameworks', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Comparative', 'NNP'), ('Study', 'NNP'), ('Open', 'NNP'), ('Source', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Frameworks', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A Comparative Study Open Source Deep Learning Frameworks']

>> Named Entities are: 
 [('ORGANIZATION', 'Comparative Study Open Source Deep')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Comparative', 'compar'), ('Study', 'studi'), ('Open', 'open'), ('Source', 'sourc'), ('Deep', 'deep'), ('Learning', 'learn'), ('Frameworks', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Comparative', 'compar'), ('Study', 'studi'), ('Open', 'open'), ('Source', 'sourc'), ('Deep', 'deep'), ('Learning', 'learn'), ('Frameworks', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Comparative', 'Comparative'), ('Study', 'Study'), ('Open', 'Open'), ('Source', 'Source'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Frameworks', 'Frameworks'), ('.', '.')]


------------------- Sentence 4 -------------------

2018 9th International

>> Tokens are: 
 ['2018', '9th', 'International']

>> Bigrams are: 
 [('2018', '9th'), ('9th', 'International')]

>> Trigrams are: 
 [('2018', '9th', 'International')]

>> POS Tags are: 
 [('2018', 'CD'), ('9th', 'CD'), ('International', 'NNP')]

>> Noun Phrases are: 
 ['International']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('9th', '9th'), ('International', 'intern')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('9th', '9th'), ('International', 'intern')]

>> Lemmatization: 
 [('2018', '2018'), ('9th', '9th'), ('International', 'International')]



========================================== PARAGRAPH 282 ===========================================

Conference on Information and Communication Systems  

------------------- Sentence 1 -------------------

Conference on Information and Communication Systems

>> Tokens are: 
 ['Conference', 'Information', 'Communication', 'Systems']

>> Bigrams are: 
 [('Conference', 'Information'), ('Information', 'Communication'), ('Communication', 'Systems')]

>> Trigrams are: 
 [('Conference', 'Information', 'Communication'), ('Information', 'Communication', 'Systems')]

>> POS Tags are: 
 [('Conference', 'NN'), ('Information', 'NNP'), ('Communication', 'NNP'), ('Systems', 'NNP')]

>> Noun Phrases are: 
 ['Conference Information Communication Systems']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference Information Communication Systems')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('Information', 'inform'), ('Communication', 'commun'), ('Systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('Information', 'inform'), ('Communication', 'communic'), ('Systems', 'system')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('Information', 'Information'), ('Communication', 'Communication'), ('Systems', 'Systems')]



========================================== PARAGRAPH 283 ===========================================

(ICICS)  6. Intelligent automation: Making cognitive real Knowledge  

------------------- Sentence 1 -------------------

(ICICS)  6.

>> Tokens are: 
 ['(', 'ICICS', ')', '6', '.']

>> Bigrams are: 
 [('(', 'ICICS'), ('ICICS', ')'), (')', '6'), ('6', '.')]

>> Trigrams are: 
 [('(', 'ICICS', ')'), ('ICICS', ')', '6'), (')', '6', '.')]

>> POS Tags are: 
 [('(', '('), ('ICICS', 'NNP'), (')', ')'), ('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['ICICS']

>> Named Entities are: 
 [('ORGANIZATION', 'ICICS')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('ICICS', 'icic'), (')', ')'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('ICICS', 'icic'), (')', ')'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('ICICS', 'ICICS'), (')', ')'), ('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Intelligent automation: Making cognitive real Knowledge

>> Tokens are: 
 ['Intelligent', 'automation', ':', 'Making', 'cognitive', 'real', 'Knowledge']

>> Bigrams are: 
 [('Intelligent', 'automation'), ('automation', ':'), (':', 'Making'), ('Making', 'cognitive'), ('cognitive', 'real'), ('real', 'Knowledge')]

>> Trigrams are: 
 [('Intelligent', 'automation', ':'), ('automation', ':', 'Making'), (':', 'Making', 'cognitive'), ('Making', 'cognitive', 'real'), ('cognitive', 'real', 'Knowledge')]

>> POS Tags are: 
 [('Intelligent', 'JJ'), ('automation', 'NN'), (':', ':'), ('Making', 'NNP'), ('cognitive', 'JJ'), ('real', 'JJ'), ('Knowledge', 'NN')]

>> Noun Phrases are: 
 ['Intelligent automation', 'Making', 'cognitive real Knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intelligent', 'intellig'), ('automation', 'autom'), (':', ':'), ('Making', 'make'), ('cognitive', 'cognit'), ('real', 'real'), ('Knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('Intelligent', 'intellig'), ('automation', 'autom'), (':', ':'), ('Making', 'make'), ('cognitive', 'cognit'), ('real', 'real'), ('Knowledge', 'knowledg')]

>> Lemmatization: 
 [('Intelligent', 'Intelligent'), ('automation', 'automation'), (':', ':'), ('Making', 'Making'), ('cognitive', 'cognitive'), ('real', 'real'), ('Knowledge', 'Knowledge')]



========================================== PARAGRAPH 284 ===========================================

Series I Chapter 2. 2018, EY report.   7. Jacques Bughin, Eric Hazan, SreeRamaswamy, Michael  

------------------- Sentence 1 -------------------

Series I Chapter 2.

>> Tokens are: 
 ['Series', 'I', 'Chapter', '2', '.']

>> Bigrams are: 
 [('Series', 'I'), ('I', 'Chapter'), ('Chapter', '2'), ('2', '.')]

>> Trigrams are: 
 [('Series', 'I', 'Chapter'), ('I', 'Chapter', '2'), ('Chapter', '2', '.')]

>> POS Tags are: 
 [('Series', 'NNP'), ('I', 'PRP'), ('Chapter', 'NNP'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Series', 'Chapter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Series', 'seri'), ('I', 'i'), ('Chapter', 'chapter'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Series', 'seri'), ('I', 'i'), ('Chapter', 'chapter'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Series', 'Series'), ('I', 'I'), ('Chapter', 'Chapter'), ('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

2018, EY report.

>> Tokens are: 
 ['2018', ',', 'EY', 'report', '.']

>> Bigrams are: 
 [('2018', ','), (',', 'EY'), ('EY', 'report'), ('report', '.')]

>> Trigrams are: 
 [('2018', ',', 'EY'), (',', 'EY', 'report'), ('EY', 'report', '.')]

>> POS Tags are: 
 [('2018', 'CD'), (',', ','), ('EY', 'NNP'), ('report', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['EY report']

>> Named Entities are: 
 [('ORGANIZATION', 'EY')] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), (',', ','), ('EY', 'ey'), ('report', 'report'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), (',', ','), ('EY', 'ey'), ('report', 'report'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), (',', ','), ('EY', 'EY'), ('report', 'report'), ('.', '.')]


------------------- Sentence 3 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 4 -------------------

Jacques Bughin, Eric Hazan, SreeRamaswamy, Michael

>> Tokens are: 
 ['Jacques', 'Bughin', ',', 'Eric', 'Hazan', ',', 'SreeRamaswamy', ',', 'Michael']

>> Bigrams are: 
 [('Jacques', 'Bughin'), ('Bughin', ','), (',', 'Eric'), ('Eric', 'Hazan'), ('Hazan', ','), (',', 'SreeRamaswamy'), ('SreeRamaswamy', ','), (',', 'Michael')]

>> Trigrams are: 
 [('Jacques', 'Bughin', ','), ('Bughin', ',', 'Eric'), (',', 'Eric', 'Hazan'), ('Eric', 'Hazan', ','), ('Hazan', ',', 'SreeRamaswamy'), (',', 'SreeRamaswamy', ','), ('SreeRamaswamy', ',', 'Michael')]

>> POS Tags are: 
 [('Jacques', 'NNS'), ('Bughin', 'NNP'), (',', ','), ('Eric', 'NNP'), ('Hazan', 'NNP'), (',', ','), ('SreeRamaswamy', 'NNP'), (',', ','), ('Michael', 'NNP')]

>> Noun Phrases are: 
 ['Jacques Bughin', 'Eric Hazan', 'SreeRamaswamy', 'Michael']

>> Named Entities are: 
 [('PERSON', 'Jacques Bughin'), ('PERSON', 'Eric Hazan'), ('ORGANIZATION', 'SreeRamaswamy'), ('PERSON', 'Michael')] 

>> Stemming using Porter Stemmer: 
 [('Jacques', 'jacqu'), ('Bughin', 'bughin'), (',', ','), ('Eric', 'eric'), ('Hazan', 'hazan'), (',', ','), ('SreeRamaswamy', 'sreeramaswami'), (',', ','), ('Michael', 'michael')]

>> Stemming using Snowball Stemmer: 
 [('Jacques', 'jacqu'), ('Bughin', 'bughin'), (',', ','), ('Eric', 'eric'), ('Hazan', 'hazan'), (',', ','), ('SreeRamaswamy', 'sreeramaswami'), (',', ','), ('Michael', 'michael')]

>> Lemmatization: 
 [('Jacques', 'Jacques'), ('Bughin', 'Bughin'), (',', ','), ('Eric', 'Eric'), ('Hazan', 'Hazan'), (',', ','), ('SreeRamaswamy', 'SreeRamaswamy'), (',', ','), ('Michael', 'Michael')]



========================================== PARAGRAPH 285 ===========================================

Chui , TeraAllas, Peter Dahlström, Nicolaus Henke, Monica  

------------------- Sentence 1 -------------------

Chui , TeraAllas, Peter Dahlström, Nicolaus Henke, Monica

>> Tokens are: 
 ['Chui', ',', 'TeraAllas', ',', 'Peter', 'Dahlström', ',', 'Nicolaus', 'Henke', ',', 'Monica']

>> Bigrams are: 
 [('Chui', ','), (',', 'TeraAllas'), ('TeraAllas', ','), (',', 'Peter'), ('Peter', 'Dahlström'), ('Dahlström', ','), (',', 'Nicolaus'), ('Nicolaus', 'Henke'), ('Henke', ','), (',', 'Monica')]

>> Trigrams are: 
 [('Chui', ',', 'TeraAllas'), (',', 'TeraAllas', ','), ('TeraAllas', ',', 'Peter'), (',', 'Peter', 'Dahlström'), ('Peter', 'Dahlström', ','), ('Dahlström', ',', 'Nicolaus'), (',', 'Nicolaus', 'Henke'), ('Nicolaus', 'Henke', ','), ('Henke', ',', 'Monica')]

>> POS Tags are: 
 [('Chui', 'NNP'), (',', ','), ('TeraAllas', 'NNP'), (',', ','), ('Peter', 'NNP'), ('Dahlström', 'NNP'), (',', ','), ('Nicolaus', 'NNP'), ('Henke', 'NNP'), (',', ','), ('Monica', 'NNP')]

>> Noun Phrases are: 
 ['Chui', 'TeraAllas', 'Peter Dahlström', 'Nicolaus Henke', 'Monica']

>> Named Entities are: 
 [('GPE', 'Chui'), ('ORGANIZATION', 'TeraAllas'), ('PERSON', 'Peter Dahlström'), ('PERSON', 'Nicolaus Henke'), ('PERSON', 'Monica')] 

>> Stemming using Porter Stemmer: 
 [('Chui', 'chui'), (',', ','), ('TeraAllas', 'teraalla'), (',', ','), ('Peter', 'peter'), ('Dahlström', 'dahlström'), (',', ','), ('Nicolaus', 'nicolau'), ('Henke', 'henk'), (',', ','), ('Monica', 'monica')]

>> Stemming using Snowball Stemmer: 
 [('Chui', 'chui'), (',', ','), ('TeraAllas', 'teraalla'), (',', ','), ('Peter', 'peter'), ('Dahlström', 'dahlström'), (',', ','), ('Nicolaus', 'nicolaus'), ('Henke', 'henk'), (',', ','), ('Monica', 'monica')]

>> Lemmatization: 
 [('Chui', 'Chui'), (',', ','), ('TeraAllas', 'TeraAllas'), (',', ','), ('Peter', 'Peter'), ('Dahlström', 'Dahlström'), (',', ','), ('Nicolaus', 'Nicolaus'), ('Henke', 'Henke'), (',', ','), ('Monica', 'Monica')]



========================================== PARAGRAPH 286 ===========================================

Trench,  2017.   MGI ARTIFICIAL INTELLIGENCE THE  NEXT DIGITAL FRONTIER? McKinsey & Company  

------------------- Sentence 1 -------------------

Trench,  2017.

>> Tokens are: 
 ['Trench', ',', '2017', '.']

>> Bigrams are: 
 [('Trench', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Trench', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Trench', 'NN'), (',', ','), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Trench']

>> Named Entities are: 
 [('GPE', 'Trench')] 

>> Stemming using Porter Stemmer: 
 [('Trench', 'trench'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Trench', 'trench'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Trench', 'Trench'), (',', ','), ('2017', '2017'), ('.', '.')]


------------------- Sentence 2 -------------------

MGI ARTIFICIAL INTELLIGENCE THE  NEXT DIGITAL FRONTIER?

>> Tokens are: 
 ['MGI', 'ARTIFICIAL', 'INTELLIGENCE', 'THE', 'NEXT', 'DIGITAL', 'FRONTIER', '?']

>> Bigrams are: 
 [('MGI', 'ARTIFICIAL'), ('ARTIFICIAL', 'INTELLIGENCE'), ('INTELLIGENCE', 'THE'), ('THE', 'NEXT'), ('NEXT', 'DIGITAL'), ('DIGITAL', 'FRONTIER'), ('FRONTIER', '?')]

>> Trigrams are: 
 [('MGI', 'ARTIFICIAL', 'INTELLIGENCE'), ('ARTIFICIAL', 'INTELLIGENCE', 'THE'), ('INTELLIGENCE', 'THE', 'NEXT'), ('THE', 'NEXT', 'DIGITAL'), ('NEXT', 'DIGITAL', 'FRONTIER'), ('DIGITAL', 'FRONTIER', '?')]

>> POS Tags are: 
 [('MGI', 'NNP'), ('ARTIFICIAL', 'NNP'), ('INTELLIGENCE', 'NNP'), ('THE', 'NNP'), ('NEXT', 'NNP'), ('DIGITAL', 'NNP'), ('FRONTIER', 'NNP'), ('?', '.')]

>> Noun Phrases are: 
 ['MGI ARTIFICIAL INTELLIGENCE THE NEXT DIGITAL FRONTIER']

>> Named Entities are: 
 [('ORGANIZATION', 'MGI'), ('ORGANIZATION', 'ARTIFICIAL'), ('ORGANIZATION', 'NEXT'), ('ORGANIZATION', 'DIGITAL')] 

>> Stemming using Porter Stemmer: 
 [('MGI', 'mgi'), ('ARTIFICIAL', 'artifici'), ('INTELLIGENCE', 'intellig'), ('THE', 'the'), ('NEXT', 'next'), ('DIGITAL', 'digit'), ('FRONTIER', 'frontier'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('MGI', 'mgi'), ('ARTIFICIAL', 'artifici'), ('INTELLIGENCE', 'intellig'), ('THE', 'the'), ('NEXT', 'next'), ('DIGITAL', 'digit'), ('FRONTIER', 'frontier'), ('?', '?')]

>> Lemmatization: 
 [('MGI', 'MGI'), ('ARTIFICIAL', 'ARTIFICIAL'), ('INTELLIGENCE', 'INTELLIGENCE'), ('THE', 'THE'), ('NEXT', 'NEXT'), ('DIGITAL', 'DIGITAL'), ('FRONTIER', 'FRONTIER'), ('?', '?')]


------------------- Sentence 3 -------------------

McKinsey & Company

>> Tokens are: 
 ['McKinsey', '&', 'Company']

>> Bigrams are: 
 [('McKinsey', '&'), ('&', 'Company')]

>> Trigrams are: 
 [('McKinsey', '&', 'Company')]

>> POS Tags are: 
 [('McKinsey', 'NNP'), ('&', 'CC'), ('Company', 'NNP')]

>> Noun Phrases are: 
 ['McKinsey', 'Company']

>> Named Entities are: 
 [('ORGANIZATION', 'McKinsey'), ('ORGANIZATION', 'Company')] 

>> Stemming using Porter Stemmer: 
 [('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani')]

>> Lemmatization: 
 [('McKinsey', 'McKinsey'), ('&', '&'), ('Company', 'Company')]



========================================== PARAGRAPH 287 ===========================================

McKinsey & Company report  July 2017  

------------------- Sentence 1 -------------------

McKinsey & Company report  July 2017

>> Tokens are: 
 ['McKinsey', '&', 'Company', 'report', 'July', '2017']

>> Bigrams are: 
 [('McKinsey', '&'), ('&', 'Company'), ('Company', 'report'), ('report', 'July'), ('July', '2017')]

>> Trigrams are: 
 [('McKinsey', '&', 'Company'), ('&', 'Company', 'report'), ('Company', 'report', 'July'), ('report', 'July', '2017')]

>> POS Tags are: 
 [('McKinsey', 'NNP'), ('&', 'CC'), ('Company', 'NNP'), ('report', 'NN'), ('July', 'NNP'), ('2017', 'CD')]

>> Noun Phrases are: 
 ['McKinsey', 'Company report July']

>> Named Entities are: 
 [('ORGANIZATION', 'McKinsey'), ('ORGANIZATION', 'Company')] 

>> Stemming using Porter Stemmer: 
 [('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), ('report', 'report'), ('July', 'juli'), ('2017', '2017')]

>> Stemming using Snowball Stemmer: 
 [('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), ('report', 'report'), ('July', 'juli'), ('2017', '2017')]

>> Lemmatization: 
 [('McKinsey', 'McKinsey'), ('&', '&'), ('Company', 'Company'), ('report', 'report'), ('July', 'July'), ('2017', '2017')]



========================================== PARAGRAPH 288 ===========================================

8. Svetlana Sicular, Kenneth Brant 2018, Hype Cycle for  ArtificialIntelligence, 2018 Gartner report July 2018.  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

Svetlana Sicular, Kenneth Brant 2018, Hype Cycle for  ArtificialIntelligence, 2018 Gartner report July 2018.

>> Tokens are: 
 ['Svetlana', 'Sicular', ',', 'Kenneth', 'Brant', '2018', ',', 'Hype', 'Cycle', 'ArtificialIntelligence', ',', '2018', 'Gartner', 'report', 'July', '2018', '.']

>> Bigrams are: 
 [('Svetlana', 'Sicular'), ('Sicular', ','), (',', 'Kenneth'), ('Kenneth', 'Brant'), ('Brant', '2018'), ('2018', ','), (',', 'Hype'), ('Hype', 'Cycle'), ('Cycle', 'ArtificialIntelligence'), ('ArtificialIntelligence', ','), (',', '2018'), ('2018', 'Gartner'), ('Gartner', 'report'), ('report', 'July'), ('July', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Svetlana', 'Sicular', ','), ('Sicular', ',', 'Kenneth'), (',', 'Kenneth', 'Brant'), ('Kenneth', 'Brant', '2018'), ('Brant', '2018', ','), ('2018', ',', 'Hype'), (',', 'Hype', 'Cycle'), ('Hype', 'Cycle', 'ArtificialIntelligence'), ('Cycle', 'ArtificialIntelligence', ','), ('ArtificialIntelligence', ',', '2018'), (',', '2018', 'Gartner'), ('2018', 'Gartner', 'report'), ('Gartner', 'report', 'July'), ('report', 'July', '2018'), ('July', '2018', '.')]

>> POS Tags are: 
 [('Svetlana', 'NNP'), ('Sicular', 'NNP'), (',', ','), ('Kenneth', 'NNP'), ('Brant', 'NNP'), ('2018', 'CD'), (',', ','), ('Hype', 'NNP'), ('Cycle', 'NNP'), ('ArtificialIntelligence', 'NNP'), (',', ','), ('2018', 'CD'), ('Gartner', 'NNP'), ('report', 'NN'), ('July', 'NNP'), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Svetlana Sicular', 'Kenneth Brant', 'Hype Cycle ArtificialIntelligence', 'Gartner report July']

>> Named Entities are: 
 [('PERSON', 'Svetlana'), ('ORGANIZATION', 'Sicular'), ('PERSON', 'Kenneth Brant'), ('PERSON', 'Hype Cycle ArtificialIntelligence')] 

>> Stemming using Porter Stemmer: 
 [('Svetlana', 'svetlana'), ('Sicular', 'sicular'), (',', ','), ('Kenneth', 'kenneth'), ('Brant', 'brant'), ('2018', '2018'), (',', ','), ('Hype', 'hype'), ('Cycle', 'cycl'), ('ArtificialIntelligence', 'artificialintellig'), (',', ','), ('2018', '2018'), ('Gartner', 'gartner'), ('report', 'report'), ('July', 'juli'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Svetlana', 'svetlana'), ('Sicular', 'sicular'), (',', ','), ('Kenneth', 'kenneth'), ('Brant', 'brant'), ('2018', '2018'), (',', ','), ('Hype', 'hype'), ('Cycle', 'cycl'), ('ArtificialIntelligence', 'artificialintellig'), (',', ','), ('2018', '2018'), ('Gartner', 'gartner'), ('report', 'report'), ('July', 'juli'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Svetlana', 'Svetlana'), ('Sicular', 'Sicular'), (',', ','), ('Kenneth', 'Kenneth'), ('Brant', 'Brant'), ('2018', '2018'), (',', ','), ('Hype', 'Hype'), ('Cycle', 'Cycle'), ('ArtificialIntelligence', 'ArtificialIntelligence'), (',', ','), ('2018', '2018'), ('Gartner', 'Gartner'), ('report', 'report'), ('July', 'July'), ('2018', '2018'), ('.', '.')]



========================================== PARAGRAPH 289 ===========================================

9. McCallum, Andrew Kachites.  "MALLET: A Machine  Learning for Language Toolkit." http://mallet.cs.umass.edu.  2002.  

------------------- Sentence 1 -------------------

9.

>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]


------------------- Sentence 2 -------------------

McCallum, Andrew Kachites.

>> Tokens are: 
 ['McCallum', ',', 'Andrew', 'Kachites', '.']

>> Bigrams are: 
 [('McCallum', ','), (',', 'Andrew'), ('Andrew', 'Kachites'), ('Kachites', '.')]

>> Trigrams are: 
 [('McCallum', ',', 'Andrew'), (',', 'Andrew', 'Kachites'), ('Andrew', 'Kachites', '.')]

>> POS Tags are: 
 [('McCallum', 'NNP'), (',', ','), ('Andrew', 'NNP'), ('Kachites', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['McCallum', 'Andrew Kachites']

>> Named Entities are: 
 [('GPE', 'McCallum'), ('PERSON', 'Andrew Kachites')] 

>> Stemming using Porter Stemmer: 
 [('McCallum', 'mccallum'), (',', ','), ('Andrew', 'andrew'), ('Kachites', 'kachit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('McCallum', 'mccallum'), (',', ','), ('Andrew', 'andrew'), ('Kachites', 'kachit'), ('.', '.')]

>> Lemmatization: 
 [('McCallum', 'McCallum'), (',', ','), ('Andrew', 'Andrew'), ('Kachites', 'Kachites'), ('.', '.')]


------------------- Sentence 3 -------------------

"MALLET: A Machine  Learning for Language Toolkit."

>> Tokens are: 
 ['``', 'MALLET', ':', 'A', 'Machine', 'Learning', 'Language', 'Toolkit', '.', "''"]

>> Bigrams are: 
 [('``', 'MALLET'), ('MALLET', ':'), (':', 'A'), ('A', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Language'), ('Language', 'Toolkit'), ('Toolkit', '.'), ('.', "''")]

>> Trigrams are: 
 [('``', 'MALLET', ':'), ('MALLET', ':', 'A'), (':', 'A', 'Machine'), ('A', 'Machine', 'Learning'), ('Machine', 'Learning', 'Language'), ('Learning', 'Language', 'Toolkit'), ('Language', 'Toolkit', '.'), ('Toolkit', '.', "''")]

>> POS Tags are: 
 [('``', '``'), ('MALLET', 'NN'), (':', ':'), ('A', 'DT'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Language', 'NNP'), ('Toolkit', 'NNP'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 ['MALLET', 'A Machine Learning Language Toolkit']

>> Named Entities are: 
 [('ORGANIZATION', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('``', '``'), ('MALLET', 'mallet'), (':', ':'), ('A', 'a'), ('Machine', 'machin'), ('Learning', 'learn'), ('Language', 'languag'), ('Toolkit', 'toolkit'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('``', '``'), ('MALLET', 'mallet'), (':', ':'), ('A', 'a'), ('Machine', 'machin'), ('Learning', 'learn'), ('Language', 'languag'), ('Toolkit', 'toolkit'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('``', '``'), ('MALLET', 'MALLET'), (':', ':'), ('A', 'A'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Language', 'Language'), ('Toolkit', 'Toolkit'), ('.', '.'), ("''", "''")]


------------------- Sentence 4 -------------------

http://mallet.cs.umass.edu.

>> Tokens are: 
 ['http', ':', '//mallet.cs.umass.edu', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//mallet.cs.umass.edu'), ('//mallet.cs.umass.edu', '.')]

>> Trigrams are: 
 [('http', ':', '//mallet.cs.umass.edu'), (':', '//mallet.cs.umass.edu', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//mallet.cs.umass.edu', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//mallet.cs.umass.edu']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//mallet.cs.umass.edu', '//mallet.cs.umass.edu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//mallet.cs.umass.edu', '//mallet.cs.umass.edu'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//mallet.cs.umass.edu', '//mallet.cs.umass.edu'), ('.', '.')]


------------------- Sentence 5 -------------------

2002.

>> Tokens are: 
 ['2002', '.']

>> Bigrams are: 
 [('2002', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2002', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('2002', '2002'), ('.', '.')]



========================================== PARAGRAPH 290 ===========================================

10. Quarteroni, Silvia. (2018). Natural Language Processing for  Industry: ELCA’s experience. Informatik-Spektrum. 41.  10.1007/s00287-018-1094-1.  

------------------- Sentence 1 -------------------

10.

>> Tokens are: 
 ['10', '.']

>> Bigrams are: 
 [('10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

Quarteroni, Silvia.

>> Tokens are: 
 ['Quarteroni', ',', 'Silvia', '.']

>> Bigrams are: 
 [('Quarteroni', ','), (',', 'Silvia'), ('Silvia', '.')]

>> Trigrams are: 
 [('Quarteroni', ',', 'Silvia'), (',', 'Silvia', '.')]

>> POS Tags are: 
 [('Quarteroni', 'NNP'), (',', ','), ('Silvia', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Quarteroni', 'Silvia']

>> Named Entities are: 
 [('GPE', 'Quarteroni'), ('GPE', 'Silvia')] 

>> Stemming using Porter Stemmer: 
 [('Quarteroni', 'quarteroni'), (',', ','), ('Silvia', 'silvia'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Quarteroni', 'quarteroni'), (',', ','), ('Silvia', 'silvia'), ('.', '.')]

>> Lemmatization: 
 [('Quarteroni', 'Quarteroni'), (',', ','), ('Silvia', 'Silvia'), ('.', '.')]


------------------- Sentence 3 -------------------

(2018).

>> Tokens are: 
 ['(', '2018', ')', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Natural Language Processing for  Industry: ELCA’s experience.

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'Industry', ':', 'ELCA', '’', 'experience', '.']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Industry'), ('Industry', ':'), (':', 'ELCA'), ('ELCA', '’'), ('’', 'experience'), ('experience', '.')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Industry'), ('Processing', 'Industry', ':'), ('Industry', ':', 'ELCA'), (':', 'ELCA', '’'), ('ELCA', '’', 'experience'), ('’', 'experience', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Industry', 'NN'), (':', ':'), ('ELCA', 'NNP'), ('’', 'NNP'), ('experience', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural Language Processing Industry', 'ELCA ’ experience']

>> Named Entities are: 
 [('ORGANIZATION', 'ELCA')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Industry', 'industri'), (':', ':'), ('ELCA', 'elca'), ('’', '’'), ('experience', 'experi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Industry', 'industri'), (':', ':'), ('ELCA', 'elca'), ('’', '’'), ('experience', 'experi'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Industry', 'Industry'), (':', ':'), ('ELCA', 'ELCA'), ('’', '’'), ('experience', 'experience'), ('.', '.')]


------------------- Sentence 5 -------------------

Informatik-Spektrum.

>> Tokens are: 
 ['Informatik-Spektrum', '.']

>> Bigrams are: 
 [('Informatik-Spektrum', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Informatik-Spektrum', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Informatik-Spektrum']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Informatik-Spektrum', 'informatik-spektrum'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Informatik-Spektrum', 'informatik-spektrum'), ('.', '.')]

>> Lemmatization: 
 [('Informatik-Spektrum', 'Informatik-Spektrum'), ('.', '.')]


------------------- Sentence 6 -------------------

41.

>> Tokens are: 
 ['41', '.']

>> Bigrams are: 
 [('41', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41', '41'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41', '41'), ('.', '.')]

>> Lemmatization: 
 [('41', '41'), ('.', '.')]


------------------- Sentence 7 -------------------

10.1007/s00287-018-1094-1.

>> Tokens are: 
 ['10.1007/s00287-018-1094-1', '.']

>> Bigrams are: 
 [('10.1007/s00287-018-1094-1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.1007/s00287-018-1094-1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.1007/s00287-018-1094-1', '10.1007/s00287-018-1094-1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.1007/s00287-018-1094-1', '10.1007/s00287-018-1094-1'), ('.', '.')]

>> Lemmatization: 
 [('10.1007/s00287-018-1094-1', '10.1007/s00287-018-1094-1'), ('.', '.')]



========================================== PARAGRAPH 291 ===========================================

11. Young, Tom &Hazarika, Devamanyu&Poria, Soujanya&  Cambria, Erik. (2018). Recent Trends in Deep Learning  Based Natural Language Processing [Review Article]. IEEE  

------------------- Sentence 1 -------------------

11.

>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]


------------------- Sentence 2 -------------------

Young, Tom &Hazarika, Devamanyu&Poria, Soujanya&  Cambria, Erik.

>> Tokens are: 
 ['Young', ',', 'Tom', '&', 'Hazarika', ',', 'Devamanyu', '&', 'Poria', ',', 'Soujanya', '&', 'Cambria', ',', 'Erik', '.']

>> Bigrams are: 
 [('Young', ','), (',', 'Tom'), ('Tom', '&'), ('&', 'Hazarika'), ('Hazarika', ','), (',', 'Devamanyu'), ('Devamanyu', '&'), ('&', 'Poria'), ('Poria', ','), (',', 'Soujanya'), ('Soujanya', '&'), ('&', 'Cambria'), ('Cambria', ','), (',', 'Erik'), ('Erik', '.')]

>> Trigrams are: 
 [('Young', ',', 'Tom'), (',', 'Tom', '&'), ('Tom', '&', 'Hazarika'), ('&', 'Hazarika', ','), ('Hazarika', ',', 'Devamanyu'), (',', 'Devamanyu', '&'), ('Devamanyu', '&', 'Poria'), ('&', 'Poria', ','), ('Poria', ',', 'Soujanya'), (',', 'Soujanya', '&'), ('Soujanya', '&', 'Cambria'), ('&', 'Cambria', ','), ('Cambria', ',', 'Erik'), (',', 'Erik', '.')]

>> POS Tags are: 
 [('Young', 'NNP'), (',', ','), ('Tom', 'NNP'), ('&', 'CC'), ('Hazarika', 'NNP'), (',', ','), ('Devamanyu', 'NNP'), ('&', 'CC'), ('Poria', 'NNP'), (',', ','), ('Soujanya', 'NNP'), ('&', 'CC'), ('Cambria', 'NNP'), (',', ','), ('Erik', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Young', 'Tom', 'Hazarika', 'Devamanyu', 'Poria', 'Soujanya', 'Cambria', 'Erik']

>> Named Entities are: 
 [('GPE', 'Young'), ('PERSON', 'Tom'), ('PERSON', 'Hazarika'), ('PERSON', 'Devamanyu'), ('GPE', 'Poria'), ('GPE', 'Soujanya'), ('GPE', 'Cambria'), ('PERSON', 'Erik')] 

>> Stemming using Porter Stemmer: 
 [('Young', 'young'), (',', ','), ('Tom', 'tom'), ('&', '&'), ('Hazarika', 'hazarika'), (',', ','), ('Devamanyu', 'devamanyu'), ('&', '&'), ('Poria', 'poria'), (',', ','), ('Soujanya', 'soujanya'), ('&', '&'), ('Cambria', 'cambria'), (',', ','), ('Erik', 'erik'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Young', 'young'), (',', ','), ('Tom', 'tom'), ('&', '&'), ('Hazarika', 'hazarika'), (',', ','), ('Devamanyu', 'devamanyu'), ('&', '&'), ('Poria', 'poria'), (',', ','), ('Soujanya', 'soujanya'), ('&', '&'), ('Cambria', 'cambria'), (',', ','), ('Erik', 'erik'), ('.', '.')]

>> Lemmatization: 
 [('Young', 'Young'), (',', ','), ('Tom', 'Tom'), ('&', '&'), ('Hazarika', 'Hazarika'), (',', ','), ('Devamanyu', 'Devamanyu'), ('&', '&'), ('Poria', 'Poria'), (',', ','), ('Soujanya', 'Soujanya'), ('&', '&'), ('Cambria', 'Cambria'), (',', ','), ('Erik', 'Erik'), ('.', '.')]


------------------- Sentence 3 -------------------

(2018).

>> Tokens are: 
 ['(', '2018', ')', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Recent Trends in Deep Learning  Based Natural Language Processing [Review Article].

>> Tokens are: 
 ['Recent', 'Trends', 'Deep', 'Learning', 'Based', 'Natural', 'Language', 'Processing', '[', 'Review', 'Article', ']', '.']

>> Bigrams are: 
 [('Recent', 'Trends'), ('Trends', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Based'), ('Based', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '['), ('[', 'Review'), ('Review', 'Article'), ('Article', ']'), (']', '.')]

>> Trigrams are: 
 [('Recent', 'Trends', 'Deep'), ('Trends', 'Deep', 'Learning'), ('Deep', 'Learning', 'Based'), ('Learning', 'Based', 'Natural'), ('Based', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '['), ('Processing', '[', 'Review'), ('[', 'Review', 'Article'), ('Review', 'Article', ']'), ('Article', ']', '.')]

>> POS Tags are: 
 [('Recent', 'JJ'), ('Trends', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Based', 'VBD'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('[', 'NNP'), ('Review', 'NNP'), ('Article', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Recent Trends Deep Learning', 'Natural Language Processing [ Review Article ]']

>> Named Entities are: 
 [('PERSON', 'Trends Deep Learning'), ('ORGANIZATION', 'Natural Language'), ('PERSON', 'Article')] 

>> Stemming using Porter Stemmer: 
 [('Recent', 'recent'), ('Trends', 'trend'), ('Deep', 'deep'), ('Learning', 'learn'), ('Based', 'base'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('[', '['), ('Review', 'review'), ('Article', 'articl'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recent', 'recent'), ('Trends', 'trend'), ('Deep', 'deep'), ('Learning', 'learn'), ('Based', 'base'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('[', '['), ('Review', 'review'), ('Article', 'articl'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Recent', 'Recent'), ('Trends', 'Trends'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Based', 'Based'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('[', '['), ('Review', 'Review'), ('Article', 'Article'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

IEEE

>> Tokens are: 
 ['IEEE']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NN')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee')]

>> Lemmatization: 
 [('IEEE', 'IEEE')]



========================================== PARAGRAPH 292 ===========================================

Computational Intelligence Magazine. 13. 55-75.  

------------------- Sentence 1 -------------------

Computational Intelligence Magazine.

>> Tokens are: 
 ['Computational', 'Intelligence', 'Magazine', '.']

>> Bigrams are: 
 [('Computational', 'Intelligence'), ('Intelligence', 'Magazine'), ('Magazine', '.')]

>> Trigrams are: 
 [('Computational', 'Intelligence', 'Magazine'), ('Intelligence', 'Magazine', '.')]

>> POS Tags are: 
 [('Computational', 'NNP'), ('Intelligence', 'NNP'), ('Magazine', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Computational Intelligence Magazine']

>> Named Entities are: 
 [('ORGANIZATION', 'Computational'), ('ORGANIZATION', 'Intelligence Magazine')] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Intelligence', 'intellig'), ('Magazine', 'magazin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Intelligence', 'intellig'), ('Magazine', 'magazin'), ('.', '.')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Intelligence', 'Intelligence'), ('Magazine', 'Magazine'), ('.', '.')]


------------------- Sentence 2 -------------------

13.

>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]


------------------- Sentence 3 -------------------

55-75.

>> Tokens are: 
 ['55-75', '.']

>> Bigrams are: 
 [('55-75', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('55-75', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('55-75', '55-75'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('55-75', '55-75'), ('.', '.')]

>> Lemmatization: 
 [('55-75', '55-75'), ('.', '.')]



========================================== PARAGRAPH 293 ===========================================

10.1109/MCI.2018.2840738.   12. Amirhosseini, Mohammad Hossein, Kazemian, Hassan,  

------------------- Sentence 1 -------------------

10.1109/MCI.2018.2840738.

>> Tokens are: 
 ['10.1109/MCI.2018.2840738', '.']

>> Bigrams are: 
 [('10.1109/MCI.2018.2840738', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.1109/MCI.2018.2840738', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.1109/MCI.2018.2840738', '10.1109/mci.2018.2840738'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.1109/MCI.2018.2840738', '10.1109/mci.2018.2840738'), ('.', '.')]

>> Lemmatization: 
 [('10.1109/MCI.2018.2840738', '10.1109/MCI.2018.2840738'), ('.', '.')]


------------------- Sentence 2 -------------------

12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]


------------------- Sentence 3 -------------------

Amirhosseini, Mohammad Hossein, Kazemian, Hassan,

>> Tokens are: 
 ['Amirhosseini', ',', 'Mohammad', 'Hossein', ',', 'Kazemian', ',', 'Hassan', ',']

>> Bigrams are: 
 [('Amirhosseini', ','), (',', 'Mohammad'), ('Mohammad', 'Hossein'), ('Hossein', ','), (',', 'Kazemian'), ('Kazemian', ','), (',', 'Hassan'), ('Hassan', ',')]

>> Trigrams are: 
 [('Amirhosseini', ',', 'Mohammad'), (',', 'Mohammad', 'Hossein'), ('Mohammad', 'Hossein', ','), ('Hossein', ',', 'Kazemian'), (',', 'Kazemian', ','), ('Kazemian', ',', 'Hassan'), (',', 'Hassan', ',')]

>> POS Tags are: 
 [('Amirhosseini', 'NNP'), (',', ','), ('Mohammad', 'NNP'), ('Hossein', 'NNP'), (',', ','), ('Kazemian', 'NNP'), (',', ','), ('Hassan', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Amirhosseini', 'Mohammad Hossein', 'Kazemian', 'Hassan']

>> Named Entities are: 
 [('GPE', 'Amirhosseini'), ('PERSON', 'Mohammad Hossein'), ('GPE', 'Kazemian'), ('GPE', 'Hassan')] 

>> Stemming using Porter Stemmer: 
 [('Amirhosseini', 'amirhosseini'), (',', ','), ('Mohammad', 'mohammad'), ('Hossein', 'hossein'), (',', ','), ('Kazemian', 'kazemian'), (',', ','), ('Hassan', 'hassan'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Amirhosseini', 'amirhosseini'), (',', ','), ('Mohammad', 'mohammad'), ('Hossein', 'hossein'), (',', ','), ('Kazemian', 'kazemian'), (',', ','), ('Hassan', 'hassan'), (',', ',')]

>> Lemmatization: 
 [('Amirhosseini', 'Amirhosseini'), (',', ','), ('Mohammad', 'Mohammad'), ('Hossein', 'Hossein'), (',', ','), ('Kazemian', 'Kazemian'), (',', ','), ('Hassan', 'Hassan'), (',', ',')]



========================================== PARAGRAPH 294 ===========================================

Ouazzane, Karim and Chandler, Chris (2018) Natural  

------------------- Sentence 1 -------------------

Ouazzane, Karim and Chandler, Chris (2018) Natural

>> Tokens are: 
 ['Ouazzane', ',', 'Karim', 'Chandler', ',', 'Chris', '(', '2018', ')', 'Natural']

>> Bigrams are: 
 [('Ouazzane', ','), (',', 'Karim'), ('Karim', 'Chandler'), ('Chandler', ','), (',', 'Chris'), ('Chris', '('), ('(', '2018'), ('2018', ')'), (')', 'Natural')]

>> Trigrams are: 
 [('Ouazzane', ',', 'Karim'), (',', 'Karim', 'Chandler'), ('Karim', 'Chandler', ','), ('Chandler', ',', 'Chris'), (',', 'Chris', '('), ('Chris', '(', '2018'), ('(', '2018', ')'), ('2018', ')', 'Natural')]

>> POS Tags are: 
 [('Ouazzane', 'NNP'), (',', ','), ('Karim', 'NNP'), ('Chandler', 'NNP'), (',', ','), ('Chris', 'NNP'), ('(', '('), ('2018', 'CD'), (')', ')'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['Ouazzane', 'Karim Chandler', 'Chris', 'Natural']

>> Named Entities are: 
 [('GPE', 'Ouazzane'), ('PERSON', 'Karim Chandler'), ('GPE', 'Chris')] 

>> Stemming using Porter Stemmer: 
 [('Ouazzane', 'ouazzan'), (',', ','), ('Karim', 'karim'), ('Chandler', 'chandler'), (',', ','), ('Chris', 'chri'), ('(', '('), ('2018', '2018'), (')', ')'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('Ouazzane', 'ouazzan'), (',', ','), ('Karim', 'karim'), ('Chandler', 'chandler'), (',', ','), ('Chris', 'chris'), ('(', '('), ('2018', '2018'), (')', ')'), ('Natural', 'natur')]

>> Lemmatization: 
 [('Ouazzane', 'Ouazzane'), (',', ','), ('Karim', 'Karim'), ('Chandler', 'Chandler'), (',', ','), ('Chris', 'Chris'), ('(', '('), ('2018', '2018'), (')', ')'), ('Natural', 'Natural')]



========================================== PARAGRAPH 295 ===========================================

language processing approach to NLP meta model  automation. In: International Joint Conference on Neural  

------------------- Sentence 1 -------------------

language processing approach to NLP meta model  automation.

>> Tokens are: 
 ['language', 'processing', 'approach', 'NLP', 'meta', 'model', 'automation', '.']

>> Bigrams are: 
 [('language', 'processing'), ('processing', 'approach'), ('approach', 'NLP'), ('NLP', 'meta'), ('meta', 'model'), ('model', 'automation'), ('automation', '.')]

>> Trigrams are: 
 [('language', 'processing', 'approach'), ('processing', 'approach', 'NLP'), ('approach', 'NLP', 'meta'), ('NLP', 'meta', 'model'), ('meta', 'model', 'automation'), ('model', 'automation', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('processing', 'NN'), ('approach', 'NN'), ('NLP', 'NNP'), ('meta', 'NN'), ('model', 'NN'), ('automation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language processing approach NLP meta model automation']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('approach', 'approach'), ('NLP', 'nlp'), ('meta', 'meta'), ('model', 'model'), ('automation', 'autom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('approach', 'approach'), ('NLP', 'nlp'), ('meta', 'meta'), ('model', 'model'), ('automation', 'autom'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('processing', 'processing'), ('approach', 'approach'), ('NLP', 'NLP'), ('meta', 'meta'), ('model', 'model'), ('automation', 'automation'), ('.', '.')]


------------------- Sentence 2 -------------------

In: International Joint Conference on Neural

>> Tokens are: 
 ['In', ':', 'International', 'Joint', 'Conference', 'Neural']

>> Bigrams are: 
 [('In', ':'), (':', 'International'), ('International', 'Joint'), ('Joint', 'Conference'), ('Conference', 'Neural')]

>> Trigrams are: 
 [('In', ':', 'International'), (':', 'International', 'Joint'), ('International', 'Joint', 'Conference'), ('Joint', 'Conference', 'Neural')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('International', 'NNP'), ('Joint', 'NNP'), ('Conference', 'NNP'), ('Neural', 'NNP')]

>> Noun Phrases are: 
 ['International Joint Conference Neural']

>> Named Entities are: 
 [('ORGANIZATION', 'International Joint Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('International', 'intern'), ('Joint', 'joint'), ('Conference', 'confer'), ('Neural', 'neural')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('International', 'intern'), ('Joint', 'joint'), ('Conference', 'confer'), ('Neural', 'neural')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('International', 'International'), ('Joint', 'Joint'), ('Conference', 'Conference'), ('Neural', 'Neural')]



========================================== PARAGRAPH 296 ===========================================

Networks (IJCNN), 8-13 July 2018, Rio de Janeiro, Brazil.  

------------------- Sentence 1 -------------------

Networks (IJCNN), 8-13 July 2018, Rio de Janeiro, Brazil.

>> Tokens are: 
 ['Networks', '(', 'IJCNN', ')', ',', '8-13', 'July', '2018', ',', 'Rio', 'de', 'Janeiro', ',', 'Brazil', '.']

>> Bigrams are: 
 [('Networks', '('), ('(', 'IJCNN'), ('IJCNN', ')'), (')', ','), (',', '8-13'), ('8-13', 'July'), ('July', '2018'), ('2018', ','), (',', 'Rio'), ('Rio', 'de'), ('de', 'Janeiro'), ('Janeiro', ','), (',', 'Brazil'), ('Brazil', '.')]

>> Trigrams are: 
 [('Networks', '(', 'IJCNN'), ('(', 'IJCNN', ')'), ('IJCNN', ')', ','), (')', ',', '8-13'), (',', '8-13', 'July'), ('8-13', 'July', '2018'), ('July', '2018', ','), ('2018', ',', 'Rio'), (',', 'Rio', 'de'), ('Rio', 'de', 'Janeiro'), ('de', 'Janeiro', ','), ('Janeiro', ',', 'Brazil'), (',', 'Brazil', '.')]

>> POS Tags are: 
 [('Networks', 'NNS'), ('(', '('), ('IJCNN', 'NNP'), (')', ')'), (',', ','), ('8-13', 'JJ'), ('July', 'NNP'), ('2018', 'CD'), (',', ','), ('Rio', 'NNP'), ('de', 'IN'), ('Janeiro', 'NNP'), (',', ','), ('Brazil', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Networks', 'IJCNN', '8-13 July', 'Rio', 'Janeiro', 'Brazil']

>> Named Entities are: 
 [('GPE', 'Networks'), ('ORGANIZATION', 'IJCNN'), ('PERSON', 'Rio'), ('PERSON', 'Janeiro'), ('GPE', 'Brazil')] 

>> Stemming using Porter Stemmer: 
 [('Networks', 'network'), ('(', '('), ('IJCNN', 'ijcnn'), (')', ')'), (',', ','), ('8-13', '8-13'), ('July', 'juli'), ('2018', '2018'), (',', ','), ('Rio', 'rio'), ('de', 'de'), ('Janeiro', 'janeiro'), (',', ','), ('Brazil', 'brazil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Networks', 'network'), ('(', '('), ('IJCNN', 'ijcnn'), (')', ')'), (',', ','), ('8-13', '8-13'), ('July', 'juli'), ('2018', '2018'), (',', ','), ('Rio', 'rio'), ('de', 'de'), ('Janeiro', 'janeiro'), (',', ','), ('Brazil', 'brazil'), ('.', '.')]

>> Lemmatization: 
 [('Networks', 'Networks'), ('(', '('), ('IJCNN', 'IJCNN'), (')', ')'), (',', ','), ('8-13', '8-13'), ('July', 'July'), ('2018', '2018'), (',', ','), ('Rio', 'Rio'), ('de', 'de'), ('Janeiro', 'Janeiro'), (',', ','), ('Brazil', 'Brazil'), ('.', '.')]



========================================== PARAGRAPH 297 ===========================================

 
