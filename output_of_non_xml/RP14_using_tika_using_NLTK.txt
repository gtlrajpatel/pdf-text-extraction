				 *** Text Processing using NLTK *** 


============================ Sentence 1 =============================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY   DOI: 10.21917/ijsc.2015.0133  946   SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY   Iqbal Muhammad 1  and Zhu Yan  2  School of Information Sciences and Technology, Southwest Jiaotong University, China   E-mail:  1 muhammadiqbal72@yahoo.com,   2 yzhu@swjtu.edu.cn   Abstract   One of the core objectives of machine learning is to instruct   computers to use data or past experience to solve a given problem. 


>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY', 'DOI', ':', '10.21917/ijsc.2015.0133', '946', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY', 'Iqbal', 'Muhammad', '1', 'Zhu', 'Yan', '2', 'School', 'Information', 'Sciences', 'Technology', ',', 'Southwest', 'Jiaotong', 'University', ',', 'China', 'E-mail', ':', '1', 'muhammadiqbal72', '@', 'yahoo.com', ',', '2', 'yzhu', '@', 'swjtu.edu.cn', 'Abstract', 'One', 'core', 'objectives', 'machine', 'learning', 'instruct', 'computers', 'use', 'data', 'past', 'experience', 'solve', 'given', 'problem', '.']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY'), ('SURVEY', 'DOI'), ('DOI', ':'), (':', '10.21917/ijsc.2015.0133'), ('10.21917/ijsc.2015.0133', '946'), ('946', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY'), ('SURVEY', 'Iqbal'), ('Iqbal', 'Muhammad'), ('Muhammad', '1'), ('1', 'Zhu'), ('Zhu', 'Yan'), ('Yan', '2'), ('2', 'School'), ('School', 'Information'), ('Information', 'Sciences'), ('Sciences', 'Technology'), ('Technology', ','), (',', 'Southwest'), ('Southwest', 'Jiaotong'), ('Jiaotong', 'University'), ('University', ','), (',', 'China'), ('China', 'E-mail'), ('E-mail', ':'), (':', '1'), ('1', 'muhammadiqbal72'), ('muhammadiqbal72', '@'), ('@', 'yahoo.com'), ('yahoo.com', ','), (',', '2'), ('2', 'yzhu'), ('yzhu', '@'), ('@', 'swjtu.edu.cn'), ('swjtu.edu.cn', 'Abstract'), ('Abstract', 'One'), ('One', 'core'), ('core', 'objectives'), ('objectives', 'machine'), ('machine', 'learning'), ('learning', 'instruct'), ('instruct', 'computers'), ('computers', 'use'), ('use', 'data'), ('data', 'past'), ('past', 'experience'), ('experience', 'solve'), ('solve', 'given'), ('given', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY'), ('A', 'SURVEY', 'DOI'), ('SURVEY', 'DOI', ':'), ('DOI', ':', '10.21917/ijsc.2015.0133'), (':', '10.21917/ijsc.2015.0133', '946'), ('10.21917/ijsc.2015.0133', '946', 'SUPERVISED'), ('946', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY'), ('A', 'SURVEY', 'Iqbal'), ('SURVEY', 'Iqbal', 'Muhammad'), ('Iqbal', 'Muhammad', '1'), ('Muhammad', '1', 'Zhu'), ('1', 'Zhu', 'Yan'), ('Zhu', 'Yan', '2'), ('Yan', '2', 'School'), ('2', 'School', 'Information'), ('School', 'Information', 'Sciences'), ('Information', 'Sciences', 'Technology'), ('Sciences', 'Technology', ','), ('Technology', ',', 'Southwest'), (',', 'Southwest', 'Jiaotong'), ('Southwest', 'Jiaotong', 'University'), ('Jiaotong', 'University', ','), ('University', ',', 'China'), (',', 'China', 'E-mail'), ('China', 'E-mail', ':'), ('E-mail', ':', '1'), (':', '1', 'muhammadiqbal72'), ('1', 'muhammadiqbal72', '@'), ('muhammadiqbal72', '@', 'yahoo.com'), ('@', 'yahoo.com', ','), ('yahoo.com', ',', '2'), (',', '2', 'yzhu'), ('2', 'yzhu', '@'), ('yzhu', '@', 'swjtu.edu.cn'), ('@', 'swjtu.edu.cn', 'Abstract'), ('swjtu.edu.cn', 'Abstract', 'One'), ('Abstract', 'One', 'core'), ('One', 'core', 'objectives'), ('core', 'objectives', 'machine'), ('objectives', 'machine', 'learning'), ('machine', 'learning', 'instruct'), ('learning', 'instruct', 'computers'), ('instruct', 'computers', 'use'), ('computers', 'use', 'data'), ('use', 'data', 'past'), ('data', 'past', 'experience'), ('past', 'experience', 'solve'), ('experience', 'solve', 'given'), ('solve', 'given', 'problem'), ('given', 'problem', '.')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NNP'), ('DOI', 'NNP'), (':', ':'), ('10.21917/ijsc.2015.0133', 'CD'), ('946', 'CD'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NNP'), ('Iqbal', 'NNP'), ('Muhammad', 'NNP'), ('1', 'CD'), ('Zhu', 'NNP'), ('Yan', 'NNP'), ('2', 'CD'), ('School', 'NNP'), ('Information', 'NNP'), ('Sciences', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Southwest', 'NNP'), ('Jiaotong', 'NNP'), ('University', 'NNP'), (',', ','), ('China', 'NNP'), ('E-mail', 'NNP'), (':', ':'), ('1', 'CD'), ('muhammadiqbal72', 'NN'), ('@', 'NNP'), ('yahoo.com', 'NN'), (',', ','), ('2', 'CD'), ('yzhu', 'NN'), ('@', 'NNP'), ('swjtu.edu.cn', 'NN'), ('Abstract', 'NNP'), ('One', 'CD'), ('core', 'NN'), ('objectives', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('instruct', 'NN'), ('computers', 'NNS'), ('use', 'VBP'), ('data', 'NNS'), ('past', 'JJ'), ('experience', 'NN'), ('solve', 'NN'), ('given', 'VBN'), ('problem', 'NN'), ('.', '.')]

 (S
  (NP IQBAL/NNP MUHAMMAD/NNP AND/NNP ZHU/NNP YAN/NNP)
  :/:
  (NP SUPERVISED/NNP MACHINE/NNP LEARNING/NNP APPROACHES/NNP)
  :/:
  (NP A/DT SURVEY/NNP DOI/NNP)
  :/:
  10.21917/ijsc.2015.0133/CD
  946/CD
  (NP SUPERVISED/NNP MACHINE/NNP LEARNING/NNP APPROACHES/NNP)
  :/:
  (NP A/DT SURVEY/NNP Iqbal/NNP Muhammad/NNP)
  1/CD
  (NP Zhu/NNP Yan/NNP)
  2/CD
  (NP School/NNP Information/NNP Sciences/NNP Technology/NNP)
  ,/,
  (NP Southwest/NNP Jiaotong/NNP University/NNP)
  ,/,
  (NP China/NNP E-mail/NNP)
  :/:
  1/CD
  (NP muhammadiqbal72/NN @/NNP yahoo.com/NN)
  ,/,
  2/CD
  (NP yzhu/NN @/NNP swjtu.edu.cn/NN Abstract/NNP)
  One/CD
  (NP core/NN objectives/NNS machine/NN)
  learning/VBG
  (NP instruct/NN computers/NNS)
  use/VBP
  (NP data/NNS)
  (NP past/JJ experience/NN solve/NN)
  given/VBN
  (NP problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY DOI', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY Iqbal Muhammad', 'Zhu Yan', 'School Information Sciences Technology', 'Southwest Jiaotong University', 'China E-mail', 'muhammadiqbal72 @ yahoo.com', 'yzhu @ swjtu.edu.cn Abstract', 'core objectives machine', 'instruct computers', 'data', 'past experience solve', 'problem']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE'), ('ORGANIZATION', 'SURVEY'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE'), ('ORGANIZATION', 'SURVEY Iqbal'), ('PERSON', 'Zhu Yan'), ('PERSON', 'School Information Sciences Technology'), ('PERSON', 'Southwest Jiaotong University'), ('GPE', 'China')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('DOI', 'doi'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133'), ('946', '946'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('Iqbal', 'iqbal'), ('Muhammad', 'muhammad'), ('1', '1'), ('Zhu', 'zhu'), ('Yan', 'yan'), ('2', '2'), ('School', 'school'), ('Information', 'inform'), ('Sciences', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Southwest', 'southwest'), ('Jiaotong', 'jiaotong'), ('University', 'univers'), (',', ','), ('China', 'china'), ('E-mail', 'e-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ','), ('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn'), ('Abstract', 'abstract'), ('One', 'one'), ('core', 'core'), ('objectives', 'object'), ('machine', 'machin'), ('learning', 'learn'), ('instruct', 'instruct'), ('computers', 'comput'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experi'), ('solve', 'solv'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('DOI', 'doi'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133'), ('946', '946'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('Iqbal', 'iqbal'), ('Muhammad', 'muhammad'), ('1', '1'), ('Zhu', 'zhu'), ('Yan', 'yan'), ('2', '2'), ('School', 'school'), ('Information', 'inform'), ('Sciences', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Southwest', 'southwest'), ('Jiaotong', 'jiaotong'), ('University', 'univers'), (',', ','), ('China', 'china'), ('E-mail', 'e-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ','), ('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn'), ('Abstract', 'abstract'), ('One', 'one'), ('core', 'core'), ('objectives', 'object'), ('machine', 'machin'), ('learning', 'learn'), ('instruct', 'instruct'), ('computers', 'comput'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experi'), ('solve', 'solv'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY'), ('DOI', 'DOI'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133'), ('946', '946'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY'), ('Iqbal', 'Iqbal'), ('Muhammad', 'Muhammad'), ('1', '1'), ('Zhu', 'Zhu'), ('Yan', 'Yan'), ('2', '2'), ('School', 'School'), ('Information', 'Information'), ('Sciences', 'Sciences'), ('Technology', 'Technology'), (',', ','), ('Southwest', 'Southwest'), ('Jiaotong', 'Jiaotong'), ('University', 'University'), (',', ','), ('China', 'China'), ('E-mail', 'E-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ','), ('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn'), ('Abstract', 'Abstract'), ('One', 'One'), ('core', 'core'), ('objectives', 'objective'), ('machine', 'machine'), ('learning', 'learning'), ('instruct', 'instruct'), ('computers', 'computer'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experience'), ('solve', 'solve'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 2 =============================

A   good number of successful applications of machine learning exist   already, including classifier to be trained on email messages to learn   in order to distinguish between spam and non-spam messages,   systems that analyze past sales data to predict customer buying   behavior, fraud detection etc. 


>> Tokens are: 
 ['A', 'good', 'number', 'successful', 'applications', 'machine', 'learning', 'exist', 'already', ',', 'including', 'classifier', 'trained', 'email', 'messages', 'learn', 'order', 'distinguish', 'spam', 'non-spam', 'messages', ',', 'systems', 'analyze', 'past', 'sales', 'data', 'predict', 'customer', 'buying', 'behavior', ',', 'fraud', 'detection', 'etc', '.']

>> Bigrams are: 
 [('A', 'good'), ('good', 'number'), ('number', 'successful'), ('successful', 'applications'), ('applications', 'machine'), ('machine', 'learning'), ('learning', 'exist'), ('exist', 'already'), ('already', ','), (',', 'including'), ('including', 'classifier'), ('classifier', 'trained'), ('trained', 'email'), ('email', 'messages'), ('messages', 'learn'), ('learn', 'order'), ('order', 'distinguish'), ('distinguish', 'spam'), ('spam', 'non-spam'), ('non-spam', 'messages'), ('messages', ','), (',', 'systems'), ('systems', 'analyze'), ('analyze', 'past'), ('past', 'sales'), ('sales', 'data'), ('data', 'predict'), ('predict', 'customer'), ('customer', 'buying'), ('buying', 'behavior'), ('behavior', ','), (',', 'fraud'), ('fraud', 'detection'), ('detection', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('A', 'good', 'number'), ('good', 'number', 'successful'), ('number', 'successful', 'applications'), ('successful', 'applications', 'machine'), ('applications', 'machine', 'learning'), ('machine', 'learning', 'exist'), ('learning', 'exist', 'already'), ('exist', 'already', ','), ('already', ',', 'including'), (',', 'including', 'classifier'), ('including', 'classifier', 'trained'), ('classifier', 'trained', 'email'), ('trained', 'email', 'messages'), ('email', 'messages', 'learn'), ('messages', 'learn', 'order'), ('learn', 'order', 'distinguish'), ('order', 'distinguish', 'spam'), ('distinguish', 'spam', 'non-spam'), ('spam', 'non-spam', 'messages'), ('non-spam', 'messages', ','), ('messages', ',', 'systems'), (',', 'systems', 'analyze'), ('systems', 'analyze', 'past'), ('analyze', 'past', 'sales'), ('past', 'sales', 'data'), ('sales', 'data', 'predict'), ('data', 'predict', 'customer'), ('predict', 'customer', 'buying'), ('customer', 'buying', 'behavior'), ('buying', 'behavior', ','), ('behavior', ',', 'fraud'), (',', 'fraud', 'detection'), ('fraud', 'detection', 'etc'), ('detection', 'etc', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('good', 'JJ'), ('number', 'NN'), ('successful', 'JJ'), ('applications', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('exist', 'JJ'), ('already', 'RB'), (',', ','), ('including', 'VBG'), ('classifier', 'NN'), ('trained', 'VBD'), ('email', 'JJ'), ('messages', 'NNS'), ('learn', 'VBP'), ('order', 'NN'), ('distinguish', 'JJ'), ('spam', 'NN'), ('non-spam', 'JJ'), ('messages', 'NNS'), (',', ','), ('systems', 'NNS'), ('analyze', 'VBP'), ('past', 'JJ'), ('sales', 'NNS'), ('data', 'NNS'), ('predict', 'VBP'), ('customer', 'NN'), ('buying', 'NN'), ('behavior', 'NN'), (',', ','), ('fraud', 'NN'), ('detection', 'NN'), ('etc', 'NN'), ('.', '.')]

 (S
  (NP A/DT good/JJ number/NN)
  (NP successful/JJ applications/NNS machine/NN)
  learning/VBG
  exist/JJ
  already/RB
  ,/,
  including/VBG
  (NP classifier/NN)
  trained/VBD
  (NP email/JJ messages/NNS)
  learn/VBP
  (NP order/NN)
  (NP distinguish/JJ spam/NN)
  (NP non-spam/JJ messages/NNS)
  ,/,
  (NP systems/NNS)
  analyze/VBP
  (NP past/JJ sales/NNS data/NNS)
  predict/VBP
  (NP customer/NN buying/NN behavior/NN)
  ,/,
  (NP fraud/NN detection/NN etc/NN)
  ./.) 


>> Noun Phrases are: 
 ['A good number', 'successful applications machine', 'classifier', 'email messages', 'order', 'distinguish spam', 'non-spam messages', 'systems', 'past sales data', 'customer buying behavior', 'fraud detection etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('successful', 'success'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('exist', 'exist'), ('already', 'alreadi'), (',', ','), ('including', 'includ'), ('classifier', 'classifi'), ('trained', 'train'), ('email', 'email'), ('messages', 'messag'), ('learn', 'learn'), ('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'messag'), (',', ','), ('systems', 'system'), ('analyze', 'analyz'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'custom'), ('buying', 'buy'), ('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detect'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('successful', 'success'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('exist', 'exist'), ('already', 'alreadi'), (',', ','), ('including', 'includ'), ('classifier', 'classifi'), ('trained', 'train'), ('email', 'email'), ('messages', 'messag'), ('learn', 'learn'), ('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'messag'), (',', ','), ('systems', 'system'), ('analyze', 'analyz'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'custom'), ('buying', 'buy'), ('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detect'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('good', 'good'), ('number', 'number'), ('successful', 'successful'), ('applications', 'application'), ('machine', 'machine'), ('learning', 'learning'), ('exist', 'exist'), ('already', 'already'), (',', ','), ('including', 'including'), ('classifier', 'classifier'), ('trained', 'trained'), ('email', 'email'), ('messages', 'message'), ('learn', 'learn'), ('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'message'), (',', ','), ('systems', 'system'), ('analyze', 'analyze'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'customer'), ('buying', 'buying'), ('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detection'), ('etc', 'etc'), ('.', '.')]



============================ Sentence 3 =============================

Machine learning can be applied as   association analysis through Supervised learning, Unsupervised   learning and Reinforcement Learning but in this study we will focus   on strength and weakness of supervised learning classification   algorithms. 


>> Tokens are: 
 ['Machine', 'learning', 'applied', 'association', 'analysis', 'Supervised', 'learning', ',', 'Unsupervised', 'learning', 'Reinforcement', 'Learning', 'study', 'focus', 'strength', 'weakness', 'supervised', 'learning', 'classification', 'algorithms', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'applied'), ('applied', 'association'), ('association', 'analysis'), ('analysis', 'Supervised'), ('Supervised', 'learning'), ('learning', ','), (',', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', 'Reinforcement'), ('Reinforcement', 'Learning'), ('Learning', 'study'), ('study', 'focus'), ('focus', 'strength'), ('strength', 'weakness'), ('weakness', 'supervised'), ('supervised', 'learning'), ('learning', 'classification'), ('classification', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'applied'), ('learning', 'applied', 'association'), ('applied', 'association', 'analysis'), ('association', 'analysis', 'Supervised'), ('analysis', 'Supervised', 'learning'), ('Supervised', 'learning', ','), ('learning', ',', 'Unsupervised'), (',', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', 'Reinforcement'), ('learning', 'Reinforcement', 'Learning'), ('Reinforcement', 'Learning', 'study'), ('Learning', 'study', 'focus'), ('study', 'focus', 'strength'), ('focus', 'strength', 'weakness'), ('strength', 'weakness', 'supervised'), ('weakness', 'supervised', 'learning'), ('supervised', 'learning', 'classification'), ('learning', 'classification', 'algorithms'), ('classification', 'algorithms', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('applied', 'VBN'), ('association', 'NN'), ('analysis', 'NN'), ('Supervised', 'VBD'), ('learning', 'NN'), (',', ','), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('Reinforcement', 'NNP'), ('Learning', 'NNP'), ('study', 'NN'), ('focus', 'NN'), ('strength', 'NN'), ('weakness', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('classification', 'NN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  applied/VBN
  (NP association/NN analysis/NN)
  Supervised/VBD
  (NP learning/NN)
  ,/,
  Unsupervised/VBD
  learning/VBG
  (NP
    Reinforcement/NNP
    Learning/NNP
    study/NN
    focus/NN
    strength/NN
    weakness/NN)
  supervised/VBD
  learning/VBG
  (NP classification/NN algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'association analysis', 'learning', 'Reinforcement Learning study focus strength weakness', 'classification algorithms']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('applied', 'appli'), ('association', 'associ'), ('analysis', 'analysi'), ('Supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), ('study', 'studi'), ('focus', 'focu'), ('strength', 'strength'), ('weakness', 'weak'), ('supervised', 'supervis'), ('learning', 'learn'), ('classification', 'classif'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('applied', 'appli'), ('association', 'associ'), ('analysis', 'analysi'), ('Supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), ('study', 'studi'), ('focus', 'focus'), ('strength', 'strength'), ('weakness', 'weak'), ('supervised', 'supervis'), ('learning', 'learn'), ('classification', 'classif'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('applied', 'applied'), ('association', 'association'), ('analysis', 'analysis'), ('Supervised', 'Supervised'), ('learning', 'learning'), (',', ','), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('Reinforcement', 'Reinforcement'), ('Learning', 'Learning'), ('study', 'study'), ('focus', 'focus'), ('strength', 'strength'), ('weakness', 'weakness'), ('supervised', 'supervised'), ('learning', 'learning'), ('classification', 'classification'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 4 =============================

The goal of supervised learning is to build a concise   model of the distribution of class labels in terms of predictor features. 


>> Tokens are: 
 ['The', 'goal', 'supervised', 'learning', 'build', 'concise', 'model', 'distribution', 'class', 'labels', 'terms', 'predictor', 'features', '.']

>> Bigrams are: 
 [('The', 'goal'), ('goal', 'supervised'), ('supervised', 'learning'), ('learning', 'build'), ('build', 'concise'), ('concise', 'model'), ('model', 'distribution'), ('distribution', 'class'), ('class', 'labels'), ('labels', 'terms'), ('terms', 'predictor'), ('predictor', 'features'), ('features', '.')]

>> Trigrams are: 
 [('The', 'goal', 'supervised'), ('goal', 'supervised', 'learning'), ('supervised', 'learning', 'build'), ('learning', 'build', 'concise'), ('build', 'concise', 'model'), ('concise', 'model', 'distribution'), ('model', 'distribution', 'class'), ('distribution', 'class', 'labels'), ('class', 'labels', 'terms'), ('labels', 'terms', 'predictor'), ('terms', 'predictor', 'features'), ('predictor', 'features', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('goal', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('build', 'JJ'), ('concise', 'NN'), ('model', 'NN'), ('distribution', 'NN'), ('class', 'NN'), ('labels', 'NNS'), ('terms', 'NNS'), ('predictor', 'NN'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP The/DT goal/NN)
  supervised/VBD
  learning/VBG
  (NP
    build/JJ
    concise/NN
    model/NN
    distribution/NN
    class/NN
    labels/NNS
    terms/NNS
    predictor/NN
    features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The goal', 'build concise model distribution class labels terms predictor features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), ('build', 'build'), ('concise', 'concis'), ('model', 'model'), ('distribution', 'distribut'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), ('build', 'build'), ('concise', 'concis'), ('model', 'model'), ('distribution', 'distribut'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('goal', 'goal'), ('supervised', 'supervised'), ('learning', 'learning'), ('build', 'build'), ('concise', 'concise'), ('model', 'model'), ('distribution', 'distribution'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'feature'), ('.', '.')]



============================ Sentence 5 =============================

The resulting classifier is then used to assign class labels to the testing   instances where the values of the predictor features are known, but   the value of the class label is unknown. 


>> Tokens are: 
 ['The', 'resulting', 'classifier', 'used', 'assign', 'class', 'labels', 'testing', 'instances', 'values', 'predictor', 'features', 'known', ',', 'value', 'class', 'label', 'unknown', '.']

>> Bigrams are: 
 [('The', 'resulting'), ('resulting', 'classifier'), ('classifier', 'used'), ('used', 'assign'), ('assign', 'class'), ('class', 'labels'), ('labels', 'testing'), ('testing', 'instances'), ('instances', 'values'), ('values', 'predictor'), ('predictor', 'features'), ('features', 'known'), ('known', ','), (',', 'value'), ('value', 'class'), ('class', 'label'), ('label', 'unknown'), ('unknown', '.')]

>> Trigrams are: 
 [('The', 'resulting', 'classifier'), ('resulting', 'classifier', 'used'), ('classifier', 'used', 'assign'), ('used', 'assign', 'class'), ('assign', 'class', 'labels'), ('class', 'labels', 'testing'), ('labels', 'testing', 'instances'), ('testing', 'instances', 'values'), ('instances', 'values', 'predictor'), ('values', 'predictor', 'features'), ('predictor', 'features', 'known'), ('features', 'known', ','), ('known', ',', 'value'), (',', 'value', 'class'), ('value', 'class', 'label'), ('class', 'label', 'unknown'), ('label', 'unknown', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('resulting', 'VBG'), ('classifier', 'NN'), ('used', 'VBN'), ('assign', 'JJ'), ('class', 'NN'), ('labels', 'NNS'), ('testing', 'VBG'), ('instances', 'NNS'), ('values', 'NNS'), ('predictor', 'VBP'), ('features', 'NNS'), ('known', 'VBN'), (',', ','), ('value', 'NN'), ('class', 'NN'), ('label', 'NN'), ('unknown', 'NN'), ('.', '.')]

 (S
  The/DT
  resulting/VBG
  (NP classifier/NN)
  used/VBN
  (NP assign/JJ class/NN labels/NNS)
  testing/VBG
  (NP instances/NNS values/NNS)
  predictor/VBP
  (NP features/NNS)
  known/VBN
  ,/,
  (NP value/NN class/NN label/NN unknown/NN)
  ./.) 


>> Noun Phrases are: 
 ['classifier', 'assign class labels', 'instances values', 'features', 'value class label unknown']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('classifier', 'classifi'), ('used', 'use'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'test'), ('instances', 'instanc'), ('values', 'valu'), ('predictor', 'predictor'), ('features', 'featur'), ('known', 'known'), (',', ','), ('value', 'valu'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('classifier', 'classifi'), ('used', 'use'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'test'), ('instances', 'instanc'), ('values', 'valu'), ('predictor', 'predictor'), ('features', 'featur'), ('known', 'known'), (',', ','), ('value', 'valu'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('resulting', 'resulting'), ('classifier', 'classifier'), ('used', 'used'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'testing'), ('instances', 'instance'), ('values', 'value'), ('predictor', 'predictor'), ('features', 'feature'), ('known', 'known'), (',', ','), ('value', 'value'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]



============================ Sentence 6 =============================

We are optimistic that this   study will help new researchers to guiding new research areas and to   compare the effectiveness and impuissance of supervised learning   algorithms. 


>> Tokens are: 
 ['We', 'optimistic', 'study', 'help', 'new', 'researchers', 'guiding', 'new', 'research', 'areas', 'compare', 'effectiveness', 'impuissance', 'supervised', 'learning', 'algorithms', '.']

>> Bigrams are: 
 [('We', 'optimistic'), ('optimistic', 'study'), ('study', 'help'), ('help', 'new'), ('new', 'researchers'), ('researchers', 'guiding'), ('guiding', 'new'), ('new', 'research'), ('research', 'areas'), ('areas', 'compare'), ('compare', 'effectiveness'), ('effectiveness', 'impuissance'), ('impuissance', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('We', 'optimistic', 'study'), ('optimistic', 'study', 'help'), ('study', 'help', 'new'), ('help', 'new', 'researchers'), ('new', 'researchers', 'guiding'), ('researchers', 'guiding', 'new'), ('guiding', 'new', 'research'), ('new', 'research', 'areas'), ('research', 'areas', 'compare'), ('areas', 'compare', 'effectiveness'), ('compare', 'effectiveness', 'impuissance'), ('effectiveness', 'impuissance', 'supervised'), ('impuissance', 'supervised', 'learning'), ('supervised', 'learning', 'algorithms'), ('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('optimistic', 'JJ'), ('study', 'NN'), ('help', 'VBP'), ('new', 'JJ'), ('researchers', 'NNS'), ('guiding', 'VBG'), ('new', 'JJ'), ('research', 'NN'), ('areas', 'NNS'), ('compare', 'VBP'), ('effectiveness', 'JJ'), ('impuissance', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('algorithms', 'NN'), ('.', '.')]

 (S
  We/PRP
  (NP optimistic/JJ study/NN)
  help/VBP
  (NP new/JJ researchers/NNS)
  guiding/VBG
  (NP new/JJ research/NN areas/NNS)
  compare/VBP
  (NP effectiveness/JJ impuissance/NN)
  supervised/VBD
  learning/VBG
  (NP algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['optimistic study', 'new researchers', 'new research areas', 'effectiveness impuissance', 'algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('optimistic', 'optimist'), ('study', 'studi'), ('help', 'help'), ('new', 'new'), ('researchers', 'research'), ('guiding', 'guid'), ('new', 'new'), ('research', 'research'), ('areas', 'area'), ('compare', 'compar'), ('effectiveness', 'effect'), ('impuissance', 'impuiss'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('optimistic', 'optimist'), ('study', 'studi'), ('help', 'help'), ('new', 'new'), ('researchers', 'research'), ('guiding', 'guid'), ('new', 'new'), ('research', 'research'), ('areas', 'area'), ('compare', 'compar'), ('effectiveness', 'effect'), ('impuissance', 'impuiss'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('optimistic', 'optimistic'), ('study', 'study'), ('help', 'help'), ('new', 'new'), ('researchers', 'researcher'), ('guiding', 'guiding'), ('new', 'new'), ('research', 'research'), ('areas', 'area'), ('compare', 'compare'), ('effectiveness', 'effectiveness'), ('impuissance', 'impuissance'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 7 =============================

Keywords:   Supervised Machine Learning, SVM, DT, Classifier   1. 


>> Tokens are: 
 ['Keywords', ':', 'Supervised', 'Machine', 'Learning', ',', 'SVM', ',', 'DT', ',', 'Classifier', '1', '.']

>> Bigrams are: 
 [('Keywords', ':'), (':', 'Supervised'), ('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', 'SVM'), ('SVM', ','), (',', 'DT'), ('DT', ','), (',', 'Classifier'), ('Classifier', '1'), ('1', '.')]

>> Trigrams are: 
 [('Keywords', ':', 'Supervised'), (':', 'Supervised', 'Machine'), ('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', 'SVM'), (',', 'SVM', ','), ('SVM', ',', 'DT'), (',', 'DT', ','), ('DT', ',', 'Classifier'), (',', 'Classifier', '1'), ('Classifier', '1', '.')]

>> POS Tags are: 
 [('Keywords', 'NNS'), (':', ':'), ('Supervised', 'VBN'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('SVM', 'NNP'), (',', ','), ('DT', 'NNP'), (',', ','), ('Classifier', 'NNP'), ('1', 'CD'), ('.', '.')]

 (S
  (NP Keywords/NNS)
  :/:
  Supervised/VBN
  (NP Machine/NNP Learning/NNP)
  ,/,
  (NP SVM/NNP)
  ,/,
  (NP DT/NNP)
  ,/,
  (NP Classifier/NNP)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Keywords', 'Machine Learning', 'SVM', 'DT', 'Classifier']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('ORGANIZATION', 'SVM'), ('ORGANIZATION', 'DT')] 

>> Stemming using Porter Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('SVM', 'svm'), (',', ','), ('DT', 'dt'), (',', ','), ('Classifier', 'classifi'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('SVM', 'svm'), (',', ','), ('DT', 'dt'), (',', ','), ('Classifier', 'classifi'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Keywords', 'Keywords'), (':', ':'), ('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('SVM', 'SVM'), (',', ','), ('DT', 'DT'), (',', ','), ('Classifier', 'Classifier'), ('1', '1'), ('.', '.')]



============================ Sentence 8 =============================

INTRODUCTION  Machine Learning (ML) can be considered as a subfield of   Artificial Intelligence since those algorithms can be seen as   building blocks to make computers learn to behave more   intelligently by somehow generalizing rather that just storing   and retrieving data items like a database system and other   applications would do. 


>> Tokens are: 
 ['INTRODUCTION', 'Machine', 'Learning', '(', 'ML', ')', 'considered', 'subfield', 'Artificial', 'Intelligence', 'since', 'algorithms', 'seen', 'building', 'blocks', 'make', 'computers', 'learn', 'behave', 'intelligently', 'somehow', 'generalizing', 'rather', 'storing', 'retrieving', 'data', 'items', 'like', 'database', 'system', 'applications', 'would', '.']

>> Bigrams are: 
 [('INTRODUCTION', 'Machine'), ('Machine', 'Learning'), ('Learning', '('), ('(', 'ML'), ('ML', ')'), (')', 'considered'), ('considered', 'subfield'), ('subfield', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'since'), ('since', 'algorithms'), ('algorithms', 'seen'), ('seen', 'building'), ('building', 'blocks'), ('blocks', 'make'), ('make', 'computers'), ('computers', 'learn'), ('learn', 'behave'), ('behave', 'intelligently'), ('intelligently', 'somehow'), ('somehow', 'generalizing'), ('generalizing', 'rather'), ('rather', 'storing'), ('storing', 'retrieving'), ('retrieving', 'data'), ('data', 'items'), ('items', 'like'), ('like', 'database'), ('database', 'system'), ('system', 'applications'), ('applications', 'would'), ('would', '.')]

>> Trigrams are: 
 [('INTRODUCTION', 'Machine', 'Learning'), ('Machine', 'Learning', '('), ('Learning', '(', 'ML'), ('(', 'ML', ')'), ('ML', ')', 'considered'), (')', 'considered', 'subfield'), ('considered', 'subfield', 'Artificial'), ('subfield', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'since'), ('Intelligence', 'since', 'algorithms'), ('since', 'algorithms', 'seen'), ('algorithms', 'seen', 'building'), ('seen', 'building', 'blocks'), ('building', 'blocks', 'make'), ('blocks', 'make', 'computers'), ('make', 'computers', 'learn'), ('computers', 'learn', 'behave'), ('learn', 'behave', 'intelligently'), ('behave', 'intelligently', 'somehow'), ('intelligently', 'somehow', 'generalizing'), ('somehow', 'generalizing', 'rather'), ('generalizing', 'rather', 'storing'), ('rather', 'storing', 'retrieving'), ('storing', 'retrieving', 'data'), ('retrieving', 'data', 'items'), ('data', 'items', 'like'), ('items', 'like', 'database'), ('like', 'database', 'system'), ('database', 'system', 'applications'), ('system', 'applications', 'would'), ('applications', 'would', '.')]

>> POS Tags are: 
 [('INTRODUCTION', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('(', '('), ('ML', 'NNP'), (')', ')'), ('considered', 'VBD'), ('subfield', 'JJ'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('since', 'IN'), ('algorithms', 'NN'), ('seen', 'VBN'), ('building', 'NN'), ('blocks', 'NNS'), ('make', 'VBP'), ('computers', 'NNS'), ('learn', 'VB'), ('behave', 'VBP'), ('intelligently', 'RB'), ('somehow', 'RB'), ('generalizing', 'VBG'), ('rather', 'RB'), ('storing', 'VBG'), ('retrieving', 'VBG'), ('data', 'NNS'), ('items', 'NNS'), ('like', 'IN'), ('database', 'NN'), ('system', 'NN'), ('applications', 'NNS'), ('would', 'MD'), ('.', '.')]

 (S
  (NP INTRODUCTION/NNP Machine/NNP Learning/NNP)
  (/(
  (NP ML/NNP)
  )/)
  considered/VBD
  (NP subfield/JJ Artificial/NNP Intelligence/NNP)
  since/IN
  (NP algorithms/NN)
  seen/VBN
  (NP building/NN blocks/NNS)
  make/VBP
  (NP computers/NNS)
  learn/VB
  behave/VBP
  intelligently/RB
  somehow/RB
  generalizing/VBG
  rather/RB
  storing/VBG
  retrieving/VBG
  (NP data/NNS items/NNS)
  like/IN
  (NP database/NN system/NN applications/NNS)
  would/MD
  ./.) 


>> Noun Phrases are: 
 ['INTRODUCTION Machine Learning', 'ML', 'subfield Artificial Intelligence', 'algorithms', 'building blocks', 'computers', 'data items', 'database system applications']

>> Named Entities are: 
 [('ORGANIZATION', 'INTRODUCTION'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Artificial Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('INTRODUCTION', 'introduct'), ('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('ML', 'ml'), (')', ')'), ('considered', 'consid'), ('subfield', 'subfield'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('since', 'sinc'), ('algorithms', 'algorithm'), ('seen', 'seen'), ('building', 'build'), ('blocks', 'block'), ('make', 'make'), ('computers', 'comput'), ('learn', 'learn'), ('behave', 'behav'), ('intelligently', 'intellig'), ('somehow', 'somehow'), ('generalizing', 'gener'), ('rather', 'rather'), ('storing', 'store'), ('retrieving', 'retriev'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'databas'), ('system', 'system'), ('applications', 'applic'), ('would', 'would'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('INTRODUCTION', 'introduct'), ('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('ML', 'ml'), (')', ')'), ('considered', 'consid'), ('subfield', 'subfield'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('since', 'sinc'), ('algorithms', 'algorithm'), ('seen', 'seen'), ('building', 'build'), ('blocks', 'block'), ('make', 'make'), ('computers', 'comput'), ('learn', 'learn'), ('behave', 'behav'), ('intelligently', 'intellig'), ('somehow', 'somehow'), ('generalizing', 'general'), ('rather', 'rather'), ('storing', 'store'), ('retrieving', 'retriev'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'databas'), ('system', 'system'), ('applications', 'applic'), ('would', 'would'), ('.', '.')]

>> Lemmatization: 
 [('INTRODUCTION', 'INTRODUCTION'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('(', '('), ('ML', 'ML'), (')', ')'), ('considered', 'considered'), ('subfield', 'subfield'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('since', 'since'), ('algorithms', 'algorithm'), ('seen', 'seen'), ('building', 'building'), ('blocks', 'block'), ('make', 'make'), ('computers', 'computer'), ('learn', 'learn'), ('behave', 'behave'), ('intelligently', 'intelligently'), ('somehow', 'somehow'), ('generalizing', 'generalizing'), ('rather', 'rather'), ('storing', 'storing'), ('retrieving', 'retrieving'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'database'), ('system', 'system'), ('applications', 'application'), ('would', 'would'), ('.', '.')]



============================ Sentence 9 =============================

Machine learning has got its inspiration   from a variety of academic disciplines, including computer   science, statistics, biology, and psychology. 


>> Tokens are: 
 ['Machine', 'learning', 'got', 'inspiration', 'variety', 'academic', 'disciplines', ',', 'including', 'computer', 'science', ',', 'statistics', ',', 'biology', ',', 'psychology', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'got'), ('got', 'inspiration'), ('inspiration', 'variety'), ('variety', 'academic'), ('academic', 'disciplines'), ('disciplines', ','), (',', 'including'), ('including', 'computer'), ('computer', 'science'), ('science', ','), (',', 'statistics'), ('statistics', ','), (',', 'biology'), ('biology', ','), (',', 'psychology'), ('psychology', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'got'), ('learning', 'got', 'inspiration'), ('got', 'inspiration', 'variety'), ('inspiration', 'variety', 'academic'), ('variety', 'academic', 'disciplines'), ('academic', 'disciplines', ','), ('disciplines', ',', 'including'), (',', 'including', 'computer'), ('including', 'computer', 'science'), ('computer', 'science', ','), ('science', ',', 'statistics'), (',', 'statistics', ','), ('statistics', ',', 'biology'), (',', 'biology', ','), ('biology', ',', 'psychology'), (',', 'psychology', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('got', 'VBD'), ('inspiration', 'JJ'), ('variety', 'NN'), ('academic', 'JJ'), ('disciplines', 'NNS'), (',', ','), ('including', 'VBG'), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('statistics', 'NNS'), (',', ','), ('biology', 'NN'), (',', ','), ('psychology', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  got/VBD
  (NP inspiration/JJ variety/NN)
  (NP academic/JJ disciplines/NNS)
  ,/,
  including/VBG
  (NP computer/NN science/NN)
  ,/,
  (NP statistics/NNS)
  ,/,
  (NP biology/NN)
  ,/,
  (NP psychology/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'inspiration variety', 'academic disciplines', 'computer science', 'statistics', 'biology', 'psychology']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('got', 'got'), ('inspiration', 'inspir'), ('variety', 'varieti'), ('academic', 'academ'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('computer', 'comput'), ('science', 'scienc'), (',', ','), ('statistics', 'statist'), (',', ','), ('biology', 'biolog'), (',', ','), ('psychology', 'psycholog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('got', 'got'), ('inspiration', 'inspir'), ('variety', 'varieti'), ('academic', 'academ'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('computer', 'comput'), ('science', 'scienc'), (',', ','), ('statistics', 'statist'), (',', ','), ('biology', 'biolog'), (',', ','), ('psychology', 'psycholog'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('got', 'got'), ('inspiration', 'inspiration'), ('variety', 'variety'), ('academic', 'academic'), ('disciplines', 'discipline'), (',', ','), ('including', 'including'), ('computer', 'computer'), ('science', 'science'), (',', ','), ('statistics', 'statistic'), (',', ','), ('biology', 'biology'), (',', ','), ('psychology', 'psychology'), ('.', '.')]



============================ Sentence 10 =============================

The core function of   Machine learning attempts is to tell computers how to   automatically find a good predictor based on past experiences   and this job is done by good classifier. 


>> Tokens are: 
 ['The', 'core', 'function', 'Machine', 'learning', 'attempts', 'tell', 'computers', 'automatically', 'find', 'good', 'predictor', 'based', 'past', 'experiences', 'job', 'done', 'good', 'classifier', '.']

>> Bigrams are: 
 [('The', 'core'), ('core', 'function'), ('function', 'Machine'), ('Machine', 'learning'), ('learning', 'attempts'), ('attempts', 'tell'), ('tell', 'computers'), ('computers', 'automatically'), ('automatically', 'find'), ('find', 'good'), ('good', 'predictor'), ('predictor', 'based'), ('based', 'past'), ('past', 'experiences'), ('experiences', 'job'), ('job', 'done'), ('done', 'good'), ('good', 'classifier'), ('classifier', '.')]

>> Trigrams are: 
 [('The', 'core', 'function'), ('core', 'function', 'Machine'), ('function', 'Machine', 'learning'), ('Machine', 'learning', 'attempts'), ('learning', 'attempts', 'tell'), ('attempts', 'tell', 'computers'), ('tell', 'computers', 'automatically'), ('computers', 'automatically', 'find'), ('automatically', 'find', 'good'), ('find', 'good', 'predictor'), ('good', 'predictor', 'based'), ('predictor', 'based', 'past'), ('based', 'past', 'experiences'), ('past', 'experiences', 'job'), ('experiences', 'job', 'done'), ('job', 'done', 'good'), ('done', 'good', 'classifier'), ('good', 'classifier', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('function', 'NN'), ('Machine', 'NNP'), ('learning', 'NN'), ('attempts', 'NNS'), ('tell', 'VBP'), ('computers', 'NNS'), ('automatically', 'RB'), ('find', 'VBP'), ('good', 'JJ'), ('predictor', 'NN'), ('based', 'VBN'), ('past', 'JJ'), ('experiences', 'NNS'), ('job', 'NN'), ('done', 'VBN'), ('good', 'JJ'), ('classifier', 'NN'), ('.', '.')]

 (S
  (NP
    The/DT
    core/NN
    function/NN
    Machine/NNP
    learning/NN
    attempts/NNS)
  tell/VBP
  (NP computers/NNS)
  automatically/RB
  find/VBP
  (NP good/JJ predictor/NN)
  based/VBN
  (NP past/JJ experiences/NNS job/NN)
  done/VBN
  (NP good/JJ classifier/NN)
  ./.) 


>> Noun Phrases are: 
 ['The core function Machine learning attempts', 'computers', 'good predictor', 'past experiences job', 'good classifier']

>> Named Entities are: 
 [('PERSON', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('Machine', 'machin'), ('learning', 'learn'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'comput'), ('automatically', 'automat'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'base'), ('past', 'past'), ('experiences', 'experi'), ('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('Machine', 'machin'), ('learning', 'learn'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'comput'), ('automatically', 'automat'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'base'), ('past', 'past'), ('experiences', 'experi'), ('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('function', 'function'), ('Machine', 'Machine'), ('learning', 'learning'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'computer'), ('automatically', 'automatically'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'based'), ('past', 'past'), ('experiences', 'experience'), ('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifier'), ('.', '.')]



============================ Sentence 11 =============================

Classification is the   process of using a model to predict unknown values (output   variables), using a number of known values (input variables). 


>> Tokens are: 
 ['Classification', 'process', 'using', 'model', 'predict', 'unknown', 'values', '(', 'output', 'variables', ')', ',', 'using', 'number', 'known', 'values', '(', 'input', 'variables', ')', '.']

>> Bigrams are: 
 [('Classification', 'process'), ('process', 'using'), ('using', 'model'), ('model', 'predict'), ('predict', 'unknown'), ('unknown', 'values'), ('values', '('), ('(', 'output'), ('output', 'variables'), ('variables', ')'), (')', ','), (',', 'using'), ('using', 'number'), ('number', 'known'), ('known', 'values'), ('values', '('), ('(', 'input'), ('input', 'variables'), ('variables', ')'), (')', '.')]

>> Trigrams are: 
 [('Classification', 'process', 'using'), ('process', 'using', 'model'), ('using', 'model', 'predict'), ('model', 'predict', 'unknown'), ('predict', 'unknown', 'values'), ('unknown', 'values', '('), ('values', '(', 'output'), ('(', 'output', 'variables'), ('output', 'variables', ')'), ('variables', ')', ','), (')', ',', 'using'), (',', 'using', 'number'), ('using', 'number', 'known'), ('number', 'known', 'values'), ('known', 'values', '('), ('values', '(', 'input'), ('(', 'input', 'variables'), ('input', 'variables', ')'), ('variables', ')', '.')]

>> POS Tags are: 
 [('Classification', 'NNP'), ('process', 'NN'), ('using', 'VBG'), ('model', 'NN'), ('predict', 'JJ'), ('unknown', 'JJ'), ('values', 'NNS'), ('(', '('), ('output', 'NN'), ('variables', 'NNS'), (')', ')'), (',', ','), ('using', 'VBG'), ('number', 'NN'), ('known', 'VBN'), ('values', 'NNS'), ('(', '('), ('input', 'VB'), ('variables', 'NNS'), (')', ')'), ('.', '.')]

 (S
  (NP Classification/NNP process/NN)
  using/VBG
  (NP model/NN)
  (NP predict/JJ unknown/JJ values/NNS)
  (/(
  (NP output/NN variables/NNS)
  )/)
  ,/,
  using/VBG
  (NP number/NN)
  known/VBN
  (NP values/NNS)
  (/(
  input/VB
  (NP variables/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Classification process', 'model', 'predict unknown values', 'output variables', 'number', 'values', 'variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('process', 'process'), ('using', 'use'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'valu'), ('(', '('), ('output', 'output'), ('variables', 'variabl'), (')', ')'), (',', ','), ('using', 'use'), ('number', 'number'), ('known', 'known'), ('values', 'valu'), ('(', '('), ('input', 'input'), ('variables', 'variabl'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('process', 'process'), ('using', 'use'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'valu'), ('(', '('), ('output', 'output'), ('variables', 'variabl'), (')', ')'), (',', ','), ('using', 'use'), ('number', 'number'), ('known', 'known'), ('values', 'valu'), ('(', '('), ('input', 'input'), ('variables', 'variabl'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('process', 'process'), ('using', 'using'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'value'), ('(', '('), ('output', 'output'), ('variables', 'variable'), (')', ')'), (',', ','), ('using', 'using'), ('number', 'number'), ('known', 'known'), ('values', 'value'), ('(', '('), ('input', 'input'), ('variables', 'variable'), (')', ')'), ('.', '.')]



============================ Sentence 12 =============================

The classification process is performed on data set D which   holds following objects:    Set size   AAAAA ,,2,1  , where A  denotes the number of attributes or the size of the set A. 


>> Tokens are: 
 ['The', 'classification', 'process', 'performed', 'data', 'set', 'D', 'holds', 'following', 'objects', ':', '\uf0b7', 'Set', 'size', '', '\uf07b', '\uf07dAAAAA', ',', ',2,1', '\uf04b\uf03d', ',', 'A', 'denotes', 'number', 'attributes', 'size', 'set', 'A', '.']

>> Bigrams are: 
 [('The', 'classification'), ('classification', 'process'), ('process', 'performed'), ('performed', 'data'), ('data', 'set'), ('set', 'D'), ('D', 'holds'), ('holds', 'following'), ('following', 'objects'), ('objects', ':'), (':', '\uf0b7'), ('\uf0b7', 'Set'), ('Set', 'size'), ('size', ''), ('', '\uf07b'), ('\uf07b', '\uf07dAAAAA'), ('\uf07dAAAAA', ','), (',', ',2,1'), (',2,1', '\uf04b\uf03d'), ('\uf04b\uf03d', ','), (',', 'A'), ('A', 'denotes'), ('denotes', 'number'), ('number', 'attributes'), ('attributes', 'size'), ('size', 'set'), ('set', 'A'), ('A', '.')]

>> Trigrams are: 
 [('The', 'classification', 'process'), ('classification', 'process', 'performed'), ('process', 'performed', 'data'), ('performed', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', 'holds'), ('D', 'holds', 'following'), ('holds', 'following', 'objects'), ('following', 'objects', ':'), ('objects', ':', '\uf0b7'), (':', '\uf0b7', 'Set'), ('\uf0b7', 'Set', 'size'), ('Set', 'size', ''), ('size', '', '\uf07b'), ('', '\uf07b', '\uf07dAAAAA'), ('\uf07b', '\uf07dAAAAA', ','), ('\uf07dAAAAA', ',', ',2,1'), (',', ',2,1', '\uf04b\uf03d'), (',2,1', '\uf04b\uf03d', ','), ('\uf04b\uf03d', ',', 'A'), (',', 'A', 'denotes'), ('A', 'denotes', 'number'), ('denotes', 'number', 'attributes'), ('number', 'attributes', 'size'), ('attributes', 'size', 'set'), ('size', 'set', 'A'), ('set', 'A', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('classification', 'NN'), ('process', 'NN'), ('performed', 'VBD'), ('data', 'NNS'), ('set', 'VBN'), ('D', 'NNP'), ('holds', 'VBZ'), ('following', 'VBG'), ('objects', 'NNS'), (':', ':'), ('\uf0b7', 'NN'), ('Set', 'NNP'), ('size', 'NN'), ('', 'NNP'), ('\uf07b', 'NNP'), ('\uf07dAAAAA', 'NNP'), (',', ','), (',2,1', 'NNP'), ('\uf04b\uf03d', 'NNP'), (',', ','), ('A', 'NNP'), ('denotes', 'VBZ'), ('number', 'NN'), ('attributes', 'NNS'), ('size', 'NN'), ('set', 'VBN'), ('A', 'NNP'), ('.', '.')]

 (S
  (NP The/DT classification/NN process/NN)
  performed/VBD
  (NP data/NNS)
  set/VBN
  (NP D/NNP)
  holds/VBZ
  following/VBG
  (NP objects/NNS)
  :/:
  (NP /NN Set/NNP size/NN /NNP /NNP AAAAA/NNP)
  ,/,
  (NP ,2,1/NNP /NNP)
  ,/,
  (NP A/NNP)
  denotes/VBZ
  (NP number/NN attributes/NNS size/NN)
  set/VBN
  (NP A/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The classification process', 'data', 'D', 'objects', '\uf0b7 Set size  \uf07b \uf07dAAAAA', ',2,1 \uf04b\uf03d', 'A', 'number attributes size', 'A']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('process', 'process'), ('performed', 'perform'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('holds', 'hold'), ('following', 'follow'), ('objects', 'object'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Set', 'set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07daaaaa'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'a'), ('denotes', 'denot'), ('number', 'number'), ('attributes', 'attribut'), ('size', 'size'), ('set', 'set'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('process', 'process'), ('performed', 'perform'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('holds', 'hold'), ('following', 'follow'), ('objects', 'object'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Set', 'set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07daaaaa'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'a'), ('denotes', 'denot'), ('number', 'number'), ('attributes', 'attribut'), ('size', 'size'), ('set', 'set'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('classification', 'classification'), ('process', 'process'), ('performed', 'performed'), ('data', 'data'), ('set', 'set'), ('D', 'D'), ('holds', 'hold'), ('following', 'following'), ('objects', 'object'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Set', 'Set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07dAAAAA'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'A'), ('denotes', 'denotes'), ('number', 'number'), ('attributes', 'attribute'), ('size', 'size'), ('set', 'set'), ('A', 'A'), ('.', '.')]



============================ Sentence 13 =============================

 Class label C: Target attribute;  CcccC ,,2,1  , where C  is the number of classes and 2C . 


>> Tokens are: 
 ['\uf0b7', 'Class', 'label', 'C', ':', 'Target', 'attribute', ';', '\uf07b', '\uf07dCcccC', ',', ',2,1', '\uf04b\uf03d', ',', 'C', 'number', 'classes', '2\uf0b3C', '.']

>> Bigrams are: 
 [('\uf0b7', 'Class'), ('Class', 'label'), ('label', 'C'), ('C', ':'), (':', 'Target'), ('Target', 'attribute'), ('attribute', ';'), (';', '\uf07b'), ('\uf07b', '\uf07dCcccC'), ('\uf07dCcccC', ','), (',', ',2,1'), (',2,1', '\uf04b\uf03d'), ('\uf04b\uf03d', ','), (',', 'C'), ('C', 'number'), ('number', 'classes'), ('classes', '2\uf0b3C'), ('2\uf0b3C', '.')]

>> Trigrams are: 
 [('\uf0b7', 'Class', 'label'), ('Class', 'label', 'C'), ('label', 'C', ':'), ('C', ':', 'Target'), (':', 'Target', 'attribute'), ('Target', 'attribute', ';'), ('attribute', ';', '\uf07b'), (';', '\uf07b', '\uf07dCcccC'), ('\uf07b', '\uf07dCcccC', ','), ('\uf07dCcccC', ',', ',2,1'), (',', ',2,1', '\uf04b\uf03d'), (',2,1', '\uf04b\uf03d', ','), ('\uf04b\uf03d', ',', 'C'), (',', 'C', 'number'), ('C', 'number', 'classes'), ('number', 'classes', '2\uf0b3C'), ('classes', '2\uf0b3C', '.')]

>> POS Tags are: 
 [('\uf0b7', 'JJ'), ('Class', 'NNP'), ('label', 'NN'), ('C', 'NNP'), (':', ':'), ('Target', 'NNP'), ('attribute', 'NN'), (';', ':'), ('\uf07b', 'CC'), ('\uf07dCcccC', 'VB'), (',', ','), (',2,1', 'NNP'), ('\uf04b\uf03d', 'NNP'), (',', ','), ('C', 'NNP'), ('number', 'NN'), ('classes', 'VBZ'), ('2\uf0b3C', 'CD'), ('.', '.')]

 (S
  (NP /JJ Class/NNP label/NN C/NNP)
  :/:
  (NP Target/NNP attribute/NN)
  ;/:
  /CC
  CcccC/VB
  ,/,
  (NP ,2,1/NNP /NNP)
  ,/,
  (NP C/NNP number/NN)
  classes/VBZ
  2C/CD
  ./.) 


>> Noun Phrases are: 
 ['\uf0b7 Class label C', 'Target attribute', ',2,1 \uf04b\uf03d', 'C number']

>> Named Entities are: 
 [('PERSON', 'Target')] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Class', 'class'), ('label', 'label'), ('C', 'c'), (':', ':'), ('Target', 'target'), ('attribute', 'attribut'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dccccc'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'c'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Class', 'class'), ('label', 'label'), ('C', 'c'), (':', ':'), ('Target', 'target'), ('attribute', 'attribut'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dccccc'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'c'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3c'), ('.', '.')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Class', 'Class'), ('label', 'label'), ('C', 'C'), (':', ':'), ('Target', 'Target'), ('attribute', 'attribute'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dCcccC'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'C'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3C'), ('.', '.')]



============================ Sentence 14 =============================

Given a data set D, the core objective of ML is to produce a   prediction/classification function to relate values of attributes in   A and classes in C.   Data mining is one of the most tools of machine learning   among the number of different applications. 


>> Tokens are: 
 ['Given', 'data', 'set', 'D', ',', 'core', 'objective', 'ML', 'produce', 'prediction/classification', 'function', 'relate', 'values', 'attributes', 'A', 'classes', 'C.', 'Data', 'mining', 'one', 'tools', 'machine', 'learning', 'among', 'number', 'different', 'applications', '.']

>> Bigrams are: 
 [('Given', 'data'), ('data', 'set'), ('set', 'D'), ('D', ','), (',', 'core'), ('core', 'objective'), ('objective', 'ML'), ('ML', 'produce'), ('produce', 'prediction/classification'), ('prediction/classification', 'function'), ('function', 'relate'), ('relate', 'values'), ('values', 'attributes'), ('attributes', 'A'), ('A', 'classes'), ('classes', 'C.'), ('C.', 'Data'), ('Data', 'mining'), ('mining', 'one'), ('one', 'tools'), ('tools', 'machine'), ('machine', 'learning'), ('learning', 'among'), ('among', 'number'), ('number', 'different'), ('different', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('Given', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', ','), ('D', ',', 'core'), (',', 'core', 'objective'), ('core', 'objective', 'ML'), ('objective', 'ML', 'produce'), ('ML', 'produce', 'prediction/classification'), ('produce', 'prediction/classification', 'function'), ('prediction/classification', 'function', 'relate'), ('function', 'relate', 'values'), ('relate', 'values', 'attributes'), ('values', 'attributes', 'A'), ('attributes', 'A', 'classes'), ('A', 'classes', 'C.'), ('classes', 'C.', 'Data'), ('C.', 'Data', 'mining'), ('Data', 'mining', 'one'), ('mining', 'one', 'tools'), ('one', 'tools', 'machine'), ('tools', 'machine', 'learning'), ('machine', 'learning', 'among'), ('learning', 'among', 'number'), ('among', 'number', 'different'), ('number', 'different', 'applications'), ('different', 'applications', '.')]

>> POS Tags are: 
 [('Given', 'VBN'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), (',', ','), ('core', 'RB'), ('objective', 'JJ'), ('ML', 'NNP'), ('produce', 'VBP'), ('prediction/classification', 'NN'), ('function', 'NN'), ('relate', 'NN'), ('values', 'NNS'), ('attributes', 'VBZ'), ('A', 'DT'), ('classes', 'NNS'), ('C.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('one', 'CD'), ('tools', 'VBZ'), ('machine', 'NN'), ('learning', 'NN'), ('among', 'IN'), ('number', 'NN'), ('different', 'JJ'), ('applications', 'NNS'), ('.', '.')]

 (S
  Given/VBN
  (NP data/NNS)
  set/VBD
  (NP D/NNP)
  ,/,
  core/RB
  (NP objective/JJ ML/NNP)
  produce/VBP
  (NP prediction/classification/NN function/NN relate/NN values/NNS)
  attributes/VBZ
  (NP A/DT classes/NNS C./NNP Data/NNP mining/NN)
  one/CD
  tools/VBZ
  (NP machine/NN learning/NN)
  among/IN
  (NP number/NN)
  (NP different/JJ applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data', 'D', 'objective ML', 'prediction/classification function relate values', 'A classes C. Data mining', 'machine learning', 'number', 'different applications']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('core', 'core'), ('objective', 'object'), ('ML', 'ml'), ('produce', 'produc'), ('prediction/classification', 'prediction/classif'), ('function', 'function'), ('relate', 'relat'), ('values', 'valu'), ('attributes', 'attribut'), ('A', 'a'), ('classes', 'class'), ('C.', 'c.'), ('Data', 'data'), ('mining', 'mine'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('among', 'among'), ('number', 'number'), ('different', 'differ'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('core', 'core'), ('objective', 'object'), ('ML', 'ml'), ('produce', 'produc'), ('prediction/classification', 'prediction/classif'), ('function', 'function'), ('relate', 'relat'), ('values', 'valu'), ('attributes', 'attribut'), ('A', 'a'), ('classes', 'class'), ('C.', 'c.'), ('Data', 'data'), ('mining', 'mine'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('among', 'among'), ('number', 'number'), ('different', 'differ'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('Given', 'Given'), ('data', 'data'), ('set', 'set'), ('D', 'D'), (',', ','), ('core', 'core'), ('objective', 'objective'), ('ML', 'ML'), ('produce', 'produce'), ('prediction/classification', 'prediction/classification'), ('function', 'function'), ('relate', 'relate'), ('values', 'value'), ('attributes', 'attribute'), ('A', 'A'), ('classes', 'class'), ('C.', 'C.'), ('Data', 'Data'), ('mining', 'mining'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machine'), ('learning', 'learning'), ('among', 'among'), ('number', 'number'), ('different', 'different'), ('applications', 'application'), ('.', '.')]



============================ Sentence 15 =============================

It is common that   people are often choosing a wrong choices during analysis phase   or, possibly, when trying to establish relationships between   multiple features. 


>> Tokens are: 
 ['It', 'common', 'people', 'often', 'choosing', 'wrong', 'choices', 'analysis', 'phase', ',', 'possibly', ',', 'trying', 'establish', 'relationships', 'multiple', 'features', '.']

>> Bigrams are: 
 [('It', 'common'), ('common', 'people'), ('people', 'often'), ('often', 'choosing'), ('choosing', 'wrong'), ('wrong', 'choices'), ('choices', 'analysis'), ('analysis', 'phase'), ('phase', ','), (',', 'possibly'), ('possibly', ','), (',', 'trying'), ('trying', 'establish'), ('establish', 'relationships'), ('relationships', 'multiple'), ('multiple', 'features'), ('features', '.')]

>> Trigrams are: 
 [('It', 'common', 'people'), ('common', 'people', 'often'), ('people', 'often', 'choosing'), ('often', 'choosing', 'wrong'), ('choosing', 'wrong', 'choices'), ('wrong', 'choices', 'analysis'), ('choices', 'analysis', 'phase'), ('analysis', 'phase', ','), ('phase', ',', 'possibly'), (',', 'possibly', ','), ('possibly', ',', 'trying'), (',', 'trying', 'establish'), ('trying', 'establish', 'relationships'), ('establish', 'relationships', 'multiple'), ('relationships', 'multiple', 'features'), ('multiple', 'features', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('common', 'JJ'), ('people', 'NNS'), ('often', 'RB'), ('choosing', 'VBG'), ('wrong', 'JJ'), ('choices', 'NNS'), ('analysis', 'NN'), ('phase', 'NN'), (',', ','), ('possibly', 'RB'), (',', ','), ('trying', 'VBG'), ('establish', 'VB'), ('relationships', 'NNS'), ('multiple', 'JJ'), ('features', 'NNS'), ('.', '.')]

 (S
  It/PRP
  (NP common/JJ people/NNS)
  often/RB
  choosing/VBG
  (NP wrong/JJ choices/NNS analysis/NN phase/NN)
  ,/,
  possibly/RB
  ,/,
  trying/VBG
  establish/VB
  (NP relationships/NNS)
  (NP multiple/JJ features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['common people', 'wrong choices analysis phase', 'relationships', 'multiple features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('common', 'common'), ('people', 'peopl'), ('often', 'often'), ('choosing', 'choos'), ('wrong', 'wrong'), ('choices', 'choic'), ('analysis', 'analysi'), ('phase', 'phase'), (',', ','), ('possibly', 'possibl'), (',', ','), ('trying', 'tri'), ('establish', 'establish'), ('relationships', 'relationship'), ('multiple', 'multipl'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('common', 'common'), ('people', 'peopl'), ('often', 'often'), ('choosing', 'choos'), ('wrong', 'wrong'), ('choices', 'choic'), ('analysis', 'analysi'), ('phase', 'phase'), (',', ','), ('possibly', 'possibl'), (',', ','), ('trying', 'tri'), ('establish', 'establish'), ('relationships', 'relationship'), ('multiple', 'multipl'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('common', 'common'), ('people', 'people'), ('often', 'often'), ('choosing', 'choosing'), ('wrong', 'wrong'), ('choices', 'choice'), ('analysis', 'analysis'), ('phase', 'phase'), (',', ','), ('possibly', 'possibly'), (',', ','), ('trying', 'trying'), ('establish', 'establish'), ('relationships', 'relationship'), ('multiple', 'multiple'), ('features', 'feature'), ('.', '.')]



============================ Sentence 16 =============================

Ultimately this makes it difficult for them to   explore solutions to certain problems. 


>> Tokens are: 
 ['Ultimately', 'makes', 'difficult', 'explore', 'solutions', 'certain', 'problems', '.']

>> Bigrams are: 
 [('Ultimately', 'makes'), ('makes', 'difficult'), ('difficult', 'explore'), ('explore', 'solutions'), ('solutions', 'certain'), ('certain', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Ultimately', 'makes', 'difficult'), ('makes', 'difficult', 'explore'), ('difficult', 'explore', 'solutions'), ('explore', 'solutions', 'certain'), ('solutions', 'certain', 'problems'), ('certain', 'problems', '.')]

>> POS Tags are: 
 [('Ultimately', 'RB'), ('makes', 'VBZ'), ('difficult', 'JJ'), ('explore', 'IN'), ('solutions', 'NNS'), ('certain', 'JJ'), ('problems', 'NNS'), ('.', '.')]

 (S
  Ultimately/RB
  makes/VBZ
  difficult/JJ
  explore/IN
  (NP solutions/NNS)
  (NP certain/JJ problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['solutions', 'certain problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ultimately', 'ultim'), ('makes', 'make'), ('difficult', 'difficult'), ('explore', 'explor'), ('solutions', 'solut'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ultimately', 'ultim'), ('makes', 'make'), ('difficult', 'difficult'), ('explore', 'explor'), ('solutions', 'solut'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Ultimately', 'Ultimately'), ('makes', 'make'), ('difficult', 'difficult'), ('explore', 'explore'), ('solutions', 'solution'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 17 =============================

Machine learning can   often be successfully applied to these problems, improving the   efficiency of systems and the designs of machines [1]. 


>> Tokens are: 
 ['Machine', 'learning', 'often', 'successfully', 'applied', 'problems', ',', 'improving', 'efficiency', 'systems', 'designs', 'machines', '[', '1', ']', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'often'), ('often', 'successfully'), ('successfully', 'applied'), ('applied', 'problems'), ('problems', ','), (',', 'improving'), ('improving', 'efficiency'), ('efficiency', 'systems'), ('systems', 'designs'), ('designs', 'machines'), ('machines', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'often'), ('learning', 'often', 'successfully'), ('often', 'successfully', 'applied'), ('successfully', 'applied', 'problems'), ('applied', 'problems', ','), ('problems', ',', 'improving'), (',', 'improving', 'efficiency'), ('improving', 'efficiency', 'systems'), ('efficiency', 'systems', 'designs'), ('systems', 'designs', 'machines'), ('designs', 'machines', '['), ('machines', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('often', 'RB'), ('successfully', 'RB'), ('applied', 'VBN'), ('problems', 'NNS'), (',', ','), ('improving', 'VBG'), ('efficiency', 'NN'), ('systems', 'NNS'), ('designs', 'VBZ'), ('machines', 'NNS'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  often/RB
  successfully/RB
  applied/VBN
  (NP problems/NNS)
  ,/,
  improving/VBG
  (NP efficiency/NN systems/NNS)
  designs/VBZ
  (NP machines/NNS)
  [/$
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'problems', 'efficiency systems', 'machines', ']']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('often', 'often'), ('successfully', 'success'), ('applied', 'appli'), ('problems', 'problem'), (',', ','), ('improving', 'improv'), ('efficiency', 'effici'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machin'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('often', 'often'), ('successfully', 'success'), ('applied', 'appli'), ('problems', 'problem'), (',', ','), ('improving', 'improv'), ('efficiency', 'effici'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machin'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('often', 'often'), ('successfully', 'successfully'), ('applied', 'applied'), ('problems', 'problem'), (',', ','), ('improving', 'improving'), ('efficiency', 'efficiency'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machine'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 18 =============================

In   machine learning algorithms every instance of particular dataset   is represented by using the same set of features. 


>> Tokens are: 
 ['In', 'machine', 'learning', 'algorithms', 'every', 'instance', 'particular', 'dataset', 'represented', 'using', 'set', 'features', '.']

>> Bigrams are: 
 [('In', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'every'), ('every', 'instance'), ('instance', 'particular'), ('particular', 'dataset'), ('dataset', 'represented'), ('represented', 'using'), ('using', 'set'), ('set', 'features'), ('features', '.')]

>> Trigrams are: 
 [('In', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'every'), ('algorithms', 'every', 'instance'), ('every', 'instance', 'particular'), ('instance', 'particular', 'dataset'), ('particular', 'dataset', 'represented'), ('dataset', 'represented', 'using'), ('represented', 'using', 'set'), ('using', 'set', 'features'), ('set', 'features', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'JJ'), ('every', 'DT'), ('instance', 'NN'), ('particular', 'JJ'), ('dataset', 'NN'), ('represented', 'VBD'), ('using', 'VBG'), ('set', 'NN'), ('features', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP machine/NN learning/NN)
  algorithms/JJ
  (NP every/DT instance/NN)
  (NP particular/JJ dataset/NN)
  represented/VBD
  using/VBG
  (NP set/NN features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['machine learning', 'every instance', 'particular dataset', 'set features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('every', 'everi'), ('instance', 'instanc'), ('particular', 'particular'), ('dataset', 'dataset'), ('represented', 'repres'), ('using', 'use'), ('set', 'set'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('every', 'everi'), ('instance', 'instanc'), ('particular', 'particular'), ('dataset', 'dataset'), ('represented', 'repres'), ('using', 'use'), ('set', 'set'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('every', 'every'), ('instance', 'instance'), ('particular', 'particular'), ('dataset', 'dataset'), ('represented', 'represented'), ('using', 'using'), ('set', 'set'), ('features', 'feature'), ('.', '.')]



============================ Sentence 19 =============================

The nature of   these features could be continuous, categorical or binary. 


>> Tokens are: 
 ['The', 'nature', 'features', 'could', 'continuous', ',', 'categorical', 'binary', '.']

>> Bigrams are: 
 [('The', 'nature'), ('nature', 'features'), ('features', 'could'), ('could', 'continuous'), ('continuous', ','), (',', 'categorical'), ('categorical', 'binary'), ('binary', '.')]

>> Trigrams are: 
 [('The', 'nature', 'features'), ('nature', 'features', 'could'), ('features', 'could', 'continuous'), ('could', 'continuous', ','), ('continuous', ',', 'categorical'), (',', 'categorical', 'binary'), ('categorical', 'binary', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('nature', 'NN'), ('features', 'NNS'), ('could', 'MD'), ('continuous', 'VB'), (',', ','), ('categorical', 'JJ'), ('binary', 'NN'), ('.', '.')]

 (S
  (NP The/DT nature/NN features/NNS)
  could/MD
  continuous/VB
  ,/,
  (NP categorical/JJ binary/NN)
  ./.) 


>> Noun Phrases are: 
 ['The nature features', 'categorical binary']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('nature', 'natur'), ('features', 'featur'), ('could', 'could'), ('continuous', 'continu'), (',', ','), ('categorical', 'categor'), ('binary', 'binari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('nature', 'natur'), ('features', 'featur'), ('could', 'could'), ('continuous', 'continu'), (',', ','), ('categorical', 'categor'), ('binary', 'binari'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('nature', 'nature'), ('features', 'feature'), ('could', 'could'), ('continuous', 'continuous'), (',', ','), ('categorical', 'categorical'), ('binary', 'binary'), ('.', '.')]



============================ Sentence 20 =============================

If   instances are given with known labels (i.e.- the corresponding   correct outputs) then the learning scheme is known as supervised   (see Table.1), while in unsupervised learning approach the   instances are unlabeled. 


>> Tokens are: 
 ['If', 'instances', 'given', 'known', 'labels', '(', 'i.e.-', 'corresponding', 'correct', 'outputs', ')', 'learning', 'scheme', 'known', 'supervised', '(', 'see', 'Table.1', ')', ',', 'unsupervised', 'learning', 'approach', 'instances', 'unlabeled', '.']

>> Bigrams are: 
 [('If', 'instances'), ('instances', 'given'), ('given', 'known'), ('known', 'labels'), ('labels', '('), ('(', 'i.e.-'), ('i.e.-', 'corresponding'), ('corresponding', 'correct'), ('correct', 'outputs'), ('outputs', ')'), (')', 'learning'), ('learning', 'scheme'), ('scheme', 'known'), ('known', 'supervised'), ('supervised', '('), ('(', 'see'), ('see', 'Table.1'), ('Table.1', ')'), (')', ','), (',', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'approach'), ('approach', 'instances'), ('instances', 'unlabeled'), ('unlabeled', '.')]

>> Trigrams are: 
 [('If', 'instances', 'given'), ('instances', 'given', 'known'), ('given', 'known', 'labels'), ('known', 'labels', '('), ('labels', '(', 'i.e.-'), ('(', 'i.e.-', 'corresponding'), ('i.e.-', 'corresponding', 'correct'), ('corresponding', 'correct', 'outputs'), ('correct', 'outputs', ')'), ('outputs', ')', 'learning'), (')', 'learning', 'scheme'), ('learning', 'scheme', 'known'), ('scheme', 'known', 'supervised'), ('known', 'supervised', '('), ('supervised', '(', 'see'), ('(', 'see', 'Table.1'), ('see', 'Table.1', ')'), ('Table.1', ')', ','), (')', ',', 'unsupervised'), (',', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'approach'), ('learning', 'approach', 'instances'), ('approach', 'instances', 'unlabeled'), ('instances', 'unlabeled', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('instances', 'NNS'), ('given', 'VBN'), ('known', 'VBN'), ('labels', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), ('corresponding', 'NN'), ('correct', 'NN'), ('outputs', 'NNS'), (')', ')'), ('learning', 'VBG'), ('scheme', 'JJ'), ('known', 'VBN'), ('supervised', 'JJ'), ('(', '('), ('see', 'VB'), ('Table.1', 'NNP'), (')', ')'), (',', ','), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('approach', 'NN'), ('instances', 'NNS'), ('unlabeled', 'VBD'), ('.', '.')]

 (S
  If/IN
  (NP instances/NNS)
  given/VBN
  known/VBN
  (NP labels/NNS)
  (/(
  (NP i.e.-/JJ corresponding/NN correct/NN outputs/NNS)
  )/)
  learning/VBG
  scheme/JJ
  known/VBN
  supervised/JJ
  (/(
  see/VB
  (NP Table.1/NNP)
  )/)
  ,/,
  unsupervised/JJ
  learning/VBG
  (NP approach/NN instances/NNS)
  unlabeled/VBD
  ./.) 


>> Noun Phrases are: 
 ['instances', 'labels', 'i.e.- corresponding correct outputs', 'Table.1', 'approach instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('instances', 'instanc'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'correspond'), ('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learn'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervis'), ('(', '('), ('see', 'see'), ('Table.1', 'table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approach', 'approach'), ('instances', 'instanc'), ('unlabeled', 'unlabel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('instances', 'instanc'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'correspond'), ('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learn'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervis'), ('(', '('), ('see', 'see'), ('Table.1', 'table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approach', 'approach'), ('instances', 'instanc'), ('unlabeled', 'unlabel'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('instances', 'instance'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'corresponding'), ('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learning'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervised'), ('(', '('), ('see', 'see'), ('Table.1', 'Table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('approach', 'approach'), ('instances', 'instance'), ('unlabeled', 'unlabeled'), ('.', '.')]



============================ Sentence 21 =============================

Through applying these unsupervised   (clustering) algorithms, researchers are optimistic to discover   unknown, but useful, classes of items [3]. 


>> Tokens are: 
 ['Through', 'applying', 'unsupervised', '(', 'clustering', ')', 'algorithms', ',', 'researchers', 'optimistic', 'discover', 'unknown', ',', 'useful', ',', 'classes', 'items', '[', '3', ']', '.']

>> Bigrams are: 
 [('Through', 'applying'), ('applying', 'unsupervised'), ('unsupervised', '('), ('(', 'clustering'), ('clustering', ')'), (')', 'algorithms'), ('algorithms', ','), (',', 'researchers'), ('researchers', 'optimistic'), ('optimistic', 'discover'), ('discover', 'unknown'), ('unknown', ','), (',', 'useful'), ('useful', ','), (',', 'classes'), ('classes', 'items'), ('items', '['), ('[', '3'), ('3', ']'), (']', '.')]

>> Trigrams are: 
 [('Through', 'applying', 'unsupervised'), ('applying', 'unsupervised', '('), ('unsupervised', '(', 'clustering'), ('(', 'clustering', ')'), ('clustering', ')', 'algorithms'), (')', 'algorithms', ','), ('algorithms', ',', 'researchers'), (',', 'researchers', 'optimistic'), ('researchers', 'optimistic', 'discover'), ('optimistic', 'discover', 'unknown'), ('discover', 'unknown', ','), ('unknown', ',', 'useful'), (',', 'useful', ','), ('useful', ',', 'classes'), (',', 'classes', 'items'), ('classes', 'items', '['), ('items', '[', '3'), ('[', '3', ']'), ('3', ']', '.')]

>> POS Tags are: 
 [('Through', 'IN'), ('applying', 'VBG'), ('unsupervised', 'JJ'), ('(', '('), ('clustering', 'VBG'), (')', ')'), ('algorithms', 'NN'), (',', ','), ('researchers', 'NNS'), ('optimistic', 'JJ'), ('discover', 'RB'), ('unknown', 'JJ'), (',', ','), ('useful', 'JJ'), (',', ','), ('classes', 'VBZ'), ('items', 'NNS'), ('[', '$'), ('3', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Through/IN
  applying/VBG
  unsupervised/JJ
  (/(
  clustering/VBG
  )/)
  (NP algorithms/NN)
  ,/,
  (NP researchers/NNS)
  optimistic/JJ
  discover/RB
  unknown/JJ
  ,/,
  useful/JJ
  ,/,
  classes/VBZ
  (NP items/NNS)
  [/$
  3/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['algorithms', 'researchers', 'items', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Through', 'through'), ('applying', 'appli'), ('unsupervised', 'unsupervis'), ('(', '('), ('clustering', 'cluster'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'research'), ('optimistic', 'optimist'), ('discover', 'discov'), ('unknown', 'unknown'), (',', ','), ('useful', 'use'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Through', 'through'), ('applying', 'appli'), ('unsupervised', 'unsupervis'), ('(', '('), ('clustering', 'cluster'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'research'), ('optimistic', 'optimist'), ('discover', 'discov'), ('unknown', 'unknown'), (',', ','), ('useful', 'use'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Through', 'Through'), ('applying', 'applying'), ('unsupervised', 'unsupervised'), ('(', '('), ('clustering', 'clustering'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'researcher'), ('optimistic', 'optimistic'), ('discover', 'discover'), ('unknown', 'unknown'), (',', ','), ('useful', 'useful'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]



============================ Sentence 22 =============================

Another kind of   machine learning is reinforcement learning. 


>> Tokens are: 
 ['Another', 'kind', 'machine', 'learning', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Another', 'kind'), ('kind', 'machine'), ('machine', 'learning'), ('learning', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Another', 'kind', 'machine'), ('kind', 'machine', 'learning'), ('machine', 'learning', 'reinforcement'), ('learning', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('kind', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('reinforcement', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Another/DT kind/NN machine/NN)
  learning/VBG
  (NP reinforcement/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Another kind machine', 'reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('kind', 'kind'), ('machine', 'machin'), ('learning', 'learn'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('kind', 'kind'), ('machine', 'machin'), ('learning', 'learn'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('kind', 'kind'), ('machine', 'machine'), ('learning', 'learning'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 23 =============================

Here the training   information provided to the learning system by the environment   (i.e.- external trainer) is in the form of a scalar reinforcement   signal that constitutes a measure of how well the system   operates. 


>> Tokens are: 
 ['Here', 'training', 'information', 'provided', 'learning', 'system', 'environment', '(', 'i.e.-', 'external', 'trainer', ')', 'form', 'scalar', 'reinforcement', 'signal', 'constitutes', 'measure', 'well', 'system', 'operates', '.']

>> Bigrams are: 
 [('Here', 'training'), ('training', 'information'), ('information', 'provided'), ('provided', 'learning'), ('learning', 'system'), ('system', 'environment'), ('environment', '('), ('(', 'i.e.-'), ('i.e.-', 'external'), ('external', 'trainer'), ('trainer', ')'), (')', 'form'), ('form', 'scalar'), ('scalar', 'reinforcement'), ('reinforcement', 'signal'), ('signal', 'constitutes'), ('constitutes', 'measure'), ('measure', 'well'), ('well', 'system'), ('system', 'operates'), ('operates', '.')]

>> Trigrams are: 
 [('Here', 'training', 'information'), ('training', 'information', 'provided'), ('information', 'provided', 'learning'), ('provided', 'learning', 'system'), ('learning', 'system', 'environment'), ('system', 'environment', '('), ('environment', '(', 'i.e.-'), ('(', 'i.e.-', 'external'), ('i.e.-', 'external', 'trainer'), ('external', 'trainer', ')'), ('trainer', ')', 'form'), (')', 'form', 'scalar'), ('form', 'scalar', 'reinforcement'), ('scalar', 'reinforcement', 'signal'), ('reinforcement', 'signal', 'constitutes'), ('signal', 'constitutes', 'measure'), ('constitutes', 'measure', 'well'), ('measure', 'well', 'system'), ('well', 'system', 'operates'), ('system', 'operates', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('training', 'VBG'), ('information', 'NN'), ('provided', 'VBD'), ('learning', 'NN'), ('system', 'NN'), ('environment', 'NN'), ('(', '('), ('i.e.-', 'JJ'), ('external', 'JJ'), ('trainer', 'NN'), (')', ')'), ('form', 'NN'), ('scalar', 'JJ'), ('reinforcement', 'JJ'), ('signal', 'NN'), ('constitutes', 'NNS'), ('measure', 'VBP'), ('well', 'RB'), ('system', 'NN'), ('operates', 'VBZ'), ('.', '.')]

 (S
  Here/RB
  training/VBG
  (NP information/NN)
  provided/VBD
  (NP learning/NN system/NN environment/NN)
  (/(
  (NP i.e.-/JJ external/JJ trainer/NN)
  )/)
  (NP form/NN)
  (NP scalar/JJ reinforcement/JJ signal/NN constitutes/NNS)
  measure/VBP
  well/RB
  (NP system/NN)
  operates/VBZ
  ./.) 


>> Noun Phrases are: 
 ['information', 'learning system environment', 'i.e.- external trainer', 'form', 'scalar reinforcement signal constitutes', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('training', 'train'), ('information', 'inform'), ('provided', 'provid'), ('learning', 'learn'), ('system', 'system'), ('environment', 'environ'), ('(', '('), ('i.e.-', 'i.e.-'), ('external', 'extern'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforc'), ('signal', 'signal'), ('constitutes', 'constitut'), ('measure', 'measur'), ('well', 'well'), ('system', 'system'), ('operates', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('training', 'train'), ('information', 'inform'), ('provided', 'provid'), ('learning', 'learn'), ('system', 'system'), ('environment', 'environ'), ('(', '('), ('i.e.-', 'i.e.-'), ('external', 'extern'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforc'), ('signal', 'signal'), ('constitutes', 'constitut'), ('measure', 'measur'), ('well', 'well'), ('system', 'system'), ('operates', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('training', 'training'), ('information', 'information'), ('provided', 'provided'), ('learning', 'learning'), ('system', 'system'), ('environment', 'environment'), ('(', '('), ('i.e.-', 'i.e.-'), ('external', 'external'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforcement'), ('signal', 'signal'), ('constitutes', 'constitutes'), ('measure', 'measure'), ('well', 'well'), ('system', 'system'), ('operates', 'operates'), ('.', '.')]



============================ Sentence 24 =============================

The learner is not told which action has to take, as in   most forms of machine learning, but instead must discover   which actions yield the most reward by trying them [1]. 


>> Tokens are: 
 ['The', 'learner', 'told', 'action', 'take', ',', 'forms', 'machine', 'learning', ',', 'instead', 'must', 'discover', 'actions', 'yield', 'reward', 'trying', '[', '1', ']', '.']

>> Bigrams are: 
 [('The', 'learner'), ('learner', 'told'), ('told', 'action'), ('action', 'take'), ('take', ','), (',', 'forms'), ('forms', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'instead'), ('instead', 'must'), ('must', 'discover'), ('discover', 'actions'), ('actions', 'yield'), ('yield', 'reward'), ('reward', 'trying'), ('trying', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'learner', 'told'), ('learner', 'told', 'action'), ('told', 'action', 'take'), ('action', 'take', ','), ('take', ',', 'forms'), (',', 'forms', 'machine'), ('forms', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'instead'), (',', 'instead', 'must'), ('instead', 'must', 'discover'), ('must', 'discover', 'actions'), ('discover', 'actions', 'yield'), ('actions', 'yield', 'reward'), ('yield', 'reward', 'trying'), ('reward', 'trying', '['), ('trying', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learner', 'NN'), ('told', 'VBD'), ('action', 'NN'), ('take', 'NN'), (',', ','), ('forms', 'NNS'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('instead', 'RB'), ('must', 'MD'), ('discover', 'VB'), ('actions', 'NNS'), ('yield', 'VBP'), ('reward', 'RB'), ('trying', 'VBG'), ('[', 'PRP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP The/DT learner/NN)
  told/VBD
  (NP action/NN take/NN)
  ,/,
  (NP forms/NNS machine/NN learning/NN)
  ,/,
  instead/RB
  must/MD
  discover/VB
  (NP actions/NNS)
  yield/VBP
  reward/RB
  trying/VBG
  [/PRP
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['The learner', 'action take', 'forms machine learning', 'actions', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ','), ('forms', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discov'), ('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'tri'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ','), ('forms', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discov'), ('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'tri'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ','), ('forms', 'form'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discover'), ('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'trying'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 25 =============================

A   number of ML applications involve tasks that can be set up as   supervised. 


>> Tokens are: 
 ['A', 'number', 'ML', 'applications', 'involve', 'tasks', 'set', 'supervised', '.']

>> Bigrams are: 
 [('A', 'number'), ('number', 'ML'), ('ML', 'applications'), ('applications', 'involve'), ('involve', 'tasks'), ('tasks', 'set'), ('set', 'supervised'), ('supervised', '.')]

>> Trigrams are: 
 [('A', 'number', 'ML'), ('number', 'ML', 'applications'), ('ML', 'applications', 'involve'), ('applications', 'involve', 'tasks'), ('involve', 'tasks', 'set'), ('tasks', 'set', 'supervised'), ('set', 'supervised', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('number', 'NN'), ('ML', 'NNP'), ('applications', 'NNS'), ('involve', 'VBP'), ('tasks', 'NNS'), ('set', 'VBD'), ('supervised', 'VBN'), ('.', '.')]

 (S
  (NP A/DT number/NN ML/NNP applications/NNS)
  involve/VBP
  (NP tasks/NNS)
  set/VBD
  supervised/VBN
  ./.) 


>> Noun Phrases are: 
 ['A number ML applications', 'tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('number', 'number'), ('ML', 'ml'), ('applications', 'applic'), ('involve', 'involv'), ('tasks', 'task'), ('set', 'set'), ('supervised', 'supervis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('number', 'number'), ('ML', 'ml'), ('applications', 'applic'), ('involve', 'involv'), ('tasks', 'task'), ('set', 'set'), ('supervised', 'supervis'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('number', 'number'), ('ML', 'ML'), ('applications', 'application'), ('involve', 'involve'), ('tasks', 'task'), ('set', 'set'), ('supervised', 'supervised'), ('.', '.')]



============================ Sentence 26 =============================

The below figure depicts the general classification   architecture. 


>> Tokens are: 
 ['The', 'figure', 'depicts', 'general', 'classification', 'architecture', '.']

>> Bigrams are: 
 [('The', 'figure'), ('figure', 'depicts'), ('depicts', 'general'), ('general', 'classification'), ('classification', 'architecture'), ('architecture', '.')]

>> Trigrams are: 
 [('The', 'figure', 'depicts'), ('figure', 'depicts', 'general'), ('depicts', 'general', 'classification'), ('general', 'classification', 'architecture'), ('classification', 'architecture', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('figure', 'NN'), ('depicts', 'VBZ'), ('general', 'JJ'), ('classification', 'NN'), ('architecture', 'NN'), ('.', '.')]

 (S
  (NP The/DT figure/NN)
  depicts/VBZ
  (NP general/JJ classification/NN architecture/NN)
  ./.) 


>> Noun Phrases are: 
 ['The figure', 'general classification architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('depicts', 'depict'), ('general', 'gener'), ('classification', 'classif'), ('architecture', 'architectur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('depicts', 'depict'), ('general', 'general'), ('classification', 'classif'), ('architecture', 'architectur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('figure', 'figure'), ('depicts', 'depicts'), ('general', 'general'), ('classification', 'classification'), ('architecture', 'architecture'), ('.', '.')]



============================ Sentence 27 =============================

Fig.1. 


>> Tokens are: 
 ['Fig.1', '.']

>> Bigrams are: 
 [('Fig.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.1', 'NNP'), ('.', '.')]

 (S (NP Fig.1/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.1', 'fig.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.1', 'fig.1'), ('.', '.')]

>> Lemmatization: 
 [('Fig.1', 'Fig.1'), ('.', '.')]



============================ Sentence 28 =============================

Classification Architecture   In this study, we will focus our attention on the methods   which are being used for supervised learning. 


>> Tokens are: 
 ['Classification', 'Architecture', 'In', 'study', ',', 'focus', 'attention', 'methods', 'used', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('Classification', 'Architecture'), ('Architecture', 'In'), ('In', 'study'), ('study', ','), (',', 'focus'), ('focus', 'attention'), ('attention', 'methods'), ('methods', 'used'), ('used', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Classification', 'Architecture', 'In'), ('Architecture', 'In', 'study'), ('In', 'study', ','), ('study', ',', 'focus'), (',', 'focus', 'attention'), ('focus', 'attention', 'methods'), ('attention', 'methods', 'used'), ('methods', 'used', 'supervised'), ('used', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('Classification', 'NN'), ('Architecture', 'NN'), ('In', 'IN'), ('study', 'NN'), (',', ','), ('focus', 'VB'), ('attention', 'NN'), ('methods', 'NNS'), ('used', 'VBN'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Classification/NN Architecture/NN)
  In/IN
  (NP study/NN)
  ,/,
  focus/VB
  (NP attention/NN methods/NNS)
  used/VBN
  supervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Classification Architecture', 'study', 'attention methods', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('Architecture', 'architectur'), ('In', 'in'), ('study', 'studi'), (',', ','), ('focus', 'focu'), ('attention', 'attent'), ('methods', 'method'), ('used', 'use'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('Architecture', 'architectur'), ('In', 'in'), ('study', 'studi'), (',', ','), ('focus', 'focus'), ('attention', 'attent'), ('methods', 'method'), ('used', 'use'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('Architecture', 'Architecture'), ('In', 'In'), ('study', 'study'), (',', ','), ('focus', 'focus'), ('attention', 'attention'), ('methods', 'method'), ('used', 'used'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 29 =============================

This study will   contribute to new researchers for getting up-to-date knowledge   about supervised ML approaches. 


>> Tokens are: 
 ['This', 'study', 'contribute', 'new', 'researchers', 'getting', 'up-to-date', 'knowledge', 'supervised', 'ML', 'approaches', '.']

>> Bigrams are: 
 [('This', 'study'), ('study', 'contribute'), ('contribute', 'new'), ('new', 'researchers'), ('researchers', 'getting'), ('getting', 'up-to-date'), ('up-to-date', 'knowledge'), ('knowledge', 'supervised'), ('supervised', 'ML'), ('ML', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('This', 'study', 'contribute'), ('study', 'contribute', 'new'), ('contribute', 'new', 'researchers'), ('new', 'researchers', 'getting'), ('researchers', 'getting', 'up-to-date'), ('getting', 'up-to-date', 'knowledge'), ('up-to-date', 'knowledge', 'supervised'), ('knowledge', 'supervised', 'ML'), ('supervised', 'ML', 'approaches'), ('ML', 'approaches', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN'), ('contribute', 'VB'), ('new', 'JJ'), ('researchers', 'NNS'), ('getting', 'VBG'), ('up-to-date', 'JJ'), ('knowledge', 'NN'), ('supervised', 'VBD'), ('ML', 'NNP'), ('approaches', 'NNS'), ('.', '.')]

 (S
  (NP This/DT study/NN)
  contribute/VB
  (NP new/JJ researchers/NNS)
  getting/VBG
  (NP up-to-date/JJ knowledge/NN)
  supervised/VBD
  (NP ML/NNP approaches/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This study', 'new researchers', 'up-to-date knowledge', 'ML approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi'), ('contribute', 'contribut'), ('new', 'new'), ('researchers', 'research'), ('getting', 'get'), ('up-to-date', 'up-to-d'), ('knowledge', 'knowledg'), ('supervised', 'supervis'), ('ML', 'ml'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi'), ('contribute', 'contribut'), ('new', 'new'), ('researchers', 'research'), ('getting', 'get'), ('up-to-date', 'up-to-d'), ('knowledge', 'knowledg'), ('supervised', 'supervis'), ('ML', 'ml'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study'), ('contribute', 'contribute'), ('new', 'new'), ('researchers', 'researcher'), ('getting', 'getting'), ('up-to-date', 'up-to-date'), ('knowledge', 'knowledge'), ('supervised', 'supervised'), ('ML', 'ML'), ('approaches', 'approach'), ('.', '.')]



============================ Sentence 30 =============================

Table.1. 


>> Tokens are: 
 ['Table.1', '.']

>> Bigrams are: 
 [('Table.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.1', 'NNP'), ('.', '.')]

 (S (NP Table.1/NNP) ./.) 


>> Noun Phrases are: 
 ['Table.1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.1', 'table.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.1', 'table.1'), ('.', '.')]

>> Lemmatization: 
 [('Table.1', 'Table.1'), ('.', '.')]



============================ Sentence 31 =============================

Instances with known labels   Data in standard Format   Case Feature 1 Feature 2  Feature n Class   1 aaa bbb  nnn Yes   2 aaa bbb  nnn Yes   3 aaa bbb  nnn No           In this work we have limited our references to refereed   journals, published books, web data and conferences. 


>> Tokens are: 
 ['Instances', 'known', 'labels', 'Data', 'standard', 'Format', 'Case', 'Feature', '1', 'Feature', '2', '', 'Feature', 'n', 'Class', '1', 'aaa', 'bbb', '', 'nnn', 'Yes', '2', 'aaa', 'bbb', '', 'nnn', 'Yes', '3', 'aaa', 'bbb', '', 'nnn', 'No', '', '', '', '', '', '', 'In', 'work', 'limited', 'references', 'refereed', 'journals', ',', 'published', 'books', ',', 'web', 'data', 'conferences', '.']

>> Bigrams are: 
 [('Instances', 'known'), ('known', 'labels'), ('labels', 'Data'), ('Data', 'standard'), ('standard', 'Format'), ('Format', 'Case'), ('Case', 'Feature'), ('Feature', '1'), ('1', 'Feature'), ('Feature', '2'), ('2', ''), ('', 'Feature'), ('Feature', 'n'), ('n', 'Class'), ('Class', '1'), ('1', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'Yes'), ('Yes', '2'), ('2', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'Yes'), ('Yes', '3'), ('3', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'No'), ('No', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', 'In'), ('In', 'work'), ('work', 'limited'), ('limited', 'references'), ('references', 'refereed'), ('refereed', 'journals'), ('journals', ','), (',', 'published'), ('published', 'books'), ('books', ','), (',', 'web'), ('web', 'data'), ('data', 'conferences'), ('conferences', '.')]

>> Trigrams are: 
 [('Instances', 'known', 'labels'), ('known', 'labels', 'Data'), ('labels', 'Data', 'standard'), ('Data', 'standard', 'Format'), ('standard', 'Format', 'Case'), ('Format', 'Case', 'Feature'), ('Case', 'Feature', '1'), ('Feature', '1', 'Feature'), ('1', 'Feature', '2'), ('Feature', '2', ''), ('2', '', 'Feature'), ('', 'Feature', 'n'), ('Feature', 'n', 'Class'), ('n', 'Class', '1'), ('Class', '1', 'aaa'), ('1', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'Yes'), ('nnn', 'Yes', '2'), ('Yes', '2', 'aaa'), ('2', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'Yes'), ('nnn', 'Yes', '3'), ('Yes', '3', 'aaa'), ('3', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'No'), ('nnn', 'No', ''), ('No', '', ''), ('', '', ''), ('', '', ''), ('', '', ''), ('', '', ''), ('', '', 'In'), ('', 'In', 'work'), ('In', 'work', 'limited'), ('work', 'limited', 'references'), ('limited', 'references', 'refereed'), ('references', 'refereed', 'journals'), ('refereed', 'journals', ','), ('journals', ',', 'published'), (',', 'published', 'books'), ('published', 'books', ','), ('books', ',', 'web'), (',', 'web', 'data'), ('web', 'data', 'conferences'), ('data', 'conferences', '.')]

>> POS Tags are: 
 [('Instances', 'NNS'), ('known', 'VBN'), ('labels', 'NNS'), ('Data', 'NNP'), ('standard', 'NN'), ('Format', 'NNP'), ('Case', 'NNP'), ('Feature', 'NNP'), ('1', 'CD'), ('Feature', 'NNP'), ('2', 'CD'), ('', 'NNP'), ('Feature', 'NNP'), ('n', 'JJ'), ('Class', 'NNP'), ('1', 'CD'), ('aaa', 'NN'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('Yes', 'UH'), ('2', 'CD'), ('aaa', 'JJ'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('Yes', 'UH'), ('3', 'CD'), ('aaa', 'JJ'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('No', 'DT'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('In', 'IN'), ('work', 'NN'), ('limited', 'JJ'), ('references', 'NNS'), ('refereed', 'VBP'), ('journals', 'NNS'), (',', ','), ('published', 'VBN'), ('books', 'NNS'), (',', ','), ('web', 'NN'), ('data', 'NNS'), ('conferences', 'NNS'), ('.', '.')]

 (S
  (NP Instances/NNS)
  known/VBN
  (NP
    labels/NNS
    Data/NNP
    standard/NN
    Format/NNP
    Case/NNP
    Feature/NNP)
  1/CD
  (NP Feature/NNP)
  2/CD
  (NP /NNP Feature/NNP)
  (NP n/JJ Class/NNP)
  1/CD
  (NP aaa/NN bbb/NN /NNP)
  nnn/VBZ
  Yes/UH
  2/CD
  (NP aaa/JJ bbb/NN /NNP)
  nnn/VBZ
  Yes/UH
  3/CD
  (NP aaa/JJ bbb/NN /NNP)
  nnn/VBZ
  (NP No/DT /NNP /NNP /NNP /NNP /NNP /NNP)
  In/IN
  (NP work/NN)
  (NP limited/JJ references/NNS)
  refereed/VBP
  (NP journals/NNS)
  ,/,
  published/VBN
  (NP books/NNS)
  ,/,
  (NP web/NN data/NNS conferences/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Instances', 'labels Data standard Format Case Feature', 'Feature', ' Feature', 'n Class', 'aaa bbb ', 'aaa bbb ', 'aaa bbb ', 'No      ', 'work', 'limited references', 'journals', 'books', 'web data conferences']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Format Case')] 

>> Stemming using Porter Stemmer: 
 [('Instances', 'instanc'), ('known', 'known'), ('labels', 'label'), ('Data', 'data'), ('standard', 'standard'), ('Format', 'format'), ('Case', 'case'), ('Feature', 'featur'), ('1', '1'), ('Feature', 'featur'), ('2', '2'), ('', ''), ('Feature', 'featur'), ('n', 'n'), ('Class', 'class'), ('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'ye'), ('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'ye'), ('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'no'), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('In', 'in'), ('work', 'work'), ('limited', 'limit'), ('references', 'refer'), ('refereed', 'refere'), ('journals', 'journal'), (',', ','), ('published', 'publish'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'confer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Instances', 'instanc'), ('known', 'known'), ('labels', 'label'), ('Data', 'data'), ('standard', 'standard'), ('Format', 'format'), ('Case', 'case'), ('Feature', 'featur'), ('1', '1'), ('Feature', 'featur'), ('2', '2'), ('', ''), ('Feature', 'featur'), ('n', 'n'), ('Class', 'class'), ('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'yes'), ('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'yes'), ('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'no'), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('In', 'in'), ('work', 'work'), ('limited', 'limit'), ('references', 'refer'), ('refereed', 'refere'), ('journals', 'journal'), (',', ','), ('published', 'publish'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'confer'), ('.', '.')]

>> Lemmatization: 
 [('Instances', 'Instances'), ('known', 'known'), ('labels', 'label'), ('Data', 'Data'), ('standard', 'standard'), ('Format', 'Format'), ('Case', 'Case'), ('Feature', 'Feature'), ('1', '1'), ('Feature', 'Feature'), ('2', '2'), ('', ''), ('Feature', 'Feature'), ('n', 'n'), ('Class', 'Class'), ('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'Yes'), ('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'Yes'), ('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'No'), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('In', 'In'), ('work', 'work'), ('limited', 'limited'), ('references', 'reference'), ('refereed', 'refereed'), ('journals', 'journal'), (',', ','), ('published', 'published'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'conference'), ('.', '.')]



============================ Sentence 32 =============================

Our major   goal for this work has been to provide a representative sample of   Training   Data   Machine   Learning   Program   Classification   Rules   Predicted   Classification   Testing Data     ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03   947   existing lines of research in each learning technique. 


>> Tokens are: 
 ['Our', 'major', 'goal', 'work', 'provide', 'representative', 'sample', 'Training', 'Data', 'Machine', 'Learning', 'Program', 'Classification', 'Rules', 'Predicted', 'Classification', 'Testing', 'Data', 'ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03', '947', 'existing', 'lines', 'research', 'learning', 'technique', '.']

>> Bigrams are: 
 [('Our', 'major'), ('major', 'goal'), ('goal', 'work'), ('work', 'provide'), ('provide', 'representative'), ('representative', 'sample'), ('sample', 'Training'), ('Training', 'Data'), ('Data', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Program'), ('Program', 'Classification'), ('Classification', 'Rules'), ('Rules', 'Predicted'), ('Predicted', 'Classification'), ('Classification', 'Testing'), ('Testing', 'Data'), ('Data', 'ISSN'), ('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03'), ('03', '947'), ('947', 'existing'), ('existing', 'lines'), ('lines', 'research'), ('research', 'learning'), ('learning', 'technique'), ('technique', '.')]

>> Trigrams are: 
 [('Our', 'major', 'goal'), ('major', 'goal', 'work'), ('goal', 'work', 'provide'), ('work', 'provide', 'representative'), ('provide', 'representative', 'sample'), ('representative', 'sample', 'Training'), ('sample', 'Training', 'Data'), ('Training', 'Data', 'Machine'), ('Data', 'Machine', 'Learning'), ('Machine', 'Learning', 'Program'), ('Learning', 'Program', 'Classification'), ('Program', 'Classification', 'Rules'), ('Classification', 'Rules', 'Predicted'), ('Rules', 'Predicted', 'Classification'), ('Predicted', 'Classification', 'Testing'), ('Classification', 'Testing', 'Data'), ('Testing', 'Data', 'ISSN'), ('Data', 'ISSN', ':'), ('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03'), (':', '03', '947'), ('03', '947', 'existing'), ('947', 'existing', 'lines'), ('existing', 'lines', 'research'), ('lines', 'research', 'learning'), ('research', 'learning', 'technique'), ('learning', 'technique', '.')]

>> POS Tags are: 
 [('Our', 'PRP$'), ('major', 'JJ'), ('goal', 'NN'), ('work', 'NN'), ('provide', 'RB'), ('representative', 'JJ'), ('sample', 'NN'), ('Training', 'NNP'), ('Data', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Program', 'NNP'), ('Classification', 'NNP'), ('Rules', 'NNP'), ('Predicted', 'NNP'), ('Classification', 'NNP'), ('Testing', 'NNP'), ('Data', 'NNP'), ('ISSN', 'NNP'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD'), ('947', 'CD'), ('existing', 'VBG'), ('lines', 'NNS'), ('research', 'NN'), ('learning', 'NN'), ('technique', 'NN'), ('.', '.')]

 (S
  Our/PRP$
  (NP major/JJ goal/NN work/NN)
  provide/RB
  (NP
    representative/JJ
    sample/NN
    Training/NNP
    Data/NNP
    Machine/NNP
    Learning/NNP
    Program/NNP
    Classification/NNP
    Rules/NNP
    Predicted/NNP
    Classification/NNP
    Testing/NNP
    Data/NNP
    ISSN/NNP)
  :/:
  2229-6956/JJ
  (/(
  (NP ONLINE/NNP)
  )/)
  (NP ICTACT/NNP JOURNAL/NNP ON/NNP SOFT/NNP COMPUTING/NNP)
  ,/,
  (NP APRIL/NNP)
  2015/CD
  ,/,
  (NP VOLUME/NNP)
  :/:
  05/CD
  ,/,
  (NP ISSUE/NNP)
  :/:
  03/CD
  947/CD
  existing/VBG
  (NP lines/NNS research/NN learning/NN technique/NN)
  ./.) 


>> Noun Phrases are: 
 ['major goal work', 'representative sample Training Data Machine Learning Program Classification Rules Predicted Classification Testing Data ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE', 'lines research learning technique']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Program'), ('PERSON', 'Rules Predicted'), ('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('Our', 'our'), ('major', 'major'), ('goal', 'goal'), ('work', 'work'), ('provide', 'provid'), ('representative', 'repres'), ('sample', 'sampl'), ('Training', 'train'), ('Data', 'data'), ('Machine', 'machin'), ('Learning', 'learn'), ('Program', 'program'), ('Classification', 'classif'), ('Rules', 'rule'), ('Predicted', 'predict'), ('Classification', 'classif'), ('Testing', 'test'), ('Data', 'data'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('947', '947'), ('existing', 'exist'), ('lines', 'line'), ('research', 'research'), ('learning', 'learn'), ('technique', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Our', 'our'), ('major', 'major'), ('goal', 'goal'), ('work', 'work'), ('provide', 'provid'), ('representative', 'repres'), ('sample', 'sampl'), ('Training', 'train'), ('Data', 'data'), ('Machine', 'machin'), ('Learning', 'learn'), ('Program', 'program'), ('Classification', 'classif'), ('Rules', 'rule'), ('Predicted', 'predict'), ('Classification', 'classif'), ('Testing', 'test'), ('Data', 'data'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('947', '947'), ('existing', 'exist'), ('lines', 'line'), ('research', 'research'), ('learning', 'learn'), ('technique', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Our', 'Our'), ('major', 'major'), ('goal', 'goal'), ('work', 'work'), ('provide', 'provide'), ('representative', 'representative'), ('sample', 'sample'), ('Training', 'Training'), ('Data', 'Data'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Program', 'Program'), ('Classification', 'Classification'), ('Rules', 'Rules'), ('Predicted', 'Predicted'), ('Classification', 'Classification'), ('Testing', 'Testing'), ('Data', 'Data'), ('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03'), ('947', '947'), ('existing', 'existing'), ('lines', 'line'), ('research', 'research'), ('learning', 'learning'), ('technique', 'technique'), ('.', '.')]



============================ Sentence 33 =============================

In each of   our listed areas, there are many other papers/books that could be   more comprehensively help the interested readers. 


>> Tokens are: 
 ['In', 'listed', 'areas', ',', 'many', 'papers/books', 'could', 'comprehensively', 'help', 'interested', 'readers', '.']

>> Bigrams are: 
 [('In', 'listed'), ('listed', 'areas'), ('areas', ','), (',', 'many'), ('many', 'papers/books'), ('papers/books', 'could'), ('could', 'comprehensively'), ('comprehensively', 'help'), ('help', 'interested'), ('interested', 'readers'), ('readers', '.')]

>> Trigrams are: 
 [('In', 'listed', 'areas'), ('listed', 'areas', ','), ('areas', ',', 'many'), (',', 'many', 'papers/books'), ('many', 'papers/books', 'could'), ('papers/books', 'could', 'comprehensively'), ('could', 'comprehensively', 'help'), ('comprehensively', 'help', 'interested'), ('help', 'interested', 'readers'), ('interested', 'readers', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('listed', 'JJ'), ('areas', 'NNS'), (',', ','), ('many', 'JJ'), ('papers/books', 'NNS'), ('could', 'MD'), ('comprehensively', 'RB'), ('help', 'VB'), ('interested', 'JJ'), ('readers', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP listed/JJ areas/NNS)
  ,/,
  (NP many/JJ papers/books/NNS)
  could/MD
  comprehensively/RB
  help/VB
  (NP interested/JJ readers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['listed areas', 'many papers/books', 'interested readers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('listed', 'list'), ('areas', 'area'), (',', ','), ('many', 'mani'), ('papers/books', 'papers/book'), ('could', 'could'), ('comprehensively', 'comprehens'), ('help', 'help'), ('interested', 'interest'), ('readers', 'reader'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('listed', 'list'), ('areas', 'area'), (',', ','), ('many', 'mani'), ('papers/books', 'papers/book'), ('could', 'could'), ('comprehensively', 'comprehens'), ('help', 'help'), ('interested', 'interest'), ('readers', 'reader'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('listed', 'listed'), ('areas', 'area'), (',', ','), ('many', 'many'), ('papers/books', 'papers/books'), ('could', 'could'), ('comprehensively', 'comprehensively'), ('help', 'help'), ('interested', 'interested'), ('readers', 'reader'), ('.', '.')]



============================ Sentence 34 =============================

In the next section, we will cover wide-ranging issues of   supervised machine learning such as selection of features and   data pre-processing. 


>> Tokens are: 
 ['In', 'next', 'section', ',', 'cover', 'wide-ranging', 'issues', 'supervised', 'machine', 'learning', 'selection', 'features', 'data', 'pre-processing', '.']

>> Bigrams are: 
 [('In', 'next'), ('next', 'section'), ('section', ','), (',', 'cover'), ('cover', 'wide-ranging'), ('wide-ranging', 'issues'), ('issues', 'supervised'), ('supervised', 'machine'), ('machine', 'learning'), ('learning', 'selection'), ('selection', 'features'), ('features', 'data'), ('data', 'pre-processing'), ('pre-processing', '.')]

>> Trigrams are: 
 [('In', 'next', 'section'), ('next', 'section', ','), ('section', ',', 'cover'), (',', 'cover', 'wide-ranging'), ('cover', 'wide-ranging', 'issues'), ('wide-ranging', 'issues', 'supervised'), ('issues', 'supervised', 'machine'), ('supervised', 'machine', 'learning'), ('machine', 'learning', 'selection'), ('learning', 'selection', 'features'), ('selection', 'features', 'data'), ('features', 'data', 'pre-processing'), ('data', 'pre-processing', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('section', 'NN'), (',', ','), ('cover', 'VB'), ('wide-ranging', 'JJ'), ('issues', 'NNS'), ('supervised', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('selection', 'NN'), ('features', 'NNS'), ('data', 'VBP'), ('pre-processing', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP next/JJ section/NN)
  ,/,
  cover/VB
  (NP wide-ranging/JJ issues/NNS)
  supervised/VBN
  (NP machine/NN)
  learning/VBG
  (NP selection/NN features/NNS)
  data/VBP
  (NP pre-processing/NN)
  ./.) 


>> Noun Phrases are: 
 ['next section', 'wide-ranging issues', 'machine', 'selection features', 'pre-processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-rang'), ('issues', 'issu'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('selection', 'select'), ('features', 'featur'), ('data', 'data'), ('pre-processing', 'pre-process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-rang'), ('issues', 'issu'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('selection', 'select'), ('features', 'featur'), ('data', 'data'), ('pre-processing', 'pre-process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-ranging'), ('issues', 'issue'), ('supervised', 'supervised'), ('machine', 'machine'), ('learning', 'learning'), ('selection', 'selection'), ('features', 'feature'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('.', '.')]



============================ Sentence 35 =============================

Logical/Symbolic techniques are being   described in section 3, whereas statistical techniques for ML are   discussed in section 4. 


>> Tokens are: 
 ['Logical/Symbolic', 'techniques', 'described', 'section', '3', ',', 'whereas', 'statistical', 'techniques', 'ML', 'discussed', 'section', '4', '.']

>> Bigrams are: 
 [('Logical/Symbolic', 'techniques'), ('techniques', 'described'), ('described', 'section'), ('section', '3'), ('3', ','), (',', 'whereas'), ('whereas', 'statistical'), ('statistical', 'techniques'), ('techniques', 'ML'), ('ML', 'discussed'), ('discussed', 'section'), ('section', '4'), ('4', '.')]

>> Trigrams are: 
 [('Logical/Symbolic', 'techniques', 'described'), ('techniques', 'described', 'section'), ('described', 'section', '3'), ('section', '3', ','), ('3', ',', 'whereas'), (',', 'whereas', 'statistical'), ('whereas', 'statistical', 'techniques'), ('statistical', 'techniques', 'ML'), ('techniques', 'ML', 'discussed'), ('ML', 'discussed', 'section'), ('discussed', 'section', '4'), ('section', '4', '.')]

>> POS Tags are: 
 [('Logical/Symbolic', 'NNP'), ('techniques', 'NNS'), ('described', 'VBD'), ('section', 'NN'), ('3', 'CD'), (',', ','), ('whereas', 'RB'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('ML', 'NNP'), ('discussed', 'VBD'), ('section', 'NN'), ('4', 'CD'), ('.', '.')]

 (S
  (NP Logical/Symbolic/NNP techniques/NNS)
  described/VBD
  (NP section/NN)
  3/CD
  ,/,
  whereas/RB
  (NP statistical/JJ techniques/NNS ML/NNP)
  discussed/VBD
  (NP section/NN)
  4/CD
  ./.) 


>> Noun Phrases are: 
 ['Logical/Symbolic techniques', 'section', 'statistical techniques ML', 'section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Logical/Symbolic', 'logical/symbol'), ('techniques', 'techniqu'), ('described', 'describ'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'wherea'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('ML', 'ml'), ('discussed', 'discuss'), ('section', 'section'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Logical/Symbolic', 'logical/symbol'), ('techniques', 'techniqu'), ('described', 'describ'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'wherea'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('ML', 'ml'), ('discussed', 'discuss'), ('section', 'section'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Logical/Symbolic', 'Logical/Symbolic'), ('techniques', 'technique'), ('described', 'described'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'whereas'), ('statistical', 'statistical'), ('techniques', 'technique'), ('ML', 'ML'), ('discussed', 'discussed'), ('section', 'section'), ('4', '4'), ('.', '.')]



============================ Sentence 36 =============================

Section 5 will cover instance based   learners, SVM is discussed in section 6. 


>> Tokens are: 
 ['Section', '5', 'cover', 'instance', 'based', 'learners', ',', 'SVM', 'discussed', 'section', '6', '.']

>> Bigrams are: 
 [('Section', '5'), ('5', 'cover'), ('cover', 'instance'), ('instance', 'based'), ('based', 'learners'), ('learners', ','), (',', 'SVM'), ('SVM', 'discussed'), ('discussed', 'section'), ('section', '6'), ('6', '.')]

>> Trigrams are: 
 [('Section', '5', 'cover'), ('5', 'cover', 'instance'), ('cover', 'instance', 'based'), ('instance', 'based', 'learners'), ('based', 'learners', ','), ('learners', ',', 'SVM'), (',', 'SVM', 'discussed'), ('SVM', 'discussed', 'section'), ('discussed', 'section', '6'), ('section', '6', '.')]

>> POS Tags are: 
 [('Section', 'NN'), ('5', 'CD'), ('cover', 'NN'), ('instance', 'NN'), ('based', 'VBN'), ('learners', 'NNS'), (',', ','), ('SVM', 'NNP'), ('discussed', 'VBD'), ('section', 'NN'), ('6', 'CD'), ('.', '.')]

 (S
  (NP Section/NN)
  5/CD
  (NP cover/NN instance/NN)
  based/VBN
  (NP learners/NNS)
  ,/,
  (NP SVM/NNP)
  discussed/VBD
  (NP section/NN)
  6/CD
  ./.) 


>> Noun Phrases are: 
 ['Section', 'cover instance', 'learners', 'SVM', 'section']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('Section', 'section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instanc'), ('based', 'base'), ('learners', 'learner'), (',', ','), ('SVM', 'svm'), ('discussed', 'discuss'), ('section', 'section'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Section', 'section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instanc'), ('based', 'base'), ('learners', 'learner'), (',', ','), ('SVM', 'svm'), ('discussed', 'discuss'), ('section', 'section'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('Section', 'Section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instance'), ('based', 'based'), ('learners', 'learner'), (',', ','), ('SVM', 'SVM'), ('discussed', 'discussed'), ('section', 'section'), ('6', '6'), ('.', '.')]



============================ Sentence 37 =============================

The last section   concludes this work. 


>> Tokens are: 
 ['The', 'last', 'section', 'concludes', 'work', '.']

>> Bigrams are: 
 [('The', 'last'), ('last', 'section'), ('section', 'concludes'), ('concludes', 'work'), ('work', '.')]

>> Trigrams are: 
 [('The', 'last', 'section'), ('last', 'section', 'concludes'), ('section', 'concludes', 'work'), ('concludes', 'work', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('last', 'JJ'), ('section', 'NN'), ('concludes', 'VBZ'), ('work', 'NN'), ('.', '.')]

 (S (NP The/DT last/JJ section/NN) concludes/VBZ (NP work/NN) ./.) 


>> Noun Phrases are: 
 ['The last section', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('last', 'last'), ('section', 'section'), ('concludes', 'conclud'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('last', 'last'), ('section', 'section'), ('concludes', 'conclud'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('last', 'last'), ('section', 'section'), ('concludes', 'concludes'), ('work', 'work'), ('.', '.')]



============================ Sentence 38 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 39 =============================

ISSUES OF SUPERVISED LEARNING  ALGORITHMS   Learning from the past experiences is an attribute of humans   while the computers do not have this ability. 


>> Tokens are: 
 ['ISSUES', 'OF', 'SUPERVISED', 'LEARNING', 'ALGORITHMS', 'Learning', 'past', 'experiences', 'attribute', 'humans', 'computers', 'ability', '.']

>> Bigrams are: 
 [('ISSUES', 'OF'), ('OF', 'SUPERVISED'), ('SUPERVISED', 'LEARNING'), ('LEARNING', 'ALGORITHMS'), ('ALGORITHMS', 'Learning'), ('Learning', 'past'), ('past', 'experiences'), ('experiences', 'attribute'), ('attribute', 'humans'), ('humans', 'computers'), ('computers', 'ability'), ('ability', '.')]

>> Trigrams are: 
 [('ISSUES', 'OF', 'SUPERVISED'), ('OF', 'SUPERVISED', 'LEARNING'), ('SUPERVISED', 'LEARNING', 'ALGORITHMS'), ('LEARNING', 'ALGORITHMS', 'Learning'), ('ALGORITHMS', 'Learning', 'past'), ('Learning', 'past', 'experiences'), ('past', 'experiences', 'attribute'), ('experiences', 'attribute', 'humans'), ('attribute', 'humans', 'computers'), ('humans', 'computers', 'ability'), ('computers', 'ability', '.')]

>> POS Tags are: 
 [('ISSUES', 'NNP'), ('OF', 'NNP'), ('SUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('ALGORITHMS', 'NNP'), ('Learning', 'NNP'), ('past', 'JJ'), ('experiences', 'NNS'), ('attribute', 'VBP'), ('humans', 'NNS'), ('computers', 'NNS'), ('ability', 'NN'), ('.', '.')]

 (S
  (NP
    ISSUES/NNP
    OF/NNP
    SUPERVISED/NNP
    LEARNING/NNP
    ALGORITHMS/NNP
    Learning/NNP)
  (NP past/JJ experiences/NNS)
  attribute/VBP
  (NP humans/NNS computers/NNS ability/NN)
  ./.) 


>> Noun Phrases are: 
 ['ISSUES OF SUPERVISED LEARNING ALGORITHMS Learning', 'past experiences', 'humans computers ability']

>> Named Entities are: 
 [('ORGANIZATION', 'ISSUES'), ('ORGANIZATION', 'OF')] 

>> Stemming using Porter Stemmer: 
 [('ISSUES', 'issu'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm'), ('Learning', 'learn'), ('past', 'past'), ('experiences', 'experi'), ('attribute', 'attribut'), ('humans', 'human'), ('computers', 'comput'), ('ability', 'abil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ISSUES', 'issu'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm'), ('Learning', 'learn'), ('past', 'past'), ('experiences', 'experi'), ('attribute', 'attribut'), ('humans', 'human'), ('computers', 'comput'), ('ability', 'abil'), ('.', '.')]

>> Lemmatization: 
 [('ISSUES', 'ISSUES'), ('OF', 'OF'), ('SUPERVISED', 'SUPERVISED'), ('LEARNING', 'LEARNING'), ('ALGORITHMS', 'ALGORITHMS'), ('Learning', 'Learning'), ('past', 'past'), ('experiences', 'experience'), ('attribute', 'attribute'), ('humans', 'human'), ('computers', 'computer'), ('ability', 'ability'), ('.', '.')]



============================ Sentence 40 =============================

In supervised or   Inductive machine learning, our main goal is to learn a target   function that can be used to predict the values of a class. 


>> Tokens are: 
 ['In', 'supervised', 'Inductive', 'machine', 'learning', ',', 'main', 'goal', 'learn', 'target', 'function', 'used', 'predict', 'values', 'class', '.']

>> Bigrams are: 
 [('In', 'supervised'), ('supervised', 'Inductive'), ('Inductive', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'main'), ('main', 'goal'), ('goal', 'learn'), ('learn', 'target'), ('target', 'function'), ('function', 'used'), ('used', 'predict'), ('predict', 'values'), ('values', 'class'), ('class', '.')]

>> Trigrams are: 
 [('In', 'supervised', 'Inductive'), ('supervised', 'Inductive', 'machine'), ('Inductive', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'main'), (',', 'main', 'goal'), ('main', 'goal', 'learn'), ('goal', 'learn', 'target'), ('learn', 'target', 'function'), ('target', 'function', 'used'), ('function', 'used', 'predict'), ('used', 'predict', 'values'), ('predict', 'values', 'class'), ('values', 'class', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('supervised', 'JJ'), ('Inductive', 'NNP'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('main', 'JJ'), ('goal', 'NN'), ('learn', 'NN'), ('target', 'NN'), ('function', 'NN'), ('used', 'VBN'), ('predict', 'NN'), ('values', 'NNS'), ('class', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP supervised/JJ Inductive/NNP machine/NN learning/NN)
  ,/,
  (NP main/JJ goal/NN learn/NN target/NN function/NN)
  used/VBN
  (NP predict/NN values/NNS class/NN)
  ./.) 


>> Noun Phrases are: 
 ['supervised Inductive machine learning', 'main goal learn target function', 'predict values class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('supervised', 'supervis'), ('Inductive', 'induct'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target'), ('function', 'function'), ('used', 'use'), ('predict', 'predict'), ('values', 'valu'), ('class', 'class'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('supervised', 'supervis'), ('Inductive', 'induct'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target'), ('function', 'function'), ('used', 'use'), ('predict', 'predict'), ('values', 'valu'), ('class', 'class'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('supervised', 'supervised'), ('Inductive', 'Inductive'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target'), ('function', 'function'), ('used', 'used'), ('predict', 'predict'), ('values', 'value'), ('class', 'class'), ('.', '.')]



============================ Sentence 41 =============================

The   process of applying supervised ML to a real-world problem is   described in below figure. 


>> Tokens are: 
 ['The', 'process', 'applying', 'supervised', 'ML', 'real-world', 'problem', 'described', 'figure', '.']

>> Bigrams are: 
 [('The', 'process'), ('process', 'applying'), ('applying', 'supervised'), ('supervised', 'ML'), ('ML', 'real-world'), ('real-world', 'problem'), ('problem', 'described'), ('described', 'figure'), ('figure', '.')]

>> Trigrams are: 
 [('The', 'process', 'applying'), ('process', 'applying', 'supervised'), ('applying', 'supervised', 'ML'), ('supervised', 'ML', 'real-world'), ('ML', 'real-world', 'problem'), ('real-world', 'problem', 'described'), ('problem', 'described', 'figure'), ('described', 'figure', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('applying', 'VBG'), ('supervised', 'VBN'), ('ML', 'NNP'), ('real-world', 'NN'), ('problem', 'NN'), ('described', 'VBD'), ('figure', 'NN'), ('.', '.')]

 (S
  (NP The/DT process/NN)
  applying/VBG
  supervised/VBN
  (NP ML/NNP real-world/NN problem/NN)
  described/VBD
  (NP figure/NN)
  ./.) 


>> Noun Phrases are: 
 ['The process', 'ML real-world problem', 'figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('supervised', 'supervis'), ('ML', 'ml'), ('real-world', 'real-world'), ('problem', 'problem'), ('described', 'describ'), ('figure', 'figur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('supervised', 'supervis'), ('ML', 'ml'), ('real-world', 'real-world'), ('problem', 'problem'), ('described', 'describ'), ('figure', 'figur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('applying', 'applying'), ('supervised', 'supervised'), ('ML', 'ML'), ('real-world', 'real-world'), ('problem', 'problem'), ('described', 'described'), ('figure', 'figure'), ('.', '.')]



============================ Sentence 42 =============================

Fig.2. 


>> Tokens are: 
 ['Fig.2', '.']

>> Bigrams are: 
 [('Fig.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.2', 'NNP'), ('.', '.')]

 (S (NP Fig.2/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.2', 'fig.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.2', 'fig.2'), ('.', '.')]

>> Lemmatization: 
 [('Fig.2', 'Fig.2'), ('.', '.')]



============================ Sentence 43 =============================

Supervised Machine Learning Model   In supervised learning the first step is dealing with dataset. 


>> Tokens are: 
 ['Supervised', 'Machine', 'Learning', 'Model', 'In', 'supervised', 'learning', 'first', 'step', 'dealing', 'dataset', '.']

>> Bigrams are: 
 [('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Model'), ('Model', 'In'), ('In', 'supervised'), ('supervised', 'learning'), ('learning', 'first'), ('first', 'step'), ('step', 'dealing'), ('dealing', 'dataset'), ('dataset', '.')]

>> Trigrams are: 
 [('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', 'Model'), ('Learning', 'Model', 'In'), ('Model', 'In', 'supervised'), ('In', 'supervised', 'learning'), ('supervised', 'learning', 'first'), ('learning', 'first', 'step'), ('first', 'step', 'dealing'), ('step', 'dealing', 'dataset'), ('dealing', 'dataset', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Model', 'NNP'), ('In', 'IN'), ('supervised', 'JJ'), ('learning', 'NN'), ('first', 'JJ'), ('step', 'NN'), ('dealing', 'VBG'), ('dataset', 'NN'), ('.', '.')]

 (S
  Supervised/VBN
  (NP Machine/NNP Learning/NNP Model/NNP)
  In/IN
  (NP supervised/JJ learning/NN)
  (NP first/JJ step/NN)
  dealing/VBG
  (NP dataset/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine Learning Model', 'supervised learning', 'first step', 'dataset']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Model')] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('Model', 'model'), ('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), ('first', 'first'), ('step', 'step'), ('dealing', 'deal'), ('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('Model', 'model'), ('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), ('first', 'first'), ('step', 'step'), ('dealing', 'deal'), ('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Model', 'Model'), ('In', 'In'), ('supervised', 'supervised'), ('learning', 'learning'), ('first', 'first'), ('step', 'step'), ('dealing', 'dealing'), ('dataset', 'dataset'), ('.', '.')]



============================ Sentence 44 =============================

In   order to perform a better training on data set an appropriate   expert could suggest better selection of features. 


>> Tokens are: 
 ['In', 'order', 'perform', 'better', 'training', 'data', 'set', 'appropriate', 'expert', 'could', 'suggest', 'better', 'selection', 'features', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'perform'), ('perform', 'better'), ('better', 'training'), ('training', 'data'), ('data', 'set'), ('set', 'appropriate'), ('appropriate', 'expert'), ('expert', 'could'), ('could', 'suggest'), ('suggest', 'better'), ('better', 'selection'), ('selection', 'features'), ('features', '.')]

>> Trigrams are: 
 [('In', 'order', 'perform'), ('order', 'perform', 'better'), ('perform', 'better', 'training'), ('better', 'training', 'data'), ('training', 'data', 'set'), ('data', 'set', 'appropriate'), ('set', 'appropriate', 'expert'), ('appropriate', 'expert', 'could'), ('expert', 'could', 'suggest'), ('could', 'suggest', 'better'), ('suggest', 'better', 'selection'), ('better', 'selection', 'features'), ('selection', 'features', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('perform', 'NN'), ('better', 'RBR'), ('training', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('appropriate', 'JJ'), ('expert', 'NN'), ('could', 'MD'), ('suggest', 'VB'), ('better', 'JJR'), ('selection', 'NN'), ('features', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP order/NN perform/NN)
  better/RBR
  (NP training/NN data/NNS)
  set/VBD
  (NP appropriate/JJ expert/NN)
  could/MD
  suggest/VB
  better/JJR
  (NP selection/NN features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['order perform', 'training data', 'appropriate expert', 'selection features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropri'), ('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'select'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropri'), ('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'select'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'training'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropriate'), ('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'selection'), ('features', 'feature'), ('.', '.')]



============================ Sentence 45 =============================

If concerned   expert is not in reach, then the other approach is brute-force,   which means measuring everything available in the hope that the   right (informative, relevant) features can be isolated. 


>> Tokens are: 
 ['If', 'concerned', 'expert', 'reach', ',', 'approach', '', 'brute-force', '', ',', 'means', 'measuring', 'everything', 'available', 'hope', 'right', '(', 'informative', ',', 'relevant', ')', 'features', 'isolated', '.']

>> Bigrams are: 
 [('If', 'concerned'), ('concerned', 'expert'), ('expert', 'reach'), ('reach', ','), (',', 'approach'), ('approach', ''), ('', 'brute-force'), ('brute-force', ''), ('', ','), (',', 'means'), ('means', 'measuring'), ('measuring', 'everything'), ('everything', 'available'), ('available', 'hope'), ('hope', 'right'), ('right', '('), ('(', 'informative'), ('informative', ','), (',', 'relevant'), ('relevant', ')'), (')', 'features'), ('features', 'isolated'), ('isolated', '.')]

>> Trigrams are: 
 [('If', 'concerned', 'expert'), ('concerned', 'expert', 'reach'), ('expert', 'reach', ','), ('reach', ',', 'approach'), (',', 'approach', ''), ('approach', '', 'brute-force'), ('', 'brute-force', ''), ('brute-force', '', ','), ('', ',', 'means'), (',', 'means', 'measuring'), ('means', 'measuring', 'everything'), ('measuring', 'everything', 'available'), ('everything', 'available', 'hope'), ('available', 'hope', 'right'), ('hope', 'right', '('), ('right', '(', 'informative'), ('(', 'informative', ','), ('informative', ',', 'relevant'), (',', 'relevant', ')'), ('relevant', ')', 'features'), (')', 'features', 'isolated'), ('features', 'isolated', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('concerned', 'VBN'), ('expert', 'NN'), ('reach', 'NN'), (',', ','), ('approach', 'NN'), ('', 'VBD'), ('brute-force', 'JJ'), ('', 'NNP'), (',', ','), ('means', 'VBZ'), ('measuring', 'VBG'), ('everything', 'NN'), ('available', 'JJ'), ('hope', 'NN'), ('right', 'NN'), ('(', '('), ('informative', 'JJ'), (',', ','), ('relevant', 'JJ'), (')', ')'), ('features', 'NNS'), ('isolated', 'VBN'), ('.', '.')]

 (S
  If/IN
  concerned/VBN
  (NP expert/NN reach/NN)
  ,/,
  (NP approach/NN)
  /VBD
  (NP brute-force/JJ /NNP)
  ,/,
  means/VBZ
  measuring/VBG
  (NP everything/NN)
  (NP available/JJ hope/NN right/NN)
  (/(
  informative/JJ
  ,/,
  relevant/JJ
  )/)
  (NP features/NNS)
  isolated/VBN
  ./.) 


>> Noun Phrases are: 
 ['expert reach', 'approach', 'brute-force ', 'everything', 'available hope right', 'features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('concerned', 'concern'), ('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), (',', ','), ('means', 'mean'), ('measuring', 'measur'), ('everything', 'everyth'), ('available', 'avail'), ('hope', 'hope'), ('right', 'right'), ('(', '('), ('informative', 'inform'), (',', ','), ('relevant', 'relev'), (')', ')'), ('features', 'featur'), ('isolated', 'isol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('concerned', 'concern'), ('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), (',', ','), ('means', 'mean'), ('measuring', 'measur'), ('everything', 'everyth'), ('available', 'avail'), ('hope', 'hope'), ('right', 'right'), ('(', '('), ('informative', 'inform'), (',', ','), ('relevant', 'relev'), (')', ')'), ('features', 'featur'), ('isolated', 'isol'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('concerned', 'concerned'), ('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-force'), ('', ''), (',', ','), ('means', 'mean'), ('measuring', 'measuring'), ('everything', 'everything'), ('available', 'available'), ('hope', 'hope'), ('right', 'right'), ('(', '('), ('informative', 'informative'), (',', ','), ('relevant', 'relevant'), (')', ')'), ('features', 'feature'), ('isolated', 'isolated'), ('.', '.')]



============================ Sentence 46 =============================

However, a   dataset collected by the brute-force method is not directly   suitable for induction. 


>> Tokens are: 
 ['However', ',', 'dataset', 'collected', '', 'brute-force', '', 'method', 'directly', 'suitable', 'induction', '.']

>> Bigrams are: 
 [('However', ','), (',', 'dataset'), ('dataset', 'collected'), ('collected', ''), ('', 'brute-force'), ('brute-force', ''), ('', 'method'), ('method', 'directly'), ('directly', 'suitable'), ('suitable', 'induction'), ('induction', '.')]

>> Trigrams are: 
 [('However', ',', 'dataset'), (',', 'dataset', 'collected'), ('dataset', 'collected', ''), ('collected', '', 'brute-force'), ('', 'brute-force', ''), ('brute-force', '', 'method'), ('', 'method', 'directly'), ('method', 'directly', 'suitable'), ('directly', 'suitable', 'induction'), ('suitable', 'induction', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('dataset', 'NN'), ('collected', 'VBD'), ('', 'JJ'), ('brute-force', 'JJ'), ('', 'NN'), ('method', 'NN'), ('directly', 'RB'), ('suitable', 'JJ'), ('induction', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP dataset/NN)
  collected/VBD
  (NP /JJ brute-force/JJ /NN method/NN)
  directly/RB
  (NP suitable/JJ induction/NN)
  ./.) 


>> Noun Phrases are: 
 ['dataset', ' brute-force  method', 'suitable induction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('dataset', 'dataset'), ('collected', 'collect'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), ('method', 'method'), ('directly', 'directli'), ('suitable', 'suitabl'), ('induction', 'induct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('dataset', 'dataset'), ('collected', 'collect'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), ('method', 'method'), ('directly', 'direct'), ('suitable', 'suitabl'), ('induction', 'induct'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('dataset', 'dataset'), ('collected', 'collected'), ('', ''), ('brute-force', 'brute-force'), ('', ''), ('method', 'method'), ('directly', 'directly'), ('suitable', 'suitable'), ('induction', 'induction'), ('.', '.')]



============================ Sentence 47 =============================

Ultimately, in most cases it contains noise   and missing feature values, and therefore requires significant   pre-processing [1]. 


>> Tokens are: 
 ['Ultimately', ',', 'cases', 'contains', 'noise', 'missing', 'feature', 'values', ',', 'therefore', 'requires', 'significant', 'pre-processing', '[', '1', ']', '.']

>> Bigrams are: 
 [('Ultimately', ','), (',', 'cases'), ('cases', 'contains'), ('contains', 'noise'), ('noise', 'missing'), ('missing', 'feature'), ('feature', 'values'), ('values', ','), (',', 'therefore'), ('therefore', 'requires'), ('requires', 'significant'), ('significant', 'pre-processing'), ('pre-processing', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Ultimately', ',', 'cases'), (',', 'cases', 'contains'), ('cases', 'contains', 'noise'), ('contains', 'noise', 'missing'), ('noise', 'missing', 'feature'), ('missing', 'feature', 'values'), ('feature', 'values', ','), ('values', ',', 'therefore'), (',', 'therefore', 'requires'), ('therefore', 'requires', 'significant'), ('requires', 'significant', 'pre-processing'), ('significant', 'pre-processing', '['), ('pre-processing', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Ultimately', 'RB'), (',', ','), ('cases', 'NNS'), ('contains', 'NNS'), ('noise', 'VBP'), ('missing', 'VBG'), ('feature', 'NN'), ('values', 'NNS'), (',', ','), ('therefore', 'RB'), ('requires', 'VBZ'), ('significant', 'JJ'), ('pre-processing', 'JJ'), ('[', 'NN'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Ultimately/RB
  ,/,
  (NP cases/NNS contains/NNS)
  noise/VBP
  missing/VBG
  (NP feature/NN values/NNS)
  ,/,
  therefore/RB
  requires/VBZ
  (NP significant/JJ pre-processing/JJ [/NN)
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['cases contains', 'feature values', 'significant pre-processing [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('cases', 'case'), ('contains', 'contain'), ('noise', 'nois'), ('missing', 'miss'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('therefore', 'therefor'), ('requires', 'requir'), ('significant', 'signific'), ('pre-processing', 'pre-process'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('cases', 'case'), ('contains', 'contain'), ('noise', 'nois'), ('missing', 'miss'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('therefore', 'therefor'), ('requires', 'requir'), ('significant', 'signific'), ('pre-processing', 'pre-process'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Ultimately', 'Ultimately'), (',', ','), ('cases', 'case'), ('contains', 'contains'), ('noise', 'noise'), ('missing', 'missing'), ('feature', 'feature'), ('values', 'value'), (',', ','), ('therefore', 'therefore'), ('requires', 'requires'), ('significant', 'significant'), ('pre-processing', 'pre-processing'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 48 =============================

In the next step, data preparation and data   preprocessing is a key function of researcher in Supervised   Machine Learning (SML). 


>> Tokens are: 
 ['In', 'next', 'step', ',', 'data', 'preparation', 'data', 'preprocessing', 'key', 'function', 'researcher', 'Supervised', 'Machine', 'Learning', '(', 'SML', ')', '.']

>> Bigrams are: 
 [('In', 'next'), ('next', 'step'), ('step', ','), (',', 'data'), ('data', 'preparation'), ('preparation', 'data'), ('data', 'preprocessing'), ('preprocessing', 'key'), ('key', 'function'), ('function', 'researcher'), ('researcher', 'Supervised'), ('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', '('), ('(', 'SML'), ('SML', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'next', 'step'), ('next', 'step', ','), ('step', ',', 'data'), (',', 'data', 'preparation'), ('data', 'preparation', 'data'), ('preparation', 'data', 'preprocessing'), ('data', 'preprocessing', 'key'), ('preprocessing', 'key', 'function'), ('key', 'function', 'researcher'), ('function', 'researcher', 'Supervised'), ('researcher', 'Supervised', 'Machine'), ('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', '('), ('Learning', '(', 'SML'), ('(', 'SML', ')'), ('SML', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('step', 'NN'), (',', ','), ('data', 'NNS'), ('preparation', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('key', 'JJ'), ('function', 'NN'), ('researcher', 'NN'), ('Supervised', 'VBD'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('(', '('), ('SML', 'NNP'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP next/JJ step/NN)
  ,/,
  (NP data/NNS preparation/NN data/NNS)
  preprocessing/VBG
  (NP key/JJ function/NN researcher/NN)
  Supervised/VBD
  (NP Machine/NNP Learning/NNP)
  (/(
  (NP SML/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['next step', 'data preparation data', 'key function researcher', 'Machine Learning', 'SML']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('ORGANIZATION', 'SML')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'prepar'), ('data', 'data'), ('preprocessing', 'preprocess'), ('key', 'key'), ('function', 'function'), ('researcher', 'research'), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('SML', 'sml'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'prepar'), ('data', 'data'), ('preprocessing', 'preprocess'), ('key', 'key'), ('function', 'function'), ('researcher', 'research'), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('SML', 'sml'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'preparation'), ('data', 'data'), ('preprocessing', 'preprocessing'), ('key', 'key'), ('function', 'function'), ('researcher', 'researcher'), ('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('(', '('), ('SML', 'SML'), (')', ')'), ('.', '.')]



============================ Sentence 49 =============================

A number of techniques have been   introduced by different researchers to deal with missing data   issue. 


>> Tokens are: 
 ['A', 'number', 'techniques', 'introduced', 'different', 'researchers', 'deal', 'missing', 'data', 'issue', '.']

>> Bigrams are: 
 [('A', 'number'), ('number', 'techniques'), ('techniques', 'introduced'), ('introduced', 'different'), ('different', 'researchers'), ('researchers', 'deal'), ('deal', 'missing'), ('missing', 'data'), ('data', 'issue'), ('issue', '.')]

>> Trigrams are: 
 [('A', 'number', 'techniques'), ('number', 'techniques', 'introduced'), ('techniques', 'introduced', 'different'), ('introduced', 'different', 'researchers'), ('different', 'researchers', 'deal'), ('researchers', 'deal', 'missing'), ('deal', 'missing', 'data'), ('missing', 'data', 'issue'), ('data', 'issue', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('number', 'NN'), ('techniques', 'NNS'), ('introduced', 'VBN'), ('different', 'JJ'), ('researchers', 'NNS'), ('deal', 'VBP'), ('missing', 'VBG'), ('data', 'NNS'), ('issue', 'NN'), ('.', '.')]

 (S
  (NP A/DT number/NN techniques/NNS)
  introduced/VBN
  (NP different/JJ researchers/NNS)
  deal/VBP
  missing/VBG
  (NP data/NNS issue/NN)
  ./.) 


>> Noun Phrases are: 
 ['A number techniques', 'different researchers', 'data issue']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('number', 'number'), ('techniques', 'techniqu'), ('introduced', 'introduc'), ('different', 'differ'), ('researchers', 'research'), ('deal', 'deal'), ('missing', 'miss'), ('data', 'data'), ('issue', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('number', 'number'), ('techniques', 'techniqu'), ('introduced', 'introduc'), ('different', 'differ'), ('researchers', 'research'), ('deal', 'deal'), ('missing', 'miss'), ('data', 'data'), ('issue', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('number', 'number'), ('techniques', 'technique'), ('introduced', 'introduced'), ('different', 'different'), ('researchers', 'researcher'), ('deal', 'deal'), ('missing', 'missing'), ('data', 'data'), ('issue', 'issue'), ('.', '.')]



============================ Sentence 50 =============================

Hodge & Austin [4] have conducted a survey of   contemporary techniques for outlier (noise) detection. 


>> Tokens are: 
 ['Hodge', '&', 'Austin', '[', '4', ']', 'conducted', 'survey', 'contemporary', 'techniques', 'outlier', '(', 'noise', ')', 'detection', '.']

>> Bigrams are: 
 [('Hodge', '&'), ('&', 'Austin'), ('Austin', '['), ('[', '4'), ('4', ']'), (']', 'conducted'), ('conducted', 'survey'), ('survey', 'contemporary'), ('contemporary', 'techniques'), ('techniques', 'outlier'), ('outlier', '('), ('(', 'noise'), ('noise', ')'), (')', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('Hodge', '&', 'Austin'), ('&', 'Austin', '['), ('Austin', '[', '4'), ('[', '4', ']'), ('4', ']', 'conducted'), (']', 'conducted', 'survey'), ('conducted', 'survey', 'contemporary'), ('survey', 'contemporary', 'techniques'), ('contemporary', 'techniques', 'outlier'), ('techniques', 'outlier', '('), ('outlier', '(', 'noise'), ('(', 'noise', ')'), ('noise', ')', 'detection'), (')', 'detection', '.')]

>> POS Tags are: 
 [('Hodge', 'NNP'), ('&', 'CC'), ('Austin', 'NNP'), ('[', 'VBZ'), ('4', 'CD'), (']', 'NN'), ('conducted', 'VBN'), ('survey', 'NN'), ('contemporary', 'JJ'), ('techniques', 'NNS'), ('outlier', 'MD'), ('(', '('), ('noise', 'NN'), (')', ')'), ('detection', 'NN'), ('.', '.')]

 (S
  (NP Hodge/NNP)
  &/CC
  (NP Austin/NNP)
  [/VBZ
  4/CD
  (NP ]/NN)
  conducted/VBN
  (NP survey/NN)
  (NP contemporary/JJ techniques/NNS)
  outlier/MD
  (/(
  (NP noise/NN)
  )/)
  (NP detection/NN)
  ./.) 


>> Noun Phrases are: 
 ['Hodge', 'Austin', ']', 'survey', 'contemporary techniques', 'noise', 'detection']

>> Named Entities are: 
 [('PERSON', 'Austin')] 

>> Stemming using Porter Stemmer: 
 [('Hodge', 'hodg'), ('&', '&'), ('Austin', 'austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conduct'), ('survey', 'survey'), ('contemporary', 'contemporari'), ('techniques', 'techniqu'), ('outlier', 'outlier'), ('(', '('), ('noise', 'nois'), (')', ')'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hodge', 'hodg'), ('&', '&'), ('Austin', 'austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conduct'), ('survey', 'survey'), ('contemporary', 'contemporari'), ('techniques', 'techniqu'), ('outlier', 'outlier'), ('(', '('), ('noise', 'nois'), (')', ')'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('Hodge', 'Hodge'), ('&', '&'), ('Austin', 'Austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conducted'), ('survey', 'survey'), ('contemporary', 'contemporary'), ('techniques', 'technique'), ('outlier', 'outlier'), ('(', '('), ('noise', 'noise'), (')', ')'), ('detection', 'detection'), ('.', '.')]



============================ Sentence 51 =============================

Karanjit   & Shuchita [5] have also discussed different outlier detection   methods which are being used in different machine learning. 


>> Tokens are: 
 ['Karanjit', '&', 'Shuchita', '[', '5', ']', 'also', 'discussed', 'different', 'outlier', 'detection', 'methods', 'used', 'different', 'machine', 'learning', '.']

>> Bigrams are: 
 [('Karanjit', '&'), ('&', 'Shuchita'), ('Shuchita', '['), ('[', '5'), ('5', ']'), (']', 'also'), ('also', 'discussed'), ('discussed', 'different'), ('different', 'outlier'), ('outlier', 'detection'), ('detection', 'methods'), ('methods', 'used'), ('used', 'different'), ('different', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Karanjit', '&', 'Shuchita'), ('&', 'Shuchita', '['), ('Shuchita', '[', '5'), ('[', '5', ']'), ('5', ']', 'also'), (']', 'also', 'discussed'), ('also', 'discussed', 'different'), ('discussed', 'different', 'outlier'), ('different', 'outlier', 'detection'), ('outlier', 'detection', 'methods'), ('detection', 'methods', 'used'), ('methods', 'used', 'different'), ('used', 'different', 'machine'), ('different', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('Karanjit', 'NNP'), ('&', 'CC'), ('Shuchita', 'NNP'), ('[', 'VBZ'), ('5', 'CD'), (']', 'NN'), ('also', 'RB'), ('discussed', 'VBD'), ('different', 'JJ'), ('outlier', 'JJR'), ('detection', 'NN'), ('methods', 'NNS'), ('used', 'VBN'), ('different', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Karanjit/NNP)
  &/CC
  (NP Shuchita/NNP)
  [/VBZ
  5/CD
  (NP ]/NN)
  also/RB
  discussed/VBD
  different/JJ
  outlier/JJR
  (NP detection/NN methods/NNS)
  used/VBN
  (NP different/JJ machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Karanjit', 'Shuchita', ']', 'detection methods', 'different machine learning']

>> Named Entities are: 
 [('GPE', 'Karanjit'), ('PERSON', 'Shuchita')] 

>> Stemming using Porter Stemmer: 
 [('Karanjit', 'karanjit'), ('&', '&'), ('Shuchita', 'shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discuss'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect'), ('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Karanjit', 'karanjit'), ('&', '&'), ('Shuchita', 'shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discuss'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect'), ('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Karanjit', 'Karanjit'), ('&', '&'), ('Shuchita', 'Shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discussed'), ('different', 'different'), ('outlier', 'outlier'), ('detection', 'detection'), ('methods', 'method'), ('used', 'used'), ('different', 'different'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 52 =============================

H.   Jair [6] has done comparison on 6 different outlier detection   methods by performing experiment on benchmark datasets and a   synthetic astronomical domain. 


>> Tokens are: 
 ['H.', 'Jair', '[', '6', ']', 'done', 'comparison', '6', 'different', 'outlier', 'detection', 'methods', 'performing', 'experiment', 'benchmark', 'datasets', 'synthetic', 'astronomical', 'domain', '.']

>> Bigrams are: 
 [('H.', 'Jair'), ('Jair', '['), ('[', '6'), ('6', ']'), (']', 'done'), ('done', 'comparison'), ('comparison', '6'), ('6', 'different'), ('different', 'outlier'), ('outlier', 'detection'), ('detection', 'methods'), ('methods', 'performing'), ('performing', 'experiment'), ('experiment', 'benchmark'), ('benchmark', 'datasets'), ('datasets', 'synthetic'), ('synthetic', 'astronomical'), ('astronomical', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('H.', 'Jair', '['), ('Jair', '[', '6'), ('[', '6', ']'), ('6', ']', 'done'), (']', 'done', 'comparison'), ('done', 'comparison', '6'), ('comparison', '6', 'different'), ('6', 'different', 'outlier'), ('different', 'outlier', 'detection'), ('outlier', 'detection', 'methods'), ('detection', 'methods', 'performing'), ('methods', 'performing', 'experiment'), ('performing', 'experiment', 'benchmark'), ('experiment', 'benchmark', 'datasets'), ('benchmark', 'datasets', 'synthetic'), ('datasets', 'synthetic', 'astronomical'), ('synthetic', 'astronomical', 'domain'), ('astronomical', 'domain', '.')]

>> POS Tags are: 
 [('H.', 'NNP'), ('Jair', 'NNP'), ('[', 'VBD'), ('6', 'CD'), (']', 'NNP'), ('done', 'VBN'), ('comparison', 'NN'), ('6', 'CD'), ('different', 'JJ'), ('outlier', 'JJR'), ('detection', 'NN'), ('methods', 'NNS'), ('performing', 'VBG'), ('experiment', 'JJ'), ('benchmark', 'NN'), ('datasets', 'NNS'), ('synthetic', 'JJ'), ('astronomical', 'JJ'), ('domain', 'NN'), ('.', '.')]

 (S
  (NP H./NNP Jair/NNP)
  [/VBD
  6/CD
  (NP ]/NNP)
  done/VBN
  (NP comparison/NN)
  6/CD
  different/JJ
  outlier/JJR
  (NP detection/NN methods/NNS)
  performing/VBG
  (NP experiment/JJ benchmark/NN datasets/NNS)
  (NP synthetic/JJ astronomical/JJ domain/NN)
  ./.) 


>> Noun Phrases are: 
 ['H. Jair', ']', 'comparison', 'detection methods', 'experiment benchmark datasets', 'synthetic astronomical domain']

>> Named Entities are: 
 [('PERSON', 'Jair')] 

>> Stemming using Porter Stemmer: 
 [('H.', 'h.'), ('Jair', 'jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect'), ('methods', 'method'), ('performing', 'perform'), ('experiment', 'experi'), ('benchmark', 'benchmark'), ('datasets', 'dataset'), ('synthetic', 'synthet'), ('astronomical', 'astronom'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('H.', 'h.'), ('Jair', 'jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect'), ('methods', 'method'), ('performing', 'perform'), ('experiment', 'experi'), ('benchmark', 'benchmark'), ('datasets', 'dataset'), ('synthetic', 'synthet'), ('astronomical', 'astronom'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('H.', 'H.'), ('Jair', 'Jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'different'), ('outlier', 'outlier'), ('detection', 'detection'), ('methods', 'method'), ('performing', 'performing'), ('experiment', 'experiment'), ('benchmark', 'benchmark'), ('datasets', 'datasets'), ('synthetic', 'synthetic'), ('astronomical', 'astronomical'), ('domain', 'domain'), ('.', '.')]



============================ Sentence 53 =============================

2.1 ALGORITHM SELECTION   The selection of algorithm for achieving good results is an   important step. 


>> Tokens are: 
 ['2.1', 'ALGORITHM', 'SELECTION', 'The', 'selection', 'algorithm', 'achieving', 'good', 'results', 'important', 'step', '.']

>> Bigrams are: 
 [('2.1', 'ALGORITHM'), ('ALGORITHM', 'SELECTION'), ('SELECTION', 'The'), ('The', 'selection'), ('selection', 'algorithm'), ('algorithm', 'achieving'), ('achieving', 'good'), ('good', 'results'), ('results', 'important'), ('important', 'step'), ('step', '.')]

>> Trigrams are: 
 [('2.1', 'ALGORITHM', 'SELECTION'), ('ALGORITHM', 'SELECTION', 'The'), ('SELECTION', 'The', 'selection'), ('The', 'selection', 'algorithm'), ('selection', 'algorithm', 'achieving'), ('algorithm', 'achieving', 'good'), ('achieving', 'good', 'results'), ('good', 'results', 'important'), ('results', 'important', 'step'), ('important', 'step', '.')]

>> POS Tags are: 
 [('2.1', 'CD'), ('ALGORITHM', 'NNP'), ('SELECTION', 'NNP'), ('The', 'DT'), ('selection', 'NN'), ('algorithm', 'IN'), ('achieving', 'VBG'), ('good', 'JJ'), ('results', 'NNS'), ('important', 'JJ'), ('step', 'NN'), ('.', '.')]

 (S
  2.1/CD
  (NP ALGORITHM/NNP SELECTION/NNP)
  (NP The/DT selection/NN)
  algorithm/IN
  achieving/VBG
  (NP good/JJ results/NNS)
  (NP important/JJ step/NN)
  ./.) 


>> Noun Phrases are: 
 ['ALGORITHM SELECTION', 'The selection', 'good results', 'important step']

>> Named Entities are: 
 [('ORGANIZATION', 'ALGORITHM')] 

>> Stemming using Porter Stemmer: 
 [('2.1', '2.1'), ('ALGORITHM', 'algorithm'), ('SELECTION', 'select'), ('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('achieving', 'achiev'), ('good', 'good'), ('results', 'result'), ('important', 'import'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2.1', '2.1'), ('ALGORITHM', 'algorithm'), ('SELECTION', 'select'), ('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('achieving', 'achiev'), ('good', 'good'), ('results', 'result'), ('important', 'import'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('2.1', '2.1'), ('ALGORITHM', 'ALGORITHM'), ('SELECTION', 'SELECTION'), ('The', 'The'), ('selection', 'selection'), ('algorithm', 'algorithm'), ('achieving', 'achieving'), ('good', 'good'), ('results', 'result'), ('important', 'important'), ('step', 'step'), ('.', '.')]



============================ Sentence 54 =============================

The algorithm evaluation is mostly judge by   prediction accuracy. 


>> Tokens are: 
 ['The', 'algorithm', 'evaluation', 'mostly', 'judge', 'prediction', 'accuracy', '.']

>> Bigrams are: 
 [('The', 'algorithm'), ('algorithm', 'evaluation'), ('evaluation', 'mostly'), ('mostly', 'judge'), ('judge', 'prediction'), ('prediction', 'accuracy'), ('accuracy', '.')]

>> Trigrams are: 
 [('The', 'algorithm', 'evaluation'), ('algorithm', 'evaluation', 'mostly'), ('evaluation', 'mostly', 'judge'), ('mostly', 'judge', 'prediction'), ('judge', 'prediction', 'accuracy'), ('prediction', 'accuracy', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('algorithm', 'JJ'), ('evaluation', 'NN'), ('mostly', 'RB'), ('judge', 'VBZ'), ('prediction', 'NN'), ('accuracy', 'NN'), ('.', '.')]

 (S
  (NP The/DT algorithm/JJ evaluation/NN)
  mostly/RB
  judge/VBZ
  (NP prediction/NN accuracy/NN)
  ./.) 


>> Noun Phrases are: 
 ['The algorithm evaluation', 'prediction accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('algorithm', 'algorithm'), ('evaluation', 'evalu'), ('mostly', 'mostli'), ('judge', 'judg'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('algorithm', 'algorithm'), ('evaluation', 'evalu'), ('mostly', 'most'), ('judge', 'judg'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('algorithm', 'algorithm'), ('evaluation', 'evaluation'), ('mostly', 'mostly'), ('judge', 'judge'), ('prediction', 'prediction'), ('accuracy', 'accuracy'), ('.', '.')]



============================ Sentence 55 =============================

The classifiers (Algorithm) evaluation is   most often based on prediction accuracy and it can be measured   by given below formula     cases test of number Total  tionsclassifica Correct of Number Accuracy   (1)   There are number of methods which are being used by   different researchers to calculate classifiers accuracy. 


>> Tokens are: 
 ['The', 'classifier', '', '(', 'Algorithm', ')', 'evaluation', 'often', 'based', 'prediction', 'accuracy', 'measured', 'given', 'formula', 'cases', 'test', 'number', 'Total', 'tionsclassifica', 'Correct', 'Number', 'Accuracy', '\uf03d', '(', '1', ')', 'There', 'number', 'methods', 'used', 'different', 'researchers', 'calculate', 'classifier', '', 'accuracy', '.']

>> Bigrams are: 
 [('The', 'classifier'), ('classifier', ''), ('', '('), ('(', 'Algorithm'), ('Algorithm', ')'), (')', 'evaluation'), ('evaluation', 'often'), ('often', 'based'), ('based', 'prediction'), ('prediction', 'accuracy'), ('accuracy', 'measured'), ('measured', 'given'), ('given', 'formula'), ('formula', 'cases'), ('cases', 'test'), ('test', 'number'), ('number', 'Total'), ('Total', 'tionsclassifica'), ('tionsclassifica', 'Correct'), ('Correct', 'Number'), ('Number', 'Accuracy'), ('Accuracy', '\uf03d'), ('\uf03d', '('), ('(', '1'), ('1', ')'), (')', 'There'), ('There', 'number'), ('number', 'methods'), ('methods', 'used'), ('used', 'different'), ('different', 'researchers'), ('researchers', 'calculate'), ('calculate', 'classifier'), ('classifier', ''), ('', 'accuracy'), ('accuracy', '.')]

>> Trigrams are: 
 [('The', 'classifier', ''), ('classifier', '', '('), ('', '(', 'Algorithm'), ('(', 'Algorithm', ')'), ('Algorithm', ')', 'evaluation'), (')', 'evaluation', 'often'), ('evaluation', 'often', 'based'), ('often', 'based', 'prediction'), ('based', 'prediction', 'accuracy'), ('prediction', 'accuracy', 'measured'), ('accuracy', 'measured', 'given'), ('measured', 'given', 'formula'), ('given', 'formula', 'cases'), ('formula', 'cases', 'test'), ('cases', 'test', 'number'), ('test', 'number', 'Total'), ('number', 'Total', 'tionsclassifica'), ('Total', 'tionsclassifica', 'Correct'), ('tionsclassifica', 'Correct', 'Number'), ('Correct', 'Number', 'Accuracy'), ('Number', 'Accuracy', '\uf03d'), ('Accuracy', '\uf03d', '('), ('\uf03d', '(', '1'), ('(', '1', ')'), ('1', ')', 'There'), (')', 'There', 'number'), ('There', 'number', 'methods'), ('number', 'methods', 'used'), ('methods', 'used', 'different'), ('used', 'different', 'researchers'), ('different', 'researchers', 'calculate'), ('researchers', 'calculate', 'classifier'), ('calculate', 'classifier', ''), ('classifier', '', 'accuracy'), ('', 'accuracy', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('classifier', 'NN'), ('', 'NNP'), ('(', '('), ('Algorithm', 'NNP'), (')', ')'), ('evaluation', 'NN'), ('often', 'RB'), ('based', 'VBN'), ('prediction', 'NN'), ('accuracy', 'NN'), ('measured', 'VBD'), ('given', 'VBN'), ('formula', 'NN'), ('cases', 'NNS'), ('test', 'VBP'), ('number', 'NN'), ('Total', 'NNP'), ('tionsclassifica', 'NN'), ('Correct', 'NNP'), ('Number', 'NNP'), ('Accuracy', 'NNP'), ('\uf03d', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')'), ('There', 'EX'), ('number', 'NN'), ('methods', 'NNS'), ('used', 'VBN'), ('different', 'JJ'), ('researchers', 'NNS'), ('calculate', 'VBP'), ('classifier', 'JJR'), ('', 'JJ'), ('accuracy', 'NN'), ('.', '.')]

 (S
  (NP The/DT classifier/NN /NNP)
  (/(
  (NP Algorithm/NNP)
  )/)
  (NP evaluation/NN)
  often/RB
  based/VBN
  (NP prediction/NN accuracy/NN)
  measured/VBD
  given/VBN
  (NP formula/NN cases/NNS)
  test/VBP
  (NP
    number/NN
    Total/NNP
    tionsclassifica/NN
    Correct/NNP
    Number/NNP
    Accuracy/NNP
    /NNP)
  (/(
  1/CD
  )/)
  There/EX
  (NP number/NN methods/NNS)
  used/VBN
  (NP different/JJ researchers/NNS)
  calculate/VBP
  classifier/JJR
  (NP /JJ accuracy/NN)
  ./.) 


>> Noun Phrases are: 
 ['The classifier ', 'Algorithm', 'evaluation', 'prediction accuracy', 'formula cases', 'number Total tionsclassifica Correct Number Accuracy \uf03d', 'number methods', 'different researchers', ' accuracy']

>> Named Entities are: 
 [('ORGANIZATION', 'Algorithm'), ('ORGANIZATION', 'Total'), ('PERSON', 'Correct Number Accuracy')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('classifier', 'classifi'), ('', ''), ('(', '('), ('Algorithm', 'algorithm'), (')', ')'), ('evaluation', 'evalu'), ('often', 'often'), ('based', 'base'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('measured', 'measur'), ('given', 'given'), ('formula', 'formula'), ('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'total'), ('tionsclassifica', 'tionsclassifica'), ('Correct', 'correct'), ('Number', 'number'), ('Accuracy', 'accuraci'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')'), ('There', 'there'), ('number', 'number'), ('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('researchers', 'research'), ('calculate', 'calcul'), ('classifier', 'classifi'), ('', ''), ('accuracy', 'accuraci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('classifier', 'classifi'), ('', ''), ('(', '('), ('Algorithm', 'algorithm'), (')', ')'), ('evaluation', 'evalu'), ('often', 'often'), ('based', 'base'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('measured', 'measur'), ('given', 'given'), ('formula', 'formula'), ('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'total'), ('tionsclassifica', 'tionsclassifica'), ('Correct', 'correct'), ('Number', 'number'), ('Accuracy', 'accuraci'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')'), ('There', 'there'), ('number', 'number'), ('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('researchers', 'research'), ('calculate', 'calcul'), ('classifier', 'classifi'), ('', ''), ('accuracy', 'accuraci'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('classifier', 'classifier'), ('', ''), ('(', '('), ('Algorithm', 'Algorithm'), (')', ')'), ('evaluation', 'evaluation'), ('often', 'often'), ('based', 'based'), ('prediction', 'prediction'), ('accuracy', 'accuracy'), ('measured', 'measured'), ('given', 'given'), ('formula', 'formula'), ('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'Total'), ('tionsclassifica', 'tionsclassifica'), ('Correct', 'Correct'), ('Number', 'Number'), ('Accuracy', 'Accuracy'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')'), ('There', 'There'), ('number', 'number'), ('methods', 'method'), ('used', 'used'), ('different', 'different'), ('researchers', 'researcher'), ('calculate', 'calculate'), ('classifier', 'classifier'), ('', ''), ('accuracy', 'accuracy'), ('.', '.')]



============================ Sentence 56 =============================

Some   researchers splits the training set in such a way that, two-thirds   retain for training and the other third for estimating performance. 


>> Tokens are: 
 ['Some', 'researcher', '', 'splits', 'training', 'set', 'way', ',', 'two-thirds', 'retain', 'training', 'third', 'estimating', 'performance', '.']

>> Bigrams are: 
 [('Some', 'researcher'), ('researcher', ''), ('', 'splits'), ('splits', 'training'), ('training', 'set'), ('set', 'way'), ('way', ','), (',', 'two-thirds'), ('two-thirds', 'retain'), ('retain', 'training'), ('training', 'third'), ('third', 'estimating'), ('estimating', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('Some', 'researcher', ''), ('researcher', '', 'splits'), ('', 'splits', 'training'), ('splits', 'training', 'set'), ('training', 'set', 'way'), ('set', 'way', ','), ('way', ',', 'two-thirds'), (',', 'two-thirds', 'retain'), ('two-thirds', 'retain', 'training'), ('retain', 'training', 'third'), ('training', 'third', 'estimating'), ('third', 'estimating', 'performance'), ('estimating', 'performance', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('researcher', 'NN'), ('', 'VBD'), ('splits', 'NNS'), ('training', 'VBG'), ('set', 'JJ'), ('way', 'NN'), (',', ','), ('two-thirds', 'NNS'), ('retain', 'VBP'), ('training', 'VBG'), ('third', 'JJ'), ('estimating', 'VBG'), ('performance', 'NN'), ('.', '.')]

 (S
  (NP Some/DT researcher/NN)
  /VBD
  (NP splits/NNS)
  training/VBG
  (NP set/JJ way/NN)
  ,/,
  (NP two-thirds/NNS)
  retain/VBP
  training/VBG
  third/JJ
  estimating/VBG
  (NP performance/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some researcher', 'splits', 'set way', 'two-thirds', 'performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('researcher', 'research'), ('', ''), ('splits', 'split'), ('training', 'train'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-third'), ('retain', 'retain'), ('training', 'train'), ('third', 'third'), ('estimating', 'estim'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('researcher', 'research'), ('', ''), ('splits', 'split'), ('training', 'train'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-third'), ('retain', 'retain'), ('training', 'train'), ('third', 'third'), ('estimating', 'estim'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('researcher', 'researcher'), ('', ''), ('splits', 'split'), ('training', 'training'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-thirds'), ('retain', 'retain'), ('training', 'training'), ('third', 'third'), ('estimating', 'estimating'), ('performance', 'performance'), ('.', '.')]



============================ Sentence 57 =============================

Cross-Validation (CV) or Rotation Estimation is another   approach. 


>> Tokens are: 
 ['Cross-Validation', '(', 'CV', ')', 'Rotation', 'Estimation', 'another', 'approach', '.']

>> Bigrams are: 
 [('Cross-Validation', '('), ('(', 'CV'), ('CV', ')'), (')', 'Rotation'), ('Rotation', 'Estimation'), ('Estimation', 'another'), ('another', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('Cross-Validation', '(', 'CV'), ('(', 'CV', ')'), ('CV', ')', 'Rotation'), (')', 'Rotation', 'Estimation'), ('Rotation', 'Estimation', 'another'), ('Estimation', 'another', 'approach'), ('another', 'approach', '.')]

>> POS Tags are: 
 [('Cross-Validation', 'NN'), ('(', '('), ('CV', 'NNP'), (')', ')'), ('Rotation', 'NNP'), ('Estimation', 'NNP'), ('another', 'DT'), ('approach', 'NN'), ('.', '.')]

 (S
  (NP Cross-Validation/NN)
  (/(
  (NP CV/NNP)
  )/)
  (NP Rotation/NNP Estimation/NNP)
  (NP another/DT approach/NN)
  ./.) 


>> Noun Phrases are: 
 ['Cross-Validation', 'CV', 'Rotation Estimation', 'another approach']

>> Named Entities are: 
 [('PERSON', 'Rotation Estimation')] 

>> Stemming using Porter Stemmer: 
 [('Cross-Validation', 'cross-valid'), ('(', '('), ('CV', 'cv'), (')', ')'), ('Rotation', 'rotat'), ('Estimation', 'estim'), ('another', 'anoth'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cross-Validation', 'cross-valid'), ('(', '('), ('CV', 'cv'), (')', ')'), ('Rotation', 'rotat'), ('Estimation', 'estim'), ('another', 'anoth'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('Cross-Validation', 'Cross-Validation'), ('(', '('), ('CV', 'CV'), (')', ')'), ('Rotation', 'Rotation'), ('Estimation', 'Estimation'), ('another', 'another'), ('approach', 'approach'), ('.', '.')]



============================ Sentence 58 =============================

CV provides a way to make a better use of the   available sample. 


>> Tokens are: 
 ['CV', 'provides', 'way', 'make', 'better', 'use', 'available', 'sample', '.']

>> Bigrams are: 
 [('CV', 'provides'), ('provides', 'way'), ('way', 'make'), ('make', 'better'), ('better', 'use'), ('use', 'available'), ('available', 'sample'), ('sample', '.')]

>> Trigrams are: 
 [('CV', 'provides', 'way'), ('provides', 'way', 'make'), ('way', 'make', 'better'), ('make', 'better', 'use'), ('better', 'use', 'available'), ('use', 'available', 'sample'), ('available', 'sample', '.')]

>> POS Tags are: 
 [('CV', 'NNP'), ('provides', 'VBZ'), ('way', 'NN'), ('make', 'VBP'), ('better', 'JJR'), ('use', 'NN'), ('available', 'JJ'), ('sample', 'NN'), ('.', '.')]

 (S
  (NP CV/NNP)
  provides/VBZ
  (NP way/NN)
  make/VBP
  better/JJR
  (NP use/NN)
  (NP available/JJ sample/NN)
  ./.) 


>> Noun Phrases are: 
 ['CV', 'way', 'use', 'available sample']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('CV', 'cv'), ('provides', 'provid'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use'), ('available', 'avail'), ('sample', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CV', 'cv'), ('provides', 'provid'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use'), ('available', 'avail'), ('sample', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('CV', 'CV'), ('provides', 'provides'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use'), ('available', 'available'), ('sample', 'sample'), ('.', '.')]



============================ Sentence 59 =============================

In k-fold cross-validation scheme, we divide   the learning sample into k disjoint subsets of the same size, i.e.-    klslslsls  211  (2)   A model is then inferred by the learning algorithm from each   sample ls\ls, i = 1,..,k and its performance is determined on the   held out sample lsi. 


>> Tokens are: 
 ['In', 'k-fold', 'cross-validation', 'scheme', ',', 'divide', 'learning', 'sample', 'k', 'disjoint', 'subsets', 'size', ',', 'i.e.-', 'klslslsls', '\uf0c8\uf0c8\uf03d', '211', '(', '2', ')', 'A', 'model', 'inferred', 'learning', 'algorithm', 'sample', 'ls\\ls', ',', '=', '1', ',', '..', ',', 'k', 'performance', 'determined', 'held', 'sample', 'lsi', '.']

>> Bigrams are: 
 [('In', 'k-fold'), ('k-fold', 'cross-validation'), ('cross-validation', 'scheme'), ('scheme', ','), (',', 'divide'), ('divide', 'learning'), ('learning', 'sample'), ('sample', 'k'), ('k', 'disjoint'), ('disjoint', 'subsets'), ('subsets', 'size'), ('size', ','), (',', 'i.e.-'), ('i.e.-', 'klslslsls'), ('klslslsls', '\uf0c8\uf0c8\uf03d'), ('\uf0c8\uf0c8\uf03d', '211'), ('211', '('), ('(', '2'), ('2', ')'), (')', 'A'), ('A', 'model'), ('model', 'inferred'), ('inferred', 'learning'), ('learning', 'algorithm'), ('algorithm', 'sample'), ('sample', 'ls\\ls'), ('ls\\ls', ','), (',', '='), ('=', '1'), ('1', ','), (',', '..'), ('..', ','), (',', 'k'), ('k', 'performance'), ('performance', 'determined'), ('determined', 'held'), ('held', 'sample'), ('sample', 'lsi'), ('lsi', '.')]

>> Trigrams are: 
 [('In', 'k-fold', 'cross-validation'), ('k-fold', 'cross-validation', 'scheme'), ('cross-validation', 'scheme', ','), ('scheme', ',', 'divide'), (',', 'divide', 'learning'), ('divide', 'learning', 'sample'), ('learning', 'sample', 'k'), ('sample', 'k', 'disjoint'), ('k', 'disjoint', 'subsets'), ('disjoint', 'subsets', 'size'), ('subsets', 'size', ','), ('size', ',', 'i.e.-'), (',', 'i.e.-', 'klslslsls'), ('i.e.-', 'klslslsls', '\uf0c8\uf0c8\uf03d'), ('klslslsls', '\uf0c8\uf0c8\uf03d', '211'), ('\uf0c8\uf0c8\uf03d', '211', '('), ('211', '(', '2'), ('(', '2', ')'), ('2', ')', 'A'), (')', 'A', 'model'), ('A', 'model', 'inferred'), ('model', 'inferred', 'learning'), ('inferred', 'learning', 'algorithm'), ('learning', 'algorithm', 'sample'), ('algorithm', 'sample', 'ls\\ls'), ('sample', 'ls\\ls', ','), ('ls\\ls', ',', '='), (',', '=', '1'), ('=', '1', ','), ('1', ',', '..'), (',', '..', ','), ('..', ',', 'k'), (',', 'k', 'performance'), ('k', 'performance', 'determined'), ('performance', 'determined', 'held'), ('determined', 'held', 'sample'), ('held', 'sample', 'lsi'), ('sample', 'lsi', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('k-fold', 'JJ'), ('cross-validation', 'NN'), ('scheme', 'NN'), (',', ','), ('divide', 'IN'), ('learning', 'VBG'), ('sample', 'JJ'), ('k', 'NNS'), ('disjoint', 'JJ'), ('subsets', 'NNS'), ('size', 'NN'), (',', ','), ('i.e.-', 'JJ'), ('klslslsls', 'NN'), ('\uf0c8\uf0c8\uf03d', '$'), ('211', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), ('A', 'DT'), ('model', 'NN'), ('inferred', 'JJ'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('sample', 'NN'), ('ls\\ls', 'NN'), (',', ','), ('=', "''"), ('1', 'CD'), (',', ','), ('..', 'NNP'), (',', ','), ('k', 'VBD'), ('performance', 'NN'), ('determined', 'VBD'), ('held', 'VBN'), ('sample', 'JJ'), ('lsi', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP k-fold/JJ cross-validation/NN scheme/NN)
  ,/,
  divide/IN
  learning/VBG
  (NP sample/JJ k/NNS)
  (NP disjoint/JJ subsets/NNS size/NN)
  ,/,
  (NP i.e.-/JJ klslslsls/NN)
  /$
  211/CD
  (/(
  2/CD
  )/)
  (NP A/DT model/NN)
  inferred/JJ
  learning/VBG
  (NP algorithm/JJ sample/NN ls\ls/NN)
  ,/,
  =/''
  1/CD
  ,/,
  (NP ../NNP)
  ,/,
  k/VBD
  (NP performance/NN)
  determined/VBD
  held/VBN
  (NP sample/JJ lsi/NN)
  ./.) 


>> Noun Phrases are: 
 ['k-fold cross-validation scheme', 'sample k', 'disjoint subsets size', 'i.e.- klslslsls', 'A model', 'algorithm sample ls\\ls', '..', 'performance', 'sample lsi']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-valid'), ('scheme', 'scheme'), (',', ','), ('divide', 'divid'), ('learning', 'learn'), ('sample', 'sampl'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-'), ('klslslsls', 'klslslsl'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')'), ('A', 'a'), ('model', 'model'), ('inferred', 'infer'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('sample', 'sampl'), ('ls\\ls', 'ls\\l'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'perform'), ('determined', 'determin'), ('held', 'held'), ('sample', 'sampl'), ('lsi', 'lsi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-valid'), ('scheme', 'scheme'), (',', ','), ('divide', 'divid'), ('learning', 'learn'), ('sample', 'sampl'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-'), ('klslslsls', 'klslslsls'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')'), ('A', 'a'), ('model', 'model'), ('inferred', 'infer'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('sample', 'sampl'), ('ls\\ls', 'ls\\ls'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'perform'), ('determined', 'determin'), ('held', 'held'), ('sample', 'sampl'), ('lsi', 'lsi'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-validation'), ('scheme', 'scheme'), (',', ','), ('divide', 'divide'), ('learning', 'learning'), ('sample', 'sample'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-'), ('klslslsls', 'klslslsls'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')'), ('A', 'A'), ('model', 'model'), ('inferred', 'inferred'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('sample', 'sample'), ('ls\\ls', 'ls\\ls'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'performance'), ('determined', 'determined'), ('held', 'held'), ('sample', 'sample'), ('lsi', 'lsi'), ('.', '.')]



============================ Sentence 60 =============================

Final performance is computed as the   average performance over all these models. 


>> Tokens are: 
 ['Final', 'performance', 'computed', 'average', 'performance', 'models', '.']

>> Bigrams are: 
 [('Final', 'performance'), ('performance', 'computed'), ('computed', 'average'), ('average', 'performance'), ('performance', 'models'), ('models', '.')]

>> Trigrams are: 
 [('Final', 'performance', 'computed'), ('performance', 'computed', 'average'), ('computed', 'average', 'performance'), ('average', 'performance', 'models'), ('performance', 'models', '.')]

>> POS Tags are: 
 [('Final', 'JJ'), ('performance', 'NN'), ('computed', 'VBD'), ('average', 'JJ'), ('performance', 'NN'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP Final/JJ performance/NN)
  computed/VBD
  (NP average/JJ performance/NN models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Final performance', 'average performance models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Final', 'final'), ('performance', 'perform'), ('computed', 'comput'), ('average', 'averag'), ('performance', 'perform'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Final', 'final'), ('performance', 'perform'), ('computed', 'comput'), ('average', 'averag'), ('performance', 'perform'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Final', 'Final'), ('performance', 'performance'), ('computed', 'computed'), ('average', 'average'), ('performance', 'performance'), ('models', 'model'), ('.', '.')]



============================ Sentence 61 =============================

Notice that when k is   equal to the number of objects in the learning sample, this   method is called leave-one-out. 


>> Tokens are: 
 ['Notice', 'k', 'equal', 'number', 'objects', 'learning', 'sample', ',', 'method', 'called', 'leave-one-out', '.']

>> Bigrams are: 
 [('Notice', 'k'), ('k', 'equal'), ('equal', 'number'), ('number', 'objects'), ('objects', 'learning'), ('learning', 'sample'), ('sample', ','), (',', 'method'), ('method', 'called'), ('called', 'leave-one-out'), ('leave-one-out', '.')]

>> Trigrams are: 
 [('Notice', 'k', 'equal'), ('k', 'equal', 'number'), ('equal', 'number', 'objects'), ('number', 'objects', 'learning'), ('objects', 'learning', 'sample'), ('learning', 'sample', ','), ('sample', ',', 'method'), (',', 'method', 'called'), ('method', 'called', 'leave-one-out'), ('called', 'leave-one-out', '.')]

>> POS Tags are: 
 [('Notice', 'NNP'), ('k', 'VBD'), ('equal', 'JJ'), ('number', 'NN'), ('objects', 'NNS'), ('learning', 'VBG'), ('sample', 'NN'), (',', ','), ('method', 'NN'), ('called', 'VBN'), ('leave-one-out', 'NN'), ('.', '.')]

 (S
  (NP Notice/NNP)
  k/VBD
  (NP equal/JJ number/NN objects/NNS)
  learning/VBG
  (NP sample/NN)
  ,/,
  (NP method/NN)
  called/VBN
  (NP leave-one-out/NN)
  ./.) 


>> Noun Phrases are: 
 ['Notice', 'equal number objects', 'sample', 'method', 'leave-one-out']

>> Named Entities are: 
 [('GPE', 'Notice')] 

>> Stemming using Porter Stemmer: 
 [('Notice', 'notic'), ('k', 'k'), ('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learn'), ('sample', 'sampl'), (',', ','), ('method', 'method'), ('called', 'call'), ('leave-one-out', 'leave-one-out'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Notice', 'notic'), ('k', 'k'), ('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learn'), ('sample', 'sampl'), (',', ','), ('method', 'method'), ('called', 'call'), ('leave-one-out', 'leave-one-out'), ('.', '.')]

>> Lemmatization: 
 [('Notice', 'Notice'), ('k', 'k'), ('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learning'), ('sample', 'sample'), (',', ','), ('method', 'method'), ('called', 'called'), ('leave-one-out', 'leave-one-out'), ('.', '.')]



============================ Sentence 62 =============================

Typically, smaller values of k   (10 or 20) are however preferred for computational reasons [7]. 


>> Tokens are: 
 ['Typically', ',', 'smaller', 'values', 'k', '(', '10', '20', ')', 'however', 'preferred', 'computational', 'reasons', '[', '7', ']', '.']

>> Bigrams are: 
 [('Typically', ','), (',', 'smaller'), ('smaller', 'values'), ('values', 'k'), ('k', '('), ('(', '10'), ('10', '20'), ('20', ')'), (')', 'however'), ('however', 'preferred'), ('preferred', 'computational'), ('computational', 'reasons'), ('reasons', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('Typically', ',', 'smaller'), (',', 'smaller', 'values'), ('smaller', 'values', 'k'), ('values', 'k', '('), ('k', '(', '10'), ('(', '10', '20'), ('10', '20', ')'), ('20', ')', 'however'), (')', 'however', 'preferred'), ('however', 'preferred', 'computational'), ('preferred', 'computational', 'reasons'), ('computational', 'reasons', '['), ('reasons', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('Typically', 'RB'), (',', ','), ('smaller', 'JJR'), ('values', 'NNS'), ('k', 'VBP'), ('(', '('), ('10', 'CD'), ('20', 'CD'), (')', ')'), ('however', 'RB'), ('preferred', 'JJ'), ('computational', 'JJ'), ('reasons', 'NNS'), ('[', 'VBP'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Typically/RB
  ,/,
  smaller/JJR
  (NP values/NNS)
  k/VBP
  (/(
  10/CD
  20/CD
  )/)
  however/RB
  (NP preferred/JJ computational/JJ reasons/NNS)
  [/VBP
  7/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['values', 'preferred computational reasons', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Typically', 'typic'), (',', ','), ('smaller', 'smaller'), ('values', 'valu'), ('k', 'k'), ('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'howev'), ('preferred', 'prefer'), ('computational', 'comput'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Typically', 'typic'), (',', ','), ('smaller', 'smaller'), ('values', 'valu'), ('k', 'k'), ('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'howev'), ('preferred', 'prefer'), ('computational', 'comput'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Typically', 'Typically'), (',', ','), ('smaller', 'smaller'), ('values', 'value'), ('k', 'k'), ('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'however'), ('preferred', 'preferred'), ('computational', 'computational'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



============================ Sentence 63 =============================

The comparison between supervised ML methods can be done   through to perform statistical comparisons of the accuracies of   trained classifiers on specific datasets. 


>> Tokens are: 
 ['The', 'comparison', 'supervised', 'ML', 'methods', 'done', 'perform', 'statistical', 'comparisons', 'accuracies', 'trained', 'classifiers', 'specific', 'datasets', '.']

>> Bigrams are: 
 [('The', 'comparison'), ('comparison', 'supervised'), ('supervised', 'ML'), ('ML', 'methods'), ('methods', 'done'), ('done', 'perform'), ('perform', 'statistical'), ('statistical', 'comparisons'), ('comparisons', 'accuracies'), ('accuracies', 'trained'), ('trained', 'classifiers'), ('classifiers', 'specific'), ('specific', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('The', 'comparison', 'supervised'), ('comparison', 'supervised', 'ML'), ('supervised', 'ML', 'methods'), ('ML', 'methods', 'done'), ('methods', 'done', 'perform'), ('done', 'perform', 'statistical'), ('perform', 'statistical', 'comparisons'), ('statistical', 'comparisons', 'accuracies'), ('comparisons', 'accuracies', 'trained'), ('accuracies', 'trained', 'classifiers'), ('trained', 'classifiers', 'specific'), ('classifiers', 'specific', 'datasets'), ('specific', 'datasets', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('comparison', 'NN'), ('supervised', 'VBD'), ('ML', 'NNP'), ('methods', 'NNS'), ('done', 'VBN'), ('perform', 'JJ'), ('statistical', 'JJ'), ('comparisons', 'NNS'), ('accuracies', 'NNS'), ('trained', 'VBD'), ('classifiers', 'NNS'), ('specific', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

 (S
  (NP The/DT comparison/NN)
  supervised/VBD
  (NP ML/NNP methods/NNS)
  done/VBN
  (NP perform/JJ statistical/JJ comparisons/NNS accuracies/NNS)
  trained/VBD
  (NP classifiers/NNS)
  (NP specific/JJ datasets/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The comparison', 'ML methods', 'perform statistical comparisons accuracies', 'classifiers', 'specific datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('comparison', 'comparison'), ('supervised', 'supervis'), ('ML', 'ml'), ('methods', 'method'), ('done', 'done'), ('perform', 'perform'), ('statistical', 'statist'), ('comparisons', 'comparison'), ('accuracies', 'accuraci'), ('trained', 'train'), ('classifiers', 'classifi'), ('specific', 'specif'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('comparison', 'comparison'), ('supervised', 'supervis'), ('ML', 'ml'), ('methods', 'method'), ('done', 'done'), ('perform', 'perform'), ('statistical', 'statist'), ('comparisons', 'comparison'), ('accuracies', 'accuraci'), ('trained', 'train'), ('classifiers', 'classifi'), ('specific', 'specif'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('comparison', 'comparison'), ('supervised', 'supervised'), ('ML', 'ML'), ('methods', 'method'), ('done', 'done'), ('perform', 'perform'), ('statistical', 'statistical'), ('comparisons', 'comparison'), ('accuracies', 'accuracy'), ('trained', 'trained'), ('classifiers', 'classifier'), ('specific', 'specific'), ('datasets', 'datasets'), ('.', '.')]



============================ Sentence 64 =============================

For doing this we can run   two different learning algorithms on samples of training set of size   N, estimate the difference in accuracy for each pair of classifiers   on a large test set[1]. 


>> Tokens are: 
 ['For', 'run', 'two', 'different', 'learning', 'algorithms', 'samples', 'training', 'set', 'size', 'N', ',', 'estimate', 'difference', 'accuracy', 'pair', 'classifiers', 'large', 'test', 'set', '[', '1', ']', '.']

>> Bigrams are: 
 [('For', 'run'), ('run', 'two'), ('two', 'different'), ('different', 'learning'), ('learning', 'algorithms'), ('algorithms', 'samples'), ('samples', 'training'), ('training', 'set'), ('set', 'size'), ('size', 'N'), ('N', ','), (',', 'estimate'), ('estimate', 'difference'), ('difference', 'accuracy'), ('accuracy', 'pair'), ('pair', 'classifiers'), ('classifiers', 'large'), ('large', 'test'), ('test', 'set'), ('set', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'run', 'two'), ('run', 'two', 'different'), ('two', 'different', 'learning'), ('different', 'learning', 'algorithms'), ('learning', 'algorithms', 'samples'), ('algorithms', 'samples', 'training'), ('samples', 'training', 'set'), ('training', 'set', 'size'), ('set', 'size', 'N'), ('size', 'N', ','), ('N', ',', 'estimate'), (',', 'estimate', 'difference'), ('estimate', 'difference', 'accuracy'), ('difference', 'accuracy', 'pair'), ('accuracy', 'pair', 'classifiers'), ('pair', 'classifiers', 'large'), ('classifiers', 'large', 'test'), ('large', 'test', 'set'), ('test', 'set', '['), ('set', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('run', 'VBN'), ('two', 'CD'), ('different', 'JJ'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('samples', 'NNS'), ('training', 'VBG'), ('set', 'VBN'), ('size', 'NN'), ('N', 'NNP'), (',', ','), ('estimate', 'NN'), ('difference', 'NN'), ('accuracy', 'NN'), ('pair', 'NN'), ('classifiers', 'NNS'), ('large', 'JJ'), ('test', 'NN'), ('set', 'VBN'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  run/VBN
  two/CD
  different/JJ
  learning/VBG
  (NP algorithms/JJ samples/NNS)
  training/VBG
  set/VBN
  (NP size/NN N/NNP)
  ,/,
  (NP estimate/NN difference/NN accuracy/NN pair/NN classifiers/NNS)
  (NP large/JJ test/NN)
  set/VBN
  [/$
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['algorithms samples', 'size N', 'estimate difference accuracy pair classifiers', 'large test', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('run', 'run'), ('two', 'two'), ('different', 'differ'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('samples', 'sampl'), ('training', 'train'), ('set', 'set'), ('size', 'size'), ('N', 'n'), (',', ','), ('estimate', 'estim'), ('difference', 'differ'), ('accuracy', 'accuraci'), ('pair', 'pair'), ('classifiers', 'classifi'), ('large', 'larg'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('run', 'run'), ('two', 'two'), ('different', 'differ'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('samples', 'sampl'), ('training', 'train'), ('set', 'set'), ('size', 'size'), ('N', 'n'), (',', ','), ('estimate', 'estim'), ('difference', 'differ'), ('accuracy', 'accuraci'), ('pair', 'pair'), ('classifiers', 'classifi'), ('large', 'larg'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('run', 'run'), ('two', 'two'), ('different', 'different'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('samples', 'sample'), ('training', 'training'), ('set', 'set'), ('size', 'size'), ('N', 'N'), (',', ','), ('estimate', 'estimate'), ('difference', 'difference'), ('accuracy', 'accuracy'), ('pair', 'pair'), ('classifiers', 'classifier'), ('large', 'large'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 65 =============================

For classification of data, a good number of   techniques have been developed by researchers, such as logical   statistics based techniques. 


>> Tokens are: 
 ['For', 'classification', 'data', ',', 'good', 'number', 'techniques', 'developed', 'researchers', ',', 'logical', 'statistics', 'based', 'techniques', '.']

>> Bigrams are: 
 [('For', 'classification'), ('classification', 'data'), ('data', ','), (',', 'good'), ('good', 'number'), ('number', 'techniques'), ('techniques', 'developed'), ('developed', 'researchers'), ('researchers', ','), (',', 'logical'), ('logical', 'statistics'), ('statistics', 'based'), ('based', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('For', 'classification', 'data'), ('classification', 'data', ','), ('data', ',', 'good'), (',', 'good', 'number'), ('good', 'number', 'techniques'), ('number', 'techniques', 'developed'), ('techniques', 'developed', 'researchers'), ('developed', 'researchers', ','), ('researchers', ',', 'logical'), (',', 'logical', 'statistics'), ('logical', 'statistics', 'based'), ('statistics', 'based', 'techniques'), ('based', 'techniques', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('classification', 'NN'), ('data', 'NNS'), (',', ','), ('good', 'JJ'), ('number', 'NN'), ('techniques', 'NNS'), ('developed', 'VBD'), ('researchers', 'NNS'), (',', ','), ('logical', 'JJ'), ('statistics', 'NNS'), ('based', 'VBN'), ('techniques', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP classification/NN data/NNS)
  ,/,
  (NP good/JJ number/NN techniques/NNS)
  developed/VBD
  (NP researchers/NNS)
  ,/,
  (NP logical/JJ statistics/NNS)
  based/VBN
  (NP techniques/NNS)
  ./.) 


>> Noun Phrases are: 
 ['classification data', 'good number techniques', 'researchers', 'logical statistics', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number'), ('techniques', 'techniqu'), ('developed', 'develop'), ('researchers', 'research'), (',', ','), ('logical', 'logic'), ('statistics', 'statist'), ('based', 'base'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number'), ('techniques', 'techniqu'), ('developed', 'develop'), ('researchers', 'research'), (',', ','), ('logical', 'logic'), ('statistics', 'statist'), ('based', 'base'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('classification', 'classification'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number'), ('techniques', 'technique'), ('developed', 'developed'), ('researchers', 'researcher'), (',', ','), ('logical', 'logical'), ('statistics', 'statistic'), ('based', 'based'), ('techniques', 'technique'), ('.', '.')]



============================ Sentence 66 =============================

In next sections, we will precisely   discuss the most important supervised machine learning   techniques, starting with logical techniques [1]. 


>> Tokens are: 
 ['In', 'next', 'sections', ',', 'precisely', 'discuss', 'important', 'supervised', 'machine', 'learning', 'techniques', ',', 'starting', 'logical', 'techniques', '[', '1', ']', '.']

>> Bigrams are: 
 [('In', 'next'), ('next', 'sections'), ('sections', ','), (',', 'precisely'), ('precisely', 'discuss'), ('discuss', 'important'), ('important', 'supervised'), ('supervised', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'starting'), ('starting', 'logical'), ('logical', 'techniques'), ('techniques', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'next', 'sections'), ('next', 'sections', ','), ('sections', ',', 'precisely'), (',', 'precisely', 'discuss'), ('precisely', 'discuss', 'important'), ('discuss', 'important', 'supervised'), ('important', 'supervised', 'machine'), ('supervised', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'starting'), (',', 'starting', 'logical'), ('starting', 'logical', 'techniques'), ('logical', 'techniques', '['), ('techniques', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('sections', 'NNS'), (',', ','), ('precisely', 'RB'), ('discuss', 'JJ'), ('important', 'JJ'), ('supervised', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('starting', 'VBG'), ('logical', 'JJ'), ('techniques', 'NNS'), ('[', 'VBP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP next/JJ sections/NNS)
  ,/,
  precisely/RB
  discuss/JJ
  important/JJ
  supervised/VBN
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  starting/VBG
  (NP logical/JJ techniques/NNS)
  [/VBP
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['next sections', 'machine', 'techniques', 'logical techniques', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precis'), ('discuss', 'discuss'), ('important', 'import'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('starting', 'start'), ('logical', 'logic'), ('techniques', 'techniqu'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precis'), ('discuss', 'discuss'), ('important', 'import'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('starting', 'start'), ('logical', 'logic'), ('techniques', 'techniqu'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precisely'), ('discuss', 'discus'), ('important', 'important'), ('supervised', 'supervised'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('starting', 'starting'), ('logical', 'logical'), ('techniques', 'technique'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 67 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 68 =============================

LOGIC BASED ALGORITHMS    In this section we will discuss two logical (symbolic)   learning methods: decision trees and rule-based classifiers. 


>> Tokens are: 
 ['LOGIC', 'BASED', 'ALGORITHMS', 'In', 'section', 'discuss', 'two', 'logical', '(', 'symbolic', ')', 'learning', 'methods', ':', 'decision', 'trees', 'rule-based', 'classifiers', '.']

>> Bigrams are: 
 [('LOGIC', 'BASED'), ('BASED', 'ALGORITHMS'), ('ALGORITHMS', 'In'), ('In', 'section'), ('section', 'discuss'), ('discuss', 'two'), ('two', 'logical'), ('logical', '('), ('(', 'symbolic'), ('symbolic', ')'), (')', 'learning'), ('learning', 'methods'), ('methods', ':'), (':', 'decision'), ('decision', 'trees'), ('trees', 'rule-based'), ('rule-based', 'classifiers'), ('classifiers', '.')]

>> Trigrams are: 
 [('LOGIC', 'BASED', 'ALGORITHMS'), ('BASED', 'ALGORITHMS', 'In'), ('ALGORITHMS', 'In', 'section'), ('In', 'section', 'discuss'), ('section', 'discuss', 'two'), ('discuss', 'two', 'logical'), ('two', 'logical', '('), ('logical', '(', 'symbolic'), ('(', 'symbolic', ')'), ('symbolic', ')', 'learning'), (')', 'learning', 'methods'), ('learning', 'methods', ':'), ('methods', ':', 'decision'), (':', 'decision', 'trees'), ('decision', 'trees', 'rule-based'), ('trees', 'rule-based', 'classifiers'), ('rule-based', 'classifiers', '.')]

>> POS Tags are: 
 [('LOGIC', 'NNP'), ('BASED', 'NNP'), ('ALGORITHMS', 'NNP'), ('In', 'IN'), ('section', 'NN'), ('discuss', 'NN'), ('two', 'CD'), ('logical', 'JJ'), ('(', '('), ('symbolic', 'JJ'), (')', ')'), ('learning', 'VBG'), ('methods', 'NNS'), (':', ':'), ('decision', 'NN'), ('trees', 'NNS'), ('rule-based', 'JJ'), ('classifiers', 'NNS'), ('.', '.')]

 (S
  (NP LOGIC/NNP BASED/NNP ALGORITHMS/NNP)
  In/IN
  (NP section/NN discuss/NN)
  two/CD
  logical/JJ
  (/(
  symbolic/JJ
  )/)
  learning/VBG
  (NP methods/NNS)
  :/:
  (NP decision/NN trees/NNS)
  (NP rule-based/JJ classifiers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['LOGIC BASED ALGORITHMS', 'section discuss', 'methods', 'decision trees', 'rule-based classifiers']

>> Named Entities are: 
 [('ORGANIZATION', 'LOGIC'), ('ORGANIZATION', 'BASED')] 

>> Stemming using Porter Stemmer: 
 [('LOGIC', 'logic'), ('BASED', 'base'), ('ALGORITHMS', 'algorithm'), ('In', 'in'), ('section', 'section'), ('discuss', 'discuss'), ('two', 'two'), ('logical', 'logic'), ('(', '('), ('symbolic', 'symbol'), (')', ')'), ('learning', 'learn'), ('methods', 'method'), (':', ':'), ('decision', 'decis'), ('trees', 'tree'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LOGIC', 'logic'), ('BASED', 'base'), ('ALGORITHMS', 'algorithm'), ('In', 'in'), ('section', 'section'), ('discuss', 'discuss'), ('two', 'two'), ('logical', 'logic'), ('(', '('), ('symbolic', 'symbol'), (')', ')'), ('learning', 'learn'), ('methods', 'method'), (':', ':'), ('decision', 'decis'), ('trees', 'tree'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('LOGIC', 'LOGIC'), ('BASED', 'BASED'), ('ALGORITHMS', 'ALGORITHMS'), ('In', 'In'), ('section', 'section'), ('discuss', 'discus'), ('two', 'two'), ('logical', 'logical'), ('(', '('), ('symbolic', 'symbolic'), (')', ')'), ('learning', 'learning'), ('methods', 'method'), (':', ':'), ('decision', 'decision'), ('trees', 'tree'), ('rule-based', 'rule-based'), ('classifiers', 'classifier'), ('.', '.')]



============================ Sentence 69 =============================

3.1 DECISION TREES   In machine learning domain the Decision Tree Induction [8,   9] is currently one of the most important supervised learning   algorithms. 


>> Tokens are: 
 ['3.1', 'DECISION', 'TREES', 'In', 'machine', 'learning', 'domain', 'Decision', 'Tree', 'Induction', '[', '8', ',', '9', ']', 'currently', 'one', 'important', 'supervised', 'learning', 'algorithms', '.']

>> Bigrams are: 
 [('3.1', 'DECISION'), ('DECISION', 'TREES'), ('TREES', 'In'), ('In', 'machine'), ('machine', 'learning'), ('learning', 'domain'), ('domain', 'Decision'), ('Decision', 'Tree'), ('Tree', 'Induction'), ('Induction', '['), ('[', '8'), ('8', ','), (',', '9'), ('9', ']'), (']', 'currently'), ('currently', 'one'), ('one', 'important'), ('important', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('3.1', 'DECISION', 'TREES'), ('DECISION', 'TREES', 'In'), ('TREES', 'In', 'machine'), ('In', 'machine', 'learning'), ('machine', 'learning', 'domain'), ('learning', 'domain', 'Decision'), ('domain', 'Decision', 'Tree'), ('Decision', 'Tree', 'Induction'), ('Tree', 'Induction', '['), ('Induction', '[', '8'), ('[', '8', ','), ('8', ',', '9'), (',', '9', ']'), ('9', ']', 'currently'), (']', 'currently', 'one'), ('currently', 'one', 'important'), ('one', 'important', 'supervised'), ('important', 'supervised', 'learning'), ('supervised', 'learning', 'algorithms'), ('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('3.1', 'CD'), ('DECISION', 'NNP'), ('TREES', 'NNP'), ('In', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('domain', 'NN'), ('Decision', 'NNP'), ('Tree', 'NNP'), ('Induction', 'NNP'), ('[', 'NNP'), ('8', 'CD'), (',', ','), ('9', 'CD'), (']', 'NN'), ('currently', 'RB'), ('one', 'CD'), ('important', 'JJ'), ('supervised', 'VBD'), ('learning', 'JJ'), ('algorithms', 'NN'), ('.', '.')]

 (S
  3.1/CD
  (NP DECISION/NNP TREES/NNP)
  In/IN
  (NP
    machine/NN
    learning/NN
    domain/NN
    Decision/NNP
    Tree/NNP
    Induction/NNP
    [/NNP)
  8/CD
  ,/,
  9/CD
  (NP ]/NN)
  currently/RB
  one/CD
  important/JJ
  supervised/VBD
  (NP learning/JJ algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['DECISION TREES', 'machine learning domain Decision Tree Induction [', ']', 'learning algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3.1', '3.1'), ('DECISION', 'decis'), ('TREES', 'tree'), ('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('domain', 'domain'), ('Decision', 'decis'), ('Tree', 'tree'), ('Induction', 'induct'), ('[', '['), ('8', '8'), (',', ','), ('9', '9'), (']', ']'), ('currently', 'current'), ('one', 'one'), ('important', 'import'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3.1', '3.1'), ('DECISION', 'decis'), ('TREES', 'tree'), ('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('domain', 'domain'), ('Decision', 'decis'), ('Tree', 'tree'), ('Induction', 'induct'), ('[', '['), ('8', '8'), (',', ','), ('9', '9'), (']', ']'), ('currently', 'current'), ('one', 'one'), ('important', 'import'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('3.1', '3.1'), ('DECISION', 'DECISION'), ('TREES', 'TREES'), ('In', 'In'), ('machine', 'machine'), ('learning', 'learning'), ('domain', 'domain'), ('Decision', 'Decision'), ('Tree', 'Tree'), ('Induction', 'Induction'), ('[', '['), ('8', '8'), (',', ','), ('9', '9'), (']', ']'), ('currently', 'currently'), ('one', 'one'), ('important', 'important'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 70 =============================

In Artificial Intelligence (AI) field, Quinlan has   contributed through his ID3 and C4.5 algorithms. 


>> Tokens are: 
 ['In', 'Artificial', 'Intelligence', '(', 'AI', ')', 'field', ',', 'Quinlan', 'contributed', 'ID3', 'C4.5', 'algorithms', '.']

>> Bigrams are: 
 [('In', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', '('), ('(', 'AI'), ('AI', ')'), (')', 'field'), ('field', ','), (',', 'Quinlan'), ('Quinlan', 'contributed'), ('contributed', 'ID3'), ('ID3', 'C4.5'), ('C4.5', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('In', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', '('), ('Intelligence', '(', 'AI'), ('(', 'AI', ')'), ('AI', ')', 'field'), (')', 'field', ','), ('field', ',', 'Quinlan'), (',', 'Quinlan', 'contributed'), ('Quinlan', 'contributed', 'ID3'), ('contributed', 'ID3', 'C4.5'), ('ID3', 'C4.5', 'algorithms'), ('C4.5', 'algorithms', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('field', 'NN'), (',', ','), ('Quinlan', 'NNP'), ('contributed', 'VBD'), ('ID3', 'NNP'), ('C4.5', 'NNP'), ('algorithms', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP Artificial/NNP Intelligence/NNP)
  (/(
  (NP AI/NNP)
  )/)
  (NP field/NN)
  ,/,
  (NP Quinlan/NNP)
  contributed/VBD
  (NP ID3/NNP C4.5/NNP algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['Artificial Intelligence', 'AI', 'field', 'Quinlan', 'ID3 C4.5 algorithms']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial Intelligence'), ('PERSON', 'Quinlan'), ('ORGANIZATION', 'ID3')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'quinlan'), ('contributed', 'contribut'), ('ID3', 'id3'), ('C4.5', 'c4.5'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'quinlan'), ('contributed', 'contribut'), ('ID3', 'id3'), ('C4.5', 'c4.5'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('(', '('), ('AI', 'AI'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'Quinlan'), ('contributed', 'contributed'), ('ID3', 'ID3'), ('C4.5', 'C4.5'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 71 =============================

C4.5 is one of   the most popular and the efficient method in decision tree-based   approach. 


>> Tokens are: 
 ['C4.5', 'one', 'popular', 'efficient', 'method', 'decision', 'tree-based', 'approach', '.']

>> Bigrams are: 
 [('C4.5', 'one'), ('one', 'popular'), ('popular', 'efficient'), ('efficient', 'method'), ('method', 'decision'), ('decision', 'tree-based'), ('tree-based', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('C4.5', 'one', 'popular'), ('one', 'popular', 'efficient'), ('popular', 'efficient', 'method'), ('efficient', 'method', 'decision'), ('method', 'decision', 'tree-based'), ('decision', 'tree-based', 'approach'), ('tree-based', 'approach', '.')]

>> POS Tags are: 
 [('C4.5', 'NNP'), ('one', 'CD'), ('popular', 'JJ'), ('efficient', 'NN'), ('method', 'NN'), ('decision', 'NN'), ('tree-based', 'JJ'), ('approach', 'NN'), ('.', '.')]

 (S
  (NP C4.5/NNP)
  one/CD
  (NP popular/JJ efficient/NN method/NN decision/NN)
  (NP tree-based/JJ approach/NN)
  ./.) 


>> Noun Phrases are: 
 ['C4.5', 'popular efficient method decision', 'tree-based approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('C4.5', 'c4.5'), ('one', 'one'), ('popular', 'popular'), ('efficient', 'effici'), ('method', 'method'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('C4.5', 'c4.5'), ('one', 'one'), ('popular', 'popular'), ('efficient', 'effici'), ('method', 'method'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('C4.5', 'C4.5'), ('one', 'one'), ('popular', 'popular'), ('efficient', 'efficient'), ('method', 'method'), ('decision', 'decision'), ('tree-based', 'tree-based'), ('approach', 'approach'), ('.', '.')]



============================ Sentence 72 =============================

Here C4.5 algorithm creates a tree model by using   values of only one attribute at a time [10]. 


>> Tokens are: 
 ['Here', 'C4.5', 'algorithm', 'creates', 'tree', 'model', 'using', 'values', 'one', 'attribute', 'time', '[', '10', ']', '.']

>> Bigrams are: 
 [('Here', 'C4.5'), ('C4.5', 'algorithm'), ('algorithm', 'creates'), ('creates', 'tree'), ('tree', 'model'), ('model', 'using'), ('using', 'values'), ('values', 'one'), ('one', 'attribute'), ('attribute', 'time'), ('time', '['), ('[', '10'), ('10', ']'), (']', '.')]

>> Trigrams are: 
 [('Here', 'C4.5', 'algorithm'), ('C4.5', 'algorithm', 'creates'), ('algorithm', 'creates', 'tree'), ('creates', 'tree', 'model'), ('tree', 'model', 'using'), ('model', 'using', 'values'), ('using', 'values', 'one'), ('values', 'one', 'attribute'), ('one', 'attribute', 'time'), ('attribute', 'time', '['), ('time', '[', '10'), ('[', '10', ']'), ('10', ']', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('C4.5', 'NNP'), ('algorithm', 'NN'), ('creates', 'VBZ'), ('tree', 'JJ'), ('model', 'NN'), ('using', 'VBG'), ('values', 'NNS'), ('one', 'CD'), ('attribute', 'NN'), ('time', 'NN'), ('[', 'VBZ'), ('10', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Here/RB
  (NP C4.5/NNP algorithm/NN)
  creates/VBZ
  (NP tree/JJ model/NN)
  using/VBG
  (NP values/NNS)
  one/CD
  (NP attribute/NN time/NN)
  [/VBZ
  10/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['C4.5 algorithm', 'tree model', 'values', 'attribute time', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('C4.5', 'c4.5'), ('algorithm', 'algorithm'), ('creates', 'creat'), ('tree', 'tree'), ('model', 'model'), ('using', 'use'), ('values', 'valu'), ('one', 'one'), ('attribute', 'attribut'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('C4.5', 'c4.5'), ('algorithm', 'algorithm'), ('creates', 'creat'), ('tree', 'tree'), ('model', 'model'), ('using', 'use'), ('values', 'valu'), ('one', 'one'), ('attribute', 'attribut'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('C4.5', 'C4.5'), ('algorithm', 'algorithm'), ('creates', 'creates'), ('tree', 'tree'), ('model', 'model'), ('using', 'using'), ('values', 'value'), ('one', 'one'), ('attribute', 'attribute'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]



============================ Sentence 73 =============================

According to authors   [7], the decision tree induction, which was initially designed to   solve classification problems, has been extended to deal with   single or multi-dimensional regression. 


>> Tokens are: 
 ['According', 'authors', '[', '7', ']', ',', 'decision', 'tree', 'induction', ',', 'initially', 'designed', 'solve', 'classification', 'problems', ',', 'extended', 'deal', 'single', 'multi-dimensional', 'regression', '.']

>> Bigrams are: 
 [('According', 'authors'), ('authors', '['), ('[', '7'), ('7', ']'), (']', ','), (',', 'decision'), ('decision', 'tree'), ('tree', 'induction'), ('induction', ','), (',', 'initially'), ('initially', 'designed'), ('designed', 'solve'), ('solve', 'classification'), ('classification', 'problems'), ('problems', ','), (',', 'extended'), ('extended', 'deal'), ('deal', 'single'), ('single', 'multi-dimensional'), ('multi-dimensional', 'regression'), ('regression', '.')]

>> Trigrams are: 
 [('According', 'authors', '['), ('authors', '[', '7'), ('[', '7', ']'), ('7', ']', ','), (']', ',', 'decision'), (',', 'decision', 'tree'), ('decision', 'tree', 'induction'), ('tree', 'induction', ','), ('induction', ',', 'initially'), (',', 'initially', 'designed'), ('initially', 'designed', 'solve'), ('designed', 'solve', 'classification'), ('solve', 'classification', 'problems'), ('classification', 'problems', ','), ('problems', ',', 'extended'), (',', 'extended', 'deal'), ('extended', 'deal', 'single'), ('deal', 'single', 'multi-dimensional'), ('single', 'multi-dimensional', 'regression'), ('multi-dimensional', 'regression', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('authors', 'NNS'), ('[', 'VBP'), ('7', 'CD'), (']', 'NN'), (',', ','), ('decision', 'NN'), ('tree', 'NN'), ('induction', 'NN'), (',', ','), ('initially', 'RB'), ('designed', 'VBN'), ('solve', 'JJ'), ('classification', 'NN'), ('problems', 'NNS'), (',', ','), ('extended', 'VBD'), ('deal', 'NN'), ('single', 'JJ'), ('multi-dimensional', 'JJ'), ('regression', 'NN'), ('.', '.')]

 (S
  According/VBG
  (NP authors/NNS)
  [/VBP
  7/CD
  (NP ]/NN)
  ,/,
  (NP decision/NN tree/NN induction/NN)
  ,/,
  initially/RB
  designed/VBN
  (NP solve/JJ classification/NN problems/NNS)
  ,/,
  extended/VBD
  (NP deal/NN)
  (NP single/JJ multi-dimensional/JJ regression/NN)
  ./.) 


>> Noun Phrases are: 
 ['authors', ']', 'decision tree induction', 'solve classification problems', 'deal', 'single multi-dimensional regression']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('authors', 'author'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decis'), ('tree', 'tree'), ('induction', 'induct'), (',', ','), ('initially', 'initi'), ('designed', 'design'), ('solve', 'solv'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('extended', 'extend'), ('deal', 'deal'), ('single', 'singl'), ('multi-dimensional', 'multi-dimension'), ('regression', 'regress'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('authors', 'author'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decis'), ('tree', 'tree'), ('induction', 'induct'), (',', ','), ('initially', 'initi'), ('designed', 'design'), ('solve', 'solv'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('extended', 'extend'), ('deal', 'deal'), ('single', 'singl'), ('multi-dimensional', 'multi-dimension'), ('regression', 'regress'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('authors', 'author'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decision'), ('tree', 'tree'), ('induction', 'induction'), (',', ','), ('initially', 'initially'), ('designed', 'designed'), ('solve', 'solve'), ('classification', 'classification'), ('problems', 'problem'), (',', ','), ('extended', 'extended'), ('deal', 'deal'), ('single', 'single'), ('multi-dimensional', 'multi-dimensional'), ('regression', 'regression'), ('.', '.')]



============================ Sentence 74 =============================

The major benefits of   decision trees are (i) produce intensive results, (ii) easy to  understand, (iii) and holds well-organized knowledge structure  [28]. 


>> Tokens are: 
 ['The', 'major', 'benefits', 'decision', 'trees', '(', ')', 'produce', 'intensive', 'results', ',', '(', 'ii', ')', 'easy', 'understand', ',', '(', 'iii', ')', 'holds', 'well-organized', 'knowledge', 'structure', '[', '28', ']', '.']

>> Bigrams are: 
 [('The', 'major'), ('major', 'benefits'), ('benefits', 'decision'), ('decision', 'trees'), ('trees', '('), ('(', ')'), (')', 'produce'), ('produce', 'intensive'), ('intensive', 'results'), ('results', ','), (',', '('), ('(', 'ii'), ('ii', ')'), (')', 'easy'), ('easy', 'understand'), ('understand', ','), (',', '('), ('(', 'iii'), ('iii', ')'), (')', 'holds'), ('holds', 'well-organized'), ('well-organized', 'knowledge'), ('knowledge', 'structure'), ('structure', '['), ('[', '28'), ('28', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'major', 'benefits'), ('major', 'benefits', 'decision'), ('benefits', 'decision', 'trees'), ('decision', 'trees', '('), ('trees', '(', ')'), ('(', ')', 'produce'), (')', 'produce', 'intensive'), ('produce', 'intensive', 'results'), ('intensive', 'results', ','), ('results', ',', '('), (',', '(', 'ii'), ('(', 'ii', ')'), ('ii', ')', 'easy'), (')', 'easy', 'understand'), ('easy', 'understand', ','), ('understand', ',', '('), (',', '(', 'iii'), ('(', 'iii', ')'), ('iii', ')', 'holds'), (')', 'holds', 'well-organized'), ('holds', 'well-organized', 'knowledge'), ('well-organized', 'knowledge', 'structure'), ('knowledge', 'structure', '['), ('structure', '[', '28'), ('[', '28', ']'), ('28', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('major', 'JJ'), ('benefits', 'NNS'), ('decision', 'NN'), ('trees', 'NNS'), ('(', '('), (')', ')'), ('produce', 'VBP'), ('intensive', 'JJ'), ('results', 'NNS'), (',', ','), ('(', '('), ('ii', 'NN'), (')', ')'), ('easy', 'JJ'), ('understand', 'NN'), (',', ','), ('(', '('), ('iii', 'NN'), (')', ')'), ('holds', 'VBZ'), ('well-organized', 'JJ'), ('knowledge', 'NN'), ('structure', 'NN'), ('[', 'VBZ'), ('28', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP The/DT major/JJ benefits/NNS decision/NN trees/NNS)
  (/(
  )/)
  produce/VBP
  (NP intensive/JJ results/NNS)
  ,/,
  (/(
  (NP ii/NN)
  )/)
  (NP easy/JJ understand/NN)
  ,/,
  (/(
  (NP iii/NN)
  )/)
  holds/VBZ
  (NP well-organized/JJ knowledge/NN structure/NN)
  [/VBZ
  28/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['The major benefits decision trees', 'intensive results', 'ii', 'easy understand', 'iii', 'well-organized knowledge structure', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('major', 'major'), ('benefits', 'benefit'), ('decision', 'decis'), ('trees', 'tree'), ('(', '('), (')', ')'), ('produce', 'produc'), ('intensive', 'intens'), ('results', 'result'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('easy', 'easi'), ('understand', 'understand'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organ'), ('knowledge', 'knowledg'), ('structure', 'structur'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('major', 'major'), ('benefits', 'benefit'), ('decision', 'decis'), ('trees', 'tree'), ('(', '('), (')', ')'), ('produce', 'produc'), ('intensive', 'intens'), ('results', 'result'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('easy', 'easi'), ('understand', 'understand'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organ'), ('knowledge', 'knowledg'), ('structure', 'structur'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('major', 'major'), ('benefits', 'benefit'), ('decision', 'decision'), ('trees', 'tree'), ('(', '('), (')', ')'), ('produce', 'produce'), ('intensive', 'intensive'), ('results', 'result'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('easy', 'easy'), ('understand', 'understand'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organized'), ('knowledge', 'knowledge'), ('structure', 'structure'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]



============================ Sentence 75 =============================

Decision Trees (DT) are trees that classify instances by   sorting them based on feature values, where each node in a   decision tree represents a feature in an instance to be classified,   and each branch represents a value that the node can assume [1]. 


>> Tokens are: 
 ['Decision', 'Trees', '(', 'DT', ')', 'trees', 'classify', 'instances', 'sorting', 'based', 'feature', 'values', ',', 'node', 'decision', 'tree', 'represents', 'feature', 'instance', 'classified', ',', 'branch', 'represents', 'value', 'node', 'assume', '[', '1', ']', '.']

>> Bigrams are: 
 [('Decision', 'Trees'), ('Trees', '('), ('(', 'DT'), ('DT', ')'), (')', 'trees'), ('trees', 'classify'), ('classify', 'instances'), ('instances', 'sorting'), ('sorting', 'based'), ('based', 'feature'), ('feature', 'values'), ('values', ','), (',', 'node'), ('node', 'decision'), ('decision', 'tree'), ('tree', 'represents'), ('represents', 'feature'), ('feature', 'instance'), ('instance', 'classified'), ('classified', ','), (',', 'branch'), ('branch', 'represents'), ('represents', 'value'), ('value', 'node'), ('node', 'assume'), ('assume', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Decision', 'Trees', '('), ('Trees', '(', 'DT'), ('(', 'DT', ')'), ('DT', ')', 'trees'), (')', 'trees', 'classify'), ('trees', 'classify', 'instances'), ('classify', 'instances', 'sorting'), ('instances', 'sorting', 'based'), ('sorting', 'based', 'feature'), ('based', 'feature', 'values'), ('feature', 'values', ','), ('values', ',', 'node'), (',', 'node', 'decision'), ('node', 'decision', 'tree'), ('decision', 'tree', 'represents'), ('tree', 'represents', 'feature'), ('represents', 'feature', 'instance'), ('feature', 'instance', 'classified'), ('instance', 'classified', ','), ('classified', ',', 'branch'), (',', 'branch', 'represents'), ('branch', 'represents', 'value'), ('represents', 'value', 'node'), ('value', 'node', 'assume'), ('node', 'assume', '['), ('assume', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Decision', 'NN'), ('Trees', 'NNP'), ('(', '('), ('DT', 'NNP'), (')', ')'), ('trees', 'VBZ'), ('classify', 'JJ'), ('instances', 'NNS'), ('sorting', 'VBG'), ('based', 'VBN'), ('feature', 'NN'), ('values', 'NNS'), (',', ','), ('node', 'JJ'), ('decision', 'NN'), ('tree', 'NN'), ('represents', 'VBZ'), ('feature', 'JJ'), ('instance', 'NN'), ('classified', 'VBD'), (',', ','), ('branch', 'NN'), ('represents', 'VBZ'), ('value', 'NN'), ('node', 'NN'), ('assume', 'VBP'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Decision/NN Trees/NNP)
  (/(
  (NP DT/NNP)
  )/)
  trees/VBZ
  (NP classify/JJ instances/NNS)
  sorting/VBG
  based/VBN
  (NP feature/NN values/NNS)
  ,/,
  (NP node/JJ decision/NN tree/NN)
  represents/VBZ
  (NP feature/JJ instance/NN)
  classified/VBD
  ,/,
  (NP branch/NN)
  represents/VBZ
  (NP value/NN node/NN)
  assume/VBP
  [/$
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Decision Trees', 'DT', 'classify instances', 'feature values', 'node decision tree', 'feature instance', 'branch', 'value node', ']']

>> Named Entities are: 
 [('GPE', 'Trees')] 

>> Stemming using Porter Stemmer: 
 [('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), ('trees', 'tree'), ('classify', 'classifi'), ('instances', 'instanc'), ('sorting', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('node', 'node'), ('decision', 'decis'), ('tree', 'tree'), ('represents', 'repres'), ('feature', 'featur'), ('instance', 'instanc'), ('classified', 'classifi'), (',', ','), ('branch', 'branch'), ('represents', 'repres'), ('value', 'valu'), ('node', 'node'), ('assume', 'assum'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), ('trees', 'tree'), ('classify', 'classifi'), ('instances', 'instanc'), ('sorting', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('node', 'node'), ('decision', 'decis'), ('tree', 'tree'), ('represents', 'repres'), ('feature', 'featur'), ('instance', 'instanc'), ('classified', 'classifi'), (',', ','), ('branch', 'branch'), ('represents', 'repres'), ('value', 'valu'), ('node', 'node'), ('assume', 'assum'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Decision', 'Decision'), ('Trees', 'Trees'), ('(', '('), ('DT', 'DT'), (')', ')'), ('trees', 'tree'), ('classify', 'classify'), ('instances', 'instance'), ('sorting', 'sorting'), ('based', 'based'), ('feature', 'feature'), ('values', 'value'), (',', ','), ('node', 'node'), ('decision', 'decision'), ('tree', 'tree'), ('represents', 'represents'), ('feature', 'feature'), ('instance', 'instance'), ('classified', 'classified'), (',', ','), ('branch', 'branch'), ('represents', 'represents'), ('value', 'value'), ('node', 'node'), ('assume', 'assume'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 76 =============================

Instances are classified starting at the root node and sorted based   on their feature values. 


>> Tokens are: 
 ['Instances', 'classified', 'starting', 'root', 'node', 'sorted', 'based', 'feature', 'values', '.']

>> Bigrams are: 
 [('Instances', 'classified'), ('classified', 'starting'), ('starting', 'root'), ('root', 'node'), ('node', 'sorted'), ('sorted', 'based'), ('based', 'feature'), ('feature', 'values'), ('values', '.')]

>> Trigrams are: 
 [('Instances', 'classified', 'starting'), ('classified', 'starting', 'root'), ('starting', 'root', 'node'), ('root', 'node', 'sorted'), ('node', 'sorted', 'based'), ('sorted', 'based', 'feature'), ('based', 'feature', 'values'), ('feature', 'values', '.')]

>> POS Tags are: 
 [('Instances', 'NNS'), ('classified', 'VBD'), ('starting', 'VBG'), ('root', 'NN'), ('node', 'RB'), ('sorted', 'VBD'), ('based', 'VBN'), ('feature', 'NN'), ('values', 'NNS'), ('.', '.')]

 (S
  (NP Instances/NNS)
  classified/VBD
  starting/VBG
  (NP root/NN)
  node/RB
  sorted/VBD
  based/VBN
  (NP feature/NN values/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Instances', 'root', 'feature values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instances', 'instanc'), ('classified', 'classifi'), ('starting', 'start'), ('root', 'root'), ('node', 'node'), ('sorted', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Instances', 'instanc'), ('classified', 'classifi'), ('starting', 'start'), ('root', 'root'), ('node', 'node'), ('sorted', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Instances', 'Instances'), ('classified', 'classified'), ('starting', 'starting'), ('root', 'root'), ('node', 'node'), ('sorted', 'sorted'), ('based', 'based'), ('feature', 'feature'), ('values', 'value'), ('.', '.')]



============================ Sentence 77 =============================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY   948   The Fig.3 is an example of a decision tree for the training set   of Table.2. 


>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY', '948', 'The', 'Fig.3', 'example', 'decision', 'tree', 'training', 'set', 'Table.2', '.']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY'), ('SURVEY', '948'), ('948', 'The'), ('The', 'Fig.3'), ('Fig.3', 'example'), ('example', 'decision'), ('decision', 'tree'), ('tree', 'training'), ('training', 'set'), ('set', 'Table.2'), ('Table.2', '.')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY'), ('A', 'SURVEY', '948'), ('SURVEY', '948', 'The'), ('948', 'The', 'Fig.3'), ('The', 'Fig.3', 'example'), ('Fig.3', 'example', 'decision'), ('example', 'decision', 'tree'), ('decision', 'tree', 'training'), ('tree', 'training', 'set'), ('training', 'set', 'Table.2'), ('set', 'Table.2', '.')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NNP'), ('948', 'CD'), ('The', 'DT'), ('Fig.3', 'NNP'), ('example', 'NN'), ('decision', 'NN'), ('tree', 'IN'), ('training', 'VBG'), ('set', 'VBN'), ('Table.2', 'NNP'), ('.', '.')]

 (S
  (NP IQBAL/NNP MUHAMMAD/NNP AND/NNP ZHU/NNP YAN/NNP)
  :/:
  (NP SUPERVISED/NNP MACHINE/NNP LEARNING/NNP APPROACHES/NNP)
  :/:
  (NP A/DT SURVEY/NNP)
  948/CD
  (NP The/DT Fig.3/NNP example/NN decision/NN)
  tree/IN
  training/VBG
  set/VBN
  (NP Table.2/NNP)
  ./.) 


>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY', 'The Fig.3 example decision', 'Table.2']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('948', '948'), ('The', 'the'), ('Fig.3', 'fig.3'), ('example', 'exampl'), ('decision', 'decis'), ('tree', 'tree'), ('training', 'train'), ('set', 'set'), ('Table.2', 'table.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('948', '948'), ('The', 'the'), ('Fig.3', 'fig.3'), ('example', 'exampl'), ('decision', 'decis'), ('tree', 'tree'), ('training', 'train'), ('set', 'set'), ('Table.2', 'table.2'), ('.', '.')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY'), ('948', '948'), ('The', 'The'), ('Fig.3', 'Fig.3'), ('example', 'example'), ('decision', 'decision'), ('tree', 'tree'), ('training', 'training'), ('set', 'set'), ('Table.2', 'Table.2'), ('.', '.')]



============================ Sentence 78 =============================

DT are extensively used is different computational   fields to classify data. 


>> Tokens are: 
 ['DT', 'extensively', 'used', 'different', 'computational', 'fields', 'classify', 'data', '.']

>> Bigrams are: 
 [('DT', 'extensively'), ('extensively', 'used'), ('used', 'different'), ('different', 'computational'), ('computational', 'fields'), ('fields', 'classify'), ('classify', 'data'), ('data', '.')]

>> Trigrams are: 
 [('DT', 'extensively', 'used'), ('extensively', 'used', 'different'), ('used', 'different', 'computational'), ('different', 'computational', 'fields'), ('computational', 'fields', 'classify'), ('fields', 'classify', 'data'), ('classify', 'data', '.')]

>> POS Tags are: 
 [('DT', 'NNP'), ('extensively', 'RB'), ('used', 'VBD'), ('different', 'JJ'), ('computational', 'JJ'), ('fields', 'NNS'), ('classify', 'VB'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP DT/NNP)
  extensively/RB
  used/VBD
  (NP different/JJ computational/JJ fields/NNS)
  classify/VB
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['DT', 'different computational fields', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('DT', 'dt'), ('extensively', 'extens'), ('used', 'use'), ('different', 'differ'), ('computational', 'comput'), ('fields', 'field'), ('classify', 'classifi'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('DT', 'dt'), ('extensively', 'extens'), ('used', 'use'), ('different', 'differ'), ('computational', 'comput'), ('fields', 'field'), ('classify', 'classifi'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('DT', 'DT'), ('extensively', 'extensively'), ('used', 'used'), ('different', 'different'), ('computational', 'computational'), ('fields', 'field'), ('classify', 'classify'), ('data', 'data'), ('.', '.')]



============================ Sentence 79 =============================

The reasons behinds the widely   acceptability of DT learning algorithms are their flexibility to   apply in wide range of problems. 


>> Tokens are: 
 ['The', 'reasons', 'behinds', 'widely', 'acceptability', 'DT', 'learning', 'algorithms', 'flexibility', 'apply', 'wide', 'range', 'problems', '.']

>> Bigrams are: 
 [('The', 'reasons'), ('reasons', 'behinds'), ('behinds', 'widely'), ('widely', 'acceptability'), ('acceptability', 'DT'), ('DT', 'learning'), ('learning', 'algorithms'), ('algorithms', 'flexibility'), ('flexibility', 'apply'), ('apply', 'wide'), ('wide', 'range'), ('range', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('The', 'reasons', 'behinds'), ('reasons', 'behinds', 'widely'), ('behinds', 'widely', 'acceptability'), ('widely', 'acceptability', 'DT'), ('acceptability', 'DT', 'learning'), ('DT', 'learning', 'algorithms'), ('learning', 'algorithms', 'flexibility'), ('algorithms', 'flexibility', 'apply'), ('flexibility', 'apply', 'wide'), ('apply', 'wide', 'range'), ('wide', 'range', 'problems'), ('range', 'problems', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('reasons', 'NNS'), ('behinds', 'VBZ'), ('widely', 'RB'), ('acceptability', 'JJ'), ('DT', 'NNP'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('flexibility', 'NN'), ('apply', 'VB'), ('wide', 'JJ'), ('range', 'NN'), ('problems', 'NNS'), ('.', '.')]

 (S
  (NP The/DT reasons/NNS)
  behinds/VBZ
  widely/RB
  (NP acceptability/JJ DT/NNP)
  learning/VBG
  (NP algorithms/JJ flexibility/NN)
  apply/VB
  (NP wide/JJ range/NN problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The reasons', 'acceptability DT', 'algorithms flexibility', 'wide range problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'wide'), ('acceptability', 'accept'), ('DT', 'dt'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('flexibility', 'flexibl'), ('apply', 'appli'), ('wide', 'wide'), ('range', 'rang'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'wide'), ('acceptability', 'accept'), ('DT', 'dt'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('flexibility', 'flexibl'), ('apply', 'appli'), ('wide', 'wide'), ('range', 'rang'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'widely'), ('acceptability', 'acceptability'), ('DT', 'DT'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('flexibility', 'flexibility'), ('apply', 'apply'), ('wide', 'wide'), ('range', 'range'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 80 =============================

An interesting and important   property of a decision tree and its resulting set of rules is that the   tree paths or the rules are mutually exclusive and exhaustive. 


>> Tokens are: 
 ['An', 'interesting', 'important', 'property', 'decision', 'tree', 'resulting', 'set', 'rules', 'tree', 'paths', 'rules', 'mutually', 'exclusive', 'exhaustive', '.']

>> Bigrams are: 
 [('An', 'interesting'), ('interesting', 'important'), ('important', 'property'), ('property', 'decision'), ('decision', 'tree'), ('tree', 'resulting'), ('resulting', 'set'), ('set', 'rules'), ('rules', 'tree'), ('tree', 'paths'), ('paths', 'rules'), ('rules', 'mutually'), ('mutually', 'exclusive'), ('exclusive', 'exhaustive'), ('exhaustive', '.')]

>> Trigrams are: 
 [('An', 'interesting', 'important'), ('interesting', 'important', 'property'), ('important', 'property', 'decision'), ('property', 'decision', 'tree'), ('decision', 'tree', 'resulting'), ('tree', 'resulting', 'set'), ('resulting', 'set', 'rules'), ('set', 'rules', 'tree'), ('rules', 'tree', 'paths'), ('tree', 'paths', 'rules'), ('paths', 'rules', 'mutually'), ('rules', 'mutually', 'exclusive'), ('mutually', 'exclusive', 'exhaustive'), ('exclusive', 'exhaustive', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('interesting', 'JJ'), ('important', 'JJ'), ('property', 'NN'), ('decision', 'NN'), ('tree', 'NN'), ('resulting', 'VBG'), ('set', 'VBN'), ('rules', 'NNS'), ('tree', 'VBP'), ('paths', 'NNS'), ('rules', 'NNS'), ('mutually', 'RB'), ('exclusive', 'JJ'), ('exhaustive', 'NN'), ('.', '.')]

 (S
  (NP
    An/DT
    interesting/JJ
    important/JJ
    property/NN
    decision/NN
    tree/NN)
  resulting/VBG
  set/VBN
  (NP rules/NNS)
  tree/VBP
  (NP paths/NNS rules/NNS)
  mutually/RB
  (NP exclusive/JJ exhaustive/NN)
  ./.) 


>> Noun Phrases are: 
 ['An interesting important property decision tree', 'rules', 'paths rules', 'exclusive exhaustive']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('important', 'import'), ('property', 'properti'), ('decision', 'decis'), ('tree', 'tree'), ('resulting', 'result'), ('set', 'set'), ('rules', 'rule'), ('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('exhaustive', 'exhaust'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('important', 'import'), ('property', 'properti'), ('decision', 'decis'), ('tree', 'tree'), ('resulting', 'result'), ('set', 'set'), ('rules', 'rule'), ('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('exhaustive', 'exhaust'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('interesting', 'interesting'), ('important', 'important'), ('property', 'property'), ('decision', 'decision'), ('tree', 'tree'), ('resulting', 'resulting'), ('set', 'set'), ('rules', 'rule'), ('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutually'), ('exclusive', 'exclusive'), ('exhaustive', 'exhaustive'), ('.', '.')]



============================ Sentence 81 =============================

This means that every data instance/record/example/vector/case   is covered by a single rule. 


>> Tokens are: 
 ['This', 'means', 'every', 'data', 'instance/record/example/vector/case', 'covered', 'single', 'rule', '.']

>> Bigrams are: 
 [('This', 'means'), ('means', 'every'), ('every', 'data'), ('data', 'instance/record/example/vector/case'), ('instance/record/example/vector/case', 'covered'), ('covered', 'single'), ('single', 'rule'), ('rule', '.')]

>> Trigrams are: 
 [('This', 'means', 'every'), ('means', 'every', 'data'), ('every', 'data', 'instance/record/example/vector/case'), ('data', 'instance/record/example/vector/case', 'covered'), ('instance/record/example/vector/case', 'covered', 'single'), ('covered', 'single', 'rule'), ('single', 'rule', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('means', 'VBZ'), ('every', 'DT'), ('data', 'NN'), ('instance/record/example/vector/case', 'NN'), ('covered', 'VBD'), ('single', 'JJ'), ('rule', 'NN'), ('.', '.')]

 (S
  This/DT
  means/VBZ
  (NP every/DT data/NN instance/record/example/vector/case/NN)
  covered/VBD
  (NP single/JJ rule/NN)
  ./.) 


>> Noun Phrases are: 
 ['every data instance/record/example/vector/case', 'single rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('means', 'mean'), ('every', 'everi'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/cas'), ('covered', 'cover'), ('single', 'singl'), ('rule', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('means', 'mean'), ('every', 'everi'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/cas'), ('covered', 'cover'), ('single', 'singl'), ('rule', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('means', 'mean'), ('every', 'every'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/case'), ('covered', 'covered'), ('single', 'single'), ('rule', 'rule'), ('.', '.')]



============================ Sentence 82 =============================

According to Pierre et al. 


>> Tokens are: 
 ['According', 'Pierre', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Pierre'), ('Pierre', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Pierre', 'et'), ('Pierre', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Pierre', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S According/VBG (NP Pierre/NNP et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Pierre et al']

>> Named Entities are: 
 [('PERSON', 'Pierre')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Pierre', 'pierr'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Pierre', 'pierr'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Pierre', 'Pierre'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 83 =============================

[7], DT   algorithms combined with ensemble methods, can provide better   results in terms of predictive accuracy and significantly in the   context of high-throughput data sets, tree-based methods are also   highly scalable from a computational point of view. 


>> Tokens are: 
 ['[', '7', ']', ',', 'DT', 'algorithms', 'combined', 'ensemble', 'methods', ',', 'provide', 'better', 'results', 'terms', 'predictive', 'accuracy', 'significantly', 'context', 'high-throughput', 'data', 'sets', ',', 'tree-based', 'methods', 'also', 'highly', 'scalable', 'computational', 'point', 'view', '.']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', ','), (',', 'DT'), ('DT', 'algorithms'), ('algorithms', 'combined'), ('combined', 'ensemble'), ('ensemble', 'methods'), ('methods', ','), (',', 'provide'), ('provide', 'better'), ('better', 'results'), ('results', 'terms'), ('terms', 'predictive'), ('predictive', 'accuracy'), ('accuracy', 'significantly'), ('significantly', 'context'), ('context', 'high-throughput'), ('high-throughput', 'data'), ('data', 'sets'), ('sets', ','), (',', 'tree-based'), ('tree-based', 'methods'), ('methods', 'also'), ('also', 'highly'), ('highly', 'scalable'), ('scalable', 'computational'), ('computational', 'point'), ('point', 'view'), ('view', '.')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', ','), (']', ',', 'DT'), (',', 'DT', 'algorithms'), ('DT', 'algorithms', 'combined'), ('algorithms', 'combined', 'ensemble'), ('combined', 'ensemble', 'methods'), ('ensemble', 'methods', ','), ('methods', ',', 'provide'), (',', 'provide', 'better'), ('provide', 'better', 'results'), ('better', 'results', 'terms'), ('results', 'terms', 'predictive'), ('terms', 'predictive', 'accuracy'), ('predictive', 'accuracy', 'significantly'), ('accuracy', 'significantly', 'context'), ('significantly', 'context', 'high-throughput'), ('context', 'high-throughput', 'data'), ('high-throughput', 'data', 'sets'), ('data', 'sets', ','), ('sets', ',', 'tree-based'), (',', 'tree-based', 'methods'), ('tree-based', 'methods', 'also'), ('methods', 'also', 'highly'), ('also', 'highly', 'scalable'), ('highly', 'scalable', 'computational'), ('scalable', 'computational', 'point'), ('computational', 'point', 'view'), ('point', 'view', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'NNS'), (',', ','), ('DT', 'NNP'), ('algorithms', 'NN'), ('combined', 'VBD'), ('ensemble', 'JJ'), ('methods', 'NNS'), (',', ','), ('provide', 'VBP'), ('better', 'JJR'), ('results', 'NNS'), ('terms', 'NNS'), ('predictive', 'JJ'), ('accuracy', 'NN'), ('significantly', 'RB'), ('context', 'JJ'), ('high-throughput', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), (',', ','), ('tree-based', 'JJ'), ('methods', 'NNS'), ('also', 'RB'), ('highly', 'RB'), ('scalable', 'JJ'), ('computational', 'JJ'), ('point', 'NN'), ('view', 'NN'), ('.', '.')]

 (S
  [/RB
  7/CD
  (NP ]/NNS)
  ,/,
  (NP DT/NNP algorithms/NN)
  combined/VBD
  (NP ensemble/JJ methods/NNS)
  ,/,
  provide/VBP
  better/JJR
  (NP results/NNS terms/NNS)
  (NP predictive/JJ accuracy/NN)
  significantly/RB
  (NP context/JJ high-throughput/JJ data/NNS sets/NNS)
  ,/,
  (NP tree-based/JJ methods/NNS)
  also/RB
  highly/RB
  (NP scalable/JJ computational/JJ point/NN view/NN)
  ./.) 


>> Noun Phrases are: 
 [']', 'DT algorithms', 'ensemble methods', 'results terms', 'predictive accuracy', 'context high-throughput data sets', 'tree-based methods', 'scalable computational point view']

>> Named Entities are: 
 [('ORGANIZATION', 'DT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'dt'), ('algorithms', 'algorithm'), ('combined', 'combin'), ('ensemble', 'ensembl'), ('methods', 'method'), (',', ','), ('provide', 'provid'), ('better', 'better'), ('results', 'result'), ('terms', 'term'), ('predictive', 'predict'), ('accuracy', 'accuraci'), ('significantly', 'significantli'), ('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-bas'), ('methods', 'method'), ('also', 'also'), ('highly', 'highli'), ('scalable', 'scalabl'), ('computational', 'comput'), ('point', 'point'), ('view', 'view'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'dt'), ('algorithms', 'algorithm'), ('combined', 'combin'), ('ensemble', 'ensembl'), ('methods', 'method'), (',', ','), ('provide', 'provid'), ('better', 'better'), ('results', 'result'), ('terms', 'term'), ('predictive', 'predict'), ('accuracy', 'accuraci'), ('significantly', 'signific'), ('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-bas'), ('methods', 'method'), ('also', 'also'), ('highly', 'high'), ('scalable', 'scalabl'), ('computational', 'comput'), ('point', 'point'), ('view', 'view'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'DT'), ('algorithms', 'algorithm'), ('combined', 'combined'), ('ensemble', 'ensemble'), ('methods', 'method'), (',', ','), ('provide', 'provide'), ('better', 'better'), ('results', 'result'), ('terms', 'term'), ('predictive', 'predictive'), ('accuracy', 'accuracy'), ('significantly', 'significantly'), ('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-based'), ('methods', 'method'), ('also', 'also'), ('highly', 'highly'), ('scalable', 'scalable'), ('computational', 'computational'), ('point', 'point'), ('view', 'view'), ('.', '.')]



============================ Sentence 84 =============================

Fig.3. 


>> Tokens are: 
 ['Fig.3', '.']

>> Bigrams are: 
 [('Fig.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.3', 'NNP'), ('.', '.')]

 (S (NP Fig.3/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.3', 'fig.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.3', 'fig.3'), ('.', '.')]

>> Lemmatization: 
 [('Fig.3', 'Fig.3'), ('.', '.')]



============================ Sentence 85 =============================

A Sample Decision Tree   By using the DT depicted in Fig.3 as an example, the   instance (at1 = a1, at2 = b2, at3 = a3, at4 = b4) would sort to the   nodes: at1, at2, and finally at3, which would classify the instance   as being positive (represented by the values Yes). 


>> Tokens are: 
 ['A', 'Sample', 'Decision', 'Tree', 'By', 'using', 'DT', 'depicted', 'Fig.3', 'example', ',', 'instance', '(', 'at1', '=', 'a1', ',', 'at2', '=', 'b2', ',', 'at3', '=', 'a3', ',', 'at4', '=', 'b4', ')', 'would', 'sort', 'nodes', ':', 'at1', ',', 'at2', ',', 'finally', 'at3', ',', 'would', 'classify', 'instance', 'positive', '(', 'represented', 'values', '', 'Yes', '', ')', '.']

>> Bigrams are: 
 [('A', 'Sample'), ('Sample', 'Decision'), ('Decision', 'Tree'), ('Tree', 'By'), ('By', 'using'), ('using', 'DT'), ('DT', 'depicted'), ('depicted', 'Fig.3'), ('Fig.3', 'example'), ('example', ','), (',', 'instance'), ('instance', '('), ('(', 'at1'), ('at1', '='), ('=', 'a1'), ('a1', ','), (',', 'at2'), ('at2', '='), ('=', 'b2'), ('b2', ','), (',', 'at3'), ('at3', '='), ('=', 'a3'), ('a3', ','), (',', 'at4'), ('at4', '='), ('=', 'b4'), ('b4', ')'), (')', 'would'), ('would', 'sort'), ('sort', 'nodes'), ('nodes', ':'), (':', 'at1'), ('at1', ','), (',', 'at2'), ('at2', ','), (',', 'finally'), ('finally', 'at3'), ('at3', ','), (',', 'would'), ('would', 'classify'), ('classify', 'instance'), ('instance', 'positive'), ('positive', '('), ('(', 'represented'), ('represented', 'values'), ('values', ''), ('', 'Yes'), ('Yes', ''), ('', ')'), (')', '.')]

>> Trigrams are: 
 [('A', 'Sample', 'Decision'), ('Sample', 'Decision', 'Tree'), ('Decision', 'Tree', 'By'), ('Tree', 'By', 'using'), ('By', 'using', 'DT'), ('using', 'DT', 'depicted'), ('DT', 'depicted', 'Fig.3'), ('depicted', 'Fig.3', 'example'), ('Fig.3', 'example', ','), ('example', ',', 'instance'), (',', 'instance', '('), ('instance', '(', 'at1'), ('(', 'at1', '='), ('at1', '=', 'a1'), ('=', 'a1', ','), ('a1', ',', 'at2'), (',', 'at2', '='), ('at2', '=', 'b2'), ('=', 'b2', ','), ('b2', ',', 'at3'), (',', 'at3', '='), ('at3', '=', 'a3'), ('=', 'a3', ','), ('a3', ',', 'at4'), (',', 'at4', '='), ('at4', '=', 'b4'), ('=', 'b4', ')'), ('b4', ')', 'would'), (')', 'would', 'sort'), ('would', 'sort', 'nodes'), ('sort', 'nodes', ':'), ('nodes', ':', 'at1'), (':', 'at1', ','), ('at1', ',', 'at2'), (',', 'at2', ','), ('at2', ',', 'finally'), (',', 'finally', 'at3'), ('finally', 'at3', ','), ('at3', ',', 'would'), (',', 'would', 'classify'), ('would', 'classify', 'instance'), ('classify', 'instance', 'positive'), ('instance', 'positive', '('), ('positive', '(', 'represented'), ('(', 'represented', 'values'), ('represented', 'values', ''), ('values', '', 'Yes'), ('', 'Yes', ''), ('Yes', '', ')'), ('', ')', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Sample', 'NNP'), ('Decision', 'NNP'), ('Tree', 'NNP'), ('By', 'IN'), ('using', 'VBG'), ('DT', 'NNP'), ('depicted', 'VBD'), ('Fig.3', 'NNP'), ('example', 'NN'), (',', ','), ('instance', 'NN'), ('(', '('), ('at1', 'JJ'), ('=', 'NNP'), ('a1', 'NN'), (',', ','), ('at2', 'JJ'), ('=', 'NNP'), ('b2', 'NN'), (',', ','), ('at3', 'JJ'), ('=', 'NNP'), ('a3', 'NN'), (',', ','), ('at4', 'JJ'), ('=', 'NNP'), ('b4', 'NN'), (')', ')'), ('would', 'MD'), ('sort', 'VB'), ('nodes', 'NNS'), (':', ':'), ('at1', 'NN'), (',', ','), ('at2', 'NN'), (',', ','), ('finally', 'RB'), ('at3', 'JJ'), (',', ','), ('would', 'MD'), ('classify', 'VB'), ('instance', 'NN'), ('positive', 'JJ'), ('(', '('), ('represented', 'VBN'), ('values', 'NNS'), ('', 'VB'), ('Yes', 'NNP'), ('', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP A/DT Sample/NNP Decision/NNP Tree/NNP)
  By/IN
  using/VBG
  (NP DT/NNP)
  depicted/VBD
  (NP Fig.3/NNP example/NN)
  ,/,
  (NP instance/NN)
  (/(
  (NP at1/JJ =/NNP a1/NN)
  ,/,
  (NP at2/JJ =/NNP b2/NN)
  ,/,
  (NP at3/JJ =/NNP a3/NN)
  ,/,
  (NP at4/JJ =/NNP b4/NN)
  )/)
  would/MD
  sort/VB
  (NP nodes/NNS)
  :/:
  (NP at1/NN)
  ,/,
  (NP at2/NN)
  ,/,
  finally/RB
  at3/JJ
  ,/,
  would/MD
  classify/VB
  (NP instance/NN)
  positive/JJ
  (/(
  represented/VBN
  (NP values/NNS)
  /VB
  (NP Yes/NNP /NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['A Sample Decision Tree', 'DT', 'Fig.3 example', 'instance', 'at1 = a1', 'at2 = b2', 'at3 = a3', 'at4 = b4', 'nodes', 'at1', 'at2', 'instance', 'values', 'Yes ']

>> Named Entities are: 
 [('ORGANIZATION', 'Sample Decision Tree'), ('ORGANIZATION', 'DT'), ('PERSON', 'Yes')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Sample', 'sampl'), ('Decision', 'decis'), ('Tree', 'tree'), ('By', 'by'), ('using', 'use'), ('DT', 'dt'), ('depicted', 'depict'), ('Fig.3', 'fig.3'), ('example', 'exampl'), (',', ','), ('instance', 'instanc'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort'), ('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'final'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classifi'), ('instance', 'instanc'), ('positive', 'posit'), ('(', '('), ('represented', 'repres'), ('values', 'valu'), ('', ''), ('Yes', 'ye'), ('', ''), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Sample', 'sampl'), ('Decision', 'decis'), ('Tree', 'tree'), ('By', 'by'), ('using', 'use'), ('DT', 'dt'), ('depicted', 'depict'), ('Fig.3', 'fig.3'), ('example', 'exampl'), (',', ','), ('instance', 'instanc'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort'), ('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'final'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classifi'), ('instance', 'instanc'), ('positive', 'posit'), ('(', '('), ('represented', 'repres'), ('values', 'valu'), ('', ''), ('Yes', 'yes'), ('', ''), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Sample', 'Sample'), ('Decision', 'Decision'), ('Tree', 'Tree'), ('By', 'By'), ('using', 'using'), ('DT', 'DT'), ('depicted', 'depicted'), ('Fig.3', 'Fig.3'), ('example', 'example'), (',', ','), ('instance', 'instance'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort'), ('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'finally'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classify'), ('instance', 'instance'), ('positive', 'positive'), ('(', '('), ('represented', 'represented'), ('values', 'value'), ('', ''), ('Yes', 'Yes'), ('', ''), (')', ')'), ('.', '.')]



============================ Sentence 86 =============================

Table.2. 


>> Tokens are: 
 ['Table.2', '.']

>> Bigrams are: 
 [('Table.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.2', 'NNP'), ('.', '.')]

 (S (NP Table.2/NNP) ./.) 


>> Noun Phrases are: 
 ['Table.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Lemmatization: 
 [('Table.2', 'Table.2'), ('.', '.')]



============================ Sentence 87 =============================

Sample Training set   at1 at2 at3 at4 Class   a1 a2 a3 a4 Yes   a1 a2 a3 b4 Yes   a1 b2 a3 a4 Yes   a1 b2 b3 b4 No   a1 c2 a3 a4 Yes   a1 c2 a3 b4 No   b1 b2 b3 b4 No   c1 b2 b3 b4 No   The feature that best divides the training data would be the   root node of the tree. 


>> Tokens are: 
 ['Sample', 'Training', 'set', 'at1', 'at2', 'at3', 'at4', 'Class', 'a1', 'a2', 'a3', 'a4', 'Yes', 'a1', 'a2', 'a3', 'b4', 'Yes', 'a1', 'b2', 'a3', 'a4', 'Yes', 'a1', 'b2', 'b3', 'b4', 'No', 'a1', 'c2', 'a3', 'a4', 'Yes', 'a1', 'c2', 'a3', 'b4', 'No', 'b1', 'b2', 'b3', 'b4', 'No', 'c1', 'b2', 'b3', 'b4', 'No', 'The', 'feature', 'best', 'divides', 'training', 'data', 'would', 'root', 'node', 'tree', '.']

>> Bigrams are: 
 [('Sample', 'Training'), ('Training', 'set'), ('set', 'at1'), ('at1', 'at2'), ('at2', 'at3'), ('at3', 'at4'), ('at4', 'Class'), ('Class', 'a1'), ('a1', 'a2'), ('a2', 'a3'), ('a3', 'a4'), ('a4', 'Yes'), ('Yes', 'a1'), ('a1', 'a2'), ('a2', 'a3'), ('a3', 'b4'), ('b4', 'Yes'), ('Yes', 'a1'), ('a1', 'b2'), ('b2', 'a3'), ('a3', 'a4'), ('a4', 'Yes'), ('Yes', 'a1'), ('a1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No'), ('No', 'a1'), ('a1', 'c2'), ('c2', 'a3'), ('a3', 'a4'), ('a4', 'Yes'), ('Yes', 'a1'), ('a1', 'c2'), ('c2', 'a3'), ('a3', 'b4'), ('b4', 'No'), ('No', 'b1'), ('b1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No'), ('No', 'c1'), ('c1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No'), ('No', 'The'), ('The', 'feature'), ('feature', 'best'), ('best', 'divides'), ('divides', 'training'), ('training', 'data'), ('data', 'would'), ('would', 'root'), ('root', 'node'), ('node', 'tree'), ('tree', '.')]

>> Trigrams are: 
 [('Sample', 'Training', 'set'), ('Training', 'set', 'at1'), ('set', 'at1', 'at2'), ('at1', 'at2', 'at3'), ('at2', 'at3', 'at4'), ('at3', 'at4', 'Class'), ('at4', 'Class', 'a1'), ('Class', 'a1', 'a2'), ('a1', 'a2', 'a3'), ('a2', 'a3', 'a4'), ('a3', 'a4', 'Yes'), ('a4', 'Yes', 'a1'), ('Yes', 'a1', 'a2'), ('a1', 'a2', 'a3'), ('a2', 'a3', 'b4'), ('a3', 'b4', 'Yes'), ('b4', 'Yes', 'a1'), ('Yes', 'a1', 'b2'), ('a1', 'b2', 'a3'), ('b2', 'a3', 'a4'), ('a3', 'a4', 'Yes'), ('a4', 'Yes', 'a1'), ('Yes', 'a1', 'b2'), ('a1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No'), ('b4', 'No', 'a1'), ('No', 'a1', 'c2'), ('a1', 'c2', 'a3'), ('c2', 'a3', 'a4'), ('a3', 'a4', 'Yes'), ('a4', 'Yes', 'a1'), ('Yes', 'a1', 'c2'), ('a1', 'c2', 'a3'), ('c2', 'a3', 'b4'), ('a3', 'b4', 'No'), ('b4', 'No', 'b1'), ('No', 'b1', 'b2'), ('b1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No'), ('b4', 'No', 'c1'), ('No', 'c1', 'b2'), ('c1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No'), ('b4', 'No', 'The'), ('No', 'The', 'feature'), ('The', 'feature', 'best'), ('feature', 'best', 'divides'), ('best', 'divides', 'training'), ('divides', 'training', 'data'), ('training', 'data', 'would'), ('data', 'would', 'root'), ('would', 'root', 'node'), ('root', 'node', 'tree'), ('node', 'tree', '.')]

>> POS Tags are: 
 [('Sample', 'JJ'), ('Training', 'NNP'), ('set', 'NN'), ('at1', 'NN'), ('at2', 'NN'), ('at3', 'NN'), ('at4', 'JJ'), ('Class', 'NNP'), ('a1', 'NN'), ('a2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NNP'), ('a1', 'NN'), ('a2', 'NN'), ('a3', 'JJ'), ('b4', 'JJ'), ('Yes', 'NNP'), ('a1', 'NN'), ('b2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NNP'), ('a1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'DT'), ('a1', 'NN'), ('c2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NNP'), ('a1', 'NN'), ('c2', 'NN'), ('a3', 'NN'), ('b4', 'VBZ'), ('No', 'DT'), ('b1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'DT'), ('c1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'CC'), ('The', 'DT'), ('feature', 'NN'), ('best', 'JJS'), ('divides', 'NNS'), ('training', 'VBG'), ('data', 'NNS'), ('would', 'MD'), ('root', 'VB'), ('node', 'JJ'), ('tree', 'NN'), ('.', '.')]

 (S
  (NP Sample/JJ Training/NNP set/NN at1/NN at2/NN at3/NN)
  (NP at4/JJ Class/NNP a1/NN a2/NN)
  (NP a3/JJ a4/JJ Yes/NNP a1/NN a2/NN)
  (NP a3/JJ b4/JJ Yes/NNP a1/NN b2/NN)
  (NP a3/JJ a4/JJ Yes/NNP a1/NN b2/NN b3/NN)
  b4/VBZ
  (NP No/DT a1/NN c2/NN)
  (NP a3/JJ a4/JJ Yes/NNP a1/NN c2/NN a3/NN)
  b4/VBZ
  (NP No/DT b1/NN b2/NN b3/NN)
  b4/VBZ
  (NP No/DT c1/NN b2/NN b3/NN)
  b4/VBZ
  No/CC
  (NP The/DT feature/NN)
  best/JJS
  (NP divides/NNS)
  training/VBG
  (NP data/NNS)
  would/MD
  root/VB
  (NP node/JJ tree/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sample Training set at1 at2 at3', 'at4 Class a1 a2', 'a3 a4 Yes a1 a2', 'a3 b4 Yes a1 b2', 'a3 a4 Yes a1 b2 b3', 'No a1 c2', 'a3 a4 Yes a1 c2 a3', 'No b1 b2 b3', 'No c1 b2 b3', 'The feature', 'divides', 'data', 'node tree']

>> Named Entities are: 
 [('PERSON', 'Sample'), ('ORGANIZATION', 'Training')] 

>> Stemming using Porter Stemmer: 
 [('Sample', 'sampl'), ('Training', 'train'), ('set', 'set'), ('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'class'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'ye'), ('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye'), ('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'no'), ('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('The', 'the'), ('feature', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('would', 'would'), ('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sample', 'sampl'), ('Training', 'train'), ('set', 'set'), ('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'class'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'yes'), ('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes'), ('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'no'), ('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no'), ('The', 'the'), ('feature', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('would', 'would'), ('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]

>> Lemmatization: 
 [('Sample', 'Sample'), ('Training', 'Training'), ('set', 'set'), ('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'Class'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes'), ('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'Yes'), ('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes'), ('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes'), ('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'No'), ('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No'), ('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No'), ('The', 'The'), ('feature', 'feature'), ('best', 'best'), ('divides', 'divide'), ('training', 'training'), ('data', 'data'), ('would', 'would'), ('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]



============================ Sentence 88 =============================

There are different methods to extract the   features that best divides the training data such as information   gain [11] and gini index [12]. 


>> Tokens are: 
 ['There', 'different', 'methods', 'extract', 'features', 'best', 'divides', 'training', 'data', 'information', 'gain', '[', '11', ']', 'gini', 'index', '[', '12', ']', '.']

>> Bigrams are: 
 [('There', 'different'), ('different', 'methods'), ('methods', 'extract'), ('extract', 'features'), ('features', 'best'), ('best', 'divides'), ('divides', 'training'), ('training', 'data'), ('data', 'information'), ('information', 'gain'), ('gain', '['), ('[', '11'), ('11', ']'), (']', 'gini'), ('gini', 'index'), ('index', '['), ('[', '12'), ('12', ']'), (']', '.')]

>> Trigrams are: 
 [('There', 'different', 'methods'), ('different', 'methods', 'extract'), ('methods', 'extract', 'features'), ('extract', 'features', 'best'), ('features', 'best', 'divides'), ('best', 'divides', 'training'), ('divides', 'training', 'data'), ('training', 'data', 'information'), ('data', 'information', 'gain'), ('information', 'gain', '['), ('gain', '[', '11'), ('[', '11', ']'), ('11', ']', 'gini'), (']', 'gini', 'index'), ('gini', 'index', '['), ('index', '[', '12'), ('[', '12', ']'), ('12', ']', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('different', 'JJ'), ('methods', 'NNS'), ('extract', 'JJ'), ('features', 'NNS'), ('best', 'JJS'), ('divides', 'NNS'), ('training', 'VBG'), ('data', 'NNS'), ('information', 'NN'), ('gain', 'NN'), ('[', 'VBD'), ('11', 'CD'), (']', 'NNP'), ('gini', 'NN'), ('index', 'NN'), ('[', 'VBD'), ('12', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  There/EX
  (NP different/JJ methods/NNS)
  (NP extract/JJ features/NNS)
  best/JJS
  (NP divides/NNS)
  training/VBG
  (NP data/NNS information/NN gain/NN)
  [/VBD
  11/CD
  (NP ]/NNP gini/NN index/NN)
  [/VBD
  12/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['different methods', 'extract features', 'divides', 'data information gain', '] gini index', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('different', 'differ'), ('methods', 'method'), ('extract', 'extract'), ('features', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('information', 'inform'), ('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('different', 'differ'), ('methods', 'method'), ('extract', 'extract'), ('features', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('information', 'inform'), ('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('different', 'different'), ('methods', 'method'), ('extract', 'extract'), ('features', 'feature'), ('best', 'best'), ('divides', 'divide'), ('training', 'training'), ('data', 'data'), ('information', 'information'), ('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]



============================ Sentence 89 =============================

Fig.4. 


>> Tokens are: 
 ['Fig.4', '.']

>> Bigrams are: 
 [('Fig.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.4', 'NNP'), ('.', '.')]

 (S (NP Fig.4/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.4', 'fig.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.4', 'fig.4'), ('.', '.')]

>> Lemmatization: 
 [('Fig.4', 'Fig.4'), ('.', '.')]



============================ Sentence 90 =============================

General pseudo-code for building decision trees   3.2 LEARNING SET OF RULES   It is also possible that decision trees can be translated into a   set of rules by creating a separate rule for each path from the   root to a leaf in the tree [13]. 


>> Tokens are: 
 ['General', 'pseudo-code', 'building', 'decision', 'trees', '3.2', 'LEARNING', 'SET', 'OF', 'RULES', 'It', 'also', 'possible', 'decision', 'trees', 'translated', 'set', 'rules', 'creating', 'separate', 'rule', 'path', 'root', 'leaf', 'tree', '[', '13', ']', '.']

>> Bigrams are: 
 [('General', 'pseudo-code'), ('pseudo-code', 'building'), ('building', 'decision'), ('decision', 'trees'), ('trees', '3.2'), ('3.2', 'LEARNING'), ('LEARNING', 'SET'), ('SET', 'OF'), ('OF', 'RULES'), ('RULES', 'It'), ('It', 'also'), ('also', 'possible'), ('possible', 'decision'), ('decision', 'trees'), ('trees', 'translated'), ('translated', 'set'), ('set', 'rules'), ('rules', 'creating'), ('creating', 'separate'), ('separate', 'rule'), ('rule', 'path'), ('path', 'root'), ('root', 'leaf'), ('leaf', 'tree'), ('tree', '['), ('[', '13'), ('13', ']'), (']', '.')]

>> Trigrams are: 
 [('General', 'pseudo-code', 'building'), ('pseudo-code', 'building', 'decision'), ('building', 'decision', 'trees'), ('decision', 'trees', '3.2'), ('trees', '3.2', 'LEARNING'), ('3.2', 'LEARNING', 'SET'), ('LEARNING', 'SET', 'OF'), ('SET', 'OF', 'RULES'), ('OF', 'RULES', 'It'), ('RULES', 'It', 'also'), ('It', 'also', 'possible'), ('also', 'possible', 'decision'), ('possible', 'decision', 'trees'), ('decision', 'trees', 'translated'), ('trees', 'translated', 'set'), ('translated', 'set', 'rules'), ('set', 'rules', 'creating'), ('rules', 'creating', 'separate'), ('creating', 'separate', 'rule'), ('separate', 'rule', 'path'), ('rule', 'path', 'root'), ('path', 'root', 'leaf'), ('root', 'leaf', 'tree'), ('leaf', 'tree', '['), ('tree', '[', '13'), ('[', '13', ']'), ('13', ']', '.')]

>> POS Tags are: 
 [('General', 'NNP'), ('pseudo-code', 'NN'), ('building', 'NN'), ('decision', 'NN'), ('trees', 'NNS'), ('3.2', 'CD'), ('LEARNING', 'NNP'), ('SET', 'NNP'), ('OF', 'NNP'), ('RULES', 'NNP'), ('It', 'PRP'), ('also', 'RB'), ('possible', 'JJ'), ('decision', 'NN'), ('trees', 'NNS'), ('translated', 'VBN'), ('set', 'NN'), ('rules', 'NNS'), ('creating', 'VBG'), ('separate', 'JJ'), ('rule', 'NN'), ('path', 'NN'), ('root', 'NN'), ('leaf', 'NN'), ('tree', 'NN'), ('[', 'VBD'), ('13', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP General/NNP pseudo-code/NN building/NN decision/NN trees/NNS)
  3.2/CD
  (NP LEARNING/NNP SET/NNP OF/NNP RULES/NNP)
  It/PRP
  also/RB
  (NP possible/JJ decision/NN trees/NNS)
  translated/VBN
  (NP set/NN rules/NNS)
  creating/VBG
  (NP separate/JJ rule/NN path/NN root/NN leaf/NN tree/NN)
  [/VBD
  13/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['General pseudo-code building decision trees', 'LEARNING SET OF RULES', 'possible decision trees', 'set rules', 'separate rule path root leaf tree', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('General', 'gener'), ('pseudo-code', 'pseudo-cod'), ('building', 'build'), ('decision', 'decis'), ('trees', 'tree'), ('3.2', '3.2'), ('LEARNING', 'learn'), ('SET', 'set'), ('OF', 'of'), ('RULES', 'rule'), ('It', 'it'), ('also', 'also'), ('possible', 'possibl'), ('decision', 'decis'), ('trees', 'tree'), ('translated', 'translat'), ('set', 'set'), ('rules', 'rule'), ('creating', 'creat'), ('separate', 'separ'), ('rule', 'rule'), ('path', 'path'), ('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('General', 'general'), ('pseudo-code', 'pseudo-cod'), ('building', 'build'), ('decision', 'decis'), ('trees', 'tree'), ('3.2', '3.2'), ('LEARNING', 'learn'), ('SET', 'set'), ('OF', 'of'), ('RULES', 'rule'), ('It', 'it'), ('also', 'also'), ('possible', 'possibl'), ('decision', 'decis'), ('trees', 'tree'), ('translated', 'translat'), ('set', 'set'), ('rules', 'rule'), ('creating', 'creat'), ('separate', 'separ'), ('rule', 'rule'), ('path', 'path'), ('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('General', 'General'), ('pseudo-code', 'pseudo-code'), ('building', 'building'), ('decision', 'decision'), ('trees', 'tree'), ('3.2', '3.2'), ('LEARNING', 'LEARNING'), ('SET', 'SET'), ('OF', 'OF'), ('RULES', 'RULES'), ('It', 'It'), ('also', 'also'), ('possible', 'possible'), ('decision', 'decision'), ('trees', 'tree'), ('translated', 'translated'), ('set', 'set'), ('rules', 'rule'), ('creating', 'creating'), ('separate', 'separate'), ('rule', 'rule'), ('path', 'path'), ('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]



============================ Sentence 91 =============================

However, rules can also be directly   induced from training data using a variety of rule-based   algorithms. 


>> Tokens are: 
 ['However', ',', 'rules', 'also', 'directly', 'induced', 'training', 'data', 'using', 'variety', 'rule-based', 'algorithms', '.']

>> Bigrams are: 
 [('However', ','), (',', 'rules'), ('rules', 'also'), ('also', 'directly'), ('directly', 'induced'), ('induced', 'training'), ('training', 'data'), ('data', 'using'), ('using', 'variety'), ('variety', 'rule-based'), ('rule-based', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('However', ',', 'rules'), (',', 'rules', 'also'), ('rules', 'also', 'directly'), ('also', 'directly', 'induced'), ('directly', 'induced', 'training'), ('induced', 'training', 'data'), ('training', 'data', 'using'), ('data', 'using', 'variety'), ('using', 'variety', 'rule-based'), ('variety', 'rule-based', 'algorithms'), ('rule-based', 'algorithms', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('rules', 'NNS'), ('also', 'RB'), ('directly', 'RB'), ('induced', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('using', 'VBG'), ('variety', 'NN'), ('rule-based', 'JJ'), ('algorithms', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP rules/NNS)
  also/RB
  directly/RB
  (NP induced/JJ training/NN data/NNS)
  using/VBG
  (NP variety/NN)
  (NP rule-based/JJ algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['rules', 'induced training data', 'variety', 'rule-based algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'directli'), ('induced', 'induc'), ('training', 'train'), ('data', 'data'), ('using', 'use'), ('variety', 'varieti'), ('rule-based', 'rule-bas'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'direct'), ('induced', 'induc'), ('training', 'train'), ('data', 'data'), ('using', 'use'), ('variety', 'varieti'), ('rule-based', 'rule-bas'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'directly'), ('induced', 'induced'), ('training', 'training'), ('data', 'data'), ('using', 'using'), ('variety', 'variety'), ('rule-based', 'rule-based'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 92 =============================

In [14], the author has provided an excellent   overview of existing work in rule-based methods. 


>> Tokens are: 
 ['In', '[', '14', ']', ',', 'author', 'provided', 'excellent', 'overview', 'existing', 'work', 'rule-based', 'methods', '.']

>> Bigrams are: 
 [('In', '['), ('[', '14'), ('14', ']'), (']', ','), (',', 'author'), ('author', 'provided'), ('provided', 'excellent'), ('excellent', 'overview'), ('overview', 'existing'), ('existing', 'work'), ('work', 'rule-based'), ('rule-based', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('In', '[', '14'), ('[', '14', ']'), ('14', ']', ','), (']', ',', 'author'), (',', 'author', 'provided'), ('author', 'provided', 'excellent'), ('provided', 'excellent', 'overview'), ('excellent', 'overview', 'existing'), ('overview', 'existing', 'work'), ('existing', 'work', 'rule-based'), ('work', 'rule-based', 'methods'), ('rule-based', 'methods', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('14', 'CD'), (']', 'NNP'), (',', ','), ('author', 'NN'), ('provided', 'VBD'), ('excellent', 'JJ'), ('overview', 'NN'), ('existing', 'VBG'), ('work', 'NN'), ('rule-based', 'JJ'), ('methods', 'NNS'), ('.', '.')]

 (S
  In/IN
  [/$
  14/CD
  (NP ]/NNP)
  ,/,
  (NP author/NN)
  provided/VBD
  (NP excellent/JJ overview/NN)
  existing/VBG
  (NP work/NN)
  (NP rule-based/JJ methods/NNS)
  ./.) 


>> Noun Phrases are: 
 [']', 'author', 'excellent overview', 'work', 'rule-based methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provid'), ('excellent', 'excel'), ('overview', 'overview'), ('existing', 'exist'), ('work', 'work'), ('rule-based', 'rule-bas'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provid'), ('excellent', 'excel'), ('overview', 'overview'), ('existing', 'exist'), ('work', 'work'), ('rule-based', 'rule-bas'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provided'), ('excellent', 'excellent'), ('overview', 'overview'), ('existing', 'existing'), ('work', 'work'), ('rule-based', 'rule-based'), ('methods', 'method'), ('.', '.')]



============================ Sentence 93 =============================

The   classification rules represent each class by Disjunctive Normal   Form (DNF). 


>> Tokens are: 
 ['The', 'classification', 'rules', 'represent', 'class', 'Disjunctive', 'Normal', 'Form', '(', 'DNF', ')', '.']

>> Bigrams are: 
 [('The', 'classification'), ('classification', 'rules'), ('rules', 'represent'), ('represent', 'class'), ('class', 'Disjunctive'), ('Disjunctive', 'Normal'), ('Normal', 'Form'), ('Form', '('), ('(', 'DNF'), ('DNF', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'classification', 'rules'), ('classification', 'rules', 'represent'), ('rules', 'represent', 'class'), ('represent', 'class', 'Disjunctive'), ('class', 'Disjunctive', 'Normal'), ('Disjunctive', 'Normal', 'Form'), ('Normal', 'Form', '('), ('Form', '(', 'DNF'), ('(', 'DNF', ')'), ('DNF', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('classification', 'NN'), ('rules', 'NNS'), ('represent', 'VBP'), ('class', 'NN'), ('Disjunctive', 'NNP'), ('Normal', 'NNP'), ('Form', 'NNP'), ('(', '('), ('DNF', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT classification/NN rules/NNS)
  represent/VBP
  (NP class/NN Disjunctive/NNP Normal/NNP Form/NNP)
  (/(
  (NP DNF/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The classification rules', 'class Disjunctive Normal Form', 'DNF']

>> Named Entities are: 
 [('ORGANIZATION', 'DNF')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('rules', 'rule'), ('represent', 'repres'), ('class', 'class'), ('Disjunctive', 'disjunct'), ('Normal', 'normal'), ('Form', 'form'), ('(', '('), ('DNF', 'dnf'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('rules', 'rule'), ('represent', 'repres'), ('class', 'class'), ('Disjunctive', 'disjunct'), ('Normal', 'normal'), ('Form', 'form'), ('(', '('), ('DNF', 'dnf'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('classification', 'classification'), ('rules', 'rule'), ('represent', 'represent'), ('class', 'class'), ('Disjunctive', 'Disjunctive'), ('Normal', 'Normal'), ('Form', 'Form'), ('(', '('), ('DNF', 'DNF'), (')', ')'), ('.', '.')]



============================ Sentence 94 =============================

A statement is in DNF if it is a disjunction   (sequence of ORs) consisting of one or more disjuncts, each of   which is a conjunction (AND) of one or more literals. 


>> Tokens are: 
 ['A', 'statement', 'DNF', 'disjunction', '(', 'sequence', 'ORs', ')', 'consisting', 'one', 'disjuncts', ',', 'conjunction', '(', 'AND', ')', 'one', 'literals', '.']

>> Bigrams are: 
 [('A', 'statement'), ('statement', 'DNF'), ('DNF', 'disjunction'), ('disjunction', '('), ('(', 'sequence'), ('sequence', 'ORs'), ('ORs', ')'), (')', 'consisting'), ('consisting', 'one'), ('one', 'disjuncts'), ('disjuncts', ','), (',', 'conjunction'), ('conjunction', '('), ('(', 'AND'), ('AND', ')'), (')', 'one'), ('one', 'literals'), ('literals', '.')]

>> Trigrams are: 
 [('A', 'statement', 'DNF'), ('statement', 'DNF', 'disjunction'), ('DNF', 'disjunction', '('), ('disjunction', '(', 'sequence'), ('(', 'sequence', 'ORs'), ('sequence', 'ORs', ')'), ('ORs', ')', 'consisting'), (')', 'consisting', 'one'), ('consisting', 'one', 'disjuncts'), ('one', 'disjuncts', ','), ('disjuncts', ',', 'conjunction'), (',', 'conjunction', '('), ('conjunction', '(', 'AND'), ('(', 'AND', ')'), ('AND', ')', 'one'), (')', 'one', 'literals'), ('one', 'literals', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('statement', 'NN'), ('DNF', 'NNP'), ('disjunction', 'NN'), ('(', '('), ('sequence', 'JJ'), ('ORs', 'NNP'), (')', ')'), ('consisting', 'VBG'), ('one', 'CD'), ('disjuncts', 'NNS'), (',', ','), ('conjunction', 'NN'), ('(', '('), ('AND', 'CC'), (')', ')'), ('one', 'CD'), ('literals', 'NNS'), ('.', '.')]

 (S
  (NP A/DT statement/NN DNF/NNP disjunction/NN)
  (/(
  (NP sequence/JJ ORs/NNP)
  )/)
  consisting/VBG
  one/CD
  (NP disjuncts/NNS)
  ,/,
  (NP conjunction/NN)
  (/(
  AND/CC
  )/)
  one/CD
  (NP literals/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A statement DNF disjunction', 'sequence ORs', 'disjuncts', 'conjunction', 'literals']

>> Named Entities are: 
 [('ORGANIZATION', 'DNF')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('statement', 'statement'), ('DNF', 'dnf'), ('disjunction', 'disjunct'), ('(', '('), ('sequence', 'sequenc'), ('ORs', 'or'), (')', ')'), ('consisting', 'consist'), ('one', 'one'), ('disjuncts', 'disjunct'), (',', ','), ('conjunction', 'conjunct'), ('(', '('), ('AND', 'and'), (')', ')'), ('one', 'one'), ('literals', 'liter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('statement', 'statement'), ('DNF', 'dnf'), ('disjunction', 'disjunct'), ('(', '('), ('sequence', 'sequenc'), ('ORs', 'or'), (')', ')'), ('consisting', 'consist'), ('one', 'one'), ('disjuncts', 'disjunct'), (',', ','), ('conjunction', 'conjunct'), ('(', '('), ('AND', 'and'), (')', ')'), ('one', 'one'), ('literals', 'liter'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('statement', 'statement'), ('DNF', 'DNF'), ('disjunction', 'disjunction'), ('(', '('), ('sequence', 'sequence'), ('ORs', 'ORs'), (')', ')'), ('consisting', 'consisting'), ('one', 'one'), ('disjuncts', 'disjuncts'), (',', ','), ('conjunction', 'conjunction'), ('(', '('), ('AND', 'AND'), (')', ')'), ('one', 'one'), ('literals', 'literal'), ('.', '.')]



============================ Sentence 95 =============================

Below is   an example of disjunctive normal forms. 


>> Tokens are: 
 ['Below', 'example', 'disjunctive', 'normal', 'forms', '.']

>> Bigrams are: 
 [('Below', 'example'), ('example', 'disjunctive'), ('disjunctive', 'normal'), ('normal', 'forms'), ('forms', '.')]

>> Trigrams are: 
 [('Below', 'example', 'disjunctive'), ('example', 'disjunctive', 'normal'), ('disjunctive', 'normal', 'forms'), ('normal', 'forms', '.')]

>> POS Tags are: 
 [('Below', 'IN'), ('example', 'NN'), ('disjunctive', 'JJ'), ('normal', 'JJ'), ('forms', 'NNS'), ('.', '.')]

 (S
  Below/IN
  (NP example/NN)
  (NP disjunctive/JJ normal/JJ forms/NNS)
  ./.) 


>> Noun Phrases are: 
 ['example', 'disjunctive normal forms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Below', 'below'), ('example', 'exampl'), ('disjunctive', 'disjunct'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Below', 'below'), ('example', 'exampl'), ('disjunctive', 'disjunct'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]

>> Lemmatization: 
 [('Below', 'Below'), ('example', 'example'), ('disjunctive', 'disjunctive'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]



============================ Sentence 96 =============================

A k-DNF expression is of the form:          nnnn AAAAAA 22121     knnknk AAA   2111 , where k is the number of   disjunctions, n is the number of conjunctions in each disjunction,   and An is defined over the alphabet   jj AAAAAA  2121 ~,~,,,,  . 


>> Tokens are: 
 ['A', 'k-DNF', 'expression', 'form', ':', '\uf028', '\uf029', '\uf028', '\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b', '\uf04b\uf04b\uf04b', 'nnnn', 'AAAAAA', '22121', '\uf028', '\uf029', '\uf028', '\uf029\uf028', '\uf029knnknk', 'AAA', '\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d', '\uf04b2111', ',', 'k', 'number', 'disjunctions', ',', 'n', 'number', 'conjunctions', 'disjunction', ',', 'An', 'defined', 'alphabet', 'jj', 'AAAAAA', '\uf04b\uf04b', '2121', '~', ',', '~', ',', ',', ',', ',', '\uf04a', '.']

>> Bigrams are: 
 [('A', 'k-DNF'), ('k-DNF', 'expression'), ('expression', 'form'), ('form', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029\uf028'), ('\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b'), ('\uf02b\uf02b', '\uf04b\uf04b\uf04b'), ('\uf04b\uf04b\uf04b', 'nnnn'), ('nnnn', 'AAAAAA'), ('AAAAAA', '22121'), ('22121', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029\uf028'), ('\uf029\uf028', '\uf029knnknk'), ('\uf029knnknk', 'AAA'), ('AAA', '\uf0d9\uf0d9\uf0d9'), ('\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d'), ('\uf02b\uf02d\uf02b\uf02d', '\uf04b2111'), ('\uf04b2111', ','), (',', 'k'), ('k', 'number'), ('number', 'disjunctions'), ('disjunctions', ','), (',', 'n'), ('n', 'number'), ('number', 'conjunctions'), ('conjunctions', 'disjunction'), ('disjunction', ','), (',', 'An'), ('An', 'defined'), ('defined', 'alphabet'), ('alphabet', 'jj'), ('jj', 'AAAAAA'), ('AAAAAA', '\uf04b\uf04b'), ('\uf04b\uf04b', '2121'), ('2121', '~'), ('~', ','), (',', '~'), ('~', ','), (',', ','), (',', ','), (',', ','), (',', '\uf04a'), ('\uf04a', '.')]

>> Trigrams are: 
 [('A', 'k-DNF', 'expression'), ('k-DNF', 'expression', 'form'), ('expression', 'form', ':'), ('form', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029\uf028'), ('\uf028', '\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b', '\uf04b\uf04b\uf04b'), ('\uf02b\uf02b', '\uf04b\uf04b\uf04b', 'nnnn'), ('\uf04b\uf04b\uf04b', 'nnnn', 'AAAAAA'), ('nnnn', 'AAAAAA', '22121'), ('AAAAAA', '22121', '\uf028'), ('22121', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029\uf028'), ('\uf028', '\uf029\uf028', '\uf029knnknk'), ('\uf029\uf028', '\uf029knnknk', 'AAA'), ('\uf029knnknk', 'AAA', '\uf0d9\uf0d9\uf0d9'), ('AAA', '\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d'), ('\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d', '\uf04b2111'), ('\uf02b\uf02d\uf02b\uf02d', '\uf04b2111', ','), ('\uf04b2111', ',', 'k'), (',', 'k', 'number'), ('k', 'number', 'disjunctions'), ('number', 'disjunctions', ','), ('disjunctions', ',', 'n'), (',', 'n', 'number'), ('n', 'number', 'conjunctions'), ('number', 'conjunctions', 'disjunction'), ('conjunctions', 'disjunction', ','), ('disjunction', ',', 'An'), (',', 'An', 'defined'), ('An', 'defined', 'alphabet'), ('defined', 'alphabet', 'jj'), ('alphabet', 'jj', 'AAAAAA'), ('jj', 'AAAAAA', '\uf04b\uf04b'), ('AAAAAA', '\uf04b\uf04b', '2121'), ('\uf04b\uf04b', '2121', '~'), ('2121', '~', ','), ('~', ',', '~'), (',', '~', ','), ('~', ',', ','), (',', ',', ','), (',', ',', ','), (',', ',', '\uf04a'), (',', '\uf04a', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('k-DNF', 'JJ'), ('expression', 'NN'), ('form', 'NN'), (':', ':'), ('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029\uf028', 'NNP'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', 'NNP'), ('\uf02b\uf02b', 'NNP'), ('\uf04b\uf04b\uf04b', 'NNP'), ('nnnn', 'VBD'), ('AAAAAA', 'NNP'), ('22121', 'CD'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029\uf028', 'NNP'), ('\uf029knnknk', 'NNP'), ('AAA', 'NNP'), ('\uf0d9\uf0d9\uf0d9', 'NNP'), ('\uf02b\uf02d\uf02b\uf02d', 'NNP'), ('\uf04b2111', 'NNP'), (',', ','), ('k', 'VBZ'), ('number', 'NN'), ('disjunctions', 'NNS'), (',', ','), ('n', 'JJ'), ('number', 'NN'), ('conjunctions', 'NNS'), ('disjunction', 'NN'), (',', ','), ('An', 'DT'), ('defined', 'JJ'), ('alphabet', 'NN'), ('jj', 'NN'), ('AAAAAA', 'NNP'), ('\uf04b\uf04b', 'NN'), ('2121', 'CD'), ('~', 'NN'), (',', ','), ('~', 'NNP'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', 'UH'), ('.', '.')]

 (S
  (NP A/DT k-DNF/JJ expression/NN form/NN)
  :/:
  (NP /JJ /NNP /NNP /NNP /NNP /NNP /NNP)
  nnnn/VBD
  (NP AAAAAA/NNP)
  22121/CD
  (NP
    /NNP
    /NNP
    /NNP
    /NNP
    knnknk/NNP
    AAA/NNP
    /NNP
    /NNP
    2111/NNP)
  ,/,
  k/VBZ
  (NP number/NN disjunctions/NNS)
  ,/,
  (NP n/JJ number/NN conjunctions/NNS disjunction/NN)
  ,/,
  (NP An/DT defined/JJ alphabet/NN jj/NN AAAAAA/NNP /NN)
  2121/CD
  (NP ~/NN)
  ,/,
  (NP ~/NNP)
  ,/,
  ,/,
  ,/,
  ,/,
  /UH
  ./.) 


>> Noun Phrases are: 
 ['A k-DNF expression form', '\uf028 \uf029 \uf028 \uf029\uf028 \uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9 \uf02b\uf02b \uf04b\uf04b\uf04b', 'AAAAAA', '\uf028 \uf029 \uf028 \uf029\uf028 \uf029knnknk AAA \uf0d9\uf0d9\uf0d9 \uf02b\uf02d\uf02b\uf02d \uf04b2111', 'number disjunctions', 'n number conjunctions disjunction', 'An defined alphabet jj AAAAAA \uf04b\uf04b', '~', '~']

>> Named Entities are: 
 [('ORGANIZATION', 'AAAAAA'), ('ORGANIZATION', 'AAAAAA')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('k-DNF', 'k-dnf'), ('expression', 'express'), ('form', 'form'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'aaaaaa'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'aaa'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number'), ('disjunctions', 'disjunct'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunct'), ('disjunction', 'disjunct'), (',', ','), ('An', 'an'), ('defined', 'defin'), ('alphabet', 'alphabet'), ('jj', 'jj'), ('AAAAAA', 'aaaaaa'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('k-DNF', 'k-dnf'), ('expression', 'express'), ('form', 'form'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'aaaaaa'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'aaa'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number'), ('disjunctions', 'disjunct'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunct'), ('disjunction', 'disjunct'), (',', ','), ('An', 'an'), ('defined', 'defin'), ('alphabet', 'alphabet'), ('jj', 'jj'), ('AAAAAA', 'aaaaaa'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('k-DNF', 'k-DNF'), ('expression', 'expression'), ('form', 'form'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'AAAAAA'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'AAA'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number'), ('disjunctions', 'disjunction'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunction'), ('disjunction', 'disjunction'), (',', ','), ('An', 'An'), ('defined', 'defined'), ('alphabet', 'alphabet'), ('jj', 'jj'), ('AAAAAA', 'AAAAAA'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]



============================ Sentence 97 =============================

Here the objective is to build   the smallest rule-set that is consistent with the training data [1]. 


>> Tokens are: 
 ['Here', 'objective', 'build', 'smallest', 'rule-set', 'consistent', 'training', 'data', '[', '1', ']', '.']

>> Bigrams are: 
 [('Here', 'objective'), ('objective', 'build'), ('build', 'smallest'), ('smallest', 'rule-set'), ('rule-set', 'consistent'), ('consistent', 'training'), ('training', 'data'), ('data', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Here', 'objective', 'build'), ('objective', 'build', 'smallest'), ('build', 'smallest', 'rule-set'), ('smallest', 'rule-set', 'consistent'), ('rule-set', 'consistent', 'training'), ('consistent', 'training', 'data'), ('training', 'data', '['), ('data', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('objective', 'JJ'), ('build', 'NN'), ('smallest', 'JJS'), ('rule-set', 'JJ'), ('consistent', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Here/RB
  (NP objective/JJ build/NN)
  smallest/JJS
  (NP rule-set/JJ consistent/JJ training/NN data/NNS)
  [/$
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['objective build', 'rule-set consistent training data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('objective', 'object'), ('build', 'build'), ('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consist'), ('training', 'train'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('objective', 'object'), ('build', 'build'), ('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consist'), ('training', 'train'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('objective', 'objective'), ('build', 'build'), ('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consistent'), ('training', 'training'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 98 =============================

A good number of learned rules is usually a positive sign that the   learning algorithm is attempting to remember the training set,   instead of discovering the assumptions that govern it. 


>> Tokens are: 
 ['A', 'good', 'number', 'learned', 'rules', 'usually', 'positive', 'sign', 'learning', 'algorithm', 'attempting', 'remember', 'training', 'set', ',', 'instead', 'discovering', 'assumptions', 'govern', '.']

>> Bigrams are: 
 [('A', 'good'), ('good', 'number'), ('number', 'learned'), ('learned', 'rules'), ('rules', 'usually'), ('usually', 'positive'), ('positive', 'sign'), ('sign', 'learning'), ('learning', 'algorithm'), ('algorithm', 'attempting'), ('attempting', 'remember'), ('remember', 'training'), ('training', 'set'), ('set', ','), (',', 'instead'), ('instead', 'discovering'), ('discovering', 'assumptions'), ('assumptions', 'govern'), ('govern', '.')]

>> Trigrams are: 
 [('A', 'good', 'number'), ('good', 'number', 'learned'), ('number', 'learned', 'rules'), ('learned', 'rules', 'usually'), ('rules', 'usually', 'positive'), ('usually', 'positive', 'sign'), ('positive', 'sign', 'learning'), ('sign', 'learning', 'algorithm'), ('learning', 'algorithm', 'attempting'), ('algorithm', 'attempting', 'remember'), ('attempting', 'remember', 'training'), ('remember', 'training', 'set'), ('training', 'set', ','), ('set', ',', 'instead'), (',', 'instead', 'discovering'), ('instead', 'discovering', 'assumptions'), ('discovering', 'assumptions', 'govern'), ('assumptions', 'govern', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('good', 'JJ'), ('number', 'NN'), ('learned', 'VBN'), ('rules', 'NNS'), ('usually', 'RB'), ('positive', 'JJ'), ('sign', 'NN'), ('learning', 'VBG'), ('algorithm', 'RP'), ('attempting', 'VBG'), ('remember', 'VB'), ('training', 'NN'), ('set', 'VBN'), (',', ','), ('instead', 'RB'), ('discovering', 'VBG'), ('assumptions', 'NNS'), ('govern', 'VBP'), ('.', '.')]

 (S
  (NP A/DT good/JJ number/NN)
  learned/VBN
  (NP rules/NNS)
  usually/RB
  (NP positive/JJ sign/NN)
  learning/VBG
  algorithm/RP
  attempting/VBG
  remember/VB
  (NP training/NN)
  set/VBN
  ,/,
  instead/RB
  discovering/VBG
  (NP assumptions/NNS)
  govern/VBP
  ./.) 


>> Noun Phrases are: 
 ['A good number', 'rules', 'positive sign', 'training', 'assumptions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('learned', 'learn'), ('rules', 'rule'), ('usually', 'usual'), ('positive', 'posit'), ('sign', 'sign'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('attempting', 'attempt'), ('remember', 'rememb'), ('training', 'train'), ('set', 'set'), (',', ','), ('instead', 'instead'), ('discovering', 'discov'), ('assumptions', 'assumpt'), ('govern', 'govern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('learned', 'learn'), ('rules', 'rule'), ('usually', 'usual'), ('positive', 'posit'), ('sign', 'sign'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('attempting', 'attempt'), ('remember', 'rememb'), ('training', 'train'), ('set', 'set'), (',', ','), ('instead', 'instead'), ('discovering', 'discov'), ('assumptions', 'assumpt'), ('govern', 'govern'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('good', 'good'), ('number', 'number'), ('learned', 'learned'), ('rules', 'rule'), ('usually', 'usually'), ('positive', 'positive'), ('sign', 'sign'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('attempting', 'attempting'), ('remember', 'remember'), ('training', 'training'), ('set', 'set'), (',', ','), ('instead', 'instead'), ('discovering', 'discovering'), ('assumptions', 'assumption'), ('govern', 'govern'), ('.', '.')]



============================ Sentence 99 =============================

A   separate-and-conquer algorithm (recursively breaking down a   problem into sub-problems) search for a rule that explains a part   of its training instances, separates these instances and recursively   conquers the remaining instances by learning more rules, until   no instances remain [1]. 


>> Tokens are: 
 ['A', 'separate-and-conquer', 'algorithm', '(', 'recursively', 'breaking', 'problem', 'sub-problems', ')', 'search', 'rule', 'explains', 'part', 'training', 'instances', ',', 'separates', 'instances', 'recursively', 'conquers', 'remaining', 'instances', 'learning', 'rules', ',', 'instances', 'remain', '[', '1', ']', '.']

>> Bigrams are: 
 [('A', 'separate-and-conquer'), ('separate-and-conquer', 'algorithm'), ('algorithm', '('), ('(', 'recursively'), ('recursively', 'breaking'), ('breaking', 'problem'), ('problem', 'sub-problems'), ('sub-problems', ')'), (')', 'search'), ('search', 'rule'), ('rule', 'explains'), ('explains', 'part'), ('part', 'training'), ('training', 'instances'), ('instances', ','), (',', 'separates'), ('separates', 'instances'), ('instances', 'recursively'), ('recursively', 'conquers'), ('conquers', 'remaining'), ('remaining', 'instances'), ('instances', 'learning'), ('learning', 'rules'), ('rules', ','), (',', 'instances'), ('instances', 'remain'), ('remain', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'separate-and-conquer', 'algorithm'), ('separate-and-conquer', 'algorithm', '('), ('algorithm', '(', 'recursively'), ('(', 'recursively', 'breaking'), ('recursively', 'breaking', 'problem'), ('breaking', 'problem', 'sub-problems'), ('problem', 'sub-problems', ')'), ('sub-problems', ')', 'search'), (')', 'search', 'rule'), ('search', 'rule', 'explains'), ('rule', 'explains', 'part'), ('explains', 'part', 'training'), ('part', 'training', 'instances'), ('training', 'instances', ','), ('instances', ',', 'separates'), (',', 'separates', 'instances'), ('separates', 'instances', 'recursively'), ('instances', 'recursively', 'conquers'), ('recursively', 'conquers', 'remaining'), ('conquers', 'remaining', 'instances'), ('remaining', 'instances', 'learning'), ('instances', 'learning', 'rules'), ('learning', 'rules', ','), ('rules', ',', 'instances'), (',', 'instances', 'remain'), ('instances', 'remain', '['), ('remain', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('separate-and-conquer', 'JJ'), ('algorithm', 'NN'), ('(', '('), ('recursively', 'RB'), ('breaking', 'VBG'), ('problem', 'NN'), ('sub-problems', 'NN'), (')', ')'), ('search', 'NN'), ('rule', 'NN'), ('explains', 'VBZ'), ('part', 'NN'), ('training', 'NN'), ('instances', 'NNS'), (',', ','), ('separates', 'NNS'), ('instances', 'NNS'), ('recursively', 'RB'), ('conquers', 'NNS'), ('remaining', 'VBG'), ('instances', 'NNS'), ('learning', 'VBG'), ('rules', 'NNS'), (',', ','), ('instances', 'NNS'), ('remain', 'VBP'), ('[', 'JJ'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP A/DT separate-and-conquer/JJ algorithm/NN)
  (/(
  recursively/RB
  breaking/VBG
  (NP problem/NN sub-problems/NN)
  )/)
  (NP search/NN rule/NN)
  explains/VBZ
  (NP part/NN training/NN instances/NNS)
  ,/,
  (NP separates/NNS instances/NNS)
  recursively/RB
  (NP conquers/NNS)
  remaining/VBG
  (NP instances/NNS)
  learning/VBG
  (NP rules/NNS)
  ,/,
  (NP instances/NNS)
  remain/VBP
  [/JJ
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['A separate-and-conquer algorithm', 'problem sub-problems', 'search rule', 'part training instances', 'separates instances', 'conquers', 'instances', 'rules', 'instances', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('separate-and-conquer', 'separate-and-conqu'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recurs'), ('breaking', 'break'), ('problem', 'problem'), ('sub-problems', 'sub-problem'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explain'), ('part', 'part'), ('training', 'train'), ('instances', 'instanc'), (',', ','), ('separates', 'separ'), ('instances', 'instanc'), ('recursively', 'recurs'), ('conquers', 'conquer'), ('remaining', 'remain'), ('instances', 'instanc'), ('learning', 'learn'), ('rules', 'rule'), (',', ','), ('instances', 'instanc'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('separate-and-conquer', 'separate-and-conqu'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recurs'), ('breaking', 'break'), ('problem', 'problem'), ('sub-problems', 'sub-problem'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explain'), ('part', 'part'), ('training', 'train'), ('instances', 'instanc'), (',', ','), ('separates', 'separ'), ('instances', 'instanc'), ('recursively', 'recurs'), ('conquers', 'conquer'), ('remaining', 'remain'), ('instances', 'instanc'), ('learning', 'learn'), ('rules', 'rule'), (',', ','), ('instances', 'instanc'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('separate-and-conquer', 'separate-and-conquer'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recursively'), ('breaking', 'breaking'), ('problem', 'problem'), ('sub-problems', 'sub-problems'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explains'), ('part', 'part'), ('training', 'training'), ('instances', 'instance'), (',', ','), ('separates', 'separate'), ('instances', 'instance'), ('recursively', 'recursively'), ('conquers', 'conquers'), ('remaining', 'remaining'), ('instances', 'instance'), ('learning', 'learning'), ('rules', 'rule'), (',', ','), ('instances', 'instance'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 100 =============================

In below Fig.5, a general pseudo-code   for rule learners is presented. 


>> Tokens are: 
 ['In', 'Fig.5', ',', 'general', 'pseudo-code', 'rule', 'learners', 'presented', '.']

>> Bigrams are: 
 [('In', 'Fig.5'), ('Fig.5', ','), (',', 'general'), ('general', 'pseudo-code'), ('pseudo-code', 'rule'), ('rule', 'learners'), ('learners', 'presented'), ('presented', '.')]

>> Trigrams are: 
 [('In', 'Fig.5', ','), ('Fig.5', ',', 'general'), (',', 'general', 'pseudo-code'), ('general', 'pseudo-code', 'rule'), ('pseudo-code', 'rule', 'learners'), ('rule', 'learners', 'presented'), ('learners', 'presented', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Fig.5', 'NNP'), (',', ','), ('general', 'JJ'), ('pseudo-code', 'NN'), ('rule', 'NN'), ('learners', 'NNS'), ('presented', 'VBD'), ('.', '.')]

 (S
  In/IN
  (NP Fig.5/NNP)
  ,/,
  (NP general/JJ pseudo-code/NN rule/NN learners/NNS)
  presented/VBD
  ./.) 


>> Noun Phrases are: 
 ['Fig.5', 'general pseudo-code rule learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Fig.5', 'fig.5'), (',', ','), ('general', 'gener'), ('pseudo-code', 'pseudo-cod'), ('rule', 'rule'), ('learners', 'learner'), ('presented', 'present'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Fig.5', 'fig.5'), (',', ','), ('general', 'general'), ('pseudo-code', 'pseudo-cod'), ('rule', 'rule'), ('learners', 'learner'), ('presented', 'present'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Fig.5', 'Fig.5'), (',', ','), ('general', 'general'), ('pseudo-code', 'pseudo-code'), ('rule', 'rule'), ('learners', 'learner'), ('presented', 'presented'), ('.', '.')]



============================ Sentence 101 =============================

Fig.5. 


>> Tokens are: 
 ['Fig.5', '.']

>> Bigrams are: 
 [('Fig.5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.5', 'NNP'), ('.', '.')]

 (S (NP Fig.5/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.5', 'fig.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.5', 'fig.5'), ('.', '.')]

>> Lemmatization: 
 [('Fig.5', 'Fig.5'), ('.', '.')]



============================ Sentence 102 =============================

A general Pseudo code for rule learners   The core difference between heuristics for rule learning   algorithms and heuristics for decision trees algorithms is that the   latter evaluate the average quality of a number of disjointed sets,   while rule learners only evaluate the quality of the set of   instances that is covered by the candidate rule [1]. 


>> Tokens are: 
 ['A', 'general', 'Pseudo', 'code', 'rule', 'learners', 'The', 'core', 'difference', 'heuristics', 'rule', 'learning', 'algorithms', 'heuristics', 'decision', 'trees', 'algorithms', 'latter', 'evaluate', 'average', 'quality', 'number', 'disjointed', 'sets', ',', 'rule', 'learners', 'evaluate', 'quality', 'set', 'instances', 'covered', 'candidate', 'rule', '[', '1', ']', '.']

>> Bigrams are: 
 [('A', 'general'), ('general', 'Pseudo'), ('Pseudo', 'code'), ('code', 'rule'), ('rule', 'learners'), ('learners', 'The'), ('The', 'core'), ('core', 'difference'), ('difference', 'heuristics'), ('heuristics', 'rule'), ('rule', 'learning'), ('learning', 'algorithms'), ('algorithms', 'heuristics'), ('heuristics', 'decision'), ('decision', 'trees'), ('trees', 'algorithms'), ('algorithms', 'latter'), ('latter', 'evaluate'), ('evaluate', 'average'), ('average', 'quality'), ('quality', 'number'), ('number', 'disjointed'), ('disjointed', 'sets'), ('sets', ','), (',', 'rule'), ('rule', 'learners'), ('learners', 'evaluate'), ('evaluate', 'quality'), ('quality', 'set'), ('set', 'instances'), ('instances', 'covered'), ('covered', 'candidate'), ('candidate', 'rule'), ('rule', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'general', 'Pseudo'), ('general', 'Pseudo', 'code'), ('Pseudo', 'code', 'rule'), ('code', 'rule', 'learners'), ('rule', 'learners', 'The'), ('learners', 'The', 'core'), ('The', 'core', 'difference'), ('core', 'difference', 'heuristics'), ('difference', 'heuristics', 'rule'), ('heuristics', 'rule', 'learning'), ('rule', 'learning', 'algorithms'), ('learning', 'algorithms', 'heuristics'), ('algorithms', 'heuristics', 'decision'), ('heuristics', 'decision', 'trees'), ('decision', 'trees', 'algorithms'), ('trees', 'algorithms', 'latter'), ('algorithms', 'latter', 'evaluate'), ('latter', 'evaluate', 'average'), ('evaluate', 'average', 'quality'), ('average', 'quality', 'number'), ('quality', 'number', 'disjointed'), ('number', 'disjointed', 'sets'), ('disjointed', 'sets', ','), ('sets', ',', 'rule'), (',', 'rule', 'learners'), ('rule', 'learners', 'evaluate'), ('learners', 'evaluate', 'quality'), ('evaluate', 'quality', 'set'), ('quality', 'set', 'instances'), ('set', 'instances', 'covered'), ('instances', 'covered', 'candidate'), ('covered', 'candidate', 'rule'), ('candidate', 'rule', '['), ('rule', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('general', 'JJ'), ('Pseudo', 'NNP'), ('code', 'NN'), ('rule', 'NN'), ('learners', 'VBZ'), ('The', 'DT'), ('core', 'NN'), ('difference', 'NN'), ('heuristics', 'NNS'), ('rule', 'VBP'), ('learning', 'VBG'), ('algorithms', 'NN'), ('heuristics', 'NNS'), ('decision', 'NN'), ('trees', 'NNS'), ('algorithms', 'VBP'), ('latter', 'JJ'), ('evaluate', 'JJ'), ('average', 'JJ'), ('quality', 'NN'), ('number', 'NN'), ('disjointed', 'VBN'), ('sets', 'NNS'), (',', ','), ('rule', 'NN'), ('learners', 'NNS'), ('evaluate', 'VBP'), ('quality', 'NN'), ('set', 'VBN'), ('instances', 'NNS'), ('covered', 'VBD'), ('candidate', 'NN'), ('rule', 'NN'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP A/DT general/JJ Pseudo/NNP code/NN rule/NN)
  learners/VBZ
  (NP The/DT core/NN difference/NN heuristics/NNS)
  rule/VBP
  learning/VBG
  (NP algorithms/NN heuristics/NNS decision/NN trees/NNS)
  algorithms/VBP
  (NP latter/JJ evaluate/JJ average/JJ quality/NN number/NN)
  disjointed/VBN
  (NP sets/NNS)
  ,/,
  (NP rule/NN learners/NNS)
  evaluate/VBP
  (NP quality/NN)
  set/VBN
  (NP instances/NNS)
  covered/VBD
  (NP candidate/NN rule/NN)
  [/VBD
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['A general Pseudo code rule', 'The core difference heuristics', 'algorithms heuristics decision trees', 'latter evaluate average quality number', 'sets', 'rule learners', 'quality', 'instances', 'candidate rule', ']']

>> Named Entities are: 
 [('PERSON', 'Pseudo')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('general', 'gener'), ('Pseudo', 'pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner'), ('The', 'the'), ('core', 'core'), ('difference', 'differ'), ('heuristics', 'heurist'), ('rule', 'rule'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('heuristics', 'heurist'), ('decision', 'decis'), ('trees', 'tree'), ('algorithms', 'algorithm'), ('latter', 'latter'), ('evaluate', 'evalu'), ('average', 'averag'), ('quality', 'qualiti'), ('number', 'number'), ('disjointed', 'disjoint'), ('sets', 'set'), (',', ','), ('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evalu'), ('quality', 'qualiti'), ('set', 'set'), ('instances', 'instanc'), ('covered', 'cover'), ('candidate', 'candid'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('general', 'general'), ('Pseudo', 'pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner'), ('The', 'the'), ('core', 'core'), ('difference', 'differ'), ('heuristics', 'heurist'), ('rule', 'rule'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('heuristics', 'heurist'), ('decision', 'decis'), ('trees', 'tree'), ('algorithms', 'algorithm'), ('latter', 'latter'), ('evaluate', 'evalu'), ('average', 'averag'), ('quality', 'qualiti'), ('number', 'number'), ('disjointed', 'disjoint'), ('sets', 'set'), (',', ','), ('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evalu'), ('quality', 'qualiti'), ('set', 'set'), ('instances', 'instanc'), ('covered', 'cover'), ('candidate', 'candid'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('general', 'general'), ('Pseudo', 'Pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner'), ('The', 'The'), ('core', 'core'), ('difference', 'difference'), ('heuristics', 'heuristic'), ('rule', 'rule'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('heuristics', 'heuristic'), ('decision', 'decision'), ('trees', 'tree'), ('algorithms', 'algorithm'), ('latter', 'latter'), ('evaluate', 'evaluate'), ('average', 'average'), ('quality', 'quality'), ('number', 'number'), ('disjointed', 'disjointed'), ('sets', 'set'), (',', ','), ('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evaluate'), ('quality', 'quality'), ('set', 'set'), ('instances', 'instance'), ('covered', 'covered'), ('candidate', 'candidate'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 103 =============================

One of the   most useful characteristic of rule based classifiers is their   comprehensibility. 


>> Tokens are: 
 ['One', 'useful', 'characteristic', 'rule', 'based', 'classifiers', 'comprehensibility', '.']

>> Bigrams are: 
 [('One', 'useful'), ('useful', 'characteristic'), ('characteristic', 'rule'), ('rule', 'based'), ('based', 'classifiers'), ('classifiers', 'comprehensibility'), ('comprehensibility', '.')]

>> Trigrams are: 
 [('One', 'useful', 'characteristic'), ('useful', 'characteristic', 'rule'), ('characteristic', 'rule', 'based'), ('rule', 'based', 'classifiers'), ('based', 'classifiers', 'comprehensibility'), ('classifiers', 'comprehensibility', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('useful', 'JJ'), ('characteristic', 'JJ'), ('rule', 'NN'), ('based', 'VBN'), ('classifiers', 'NNS'), ('comprehensibility', 'NN'), ('.', '.')]

 (S
  One/CD
  (NP useful/JJ characteristic/JJ rule/NN)
  based/VBN
  (NP classifiers/NNS comprehensibility/NN)
  ./.) 


>> Noun Phrases are: 
 ['useful characteristic rule', 'classifiers comprehensibility']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('useful', 'use'), ('characteristic', 'characterist'), ('rule', 'rule'), ('based', 'base'), ('classifiers', 'classifi'), ('comprehensibility', 'comprehens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('useful', 'use'), ('characteristic', 'characterist'), ('rule', 'rule'), ('based', 'base'), ('classifiers', 'classifi'), ('comprehensibility', 'comprehens'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('useful', 'useful'), ('characteristic', 'characteristic'), ('rule', 'rule'), ('based', 'based'), ('classifiers', 'classifier'), ('comprehensibility', 'comprehensibility'), ('.', '.')]



============================ Sentence 104 =============================

In order to achieve better performance, even   though some rule-based classifiers can deal with numerical   features, some experts propose these features should be   discredited before induction, so as to reduce training time and   increase classification accuracy [15]. 


>> Tokens are: 
 ['In', 'order', 'achieve', 'better', 'performance', ',', 'even', 'though', 'rule-based', 'classifiers', 'deal', 'numerical', 'features', ',', 'experts', 'propose', 'features', 'discredited', 'induction', ',', 'reduce', 'training', 'time', 'increase', 'classification', 'accuracy', '[', '15', ']', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'achieve'), ('achieve', 'better'), ('better', 'performance'), ('performance', ','), (',', 'even'), ('even', 'though'), ('though', 'rule-based'), ('rule-based', 'classifiers'), ('classifiers', 'deal'), ('deal', 'numerical'), ('numerical', 'features'), ('features', ','), (',', 'experts'), ('experts', 'propose'), ('propose', 'features'), ('features', 'discredited'), ('discredited', 'induction'), ('induction', ','), (',', 'reduce'), ('reduce', 'training'), ('training', 'time'), ('time', 'increase'), ('increase', 'classification'), ('classification', 'accuracy'), ('accuracy', '['), ('[', '15'), ('15', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'order', 'achieve'), ('order', 'achieve', 'better'), ('achieve', 'better', 'performance'), ('better', 'performance', ','), ('performance', ',', 'even'), (',', 'even', 'though'), ('even', 'though', 'rule-based'), ('though', 'rule-based', 'classifiers'), ('rule-based', 'classifiers', 'deal'), ('classifiers', 'deal', 'numerical'), ('deal', 'numerical', 'features'), ('numerical', 'features', ','), ('features', ',', 'experts'), (',', 'experts', 'propose'), ('experts', 'propose', 'features'), ('propose', 'features', 'discredited'), ('features', 'discredited', 'induction'), ('discredited', 'induction', ','), ('induction', ',', 'reduce'), (',', 'reduce', 'training'), ('reduce', 'training', 'time'), ('training', 'time', 'increase'), ('time', 'increase', 'classification'), ('increase', 'classification', 'accuracy'), ('classification', 'accuracy', '['), ('accuracy', '[', '15'), ('[', '15', ']'), ('15', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('achieve', 'VBP'), ('better', 'JJR'), ('performance', 'NN'), (',', ','), ('even', 'RB'), ('though', 'IN'), ('rule-based', 'JJ'), ('classifiers', 'NNS'), ('deal', 'VB'), ('numerical', 'JJ'), ('features', 'NNS'), (',', ','), ('experts', 'NNS'), ('propose', 'VBP'), ('features', 'NNS'), ('discredited', 'VBN'), ('induction', 'NN'), (',', ','), ('reduce', 'VB'), ('training', 'NN'), ('time', 'NN'), ('increase', 'NN'), ('classification', 'NN'), ('accuracy', 'NN'), ('[', 'VBD'), ('15', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP order/NN)
  achieve/VBP
  better/JJR
  (NP performance/NN)
  ,/,
  even/RB
  though/IN
  (NP rule-based/JJ classifiers/NNS)
  deal/VB
  (NP numerical/JJ features/NNS)
  ,/,
  (NP experts/NNS)
  propose/VBP
  (NP features/NNS)
  discredited/VBN
  (NP induction/NN)
  ,/,
  reduce/VB
  (NP training/NN time/NN increase/NN classification/NN accuracy/NN)
  [/VBD
  15/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['order', 'performance', 'rule-based classifiers', 'numerical features', 'experts', 'features', 'induction', 'training time increase classification accuracy', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('achieve', 'achiev'), ('better', 'better'), ('performance', 'perform'), (',', ','), ('even', 'even'), ('though', 'though'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('deal', 'deal'), ('numerical', 'numer'), ('features', 'featur'), (',', ','), ('experts', 'expert'), ('propose', 'propos'), ('features', 'featur'), ('discredited', 'discredit'), ('induction', 'induct'), (',', ','), ('reduce', 'reduc'), ('training', 'train'), ('time', 'time'), ('increase', 'increas'), ('classification', 'classif'), ('accuracy', 'accuraci'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('achieve', 'achiev'), ('better', 'better'), ('performance', 'perform'), (',', ','), ('even', 'even'), ('though', 'though'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('deal', 'deal'), ('numerical', 'numer'), ('features', 'featur'), (',', ','), ('experts', 'expert'), ('propose', 'propos'), ('features', 'featur'), ('discredited', 'discredit'), ('induction', 'induct'), (',', ','), ('reduce', 'reduc'), ('training', 'train'), ('time', 'time'), ('increase', 'increas'), ('classification', 'classif'), ('accuracy', 'accuraci'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('achieve', 'achieve'), ('better', 'better'), ('performance', 'performance'), (',', ','), ('even', 'even'), ('though', 'though'), ('rule-based', 'rule-based'), ('classifiers', 'classifier'), ('deal', 'deal'), ('numerical', 'numerical'), ('features', 'feature'), (',', ','), ('experts', 'expert'), ('propose', 'propose'), ('features', 'feature'), ('discredited', 'discredited'), ('induction', 'induction'), (',', ','), ('reduce', 'reduce'), ('training', 'training'), ('time', 'time'), ('increase', 'increase'), ('classification', 'classification'), ('accuracy', 'accuracy'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]



============================ Sentence 105 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 106 =============================

STATISTICAL LEARNING ALGORITHMS   Statistical learning is a framework for machine learning   drawing from the fields of statistics and functional analysis [16]. 


>> Tokens are: 
 ['STATISTICAL', 'LEARNING', 'ALGORITHMS', 'Statistical', 'learning', 'framework', 'machine', 'learning', 'drawing', 'fields', 'statistics', 'functional', 'analysis', '[', '16', ']', '.']

>> Bigrams are: 
 [('STATISTICAL', 'LEARNING'), ('LEARNING', 'ALGORITHMS'), ('ALGORITHMS', 'Statistical'), ('Statistical', 'learning'), ('learning', 'framework'), ('framework', 'machine'), ('machine', 'learning'), ('learning', 'drawing'), ('drawing', 'fields'), ('fields', 'statistics'), ('statistics', 'functional'), ('functional', 'analysis'), ('analysis', '['), ('[', '16'), ('16', ']'), (']', '.')]

>> Trigrams are: 
 [('STATISTICAL', 'LEARNING', 'ALGORITHMS'), ('LEARNING', 'ALGORITHMS', 'Statistical'), ('ALGORITHMS', 'Statistical', 'learning'), ('Statistical', 'learning', 'framework'), ('learning', 'framework', 'machine'), ('framework', 'machine', 'learning'), ('machine', 'learning', 'drawing'), ('learning', 'drawing', 'fields'), ('drawing', 'fields', 'statistics'), ('fields', 'statistics', 'functional'), ('statistics', 'functional', 'analysis'), ('functional', 'analysis', '['), ('analysis', '[', '16'), ('[', '16', ']'), ('16', ']', '.')]

>> POS Tags are: 
 [('STATISTICAL', 'NNP'), ('LEARNING', 'NNP'), ('ALGORITHMS', 'NNP'), ('Statistical', 'NNP'), ('learning', 'VBG'), ('framework', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('drawing', 'VBG'), ('fields', 'NNS'), ('statistics', 'NNS'), ('functional', 'JJ'), ('analysis', 'NN'), ('[', 'VBD'), ('16', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP STATISTICAL/NNP LEARNING/NNP ALGORITHMS/NNP Statistical/NNP)
  learning/VBG
  (NP framework/NN machine/NN)
  learning/VBG
  drawing/VBG
  (NP fields/NNS statistics/NNS)
  (NP functional/JJ analysis/NN)
  [/VBD
  16/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['STATISTICAL LEARNING ALGORITHMS Statistical', 'framework machine', 'fields statistics', 'functional analysis', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'STATISTICAL'), ('ORGANIZATION', 'LEARNING')] 

>> Stemming using Porter Stemmer: 
 [('STATISTICAL', 'statist'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm'), ('Statistical', 'statist'), ('learning', 'learn'), ('framework', 'framework'), ('machine', 'machin'), ('learning', 'learn'), ('drawing', 'draw'), ('fields', 'field'), ('statistics', 'statist'), ('functional', 'function'), ('analysis', 'analysi'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('STATISTICAL', 'statist'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm'), ('Statistical', 'statist'), ('learning', 'learn'), ('framework', 'framework'), ('machine', 'machin'), ('learning', 'learn'), ('drawing', 'draw'), ('fields', 'field'), ('statistics', 'statist'), ('functional', 'function'), ('analysis', 'analysi'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('STATISTICAL', 'STATISTICAL'), ('LEARNING', 'LEARNING'), ('ALGORITHMS', 'ALGORITHMS'), ('Statistical', 'Statistical'), ('learning', 'learning'), ('framework', 'framework'), ('machine', 'machine'), ('learning', 'learning'), ('drawing', 'drawing'), ('fields', 'field'), ('statistics', 'statistic'), ('functional', 'functional'), ('analysis', 'analysis'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]



============================ Sentence 107 =============================

1. 


>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

 (S 1/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



============================ Sentence 108 =============================

Initialize rule set to a default   2. 


>> Tokens are: 
 ['Initialize', 'rule', 'set', 'default', '2', '.']

>> Bigrams are: 
 [('Initialize', 'rule'), ('rule', 'set'), ('set', 'default'), ('default', '2'), ('2', '.')]

>> Trigrams are: 
 [('Initialize', 'rule', 'set'), ('rule', 'set', 'default'), ('set', 'default', '2'), ('default', '2', '.')]

>> POS Tags are: 
 [('Initialize', 'NNP'), ('rule', 'NN'), ('set', 'VBN'), ('default', 'NN'), ('2', 'CD'), ('.', '.')]

 (S (NP Initialize/NNP rule/NN) set/VBN (NP default/NN) 2/CD ./.) 


>> Noun Phrases are: 
 ['Initialize rule', 'default']

>> Named Entities are: 
 [('GPE', 'Initialize')] 

>> Stemming using Porter Stemmer: 
 [('Initialize', 'initi'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Initialize', 'initi'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Initialize', 'Initialize'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]



============================ Sentence 109 =============================

Initialize examples to either all available examples   or all examples not correctly handled by rule set. 


>> Tokens are: 
 ['Initialize', 'examples', 'either', 'available', 'examples', 'examples', 'correctly', 'handled', 'rule', 'set', '.']

>> Bigrams are: 
 [('Initialize', 'examples'), ('examples', 'either'), ('either', 'available'), ('available', 'examples'), ('examples', 'examples'), ('examples', 'correctly'), ('correctly', 'handled'), ('handled', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Initialize', 'examples', 'either'), ('examples', 'either', 'available'), ('either', 'available', 'examples'), ('available', 'examples', 'examples'), ('examples', 'examples', 'correctly'), ('examples', 'correctly', 'handled'), ('correctly', 'handled', 'rule'), ('handled', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('Initialize', 'NNP'), ('examples', 'VBZ'), ('either', 'CC'), ('available', 'JJ'), ('examples', 'NNS'), ('examples', 'NNS'), ('correctly', 'RB'), ('handled', 'VBD'), ('rule', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  (NP Initialize/NNP)
  examples/VBZ
  either/CC
  (NP available/JJ examples/NNS examples/NNS)
  correctly/RB
  handled/VBD
  (NP rule/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['Initialize', 'available examples examples', 'rule set']

>> Named Entities are: 
 [('GPE', 'Initialize')] 

>> Stemming using Porter Stemmer: 
 [('Initialize', 'initi'), ('examples', 'exampl'), ('either', 'either'), ('available', 'avail'), ('examples', 'exampl'), ('examples', 'exampl'), ('correctly', 'correctli'), ('handled', 'handl'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Initialize', 'initi'), ('examples', 'exampl'), ('either', 'either'), ('available', 'avail'), ('examples', 'exampl'), ('examples', 'exampl'), ('correctly', 'correct'), ('handled', 'handl'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Initialize', 'Initialize'), ('examples', 'example'), ('either', 'either'), ('available', 'available'), ('examples', 'example'), ('examples', 'example'), ('correctly', 'correctly'), ('handled', 'handled'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]



============================ Sentence 110 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 111 =============================

Repeat         (a) Find best, the best rule with respect to examples. 


>> Tokens are: 
 ['Repeat', '(', ')', 'Find', 'best', ',', 'best', 'rule', 'respect', 'examples', '.']

>> Bigrams are: 
 [('Repeat', '('), ('(', ')'), (')', 'Find'), ('Find', 'best'), ('best', ','), (',', 'best'), ('best', 'rule'), ('rule', 'respect'), ('respect', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('Repeat', '(', ')'), ('(', ')', 'Find'), (')', 'Find', 'best'), ('Find', 'best', ','), ('best', ',', 'best'), (',', 'best', 'rule'), ('best', 'rule', 'respect'), ('rule', 'respect', 'examples'), ('respect', 'examples', '.')]

>> POS Tags are: 
 [('Repeat', 'NNP'), ('(', '('), (')', ')'), ('Find', 'NNP'), ('best', 'JJS'), (',', ','), ('best', 'JJS'), ('rule', 'NN'), ('respect', 'NN'), ('examples', 'NNS'), ('.', '.')]

 (S
  (NP Repeat/NNP)
  (/(
  )/)
  (NP Find/NNP)
  best/JJS
  ,/,
  best/JJS
  (NP rule/NN respect/NN examples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Repeat', 'Find', 'rule respect examples']

>> Named Entities are: 
 [('GPE', 'Repeat')] 

>> Stemming using Porter Stemmer: 
 [('Repeat', 'repeat'), ('(', '('), (')', ')'), ('Find', 'find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Repeat', 'repeat'), ('(', '('), (')', ')'), ('Find', 'find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('Repeat', 'Repeat'), ('(', '('), (')', ')'), ('Find', 'Find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'example'), ('.', '.')]



============================ Sentence 112 =============================

(b) If such a rule can be found    i. 


>> Tokens are: 
 ['(', 'b', ')', 'If', 'rule', 'found', '.']

>> Bigrams are: 
 [('(', 'b'), ('b', ')'), (')', 'If'), ('If', 'rule'), ('rule', 'found'), ('found', '.')]

>> Trigrams are: 
 [('(', 'b', ')'), ('b', ')', 'If'), (')', 'If', 'rule'), ('If', 'rule', 'found'), ('rule', 'found', '.')]

>> POS Tags are: 
 [('(', '('), ('b', 'NN'), (')', ')'), ('If', 'IN'), ('rule', 'NN'), ('found', 'VBD'), ('.', '.')]

 (S (/( (NP b/NN) )/) If/IN (NP rule/NN) found/VBD ./.) 


>> Noun Phrases are: 
 ['b', 'rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'if'), ('rule', 'rule'), ('found', 'found'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'if'), ('rule', 'rule'), ('found', 'found'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'If'), ('rule', 'rule'), ('found', 'found'), ('.', '.')]



============================ Sentence 113 =============================

Add best to rule set. 


>> Tokens are: 
 ['Add', 'best', 'rule', 'set', '.']

>> Bigrams are: 
 [('Add', 'best'), ('best', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Add', 'best', 'rule'), ('best', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('Add', 'NNP'), ('best', 'JJS'), ('rule', 'NN'), ('set', 'NN'), ('.', '.')]

 (S (NP Add/NNP) best/JJS (NP rule/NN set/NN) ./.) 


>> Noun Phrases are: 
 ['Add', 'rule set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Add', 'add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Add', 'add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Add', 'Add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]



============================ Sentence 114 =============================

ii. 


>> Tokens are: 
 ['ii', '.']

>> Bigrams are: 
 [('ii', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ii', 'NN'), ('.', '.')]

 (S (NP ii/NN) ./.) 


>> Noun Phrases are: 
 ['ii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ii', 'ii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ii', 'ii'), ('.', '.')]

>> Lemmatization: 
 [('ii', 'ii'), ('.', '.')]



============================ Sentence 115 =============================

Set examples to all examples not handled   correctly by rule set. 


>> Tokens are: 
 ['Set', 'examples', 'examples', 'handled', 'correctly', 'rule', 'set', '.']

>> Bigrams are: 
 [('Set', 'examples'), ('examples', 'examples'), ('examples', 'handled'), ('handled', 'correctly'), ('correctly', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Set', 'examples', 'examples'), ('examples', 'examples', 'handled'), ('examples', 'handled', 'correctly'), ('handled', 'correctly', 'rule'), ('correctly', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('Set', 'NNP'), ('examples', 'NNS'), ('examples', 'NNS'), ('handled', 'VBD'), ('correctly', 'RB'), ('rule', 'JJ'), ('set', 'NN'), ('.', '.')]

 (S
  (NP Set/NNP examples/NNS examples/NNS)
  handled/VBD
  correctly/RB
  (NP rule/JJ set/NN)
  ./.) 


>> Noun Phrases are: 
 ['Set examples examples', 'rule set']

>> Named Entities are: 
 [('GPE', 'Set')] 

>> Stemming using Porter Stemmer: 
 [('Set', 'set'), ('examples', 'exampl'), ('examples', 'exampl'), ('handled', 'handl'), ('correctly', 'correctli'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Set', 'set'), ('examples', 'exampl'), ('examples', 'exampl'), ('handled', 'handl'), ('correctly', 'correct'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Set', 'Set'), ('examples', 'example'), ('examples', 'example'), ('handled', 'handled'), ('correctly', 'correctly'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]



============================ Sentence 116 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 117 =============================

Until no rule best can be found    1. 


>> Tokens are: 
 ['Until', 'rule', 'best', 'found', '1', '.']

>> Bigrams are: 
 [('Until', 'rule'), ('rule', 'best'), ('best', 'found'), ('found', '1'), ('1', '.')]

>> Trigrams are: 
 [('Until', 'rule', 'best'), ('rule', 'best', 'found'), ('best', 'found', '1'), ('found', '1', '.')]

>> POS Tags are: 
 [('Until', 'IN'), ('rule', 'NN'), ('best', 'RB'), ('found', 'VBD'), ('1', 'CD'), ('.', '.')]

 (S Until/IN (NP rule/NN) best/RB found/VBD 1/CD ./.) 


>> Noun Phrases are: 
 ['rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Until', 'until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Until', 'until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Until', 'Until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found'), ('1', '1'), ('.', '.')]



============================ Sentence 118 =============================

Check for base cases   2. 


>> Tokens are: 
 ['Check', 'base', 'cases', '2', '.']

>> Bigrams are: 
 [('Check', 'base'), ('base', 'cases'), ('cases', '2'), ('2', '.')]

>> Trigrams are: 
 [('Check', 'base', 'cases'), ('base', 'cases', '2'), ('cases', '2', '.')]

>> POS Tags are: 
 [('Check', 'NNP'), ('base', 'NN'), ('cases', 'NNS'), ('2', 'CD'), ('.', '.')]

 (S (NP Check/NNP base/NN cases/NNS) 2/CD ./.) 


>> Noun Phrases are: 
 ['Check base cases']

>> Named Entities are: 
 [('GPE', 'Check')] 

>> Stemming using Porter Stemmer: 
 [('Check', 'check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Check', 'check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Check', 'Check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]



============================ Sentence 119 =============================

For each attribute a  calculate   i. Normalized the information gain (IG) from splitting  on attribute a. 


>> Tokens are: 
 ['For', 'attribute', '', '', 'calculate', 'i.', 'Normalized', 'information', 'gain', '(', 'IG', ')', 'splitting', 'attribute', '', '', '.']

>> Bigrams are: 
 [('For', 'attribute'), ('attribute', ''), ('', ''), ('', 'calculate'), ('calculate', 'i.'), ('i.', 'Normalized'), ('Normalized', 'information'), ('information', 'gain'), ('gain', '('), ('(', 'IG'), ('IG', ')'), (')', 'splitting'), ('splitting', 'attribute'), ('attribute', ''), ('', ''), ('', '.')]

>> Trigrams are: 
 [('For', 'attribute', ''), ('attribute', '', ''), ('', '', 'calculate'), ('', 'calculate', 'i.'), ('calculate', 'i.', 'Normalized'), ('i.', 'Normalized', 'information'), ('Normalized', 'information', 'gain'), ('information', 'gain', '('), ('gain', '(', 'IG'), ('(', 'IG', ')'), ('IG', ')', 'splitting'), (')', 'splitting', 'attribute'), ('splitting', 'attribute', ''), ('attribute', '', ''), ('', '', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('attribute', 'JJ'), ('', 'NNP'), ('', 'NNP'), ('calculate', 'NN'), ('i.', 'NN'), ('Normalized', 'NNP'), ('information', 'NN'), ('gain', 'NN'), ('(', '('), ('IG', 'NNP'), (')', ')'), ('splitting', 'VBG'), ('attribute', 'JJ'), ('', 'JJ'), ('', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP
    attribute/JJ
    /NNP
    /NNP
    calculate/NN
    i./NN
    Normalized/NNP
    information/NN
    gain/NN)
  (/(
  (NP IG/NNP)
  )/)
  splitting/VBG
  (NP attribute/JJ /JJ /NN)
  ./.) 


>> Noun Phrases are: 
 ['attribute   calculate i. Normalized information gain', 'IG', 'attribute  ']

>> Named Entities are: 
 [('GPE', 'Normalized')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('attribute', 'attribut'), ('', ''), ('', ''), ('calculate', 'calcul'), ('i.', 'i.'), ('Normalized', 'normal'), ('information', 'inform'), ('gain', 'gain'), ('(', '('), ('IG', 'ig'), (')', ')'), ('splitting', 'split'), ('attribute', 'attribut'), ('', ''), ('', ''), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('attribute', 'attribut'), ('', ''), ('', ''), ('calculate', 'calcul'), ('i.', 'i.'), ('Normalized', 'normal'), ('information', 'inform'), ('gain', 'gain'), ('(', '('), ('IG', 'ig'), (')', ')'), ('splitting', 'split'), ('attribute', 'attribut'), ('', ''), ('', ''), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('attribute', 'attribute'), ('', ''), ('', ''), ('calculate', 'calculate'), ('i.', 'i.'), ('Normalized', 'Normalized'), ('information', 'information'), ('gain', 'gain'), ('(', '('), ('IG', 'IG'), (')', ')'), ('splitting', 'splitting'), ('attribute', 'attribute'), ('', ''), ('', ''), ('.', '.')]



============================ Sentence 120 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 121 =============================

Find the best a, attribute that has highest IG   4. 


>> Tokens are: 
 ['Find', 'best', '', '', ',', 'attribute', 'highest', 'IG', '4', '.']

>> Bigrams are: 
 [('Find', 'best'), ('best', ''), ('', ''), ('', ','), (',', 'attribute'), ('attribute', 'highest'), ('highest', 'IG'), ('IG', '4'), ('4', '.')]

>> Trigrams are: 
 [('Find', 'best', ''), ('best', '', ''), ('', '', ','), ('', ',', 'attribute'), (',', 'attribute', 'highest'), ('attribute', 'highest', 'IG'), ('highest', 'IG', '4'), ('IG', '4', '.')]

>> POS Tags are: 
 [('Find', 'NNP'), ('best', 'JJS'), ('', 'NN'), ('', 'NN'), (',', ','), ('attribute', 'JJ'), ('highest', 'JJS'), ('IG', 'JJ'), ('4', 'CD'), ('.', '.')]

 (S
  (NP Find/NNP)
  best/JJS
  (NP /NN /NN)
  ,/,
  attribute/JJ
  highest/JJS
  IG/JJ
  4/CD
  ./.) 


>> Noun Phrases are: 
 ['Find', ' ']

>> Named Entities are: 
 [('GPE', 'Find')] 

>> Stemming using Porter Stemmer: 
 [('Find', 'find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribut'), ('highest', 'highest'), ('IG', 'ig'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Find', 'find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribut'), ('highest', 'highest'), ('IG', 'ig'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Find', 'Find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribute'), ('highest', 'highest'), ('IG', 'IG'), ('4', '4'), ('.', '.')]



============================ Sentence 122 =============================

Create a decision node: node that splits on best of a  5. 


>> Tokens are: 
 ['Create', 'decision', 'node', ':', 'node', 'splits', 'best', '', '', '5', '.']

>> Bigrams are: 
 [('Create', 'decision'), ('decision', 'node'), ('node', ':'), (':', 'node'), ('node', 'splits'), ('splits', 'best'), ('best', ''), ('', ''), ('', '5'), ('5', '.')]

>> Trigrams are: 
 [('Create', 'decision', 'node'), ('decision', 'node', ':'), ('node', ':', 'node'), (':', 'node', 'splits'), ('node', 'splits', 'best'), ('splits', 'best', ''), ('best', '', ''), ('', '', '5'), ('', '5', '.')]

>> POS Tags are: 
 [('Create', 'NNP'), ('decision', 'NN'), ('node', 'NN'), (':', ':'), ('node', 'JJ'), ('splits', 'NNS'), ('best', 'JJS'), ('', 'NN'), ('', 'NN'), ('5', 'CD'), ('.', '.')]

 (S
  (NP Create/NNP decision/NN node/NN)
  :/:
  (NP node/JJ splits/NNS)
  best/JJS
  (NP /NN /NN)
  5/CD
  ./.) 


>> Noun Phrases are: 
 ['Create decision node', 'node splits', ' ']

>> Named Entities are: 
 [('GPE', 'Create')] 

>> Stemming using Porter Stemmer: 
 [('Create', 'creat'), ('decision', 'decis'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Create', 'creat'), ('decision', 'decis'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('Create', 'Create'), ('decision', 'decision'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]



============================ Sentence 123 =============================

Recurse on the sub-lists obtained by Splitting on a best   and add those nodes as children of node   at1   at2 No No      at4 at3  No   Yes   No     Yes No   http://mathworld.wolfram.com/Disjunction.html http://mathworld.wolfram.com/OR.html http://mathworld.wolfram.com/Disjunct.html http://mathworld.wolfram.com/Conjunction.html http://mathworld.wolfram.com/AND.html http://mathworld.wolfram.com/Literal.html   ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03   949   Statistical learning theory deals with the problem of finding a   predictive function based on data and it has a good number of   applications in the field of AI. 


>> Tokens are: 
 ['Recurse', 'sub-lists', 'obtained', 'Splitting', 'best', 'add', 'nodes', 'children', 'node', 'at1', 'at2', 'No', 'No', 'at4', 'at3', 'No', 'Yes', 'No', 'Yes', 'No', 'http', ':', '//mathworld.wolfram.com/Disjunction.html', 'http', ':', '//mathworld.wolfram.com/OR.html', 'http', ':', '//mathworld.wolfram.com/Disjunct.html', 'http', ':', '//mathworld.wolfram.com/Conjunction.html', 'http', ':', '//mathworld.wolfram.com/AND.html', 'http', ':', '//mathworld.wolfram.com/Literal.html', 'ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03', '949', 'Statistical', 'learning', 'theory', 'deals', 'problem', 'finding', 'predictive', 'function', 'based', 'data', 'good', 'number', 'applications', 'field', 'AI', '.']

>> Bigrams are: 
 [('Recurse', 'sub-lists'), ('sub-lists', 'obtained'), ('obtained', 'Splitting'), ('Splitting', 'best'), ('best', 'add'), ('add', 'nodes'), ('nodes', 'children'), ('children', 'node'), ('node', 'at1'), ('at1', 'at2'), ('at2', 'No'), ('No', 'No'), ('No', 'at4'), ('at4', 'at3'), ('at3', 'No'), ('No', 'Yes'), ('Yes', 'No'), ('No', 'Yes'), ('Yes', 'No'), ('No', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/Disjunction.html'), ('//mathworld.wolfram.com/Disjunction.html', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/OR.html'), ('//mathworld.wolfram.com/OR.html', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/Disjunct.html'), ('//mathworld.wolfram.com/Disjunct.html', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/Conjunction.html'), ('//mathworld.wolfram.com/Conjunction.html', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/AND.html'), ('//mathworld.wolfram.com/AND.html', 'http'), ('http', ':'), (':', '//mathworld.wolfram.com/Literal.html'), ('//mathworld.wolfram.com/Literal.html', 'ISSN'), ('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03'), ('03', '949'), ('949', 'Statistical'), ('Statistical', 'learning'), ('learning', 'theory'), ('theory', 'deals'), ('deals', 'problem'), ('problem', 'finding'), ('finding', 'predictive'), ('predictive', 'function'), ('function', 'based'), ('based', 'data'), ('data', 'good'), ('good', 'number'), ('number', 'applications'), ('applications', 'field'), ('field', 'AI'), ('AI', '.')]

>> Trigrams are: 
 [('Recurse', 'sub-lists', 'obtained'), ('sub-lists', 'obtained', 'Splitting'), ('obtained', 'Splitting', 'best'), ('Splitting', 'best', 'add'), ('best', 'add', 'nodes'), ('add', 'nodes', 'children'), ('nodes', 'children', 'node'), ('children', 'node', 'at1'), ('node', 'at1', 'at2'), ('at1', 'at2', 'No'), ('at2', 'No', 'No'), ('No', 'No', 'at4'), ('No', 'at4', 'at3'), ('at4', 'at3', 'No'), ('at3', 'No', 'Yes'), ('No', 'Yes', 'No'), ('Yes', 'No', 'Yes'), ('No', 'Yes', 'No'), ('Yes', 'No', 'http'), ('No', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/Disjunction.html'), (':', '//mathworld.wolfram.com/Disjunction.html', 'http'), ('//mathworld.wolfram.com/Disjunction.html', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/OR.html'), (':', '//mathworld.wolfram.com/OR.html', 'http'), ('//mathworld.wolfram.com/OR.html', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/Disjunct.html'), (':', '//mathworld.wolfram.com/Disjunct.html', 'http'), ('//mathworld.wolfram.com/Disjunct.html', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/Conjunction.html'), (':', '//mathworld.wolfram.com/Conjunction.html', 'http'), ('//mathworld.wolfram.com/Conjunction.html', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/AND.html'), (':', '//mathworld.wolfram.com/AND.html', 'http'), ('//mathworld.wolfram.com/AND.html', 'http', ':'), ('http', ':', '//mathworld.wolfram.com/Literal.html'), (':', '//mathworld.wolfram.com/Literal.html', 'ISSN'), ('//mathworld.wolfram.com/Literal.html', 'ISSN', ':'), ('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03'), (':', '03', '949'), ('03', '949', 'Statistical'), ('949', 'Statistical', 'learning'), ('Statistical', 'learning', 'theory'), ('learning', 'theory', 'deals'), ('theory', 'deals', 'problem'), ('deals', 'problem', 'finding'), ('problem', 'finding', 'predictive'), ('finding', 'predictive', 'function'), ('predictive', 'function', 'based'), ('function', 'based', 'data'), ('based', 'data', 'good'), ('data', 'good', 'number'), ('good', 'number', 'applications'), ('number', 'applications', 'field'), ('applications', 'field', 'AI'), ('field', 'AI', '.')]

>> POS Tags are: 
 [('Recurse', 'JJ'), ('sub-lists', 'NNS'), ('obtained', 'VBD'), ('Splitting', 'VBG'), ('best', 'JJS'), ('add', 'NN'), ('nodes', 'NNS'), ('children', 'NNS'), ('node', 'RB'), ('at1', 'VBP'), ('at2', 'JJ'), ('No', 'NNP'), ('No', 'NNP'), ('at4', 'RB'), ('at3', 'VBZ'), ('No', 'NNP'), ('Yes', 'NNP'), ('No', 'NNP'), ('Yes', 'NNP'), ('No', 'NNP'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/Disjunction.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/OR.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/Disjunct.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/Conjunction.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/AND.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//mathworld.wolfram.com/Literal.html', 'JJ'), ('ISSN', 'NNP'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD'), ('949', 'CD'), ('Statistical', 'JJ'), ('learning', 'VBG'), ('theory', 'JJ'), ('deals', 'NNS'), ('problem', 'NN'), ('finding', 'VBG'), ('predictive', 'JJ'), ('function', 'NN'), ('based', 'VBN'), ('data', 'NNS'), ('good', 'JJ'), ('number', 'NN'), ('applications', 'NNS'), ('field', 'NN'), ('AI', 'NNP'), ('.', '.')]

 (S
  (NP Recurse/JJ sub-lists/NNS)
  obtained/VBD
  Splitting/VBG
  best/JJS
  (NP add/NN nodes/NNS children/NNS)
  node/RB
  at1/VBP
  (NP at2/JJ No/NNP No/NNP)
  at4/RB
  at3/VBZ
  (NP No/NNP Yes/NNP No/NNP Yes/NNP No/NNP http/NN)
  :/:
  (NP //mathworld.wolfram.com/Disjunction.html/JJ http/NN)
  :/:
  (NP //mathworld.wolfram.com/OR.html/JJ http/NN)
  :/:
  (NP //mathworld.wolfram.com/Disjunct.html/JJ http/NN)
  :/:
  (NP //mathworld.wolfram.com/Conjunction.html/JJ http/NN)
  :/:
  (NP //mathworld.wolfram.com/AND.html/JJ http/NN)
  :/:
  (NP //mathworld.wolfram.com/Literal.html/JJ ISSN/NNP)
  :/:
  2229-6956/JJ
  (/(
  (NP ONLINE/NNP)
  )/)
  (NP ICTACT/NNP JOURNAL/NNP ON/NNP SOFT/NNP COMPUTING/NNP)
  ,/,
  (NP APRIL/NNP)
  2015/CD
  ,/,
  (NP VOLUME/NNP)
  :/:
  05/CD
  ,/,
  (NP ISSUE/NNP)
  :/:
  03/CD
  949/CD
  Statistical/JJ
  learning/VBG
  (NP theory/JJ deals/NNS problem/NN)
  finding/VBG
  (NP predictive/JJ function/NN)
  based/VBN
  (NP data/NNS)
  (NP good/JJ number/NN applications/NNS field/NN AI/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Recurse sub-lists', 'add nodes children', 'at2 No No', 'No Yes No Yes No http', '//mathworld.wolfram.com/Disjunction.html http', '//mathworld.wolfram.com/OR.html http', '//mathworld.wolfram.com/Disjunct.html http', '//mathworld.wolfram.com/Conjunction.html http', '//mathworld.wolfram.com/AND.html http', '//mathworld.wolfram.com/Literal.html ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE', 'theory deals problem', 'predictive function', 'data', 'good number applications field AI']

>> Named Entities are: 
 [('GPE', 'Recurse'), ('ORGANIZATION', 'No No'), ('ORGANIZATION', 'No Yes No'), ('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('Recurse', 'recurs'), ('sub-lists', 'sub-list'), ('obtained', 'obtain'), ('Splitting', 'split'), ('best', 'best'), ('add', 'add'), ('nodes', 'node'), ('children', 'children'), ('node', 'node'), ('at1', 'at1'), ('at2', 'at2'), ('No', 'no'), ('No', 'no'), ('at4', 'at4'), ('at3', 'at3'), ('No', 'no'), ('Yes', 'ye'), ('No', 'no'), ('Yes', 'ye'), ('No', 'no'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunction.html', '//mathworld.wolfram.com/disjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/OR.html', '//mathworld.wolfram.com/or.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunct.html', '//mathworld.wolfram.com/disjunct.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Conjunction.html', '//mathworld.wolfram.com/conjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/AND.html', '//mathworld.wolfram.com/and.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Literal.html', '//mathworld.wolfram.com/literal.html'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('949', '949'), ('Statistical', 'statist'), ('learning', 'learn'), ('theory', 'theori'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'find'), ('predictive', 'predict'), ('function', 'function'), ('based', 'base'), ('data', 'data'), ('good', 'good'), ('number', 'number'), ('applications', 'applic'), ('field', 'field'), ('AI', 'ai'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recurse', 'recurs'), ('sub-lists', 'sub-list'), ('obtained', 'obtain'), ('Splitting', 'split'), ('best', 'best'), ('add', 'add'), ('nodes', 'node'), ('children', 'children'), ('node', 'node'), ('at1', 'at1'), ('at2', 'at2'), ('No', 'no'), ('No', 'no'), ('at4', 'at4'), ('at3', 'at3'), ('No', 'no'), ('Yes', 'yes'), ('No', 'no'), ('Yes', 'yes'), ('No', 'no'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunction.html', '//mathworld.wolfram.com/disjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/OR.html', '//mathworld.wolfram.com/or.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunct.html', '//mathworld.wolfram.com/disjunct.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Conjunction.html', '//mathworld.wolfram.com/conjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/AND.html', '//mathworld.wolfram.com/and.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Literal.html', '//mathworld.wolfram.com/literal.html'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('949', '949'), ('Statistical', 'statist'), ('learning', 'learn'), ('theory', 'theori'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'find'), ('predictive', 'predict'), ('function', 'function'), ('based', 'base'), ('data', 'data'), ('good', 'good'), ('number', 'number'), ('applications', 'applic'), ('field', 'field'), ('AI', 'ai'), ('.', '.')]

>> Lemmatization: 
 [('Recurse', 'Recurse'), ('sub-lists', 'sub-lists'), ('obtained', 'obtained'), ('Splitting', 'Splitting'), ('best', 'best'), ('add', 'add'), ('nodes', 'node'), ('children', 'child'), ('node', 'node'), ('at1', 'at1'), ('at2', 'at2'), ('No', 'No'), ('No', 'No'), ('at4', 'at4'), ('at3', 'at3'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('Yes', 'Yes'), ('No', 'No'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunction.html', '//mathworld.wolfram.com/Disjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/OR.html', '//mathworld.wolfram.com/OR.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Disjunct.html', '//mathworld.wolfram.com/Disjunct.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Conjunction.html', '//mathworld.wolfram.com/Conjunction.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/AND.html', '//mathworld.wolfram.com/AND.html'), ('http', 'http'), (':', ':'), ('//mathworld.wolfram.com/Literal.html', '//mathworld.wolfram.com/Literal.html'), ('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03'), ('949', '949'), ('Statistical', 'Statistical'), ('learning', 'learning'), ('theory', 'theory'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'finding'), ('predictive', 'predictive'), ('function', 'function'), ('based', 'based'), ('data', 'data'), ('good', 'good'), ('number', 'number'), ('applications', 'application'), ('field', 'field'), ('AI', 'AI'), ('.', '.')]



============================ Sentence 124 =============================

The major of goal of statistical   learning algorithms is to provide a framework for studying the   problem of inference that is obtaining knowledge, making   predictions and making decision by constructing model from a   set of data [17]. 


>> Tokens are: 
 ['The', 'major', 'goal', 'statistical', 'learning', 'algorithms', 'provide', 'framework', 'studying', 'problem', 'inference', 'obtaining', 'knowledge', ',', 'making', 'predictions', 'making', 'decision', 'constructing', 'model', 'set', 'data', '[', '17', ']', '.']

>> Bigrams are: 
 [('The', 'major'), ('major', 'goal'), ('goal', 'statistical'), ('statistical', 'learning'), ('learning', 'algorithms'), ('algorithms', 'provide'), ('provide', 'framework'), ('framework', 'studying'), ('studying', 'problem'), ('problem', 'inference'), ('inference', 'obtaining'), ('obtaining', 'knowledge'), ('knowledge', ','), (',', 'making'), ('making', 'predictions'), ('predictions', 'making'), ('making', 'decision'), ('decision', 'constructing'), ('constructing', 'model'), ('model', 'set'), ('set', 'data'), ('data', '['), ('[', '17'), ('17', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'major', 'goal'), ('major', 'goal', 'statistical'), ('goal', 'statistical', 'learning'), ('statistical', 'learning', 'algorithms'), ('learning', 'algorithms', 'provide'), ('algorithms', 'provide', 'framework'), ('provide', 'framework', 'studying'), ('framework', 'studying', 'problem'), ('studying', 'problem', 'inference'), ('problem', 'inference', 'obtaining'), ('inference', 'obtaining', 'knowledge'), ('obtaining', 'knowledge', ','), ('knowledge', ',', 'making'), (',', 'making', 'predictions'), ('making', 'predictions', 'making'), ('predictions', 'making', 'decision'), ('making', 'decision', 'constructing'), ('decision', 'constructing', 'model'), ('constructing', 'model', 'set'), ('model', 'set', 'data'), ('set', 'data', '['), ('data', '[', '17'), ('[', '17', ']'), ('17', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('major', 'JJ'), ('goal', 'NN'), ('statistical', 'JJ'), ('learning', 'NN'), ('algorithms', 'NNS'), ('provide', 'VBP'), ('framework', 'NN'), ('studying', 'VBG'), ('problem', 'NN'), ('inference', 'NN'), ('obtaining', 'VBG'), ('knowledge', 'NN'), (',', ','), ('making', 'VBG'), ('predictions', 'NNS'), ('making', 'VBG'), ('decision', 'NN'), ('constructing', 'VBG'), ('model', 'NN'), ('set', 'VBN'), ('data', 'NNS'), ('[', '$'), ('17', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP The/DT major/JJ goal/NN)
  (NP statistical/JJ learning/NN algorithms/NNS)
  provide/VBP
  (NP framework/NN)
  studying/VBG
  (NP problem/NN inference/NN)
  obtaining/VBG
  (NP knowledge/NN)
  ,/,
  making/VBG
  (NP predictions/NNS)
  making/VBG
  (NP decision/NN)
  constructing/VBG
  (NP model/NN)
  set/VBN
  (NP data/NNS)
  [/$
  17/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['The major goal', 'statistical learning algorithms', 'framework', 'problem inference', 'knowledge', 'predictions', 'decision', 'model', 'data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('framework', 'framework'), ('studying', 'studi'), ('problem', 'problem'), ('inference', 'infer'), ('obtaining', 'obtain'), ('knowledge', 'knowledg'), (',', ','), ('making', 'make'), ('predictions', 'predict'), ('making', 'make'), ('decision', 'decis'), ('constructing', 'construct'), ('model', 'model'), ('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('framework', 'framework'), ('studying', 'studi'), ('problem', 'problem'), ('inference', 'infer'), ('obtaining', 'obtain'), ('knowledge', 'knowledg'), (',', ','), ('making', 'make'), ('predictions', 'predict'), ('making', 'make'), ('decision', 'decis'), ('constructing', 'construct'), ('model', 'model'), ('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statistical'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('provide', 'provide'), ('framework', 'framework'), ('studying', 'studying'), ('problem', 'problem'), ('inference', 'inference'), ('obtaining', 'obtaining'), ('knowledge', 'knowledge'), (',', ','), ('making', 'making'), ('predictions', 'prediction'), ('making', 'making'), ('decision', 'decision'), ('constructing', 'constructing'), ('model', 'model'), ('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]



============================ Sentence 125 =============================

Bayesian networks are the most well known representative of   statistical learning algorithms. 


>> Tokens are: 
 ['Bayesian', 'networks', 'well', 'known', 'representative', 'statistical', 'learning', 'algorithms', '.']

>> Bigrams are: 
 [('Bayesian', 'networks'), ('networks', 'well'), ('well', 'known'), ('known', 'representative'), ('representative', 'statistical'), ('statistical', 'learning'), ('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Bayesian', 'networks', 'well'), ('networks', 'well', 'known'), ('well', 'known', 'representative'), ('known', 'representative', 'statistical'), ('representative', 'statistical', 'learning'), ('statistical', 'learning', 'algorithms'), ('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('networks', 'NNS'), ('well', 'RB'), ('known', 'VBN'), ('representative', 'JJ'), ('statistical', 'JJ'), ('learning', 'NN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  (NP Bayesian/JJ networks/NNS)
  well/RB
  known/VBN
  (NP representative/JJ statistical/JJ learning/NN algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['Bayesian networks', 'representative statistical learning algorithms']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'repres'), ('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'repres'), ('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'representative'), ('statistical', 'statistical'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 126 =============================

A good source for learning   Bayesian Networks (BN) theory is [18], where readers can learn   applications of BN. 


>> Tokens are: 
 ['A', 'good', 'source', 'learning', 'Bayesian', 'Networks', '(', 'BN', ')', 'theory', '[', '18', ']', ',', 'readers', 'learn', 'applications', 'BN', '.']

>> Bigrams are: 
 [('A', 'good'), ('good', 'source'), ('source', 'learning'), ('learning', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', '('), ('(', 'BN'), ('BN', ')'), (')', 'theory'), ('theory', '['), ('[', '18'), ('18', ']'), (']', ','), (',', 'readers'), ('readers', 'learn'), ('learn', 'applications'), ('applications', 'BN'), ('BN', '.')]

>> Trigrams are: 
 [('A', 'good', 'source'), ('good', 'source', 'learning'), ('source', 'learning', 'Bayesian'), ('learning', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', '('), ('Networks', '(', 'BN'), ('(', 'BN', ')'), ('BN', ')', 'theory'), (')', 'theory', '['), ('theory', '[', '18'), ('[', '18', ']'), ('18', ']', ','), (']', ',', 'readers'), (',', 'readers', 'learn'), ('readers', 'learn', 'applications'), ('learn', 'applications', 'BN'), ('applications', 'BN', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('good', 'JJ'), ('source', 'NN'), ('learning', 'VBG'), ('Bayesian', 'JJ'), ('Networks', 'NNP'), ('(', '('), ('BN', 'NNP'), (')', ')'), ('theory', 'NN'), ('[', '$'), ('18', 'CD'), (']', 'NNP'), (',', ','), ('readers', 'NNS'), ('learn', 'VBP'), ('applications', 'NNS'), ('BN', 'NNP'), ('.', '.')]

 (S
  (NP A/DT good/JJ source/NN)
  learning/VBG
  (NP Bayesian/JJ Networks/NNP)
  (/(
  (NP BN/NNP)
  )/)
  (NP theory/NN)
  [/$
  18/CD
  (NP ]/NNP)
  ,/,
  (NP readers/NNS)
  learn/VBP
  (NP applications/NNS BN/NNP)
  ./.) 


>> Noun Phrases are: 
 ['A good source', 'Bayesian Networks', 'BN', 'theory', ']', 'readers', 'applications BN']

>> Named Entities are: 
 [('PERSON', 'Bayesian Networks')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('good', 'good'), ('source', 'sourc'), ('learning', 'learn'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('theory', 'theori'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('good', 'good'), ('source', 'sourc'), ('learning', 'learn'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('theory', 'theori'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('good', 'good'), ('source', 'source'), ('learning', 'learning'), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('BN', 'BN'), (')', ')'), ('theory', 'theory'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn'), ('applications', 'application'), ('BN', 'BN'), ('.', '.')]



============================ Sentence 127 =============================

Statistical methods are characterized by having an explicit   underlying probability model, which provides a probability that an   instance belongs in each class, rather than simply a classification. 


>> Tokens are: 
 ['Statistical', 'methods', 'characterized', 'explicit', 'underlying', 'probability', 'model', ',', 'provides', 'probability', 'instance', 'belongs', 'class', ',', 'rather', 'simply', 'classification', '.']

>> Bigrams are: 
 [('Statistical', 'methods'), ('methods', 'characterized'), ('characterized', 'explicit'), ('explicit', 'underlying'), ('underlying', 'probability'), ('probability', 'model'), ('model', ','), (',', 'provides'), ('provides', 'probability'), ('probability', 'instance'), ('instance', 'belongs'), ('belongs', 'class'), ('class', ','), (',', 'rather'), ('rather', 'simply'), ('simply', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('Statistical', 'methods', 'characterized'), ('methods', 'characterized', 'explicit'), ('characterized', 'explicit', 'underlying'), ('explicit', 'underlying', 'probability'), ('underlying', 'probability', 'model'), ('probability', 'model', ','), ('model', ',', 'provides'), (',', 'provides', 'probability'), ('provides', 'probability', 'instance'), ('probability', 'instance', 'belongs'), ('instance', 'belongs', 'class'), ('belongs', 'class', ','), ('class', ',', 'rather'), (',', 'rather', 'simply'), ('rather', 'simply', 'classification'), ('simply', 'classification', '.')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('methods', 'NNS'), ('characterized', 'VBN'), ('explicit', 'JJ'), ('underlying', 'JJ'), ('probability', 'NN'), ('model', 'NN'), (',', ','), ('provides', 'VBZ'), ('probability', 'NN'), ('instance', 'NN'), ('belongs', 'NNS'), ('class', 'NN'), (',', ','), ('rather', 'RB'), ('simply', 'RB'), ('classification', 'NN'), ('.', '.')]

 (S
  (NP Statistical/JJ methods/NNS)
  characterized/VBN
  (NP explicit/JJ underlying/JJ probability/NN model/NN)
  ,/,
  provides/VBZ
  (NP probability/NN instance/NN belongs/NNS class/NN)
  ,/,
  rather/RB
  simply/RB
  (NP classification/NN)
  ./.) 


>> Noun Phrases are: 
 ['Statistical methods', 'explicit underlying probability model', 'probability instance belongs class', 'classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('methods', 'method'), ('characterized', 'character'), ('explicit', 'explicit'), ('underlying', 'underli'), ('probability', 'probabl'), ('model', 'model'), (',', ','), ('provides', 'provid'), ('probability', 'probabl'), ('instance', 'instanc'), ('belongs', 'belong'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simpli'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('methods', 'method'), ('characterized', 'character'), ('explicit', 'explicit'), ('underlying', 'under'), ('probability', 'probabl'), ('model', 'model'), (',', ','), ('provides', 'provid'), ('probability', 'probabl'), ('instance', 'instanc'), ('belongs', 'belong'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simpli'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('methods', 'method'), ('characterized', 'characterized'), ('explicit', 'explicit'), ('underlying', 'underlying'), ('probability', 'probability'), ('model', 'model'), (',', ','), ('provides', 'provides'), ('probability', 'probability'), ('instance', 'instance'), ('belongs', 'belongs'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simply'), ('classification', 'classification'), ('.', '.')]



============================ Sentence 128 =============================

Linear Discriminate Analysis (LDA),which was developed in   1936, and the related Fishers linear discriminate are famous   methods used in statistics and machine learning to retrieve the   linear combination of features which best separate two or more   classes of object [1]. 


>> Tokens are: 
 ['Linear', 'Discriminate', 'Analysis', '(', 'LDA', ')', ',', 'developed', '1936', ',', 'related', 'Fisher', '', 'linear', 'discriminate', 'famous', 'methods', 'used', 'statistics', 'machine', 'learning', 'retrieve', 'linear', 'combination', 'features', 'best', 'separate', 'two', 'classes', 'object', '[', '1', ']', '.']

>> Bigrams are: 
 [('Linear', 'Discriminate'), ('Discriminate', 'Analysis'), ('Analysis', '('), ('(', 'LDA'), ('LDA', ')'), (')', ','), (',', 'developed'), ('developed', '1936'), ('1936', ','), (',', 'related'), ('related', 'Fisher'), ('Fisher', ''), ('', 'linear'), ('linear', 'discriminate'), ('discriminate', 'famous'), ('famous', 'methods'), ('methods', 'used'), ('used', 'statistics'), ('statistics', 'machine'), ('machine', 'learning'), ('learning', 'retrieve'), ('retrieve', 'linear'), ('linear', 'combination'), ('combination', 'features'), ('features', 'best'), ('best', 'separate'), ('separate', 'two'), ('two', 'classes'), ('classes', 'object'), ('object', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Linear', 'Discriminate', 'Analysis'), ('Discriminate', 'Analysis', '('), ('Analysis', '(', 'LDA'), ('(', 'LDA', ')'), ('LDA', ')', ','), (')', ',', 'developed'), (',', 'developed', '1936'), ('developed', '1936', ','), ('1936', ',', 'related'), (',', 'related', 'Fisher'), ('related', 'Fisher', ''), ('Fisher', '', 'linear'), ('', 'linear', 'discriminate'), ('linear', 'discriminate', 'famous'), ('discriminate', 'famous', 'methods'), ('famous', 'methods', 'used'), ('methods', 'used', 'statistics'), ('used', 'statistics', 'machine'), ('statistics', 'machine', 'learning'), ('machine', 'learning', 'retrieve'), ('learning', 'retrieve', 'linear'), ('retrieve', 'linear', 'combination'), ('linear', 'combination', 'features'), ('combination', 'features', 'best'), ('features', 'best', 'separate'), ('best', 'separate', 'two'), ('separate', 'two', 'classes'), ('two', 'classes', 'object'), ('classes', 'object', '['), ('object', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Linear', 'JJ'), ('Discriminate', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LDA', 'NNP'), (')', ')'), (',', ','), ('developed', 'JJ'), ('1936', 'CD'), (',', ','), ('related', 'VBN'), ('Fisher', 'NNP'), ('', 'JJ'), ('linear', 'JJ'), ('discriminate', 'NN'), ('famous', 'JJ'), ('methods', 'NNS'), ('used', 'VBN'), ('statistics', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('retrieve', 'JJ'), ('linear', 'JJ'), ('combination', 'NN'), ('features', 'NNS'), ('best', 'RB'), ('separate', 'VBP'), ('two', 'CD'), ('classes', 'NNS'), ('object', 'VBP'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Linear/JJ Discriminate/NNP Analysis/NNP)
  (/(
  (NP LDA/NNP)
  )/)
  ,/,
  developed/JJ
  1936/CD
  ,/,
  related/VBN
  (NP Fisher/NNP)
  (NP /JJ linear/JJ discriminate/NN)
  (NP famous/JJ methods/NNS)
  used/VBN
  (NP statistics/NNS machine/NN)
  learning/VBG
  (NP retrieve/JJ linear/JJ combination/NN features/NNS)
  best/RB
  separate/VBP
  two/CD
  (NP classes/NNS)
  object/VBP
  [/$
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Linear Discriminate Analysis', 'LDA', 'Fisher', ' linear discriminate', 'famous methods', 'statistics machine', 'retrieve linear combination features', 'classes', ']']

>> Named Entities are: 
 [('PERSON', 'Linear'), ('ORGANIZATION', 'Discriminate Analysis'), ('ORGANIZATION', 'LDA'), ('PERSON', 'Fisher')] 

>> Stemming using Porter Stemmer: 
 [('Linear', 'linear'), ('Discriminate', 'discrimin'), ('Analysis', 'analysi'), ('(', '('), ('LDA', 'lda'), (')', ')'), (',', ','), ('developed', 'develop'), ('1936', '1936'), (',', ','), ('related', 'relat'), ('Fisher', 'fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discrimin'), ('famous', 'famou'), ('methods', 'method'), ('used', 'use'), ('statistics', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('retrieve', 'retriev'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('best', 'best'), ('separate', 'separ'), ('two', 'two'), ('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Linear', 'linear'), ('Discriminate', 'discrimin'), ('Analysis', 'analysi'), ('(', '('), ('LDA', 'lda'), (')', ')'), (',', ','), ('developed', 'develop'), ('1936', '1936'), (',', ','), ('related', 'relat'), ('Fisher', 'fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discrimin'), ('famous', 'famous'), ('methods', 'method'), ('used', 'use'), ('statistics', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('retrieve', 'retriev'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('best', 'best'), ('separate', 'separ'), ('two', 'two'), ('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Linear', 'Linear'), ('Discriminate', 'Discriminate'), ('Analysis', 'Analysis'), ('(', '('), ('LDA', 'LDA'), (')', ')'), (',', ','), ('developed', 'developed'), ('1936', '1936'), (',', ','), ('related', 'related'), ('Fisher', 'Fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discriminate'), ('famous', 'famous'), ('methods', 'method'), ('used', 'used'), ('statistics', 'statistic'), ('machine', 'machine'), ('learning', 'learning'), ('retrieve', 'retrieve'), ('linear', 'linear'), ('combination', 'combination'), ('features', 'feature'), ('best', 'best'), ('separate', 'separate'), ('two', 'two'), ('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 129 =============================

The purpose of discriminate analysis is to   classify objects (nations, people, customers) into one of two or   more groups based on set of features that describe the objects (e.g.-.-   gender, marital status, income, height, weight...). 


>> Tokens are: 
 ['The', 'purpose', 'discriminate', 'analysis', 'classify', 'objects', '(', 'nations', ',', 'people', ',', 'customers', ')', 'one', 'two', 'groups', 'based', 'set', 'features', 'describe', 'objects', '(', 'e.g.-.-', 'gender', ',', 'marital', 'status', ',', 'income', ',', 'height', ',', 'weight', '...', ')', '.']

>> Bigrams are: 
 [('The', 'purpose'), ('purpose', 'discriminate'), ('discriminate', 'analysis'), ('analysis', 'classify'), ('classify', 'objects'), ('objects', '('), ('(', 'nations'), ('nations', ','), (',', 'people'), ('people', ','), (',', 'customers'), ('customers', ')'), (')', 'one'), ('one', 'two'), ('two', 'groups'), ('groups', 'based'), ('based', 'set'), ('set', 'features'), ('features', 'describe'), ('describe', 'objects'), ('objects', '('), ('(', 'e.g.-.-'), ('e.g.-.-', 'gender'), ('gender', ','), (',', 'marital'), ('marital', 'status'), ('status', ','), (',', 'income'), ('income', ','), (',', 'height'), ('height', ','), (',', 'weight'), ('weight', '...'), ('...', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'purpose', 'discriminate'), ('purpose', 'discriminate', 'analysis'), ('discriminate', 'analysis', 'classify'), ('analysis', 'classify', 'objects'), ('classify', 'objects', '('), ('objects', '(', 'nations'), ('(', 'nations', ','), ('nations', ',', 'people'), (',', 'people', ','), ('people', ',', 'customers'), (',', 'customers', ')'), ('customers', ')', 'one'), (')', 'one', 'two'), ('one', 'two', 'groups'), ('two', 'groups', 'based'), ('groups', 'based', 'set'), ('based', 'set', 'features'), ('set', 'features', 'describe'), ('features', 'describe', 'objects'), ('describe', 'objects', '('), ('objects', '(', 'e.g.-.-'), ('(', 'e.g.-.-', 'gender'), ('e.g.-.-', 'gender', ','), ('gender', ',', 'marital'), (',', 'marital', 'status'), ('marital', 'status', ','), ('status', ',', 'income'), (',', 'income', ','), ('income', ',', 'height'), (',', 'height', ','), ('height', ',', 'weight'), (',', 'weight', '...'), ('weight', '...', ')'), ('...', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('purpose', 'JJ'), ('discriminate', 'NN'), ('analysis', 'NN'), ('classify', 'NN'), ('objects', 'NNS'), ('(', '('), ('nations', 'NNS'), (',', ','), ('people', 'NNS'), (',', ','), ('customers', 'NN'), (')', ')'), ('one', 'CD'), ('two', 'CD'), ('groups', 'NNS'), ('based', 'VBN'), ('set', 'VBN'), ('features', 'NNS'), ('describe', 'JJ'), ('objects', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), ('gender', 'NN'), (',', ','), ('marital', 'JJ'), ('status', 'NN'), (',', ','), ('income', 'NN'), (',', ','), ('height', 'NN'), (',', ','), ('weight', 'NN'), ('...', ':'), (')', ')'), ('.', '.')]

 (S
  (NP
    The/DT
    purpose/JJ
    discriminate/NN
    analysis/NN
    classify/NN
    objects/NNS)
  (/(
  (NP nations/NNS)
  ,/,
  (NP people/NNS)
  ,/,
  (NP customers/NN)
  )/)
  one/CD
  two/CD
  (NP groups/NNS)
  based/VBN
  set/VBN
  (NP features/NNS)
  (NP describe/JJ objects/NNS)
  (/(
  (NP e.g.-.-/JJ gender/NN)
  ,/,
  (NP marital/JJ status/NN)
  ,/,
  (NP income/NN)
  ,/,
  (NP height/NN)
  ,/,
  (NP weight/NN)
  .../:
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The purpose discriminate analysis classify objects', 'nations', 'people', 'customers', 'groups', 'features', 'describe objects', 'e.g.-.- gender', 'marital status', 'income', 'height', 'weight']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('discriminate', 'discrimin'), ('analysis', 'analysi'), ('classify', 'classifi'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'peopl'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two'), ('groups', 'group'), ('based', 'base'), ('set', 'set'), ('features', 'featur'), ('describe', 'describ'), ('objects', 'object'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('gender', 'gender'), (',', ','), ('marital', 'marit'), ('status', 'statu'), (',', ','), ('income', 'incom'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('discriminate', 'discrimin'), ('analysis', 'analysi'), ('classify', 'classifi'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'peopl'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two'), ('groups', 'group'), ('based', 'base'), ('set', 'set'), ('features', 'featur'), ('describe', 'describ'), ('objects', 'object'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('gender', 'gender'), (',', ','), ('marital', 'marit'), ('status', 'status'), (',', ','), ('income', 'incom'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('purpose', 'purpose'), ('discriminate', 'discriminate'), ('analysis', 'analysis'), ('classify', 'classify'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'people'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two'), ('groups', 'group'), ('based', 'based'), ('set', 'set'), ('features', 'feature'), ('describe', 'describe'), ('objects', 'object'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('gender', 'gender'), (',', ','), ('marital', 'marital'), ('status', 'status'), (',', ','), ('income', 'income'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]



============================ Sentence 130 =============================

The another   method for estimating probability distributions from data is   maximum entropy. 


>> Tokens are: 
 ['The', 'another', 'method', 'estimating', 'probability', 'distributions', 'data', 'maximum', 'entropy', '.']

>> Bigrams are: 
 [('The', 'another'), ('another', 'method'), ('method', 'estimating'), ('estimating', 'probability'), ('probability', 'distributions'), ('distributions', 'data'), ('data', 'maximum'), ('maximum', 'entropy'), ('entropy', '.')]

>> Trigrams are: 
 [('The', 'another', 'method'), ('another', 'method', 'estimating'), ('method', 'estimating', 'probability'), ('estimating', 'probability', 'distributions'), ('probability', 'distributions', 'data'), ('distributions', 'data', 'maximum'), ('data', 'maximum', 'entropy'), ('maximum', 'entropy', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('another', 'DT'), ('method', 'NN'), ('estimating', 'VBG'), ('probability', 'NN'), ('distributions', 'NNS'), ('data', 'VBP'), ('maximum', 'JJ'), ('entropy', 'NN'), ('.', '.')]

 (S
  The/DT
  (NP another/DT method/NN)
  estimating/VBG
  (NP probability/NN distributions/NNS)
  data/VBP
  (NP maximum/JJ entropy/NN)
  ./.) 


>> Noun Phrases are: 
 ['another method', 'probability distributions', 'maximum entropy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('another', 'anoth'), ('method', 'method'), ('estimating', 'estim'), ('probability', 'probabl'), ('distributions', 'distribut'), ('data', 'data'), ('maximum', 'maximum'), ('entropy', 'entropi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('another', 'anoth'), ('method', 'method'), ('estimating', 'estim'), ('probability', 'probabl'), ('distributions', 'distribut'), ('data', 'data'), ('maximum', 'maximum'), ('entropy', 'entropi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('another', 'another'), ('method', 'method'), ('estimating', 'estimating'), ('probability', 'probability'), ('distributions', 'distribution'), ('data', 'data'), ('maximum', 'maximum'), ('entropy', 'entropy'), ('.', '.')]



============================ Sentence 131 =============================

According to the base theory of maximum   entropy, if nothing is known about a distribution except that it   belongs to a certain class, then the distribution with the largest   entropy should be chosen as the default. 


>> Tokens are: 
 ['According', 'base', 'theory', 'maximum', 'entropy', ',', 'nothing', 'known', 'distribution', 'except', 'belongs', 'certain', 'class', ',', 'distribution', 'largest', 'entropy', 'chosen', 'default', '.']

>> Bigrams are: 
 [('According', 'base'), ('base', 'theory'), ('theory', 'maximum'), ('maximum', 'entropy'), ('entropy', ','), (',', 'nothing'), ('nothing', 'known'), ('known', 'distribution'), ('distribution', 'except'), ('except', 'belongs'), ('belongs', 'certain'), ('certain', 'class'), ('class', ','), (',', 'distribution'), ('distribution', 'largest'), ('largest', 'entropy'), ('entropy', 'chosen'), ('chosen', 'default'), ('default', '.')]

>> Trigrams are: 
 [('According', 'base', 'theory'), ('base', 'theory', 'maximum'), ('theory', 'maximum', 'entropy'), ('maximum', 'entropy', ','), ('entropy', ',', 'nothing'), (',', 'nothing', 'known'), ('nothing', 'known', 'distribution'), ('known', 'distribution', 'except'), ('distribution', 'except', 'belongs'), ('except', 'belongs', 'certain'), ('belongs', 'certain', 'class'), ('certain', 'class', ','), ('class', ',', 'distribution'), (',', 'distribution', 'largest'), ('distribution', 'largest', 'entropy'), ('largest', 'entropy', 'chosen'), ('entropy', 'chosen', 'default'), ('chosen', 'default', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('base', 'NN'), ('theory', 'NN'), ('maximum', 'JJ'), ('entropy', 'NN'), (',', ','), ('nothing', 'NN'), ('known', 'VBN'), ('distribution', 'NN'), ('except', 'IN'), ('belongs', 'NNS'), ('certain', 'JJ'), ('class', 'NN'), (',', ','), ('distribution', 'NN'), ('largest', 'JJS'), ('entropy', 'NN'), ('chosen', 'NN'), ('default', 'NN'), ('.', '.')]

 (S
  According/VBG
  (NP base/NN theory/NN)
  (NP maximum/JJ entropy/NN)
  ,/,
  (NP nothing/NN)
  known/VBN
  (NP distribution/NN)
  except/IN
  (NP belongs/NNS)
  (NP certain/JJ class/NN)
  ,/,
  (NP distribution/NN)
  largest/JJS
  (NP entropy/NN chosen/NN default/NN)
  ./.) 


>> Noun Phrases are: 
 ['base theory', 'maximum entropy', 'nothing', 'distribution', 'belongs', 'certain class', 'distribution', 'entropy chosen default']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('base', 'base'), ('theory', 'theori'), ('maximum', 'maximum'), ('entropy', 'entropi'), (',', ','), ('nothing', 'noth'), ('known', 'known'), ('distribution', 'distribut'), ('except', 'except'), ('belongs', 'belong'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribut'), ('largest', 'largest'), ('entropy', 'entropi'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('base', 'base'), ('theory', 'theori'), ('maximum', 'maximum'), ('entropy', 'entropi'), (',', ','), ('nothing', 'noth'), ('known', 'known'), ('distribution', 'distribut'), ('except', 'except'), ('belongs', 'belong'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribut'), ('largest', 'largest'), ('entropy', 'entropi'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('base', 'base'), ('theory', 'theory'), ('maximum', 'maximum'), ('entropy', 'entropy'), (',', ','), ('nothing', 'nothing'), ('known', 'known'), ('distribution', 'distribution'), ('except', 'except'), ('belongs', 'belongs'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribution'), ('largest', 'largest'), ('entropy', 'entropy'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]



============================ Sentence 132 =============================

4.1 NAIVE BAYES CLASSIFIERS   Bayesian networks are widely used to perform classification   tasks. 


>> Tokens are: 
 ['4.1', 'NAIVE', 'BAYES', 'CLASSIFIERS', 'Bayesian', 'networks', 'widely', 'used', 'perform', 'classification', 'tasks', '.']

>> Bigrams are: 
 [('4.1', 'NAIVE'), ('NAIVE', 'BAYES'), ('BAYES', 'CLASSIFIERS'), ('CLASSIFIERS', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'widely'), ('widely', 'used'), ('used', 'perform'), ('perform', 'classification'), ('classification', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('4.1', 'NAIVE', 'BAYES'), ('NAIVE', 'BAYES', 'CLASSIFIERS'), ('BAYES', 'CLASSIFIERS', 'Bayesian'), ('CLASSIFIERS', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'widely'), ('networks', 'widely', 'used'), ('widely', 'used', 'perform'), ('used', 'perform', 'classification'), ('perform', 'classification', 'tasks'), ('classification', 'tasks', '.')]

>> POS Tags are: 
 [('4.1', 'CD'), ('NAIVE', 'NNP'), ('BAYES', 'NNP'), ('CLASSIFIERS', 'NNP'), ('Bayesian', 'NNP'), ('networks', 'VBZ'), ('widely', 'RB'), ('used', 'VBN'), ('perform', 'NN'), ('classification', 'NN'), ('tasks', 'NNS'), ('.', '.')]

 (S
  4.1/CD
  (NP NAIVE/NNP BAYES/NNP CLASSIFIERS/NNP Bayesian/NNP)
  networks/VBZ
  widely/RB
  used/VBN
  (NP perform/NN classification/NN tasks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['NAIVE BAYES CLASSIFIERS Bayesian', 'perform classification tasks']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('4.1', '4.1'), ('NAIVE', 'naiv'), ('BAYES', 'bay'), ('CLASSIFIERS', 'classifi'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('widely', 'wide'), ('used', 'use'), ('perform', 'perform'), ('classification', 'classif'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4.1', '4.1'), ('NAIVE', 'naiv'), ('BAYES', 'bay'), ('CLASSIFIERS', 'classifi'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('widely', 'wide'), ('used', 'use'), ('perform', 'perform'), ('classification', 'classif'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('4.1', '4.1'), ('NAIVE', 'NAIVE'), ('BAYES', 'BAYES'), ('CLASSIFIERS', 'CLASSIFIERS'), ('Bayesian', 'Bayesian'), ('networks', 'network'), ('widely', 'widely'), ('used', 'used'), ('perform', 'perform'), ('classification', 'classification'), ('tasks', 'task'), ('.', '.')]



============================ Sentence 133 =============================

Naive Bayesian Networks (NBN) are very simple   Bayesian networks which are composed of directed acyclic   graphs with only one parent (representing the unobserved node)   and several children (corresponding to observed nodes) with a   strong assumption of independence among child nodes in the   context of their parent [21]. 


>> Tokens are: 
 ['Naive', 'Bayesian', 'Networks', '(', 'NBN', ')', 'simple', 'Bayesian', 'networks', 'composed', 'directed', 'acyclic', 'graphs', 'one', 'parent', '(', 'representing', 'unobserved', 'node', ')', 'several', 'children', '(', 'corresponding', 'observed', 'nodes', ')', 'strong', 'assumption', 'independence', 'among', 'child', 'nodes', 'context', 'parent', '[', '21', ']', '.']

>> Bigrams are: 
 [('Naive', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', '('), ('(', 'NBN'), ('NBN', ')'), (')', 'simple'), ('simple', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'composed'), ('composed', 'directed'), ('directed', 'acyclic'), ('acyclic', 'graphs'), ('graphs', 'one'), ('one', 'parent'), ('parent', '('), ('(', 'representing'), ('representing', 'unobserved'), ('unobserved', 'node'), ('node', ')'), (')', 'several'), ('several', 'children'), ('children', '('), ('(', 'corresponding'), ('corresponding', 'observed'), ('observed', 'nodes'), ('nodes', ')'), (')', 'strong'), ('strong', 'assumption'), ('assumption', 'independence'), ('independence', 'among'), ('among', 'child'), ('child', 'nodes'), ('nodes', 'context'), ('context', 'parent'), ('parent', '['), ('[', '21'), ('21', ']'), (']', '.')]

>> Trigrams are: 
 [('Naive', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', '('), ('Networks', '(', 'NBN'), ('(', 'NBN', ')'), ('NBN', ')', 'simple'), (')', 'simple', 'Bayesian'), ('simple', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'composed'), ('networks', 'composed', 'directed'), ('composed', 'directed', 'acyclic'), ('directed', 'acyclic', 'graphs'), ('acyclic', 'graphs', 'one'), ('graphs', 'one', 'parent'), ('one', 'parent', '('), ('parent', '(', 'representing'), ('(', 'representing', 'unobserved'), ('representing', 'unobserved', 'node'), ('unobserved', 'node', ')'), ('node', ')', 'several'), (')', 'several', 'children'), ('several', 'children', '('), ('children', '(', 'corresponding'), ('(', 'corresponding', 'observed'), ('corresponding', 'observed', 'nodes'), ('observed', 'nodes', ')'), ('nodes', ')', 'strong'), (')', 'strong', 'assumption'), ('strong', 'assumption', 'independence'), ('assumption', 'independence', 'among'), ('independence', 'among', 'child'), ('among', 'child', 'nodes'), ('child', 'nodes', 'context'), ('nodes', 'context', 'parent'), ('context', 'parent', '['), ('parent', '[', '21'), ('[', '21', ']'), ('21', ']', '.')]

>> POS Tags are: 
 [('Naive', 'JJ'), ('Bayesian', 'JJ'), ('Networks', 'NNP'), ('(', '('), ('NBN', 'NNP'), (')', ')'), ('simple', 'NN'), ('Bayesian', 'JJ'), ('networks', 'NNS'), ('composed', 'VBD'), ('directed', 'VBN'), ('acyclic', 'JJ'), ('graphs', 'NN'), ('one', 'CD'), ('parent', 'NN'), ('(', '('), ('representing', 'VBG'), ('unobserved', 'JJ'), ('node', 'NN'), (')', ')'), ('several', 'JJ'), ('children', 'NNS'), ('(', '('), ('corresponding', 'VBG'), ('observed', 'VBN'), ('nodes', 'NNS'), (')', ')'), ('strong', 'JJ'), ('assumption', 'NN'), ('independence', 'NN'), ('among', 'IN'), ('child', 'JJ'), ('nodes', 'NNS'), ('context', 'JJ'), ('parent', 'NN'), ('[', 'VBD'), ('21', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Naive/JJ Bayesian/JJ Networks/NNP)
  (/(
  (NP NBN/NNP)
  )/)
  (NP simple/NN)
  (NP Bayesian/JJ networks/NNS)
  composed/VBD
  directed/VBN
  (NP acyclic/JJ graphs/NN)
  one/CD
  (NP parent/NN)
  (/(
  representing/VBG
  (NP unobserved/JJ node/NN)
  )/)
  (NP several/JJ children/NNS)
  (/(
  corresponding/VBG
  observed/VBN
  (NP nodes/NNS)
  )/)
  (NP strong/JJ assumption/NN independence/NN)
  among/IN
  (NP child/JJ nodes/NNS)
  (NP context/JJ parent/NN)
  [/VBD
  21/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Naive Bayesian Networks', 'NBN', 'simple', 'Bayesian networks', 'acyclic graphs', 'parent', 'unobserved node', 'several children', 'nodes', 'strong assumption independence', 'child nodes', 'context parent', ']']

>> Named Entities are: 
 [('PERSON', 'Bayesian Networks'), ('ORGANIZATION', 'NBN'), ('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Naive', 'naiv'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('NBN', 'nbn'), (')', ')'), ('simple', 'simpl'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('composed', 'compos'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'repres'), ('unobserved', 'unobserv'), ('node', 'node'), (')', ')'), ('several', 'sever'), ('children', 'children'), ('(', '('), ('corresponding', 'correspond'), ('observed', 'observ'), ('nodes', 'node'), (')', ')'), ('strong', 'strong'), ('assumption', 'assumpt'), ('independence', 'independ'), ('among', 'among'), ('child', 'child'), ('nodes', 'node'), ('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Naive', 'naiv'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('NBN', 'nbn'), (')', ')'), ('simple', 'simpl'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('composed', 'compos'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'repres'), ('unobserved', 'unobserv'), ('node', 'node'), (')', ')'), ('several', 'sever'), ('children', 'children'), ('(', '('), ('corresponding', 'correspond'), ('observed', 'observ'), ('nodes', 'node'), (')', ')'), ('strong', 'strong'), ('assumption', 'assumpt'), ('independence', 'independ'), ('among', 'among'), ('child', 'child'), ('nodes', 'node'), ('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Naive', 'Naive'), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('NBN', 'NBN'), (')', ')'), ('simple', 'simple'), ('Bayesian', 'Bayesian'), ('networks', 'network'), ('composed', 'composed'), ('directed', 'directed'), ('acyclic', 'acyclic'), ('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'representing'), ('unobserved', 'unobserved'), ('node', 'node'), (')', ')'), ('several', 'several'), ('children', 'child'), ('(', '('), ('corresponding', 'corresponding'), ('observed', 'observed'), ('nodes', 'node'), (')', ')'), ('strong', 'strong'), ('assumption', 'assumption'), ('independence', 'independence'), ('among', 'among'), ('child', 'child'), ('nodes', 'node'), ('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]



============================ Sentence 134 =============================

According to author [20] the   independence model (Naive Bayes) is based on estimating:                          JXPjP  XPPiP  JXPjP  XPiP  XJP  XP R  r  r |  |  |  |  |  |         (3)   Here comparing these two probabilities, the larger   probability indicates that the class label value that is more likely   to be the actual label (if R>1: predict i else predict j) [1]. 


>> Tokens are: 
 ['According', 'author', '[', '20', ']', 'independence', 'model', '(', 'Naive', 'Bayes', ')', 'based', 'estimating', ':', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029JXPjP', 'XPPiP', 'JXPjP', 'XPiP', 'XJP', 'XP', 'R', 'r', 'r', '|', '|', '|', '|', '|', '|', '\uf050', '\uf050', '\uf03d\uf03d\uf03d', '\uf069\uf069\uf069', '(', '3', ')', 'Here', 'comparing', 'two', 'probabilities', ',', 'larger', 'probability', 'indicates', 'class', 'label', 'value', 'likely', 'actual', 'label', '(', 'R', '>', '1', ':', 'predict', 'else', 'predict', 'j', ')', '[', '1', ']', '.']

>> Bigrams are: 
 [('According', 'author'), ('author', '['), ('[', '20'), ('20', ']'), (']', 'independence'), ('independence', 'model'), ('model', '('), ('(', 'Naive'), ('Naive', 'Bayes'), ('Bayes', ')'), (')', 'based'), ('based', 'estimating'), ('estimating', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029JXPjP'), ('\uf029JXPjP', 'XPPiP'), ('XPPiP', 'JXPjP'), ('JXPjP', 'XPiP'), ('XPiP', 'XJP'), ('XJP', 'XP'), ('XP', 'R'), ('R', 'r'), ('r', 'r'), ('r', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '\uf050'), ('\uf050', '\uf050'), ('\uf050', '\uf03d\uf03d\uf03d'), ('\uf03d\uf03d\uf03d', '\uf069\uf069\uf069'), ('\uf069\uf069\uf069', '('), ('(', '3'), ('3', ')'), (')', 'Here'), ('Here', 'comparing'), ('comparing', 'two'), ('two', 'probabilities'), ('probabilities', ','), (',', 'larger'), ('larger', 'probability'), ('probability', 'indicates'), ('indicates', 'class'), ('class', 'label'), ('label', 'value'), ('value', 'likely'), ('likely', 'actual'), ('actual', 'label'), ('label', '('), ('(', 'R'), ('R', '>'), ('>', '1'), ('1', ':'), (':', 'predict'), ('predict', 'else'), ('else', 'predict'), ('predict', 'j'), ('j', ')'), (')', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('According', 'author', '['), ('author', '[', '20'), ('[', '20', ']'), ('20', ']', 'independence'), (']', 'independence', 'model'), ('independence', 'model', '('), ('model', '(', 'Naive'), ('(', 'Naive', 'Bayes'), ('Naive', 'Bayes', ')'), ('Bayes', ')', 'based'), (')', 'based', 'estimating'), ('based', 'estimating', ':'), ('estimating', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029JXPjP'), ('\uf028', '\uf029JXPjP', 'XPPiP'), ('\uf029JXPjP', 'XPPiP', 'JXPjP'), ('XPPiP', 'JXPjP', 'XPiP'), ('JXPjP', 'XPiP', 'XJP'), ('XPiP', 'XJP', 'XP'), ('XJP', 'XP', 'R'), ('XP', 'R', 'r'), ('R', 'r', 'r'), ('r', 'r', '|'), ('r', '|', '|'), ('|', '|', '|'), ('|', '|', '|'), ('|', '|', '|'), ('|', '|', '|'), ('|', '|', '\uf050'), ('|', '\uf050', '\uf050'), ('\uf050', '\uf050', '\uf03d\uf03d\uf03d'), ('\uf050', '\uf03d\uf03d\uf03d', '\uf069\uf069\uf069'), ('\uf03d\uf03d\uf03d', '\uf069\uf069\uf069', '('), ('\uf069\uf069\uf069', '(', '3'), ('(', '3', ')'), ('3', ')', 'Here'), (')', 'Here', 'comparing'), ('Here', 'comparing', 'two'), ('comparing', 'two', 'probabilities'), ('two', 'probabilities', ','), ('probabilities', ',', 'larger'), (',', 'larger', 'probability'), ('larger', 'probability', 'indicates'), ('probability', 'indicates', 'class'), ('indicates', 'class', 'label'), ('class', 'label', 'value'), ('label', 'value', 'likely'), ('value', 'likely', 'actual'), ('likely', 'actual', 'label'), ('actual', 'label', '('), ('label', '(', 'R'), ('(', 'R', '>'), ('R', '>', '1'), ('>', '1', ':'), ('1', ':', 'predict'), (':', 'predict', 'else'), ('predict', 'else', 'predict'), ('else', 'predict', 'j'), ('predict', 'j', ')'), ('j', ')', '['), (')', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('author', 'NN'), ('[', 'NN'), ('20', 'CD'), (']', 'JJ'), ('independence', 'NN'), ('model', 'NN'), ('(', '('), ('Naive', 'JJ'), ('Bayes', 'NNP'), (')', ')'), ('based', 'VBN'), ('estimating', 'NN'), (':', ':'), ('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029JXPjP', 'NNP'), ('XPPiP', 'NNP'), ('JXPjP', 'NNP'), ('XPiP', 'NNP'), ('XJP', 'NNP'), ('XP', 'NNP'), ('R', 'NNP'), ('r', 'NN'), ('r', 'NN'), ('|', 'NNP'), ('|', 'NNP'), ('|', 'NNP'), ('|', 'NNP'), ('|', 'NNP'), ('|', 'NNP'), ('\uf050', 'NNP'), ('\uf050', 'NNP'), ('\uf03d\uf03d\uf03d', 'NNP'), ('\uf069\uf069\uf069', 'NNP'), ('(', '('), ('3', 'CD'), (')', ')'), ('Here', 'RB'), ('comparing', 'VBG'), ('two', 'CD'), ('probabilities', 'NNS'), (',', ','), ('larger', 'JJR'), ('probability', 'NN'), ('indicates', 'VBZ'), ('class', 'NN'), ('label', 'NN'), ('value', 'NN'), ('likely', 'RB'), ('actual', 'JJ'), ('label', 'NN'), ('(', '('), ('R', 'NNP'), ('>', 'VBZ'), ('1', 'CD'), (':', ':'), ('predict', 'NN'), ('else', 'RB'), ('predict', 'VBP'), ('j', 'NN'), (')', ')'), ('[', 'VBZ'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  According/VBG
  (NP author/NN [/NN)
  20/CD
  (NP ]/JJ independence/NN model/NN)
  (/(
  (NP Naive/JJ Bayes/NNP)
  )/)
  based/VBN
  (NP estimating/NN)
  :/:
  (NP
    /JJ
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    JXPjP/NNP
    XPPiP/NNP
    JXPjP/NNP
    XPiP/NNP
    XJP/NNP
    XP/NNP
    R/NNP
    r/NN
    r/NN
    |/NNP
    |/NNP
    |/NNP
    |/NNP
    |/NNP
    |/NNP
    /NNP
    /NNP
    /NNP
    /NNP)
  (/(
  3/CD
  )/)
  Here/RB
  comparing/VBG
  two/CD
  (NP probabilities/NNS)
  ,/,
  larger/JJR
  (NP probability/NN)
  indicates/VBZ
  (NP class/NN label/NN value/NN)
  likely/RB
  (NP actual/JJ label/NN)
  (/(
  (NP R/NNP)
  >/VBZ
  1/CD
  :/:
  (NP predict/NN)
  else/RB
  predict/VBP
  (NP j/NN)
  )/)
  [/VBZ
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['author [', '] independence model', 'Naive Bayes', 'estimating', '\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029JXPjP XPPiP JXPjP XPiP XJP XP R r r | | | | | | \uf050 \uf050 \uf03d\uf03d\uf03d \uf069\uf069\uf069', 'probabilities', 'probability', 'class label value', 'actual label', 'R', 'predict', 'j', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Naive Bayes'), ('ORGANIZATION', 'R')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']'), ('independence', 'independ'), ('model', 'model'), ('(', '('), ('Naive', 'naiv'), ('Bayes', 'bay'), (')', ')'), ('based', 'base'), ('estimating', 'estim'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029jxpjp'), ('XPPiP', 'xppip'), ('JXPjP', 'jxpjp'), ('XPiP', 'xpip'), ('XJP', 'xjp'), ('XP', 'xp'), ('R', 'r'), ('r', 'r'), ('r', 'r'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('\uf050', '\uf050'), ('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d'), ('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')'), ('Here', 'here'), ('comparing', 'compar'), ('two', 'two'), ('probabilities', 'probabl'), (',', ','), ('larger', 'larger'), ('probability', 'probabl'), ('indicates', 'indic'), ('class', 'class'), ('label', 'label'), ('value', 'valu'), ('likely', 'like'), ('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'r'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'els'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']'), ('independence', 'independ'), ('model', 'model'), ('(', '('), ('Naive', 'naiv'), ('Bayes', 'bay'), (')', ')'), ('based', 'base'), ('estimating', 'estim'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029jxpjp'), ('XPPiP', 'xppip'), ('JXPjP', 'jxpjp'), ('XPiP', 'xpip'), ('XJP', 'xjp'), ('XP', 'xp'), ('R', 'r'), ('r', 'r'), ('r', 'r'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('\uf050', '\uf050'), ('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d'), ('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')'), ('Here', 'here'), ('comparing', 'compar'), ('two', 'two'), ('probabilities', 'probabl'), (',', ','), ('larger', 'larger'), ('probability', 'probabl'), ('indicates', 'indic'), ('class', 'class'), ('label', 'label'), ('value', 'valu'), ('likely', 'like'), ('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'r'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'els'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']'), ('independence', 'independence'), ('model', 'model'), ('(', '('), ('Naive', 'Naive'), ('Bayes', 'Bayes'), (')', ')'), ('based', 'based'), ('estimating', 'estimating'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029JXPjP'), ('XPPiP', 'XPPiP'), ('JXPjP', 'JXPjP'), ('XPiP', 'XPiP'), ('XJP', 'XJP'), ('XP', 'XP'), ('R', 'R'), ('r', 'r'), ('r', 'r'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('|', '|'), ('\uf050', '\uf050'), ('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d'), ('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')'), ('Here', 'Here'), ('comparing', 'comparing'), ('two', 'two'), ('probabilities', 'probability'), (',', ','), ('larger', 'larger'), ('probability', 'probability'), ('indicates', 'indicates'), ('class', 'class'), ('label', 'label'), ('value', 'value'), ('likely', 'likely'), ('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'R'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'else'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 135 =============================

As   shown in the below figure, the links in a Naive Bayes model are   directed from output to input, which gives the model its   simplicity, as there are no interactions between the inputs, except   indirectly via the output. 


>> Tokens are: 
 ['As', 'shown', 'figure', ',', 'links', 'Naive', 'Bayes', 'model', 'directed', 'output', 'input', ',', 'gives', 'model', 'simplicity', ',', 'interactions', 'inputs', ',', 'except', 'indirectly', 'via', 'output', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'figure'), ('figure', ','), (',', 'links'), ('links', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'model'), ('model', 'directed'), ('directed', 'output'), ('output', 'input'), ('input', ','), (',', 'gives'), ('gives', 'model'), ('model', 'simplicity'), ('simplicity', ','), (',', 'interactions'), ('interactions', 'inputs'), ('inputs', ','), (',', 'except'), ('except', 'indirectly'), ('indirectly', 'via'), ('via', 'output'), ('output', '.')]

>> Trigrams are: 
 [('As', 'shown', 'figure'), ('shown', 'figure', ','), ('figure', ',', 'links'), (',', 'links', 'Naive'), ('links', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'model'), ('Bayes', 'model', 'directed'), ('model', 'directed', 'output'), ('directed', 'output', 'input'), ('output', 'input', ','), ('input', ',', 'gives'), (',', 'gives', 'model'), ('gives', 'model', 'simplicity'), ('model', 'simplicity', ','), ('simplicity', ',', 'interactions'), (',', 'interactions', 'inputs'), ('interactions', 'inputs', ','), ('inputs', ',', 'except'), (',', 'except', 'indirectly'), ('except', 'indirectly', 'via'), ('indirectly', 'via', 'output'), ('via', 'output', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('figure', 'NN'), (',', ','), ('links', 'VBZ'), ('Naive', 'NNP'), ('Bayes', 'NNP'), ('model', 'NN'), ('directed', 'VBD'), ('output', 'NN'), ('input', 'NN'), (',', ','), ('gives', 'VBZ'), ('model', 'NN'), ('simplicity', 'NN'), (',', ','), ('interactions', 'NNS'), ('inputs', 'NNS'), (',', ','), ('except', 'IN'), ('indirectly', 'RB'), ('via', 'IN'), ('output', 'NN'), ('.', '.')]

 (S
  As/IN
  shown/VBN
  (NP figure/NN)
  ,/,
  links/VBZ
  (NP Naive/NNP Bayes/NNP model/NN)
  directed/VBD
  (NP output/NN input/NN)
  ,/,
  gives/VBZ
  (NP model/NN simplicity/NN)
  ,/,
  (NP interactions/NNS inputs/NNS)
  ,/,
  except/IN
  indirectly/RB
  via/IN
  (NP output/NN)
  ./.) 


>> Noun Phrases are: 
 ['figure', 'Naive Bayes model', 'output input', 'model simplicity', 'interactions inputs', 'output']

>> Named Entities are: 
 [('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('figure', 'figur'), (',', ','), ('links', 'link'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model'), ('directed', 'direct'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model'), ('simplicity', 'simplic'), (',', ','), ('interactions', 'interact'), ('inputs', 'input'), (',', ','), ('except', 'except'), ('indirectly', 'indirectli'), ('via', 'via'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('figure', 'figur'), (',', ','), ('links', 'link'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model'), ('directed', 'direct'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model'), ('simplicity', 'simplic'), (',', ','), ('interactions', 'interact'), ('inputs', 'input'), (',', ','), ('except', 'except'), ('indirectly', 'indirect'), ('via', 'via'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('figure', 'figure'), (',', ','), ('links', 'link'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('model', 'model'), ('directed', 'directed'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model'), ('simplicity', 'simplicity'), (',', ','), ('interactions', 'interaction'), ('inputs', 'input'), (',', ','), ('except', 'except'), ('indirectly', 'indirectly'), ('via', 'via'), ('output', 'output'), ('.', '.')]



============================ Sentence 136 =============================

Fig.6. 


>> Tokens are: 
 ['Fig.6', '.']

>> Bigrams are: 
 [('Fig.6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.6', 'NNP'), ('.', '.')]

 (S (NP Fig.6/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.6', 'fig.6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.6', 'fig.6'), ('.', '.')]

>> Lemmatization: 
 [('Fig.6', 'Fig.6'), ('.', '.')]



============================ Sentence 137 =============================

Naive Bayes model   An advantage of the Naive Bayes classifier is that it requires   a small amount of training data to estimate the parameters   necessary for classification. 


>> Tokens are: 
 ['Naive', 'Bayes', 'model', 'An', 'advantage', 'Naive', 'Bayes', 'classifier', 'requires', 'small', 'amount', 'training', 'data', 'estimate', 'parameters', 'necessary', 'classification', '.']

>> Bigrams are: 
 [('Naive', 'Bayes'), ('Bayes', 'model'), ('model', 'An'), ('An', 'advantage'), ('advantage', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'classifier'), ('classifier', 'requires'), ('requires', 'small'), ('small', 'amount'), ('amount', 'training'), ('training', 'data'), ('data', 'estimate'), ('estimate', 'parameters'), ('parameters', 'necessary'), ('necessary', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('Naive', 'Bayes', 'model'), ('Bayes', 'model', 'An'), ('model', 'An', 'advantage'), ('An', 'advantage', 'Naive'), ('advantage', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'classifier'), ('Bayes', 'classifier', 'requires'), ('classifier', 'requires', 'small'), ('requires', 'small', 'amount'), ('small', 'amount', 'training'), ('amount', 'training', 'data'), ('training', 'data', 'estimate'), ('data', 'estimate', 'parameters'), ('estimate', 'parameters', 'necessary'), ('parameters', 'necessary', 'classification'), ('necessary', 'classification', '.')]

>> POS Tags are: 
 [('Naive', 'JJ'), ('Bayes', 'NNP'), ('model', 'NN'), ('An', 'DT'), ('advantage', 'NN'), ('Naive', 'JJ'), ('Bayes', 'NNP'), ('classifier', 'NN'), ('requires', 'VBZ'), ('small', 'JJ'), ('amount', 'NN'), ('training', 'NN'), ('data', 'NNS'), ('estimate', 'NN'), ('parameters', 'NNS'), ('necessary', 'JJ'), ('classification', 'NN'), ('.', '.')]

 (S
  (NP Naive/JJ Bayes/NNP model/NN)
  (NP An/DT advantage/NN)
  (NP Naive/JJ Bayes/NNP classifier/NN)
  requires/VBZ
  (NP
    small/JJ
    amount/NN
    training/NN
    data/NNS
    estimate/NN
    parameters/NNS)
  (NP necessary/JJ classification/NN)
  ./.) 


>> Noun Phrases are: 
 ['Naive Bayes model', 'An advantage', 'Naive Bayes classifier', 'small amount training data estimate parameters', 'necessary classification']

>> Named Entities are: 
 [('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model'), ('An', 'an'), ('advantage', 'advantag'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifier', 'classifi'), ('requires', 'requir'), ('small', 'small'), ('amount', 'amount'), ('training', 'train'), ('data', 'data'), ('estimate', 'estim'), ('parameters', 'paramet'), ('necessary', 'necessari'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model'), ('An', 'an'), ('advantage', 'advantag'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifier', 'classifi'), ('requires', 'requir'), ('small', 'small'), ('amount', 'amount'), ('training', 'train'), ('data', 'data'), ('estimate', 'estim'), ('parameters', 'paramet'), ('necessary', 'necessari'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('Naive', 'Naive'), ('Bayes', 'Bayes'), ('model', 'model'), ('An', 'An'), ('advantage', 'advantage'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('classifier', 'classifier'), ('requires', 'requires'), ('small', 'small'), ('amount', 'amount'), ('training', 'training'), ('data', 'data'), ('estimate', 'estimate'), ('parameters', 'parameter'), ('necessary', 'necessary'), ('classification', 'classification'), ('.', '.')]



============================ Sentence 138 =============================

4.2 BAYESIAN NETWORKS   Bayesian Networks (BN) are graphical models that are used   to illustrate relationships between events or ideas to infer   probabilities or uncertainties associated with those ideas or   events. 


>> Tokens are: 
 ['4.2', 'BAYESIAN', 'NETWORKS', 'Bayesian', 'Networks', '(', 'BN', ')', 'graphical', 'models', 'used', 'illustrate', 'relationships', 'events', 'ideas', 'infer', 'probabilities', 'uncertainties', 'associated', 'ideas', 'events', '.']

>> Bigrams are: 
 [('4.2', 'BAYESIAN'), ('BAYESIAN', 'NETWORKS'), ('NETWORKS', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', '('), ('(', 'BN'), ('BN', ')'), (')', 'graphical'), ('graphical', 'models'), ('models', 'used'), ('used', 'illustrate'), ('illustrate', 'relationships'), ('relationships', 'events'), ('events', 'ideas'), ('ideas', 'infer'), ('infer', 'probabilities'), ('probabilities', 'uncertainties'), ('uncertainties', 'associated'), ('associated', 'ideas'), ('ideas', 'events'), ('events', '.')]

>> Trigrams are: 
 [('4.2', 'BAYESIAN', 'NETWORKS'), ('BAYESIAN', 'NETWORKS', 'Bayesian'), ('NETWORKS', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', '('), ('Networks', '(', 'BN'), ('(', 'BN', ')'), ('BN', ')', 'graphical'), (')', 'graphical', 'models'), ('graphical', 'models', 'used'), ('models', 'used', 'illustrate'), ('used', 'illustrate', 'relationships'), ('illustrate', 'relationships', 'events'), ('relationships', 'events', 'ideas'), ('events', 'ideas', 'infer'), ('ideas', 'infer', 'probabilities'), ('infer', 'probabilities', 'uncertainties'), ('probabilities', 'uncertainties', 'associated'), ('uncertainties', 'associated', 'ideas'), ('associated', 'ideas', 'events'), ('ideas', 'events', '.')]

>> POS Tags are: 
 [('4.2', 'CD'), ('BAYESIAN', 'NNP'), ('NETWORKS', 'NNP'), ('Bayesian', 'NNP'), ('Networks', 'NNP'), ('(', '('), ('BN', 'NNP'), (')', ')'), ('graphical', 'JJ'), ('models', 'NNS'), ('used', 'VBN'), ('illustrate', 'JJ'), ('relationships', 'NNS'), ('events', 'NNS'), ('ideas', 'NNS'), ('infer', 'VBP'), ('probabilities', 'NNS'), ('uncertainties', 'NNS'), ('associated', 'VBN'), ('ideas', 'JJ'), ('events', 'NNS'), ('.', '.')]

 (S
  4.2/CD
  (NP BAYESIAN/NNP NETWORKS/NNP Bayesian/NNP Networks/NNP)
  (/(
  (NP BN/NNP)
  )/)
  (NP graphical/JJ models/NNS)
  used/VBN
  (NP illustrate/JJ relationships/NNS events/NNS ideas/NNS)
  infer/VBP
  (NP probabilities/NNS uncertainties/NNS)
  associated/VBN
  (NP ideas/JJ events/NNS)
  ./.) 


>> Noun Phrases are: 
 ['BAYESIAN NETWORKS Bayesian Networks', 'BN', 'graphical models', 'illustrate relationships events ideas', 'probabilities uncertainties', 'ideas events']

>> Named Entities are: 
 [('ORGANIZATION', 'BAYESIAN'), ('ORGANIZATION', 'NETWORKS Bayesian Networks')] 

>> Stemming using Porter Stemmer: 
 [('4.2', '4.2'), ('BAYESIAN', 'bayesian'), ('NETWORKS', 'network'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('graphical', 'graphic'), ('models', 'model'), ('used', 'use'), ('illustrate', 'illustr'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer'), ('probabilities', 'probabl'), ('uncertainties', 'uncertainti'), ('associated', 'associ'), ('ideas', 'idea'), ('events', 'event'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4.2', '4.2'), ('BAYESIAN', 'bayesian'), ('NETWORKS', 'network'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('graphical', 'graphic'), ('models', 'model'), ('used', 'use'), ('illustrate', 'illustr'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer'), ('probabilities', 'probabl'), ('uncertainties', 'uncertainti'), ('associated', 'associ'), ('ideas', 'idea'), ('events', 'event'), ('.', '.')]

>> Lemmatization: 
 [('4.2', '4.2'), ('BAYESIAN', 'BAYESIAN'), ('NETWORKS', 'NETWORKS'), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('BN', 'BN'), (')', ')'), ('graphical', 'graphical'), ('models', 'model'), ('used', 'used'), ('illustrate', 'illustrate'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer'), ('probabilities', 'probability'), ('uncertainties', 'uncertainty'), ('associated', 'associated'), ('ideas', 'idea'), ('events', 'event'), ('.', '.')]



============================ Sentence 139 =============================

Information retrieval, predictions based on limited input   or recognition software is some main applications of BN. 


>> Tokens are: 
 ['Information', 'retrieval', ',', 'predictions', 'based', 'limited', 'input', 'recognition', 'software', 'main', 'applications', 'BN', '.']

>> Bigrams are: 
 [('Information', 'retrieval'), ('retrieval', ','), (',', 'predictions'), ('predictions', 'based'), ('based', 'limited'), ('limited', 'input'), ('input', 'recognition'), ('recognition', 'software'), ('software', 'main'), ('main', 'applications'), ('applications', 'BN'), ('BN', '.')]

>> Trigrams are: 
 [('Information', 'retrieval', ','), ('retrieval', ',', 'predictions'), (',', 'predictions', 'based'), ('predictions', 'based', 'limited'), ('based', 'limited', 'input'), ('limited', 'input', 'recognition'), ('input', 'recognition', 'software'), ('recognition', 'software', 'main'), ('software', 'main', 'applications'), ('main', 'applications', 'BN'), ('applications', 'BN', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('retrieval', 'NN'), (',', ','), ('predictions', 'NNS'), ('based', 'VBN'), ('limited', 'JJ'), ('input', 'NN'), ('recognition', 'NN'), ('software', 'NN'), ('main', 'JJ'), ('applications', 'NNS'), ('BN', 'NNP'), ('.', '.')]

 (S
  (NP Information/NN retrieval/NN)
  ,/,
  (NP predictions/NNS)
  based/VBN
  (NP limited/JJ input/NN recognition/NN software/NN)
  (NP main/JJ applications/NNS BN/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Information retrieval', 'predictions', 'limited input recognition software', 'main applications BN']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('predictions', 'predict'), ('based', 'base'), ('limited', 'limit'), ('input', 'input'), ('recognition', 'recognit'), ('software', 'softwar'), ('main', 'main'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('predictions', 'predict'), ('based', 'base'), ('limited', 'limit'), ('input', 'input'), ('recognition', 'recognit'), ('software', 'softwar'), ('main', 'main'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('retrieval', 'retrieval'), (',', ','), ('predictions', 'prediction'), ('based', 'based'), ('limited', 'limited'), ('input', 'input'), ('recognition', 'recognition'), ('software', 'software'), ('main', 'main'), ('applications', 'application'), ('BN', 'BN'), ('.', '.')]



============================ Sentence 140 =============================

The Bayesian network structure S is a directed acyclic graph   (DAG) and the nodes in S are in one-to-one correspondence with   the features X. 


>> Tokens are: 
 ['The', 'Bayesian', 'network', 'structure', 'S', 'directed', 'acyclic', 'graph', '(', 'DAG', ')', 'nodes', 'S', 'one-to-one', 'correspondence', 'features', 'X', '.']

>> Bigrams are: 
 [('The', 'Bayesian'), ('Bayesian', 'network'), ('network', 'structure'), ('structure', 'S'), ('S', 'directed'), ('directed', 'acyclic'), ('acyclic', 'graph'), ('graph', '('), ('(', 'DAG'), ('DAG', ')'), (')', 'nodes'), ('nodes', 'S'), ('S', 'one-to-one'), ('one-to-one', 'correspondence'), ('correspondence', 'features'), ('features', 'X'), ('X', '.')]

>> Trigrams are: 
 [('The', 'Bayesian', 'network'), ('Bayesian', 'network', 'structure'), ('network', 'structure', 'S'), ('structure', 'S', 'directed'), ('S', 'directed', 'acyclic'), ('directed', 'acyclic', 'graph'), ('acyclic', 'graph', '('), ('graph', '(', 'DAG'), ('(', 'DAG', ')'), ('DAG', ')', 'nodes'), (')', 'nodes', 'S'), ('nodes', 'S', 'one-to-one'), ('S', 'one-to-one', 'correspondence'), ('one-to-one', 'correspondence', 'features'), ('correspondence', 'features', 'X'), ('features', 'X', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Bayesian', 'JJ'), ('network', 'NN'), ('structure', 'NN'), ('S', 'NNP'), ('directed', 'VBD'), ('acyclic', 'JJ'), ('graph', 'NN'), ('(', '('), ('DAG', 'NNP'), (')', ')'), ('nodes', 'VBZ'), ('S', 'JJ'), ('one-to-one', 'JJ'), ('correspondence', 'NN'), ('features', 'NNS'), ('X', 'NNP'), ('.', '.')]

 (S
  (NP The/DT Bayesian/JJ network/NN structure/NN S/NNP)
  directed/VBD
  (NP acyclic/JJ graph/NN)
  (/(
  (NP DAG/NNP)
  )/)
  nodes/VBZ
  (NP S/JJ one-to-one/JJ correspondence/NN features/NNS X/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The Bayesian network structure S', 'acyclic graph', 'DAG', 'S one-to-one correspondence features X']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('ORGANIZATION', 'DAG')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Bayesian', 'bayesian'), ('network', 'network'), ('structure', 'structur'), ('S', 's'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graph', 'graph'), ('(', '('), ('DAG', 'dag'), (')', ')'), ('nodes', 'node'), ('S', 's'), ('one-to-one', 'one-to-on'), ('correspondence', 'correspond'), ('features', 'featur'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Bayesian', 'bayesian'), ('network', 'network'), ('structure', 'structur'), ('S', 's'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graph', 'graph'), ('(', '('), ('DAG', 'dag'), (')', ')'), ('nodes', 'node'), ('S', 's'), ('one-to-one', 'one-to-on'), ('correspondence', 'correspond'), ('features', 'featur'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Bayesian', 'Bayesian'), ('network', 'network'), ('structure', 'structure'), ('S', 'S'), ('directed', 'directed'), ('acyclic', 'acyclic'), ('graph', 'graph'), ('(', '('), ('DAG', 'DAG'), (')', ')'), ('nodes', 'node'), ('S', 'S'), ('one-to-one', 'one-to-one'), ('correspondence', 'correspondence'), ('features', 'feature'), ('X', 'X'), ('.', '.')]



============================ Sentence 141 =============================

The arcs represent casual influences among the   features while the lack of possible arcs in S encodes conditional   independencies. 


>> Tokens are: 
 ['The', 'arcs', 'represent', 'casual', 'influences', 'among', 'features', 'lack', 'possible', 'arcs', 'S', 'encodes', 'conditional', 'independencies', '.']

>> Bigrams are: 
 [('The', 'arcs'), ('arcs', 'represent'), ('represent', 'casual'), ('casual', 'influences'), ('influences', 'among'), ('among', 'features'), ('features', 'lack'), ('lack', 'possible'), ('possible', 'arcs'), ('arcs', 'S'), ('S', 'encodes'), ('encodes', 'conditional'), ('conditional', 'independencies'), ('independencies', '.')]

>> Trigrams are: 
 [('The', 'arcs', 'represent'), ('arcs', 'represent', 'casual'), ('represent', 'casual', 'influences'), ('casual', 'influences', 'among'), ('influences', 'among', 'features'), ('among', 'features', 'lack'), ('features', 'lack', 'possible'), ('lack', 'possible', 'arcs'), ('possible', 'arcs', 'S'), ('arcs', 'S', 'encodes'), ('S', 'encodes', 'conditional'), ('encodes', 'conditional', 'independencies'), ('conditional', 'independencies', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('arcs', 'JJ'), ('represent', 'NN'), ('casual', 'JJ'), ('influences', 'NNS'), ('among', 'IN'), ('features', 'NNS'), ('lack', 'VBP'), ('possible', 'JJ'), ('arcs', 'NN'), ('S', 'NNP'), ('encodes', 'VBZ'), ('conditional', 'JJ'), ('independencies', 'NNS'), ('.', '.')]

 (S
  (NP The/DT arcs/JJ represent/NN)
  (NP casual/JJ influences/NNS)
  among/IN
  (NP features/NNS)
  lack/VBP
  (NP possible/JJ arcs/NN S/NNP)
  encodes/VBZ
  (NP conditional/JJ independencies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The arcs represent', 'casual influences', 'features', 'possible arcs S', 'conditional independencies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('arcs', 'arc'), ('represent', 'repres'), ('casual', 'casual'), ('influences', 'influenc'), ('among', 'among'), ('features', 'featur'), ('lack', 'lack'), ('possible', 'possibl'), ('arcs', 'arc'), ('S', 's'), ('encodes', 'encod'), ('conditional', 'condit'), ('independencies', 'independ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('arcs', 'arc'), ('represent', 'repres'), ('casual', 'casual'), ('influences', 'influenc'), ('among', 'among'), ('features', 'featur'), ('lack', 'lack'), ('possible', 'possibl'), ('arcs', 'arc'), ('S', 's'), ('encodes', 'encod'), ('conditional', 'condit'), ('independencies', 'independ'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('arcs', 'arc'), ('represent', 'represent'), ('casual', 'casual'), ('influences', 'influence'), ('among', 'among'), ('features', 'feature'), ('lack', 'lack'), ('possible', 'possible'), ('arcs', 'arc'), ('S', 'S'), ('encodes', 'encodes'), ('conditional', 'conditional'), ('independencies', 'independency'), ('.', '.')]



============================ Sentence 142 =============================

Moreover, a feature (node) is conditionally   independent from its non-descendants given its parents (X1 is   conditionally independent from X2). 


>> Tokens are: 
 ['Moreover', ',', 'feature', '(', 'node', ')', 'conditionally', 'independent', 'non-descendants', 'given', 'parents', '(', 'X1', 'conditionally', 'independent', 'X2', ')', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'feature'), ('feature', '('), ('(', 'node'), ('node', ')'), (')', 'conditionally'), ('conditionally', 'independent'), ('independent', 'non-descendants'), ('non-descendants', 'given'), ('given', 'parents'), ('parents', '('), ('(', 'X1'), ('X1', 'conditionally'), ('conditionally', 'independent'), ('independent', 'X2'), ('X2', ')'), (')', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'feature'), (',', 'feature', '('), ('feature', '(', 'node'), ('(', 'node', ')'), ('node', ')', 'conditionally'), (')', 'conditionally', 'independent'), ('conditionally', 'independent', 'non-descendants'), ('independent', 'non-descendants', 'given'), ('non-descendants', 'given', 'parents'), ('given', 'parents', '('), ('parents', '(', 'X1'), ('(', 'X1', 'conditionally'), ('X1', 'conditionally', 'independent'), ('conditionally', 'independent', 'X2'), ('independent', 'X2', ')'), ('X2', ')', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('feature', 'NN'), ('(', '('), ('node', 'NN'), (')', ')'), ('conditionally', 'RB'), ('independent', 'JJ'), ('non-descendants', 'NNS'), ('given', 'VBN'), ('parents', 'NNS'), ('(', '('), ('X1', 'NNP'), ('conditionally', 'RB'), ('independent', 'JJ'), ('X2', 'NN'), (')', ')'), ('.', '.')]

 (S
  Moreover/RB
  ,/,
  (NP feature/NN)
  (/(
  (NP node/NN)
  )/)
  conditionally/RB
  (NP independent/JJ non-descendants/NNS)
  given/VBN
  (NP parents/NNS)
  (/(
  (NP X1/NNP)
  conditionally/RB
  (NP independent/JJ X2/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['feature', 'node', 'independent non-descendants', 'parents', 'X1', 'independent X2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('feature', 'featur'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'condit'), ('independent', 'independ'), ('non-descendants', 'non-descend'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'x1'), ('conditionally', 'condit'), ('independent', 'independ'), ('X2', 'x2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('feature', 'featur'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'condit'), ('independent', 'independ'), ('non-descendants', 'non-descend'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'x1'), ('conditionally', 'condit'), ('independent', 'independ'), ('X2', 'x2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('feature', 'feature'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'conditionally'), ('independent', 'independent'), ('non-descendants', 'non-descendants'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'X1'), ('conditionally', 'conditionally'), ('independent', 'independent'), ('X2', 'X2'), (')', ')'), ('.', '.')]



============================ Sentence 143 =============================

The below example shows that there are two events which   could cause grass to be wet i.e.- either the sprinkler is on or its   raining. 


>> Tokens are: 
 ['The', 'example', 'shows', 'two', 'events', 'could', 'cause', 'grass', 'wet', 'i.e.-', 'either', 'sprinkler', '', 'raining', '.']

>> Bigrams are: 
 [('The', 'example'), ('example', 'shows'), ('shows', 'two'), ('two', 'events'), ('events', 'could'), ('could', 'cause'), ('cause', 'grass'), ('grass', 'wet'), ('wet', 'i.e.-'), ('i.e.-', 'either'), ('either', 'sprinkler'), ('sprinkler', ''), ('', 'raining'), ('raining', '.')]

>> Trigrams are: 
 [('The', 'example', 'shows'), ('example', 'shows', 'two'), ('shows', 'two', 'events'), ('two', 'events', 'could'), ('events', 'could', 'cause'), ('could', 'cause', 'grass'), ('cause', 'grass', 'wet'), ('grass', 'wet', 'i.e.-'), ('wet', 'i.e.-', 'either'), ('i.e.-', 'either', 'sprinkler'), ('either', 'sprinkler', ''), ('sprinkler', '', 'raining'), ('', 'raining', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('example', 'NN'), ('shows', 'VBZ'), ('two', 'CD'), ('events', 'NNS'), ('could', 'MD'), ('cause', 'VB'), ('grass', 'NN'), ('wet', 'IN'), ('i.e.-', 'JJ'), ('either', 'DT'), ('sprinkler', 'NN'), ('', 'NN'), ('raining', 'NN'), ('.', '.')]

 (S
  (NP The/DT example/NN)
  shows/VBZ
  two/CD
  (NP events/NNS)
  could/MD
  cause/VB
  (NP grass/NN)
  wet/IN
  i.e.-/JJ
  (NP either/DT sprinkler/NN /NN raining/NN)
  ./.) 


>> Noun Phrases are: 
 ['The example', 'events', 'grass', 'either sprinkler  raining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('example', 'exampl'), ('shows', 'show'), ('two', 'two'), ('events', 'event'), ('could', 'could'), ('cause', 'caus'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', ''), ('raining', 'rain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('example', 'exampl'), ('shows', 'show'), ('two', 'two'), ('events', 'event'), ('could', 'could'), ('cause', 'caus'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', ''), ('raining', 'rain'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('example', 'example'), ('shows', 'show'), ('two', 'two'), ('events', 'event'), ('could', 'could'), ('cause', 'cause'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', ''), ('raining', 'raining'), ('.', '.')]



============================ Sentence 144 =============================

Additionally here we also, suppose that the rain has a   direct effect on the use of the sprinkler (namely that when it   rains, the sprinkler is usually not turned on). 


>> Tokens are: 
 ['Additionally', 'also', ',', 'suppose', 'rain', 'direct', 'effect', 'use', 'sprinkler', '(', 'namely', 'rains', ',', 'sprinkler', 'usually', 'turned', ')', '.']

>> Bigrams are: 
 [('Additionally', 'also'), ('also', ','), (',', 'suppose'), ('suppose', 'rain'), ('rain', 'direct'), ('direct', 'effect'), ('effect', 'use'), ('use', 'sprinkler'), ('sprinkler', '('), ('(', 'namely'), ('namely', 'rains'), ('rains', ','), (',', 'sprinkler'), ('sprinkler', 'usually'), ('usually', 'turned'), ('turned', ')'), (')', '.')]

>> Trigrams are: 
 [('Additionally', 'also', ','), ('also', ',', 'suppose'), (',', 'suppose', 'rain'), ('suppose', 'rain', 'direct'), ('rain', 'direct', 'effect'), ('direct', 'effect', 'use'), ('effect', 'use', 'sprinkler'), ('use', 'sprinkler', '('), ('sprinkler', '(', 'namely'), ('(', 'namely', 'rains'), ('namely', 'rains', ','), ('rains', ',', 'sprinkler'), (',', 'sprinkler', 'usually'), ('sprinkler', 'usually', 'turned'), ('usually', 'turned', ')'), ('turned', ')', '.')]

>> POS Tags are: 
 [('Additionally', 'RB'), ('also', 'RB'), (',', ','), ('suppose', 'JJ'), ('rain', 'NN'), ('direct', 'JJ'), ('effect', 'NN'), ('use', 'NN'), ('sprinkler', 'NN'), ('(', '('), ('namely', 'RB'), ('rains', 'VBZ'), (',', ','), ('sprinkler', 'NN'), ('usually', 'RB'), ('turned', 'VBN'), (')', ')'), ('.', '.')]

 (S
  Additionally/RB
  also/RB
  ,/,
  (NP suppose/JJ rain/NN)
  (NP direct/JJ effect/NN use/NN sprinkler/NN)
  (/(
  namely/RB
  rains/VBZ
  ,/,
  (NP sprinkler/NN)
  usually/RB
  turned/VBN
  )/)
  ./.) 


>> Noun Phrases are: 
 ['suppose rain', 'direct effect use sprinkler', 'sprinkler']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Additionally', 'addit'), ('also', 'also'), (',', ','), ('suppose', 'suppos'), ('rain', 'rain'), ('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'name'), ('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usual'), ('turned', 'turn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Additionally', 'addit'), ('also', 'also'), (',', ','), ('suppose', 'suppos'), ('rain', 'rain'), ('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'name'), ('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usual'), ('turned', 'turn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Additionally', 'Additionally'), ('also', 'also'), (',', ','), ('suppose', 'suppose'), ('rain', 'rain'), ('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'namely'), ('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usually'), ('turned', 'turned'), (')', ')'), ('.', '.')]



============================ Sentence 145 =============================

Then the situation   can be modeled with a Bayesian network. 


>> Tokens are: 
 ['Then', 'situation', 'modeled', 'Bayesian', 'network', '.']

>> Bigrams are: 
 [('Then', 'situation'), ('situation', 'modeled'), ('modeled', 'Bayesian'), ('Bayesian', 'network'), ('network', '.')]

>> Trigrams are: 
 [('Then', 'situation', 'modeled'), ('situation', 'modeled', 'Bayesian'), ('modeled', 'Bayesian', 'network'), ('Bayesian', 'network', '.')]

>> POS Tags are: 
 [('Then', 'RB'), ('situation', 'NN'), ('modeled', 'VBD'), ('Bayesian', 'JJ'), ('network', 'NN'), ('.', '.')]

 (S
  Then/RB
  (NP situation/NN)
  modeled/VBD
  (NP Bayesian/JJ network/NN)
  ./.) 


>> Noun Phrases are: 
 ['situation', 'Bayesian network']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), ('situation', 'situat'), ('modeled', 'model'), ('Bayesian', 'bayesian'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), ('situation', 'situat'), ('modeled', 'model'), ('Bayesian', 'bayesian'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Then', 'Then'), ('situation', 'situation'), ('modeled', 'modeled'), ('Bayesian', 'Bayesian'), ('network', 'network'), ('.', '.')]



============================ Sentence 146 =============================

All three variables   have two possible values, T (for true) and F (for false) [22]. 


>> Tokens are: 
 ['All', 'three', 'variables', 'two', 'possible', 'values', ',', 'T', '(', 'true', ')', 'F', '(', 'false', ')', '[', '22', ']', '.']

>> Bigrams are: 
 [('All', 'three'), ('three', 'variables'), ('variables', 'two'), ('two', 'possible'), ('possible', 'values'), ('values', ','), (',', 'T'), ('T', '('), ('(', 'true'), ('true', ')'), (')', 'F'), ('F', '('), ('(', 'false'), ('false', ')'), (')', '['), ('[', '22'), ('22', ']'), (']', '.')]

>> Trigrams are: 
 [('All', 'three', 'variables'), ('three', 'variables', 'two'), ('variables', 'two', 'possible'), ('two', 'possible', 'values'), ('possible', 'values', ','), ('values', ',', 'T'), (',', 'T', '('), ('T', '(', 'true'), ('(', 'true', ')'), ('true', ')', 'F'), (')', 'F', '('), ('F', '(', 'false'), ('(', 'false', ')'), ('false', ')', '['), (')', '[', '22'), ('[', '22', ']'), ('22', ']', '.')]

>> POS Tags are: 
 [('All', 'DT'), ('three', 'CD'), ('variables', 'NNS'), ('two', 'CD'), ('possible', 'JJ'), ('values', 'NNS'), (',', ','), ('T', 'NNP'), ('(', '('), ('true', 'JJ'), (')', ')'), ('F', 'NNP'), ('(', '('), ('false', 'JJ'), (')', ')'), ('[', 'VBP'), ('22', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  All/DT
  three/CD
  (NP variables/NNS)
  two/CD
  (NP possible/JJ values/NNS)
  ,/,
  (NP T/NNP)
  (/(
  true/JJ
  )/)
  (NP F/NNP)
  (/(
  false/JJ
  )/)
  [/VBP
  22/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['variables', 'possible values', 'T', 'F', ']']

>> Named Entities are: 
 [('GPE', 'T')] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('three', 'three'), ('variables', 'variabl'), ('two', 'two'), ('possible', 'possibl'), ('values', 'valu'), (',', ','), ('T', 't'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'f'), ('(', '('), ('false', 'fals'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('three', 'three'), ('variables', 'variabl'), ('two', 'two'), ('possible', 'possibl'), ('values', 'valu'), (',', ','), ('T', 't'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'f'), ('(', '('), ('false', 'fals'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('All', 'All'), ('three', 'three'), ('variables', 'variable'), ('two', 'two'), ('possible', 'possible'), ('values', 'value'), (',', ','), ('T', 'T'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'F'), ('(', '('), ('false', 'false'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]



============================ Sentence 147 =============================

Fig.7. 


>> Tokens are: 
 ['Fig.7', '.']

>> Bigrams are: 
 [('Fig.7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.7', 'NNP'), ('.', '.')]

 (S (NP Fig.7/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.7']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.7', 'fig.7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.7', 'fig.7'), ('.', '.')]

>> Lemmatization: 
 [('Fig.7', 'Fig.7'), ('.', '.')]



============================ Sentence 148 =============================

Bayesian network with conditional probability tables   The below is a joint probability function:           RPRSPRSGPRSGP ,,,   (4)  where, the names of the variables have been abbreviated to:   G = Grass wet (yes/no)   S = Sprinkler turned on (yes/no)   R = Raining (yes/no). 


>> Tokens are: 
 ['Bayesian', 'network', 'conditional', 'probability', 'tables', 'The', 'joint', 'probability', 'function', ':', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029RPRSPRSGPRSGP', ',', ',', ',', '\uf03d', '(', '4', ')', ',', 'names', 'variables', 'abbreviated', ':', 'G', '=', 'Grass', 'wet', '(', 'yes/no', ')', 'S', '=', 'Sprinkler', 'turned', '(', 'yes/no', ')', 'R', '=', 'Raining', '(', 'yes/no', ')', '.']

>> Bigrams are: 
 [('Bayesian', 'network'), ('network', 'conditional'), ('conditional', 'probability'), ('probability', 'tables'), ('tables', 'The'), ('The', 'joint'), ('joint', 'probability'), ('probability', 'function'), ('function', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029RPRSPRSGPRSGP'), ('\uf029RPRSPRSGPRSGP', ','), (',', ','), (',', ','), (',', '\uf03d'), ('\uf03d', '('), ('(', '4'), ('4', ')'), (')', ','), (',', 'names'), ('names', 'variables'), ('variables', 'abbreviated'), ('abbreviated', ':'), (':', 'G'), ('G', '='), ('=', 'Grass'), ('Grass', 'wet'), ('wet', '('), ('(', 'yes/no'), ('yes/no', ')'), (')', 'S'), ('S', '='), ('=', 'Sprinkler'), ('Sprinkler', 'turned'), ('turned', '('), ('(', 'yes/no'), ('yes/no', ')'), (')', 'R'), ('R', '='), ('=', 'Raining'), ('Raining', '('), ('(', 'yes/no'), ('yes/no', ')'), (')', '.')]

>> Trigrams are: 
 [('Bayesian', 'network', 'conditional'), ('network', 'conditional', 'probability'), ('conditional', 'probability', 'tables'), ('probability', 'tables', 'The'), ('tables', 'The', 'joint'), ('The', 'joint', 'probability'), ('joint', 'probability', 'function'), ('probability', 'function', ':'), ('function', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029RPRSPRSGPRSGP'), ('\uf028', '\uf029RPRSPRSGPRSGP', ','), ('\uf029RPRSPRSGPRSGP', ',', ','), (',', ',', ','), (',', ',', '\uf03d'), (',', '\uf03d', '('), ('\uf03d', '(', '4'), ('(', '4', ')'), ('4', ')', ','), (')', ',', 'names'), (',', 'names', 'variables'), ('names', 'variables', 'abbreviated'), ('variables', 'abbreviated', ':'), ('abbreviated', ':', 'G'), (':', 'G', '='), ('G', '=', 'Grass'), ('=', 'Grass', 'wet'), ('Grass', 'wet', '('), ('wet', '(', 'yes/no'), ('(', 'yes/no', ')'), ('yes/no', ')', 'S'), (')', 'S', '='), ('S', '=', 'Sprinkler'), ('=', 'Sprinkler', 'turned'), ('Sprinkler', 'turned', '('), ('turned', '(', 'yes/no'), ('(', 'yes/no', ')'), ('yes/no', ')', 'R'), (')', 'R', '='), ('R', '=', 'Raining'), ('=', 'Raining', '('), ('Raining', '(', 'yes/no'), ('(', 'yes/no', ')'), ('yes/no', ')', '.')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('network', 'NN'), ('conditional', 'JJ'), ('probability', 'NN'), ('tables', 'VBZ'), ('The', 'DT'), ('joint', 'JJ'), ('probability', 'NN'), ('function', 'NN'), (':', ':'), ('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029RPRSPRSGPRSGP', 'NNP'), (',', ','), (',', ','), (',', ','), ('\uf03d', 'NNP'), ('(', '('), ('4', 'CD'), (')', ')'), (',', ','), ('names', 'JJ'), ('variables', 'NNS'), ('abbreviated', 'VBN'), (':', ':'), ('G', 'NNP'), ('=', 'NNP'), ('Grass', 'NNP'), ('wet', 'NN'), ('(', '('), ('yes/no', 'NN'), (')', ')'), ('S', 'NNP'), ('=', 'NNP'), ('Sprinkler', 'NNP'), ('turned', 'VBD'), ('(', '('), ('yes/no', 'NN'), (')', ')'), ('R', 'NNP'), ('=', 'NNP'), ('Raining', 'NNP'), ('(', '('), ('yes/no', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Bayesian/JJ network/NN)
  (NP conditional/JJ probability/NN)
  tables/VBZ
  (NP The/DT joint/JJ probability/NN function/NN)
  :/:
  (NP /JJ /NNP /NNP /NNP /NNP /NNP /NNP RPRSPRSGPRSGP/NNP)
  ,/,
  ,/,
  ,/,
  (NP /NNP)
  (/(
  4/CD
  )/)
  ,/,
  (NP names/JJ variables/NNS)
  abbreviated/VBN
  :/:
  (NP G/NNP =/NNP Grass/NNP wet/NN)
  (/(
  (NP yes/no/NN)
  )/)
  (NP S/NNP =/NNP Sprinkler/NNP)
  turned/VBD
  (/(
  (NP yes/no/NN)
  )/)
  (NP R/NNP =/NNP Raining/NNP)
  (/(
  (NP yes/no/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Bayesian network', 'conditional probability', 'The joint probability function', '\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029RPRSPRSGPRSGP', '\uf03d', 'names variables', 'G = Grass wet', 'yes/no', 'S = Sprinkler', 'yes/no', 'R = Raining', 'yes/no']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('PERSON', 'Sprinkler')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('network', 'network'), ('conditional', 'condit'), ('probability', 'probabl'), ('tables', 'tabl'), ('The', 'the'), ('joint', 'joint'), ('probability', 'probabl'), ('function', 'function'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029rprsprsgprsgp'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variabl'), ('abbreviated', 'abbrevi'), (':', ':'), ('G', 'g'), ('=', '='), ('Grass', 'grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('S', 's'), ('=', '='), ('Sprinkler', 'sprinkler'), ('turned', 'turn'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('R', 'r'), ('=', '='), ('Raining', 'rain'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('network', 'network'), ('conditional', 'condit'), ('probability', 'probabl'), ('tables', 'tabl'), ('The', 'the'), ('joint', 'joint'), ('probability', 'probabl'), ('function', 'function'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029rprsprsgprsgp'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variabl'), ('abbreviated', 'abbrevi'), (':', ':'), ('G', 'g'), ('=', '='), ('Grass', 'grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('S', 's'), ('=', '='), ('Sprinkler', 'sprinkler'), ('turned', 'turn'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('R', 'r'), ('=', '='), ('Raining', 'rain'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('network', 'network'), ('conditional', 'conditional'), ('probability', 'probability'), ('tables', 'table'), ('The', 'The'), ('joint', 'joint'), ('probability', 'probability'), ('function', 'function'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029RPRSPRSGPRSGP'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variable'), ('abbreviated', 'abbreviated'), (':', ':'), ('G', 'G'), ('=', '='), ('Grass', 'Grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('S', 'S'), ('=', '='), ('Sprinkler', 'Sprinkler'), ('turned', 'turned'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('R', 'R'), ('=', '='), ('Raining', 'Raining'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]



============================ Sentence 149 =============================

Cheng et al. 


>> Tokens are: 
 ['Cheng', 'et', 'al', '.']

>> Bigrams are: 
 [('Cheng', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Cheng', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Cheng', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Cheng/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Cheng', 'al']

>> Named Entities are: 
 [('GPE', 'Cheng')] 

>> Stemming using Porter Stemmer: 
 [('Cheng', 'cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheng', 'cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Cheng', 'Cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 150 =============================

draw the attention of a problem of BN classifiers   that it is not suitable for datasets with many features. 


>> Tokens are: 
 ['draw', 'attention', 'problem', 'BN', 'classifiers', 'suitable', 'datasets', 'many', 'features', '.']

>> Bigrams are: 
 [('draw', 'attention'), ('attention', 'problem'), ('problem', 'BN'), ('BN', 'classifiers'), ('classifiers', 'suitable'), ('suitable', 'datasets'), ('datasets', 'many'), ('many', 'features'), ('features', '.')]

>> Trigrams are: 
 [('draw', 'attention', 'problem'), ('attention', 'problem', 'BN'), ('problem', 'BN', 'classifiers'), ('BN', 'classifiers', 'suitable'), ('classifiers', 'suitable', 'datasets'), ('suitable', 'datasets', 'many'), ('datasets', 'many', 'features'), ('many', 'features', '.')]

>> POS Tags are: 
 [('draw', 'JJ'), ('attention', 'NN'), ('problem', 'NN'), ('BN', 'NNP'), ('classifiers', 'NNS'), ('suitable', 'JJ'), ('datasets', 'NNS'), ('many', 'JJ'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP draw/JJ attention/NN problem/NN BN/NNP classifiers/NNS)
  (NP suitable/JJ datasets/NNS)
  (NP many/JJ features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['draw attention problem BN classifiers', 'suitable datasets', 'many features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('draw', 'draw'), ('attention', 'attent'), ('problem', 'problem'), ('BN', 'bn'), ('classifiers', 'classifi'), ('suitable', 'suitabl'), ('datasets', 'dataset'), ('many', 'mani'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('draw', 'draw'), ('attention', 'attent'), ('problem', 'problem'), ('BN', 'bn'), ('classifiers', 'classifi'), ('suitable', 'suitabl'), ('datasets', 'dataset'), ('many', 'mani'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('draw', 'draw'), ('attention', 'attention'), ('problem', 'problem'), ('BN', 'BN'), ('classifiers', 'classifier'), ('suitable', 'suitable'), ('datasets', 'datasets'), ('many', 'many'), ('features', 'feature'), ('.', '.')]



============================ Sentence 151 =============================

The reason   for this is that trying to construct a very large network is simply   not feasible in terms of time and space [23]. 


>> Tokens are: 
 ['The', 'reason', 'trying', 'construct', 'large', 'network', 'simply', 'feasible', 'terms', 'time', 'space', '[', '23', ']', '.']

>> Bigrams are: 
 [('The', 'reason'), ('reason', 'trying'), ('trying', 'construct'), ('construct', 'large'), ('large', 'network'), ('network', 'simply'), ('simply', 'feasible'), ('feasible', 'terms'), ('terms', 'time'), ('time', 'space'), ('space', '['), ('[', '23'), ('23', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'reason', 'trying'), ('reason', 'trying', 'construct'), ('trying', 'construct', 'large'), ('construct', 'large', 'network'), ('large', 'network', 'simply'), ('network', 'simply', 'feasible'), ('simply', 'feasible', 'terms'), ('feasible', 'terms', 'time'), ('terms', 'time', 'space'), ('time', 'space', '['), ('space', '[', '23'), ('[', '23', ']'), ('23', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('reason', 'NN'), ('trying', 'VBG'), ('construct', 'NN'), ('large', 'JJ'), ('network', 'NN'), ('simply', 'RB'), ('feasible', 'JJ'), ('terms', 'NNS'), ('time', 'NN'), ('space', 'NN'), ('[', 'NNP'), ('23', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP The/DT reason/NN)
  trying/VBG
  (NP construct/NN)
  (NP large/JJ network/NN)
  simply/RB
  (NP feasible/JJ terms/NNS time/NN space/NN [/NNP)
  23/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['The reason', 'construct', 'large network', 'feasible terms time space [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reason', 'reason'), ('trying', 'tri'), ('construct', 'construct'), ('large', 'larg'), ('network', 'network'), ('simply', 'simpli'), ('feasible', 'feasibl'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reason', 'reason'), ('trying', 'tri'), ('construct', 'construct'), ('large', 'larg'), ('network', 'network'), ('simply', 'simpli'), ('feasible', 'feasibl'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('reason', 'reason'), ('trying', 'trying'), ('construct', 'construct'), ('large', 'large'), ('network', 'network'), ('simply', 'simply'), ('feasible', 'feasible'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]



============================ Sentence 152 =============================

The pseudo code of   training BN is shown in below figure:   Input 1   Input 2   Input 3   Input 4   Output 1     IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY   950      Fig.8. 


>> Tokens are: 
 ['The', 'pseudo', 'code', 'training', 'BN', 'shown', 'figure', ':', 'Input', '1', 'Input', '2', 'Input', '3', 'Input', '4', 'Output', '1', 'IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY', '950', 'Fig.8', '.']

>> Bigrams are: 
 [('The', 'pseudo'), ('pseudo', 'code'), ('code', 'training'), ('training', 'BN'), ('BN', 'shown'), ('shown', 'figure'), ('figure', ':'), (':', 'Input'), ('Input', '1'), ('1', 'Input'), ('Input', '2'), ('2', 'Input'), ('Input', '3'), ('3', 'Input'), ('Input', '4'), ('4', 'Output'), ('Output', '1'), ('1', 'IQBAL'), ('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY'), ('SURVEY', '950'), ('950', 'Fig.8'), ('Fig.8', '.')]

>> Trigrams are: 
 [('The', 'pseudo', 'code'), ('pseudo', 'code', 'training'), ('code', 'training', 'BN'), ('training', 'BN', 'shown'), ('BN', 'shown', 'figure'), ('shown', 'figure', ':'), ('figure', ':', 'Input'), (':', 'Input', '1'), ('Input', '1', 'Input'), ('1', 'Input', '2'), ('Input', '2', 'Input'), ('2', 'Input', '3'), ('Input', '3', 'Input'), ('3', 'Input', '4'), ('Input', '4', 'Output'), ('4', 'Output', '1'), ('Output', '1', 'IQBAL'), ('1', 'IQBAL', 'MUHAMMAD'), ('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY'), ('A', 'SURVEY', '950'), ('SURVEY', '950', 'Fig.8'), ('950', 'Fig.8', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('pseudo', 'NN'), ('code', 'NN'), ('training', 'NN'), ('BN', 'NNP'), ('shown', 'VBN'), ('figure', 'NN'), (':', ':'), ('Input', 'NN'), ('1', 'CD'), ('Input', 'NNP'), ('2', 'CD'), ('Input', 'NNP'), ('3', 'CD'), ('Input', 'NNP'), ('4', 'CD'), ('Output', 'NNP'), ('1', 'CD'), ('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NNP'), ('950', 'CD'), ('Fig.8', 'NNP'), ('.', '.')]

 (S
  (NP The/DT pseudo/NN code/NN training/NN BN/NNP)
  shown/VBN
  (NP figure/NN)
  :/:
  (NP Input/NN)
  1/CD
  (NP Input/NNP)
  2/CD
  (NP Input/NNP)
  3/CD
  (NP Input/NNP)
  4/CD
  (NP Output/NNP)
  1/CD
  (NP IQBAL/NNP MUHAMMAD/NNP AND/NNP ZHU/NNP YAN/NNP)
  :/:
  (NP SUPERVISED/NNP MACHINE/NNP LEARNING/NNP APPROACHES/NNP)
  :/:
  (NP A/DT SURVEY/NNP)
  950/CD
  (NP Fig.8/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The pseudo code training BN', 'figure', 'Input', 'Input', 'Input', 'Input', 'Output', 'IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY', 'Fig.8']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('training', 'train'), ('BN', 'bn'), ('shown', 'shown'), ('figure', 'figur'), (':', ':'), ('Input', 'input'), ('1', '1'), ('Input', 'input'), ('2', '2'), ('Input', 'input'), ('3', '3'), ('Input', 'input'), ('4', '4'), ('Output', 'output'), ('1', '1'), ('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('950', '950'), ('Fig.8', 'fig.8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('training', 'train'), ('BN', 'bn'), ('shown', 'shown'), ('figure', 'figur'), (':', ':'), ('Input', 'input'), ('1', '1'), ('Input', 'input'), ('2', '2'), ('Input', 'input'), ('3', '3'), ('Input', 'input'), ('4', '4'), ('Output', 'output'), ('1', '1'), ('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('950', '950'), ('Fig.8', 'fig.8'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('pseudo', 'pseudo'), ('code', 'code'), ('training', 'training'), ('BN', 'BN'), ('shown', 'shown'), ('figure', 'figure'), (':', ':'), ('Input', 'Input'), ('1', '1'), ('Input', 'Input'), ('2', '2'), ('Input', 'Input'), ('3', '3'), ('Input', 'Input'), ('4', '4'), ('Output', 'Output'), ('1', '1'), ('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY'), ('950', '950'), ('Fig.8', 'Fig.8'), ('.', '.')]



============================ Sentence 153 =============================

Pseudo-code for training of BN   5. 


>> Tokens are: 
 ['Pseudo-code', 'training', 'BN', '5', '.']

>> Bigrams are: 
 [('Pseudo-code', 'training'), ('training', 'BN'), ('BN', '5'), ('5', '.')]

>> Trigrams are: 
 [('Pseudo-code', 'training', 'BN'), ('training', 'BN', '5'), ('BN', '5', '.')]

>> POS Tags are: 
 [('Pseudo-code', 'JJ'), ('training', 'NN'), ('BN', 'NNP'), ('5', 'CD'), ('.', '.')]

 (S (NP Pseudo-code/JJ training/NN BN/NNP) 5/CD ./.) 


>> Noun Phrases are: 
 ['Pseudo-code training BN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('training', 'train'), ('BN', 'bn'), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('training', 'train'), ('BN', 'bn'), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('Pseudo-code', 'Pseudo-code'), ('training', 'training'), ('BN', 'BN'), ('5', '5'), ('.', '.')]



============================ Sentence 154 =============================

INSTANCE-BASED LEARNING   About this learning scheme, the author [24] describes it as   lazy-learning algorithms, as they delay the induction or   generalization process until classification is performed. 


>> Tokens are: 
 ['INSTANCE-BASED', 'LEARNING', 'About', 'learning', 'scheme', ',', 'author', '[', '24', ']', 'describes', 'lazy-learning', 'algorithms', ',', 'delay', 'induction', 'generalization', 'process', 'classification', 'performed', '.']

>> Bigrams are: 
 [('INSTANCE-BASED', 'LEARNING'), ('LEARNING', 'About'), ('About', 'learning'), ('learning', 'scheme'), ('scheme', ','), (',', 'author'), ('author', '['), ('[', '24'), ('24', ']'), (']', 'describes'), ('describes', 'lazy-learning'), ('lazy-learning', 'algorithms'), ('algorithms', ','), (',', 'delay'), ('delay', 'induction'), ('induction', 'generalization'), ('generalization', 'process'), ('process', 'classification'), ('classification', 'performed'), ('performed', '.')]

>> Trigrams are: 
 [('INSTANCE-BASED', 'LEARNING', 'About'), ('LEARNING', 'About', 'learning'), ('About', 'learning', 'scheme'), ('learning', 'scheme', ','), ('scheme', ',', 'author'), (',', 'author', '['), ('author', '[', '24'), ('[', '24', ']'), ('24', ']', 'describes'), (']', 'describes', 'lazy-learning'), ('describes', 'lazy-learning', 'algorithms'), ('lazy-learning', 'algorithms', ','), ('algorithms', ',', 'delay'), (',', 'delay', 'induction'), ('delay', 'induction', 'generalization'), ('induction', 'generalization', 'process'), ('generalization', 'process', 'classification'), ('process', 'classification', 'performed'), ('classification', 'performed', '.')]

>> POS Tags are: 
 [('INSTANCE-BASED', 'JJ'), ('LEARNING', 'NNP'), ('About', 'IN'), ('learning', 'VBG'), ('scheme', 'NN'), (',', ','), ('author', 'NN'), ('[', 'VBD'), ('24', 'CD'), (']', 'JJ'), ('describes', 'NNS'), ('lazy-learning', 'JJ'), ('algorithms', 'NN'), (',', ','), ('delay', 'NN'), ('induction', 'NN'), ('generalization', 'NN'), ('process', 'NN'), ('classification', 'NN'), ('performed', 'VBD'), ('.', '.')]

 (S
  (NP INSTANCE-BASED/JJ LEARNING/NNP)
  About/IN
  learning/VBG
  (NP scheme/NN)
  ,/,
  (NP author/NN)
  [/VBD
  24/CD
  (NP ]/JJ describes/NNS)
  (NP lazy-learning/JJ algorithms/NN)
  ,/,
  (NP
    delay/NN
    induction/NN
    generalization/NN
    process/NN
    classification/NN)
  performed/VBD
  ./.) 


>> Noun Phrases are: 
 ['INSTANCE-BASED LEARNING', 'scheme', 'author', '] describes', 'lazy-learning algorithms', 'delay induction generalization process classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('INSTANCE-BASED', 'instance-bas'), ('LEARNING', 'learn'), ('About', 'about'), ('learning', 'learn'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describ'), ('lazy-learning', 'lazy-learn'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induct'), ('generalization', 'gener'), ('process', 'process'), ('classification', 'classif'), ('performed', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('INSTANCE-BASED', 'instance-bas'), ('LEARNING', 'learn'), ('About', 'about'), ('learning', 'learn'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describ'), ('lazy-learning', 'lazy-learn'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induct'), ('generalization', 'general'), ('process', 'process'), ('classification', 'classif'), ('performed', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('INSTANCE-BASED', 'INSTANCE-BASED'), ('LEARNING', 'LEARNING'), ('About', 'About'), ('learning', 'learning'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describes'), ('lazy-learning', 'lazy-learning'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induction'), ('generalization', 'generalization'), ('process', 'process'), ('classification', 'classification'), ('performed', 'performed'), ('.', '.')]



============================ Sentence 155 =============================

These   algorithms require less computational time during the training   phase than other eager-learning algorithms (such as decision trees,   neural and Bayes nets) but need more computation time during the   classification process. 


>> Tokens are: 
 ['These', 'algorithms', 'require', 'less', 'computational', 'time', 'training', 'phase', 'eager-learning', 'algorithms', '(', 'decision', 'trees', ',', 'neural', 'Bayes', 'nets', ')', 'need', 'computation', 'time', 'classification', 'process', '.']

>> Bigrams are: 
 [('These', 'algorithms'), ('algorithms', 'require'), ('require', 'less'), ('less', 'computational'), ('computational', 'time'), ('time', 'training'), ('training', 'phase'), ('phase', 'eager-learning'), ('eager-learning', 'algorithms'), ('algorithms', '('), ('(', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'neural'), ('neural', 'Bayes'), ('Bayes', 'nets'), ('nets', ')'), (')', 'need'), ('need', 'computation'), ('computation', 'time'), ('time', 'classification'), ('classification', 'process'), ('process', '.')]

>> Trigrams are: 
 [('These', 'algorithms', 'require'), ('algorithms', 'require', 'less'), ('require', 'less', 'computational'), ('less', 'computational', 'time'), ('computational', 'time', 'training'), ('time', 'training', 'phase'), ('training', 'phase', 'eager-learning'), ('phase', 'eager-learning', 'algorithms'), ('eager-learning', 'algorithms', '('), ('algorithms', '(', 'decision'), ('(', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'neural'), (',', 'neural', 'Bayes'), ('neural', 'Bayes', 'nets'), ('Bayes', 'nets', ')'), ('nets', ')', 'need'), (')', 'need', 'computation'), ('need', 'computation', 'time'), ('computation', 'time', 'classification'), ('time', 'classification', 'process'), ('classification', 'process', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('algorithms', 'JJ'), ('require', 'NN'), ('less', 'JJR'), ('computational', 'JJ'), ('time', 'NN'), ('training', 'VBG'), ('phase', 'JJ'), ('eager-learning', 'JJ'), ('algorithms', 'NN'), ('(', '('), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('neural', 'JJ'), ('Bayes', 'NNP'), ('nets', 'NNS'), (')', ')'), ('need', 'VBP'), ('computation', 'NN'), ('time', 'NN'), ('classification', 'NN'), ('process', 'NN'), ('.', '.')]

 (S
  (NP These/DT algorithms/JJ require/NN)
  less/JJR
  (NP computational/JJ time/NN)
  training/VBG
  (NP phase/JJ eager-learning/JJ algorithms/NN)
  (/(
  (NP decision/NN trees/NNS)
  ,/,
  (NP neural/JJ Bayes/NNP nets/NNS)
  )/)
  need/VBP
  (NP computation/NN time/NN classification/NN process/NN)
  ./.) 


>> Noun Phrases are: 
 ['These algorithms require', 'computational time', 'phase eager-learning algorithms', 'decision trees', 'neural Bayes nets', 'computation time classification process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('algorithms', 'algorithm'), ('require', 'requir'), ('less', 'less'), ('computational', 'comput'), ('time', 'time'), ('training', 'train'), ('phase', 'phase'), ('eager-learning', 'eager-learn'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('neural', 'neural'), ('Bayes', 'bay'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'comput'), ('time', 'time'), ('classification', 'classif'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('algorithms', 'algorithm'), ('require', 'requir'), ('less', 'less'), ('computational', 'comput'), ('time', 'time'), ('training', 'train'), ('phase', 'phase'), ('eager-learning', 'eager-learn'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('neural', 'neural'), ('Bayes', 'bay'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'comput'), ('time', 'time'), ('classification', 'classif'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('algorithms', 'algorithm'), ('require', 'require'), ('less', 'le'), ('computational', 'computational'), ('time', 'time'), ('training', 'training'), ('phase', 'phase'), ('eager-learning', 'eager-learning'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('neural', 'neural'), ('Bayes', 'Bayes'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'computation'), ('time', 'time'), ('classification', 'classification'), ('process', 'process'), ('.', '.')]



============================ Sentence 156 =============================

Nearest Neighbor algorithm is an example   of instance-based learning algorithms [1]. 


>> Tokens are: 
 ['Nearest', 'Neighbor', 'algorithm', 'example', 'instance-based', 'learning', 'algorithms', '[', '1', ']', '.']

>> Bigrams are: 
 [('Nearest', 'Neighbor'), ('Neighbor', 'algorithm'), ('algorithm', 'example'), ('example', 'instance-based'), ('instance-based', 'learning'), ('learning', 'algorithms'), ('algorithms', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('Nearest', 'Neighbor', 'algorithm'), ('Neighbor', 'algorithm', 'example'), ('algorithm', 'example', 'instance-based'), ('example', 'instance-based', 'learning'), ('instance-based', 'learning', 'algorithms'), ('learning', 'algorithms', '['), ('algorithms', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('Nearest', 'JJS'), ('Neighbor', 'NN'), ('algorithm', 'JJ'), ('example', 'NN'), ('instance-based', 'JJ'), ('learning', 'NN'), ('algorithms', 'NN'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Nearest/JJS
  (NP Neighbor/NN)
  (NP algorithm/JJ example/NN)
  (NP instance-based/JJ learning/NN algorithms/NN)
  [/VBD
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Neighbor', 'algorithm example', 'instance-based learning algorithms', ']']

>> Named Entities are: 
 [('GPE', 'Nearest'), ('ORGANIZATION', 'Neighbor')] 

>> Stemming using Porter Stemmer: 
 [('Nearest', 'nearest'), ('Neighbor', 'neighbor'), ('algorithm', 'algorithm'), ('example', 'exampl'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nearest', 'nearest'), ('Neighbor', 'neighbor'), ('algorithm', 'algorithm'), ('example', 'exampl'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Nearest', 'Nearest'), ('Neighbor', 'Neighbor'), ('algorithm', 'algorithm'), ('example', 'example'), ('instance-based', 'instance-based'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 157 =============================

Aha [25] and De et. 


>> Tokens are: 
 ['Aha', '[', '25', ']', 'De', 'et', '.']

>> Bigrams are: 
 [('Aha', '['), ('[', '25'), ('25', ']'), (']', 'De'), ('De', 'et'), ('et', '.')]

>> Trigrams are: 
 [('Aha', '[', '25'), ('[', '25', ']'), ('25', ']', 'De'), (']', 'De', 'et'), ('De', 'et', '.')]

>> POS Tags are: 
 [('Aha', 'NNP'), ('[', 'VBD'), ('25', 'CD'), (']', 'NNP'), ('De', 'NNP'), ('et', 'FW'), ('.', '.')]

 (S (NP Aha/NNP) [/VBD 25/CD (NP ]/NNP De/NNP) et/FW ./.) 


>> Noun Phrases are: 
 ['Aha', '] De']

>> Named Entities are: 
 [('PERSON', 'Aha')] 

>> Stemming using Porter Stemmer: 
 [('Aha', 'aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'de'), ('et', 'et'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aha', 'aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'de'), ('et', 'et'), ('.', '.')]

>> Lemmatization: 
 [('Aha', 'Aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'De'), ('et', 'et'), ('.', '.')]



============================ Sentence 158 =============================

al   [26] discussed the instance-based learning classifiers. 


>> Tokens are: 
 ['al', '[', '26', ']', 'discussed', 'instance-based', 'learning', 'classifiers', '.']

>> Bigrams are: 
 [('al', '['), ('[', '26'), ('26', ']'), (']', 'discussed'), ('discussed', 'instance-based'), ('instance-based', 'learning'), ('learning', 'classifiers'), ('classifiers', '.')]

>> Trigrams are: 
 [('al', '[', '26'), ('[', '26', ']'), ('26', ']', 'discussed'), (']', 'discussed', 'instance-based'), ('discussed', 'instance-based', 'learning'), ('instance-based', 'learning', 'classifiers'), ('learning', 'classifiers', '.')]

>> POS Tags are: 
 [('al', 'NN'), ('[', 'VBZ'), ('26', 'CD'), (']', 'NN'), ('discussed', 'VBD'), ('instance-based', 'JJ'), ('learning', 'NN'), ('classifiers', 'NNS'), ('.', '.')]

 (S
  (NP al/NN)
  [/VBZ
  26/CD
  (NP ]/NN)
  discussed/VBD
  (NP instance-based/JJ learning/NN classifiers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['al', ']', 'instance-based learning classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al', 'al'), ('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discuss'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('classifiers', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('al', 'al'), ('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discuss'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('classifiers', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('al', 'al'), ('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discussed'), ('instance-based', 'instance-based'), ('learning', 'learning'), ('classifiers', 'classifier'), ('.', '.')]



============================ Sentence 159 =============================

k-Nearest-Neighbor (kNN) classification  is one of the most   widely used method for a classification of objects when there is   little or no prior knowledge about the distribution of the data. 


>> Tokens are: 
 ['k-Nearest-Neighbor', '(', 'kNN', ')', 'classification', 'one', 'widely', 'used', 'method', 'classification', 'objects', 'little', 'prior', 'knowledge', 'distribution', 'data', '.']

>> Bigrams are: 
 [('k-Nearest-Neighbor', '('), ('(', 'kNN'), ('kNN', ')'), (')', 'classification'), ('classification', 'one'), ('one', 'widely'), ('widely', 'used'), ('used', 'method'), ('method', 'classification'), ('classification', 'objects'), ('objects', 'little'), ('little', 'prior'), ('prior', 'knowledge'), ('knowledge', 'distribution'), ('distribution', 'data'), ('data', '.')]

>> Trigrams are: 
 [('k-Nearest-Neighbor', '(', 'kNN'), ('(', 'kNN', ')'), ('kNN', ')', 'classification'), (')', 'classification', 'one'), ('classification', 'one', 'widely'), ('one', 'widely', 'used'), ('widely', 'used', 'method'), ('used', 'method', 'classification'), ('method', 'classification', 'objects'), ('classification', 'objects', 'little'), ('objects', 'little', 'prior'), ('little', 'prior', 'knowledge'), ('prior', 'knowledge', 'distribution'), ('knowledge', 'distribution', 'data'), ('distribution', 'data', '.')]

>> POS Tags are: 
 [('k-Nearest-Neighbor', 'NN'), ('(', '('), ('kNN', 'NN'), (')', ')'), ('classification', 'NN'), ('one', 'CD'), ('widely', 'RB'), ('used', 'VBN'), ('method', 'NN'), ('classification', 'NN'), ('objects', 'VBZ'), ('little', 'JJ'), ('prior', 'JJ'), ('knowledge', 'NN'), ('distribution', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP k-Nearest-Neighbor/NN)
  (/(
  (NP kNN/NN)
  )/)
  (NP classification/NN)
  one/CD
  widely/RB
  used/VBN
  (NP method/NN classification/NN)
  objects/VBZ
  (NP little/JJ prior/JJ knowledge/NN distribution/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['k-Nearest-Neighbor', 'kNN', 'classification', 'method classification', 'little prior knowledge distribution data']

>> Named Entities are: 
 [('ORGANIZATION', 'kNN')] 

>> Stemming using Porter Stemmer: 
 [('k-Nearest-Neighbor', 'k-nearest-neighbor'), ('(', '('), ('kNN', 'knn'), (')', ')'), ('classification', 'classif'), ('one', 'one'), ('widely', 'wide'), ('used', 'use'), ('method', 'method'), ('classification', 'classif'), ('objects', 'object'), ('little', 'littl'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('distribution', 'distribut'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('k-Nearest-Neighbor', 'k-nearest-neighbor'), ('(', '('), ('kNN', 'knn'), (')', ')'), ('classification', 'classif'), ('one', 'one'), ('widely', 'wide'), ('used', 'use'), ('method', 'method'), ('classification', 'classif'), ('objects', 'object'), ('little', 'littl'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('distribution', 'distribut'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('k-Nearest-Neighbor', 'k-Nearest-Neighbor'), ('(', '('), ('kNN', 'kNN'), (')', ')'), ('classification', 'classification'), ('one', 'one'), ('widely', 'widely'), ('used', 'used'), ('method', 'method'), ('classification', 'classification'), ('objects', 'object'), ('little', 'little'), ('prior', 'prior'), ('knowledge', 'knowledge'), ('distribution', 'distribution'), ('data', 'data'), ('.', '.')]



============================ Sentence 160 =============================

kNN is a good choice to perform discriminate analysis when   reliable parametric estimates of probability densities are   unknown or difficult to determine[27]. 


>> Tokens are: 
 ['kNN', 'good', 'choice', 'perform', 'discriminate', 'analysis', 'reliable', 'parametric', 'estimates', 'probability', 'densities', 'unknown', 'difficult', 'determine', '[', '27', ']', '.']

>> Bigrams are: 
 [('kNN', 'good'), ('good', 'choice'), ('choice', 'perform'), ('perform', 'discriminate'), ('discriminate', 'analysis'), ('analysis', 'reliable'), ('reliable', 'parametric'), ('parametric', 'estimates'), ('estimates', 'probability'), ('probability', 'densities'), ('densities', 'unknown'), ('unknown', 'difficult'), ('difficult', 'determine'), ('determine', '['), ('[', '27'), ('27', ']'), (']', '.')]

>> Trigrams are: 
 [('kNN', 'good', 'choice'), ('good', 'choice', 'perform'), ('choice', 'perform', 'discriminate'), ('perform', 'discriminate', 'analysis'), ('discriminate', 'analysis', 'reliable'), ('analysis', 'reliable', 'parametric'), ('reliable', 'parametric', 'estimates'), ('parametric', 'estimates', 'probability'), ('estimates', 'probability', 'densities'), ('probability', 'densities', 'unknown'), ('densities', 'unknown', 'difficult'), ('unknown', 'difficult', 'determine'), ('difficult', 'determine', '['), ('determine', '[', '27'), ('[', '27', ']'), ('27', ']', '.')]

>> POS Tags are: 
 [('kNN', 'RB'), ('good', 'JJ'), ('choice', 'NN'), ('perform', 'NN'), ('discriminate', 'NN'), ('analysis', 'NN'), ('reliable', 'JJ'), ('parametric', 'JJ'), ('estimates', 'NNS'), ('probability', 'NN'), ('densities', 'NNS'), ('unknown', 'IN'), ('difficult', 'JJ'), ('determine', 'NN'), ('[', '$'), ('27', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  kNN/RB
  (NP good/JJ choice/NN perform/NN discriminate/NN analysis/NN)
  (NP
    reliable/JJ
    parametric/JJ
    estimates/NNS
    probability/NN
    densities/NNS)
  unknown/IN
  (NP difficult/JJ determine/NN)
  [/$
  27/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['good choice perform discriminate analysis', 'reliable parametric estimates probability densities', 'difficult determine', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kNN', 'knn'), ('good', 'good'), ('choice', 'choic'), ('perform', 'perform'), ('discriminate', 'discrimin'), ('analysis', 'analysi'), ('reliable', 'reliabl'), ('parametric', 'parametr'), ('estimates', 'estim'), ('probability', 'probabl'), ('densities', 'densiti'), ('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determin'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('kNN', 'knn'), ('good', 'good'), ('choice', 'choic'), ('perform', 'perform'), ('discriminate', 'discrimin'), ('analysis', 'analysi'), ('reliable', 'reliabl'), ('parametric', 'parametr'), ('estimates', 'estim'), ('probability', 'probabl'), ('densities', 'densiti'), ('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determin'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('kNN', 'kNN'), ('good', 'good'), ('choice', 'choice'), ('perform', 'perform'), ('discriminate', 'discriminate'), ('analysis', 'analysis'), ('reliable', 'reliable'), ('parametric', 'parametric'), ('estimates', 'estimate'), ('probability', 'probability'), ('densities', 'density'), ('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determine'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]



============================ Sentence 161 =============================

kNN is a example of supervised learning algorithm  in which   the result of new instance query is classified based on majority   of k-nearest neighbor category. 


>> Tokens are: 
 ['kNN', 'example', 'supervised', 'learning', 'algorithm', 'result', 'new', 'instance', 'query', 'classified', 'based', 'majority', 'k-nearest', 'neighbor', 'category', '.']

>> Bigrams are: 
 [('kNN', 'example'), ('example', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithm'), ('algorithm', 'result'), ('result', 'new'), ('new', 'instance'), ('instance', 'query'), ('query', 'classified'), ('classified', 'based'), ('based', 'majority'), ('majority', 'k-nearest'), ('k-nearest', 'neighbor'), ('neighbor', 'category'), ('category', '.')]

>> Trigrams are: 
 [('kNN', 'example', 'supervised'), ('example', 'supervised', 'learning'), ('supervised', 'learning', 'algorithm'), ('learning', 'algorithm', 'result'), ('algorithm', 'result', 'new'), ('result', 'new', 'instance'), ('new', 'instance', 'query'), ('instance', 'query', 'classified'), ('query', 'classified', 'based'), ('classified', 'based', 'majority'), ('based', 'majority', 'k-nearest'), ('majority', 'k-nearest', 'neighbor'), ('k-nearest', 'neighbor', 'category'), ('neighbor', 'category', '.')]

>> POS Tags are: 
 [('kNN', 'JJ'), ('example', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('algorithm', 'RB'), ('result', 'VB'), ('new', 'JJ'), ('instance', 'NN'), ('query', 'NN'), ('classified', 'VBD'), ('based', 'VBN'), ('majority', 'NN'), ('k-nearest', 'JJ'), ('neighbor', 'NN'), ('category', 'NN'), ('.', '.')]

 (S
  (NP kNN/JJ example/NN)
  supervised/VBD
  learning/VBG
  algorithm/RB
  result/VB
  (NP new/JJ instance/NN query/NN)
  classified/VBD
  based/VBN
  (NP majority/NN)
  (NP k-nearest/JJ neighbor/NN category/NN)
  ./.) 


>> Noun Phrases are: 
 ['kNN example', 'new instance query', 'majority', 'k-nearest neighbor category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kNN', 'knn'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('result', 'result'), ('new', 'new'), ('instance', 'instanc'), ('query', 'queri'), ('classified', 'classifi'), ('based', 'base'), ('majority', 'major'), ('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('kNN', 'knn'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('result', 'result'), ('new', 'new'), ('instance', 'instanc'), ('query', 'queri'), ('classified', 'classifi'), ('based', 'base'), ('majority', 'major'), ('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('kNN', 'kNN'), ('example', 'example'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('result', 'result'), ('new', 'new'), ('instance', 'instance'), ('query', 'query'), ('classified', 'classified'), ('based', 'based'), ('majority', 'majority'), ('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'category'), ('.', '.')]



============================ Sentence 162 =============================

The core function of algorithm is   to classify a new object based on attributes and training samples. 


>> Tokens are: 
 ['The', 'core', 'function', 'algorithm', 'classify', 'new', 'object', 'based', 'attributes', 'training', 'samples', '.']

>> Bigrams are: 
 [('The', 'core'), ('core', 'function'), ('function', 'algorithm'), ('algorithm', 'classify'), ('classify', 'new'), ('new', 'object'), ('object', 'based'), ('based', 'attributes'), ('attributes', 'training'), ('training', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('The', 'core', 'function'), ('core', 'function', 'algorithm'), ('function', 'algorithm', 'classify'), ('algorithm', 'classify', 'new'), ('classify', 'new', 'object'), ('new', 'object', 'based'), ('object', 'based', 'attributes'), ('based', 'attributes', 'training'), ('attributes', 'training', 'samples'), ('training', 'samples', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('function', 'NN'), ('algorithm', 'IN'), ('classify', 'JJ'), ('new', 'JJ'), ('object', 'NN'), ('based', 'VBN'), ('attributes', 'VBZ'), ('training', 'VBG'), ('samples', 'NNS'), ('.', '.')]

 (S
  (NP The/DT core/NN function/NN)
  algorithm/IN
  (NP classify/JJ new/JJ object/NN)
  based/VBN
  attributes/VBZ
  training/VBG
  (NP samples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The core function', 'classify new object', 'samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm'), ('classify', 'classifi'), ('new', 'new'), ('object', 'object'), ('based', 'base'), ('attributes', 'attribut'), ('training', 'train'), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm'), ('classify', 'classifi'), ('new', 'new'), ('object', 'object'), ('based', 'base'), ('attributes', 'attribut'), ('training', 'train'), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm'), ('classify', 'classify'), ('new', 'new'), ('object', 'object'), ('based', 'based'), ('attributes', 'attribute'), ('training', 'training'), ('samples', 'sample'), ('.', '.')]



============================ Sentence 163 =============================

Here the classification is using majority vote among the   classification of the k objects. 


>> Tokens are: 
 ['Here', 'classification', 'using', 'majority', 'vote', 'among', 'classification', 'k', 'objects', '.']

>> Bigrams are: 
 [('Here', 'classification'), ('classification', 'using'), ('using', 'majority'), ('majority', 'vote'), ('vote', 'among'), ('among', 'classification'), ('classification', 'k'), ('k', 'objects'), ('objects', '.')]

>> Trigrams are: 
 [('Here', 'classification', 'using'), ('classification', 'using', 'majority'), ('using', 'majority', 'vote'), ('majority', 'vote', 'among'), ('vote', 'among', 'classification'), ('among', 'classification', 'k'), ('classification', 'k', 'objects'), ('k', 'objects', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('classification', 'NN'), ('using', 'VBG'), ('majority', 'NN'), ('vote', 'NN'), ('among', 'IN'), ('classification', 'NN'), ('k', 'NN'), ('objects', 'NNS'), ('.', '.')]

 (S
  Here/RB
  (NP classification/NN)
  using/VBG
  (NP majority/NN vote/NN)
  among/IN
  (NP classification/NN k/NN objects/NNS)
  ./.) 


>> Noun Phrases are: 
 ['classification', 'majority vote', 'classification k objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('classification', 'classif'), ('using', 'use'), ('majority', 'major'), ('vote', 'vote'), ('among', 'among'), ('classification', 'classif'), ('k', 'k'), ('objects', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('classification', 'classif'), ('using', 'use'), ('majority', 'major'), ('vote', 'vote'), ('among', 'among'), ('classification', 'classif'), ('k', 'k'), ('objects', 'object'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('classification', 'classification'), ('using', 'using'), ('majority', 'majority'), ('vote', 'vote'), ('among', 'among'), ('classification', 'classification'), ('k', 'k'), ('objects', 'object'), ('.', '.')]



============================ Sentence 164 =============================

For example we have conducted a   survey on consumption of any particular item to know its worth   in the market. 


>> Tokens are: 
 ['For', 'example', 'conducted', 'survey', 'consumption', 'particular', 'item', 'know', '', 'worth', 'market', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', 'conducted'), ('conducted', 'survey'), ('survey', 'consumption'), ('consumption', 'particular'), ('particular', 'item'), ('item', 'know'), ('know', ''), ('', 'worth'), ('worth', 'market'), ('market', '.')]

>> Trigrams are: 
 [('For', 'example', 'conducted'), ('example', 'conducted', 'survey'), ('conducted', 'survey', 'consumption'), ('survey', 'consumption', 'particular'), ('consumption', 'particular', 'item'), ('particular', 'item', 'know'), ('item', 'know', ''), ('know', '', 'worth'), ('', 'worth', 'market'), ('worth', 'market', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), ('conducted', 'VBN'), ('survey', 'NN'), ('consumption', 'NN'), ('particular', 'JJ'), ('item', 'NN'), ('know', 'VBP'), ('', 'VBZ'), ('worth', 'JJ'), ('market', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  conducted/VBN
  (NP survey/NN consumption/NN)
  (NP particular/JJ item/NN)
  know/VBP
  /VBZ
  (NP worth/JJ market/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'survey consumption', 'particular item', 'worth market']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('conducted', 'conduct'), ('survey', 'survey'), ('consumption', 'consumpt'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth'), ('market', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('conducted', 'conduct'), ('survey', 'survey'), ('consumption', 'consumpt'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth'), ('market', 'market'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), ('conducted', 'conducted'), ('survey', 'survey'), ('consumption', 'consumption'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth'), ('market', 'market'), ('.', '.')]



============================ Sentence 165 =============================

Below is a sample training table. 


>> Tokens are: 
 ['Below', 'sample', 'training', 'table', '.']

>> Bigrams are: 
 [('Below', 'sample'), ('sample', 'training'), ('training', 'table'), ('table', '.')]

>> Trigrams are: 
 [('Below', 'sample', 'training'), ('sample', 'training', 'table'), ('training', 'table', '.')]

>> POS Tags are: 
 [('Below', 'IN'), ('sample', 'JJ'), ('training', 'NN'), ('table', 'NN'), ('.', '.')]

 (S Below/IN (NP sample/JJ training/NN table/NN) ./.) 


>> Noun Phrases are: 
 ['sample training table']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Below', 'below'), ('sample', 'sampl'), ('training', 'train'), ('table', 'tabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Below', 'below'), ('sample', 'sampl'), ('training', 'train'), ('table', 'tabl'), ('.', '.')]

>> Lemmatization: 
 [('Below', 'Below'), ('sample', 'sample'), ('training', 'training'), ('table', 'table'), ('.', '.')]



============================ Sentence 166 =============================

Table.3. 


>> Tokens are: 
 ['Table.3', '.']

>> Bigrams are: 
 [('Table.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.3', 'NNP'), ('.', '.')]

 (S (NP Table.3/NNP) ./.) 


>> Noun Phrases are: 
 ['Table.3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.3', 'table.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.3', 'table.3'), ('.', '.')]

>> Lemmatization: 
 [('Table.3', 'Table.3'), ('.', '.')]



============================ Sentence 167 =============================

Training sample   X1 X2 Result   8 8 NO   8 5 NO   4 5 Yes   1 5 Yes   The outcome Yes or No is depended on the variable   values of X1 and X2, so if we want to know the outcome of that   combination which is not available in data table, for example,   when  x1 = 4, and x2 = 8 then without doing lengthy exercise of   conducting surveys, we can predict the results by using kNN   classification method. 


>> Tokens are: 
 ['Training', 'sample', 'X1', 'X2', 'Result', '8', '8', 'NO', '8', '5', 'NO', '4', '5', 'Yes', '1', '5', 'Yes', 'The', 'outcome', '', 'Yes', '', '', 'No', '', 'depended', 'variable', 'values', 'X1', 'X2', ',', 'want', 'know', 'outcome', 'combination', 'available', 'data', 'table', ',', 'example', ',', 'x1', '=', '4', ',', 'x2', '=', '8', 'without', 'lengthy', 'exercise', 'conducting', 'surveys', ',', 'predict', 'results', 'using', 'kNN', 'classification', 'method', '.']

>> Bigrams are: 
 [('Training', 'sample'), ('sample', 'X1'), ('X1', 'X2'), ('X2', 'Result'), ('Result', '8'), ('8', '8'), ('8', 'NO'), ('NO', '8'), ('8', '5'), ('5', 'NO'), ('NO', '4'), ('4', '5'), ('5', 'Yes'), ('Yes', '1'), ('1', '5'), ('5', 'Yes'), ('Yes', 'The'), ('The', 'outcome'), ('outcome', ''), ('', 'Yes'), ('Yes', ''), ('', ''), ('', 'No'), ('No', ''), ('', 'depended'), ('depended', 'variable'), ('variable', 'values'), ('values', 'X1'), ('X1', 'X2'), ('X2', ','), (',', 'want'), ('want', 'know'), ('know', 'outcome'), ('outcome', 'combination'), ('combination', 'available'), ('available', 'data'), ('data', 'table'), ('table', ','), (',', 'example'), ('example', ','), (',', 'x1'), ('x1', '='), ('=', '4'), ('4', ','), (',', 'x2'), ('x2', '='), ('=', '8'), ('8', 'without'), ('without', 'lengthy'), ('lengthy', 'exercise'), ('exercise', 'conducting'), ('conducting', 'surveys'), ('surveys', ','), (',', 'predict'), ('predict', 'results'), ('results', 'using'), ('using', 'kNN'), ('kNN', 'classification'), ('classification', 'method'), ('method', '.')]

>> Trigrams are: 
 [('Training', 'sample', 'X1'), ('sample', 'X1', 'X2'), ('X1', 'X2', 'Result'), ('X2', 'Result', '8'), ('Result', '8', '8'), ('8', '8', 'NO'), ('8', 'NO', '8'), ('NO', '8', '5'), ('8', '5', 'NO'), ('5', 'NO', '4'), ('NO', '4', '5'), ('4', '5', 'Yes'), ('5', 'Yes', '1'), ('Yes', '1', '5'), ('1', '5', 'Yes'), ('5', 'Yes', 'The'), ('Yes', 'The', 'outcome'), ('The', 'outcome', ''), ('outcome', '', 'Yes'), ('', 'Yes', ''), ('Yes', '', ''), ('', '', 'No'), ('', 'No', ''), ('No', '', 'depended'), ('', 'depended', 'variable'), ('depended', 'variable', 'values'), ('variable', 'values', 'X1'), ('values', 'X1', 'X2'), ('X1', 'X2', ','), ('X2', ',', 'want'), (',', 'want', 'know'), ('want', 'know', 'outcome'), ('know', 'outcome', 'combination'), ('outcome', 'combination', 'available'), ('combination', 'available', 'data'), ('available', 'data', 'table'), ('data', 'table', ','), ('table', ',', 'example'), (',', 'example', ','), ('example', ',', 'x1'), (',', 'x1', '='), ('x1', '=', '4'), ('=', '4', ','), ('4', ',', 'x2'), (',', 'x2', '='), ('x2', '=', '8'), ('=', '8', 'without'), ('8', 'without', 'lengthy'), ('without', 'lengthy', 'exercise'), ('lengthy', 'exercise', 'conducting'), ('exercise', 'conducting', 'surveys'), ('conducting', 'surveys', ','), ('surveys', ',', 'predict'), (',', 'predict', 'results'), ('predict', 'results', 'using'), ('results', 'using', 'kNN'), ('using', 'kNN', 'classification'), ('kNN', 'classification', 'method'), ('classification', 'method', '.')]

>> POS Tags are: 
 [('Training', 'VBG'), ('sample', 'JJ'), ('X1', 'NNP'), ('X2', 'NNP'), ('Result', 'NNP'), ('8', 'CD'), ('8', 'CD'), ('NO', 'RB'), ('8', 'CD'), ('5', 'CD'), ('NO', 'RB'), ('4', 'CD'), ('5', 'CD'), ('Yes', 'UH'), ('1', 'CD'), ('5', 'CD'), ('Yes', 'NNPS'), ('The', 'DT'), ('outcome', 'NN'), ('', 'NNP'), ('Yes', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('No', 'NNP'), ('', 'NNP'), ('depended', 'VBD'), ('variable', 'JJ'), ('values', 'NNS'), ('X1', 'NNP'), ('X2', 'NNP'), (',', ','), ('want', 'VBP'), ('know', 'JJ'), ('outcome', 'NN'), ('combination', 'NN'), ('available', 'JJ'), ('data', 'NNS'), ('table', 'NN'), (',', ','), ('example', 'NN'), (',', ','), ('x1', 'NNP'), ('=', 'NNP'), ('4', 'CD'), (',', ','), ('x2', 'NNP'), ('=', 'NNP'), ('8', 'CD'), ('without', 'IN'), ('lengthy', 'JJ'), ('exercise', 'NN'), ('conducting', 'VBG'), ('surveys', 'NNS'), (',', ','), ('predict', 'VBP'), ('results', 'NNS'), ('using', 'VBG'), ('kNN', 'JJ'), ('classification', 'NN'), ('method', 'NN'), ('.', '.')]

 (S
  Training/VBG
  (NP sample/JJ X1/NNP X2/NNP Result/NNP)
  8/CD
  8/CD
  NO/RB
  8/CD
  5/CD
  NO/RB
  4/CD
  5/CD
  Yes/UH
  1/CD
  5/CD
  Yes/NNPS
  (NP The/DT outcome/NN /NNP Yes/NNP /NNP /NNP No/NNP /NNP)
  depended/VBD
  (NP variable/JJ values/NNS X1/NNP X2/NNP)
  ,/,
  want/VBP
  (NP know/JJ outcome/NN combination/NN)
  (NP available/JJ data/NNS table/NN)
  ,/,
  (NP example/NN)
  ,/,
  (NP x1/NNP =/NNP)
  4/CD
  ,/,
  (NP x2/NNP =/NNP)
  8/CD
  without/IN
  (NP lengthy/JJ exercise/NN)
  conducting/VBG
  (NP surveys/NNS)
  ,/,
  predict/VBP
  (NP results/NNS)
  using/VBG
  (NP kNN/JJ classification/NN method/NN)
  ./.) 


>> Noun Phrases are: 
 ['sample X1 X2 Result', 'The outcome  Yes   No ', 'variable values X1 X2', 'know outcome combination', 'available data table', 'example', 'x1 =', 'x2 =', 'lengthy exercise', 'surveys', 'results', 'kNN classification method']

>> Named Entities are: 
 [('ORGANIZATION', 'kNN')] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('sample', 'sampl'), ('X1', 'x1'), ('X2', 'x2'), ('Result', 'result'), ('8', '8'), ('8', '8'), ('NO', 'no'), ('8', '8'), ('5', '5'), ('NO', 'no'), ('4', '4'), ('5', '5'), ('Yes', 'ye'), ('1', '1'), ('5', '5'), ('Yes', 'ye'), ('The', 'the'), ('outcome', 'outcom'), ('', ''), ('Yes', 'ye'), ('', ''), ('', ''), ('No', 'no'), ('', ''), ('depended', 'depend'), ('variable', 'variabl'), ('values', 'valu'), ('X1', 'x1'), ('X2', 'x2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcom'), ('combination', 'combin'), ('available', 'avail'), ('data', 'data'), ('table', 'tabl'), (',', ','), ('example', 'exampl'), (',', ','), ('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthi'), ('exercise', 'exercis'), ('conducting', 'conduct'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'use'), ('kNN', 'knn'), ('classification', 'classif'), ('method', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('sample', 'sampl'), ('X1', 'x1'), ('X2', 'x2'), ('Result', 'result'), ('8', '8'), ('8', '8'), ('NO', 'no'), ('8', '8'), ('5', '5'), ('NO', 'no'), ('4', '4'), ('5', '5'), ('Yes', 'yes'), ('1', '1'), ('5', '5'), ('Yes', 'yes'), ('The', 'the'), ('outcome', 'outcom'), ('', ''), ('Yes', 'yes'), ('', ''), ('', ''), ('No', 'no'), ('', ''), ('depended', 'depend'), ('variable', 'variabl'), ('values', 'valu'), ('X1', 'x1'), ('X2', 'x2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcom'), ('combination', 'combin'), ('available', 'avail'), ('data', 'data'), ('table', 'tabl'), (',', ','), ('example', 'exampl'), (',', ','), ('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthi'), ('exercise', 'exercis'), ('conducting', 'conduct'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'use'), ('kNN', 'knn'), ('classification', 'classif'), ('method', 'method'), ('.', '.')]

>> Lemmatization: 
 [('Training', 'Training'), ('sample', 'sample'), ('X1', 'X1'), ('X2', 'X2'), ('Result', 'Result'), ('8', '8'), ('8', '8'), ('NO', 'NO'), ('8', '8'), ('5', '5'), ('NO', 'NO'), ('4', '4'), ('5', '5'), ('Yes', 'Yes'), ('1', '1'), ('5', '5'), ('Yes', 'Yes'), ('The', 'The'), ('outcome', 'outcome'), ('', ''), ('Yes', 'Yes'), ('', ''), ('', ''), ('No', 'No'), ('', ''), ('depended', 'depended'), ('variable', 'variable'), ('values', 'value'), ('X1', 'X1'), ('X2', 'X2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcome'), ('combination', 'combination'), ('available', 'available'), ('data', 'data'), ('table', 'table'), (',', ','), ('example', 'example'), (',', ','), ('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthy'), ('exercise', 'exercise'), ('conducting', 'conducting'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'using'), ('kNN', 'kNN'), ('classification', 'classification'), ('method', 'method'), ('.', '.')]



============================ Sentence 168 =============================

The below pseudo code is an example for the instance base   learning methods. 


>> Tokens are: 
 ['The', 'pseudo', 'code', 'example', 'instance', 'base', 'learning', 'methods', '.']

>> Bigrams are: 
 [('The', 'pseudo'), ('pseudo', 'code'), ('code', 'example'), ('example', 'instance'), ('instance', 'base'), ('base', 'learning'), ('learning', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('The', 'pseudo', 'code'), ('pseudo', 'code', 'example'), ('code', 'example', 'instance'), ('example', 'instance', 'base'), ('instance', 'base', 'learning'), ('base', 'learning', 'methods'), ('learning', 'methods', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('pseudo', 'NN'), ('code', 'NN'), ('example', 'NN'), ('instance', 'NN'), ('base', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('.', '.')]

 (S
  (NP The/DT pseudo/NN code/NN example/NN instance/NN base/NN)
  learning/VBG
  (NP methods/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The pseudo code example instance base', 'methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'exampl'), ('instance', 'instanc'), ('base', 'base'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'exampl'), ('instance', 'instanc'), ('base', 'base'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'example'), ('instance', 'instance'), ('base', 'base'), ('learning', 'learning'), ('methods', 'method'), ('.', '.')]



============================ Sentence 169 =============================

Fig.9. 


>> Tokens are: 
 ['Fig.9', '.']

>> Bigrams are: 
 [('Fig.9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.9', 'NNP'), ('.', '.')]

 (S (NP Fig.9/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.9', 'fig.9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.9', 'fig.9'), ('.', '.')]

>> Lemmatization: 
 [('Fig.9', 'Fig.9'), ('.', '.')]



============================ Sentence 170 =============================

Pseudo-code for instance-based learners   6. 


>> Tokens are: 
 ['Pseudo-code', 'instance-based', 'learners', '6', '.']

>> Bigrams are: 
 [('Pseudo-code', 'instance-based'), ('instance-based', 'learners'), ('learners', '6'), ('6', '.')]

>> Trigrams are: 
 [('Pseudo-code', 'instance-based', 'learners'), ('instance-based', 'learners', '6'), ('learners', '6', '.')]

>> POS Tags are: 
 [('Pseudo-code', 'JJ'), ('instance-based', 'JJ'), ('learners', 'NNS'), ('6', 'CD'), ('.', '.')]

 (S (NP Pseudo-code/JJ instance-based/JJ learners/NNS) 6/CD ./.) 


>> Noun Phrases are: 
 ['Pseudo-code instance-based learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('instance-based', 'instance-bas'), ('learners', 'learner'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('instance-based', 'instance-bas'), ('learners', 'learner'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('Pseudo-code', 'Pseudo-code'), ('instance-based', 'instance-based'), ('learners', 'learner'), ('6', '6'), ('.', '.')]



============================ Sentence 171 =============================

SUPPORT VECTOR MACHINES   Support Vector Machines (SVMs) are a set of supervised   learning methods which have been used for classification,   regression and outliers detection. 


>> Tokens are: 
 ['SUPPORT', 'VECTOR', 'MACHINES', 'Support', 'Vector', 'Machines', '(', 'SVMs', ')', 'set', 'supervised', 'learning', 'methods', 'used', 'classification', ',', 'regression', 'outlier', '', 'detection', '.']

>> Bigrams are: 
 [('SUPPORT', 'VECTOR'), ('VECTOR', 'MACHINES'), ('MACHINES', 'Support'), ('Support', 'Vector'), ('Vector', 'Machines'), ('Machines', '('), ('(', 'SVMs'), ('SVMs', ')'), (')', 'set'), ('set', 'supervised'), ('supervised', 'learning'), ('learning', 'methods'), ('methods', 'used'), ('used', 'classification'), ('classification', ','), (',', 'regression'), ('regression', 'outlier'), ('outlier', ''), ('', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('SUPPORT', 'VECTOR', 'MACHINES'), ('VECTOR', 'MACHINES', 'Support'), ('MACHINES', 'Support', 'Vector'), ('Support', 'Vector', 'Machines'), ('Vector', 'Machines', '('), ('Machines', '(', 'SVMs'), ('(', 'SVMs', ')'), ('SVMs', ')', 'set'), (')', 'set', 'supervised'), ('set', 'supervised', 'learning'), ('supervised', 'learning', 'methods'), ('learning', 'methods', 'used'), ('methods', 'used', 'classification'), ('used', 'classification', ','), ('classification', ',', 'regression'), (',', 'regression', 'outlier'), ('regression', 'outlier', ''), ('outlier', '', 'detection'), ('', 'detection', '.')]

>> POS Tags are: 
 [('SUPPORT', 'NNP'), ('VECTOR', 'NNP'), ('MACHINES', 'NNP'), ('Support', 'NNP'), ('Vector', 'NNP'), ('Machines', 'NNP'), ('(', '('), ('SVMs', 'NNP'), (')', ')'), ('set', 'VBD'), ('supervised', 'VBN'), ('learning', 'VBG'), ('methods', 'NNS'), ('used', 'VBN'), ('classification', 'NN'), (',', ','), ('regression', 'NN'), ('outlier', 'JJR'), ('', 'JJ'), ('detection', 'NN'), ('.', '.')]

 (S
  (NP
    SUPPORT/NNP
    VECTOR/NNP
    MACHINES/NNP
    Support/NNP
    Vector/NNP
    Machines/NNP)
  (/(
  (NP SVMs/NNP)
  )/)
  set/VBD
  supervised/VBN
  learning/VBG
  (NP methods/NNS)
  used/VBN
  (NP classification/NN)
  ,/,
  (NP regression/NN)
  outlier/JJR
  (NP /JJ detection/NN)
  ./.) 


>> Noun Phrases are: 
 ['SUPPORT VECTOR MACHINES Support Vector Machines', 'SVMs', 'methods', 'classification', 'regression', ' detection']

>> Named Entities are: 
 [('ORGANIZATION', 'SUPPORT'), ('ORGANIZATION', 'VECTOR'), ('ORGANIZATION', 'MACHINES Support'), ('ORGANIZATION', 'SVMs')] 

>> Stemming using Porter Stemmer: 
 [('SUPPORT', 'support'), ('VECTOR', 'vector'), ('MACHINES', 'machin'), ('Support', 'support'), ('Vector', 'vector'), ('Machines', 'machin'), ('(', '('), ('SVMs', 'svm'), (')', ')'), ('set', 'set'), ('supervised', 'supervis'), ('learning', 'learn'), ('methods', 'method'), ('used', 'use'), ('classification', 'classif'), (',', ','), ('regression', 'regress'), ('outlier', 'outlier'), ('', ''), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SUPPORT', 'support'), ('VECTOR', 'vector'), ('MACHINES', 'machin'), ('Support', 'support'), ('Vector', 'vector'), ('Machines', 'machin'), ('(', '('), ('SVMs', 'svms'), (')', ')'), ('set', 'set'), ('supervised', 'supervis'), ('learning', 'learn'), ('methods', 'method'), ('used', 'use'), ('classification', 'classif'), (',', ','), ('regression', 'regress'), ('outlier', 'outlier'), ('', ''), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('SUPPORT', 'SUPPORT'), ('VECTOR', 'VECTOR'), ('MACHINES', 'MACHINES'), ('Support', 'Support'), ('Vector', 'Vector'), ('Machines', 'Machines'), ('(', '('), ('SVMs', 'SVMs'), (')', ')'), ('set', 'set'), ('supervised', 'supervised'), ('learning', 'learning'), ('methods', 'method'), ('used', 'used'), ('classification', 'classification'), (',', ','), ('regression', 'regression'), ('outlier', 'outlier'), ('', ''), ('detection', 'detection'), ('.', '.')]



============================ Sentence 172 =============================

There are number of benefits   for using SVM such as: (i) It is effective is high dimensional  space, (ii) Uses a subset of training points in the decision function  (called support vectors), so it is also memory efficient, (iii) It is  versatile because holds different kernel functions can be   specified for the decision function. 


>> Tokens are: 
 ['There', 'number', 'benefits', 'using', 'SVM', ':', '(', ')', 'It', 'effective', 'high', 'dimensional', 'space', ',', '(', 'ii', ')', 'Uses', 'subset', 'training', 'points', 'decision', 'function', '(', 'called', 'support', 'vectors', ')', ',', 'also', 'memory', 'efficient', ',', '(', 'iii', ')', 'It', 'versatile', 'holds', 'different', 'kernel', 'functions', 'specified', 'decision', 'function', '.']

>> Bigrams are: 
 [('There', 'number'), ('number', 'benefits'), ('benefits', 'using'), ('using', 'SVM'), ('SVM', ':'), (':', '('), ('(', ')'), (')', 'It'), ('It', 'effective'), ('effective', 'high'), ('high', 'dimensional'), ('dimensional', 'space'), ('space', ','), (',', '('), ('(', 'ii'), ('ii', ')'), (')', 'Uses'), ('Uses', 'subset'), ('subset', 'training'), ('training', 'points'), ('points', 'decision'), ('decision', 'function'), ('function', '('), ('(', 'called'), ('called', 'support'), ('support', 'vectors'), ('vectors', ')'), (')', ','), (',', 'also'), ('also', 'memory'), ('memory', 'efficient'), ('efficient', ','), (',', '('), ('(', 'iii'), ('iii', ')'), (')', 'It'), ('It', 'versatile'), ('versatile', 'holds'), ('holds', 'different'), ('different', 'kernel'), ('kernel', 'functions'), ('functions', 'specified'), ('specified', 'decision'), ('decision', 'function'), ('function', '.')]

>> Trigrams are: 
 [('There', 'number', 'benefits'), ('number', 'benefits', 'using'), ('benefits', 'using', 'SVM'), ('using', 'SVM', ':'), ('SVM', ':', '('), (':', '(', ')'), ('(', ')', 'It'), (')', 'It', 'effective'), ('It', 'effective', 'high'), ('effective', 'high', 'dimensional'), ('high', 'dimensional', 'space'), ('dimensional', 'space', ','), ('space', ',', '('), (',', '(', 'ii'), ('(', 'ii', ')'), ('ii', ')', 'Uses'), (')', 'Uses', 'subset'), ('Uses', 'subset', 'training'), ('subset', 'training', 'points'), ('training', 'points', 'decision'), ('points', 'decision', 'function'), ('decision', 'function', '('), ('function', '(', 'called'), ('(', 'called', 'support'), ('called', 'support', 'vectors'), ('support', 'vectors', ')'), ('vectors', ')', ','), (')', ',', 'also'), (',', 'also', 'memory'), ('also', 'memory', 'efficient'), ('memory', 'efficient', ','), ('efficient', ',', '('), (',', '(', 'iii'), ('(', 'iii', ')'), ('iii', ')', 'It'), (')', 'It', 'versatile'), ('It', 'versatile', 'holds'), ('versatile', 'holds', 'different'), ('holds', 'different', 'kernel'), ('different', 'kernel', 'functions'), ('kernel', 'functions', 'specified'), ('functions', 'specified', 'decision'), ('specified', 'decision', 'function'), ('decision', 'function', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('number', 'NN'), ('benefits', 'NNS'), ('using', 'VBG'), ('SVM', 'NNP'), (':', ':'), ('(', '('), (')', ')'), ('It', 'PRP'), ('effective', 'JJ'), ('high', 'JJ'), ('dimensional', 'JJ'), ('space', 'NN'), (',', ','), ('(', '('), ('ii', 'NN'), (')', ')'), ('Uses', 'VBZ'), ('subset', 'JJ'), ('training', 'NN'), ('points', 'NNS'), ('decision', 'NN'), ('function', 'NN'), ('(', '('), ('called', 'VBN'), ('support', 'NN'), ('vectors', 'NNS'), (')', ')'), (',', ','), ('also', 'RB'), ('memory', 'NN'), ('efficient', 'NN'), (',', ','), ('(', '('), ('iii', 'NN'), (')', ')'), ('It', 'PRP'), ('versatile', 'JJ'), ('holds', 'VBZ'), ('different', 'JJ'), ('kernel', 'NNS'), ('functions', 'NNS'), ('specified', 'VBD'), ('decision', 'NN'), ('function', 'NN'), ('.', '.')]

 (S
  There/EX
  (NP number/NN benefits/NNS)
  using/VBG
  (NP SVM/NNP)
  :/:
  (/(
  )/)
  It/PRP
  (NP effective/JJ high/JJ dimensional/JJ space/NN)
  ,/,
  (/(
  (NP ii/NN)
  )/)
  Uses/VBZ
  (NP subset/JJ training/NN points/NNS decision/NN function/NN)
  (/(
  called/VBN
  (NP support/NN vectors/NNS)
  )/)
  ,/,
  also/RB
  (NP memory/NN efficient/NN)
  ,/,
  (/(
  (NP iii/NN)
  )/)
  It/PRP
  versatile/JJ
  holds/VBZ
  (NP different/JJ kernel/NNS functions/NNS)
  specified/VBD
  (NP decision/NN function/NN)
  ./.) 


>> Noun Phrases are: 
 ['number benefits', 'SVM', 'effective high dimensional space', 'ii', 'subset training points decision function', 'support vectors', 'memory efficient', 'iii', 'different kernel functions', 'decision function']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('number', 'number'), ('benefits', 'benefit'), ('using', 'use'), ('SVM', 'svm'), (':', ':'), ('(', '('), (')', ')'), ('It', 'it'), ('effective', 'effect'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('Uses', 'use'), ('subset', 'subset'), ('training', 'train'), ('points', 'point'), ('decision', 'decis'), ('function', 'function'), ('(', '('), ('called', 'call'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memori'), ('efficient', 'effici'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('It', 'it'), ('versatile', 'versatil'), ('holds', 'hold'), ('different', 'differ'), ('kernel', 'kernel'), ('functions', 'function'), ('specified', 'specifi'), ('decision', 'decis'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('number', 'number'), ('benefits', 'benefit'), ('using', 'use'), ('SVM', 'svm'), (':', ':'), ('(', '('), (')', ')'), ('It', 'it'), ('effective', 'effect'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('Uses', 'use'), ('subset', 'subset'), ('training', 'train'), ('points', 'point'), ('decision', 'decis'), ('function', 'function'), ('(', '('), ('called', 'call'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memori'), ('efficient', 'effici'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('It', 'it'), ('versatile', 'versatil'), ('holds', 'hold'), ('different', 'differ'), ('kernel', 'kernel'), ('functions', 'function'), ('specified', 'specifi'), ('decision', 'decis'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('number', 'number'), ('benefits', 'benefit'), ('using', 'using'), ('SVM', 'SVM'), (':', ':'), ('(', '('), (')', ')'), ('It', 'It'), ('effective', 'effective'), ('high', 'high'), ('dimensional', 'dimensional'), ('space', 'space'), (',', ','), ('(', '('), ('ii', 'ii'), (')', ')'), ('Uses', 'Uses'), ('subset', 'subset'), ('training', 'training'), ('points', 'point'), ('decision', 'decision'), ('function', 'function'), ('(', '('), ('called', 'called'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memory'), ('efficient', 'efficient'), (',', ','), ('(', '('), ('iii', 'iii'), (')', ')'), ('It', 'It'), ('versatile', 'versatile'), ('holds', 'hold'), ('different', 'different'), ('kernel', 'kernel'), ('functions', 'function'), ('specified', 'specified'), ('decision', 'decision'), ('function', 'function'), ('.', '.')]



============================ Sentence 173 =============================

Common kernels are   provided, but it is also possible to specify custom kernels. 


>> Tokens are: 
 ['Common', 'kernels', 'provided', ',', 'also', 'possible', 'specify', 'custom', 'kernels', '.']

>> Bigrams are: 
 [('Common', 'kernels'), ('kernels', 'provided'), ('provided', ','), (',', 'also'), ('also', 'possible'), ('possible', 'specify'), ('specify', 'custom'), ('custom', 'kernels'), ('kernels', '.')]

>> Trigrams are: 
 [('Common', 'kernels', 'provided'), ('kernels', 'provided', ','), ('provided', ',', 'also'), (',', 'also', 'possible'), ('also', 'possible', 'specify'), ('possible', 'specify', 'custom'), ('specify', 'custom', 'kernels'), ('custom', 'kernels', '.')]

>> POS Tags are: 
 [('Common', 'JJ'), ('kernels', 'NNS'), ('provided', 'VBN'), (',', ','), ('also', 'RB'), ('possible', 'JJ'), ('specify', 'NN'), ('custom', 'NN'), ('kernels', 'NNS'), ('.', '.')]

 (S
  (NP Common/JJ kernels/NNS)
  provided/VBN
  ,/,
  also/RB
  (NP possible/JJ specify/NN custom/NN kernels/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Common kernels', 'possible specify custom kernels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Common', 'common'), ('kernels', 'kernel'), ('provided', 'provid'), (',', ','), ('also', 'also'), ('possible', 'possibl'), ('specify', 'specifi'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Common', 'common'), ('kernels', 'kernel'), ('provided', 'provid'), (',', ','), ('also', 'also'), ('possible', 'possibl'), ('specify', 'specifi'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]

>> Lemmatization: 
 [('Common', 'Common'), ('kernels', 'kernel'), ('provided', 'provided'), (',', ','), ('also', 'also'), ('possible', 'possible'), ('specify', 'specify'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]



============================ Sentence 174 =============================

Most real-world problems involve non-separable data for   which no hyperplane exists that successfully separates the   positive from negative instances in the training set. 


>> Tokens are: 
 ['Most', 'real-world', 'problems', 'involve', 'non-separable', 'data', 'hyperplane', 'exists', 'successfully', 'separates', 'positive', 'negative', 'instances', 'training', 'set', '.']

>> Bigrams are: 
 [('Most', 'real-world'), ('real-world', 'problems'), ('problems', 'involve'), ('involve', 'non-separable'), ('non-separable', 'data'), ('data', 'hyperplane'), ('hyperplane', 'exists'), ('exists', 'successfully'), ('successfully', 'separates'), ('separates', 'positive'), ('positive', 'negative'), ('negative', 'instances'), ('instances', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Most', 'real-world', 'problems'), ('real-world', 'problems', 'involve'), ('problems', 'involve', 'non-separable'), ('involve', 'non-separable', 'data'), ('non-separable', 'data', 'hyperplane'), ('data', 'hyperplane', 'exists'), ('hyperplane', 'exists', 'successfully'), ('exists', 'successfully', 'separates'), ('successfully', 'separates', 'positive'), ('separates', 'positive', 'negative'), ('positive', 'negative', 'instances'), ('negative', 'instances', 'training'), ('instances', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('real-world', 'JJ'), ('problems', 'NNS'), ('involve', 'VBP'), ('non-separable', 'JJ'), ('data', 'NNS'), ('hyperplane', 'NN'), ('exists', 'VBZ'), ('successfully', 'RB'), ('separates', 'NNS'), ('positive', 'JJ'), ('negative', 'JJ'), ('instances', 'NNS'), ('training', 'VBG'), ('set', 'NN'), ('.', '.')]

 (S
  Most/JJS
  (NP real-world/JJ problems/NNS)
  involve/VBP
  (NP non-separable/JJ data/NNS hyperplane/NN)
  exists/VBZ
  successfully/RB
  (NP separates/NNS)
  (NP positive/JJ negative/JJ instances/NNS)
  training/VBG
  (NP set/NN)
  ./.) 


>> Noun Phrases are: 
 ['real-world problems', 'non-separable data hyperplane', 'separates', 'positive negative instances', 'set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involv'), ('non-separable', 'non-separ'), ('data', 'data'), ('hyperplane', 'hyperplan'), ('exists', 'exist'), ('successfully', 'success'), ('separates', 'separ'), ('positive', 'posit'), ('negative', 'neg'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involv'), ('non-separable', 'non-separ'), ('data', 'data'), ('hyperplane', 'hyperplan'), ('exists', 'exist'), ('successfully', 'success'), ('separates', 'separ'), ('positive', 'posit'), ('negative', 'negat'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involve'), ('non-separable', 'non-separable'), ('data', 'data'), ('hyperplane', 'hyperplane'), ('exists', 'exists'), ('successfully', 'successfully'), ('separates', 'separate'), ('positive', 'positive'), ('negative', 'negative'), ('instances', 'instance'), ('training', 'training'), ('set', 'set'), ('.', '.')]



============================ Sentence 175 =============================

One good   solution to this inseparability problem is to map the data onto a   higher dimensional space and define a separating hyperplane   there. 


>> Tokens are: 
 ['One', 'good', 'solution', 'inseparability', 'problem', 'map', 'data', 'onto', 'higher', 'dimensional', 'space', 'define', 'separating', 'hyperplane', '.']

>> Bigrams are: 
 [('One', 'good'), ('good', 'solution'), ('solution', 'inseparability'), ('inseparability', 'problem'), ('problem', 'map'), ('map', 'data'), ('data', 'onto'), ('onto', 'higher'), ('higher', 'dimensional'), ('dimensional', 'space'), ('space', 'define'), ('define', 'separating'), ('separating', 'hyperplane'), ('hyperplane', '.')]

>> Trigrams are: 
 [('One', 'good', 'solution'), ('good', 'solution', 'inseparability'), ('solution', 'inseparability', 'problem'), ('inseparability', 'problem', 'map'), ('problem', 'map', 'data'), ('map', 'data', 'onto'), ('data', 'onto', 'higher'), ('onto', 'higher', 'dimensional'), ('higher', 'dimensional', 'space'), ('dimensional', 'space', 'define'), ('space', 'define', 'separating'), ('define', 'separating', 'hyperplane'), ('separating', 'hyperplane', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('good', 'JJ'), ('solution', 'NN'), ('inseparability', 'NN'), ('problem', 'NN'), ('map', 'NN'), ('data', 'NNS'), ('onto', 'IN'), ('higher', 'JJR'), ('dimensional', 'JJ'), ('space', 'NN'), ('define', 'NN'), ('separating', 'VBG'), ('hyperplane', 'NN'), ('.', '.')]

 (S
  One/CD
  (NP
    good/JJ
    solution/NN
    inseparability/NN
    problem/NN
    map/NN
    data/NNS)
  onto/IN
  higher/JJR
  (NP dimensional/JJ space/NN define/NN)
  separating/VBG
  (NP hyperplane/NN)
  ./.) 


>> Noun Phrases are: 
 ['good solution inseparability problem map data', 'dimensional space define', 'hyperplane']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('good', 'good'), ('solution', 'solut'), ('inseparability', 'insepar'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto'), ('higher', 'higher'), ('dimensional', 'dimension'), ('space', 'space'), ('define', 'defin'), ('separating', 'separ'), ('hyperplane', 'hyperplan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('good', 'good'), ('solution', 'solut'), ('inseparability', 'insepar'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto'), ('higher', 'higher'), ('dimensional', 'dimension'), ('space', 'space'), ('define', 'defin'), ('separating', 'separ'), ('hyperplane', 'hyperplan'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('good', 'good'), ('solution', 'solution'), ('inseparability', 'inseparability'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto'), ('higher', 'higher'), ('dimensional', 'dimensional'), ('space', 'space'), ('define', 'define'), ('separating', 'separating'), ('hyperplane', 'hyperplane'), ('.', '.')]



============================ Sentence 176 =============================

This higher-dimensional space is called the transformed   feature space, as opposed to the input space occupied by the   training instances [1]. 


>> Tokens are: 
 ['This', 'higher-dimensional', 'space', 'called', 'transformed', 'feature', 'space', ',', 'opposed', 'input', 'space', 'occupied', 'training', 'instances', '[', '1', ']', '.']

>> Bigrams are: 
 [('This', 'higher-dimensional'), ('higher-dimensional', 'space'), ('space', 'called'), ('called', 'transformed'), ('transformed', 'feature'), ('feature', 'space'), ('space', ','), (',', 'opposed'), ('opposed', 'input'), ('input', 'space'), ('space', 'occupied'), ('occupied', 'training'), ('training', 'instances'), ('instances', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'higher-dimensional', 'space'), ('higher-dimensional', 'space', 'called'), ('space', 'called', 'transformed'), ('called', 'transformed', 'feature'), ('transformed', 'feature', 'space'), ('feature', 'space', ','), ('space', ',', 'opposed'), (',', 'opposed', 'input'), ('opposed', 'input', 'space'), ('input', 'space', 'occupied'), ('space', 'occupied', 'training'), ('occupied', 'training', 'instances'), ('training', 'instances', '['), ('instances', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('higher-dimensional', 'JJ'), ('space', 'NN'), ('called', 'VBN'), ('transformed', 'JJ'), ('feature', 'NN'), ('space', 'NN'), (',', ','), ('opposed', 'VBD'), ('input', 'JJ'), ('space', 'NN'), ('occupied', 'VBD'), ('training', 'NN'), ('instances', 'NNS'), ('[', 'VBP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT higher-dimensional/JJ space/NN)
  called/VBN
  (NP transformed/JJ feature/NN space/NN)
  ,/,
  opposed/VBD
  (NP input/JJ space/NN)
  occupied/VBD
  (NP training/NN instances/NNS)
  [/VBP
  1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This higher-dimensional space', 'transformed feature space', 'input space', 'training instances', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('higher-dimensional', 'higher-dimension'), ('space', 'space'), ('called', 'call'), ('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), (',', ','), ('opposed', 'oppos'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupi'), ('training', 'train'), ('instances', 'instanc'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('higher-dimensional', 'higher-dimension'), ('space', 'space'), ('called', 'call'), ('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), (',', ','), ('opposed', 'oppos'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupi'), ('training', 'train'), ('instances', 'instanc'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('higher-dimensional', 'higher-dimensional'), ('space', 'space'), ('called', 'called'), ('transformed', 'transformed'), ('feature', 'feature'), ('space', 'space'), (',', ','), ('opposed', 'opposed'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupied'), ('training', 'training'), ('instances', 'instance'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



============================ Sentence 177 =============================

Fig.10. 


>> Tokens are: 
 ['Fig.10', '.']

>> Bigrams are: 
 [('Fig.10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.10', 'NNP'), ('.', '.')]

 (S (NP Fig.10/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.10']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.10', 'fig.10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.10', 'fig.10'), ('.', '.')]

>> Lemmatization: 
 [('Fig.10', 'Fig.10'), ('.', '.')]



============================ Sentence 178 =============================

Maximum margin through SVM   In order to get better results the selection of an appropriate   kernel function is important, since the kernel function defines   the transformed feature space in which the training set instances   Procedure InstanceBaseLearner (Testing Instances). 


>> Tokens are: 
 ['Maximum', 'margin', 'SVM', 'In', 'order', 'get', 'better', 'results', 'selection', 'appropriate', 'kernel', 'function', 'important', ',', 'since', 'kernel', 'function', 'defines', 'transformed', 'feature', 'space', 'training', 'set', 'instances', 'Procedure', 'InstanceBaseLearner', '(', 'Testing', 'Instances', ')', '.']

>> Bigrams are: 
 [('Maximum', 'margin'), ('margin', 'SVM'), ('SVM', 'In'), ('In', 'order'), ('order', 'get'), ('get', 'better'), ('better', 'results'), ('results', 'selection'), ('selection', 'appropriate'), ('appropriate', 'kernel'), ('kernel', 'function'), ('function', 'important'), ('important', ','), (',', 'since'), ('since', 'kernel'), ('kernel', 'function'), ('function', 'defines'), ('defines', 'transformed'), ('transformed', 'feature'), ('feature', 'space'), ('space', 'training'), ('training', 'set'), ('set', 'instances'), ('instances', 'Procedure'), ('Procedure', 'InstanceBaseLearner'), ('InstanceBaseLearner', '('), ('(', 'Testing'), ('Testing', 'Instances'), ('Instances', ')'), (')', '.')]

>> Trigrams are: 
 [('Maximum', 'margin', 'SVM'), ('margin', 'SVM', 'In'), ('SVM', 'In', 'order'), ('In', 'order', 'get'), ('order', 'get', 'better'), ('get', 'better', 'results'), ('better', 'results', 'selection'), ('results', 'selection', 'appropriate'), ('selection', 'appropriate', 'kernel'), ('appropriate', 'kernel', 'function'), ('kernel', 'function', 'important'), ('function', 'important', ','), ('important', ',', 'since'), (',', 'since', 'kernel'), ('since', 'kernel', 'function'), ('kernel', 'function', 'defines'), ('function', 'defines', 'transformed'), ('defines', 'transformed', 'feature'), ('transformed', 'feature', 'space'), ('feature', 'space', 'training'), ('space', 'training', 'set'), ('training', 'set', 'instances'), ('set', 'instances', 'Procedure'), ('instances', 'Procedure', 'InstanceBaseLearner'), ('Procedure', 'InstanceBaseLearner', '('), ('InstanceBaseLearner', '(', 'Testing'), ('(', 'Testing', 'Instances'), ('Testing', 'Instances', ')'), ('Instances', ')', '.')]

>> POS Tags are: 
 [('Maximum', 'NNP'), ('margin', 'NN'), ('SVM', 'NNP'), ('In', 'IN'), ('order', 'NN'), ('get', 'VBP'), ('better', 'JJR'), ('results', 'NNS'), ('selection', 'JJ'), ('appropriate', 'JJ'), ('kernel', 'NNS'), ('function', 'NN'), ('important', 'JJ'), (',', ','), ('since', 'IN'), ('kernel', 'NN'), ('function', 'NN'), ('defines', 'NNS'), ('transformed', 'VBD'), ('feature', 'JJ'), ('space', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('instances', 'NNS'), ('Procedure', 'NNP'), ('InstanceBaseLearner', 'NNP'), ('(', '('), ('Testing', 'NNP'), ('Instances', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Maximum/NNP margin/NN SVM/NNP)
  In/IN
  (NP order/NN)
  get/VBP
  better/JJR
  (NP results/NNS)
  (NP selection/JJ appropriate/JJ kernel/NNS function/NN)
  important/JJ
  ,/,
  since/IN
  (NP kernel/NN function/NN defines/NNS)
  transformed/VBD
  (NP feature/JJ space/NN training/NN)
  set/VBN
  (NP instances/NNS Procedure/NNP InstanceBaseLearner/NNP)
  (/(
  (NP Testing/NNP Instances/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Maximum margin SVM', 'order', 'results', 'selection appropriate kernel function', 'kernel function defines', 'feature space training', 'instances Procedure InstanceBaseLearner', 'Testing Instances']

>> Named Entities are: 
 [('GPE', 'Maximum'), ('ORGANIZATION', 'Testing')] 

>> Stemming using Porter Stemmer: 
 [('Maximum', 'maximum'), ('margin', 'margin'), ('SVM', 'svm'), ('In', 'in'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'select'), ('appropriate', 'appropri'), ('kernel', 'kernel'), ('function', 'function'), ('important', 'import'), (',', ','), ('since', 'sinc'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defin'), ('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), ('training', 'train'), ('set', 'set'), ('instances', 'instanc'), ('Procedure', 'procedur'), ('InstanceBaseLearner', 'instancebaselearn'), ('(', '('), ('Testing', 'test'), ('Instances', 'instanc'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Maximum', 'maximum'), ('margin', 'margin'), ('SVM', 'svm'), ('In', 'in'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'select'), ('appropriate', 'appropri'), ('kernel', 'kernel'), ('function', 'function'), ('important', 'import'), (',', ','), ('since', 'sinc'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defin'), ('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), ('training', 'train'), ('set', 'set'), ('instances', 'instanc'), ('Procedure', 'procedur'), ('InstanceBaseLearner', 'instancebaselearn'), ('(', '('), ('Testing', 'test'), ('Instances', 'instanc'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Maximum', 'Maximum'), ('margin', 'margin'), ('SVM', 'SVM'), ('In', 'In'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'selection'), ('appropriate', 'appropriate'), ('kernel', 'kernel'), ('function', 'function'), ('important', 'important'), (',', ','), ('since', 'since'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defines'), ('transformed', 'transformed'), ('feature', 'feature'), ('space', 'space'), ('training', 'training'), ('set', 'set'), ('instances', 'instance'), ('Procedure', 'Procedure'), ('InstanceBaseLearner', 'InstanceBaseLearner'), ('(', '('), ('Testing', 'Testing'), ('Instances', 'Instances'), (')', ')'), ('.', '.')]



============================ Sentence 179 =============================

for each testing instance      {   find the k most nearest instances of the   training set according to a distance metric        Resulting Class: most frequent class        label of the k nearest instances      }      Initialize an Empty Bayesian Network G containing n   nodes (i.e.-, a BN with n nodes but no edges). 


>> Tokens are: 
 ['testing', 'instance', '{', 'find', 'k', 'nearest', 'instances', 'training', 'set', 'according', 'distance', 'metric', 'Resulting', 'Class', ':', 'frequent', 'class', 'label', 'k', 'nearest', 'instances', '}', 'Initialize', 'Empty', 'Bayesian', 'Network', 'G', 'containing', 'n', 'nodes', '(', 'i.e.-', ',', 'BN', 'n', 'nodes', 'edges', ')', '.']

>> Bigrams are: 
 [('testing', 'instance'), ('instance', '{'), ('{', 'find'), ('find', 'k'), ('k', 'nearest'), ('nearest', 'instances'), ('instances', 'training'), ('training', 'set'), ('set', 'according'), ('according', 'distance'), ('distance', 'metric'), ('metric', 'Resulting'), ('Resulting', 'Class'), ('Class', ':'), (':', 'frequent'), ('frequent', 'class'), ('class', 'label'), ('label', 'k'), ('k', 'nearest'), ('nearest', 'instances'), ('instances', '}'), ('}', 'Initialize'), ('Initialize', 'Empty'), ('Empty', 'Bayesian'), ('Bayesian', 'Network'), ('Network', 'G'), ('G', 'containing'), ('containing', 'n'), ('n', 'nodes'), ('nodes', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'BN'), ('BN', 'n'), ('n', 'nodes'), ('nodes', 'edges'), ('edges', ')'), (')', '.')]

>> Trigrams are: 
 [('testing', 'instance', '{'), ('instance', '{', 'find'), ('{', 'find', 'k'), ('find', 'k', 'nearest'), ('k', 'nearest', 'instances'), ('nearest', 'instances', 'training'), ('instances', 'training', 'set'), ('training', 'set', 'according'), ('set', 'according', 'distance'), ('according', 'distance', 'metric'), ('distance', 'metric', 'Resulting'), ('metric', 'Resulting', 'Class'), ('Resulting', 'Class', ':'), ('Class', ':', 'frequent'), (':', 'frequent', 'class'), ('frequent', 'class', 'label'), ('class', 'label', 'k'), ('label', 'k', 'nearest'), ('k', 'nearest', 'instances'), ('nearest', 'instances', '}'), ('instances', '}', 'Initialize'), ('}', 'Initialize', 'Empty'), ('Initialize', 'Empty', 'Bayesian'), ('Empty', 'Bayesian', 'Network'), ('Bayesian', 'Network', 'G'), ('Network', 'G', 'containing'), ('G', 'containing', 'n'), ('containing', 'n', 'nodes'), ('n', 'nodes', '('), ('nodes', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'BN'), (',', 'BN', 'n'), ('BN', 'n', 'nodes'), ('n', 'nodes', 'edges'), ('nodes', 'edges', ')'), ('edges', ')', '.')]

>> POS Tags are: 
 [('testing', 'VBG'), ('instance', 'NN'), ('{', '('), ('find', 'VB'), ('k', 'JJ'), ('nearest', 'JJS'), ('instances', 'NNS'), ('training', 'VBG'), ('set', 'NN'), ('according', 'VBG'), ('distance', 'NN'), ('metric', 'JJ'), ('Resulting', 'VBG'), ('Class', 'NN'), (':', ':'), ('frequent', 'JJ'), ('class', 'NN'), ('label', 'NN'), ('k', 'NN'), ('nearest', 'JJS'), ('instances', 'NNS'), ('}', ')'), ('Initialize', 'NNP'), ('Empty', 'NNP'), ('Bayesian', 'NNP'), ('Network', 'NNP'), ('G', 'NNP'), ('containing', 'VBG'), ('n', 'JJ'), ('nodes', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('BN', 'NNP'), ('n', 'FW'), ('nodes', 'NNS'), ('edges', 'NNS'), (')', ')'), ('.', '.')]

 (S
  testing/VBG
  (NP instance/NN)
  {/(
  find/VB
  k/JJ
  nearest/JJS
  (NP instances/NNS)
  training/VBG
  (NP set/NN)
  according/VBG
  (NP distance/NN)
  metric/JJ
  Resulting/VBG
  (NP Class/NN)
  :/:
  (NP frequent/JJ class/NN label/NN k/NN)
  nearest/JJS
  (NP instances/NNS)
  }/)
  (NP Initialize/NNP Empty/NNP Bayesian/NNP Network/NNP G/NNP)
  containing/VBG
  (NP n/JJ nodes/NNS)
  (/(
  i.e.-/JJ
  ,/,
  (NP BN/NNP)
  n/FW
  (NP nodes/NNS edges/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'instances', 'set', 'distance', 'Class', 'frequent class label k', 'instances', 'Initialize Empty Bayesian Network G', 'n nodes', 'BN', 'nodes edges']

>> Named Entities are: 
 [('PERSON', 'Class'), ('PERSON', 'Initialize Empty Bayesian Network'), ('ORGANIZATION', 'BN')] 

>> Stemming using Porter Stemmer: 
 [('testing', 'test'), ('instance', 'instanc'), ('{', '{'), ('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('according', 'accord'), ('distance', 'distanc'), ('metric', 'metric'), ('Resulting', 'result'), ('Class', 'class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class'), ('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc'), ('}', '}'), ('Initialize', 'initi'), ('Empty', 'empti'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('G', 'g'), ('containing', 'contain'), ('n', 'n'), ('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'bn'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edg'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('testing', 'test'), ('instance', 'instanc'), ('{', '{'), ('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('according', 'accord'), ('distance', 'distanc'), ('metric', 'metric'), ('Resulting', 'result'), ('Class', 'class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class'), ('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc'), ('}', '}'), ('Initialize', 'initi'), ('Empty', 'empti'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('G', 'g'), ('containing', 'contain'), ('n', 'n'), ('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'bn'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edg'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('testing', 'testing'), ('instance', 'instance'), ('{', '{'), ('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instance'), ('training', 'training'), ('set', 'set'), ('according', 'according'), ('distance', 'distance'), ('metric', 'metric'), ('Resulting', 'Resulting'), ('Class', 'Class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class'), ('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instance'), ('}', '}'), ('Initialize', 'Initialize'), ('Empty', 'Empty'), ('Bayesian', 'Bayesian'), ('Network', 'Network'), ('G', 'G'), ('containing', 'containing'), ('n', 'n'), ('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'BN'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edge'), (')', ')'), ('.', '.')]



============================ Sentence 180 =============================

(1) Evaluate the score of G: Score (G) (2) G = G (3) for i = 1 to n do (4) for j = 1 to n do (5) if i  j then (6) if there is no edge between the nodes i and  j in G then. 


>> Tokens are: 
 ['(', '1', ')', 'Evaluate', 'score', 'G', ':', 'Score', '(', 'G', ')', '(', '2', ')', 'G', '', '=', 'G', '(', '3', ')', '=', '1', 'n', '(', '4', ')', 'j', '=', '1', 'n', '(', '5', ')', '', 'j', '(', '6', ')', 'edge', 'nodes', 'j', 'G', '.']

>> Bigrams are: 
 [('(', '1'), ('1', ')'), (')', 'Evaluate'), ('Evaluate', 'score'), ('score', 'G'), ('G', ':'), (':', 'Score'), ('Score', '('), ('(', 'G'), ('G', ')'), (')', '('), ('(', '2'), ('2', ')'), (')', 'G'), ('G', ''), ('', '='), ('=', 'G'), ('G', '('), ('(', '3'), ('3', ')'), (')', '='), ('=', '1'), ('1', 'n'), ('n', '('), ('(', '4'), ('4', ')'), (')', 'j'), ('j', '='), ('=', '1'), ('1', 'n'), ('n', '('), ('(', '5'), ('5', ')'), (')', ''), ('', 'j'), ('j', '('), ('(', '6'), ('6', ')'), (')', 'edge'), ('edge', 'nodes'), ('nodes', 'j'), ('j', 'G'), ('G', '.')]

>> Trigrams are: 
 [('(', '1', ')'), ('1', ')', 'Evaluate'), (')', 'Evaluate', 'score'), ('Evaluate', 'score', 'G'), ('score', 'G', ':'), ('G', ':', 'Score'), (':', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ')'), ('G', ')', '('), (')', '(', '2'), ('(', '2', ')'), ('2', ')', 'G'), (')', 'G', ''), ('G', '', '='), ('', '=', 'G'), ('=', 'G', '('), ('G', '(', '3'), ('(', '3', ')'), ('3', ')', '='), (')', '=', '1'), ('=', '1', 'n'), ('1', 'n', '('), ('n', '(', '4'), ('(', '4', ')'), ('4', ')', 'j'), (')', 'j', '='), ('j', '=', '1'), ('=', '1', 'n'), ('1', 'n', '('), ('n', '(', '5'), ('(', '5', ')'), ('5', ')', ''), (')', '', 'j'), ('', 'j', '('), ('j', '(', '6'), ('(', '6', ')'), ('6', ')', 'edge'), (')', 'edge', 'nodes'), ('edge', 'nodes', 'j'), ('nodes', 'j', 'G'), ('j', 'G', '.')]

>> POS Tags are: 
 [('(', '('), ('1', 'CD'), (')', ')'), ('Evaluate', 'NNP'), ('score', 'NN'), ('G', 'NNP'), (':', ':'), ('Score', 'NN'), ('(', '('), ('G', 'NNP'), (')', ')'), ('(', '('), ('2', 'CD'), (')', ')'), ('G', 'NNP'), ('', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('(', '('), ('3', 'CD'), (')', ')'), ('=', 'VBD'), ('1', 'CD'), ('n', 'NN'), ('(', '('), ('4', 'CD'), (')', ')'), ('j', 'NN'), ('=', '$'), ('1', 'CD'), ('n', 'NN'), ('(', '('), ('5', 'CD'), (')', ')'), ('', 'NN'), ('j', 'NN'), ('(', '('), ('6', 'CD'), (')', ')'), ('edge', 'NN'), ('nodes', 'NNS'), ('j', 'VBP'), ('G', 'NNP'), ('.', '.')]

 (S
  (/(
  1/CD
  )/)
  (NP Evaluate/NNP score/NN G/NNP)
  :/:
  (NP Score/NN)
  (/(
  (NP G/NNP)
  )/)
  (/(
  2/CD
  )/)
  (NP G/NNP /NNP =/NNP G/NNP)
  (/(
  3/CD
  )/)
  =/VBD
  1/CD
  (NP n/NN)
  (/(
  4/CD
  )/)
  (NP j/NN)
  =/$
  1/CD
  (NP n/NN)
  (/(
  5/CD
  )/)
  (NP /NN j/NN)
  (/(
  6/CD
  )/)
  (NP edge/NN nodes/NNS)
  j/VBP
  (NP G/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Evaluate score G', 'Score', 'G', 'G  = G', 'n', 'j', 'n', ' j', 'edge nodes', 'G']

>> Named Entities are: 
 [('ORGANIZATION', 'Evaluate')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Evaluate', 'evalu'), ('score', 'score'), ('G', 'g'), (':', ':'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), ('(', '('), ('2', '2'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('(', '('), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('(', '('), ('6', '6'), (')', ')'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Evaluate', 'evalu'), ('score', 'score'), ('G', 'g'), (':', ':'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), ('(', '('), ('2', '2'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('(', '('), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('(', '('), ('6', '6'), (')', ')'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1', '1'), (')', ')'), ('Evaluate', 'Evaluate'), ('score', 'score'), ('G', 'G'), (':', ':'), ('Score', 'Score'), ('(', '('), ('G', 'G'), (')', ')'), ('(', '('), ('2', '2'), (')', ')'), ('G', 'G'), ('', ''), ('=', '='), ('G', 'G'), ('(', '('), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('(', '('), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('(', '('), ('6', '6'), (')', ')'), ('edge', 'edge'), ('nodes', 'node'), ('j', 'j'), ('G', 'G'), ('.', '.')]



============================ Sentence 181 =============================

(7) Modify G by adding an edge between the nodes i and j in G such that i is a   parent of j: (i  j)    (8) if the resulting G is a DAG then (9) if (Score(G) > Score (G)) then (10) G = G (11) end if (12) end if (13) end if (14) end if (15) G = G (16) end for  (17) end for  f(x)   http://scikit-learn.org/stable/modules/svm.html#svm-classification http://scikit-learn.org/stable/modules/svm.html#svm-regression http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection   ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03   951   will be classified. 


>> Tokens are: 
 ['(', '7', ')', 'Modify', 'G', '', 'adding', 'edge', 'nodes', 'j', 'G', 'parent', 'j', ':', '(', '', 'j', ')', '(', '8', ')', 'resulting', 'G', '', 'DAG', '(', '9', ')', '(', 'Score', '(', 'G', '', ')', '>', 'Score', '(', 'G', ')', ')', '(', '10', ')', 'G', '=', 'G', '', '(', '11', ')', 'end', '(', '12', ')', 'end', '(', '13', ')', 'end', '(', '14', ')', 'end', '(', '15', ')', 'G', '', '=', 'G', '(', '16', ')', 'end', '(', '17', ')', 'end', 'f', '(', 'x', ')', 'http', ':', '//scikit-learn.org/stable/modules/svm.html', '#', 'svm-classification', 'http', ':', '//scikit-learn.org/stable/modules/svm.html', '#', 'svm-regression', 'http', ':', '//scikit-learn.org/stable/modules/svm.html', '#', 'svm-outlier-detection', 'ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03', '951', 'classified', '.']

>> Bigrams are: 
 [('(', '7'), ('7', ')'), (')', 'Modify'), ('Modify', 'G'), ('G', ''), ('', 'adding'), ('adding', 'edge'), ('edge', 'nodes'), ('nodes', 'j'), ('j', 'G'), ('G', 'parent'), ('parent', 'j'), ('j', ':'), (':', '('), ('(', ''), ('', 'j'), ('j', ')'), (')', '('), ('(', '8'), ('8', ')'), (')', 'resulting'), ('resulting', 'G'), ('G', ''), ('', 'DAG'), ('DAG', '('), ('(', '9'), ('9', ')'), (')', '('), ('(', 'Score'), ('Score', '('), ('(', 'G'), ('G', ''), ('', ')'), (')', '>'), ('>', 'Score'), ('Score', '('), ('(', 'G'), ('G', ')'), (')', ')'), (')', '('), ('(', '10'), ('10', ')'), (')', 'G'), ('G', '='), ('=', 'G'), ('G', ''), ('', '('), ('(', '11'), ('11', ')'), (')', 'end'), ('end', '('), ('(', '12'), ('12', ')'), (')', 'end'), ('end', '('), ('(', '13'), ('13', ')'), (')', 'end'), ('end', '('), ('(', '14'), ('14', ')'), (')', 'end'), ('end', '('), ('(', '15'), ('15', ')'), (')', 'G'), ('G', ''), ('', '='), ('=', 'G'), ('G', '('), ('(', '16'), ('16', ')'), (')', 'end'), ('end', '('), ('(', '17'), ('17', ')'), (')', 'end'), ('end', 'f'), ('f', '('), ('(', 'x'), ('x', ')'), (')', 'http'), ('http', ':'), (':', '//scikit-learn.org/stable/modules/svm.html'), ('//scikit-learn.org/stable/modules/svm.html', '#'), ('#', 'svm-classification'), ('svm-classification', 'http'), ('http', ':'), (':', '//scikit-learn.org/stable/modules/svm.html'), ('//scikit-learn.org/stable/modules/svm.html', '#'), ('#', 'svm-regression'), ('svm-regression', 'http'), ('http', ':'), (':', '//scikit-learn.org/stable/modules/svm.html'), ('//scikit-learn.org/stable/modules/svm.html', '#'), ('#', 'svm-outlier-detection'), ('svm-outlier-detection', 'ISSN'), ('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03'), ('03', '951'), ('951', 'classified'), ('classified', '.')]

>> Trigrams are: 
 [('(', '7', ')'), ('7', ')', 'Modify'), (')', 'Modify', 'G'), ('Modify', 'G', ''), ('G', '', 'adding'), ('', 'adding', 'edge'), ('adding', 'edge', 'nodes'), ('edge', 'nodes', 'j'), ('nodes', 'j', 'G'), ('j', 'G', 'parent'), ('G', 'parent', 'j'), ('parent', 'j', ':'), ('j', ':', '('), (':', '(', ''), ('(', '', 'j'), ('', 'j', ')'), ('j', ')', '('), (')', '(', '8'), ('(', '8', ')'), ('8', ')', 'resulting'), (')', 'resulting', 'G'), ('resulting', 'G', ''), ('G', '', 'DAG'), ('', 'DAG', '('), ('DAG', '(', '9'), ('(', '9', ')'), ('9', ')', '('), (')', '(', 'Score'), ('(', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ''), ('G', '', ')'), ('', ')', '>'), (')', '>', 'Score'), ('>', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ')'), ('G', ')', ')'), (')', ')', '('), (')', '(', '10'), ('(', '10', ')'), ('10', ')', 'G'), (')', 'G', '='), ('G', '=', 'G'), ('=', 'G', ''), ('G', '', '('), ('', '(', '11'), ('(', '11', ')'), ('11', ')', 'end'), (')', 'end', '('), ('end', '(', '12'), ('(', '12', ')'), ('12', ')', 'end'), (')', 'end', '('), ('end', '(', '13'), ('(', '13', ')'), ('13', ')', 'end'), (')', 'end', '('), ('end', '(', '14'), ('(', '14', ')'), ('14', ')', 'end'), (')', 'end', '('), ('end', '(', '15'), ('(', '15', ')'), ('15', ')', 'G'), (')', 'G', ''), ('G', '', '='), ('', '=', 'G'), ('=', 'G', '('), ('G', '(', '16'), ('(', '16', ')'), ('16', ')', 'end'), (')', 'end', '('), ('end', '(', '17'), ('(', '17', ')'), ('17', ')', 'end'), (')', 'end', 'f'), ('end', 'f', '('), ('f', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'http'), (')', 'http', ':'), ('http', ':', '//scikit-learn.org/stable/modules/svm.html'), (':', '//scikit-learn.org/stable/modules/svm.html', '#'), ('//scikit-learn.org/stable/modules/svm.html', '#', 'svm-classification'), ('#', 'svm-classification', 'http'), ('svm-classification', 'http', ':'), ('http', ':', '//scikit-learn.org/stable/modules/svm.html'), (':', '//scikit-learn.org/stable/modules/svm.html', '#'), ('//scikit-learn.org/stable/modules/svm.html', '#', 'svm-regression'), ('#', 'svm-regression', 'http'), ('svm-regression', 'http', ':'), ('http', ':', '//scikit-learn.org/stable/modules/svm.html'), (':', '//scikit-learn.org/stable/modules/svm.html', '#'), ('//scikit-learn.org/stable/modules/svm.html', '#', 'svm-outlier-detection'), ('#', 'svm-outlier-detection', 'ISSN'), ('svm-outlier-detection', 'ISSN', ':'), ('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03'), (':', '03', '951'), ('03', '951', 'classified'), ('951', 'classified', '.')]

>> POS Tags are: 
 [('(', '('), ('7', 'CD'), (')', ')'), ('Modify', 'NNP'), ('G', 'NNP'), ('', 'NNP'), ('adding', 'VBG'), ('edge', 'NN'), ('nodes', 'NNS'), ('j', 'VBP'), ('G', 'NNP'), ('parent', 'NN'), ('j', 'NN'), (':', ':'), ('(', '('), ('', 'NNP'), ('j', 'NN'), (')', ')'), ('(', '('), ('8', 'CD'), (')', ')'), ('resulting', 'VBG'), ('G', 'NNP'), ('', 'NNP'), ('DAG', 'NNP'), ('(', '('), ('9', 'CD'), (')', ')'), ('(', '('), ('Score', 'NNP'), ('(', '('), ('G', 'NNP'), ('', 'NNP'), (')', ')'), ('>', 'VBZ'), ('Score', 'NNP'), ('(', '('), ('G', 'NNP'), (')', ')'), (')', ')'), ('(', '('), ('10', 'CD'), (')', ')'), ('G', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('', 'NNP'), ('(', '('), ('11', 'CD'), (')', ')'), ('end', 'NN'), ('(', '('), ('12', 'CD'), (')', ')'), ('end', 'NN'), ('(', '('), ('13', 'CD'), (')', ')'), ('end', 'NN'), ('(', '('), ('14', 'CD'), (')', ')'), ('end', 'NN'), ('(', '('), ('15', 'CD'), (')', ')'), ('G', 'NNP'), ('', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('(', '('), ('16', 'CD'), (')', ')'), ('end', 'NN'), ('(', '('), ('17', 'CD'), (')', ')'), ('end', 'NN'), ('f', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('http', 'NN'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', 'JJ'), ('#', '#'), ('svm-classification', 'NN'), ('http', 'NN'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', 'JJ'), ('#', '#'), ('svm-regression', 'NN'), ('http', 'NN'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', 'JJ'), ('#', '#'), ('svm-outlier-detection', 'NN'), ('ISSN', 'NN'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD'), ('951', 'CD'), ('classified', 'NNS'), ('.', '.')]

 (S
  (/(
  7/CD
  )/)
  (NP Modify/NNP G/NNP /NNP)
  adding/VBG
  (NP edge/NN nodes/NNS)
  j/VBP
  (NP G/NNP parent/NN j/NN)
  :/:
  (/(
  (NP /NNP j/NN)
  )/)
  (/(
  8/CD
  )/)
  resulting/VBG
  (NP G/NNP /NNP DAG/NNP)
  (/(
  9/CD
  )/)
  (/(
  (NP Score/NNP)
  (/(
  (NP G/NNP /NNP)
  )/)
  >/VBZ
  (NP Score/NNP)
  (/(
  (NP G/NNP)
  )/)
  )/)
  (/(
  10/CD
  )/)
  (NP G/NNP =/NNP G/NNP /NNP)
  (/(
  11/CD
  )/)
  (NP end/NN)
  (/(
  12/CD
  )/)
  (NP end/NN)
  (/(
  13/CD
  )/)
  (NP end/NN)
  (/(
  14/CD
  )/)
  (NP end/NN)
  (/(
  15/CD
  )/)
  (NP G/NNP /NNP =/NNP G/NNP)
  (/(
  16/CD
  )/)
  (NP end/NN)
  (/(
  17/CD
  )/)
  (NP end/NN f/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP http/NN)
  :/:
  //scikit-learn.org/stable/modules/svm.html/JJ
  #/#
  (NP svm-classification/NN http/NN)
  :/:
  //scikit-learn.org/stable/modules/svm.html/JJ
  #/#
  (NP svm-regression/NN http/NN)
  :/:
  //scikit-learn.org/stable/modules/svm.html/JJ
  #/#
  (NP svm-outlier-detection/NN ISSN/NN)
  :/:
  2229-6956/JJ
  (/(
  (NP ONLINE/NNP)
  )/)
  (NP ICTACT/NNP JOURNAL/NNP ON/NNP SOFT/NNP COMPUTING/NNP)
  ,/,
  (NP APRIL/NNP)
  2015/CD
  ,/,
  (NP VOLUME/NNP)
  :/:
  05/CD
  ,/,
  (NP ISSUE/NNP)
  :/:
  03/CD
  951/CD
  (NP classified/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Modify G ', 'edge nodes', 'G parent j', ' j', 'G  DAG', 'Score', 'G ', 'Score', 'G', 'G = G ', 'end', 'end', 'end', 'end', 'G  = G', 'end', 'end f', 'x', 'http', 'svm-classification http', 'svm-regression http', 'svm-outlier-detection ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE', 'classified']

>> Named Entities are: 
 [('PERSON', 'Modify G'), ('PERSON', 'G'), ('GPE', 'Score'), ('GPE', 'Score'), ('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('7', '7'), (')', ')'), ('Modify', 'modifi'), ('G', 'g'), ('', ''), ('adding', 'ad'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g'), ('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('resulting', 'result'), ('G', 'g'), ('', ''), ('DAG', 'dag'), ('(', '('), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'score'), ('(', '('), ('G', 'g'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), (')', ')'), ('(', '('), ('10', '10'), (')', ')'), ('G', 'g'), ('=', '='), ('G', 'g'), ('', ''), ('(', '('), ('11', '11'), (')', ')'), ('end', 'end'), ('(', '('), ('12', '12'), (')', ')'), ('end', 'end'), ('(', '('), ('13', '13'), (')', ')'), ('end', 'end'), ('(', '('), ('14', '14'), (')', ')'), ('end', 'end'), ('(', '('), ('15', '15'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('(', '('), ('16', '16'), (')', ')'), ('end', 'end'), ('(', '('), ('17', '17'), (')', ')'), ('end', 'end'), ('f', 'f'), ('(', '('), ('x', 'x'), (')', ')'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-classification', 'svm-classif'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-regression', 'svm-regress'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-outlier-detection', 'svm-outlier-detect'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('951', '951'), ('classified', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('7', '7'), (')', ')'), ('Modify', 'modifi'), ('G', 'g'), ('', ''), ('adding', 'ad'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g'), ('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('resulting', 'result'), ('G', 'g'), ('', ''), ('DAG', 'dag'), ('(', '('), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'score'), ('(', '('), ('G', 'g'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), (')', ')'), ('(', '('), ('10', '10'), (')', ')'), ('G', 'g'), ('=', '='), ('G', 'g'), ('', ''), ('(', '('), ('11', '11'), (')', ')'), ('end', 'end'), ('(', '('), ('12', '12'), (')', ')'), ('end', 'end'), ('(', '('), ('13', '13'), (')', ')'), ('end', 'end'), ('(', '('), ('14', '14'), (')', ')'), ('end', 'end'), ('(', '('), ('15', '15'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('(', '('), ('16', '16'), (')', ')'), ('end', 'end'), ('(', '('), ('17', '17'), (')', ')'), ('end', 'end'), ('f', 'f'), ('(', '('), ('x', 'x'), (')', ')'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-classification', 'svm-classif'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-regression', 'svm-regress'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-outlier-detection', 'svm-outlier-detect'), ('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03'), ('951', '951'), ('classified', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('7', '7'), (')', ')'), ('Modify', 'Modify'), ('G', 'G'), ('', ''), ('adding', 'adding'), ('edge', 'edge'), ('nodes', 'node'), ('j', 'j'), ('G', 'G'), ('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('resulting', 'resulting'), ('G', 'G'), ('', ''), ('DAG', 'DAG'), ('(', '('), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'Score'), ('(', '('), ('G', 'G'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'Score'), ('(', '('), ('G', 'G'), (')', ')'), (')', ')'), ('(', '('), ('10', '10'), (')', ')'), ('G', 'G'), ('=', '='), ('G', 'G'), ('', ''), ('(', '('), ('11', '11'), (')', ')'), ('end', 'end'), ('(', '('), ('12', '12'), (')', ')'), ('end', 'end'), ('(', '('), ('13', '13'), (')', ')'), ('end', 'end'), ('(', '('), ('14', '14'), (')', ')'), ('end', 'end'), ('(', '('), ('15', '15'), (')', ')'), ('G', 'G'), ('', ''), ('=', '='), ('G', 'G'), ('(', '('), ('16', '16'), (')', ')'), ('end', 'end'), ('(', '('), ('17', '17'), (')', ')'), ('end', 'end'), ('f', 'f'), ('(', '('), ('x', 'x'), (')', ')'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-classification', 'svm-classification'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-regression', 'svm-regression'), ('http', 'http'), (':', ':'), ('//scikit-learn.org/stable/modules/svm.html', '//scikit-learn.org/stable/modules/svm.html'), ('#', '#'), ('svm-outlier-detection', 'svm-outlier-detection'), ('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03'), ('951', '951'), ('classified', 'classified'), ('.', '.')]



============================ Sentence 182 =============================

Some new kernels are being proposed by   researchers but given bellow is list of some popular kernels:    Linear:   j T iji XXXXK ,     Polynomial:     0,,   djTiji rXXXXK    Radial Basis Function (RBF):     0,exp, 2            jiji XXXXK     Sigmoid:    rXXXXK jTiji  tanh,   Here dr  and ,  are the kernel parameters. 


>> Tokens are: 
 ['Some', 'new', 'kernels', 'proposed', 'researchers', 'given', 'bellow', 'list', 'popular', 'kernels', ':', '\uf0b7', 'Linear', ':', '\uf028', '\uf029', 'j', 'T', 'iji', 'XXXXK', '\uf03d', ',', '\uf0b7', 'Polynomial', ':', '\uf028', '\uf029', '\uf028', '\uf029', '0', ',', ',', '\uf03e\uf02b\uf03d', '\uf067\uf067', 'djTiji', 'rXXXXK', '\uf0b7', 'Radial', 'Basis', 'Function', '(', 'RBF', ')', ':', '\uf028', '\uf029', '0', ',', 'exp', ',', '2', '\uf03e\uf0f7', '\uf0f8', '\uf0f6', '\uf0e7', '\uf0e8', '\uf0e6', '\uf02d\uf02d\uf03d', '\uf067\uf067', 'jiji', 'XXXXK', '\uf0b7', 'Sigmoid', ':', '\uf028', '\uf029', '\uf028', '\uf029rXXXXK', 'jTiji', '\uf02b\uf03d', '\uf067tanh', ',', 'Here', 'dr', ',', '\uf067', 'kernel', 'parameters', '.']

>> Bigrams are: 
 [('Some', 'new'), ('new', 'kernels'), ('kernels', 'proposed'), ('proposed', 'researchers'), ('researchers', 'given'), ('given', 'bellow'), ('bellow', 'list'), ('list', 'popular'), ('popular', 'kernels'), ('kernels', ':'), (':', '\uf0b7'), ('\uf0b7', 'Linear'), ('Linear', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', 'j'), ('j', 'T'), ('T', 'iji'), ('iji', 'XXXXK'), ('XXXXK', '\uf03d'), ('\uf03d', ','), (',', '\uf0b7'), ('\uf0b7', 'Polynomial'), ('Polynomial', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '0'), ('0', ','), (',', ','), (',', '\uf03e\uf02b\uf03d'), ('\uf03e\uf02b\uf03d', '\uf067\uf067'), ('\uf067\uf067', 'djTiji'), ('djTiji', 'rXXXXK'), ('rXXXXK', '\uf0b7'), ('\uf0b7', 'Radial'), ('Radial', 'Basis'), ('Basis', 'Function'), ('Function', '('), ('(', 'RBF'), ('RBF', ')'), (')', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '0'), ('0', ','), (',', 'exp'), ('exp', ','), (',', '2'), ('2', '\uf03e\uf0f7'), ('\uf03e\uf0f7', '\uf0f8'), ('\uf0f8', '\uf0f6'), ('\uf0f6', '\uf0e7'), ('\uf0e7', '\uf0e8'), ('\uf0e8', '\uf0e6'), ('\uf0e6', '\uf02d\uf02d\uf03d'), ('\uf02d\uf02d\uf03d', '\uf067\uf067'), ('\uf067\uf067', 'jiji'), ('jiji', 'XXXXK'), ('XXXXK', '\uf0b7'), ('\uf0b7', 'Sigmoid'), ('Sigmoid', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029rXXXXK'), ('\uf029rXXXXK', 'jTiji'), ('jTiji', '\uf02b\uf03d'), ('\uf02b\uf03d', '\uf067tanh'), ('\uf067tanh', ','), (',', 'Here'), ('Here', 'dr'), ('dr', ','), (',', '\uf067'), ('\uf067', 'kernel'), ('kernel', 'parameters'), ('parameters', '.')]

>> Trigrams are: 
 [('Some', 'new', 'kernels'), ('new', 'kernels', 'proposed'), ('kernels', 'proposed', 'researchers'), ('proposed', 'researchers', 'given'), ('researchers', 'given', 'bellow'), ('given', 'bellow', 'list'), ('bellow', 'list', 'popular'), ('list', 'popular', 'kernels'), ('popular', 'kernels', ':'), ('kernels', ':', '\uf0b7'), (':', '\uf0b7', 'Linear'), ('\uf0b7', 'Linear', ':'), ('Linear', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', 'j'), ('\uf029', 'j', 'T'), ('j', 'T', 'iji'), ('T', 'iji', 'XXXXK'), ('iji', 'XXXXK', '\uf03d'), ('XXXXK', '\uf03d', ','), ('\uf03d', ',', '\uf0b7'), (',', '\uf0b7', 'Polynomial'), ('\uf0b7', 'Polynomial', ':'), ('Polynomial', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '0'), ('\uf029', '0', ','), ('0', ',', ','), (',', ',', '\uf03e\uf02b\uf03d'), (',', '\uf03e\uf02b\uf03d', '\uf067\uf067'), ('\uf03e\uf02b\uf03d', '\uf067\uf067', 'djTiji'), ('\uf067\uf067', 'djTiji', 'rXXXXK'), ('djTiji', 'rXXXXK', '\uf0b7'), ('rXXXXK', '\uf0b7', 'Radial'), ('\uf0b7', 'Radial', 'Basis'), ('Radial', 'Basis', 'Function'), ('Basis', 'Function', '('), ('Function', '(', 'RBF'), ('(', 'RBF', ')'), ('RBF', ')', ':'), (')', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '0'), ('\uf029', '0', ','), ('0', ',', 'exp'), (',', 'exp', ','), ('exp', ',', '2'), (',', '2', '\uf03e\uf0f7'), ('2', '\uf03e\uf0f7', '\uf0f8'), ('\uf03e\uf0f7', '\uf0f8', '\uf0f6'), ('\uf0f8', '\uf0f6', '\uf0e7'), ('\uf0f6', '\uf0e7', '\uf0e8'), ('\uf0e7', '\uf0e8', '\uf0e6'), ('\uf0e8', '\uf0e6', '\uf02d\uf02d\uf03d'), ('\uf0e6', '\uf02d\uf02d\uf03d', '\uf067\uf067'), ('\uf02d\uf02d\uf03d', '\uf067\uf067', 'jiji'), ('\uf067\uf067', 'jiji', 'XXXXK'), ('jiji', 'XXXXK', '\uf0b7'), ('XXXXK', '\uf0b7', 'Sigmoid'), ('\uf0b7', 'Sigmoid', ':'), ('Sigmoid', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029rXXXXK'), ('\uf028', '\uf029rXXXXK', 'jTiji'), ('\uf029rXXXXK', 'jTiji', '\uf02b\uf03d'), ('jTiji', '\uf02b\uf03d', '\uf067tanh'), ('\uf02b\uf03d', '\uf067tanh', ','), ('\uf067tanh', ',', 'Here'), (',', 'Here', 'dr'), ('Here', 'dr', ','), ('dr', ',', '\uf067'), (',', '\uf067', 'kernel'), ('\uf067', 'kernel', 'parameters'), ('kernel', 'parameters', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('new', 'JJ'), ('kernels', 'NNS'), ('proposed', 'VBN'), ('researchers', 'NNS'), ('given', 'VBN'), ('bellow', 'JJ'), ('list', 'NN'), ('popular', 'JJ'), ('kernels', 'NNS'), (':', ':'), ('\uf0b7', 'JJ'), ('Linear', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('j', 'NN'), ('T', 'NNP'), ('iji', 'NN'), ('XXXXK', 'NNP'), ('\uf03d', 'NNP'), (',', ','), ('\uf0b7', 'NNP'), ('Polynomial', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('0', 'CD'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', 'NNP'), ('\uf067\uf067', 'NNP'), ('djTiji', 'NN'), ('rXXXXK', 'NN'), ('\uf0b7', 'NNP'), ('Radial', 'NNP'), ('Basis', 'NNP'), ('Function', 'NNP'), ('(', '('), ('RBF', 'NNP'), (')', ')'), (':', ':'), ('\uf028', 'JJ'), ('\uf029', 'NN'), ('0', 'CD'), (',', ','), ('exp', 'NN'), (',', ','), ('2', 'CD'), ('\uf03e\uf0f7', 'NN'), ('\uf0f8', 'NNP'), ('\uf0f6', 'NNP'), ('\uf0e7', 'NNP'), ('\uf0e8', 'NNP'), ('\uf0e6', 'NNP'), ('\uf02d\uf02d\uf03d', 'NNP'), ('\uf067\uf067', 'NNP'), ('jiji', 'NN'), ('XXXXK', 'NNP'), ('\uf0b7', 'NNP'), ('Sigmoid', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029rXXXXK', 'NNP'), ('jTiji', 'NN'), ('\uf02b\uf03d', 'NNP'), ('\uf067tanh', 'NNP'), (',', ','), ('Here', 'RB'), ('dr', 'NN'), (',', ','), ('\uf067', 'NNP'), ('kernel', 'NN'), ('parameters', 'NNS'), ('.', '.')]

 (S
  (NP Some/DT new/JJ kernels/NNS)
  proposed/VBN
  (NP researchers/NNS)
  given/VBN
  (NP bellow/JJ list/NN)
  (NP popular/JJ kernels/NNS)
  :/:
  (NP /JJ Linear/NNP)
  :/:
  (NP /NN /NNP j/NN T/NNP iji/NN XXXXK/NNP /NNP)
  ,/,
  (NP /NNP Polynomial/NNP)
  :/:
  (NP /NN /NNP /NNP /NNP)
  0/CD
  ,/,
  ,/,
  (NP
    /NNP
    /NNP
    djTiji/NN
    rXXXXK/NN
    /NNP
    Radial/NNP
    Basis/NNP
    Function/NNP)
  (/(
  (NP RBF/NNP)
  )/)
  :/:
  (NP /JJ /NN)
  0/CD
  ,/,
  (NP exp/NN)
  ,/,
  2/CD
  (NP
    /NN
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    /NNP
    jiji/NN
    XXXXK/NNP
    /NNP
    Sigmoid/NNP)
  :/:
  (NP /NN /NNP /NNP rXXXXK/NNP jTiji/NN /NNP tanh/NNP)
  ,/,
  Here/RB
  (NP dr/NN)
  ,/,
  (NP /NNP kernel/NN parameters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Some new kernels', 'researchers', 'bellow list', 'popular kernels', '\uf0b7 Linear', '\uf028 \uf029 j T iji XXXXK \uf03d', '\uf0b7 Polynomial', '\uf028 \uf029 \uf028 \uf029', '\uf03e\uf02b\uf03d \uf067\uf067 djTiji rXXXXK \uf0b7 Radial Basis Function', 'RBF', '\uf028 \uf029', 'exp', '\uf03e\uf0f7 \uf0f8 \uf0f6 \uf0e7 \uf0e8 \uf0e6 \uf02d\uf02d\uf03d \uf067\uf067 jiji XXXXK \uf0b7 Sigmoid', '\uf028 \uf029 \uf028 \uf029rXXXXK jTiji \uf02b\uf03d \uf067tanh', 'dr', '\uf067 kernel parameters']

>> Named Entities are: 
 [('ORGANIZATION', 'XXXXK'), ('ORGANIZATION', 'rXXXXK'), ('ORGANIZATION', 'RBF'), ('ORGANIZATION', 'XXXXK')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'propos'), ('researchers', 'research'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Linear', 'linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 't'), ('iji', 'iji'), ('XXXXK', 'xxxxk'), ('\uf03d', '\uf03d'), (',', ','), ('\uf0b7', '\uf0b7'), ('Polynomial', 'polynomi'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djtiji'), ('rXXXXK', 'rxxxxk'), ('\uf0b7', '\uf0b7'), ('Radial', 'radial'), ('Basis', 'basi'), ('Function', 'function'), ('(', '('), ('RBF', 'rbf'), (')', ')'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2'), ('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8'), ('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8'), ('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'xxxxk'), ('\uf0b7', '\uf0b7'), ('Sigmoid', 'sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rxxxxk'), ('jTiji', 'jtiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'paramet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'propos'), ('researchers', 'research'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Linear', 'linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 't'), ('iji', 'iji'), ('XXXXK', 'xxxxk'), ('\uf03d', '\uf03d'), (',', ','), ('\uf0b7', '\uf0b7'), ('Polynomial', 'polynomi'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djtiji'), ('rXXXXK', 'rxxxxk'), ('\uf0b7', '\uf0b7'), ('Radial', 'radial'), ('Basis', 'basi'), ('Function', 'function'), ('(', '('), ('RBF', 'rbf'), (')', ')'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2'), ('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8'), ('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8'), ('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'xxxxk'), ('\uf0b7', '\uf0b7'), ('Sigmoid', 'sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rxxxxk'), ('jTiji', 'jtiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'paramet'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'proposed'), ('researchers', 'researcher'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':'), ('\uf0b7', '\uf0b7'), ('Linear', 'Linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 'T'), ('iji', 'iji'), ('XXXXK', 'XXXXK'), ('\uf03d', '\uf03d'), (',', ','), ('\uf0b7', '\uf0b7'), ('Polynomial', 'Polynomial'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djTiji'), ('rXXXXK', 'rXXXXK'), ('\uf0b7', '\uf0b7'), ('Radial', 'Radial'), ('Basis', 'Basis'), ('Function', 'Function'), ('(', '('), ('RBF', 'RBF'), (')', ')'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2'), ('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8'), ('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8'), ('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'XXXXK'), ('\uf0b7', '\uf0b7'), ('Sigmoid', 'Sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rXXXXK'), ('jTiji', 'jTiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'Here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'parameter'), ('.', '.')]



============================ Sentence 183 =============================

Where, iX is a   training vector and mapped into a high dimensional space by the  function  and    jji XXXK ,  is known as kernel function. 


>> Tokens are: 
 ['Where', ',', 'iX', 'training', 'vector', 'mapped', 'high', 'dimensional', 'space', 'function', '\uf066', '\uf028', '\uf029', '\uf028', '\uf029jji', 'XXXK', '\uf066\uf0ba', ',', 'known', 'kernel', 'function', '.']

>> Bigrams are: 
 [('Where', ','), (',', 'iX'), ('iX', 'training'), ('training', 'vector'), ('vector', 'mapped'), ('mapped', 'high'), ('high', 'dimensional'), ('dimensional', 'space'), ('space', 'function'), ('function', '\uf066'), ('\uf066', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029jji'), ('\uf029jji', 'XXXK'), ('XXXK', '\uf066\uf0ba'), ('\uf066\uf0ba', ','), (',', 'known'), ('known', 'kernel'), ('kernel', 'function'), ('function', '.')]

>> Trigrams are: 
 [('Where', ',', 'iX'), (',', 'iX', 'training'), ('iX', 'training', 'vector'), ('training', 'vector', 'mapped'), ('vector', 'mapped', 'high'), ('mapped', 'high', 'dimensional'), ('high', 'dimensional', 'space'), ('dimensional', 'space', 'function'), ('space', 'function', '\uf066'), ('function', '\uf066', '\uf028'), ('\uf066', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029jji'), ('\uf028', '\uf029jji', 'XXXK'), ('\uf029jji', 'XXXK', '\uf066\uf0ba'), ('XXXK', '\uf066\uf0ba', ','), ('\uf066\uf0ba', ',', 'known'), (',', 'known', 'kernel'), ('known', 'kernel', 'function'), ('kernel', 'function', '.')]

>> POS Tags are: 
 [('Where', 'WRB'), (',', ','), ('iX', 'VB'), ('training', 'VBG'), ('vector', 'NN'), ('mapped', 'VBD'), ('high', 'JJ'), ('dimensional', 'JJ'), ('space', 'NN'), ('function', 'NN'), ('\uf066', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029jji', 'NNP'), ('XXXK', 'NNP'), ('\uf066\uf0ba', 'NNP'), (',', ','), ('known', 'VBN'), ('kernel', 'NN'), ('function', 'NN'), ('.', '.')]

 (S
  Where/WRB
  ,/,
  iX/VB
  training/VBG
  (NP vector/NN)
  mapped/VBD
  (NP
    high/JJ
    dimensional/JJ
    space/NN
    function/NN
    /NNP
    /NNP
    /NNP
    /NNP
    jji/NNP
    XXXK/NNP
    /NNP)
  ,/,
  known/VBN
  (NP kernel/NN function/NN)
  ./.) 


>> Noun Phrases are: 
 ['vector', 'high dimensional space function \uf066 \uf028 \uf029 \uf028 \uf029jji XXXK \uf066\uf0ba', 'kernel function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), (',', ','), ('iX', 'ix'), ('training', 'train'), ('vector', 'vector'), ('mapped', 'map'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'xxxk'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), (',', ','), ('iX', 'ix'), ('training', 'train'), ('vector', 'vector'), ('mapped', 'map'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'xxxk'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('Where', 'Where'), (',', ','), ('iX', 'iX'), ('training', 'training'), ('vector', 'vector'), ('mapped', 'mapped'), ('high', 'high'), ('dimensional', 'dimensional'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'XXXK'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]



============================ Sentence 184 =============================

7. 


>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

 (S 7/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]



============================ Sentence 185 =============================

DEEP LEARNING    The use of deep artificial neural networks has gain popularity   for the last few years in pattern recognition and machine   learning. 


>> Tokens are: 
 ['DEEP', 'LEARNING', 'The', 'use', 'deep', 'artificial', 'neural', 'networks', 'gain', 'popularity', 'last', 'years', 'pattern', 'recognition', 'machine', 'learning', '.']

>> Bigrams are: 
 [('DEEP', 'LEARNING'), ('LEARNING', 'The'), ('The', 'use'), ('use', 'deep'), ('deep', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'gain'), ('gain', 'popularity'), ('popularity', 'last'), ('last', 'years'), ('years', 'pattern'), ('pattern', 'recognition'), ('recognition', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('DEEP', 'LEARNING', 'The'), ('LEARNING', 'The', 'use'), ('The', 'use', 'deep'), ('use', 'deep', 'artificial'), ('deep', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'gain'), ('networks', 'gain', 'popularity'), ('gain', 'popularity', 'last'), ('popularity', 'last', 'years'), ('last', 'years', 'pattern'), ('years', 'pattern', 'recognition'), ('pattern', 'recognition', 'machine'), ('recognition', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('DEEP', 'NNP'), ('LEARNING', 'NNP'), ('The', 'DT'), ('use', 'NN'), ('deep', 'JJ'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('gain', 'VBP'), ('popularity', 'NN'), ('last', 'JJ'), ('years', 'NNS'), ('pattern', 'JJ'), ('recognition', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP DEEP/NNP LEARNING/NNP)
  (NP The/DT use/NN)
  (NP deep/JJ artificial/JJ neural/JJ networks/NNS)
  gain/VBP
  (NP popularity/NN)
  (NP last/JJ years/NNS)
  (NP pattern/JJ recognition/NN machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['DEEP LEARNING', 'The use', 'deep artificial neural networks', 'popularity', 'last years', 'pattern recognition machine learning']

>> Named Entities are: 
 [('ORGANIZATION', 'DEEP')] 

>> Stemming using Porter Stemmer: 
 [('DEEP', 'deep'), ('LEARNING', 'learn'), ('The', 'the'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popular'), ('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('DEEP', 'deep'), ('LEARNING', 'learn'), ('The', 'the'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popular'), ('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('DEEP', 'DEEP'), ('LEARNING', 'LEARNING'), ('The', 'The'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artificial'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popularity'), ('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognition'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 186 =============================

Most of the popular Deep Learning Techniques are   built from Artificial Neural Network (ANN). 


>> Tokens are: 
 ['Most', 'popular', 'Deep', 'Learning', 'Techniques', 'built', 'Artificial', 'Neural', 'Network', '(', 'ANN', ')', '.']

>> Bigrams are: 
 [('Most', 'popular'), ('popular', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Techniques'), ('Techniques', 'built'), ('built', 'Artificial'), ('Artificial', 'Neural'), ('Neural', 'Network'), ('Network', '('), ('(', 'ANN'), ('ANN', ')'), (')', '.')]

>> Trigrams are: 
 [('Most', 'popular', 'Deep'), ('popular', 'Deep', 'Learning'), ('Deep', 'Learning', 'Techniques'), ('Learning', 'Techniques', 'built'), ('Techniques', 'built', 'Artificial'), ('built', 'Artificial', 'Neural'), ('Artificial', 'Neural', 'Network'), ('Neural', 'Network', '('), ('Network', '(', 'ANN'), ('(', 'ANN', ')'), ('ANN', ')', '.')]

>> POS Tags are: 
 [('Most', 'RBS'), ('popular', 'JJ'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Techniques', 'NNP'), ('built', 'VBN'), ('Artificial', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('(', '('), ('ANN', 'NNP'), (')', ')'), ('.', '.')]

 (S
  Most/RBS
  (NP popular/JJ Deep/NNP Learning/NNP Techniques/NNP)
  built/VBN
  (NP Artificial/NNP Neural/NNP Network/NNP)
  (/(
  (NP ANN/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['popular Deep Learning Techniques', 'Artificial Neural Network', 'ANN']

>> Named Entities are: 
 [('PERSON', 'Artificial Neural Network'), ('ORGANIZATION', 'ANN')] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('Deep', 'deep'), ('Learning', 'learn'), ('Techniques', 'techniqu'), ('built', 'built'), ('Artificial', 'artifici'), ('Neural', 'neural'), ('Network', 'network'), ('(', '('), ('ANN', 'ann'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('Deep', 'deep'), ('Learning', 'learn'), ('Techniques', 'techniqu'), ('built', 'built'), ('Artificial', 'artifici'), ('Neural', 'neural'), ('Network', 'network'), ('(', '('), ('ANN', 'ann'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('popular', 'popular'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Techniques', 'Techniques'), ('built', 'built'), ('Artificial', 'Artificial'), ('Neural', 'Neural'), ('Network', 'Network'), ('(', '('), ('ANN', 'ANN'), (')', ')'), ('.', '.')]



============================ Sentence 187 =============================

Deep learning can   be defined as a model (e.g.-.-, neural network) with many layers,   trained in a layer- wise fashion. 


>> Tokens are: 
 ['Deep', 'learning', 'defined', 'model', '(', 'e.g.-.-', ',', 'neural', 'network', ')', 'many', 'layers', ',', 'trained', 'layer-', 'wise', 'fashion', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'defined'), ('defined', 'model'), ('model', '('), ('(', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'neural'), ('neural', 'network'), ('network', ')'), (')', 'many'), ('many', 'layers'), ('layers', ','), (',', 'trained'), ('trained', 'layer-'), ('layer-', 'wise'), ('wise', 'fashion'), ('fashion', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'defined'), ('learning', 'defined', 'model'), ('defined', 'model', '('), ('model', '(', 'e.g.-.-'), ('(', 'e.g.-.-', ','), ('e.g.-.-', ',', 'neural'), (',', 'neural', 'network'), ('neural', 'network', ')'), ('network', ')', 'many'), (')', 'many', 'layers'), ('many', 'layers', ','), ('layers', ',', 'trained'), (',', 'trained', 'layer-'), ('trained', 'layer-', 'wise'), ('layer-', 'wise', 'fashion'), ('wise', 'fashion', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('defined', 'VBD'), ('model', 'NN'), ('(', '('), ('e.g.-.-', 'JJ'), (',', ','), ('neural', 'JJ'), ('network', 'NN'), (')', ')'), ('many', 'JJ'), ('layers', 'NNS'), (',', ','), ('trained', 'VBD'), ('layer-', 'JJ'), ('wise', 'NN'), ('fashion', 'NN'), ('.', '.')]

 (S
  (NP Deep/NNP learning/NN)
  defined/VBD
  (NP model/NN)
  (/(
  e.g.-.-/JJ
  ,/,
  (NP neural/JJ network/NN)
  )/)
  (NP many/JJ layers/NNS)
  ,/,
  trained/VBD
  (NP layer-/JJ wise/NN fashion/NN)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning', 'model', 'neural network', 'many layers', 'layer- wise fashion']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('defined', 'defin'), ('model', 'model'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'mani'), ('layers', 'layer'), (',', ','), ('trained', 'train'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('defined', 'defin'), ('model', 'model'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'mani'), ('layers', 'layer'), (',', ','), ('trained', 'train'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('defined', 'defined'), ('model', 'model'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'many'), ('layers', 'layer'), (',', ','), ('trained', 'trained'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]



============================ Sentence 188 =============================

Deep learning has had a   tremendous impact on various applications such as computer   vision, speech recognition, natural language processing [29], and   crawling deep web [30]. 


>> Tokens are: 
 ['Deep', 'learning', 'tremendous', 'impact', 'various', 'applications', 'computer', 'vision', ',', 'speech', 'recognition', ',', 'natural', 'language', 'processing', '[', '29', ']', ',', 'crawling', 'deep', 'web', '[', '30', ']', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'tremendous'), ('tremendous', 'impact'), ('impact', 'various'), ('various', 'applications'), ('applications', 'computer'), ('computer', 'vision'), ('vision', ','), (',', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', '['), ('[', '29'), ('29', ']'), (']', ','), (',', 'crawling'), ('crawling', 'deep'), ('deep', 'web'), ('web', '['), ('[', '30'), ('30', ']'), (']', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'tremendous'), ('learning', 'tremendous', 'impact'), ('tremendous', 'impact', 'various'), ('impact', 'various', 'applications'), ('various', 'applications', 'computer'), ('applications', 'computer', 'vision'), ('computer', 'vision', ','), ('vision', ',', 'speech'), (',', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'natural'), (',', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', '['), ('processing', '[', '29'), ('[', '29', ']'), ('29', ']', ','), (']', ',', 'crawling'), (',', 'crawling', 'deep'), ('crawling', 'deep', 'web'), ('deep', 'web', '['), ('web', '[', '30'), ('[', '30', ']'), ('30', ']', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'VBG'), ('tremendous', 'JJ'), ('impact', 'NN'), ('various', 'JJ'), ('applications', 'NNS'), ('computer', 'NN'), ('vision', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('[', '$'), ('29', 'CD'), (']', 'NNP'), (',', ','), ('crawling', 'VBG'), ('deep', 'JJ'), ('web', 'NN'), ('[', 'VBD'), ('30', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Deep/NNP)
  learning/VBG
  (NP tremendous/JJ impact/NN)
  (NP various/JJ applications/NNS computer/NN vision/NN)
  ,/,
  (NP speech/NN recognition/NN)
  ,/,
  (NP natural/JJ language/NN processing/NN)
  [/$
  29/CD
  (NP ]/NNP)
  ,/,
  crawling/VBG
  (NP deep/JJ web/NN)
  [/VBD
  30/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Deep', 'tremendous impact', 'various applications computer vision', 'speech recognition', 'natural language processing', ']', 'deep web', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('tremendous', 'tremend'), ('impact', 'impact'), ('various', 'variou'), ('applications', 'applic'), ('computer', 'comput'), ('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('crawling', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('tremendous', 'tremend'), ('impact', 'impact'), ('various', 'various'), ('applications', 'applic'), ('computer', 'comput'), ('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('crawling', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('tremendous', 'tremendous'), ('impact', 'impact'), ('various', 'various'), ('applications', 'application'), ('computer', 'computer'), ('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('crawling', 'crawling'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]



============================ Sentence 189 =============================

Samy et al. 


>> Tokens are: 
 ['Samy', 'et', 'al', '.']

>> Bigrams are: 
 [('Samy', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Samy', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Samy', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Samy/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Samy', 'al']

>> Named Entities are: 
 [('GPE', 'Samy')] 

>> Stemming using Porter Stemmer: 
 [('Samy', 'sami'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Samy', 'sami'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Samy', 'Samy'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 190 =============================

[29] have discussed   challenges and new applications of deep learning in their study. 


>> Tokens are: 
 ['[', '29', ']', 'discussed', 'challenges', 'new', 'applications', 'deep', 'learning', 'study', '.']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'discussed'), ('discussed', 'challenges'), ('challenges', 'new'), ('new', 'applications'), ('applications', 'deep'), ('deep', 'learning'), ('learning', 'study'), ('study', '.')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'discussed'), (']', 'discussed', 'challenges'), ('discussed', 'challenges', 'new'), ('challenges', 'new', 'applications'), ('new', 'applications', 'deep'), ('applications', 'deep', 'learning'), ('deep', 'learning', 'study'), ('learning', 'study', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'NNS'), ('discussed', 'VBN'), ('challenges', 'VBZ'), ('new', 'JJ'), ('applications', 'NNS'), ('deep', 'VBP'), ('learning', 'VBG'), ('study', 'NN'), ('.', '.')]

 (S
  [/RB
  29/CD
  (NP ]/NNS)
  discussed/VBN
  challenges/VBZ
  (NP new/JJ applications/NNS)
  deep/VBP
  learning/VBG
  (NP study/NN)
  ./.) 


>> Noun Phrases are: 
 [']', 'new applications', 'study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discuss'), ('challenges', 'challeng'), ('new', 'new'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discuss'), ('challenges', 'challeng'), ('new', 'new'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discussed'), ('challenges', 'challenge'), ('new', 'new'), ('applications', 'application'), ('deep', 'deep'), ('learning', 'learning'), ('study', 'study'), ('.', '.')]



============================ Sentence 191 =============================

Fig.11. 


>> Tokens are: 
 ['Fig.11', '.']

>> Bigrams are: 
 [('Fig.11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.11', 'NNP'), ('.', '.')]

 (S (NP Fig.11/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig.11']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.11', 'fig.11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.11', 'fig.11'), ('.', '.')]

>> Lemmatization: 
 [('Fig.11', 'Fig.11'), ('.', '.')]



============================ Sentence 192 =============================

Deep network Architecture   The Fig.11 depicts the deep learning network architecture   with one 3-unit input layer, one 2-unit output layer, and two 5-  unit hidden layers. 


>> Tokens are: 
 ['Deep', 'network', 'Architecture', 'The', 'Fig.11', 'depicts', 'deep', 'learning', 'network', 'architecture', 'one', '3-unit', 'input', 'layer', ',', 'one', '2-unit', 'output', 'layer', ',', 'two', '5-', 'unit', 'hidden', 'layers', '.']

>> Bigrams are: 
 [('Deep', 'network'), ('network', 'Architecture'), ('Architecture', 'The'), ('The', 'Fig.11'), ('Fig.11', 'depicts'), ('depicts', 'deep'), ('deep', 'learning'), ('learning', 'network'), ('network', 'architecture'), ('architecture', 'one'), ('one', '3-unit'), ('3-unit', 'input'), ('input', 'layer'), ('layer', ','), (',', 'one'), ('one', '2-unit'), ('2-unit', 'output'), ('output', 'layer'), ('layer', ','), (',', 'two'), ('two', '5-'), ('5-', 'unit'), ('unit', 'hidden'), ('hidden', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('Deep', 'network', 'Architecture'), ('network', 'Architecture', 'The'), ('Architecture', 'The', 'Fig.11'), ('The', 'Fig.11', 'depicts'), ('Fig.11', 'depicts', 'deep'), ('depicts', 'deep', 'learning'), ('deep', 'learning', 'network'), ('learning', 'network', 'architecture'), ('network', 'architecture', 'one'), ('architecture', 'one', '3-unit'), ('one', '3-unit', 'input'), ('3-unit', 'input', 'layer'), ('input', 'layer', ','), ('layer', ',', 'one'), (',', 'one', '2-unit'), ('one', '2-unit', 'output'), ('2-unit', 'output', 'layer'), ('output', 'layer', ','), ('layer', ',', 'two'), (',', 'two', '5-'), ('two', '5-', 'unit'), ('5-', 'unit', 'hidden'), ('unit', 'hidden', 'layers'), ('hidden', 'layers', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('network', 'NN'), ('Architecture', 'NNP'), ('The', 'DT'), ('Fig.11', 'NNP'), ('depicts', 'VBZ'), ('deep', 'JJ'), ('learning', 'NN'), ('network', 'NN'), ('architecture', 'NN'), ('one', 'CD'), ('3-unit', 'JJ'), ('input', 'NN'), ('layer', 'NN'), (',', ','), ('one', 'CD'), ('2-unit', 'JJ'), ('output', 'NN'), ('layer', 'NN'), (',', ','), ('two', 'CD'), ('5-', 'JJ'), ('unit', 'NN'), ('hidden', 'JJ'), ('layers', 'NNS'), ('.', '.')]

 (S
  (NP Deep/JJ network/NN Architecture/NNP)
  (NP The/DT Fig.11/NNP)
  depicts/VBZ
  (NP deep/JJ learning/NN network/NN architecture/NN)
  one/CD
  (NP 3-unit/JJ input/NN layer/NN)
  ,/,
  one/CD
  (NP 2-unit/JJ output/NN layer/NN)
  ,/,
  two/CD
  (NP 5-/JJ unit/NN)
  (NP hidden/JJ layers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep network Architecture', 'The Fig.11', 'deep learning network architecture', '3-unit input layer', '2-unit output layer', '5- unit', 'hidden layers']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('network', 'network'), ('Architecture', 'architectur'), ('The', 'the'), ('Fig.11', 'fig.11'), ('depicts', 'depict'), ('deep', 'deep'), ('learning', 'learn'), ('network', 'network'), ('architecture', 'architectur'), ('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-'), ('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('network', 'network'), ('Architecture', 'architectur'), ('The', 'the'), ('Fig.11', 'fig.11'), ('depicts', 'depict'), ('deep', 'deep'), ('learning', 'learn'), ('network', 'network'), ('architecture', 'architectur'), ('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-'), ('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('network', 'network'), ('Architecture', 'Architecture'), ('The', 'The'), ('Fig.11', 'Fig.11'), ('depicts', 'depicts'), ('deep', 'deep'), ('learning', 'learning'), ('network', 'network'), ('architecture', 'architecture'), ('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-'), ('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]



============================ Sentence 193 =============================

Deep learning has also been successfully implemented in   industry products that ultimately take advantage of the large   volume of data. 


>> Tokens are: 
 ['Deep', 'learning', 'also', 'successfully', 'implemented', 'industry', 'products', 'ultimately', 'take', 'advantage', 'large', 'volume', 'data', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'also'), ('also', 'successfully'), ('successfully', 'implemented'), ('implemented', 'industry'), ('industry', 'products'), ('products', 'ultimately'), ('ultimately', 'take'), ('take', 'advantage'), ('advantage', 'large'), ('large', 'volume'), ('volume', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'also'), ('learning', 'also', 'successfully'), ('also', 'successfully', 'implemented'), ('successfully', 'implemented', 'industry'), ('implemented', 'industry', 'products'), ('industry', 'products', 'ultimately'), ('products', 'ultimately', 'take'), ('ultimately', 'take', 'advantage'), ('take', 'advantage', 'large'), ('advantage', 'large', 'volume'), ('large', 'volume', 'data'), ('volume', 'data', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('also', 'RB'), ('successfully', 'RB'), ('implemented', 'VBN'), ('industry', 'NN'), ('products', 'NNS'), ('ultimately', 'RB'), ('take', 'VBP'), ('advantage', 'JJ'), ('large', 'JJ'), ('volume', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Deep/NNP learning/NN)
  also/RB
  successfully/RB
  implemented/VBN
  (NP industry/NN products/NNS)
  ultimately/RB
  take/VBP
  (NP advantage/JJ large/JJ volume/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning', 'industry products', 'advantage large volume data']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('also', 'also'), ('successfully', 'success'), ('implemented', 'implement'), ('industry', 'industri'), ('products', 'product'), ('ultimately', 'ultim'), ('take', 'take'), ('advantage', 'advantag'), ('large', 'larg'), ('volume', 'volum'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('also', 'also'), ('successfully', 'success'), ('implemented', 'implement'), ('industry', 'industri'), ('products', 'product'), ('ultimately', 'ultim'), ('take', 'take'), ('advantage', 'advantag'), ('large', 'larg'), ('volume', 'volum'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('also', 'also'), ('successfully', 'successfully'), ('implemented', 'implemented'), ('industry', 'industry'), ('products', 'product'), ('ultimately', 'ultimately'), ('take', 'take'), ('advantage', 'advantage'), ('large', 'large'), ('volume', 'volume'), ('data', 'data'), ('.', '.')]



============================ Sentence 194 =============================

Top Information Technology (IT) companies   like Microsoft, Google, Apple, Yahoo, Baidu, Amazon and   Facebook, who collect and analyze massive amounts of data on a   daily basis, have been investing a good share on finances on   deep learning related projects. 


>> Tokens are: 
 ['Top', 'Information', 'Technology', '(', 'IT', ')', 'companies', 'like', 'Microsoft', ',', 'Google', ',', 'Apple', ',', 'Yahoo', ',', 'Baidu', ',', 'Amazon', 'Facebook', ',', 'collect', 'analyze', 'massive', 'amounts', 'data', 'daily', 'basis', ',', 'investing', 'good', 'share', 'finances', 'deep', 'learning', 'related', 'projects', '.']

>> Bigrams are: 
 [('Top', 'Information'), ('Information', 'Technology'), ('Technology', '('), ('(', 'IT'), ('IT', ')'), (')', 'companies'), ('companies', 'like'), ('like', 'Microsoft'), ('Microsoft', ','), (',', 'Google'), ('Google', ','), (',', 'Apple'), ('Apple', ','), (',', 'Yahoo'), ('Yahoo', ','), (',', 'Baidu'), ('Baidu', ','), (',', 'Amazon'), ('Amazon', 'Facebook'), ('Facebook', ','), (',', 'collect'), ('collect', 'analyze'), ('analyze', 'massive'), ('massive', 'amounts'), ('amounts', 'data'), ('data', 'daily'), ('daily', 'basis'), ('basis', ','), (',', 'investing'), ('investing', 'good'), ('good', 'share'), ('share', 'finances'), ('finances', 'deep'), ('deep', 'learning'), ('learning', 'related'), ('related', 'projects'), ('projects', '.')]

>> Trigrams are: 
 [('Top', 'Information', 'Technology'), ('Information', 'Technology', '('), ('Technology', '(', 'IT'), ('(', 'IT', ')'), ('IT', ')', 'companies'), (')', 'companies', 'like'), ('companies', 'like', 'Microsoft'), ('like', 'Microsoft', ','), ('Microsoft', ',', 'Google'), (',', 'Google', ','), ('Google', ',', 'Apple'), (',', 'Apple', ','), ('Apple', ',', 'Yahoo'), (',', 'Yahoo', ','), ('Yahoo', ',', 'Baidu'), (',', 'Baidu', ','), ('Baidu', ',', 'Amazon'), (',', 'Amazon', 'Facebook'), ('Amazon', 'Facebook', ','), ('Facebook', ',', 'collect'), (',', 'collect', 'analyze'), ('collect', 'analyze', 'massive'), ('analyze', 'massive', 'amounts'), ('massive', 'amounts', 'data'), ('amounts', 'data', 'daily'), ('data', 'daily', 'basis'), ('daily', 'basis', ','), ('basis', ',', 'investing'), (',', 'investing', 'good'), ('investing', 'good', 'share'), ('good', 'share', 'finances'), ('share', 'finances', 'deep'), ('finances', 'deep', 'learning'), ('deep', 'learning', 'related'), ('learning', 'related', 'projects'), ('related', 'projects', '.')]

>> POS Tags are: 
 [('Top', 'JJ'), ('Information', 'NNP'), ('Technology', 'NNP'), ('(', '('), ('IT', 'NNP'), (')', ')'), ('companies', 'NNS'), ('like', 'IN'), ('Microsoft', 'NNP'), (',', ','), ('Google', 'NNP'), (',', ','), ('Apple', 'NNP'), (',', ','), ('Yahoo', 'NNP'), (',', ','), ('Baidu', 'NNP'), (',', ','), ('Amazon', 'NNP'), ('Facebook', 'NNP'), (',', ','), ('collect', 'VBP'), ('analyze', 'JJ'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('daily', 'RB'), ('basis', 'NN'), (',', ','), ('investing', 'VBG'), ('good', 'JJ'), ('share', 'NN'), ('finances', 'NNS'), ('deep', 'RB'), ('learning', 'VBG'), ('related', 'JJ'), ('projects', 'NNS'), ('.', '.')]

 (S
  (NP Top/JJ Information/NNP Technology/NNP)
  (/(
  (NP IT/NNP)
  )/)
  (NP companies/NNS)
  like/IN
  (NP Microsoft/NNP)
  ,/,
  (NP Google/NNP)
  ,/,
  (NP Apple/NNP)
  ,/,
  (NP Yahoo/NNP)
  ,/,
  (NP Baidu/NNP)
  ,/,
  (NP Amazon/NNP Facebook/NNP)
  ,/,
  collect/VBP
  (NP analyze/JJ massive/JJ amounts/NNS data/NNS)
  daily/RB
  (NP basis/NN)
  ,/,
  investing/VBG
  (NP good/JJ share/NN finances/NNS)
  deep/RB
  learning/VBG
  (NP related/JJ projects/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Top Information Technology', 'IT', 'companies', 'Microsoft', 'Google', 'Apple', 'Yahoo', 'Baidu', 'Amazon Facebook', 'analyze massive amounts data', 'basis', 'good share finances', 'related projects']

>> Named Entities are: 
 [('ORGANIZATION', 'Microsoft'), ('GPE', 'Google'), ('PERSON', 'Apple'), ('PERSON', 'Yahoo'), ('PERSON', 'Baidu'), ('PERSON', 'Amazon Facebook')] 

>> Stemming using Porter Stemmer: 
 [('Top', 'top'), ('Information', 'inform'), ('Technology', 'technolog'), ('(', '('), ('IT', 'it'), (')', ')'), ('companies', 'compani'), ('like', 'like'), ('Microsoft', 'microsoft'), (',', ','), ('Google', 'googl'), (',', ','), ('Apple', 'appl'), (',', ','), ('Yahoo', 'yahoo'), (',', ','), ('Baidu', 'baidu'), (',', ','), ('Amazon', 'amazon'), ('Facebook', 'facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyz'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('daily', 'daili'), ('basis', 'basi'), (',', ','), ('investing', 'invest'), ('good', 'good'), ('share', 'share'), ('finances', 'financ'), ('deep', 'deep'), ('learning', 'learn'), ('related', 'relat'), ('projects', 'project'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Top', 'top'), ('Information', 'inform'), ('Technology', 'technolog'), ('(', '('), ('IT', 'it'), (')', ')'), ('companies', 'compani'), ('like', 'like'), ('Microsoft', 'microsoft'), (',', ','), ('Google', 'googl'), (',', ','), ('Apple', 'appl'), (',', ','), ('Yahoo', 'yahoo'), (',', ','), ('Baidu', 'baidu'), (',', ','), ('Amazon', 'amazon'), ('Facebook', 'facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyz'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('daily', 'daili'), ('basis', 'basi'), (',', ','), ('investing', 'invest'), ('good', 'good'), ('share', 'share'), ('finances', 'financ'), ('deep', 'deep'), ('learning', 'learn'), ('related', 'relat'), ('projects', 'project'), ('.', '.')]

>> Lemmatization: 
 [('Top', 'Top'), ('Information', 'Information'), ('Technology', 'Technology'), ('(', '('), ('IT', 'IT'), (')', ')'), ('companies', 'company'), ('like', 'like'), ('Microsoft', 'Microsoft'), (',', ','), ('Google', 'Google'), (',', ','), ('Apple', 'Apple'), (',', ','), ('Yahoo', 'Yahoo'), (',', ','), ('Baidu', 'Baidu'), (',', ','), ('Amazon', 'Amazon'), ('Facebook', 'Facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyze'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), ('daily', 'daily'), ('basis', 'basis'), (',', ','), ('investing', 'investing'), ('good', 'good'), ('share', 'share'), ('finances', 'finance'), ('deep', 'deep'), ('learning', 'learning'), ('related', 'related'), ('projects', 'project'), ('.', '.')]



============================ Sentence 195 =============================

For example, Apple's Siri and   Google Voice Search offer a wide variety of services including   weather reports, sport news, answers to users questions, and   reminders etc., by utilizing deep learning algorithms [31]. 


>> Tokens are: 
 ['For', 'example', ',', 'Apple', "'s", 'Siri', 'Google', 'Voice', 'Search', 'offer', 'wide', 'variety', 'services', 'including', 'weather', 'reports', ',', 'sport', 'news', ',', 'answers', 'user', '', 'questions', ',', 'reminders', 'etc.', ',', 'utilizing', 'deep', 'learning', 'algorithms', '[', '31', ']', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'Apple'), ('Apple', "'s"), ("'s", 'Siri'), ('Siri', 'Google'), ('Google', 'Voice'), ('Voice', 'Search'), ('Search', 'offer'), ('offer', 'wide'), ('wide', 'variety'), ('variety', 'services'), ('services', 'including'), ('including', 'weather'), ('weather', 'reports'), ('reports', ','), (',', 'sport'), ('sport', 'news'), ('news', ','), (',', 'answers'), ('answers', 'user'), ('user', ''), ('', 'questions'), ('questions', ','), (',', 'reminders'), ('reminders', 'etc.'), ('etc.', ','), (',', 'utilizing'), ('utilizing', 'deep'), ('deep', 'learning'), ('learning', 'algorithms'), ('algorithms', '['), ('[', '31'), ('31', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'Apple'), (',', 'Apple', "'s"), ('Apple', "'s", 'Siri'), ("'s", 'Siri', 'Google'), ('Siri', 'Google', 'Voice'), ('Google', 'Voice', 'Search'), ('Voice', 'Search', 'offer'), ('Search', 'offer', 'wide'), ('offer', 'wide', 'variety'), ('wide', 'variety', 'services'), ('variety', 'services', 'including'), ('services', 'including', 'weather'), ('including', 'weather', 'reports'), ('weather', 'reports', ','), ('reports', ',', 'sport'), (',', 'sport', 'news'), ('sport', 'news', ','), ('news', ',', 'answers'), (',', 'answers', 'user'), ('answers', 'user', ''), ('user', '', 'questions'), ('', 'questions', ','), ('questions', ',', 'reminders'), (',', 'reminders', 'etc.'), ('reminders', 'etc.', ','), ('etc.', ',', 'utilizing'), (',', 'utilizing', 'deep'), ('utilizing', 'deep', 'learning'), ('deep', 'learning', 'algorithms'), ('learning', 'algorithms', '['), ('algorithms', '[', '31'), ('[', '31', ']'), ('31', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('Apple', 'NNP'), ("'s", 'POS'), ('Siri', 'NNP'), ('Google', 'NNP'), ('Voice', 'NNP'), ('Search', 'NNP'), ('offer', 'NN'), ('wide', 'JJ'), ('variety', 'NN'), ('services', 'NNS'), ('including', 'VBG'), ('weather', 'JJR'), ('reports', 'NNS'), (',', ','), ('sport', 'NN'), ('news', 'NN'), (',', ','), ('answers', 'NNS'), ('user', 'VBP'), ('', 'JJ'), ('questions', 'NNS'), (',', ','), ('reminders', 'NNS'), ('etc.', 'VBP'), (',', ','), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('algorithms', 'JJ'), ('[', '$'), ('31', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP Apple/NNP)
  's/POS
  (NP Siri/NNP Google/NNP Voice/NNP Search/NNP offer/NN)
  (NP wide/JJ variety/NN services/NNS)
  including/VBG
  weather/JJR
  (NP reports/NNS)
  ,/,
  (NP sport/NN news/NN)
  ,/,
  (NP answers/NNS)
  user/VBP
  (NP /JJ questions/NNS)
  ,/,
  (NP reminders/NNS)
  etc./VBP
  ,/,
  (NP utilizing/JJ deep/JJ learning/NN)
  algorithms/JJ
  [/$
  31/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'Apple', 'Siri Google Voice Search offer', 'wide variety services', 'reports', 'sport news', 'answers', ' questions', 'reminders', 'utilizing deep learning', ']']

>> Named Entities are: 
 [('PERSON', 'Apple'), ('PERSON', 'Siri Google')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('Apple', 'appl'), ("'s", "'s"), ('Siri', 'siri'), ('Google', 'googl'), ('Voice', 'voic'), ('Search', 'search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'varieti'), ('services', 'servic'), ('including', 'includ'), ('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ','), ('reminders', 'remind'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'util'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('Apple', 'appl'), ("'s", "'s"), ('Siri', 'siri'), ('Google', 'googl'), ('Voice', 'voic'), ('Search', 'search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'varieti'), ('services', 'servic'), ('including', 'includ'), ('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ','), ('reminders', 'remind'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'util'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('Apple', 'Apple'), ("'s", "'s"), ('Siri', 'Siri'), ('Google', 'Google'), ('Voice', 'Voice'), ('Search', 'Search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'variety'), ('services', 'service'), ('including', 'including'), ('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ','), ('reminders', 'reminder'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'utilizing'), ('deep', 'deep'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]



============================ Sentence 196 =============================

Currently, these two applications support wide range spoken   languages. 


>> Tokens are: 
 ['Currently', ',', 'two', 'applications', 'support', 'wide', 'range', 'spoken', 'languages', '.']

>> Bigrams are: 
 [('Currently', ','), (',', 'two'), ('two', 'applications'), ('applications', 'support'), ('support', 'wide'), ('wide', 'range'), ('range', 'spoken'), ('spoken', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('Currently', ',', 'two'), (',', 'two', 'applications'), ('two', 'applications', 'support'), ('applications', 'support', 'wide'), ('support', 'wide', 'range'), ('wide', 'range', 'spoken'), ('range', 'spoken', 'languages'), ('spoken', 'languages', '.')]

>> POS Tags are: 
 [('Currently', 'RB'), (',', ','), ('two', 'CD'), ('applications', 'NNS'), ('support', 'NN'), ('wide', 'JJ'), ('range', 'NN'), ('spoken', 'VBN'), ('languages', 'NNS'), ('.', '.')]

 (S
  Currently/RB
  ,/,
  two/CD
  (NP applications/NNS support/NN)
  (NP wide/JJ range/NN)
  spoken/VBN
  (NP languages/NNS)
  ./.) 


>> Noun Phrases are: 
 ['applications support', 'wide range', 'languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Currently', 'current'), (',', ','), ('two', 'two'), ('applications', 'applic'), ('support', 'support'), ('wide', 'wide'), ('range', 'rang'), ('spoken', 'spoken'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Currently', 'current'), (',', ','), ('two', 'two'), ('applications', 'applic'), ('support', 'support'), ('wide', 'wide'), ('range', 'rang'), ('spoken', 'spoken'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('Currently', 'Currently'), (',', ','), ('two', 'two'), ('applications', 'application'), ('support', 'support'), ('wide', 'wide'), ('range', 'range'), ('spoken', 'spoken'), ('languages', 'language'), ('.', '.')]



============================ Sentence 197 =============================

Table.4. 


>> Tokens are: 
 ['Table.4', '.']

>> Bigrams are: 
 [('Table.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.4', 'NNP'), ('.', '.')]

 (S (NP Table.4/NNP) ./.) 


>> Noun Phrases are: 
 ['Table.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.4', 'table.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.4', 'table.4'), ('.', '.')]

>> Lemmatization: 
 [('Table.4', 'Table.4'), ('.', '.')]



============================ Sentence 198 =============================

Large scale deep learning research progress   Method Computing power  # of examples and   parameters   Average   running   Time   DBN [32]  NVIDIA GTX 280   GPU (1 GB RAM)   1million images and   1006 parameters  ~ 1 day   CNN [33]  Two GTX 580   GPUs( 6 GB RAM)   1.2 million high  resolution (256  256)   images and 606   parameters   ~ 5-6 days   DisBelief [34]   1000 CPUs with   Downpour SGD with   Adagrad   1.1 billion audio   examples with 42 million   parameters   ~ 16 hours   Sparse  Autoencoder   [35]   1000 CPUs with   16,000 core   10 million (200  200 )  Images and 1 billion   parameters   ~ 3Days   COTS HPC   [36]   64 NVIDIA GTX  680 GPUs   (256 GB RAM)   10 million (200  200 )  Images and 11 billion   parameters   ~ 3Days   The Table.4 summarizes the current progress in deep   learning algorithms. 


>> Tokens are: 
 ['Large', 'scale', 'deep', 'learning', 'research', 'progress', 'Method', 'Computing', 'power', '#', 'examples', 'parameters', 'Average', 'running', 'Time', 'DBN', '[', '32', ']', 'NVIDIA', 'GTX', '280', 'GPU', '(', '1', 'GB', 'RAM', ')', '1million', 'images', '1006', 'parameters', '~', '1', 'day', 'CNN', '[', '33', ']', 'Two', 'GTX', '580', 'GPUs', '(', '6', 'GB', 'RAM', ')', '1.2', 'million', 'high', 'resolution', '(', '256', '', '256', ')', 'images', '606', 'parameters', '~', '5-6', 'days', 'DisBelief', '[', '34', ']', '1000', 'CPUs', 'Downpour', 'SGD', 'Adagrad', '1.1', 'billion', 'audio', 'examples', '42', 'million', 'parameters', '~', '16', 'hours', 'Sparse', 'Autoencoder', '[', '35', ']', '1000', 'CPUs', '16,000', 'core', '10', 'million', '(', '200', '', '200', ')', 'Images', '1', 'billion', 'parameters', '~', '3Days', 'COTS', 'HPC', '[', '36', ']', '64', 'NVIDIA', 'GTX', '680', 'GPUs', '(', '256', 'GB', 'RAM', ')', '10', 'million', '(', '200', '', '200', ')', 'Images', '11', 'billion', 'parameters', '~', '3Days', 'The', 'Table.4', 'summarizes', 'current', 'progress', 'deep', 'learning', 'algorithms', '.']

>> Bigrams are: 
 [('Large', 'scale'), ('scale', 'deep'), ('deep', 'learning'), ('learning', 'research'), ('research', 'progress'), ('progress', 'Method'), ('Method', 'Computing'), ('Computing', 'power'), ('power', '#'), ('#', 'examples'), ('examples', 'parameters'), ('parameters', 'Average'), ('Average', 'running'), ('running', 'Time'), ('Time', 'DBN'), ('DBN', '['), ('[', '32'), ('32', ']'), (']', 'NVIDIA'), ('NVIDIA', 'GTX'), ('GTX', '280'), ('280', 'GPU'), ('GPU', '('), ('(', '1'), ('1', 'GB'), ('GB', 'RAM'), ('RAM', ')'), (')', '1million'), ('1million', 'images'), ('images', '1006'), ('1006', 'parameters'), ('parameters', '~'), ('~', '1'), ('1', 'day'), ('day', 'CNN'), ('CNN', '['), ('[', '33'), ('33', ']'), (']', 'Two'), ('Two', 'GTX'), ('GTX', '580'), ('580', 'GPUs'), ('GPUs', '('), ('(', '6'), ('6', 'GB'), ('GB', 'RAM'), ('RAM', ')'), (')', '1.2'), ('1.2', 'million'), ('million', 'high'), ('high', 'resolution'), ('resolution', '('), ('(', '256'), ('256', ''), ('', '256'), ('256', ')'), (')', 'images'), ('images', '606'), ('606', 'parameters'), ('parameters', '~'), ('~', '5-6'), ('5-6', 'days'), ('days', 'DisBelief'), ('DisBelief', '['), ('[', '34'), ('34', ']'), (']', '1000'), ('1000', 'CPUs'), ('CPUs', 'Downpour'), ('Downpour', 'SGD'), ('SGD', 'Adagrad'), ('Adagrad', '1.1'), ('1.1', 'billion'), ('billion', 'audio'), ('audio', 'examples'), ('examples', '42'), ('42', 'million'), ('million', 'parameters'), ('parameters', '~'), ('~', '16'), ('16', 'hours'), ('hours', 'Sparse'), ('Sparse', 'Autoencoder'), ('Autoencoder', '['), ('[', '35'), ('35', ']'), (']', '1000'), ('1000', 'CPUs'), ('CPUs', '16,000'), ('16,000', 'core'), ('core', '10'), ('10', 'million'), ('million', '('), ('(', '200'), ('200', ''), ('', '200'), ('200', ')'), (')', 'Images'), ('Images', '1'), ('1', 'billion'), ('billion', 'parameters'), ('parameters', '~'), ('~', '3Days'), ('3Days', 'COTS'), ('COTS', 'HPC'), ('HPC', '['), ('[', '36'), ('36', ']'), (']', '64'), ('64', 'NVIDIA'), ('NVIDIA', 'GTX'), ('GTX', '680'), ('680', 'GPUs'), ('GPUs', '('), ('(', '256'), ('256', 'GB'), ('GB', 'RAM'), ('RAM', ')'), (')', '10'), ('10', 'million'), ('million', '('), ('(', '200'), ('200', ''), ('', '200'), ('200', ')'), (')', 'Images'), ('Images', '11'), ('11', 'billion'), ('billion', 'parameters'), ('parameters', '~'), ('~', '3Days'), ('3Days', 'The'), ('The', 'Table.4'), ('Table.4', 'summarizes'), ('summarizes', 'current'), ('current', 'progress'), ('progress', 'deep'), ('deep', 'learning'), ('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Large', 'scale', 'deep'), ('scale', 'deep', 'learning'), ('deep', 'learning', 'research'), ('learning', 'research', 'progress'), ('research', 'progress', 'Method'), ('progress', 'Method', 'Computing'), ('Method', 'Computing', 'power'), ('Computing', 'power', '#'), ('power', '#', 'examples'), ('#', 'examples', 'parameters'), ('examples', 'parameters', 'Average'), ('parameters', 'Average', 'running'), ('Average', 'running', 'Time'), ('running', 'Time', 'DBN'), ('Time', 'DBN', '['), ('DBN', '[', '32'), ('[', '32', ']'), ('32', ']', 'NVIDIA'), (']', 'NVIDIA', 'GTX'), ('NVIDIA', 'GTX', '280'), ('GTX', '280', 'GPU'), ('280', 'GPU', '('), ('GPU', '(', '1'), ('(', '1', 'GB'), ('1', 'GB', 'RAM'), ('GB', 'RAM', ')'), ('RAM', ')', '1million'), (')', '1million', 'images'), ('1million', 'images', '1006'), ('images', '1006', 'parameters'), ('1006', 'parameters', '~'), ('parameters', '~', '1'), ('~', '1', 'day'), ('1', 'day', 'CNN'), ('day', 'CNN', '['), ('CNN', '[', '33'), ('[', '33', ']'), ('33', ']', 'Two'), (']', 'Two', 'GTX'), ('Two', 'GTX', '580'), ('GTX', '580', 'GPUs'), ('580', 'GPUs', '('), ('GPUs', '(', '6'), ('(', '6', 'GB'), ('6', 'GB', 'RAM'), ('GB', 'RAM', ')'), ('RAM', ')', '1.2'), (')', '1.2', 'million'), ('1.2', 'million', 'high'), ('million', 'high', 'resolution'), ('high', 'resolution', '('), ('resolution', '(', '256'), ('(', '256', ''), ('256', '', '256'), ('', '256', ')'), ('256', ')', 'images'), (')', 'images', '606'), ('images', '606', 'parameters'), ('606', 'parameters', '~'), ('parameters', '~', '5-6'), ('~', '5-6', 'days'), ('5-6', 'days', 'DisBelief'), ('days', 'DisBelief', '['), ('DisBelief', '[', '34'), ('[', '34', ']'), ('34', ']', '1000'), (']', '1000', 'CPUs'), ('1000', 'CPUs', 'Downpour'), ('CPUs', 'Downpour', 'SGD'), ('Downpour', 'SGD', 'Adagrad'), ('SGD', 'Adagrad', '1.1'), ('Adagrad', '1.1', 'billion'), ('1.1', 'billion', 'audio'), ('billion', 'audio', 'examples'), ('audio', 'examples', '42'), ('examples', '42', 'million'), ('42', 'million', 'parameters'), ('million', 'parameters', '~'), ('parameters', '~', '16'), ('~', '16', 'hours'), ('16', 'hours', 'Sparse'), ('hours', 'Sparse', 'Autoencoder'), ('Sparse', 'Autoencoder', '['), ('Autoencoder', '[', '35'), ('[', '35', ']'), ('35', ']', '1000'), (']', '1000', 'CPUs'), ('1000', 'CPUs', '16,000'), ('CPUs', '16,000', 'core'), ('16,000', 'core', '10'), ('core', '10', 'million'), ('10', 'million', '('), ('million', '(', '200'), ('(', '200', ''), ('200', '', '200'), ('', '200', ')'), ('200', ')', 'Images'), (')', 'Images', '1'), ('Images', '1', 'billion'), ('1', 'billion', 'parameters'), ('billion', 'parameters', '~'), ('parameters', '~', '3Days'), ('~', '3Days', 'COTS'), ('3Days', 'COTS', 'HPC'), ('COTS', 'HPC', '['), ('HPC', '[', '36'), ('[', '36', ']'), ('36', ']', '64'), (']', '64', 'NVIDIA'), ('64', 'NVIDIA', 'GTX'), ('NVIDIA', 'GTX', '680'), ('GTX', '680', 'GPUs'), ('680', 'GPUs', '('), ('GPUs', '(', '256'), ('(', '256', 'GB'), ('256', 'GB', 'RAM'), ('GB', 'RAM', ')'), ('RAM', ')', '10'), (')', '10', 'million'), ('10', 'million', '('), ('million', '(', '200'), ('(', '200', ''), ('200', '', '200'), ('', '200', ')'), ('200', ')', 'Images'), (')', 'Images', '11'), ('Images', '11', 'billion'), ('11', 'billion', 'parameters'), ('billion', 'parameters', '~'), ('parameters', '~', '3Days'), ('~', '3Days', 'The'), ('3Days', 'The', 'Table.4'), ('The', 'Table.4', 'summarizes'), ('Table.4', 'summarizes', 'current'), ('summarizes', 'current', 'progress'), ('current', 'progress', 'deep'), ('progress', 'deep', 'learning'), ('deep', 'learning', 'algorithms'), ('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('Large', 'JJ'), ('scale', 'NN'), ('deep', 'JJ'), ('learning', 'NN'), ('research', 'NN'), ('progress', 'NN'), ('Method', 'NNP'), ('Computing', 'NNP'), ('power', 'NN'), ('#', '#'), ('examples', 'VBZ'), ('parameters', 'NNS'), ('Average', 'NNP'), ('running', 'VBG'), ('Time', 'NNP'), ('DBN', 'NNP'), ('[', 'VBD'), ('32', 'CD'), (']', 'JJ'), ('NVIDIA', 'NNP'), ('GTX', 'NNP'), ('280', 'CD'), ('GPU', 'NNP'), ('(', '('), ('1', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')'), ('1million', 'CD'), ('images', 'NNS'), ('1006', 'CD'), ('parameters', 'NNS'), ('~', 'VBP'), ('1', 'CD'), ('day', 'NN'), ('CNN', 'NNP'), ('[', 'NNP'), ('33', 'CD'), (']', 'NNP'), ('Two', 'CD'), ('GTX', 'NNP'), ('580', 'CD'), ('GPUs', 'NNP'), ('(', '('), ('6', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')'), ('1.2', 'CD'), ('million', 'CD'), ('high', 'JJ'), ('resolution', 'NN'), ('(', '('), ('256', 'CD'), ('', 'RB'), ('256', 'CD'), (')', ')'), ('images', 'VBZ'), ('606', 'CD'), ('parameters', 'NNS'), ('~', 'JJ'), ('5-6', 'JJ'), ('days', 'NNS'), ('DisBelief', 'NNP'), ('[', 'VBD'), ('34', 'CD'), (']', 'NN'), ('1000', 'CD'), ('CPUs', 'NNP'), ('Downpour', 'NNP'), ('SGD', 'NNP'), ('Adagrad', 'NNP'), ('1.1', 'CD'), ('billion', 'CD'), ('audio', 'JJ'), ('examples', 'VBZ'), ('42', 'CD'), ('million', 'CD'), ('parameters', 'NNS'), ('~', 'POS'), ('16', 'CD'), ('hours', 'NNS'), ('Sparse', 'NNP'), ('Autoencoder', 'NNP'), ('[', 'VBD'), ('35', 'CD'), (']', 'NN'), ('1000', 'CD'), ('CPUs', 'NNP'), ('16,000', 'CD'), ('core', 'NN'), ('10', 'CD'), ('million', 'CD'), ('(', '('), ('200', 'CD'), ('', 'RB'), ('200', 'CD'), (')', ')'), ('Images', 'VBZ'), ('1', 'CD'), ('billion', 'CD'), ('parameters', 'NNS'), ('~', 'VBP'), ('3Days', 'CD'), ('COTS', 'NNP'), ('HPC', 'NNP'), ('[', 'VBD'), ('36', 'CD'), (']', 'JJ'), ('64', 'CD'), ('NVIDIA', 'NNP'), ('GTX', 'NNP'), ('680', 'CD'), ('GPUs', 'NNP'), ('(', '('), ('256', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')'), ('10', 'CD'), ('million', 'CD'), ('(', '('), ('200', 'CD'), ('', 'RB'), ('200', 'CD'), (')', ')'), ('Images', 'VBZ'), ('11', 'CD'), ('billion', 'CD'), ('parameters', 'NNS'), ('~', 'VBP'), ('3Days', 'CD'), ('The', 'DT'), ('Table.4', 'NNP'), ('summarizes', 'VBZ'), ('current', 'JJ'), ('progress', 'NN'), ('deep', 'JJ'), ('learning', 'NN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  (NP Large/JJ scale/NN)
  (NP
    deep/JJ
    learning/NN
    research/NN
    progress/NN
    Method/NNP
    Computing/NNP
    power/NN)
  #/#
  examples/VBZ
  (NP parameters/NNS Average/NNP)
  running/VBG
  (NP Time/NNP DBN/NNP)
  [/VBD
  32/CD
  (NP ]/JJ NVIDIA/NNP GTX/NNP)
  280/CD
  (NP GPU/NNP)
  (/(
  1/CD
  (NP GB/NNP RAM/NNP)
  )/)
  1million/CD
  (NP images/NNS)
  1006/CD
  (NP parameters/NNS)
  ~/VBP
  1/CD
  (NP day/NN CNN/NNP [/NNP)
  33/CD
  (NP ]/NNP)
  Two/CD
  (NP GTX/NNP)
  580/CD
  (NP GPUs/NNP)
  (/(
  6/CD
  (NP GB/NNP RAM/NNP)
  )/)
  1.2/CD
  million/CD
  (NP high/JJ resolution/NN)
  (/(
  256/CD
  /RB
  256/CD
  )/)
  images/VBZ
  606/CD
  (NP parameters/NNS)
  (NP ~/JJ 5-6/JJ days/NNS DisBelief/NNP)
  [/VBD
  34/CD
  (NP ]/NN)
  1000/CD
  (NP CPUs/NNP Downpour/NNP SGD/NNP Adagrad/NNP)
  1.1/CD
  billion/CD
  audio/JJ
  examples/VBZ
  42/CD
  million/CD
  (NP parameters/NNS)
  ~/POS
  16/CD
  (NP hours/NNS Sparse/NNP Autoencoder/NNP)
  [/VBD
  35/CD
  (NP ]/NN)
  1000/CD
  (NP CPUs/NNP)
  16,000/CD
  (NP core/NN)
  10/CD
  million/CD
  (/(
  200/CD
  /RB
  200/CD
  )/)
  Images/VBZ
  1/CD
  billion/CD
  (NP parameters/NNS)
  ~/VBP
  3Days/CD
  (NP COTS/NNP HPC/NNP)
  [/VBD
  36/CD
  ]/JJ
  64/CD
  (NP NVIDIA/NNP GTX/NNP)
  680/CD
  (NP GPUs/NNP)
  (/(
  256/CD
  (NP GB/NNP RAM/NNP)
  )/)
  10/CD
  million/CD
  (/(
  200/CD
  /RB
  200/CD
  )/)
  Images/VBZ
  11/CD
  billion/CD
  (NP parameters/NNS)
  ~/VBP
  3Days/CD
  (NP The/DT Table.4/NNP)
  summarizes/VBZ
  (NP current/JJ progress/NN)
  (NP deep/JJ learning/NN algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['Large scale', 'deep learning research progress Method Computing power', 'parameters Average', 'Time DBN', '] NVIDIA GTX', 'GPU', 'GB RAM', 'images', 'parameters', 'day CNN [', ']', 'GTX', 'GPUs', 'GB RAM', 'high resolution', 'parameters', '~ 5-6 days DisBelief', ']', 'CPUs Downpour SGD Adagrad', 'parameters', 'hours Sparse Autoencoder', ']', 'CPUs', 'core', 'parameters', 'COTS HPC', 'NVIDIA GTX', 'GPUs', 'GB RAM', 'parameters', 'The Table.4', 'current progress', 'deep learning algorithms']

>> Named Entities are: 
 [('GPE', 'Large'), ('ORGANIZATION', 'Method'), ('PERSON', 'Time DBN'), ('ORGANIZATION', 'NVIDIA'), ('ORGANIZATION', 'CNN'), ('ORGANIZATION', 'DisBelief'), ('ORGANIZATION', 'CPUs Downpour'), ('PERSON', 'Sparse Autoencoder'), ('ORGANIZATION', 'COTS'), ('ORGANIZATION', 'NVIDIA')] 

>> Stemming using Porter Stemmer: 
 [('Large', 'larg'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learn'), ('research', 'research'), ('progress', 'progress'), ('Method', 'method'), ('Computing', 'comput'), ('power', 'power'), ('#', '#'), ('examples', 'exampl'), ('parameters', 'paramet'), ('Average', 'averag'), ('running', 'run'), ('Time', 'time'), ('DBN', 'dbn'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('280', '280'), ('GPU', 'gpu'), ('(', '('), ('1', '1'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('1million', '1million'), ('images', 'imag'), ('1006', '1006'), ('parameters', 'paramet'), ('~', '~'), ('1', '1'), ('day', 'day'), ('CNN', 'cnn'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'two'), ('GTX', 'gtx'), ('580', '580'), ('GPUs', 'gpu'), ('(', '('), ('6', '6'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolut'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')'), ('images', 'imag'), ('606', '606'), ('parameters', 'paramet'), ('~', '~'), ('5-6', '5-6'), ('days', 'day'), ('DisBelief', 'disbelief'), ('[', '['), ('34', '34'), (']', ']'), ('1000', '1000'), ('CPUs', 'cpu'), ('Downpour', 'downpour'), ('SGD', 'sgd'), ('Adagrad', 'adagrad'), ('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio'), ('examples', 'exampl'), ('42', '42'), ('million', 'million'), ('parameters', 'paramet'), ('~', '~'), ('16', '16'), ('hours', 'hour'), ('Sparse', 'spars'), ('Autoencoder', 'autoencod'), ('[', '['), ('35', '35'), (']', ']'), ('1000', '1000'), ('CPUs', 'cpu'), ('16,000', '16,000'), ('core', 'core'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('1', '1'), ('billion', 'billion'), ('parameters', 'paramet'), ('~', '~'), ('3Days', '3day'), ('COTS', 'cot'), ('HPC', 'hpc'), ('[', '['), ('36', '36'), (']', ']'), ('64', '64'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('680', '680'), ('GPUs', 'gpu'), ('(', '('), ('256', '256'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('11', '11'), ('billion', 'billion'), ('parameters', 'paramet'), ('~', '~'), ('3Days', '3day'), ('The', 'the'), ('Table.4', 'table.4'), ('summarizes', 'summar'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Large', 'larg'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learn'), ('research', 'research'), ('progress', 'progress'), ('Method', 'method'), ('Computing', 'comput'), ('power', 'power'), ('#', '#'), ('examples', 'exampl'), ('parameters', 'paramet'), ('Average', 'averag'), ('running', 'run'), ('Time', 'time'), ('DBN', 'dbn'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('280', '280'), ('GPU', 'gpu'), ('(', '('), ('1', '1'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('1million', '1million'), ('images', 'imag'), ('1006', '1006'), ('parameters', 'paramet'), ('~', '~'), ('1', '1'), ('day', 'day'), ('CNN', 'cnn'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'two'), ('GTX', 'gtx'), ('580', '580'), ('GPUs', 'gpus'), ('(', '('), ('6', '6'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolut'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')'), ('images', 'imag'), ('606', '606'), ('parameters', 'paramet'), ('~', '~'), ('5-6', '5-6'), ('days', 'day'), ('DisBelief', 'disbelief'), ('[', '['), ('34', '34'), (']', ']'), ('1000', '1000'), ('CPUs', 'cpus'), ('Downpour', 'downpour'), ('SGD', 'sgd'), ('Adagrad', 'adagrad'), ('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio'), ('examples', 'exampl'), ('42', '42'), ('million', 'million'), ('parameters', 'paramet'), ('~', '~'), ('16', '16'), ('hours', 'hour'), ('Sparse', 'spars'), ('Autoencoder', 'autoencod'), ('[', '['), ('35', '35'), (']', ']'), ('1000', '1000'), ('CPUs', 'cpus'), ('16,000', '16,000'), ('core', 'core'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('1', '1'), ('billion', 'billion'), ('parameters', 'paramet'), ('~', '~'), ('3Days', '3day'), ('COTS', 'cot'), ('HPC', 'hpc'), ('[', '['), ('36', '36'), (']', ']'), ('64', '64'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('680', '680'), ('GPUs', 'gpus'), ('(', '('), ('256', '256'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('11', '11'), ('billion', 'billion'), ('parameters', 'paramet'), ('~', '~'), ('3Days', '3day'), ('The', 'the'), ('Table.4', 'table.4'), ('summarizes', 'summar'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Large', 'Large'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learning'), ('research', 'research'), ('progress', 'progress'), ('Method', 'Method'), ('Computing', 'Computing'), ('power', 'power'), ('#', '#'), ('examples', 'example'), ('parameters', 'parameter'), ('Average', 'Average'), ('running', 'running'), ('Time', 'Time'), ('DBN', 'DBN'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'NVIDIA'), ('GTX', 'GTX'), ('280', '280'), ('GPU', 'GPU'), ('(', '('), ('1', '1'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')'), ('1million', '1million'), ('images', 'image'), ('1006', '1006'), ('parameters', 'parameter'), ('~', '~'), ('1', '1'), ('day', 'day'), ('CNN', 'CNN'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'Two'), ('GTX', 'GTX'), ('580', '580'), ('GPUs', 'GPUs'), ('(', '('), ('6', '6'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')'), ('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolution'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')'), ('images', 'image'), ('606', '606'), ('parameters', 'parameter'), ('~', '~'), ('5-6', '5-6'), ('days', 'day'), ('DisBelief', 'DisBelief'), ('[', '['), ('34', '34'), (']', ']'), ('1000', '1000'), ('CPUs', 'CPUs'), ('Downpour', 'Downpour'), ('SGD', 'SGD'), ('Adagrad', 'Adagrad'), ('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio'), ('examples', 'example'), ('42', '42'), ('million', 'million'), ('parameters', 'parameter'), ('~', '~'), ('16', '16'), ('hours', 'hour'), ('Sparse', 'Sparse'), ('Autoencoder', 'Autoencoder'), ('[', '['), ('35', '35'), (']', ']'), ('1000', '1000'), ('CPUs', 'CPUs'), ('16,000', '16,000'), ('core', 'core'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'Images'), ('1', '1'), ('billion', 'billion'), ('parameters', 'parameter'), ('~', '~'), ('3Days', '3Days'), ('COTS', 'COTS'), ('HPC', 'HPC'), ('[', '['), ('36', '36'), (']', ']'), ('64', '64'), ('NVIDIA', 'NVIDIA'), ('GTX', 'GTX'), ('680', '680'), ('GPUs', 'GPUs'), ('(', '('), ('256', '256'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')'), ('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'Images'), ('11', '11'), ('billion', 'billion'), ('parameters', 'parameter'), ('~', '~'), ('3Days', '3Days'), ('The', 'The'), ('Table.4', 'Table.4'), ('summarizes', 'summarizes'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 199 =============================

It has been observed that different deep   learning technologies [32-36] required huge computational   resources to achieve significant results. 


>> Tokens are: 
 ['It', 'observed', 'different', 'deep', 'learning', 'technologies', '[', '32-36', ']', 'required', 'huge', 'computational', 'resources', 'achieve', 'significant', 'results', '.']

>> Bigrams are: 
 [('It', 'observed'), ('observed', 'different'), ('different', 'deep'), ('deep', 'learning'), ('learning', 'technologies'), ('technologies', '['), ('[', '32-36'), ('32-36', ']'), (']', 'required'), ('required', 'huge'), ('huge', 'computational'), ('computational', 'resources'), ('resources', 'achieve'), ('achieve', 'significant'), ('significant', 'results'), ('results', '.')]

>> Trigrams are: 
 [('It', 'observed', 'different'), ('observed', 'different', 'deep'), ('different', 'deep', 'learning'), ('deep', 'learning', 'technologies'), ('learning', 'technologies', '['), ('technologies', '[', '32-36'), ('[', '32-36', ']'), ('32-36', ']', 'required'), (']', 'required', 'huge'), ('required', 'huge', 'computational'), ('huge', 'computational', 'resources'), ('computational', 'resources', 'achieve'), ('resources', 'achieve', 'significant'), ('achieve', 'significant', 'results'), ('significant', 'results', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('observed', 'VBD'), ('different', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('technologies', 'NNS'), ('[', 'VBP'), ('32-36', 'JJ'), (']', 'NN'), ('required', 'VBN'), ('huge', 'JJ'), ('computational', 'JJ'), ('resources', 'NNS'), ('achieve', 'VBP'), ('significant', 'JJ'), ('results', 'NNS'), ('.', '.')]

 (S
  It/PRP
  observed/VBD
  (NP different/JJ deep/JJ learning/NN technologies/NNS)
  [/VBP
  (NP 32-36/JJ ]/NN)
  required/VBN
  (NP huge/JJ computational/JJ resources/NNS)
  achieve/VBP
  (NP significant/JJ results/NNS)
  ./.) 


>> Noun Phrases are: 
 ['different deep learning technologies', '32-36 ]', 'huge computational resources', 'significant results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('observed', 'observ'), ('different', 'differ'), ('deep', 'deep'), ('learning', 'learn'), ('technologies', 'technolog'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'requir'), ('huge', 'huge'), ('computational', 'comput'), ('resources', 'resourc'), ('achieve', 'achiev'), ('significant', 'signific'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('observed', 'observ'), ('different', 'differ'), ('deep', 'deep'), ('learning', 'learn'), ('technologies', 'technolog'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'requir'), ('huge', 'huge'), ('computational', 'comput'), ('resources', 'resourc'), ('achieve', 'achiev'), ('significant', 'signific'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('observed', 'observed'), ('different', 'different'), ('deep', 'deep'), ('learning', 'learning'), ('technologies', 'technology'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'required'), ('huge', 'huge'), ('computational', 'computational'), ('resources', 'resource'), ('achieve', 'achieve'), ('significant', 'significant'), ('results', 'result'), ('.', '.')]



============================ Sentence 200 =============================

8. 


>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

 (S 8/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]



============================ Sentence 201 =============================

CONCLUSION   Supervised machine learning methods are being applied in   different domains. 


>> Tokens are: 
 ['CONCLUSION', 'Supervised', 'machine', 'learning', 'methods', 'applied', 'different', 'domains', '.']

>> Bigrams are: 
 [('CONCLUSION', 'Supervised'), ('Supervised', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'applied'), ('applied', 'different'), ('different', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('CONCLUSION', 'Supervised', 'machine'), ('Supervised', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'applied'), ('methods', 'applied', 'different'), ('applied', 'different', 'domains'), ('different', 'domains', '.')]

>> POS Tags are: 
 [('CONCLUSION', 'NNP'), ('Supervised', 'VBD'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('applied', 'VBN'), ('different', 'JJ'), ('domains', 'NNS'), ('.', '.')]

 (S
  (NP CONCLUSION/NNP)
  Supervised/VBD
  (NP machine/NN)
  learning/VBG
  (NP methods/NNS)
  applied/VBN
  (NP different/JJ domains/NNS)
  ./.) 


>> Noun Phrases are: 
 ['CONCLUSION', 'machine', 'methods', 'different domains']

>> Named Entities are: 
 [('ORGANIZATION', 'CONCLUSION')] 

>> Stemming using Porter Stemmer: 
 [('CONCLUSION', 'conclus'), ('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('applied', 'appli'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CONCLUSION', 'conclus'), ('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('applied', 'appli'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('CONCLUSION', 'CONCLUSION'), ('Supervised', 'Supervised'), ('machine', 'machine'), ('learning', 'learning'), ('methods', 'method'), ('applied', 'applied'), ('different', 'different'), ('domains', 'domain'), ('.', '.')]



============================ Sentence 202 =============================

Due to scope of this paper, it is very difficult to   discuss the strength and weaknesses of each algorithm of ML. 


>> Tokens are: 
 ['Due', 'scope', 'paper', ',', 'difficult', 'discuss', 'strength', 'weaknesses', 'algorithm', 'ML', '.']

>> Bigrams are: 
 [('Due', 'scope'), ('scope', 'paper'), ('paper', ','), (',', 'difficult'), ('difficult', 'discuss'), ('discuss', 'strength'), ('strength', 'weaknesses'), ('weaknesses', 'algorithm'), ('algorithm', 'ML'), ('ML', '.')]

>> Trigrams are: 
 [('Due', 'scope', 'paper'), ('scope', 'paper', ','), ('paper', ',', 'difficult'), (',', 'difficult', 'discuss'), ('difficult', 'discuss', 'strength'), ('discuss', 'strength', 'weaknesses'), ('strength', 'weaknesses', 'algorithm'), ('weaknesses', 'algorithm', 'ML'), ('algorithm', 'ML', '.')]

>> POS Tags are: 
 [('Due', 'NNP'), ('scope', 'NN'), ('paper', 'NN'), (',', ','), ('difficult', 'JJ'), ('discuss', 'JJ'), ('strength', 'NN'), ('weaknesses', 'NNS'), ('algorithm', 'VBP'), ('ML', 'NNP'), ('.', '.')]

 (S
  (NP Due/NNP scope/NN paper/NN)
  ,/,
  (NP difficult/JJ discuss/JJ strength/NN weaknesses/NNS)
  algorithm/VBP
  (NP ML/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Due scope paper', 'difficult discuss strength weaknesses', 'ML']

>> Named Entities are: 
 [('GPE', 'Due')] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult'), ('discuss', 'discuss'), ('strength', 'strength'), ('weaknesses', 'weak'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult'), ('discuss', 'discuss'), ('strength', 'strength'), ('weaknesses', 'weak'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('.', '.')]

>> Lemmatization: 
 [('Due', 'Due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult'), ('discuss', 'discus'), ('strength', 'strength'), ('weaknesses', 'weakness'), ('algorithm', 'algorithm'), ('ML', 'ML'), ('.', '.')]



============================ Sentence 203 =============================

The   selection of algorithm in ML is mainly depends on task nature. 


>> Tokens are: 
 ['The', 'selection', 'algorithm', 'ML', 'mainly', 'depends', 'task', 'nature', '.']

>> Bigrams are: 
 [('The', 'selection'), ('selection', 'algorithm'), ('algorithm', 'ML'), ('ML', 'mainly'), ('mainly', 'depends'), ('depends', 'task'), ('task', 'nature'), ('nature', '.')]

>> Trigrams are: 
 [('The', 'selection', 'algorithm'), ('selection', 'algorithm', 'ML'), ('algorithm', 'ML', 'mainly'), ('ML', 'mainly', 'depends'), ('mainly', 'depends', 'task'), ('depends', 'task', 'nature'), ('task', 'nature', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('selection', 'NN'), ('algorithm', 'VBZ'), ('ML', 'NNP'), ('mainly', 'RB'), ('depends', 'VBZ'), ('task', 'JJ'), ('nature', 'NN'), ('.', '.')]

 (S
  (NP The/DT selection/NN)
  algorithm/VBZ
  (NP ML/NNP)
  mainly/RB
  depends/VBZ
  (NP task/JJ nature/NN)
  ./.) 


>> Noun Phrases are: 
 ['The selection', 'ML', 'task nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('mainly', 'mainli'), ('depends', 'depend'), ('task', 'task'), ('nature', 'natur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('mainly', 'main'), ('depends', 'depend'), ('task', 'task'), ('nature', 'natur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('selection', 'selection'), ('algorithm', 'algorithm'), ('ML', 'ML'), ('mainly', 'mainly'), ('depends', 'depends'), ('task', 'task'), ('nature', 'nature'), ('.', '.')]



============================ Sentence 204 =============================

The   performance of SVM and Neural Networks is better when dealing   with multidimensions and continuous features. 


>> Tokens are: 
 ['The', 'performance', 'SVM', 'Neural', 'Networks', 'better', 'dealing', 'multidimensions', 'continuous', 'features', '.']

>> Bigrams are: 
 [('The', 'performance'), ('performance', 'SVM'), ('SVM', 'Neural'), ('Neural', 'Networks'), ('Networks', 'better'), ('better', 'dealing'), ('dealing', 'multidimensions'), ('multidimensions', 'continuous'), ('continuous', 'features'), ('features', '.')]

>> Trigrams are: 
 [('The', 'performance', 'SVM'), ('performance', 'SVM', 'Neural'), ('SVM', 'Neural', 'Networks'), ('Neural', 'Networks', 'better'), ('Networks', 'better', 'dealing'), ('better', 'dealing', 'multidimensions'), ('dealing', 'multidimensions', 'continuous'), ('multidimensions', 'continuous', 'features'), ('continuous', 'features', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('performance', 'NN'), ('SVM', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('better', 'RBR'), ('dealing', 'VBG'), ('multidimensions', 'NNS'), ('continuous', 'JJ'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP The/DT performance/NN SVM/NNP Neural/NNP Networks/NNP)
  better/RBR
  dealing/VBG
  (NP multidimensions/NNS)
  (NP continuous/JJ features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The performance SVM Neural Networks', 'multidimensions', 'continuous features']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM Neural Networks')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('SVM', 'svm'), ('Neural', 'neural'), ('Networks', 'network'), ('better', 'better'), ('dealing', 'deal'), ('multidimensions', 'multidimens'), ('continuous', 'continu'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('SVM', 'svm'), ('Neural', 'neural'), ('Networks', 'network'), ('better', 'better'), ('dealing', 'deal'), ('multidimensions', 'multidimens'), ('continuous', 'continu'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('performance', 'performance'), ('SVM', 'SVM'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('better', 'better'), ('dealing', 'dealing'), ('multidimensions', 'multidimensions'), ('continuous', 'continuous'), ('features', 'feature'), ('.', '.')]



============================ Sentence 205 =============================

While logic-based   systems tend to perform better when dealing with   discrete/categorical features. 


>> Tokens are: 
 ['While', 'logic-based', 'systems', 'tend', 'perform', 'better', 'dealing', 'discrete/categorical', 'features', '.']

>> Bigrams are: 
 [('While', 'logic-based'), ('logic-based', 'systems'), ('systems', 'tend'), ('tend', 'perform'), ('perform', 'better'), ('better', 'dealing'), ('dealing', 'discrete/categorical'), ('discrete/categorical', 'features'), ('features', '.')]

>> Trigrams are: 
 [('While', 'logic-based', 'systems'), ('logic-based', 'systems', 'tend'), ('systems', 'tend', 'perform'), ('tend', 'perform', 'better'), ('perform', 'better', 'dealing'), ('better', 'dealing', 'discrete/categorical'), ('dealing', 'discrete/categorical', 'features'), ('discrete/categorical', 'features', '.')]

>> POS Tags are: 
 [('While', 'IN'), ('logic-based', 'JJ'), ('systems', 'NNS'), ('tend', 'VBP'), ('perform', 'VB'), ('better', 'JJR'), ('dealing', 'VBG'), ('discrete/categorical', 'JJ'), ('features', 'NNS'), ('.', '.')]

 (S
  While/IN
  (NP logic-based/JJ systems/NNS)
  tend/VBP
  perform/VB
  better/JJR
  dealing/VBG
  (NP discrete/categorical/JJ features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['logic-based systems', 'discrete/categorical features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('logic-based', 'logic-bas'), ('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'deal'), ('discrete/categorical', 'discrete/categor'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('logic-based', 'logic-bas'), ('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'deal'), ('discrete/categorical', 'discrete/categor'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('While', 'While'), ('logic-based', 'logic-based'), ('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'dealing'), ('discrete/categorical', 'discrete/categorical'), ('features', 'feature'), ('.', '.')]



============================ Sentence 206 =============================

For neural network models and SVMs,   a large sample size is required in order to achieve its maximum   prediction accuracy whereas NB may need a relatively small   dataset. 


>> Tokens are: 
 ['For', 'neural', 'network', 'models', 'SVMs', ',', 'large', 'sample', 'size', 'required', 'order', 'achieve', 'maximum', 'prediction', 'accuracy', 'whereas', 'NB', 'may', 'need', 'relatively', 'small', 'dataset', '.']

>> Bigrams are: 
 [('For', 'neural'), ('neural', 'network'), ('network', 'models'), ('models', 'SVMs'), ('SVMs', ','), (',', 'large'), ('large', 'sample'), ('sample', 'size'), ('size', 'required'), ('required', 'order'), ('order', 'achieve'), ('achieve', 'maximum'), ('maximum', 'prediction'), ('prediction', 'accuracy'), ('accuracy', 'whereas'), ('whereas', 'NB'), ('NB', 'may'), ('may', 'need'), ('need', 'relatively'), ('relatively', 'small'), ('small', 'dataset'), ('dataset', '.')]

>> Trigrams are: 
 [('For', 'neural', 'network'), ('neural', 'network', 'models'), ('network', 'models', 'SVMs'), ('models', 'SVMs', ','), ('SVMs', ',', 'large'), (',', 'large', 'sample'), ('large', 'sample', 'size'), ('sample', 'size', 'required'), ('size', 'required', 'order'), ('required', 'order', 'achieve'), ('order', 'achieve', 'maximum'), ('achieve', 'maximum', 'prediction'), ('maximum', 'prediction', 'accuracy'), ('prediction', 'accuracy', 'whereas'), ('accuracy', 'whereas', 'NB'), ('whereas', 'NB', 'may'), ('NB', 'may', 'need'), ('may', 'need', 'relatively'), ('need', 'relatively', 'small'), ('relatively', 'small', 'dataset'), ('small', 'dataset', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('neural', 'JJ'), ('network', 'NN'), ('models', 'NNS'), ('SVMs', 'NNP'), (',', ','), ('large', 'JJ'), ('sample', 'JJ'), ('size', 'NN'), ('required', 'VBN'), ('order', 'NN'), ('achieve', 'NNS'), ('maximum', 'JJ'), ('prediction', 'NN'), ('accuracy', 'NN'), ('whereas', 'IN'), ('NB', 'NNP'), ('may', 'MD'), ('need', 'VB'), ('relatively', 'RB'), ('small', 'JJ'), ('dataset', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP neural/JJ network/NN models/NNS SVMs/NNP)
  ,/,
  (NP large/JJ sample/JJ size/NN)
  required/VBN
  (NP order/NN achieve/NNS)
  (NP maximum/JJ prediction/NN accuracy/NN)
  whereas/IN
  (NP NB/NNP)
  may/MD
  need/VB
  relatively/RB
  (NP small/JJ dataset/NN)
  ./.) 


>> Noun Phrases are: 
 ['neural network models SVMs', 'large sample size', 'order achieve', 'maximum prediction accuracy', 'NB', 'small dataset']

>> Named Entities are: 
 [('ORGANIZATION', 'SVMs')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'svm'), (',', ','), ('large', 'larg'), ('sample', 'sampl'), ('size', 'size'), ('required', 'requir'), ('order', 'order'), ('achieve', 'achiev'), ('maximum', 'maximum'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('whereas', 'wherea'), ('NB', 'nb'), ('may', 'may'), ('need', 'need'), ('relatively', 'rel'), ('small', 'small'), ('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'svms'), (',', ','), ('large', 'larg'), ('sample', 'sampl'), ('size', 'size'), ('required', 'requir'), ('order', 'order'), ('achieve', 'achiev'), ('maximum', 'maximum'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('whereas', 'wherea'), ('NB', 'nb'), ('may', 'may'), ('need', 'need'), ('relatively', 'relat'), ('small', 'small'), ('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'SVMs'), (',', ','), ('large', 'large'), ('sample', 'sample'), ('size', 'size'), ('required', 'required'), ('order', 'order'), ('achieve', 'achieve'), ('maximum', 'maximum'), ('prediction', 'prediction'), ('accuracy', 'accuracy'), ('whereas', 'whereas'), ('NB', 'NB'), ('may', 'may'), ('need', 'need'), ('relatively', 'relatively'), ('small', 'small'), ('dataset', 'dataset'), ('.', '.')]



============================ Sentence 207 =============================

For the last few years deep learning is becoming a   mainstream technology for variety of application domains, like face   detection, speech recognition and detection, object recognition,   natural language processing and robotics. 


>> Tokens are: 
 ['For', 'last', 'years', 'deep', 'learning', 'becoming', 'mainstream', 'technology', 'variety', 'application', 'domains', ',', 'like', 'face', 'detection', ',', 'speech', 'recognition', 'detection', ',', 'object', 'recognition', ',', 'natural', 'language', 'processing', 'robotics', '.']

>> Bigrams are: 
 [('For', 'last'), ('last', 'years'), ('years', 'deep'), ('deep', 'learning'), ('learning', 'becoming'), ('becoming', 'mainstream'), ('mainstream', 'technology'), ('technology', 'variety'), ('variety', 'application'), ('application', 'domains'), ('domains', ','), (',', 'like'), ('like', 'face'), ('face', 'detection'), ('detection', ','), (',', 'speech'), ('speech', 'recognition'), ('recognition', 'detection'), ('detection', ','), (',', 'object'), ('object', 'recognition'), ('recognition', ','), (',', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'robotics'), ('robotics', '.')]

>> Trigrams are: 
 [('For', 'last', 'years'), ('last', 'years', 'deep'), ('years', 'deep', 'learning'), ('deep', 'learning', 'becoming'), ('learning', 'becoming', 'mainstream'), ('becoming', 'mainstream', 'technology'), ('mainstream', 'technology', 'variety'), ('technology', 'variety', 'application'), ('variety', 'application', 'domains'), ('application', 'domains', ','), ('domains', ',', 'like'), (',', 'like', 'face'), ('like', 'face', 'detection'), ('face', 'detection', ','), ('detection', ',', 'speech'), (',', 'speech', 'recognition'), ('speech', 'recognition', 'detection'), ('recognition', 'detection', ','), ('detection', ',', 'object'), (',', 'object', 'recognition'), ('object', 'recognition', ','), ('recognition', ',', 'natural'), (',', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'robotics'), ('processing', 'robotics', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('last', 'JJ'), ('years', 'NNS'), ('deep', 'RB'), ('learning', 'VBG'), ('becoming', 'VBG'), ('mainstream', 'JJ'), ('technology', 'NN'), ('variety', 'NN'), ('application', 'NN'), ('domains', 'NNS'), (',', ','), ('like', 'IN'), ('face', 'NN'), ('detection', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), ('detection', 'NN'), (',', ','), ('object', 'JJ'), ('recognition', 'NN'), (',', ','), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('robotics', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP last/JJ years/NNS)
  deep/RB
  learning/VBG
  becoming/VBG
  (NP
    mainstream/JJ
    technology/NN
    variety/NN
    application/NN
    domains/NNS)
  ,/,
  like/IN
  (NP face/NN detection/NN)
  ,/,
  (NP speech/NN recognition/NN detection/NN)
  ,/,
  (NP object/JJ recognition/NN)
  ,/,
  (NP natural/JJ language/NN processing/NN robotics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['last years', 'mainstream technology variety application domains', 'face detection', 'speech recognition detection', 'object recognition', 'natural language processing robotics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learn'), ('becoming', 'becom'), ('mainstream', 'mainstream'), ('technology', 'technolog'), ('variety', 'varieti'), ('application', 'applic'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face'), ('detection', 'detect'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('detection', 'detect'), (',', ','), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('robotics', 'robot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learn'), ('becoming', 'becom'), ('mainstream', 'mainstream'), ('technology', 'technolog'), ('variety', 'varieti'), ('application', 'applic'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face'), ('detection', 'detect'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('detection', 'detect'), (',', ','), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('robotics', 'robot'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learning'), ('becoming', 'becoming'), ('mainstream', 'mainstream'), ('technology', 'technology'), ('variety', 'variety'), ('application', 'application'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face'), ('detection', 'detection'), (',', ','), ('speech', 'speech'), ('recognition', 'recognition'), ('detection', 'detection'), (',', ','), ('object', 'object'), ('recognition', 'recognition'), (',', ','), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('robotics', 'robotics'), ('.', '.')]



============================ Sentence 208 =============================

We believe that the   challenges posed by big data will bring ample opportunities for ML   algorithms and especially to deep learning methods. 


>> Tokens are: 
 ['We', 'believe', 'challenges', 'posed', 'big', 'data', 'bring', 'ample', 'opportunities', 'ML', 'algorithms', 'especially', 'deep', 'learning', 'methods', '.']

>> Bigrams are: 
 [('We', 'believe'), ('believe', 'challenges'), ('challenges', 'posed'), ('posed', 'big'), ('big', 'data'), ('data', 'bring'), ('bring', 'ample'), ('ample', 'opportunities'), ('opportunities', 'ML'), ('ML', 'algorithms'), ('algorithms', 'especially'), ('especially', 'deep'), ('deep', 'learning'), ('learning', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('We', 'believe', 'challenges'), ('believe', 'challenges', 'posed'), ('challenges', 'posed', 'big'), ('posed', 'big', 'data'), ('big', 'data', 'bring'), ('data', 'bring', 'ample'), ('bring', 'ample', 'opportunities'), ('ample', 'opportunities', 'ML'), ('opportunities', 'ML', 'algorithms'), ('ML', 'algorithms', 'especially'), ('algorithms', 'especially', 'deep'), ('especially', 'deep', 'learning'), ('deep', 'learning', 'methods'), ('learning', 'methods', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('believe', 'VBP'), ('challenges', 'NNS'), ('posed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('bring', 'VBP'), ('ample', 'JJ'), ('opportunities', 'NNS'), ('ML', 'NNP'), ('algorithms', 'VBP'), ('especially', 'RB'), ('deep', 'JJ'), ('learning', 'VBG'), ('methods', 'NNS'), ('.', '.')]

 (S
  We/PRP
  believe/VBP
  (NP challenges/NNS)
  posed/VBD
  (NP big/JJ data/NNS)
  bring/VBP
  (NP ample/JJ opportunities/NNS ML/NNP)
  algorithms/VBP
  especially/RB
  deep/JJ
  learning/VBG
  (NP methods/NNS)
  ./.) 


>> Noun Phrases are: 
 ['challenges', 'big data', 'ample opportunities ML', 'methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('believe', 'believ'), ('challenges', 'challeng'), ('posed', 'pose'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ampl'), ('opportunities', 'opportun'), ('ML', 'ml'), ('algorithms', 'algorithm'), ('especially', 'especi'), ('deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('believe', 'believ'), ('challenges', 'challeng'), ('posed', 'pose'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ampl'), ('opportunities', 'opportun'), ('ML', 'ml'), ('algorithms', 'algorithm'), ('especially', 'especi'), ('deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('believe', 'believe'), ('challenges', 'challenge'), ('posed', 'posed'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ample'), ('opportunities', 'opportunity'), ('ML', 'ML'), ('algorithms', 'algorithm'), ('especially', 'especially'), ('deep', 'deep'), ('learning', 'learning'), ('methods', 'method'), ('.', '.')]



============================ Sentence 209 =============================

ACKNOWLEDGEMENT   I would like to express my gratitude to my teacher, Dr. Wang   Hongjun, whose expertise and guidance added considerably to   my graduate experience. 


>> Tokens are: 
 ['ACKNOWLEDGEMENT', 'I', 'would', 'like', 'express', 'gratitude', 'teacher', ',', 'Dr.', 'Wang', 'Hongjun', ',', 'whose', 'expertise', 'guidance', 'added', 'considerably', 'graduate', 'experience', '.']

>> Bigrams are: 
 [('ACKNOWLEDGEMENT', 'I'), ('I', 'would'), ('would', 'like'), ('like', 'express'), ('express', 'gratitude'), ('gratitude', 'teacher'), ('teacher', ','), (',', 'Dr.'), ('Dr.', 'Wang'), ('Wang', 'Hongjun'), ('Hongjun', ','), (',', 'whose'), ('whose', 'expertise'), ('expertise', 'guidance'), ('guidance', 'added'), ('added', 'considerably'), ('considerably', 'graduate'), ('graduate', 'experience'), ('experience', '.')]

>> Trigrams are: 
 [('ACKNOWLEDGEMENT', 'I', 'would'), ('I', 'would', 'like'), ('would', 'like', 'express'), ('like', 'express', 'gratitude'), ('express', 'gratitude', 'teacher'), ('gratitude', 'teacher', ','), ('teacher', ',', 'Dr.'), (',', 'Dr.', 'Wang'), ('Dr.', 'Wang', 'Hongjun'), ('Wang', 'Hongjun', ','), ('Hongjun', ',', 'whose'), (',', 'whose', 'expertise'), ('whose', 'expertise', 'guidance'), ('expertise', 'guidance', 'added'), ('guidance', 'added', 'considerably'), ('added', 'considerably', 'graduate'), ('considerably', 'graduate', 'experience'), ('graduate', 'experience', '.')]

>> POS Tags are: 
 [('ACKNOWLEDGEMENT', 'NNP'), ('I', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('express', 'JJ'), ('gratitude', 'NN'), ('teacher', 'NN'), (',', ','), ('Dr.', 'NNP'), ('Wang', 'NNP'), ('Hongjun', 'NNP'), (',', ','), ('whose', 'WP$'), ('expertise', 'NN'), ('guidance', 'NN'), ('added', 'VBD'), ('considerably', 'RB'), ('graduate', 'JJ'), ('experience', 'NN'), ('.', '.')]

 (S
  (NP ACKNOWLEDGEMENT/NNP)
  I/PRP
  would/MD
  like/VB
  (NP express/JJ gratitude/NN teacher/NN)
  ,/,
  (NP Dr./NNP Wang/NNP Hongjun/NNP)
  ,/,
  whose/WP$
  (NP expertise/NN guidance/NN)
  added/VBD
  considerably/RB
  (NP graduate/JJ experience/NN)
  ./.) 


>> Noun Phrases are: 
 ['ACKNOWLEDGEMENT', 'express gratitude teacher', 'Dr. Wang Hongjun', 'expertise guidance', 'graduate experience']

>> Named Entities are: 
 [('PERSON', 'Wang Hongjun')] 

>> Stemming using Porter Stemmer: 
 [('ACKNOWLEDGEMENT', 'acknowledg'), ('I', 'i'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitud'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'dr.'), ('Wang', 'wang'), ('Hongjun', 'hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertis'), ('guidance', 'guidanc'), ('added', 'ad'), ('considerably', 'consider'), ('graduate', 'graduat'), ('experience', 'experi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACKNOWLEDGEMENT', 'acknowledg'), ('I', 'i'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitud'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'dr.'), ('Wang', 'wang'), ('Hongjun', 'hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertis'), ('guidance', 'guidanc'), ('added', 'ad'), ('considerably', 'consider'), ('graduate', 'graduat'), ('experience', 'experi'), ('.', '.')]

>> Lemmatization: 
 [('ACKNOWLEDGEMENT', 'ACKNOWLEDGEMENT'), ('I', 'I'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitude'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'Dr.'), ('Wang', 'Wang'), ('Hongjun', 'Hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertise'), ('guidance', 'guidance'), ('added', 'added'), ('considerably', 'considerably'), ('graduate', 'graduate'), ('experience', 'experience'), ('.', '.')]



============================ Sentence 210 =============================

I appreciate his vast knowledge and his   consistent assistance in completing this work. 


>> Tokens are: 
 ['I', 'appreciate', 'vast', 'knowledge', 'consistent', 'assistance', 'completing', 'work', '.']

>> Bigrams are: 
 [('I', 'appreciate'), ('appreciate', 'vast'), ('vast', 'knowledge'), ('knowledge', 'consistent'), ('consistent', 'assistance'), ('assistance', 'completing'), ('completing', 'work'), ('work', '.')]

>> Trigrams are: 
 [('I', 'appreciate', 'vast'), ('appreciate', 'vast', 'knowledge'), ('vast', 'knowledge', 'consistent'), ('knowledge', 'consistent', 'assistance'), ('consistent', 'assistance', 'completing'), ('assistance', 'completing', 'work'), ('completing', 'work', '.')]

>> POS Tags are: 
 [('I', 'PRP'), ('appreciate', 'VBP'), ('vast', 'JJ'), ('knowledge', 'NN'), ('consistent', 'JJ'), ('assistance', 'NN'), ('completing', 'VBG'), ('work', 'NN'), ('.', '.')]

 (S
  I/PRP
  appreciate/VBP
  (NP vast/JJ knowledge/NN)
  (NP consistent/JJ assistance/NN)
  completing/VBG
  (NP work/NN)
  ./.) 


>> Noun Phrases are: 
 ['vast knowledge', 'consistent assistance', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('appreciate', 'appreci'), ('vast', 'vast'), ('knowledge', 'knowledg'), ('consistent', 'consist'), ('assistance', 'assist'), ('completing', 'complet'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('appreciate', 'appreci'), ('vast', 'vast'), ('knowledge', 'knowledg'), ('consistent', 'consist'), ('assistance', 'assist'), ('completing', 'complet'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), ('appreciate', 'appreciate'), ('vast', 'vast'), ('knowledge', 'knowledge'), ('consistent', 'consistent'), ('assistance', 'assistance'), ('completing', 'completing'), ('work', 'work'), ('.', '.')]



============================ Sentence 211 =============================

I would also like   to thank the other PhD Scholars of my school, Mr. Amjad   Ahmed, and Mr. Mehtab Afzal for the assistance they provided   to understand machine learning. 


>> Tokens are: 
 ['I', 'would', 'also', 'like', 'thank', 'PhD', 'Scholars', 'school', ',', 'Mr.', 'Amjad', 'Ahmed', ',', 'Mr.', 'Mehtab', 'Afzal', 'assistance', 'provided', 'understand', 'machine', 'learning', '.']

>> Bigrams are: 
 [('I', 'would'), ('would', 'also'), ('also', 'like'), ('like', 'thank'), ('thank', 'PhD'), ('PhD', 'Scholars'), ('Scholars', 'school'), ('school', ','), (',', 'Mr.'), ('Mr.', 'Amjad'), ('Amjad', 'Ahmed'), ('Ahmed', ','), (',', 'Mr.'), ('Mr.', 'Mehtab'), ('Mehtab', 'Afzal'), ('Afzal', 'assistance'), ('assistance', 'provided'), ('provided', 'understand'), ('understand', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('I', 'would', 'also'), ('would', 'also', 'like'), ('also', 'like', 'thank'), ('like', 'thank', 'PhD'), ('thank', 'PhD', 'Scholars'), ('PhD', 'Scholars', 'school'), ('Scholars', 'school', ','), ('school', ',', 'Mr.'), (',', 'Mr.', 'Amjad'), ('Mr.', 'Amjad', 'Ahmed'), ('Amjad', 'Ahmed', ','), ('Ahmed', ',', 'Mr.'), (',', 'Mr.', 'Mehtab'), ('Mr.', 'Mehtab', 'Afzal'), ('Mehtab', 'Afzal', 'assistance'), ('Afzal', 'assistance', 'provided'), ('assistance', 'provided', 'understand'), ('provided', 'understand', 'machine'), ('understand', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('I', 'PRP'), ('would', 'MD'), ('also', 'RB'), ('like', 'IN'), ('thank', 'NN'), ('PhD', 'NNP'), ('Scholars', 'NNP'), ('school', 'NN'), (',', ','), ('Mr.', 'NNP'), ('Amjad', 'NNP'), ('Ahmed', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Mehtab', 'NNP'), ('Afzal', 'NNP'), ('assistance', 'NN'), ('provided', 'VBD'), ('understand', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  I/PRP
  would/MD
  also/RB
  like/IN
  (NP thank/NN PhD/NNP Scholars/NNP school/NN)
  ,/,
  (NP Mr./NNP Amjad/NNP Ahmed/NNP)
  ,/,
  (NP Mr./NNP Mehtab/NNP Afzal/NNP assistance/NN)
  provided/VBD
  (NP understand/JJ machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['thank PhD Scholars school', 'Mr. Amjad Ahmed', 'Mr. Mehtab Afzal assistance', 'understand machine learning']

>> Named Entities are: 
 [('ORGANIZATION', 'PhD Scholars'), ('PERSON', 'Mr. Amjad Ahmed'), ('PERSON', 'Mr. Mehtab Afzal')] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('would', 'would'), ('also', 'also'), ('like', 'like'), ('thank', 'thank'), ('PhD', 'phd'), ('Scholars', 'scholar'), ('school', 'school'), (',', ','), ('Mr.', 'mr.'), ('Amjad', 'amjad'), ('Ahmed', 'ahm'), (',', ','), ('Mr.', 'mr.'), ('Mehtab', 'mehtab'), ('Afzal', 'afzal'), ('assistance', 'assist'), ('provided', 'provid'), ('understand', 'understand'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('would', 'would'), ('also', 'also'), ('like', 'like'), ('thank', 'thank'), ('PhD', 'phd'), ('Scholars', 'scholar'), ('school', 'school'), (',', ','), ('Mr.', 'mr.'), ('Amjad', 'amjad'), ('Ahmed', 'ahm'), (',', ','), ('Mr.', 'mr.'), ('Mehtab', 'mehtab'), ('Afzal', 'afzal'), ('assistance', 'assist'), ('provided', 'provid'), ('understand', 'understand'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), ('would', 'would'), ('also', 'also'), ('like', 'like'), ('thank', 'thank'), ('PhD', 'PhD'), ('Scholars', 'Scholars'), ('school', 'school'), (',', ','), ('Mr.', 'Mr.'), ('Amjad', 'Amjad'), ('Ahmed', 'Ahmed'), (',', ','), ('Mr.', 'Mr.'), ('Mehtab', 'Mehtab'), ('Afzal', 'Afzal'), ('assistance', 'assistance'), ('provided', 'provided'), ('understand', 'understand'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 212 =============================

Very special thanks goes to Dr.   Zhu Yan, without whose motivation and encouragement, I   confess that it would be difficult for me to move forward in my   PhD Program. 


>> Tokens are: 
 ['Very', 'special', 'thanks', 'goes', 'Dr.', 'Zhu', 'Yan', ',', 'without', 'whose', 'motivation', 'encouragement', ',', 'I', 'confess', 'would', 'difficult', 'move', 'forward', 'PhD', 'Program', '.']

>> Bigrams are: 
 [('Very', 'special'), ('special', 'thanks'), ('thanks', 'goes'), ('goes', 'Dr.'), ('Dr.', 'Zhu'), ('Zhu', 'Yan'), ('Yan', ','), (',', 'without'), ('without', 'whose'), ('whose', 'motivation'), ('motivation', 'encouragement'), ('encouragement', ','), (',', 'I'), ('I', 'confess'), ('confess', 'would'), ('would', 'difficult'), ('difficult', 'move'), ('move', 'forward'), ('forward', 'PhD'), ('PhD', 'Program'), ('Program', '.')]

>> Trigrams are: 
 [('Very', 'special', 'thanks'), ('special', 'thanks', 'goes'), ('thanks', 'goes', 'Dr.'), ('goes', 'Dr.', 'Zhu'), ('Dr.', 'Zhu', 'Yan'), ('Zhu', 'Yan', ','), ('Yan', ',', 'without'), (',', 'without', 'whose'), ('without', 'whose', 'motivation'), ('whose', 'motivation', 'encouragement'), ('motivation', 'encouragement', ','), ('encouragement', ',', 'I'), (',', 'I', 'confess'), ('I', 'confess', 'would'), ('confess', 'would', 'difficult'), ('would', 'difficult', 'move'), ('difficult', 'move', 'forward'), ('move', 'forward', 'PhD'), ('forward', 'PhD', 'Program'), ('PhD', 'Program', '.')]

>> POS Tags are: 
 [('Very', 'RB'), ('special', 'JJ'), ('thanks', 'NNS'), ('goes', 'VBZ'), ('Dr.', 'NNP'), ('Zhu', 'NNP'), ('Yan', 'NNP'), (',', ','), ('without', 'IN'), ('whose', 'WP$'), ('motivation', 'NN'), ('encouragement', 'NN'), (',', ','), ('I', 'PRP'), ('confess', 'VBP'), ('would', 'MD'), ('difficult', 'JJ'), ('move', 'VB'), ('forward', 'RB'), ('PhD', 'NNP'), ('Program', 'NNP'), ('.', '.')]

 (S
  Very/RB
  (NP special/JJ thanks/NNS)
  goes/VBZ
  (NP Dr./NNP Zhu/NNP Yan/NNP)
  ,/,
  without/IN
  whose/WP$
  (NP motivation/NN encouragement/NN)
  ,/,
  I/PRP
  confess/VBP
  would/MD
  difficult/JJ
  move/VB
  forward/RB
  (NP PhD/NNP Program/NNP)
  ./.) 


>> Noun Phrases are: 
 ['special thanks', 'Dr. Zhu Yan', 'motivation encouragement', 'PhD Program']

>> Named Entities are: 
 [('PERSON', 'Zhu Yan'), ('ORGANIZATION', 'PhD Program')] 

>> Stemming using Porter Stemmer: 
 [('Very', 'veri'), ('special', 'special'), ('thanks', 'thank'), ('goes', 'goe'), ('Dr.', 'dr.'), ('Zhu', 'zhu'), ('Yan', 'yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motiv'), ('encouragement', 'encourag'), (',', ','), ('I', 'i'), ('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward'), ('PhD', 'phd'), ('Program', 'program'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Very', 'veri'), ('special', 'special'), ('thanks', 'thank'), ('goes', 'goe'), ('Dr.', 'dr.'), ('Zhu', 'zhu'), ('Yan', 'yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motiv'), ('encouragement', 'encourag'), (',', ','), ('I', 'i'), ('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward'), ('PhD', 'phd'), ('Program', 'program'), ('.', '.')]

>> Lemmatization: 
 [('Very', 'Very'), ('special', 'special'), ('thanks', 'thanks'), ('goes', 'go'), ('Dr.', 'Dr.'), ('Zhu', 'Zhu'), ('Yan', 'Yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motivation'), ('encouragement', 'encouragement'), (',', ','), ('I', 'I'), ('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward'), ('PhD', 'PhD'), ('Program', 'Program'), ('.', '.')]



============================ Sentence 213 =============================

REFERENCES   [1] S. B. Kotsiantis, Supervised Machine Learning: A Review  of Classification Techniques, Informatica, Vol. 


>> Tokens are: 
 ['REFERENCES', '[', '1', ']', 'S.', 'B.', 'Kotsiantis', ',', '', 'Supervised', 'Machine', 'Learning', ':', 'A', 'Review', 'Classification', 'Techniques', '', ',', 'Informatica', ',', 'Vol', '.']

>> Bigrams are: 
 [('REFERENCES', '['), ('[', '1'), ('1', ']'), (']', 'S.'), ('S.', 'B.'), ('B.', 'Kotsiantis'), ('Kotsiantis', ','), (',', ''), ('', 'Supervised'), ('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'A'), ('A', 'Review'), ('Review', 'Classification'), ('Classification', 'Techniques'), ('Techniques', ''), ('', ','), (',', 'Informatica'), ('Informatica', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('REFERENCES', '[', '1'), ('[', '1', ']'), ('1', ']', 'S.'), (']', 'S.', 'B.'), ('S.', 'B.', 'Kotsiantis'), ('B.', 'Kotsiantis', ','), ('Kotsiantis', ',', ''), (',', '', 'Supervised'), ('', 'Supervised', 'Machine'), ('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'A'), (':', 'A', 'Review'), ('A', 'Review', 'Classification'), ('Review', 'Classification', 'Techniques'), ('Classification', 'Techniques', ''), ('Techniques', '', ','), ('', ',', 'Informatica'), (',', 'Informatica', ','), ('Informatica', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('REFERENCES', 'NNP'), ('[', 'VBD'), ('1', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('B.', 'NNP'), ('Kotsiantis', 'NNP'), (',', ','), ('', 'NNP'), ('Supervised', 'VBD'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('A', 'DT'), ('Review', 'NNP'), ('Classification', 'NNP'), ('Techniques', 'NNP'), ('', 'NNP'), (',', ','), ('Informatica', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  (NP REFERENCES/NNP)
  [/VBD
  1/CD
  (NP ]/NNP S./NNP B./NNP Kotsiantis/NNP)
  ,/,
  (NP /NNP)
  Supervised/VBD
  (NP Machine/NNP Learning/NNP)
  :/:
  (NP A/DT Review/NNP Classification/NNP Techniques/NNP /NNP)
  ,/,
  (NP Informatica/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['REFERENCES', '] S. B. Kotsiantis', '', 'Machine Learning', 'A Review Classification Techniques ', 'Informatica', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'REFERENCES'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Review Classification Techniques'), ('GPE', 'Informatica'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('REFERENCES', 'refer'), ('[', '['), ('1', '1'), (']', ']'), ('S.', 's.'), ('B.', 'b.'), ('Kotsiantis', 'kotsianti'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Review', 'review'), ('Classification', 'classif'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('Informatica', 'informatica'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('REFERENCES', 'refer'), ('[', '['), ('1', '1'), (']', ']'), ('S.', 's.'), ('B.', 'b.'), ('Kotsiantis', 'kotsianti'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Review', 'review'), ('Classification', 'classif'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('Informatica', 'informatica'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('REFERENCES', 'REFERENCES'), ('[', '['), ('1', '1'), (']', ']'), ('S.', 'S.'), ('B.', 'B.'), ('Kotsiantis', 'Kotsiantis'), (',', ','), ('', ''), ('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('A', 'A'), ('Review', 'Review'), ('Classification', 'Classification'), ('Techniques', 'Techniques'), ('', ''), (',', ','), ('Informatica', 'Informatica'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 214 =============================

31, No. 


>> Tokens are: 
 ['31', ',', 'No', '.']

>> Bigrams are: 
 [('31', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('31', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('31', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 31/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('31', '31'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('31', '31'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('31', '31'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 215 =============================

3,   pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 216 =============================

249-268, 2007.   javascript:void(0); javascript:void(0); javascript:void(0); javascript:void(0);   IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY   952   [2] James Cussens, Machine Learning, IEEE Journal of  Computing and Control, Vol. 


>> Tokens are: 
 ['249-268', ',', '2007.', 'javascript', ':', 'void', '(', '0', ')', ';', 'javascript', ':', 'void', '(', '0', ')', ';', 'javascript', ':', 'void', '(', '0', ')', ';', 'javascript', ':', 'void', '(', '0', ')', ';', 'IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY', '952', '[', '2', ']', 'James', 'Cussens', ',', '', 'Machine', 'Learning', '', ',', 'IEEE', 'Journal', 'Computing', 'Control', ',', 'Vol', '.']

>> Bigrams are: 
 [('249-268', ','), (',', '2007.'), ('2007.', 'javascript'), ('javascript', ':'), (':', 'void'), ('void', '('), ('(', '0'), ('0', ')'), (')', ';'), (';', 'javascript'), ('javascript', ':'), (':', 'void'), ('void', '('), ('(', '0'), ('0', ')'), (')', ';'), (';', 'javascript'), ('javascript', ':'), (':', 'void'), ('void', '('), ('(', '0'), ('0', ')'), (')', ';'), (';', 'javascript'), ('javascript', ':'), (':', 'void'), ('void', '('), ('(', '0'), ('0', ')'), (')', ';'), (';', 'IQBAL'), ('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY'), ('SURVEY', '952'), ('952', '['), ('[', '2'), ('2', ']'), (']', 'James'), ('James', 'Cussens'), ('Cussens', ','), (',', ''), ('', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Journal'), ('Journal', 'Computing'), ('Computing', 'Control'), ('Control', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('249-268', ',', '2007.'), (',', '2007.', 'javascript'), ('2007.', 'javascript', ':'), ('javascript', ':', 'void'), (':', 'void', '('), ('void', '(', '0'), ('(', '0', ')'), ('0', ')', ';'), (')', ';', 'javascript'), (';', 'javascript', ':'), ('javascript', ':', 'void'), (':', 'void', '('), ('void', '(', '0'), ('(', '0', ')'), ('0', ')', ';'), (')', ';', 'javascript'), (';', 'javascript', ':'), ('javascript', ':', 'void'), (':', 'void', '('), ('void', '(', '0'), ('(', '0', ')'), ('0', ')', ';'), (')', ';', 'javascript'), (';', 'javascript', ':'), ('javascript', ':', 'void'), (':', 'void', '('), ('void', '(', '0'), ('(', '0', ')'), ('0', ')', ';'), (')', ';', 'IQBAL'), (';', 'IQBAL', 'MUHAMMAD'), ('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY'), ('A', 'SURVEY', '952'), ('SURVEY', '952', '['), ('952', '[', '2'), ('[', '2', ']'), ('2', ']', 'James'), (']', 'James', 'Cussens'), ('James', 'Cussens', ','), ('Cussens', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Journal'), ('IEEE', 'Journal', 'Computing'), ('Journal', 'Computing', 'Control'), ('Computing', 'Control', ','), ('Control', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('249-268', 'JJ'), (',', ','), ('2007.', 'CD'), ('javascript', 'NN'), (':', ':'), ('void', 'NN'), ('(', '('), ('0', 'CD'), (')', ')'), (';', ':'), ('javascript', 'NN'), (':', ':'), ('void', 'NN'), ('(', '('), ('0', 'CD'), (')', ')'), (';', ':'), ('javascript', 'NN'), (':', ':'), ('void', 'NN'), ('(', '('), ('0', 'CD'), (')', ')'), (';', ':'), ('javascript', 'NN'), (':', ':'), ('void', 'NN'), ('(', '('), ('0', 'CD'), (')', ')'), (';', ':'), ('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NNP'), ('952', 'CD'), ('[', 'VBD'), ('2', 'CD'), (']', 'NNP'), ('James', 'NNP'), ('Cussens', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Journal', 'NNP'), ('Computing', 'NNP'), ('Control', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  249-268/JJ
  ,/,
  2007./CD
  (NP javascript/NN)
  :/:
  (NP void/NN)
  (/(
  0/CD
  )/)
  ;/:
  (NP javascript/NN)
  :/:
  (NP void/NN)
  (/(
  0/CD
  )/)
  ;/:
  (NP javascript/NN)
  :/:
  (NP void/NN)
  (/(
  0/CD
  )/)
  ;/:
  (NP javascript/NN)
  :/:
  (NP void/NN)
  (/(
  0/CD
  )/)
  ;/:
  (NP IQBAL/NNP MUHAMMAD/NNP AND/NNP ZHU/NNP YAN/NNP)
  :/:
  (NP SUPERVISED/NNP MACHINE/NNP LEARNING/NNP APPROACHES/NNP)
  :/:
  (NP A/DT SURVEY/NNP)
  952/CD
  [/VBD
  2/CD
  (NP ]/NNP James/NNP Cussens/NNP)
  ,/,
  (NP /NNP Machine/NNP Learning/NNP /NNP)
  ,/,
  (NP IEEE/NNP Journal/NNP Computing/NNP Control/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['javascript', 'void', 'javascript', 'void', 'javascript', 'void', 'javascript', 'void', 'IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY', '] James Cussens', ' Machine Learning ', 'IEEE Journal Computing Control', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE'), ('PERSON', 'James Cussens'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'IEEE Journal'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('249-268', '249-268'), (',', ','), ('2007.', '2007.'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('952', '952'), ('[', '['), ('2', '2'), (']', ']'), ('James', 'jame'), ('Cussens', 'cussen'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Computing', 'comput'), ('Control', 'control'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('249-268', '249-268'), (',', ','), ('2007.', '2007.'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey'), ('952', '952'), ('[', '['), ('2', '2'), (']', ']'), ('James', 'jame'), ('Cussens', 'cussen'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Computing', 'comput'), ('Control', 'control'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('249-268', '249-268'), (',', ','), ('2007.', '2007.'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('javascript', 'javascript'), (':', ':'), ('void', 'void'), ('(', '('), ('0', '0'), (')', ')'), (';', ';'), ('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY'), ('952', '952'), ('[', '['), ('2', '2'), (']', ']'), ('James', 'James'), ('Cussens', 'Cussens'), (',', ','), ('', ''), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Journal', 'Journal'), ('Computing', 'Computing'), ('Control', 'Control'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 217 =============================

7, No. 


>> Tokens are: 
 ['7', ',', 'No', '.']

>> Bigrams are: 
 [('7', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('7', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 7/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 218 =============================

4, pp 164-168, 1996. 


>> Tokens are: 
 ['4', ',', 'pp', '164-168', ',', '1996', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '164-168'), ('164-168', ','), (',', '1996'), ('1996', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '164-168'), ('pp', '164-168', ','), ('164-168', ',', '1996'), (',', '1996', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'JJ'), ('164-168', 'CD'), (',', ','), ('1996', 'CD'), ('.', '.')]

 (S 4/CD ,/, pp/JJ 164-168/CD ,/, 1996/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]



============================ Sentence 219 =============================

[3] Richard S. Sutton and Andrew G. Barto, Reinforcement  Learning: An Introduction, Cambridge, MA: MIT Press, 1998. 


>> Tokens are: 
 ['[', '3', ']', 'Richard', 'S.', 'Sutton', 'Andrew', 'G.', 'Barto', ',', '', 'Reinforcement', 'Learning', ':', 'An', 'Introduction', '', ',', 'Cambridge', ',', 'MA', ':', 'MIT', 'Press', ',', '1998', '.']

>> Bigrams are: 
 [('[', '3'), ('3', ']'), (']', 'Richard'), ('Richard', 'S.'), ('S.', 'Sutton'), ('Sutton', 'Andrew'), ('Andrew', 'G.'), ('G.', 'Barto'), ('Barto', ','), (',', ''), ('', 'Reinforcement'), ('Reinforcement', 'Learning'), ('Learning', ':'), (':', 'An'), ('An', 'Introduction'), ('Introduction', ''), ('', ','), (',', 'Cambridge'), ('Cambridge', ','), (',', 'MA'), ('MA', ':'), (':', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('[', '3', ']'), ('3', ']', 'Richard'), (']', 'Richard', 'S.'), ('Richard', 'S.', 'Sutton'), ('S.', 'Sutton', 'Andrew'), ('Sutton', 'Andrew', 'G.'), ('Andrew', 'G.', 'Barto'), ('G.', 'Barto', ','), ('Barto', ',', ''), (',', '', 'Reinforcement'), ('', 'Reinforcement', 'Learning'), ('Reinforcement', 'Learning', ':'), ('Learning', ':', 'An'), (':', 'An', 'Introduction'), ('An', 'Introduction', ''), ('Introduction', '', ','), ('', ',', 'Cambridge'), (',', 'Cambridge', ','), ('Cambridge', ',', 'MA'), (',', 'MA', ':'), ('MA', ':', 'MIT'), (':', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('3', 'CD'), (']', 'JJ'), ('Richard', 'NNP'), ('S.', 'NNP'), ('Sutton', 'NNP'), ('Andrew', 'NNP'), ('G.', 'NNP'), ('Barto', 'NNP'), (',', ','), ('', 'NNP'), ('Reinforcement', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('An', 'DT'), ('Introduction', 'NNP'), ('', 'NN'), (',', ','), ('Cambridge', 'NNP'), (',', ','), ('MA', 'NNP'), (':', ':'), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('1998', 'CD'), ('.', '.')]

 (S
  [/RB
  3/CD
  (NP ]/JJ Richard/NNP S./NNP Sutton/NNP Andrew/NNP G./NNP Barto/NNP)
  ,/,
  (NP /NNP Reinforcement/NNP Learning/NNP)
  :/:
  (NP An/DT Introduction/NNP /NN)
  ,/,
  (NP Cambridge/NNP)
  ,/,
  (NP MA/NNP)
  :/:
  (NP MIT/NNP Press/NNP)
  ,/,
  1998/CD
  ./.) 


>> Noun Phrases are: 
 ['] Richard S. Sutton Andrew G. Barto', ' Reinforcement Learning', 'An Introduction ', 'Cambridge', 'MA', 'MIT Press']

>> Named Entities are: 
 [('PERSON', 'Richard S. Sutton'), ('PERSON', 'Andrew G. Barto'), ('GPE', 'Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'richard'), ('S.', 's.'), ('Sutton', 'sutton'), ('Andrew', 'andrew'), ('G.', 'g.'), ('Barto', 'barto'), (',', ','), ('', ''), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), (':', ':'), ('An', 'an'), ('Introduction', 'introduct'), ('', ''), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'richard'), ('S.', 's.'), ('Sutton', 'sutton'), ('Andrew', 'andrew'), ('G.', 'g.'), ('Barto', 'barto'), (',', ','), ('', ''), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), (':', ':'), ('An', 'an'), ('Introduction', 'introduct'), ('', ''), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'Richard'), ('S.', 'S.'), ('Sutton', 'Sutton'), ('Andrew', 'Andrew'), ('G.', 'G.'), ('Barto', 'Barto'), (',', ','), ('', ''), ('Reinforcement', 'Reinforcement'), ('Learning', 'Learning'), (':', ':'), ('An', 'An'), ('Introduction', 'Introduction'), ('', ''), (',', ','), ('Cambridge', 'Cambridge'), (',', ','), ('MA', 'MA'), (':', ':'), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('1998', '1998'), ('.', '.')]



============================ Sentence 220 =============================

[4] Victoria J. Hodge and Jim Austin, A Survey of Outlier  Detection Methodologies, Artificial Intelligence Review,   Vol. 


>> Tokens are: 
 ['[', '4', ']', 'Victoria', 'J.', 'Hodge', 'Jim', 'Austin', ',', '', 'A', 'Survey', 'Outlier', 'Detection', 'Methodologies', '', ',', 'Artificial', 'Intelligence', 'Review', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '4'), ('4', ']'), (']', 'Victoria'), ('Victoria', 'J.'), ('J.', 'Hodge'), ('Hodge', 'Jim'), ('Jim', 'Austin'), ('Austin', ','), (',', ''), ('', 'A'), ('A', 'Survey'), ('Survey', 'Outlier'), ('Outlier', 'Detection'), ('Detection', 'Methodologies'), ('Methodologies', ''), ('', ','), (',', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Review'), ('Review', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '4', ']'), ('4', ']', 'Victoria'), (']', 'Victoria', 'J.'), ('Victoria', 'J.', 'Hodge'), ('J.', 'Hodge', 'Jim'), ('Hodge', 'Jim', 'Austin'), ('Jim', 'Austin', ','), ('Austin', ',', ''), (',', '', 'A'), ('', 'A', 'Survey'), ('A', 'Survey', 'Outlier'), ('Survey', 'Outlier', 'Detection'), ('Outlier', 'Detection', 'Methodologies'), ('Detection', 'Methodologies', ''), ('Methodologies', '', ','), ('', ',', 'Artificial'), (',', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Review'), ('Intelligence', 'Review', ','), ('Review', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('4', 'CD'), (']', 'JJ'), ('Victoria', 'NNP'), ('J.', 'NNP'), ('Hodge', 'NNP'), ('Jim', 'NNP'), ('Austin', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Survey', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), ('Methodologies', 'NNP'), ('', 'NNP'), (',', ','), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Review', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  4/CD
  (NP ]/JJ Victoria/NNP J./NNP Hodge/NNP Jim/NNP Austin/NNP)
  ,/,
  /VBZ
  (NP
    A/NNP
    Survey/NNP
    Outlier/NNP
    Detection/NNP
    Methodologies/NNP
    /NNP)
  ,/,
  (NP Artificial/NNP Intelligence/NNP Review/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Victoria J. Hodge Jim Austin', 'A Survey Outlier Detection Methodologies ', 'Artificial Intelligence Review', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Victoria'), ('PERSON', 'Jim Austin'), ('ORGANIZATION', 'Artificial Intelligence Review'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'victoria'), ('J.', 'j.'), ('Hodge', 'hodg'), ('Jim', 'jim'), ('Austin', 'austin'), (',', ','), ('', ''), ('A', 'a'), ('Survey', 'survey'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Methodologies', 'methodolog'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'victoria'), ('J.', 'j.'), ('Hodge', 'hodg'), ('Jim', 'jim'), ('Austin', 'austin'), (',', ','), ('', ''), ('A', 'a'), ('Survey', 'survey'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Methodologies', 'methodolog'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'Victoria'), ('J.', 'J.'), ('Hodge', 'Hodge'), ('Jim', 'Jim'), ('Austin', 'Austin'), (',', ','), ('', ''), ('A', 'A'), ('Survey', 'Survey'), ('Outlier', 'Outlier'), ('Detection', 'Detection'), ('Methodologies', 'Methodologies'), ('', ''), (',', ','), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Review', 'Review'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 221 =============================

22, No. 


>> Tokens are: 
 ['22', ',', 'No', '.']

>> Bigrams are: 
 [('22', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('22', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('22', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 22/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 222 =============================

2, pp. 


>> Tokens are: 
 ['2', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 2/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 223 =============================

85-126, 2004. 


>> Tokens are: 
 ['85-126', ',', '2004', '.']

>> Bigrams are: 
 [('85-126', ','), (',', '2004'), ('2004', '.')]

>> Trigrams are: 
 [('85-126', ',', '2004'), (',', '2004', '.')]

>> POS Tags are: 
 [('85-126', 'CD'), (',', ','), ('2004', 'CD'), ('.', '.')]

 (S 85-126/CD ,/, 2004/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Lemmatization: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]



============================ Sentence 224 =============================

[5] Karanjit Singh and Shuchita Upadhyaya, Outlier Detection:  Applications and Techniques, International Journal of Computer   Science Issues, Vol. 


>> Tokens are: 
 ['[', '5', ']', 'Karanjit', 'Singh', 'Shuchita', 'Upadhyaya', ',', '', 'Outlier', 'Detection', ':', 'Applications', 'Techniques', '', ',', 'International', 'Journal', 'Computer', 'Science', 'Issues', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'Karanjit'), ('Karanjit', 'Singh'), ('Singh', 'Shuchita'), ('Shuchita', 'Upadhyaya'), ('Upadhyaya', ','), (',', ''), ('', 'Outlier'), ('Outlier', 'Detection'), ('Detection', ':'), (':', 'Applications'), ('Applications', 'Techniques'), ('Techniques', ''), ('', ','), (',', 'International'), ('International', 'Journal'), ('Journal', 'Computer'), ('Computer', 'Science'), ('Science', 'Issues'), ('Issues', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'Karanjit'), (']', 'Karanjit', 'Singh'), ('Karanjit', 'Singh', 'Shuchita'), ('Singh', 'Shuchita', 'Upadhyaya'), ('Shuchita', 'Upadhyaya', ','), ('Upadhyaya', ',', ''), (',', '', 'Outlier'), ('', 'Outlier', 'Detection'), ('Outlier', 'Detection', ':'), ('Detection', ':', 'Applications'), (':', 'Applications', 'Techniques'), ('Applications', 'Techniques', ''), ('Techniques', '', ','), ('', ',', 'International'), (',', 'International', 'Journal'), ('International', 'Journal', 'Computer'), ('Journal', 'Computer', 'Science'), ('Computer', 'Science', 'Issues'), ('Science', 'Issues', ','), ('Issues', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'JJ'), ('Karanjit', 'NNP'), ('Singh', 'NNP'), ('Shuchita', 'NNP'), ('Upadhyaya', 'NNP'), (',', ','), ('', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), (':', ':'), ('Applications', 'NNS'), ('Techniques', 'NNP'), ('', 'NNP'), (',', ','), ('International', 'NNP'), ('Journal', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Issues', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  5/CD
  (NP ]/JJ Karanjit/NNP Singh/NNP Shuchita/NNP Upadhyaya/NNP)
  ,/,
  (NP /NNP Outlier/NNP Detection/NNP)
  :/:
  (NP Applications/NNS Techniques/NNP /NNP)
  ,/,
  (NP
    International/NNP
    Journal/NNP
    Computer/NNP
    Science/NNP
    Issues/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Karanjit Singh Shuchita Upadhyaya', ' Outlier Detection', 'Applications Techniques ', 'International Journal Computer Science Issues', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Karanjit Singh Shuchita Upadhyaya'), ('PERSON', 'Techniques'), ('ORGANIZATION', 'International Journal Computer Science Issues'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'karanjit'), ('Singh', 'singh'), ('Shuchita', 'shuchita'), ('Upadhyaya', 'upadhyaya'), (',', ','), ('', ''), ('Outlier', 'outlier'), ('Detection', 'detect'), (':', ':'), ('Applications', 'applic'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Issues', 'issu'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'karanjit'), ('Singh', 'singh'), ('Shuchita', 'shuchita'), ('Upadhyaya', 'upadhyaya'), (',', ','), ('', ''), ('Outlier', 'outlier'), ('Detection', 'detect'), (':', ':'), ('Applications', 'applic'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Issues', 'issu'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'Karanjit'), ('Singh', 'Singh'), ('Shuchita', 'Shuchita'), ('Upadhyaya', 'Upadhyaya'), (',', ','), ('', ''), ('Outlier', 'Outlier'), ('Detection', 'Detection'), (':', ':'), ('Applications', 'Applications'), ('Techniques', 'Techniques'), ('', ''), (',', ','), ('International', 'International'), ('Journal', 'Journal'), ('Computer', 'Computer'), ('Science', 'Science'), ('Issues', 'Issues'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 225 =============================

9, Issue. 


>> Tokens are: 
 ['9', ',', 'Issue', '.']

>> Bigrams are: 
 [('9', ','), (',', 'Issue'), ('Issue', '.')]

>> Trigrams are: 
 [('9', ',', 'Issue'), (',', 'Issue', '.')]

>> POS Tags are: 
 [('9', 'CD'), (',', ','), ('Issue', 'NNP'), ('.', '.')]

 (S 9/CD ,/, (NP Issue/NNP) ./.) 


>> Noun Phrases are: 
 ['Issue']

>> Named Entities are: 
 [('PERSON', 'Issue')] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), (',', ','), ('Issue', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), (',', ','), ('Issue', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), (',', ','), ('Issue', 'Issue'), ('.', '.')]



============================ Sentence 226 =============================

1, No. 


>> Tokens are: 
 ['1', ',', 'No', '.']

>> Bigrams are: 
 [('1', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('1', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 1/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 227 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 228 =============================

307-323, 2012. 


>> Tokens are: 
 ['307-323', ',', '2012', '.']

>> Bigrams are: 
 [('307-323', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('307-323', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('307-323', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S 307-323/CD ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 229 =============================

[6] Hugo Jair Escalante, A Comparison of Outlier Detection  Algorithms for Machine Learning, CIC-2005 Congreso   Internacional en Computacion-IPN, 2005. 


>> Tokens are: 
 ['[', '6', ']', 'Hugo', 'Jair', 'Escalante', ',', '', 'A', 'Comparison', 'Outlier', 'Detection', 'Algorithms', 'Machine', 'Learning', '', ',', 'CIC-2005', 'Congreso', 'Internacional', 'en', 'Computacion-IPN', ',', '2005', '.']

>> Bigrams are: 
 [('[', '6'), ('6', ']'), (']', 'Hugo'), ('Hugo', 'Jair'), ('Jair', 'Escalante'), ('Escalante', ','), (',', ''), ('', 'A'), ('A', 'Comparison'), ('Comparison', 'Outlier'), ('Outlier', 'Detection'), ('Detection', 'Algorithms'), ('Algorithms', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'CIC-2005'), ('CIC-2005', 'Congreso'), ('Congreso', 'Internacional'), ('Internacional', 'en'), ('en', 'Computacion-IPN'), ('Computacion-IPN', ','), (',', '2005'), ('2005', '.')]

>> Trigrams are: 
 [('[', '6', ']'), ('6', ']', 'Hugo'), (']', 'Hugo', 'Jair'), ('Hugo', 'Jair', 'Escalante'), ('Jair', 'Escalante', ','), ('Escalante', ',', ''), (',', '', 'A'), ('', 'A', 'Comparison'), ('A', 'Comparison', 'Outlier'), ('Comparison', 'Outlier', 'Detection'), ('Outlier', 'Detection', 'Algorithms'), ('Detection', 'Algorithms', 'Machine'), ('Algorithms', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'CIC-2005'), (',', 'CIC-2005', 'Congreso'), ('CIC-2005', 'Congreso', 'Internacional'), ('Congreso', 'Internacional', 'en'), ('Internacional', 'en', 'Computacion-IPN'), ('en', 'Computacion-IPN', ','), ('Computacion-IPN', ',', '2005'), (',', '2005', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('6', 'CD'), (']', 'JJ'), ('Hugo', 'NNP'), ('Jair', 'NNP'), ('Escalante', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Comparison', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), ('Algorithms', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('CIC-2005', 'NNP'), ('Congreso', 'NNP'), ('Internacional', 'NNP'), ('en', 'IN'), ('Computacion-IPN', 'NNP'), (',', ','), ('2005', 'CD'), ('.', '.')]

 (S
  [/RB
  6/CD
  (NP ]/JJ Hugo/NNP Jair/NNP Escalante/NNP)
  ,/,
  /VBZ
  (NP
    A/NNP
    Comparison/NNP
    Outlier/NNP
    Detection/NNP
    Algorithms/NNP
    Machine/NNP
    Learning/NNP
    /NNP)
  ,/,
  (NP CIC-2005/NNP Congreso/NNP Internacional/NNP)
  en/IN
  (NP Computacion-IPN/NNP)
  ,/,
  2005/CD
  ./.) 


>> Noun Phrases are: 
 ['] Hugo Jair Escalante', 'A Comparison Outlier Detection Algorithms Machine Learning ', 'CIC-2005 Congreso Internacional', 'Computacion-IPN']

>> Named Entities are: 
 [('PERSON', 'Hugo Jair Escalante'), ('ORGANIZATION', 'Comparison Outlier'), ('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'hugo'), ('Jair', 'jair'), ('Escalante', 'escalant'), (',', ','), ('', ''), ('A', 'a'), ('Comparison', 'comparison'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Algorithms', 'algorithm'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('CIC-2005', 'cic-2005'), ('Congreso', 'congreso'), ('Internacional', 'internacion'), ('en', 'en'), ('Computacion-IPN', 'computacion-ipn'), (',', ','), ('2005', '2005'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'hugo'), ('Jair', 'jair'), ('Escalante', 'escalant'), (',', ','), ('', ''), ('A', 'a'), ('Comparison', 'comparison'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Algorithms', 'algorithm'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('CIC-2005', 'cic-2005'), ('Congreso', 'congreso'), ('Internacional', 'internacion'), ('en', 'en'), ('Computacion-IPN', 'computacion-ipn'), (',', ','), ('2005', '2005'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'Hugo'), ('Jair', 'Jair'), ('Escalante', 'Escalante'), (',', ','), ('', ''), ('A', 'A'), ('Comparison', 'Comparison'), ('Outlier', 'Outlier'), ('Detection', 'Detection'), ('Algorithms', 'Algorithms'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('CIC-2005', 'CIC-2005'), ('Congreso', 'Congreso'), ('Internacional', 'Internacional'), ('en', 'en'), ('Computacion-IPN', 'Computacion-IPN'), (',', ','), ('2005', '2005'), ('.', '.')]



============================ Sentence 230 =============================

[7] Pierre Geurts, Alexandre Irrthum, Louis Wehenkel,  Supervised learning with decision tree-based methods in   computational and systems biology, Molecular   BioSystems, Vol. 


>> Tokens are: 
 ['[', '7', ']', 'Pierre', 'Geurts', ',', 'Alexandre', 'Irrthum', ',', 'Louis', 'Wehenkel', ',', '', 'Supervised', 'learning', 'decision', 'tree-based', 'methods', 'computational', 'systems', 'biology', '', ',', 'Molecular', 'BioSystems', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', 'Pierre'), ('Pierre', 'Geurts'), ('Geurts', ','), (',', 'Alexandre'), ('Alexandre', 'Irrthum'), ('Irrthum', ','), (',', 'Louis'), ('Louis', 'Wehenkel'), ('Wehenkel', ','), (',', ''), ('', 'Supervised'), ('Supervised', 'learning'), ('learning', 'decision'), ('decision', 'tree-based'), ('tree-based', 'methods'), ('methods', 'computational'), ('computational', 'systems'), ('systems', 'biology'), ('biology', ''), ('', ','), (',', 'Molecular'), ('Molecular', 'BioSystems'), ('BioSystems', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', 'Pierre'), (']', 'Pierre', 'Geurts'), ('Pierre', 'Geurts', ','), ('Geurts', ',', 'Alexandre'), (',', 'Alexandre', 'Irrthum'), ('Alexandre', 'Irrthum', ','), ('Irrthum', ',', 'Louis'), (',', 'Louis', 'Wehenkel'), ('Louis', 'Wehenkel', ','), ('Wehenkel', ',', ''), (',', '', 'Supervised'), ('', 'Supervised', 'learning'), ('Supervised', 'learning', 'decision'), ('learning', 'decision', 'tree-based'), ('decision', 'tree-based', 'methods'), ('tree-based', 'methods', 'computational'), ('methods', 'computational', 'systems'), ('computational', 'systems', 'biology'), ('systems', 'biology', ''), ('biology', '', ','), ('', ',', 'Molecular'), (',', 'Molecular', 'BioSystems'), ('Molecular', 'BioSystems', ','), ('BioSystems', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('Pierre', 'NNP'), ('Geurts', 'NNP'), (',', ','), ('Alexandre', 'NNP'), ('Irrthum', 'NNP'), (',', ','), ('Louis', 'NNP'), ('Wehenkel', 'NNP'), (',', ','), ('', 'NNP'), ('Supervised', 'VBD'), ('learning', 'VBG'), ('decision', 'NN'), ('tree-based', 'JJ'), ('methods', 'NNS'), ('computational', 'JJ'), ('systems', 'NNS'), ('biology', 'NN'), ('', 'NNP'), (',', ','), ('Molecular', 'NNP'), ('BioSystems', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  7/CD
  (NP ]/JJ Pierre/NNP Geurts/NNP)
  ,/,
  (NP Alexandre/NNP Irrthum/NNP)
  ,/,
  (NP Louis/NNP Wehenkel/NNP)
  ,/,
  (NP /NNP)
  Supervised/VBD
  learning/VBG
  (NP decision/NN)
  (NP tree-based/JJ methods/NNS)
  (NP computational/JJ systems/NNS biology/NN /NNP)
  ,/,
  (NP Molecular/NNP BioSystems/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Pierre Geurts', 'Alexandre Irrthum', 'Louis Wehenkel', '', 'decision', 'tree-based methods', 'computational systems biology ', 'Molecular BioSystems', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Pierre Geurts'), ('PERSON', 'Alexandre Irrthum'), ('PERSON', 'Louis Wehenkel'), ('PERSON', 'Molecular BioSystems'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'pierr'), ('Geurts', 'geurt'), (',', ','), ('Alexandre', 'alexandr'), ('Irrthum', 'irrthum'), (',', ','), ('Louis', 'loui'), ('Wehenkel', 'wehenkel'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('learning', 'learn'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('methods', 'method'), ('computational', 'comput'), ('systems', 'system'), ('biology', 'biolog'), ('', ''), (',', ','), ('Molecular', 'molecular'), ('BioSystems', 'biosystem'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'pierr'), ('Geurts', 'geurt'), (',', ','), ('Alexandre', 'alexandr'), ('Irrthum', 'irrthum'), (',', ','), ('Louis', 'loui'), ('Wehenkel', 'wehenkel'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('learning', 'learn'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('methods', 'method'), ('computational', 'comput'), ('systems', 'system'), ('biology', 'biolog'), ('', ''), (',', ','), ('Molecular', 'molecular'), ('BioSystems', 'biosystem'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'Pierre'), ('Geurts', 'Geurts'), (',', ','), ('Alexandre', 'Alexandre'), ('Irrthum', 'Irrthum'), (',', ','), ('Louis', 'Louis'), ('Wehenkel', 'Wehenkel'), (',', ','), ('', ''), ('Supervised', 'Supervised'), ('learning', 'learning'), ('decision', 'decision'), ('tree-based', 'tree-based'), ('methods', 'method'), ('computational', 'computational'), ('systems', 'system'), ('biology', 'biology'), ('', ''), (',', ','), ('Molecular', 'Molecular'), ('BioSystems', 'BioSystems'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 231 =============================

5, No. 


>> Tokens are: 
 ['5', ',', 'No', '.']

>> Bigrams are: 
 [('5', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('5', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 5/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 232 =============================

12, pp. 


>> Tokens are: 
 ['12', ',', 'pp', '.']

>> Bigrams are: 
 [('12', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('12', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 12/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 233 =============================

1593-1605, 2009. 


>> Tokens are: 
 ['1593-1605', ',', '2009', '.']

>> Bigrams are: 
 [('1593-1605', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('1593-1605', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('1593-1605', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

 (S 1593-1605/CD ,/, 2009/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]



============================ Sentence 234 =============================

[8] L. Breiman, J. Friedman, R. A. Olsen and C. J. 


>> Tokens are: 
 ['[', '8', ']', 'L.', 'Breiman', ',', 'J.', 'Friedman', ',', 'R.', 'A.', 'Olsen', 'C.', 'J', '.']

>> Bigrams are: 
 [('[', '8'), ('8', ']'), (']', 'L.'), ('L.', 'Breiman'), ('Breiman', ','), (',', 'J.'), ('J.', 'Friedman'), ('Friedman', ','), (',', 'R.'), ('R.', 'A.'), ('A.', 'Olsen'), ('Olsen', 'C.'), ('C.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '8', ']'), ('8', ']', 'L.'), (']', 'L.', 'Breiman'), ('L.', 'Breiman', ','), ('Breiman', ',', 'J.'), (',', 'J.', 'Friedman'), ('J.', 'Friedman', ','), ('Friedman', ',', 'R.'), (',', 'R.', 'A.'), ('R.', 'A.', 'Olsen'), ('A.', 'Olsen', 'C.'), ('Olsen', 'C.', 'J'), ('C.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('8', 'CD'), (']', 'JJ'), ('L.', 'NNP'), ('Breiman', 'NNP'), (',', ','), ('J.', 'NNP'), ('Friedman', 'NNP'), (',', ','), ('R.', 'NNP'), ('A.', 'NNP'), ('Olsen', 'NNP'), ('C.', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S
  [/RB
  8/CD
  (NP ]/JJ L./NNP Breiman/NNP)
  ,/,
  (NP J./NNP Friedman/NNP)
  ,/,
  (NP R./NNP A./NNP Olsen/NNP C./NNP J/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] L. Breiman', 'J. Friedman', 'R. A. Olsen C. J']

>> Named Entities are: 
 [('PERSON', 'J. Friedman')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'l.'), ('Breiman', 'breiman'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('R.', 'r.'), ('A.', 'a.'), ('Olsen', 'olsen'), ('C.', 'c.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'l.'), ('Breiman', 'breiman'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('R.', 'r.'), ('A.', 'a.'), ('Olsen', 'olsen'), ('C.', 'c.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'L.'), ('Breiman', 'Breiman'), (',', ','), ('J.', 'J.'), ('Friedman', 'Friedman'), (',', ','), ('R.', 'R.'), ('A.', 'A.'), ('Olsen', 'Olsen'), ('C.', 'C.'), ('J', 'J'), ('.', '.')]



============================ Sentence 235 =============================

Stone,  Classification and Regression Trees, Belmont,   California: Wadsworth International Group, 1984. 


>> Tokens are: 
 ['Stone', ',', '', 'Classification', 'Regression', 'Trees', '', ',', 'Belmont', ',', 'California', ':', 'Wadsworth', 'International', 'Group', ',', '1984', '.']

>> Bigrams are: 
 [('Stone', ','), (',', ''), ('', 'Classification'), ('Classification', 'Regression'), ('Regression', 'Trees'), ('Trees', ''), ('', ','), (',', 'Belmont'), ('Belmont', ','), (',', 'California'), ('California', ':'), (':', 'Wadsworth'), ('Wadsworth', 'International'), ('International', 'Group'), ('Group', ','), (',', '1984'), ('1984', '.')]

>> Trigrams are: 
 [('Stone', ',', ''), (',', '', 'Classification'), ('', 'Classification', 'Regression'), ('Classification', 'Regression', 'Trees'), ('Regression', 'Trees', ''), ('Trees', '', ','), ('', ',', 'Belmont'), (',', 'Belmont', ','), ('Belmont', ',', 'California'), (',', 'California', ':'), ('California', ':', 'Wadsworth'), (':', 'Wadsworth', 'International'), ('Wadsworth', 'International', 'Group'), ('International', 'Group', ','), ('Group', ',', '1984'), (',', '1984', '.')]

>> POS Tags are: 
 [('Stone', 'NN'), (',', ','), ('', 'JJ'), ('Classification', 'NNP'), ('Regression', 'NNP'), ('Trees', 'NNP'), ('', 'NNP'), (',', ','), ('Belmont', 'NNP'), (',', ','), ('California', 'NNP'), (':', ':'), ('Wadsworth', 'JJ'), ('International', 'NNP'), ('Group', 'NNP'), (',', ','), ('1984', 'CD'), ('.', '.')]

 (S
  (NP Stone/NN)
  ,/,
  (NP /JJ Classification/NNP Regression/NNP Trees/NNP /NNP)
  ,/,
  (NP Belmont/NNP)
  ,/,
  (NP California/NNP)
  :/:
  (NP Wadsworth/JJ International/NNP Group/NNP)
  ,/,
  1984/CD
  ./.) 


>> Noun Phrases are: 
 ['Stone', ' Classification Regression Trees ', 'Belmont', 'California', 'Wadsworth International Group']

>> Named Entities are: 
 [('GPE', 'Stone'), ('PERSON', 'Trees'), ('GPE', 'Belmont'), ('GPE', 'California'), ('PERSON', 'Wadsworth'), ('ORGANIZATION', 'International Group')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('', ''), (',', ','), ('Belmont', 'belmont'), (',', ','), ('California', 'california'), (':', ':'), ('Wadsworth', 'wadsworth'), ('International', 'intern'), ('Group', 'group'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('', ''), (',', ','), ('Belmont', 'belmont'), (',', ','), ('California', 'california'), (':', ':'), ('Wadsworth', 'wadsworth'), ('International', 'intern'), ('Group', 'group'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Lemmatization: 
 [('Stone', 'Stone'), (',', ','), ('', ''), ('Classification', 'Classification'), ('Regression', 'Regression'), ('Trees', 'Trees'), ('', ''), (',', ','), ('Belmont', 'Belmont'), (',', ','), ('California', 'California'), (':', ':'), ('Wadsworth', 'Wadsworth'), ('International', 'International'), ('Group', 'Group'), (',', ','), ('1984', '1984'), ('.', '.')]



============================ Sentence 236 =============================

[9] J. Quinlan, C4.5: Programs for machine learning, San  Francisco, CA: Morgan Kaufmann, 1986. 


>> Tokens are: 
 ['[', '9', ']', 'J.', 'Quinlan', ',', '', 'C4.5', ':', 'Programs', 'machine', 'learning', '', ',', 'San', 'Francisco', ',', 'CA', ':', 'Morgan', 'Kaufmann', ',', '1986', '.']

>> Bigrams are: 
 [('[', '9'), ('9', ']'), (']', 'J.'), ('J.', 'Quinlan'), ('Quinlan', ','), (',', ''), ('', 'C4.5'), ('C4.5', ':'), (':', 'Programs'), ('Programs', 'machine'), ('machine', 'learning'), ('learning', ''), ('', ','), (',', 'San'), ('San', 'Francisco'), ('Francisco', ','), (',', 'CA'), ('CA', ':'), (':', 'Morgan'), ('Morgan', 'Kaufmann'), ('Kaufmann', ','), (',', '1986'), ('1986', '.')]

>> Trigrams are: 
 [('[', '9', ']'), ('9', ']', 'J.'), (']', 'J.', 'Quinlan'), ('J.', 'Quinlan', ','), ('Quinlan', ',', ''), (',', '', 'C4.5'), ('', 'C4.5', ':'), ('C4.5', ':', 'Programs'), (':', 'Programs', 'machine'), ('Programs', 'machine', 'learning'), ('machine', 'learning', ''), ('learning', '', ','), ('', ',', 'San'), (',', 'San', 'Francisco'), ('San', 'Francisco', ','), ('Francisco', ',', 'CA'), (',', 'CA', ':'), ('CA', ':', 'Morgan'), (':', 'Morgan', 'Kaufmann'), ('Morgan', 'Kaufmann', ','), ('Kaufmann', ',', '1986'), (',', '1986', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('9', 'CD'), (']', 'NNP'), ('J.', 'NNP'), ('Quinlan', 'NNP'), (',', ','), ('', 'NNP'), ('C4.5', 'NNP'), (':', ':'), ('Programs', 'NNP'), ('machine', 'NN'), ('learning', 'VBG'), ('', 'NN'), (',', ','), ('San', 'NNP'), ('Francisco', 'NNP'), (',', ','), ('CA', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kaufmann', 'NNP'), (',', ','), ('1986', 'CD'), ('.', '.')]

 (S
  [/RB
  9/CD
  (NP ]/NNP J./NNP Quinlan/NNP)
  ,/,
  (NP /NNP C4.5/NNP)
  :/:
  (NP Programs/NNP machine/NN)
  learning/VBG
  (NP /NN)
  ,/,
  (NP San/NNP Francisco/NNP)
  ,/,
  (NP CA/NNP)
  :/:
  (NP Morgan/NNP Kaufmann/NNP)
  ,/,
  1986/CD
  ./.) 


>> Noun Phrases are: 
 ['] J. Quinlan', ' C4.5', 'Programs machine', '', 'San Francisco', 'CA', 'Morgan Kaufmann']

>> Named Entities are: 
 [('PERSON', 'Quinlan'), ('PERSON', 'San Francisco'), ('PERSON', 'Morgan Kaufmann')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'j.'), ('Quinlan', 'quinlan'), (',', ','), ('', ''), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('machine', 'machin'), ('learning', 'learn'), ('', ''), (',', ','), ('San', 'san'), ('Francisco', 'francisco'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'j.'), ('Quinlan', 'quinlan'), (',', ','), ('', ''), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('machine', 'machin'), ('learning', 'learn'), ('', ''), (',', ','), ('San', 'san'), ('Francisco', 'francisco'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'J.'), ('Quinlan', 'Quinlan'), (',', ','), ('', ''), ('C4.5', 'C4.5'), (':', ':'), ('Programs', 'Programs'), ('machine', 'machine'), ('learning', 'learning'), ('', ''), (',', ','), ('San', 'San'), ('Francisco', 'Francisco'), (',', ','), ('CA', 'CA'), (':', ':'), ('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]



============================ Sentence 237 =============================

[10] Masud Karim and Rashedur M. Rahman, Decision Tree  and Nave Bayes Algorithm for Classification and   Generation of Actionable Knowledge for Direct   Marketing, Journal of Software Engineering and   Applications, Vol. 


>> Tokens are: 
 ['[', '10', ']', 'Masud', 'Karim', 'Rashedur', 'M.', 'Rahman', ',', '', 'Decision', 'Tree', 'Nave', 'Bayes', 'Algorithm', 'Classification', 'Generation', 'Actionable', 'Knowledge', 'Direct', 'Marketing', '', ',', 'Journal', 'Software', 'Engineering', 'Applications', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '10'), ('10', ']'), (']', 'Masud'), ('Masud', 'Karim'), ('Karim', 'Rashedur'), ('Rashedur', 'M.'), ('M.', 'Rahman'), ('Rahman', ','), (',', ''), ('', 'Decision'), ('Decision', 'Tree'), ('Tree', 'Nave'), ('Nave', 'Bayes'), ('Bayes', 'Algorithm'), ('Algorithm', 'Classification'), ('Classification', 'Generation'), ('Generation', 'Actionable'), ('Actionable', 'Knowledge'), ('Knowledge', 'Direct'), ('Direct', 'Marketing'), ('Marketing', ''), ('', ','), (',', 'Journal'), ('Journal', 'Software'), ('Software', 'Engineering'), ('Engineering', 'Applications'), ('Applications', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '10', ']'), ('10', ']', 'Masud'), (']', 'Masud', 'Karim'), ('Masud', 'Karim', 'Rashedur'), ('Karim', 'Rashedur', 'M.'), ('Rashedur', 'M.', 'Rahman'), ('M.', 'Rahman', ','), ('Rahman', ',', ''), (',', '', 'Decision'), ('', 'Decision', 'Tree'), ('Decision', 'Tree', 'Nave'), ('Tree', 'Nave', 'Bayes'), ('Nave', 'Bayes', 'Algorithm'), ('Bayes', 'Algorithm', 'Classification'), ('Algorithm', 'Classification', 'Generation'), ('Classification', 'Generation', 'Actionable'), ('Generation', 'Actionable', 'Knowledge'), ('Actionable', 'Knowledge', 'Direct'), ('Knowledge', 'Direct', 'Marketing'), ('Direct', 'Marketing', ''), ('Marketing', '', ','), ('', ',', 'Journal'), (',', 'Journal', 'Software'), ('Journal', 'Software', 'Engineering'), ('Software', 'Engineering', 'Applications'), ('Engineering', 'Applications', ','), ('Applications', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('Masud', 'NNP'), ('Karim', 'NNP'), ('Rashedur', 'NNP'), ('M.', 'NNP'), ('Rahman', 'NNP'), (',', ','), ('', 'NNP'), ('Decision', 'NNP'), ('Tree', 'NNP'), ('Nave', 'NNP'), ('Bayes', 'NNP'), ('Algorithm', 'NNP'), ('Classification', 'NNP'), ('Generation', 'NNP'), ('Actionable', 'NNP'), ('Knowledge', 'NNP'), ('Direct', 'NNP'), ('Marketing', 'NNP'), ('', 'NNP'), (',', ','), ('Journal', 'NNP'), ('Software', 'NNP'), ('Engineering', 'NNP'), ('Applications', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  10/CD
  (NP ]/JJ Masud/NNP Karim/NNP Rashedur/NNP M./NNP Rahman/NNP)
  ,/,
  (NP
    /NNP
    Decision/NNP
    Tree/NNP
    Nave/NNP
    Bayes/NNP
    Algorithm/NNP
    Classification/NNP
    Generation/NNP
    Actionable/NNP
    Knowledge/NNP
    Direct/NNP
    Marketing/NNP
    /NNP)
  ,/,
  (NP Journal/NNP Software/NNP Engineering/NNP Applications/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Masud Karim Rashedur M. Rahman', ' Decision Tree Nave Bayes Algorithm Classification Generation Actionable Knowledge Direct Marketing ', 'Journal Software Engineering Applications', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Masud Karim Rashedur'), ('PERSON', 'Rahman'), ('PERSON', 'Journal Software Engineering Applications'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'masud'), ('Karim', 'karim'), ('Rashedur', 'rashedur'), ('M.', 'm.'), ('Rahman', 'rahman'), (',', ','), ('', ''), ('Decision', 'decis'), ('Tree', 'tree'), ('Nave', 'nav'), ('Bayes', 'bay'), ('Algorithm', 'algorithm'), ('Classification', 'classif'), ('Generation', 'gener'), ('Actionable', 'action'), ('Knowledge', 'knowledg'), ('Direct', 'direct'), ('Marketing', 'market'), ('', ''), (',', ','), ('Journal', 'journal'), ('Software', 'softwar'), ('Engineering', 'engin'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'masud'), ('Karim', 'karim'), ('Rashedur', 'rashedur'), ('M.', 'm.'), ('Rahman', 'rahman'), (',', ','), ('', ''), ('Decision', 'decis'), ('Tree', 'tree'), ('Nave', 'nav'), ('Bayes', 'bay'), ('Algorithm', 'algorithm'), ('Classification', 'classif'), ('Generation', 'generat'), ('Actionable', 'action'), ('Knowledge', 'knowledg'), ('Direct', 'direct'), ('Marketing', 'market'), ('', ''), (',', ','), ('Journal', 'journal'), ('Software', 'softwar'), ('Engineering', 'engin'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'Masud'), ('Karim', 'Karim'), ('Rashedur', 'Rashedur'), ('M.', 'M.'), ('Rahman', 'Rahman'), (',', ','), ('', ''), ('Decision', 'Decision'), ('Tree', 'Tree'), ('Nave', 'Nave'), ('Bayes', 'Bayes'), ('Algorithm', 'Algorithm'), ('Classification', 'Classification'), ('Generation', 'Generation'), ('Actionable', 'Actionable'), ('Knowledge', 'Knowledge'), ('Direct', 'Direct'), ('Marketing', 'Marketing'), ('', ''), (',', ','), ('Journal', 'Journal'), ('Software', 'Software'), ('Engineering', 'Engineering'), ('Applications', 'Applications'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 238 =============================

6, No. 


>> Tokens are: 
 ['6', ',', 'No', '.']

>> Bigrams are: 
 [('6', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('6', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 6/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 239 =============================

4, pp. 


>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 4/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 240 =============================

196-206, 2013. 


>> Tokens are: 
 ['196-206', ',', '2013', '.']

>> Bigrams are: 
 [('196-206', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('196-206', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('196-206', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S 196-206/CD ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 241 =============================

[11] Earl B. 


>> Tokens are: 
 ['[', '11', ']', 'Earl', 'B', '.']

>> Bigrams are: 
 [('[', '11'), ('11', ']'), (']', 'Earl'), ('Earl', 'B'), ('B', '.')]

>> Trigrams are: 
 [('[', '11', ']'), ('11', ']', 'Earl'), (']', 'Earl', 'B'), ('Earl', 'B', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('Earl', 'NNP'), ('B', 'NNP'), ('.', '.')]

 (S [/RB 11/CD (NP ]/JJ Earl/NNP B/NNP) ./.) 


>> Noun Phrases are: 
 ['] Earl B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'earl'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'earl'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'Earl'), ('B', 'B'), ('.', '.')]



============================ Sentence 242 =============================

Hunt, Janet Marin and Philip J. 


>> Tokens are: 
 ['Hunt', ',', 'Janet', 'Marin', 'Philip', 'J', '.']

>> Bigrams are: 
 [('Hunt', ','), (',', 'Janet'), ('Janet', 'Marin'), ('Marin', 'Philip'), ('Philip', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Hunt', ',', 'Janet'), (',', 'Janet', 'Marin'), ('Janet', 'Marin', 'Philip'), ('Marin', 'Philip', 'J'), ('Philip', 'J', '.')]

>> POS Tags are: 
 [('Hunt', 'NNP'), (',', ','), ('Janet', 'NNP'), ('Marin', 'NNP'), ('Philip', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S (NP Hunt/NNP) ,/, (NP Janet/NNP Marin/NNP Philip/NNP J/NNP) ./.) 


>> Noun Phrases are: 
 ['Hunt', 'Janet Marin Philip J']

>> Named Entities are: 
 [('GPE', 'Hunt'), ('PERSON', 'Janet Marin Philip J')] 

>> Stemming using Porter Stemmer: 
 [('Hunt', 'hunt'), (',', ','), ('Janet', 'janet'), ('Marin', 'marin'), ('Philip', 'philip'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hunt', 'hunt'), (',', ','), ('Janet', 'janet'), ('Marin', 'marin'), ('Philip', 'philip'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Hunt', 'Hunt'), (',', ','), ('Janet', 'Janet'), ('Marin', 'Marin'), ('Philip', 'Philip'), ('J', 'J'), ('.', '.')]



============================ Sentence 243 =============================

Stone, Experiments  in Induction, New York: Academic Press, 1966. 


>> Tokens are: 
 ['Stone', ',', '', 'Experiments', 'Induction', '', ',', 'New', 'York', ':', 'Academic', 'Press', ',', '1966', '.']

>> Bigrams are: 
 [('Stone', ','), (',', ''), ('', 'Experiments'), ('Experiments', 'Induction'), ('Induction', ''), ('', ','), (',', 'New'), ('New', 'York'), ('York', ':'), (':', 'Academic'), ('Academic', 'Press'), ('Press', ','), (',', '1966'), ('1966', '.')]

>> Trigrams are: 
 [('Stone', ',', ''), (',', '', 'Experiments'), ('', 'Experiments', 'Induction'), ('Experiments', 'Induction', ''), ('Induction', '', ','), ('', ',', 'New'), (',', 'New', 'York'), ('New', 'York', ':'), ('York', ':', 'Academic'), (':', 'Academic', 'Press'), ('Academic', 'Press', ','), ('Press', ',', '1966'), (',', '1966', '.')]

>> POS Tags are: 
 [('Stone', 'NN'), (',', ','), ('', 'JJ'), ('Experiments', 'NNPS'), ('Induction', 'NNP'), ('', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (':', ':'), ('Academic', 'JJ'), ('Press', 'NNP'), (',', ','), ('1966', 'CD'), ('.', '.')]

 (S
  (NP Stone/NN)
  ,/,
  /JJ
  Experiments/NNPS
  (NP Induction/NNP /NNP)
  ,/,
  (NP New/NNP York/NNP)
  :/:
  (NP Academic/JJ Press/NNP)
  ,/,
  1966/CD
  ./.) 


>> Noun Phrases are: 
 ['Stone', 'Induction ', 'New York', 'Academic Press']

>> Named Entities are: 
 [('GPE', 'Stone'), ('ORGANIZATION', 'Experiments Induction'), ('GPE', 'New York'), ('ORGANIZATION', 'Academic Press')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Experiments', 'experi'), ('Induction', 'induct'), ('', ''), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('Academic', 'academ'), ('Press', 'press'), (',', ','), ('1966', '1966'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Experiments', 'experi'), ('Induction', 'induct'), ('', ''), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('Academic', 'academ'), ('Press', 'press'), (',', ','), ('1966', '1966'), ('.', '.')]

>> Lemmatization: 
 [('Stone', 'Stone'), (',', ','), ('', ''), ('Experiments', 'Experiments'), ('Induction', 'Induction'), ('', ''), (',', ','), ('New', 'New'), ('York', 'York'), (':', ':'), ('Academic', 'Academic'), ('Press', 'Press'), (',', ','), ('1966', '1966'), ('.', '.')]



============================ Sentence 244 =============================

[12] Leo Breiman, Jerome Friedman, Charles J. 


>> Tokens are: 
 ['[', '12', ']', 'Leo', 'Breiman', ',', 'Jerome', 'Friedman', ',', 'Charles', 'J', '.']

>> Bigrams are: 
 [('[', '12'), ('12', ']'), (']', 'Leo'), ('Leo', 'Breiman'), ('Breiman', ','), (',', 'Jerome'), ('Jerome', 'Friedman'), ('Friedman', ','), (',', 'Charles'), ('Charles', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '12', ']'), ('12', ']', 'Leo'), (']', 'Leo', 'Breiman'), ('Leo', 'Breiman', ','), ('Breiman', ',', 'Jerome'), (',', 'Jerome', 'Friedman'), ('Jerome', 'Friedman', ','), ('Friedman', ',', 'Charles'), (',', 'Charles', 'J'), ('Charles', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('12', 'CD'), (']', 'JJ'), ('Leo', 'NNP'), ('Breiman', 'NNP'), (',', ','), ('Jerome', 'NNP'), ('Friedman', 'NNP'), (',', ','), ('Charles', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S
  [/RB
  12/CD
  (NP ]/JJ Leo/NNP Breiman/NNP)
  ,/,
  (NP Jerome/NNP Friedman/NNP)
  ,/,
  (NP Charles/NNP J/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Leo Breiman', 'Jerome Friedman', 'Charles J']

>> Named Entities are: 
 [('PERSON', 'Leo Breiman'), ('PERSON', 'Jerome Friedman'), ('PERSON', 'Charles J')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'leo'), ('Breiman', 'breiman'), (',', ','), ('Jerome', 'jerom'), ('Friedman', 'friedman'), (',', ','), ('Charles', 'charl'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'leo'), ('Breiman', 'breiman'), (',', ','), ('Jerome', 'jerom'), ('Friedman', 'friedman'), (',', ','), ('Charles', 'charl'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'Leo'), ('Breiman', 'Breiman'), (',', ','), ('Jerome', 'Jerome'), ('Friedman', 'Friedman'), (',', ','), ('Charles', 'Charles'), ('J', 'J'), ('.', '.')]



============================ Sentence 245 =============================

Stone and R. A.  Olshen, Classification and Regression Trees (Wadsworth   Statistics/Probability), Chapman and Hall/CRC, 1984. 


>> Tokens are: 
 ['Stone', 'R.', 'A.', 'Olshen', ',', '', 'Classification', 'Regression', 'Trees', '(', 'Wadsworth', 'Statistics/Probability', ')', '', ',', 'Chapman', 'Hall/CRC', ',', '1984', '.']

>> Bigrams are: 
 [('Stone', 'R.'), ('R.', 'A.'), ('A.', 'Olshen'), ('Olshen', ','), (',', ''), ('', 'Classification'), ('Classification', 'Regression'), ('Regression', 'Trees'), ('Trees', '('), ('(', 'Wadsworth'), ('Wadsworth', 'Statistics/Probability'), ('Statistics/Probability', ')'), (')', ''), ('', ','), (',', 'Chapman'), ('Chapman', 'Hall/CRC'), ('Hall/CRC', ','), (',', '1984'), ('1984', '.')]

>> Trigrams are: 
 [('Stone', 'R.', 'A.'), ('R.', 'A.', 'Olshen'), ('A.', 'Olshen', ','), ('Olshen', ',', ''), (',', '', 'Classification'), ('', 'Classification', 'Regression'), ('Classification', 'Regression', 'Trees'), ('Regression', 'Trees', '('), ('Trees', '(', 'Wadsworth'), ('(', 'Wadsworth', 'Statistics/Probability'), ('Wadsworth', 'Statistics/Probability', ')'), ('Statistics/Probability', ')', ''), (')', '', ','), ('', ',', 'Chapman'), (',', 'Chapman', 'Hall/CRC'), ('Chapman', 'Hall/CRC', ','), ('Hall/CRC', ',', '1984'), (',', '1984', '.')]

>> POS Tags are: 
 [('Stone', 'NNP'), ('R.', 'NNP'), ('A.', 'NN'), ('Olshen', 'NNP'), (',', ','), ('', 'NNP'), ('Classification', 'NNP'), ('Regression', 'NNP'), ('Trees', 'NNP'), ('(', '('), ('Wadsworth', 'NNP'), ('Statistics/Probability', 'NNP'), (')', ')'), ('', 'NN'), (',', ','), ('Chapman', 'NNP'), ('Hall/CRC', 'NNP'), (',', ','), ('1984', 'CD'), ('.', '.')]

 (S
  (NP Stone/NNP R./NNP A./NN Olshen/NNP)
  ,/,
  (NP /NNP Classification/NNP Regression/NNP Trees/NNP)
  (/(
  (NP Wadsworth/NNP Statistics/Probability/NNP)
  )/)
  (NP /NN)
  ,/,
  (NP Chapman/NNP Hall/CRC/NNP)
  ,/,
  1984/CD
  ./.) 


>> Noun Phrases are: 
 ['Stone R. A. Olshen', ' Classification Regression Trees', 'Wadsworth Statistics/Probability', '', 'Chapman Hall/CRC']

>> Named Entities are: 
 [('PERSON', 'Stone'), ('PERSON', 'Olshen'), ('ORGANIZATION', 'Wadsworth'), ('PERSON', 'Chapman Hall/CRC')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), ('R.', 'r.'), ('A.', 'a.'), ('Olshen', 'olshen'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('(', '('), ('Wadsworth', 'wadsworth'), ('Statistics/Probability', 'statistics/prob'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'chapman'), ('Hall/CRC', 'hall/crc'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), ('R.', 'r.'), ('A.', 'a.'), ('Olshen', 'olshen'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('(', '('), ('Wadsworth', 'wadsworth'), ('Statistics/Probability', 'statistics/prob'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'chapman'), ('Hall/CRC', 'hall/crc'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Lemmatization: 
 [('Stone', 'Stone'), ('R.', 'R.'), ('A.', 'A.'), ('Olshen', 'Olshen'), (',', ','), ('', ''), ('Classification', 'Classification'), ('Regression', 'Regression'), ('Trees', 'Trees'), ('(', '('), ('Wadsworth', 'Wadsworth'), ('Statistics/Probability', 'Statistics/Probability'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'Chapman'), ('Hall/CRC', 'Hall/CRC'), (',', ','), ('1984', '1984'), ('.', '.')]



============================ Sentence 246 =============================

[13] Steven L. Salzberg, Book Review: C4.5: Programs for  Machine Learning by J. Ross Quinlan. 


>> Tokens are: 
 ['[', '13', ']', 'Steven', 'L.', 'Salzberg', ',', '', 'Book', 'Review', ':', 'C4.5', ':', 'Programs', 'Machine', 'Learning', 'J.', 'Ross', 'Quinlan', '.']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', 'Steven'), ('Steven', 'L.'), ('L.', 'Salzberg'), ('Salzberg', ','), (',', ''), ('', 'Book'), ('Book', 'Review'), ('Review', ':'), (':', 'C4.5'), ('C4.5', ':'), (':', 'Programs'), ('Programs', 'Machine'), ('Machine', 'Learning'), ('Learning', 'J.'), ('J.', 'Ross'), ('Ross', 'Quinlan'), ('Quinlan', '.')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', 'Steven'), (']', 'Steven', 'L.'), ('Steven', 'L.', 'Salzberg'), ('L.', 'Salzberg', ','), ('Salzberg', ',', ''), (',', '', 'Book'), ('', 'Book', 'Review'), ('Book', 'Review', ':'), ('Review', ':', 'C4.5'), (':', 'C4.5', ':'), ('C4.5', ':', 'Programs'), (':', 'Programs', 'Machine'), ('Programs', 'Machine', 'Learning'), ('Machine', 'Learning', 'J.'), ('Learning', 'J.', 'Ross'), ('J.', 'Ross', 'Quinlan'), ('Ross', 'Quinlan', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('Steven', 'NNP'), ('L.', 'NNP'), ('Salzberg', 'NNP'), (',', ','), ('', 'NNP'), ('Book', 'NNP'), ('Review', 'NNP'), (':', ':'), ('C4.5', 'NN'), (':', ':'), ('Programs', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('J.', 'NNP'), ('Ross', 'NNP'), ('Quinlan', 'NNP'), ('.', '.')]

 (S
  [/RB
  13/CD
  (NP ]/JJ Steven/NNP L./NNP Salzberg/NNP)
  ,/,
  (NP /NNP Book/NNP Review/NNP)
  :/:
  (NP C4.5/NN)
  :/:
  (NP
    Programs/NNP
    Machine/NNP
    Learning/NNP
    J./NNP
    Ross/NNP
    Quinlan/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Steven L. Salzberg', ' Book Review', 'C4.5', 'Programs Machine Learning J. Ross Quinlan']

>> Named Entities are: 
 [('PERSON', 'Steven L. Salzberg'), ('PERSON', 'Machine Learning J. Ross Quinlan')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'steven'), ('L.', 'l.'), ('Salzberg', 'salzberg'), (',', ','), ('', ''), ('Book', 'book'), ('Review', 'review'), (':', ':'), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('Machine', 'machin'), ('Learning', 'learn'), ('J.', 'j.'), ('Ross', 'ross'), ('Quinlan', 'quinlan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'steven'), ('L.', 'l.'), ('Salzberg', 'salzberg'), (',', ','), ('', ''), ('Book', 'book'), ('Review', 'review'), (':', ':'), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('Machine', 'machin'), ('Learning', 'learn'), ('J.', 'j.'), ('Ross', 'ross'), ('Quinlan', 'quinlan'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'Steven'), ('L.', 'L.'), ('Salzberg', 'Salzberg'), (',', ','), ('', ''), ('Book', 'Book'), ('Review', 'Review'), (':', ':'), ('C4.5', 'C4.5'), (':', ':'), ('Programs', 'Programs'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('J.', 'J.'), ('Ross', 'Ross'), ('Quinlan', 'Quinlan'), ('.', '.')]



============================ Sentence 247 =============================

Inc., 1993,   Machine Learning, Vol. 


>> Tokens are: 
 ['Inc.', ',', '1993', '', ',', 'Machine', 'Learning', ',', 'Vol', '.']

>> Bigrams are: 
 [('Inc.', ','), (',', '1993'), ('1993', ''), ('', ','), (',', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Inc.', ',', '1993'), (',', '1993', ''), ('1993', '', ','), ('', ',', 'Machine'), (',', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Inc.', 'NNP'), (',', ','), ('1993', 'CD'), ('', 'NN'), (',', ','), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  (NP Inc./NNP)
  ,/,
  1993/CD
  (NP /NN)
  ,/,
  (NP Machine/NNP Learning/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Inc.', '', 'Machine Learning', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Inc.', 'inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inc.', 'inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ','), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Inc.', 'Inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ','), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 248 =============================

16, No. 


>> Tokens are: 
 ['16', ',', 'No', '.']

>> Bigrams are: 
 [('16', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('16', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('16', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 16/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 249 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 250 =============================

235-240, 1994. 


>> Tokens are: 
 ['235-240', ',', '1994', '.']

>> Bigrams are: 
 [('235-240', ','), (',', '1994'), ('1994', '.')]

>> Trigrams are: 
 [('235-240', ',', '1994'), (',', '1994', '.')]

>> POS Tags are: 
 [('235-240', 'CD'), (',', ','), ('1994', 'CD'), ('.', '.')]

 (S 235-240/CD ,/, 1994/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]

>> Lemmatization: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]



============================ Sentence 251 =============================

[14] Johannes Frnkranz, Separate-and-Conquer Rule Learning,  Artificial Intelligence Review, Vol. 


>> Tokens are: 
 ['[', '14', ']', 'Johannes', 'Frnkranz', ',', '', 'Separate-and-Conquer', 'Rule', 'Learning', '', ',', 'Artificial', 'Intelligence', 'Review', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '14'), ('14', ']'), (']', 'Johannes'), ('Johannes', 'Frnkranz'), ('Frnkranz', ','), (',', ''), ('', 'Separate-and-Conquer'), ('Separate-and-Conquer', 'Rule'), ('Rule', 'Learning'), ('Learning', ''), ('', ','), (',', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Review'), ('Review', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '14', ']'), ('14', ']', 'Johannes'), (']', 'Johannes', 'Frnkranz'), ('Johannes', 'Frnkranz', ','), ('Frnkranz', ',', ''), (',', '', 'Separate-and-Conquer'), ('', 'Separate-and-Conquer', 'Rule'), ('Separate-and-Conquer', 'Rule', 'Learning'), ('Rule', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Artificial'), (',', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Review'), ('Intelligence', 'Review', ','), ('Review', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('14', 'CD'), (']', 'JJ'), ('Johannes', 'NNPS'), ('Frnkranz', 'NNP'), (',', ','), ('', 'NNP'), ('Separate-and-Conquer', 'NNP'), ('Rule', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Review', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  14/CD
  ]/JJ
  Johannes/NNPS
  (NP Frnkranz/NNP)
  ,/,
  (NP /NNP Separate-and-Conquer/NNP Rule/NNP Learning/NNP /NNP)
  ,/,
  (NP Artificial/NNP Intelligence/NNP Review/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Frnkranz', ' Separate-and-Conquer Rule Learning ', 'Artificial Intelligence Review', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Johannes Frnkranz'), ('ORGANIZATION', 'Artificial Intelligence Review'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'johann'), ('Frnkranz', 'frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'separate-and-conqu'), ('Rule', 'rule'), ('Learning', 'learn'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'johann'), ('Frnkranz', 'frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'separate-and-conqu'), ('Rule', 'rule'), ('Learning', 'learn'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'Johannes'), ('Frnkranz', 'Frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'Separate-and-Conquer'), ('Rule', 'Rule'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Review', 'Review'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 252 =============================

13, pp. 


>> Tokens are: 
 ['13', ',', 'pp', '.']

>> Bigrams are: 
 [('13', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('13', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('13', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 13/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 253 =============================

3-54, 1999. 


>> Tokens are: 
 ['3-54', ',', '1999', '.']

>> Bigrams are: 
 [('3-54', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('3-54', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('3-54', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

 (S 3-54/CD ,/, 1999/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]



============================ Sentence 254 =============================

[15] Aijun An and Nick Cercone, Discretization of continuous  attributes for learning classification rules, Third Pacific-  Asia Conference on Methodologies for Knowledge   Discovery & Data Mining, Vol. 


>> Tokens are: 
 ['[', '15', ']', 'Aijun', 'An', 'Nick', 'Cercone', ',', '', 'Discretization', 'continuous', 'attributes', 'learning', 'classification', 'rules', '', ',', 'Third', 'Pacific-', 'Asia', 'Conference', 'Methodologies', 'Knowledge', 'Discovery', '&', 'Data', 'Mining', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '15'), ('15', ']'), (']', 'Aijun'), ('Aijun', 'An'), ('An', 'Nick'), ('Nick', 'Cercone'), ('Cercone', ','), (',', ''), ('', 'Discretization'), ('Discretization', 'continuous'), ('continuous', 'attributes'), ('attributes', 'learning'), ('learning', 'classification'), ('classification', 'rules'), ('rules', ''), ('', ','), (',', 'Third'), ('Third', 'Pacific-'), ('Pacific-', 'Asia'), ('Asia', 'Conference'), ('Conference', 'Methodologies'), ('Methodologies', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', '&'), ('&', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '15', ']'), ('15', ']', 'Aijun'), (']', 'Aijun', 'An'), ('Aijun', 'An', 'Nick'), ('An', 'Nick', 'Cercone'), ('Nick', 'Cercone', ','), ('Cercone', ',', ''), (',', '', 'Discretization'), ('', 'Discretization', 'continuous'), ('Discretization', 'continuous', 'attributes'), ('continuous', 'attributes', 'learning'), ('attributes', 'learning', 'classification'), ('learning', 'classification', 'rules'), ('classification', 'rules', ''), ('rules', '', ','), ('', ',', 'Third'), (',', 'Third', 'Pacific-'), ('Third', 'Pacific-', 'Asia'), ('Pacific-', 'Asia', 'Conference'), ('Asia', 'Conference', 'Methodologies'), ('Conference', 'Methodologies', 'Knowledge'), ('Methodologies', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', '&'), ('Discovery', '&', 'Data'), ('&', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNP'), ('Aijun', 'NNP'), ('An', 'DT'), ('Nick', 'NNP'), ('Cercone', 'NNP'), (',', ','), ('', 'NNP'), ('Discretization', 'NNP'), ('continuous', 'JJ'), ('attributes', 'NNS'), ('learning', 'VBG'), ('classification', 'NN'), ('rules', 'NNS'), ('', 'VBP'), (',', ','), ('Third', 'JJ'), ('Pacific-', 'NNP'), ('Asia', 'NNP'), ('Conference', 'NNP'), ('Methodologies', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('&', 'CC'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  15/CD
  (NP ]/NNP Aijun/NNP)
  (NP An/DT Nick/NNP Cercone/NNP)
  ,/,
  (NP /NNP Discretization/NNP)
  (NP continuous/JJ attributes/NNS)
  learning/VBG
  (NP classification/NN rules/NNS)
  /VBP
  ,/,
  (NP
    Third/JJ
    Pacific-/NNP
    Asia/NNP
    Conference/NNP
    Methodologies/NNP
    Knowledge/NNP
    Discovery/NNP)
  &/CC
  (NP Data/NNP Mining/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Aijun', 'An Nick Cercone', ' Discretization', 'continuous attributes', 'classification rules', 'Third Pacific- Asia Conference Methodologies Knowledge Discovery', 'Data Mining', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Nick Cercone'), ('PERSON', 'Third Pacific- Asia Conference Methodologies Knowledge Discovery'), ('PERSON', 'Data Mining'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'aijun'), ('An', 'an'), ('Nick', 'nick'), ('Cercone', 'cercon'), (',', ','), ('', ''), ('Discretization', 'discret'), ('continuous', 'continu'), ('attributes', 'attribut'), ('learning', 'learn'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'third'), ('Pacific-', 'pacific-'), ('Asia', 'asia'), ('Conference', 'confer'), ('Methodologies', 'methodolog'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('&', '&'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'aijun'), ('An', 'an'), ('Nick', 'nick'), ('Cercone', 'cercon'), (',', ','), ('', ''), ('Discretization', 'discret'), ('continuous', 'continu'), ('attributes', 'attribut'), ('learning', 'learn'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'third'), ('Pacific-', 'pacific-'), ('Asia', 'asia'), ('Conference', 'confer'), ('Methodologies', 'methodolog'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('&', '&'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'Aijun'), ('An', 'An'), ('Nick', 'Nick'), ('Cercone', 'Cercone'), (',', ','), ('', ''), ('Discretization', 'Discretization'), ('continuous', 'continuous'), ('attributes', 'attribute'), ('learning', 'learning'), ('classification', 'classification'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'Third'), ('Pacific-', 'Pacific-'), ('Asia', 'Asia'), ('Conference', 'Conference'), ('Methodologies', 'Methodologies'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('&', '&'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 255 =============================

1574, pp. 


>> Tokens are: 
 ['1574', ',', 'pp', '.']

>> Bigrams are: 
 [('1574', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1574', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1574', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1574/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 256 =============================

509-514, 1999. 


>> Tokens are: 
 ['509-514', ',', '1999', '.']

>> Bigrams are: 
 [('509-514', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('509-514', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('509-514', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

 (S 509-514/CD ,/, 1999/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]



============================ Sentence 257 =============================

[16] Mehryar Mohri, Afshin Rostamizadeh and Ameet  Talwalkar, Foundations of Machine Learning, One   Rogers Street Cambridge MA: The MIT Press, 2012. 


>> Tokens are: 
 ['[', '16', ']', 'Mehryar', 'Mohri', ',', 'Afshin', 'Rostamizadeh', 'Ameet', 'Talwalkar', ',', '', 'Foundations', 'Machine', 'Learning', '', ',', 'One', 'Rogers', 'Street', 'Cambridge', 'MA', ':', 'The', 'MIT', 'Press', ',', '2012', '.']

>> Bigrams are: 
 [('[', '16'), ('16', ']'), (']', 'Mehryar'), ('Mehryar', 'Mohri'), ('Mohri', ','), (',', 'Afshin'), ('Afshin', 'Rostamizadeh'), ('Rostamizadeh', 'Ameet'), ('Ameet', 'Talwalkar'), ('Talwalkar', ','), (',', ''), ('', 'Foundations'), ('Foundations', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'One'), ('One', 'Rogers'), ('Rogers', 'Street'), ('Street', 'Cambridge'), ('Cambridge', 'MA'), ('MA', ':'), (':', 'The'), ('The', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('[', '16', ']'), ('16', ']', 'Mehryar'), (']', 'Mehryar', 'Mohri'), ('Mehryar', 'Mohri', ','), ('Mohri', ',', 'Afshin'), (',', 'Afshin', 'Rostamizadeh'), ('Afshin', 'Rostamizadeh', 'Ameet'), ('Rostamizadeh', 'Ameet', 'Talwalkar'), ('Ameet', 'Talwalkar', ','), ('Talwalkar', ',', ''), (',', '', 'Foundations'), ('', 'Foundations', 'Machine'), ('Foundations', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'One'), (',', 'One', 'Rogers'), ('One', 'Rogers', 'Street'), ('Rogers', 'Street', 'Cambridge'), ('Street', 'Cambridge', 'MA'), ('Cambridge', 'MA', ':'), ('MA', ':', 'The'), (':', 'The', 'MIT'), ('The', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('16', 'CD'), (']', 'JJ'), ('Mehryar', 'NNP'), ('Mohri', 'NNP'), (',', ','), ('Afshin', 'NNP'), ('Rostamizadeh', 'NNP'), ('Ameet', 'NNP'), ('Talwalkar', 'NNP'), (',', ','), ('', 'JJ'), ('Foundations', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('One', 'CD'), ('Rogers', 'NNP'), ('Street', 'NNP'), ('Cambridge', 'NNP'), ('MA', 'NNP'), (':', ':'), ('The', 'DT'), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S
  [/RB
  16/CD
  (NP ]/JJ Mehryar/NNP Mohri/NNP)
  ,/,
  (NP Afshin/NNP Rostamizadeh/NNP Ameet/NNP Talwalkar/NNP)
  ,/,
  (NP /JJ Foundations/NNP Machine/NNP Learning/NNP /NNP)
  ,/,
  One/CD
  (NP Rogers/NNP Street/NNP Cambridge/NNP MA/NNP)
  :/:
  (NP The/DT MIT/NNP Press/NNP)
  ,/,
  2012/CD
  ./.) 


>> Noun Phrases are: 
 ['] Mehryar Mohri', 'Afshin Rostamizadeh Ameet Talwalkar', ' Foundations Machine Learning ', 'Rogers Street Cambridge MA', 'The MIT Press']

>> Named Entities are: 
 [('PERSON', 'Mehryar Mohri'), ('PERSON', 'Afshin Rostamizadeh Ameet Talwalkar'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Rogers Street'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'mehryar'), ('Mohri', 'mohri'), (',', ','), ('Afshin', 'afshin'), ('Rostamizadeh', 'rostamizadeh'), ('Ameet', 'ameet'), ('Talwalkar', 'talwalkar'), (',', ','), ('', ''), ('Foundations', 'foundat'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('One', 'one'), ('Rogers', 'roger'), ('Street', 'street'), ('Cambridge', 'cambridg'), ('MA', 'ma'), (':', ':'), ('The', 'the'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'mehryar'), ('Mohri', 'mohri'), (',', ','), ('Afshin', 'afshin'), ('Rostamizadeh', 'rostamizadeh'), ('Ameet', 'ameet'), ('Talwalkar', 'talwalkar'), (',', ','), ('', ''), ('Foundations', 'foundat'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('One', 'one'), ('Rogers', 'roger'), ('Street', 'street'), ('Cambridge', 'cambridg'), ('MA', 'ma'), (':', ':'), ('The', 'the'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'Mehryar'), ('Mohri', 'Mohri'), (',', ','), ('Afshin', 'Afshin'), ('Rostamizadeh', 'Rostamizadeh'), ('Ameet', 'Ameet'), ('Talwalkar', 'Talwalkar'), (',', ','), ('', ''), ('Foundations', 'Foundations'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('One', 'One'), ('Rogers', 'Rogers'), ('Street', 'Street'), ('Cambridge', 'Cambridge'), ('MA', 'MA'), (':', ':'), ('The', 'The'), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 258 =============================

[17] Olivier Bousquet, Stephane Boucheron and Gabor  Lugosi, Introduction to Statistical Learning Theory,   Lecture Notes in Computer Science, Vol. 


>> Tokens are: 
 ['[', '17', ']', 'Olivier', 'Bousquet', ',', 'Stephane', 'Boucheron', 'Gabor', 'Lugosi', ',', '', 'Introduction', 'Statistical', 'Learning', 'Theory', '', ',', 'Lecture', 'Notes', 'Computer', 'Science', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '17'), ('17', ']'), (']', 'Olivier'), ('Olivier', 'Bousquet'), ('Bousquet', ','), (',', 'Stephane'), ('Stephane', 'Boucheron'), ('Boucheron', 'Gabor'), ('Gabor', 'Lugosi'), ('Lugosi', ','), (',', ''), ('', 'Introduction'), ('Introduction', 'Statistical'), ('Statistical', 'Learning'), ('Learning', 'Theory'), ('Theory', ''), ('', ','), (',', 'Lecture'), ('Lecture', 'Notes'), ('Notes', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '17', ']'), ('17', ']', 'Olivier'), (']', 'Olivier', 'Bousquet'), ('Olivier', 'Bousquet', ','), ('Bousquet', ',', 'Stephane'), (',', 'Stephane', 'Boucheron'), ('Stephane', 'Boucheron', 'Gabor'), ('Boucheron', 'Gabor', 'Lugosi'), ('Gabor', 'Lugosi', ','), ('Lugosi', ',', ''), (',', '', 'Introduction'), ('', 'Introduction', 'Statistical'), ('Introduction', 'Statistical', 'Learning'), ('Statistical', 'Learning', 'Theory'), ('Learning', 'Theory', ''), ('Theory', '', ','), ('', ',', 'Lecture'), (',', 'Lecture', 'Notes'), ('Lecture', 'Notes', 'Computer'), ('Notes', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('17', 'CD'), (']', 'NNS'), ('Olivier', 'NNP'), ('Bousquet', 'NNP'), (',', ','), ('Stephane', 'NNP'), ('Boucheron', 'NNP'), ('Gabor', 'NNP'), ('Lugosi', 'NNP'), (',', ','), ('', 'NNP'), ('Introduction', 'NNP'), ('Statistical', 'NNP'), ('Learning', 'NNP'), ('Theory', 'NNP'), ('', 'NNP'), (',', ','), ('Lecture', 'NNP'), ('Notes', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  17/CD
  (NP ]/NNS Olivier/NNP Bousquet/NNP)
  ,/,
  (NP Stephane/NNP Boucheron/NNP Gabor/NNP Lugosi/NNP)
  ,/,
  (NP
    /NNP
    Introduction/NNP
    Statistical/NNP
    Learning/NNP
    Theory/NNP
    /NNP)
  ,/,
  (NP Lecture/NNP Notes/NNP Computer/NNP Science/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Olivier Bousquet', 'Stephane Boucheron Gabor Lugosi', ' Introduction Statistical Learning Theory ', 'Lecture Notes Computer Science', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Olivier Bousquet'), ('PERSON', 'Boucheron'), ('PERSON', 'Lecture Notes Computer Science'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'olivi'), ('Bousquet', 'bousquet'), (',', ','), ('Stephane', 'stephan'), ('Boucheron', 'boucheron'), ('Gabor', 'gabor'), ('Lugosi', 'lugosi'), (',', ','), ('', ''), ('Introduction', 'introduct'), ('Statistical', 'statist'), ('Learning', 'learn'), ('Theory', 'theori'), ('', ''), (',', ','), ('Lecture', 'lectur'), ('Notes', 'note'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'olivi'), ('Bousquet', 'bousquet'), (',', ','), ('Stephane', 'stephan'), ('Boucheron', 'boucheron'), ('Gabor', 'gabor'), ('Lugosi', 'lugosi'), (',', ','), ('', ''), ('Introduction', 'introduct'), ('Statistical', 'statist'), ('Learning', 'learn'), ('Theory', 'theori'), ('', ''), (',', ','), ('Lecture', 'lectur'), ('Notes', 'note'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'Olivier'), ('Bousquet', 'Bousquet'), (',', ','), ('Stephane', 'Stephane'), ('Boucheron', 'Boucheron'), ('Gabor', 'Gabor'), ('Lugosi', 'Lugosi'), (',', ','), ('', ''), ('Introduction', 'Introduction'), ('Statistical', 'Statistical'), ('Learning', 'Learning'), ('Theory', 'Theory'), ('', ''), (',', ','), ('Lecture', 'Lecture'), ('Notes', 'Notes'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 259 =============================

3176, pp. 


>> Tokens are: 
 ['3176', ',', 'pp', '.']

>> Bigrams are: 
 [('3176', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3176', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3176', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3176/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 260 =============================

175-  213, 2004. 


>> Tokens are: 
 ['175-', '213', ',', '2004', '.']

>> Bigrams are: 
 [('175-', '213'), ('213', ','), (',', '2004'), ('2004', '.')]

>> Trigrams are: 
 [('175-', '213', ','), ('213', ',', '2004'), (',', '2004', '.')]

>> POS Tags are: 
 [('175-', 'JJ'), ('213', 'CD'), (',', ','), ('2004', 'CD'), ('.', '.')]

 (S 175-/JJ 213/CD ,/, 2004/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('175-', '175-'), ('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('175-', '175-'), ('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Lemmatization: 
 [('175-', '175-'), ('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]



============================ Sentence 261 =============================

[18] Olivier Pourret, Patrick Naim and Bruce Marcot, Bayesian  Networks: A Practical Guide to Applications, Wiley   Publishers, 2008. 


>> Tokens are: 
 ['[', '18', ']', 'Olivier', 'Pourret', ',', 'Patrick', 'Naim', 'Bruce', 'Marcot', ',', '', 'Bayesian', 'Networks', ':', 'A', 'Practical', 'Guide', 'Applications', '', ',', 'Wiley', 'Publishers', ',', '2008', '.']

>> Bigrams are: 
 [('[', '18'), ('18', ']'), (']', 'Olivier'), ('Olivier', 'Pourret'), ('Pourret', ','), (',', 'Patrick'), ('Patrick', 'Naim'), ('Naim', 'Bruce'), ('Bruce', 'Marcot'), ('Marcot', ','), (',', ''), ('', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', ':'), (':', 'A'), ('A', 'Practical'), ('Practical', 'Guide'), ('Guide', 'Applications'), ('Applications', ''), ('', ','), (',', 'Wiley'), ('Wiley', 'Publishers'), ('Publishers', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('[', '18', ']'), ('18', ']', 'Olivier'), (']', 'Olivier', 'Pourret'), ('Olivier', 'Pourret', ','), ('Pourret', ',', 'Patrick'), (',', 'Patrick', 'Naim'), ('Patrick', 'Naim', 'Bruce'), ('Naim', 'Bruce', 'Marcot'), ('Bruce', 'Marcot', ','), ('Marcot', ',', ''), (',', '', 'Bayesian'), ('', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', ':'), ('Networks', ':', 'A'), (':', 'A', 'Practical'), ('A', 'Practical', 'Guide'), ('Practical', 'Guide', 'Applications'), ('Guide', 'Applications', ''), ('Applications', '', ','), ('', ',', 'Wiley'), (',', 'Wiley', 'Publishers'), ('Wiley', 'Publishers', ','), ('Publishers', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('18', 'CD'), (']', 'NNS'), ('Olivier', 'NNP'), ('Pourret', 'NNP'), (',', ','), ('Patrick', 'NNP'), ('Naim', 'NNP'), ('Bruce', 'NNP'), ('Marcot', 'NNP'), (',', ','), ('', 'NNP'), ('Bayesian', 'NNP'), ('Networks', 'NNP'), (':', ':'), ('A', 'DT'), ('Practical', 'NNP'), ('Guide', 'NNP'), ('Applications', 'NNP'), ('', 'NNP'), (',', ','), ('Wiley', 'NNP'), ('Publishers', 'NNP'), (',', ','), ('2008', 'CD'), ('.', '.')]

 (S
  [/RB
  18/CD
  (NP ]/NNS Olivier/NNP Pourret/NNP)
  ,/,
  (NP Patrick/NNP Naim/NNP Bruce/NNP Marcot/NNP)
  ,/,
  (NP /NNP Bayesian/NNP Networks/NNP)
  :/:
  (NP A/DT Practical/NNP Guide/NNP Applications/NNP /NNP)
  ,/,
  (NP Wiley/NNP Publishers/NNP)
  ,/,
  2008/CD
  ./.) 


>> Noun Phrases are: 
 ['] Olivier Pourret', 'Patrick Naim Bruce Marcot', ' Bayesian Networks', 'A Practical Guide Applications ', 'Wiley Publishers']

>> Named Entities are: 
 [('PERSON', 'Olivier Pourret'), ('PERSON', 'Patrick Naim Bruce Marcot'), ('PERSON', 'Bayesian Networks'), ('ORGANIZATION', 'Practical Guide Applications'), ('PERSON', 'Wiley Publishers')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'olivi'), ('Pourret', 'pourret'), (',', ','), ('Patrick', 'patrick'), ('Naim', 'naim'), ('Bruce', 'bruce'), ('Marcot', 'marcot'), (',', ','), ('', ''), ('Bayesian', 'bayesian'), ('Networks', 'network'), (':', ':'), ('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Applications', 'applic'), ('', ''), (',', ','), ('Wiley', 'wiley'), ('Publishers', 'publish'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'olivi'), ('Pourret', 'pourret'), (',', ','), ('Patrick', 'patrick'), ('Naim', 'naim'), ('Bruce', 'bruce'), ('Marcot', 'marcot'), (',', ','), ('', ''), ('Bayesian', 'bayesian'), ('Networks', 'network'), (':', ':'), ('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Applications', 'applic'), ('', ''), (',', ','), ('Wiley', 'wiley'), ('Publishers', 'publish'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'Olivier'), ('Pourret', 'Pourret'), (',', ','), ('Patrick', 'Patrick'), ('Naim', 'Naim'), ('Bruce', 'Bruce'), ('Marcot', 'Marcot'), (',', ','), ('', ''), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), (':', ':'), ('A', 'A'), ('Practical', 'Practical'), ('Guide', 'Guide'), ('Applications', 'Applications'), ('', ''), (',', ','), ('Wiley', 'Wiley'), ('Publishers', 'Publishers'), (',', ','), ('2008', '2008'), ('.', '.')]



============================ Sentence 262 =============================

[19] Kamal Nigam, John Lafferty and Andrew McCallum,  Using Maximum Entropy for Text Classification,   Workshop on Machine Learning for Information Filtering,   pp. 


>> Tokens are: 
 ['[', '19', ']', 'Kamal', 'Nigam', ',', 'John', 'Lafferty', 'Andrew', 'McCallum', ',', '', 'Using', 'Maximum', 'Entropy', 'Text', 'Classification', '', ',', 'Workshop', 'Machine', 'Learning', 'Information', 'Filtering', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '19'), ('19', ']'), (']', 'Kamal'), ('Kamal', 'Nigam'), ('Nigam', ','), (',', 'John'), ('John', 'Lafferty'), ('Lafferty', 'Andrew'), ('Andrew', 'McCallum'), ('McCallum', ','), (',', ''), ('', 'Using'), ('Using', 'Maximum'), ('Maximum', 'Entropy'), ('Entropy', 'Text'), ('Text', 'Classification'), ('Classification', ''), ('', ','), (',', 'Workshop'), ('Workshop', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Information'), ('Information', 'Filtering'), ('Filtering', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '19', ']'), ('19', ']', 'Kamal'), (']', 'Kamal', 'Nigam'), ('Kamal', 'Nigam', ','), ('Nigam', ',', 'John'), (',', 'John', 'Lafferty'), ('John', 'Lafferty', 'Andrew'), ('Lafferty', 'Andrew', 'McCallum'), ('Andrew', 'McCallum', ','), ('McCallum', ',', ''), (',', '', 'Using'), ('', 'Using', 'Maximum'), ('Using', 'Maximum', 'Entropy'), ('Maximum', 'Entropy', 'Text'), ('Entropy', 'Text', 'Classification'), ('Text', 'Classification', ''), ('Classification', '', ','), ('', ',', 'Workshop'), (',', 'Workshop', 'Machine'), ('Workshop', 'Machine', 'Learning'), ('Machine', 'Learning', 'Information'), ('Learning', 'Information', 'Filtering'), ('Information', 'Filtering', ','), ('Filtering', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('19', 'CD'), (']', 'NNS'), ('Kamal', 'NNP'), ('Nigam', 'NNP'), (',', ','), ('John', 'NNP'), ('Lafferty', 'NNP'), ('Andrew', 'NNP'), ('McCallum', 'NNP'), (',', ','), ('', 'NNP'), ('Using', 'NNP'), ('Maximum', 'NNP'), ('Entropy', 'NNP'), ('Text', 'NNP'), ('Classification', 'NNP'), ('', 'NNP'), (',', ','), ('Workshop', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Information', 'NNP'), ('Filtering', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  19/CD
  (NP ]/NNS Kamal/NNP Nigam/NNP)
  ,/,
  (NP John/NNP Lafferty/NNP Andrew/NNP McCallum/NNP)
  ,/,
  (NP
    /NNP
    Using/NNP
    Maximum/NNP
    Entropy/NNP
    Text/NNP
    Classification/NNP
    /NNP)
  ,/,
  (NP
    Workshop/NNP
    Machine/NNP
    Learning/NNP
    Information/NNP
    Filtering/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] Kamal Nigam', 'John Lafferty Andrew McCallum', ' Using Maximum Entropy Text Classification ', 'Workshop Machine Learning Information Filtering', 'pp']

>> Named Entities are: 
 [('PERSON', 'Kamal Nigam'), ('PERSON', 'John Lafferty'), ('PERSON', 'Andrew McCallum'), ('PERSON', 'Maximum Entropy Text'), ('PERSON', 'Workshop Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'kamal'), ('Nigam', 'nigam'), (',', ','), ('John', 'john'), ('Lafferty', 'lafferti'), ('Andrew', 'andrew'), ('McCallum', 'mccallum'), (',', ','), ('', ''), ('Using', 'use'), ('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Text', 'text'), ('Classification', 'classif'), ('', ''), (',', ','), ('Workshop', 'workshop'), ('Machine', 'machin'), ('Learning', 'learn'), ('Information', 'inform'), ('Filtering', 'filter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'kamal'), ('Nigam', 'nigam'), (',', ','), ('John', 'john'), ('Lafferty', 'lafferti'), ('Andrew', 'andrew'), ('McCallum', 'mccallum'), (',', ','), ('', ''), ('Using', 'use'), ('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Text', 'text'), ('Classification', 'classif'), ('', ''), (',', ','), ('Workshop', 'workshop'), ('Machine', 'machin'), ('Learning', 'learn'), ('Information', 'inform'), ('Filtering', 'filter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'Kamal'), ('Nigam', 'Nigam'), (',', ','), ('John', 'John'), ('Lafferty', 'Lafferty'), ('Andrew', 'Andrew'), ('McCallum', 'McCallum'), (',', ','), ('', ''), ('Using', 'Using'), ('Maximum', 'Maximum'), ('Entropy', 'Entropy'), ('Text', 'Text'), ('Classification', 'Classification'), ('', ''), (',', ','), ('Workshop', 'Workshop'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Information', 'Information'), ('Filtering', 'Filtering'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 263 =============================

61-67, 1999. 


>> Tokens are: 
 ['61-67', ',', '1999', '.']

>> Bigrams are: 
 [('61-67', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('61-67', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('61-67', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

 (S 61-67/CD ,/, 1999/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]



============================ Sentence 264 =============================

[20] N. J. Nilsson, Learning Machines: Foundations of  Trainable Pattern-Classifying Systems, First Edition, New   York: McGraw-Hill, 1965. 


>> Tokens are: 
 ['[', '20', ']', 'N.', 'J.', 'Nilsson', ',', '', 'Learning', 'Machines', ':', 'Foundations', 'Trainable', 'Pattern-Classifying', 'Systems', '', ',', 'First', 'Edition', ',', 'New', 'York', ':', 'McGraw-Hill', ',', '1965', '.']

>> Bigrams are: 
 [('[', '20'), ('20', ']'), (']', 'N.'), ('N.', 'J.'), ('J.', 'Nilsson'), ('Nilsson', ','), (',', ''), ('', 'Learning'), ('Learning', 'Machines'), ('Machines', ':'), (':', 'Foundations'), ('Foundations', 'Trainable'), ('Trainable', 'Pattern-Classifying'), ('Pattern-Classifying', 'Systems'), ('Systems', ''), ('', ','), (',', 'First'), ('First', 'Edition'), ('Edition', ','), (',', 'New'), ('New', 'York'), ('York', ':'), (':', 'McGraw-Hill'), ('McGraw-Hill', ','), (',', '1965'), ('1965', '.')]

>> Trigrams are: 
 [('[', '20', ']'), ('20', ']', 'N.'), (']', 'N.', 'J.'), ('N.', 'J.', 'Nilsson'), ('J.', 'Nilsson', ','), ('Nilsson', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'Machines'), ('Learning', 'Machines', ':'), ('Machines', ':', 'Foundations'), (':', 'Foundations', 'Trainable'), ('Foundations', 'Trainable', 'Pattern-Classifying'), ('Trainable', 'Pattern-Classifying', 'Systems'), ('Pattern-Classifying', 'Systems', ''), ('Systems', '', ','), ('', ',', 'First'), (',', 'First', 'Edition'), ('First', 'Edition', ','), ('Edition', ',', 'New'), (',', 'New', 'York'), ('New', 'York', ':'), ('York', ':', 'McGraw-Hill'), (':', 'McGraw-Hill', ','), ('McGraw-Hill', ',', '1965'), (',', '1965', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('20', 'CD'), (']', 'JJ'), ('N.', 'NNP'), ('J.', 'NNP'), ('Nilsson', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('Machines', 'NNS'), (':', ':'), ('Foundations', 'NNS'), ('Trainable', 'JJ'), ('Pattern-Classifying', 'JJ'), ('Systems', 'NNPS'), ('', 'NNP'), (',', ','), ('First', 'NNP'), ('Edition', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (':', ':'), ('McGraw-Hill', 'NN'), (',', ','), ('1965', 'CD'), ('.', '.')]

 (S
  [/RB
  20/CD
  (NP ]/JJ N./NNP J./NNP Nilsson/NNP)
  ,/,
  (NP /NNP Learning/NNP Machines/NNS)
  :/:
  (NP Foundations/NNS)
  Trainable/JJ
  Pattern-Classifying/JJ
  Systems/NNPS
  (NP /NNP)
  ,/,
  (NP First/NNP Edition/NNP)
  ,/,
  (NP New/NNP York/NNP)
  :/:
  (NP McGraw-Hill/NN)
  ,/,
  1965/CD
  ./.) 


>> Noun Phrases are: 
 ['] N. J. Nilsson', ' Learning Machines', 'Foundations', '', 'First Edition', 'New York', 'McGraw-Hill']

>> Named Entities are: 
 [('PERSON', 'Nilsson'), ('ORGANIZATION', 'Systems'), ('PERSON', 'First Edition'), ('GPE', 'New York')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'n.'), ('J.', 'j.'), ('Nilsson', 'nilsson'), (',', ','), ('', ''), ('Learning', 'learn'), ('Machines', 'machin'), (':', ':'), ('Foundations', 'foundat'), ('Trainable', 'trainabl'), ('Pattern-Classifying', 'pattern-classifi'), ('Systems', 'system'), ('', ''), (',', ','), ('First', 'first'), ('Edition', 'edit'), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('McGraw-Hill', 'mcgraw-hil'), (',', ','), ('1965', '1965'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'n.'), ('J.', 'j.'), ('Nilsson', 'nilsson'), (',', ','), ('', ''), ('Learning', 'learn'), ('Machines', 'machin'), (':', ':'), ('Foundations', 'foundat'), ('Trainable', 'trainabl'), ('Pattern-Classifying', 'pattern-classifi'), ('Systems', 'system'), ('', ''), (',', ','), ('First', 'first'), ('Edition', 'edit'), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('McGraw-Hill', 'mcgraw-hil'), (',', ','), ('1965', '1965'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'N.'), ('J.', 'J.'), ('Nilsson', 'Nilsson'), (',', ','), ('', ''), ('Learning', 'Learning'), ('Machines', 'Machines'), (':', ':'), ('Foundations', 'Foundations'), ('Trainable', 'Trainable'), ('Pattern-Classifying', 'Pattern-Classifying'), ('Systems', 'Systems'), ('', ''), (',', ','), ('First', 'First'), ('Edition', 'Edition'), (',', ','), ('New', 'New'), ('York', 'York'), (':', ':'), ('McGraw-Hill', 'McGraw-Hill'), (',', ','), ('1965', '1965'), ('.', '.')]



============================ Sentence 265 =============================

[21] Isidore Jacob Good, Probability and the Weighing of  Evidence, The University of Wisconsin - Madison:   Charles Griffin, 1950. 


>> Tokens are: 
 ['[', '21', ']', 'Isidore', 'Jacob', 'Good', ',', '', 'Probability', 'Weighing', 'Evidence', '', ',', 'The', 'University', 'Wisconsin', '-', 'Madison', ':', 'Charles', 'Griffin', ',', '1950', '.']

>> Bigrams are: 
 [('[', '21'), ('21', ']'), (']', 'Isidore'), ('Isidore', 'Jacob'), ('Jacob', 'Good'), ('Good', ','), (',', ''), ('', 'Probability'), ('Probability', 'Weighing'), ('Weighing', 'Evidence'), ('Evidence', ''), ('', ','), (',', 'The'), ('The', 'University'), ('University', 'Wisconsin'), ('Wisconsin', '-'), ('-', 'Madison'), ('Madison', ':'), (':', 'Charles'), ('Charles', 'Griffin'), ('Griffin', ','), (',', '1950'), ('1950', '.')]

>> Trigrams are: 
 [('[', '21', ']'), ('21', ']', 'Isidore'), (']', 'Isidore', 'Jacob'), ('Isidore', 'Jacob', 'Good'), ('Jacob', 'Good', ','), ('Good', ',', ''), (',', '', 'Probability'), ('', 'Probability', 'Weighing'), ('Probability', 'Weighing', 'Evidence'), ('Weighing', 'Evidence', ''), ('Evidence', '', ','), ('', ',', 'The'), (',', 'The', 'University'), ('The', 'University', 'Wisconsin'), ('University', 'Wisconsin', '-'), ('Wisconsin', '-', 'Madison'), ('-', 'Madison', ':'), ('Madison', ':', 'Charles'), (':', 'Charles', 'Griffin'), ('Charles', 'Griffin', ','), ('Griffin', ',', '1950'), (',', '1950', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('21', 'CD'), (']', 'NNS'), ('Isidore', 'NNP'), ('Jacob', 'NNP'), ('Good', 'NNP'), (',', ','), ('', 'NNP'), ('Probability', 'NNP'), ('Weighing', 'NNP'), ('Evidence', 'NNP'), ('', 'NNP'), (',', ','), ('The', 'DT'), ('University', 'NNP'), ('Wisconsin', 'NNP'), ('-', ':'), ('Madison', 'NN'), (':', ':'), ('Charles', 'NNP'), ('Griffin', 'NNP'), (',', ','), ('1950', 'CD'), ('.', '.')]

 (S
  [/RB
  21/CD
  (NP ]/NNS Isidore/NNP Jacob/NNP Good/NNP)
  ,/,
  (NP /NNP Probability/NNP Weighing/NNP Evidence/NNP /NNP)
  ,/,
  (NP The/DT University/NNP Wisconsin/NNP)
  -/:
  (NP Madison/NN)
  :/:
  (NP Charles/NNP Griffin/NNP)
  ,/,
  1950/CD
  ./.) 


>> Noun Phrases are: 
 ['] Isidore Jacob Good', ' Probability Weighing Evidence ', 'The University Wisconsin', 'Madison', 'Charles Griffin']

>> Named Entities are: 
 [('PERSON', 'Isidore Jacob Good'), ('ORGANIZATION', 'The University Wisconsin'), ('PERSON', 'Madison'), ('PERSON', 'Charles Griffin')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'isidor'), ('Jacob', 'jacob'), ('Good', 'good'), (',', ','), ('', ''), ('Probability', 'probabl'), ('Weighing', 'weigh'), ('Evidence', 'evid'), ('', ''), (',', ','), ('The', 'the'), ('University', 'univers'), ('Wisconsin', 'wisconsin'), ('-', '-'), ('Madison', 'madison'), (':', ':'), ('Charles', 'charl'), ('Griffin', 'griffin'), (',', ','), ('1950', '1950'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'isidor'), ('Jacob', 'jacob'), ('Good', 'good'), (',', ','), ('', ''), ('Probability', 'probabl'), ('Weighing', 'weigh'), ('Evidence', 'evid'), ('', ''), (',', ','), ('The', 'the'), ('University', 'univers'), ('Wisconsin', 'wisconsin'), ('-', '-'), ('Madison', 'madison'), (':', ':'), ('Charles', 'charl'), ('Griffin', 'griffin'), (',', ','), ('1950', '1950'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'Isidore'), ('Jacob', 'Jacob'), ('Good', 'Good'), (',', ','), ('', ''), ('Probability', 'Probability'), ('Weighing', 'Weighing'), ('Evidence', 'Evidence'), ('', ''), (',', ','), ('The', 'The'), ('University', 'University'), ('Wisconsin', 'Wisconsin'), ('-', '-'), ('Madison', 'Madison'), (':', ':'), ('Charles', 'Charles'), ('Griffin', 'Griffin'), (',', ','), ('1950', '1950'), ('.', '.')]



============================ Sentence 266 =============================

[22] Shiliang Sun, Changshui Zhang and Guoqiang Yu, A  Bayesian Network Approach to Traffic Flow Forecasting,   IEEE Transactions on Intelligent Transportation Systems,   Vol. 


>> Tokens are: 
 ['[', '22', ']', 'Shiliang', 'Sun', ',', 'Changshui', 'Zhang', 'Guoqiang', 'Yu', ',', '', 'A', 'Bayesian', 'Network', 'Approach', 'Traffic', 'Flow', 'Forecasting', '', ',', 'IEEE', 'Transactions', 'Intelligent', 'Transportation', 'Systems', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '22'), ('22', ']'), (']', 'Shiliang'), ('Shiliang', 'Sun'), ('Sun', ','), (',', 'Changshui'), ('Changshui', 'Zhang'), ('Zhang', 'Guoqiang'), ('Guoqiang', 'Yu'), ('Yu', ','), (',', ''), ('', 'A'), ('A', 'Bayesian'), ('Bayesian', 'Network'), ('Network', 'Approach'), ('Approach', 'Traffic'), ('Traffic', 'Flow'), ('Flow', 'Forecasting'), ('Forecasting', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Intelligent'), ('Intelligent', 'Transportation'), ('Transportation', 'Systems'), ('Systems', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '22', ']'), ('22', ']', 'Shiliang'), (']', 'Shiliang', 'Sun'), ('Shiliang', 'Sun', ','), ('Sun', ',', 'Changshui'), (',', 'Changshui', 'Zhang'), ('Changshui', 'Zhang', 'Guoqiang'), ('Zhang', 'Guoqiang', 'Yu'), ('Guoqiang', 'Yu', ','), ('Yu', ',', ''), (',', '', 'A'), ('', 'A', 'Bayesian'), ('A', 'Bayesian', 'Network'), ('Bayesian', 'Network', 'Approach'), ('Network', 'Approach', 'Traffic'), ('Approach', 'Traffic', 'Flow'), ('Traffic', 'Flow', 'Forecasting'), ('Flow', 'Forecasting', ''), ('Forecasting', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Intelligent'), ('Transactions', 'Intelligent', 'Transportation'), ('Intelligent', 'Transportation', 'Systems'), ('Transportation', 'Systems', ','), ('Systems', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('22', 'CD'), (']', 'NNS'), ('Shiliang', 'NNP'), ('Sun', 'NNP'), (',', ','), ('Changshui', 'NNP'), ('Zhang', 'NNP'), ('Guoqiang', 'NNP'), ('Yu', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Bayesian', 'NNP'), ('Network', 'NNP'), ('Approach', 'NNP'), ('Traffic', 'NNP'), ('Flow', 'NNP'), ('Forecasting', 'NNP'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Intelligent', 'NNP'), ('Transportation', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  22/CD
  (NP ]/NNS Shiliang/NNP Sun/NNP)
  ,/,
  (NP Changshui/NNP Zhang/NNP Guoqiang/NNP Yu/NNP)
  ,/,
  /VBZ
  (NP
    A/NNP
    Bayesian/NNP
    Network/NNP
    Approach/NNP
    Traffic/NNP
    Flow/NNP
    Forecasting/NNP
    /NNP)
  ,/,
  (NP
    IEEE/NNP
    Transactions/NNP
    Intelligent/NNP
    Transportation/NNP
    Systems/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Shiliang Sun', 'Changshui Zhang Guoqiang Yu', 'A Bayesian Network Approach Traffic Flow Forecasting ', 'IEEE Transactions Intelligent Transportation Systems', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Shiliang Sun'), ('PERSON', 'Changshui Zhang Guoqiang Yu'), ('PERSON', 'Network Approach Traffic Flow'), ('ORGANIZATION', 'IEEE Transactions'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'shiliang'), ('Sun', 'sun'), (',', ','), ('Changshui', 'changshui'), ('Zhang', 'zhang'), ('Guoqiang', 'guoqiang'), ('Yu', 'yu'), (',', ','), ('', ''), ('A', 'a'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('Approach', 'approach'), ('Traffic', 'traffic'), ('Flow', 'flow'), ('Forecasting', 'forecast'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Intelligent', 'intellig'), ('Transportation', 'transport'), ('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'shiliang'), ('Sun', 'sun'), (',', ','), ('Changshui', 'changshui'), ('Zhang', 'zhang'), ('Guoqiang', 'guoqiang'), ('Yu', 'yu'), (',', ','), ('', ''), ('A', 'a'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('Approach', 'approach'), ('Traffic', 'traffic'), ('Flow', 'flow'), ('Forecasting', 'forecast'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Intelligent', 'intellig'), ('Transportation', 'transport'), ('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'Shiliang'), ('Sun', 'Sun'), (',', ','), ('Changshui', 'Changshui'), ('Zhang', 'Zhang'), ('Guoqiang', 'Guoqiang'), ('Yu', 'Yu'), (',', ','), ('', ''), ('A', 'A'), ('Bayesian', 'Bayesian'), ('Network', 'Network'), ('Approach', 'Approach'), ('Traffic', 'Traffic'), ('Flow', 'Flow'), ('Forecasting', 'Forecasting'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Intelligent', 'Intelligent'), ('Transportation', 'Transportation'), ('Systems', 'Systems'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 267 =============================

7, No. 


>> Tokens are: 
 ['7', ',', 'No', '.']

>> Bigrams are: 
 [('7', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('7', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 7/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 268 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 269 =============================

124-132, 2006. 


>> Tokens are: 
 ['124-132', ',', '2006', '.']

>> Bigrams are: 
 [('124-132', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('124-132', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('124-132', 'CD'), (',', ','), ('2006', 'CD'), ('.', '.')]

 (S 124-132/CD ,/, 2006/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]



============================ Sentence 270 =============================

[23] Jie Cheng, Russell Greiner, Jonathan Kelly, David Bell and  Weiru Liu, Learning Bayesian networks from data: An   information-Theory based approach, The Artificial   Intelligence Journal, Vol. 


>> Tokens are: 
 ['[', '23', ']', 'Jie', 'Cheng', ',', 'Russell', 'Greiner', ',', 'Jonathan', 'Kelly', ',', 'David', 'Bell', 'Weiru', 'Liu', ',', '', 'Learning', 'Bayesian', 'networks', 'data', ':', 'An', 'information-Theory', 'based', 'approach', '', ',', 'The', 'Artificial', 'Intelligence', 'Journal', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '23'), ('23', ']'), (']', 'Jie'), ('Jie', 'Cheng'), ('Cheng', ','), (',', 'Russell'), ('Russell', 'Greiner'), ('Greiner', ','), (',', 'Jonathan'), ('Jonathan', 'Kelly'), ('Kelly', ','), (',', 'David'), ('David', 'Bell'), ('Bell', 'Weiru'), ('Weiru', 'Liu'), ('Liu', ','), (',', ''), ('', 'Learning'), ('Learning', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'data'), ('data', ':'), (':', 'An'), ('An', 'information-Theory'), ('information-Theory', 'based'), ('based', 'approach'), ('approach', ''), ('', ','), (',', 'The'), ('The', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Journal'), ('Journal', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '23', ']'), ('23', ']', 'Jie'), (']', 'Jie', 'Cheng'), ('Jie', 'Cheng', ','), ('Cheng', ',', 'Russell'), (',', 'Russell', 'Greiner'), ('Russell', 'Greiner', ','), ('Greiner', ',', 'Jonathan'), (',', 'Jonathan', 'Kelly'), ('Jonathan', 'Kelly', ','), ('Kelly', ',', 'David'), (',', 'David', 'Bell'), ('David', 'Bell', 'Weiru'), ('Bell', 'Weiru', 'Liu'), ('Weiru', 'Liu', ','), ('Liu', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'Bayesian'), ('Learning', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'data'), ('networks', 'data', ':'), ('data', ':', 'An'), (':', 'An', 'information-Theory'), ('An', 'information-Theory', 'based'), ('information-Theory', 'based', 'approach'), ('based', 'approach', ''), ('approach', '', ','), ('', ',', 'The'), (',', 'The', 'Artificial'), ('The', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Journal'), ('Intelligence', 'Journal', ','), ('Journal', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('23', 'CD'), (']', 'JJ'), ('Jie', 'NNP'), ('Cheng', 'NNP'), (',', ','), ('Russell', 'NNP'), ('Greiner', 'NNP'), (',', ','), ('Jonathan', 'NNP'), ('Kelly', 'NNP'), (',', ','), ('David', 'NNP'), ('Bell', 'NNP'), ('Weiru', 'NNP'), ('Liu', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('Bayesian', 'NNP'), ('networks', 'NNS'), ('data', 'NNS'), (':', ':'), ('An', 'DT'), ('information-Theory', 'NN'), ('based', 'VBN'), ('approach', 'NN'), ('', 'NN'), (',', ','), ('The', 'DT'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Journal', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  23/CD
  (NP ]/JJ Jie/NNP Cheng/NNP)
  ,/,
  (NP Russell/NNP Greiner/NNP)
  ,/,
  (NP Jonathan/NNP Kelly/NNP)
  ,/,
  (NP David/NNP Bell/NNP Weiru/NNP Liu/NNP)
  ,/,
  (NP /NNP Learning/NNP Bayesian/NNP networks/NNS data/NNS)
  :/:
  (NP An/DT information-Theory/NN)
  based/VBN
  (NP approach/NN /NN)
  ,/,
  (NP The/DT Artificial/NNP Intelligence/NNP Journal/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Jie Cheng', 'Russell Greiner', 'Jonathan Kelly', 'David Bell Weiru Liu', ' Learning Bayesian networks data', 'An information-Theory', 'approach ', 'The Artificial Intelligence Journal', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Russell Greiner'), ('PERSON', 'Jonathan Kelly'), ('PERSON', 'David Bell Weiru Liu'), ('ORGANIZATION', 'Artificial Intelligence Journal'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'jie'), ('Cheng', 'cheng'), (',', ','), ('Russell', 'russel'), ('Greiner', 'greiner'), (',', ','), ('Jonathan', 'jonathan'), ('Kelly', 'kelli'), (',', ','), ('David', 'david'), ('Bell', 'bell'), ('Weiru', 'weiru'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'an'), ('information-Theory', 'information-theori'), ('based', 'base'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'the'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Journal', 'journal'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'jie'), ('Cheng', 'cheng'), (',', ','), ('Russell', 'russel'), ('Greiner', 'greiner'), (',', ','), ('Jonathan', 'jonathan'), ('Kelly', 'kelli'), (',', ','), ('David', 'david'), ('Bell', 'bell'), ('Weiru', 'weiru'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'an'), ('information-Theory', 'information-theori'), ('based', 'base'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'the'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Journal', 'journal'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'Jie'), ('Cheng', 'Cheng'), (',', ','), ('Russell', 'Russell'), ('Greiner', 'Greiner'), (',', ','), ('Jonathan', 'Jonathan'), ('Kelly', 'Kelly'), (',', ','), ('David', 'David'), ('Bell', 'Bell'), ('Weiru', 'Weiru'), ('Liu', 'Liu'), (',', ','), ('', ''), ('Learning', 'Learning'), ('Bayesian', 'Bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'An'), ('information-Theory', 'information-Theory'), ('based', 'based'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'The'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Journal', 'Journal'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 271 =============================

137, pp. 


>> Tokens are: 
 ['137', ',', 'pp', '.']

>> Bigrams are: 
 [('137', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('137', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('137', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 137/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 272 =============================

43-90, 2002. 


>> Tokens are: 
 ['43-90', ',', '2002', '.']

>> Bigrams are: 
 [('43-90', ','), (',', '2002'), ('2002', '.')]

>> Trigrams are: 
 [('43-90', ',', '2002'), (',', '2002', '.')]

>> POS Tags are: 
 [('43-90', 'CD'), (',', ','), ('2002', 'CD'), ('.', '.')]

 (S 43-90/CD ,/, 2002/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]



============================ Sentence 273 =============================

[24] Tom M. Mitchell, Machine Learning: A Guide to Current  Research, The Springer International Series in Engineering   and Computer Science Series, McGraw Hill, 1997. 


>> Tokens are: 
 ['[', '24', ']', 'Tom', 'M.', 'Mitchell', ',', '', 'Machine', 'Learning', ':', 'A', 'Guide', 'Current', 'Research', '', ',', 'The', 'Springer', 'International', 'Series', 'Engineering', 'Computer', 'Science', 'Series', ',', 'McGraw', 'Hill', ',', '1997', '.']

>> Bigrams are: 
 [('[', '24'), ('24', ']'), (']', 'Tom'), ('Tom', 'M.'), ('M.', 'Mitchell'), ('Mitchell', ','), (',', ''), ('', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'A'), ('A', 'Guide'), ('Guide', 'Current'), ('Current', 'Research'), ('Research', ''), ('', ','), (',', 'The'), ('The', 'Springer'), ('Springer', 'International'), ('International', 'Series'), ('Series', 'Engineering'), ('Engineering', 'Computer'), ('Computer', 'Science'), ('Science', 'Series'), ('Series', ','), (',', 'McGraw'), ('McGraw', 'Hill'), ('Hill', ','), (',', '1997'), ('1997', '.')]

>> Trigrams are: 
 [('[', '24', ']'), ('24', ']', 'Tom'), (']', 'Tom', 'M.'), ('Tom', 'M.', 'Mitchell'), ('M.', 'Mitchell', ','), ('Mitchell', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'A'), (':', 'A', 'Guide'), ('A', 'Guide', 'Current'), ('Guide', 'Current', 'Research'), ('Current', 'Research', ''), ('Research', '', ','), ('', ',', 'The'), (',', 'The', 'Springer'), ('The', 'Springer', 'International'), ('Springer', 'International', 'Series'), ('International', 'Series', 'Engineering'), ('Series', 'Engineering', 'Computer'), ('Engineering', 'Computer', 'Science'), ('Computer', 'Science', 'Series'), ('Science', 'Series', ','), ('Series', ',', 'McGraw'), (',', 'McGraw', 'Hill'), ('McGraw', 'Hill', ','), ('Hill', ',', '1997'), (',', '1997', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('24', 'CD'), (']', 'JJ'), ('Tom', 'NNP'), ('M.', 'NNP'), ('Mitchell', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('A', 'DT'), ('Guide', 'NNP'), ('Current', 'NNP'), ('Research', 'NNP'), ('', 'NNP'), (',', ','), ('The', 'DT'), ('Springer', 'NNP'), ('International', 'NNP'), ('Series', 'NNP'), ('Engineering', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Series', 'NNP'), (',', ','), ('McGraw', 'NNP'), ('Hill', 'NNP'), (',', ','), ('1997', 'CD'), ('.', '.')]

 (S
  [/RB
  24/CD
  (NP ]/JJ Tom/NNP M./NNP Mitchell/NNP)
  ,/,
  (NP /NNP Machine/NNP Learning/NNP)
  :/:
  (NP A/DT Guide/NNP Current/NNP Research/NNP /NNP)
  ,/,
  (NP
    The/DT
    Springer/NNP
    International/NNP
    Series/NNP
    Engineering/NNP
    Computer/NNP
    Science/NNP
    Series/NNP)
  ,/,
  (NP McGraw/NNP Hill/NNP)
  ,/,
  1997/CD
  ./.) 


>> Noun Phrases are: 
 ['] Tom M. Mitchell', ' Machine Learning', 'A Guide Current Research ', 'The Springer International Series Engineering Computer Science Series', 'McGraw Hill']

>> Named Entities are: 
 [('PERSON', 'Tom M. Mitchell'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Springer International Series'), ('ORGANIZATION', 'McGraw Hill')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'tom'), ('M.', 'm.'), ('Mitchell', 'mitchel'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Guide', 'guid'), ('Current', 'current'), ('Research', 'research'), ('', ''), (',', ','), ('The', 'the'), ('Springer', 'springer'), ('International', 'intern'), ('Series', 'seri'), ('Engineering', 'engin'), ('Computer', 'comput'), ('Science', 'scienc'), ('Series', 'seri'), (',', ','), ('McGraw', 'mcgraw'), ('Hill', 'hill'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'tom'), ('M.', 'm.'), ('Mitchell', 'mitchel'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Guide', 'guid'), ('Current', 'current'), ('Research', 'research'), ('', ''), (',', ','), ('The', 'the'), ('Springer', 'springer'), ('International', 'intern'), ('Series', 'seri'), ('Engineering', 'engin'), ('Computer', 'comput'), ('Science', 'scienc'), ('Series', 'seri'), (',', ','), ('McGraw', 'mcgraw'), ('Hill', 'hill'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'Tom'), ('M.', 'M.'), ('Mitchell', 'Mitchell'), (',', ','), ('', ''), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('A', 'A'), ('Guide', 'Guide'), ('Current', 'Current'), ('Research', 'Research'), ('', ''), (',', ','), ('The', 'The'), ('Springer', 'Springer'), ('International', 'International'), ('Series', 'Series'), ('Engineering', 'Engineering'), ('Computer', 'Computer'), ('Science', 'Science'), ('Series', 'Series'), (',', ','), ('McGraw', 'McGraw'), ('Hill', 'Hill'), (',', ','), ('1997', '1997'), ('.', '.')]



============================ Sentence 274 =============================

[25] D. Aha, Lazy Learning, Dordrecht: Kluwer Academic  Publishers, 1997. 


>> Tokens are: 
 ['[', '25', ']', 'D.', 'Aha', ',', '', 'Lazy', 'Learning', '', ',', 'Dordrecht', ':', 'Kluwer', 'Academic', 'Publishers', ',', '1997', '.']

>> Bigrams are: 
 [('[', '25'), ('25', ']'), (']', 'D.'), ('D.', 'Aha'), ('Aha', ','), (',', ''), ('', 'Lazy'), ('Lazy', 'Learning'), ('Learning', ''), ('', ','), (',', 'Dordrecht'), ('Dordrecht', ':'), (':', 'Kluwer'), ('Kluwer', 'Academic'), ('Academic', 'Publishers'), ('Publishers', ','), (',', '1997'), ('1997', '.')]

>> Trigrams are: 
 [('[', '25', ']'), ('25', ']', 'D.'), (']', 'D.', 'Aha'), ('D.', 'Aha', ','), ('Aha', ',', ''), (',', '', 'Lazy'), ('', 'Lazy', 'Learning'), ('Lazy', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Dordrecht'), (',', 'Dordrecht', ':'), ('Dordrecht', ':', 'Kluwer'), (':', 'Kluwer', 'Academic'), ('Kluwer', 'Academic', 'Publishers'), ('Academic', 'Publishers', ','), ('Publishers', ',', '1997'), (',', '1997', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('25', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Aha', 'NNP'), (',', ','), ('', 'NNP'), ('Lazy', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Dordrecht', 'NNP'), (':', ':'), ('Kluwer', 'NNP'), ('Academic', 'NNP'), ('Publishers', 'NNP'), (',', ','), ('1997', 'CD'), ('.', '.')]

 (S
  [/RB
  25/CD
  (NP ]/JJ D./NNP Aha/NNP)
  ,/,
  (NP /NNP Lazy/NNP Learning/NNP /NNP)
  ,/,
  (NP Dordrecht/NNP)
  :/:
  (NP Kluwer/NNP Academic/NNP Publishers/NNP)
  ,/,
  1997/CD
  ./.) 


>> Noun Phrases are: 
 ['] D. Aha', ' Lazy Learning ', 'Dordrecht', 'Kluwer Academic Publishers']

>> Named Entities are: 
 [('PERSON', 'Dordrecht'), ('PERSON', 'Kluwer Academic Publishers')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'd.'), ('Aha', 'aha'), (',', ','), ('', ''), ('Lazy', 'lazi'), ('Learning', 'learn'), ('', ''), (',', ','), ('Dordrecht', 'dordrecht'), (':', ':'), ('Kluwer', 'kluwer'), ('Academic', 'academ'), ('Publishers', 'publish'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'd.'), ('Aha', 'aha'), (',', ','), ('', ''), ('Lazy', 'lazi'), ('Learning', 'learn'), ('', ''), (',', ','), ('Dordrecht', 'dordrecht'), (':', ':'), ('Kluwer', 'kluwer'), ('Academic', 'academ'), ('Publishers', 'publish'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'D.'), ('Aha', 'Aha'), (',', ','), ('', ''), ('Lazy', 'Lazy'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Dordrecht', 'Dordrecht'), (':', ':'), ('Kluwer', 'Kluwer'), ('Academic', 'Academic'), ('Publishers', 'Publishers'), (',', ','), ('1997', '1997'), ('.', '.')]



============================ Sentence 275 =============================

[26] Ramon Lopez De Mantaras and Eva Armengol, Machine  learning from examples: Inductive and Lazy methods, Data and   Knowledge Engineering, Vol. 


>> Tokens are: 
 ['[', '26', ']', 'Ramon', 'Lopez', 'De', 'Mantaras', 'Eva', 'Armengol', ',', '', 'Machine', 'learning', 'examples', ':', 'Inductive', 'Lazy', 'methods', '', ',', 'Data', 'Knowledge', 'Engineering', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '26'), ('26', ']'), (']', 'Ramon'), ('Ramon', 'Lopez'), ('Lopez', 'De'), ('De', 'Mantaras'), ('Mantaras', 'Eva'), ('Eva', 'Armengol'), ('Armengol', ','), (',', ''), ('', 'Machine'), ('Machine', 'learning'), ('learning', 'examples'), ('examples', ':'), (':', 'Inductive'), ('Inductive', 'Lazy'), ('Lazy', 'methods'), ('methods', ''), ('', ','), (',', 'Data'), ('Data', 'Knowledge'), ('Knowledge', 'Engineering'), ('Engineering', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '26', ']'), ('26', ']', 'Ramon'), (']', 'Ramon', 'Lopez'), ('Ramon', 'Lopez', 'De'), ('Lopez', 'De', 'Mantaras'), ('De', 'Mantaras', 'Eva'), ('Mantaras', 'Eva', 'Armengol'), ('Eva', 'Armengol', ','), ('Armengol', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'learning'), ('Machine', 'learning', 'examples'), ('learning', 'examples', ':'), ('examples', ':', 'Inductive'), (':', 'Inductive', 'Lazy'), ('Inductive', 'Lazy', 'methods'), ('Lazy', 'methods', ''), ('methods', '', ','), ('', ',', 'Data'), (',', 'Data', 'Knowledge'), ('Data', 'Knowledge', 'Engineering'), ('Knowledge', 'Engineering', ','), ('Engineering', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('26', 'CD'), (']', 'JJ'), ('Ramon', 'NNP'), ('Lopez', 'NNP'), ('De', 'NNP'), ('Mantaras', 'NNP'), ('Eva', 'NNP'), ('Armengol', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('learning', 'VBG'), ('examples', 'NNS'), (':', ':'), ('Inductive', 'JJ'), ('Lazy', 'NNP'), ('methods', 'NNS'), ('', 'NNP'), (',', ','), ('Data', 'NNP'), ('Knowledge', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  26/CD
  (NP
    ]/JJ
    Ramon/NNP
    Lopez/NNP
    De/NNP
    Mantaras/NNP
    Eva/NNP
    Armengol/NNP)
  ,/,
  (NP /NNP Machine/NNP)
  learning/VBG
  (NP examples/NNS)
  :/:
  (NP Inductive/JJ Lazy/NNP methods/NNS /NNP)
  ,/,
  (NP Data/NNP Knowledge/NNP Engineering/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Ramon Lopez De Mantaras Eva Armengol', ' Machine', 'examples', 'Inductive Lazy methods ', 'Data Knowledge Engineering', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Ramon Lopez De Mantaras Eva Armengol'), ('PERSON', 'Data Knowledge Engineering'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'ramon'), ('Lopez', 'lopez'), ('De', 'de'), ('Mantaras', 'mantara'), ('Eva', 'eva'), ('Armengol', 'armengol'), (',', ','), ('', ''), ('Machine', 'machin'), ('learning', 'learn'), ('examples', 'exampl'), (':', ':'), ('Inductive', 'induct'), ('Lazy', 'lazi'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'data'), ('Knowledge', 'knowledg'), ('Engineering', 'engin'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'ramon'), ('Lopez', 'lopez'), ('De', 'de'), ('Mantaras', 'mantara'), ('Eva', 'eva'), ('Armengol', 'armengol'), (',', ','), ('', ''), ('Machine', 'machin'), ('learning', 'learn'), ('examples', 'exampl'), (':', ':'), ('Inductive', 'induct'), ('Lazy', 'lazi'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'data'), ('Knowledge', 'knowledg'), ('Engineering', 'engin'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'Ramon'), ('Lopez', 'Lopez'), ('De', 'De'), ('Mantaras', 'Mantaras'), ('Eva', 'Eva'), ('Armengol', 'Armengol'), (',', ','), ('', ''), ('Machine', 'Machine'), ('learning', 'learning'), ('examples', 'example'), (':', ':'), ('Inductive', 'Inductive'), ('Lazy', 'Lazy'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'Data'), ('Knowledge', 'Knowledge'), ('Engineering', 'Engineering'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 276 =============================

25, No. 


>> Tokens are: 
 ['25', ',', 'No', '.']

>> Bigrams are: 
 [('25', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('25', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('25', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 25/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25', '25'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('25', '25'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 277 =============================

1-2, pp. 


>> Tokens are: 
 ['1-2', ',', 'pp', '.']

>> Bigrams are: 
 [('1-2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1-2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1-2', 'JJ'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1-2/JJ ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 278 =============================

99-123, 1998. 


>> Tokens are: 
 ['99-123', ',', '1998', '.']

>> Bigrams are: 
 [('99-123', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('99-123', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('99-123', 'CD'), (',', ','), ('1998', 'CD'), ('.', '.')]

 (S 99-123/CD ,/, 1998/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]



============================ Sentence 279 =============================

[27] Hamid Parvin, Hoseinali Alizadeh and Behrouz Minati, A  Modification on K-Nearest Neighbor Classifier, Global   Journal of Computer Science and Technology, Vol. 


>> Tokens are: 
 ['[', '27', ']', 'Hamid', 'Parvin', ',', 'Hoseinali', 'Alizadeh', 'Behrouz', 'Minati', ',', '', 'A', 'Modification', 'K-Nearest', 'Neighbor', 'Classifier', '', ',', 'Global', 'Journal', 'Computer', 'Science', 'Technology', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '27'), ('27', ']'), (']', 'Hamid'), ('Hamid', 'Parvin'), ('Parvin', ','), (',', 'Hoseinali'), ('Hoseinali', 'Alizadeh'), ('Alizadeh', 'Behrouz'), ('Behrouz', 'Minati'), ('Minati', ','), (',', ''), ('', 'A'), ('A', 'Modification'), ('Modification', 'K-Nearest'), ('K-Nearest', 'Neighbor'), ('Neighbor', 'Classifier'), ('Classifier', ''), ('', ','), (',', 'Global'), ('Global', 'Journal'), ('Journal', 'Computer'), ('Computer', 'Science'), ('Science', 'Technology'), ('Technology', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '27', ']'), ('27', ']', 'Hamid'), (']', 'Hamid', 'Parvin'), ('Hamid', 'Parvin', ','), ('Parvin', ',', 'Hoseinali'), (',', 'Hoseinali', 'Alizadeh'), ('Hoseinali', 'Alizadeh', 'Behrouz'), ('Alizadeh', 'Behrouz', 'Minati'), ('Behrouz', 'Minati', ','), ('Minati', ',', ''), (',', '', 'A'), ('', 'A', 'Modification'), ('A', 'Modification', 'K-Nearest'), ('Modification', 'K-Nearest', 'Neighbor'), ('K-Nearest', 'Neighbor', 'Classifier'), ('Neighbor', 'Classifier', ''), ('Classifier', '', ','), ('', ',', 'Global'), (',', 'Global', 'Journal'), ('Global', 'Journal', 'Computer'), ('Journal', 'Computer', 'Science'), ('Computer', 'Science', 'Technology'), ('Science', 'Technology', ','), ('Technology', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('27', 'CD'), (']', 'NNS'), ('Hamid', 'NNP'), ('Parvin', 'NNP'), (',', ','), ('Hoseinali', 'NNP'), ('Alizadeh', 'NNP'), ('Behrouz', 'NNP'), ('Minati', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'DT'), ('Modification', 'NNP'), ('K-Nearest', 'NNP'), ('Neighbor', 'NNP'), ('Classifier', 'NNP'), ('', 'NNP'), (',', ','), ('Global', 'NNP'), ('Journal', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  27/CD
  (NP ]/NNS Hamid/NNP Parvin/NNP)
  ,/,
  (NP Hoseinali/NNP Alizadeh/NNP Behrouz/NNP Minati/NNP)
  ,/,
  /VBZ
  (NP
    A/DT
    Modification/NNP
    K-Nearest/NNP
    Neighbor/NNP
    Classifier/NNP
    /NNP)
  ,/,
  (NP Global/NNP Journal/NNP Computer/NNP Science/NNP Technology/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Hamid Parvin', 'Hoseinali Alizadeh Behrouz Minati', 'A Modification K-Nearest Neighbor Classifier ', 'Global Journal Computer Science Technology', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Hamid Parvin'), ('PERSON', 'Hoseinali Alizadeh Behrouz Minati'), ('PERSON', 'Global Journal Computer Science Technology'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'hamid'), ('Parvin', 'parvin'), (',', ','), ('Hoseinali', 'hoseinali'), ('Alizadeh', 'alizadeh'), ('Behrouz', 'behrouz'), ('Minati', 'minati'), (',', ','), ('', ''), ('A', 'a'), ('Modification', 'modif'), ('K-Nearest', 'k-nearest'), ('Neighbor', 'neighbor'), ('Classifier', 'classifi'), ('', ''), (',', ','), ('Global', 'global'), ('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'hamid'), ('Parvin', 'parvin'), (',', ','), ('Hoseinali', 'hoseinali'), ('Alizadeh', 'alizadeh'), ('Behrouz', 'behrouz'), ('Minati', 'minati'), (',', ','), ('', ''), ('A', 'a'), ('Modification', 'modif'), ('K-Nearest', 'k-nearest'), ('Neighbor', 'neighbor'), ('Classifier', 'classifi'), ('', ''), (',', ','), ('Global', 'global'), ('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'Hamid'), ('Parvin', 'Parvin'), (',', ','), ('Hoseinali', 'Hoseinali'), ('Alizadeh', 'Alizadeh'), ('Behrouz', 'Behrouz'), ('Minati', 'Minati'), (',', ','), ('', ''), ('A', 'A'), ('Modification', 'Modification'), ('K-Nearest', 'K-Nearest'), ('Neighbor', 'Neighbor'), ('Classifier', 'Classifier'), ('', ''), (',', ','), ('Global', 'Global'), ('Journal', 'Journal'), ('Computer', 'Computer'), ('Science', 'Science'), ('Technology', 'Technology'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 280 =============================

10, No. 


>> Tokens are: 
 ['10', ',', 'No', '.']

>> Bigrams are: 
 [('10', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('10', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 10/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 281 =============================

14 (Ver.1.0), pp. 


>> Tokens are: 
 ['14', '(', 'Ver.1.0', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('14', '('), ('(', 'Ver.1.0'), ('Ver.1.0', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('14', '(', 'Ver.1.0'), ('(', 'Ver.1.0', ')'), ('Ver.1.0', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('14', 'CD'), ('(', '('), ('Ver.1.0', 'NNP'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 14/CD (/( (NP Ver.1.0/NNP) )/) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Ver.1.0', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'Ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 282 =============================

37-41, 2010. 


>> Tokens are: 
 ['37-41', ',', '2010', '.']

>> Bigrams are: 
 [('37-41', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('37-41', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('37-41', 'CD'), (',', ','), ('2010', 'CD'), ('.', '.')]

 (S 37-41/CD ,/, 2010/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]



============================ Sentence 283 =============================

[28] Yen-Liang Chen and Lucas Tzu-Hsuan Hung, Using  decision trees to summarize associative classification   rules, Expert Systems with Applications, Vol. 


>> Tokens are: 
 ['[', '28', ']', 'Yen-Liang', 'Chen', 'Lucas', 'Tzu-Hsuan', 'Hung', ',', '', 'Using', 'decision', 'trees', 'summarize', 'associative', 'classification', 'rules', '', ',', 'Expert', 'Systems', 'Applications', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '28'), ('28', ']'), (']', 'Yen-Liang'), ('Yen-Liang', 'Chen'), ('Chen', 'Lucas'), ('Lucas', 'Tzu-Hsuan'), ('Tzu-Hsuan', 'Hung'), ('Hung', ','), (',', ''), ('', 'Using'), ('Using', 'decision'), ('decision', 'trees'), ('trees', 'summarize'), ('summarize', 'associative'), ('associative', 'classification'), ('classification', 'rules'), ('rules', ''), ('', ','), (',', 'Expert'), ('Expert', 'Systems'), ('Systems', 'Applications'), ('Applications', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '28', ']'), ('28', ']', 'Yen-Liang'), (']', 'Yen-Liang', 'Chen'), ('Yen-Liang', 'Chen', 'Lucas'), ('Chen', 'Lucas', 'Tzu-Hsuan'), ('Lucas', 'Tzu-Hsuan', 'Hung'), ('Tzu-Hsuan', 'Hung', ','), ('Hung', ',', ''), (',', '', 'Using'), ('', 'Using', 'decision'), ('Using', 'decision', 'trees'), ('decision', 'trees', 'summarize'), ('trees', 'summarize', 'associative'), ('summarize', 'associative', 'classification'), ('associative', 'classification', 'rules'), ('classification', 'rules', ''), ('rules', '', ','), ('', ',', 'Expert'), (',', 'Expert', 'Systems'), ('Expert', 'Systems', 'Applications'), ('Systems', 'Applications', ','), ('Applications', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('28', 'CD'), (']', 'JJ'), ('Yen-Liang', 'NNP'), ('Chen', 'NNP'), ('Lucas', 'NNP'), ('Tzu-Hsuan', 'NNP'), ('Hung', 'NNP'), (',', ','), ('', 'NNP'), ('Using', 'NNP'), ('decision', 'NN'), ('trees', 'NNS'), ('summarize', 'VBP'), ('associative', 'JJ'), ('classification', 'NN'), ('rules', 'NNS'), ('', 'VBP'), (',', ','), ('Expert', 'NNP'), ('Systems', 'NNP'), ('Applications', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  28/CD
  (NP ]/JJ Yen-Liang/NNP Chen/NNP Lucas/NNP Tzu-Hsuan/NNP Hung/NNP)
  ,/,
  (NP /NNP Using/NNP decision/NN trees/NNS)
  summarize/VBP
  (NP associative/JJ classification/NN rules/NNS)
  /VBP
  ,/,
  (NP Expert/NNP Systems/NNP Applications/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Yen-Liang Chen Lucas Tzu-Hsuan Hung', ' Using decision trees', 'associative classification rules', 'Expert Systems Applications', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Chen Lucas'), ('PERSON', 'Expert Systems Applications'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'yen-liang'), ('Chen', 'chen'), ('Lucas', 'luca'), ('Tzu-Hsuan', 'tzu-hsuan'), ('Hung', 'hung'), (',', ','), ('', ''), ('Using', 'use'), ('decision', 'decis'), ('trees', 'tree'), ('summarize', 'summar'), ('associative', 'associ'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'expert'), ('Systems', 'system'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'yen-liang'), ('Chen', 'chen'), ('Lucas', 'luca'), ('Tzu-Hsuan', 'tzu-hsuan'), ('Hung', 'hung'), (',', ','), ('', ''), ('Using', 'use'), ('decision', 'decis'), ('trees', 'tree'), ('summarize', 'summar'), ('associative', 'associ'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'expert'), ('Systems', 'system'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'Yen-Liang'), ('Chen', 'Chen'), ('Lucas', 'Lucas'), ('Tzu-Hsuan', 'Tzu-Hsuan'), ('Hung', 'Hung'), (',', ','), ('', ''), ('Using', 'Using'), ('decision', 'decision'), ('trees', 'tree'), ('summarize', 'summarize'), ('associative', 'associative'), ('classification', 'classification'), ('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'Expert'), ('Systems', 'Systems'), ('Applications', 'Applications'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 284 =============================

36, No. 


>> Tokens are: 
 ['36', ',', 'No', '.']

>> Bigrams are: 
 [('36', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('36', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('36', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 36/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('36', '36'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('36', '36'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('36', '36'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 285 =============================

2,   Part 1, pp. 


>> Tokens are: 
 ['2', ',', 'Part', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'Part'), ('Part', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'Part'), (',', 'Part', '1'), ('Part', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('Part', 'NNP'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 2/CD ,/, (NP Part/NNP) 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Part', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Part')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('Part', 'part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('Part', 'part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('Part', 'Part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 286 =============================

2338-2351, 2009. 


>> Tokens are: 
 ['2338-2351', ',', '2009', '.']

>> Bigrams are: 
 [('2338-2351', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('2338-2351', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('2338-2351', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

 (S 2338-2351/CD ,/, 2009/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]



============================ Sentence 287 =============================

[29] Samy Bengio, Li Deng, Hugo Larochelle, Honglak Lee, and  Ruslan Salakhutdinov, Guest Editors Introduction: Special   Section on Learning Deep Architectures, IEEE   Transactions on   Pattern Analysis and Machine   Intelligence, Vol. 


>> Tokens are: 
 ['[', '29', ']', 'Samy', 'Bengio', ',', 'Li', 'Deng', ',', 'Hugo', 'Larochelle', ',', 'Honglak', 'Lee', ',', 'Ruslan', 'Salakhutdinov', ',', '', 'Guest', 'Editors', '', 'Introduction', ':', 'Special', 'Section', 'Learning', 'Deep', 'Architectures', '', ',', 'IEEE', 'Transactions', 'Pattern', 'Analysis', 'Machine', 'Intelligence', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'Samy'), ('Samy', 'Bengio'), ('Bengio', ','), (',', 'Li'), ('Li', 'Deng'), ('Deng', ','), (',', 'Hugo'), ('Hugo', 'Larochelle'), ('Larochelle', ','), (',', 'Honglak'), ('Honglak', 'Lee'), ('Lee', ','), (',', 'Ruslan'), ('Ruslan', 'Salakhutdinov'), ('Salakhutdinov', ','), (',', ''), ('', 'Guest'), ('Guest', 'Editors'), ('Editors', ''), ('', 'Introduction'), ('Introduction', ':'), (':', 'Special'), ('Special', 'Section'), ('Section', 'Learning'), ('Learning', 'Deep'), ('Deep', 'Architectures'), ('Architectures', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Pattern'), ('Pattern', 'Analysis'), ('Analysis', 'Machine'), ('Machine', 'Intelligence'), ('Intelligence', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'Samy'), (']', 'Samy', 'Bengio'), ('Samy', 'Bengio', ','), ('Bengio', ',', 'Li'), (',', 'Li', 'Deng'), ('Li', 'Deng', ','), ('Deng', ',', 'Hugo'), (',', 'Hugo', 'Larochelle'), ('Hugo', 'Larochelle', ','), ('Larochelle', ',', 'Honglak'), (',', 'Honglak', 'Lee'), ('Honglak', 'Lee', ','), ('Lee', ',', 'Ruslan'), (',', 'Ruslan', 'Salakhutdinov'), ('Ruslan', 'Salakhutdinov', ','), ('Salakhutdinov', ',', ''), (',', '', 'Guest'), ('', 'Guest', 'Editors'), ('Guest', 'Editors', ''), ('Editors', '', 'Introduction'), ('', 'Introduction', ':'), ('Introduction', ':', 'Special'), (':', 'Special', 'Section'), ('Special', 'Section', 'Learning'), ('Section', 'Learning', 'Deep'), ('Learning', 'Deep', 'Architectures'), ('Deep', 'Architectures', ''), ('Architectures', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Pattern'), ('Transactions', 'Pattern', 'Analysis'), ('Pattern', 'Analysis', 'Machine'), ('Analysis', 'Machine', 'Intelligence'), ('Machine', 'Intelligence', ','), ('Intelligence', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'JJ'), ('Samy', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('Li', 'NNP'), ('Deng', 'NNP'), (',', ','), ('Hugo', 'NNP'), ('Larochelle', 'NNP'), (',', ','), ('Honglak', 'NNP'), ('Lee', 'NNP'), (',', ','), ('Ruslan', 'NNP'), ('Salakhutdinov', 'NNP'), (',', ','), ('', 'NNP'), ('Guest', 'NNP'), ('Editors', 'NNPS'), ('', 'NNP'), ('Introduction', 'NNP'), (':', ':'), ('Special', 'JJ'), ('Section', 'NN'), ('Learning', 'NNP'), ('Deep', 'NNP'), ('Architectures', 'NNP'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Pattern', 'NNP'), ('Analysis', 'NNP'), ('Machine', 'NNP'), ('Intelligence', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  29/CD
  (NP ]/JJ Samy/NNP Bengio/NNP)
  ,/,
  (NP Li/NNP Deng/NNP)
  ,/,
  (NP Hugo/NNP Larochelle/NNP)
  ,/,
  (NP Honglak/NNP Lee/NNP)
  ,/,
  (NP Ruslan/NNP Salakhutdinov/NNP)
  ,/,
  (NP /NNP Guest/NNP)
  Editors/NNPS
  (NP /NNP Introduction/NNP)
  :/:
  (NP
    Special/JJ
    Section/NN
    Learning/NNP
    Deep/NNP
    Architectures/NNP
    /NNP)
  ,/,
  (NP
    IEEE/NNP
    Transactions/NNP
    Pattern/NNP
    Analysis/NNP
    Machine/NNP
    Intelligence/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Samy Bengio', 'Li Deng', 'Hugo Larochelle', 'Honglak Lee', 'Ruslan Salakhutdinov', ' Guest', ' Introduction', 'Special Section Learning Deep Architectures ', 'IEEE Transactions Pattern Analysis Machine Intelligence', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Samy Bengio'), ('PERSON', 'Li Deng'), ('PERSON', 'Hugo Larochelle'), ('PERSON', 'Honglak Lee'), ('PERSON', 'Ruslan Salakhutdinov'), ('ORGANIZATION', 'IEEE Transactions Pattern Analysis Machine Intelligence'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'sami'), ('Bengio', 'bengio'), (',', ','), ('Li', 'li'), ('Deng', 'deng'), (',', ','), ('Hugo', 'hugo'), ('Larochelle', 'larochel'), (',', ','), ('Honglak', 'honglak'), ('Lee', 'lee'), (',', ','), ('Ruslan', 'ruslan'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('', ''), ('Guest', 'guest'), ('Editors', 'editor'), ('', ''), ('Introduction', 'introduct'), (':', ':'), ('Special', 'special'), ('Section', 'section'), ('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Pattern', 'pattern'), ('Analysis', 'analysi'), ('Machine', 'machin'), ('Intelligence', 'intellig'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'sami'), ('Bengio', 'bengio'), (',', ','), ('Li', 'li'), ('Deng', 'deng'), (',', ','), ('Hugo', 'hugo'), ('Larochelle', 'larochell'), (',', ','), ('Honglak', 'honglak'), ('Lee', 'lee'), (',', ','), ('Ruslan', 'ruslan'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('', ''), ('Guest', 'guest'), ('Editors', 'editor'), ('', ''), ('Introduction', 'introduct'), (':', ':'), ('Special', 'special'), ('Section', 'section'), ('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Pattern', 'pattern'), ('Analysis', 'analysi'), ('Machine', 'machin'), ('Intelligence', 'intellig'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'Samy'), ('Bengio', 'Bengio'), (',', ','), ('Li', 'Li'), ('Deng', 'Deng'), (',', ','), ('Hugo', 'Hugo'), ('Larochelle', 'Larochelle'), (',', ','), ('Honglak', 'Honglak'), ('Lee', 'Lee'), (',', ','), ('Ruslan', 'Ruslan'), ('Salakhutdinov', 'Salakhutdinov'), (',', ','), ('', ''), ('Guest', 'Guest'), ('Editors', 'Editors'), ('', ''), ('Introduction', 'Introduction'), (':', ':'), ('Special', 'Special'), ('Section', 'Section'), ('Learning', 'Learning'), ('Deep', 'Deep'), ('Architectures', 'Architectures'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Pattern', 'Pattern'), ('Analysis', 'Analysis'), ('Machine', 'Machine'), ('Intelligence', 'Intelligence'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 288 =============================

35, No. 


>> Tokens are: 
 ['35', ',', 'No', '.']

>> Bigrams are: 
 [('35', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('35', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 35/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 289 =============================

8, pp. 


>> Tokens are: 
 ['8', ',', 'pp', '.']

>> Bigrams are: 
 [('8', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('8', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 8/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 290 =============================

1795-1797, 2013. 


>> Tokens are: 
 ['1795-1797', ',', '2013', '.']

>> Bigrams are: 
 [('1795-1797', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('1795-1797', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('1795-1797', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S 1795-1797/CD ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 291 =============================

[30] Qinghua Zheng, Zhaohui Wu, Xiaocheng Cheng, Lu Jiang  and Jun Liu, Learning to crawl deep web, Information   Systems, Vol. 


>> Tokens are: 
 ['[', '30', ']', 'Qinghua', 'Zheng', ',', 'Zhaohui', 'Wu', ',', 'Xiaocheng', 'Cheng', ',', 'Lu', 'Jiang', 'Jun', 'Liu', ',', '', 'Learning', 'crawl', 'deep', 'web', '', ',', 'Information', 'Systems', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '30'), ('30', ']'), (']', 'Qinghua'), ('Qinghua', 'Zheng'), ('Zheng', ','), (',', 'Zhaohui'), ('Zhaohui', 'Wu'), ('Wu', ','), (',', 'Xiaocheng'), ('Xiaocheng', 'Cheng'), ('Cheng', ','), (',', 'Lu'), ('Lu', 'Jiang'), ('Jiang', 'Jun'), ('Jun', 'Liu'), ('Liu', ','), (',', ''), ('', 'Learning'), ('Learning', 'crawl'), ('crawl', 'deep'), ('deep', 'web'), ('web', ''), ('', ','), (',', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '30', ']'), ('30', ']', 'Qinghua'), (']', 'Qinghua', 'Zheng'), ('Qinghua', 'Zheng', ','), ('Zheng', ',', 'Zhaohui'), (',', 'Zhaohui', 'Wu'), ('Zhaohui', 'Wu', ','), ('Wu', ',', 'Xiaocheng'), (',', 'Xiaocheng', 'Cheng'), ('Xiaocheng', 'Cheng', ','), ('Cheng', ',', 'Lu'), (',', 'Lu', 'Jiang'), ('Lu', 'Jiang', 'Jun'), ('Jiang', 'Jun', 'Liu'), ('Jun', 'Liu', ','), ('Liu', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'crawl'), ('Learning', 'crawl', 'deep'), ('crawl', 'deep', 'web'), ('deep', 'web', ''), ('web', '', ','), ('', ',', 'Information'), (',', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('30', 'CD'), (']', 'JJ'), ('Qinghua', 'NNP'), ('Zheng', 'NNP'), (',', ','), ('Zhaohui', 'NNP'), ('Wu', 'NNP'), (',', ','), ('Xiaocheng', 'NNP'), ('Cheng', 'NNP'), (',', ','), ('Lu', 'NNP'), ('Jiang', 'NNP'), ('Jun', 'NNP'), ('Liu', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('crawl', 'JJ'), ('deep', 'JJ'), ('web', 'NN'), ('', 'NNP'), (',', ','), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  30/CD
  (NP ]/JJ Qinghua/NNP Zheng/NNP)
  ,/,
  (NP Zhaohui/NNP Wu/NNP)
  ,/,
  (NP Xiaocheng/NNP Cheng/NNP)
  ,/,
  (NP Lu/NNP Jiang/NNP Jun/NNP Liu/NNP)
  ,/,
  (NP /NNP Learning/NNP)
  (NP crawl/JJ deep/JJ web/NN /NNP)
  ,/,
  (NP Information/NNP Systems/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Qinghua Zheng', 'Zhaohui Wu', 'Xiaocheng Cheng', 'Lu Jiang Jun Liu', ' Learning', 'crawl deep web ', 'Information Systems', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Qinghua Zheng'), ('PERSON', 'Zhaohui Wu'), ('PERSON', 'Xiaocheng Cheng'), ('PERSON', 'Lu Jiang Jun Liu'), ('ORGANIZATION', 'Information Systems'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'qinghua'), ('Zheng', 'zheng'), (',', ','), ('Zhaohui', 'zhaohui'), ('Wu', 'wu'), (',', ','), ('Xiaocheng', 'xiaocheng'), ('Cheng', 'cheng'), (',', ','), ('Lu', 'lu'), ('Jiang', 'jiang'), ('Jun', 'jun'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'qinghua'), ('Zheng', 'zheng'), (',', ','), ('Zhaohui', 'zhaohui'), ('Wu', 'wu'), (',', ','), ('Xiaocheng', 'xiaocheng'), ('Cheng', 'cheng'), (',', ','), ('Lu', 'lu'), ('Jiang', 'jiang'), ('Jun', 'jun'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'Qinghua'), ('Zheng', 'Zheng'), (',', ','), ('Zhaohui', 'Zhaohui'), ('Wu', 'Wu'), (',', ','), ('Xiaocheng', 'Xiaocheng'), ('Cheng', 'Cheng'), (',', ','), ('Lu', 'Lu'), ('Jiang', 'Jiang'), ('Jun', 'Jun'), ('Liu', 'Liu'), (',', ','), ('', ''), ('Learning', 'Learning'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 292 =============================

38, No. 


>> Tokens are: 
 ['38', ',', 'No', '.']

>> Bigrams are: 
 [('38', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('38', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('38', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 38/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38', '38'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38', '38'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('38', '38'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 293 =============================

6, pp. 


>> Tokens are: 
 ['6', ',', 'pp', '.']

>> Bigrams are: 
 [('6', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('6', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 6/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 294 =============================

801-819, 2013. 


>> Tokens are: 
 ['801-819', ',', '2013', '.']

>> Bigrams are: 
 [('801-819', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('801-819', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('801-819', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S 801-819/CD ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 295 =============================

[31] Xue-Wen Chen and Xiaotong Lin, Big Data Deep  Learning: Challenges and Perspectives, IEEE Access   Practical Innovations: Open Solutions and Access and   IEEE, Vol. 


>> Tokens are: 
 ['[', '31', ']', 'Xue-Wen', 'Chen', 'Xiaotong', 'Lin', ',', '', 'Big', 'Data', 'Deep', 'Learning', ':', 'Challenges', 'Perspectives', '', ',', 'IEEE', 'Access', 'Practical', 'Innovations', ':', 'Open', 'Solutions', 'Access', 'IEEE', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '31'), ('31', ']'), (']', 'Xue-Wen'), ('Xue-Wen', 'Chen'), ('Chen', 'Xiaotong'), ('Xiaotong', 'Lin'), ('Lin', ','), (',', ''), ('', 'Big'), ('Big', 'Data'), ('Data', 'Deep'), ('Deep', 'Learning'), ('Learning', ':'), (':', 'Challenges'), ('Challenges', 'Perspectives'), ('Perspectives', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Access'), ('Access', 'Practical'), ('Practical', 'Innovations'), ('Innovations', ':'), (':', 'Open'), ('Open', 'Solutions'), ('Solutions', 'Access'), ('Access', 'IEEE'), ('IEEE', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '31', ']'), ('31', ']', 'Xue-Wen'), (']', 'Xue-Wen', 'Chen'), ('Xue-Wen', 'Chen', 'Xiaotong'), ('Chen', 'Xiaotong', 'Lin'), ('Xiaotong', 'Lin', ','), ('Lin', ',', ''), (',', '', 'Big'), ('', 'Big', 'Data'), ('Big', 'Data', 'Deep'), ('Data', 'Deep', 'Learning'), ('Deep', 'Learning', ':'), ('Learning', ':', 'Challenges'), (':', 'Challenges', 'Perspectives'), ('Challenges', 'Perspectives', ''), ('Perspectives', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Access'), ('IEEE', 'Access', 'Practical'), ('Access', 'Practical', 'Innovations'), ('Practical', 'Innovations', ':'), ('Innovations', ':', 'Open'), (':', 'Open', 'Solutions'), ('Open', 'Solutions', 'Access'), ('Solutions', 'Access', 'IEEE'), ('Access', 'IEEE', ','), ('IEEE', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('31', 'CD'), (']', 'JJ'), ('Xue-Wen', 'JJ'), ('Chen', 'NNP'), ('Xiaotong', 'NNP'), ('Lin', 'NNP'), (',', ','), ('', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('Challenges', 'VBZ'), ('Perspectives', 'NNS'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Access', 'NNP'), ('Practical', 'NNP'), ('Innovations', 'NNS'), (':', ':'), ('Open', 'JJ'), ('Solutions', 'NNP'), ('Access', 'NNP'), ('IEEE', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  31/CD
  (NP ]/JJ Xue-Wen/JJ Chen/NNP Xiaotong/NNP Lin/NNP)
  ,/,
  (NP /NNP Big/NNP Data/NNP Deep/NNP Learning/NNP)
  :/:
  Challenges/VBZ
  (NP Perspectives/NNS /NNP)
  ,/,
  (NP IEEE/NNP Access/NNP Practical/NNP Innovations/NNS)
  :/:
  (NP Open/JJ Solutions/NNP Access/NNP IEEE/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Xue-Wen Chen Xiaotong Lin', ' Big Data Deep Learning', 'Perspectives ', 'IEEE Access Practical Innovations', 'Open Solutions Access IEEE', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Chen Xiaotong Lin'), ('ORGANIZATION', 'IEEE Access'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'xue-wen'), ('Chen', 'chen'), ('Xiaotong', 'xiaotong'), ('Lin', 'lin'), (',', ','), ('', ''), ('Big', 'big'), ('Data', 'data'), ('Deep', 'deep'), ('Learning', 'learn'), (':', ':'), ('Challenges', 'challeng'), ('Perspectives', 'perspect'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Access', 'access'), ('Practical', 'practic'), ('Innovations', 'innov'), (':', ':'), ('Open', 'open'), ('Solutions', 'solut'), ('Access', 'access'), ('IEEE', 'ieee'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'xue-wen'), ('Chen', 'chen'), ('Xiaotong', 'xiaotong'), ('Lin', 'lin'), (',', ','), ('', ''), ('Big', 'big'), ('Data', 'data'), ('Deep', 'deep'), ('Learning', 'learn'), (':', ':'), ('Challenges', 'challeng'), ('Perspectives', 'perspect'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Access', 'access'), ('Practical', 'practic'), ('Innovations', 'innov'), (':', ':'), ('Open', 'open'), ('Solutions', 'solut'), ('Access', 'access'), ('IEEE', 'ieee'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'Xue-Wen'), ('Chen', 'Chen'), ('Xiaotong', 'Xiaotong'), ('Lin', 'Lin'), (',', ','), ('', ''), ('Big', 'Big'), ('Data', 'Data'), ('Deep', 'Deep'), ('Learning', 'Learning'), (':', ':'), ('Challenges', 'Challenges'), ('Perspectives', 'Perspectives'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Access', 'Access'), ('Practical', 'Practical'), ('Innovations', 'Innovations'), (':', ':'), ('Open', 'Open'), ('Solutions', 'Solutions'), ('Access', 'Access'), ('IEEE', 'IEEE'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 296 =============================

2, pp. 


>> Tokens are: 
 ['2', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 2/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 297 =============================

514-525, 2014. 


>> Tokens are: 
 ['514-525', ',', '2014', '.']

>> Bigrams are: 
 [('514-525', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('514-525', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('514-525', 'CD'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S 514-525/CD ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 298 =============================

[32] Rajat Raina, Anand Madhavan and Andrew Yg, Large- scale Deep Unsupervised Learning using Graphics   Processors, 26 th  International Conference on Machine   Learning, pp. 


>> Tokens are: 
 ['[', '32', ']', 'Rajat', 'Raina', ',', 'Anand', 'Madhavan', 'Andrew', 'Yg', ',', '', 'Large-', 'scale', 'Deep', 'Unsupervised', 'Learning', 'using', 'Graphics', 'Processors', '', ',', '26', 'th', 'International', 'Conference', 'Machine', 'Learning', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '32'), ('32', ']'), (']', 'Rajat'), ('Rajat', 'Raina'), ('Raina', ','), (',', 'Anand'), ('Anand', 'Madhavan'), ('Madhavan', 'Andrew'), ('Andrew', 'Yg'), ('Yg', ','), (',', ''), ('', 'Large-'), ('Large-', 'scale'), ('scale', 'Deep'), ('Deep', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', 'using'), ('using', 'Graphics'), ('Graphics', 'Processors'), ('Processors', ''), ('', ','), (',', '26'), ('26', 'th'), ('th', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '32', ']'), ('32', ']', 'Rajat'), (']', 'Rajat', 'Raina'), ('Rajat', 'Raina', ','), ('Raina', ',', 'Anand'), (',', 'Anand', 'Madhavan'), ('Anand', 'Madhavan', 'Andrew'), ('Madhavan', 'Andrew', 'Yg'), ('Andrew', 'Yg', ','), ('Yg', ',', ''), (',', '', 'Large-'), ('', 'Large-', 'scale'), ('Large-', 'scale', 'Deep'), ('scale', 'Deep', 'Unsupervised'), ('Deep', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', 'using'), ('Learning', 'using', 'Graphics'), ('using', 'Graphics', 'Processors'), ('Graphics', 'Processors', ''), ('Processors', '', ','), ('', ',', '26'), (',', '26', 'th'), ('26', 'th', 'International'), ('th', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('32', 'CD'), (']', 'JJ'), ('Rajat', 'NNP'), ('Raina', 'NNP'), (',', ','), ('Anand', 'NNP'), ('Madhavan', 'NNP'), ('Andrew', 'NNP'), ('Yg', 'NNP'), (',', ','), ('', 'NNP'), ('Large-', 'NNP'), ('scale', 'NN'), ('Deep', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('using', 'VBG'), ('Graphics', 'NNP'), ('Processors', 'NNPS'), ('', 'NNP'), (',', ','), ('26', 'CD'), ('th', 'JJ'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  32/CD
  (NP ]/JJ Rajat/NNP Raina/NNP)
  ,/,
  (NP Anand/NNP Madhavan/NNP Andrew/NNP Yg/NNP)
  ,/,
  (NP /NNP Large-/NNP scale/NN Deep/NNP)
  Unsupervised/VBD
  (NP Learning/NNP)
  using/VBG
  (NP Graphics/NNP)
  Processors/NNPS
  (NP /NNP)
  ,/,
  26/CD
  (NP
    th/JJ
    International/NNP
    Conference/NNP
    Machine/NNP
    Learning/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] Rajat Raina', 'Anand Madhavan Andrew Yg', ' Large- scale Deep', 'Learning', 'Graphics', '', 'th International Conference Machine Learning', 'pp']

>> Named Entities are: 
 [('PERSON', 'Rajat Raina'), ('PERSON', 'Anand Madhavan'), ('PERSON', 'Andrew Yg'), ('PERSON', 'Deep'), ('ORGANIZATION', 'Graphics Processors'), ('ORGANIZATION', 'International Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'rajat'), ('Raina', 'raina'), (',', ','), ('Anand', 'anand'), ('Madhavan', 'madhavan'), ('Andrew', 'andrew'), ('Yg', 'yg'), (',', ','), ('', ''), ('Large-', 'large-'), ('scale', 'scale'), ('Deep', 'deep'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('using', 'use'), ('Graphics', 'graphic'), ('Processors', 'processor'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'rajat'), ('Raina', 'raina'), (',', ','), ('Anand', 'anand'), ('Madhavan', 'madhavan'), ('Andrew', 'andrew'), ('Yg', 'yg'), (',', ','), ('', ''), ('Large-', 'large-'), ('scale', 'scale'), ('Deep', 'deep'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('using', 'use'), ('Graphics', 'graphic'), ('Processors', 'processor'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'Rajat'), ('Raina', 'Raina'), (',', ','), ('Anand', 'Anand'), ('Madhavan', 'Madhavan'), ('Andrew', 'Andrew'), ('Yg', 'Yg'), (',', ','), ('', ''), ('Large-', 'Large-'), ('scale', 'scale'), ('Deep', 'Deep'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('using', 'using'), ('Graphics', 'Graphics'), ('Processors', 'Processors'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 299 =============================

609-616, 2009. 


>> Tokens are: 
 ['609-616', ',', '2009', '.']

>> Bigrams are: 
 [('609-616', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('609-616', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('609-616', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

 (S 609-616/CD ,/, 2009/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]



============================ Sentence 300 =============================

[33] Alex Krizhevsky, Ilya Sutskever and Geoffrey E. Hinton,  ImageNet Classification with Deep Convolutional Neural   Networks, Advances in Neural Information Processing   System, pp. 


>> Tokens are: 
 ['[', '33', ']', 'Alex', 'Krizhevsky', ',', 'Ilya', 'Sutskever', 'Geoffrey', 'E.', 'Hinton', ',', '', 'ImageNet', 'Classification', 'Deep', 'Convolutional', 'Neural', 'Networks', '', ',', 'Advances', 'Neural', 'Information', 'Processing', 'System', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '33'), ('33', ']'), (']', 'Alex'), ('Alex', 'Krizhevsky'), ('Krizhevsky', ','), (',', 'Ilya'), ('Ilya', 'Sutskever'), ('Sutskever', 'Geoffrey'), ('Geoffrey', 'E.'), ('E.', 'Hinton'), ('Hinton', ','), (',', ''), ('', 'ImageNet'), ('ImageNet', 'Classification'), ('Classification', 'Deep'), ('Deep', 'Convolutional'), ('Convolutional', 'Neural'), ('Neural', 'Networks'), ('Networks', ''), ('', ','), (',', 'Advances'), ('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'System'), ('System', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '33', ']'), ('33', ']', 'Alex'), (']', 'Alex', 'Krizhevsky'), ('Alex', 'Krizhevsky', ','), ('Krizhevsky', ',', 'Ilya'), (',', 'Ilya', 'Sutskever'), ('Ilya', 'Sutskever', 'Geoffrey'), ('Sutskever', 'Geoffrey', 'E.'), ('Geoffrey', 'E.', 'Hinton'), ('E.', 'Hinton', ','), ('Hinton', ',', ''), (',', '', 'ImageNet'), ('', 'ImageNet', 'Classification'), ('ImageNet', 'Classification', 'Deep'), ('Classification', 'Deep', 'Convolutional'), ('Deep', 'Convolutional', 'Neural'), ('Convolutional', 'Neural', 'Networks'), ('Neural', 'Networks', ''), ('Networks', '', ','), ('', ',', 'Advances'), (',', 'Advances', 'Neural'), ('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'System'), ('Processing', 'System', ','), ('System', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('33', 'CD'), (']', 'JJ'), ('Alex', 'NNP'), ('Krizhevsky', 'NNP'), (',', ','), ('Ilya', 'NNP'), ('Sutskever', 'NNP'), ('Geoffrey', 'NNP'), ('E.', 'NNP'), ('Hinton', 'NNP'), (',', ','), ('', 'NNP'), ('ImageNet', 'NNP'), ('Classification', 'NNP'), ('Deep', 'NNP'), ('Convolutional', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('', 'NNP'), (',', ','), ('Advances', 'NNP'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('System', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  33/CD
  (NP ]/JJ Alex/NNP Krizhevsky/NNP)
  ,/,
  (NP Ilya/NNP Sutskever/NNP Geoffrey/NNP E./NNP Hinton/NNP)
  ,/,
  (NP
    /NNP
    ImageNet/NNP
    Classification/NNP
    Deep/NNP
    Convolutional/NNP
    Neural/NNP
    Networks/NNP
    /NNP)
  ,/,
  (NP
    Advances/NNP
    Neural/NNP
    Information/NNP
    Processing/NNP
    System/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] Alex Krizhevsky', 'Ilya Sutskever Geoffrey E. Hinton', ' ImageNet Classification Deep Convolutional Neural Networks ', 'Advances Neural Information Processing System', 'pp']

>> Named Entities are: 
 [('PERSON', 'Alex Krizhevsky'), ('PERSON', 'Ilya Sutskever Geoffrey'), ('PERSON', 'Hinton'), ('PERSON', 'Networks'), ('PERSON', 'Advances Neural')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'alex'), ('Krizhevsky', 'krizhevski'), (',', ','), ('Ilya', 'ilya'), ('Sutskever', 'sutskev'), ('Geoffrey', 'geoffrey'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('', ''), ('ImageNet', 'imagenet'), ('Classification', 'classif'), ('Deep', 'deep'), ('Convolutional', 'convolut'), ('Neural', 'neural'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'alex'), ('Krizhevsky', 'krizhevski'), (',', ','), ('Ilya', 'ilya'), ('Sutskever', 'sutskev'), ('Geoffrey', 'geoffrey'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('', ''), ('ImageNet', 'imagenet'), ('Classification', 'classif'), ('Deep', 'deep'), ('Convolutional', 'convolut'), ('Neural', 'neural'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'Alex'), ('Krizhevsky', 'Krizhevsky'), (',', ','), ('Ilya', 'Ilya'), ('Sutskever', 'Sutskever'), ('Geoffrey', 'Geoffrey'), ('E.', 'E.'), ('Hinton', 'Hinton'), (',', ','), ('', ''), ('ImageNet', 'ImageNet'), ('Classification', 'Classification'), ('Deep', 'Deep'), ('Convolutional', 'Convolutional'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('', ''), (',', ','), ('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('System', 'System'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 301 =============================

1106-1114, 2012. 


>> Tokens are: 
 ['1106-1114', ',', '2012', '.']

>> Bigrams are: 
 [('1106-1114', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('1106-1114', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('1106-1114', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S 1106-1114/CD ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 302 =============================

[34] Jeffrey Dean, Greg S. Corrado and Rajat Monga Kai, Large  Scale Distributed Deep Networks, Advances in Neural   Information Processing System, pp. 


>> Tokens are: 
 ['[', '34', ']', 'Jeffrey', 'Dean', ',', 'Greg', 'S.', 'Corrado', 'Rajat', 'Monga', 'Kai', ',', '', 'Large', 'Scale', 'Distributed', 'Deep', 'Networks', '', ',', 'Advances', 'Neural', 'Information', 'Processing', 'System', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '34'), ('34', ']'), (']', 'Jeffrey'), ('Jeffrey', 'Dean'), ('Dean', ','), (',', 'Greg'), ('Greg', 'S.'), ('S.', 'Corrado'), ('Corrado', 'Rajat'), ('Rajat', 'Monga'), ('Monga', 'Kai'), ('Kai', ','), (',', ''), ('', 'Large'), ('Large', 'Scale'), ('Scale', 'Distributed'), ('Distributed', 'Deep'), ('Deep', 'Networks'), ('Networks', ''), ('', ','), (',', 'Advances'), ('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'System'), ('System', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '34', ']'), ('34', ']', 'Jeffrey'), (']', 'Jeffrey', 'Dean'), ('Jeffrey', 'Dean', ','), ('Dean', ',', 'Greg'), (',', 'Greg', 'S.'), ('Greg', 'S.', 'Corrado'), ('S.', 'Corrado', 'Rajat'), ('Corrado', 'Rajat', 'Monga'), ('Rajat', 'Monga', 'Kai'), ('Monga', 'Kai', ','), ('Kai', ',', ''), (',', '', 'Large'), ('', 'Large', 'Scale'), ('Large', 'Scale', 'Distributed'), ('Scale', 'Distributed', 'Deep'), ('Distributed', 'Deep', 'Networks'), ('Deep', 'Networks', ''), ('Networks', '', ','), ('', ',', 'Advances'), (',', 'Advances', 'Neural'), ('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'System'), ('Processing', 'System', ','), ('System', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('34', 'CD'), (']', 'JJ'), ('Jeffrey', 'NNP'), ('Dean', 'NNP'), (',', ','), ('Greg', 'NNP'), ('S.', 'NNP'), ('Corrado', 'NNP'), ('Rajat', 'NNP'), ('Monga', 'NNP'), ('Kai', 'NNP'), (',', ','), ('', 'NNP'), ('Large', 'NNP'), ('Scale', 'NNP'), ('Distributed', 'NNP'), ('Deep', 'NNP'), ('Networks', 'NNP'), ('', 'NNP'), (',', ','), ('Advances', 'NNP'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('System', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  34/CD
  (NP ]/JJ Jeffrey/NNP Dean/NNP)
  ,/,
  (NP Greg/NNP S./NNP Corrado/NNP Rajat/NNP Monga/NNP Kai/NNP)
  ,/,
  (NP
    /NNP
    Large/NNP
    Scale/NNP
    Distributed/NNP
    Deep/NNP
    Networks/NNP
    /NNP)
  ,/,
  (NP
    Advances/NNP
    Neural/NNP
    Information/NNP
    Processing/NNP
    System/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] Jeffrey Dean', 'Greg S. Corrado Rajat Monga Kai', ' Large Scale Distributed Deep Networks ', 'Advances Neural Information Processing System', 'pp']

>> Named Entities are: 
 [('PERSON', 'Jeffrey Dean'), ('PERSON', 'Greg S. Corrado Rajat Monga Kai'), ('PERSON', 'Large Scale Distributed Deep Networks'), ('PERSON', 'Advances Neural')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), ('Rajat', 'rajat'), ('Monga', 'monga'), ('Kai', 'kai'), (',', ','), ('', ''), ('Large', 'larg'), ('Scale', 'scale'), ('Distributed', 'distribut'), ('Deep', 'deep'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), ('Rajat', 'rajat'), ('Monga', 'monga'), ('Kai', 'kai'), (',', ','), ('', ''), ('Large', 'larg'), ('Scale', 'scale'), ('Distributed', 'distribut'), ('Deep', 'deep'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'Jeffrey'), ('Dean', 'Dean'), (',', ','), ('Greg', 'Greg'), ('S.', 'S.'), ('Corrado', 'Corrado'), ('Rajat', 'Rajat'), ('Monga', 'Monga'), ('Kai', 'Kai'), (',', ','), ('', ''), ('Large', 'Large'), ('Scale', 'Scale'), ('Distributed', 'Distributed'), ('Deep', 'Deep'), ('Networks', 'Networks'), ('', ''), (',', ','), ('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('System', 'System'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 303 =============================

1232-1240, 2012. 


>> Tokens are: 
 ['1232-1240', ',', '2012', '.']

>> Bigrams are: 
 [('1232-1240', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('1232-1240', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('1232-1240', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S 1232-1240/CD ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 304 =============================

[35] Quoc V. Le, MarcAurelio Ranzato, Rajat Monga, Matthieu  Devin, Kai Chen, Greg S. Corrado, Jeffrey  Dean, and   Andrew Y. Ng, Building High-level Features Using Large   Scale Unsupervised Learning, Proceedings of the 29 th    International Conference on Machine Learning, 2012. 


>> Tokens are: 
 ['[', '35', ']', 'Quoc', 'V.', 'Le', ',', 'Marc', '', 'Aurelio', 'Ranzato', ',', 'Rajat', 'Monga', ',', 'Matthieu', 'Devin', ',', 'Kai', 'Chen', ',', 'Greg', 'S.', 'Corrado', ',', 'Jeffrey', 'Dean', ',', 'Andrew', 'Y.', 'Ng', ',', '', 'Building', 'High-level', 'Features', 'Using', 'Large', 'Scale', 'Unsupervised', 'Learning', '', ',', 'Proceedings', '29', 'th', 'International', 'Conference', 'Machine', 'Learning', ',', '2012', '.']

>> Bigrams are: 
 [('[', '35'), ('35', ']'), (']', 'Quoc'), ('Quoc', 'V.'), ('V.', 'Le'), ('Le', ','), (',', 'Marc'), ('Marc', ''), ('', 'Aurelio'), ('Aurelio', 'Ranzato'), ('Ranzato', ','), (',', 'Rajat'), ('Rajat', 'Monga'), ('Monga', ','), (',', 'Matthieu'), ('Matthieu', 'Devin'), ('Devin', ','), (',', 'Kai'), ('Kai', 'Chen'), ('Chen', ','), (',', 'Greg'), ('Greg', 'S.'), ('S.', 'Corrado'), ('Corrado', ','), (',', 'Jeffrey'), ('Jeffrey', 'Dean'), ('Dean', ','), (',', 'Andrew'), ('Andrew', 'Y.'), ('Y.', 'Ng'), ('Ng', ','), (',', ''), ('', 'Building'), ('Building', 'High-level'), ('High-level', 'Features'), ('Features', 'Using'), ('Using', 'Large'), ('Large', 'Scale'), ('Scale', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', ''), ('', ','), (',', 'Proceedings'), ('Proceedings', '29'), ('29', 'th'), ('th', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('[', '35', ']'), ('35', ']', 'Quoc'), (']', 'Quoc', 'V.'), ('Quoc', 'V.', 'Le'), ('V.', 'Le', ','), ('Le', ',', 'Marc'), (',', 'Marc', ''), ('Marc', '', 'Aurelio'), ('', 'Aurelio', 'Ranzato'), ('Aurelio', 'Ranzato', ','), ('Ranzato', ',', 'Rajat'), (',', 'Rajat', 'Monga'), ('Rajat', 'Monga', ','), ('Monga', ',', 'Matthieu'), (',', 'Matthieu', 'Devin'), ('Matthieu', 'Devin', ','), ('Devin', ',', 'Kai'), (',', 'Kai', 'Chen'), ('Kai', 'Chen', ','), ('Chen', ',', 'Greg'), (',', 'Greg', 'S.'), ('Greg', 'S.', 'Corrado'), ('S.', 'Corrado', ','), ('Corrado', ',', 'Jeffrey'), (',', 'Jeffrey', 'Dean'), ('Jeffrey', 'Dean', ','), ('Dean', ',', 'Andrew'), (',', 'Andrew', 'Y.'), ('Andrew', 'Y.', 'Ng'), ('Y.', 'Ng', ','), ('Ng', ',', ''), (',', '', 'Building'), ('', 'Building', 'High-level'), ('Building', 'High-level', 'Features'), ('High-level', 'Features', 'Using'), ('Features', 'Using', 'Large'), ('Using', 'Large', 'Scale'), ('Large', 'Scale', 'Unsupervised'), ('Scale', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Proceedings'), (',', 'Proceedings', '29'), ('Proceedings', '29', 'th'), ('29', 'th', 'International'), ('th', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('35', 'CD'), (']', 'JJ'), ('Quoc', 'NNP'), ('V.', 'NNP'), ('Le', 'NNP'), (',', ','), ('Marc', 'NNP'), ('', 'NNP'), ('Aurelio', 'NNP'), ('Ranzato', 'NNP'), (',', ','), ('Rajat', 'NNP'), ('Monga', 'NNP'), (',', ','), ('Matthieu', 'NNP'), ('Devin', 'NNP'), (',', ','), ('Kai', 'NNP'), ('Chen', 'NNP'), (',', ','), ('Greg', 'NNP'), ('S.', 'NNP'), ('Corrado', 'NNP'), (',', ','), ('Jeffrey', 'NNP'), ('Dean', 'NNP'), (',', ','), ('Andrew', 'NNP'), ('Y.', 'NNP'), ('Ng', 'NNP'), (',', ','), ('', 'NNP'), ('Building', 'NNP'), ('High-level', 'NNP'), ('Features', 'NNP'), ('Using', 'NNP'), ('Large', 'NNP'), ('Scale', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Proceedings', 'NNP'), ('29', 'CD'), ('th', 'IN'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S
  [/RB
  35/CD
  (NP ]/JJ Quoc/NNP V./NNP Le/NNP)
  ,/,
  (NP Marc/NNP /NNP Aurelio/NNP Ranzato/NNP)
  ,/,
  (NP Rajat/NNP Monga/NNP)
  ,/,
  (NP Matthieu/NNP Devin/NNP)
  ,/,
  (NP Kai/NNP Chen/NNP)
  ,/,
  (NP Greg/NNP S./NNP Corrado/NNP)
  ,/,
  (NP Jeffrey/NNP Dean/NNP)
  ,/,
  (NP Andrew/NNP Y./NNP Ng/NNP)
  ,/,
  (NP
    /NNP
    Building/NNP
    High-level/NNP
    Features/NNP
    Using/NNP
    Large/NNP
    Scale/NNP)
  Unsupervised/VBD
  (NP Learning/NNP /NNP)
  ,/,
  (NP Proceedings/NNP)
  29/CD
  th/IN
  (NP International/NNP Conference/NNP Machine/NNP Learning/NNP)
  ,/,
  2012/CD
  ./.) 


>> Noun Phrases are: 
 ['] Quoc V. Le', 'Marc  Aurelio Ranzato', 'Rajat Monga', 'Matthieu Devin', 'Kai Chen', 'Greg S. Corrado', 'Jeffrey Dean', 'Andrew Y. Ng', ' Building High-level Features Using Large Scale', 'Learning ', 'Proceedings', 'International Conference Machine Learning']

>> Named Entities are: 
 [('PERSON', 'Quoc V. Le'), ('PERSON', 'Marc'), ('PERSON', 'Aurelio Ranzato'), ('PERSON', 'Rajat Monga'), ('PERSON', 'Matthieu Devin'), ('PERSON', 'Kai Chen'), ('PERSON', 'Greg S. Corrado'), ('PERSON', 'Jeffrey Dean'), ('PERSON', 'Andrew Y. Ng'), ('PERSON', 'Features Using Large Scale'), ('ORGANIZATION', 'International Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'quoc'), ('V.', 'v.'), ('Le', 'le'), (',', ','), ('Marc', 'marc'), ('', ''), ('Aurelio', 'aurelio'), ('Ranzato', 'ranzato'), (',', ','), ('Rajat', 'rajat'), ('Monga', 'monga'), (',', ','), ('Matthieu', 'matthieu'), ('Devin', 'devin'), (',', ','), ('Kai', 'kai'), ('Chen', 'chen'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), (',', ','), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Andrew', 'andrew'), ('Y.', 'y.'), ('Ng', 'ng'), (',', ','), ('', ''), ('Building', 'build'), ('High-level', 'high-level'), ('Features', 'featur'), ('Using', 'use'), ('Large', 'larg'), ('Scale', 'scale'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('', ''), (',', ','), ('Proceedings', 'proceed'), ('29', '29'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'quoc'), ('V.', 'v.'), ('Le', 'le'), (',', ','), ('Marc', 'marc'), ('', ''), ('Aurelio', 'aurelio'), ('Ranzato', 'ranzato'), (',', ','), ('Rajat', 'rajat'), ('Monga', 'monga'), (',', ','), ('Matthieu', 'matthieu'), ('Devin', 'devin'), (',', ','), ('Kai', 'kai'), ('Chen', 'chen'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), (',', ','), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Andrew', 'andrew'), ('Y.', 'y.'), ('Ng', 'ng'), (',', ','), ('', ''), ('Building', 'build'), ('High-level', 'high-level'), ('Features', 'featur'), ('Using', 'use'), ('Large', 'larg'), ('Scale', 'scale'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('', ''), (',', ','), ('Proceedings', 'proceed'), ('29', '29'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'Quoc'), ('V.', 'V.'), ('Le', 'Le'), (',', ','), ('Marc', 'Marc'), ('', ''), ('Aurelio', 'Aurelio'), ('Ranzato', 'Ranzato'), (',', ','), ('Rajat', 'Rajat'), ('Monga', 'Monga'), (',', ','), ('Matthieu', 'Matthieu'), ('Devin', 'Devin'), (',', ','), ('Kai', 'Kai'), ('Chen', 'Chen'), (',', ','), ('Greg', 'Greg'), ('S.', 'S.'), ('Corrado', 'Corrado'), (',', ','), ('Jeffrey', 'Jeffrey'), ('Dean', 'Dean'), (',', ','), ('Andrew', 'Andrew'), ('Y.', 'Y.'), ('Ng', 'Ng'), (',', ','), ('', ''), ('Building', 'Building'), ('High-level', 'High-level'), ('Features', 'Features'), ('Using', 'Using'), ('Large', 'Large'), ('Scale', 'Scale'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Proceedings', 'Proceedings'), ('29', '29'), ('th', 'th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 305 =============================

[36] A. Coats and B. Huval, Deep Learning with COTS HPS  systems, Journal of Machine Learning Research, Vol. 


>> Tokens are: 
 ['[', '36', ']', 'A.', 'Coats', 'B.', 'Huval', ',', '', 'Deep', 'Learning', 'COTS', 'HPS', 'systems', '', ',', 'Journal', 'Machine', 'Learning', 'Research', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '36'), ('36', ']'), (']', 'A.'), ('A.', 'Coats'), ('Coats', 'B.'), ('B.', 'Huval'), ('Huval', ','), (',', ''), ('', 'Deep'), ('Deep', 'Learning'), ('Learning', 'COTS'), ('COTS', 'HPS'), ('HPS', 'systems'), ('systems', ''), ('', ','), (',', 'Journal'), ('Journal', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Research'), ('Research', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '36', ']'), ('36', ']', 'A.'), (']', 'A.', 'Coats'), ('A.', 'Coats', 'B.'), ('Coats', 'B.', 'Huval'), ('B.', 'Huval', ','), ('Huval', ',', ''), (',', '', 'Deep'), ('', 'Deep', 'Learning'), ('Deep', 'Learning', 'COTS'), ('Learning', 'COTS', 'HPS'), ('COTS', 'HPS', 'systems'), ('HPS', 'systems', ''), ('systems', '', ','), ('', ',', 'Journal'), (',', 'Journal', 'Machine'), ('Journal', 'Machine', 'Learning'), ('Machine', 'Learning', 'Research'), ('Learning', 'Research', ','), ('Research', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('36', 'CD'), (']', 'JJ'), ('A.', 'NN'), ('Coats', 'NNP'), ('B.', 'NNP'), ('Huval', 'NNP'), (',', ','), ('', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('COTS', 'NNP'), ('HPS', 'NNP'), ('systems', 'NNS'), ('', 'NNP'), (',', ','), ('Journal', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Research', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

 (S
  [/RB
  36/CD
  (NP ]/JJ A./NN Coats/NNP B./NNP Huval/NNP)
  ,/,
  (NP /NNP Deep/NNP Learning/NNP COTS/NNP HPS/NNP systems/NNS /NNP)
  ,/,
  (NP Journal/NNP Machine/NNP Learning/NNP Research/NNP)
  ,/,
  (NP Vol/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] A. Coats B. Huval', ' Deep Learning COTS HPS systems ', 'Journal Machine Learning Research', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Coats B. Huval'), ('PERSON', 'Journal Machine Learning Research'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'a.'), ('Coats', 'coat'), ('B.', 'b.'), ('Huval', 'huval'), (',', ','), ('', ''), ('Deep', 'deep'), ('Learning', 'learn'), ('COTS', 'cot'), ('HPS', 'hp'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'journal'), ('Machine', 'machin'), ('Learning', 'learn'), ('Research', 'research'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'a.'), ('Coats', 'coat'), ('B.', 'b.'), ('Huval', 'huval'), (',', ','), ('', ''), ('Deep', 'deep'), ('Learning', 'learn'), ('COTS', 'cot'), ('HPS', 'hps'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'journal'), ('Machine', 'machin'), ('Learning', 'learn'), ('Research', 'research'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'A.'), ('Coats', 'Coats'), ('B.', 'B.'), ('Huval', 'Huval'), (',', ','), ('', ''), ('Deep', 'Deep'), ('Learning', 'Learning'), ('COTS', 'COTS'), ('HPS', 'HPS'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'Journal'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Research', 'Research'), (',', ','), ('Vol', 'Vol'), ('.', '.')]



============================ Sentence 306 =============================

28,   No. 


>> Tokens are: 
 ['28', ',', 'No', '.']

>> Bigrams are: 
 [('28', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('28', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('28', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

 (S 28/CD ,/, No/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('28', '28'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('28', '28'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('28', '28'), (',', ','), ('No', 'No'), ('.', '.')]



============================ Sentence 307 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 308 =============================

1337-1345, 2013.      http://webdocs.cs.ualberta.ca/~sutton/index.html http://www-anw.cs.umass.edu/~barto/ http://link.springer.com/search?facet-author=%22Aijun+An%22 http://link.springer.com/search?facet-author=%22Nick+Cercone%22 http://en.wikipedia.org/wiki/Mehryar_Mohri http://www.sciencedirect.com/science/journal/03064379 http://www.sciencedirect.com/science/journal/03064379 http://www.sciencedirect.com/science/journal/03064379 http://www.sciencedirect.com/science/journal/03064379/38/6 


>> Tokens are: 
 ['1337-1345', ',', '2013.', 'http', ':', '//webdocs.cs.ualberta.ca/~sutton/index.html', 'http', ':', '//www-anw.cs.umass.edu/~barto/', 'http', ':', '//link.springer.com/search', '?', 'facet-author=', '%', '22Aijun+An', '%', '22', 'http', ':', '//link.springer.com/search', '?', 'facet-author=', '%', '22Nick+Cercone', '%', '22', 'http', ':', '//en.wikipedia.org/wiki/Mehryar_Mohri', 'http', ':', '//www.sciencedirect.com/science/journal/03064379', 'http', ':', '//www.sciencedirect.com/science/journal/03064379', 'http', ':', '//www.sciencedirect.com/science/journal/03064379', 'http', ':', '//www.sciencedirect.com/science/journal/03064379/38/6']

>> Bigrams are: 
 [('1337-1345', ','), (',', '2013.'), ('2013.', 'http'), ('http', ':'), (':', '//webdocs.cs.ualberta.ca/~sutton/index.html'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', 'http'), ('http', ':'), (':', '//www-anw.cs.umass.edu/~barto/'), ('//www-anw.cs.umass.edu/~barto/', 'http'), ('http', ':'), (':', '//link.springer.com/search'), ('//link.springer.com/search', '?'), ('?', 'facet-author='), ('facet-author=', '%'), ('%', '22Aijun+An'), ('22Aijun+An', '%'), ('%', '22'), ('22', 'http'), ('http', ':'), (':', '//link.springer.com/search'), ('//link.springer.com/search', '?'), ('?', 'facet-author='), ('facet-author=', '%'), ('%', '22Nick+Cercone'), ('22Nick+Cercone', '%'), ('%', '22'), ('22', 'http'), ('http', ':'), (':', '//en.wikipedia.org/wiki/Mehryar_Mohri'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', 'http'), ('http', ':'), (':', '//www.sciencedirect.com/science/journal/03064379'), ('//www.sciencedirect.com/science/journal/03064379', 'http'), ('http', ':'), (':', '//www.sciencedirect.com/science/journal/03064379'), ('//www.sciencedirect.com/science/journal/03064379', 'http'), ('http', ':'), (':', '//www.sciencedirect.com/science/journal/03064379'), ('//www.sciencedirect.com/science/journal/03064379', 'http'), ('http', ':'), (':', '//www.sciencedirect.com/science/journal/03064379/38/6')]

>> Trigrams are: 
 [('1337-1345', ',', '2013.'), (',', '2013.', 'http'), ('2013.', 'http', ':'), ('http', ':', '//webdocs.cs.ualberta.ca/~sutton/index.html'), (':', '//webdocs.cs.ualberta.ca/~sutton/index.html', 'http'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', 'http', ':'), ('http', ':', '//www-anw.cs.umass.edu/~barto/'), (':', '//www-anw.cs.umass.edu/~barto/', 'http'), ('//www-anw.cs.umass.edu/~barto/', 'http', ':'), ('http', ':', '//link.springer.com/search'), (':', '//link.springer.com/search', '?'), ('//link.springer.com/search', '?', 'facet-author='), ('?', 'facet-author=', '%'), ('facet-author=', '%', '22Aijun+An'), ('%', '22Aijun+An', '%'), ('22Aijun+An', '%', '22'), ('%', '22', 'http'), ('22', 'http', ':'), ('http', ':', '//link.springer.com/search'), (':', '//link.springer.com/search', '?'), ('//link.springer.com/search', '?', 'facet-author='), ('?', 'facet-author=', '%'), ('facet-author=', '%', '22Nick+Cercone'), ('%', '22Nick+Cercone', '%'), ('22Nick+Cercone', '%', '22'), ('%', '22', 'http'), ('22', 'http', ':'), ('http', ':', '//en.wikipedia.org/wiki/Mehryar_Mohri'), (':', '//en.wikipedia.org/wiki/Mehryar_Mohri', 'http'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', 'http', ':'), ('http', ':', '//www.sciencedirect.com/science/journal/03064379'), (':', '//www.sciencedirect.com/science/journal/03064379', 'http'), ('//www.sciencedirect.com/science/journal/03064379', 'http', ':'), ('http', ':', '//www.sciencedirect.com/science/journal/03064379'), (':', '//www.sciencedirect.com/science/journal/03064379', 'http'), ('//www.sciencedirect.com/science/journal/03064379', 'http', ':'), ('http', ':', '//www.sciencedirect.com/science/journal/03064379'), (':', '//www.sciencedirect.com/science/journal/03064379', 'http'), ('//www.sciencedirect.com/science/journal/03064379', 'http', ':'), ('http', ':', '//www.sciencedirect.com/science/journal/03064379/38/6')]

>> POS Tags are: 
 [('1337-1345', 'JJ'), (',', ','), ('2013.', 'CD'), ('http', 'NN'), (':', ':'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', 'JJ'), ('http', 'NN'), (':', ':'), ('//www-anw.cs.umass.edu/~barto/', 'JJ'), ('http', 'NN'), (':', ':'), ('//link.springer.com/search', 'NN'), ('?', '.'), ('facet-author=', 'JJ'), ('%', 'NN'), ('22Aijun+An', 'CD'), ('%', 'NN'), ('22', 'CD'), ('http', 'NN'), (':', ':'), ('//link.springer.com/search', 'NN'), ('?', '.'), ('facet-author=', 'JJ'), ('%', 'NN'), ('22Nick+Cercone', 'CD'), ('%', 'NN'), ('22', 'CD'), ('http', 'NN'), (':', ':'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', 'JJ'), ('http', 'NN'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', 'JJ'), ('http', 'NN'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', 'JJ'), ('http', 'NN'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', 'JJ'), ('http', 'NN'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379/38/6', 'NN')]

 (S
  1337-1345/JJ
  ,/,
  2013./CD
  (NP http/NN)
  :/:
  (NP //webdocs.cs.ualberta.ca/~sutton/index.html/JJ http/NN)
  :/:
  (NP //www-anw.cs.umass.edu/~barto//JJ http/NN)
  :/:
  (NP //link.springer.com/search/NN)
  ?/.
  (NP facet-author=/JJ %/NN)
  22Aijun+An/CD
  (NP %/NN)
  22/CD
  (NP http/NN)
  :/:
  (NP //link.springer.com/search/NN)
  ?/.
  (NP facet-author=/JJ %/NN)
  22Nick+Cercone/CD
  (NP %/NN)
  22/CD
  (NP http/NN)
  :/:
  (NP //en.wikipedia.org/wiki/Mehryar_Mohri/JJ http/NN)
  :/:
  (NP //www.sciencedirect.com/science/journal/03064379/JJ http/NN)
  :/:
  (NP //www.sciencedirect.com/science/journal/03064379/JJ http/NN)
  :/:
  (NP //www.sciencedirect.com/science/journal/03064379/JJ http/NN)
  :/:
  (NP //www.sciencedirect.com/science/journal/03064379/38/6/NN)) 


>> Noun Phrases are: 
 ['http', '//webdocs.cs.ualberta.ca/~sutton/index.html http', '//www-anw.cs.umass.edu/~barto/ http', '//link.springer.com/search', 'facet-author= %', '%', 'http', '//link.springer.com/search', 'facet-author= %', '%', 'http', '//en.wikipedia.org/wiki/Mehryar_Mohri http', '//www.sciencedirect.com/science/journal/03064379 http', '//www.sciencedirect.com/science/journal/03064379 http', '//www.sciencedirect.com/science/journal/03064379 http', '//www.sciencedirect.com/science/journal/03064379/38/6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013.', '2013.'), ('http', 'http'), (':', ':'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', '//webdocs.cs.ualberta.ca/~sutton/index.html'), ('http', 'http'), (':', ':'), ('//www-anw.cs.umass.edu/~barto/', '//www-anw.cs.umass.edu/~barto/'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Aijun+An', '22aijun+an'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Nick+Cercone', '22nick+cercon'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', '//en.wikipedia.org/wiki/mehryar_mohri'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379/38/6', '//www.sciencedirect.com/science/journal/03064379/38/6')]

>> Stemming using Snowball Stemmer: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013.', '2013.'), ('http', 'http'), (':', ':'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', '//webdocs.cs.ualberta.ca/~sutton/index.html'), ('http', 'http'), (':', ':'), ('//www-anw.cs.umass.edu/~barto/', '//www-anw.cs.umass.edu/~barto/'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Aijun+An', '22aijun+an'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Nick+Cercone', '22nick+cercon'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', '//en.wikipedia.org/wiki/mehryar_mohri'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379/38/6', '//www.sciencedirect.com/science/journal/03064379/38/6')]

>> Lemmatization: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013.', '2013.'), ('http', 'http'), (':', ':'), ('//webdocs.cs.ualberta.ca/~sutton/index.html', '//webdocs.cs.ualberta.ca/~sutton/index.html'), ('http', 'http'), (':', ':'), ('//www-anw.cs.umass.edu/~barto/', '//www-anw.cs.umass.edu/~barto/'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Aijun+An', '22Aijun+An'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//link.springer.com/search', '//link.springer.com/search'), ('?', '?'), ('facet-author=', 'facet-author='), ('%', '%'), ('22Nick+Cercone', '22Nick+Cercone'), ('%', '%'), ('22', '22'), ('http', 'http'), (':', ':'), ('//en.wikipedia.org/wiki/Mehryar_Mohri', '//en.wikipedia.org/wiki/Mehryar_Mohri'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379', '//www.sciencedirect.com/science/journal/03064379'), ('http', 'http'), (':', ':'), ('//www.sciencedirect.com/science/journal/03064379/38/6', '//www.sciencedirect.com/science/journal/03064379/38/6')]

