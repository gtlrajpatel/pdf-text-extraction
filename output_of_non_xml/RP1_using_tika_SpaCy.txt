				 *** Text Processing using Spacy *** 


============================ Sentence 1 =============================

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[]


============================ Sentence 2 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 3 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 4 =============================

P A P E R  sentiment  recall  precision  part of speech  machine learning  data ratio  NLP  syntax tuning  themes  named entity extraction  accuracy  training  AI  Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com   Machine Learning for   Natural Language Processing    and Text Analytics  https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[P, P, E, R,  , sentiment,  , recall,  , precision,  , speech,  , machine, learning,  , data, ratio,  , NLP,  , syntax, tuning,  , themes,  , named, entity, extraction,  , accuracy,  , training,  , AI,  , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA, |, 1, -, 800, -, 377, -, 8036, |, www.lexalytics.com,   , Machine, Learning,   , Natural, Language, Processing,    , Text, Analytics,  , https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('sentiment', 'NOUN'), (' ', 'SPACE'), ('recall', 'VERB'), (' ', 'SPACE'), ('precision', 'NOUN'), (' ', 'SPACE'), ('speech', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'VERB'), (' ', 'SPACE'), ('data', 'NOUN'), ('ratio', 'NOUN'), (' ', 'SPACE'), ('NLP', 'PROPN'), (' ', 'SPACE'), ('syntax', 'NOUN'), ('tuning', 'VERB'), (' ', 'SPACE'), ('themes', 'NOUN'), (' ', 'SPACE'), ('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN'), (' ', 'SPACE'), ('accuracy', 'NOUN'), (' ', 'SPACE'), ('training', 'NOUN'), (' ', 'SPACE'), ('AI', 'PROPN'), (' ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'NOUN'), ('1', 'NUM'), ('-', 'NUM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('www.lexalytics.com', 'X'), ('  ', 'SPACE'), ('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Natural', 'PROPN'), ('Language', 'PROPN'), ('Processing', 'NOUN'), ('   ', 'SPACE'), ('Text', 'PROPN'), ('Analytics', 'PROPN'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'nmod'), (' ', 'compound'), ('sentiment', 'nsubj'), (' ', 'appos'), ('recall', 'ROOT'), (' ', 'dobj'), ('precision', 'compound'), (' ', 'dobj'), ('speech', 'compound'), (' ', 'compound'), ('machine', 'pobj'), ('learning', 'advcl'), (' ', 'dobj'), ('data', 'compound'), ('ratio', 'dobj'), (' ', 'punct'), ('NLP', 'compound'), (' ', 'nsubj'), ('syntax', 'nsubj'), ('tuning', 'advcl'), (' ', 'compound'), ('themes', 'dobj'), (' ', 'punct'), ('named', 'acl'), ('entity', 'compound'), ('extraction', 'dobj'), (' ', 'prep'), ('accuracy', 'compound'), (' ', 'pobj'), ('training', 'advcl'), (' ', 'dobj'), ('AI', 'nmod'), (' ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'dobj'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'npadvmod'), ('01002', 'punct'), ('USA', 'appos'), ('|', 'npadvmod'), ('1', 'nummod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'dobj'), ('www.lexalytics.com', 'punct'), ('  ', 'dobj'), ('Machine', 'compound'), ('Learning', 'dobj'), ('  ', 'pobj'), ('Natural', 'compound'), ('Language', 'compound'), ('Processing', 'appos'), ('   ', 'appos'), ('Text', 'compound'), ('Analytics', 'conj'), (' ', 'compound'), ('https://www.lexalytics.com/', 'dobj'), ('https://www.lexalytics.com/', 'dobj'), ('  ', 'dobj'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , sentiment], [sentiment,  ], [ , recall], [recall,  ], [ , precision], [precision,  ], [ , speech], [speech,  ], [ , machine], [machine, learning], [learning,  ], [ , data], [data, ratio], [ratio,  ], [ , NLP], [NLP,  ], [ , syntax], [syntax, tuning], [tuning,  ], [ , themes], [themes,  ], [ , named], [named, entity], [entity, extraction], [extraction,  ], [ , accuracy], [accuracy,  ], [ , training], [training,  ], [ , AI], [AI,  ], [ , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA, |], [|, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|, www.lexalytics.com], [www.lexalytics.com,   ], [  , Machine], [Machine, Learning], [Learning,   ], [  , Natural], [Natural, Language], [Language, Processing], [Processing,    ], [   , Text], [Text, Analytics], [Analytics,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , sentiment], [ , sentiment,  ], [sentiment,  , recall], [ , recall,  ], [recall,  , precision], [ , precision,  ], [precision,  , speech], [ , speech,  ], [speech,  , machine], [ , machine, learning], [machine, learning,  ], [learning,  , data], [ , data, ratio], [data, ratio,  ], [ratio,  , NLP], [ , NLP,  ], [NLP,  , syntax], [ , syntax, tuning], [syntax, tuning,  ], [tuning,  , themes], [ , themes,  ], [themes,  , named], [ , named, entity], [named, entity, extraction], [entity, extraction,  ], [extraction,  , accuracy], [ , accuracy,  ], [accuracy,  , training], [ , training,  ], [training,  , AI], [ , AI,  ], [AI,  , Lexalytics], [ , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA, |], [USA, |, 1], [|, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |, www.lexalytics.com], [|, www.lexalytics.com,   ], [www.lexalytics.com,   , Machine], [  , Machine, Learning], [Machine, Learning,   ], [Learning,   , Natural], [  , Natural, Language], [Natural, Language, Processing], [Language, Processing,    ], [Processing,    , Text], [   , Text, Analytics], [Text, Analytics,  ], [Analytics,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[P A P E R  sentiment, part, speech  machine, data ratio, syntax,  themes, entity extraction, AI  Lexalytics, Inc., 48 North Pleasant St. Unit, USA, 377-8036 |, Machine Learning, Natural Language Processing, Text Analytics,  https://www.lexalytics.com/, https://www.lexalytics.com/]

>> Named Entities are: 
[('NLP', 'ORG'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA 01002 USA | 1-800-377-8036', 'ORG'), ('Text Analytics', 'PERSON')]


============================ Sentence 5 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 6 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 7 =============================

P A P E R  T A B L E   


>> Tokens are: 
[P, P, E, R,  , T, B, L, E,  ] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('T', 'PROPN'), ('B', 'PROPN'), ('L', 'PROPN'), ('E', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'nmod'), (' ', 'nmod'), ('T', 'compound'), ('B', 'compound'), ('L', 'nmod'), ('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , T], [T, B], [B, L], [L, E], [E,  ]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , T], [ , T, B], [T, B, L], [B, L, E], [L, E,  ]]

>> Noun Phrases are: 
[P A P E R  T A B L E]

>> Named Entities are: 
[]


============================ Sentence 8 =============================

O F  C O N T E N T S   


>> Tokens are: 
[O, F,  , C, O, N, T, E, N, T, S,  ] 

>> PoS Tags are: 
[('O', 'INTJ'), ('F', 'NOUN'), (' ', 'SPACE'), ('C', 'PROPN'), ('O', 'NOUN'), ('N', 'PROPN'), ('T', 'PROPN'), ('E', 'NOUN'), ('N', 'NOUN'), ('T', 'NOUN'), ('S', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('O', 'intj'), ('F', 'compound'), (' ', 'compound'), ('C', 'compound'), ('O', 'nmod'), ('N', 'compound'), ('T', 'compound'), ('E', 'compound'), ('N', 'compound'), ('T', 'compound'), ('S', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[O, F], [F,  ], [ , C], [C, O], [O, N], [N, T], [T, E], [E, N], [N, T], [T, S], [S,  ]]

>> Trigrams: 
[[O, F,  ], [F,  , C], [ , C, O], [C, O, N], [O, N, T], [N, T, E], [T, E, N], [E, N, T], [N, T, S], [T, S,  ]]

>> Noun Phrases are: 
[O F  C O N T E N T S]

>> Named Entities are: 
[]


============================ Sentence 9 =============================

2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[2|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('2|', 'PRON'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('2|', 'compound'), ('      ', 'nmod'), ('|', 'punct'), ('  ', 'prep'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[2|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[2|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 10 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 11 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 12 =============================

Introduction Machine learning is everywhere, from helping us make better toast to  researching drug discovery and designs. 


>> Tokens are: 
[Introduction, Machine, learning, ,, helping, better, toast,  , researching, drug, discovery, designs, .] 

>> PoS Tags are: 
[('Introduction', 'NOUN'), ('Machine', 'PROPN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('helping', 'VERB'), ('better', 'ADJ'), ('toast', 'NOUN'), (' ', 'SPACE'), ('researching', 'VERB'), ('drug', 'NOUN'), ('discovery', 'NOUN'), ('designs', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Introduction', 'compound'), ('Machine', 'compound'), ('learning', 'nsubj'), (',', 'punct'), ('helping', 'pcomp'), ('better', 'amod'), ('toast', 'dobj'), (' ', 'pobj'), ('researching', 'acl'), ('drug', 'compound'), ('discovery', 'dobj'), ('designs', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Introduction, Machine], [Machine, learning], [learning, ,], [,, helping], [helping, better], [better, toast], [toast,  ], [ , researching], [researching, drug], [drug, discovery], [discovery, designs], [designs, .]]

>> Trigrams: 
[[Introduction, Machine, learning], [Machine, learning, ,], [learning, ,, helping], [,, helping, better], [helping, better, toast], [better, toast,  ], [toast,  , researching], [ , researching, drug], [researching, drug, discovery], [drug, discovery, designs], [discovery, designs, .]]

>> Noun Phrases are: 
[Introduction Machine learning, us, better toast, drug discovery, designs]

>> Named Entities are: 
[]


============================ Sentence 13 =============================

Sometimes the term is used  interchangeably with artificial intelligence (AI), but they’re not the same  thing. 


>> Tokens are: 
[term,  , interchangeably, artificial, intelligence, (, AI, ), ,,  , thing, .] 

>> PoS Tags are: 
[('term', 'NOUN'), (' ', 'SPACE'), ('interchangeably', 'ADV'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), ('(', 'PUNCT'), ('AI', 'PROPN'), (')', 'PUNCT'), (',', 'PUNCT'), (' ', 'SPACE'), ('thing', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('term', 'nsubjpass'), (' ', 'dobj'), ('interchangeably', 'advmod'), ('artificial', 'amod'), ('intelligence', 'pobj'), ('(', 'punct'), ('AI', 'appos'), (')', 'punct'), (',', 'punct'), (' ', 'compound'), ('thing', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[term,  ], [ , interchangeably], [interchangeably, artificial], [artificial, intelligence], [intelligence, (], [(, AI], [AI, )], [), ,], [,,  ], [ , thing], [thing, .]]

>> Trigrams: 
[[term,  , interchangeably], [ , interchangeably, artificial], [interchangeably, artificial, intelligence], [artificial, intelligence, (], [intelligence, (, AI], [(, AI, )], [AI, ), ,], [), ,,  ], [,,  , thing], [ , thing, .]]

>> Noun Phrases are: 
[the term, artificial intelligence, (AI, they, the same  thing]

>> Named Entities are: 
[('AI', 'ORG')]


============================ Sentence 14 =============================

While all AI involves machine learning, not all machine learning is AI. 


>> Tokens are: 
[AI, involves, machine, learning, ,, machine, learning, AI, .] 

>> PoS Tags are: 
[('AI', 'PROPN'), ('involves', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('AI', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('AI', 'nsubj'), ('involves', 'advcl'), ('machine', 'compound'), ('learning', 'dobj'), (',', 'punct'), ('machine', 'compound'), ('learning', 'nsubj'), ('AI', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[AI, involves], [involves, machine], [machine, learning], [learning, ,], [,, machine], [machine, learning], [learning, AI], [AI, .]]

>> Trigrams: 
[[AI, involves, machine], [involves, machine, learning], [machine, learning, ,], [learning, ,, machine], [,, machine, learning], [machine, learning, AI], [learning, AI, .]]

>> Noun Phrases are: 
[all AI, machine learning, not all machine learning, AI]

>> Named Entities are: 
[('AI', 'ORG'), ('AI', 'ORG')]


============================ Sentence 15 =============================

  Lexalytics’ core text analytics engine, Salience, can be considered a  “narrow” AI: It uses many different types of machine learning to solve  the task of understanding and analyzing text, but is focused exclusively  on text. 


>> Tokens are: 
[  , Lexalytics, ’, core, text, analytics, engine, ,, Salience, ,, considered,  , “, narrow, ”, AI, :, uses, different, types, machine, learning, solve,  , task, understanding, analyzing, text, ,, focused, exclusively,  , text, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Lexalytics', 'PROPN'), ('’', 'PART'), ('core', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('Salience', 'PROPN'), (',', 'PUNCT'), ('considered', 'VERB'), (' ', 'SPACE'), ('“', 'PUNCT'), ('narrow', 'ADJ'), ('”', 'PUNCT'), ('AI', 'PROPN'), (':', 'PUNCT'), ('uses', 'VERB'), ('different', 'ADJ'), ('types', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('solve', 'VERB'), (' ', 'SPACE'), ('task', 'NOUN'), ('understanding', 'NOUN'), ('analyzing', 'VERB'), ('text', 'NOUN'), (',', 'PUNCT'), ('focused', 'VERB'), ('exclusively', 'ADV'), (' ', 'SPACE'), ('text', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nmod'), ('Lexalytics', 'poss'), ('’', 'case'), ('core', 'compound'), ('text', 'compound'), ('analytics', 'compound'), ('engine', 'nsubjpass'), (',', 'punct'), ('Salience', 'appos'), (',', 'punct'), ('considered', 'ccomp'), (' ', 'nmod'), ('“', 'punct'), ('narrow', 'amod'), ('”', 'punct'), ('AI', 'oprd'), (':', 'punct'), ('uses', 'ROOT'), ('different', 'amod'), ('types', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('solve', 'xcomp'), (' ', 'dative'), ('task', 'dobj'), ('understanding', 'pobj'), ('analyzing', 'conj'), ('text', 'dobj'), (',', 'punct'), ('focused', 'conj'), ('exclusively', 'advmod'), (' ', 'npadvmod'), ('text', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[  , Lexalytics], [Lexalytics, ’], [’, core], [core, text], [text, analytics], [analytics, engine], [engine, ,], [,, Salience], [Salience, ,], [,, considered], [considered,  ], [ , “], [“, narrow], [narrow, ”], [”, AI], [AI, :], [:, uses], [uses, different], [different, types], [types, machine], [machine, learning], [learning, solve], [solve,  ], [ , task], [task, understanding], [understanding, analyzing], [analyzing, text], [text, ,], [,, focused], [focused, exclusively], [exclusively,  ], [ , text], [text, .]]

>> Trigrams: 
[[  , Lexalytics, ’], [Lexalytics, ’, core], [’, core, text], [core, text, analytics], [text, analytics, engine], [analytics, engine, ,], [engine, ,, Salience], [,, Salience, ,], [Salience, ,, considered], [,, considered,  ], [considered,  , “], [ , “, narrow], [“, narrow, ”], [narrow, ”, AI], [”, AI, :], [AI, :, uses], [:, uses, different], [uses, different, types], [different, types, machine], [types, machine, learning], [machine, learning, solve], [learning, solve,  ], [solve,  , task], [ , task, understanding], [task, understanding, analyzing], [understanding, analyzing, text], [analyzing, text, ,], [text, ,, focused], [,, focused, exclusively], [focused, exclusively,  ], [exclusively,  , text], [ , text, .]]

>> Noun Phrases are: 
[  Lexalytics’ core text analytics engine, Salience, a  “narrow” AI, It, many different types, the task, understanding, text, text]

>> Named Entities are: 
[('Salience', 'PERSON')]


============================ Sentence 16 =============================

We’ll be looking at the machine learning and natural language  processing (NLP) elements that Salience is built upon. 


>> Tokens are: 
[looking, machine, learning, natural, language,  , processing, (, NLP, ), elements, Salience, built, .] 

>> PoS Tags are: 
[('looking', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), (' ', 'SPACE'), ('processing', 'NOUN'), ('(', 'PUNCT'), ('NLP', 'PROPN'), (')', 'PUNCT'), ('elements', 'NOUN'), ('Salience', 'PROPN'), ('built', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('looking', 'ROOT'), ('machine', 'compound'), ('learning', 'pobj'), ('natural', 'amod'), ('language', 'conj'), (' ', 'compound'), ('processing', 'nmod'), ('(', 'punct'), ('NLP', 'appos'), (')', 'punct'), ('elements', 'dobj'), ('Salience', 'nsubjpass'), ('built', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[looking, machine], [machine, learning], [learning, natural], [natural, language], [language,  ], [ , processing], [processing, (], [(, NLP], [NLP, )], [), elements], [elements, Salience], [Salience, built], [built, .]]

>> Trigrams: 
[[looking, machine, learning], [machine, learning, natural], [learning, natural, language], [natural, language,  ], [language,  , processing], [ , processing, (], [processing, (, NLP], [(, NLP, )], [NLP, ), elements], [), elements, Salience], [elements, Salience, built], [Salience, built, .]]

>> Noun Phrases are: 
[We, the machine learning, natural language, NLP, Salience]

>> Named Entities are: 
[('NLP', 'ORG'), ('Salience', 'ORG')]


============================ Sentence 17 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 18 =============================

We’ll discuss the different aspects of text analytics and how Lexalytics,  a company with more than a decade of experience in machine learning,  applies machine learning to solve problems in natural language processing. 


>> Tokens are: 
[discuss, different, aspects, text, analytics, Lexalytics, ,,  , company, decade, experience, machine, learning, ,,  , applies, machine, learning, solve, problems, natural, language, processing, .] 

>> PoS Tags are: 
[('discuss', 'VERB'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('company', 'NOUN'), ('decade', 'NOUN'), ('experience', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('applies', 'VERB'), ('machine', 'NOUN'), ('learning', 'VERB'), ('solve', 'VERB'), ('problems', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('discuss', 'ccomp'), ('different', 'amod'), ('aspects', 'dobj'), ('text', 'compound'), ('analytics', 'pobj'), ('Lexalytics', 'conj'), (',', 'punct'), (' ', 'conj'), ('company', 'appos'), ('decade', 'pobj'), ('experience', 'pobj'), ('machine', 'compound'), ('learning', 'pobj'), (',', 'punct'), (' ', 'nsubj'), ('applies', 'ROOT'), ('machine', 'dobj'), ('learning', 'advcl'), ('solve', 'xcomp'), ('problems', 'dobj'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[discuss, different], [different, aspects], [aspects, text], [text, analytics], [analytics, Lexalytics], [Lexalytics, ,], [,,  ], [ , company], [company, decade], [decade, experience], [experience, machine], [machine, learning], [learning, ,], [,,  ], [ , applies], [applies, machine], [machine, learning], [learning, solve], [solve, problems], [problems, natural], [natural, language], [language, processing], [processing, .]]

>> Trigrams: 
[[discuss, different, aspects], [different, aspects, text], [aspects, text, analytics], [text, analytics, Lexalytics], [analytics, Lexalytics, ,], [Lexalytics, ,,  ], [,,  , company], [ , company, decade], [company, decade, experience], [decade, experience, machine], [experience, machine, learning], [machine, learning, ,], [learning, ,,  ], [,,  , applies], [ , applies, machine], [applies, machine, learning], [machine, learning, solve], [learning, solve, problems], [solve, problems, natural], [problems, natural, language], [natural, language, processing], [language, processing, .]]

>> Noun Phrases are: 
[We, the different aspects, text analytics, how Lexalytics, a company, more than a decade, experience, machine learning, machine, problems, natural language processing]

>> Named Entities are: 
[('Lexalytics', 'ORG'), ('more than a decade', 'DATE')]


============================ Sentence 19 =============================

      3 KINDS OF TEXT ANALYTICS SYSTEMS    Rules-based (pure NLP)     Machine learning-based (pure ML)    Hybrid (a combination of ML and NLP)   


>> Tokens are: 
[      , 3, KINDS, TEXT, ANALYTICS, SYSTEMS,    , Rules, -, based, (, pure, NLP, ),     , Machine, learning, -, based, (, pure, ML, ),    , Hybrid, (, combination, ML, NLP, ),  ] 

>> PoS Tags are: 
[('      ', 'SPACE'), ('3', 'NUM'), ('KINDS', 'NOUN'), ('TEXT', 'PROPN'), ('ANALYTICS', 'PROPN'), ('SYSTEMS', 'PROPN'), ('   ', 'SPACE'), ('Rules', 'PROPN'), ('-', 'PUNCT'), ('based', 'VERB'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('NLP', 'PROPN'), (')', 'PUNCT'), ('    ', 'SPACE'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('-', 'PUNCT'), ('based', 'VERB'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('ML', 'PROPN'), (')', 'PUNCT'), ('   ', 'SPACE'), ('Hybrid', 'PROPN'), ('(', 'PUNCT'), ('combination', 'NOUN'), ('ML', 'PROPN'), ('NLP', 'PROPN'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('      ', 'nummod'), ('3', 'nummod'), ('KINDS', 'appos'), ('TEXT', 'compound'), ('ANALYTICS', 'nmod'), ('SYSTEMS', 'pobj'), ('   ', 'nummod'), ('Rules', 'npadvmod'), ('-', 'punct'), ('based', 'amod'), ('(', 'punct'), ('pure', 'amod'), ('NLP', 'appos'), (')', 'punct'), ('    ', 'nummod'), ('Machine', 'npadvmod'), ('learning', 'npadvmod'), ('-', 'punct'), ('based', 'amod'), ('(', 'punct'), ('pure', 'amod'), ('ML', 'nmod'), (')', 'punct'), ('   ', 'compound'), ('Hybrid', 'ROOT'), ('(', 'punct'), ('combination', 'appos'), ('ML', 'pobj'), ('NLP', 'conj'), (')', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[      , 3], [3, KINDS], [KINDS, TEXT], [TEXT, ANALYTICS], [ANALYTICS, SYSTEMS], [SYSTEMS,    ], [   , Rules], [Rules, -], [-, based], [based, (], [(, pure], [pure, NLP], [NLP, )], [),     ], [    , Machine], [Machine, learning], [learning, -], [-, based], [based, (], [(, pure], [pure, ML], [ML, )], [),    ], [   , Hybrid], [Hybrid, (], [(, combination], [combination, ML], [ML, NLP], [NLP, )], [),  ]]

>> Trigrams: 
[[      , 3, KINDS], [3, KINDS, TEXT], [KINDS, TEXT, ANALYTICS], [TEXT, ANALYTICS, SYSTEMS], [ANALYTICS, SYSTEMS,    ], [SYSTEMS,    , Rules], [   , Rules, -], [Rules, -, based], [-, based, (], [based, (, pure], [(, pure, NLP], [pure, NLP, )], [NLP, ),     ], [),     , Machine], [    , Machine, learning], [Machine, learning, -], [learning, -, based], [-, based, (], [based, (, pure], [(, pure, ML], [pure, ML, )], [ML, ),    ], [),    , Hybrid], [   , Hybrid, (], [Hybrid, (, combination], [(, combination, ML], [combination, ML, NLP], [ML, NLP, )], [NLP, ),  ]]

>> Noun Phrases are: 
[3 KINDS, TEXT ANALYTICS SYSTEMS, Rules-based (pure NLP, a combination, ML, NLP]

>> Named Entities are: 
[('3', 'CARDINAL'), ('KINDS', 'ORG'), ('NLP', 'ORG'), ('ML', 'FAC'), ('ML', 'ORG'), ('NLP', 'ORG')]


============================ Sentence 20 =============================

For further reading, you can consult our white papers “Build vs. Buy,”  which talks about the economics of machine learning in a text analytics  context, and “Tune First, Then Train,” which discusses our philosophy   of customization for better accuracy and more-relevant results. 


>> Tokens are: 
[reading, ,, consult, white, papers, “, Build, vs., Buy, ,, ”,  , talks, economics, machine, learning, text, analytics,  , context, ,, “, Tune, ,, Train, ,, ”, discusses, philosophy,   , customization, better, accuracy, -, relevant, results, .] 

>> PoS Tags are: 
[('reading', 'NOUN'), (',', 'PUNCT'), ('consult', 'VERB'), ('white', 'ADJ'), ('papers', 'NOUN'), ('“', 'PUNCT'), ('Build', 'VERB'), ('vs.', 'ADP'), ('Buy', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('talks', 'VERB'), ('economics', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('text', 'NOUN'), ('analytics', 'NOUN'), (' ', 'SPACE'), ('context', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('discusses', 'VERB'), ('philosophy', 'NOUN'), ('  ', 'SPACE'), ('customization', 'NOUN'), ('better', 'ADJ'), ('accuracy', 'NOUN'), ('-', 'PUNCT'), ('relevant', 'ADJ'), ('results', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('reading', 'pobj'), (',', 'punct'), ('consult', 'ROOT'), ('white', 'amod'), ('papers', 'dobj'), ('“', 'punct'), ('Build', 'appos'), ('vs.', 'prep'), ('Buy', 'pobj'), (',', 'punct'), ('”', 'punct'), (' ', 'appos'), ('talks', 'relcl'), ('economics', 'pobj'), ('machine', 'compound'), ('learning', 'pobj'), ('text', 'compound'), ('analytics', 'pobj'), (' ', 'prep'), ('context', 'pobj'), (',', 'punct'), ('“', 'punct'), ('Tune', 'compound'), (',', 'punct'), ('Train', 'conj'), (',', 'punct'), ('”', 'punct'), ('discusses', 'relcl'), ('philosophy', 'dobj'), ('  ', 'dobj'), ('customization', 'pobj'), ('better', 'amod'), ('accuracy', 'pobj'), ('-', 'punct'), ('relevant', 'amod'), ('results', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[reading, ,], [,, consult], [consult, white], [white, papers], [papers, “], [“, Build], [Build, vs.], [vs., Buy], [Buy, ,], [,, ”], [”,  ], [ , talks], [talks, economics], [economics, machine], [machine, learning], [learning, text], [text, analytics], [analytics,  ], [ , context], [context, ,], [,, “], [“, Tune], [Tune, ,], [,, Train], [Train, ,], [,, ”], [”, discusses], [discusses, philosophy], [philosophy,   ], [  , customization], [customization, better], [better, accuracy], [accuracy, -], [-, relevant], [relevant, results], [results, .]]

>> Trigrams: 
[[reading, ,, consult], [,, consult, white], [consult, white, papers], [white, papers, “], [papers, “, Build], [“, Build, vs.], [Build, vs., Buy], [vs., Buy, ,], [Buy, ,, ”], [,, ”,  ], [”,  , talks], [ , talks, economics], [talks, economics, machine], [economics, machine, learning], [machine, learning, text], [learning, text, analytics], [text, analytics,  ], [analytics,  , context], [ , context, ,], [context, ,, “], [,, “, Tune], [“, Tune, ,], [Tune, ,, Train], [,, Train, ,], [Train, ,, ”], [,, ”, discusses], [”, discusses, philosophy], [discusses, philosophy,   ], [philosophy,   , customization], [  , customization, better], [customization, better, accuracy], [better, accuracy, -], [accuracy, -, relevant], [-, relevant, results], [relevant, results, .]]

>> Noun Phrases are: 
[further reading, you, our white papers, Buy, the economics, a text analytics, context, “Tune First, Then Train, our philosophy, customization, better accuracy, more-relevant results]

>> Named Entities are: 
[('Build', 'PERSON'), ('Tune First, Then Train', 'WORK_OF_ART')]


============================ Sentence 21 =============================

When  taken together with this paper, these resources offer a more complete  view of text analytics solutions. 


>> Tokens are: 
[ , taken, paper, ,, resources, offer, complete,  , view, text, analytics, solutions, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('taken', 'VERB'), ('paper', 'NOUN'), (',', 'PUNCT'), ('resources', 'NOUN'), ('offer', 'VERB'), ('complete', 'ADJ'), (' ', 'SPACE'), ('view', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('solutions', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('taken', 'advcl'), ('paper', 'pobj'), (',', 'punct'), ('resources', 'nsubj'), ('offer', 'ROOT'), ('complete', 'amod'), (' ', 'compound'), ('view', 'dobj'), ('text', 'compound'), ('analytics', 'compound'), ('solutions', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , taken], [taken, paper], [paper, ,], [,, resources], [resources, offer], [offer, complete], [complete,  ], [ , view], [view, text], [text, analytics], [analytics, solutions], [solutions, .]]

>> Trigrams: 
[[ , taken, paper], [taken, paper, ,], [paper, ,, resources], [,, resources, offer], [resources, offer, complete], [offer, complete,  ], [complete,  , view], [ , view, text], [view, text, analytics], [text, analytics, solutions], [analytics, solutions, .]]

>> Noun Phrases are: 
[this paper, these resources, a more complete  view, text analytics solutions]

>> Named Entities are: 
[]


============================ Sentence 22 =============================

 Machine Learning   is Really Machine Teaching  .........................3   Supervised, Semi-Supervised and   


>> Tokens are: 
[ , Machine, Learning,   , Machine, Teaching,  , ........................., 3,   , Supervised, ,, Semi, -, Supervised,  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Machine', 'PROPN'), ('Teaching', 'PROPN'), (' ', 'SPACE'), ('.........................', 'PUNCT'), ('3', 'NUM'), ('  ', 'SPACE'), ('Supervised', 'VERB'), (',', 'PUNCT'), ('Semi', 'ADJ'), ('-', 'ADJ'), ('Supervised', 'ADJ'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('Machine', 'compound'), ('Learning', 'nsubj'), ('  ', 'appos'), ('Machine', 'compound'), ('Teaching', 'attr'), (' ', 'appos'), ('.........................', 'punct'), ('3', 'nummod'), ('  ', 'npadvmod'), ('Supervised', 'ccomp'), (',', 'punct'), ('Semi', 'conj'), ('-', 'punct'), ('Supervised', 'conj'), (' ', 'conj')]

>> Bigrams: 
[[ , Machine], [Machine, Learning], [Learning,   ], [  , Machine], [Machine, Teaching], [Teaching,  ], [ , .........................], [........................., 3], [3,   ], [  , Supervised], [Supervised, ,], [,, Semi], [Semi, -], [-, Supervised], [Supervised,  ]]

>> Trigrams: 
[[ , Machine, Learning], [Machine, Learning,   ], [Learning,   , Machine], [  , Machine, Teaching], [Machine, Teaching,  ], [Teaching,  , .........................], [ , ........................., 3], [........................., 3,   ], [3,   , Supervised], [  , Supervised, ,], [Supervised, ,, Semi], [,, Semi, -], [Semi, -, Supervised], [-, Supervised,  ]]

>> Noun Phrases are: 
[ Machine Learning, Machine Teaching]

>> Named Entities are: 
[('3', 'CARDINAL')]


============================ Sentence 23 =============================

Unsupervised Machine Learning   Supervised Learning .............................. 


>> Tokens are: 
[Unsupervised, Machine, Learning,   , Supervised, Learning, ..............................] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Supervised', 'PROPN'), ('Learning', 'PROPN'), ('..............................', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('Machine', 'compound'), ('Learning', 'dep'), ('  ', 'appos'), ('Supervised', 'compound'), ('Learning', 'ROOT'), ('..............................', 'punct')]

>> Bigrams: 
[[Unsupervised, Machine], [Machine, Learning], [Learning,   ], [  , Supervised], [Supervised, Learning], [Learning, ..............................]]

>> Trigrams: 
[[Unsupervised, Machine, Learning], [Machine, Learning,   ], [Learning,   , Supervised], [  , Supervised, Learning], [Supervised, Learning, ..............................]]

>> Noun Phrases are: 
[Unsupervised Machine Learning   Supervised Learning]

>> Named Entities are: 
[]


============================ Sentence 24 =============================

5  Semi-Supervised Learning ................6   


>> Tokens are: 
[5,  , Semi, -, Supervised, Learning, ................, 6,  ] 

>> PoS Tags are: 
[('5', 'NUM'), (' ', 'SPACE'), ('Semi', 'ADJ'), ('-', 'ADJ'), ('Supervised', 'ADJ'), ('Learning', 'NOUN'), ('................', 'PUNCT'), ('6', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('5', 'nummod'), (' ', 'dep'), ('Semi', 'amod'), ('-', 'amod'), ('Supervised', 'amod'), ('Learning', 'ROOT'), ('................', 'punct'), ('6', 'nummod'), (' ', 'appos')]

>> Bigrams: 
[[5,  ], [ , Semi], [Semi, -], [-, Supervised], [Supervised, Learning], [Learning, ................], [................, 6], [6,  ]]

>> Trigrams: 
[[5,  , Semi], [ , Semi, -], [Semi, -, Supervised], [-, Supervised, Learning], [Supervised, Learning, ................], [Learning, ................, 6], [................, 6,  ]]

>> Noun Phrases are: 
[5  Semi-Supervised Learning]

>> Named Entities are: 
[]


============================ Sentence 25 =============================

Unsupervised Learning ........................ 


>> Tokens are: 
[Unsupervised, Learning, ........................] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('Learning', 'PROPN'), ('........................', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('Learning', 'ROOT'), ('........................', 'punct')]

>> Bigrams: 
[[Unsupervised, Learning], [Learning, ........................]]

>> Trigrams: 
[[Unsupervised, Learning, ........................]]

>> Noun Phrases are: 
[Unsupervised Learning]

>> Named Entities are: 
[]


============================ Sentence 26 =============================

6  Happier by the Dozen:   The More Models, the Merrier .................... 7   


>> Tokens are: 
[6,  , Happier, Dozen, :,   , Models, ,, Merrier, ...................., 7,  ] 

>> PoS Tags are: 
[('6', 'NUM'), (' ', 'SPACE'), ('Happier', 'VERB'), ('Dozen', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Models', 'PROPN'), (',', 'PUNCT'), ('Merrier', 'PROPN'), ('....................', 'PUNCT'), ('7', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('6', 'nummod'), (' ', 'npadvmod'), ('Happier', 'ROOT'), ('Dozen', 'pobj'), (':', 'punct'), ('  ', 'appos'), ('Models', 'appos'), (',', 'punct'), ('Merrier', 'appos'), ('....................', 'punct'), ('7', 'appos'), (' ', 'punct')]

>> Bigrams: 
[[6,  ], [ , Happier], [Happier, Dozen], [Dozen, :], [:,   ], [  , Models], [Models, ,], [,, Merrier], [Merrier, ....................], [...................., 7], [7,  ]]

>> Trigrams: 
[[6,  , Happier], [ , Happier, Dozen], [Happier, Dozen, :], [Dozen, :,   ], [:,   , Models], [  , Models, ,], [Models, ,, Merrier], [,, Merrier, ....................], [Merrier, ...................., 7], [...................., 7,  ]]

>> Noun Phrases are: 
[the Dozen, The More Models, the Merrier]

>> Named Entities are: 
[('Models', 'PRODUCT'), ('Merrier', 'ORG')]


============================ Sentence 27 =============================

Coding vs. Learning:   Making the Case for Each ............................9  Black Box/Clear Box:    


>> Tokens are: 
[Coding, vs., Learning, :,   , Making, Case, ............................, 9,  , Black, Box, /, Clear, Box, :,   ] 

>> PoS Tags are: 
[('Coding', 'VERB'), ('vs.', 'ADP'), ('Learning', 'PROPN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Making', 'VERB'), ('Case', 'NOUN'), ('............................', 'PUNCT'), ('9', 'NUM'), (' ', 'SPACE'), ('Black', 'PROPN'), ('Box', 'PROPN'), ('/', 'SYM'), ('Clear', 'PROPN'), ('Box', 'PROPN'), (':', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('Coding', 'ROOT'), ('vs.', 'prep'), ('Learning', 'pobj'), (':', 'punct'), ('  ', 'appos'), ('Making', 'acl'), ('Case', 'dobj'), ('............................', 'punct'), ('9', 'nummod'), (' ', 'nmod'), ('Black', 'nmod'), ('Box', 'nmod'), ('/', 'punct'), ('Clear', 'compound'), ('Box', 'npadvmod'), (':', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[Coding, vs.], [vs., Learning], [Learning, :], [:,   ], [  , Making], [Making, Case], [Case, ............................], [............................, 9], [9,  ], [ , Black], [Black, Box], [Box, /], [/, Clear], [Clear, Box], [Box, :], [:,   ]]

>> Trigrams: 
[[Coding, vs., Learning], [vs., Learning, :], [Learning, :,   ], [:,   , Making], [  , Making, Case], [Making, Case, ............................], [Case, ............................, 9], [............................, 9,  ], [9,  , Black], [ , Black, Box], [Black, Box, /], [Box, /, Clear], [/, Clear, Box], [Clear, Box, :], [Box, :,   ]]

>> Noun Phrases are: 
[Learning, the Case]

>> Named Entities are: 
[('Box', 'PERSON')]


============================ Sentence 28 =============================

Looking Inside the Data ............................... 10   


>> Tokens are: 
[Looking, Inside, Data, ..............................., 10,  ] 

>> PoS Tags are: 
[('Looking', 'VERB'), ('Inside', 'ADP'), ('Data', 'PROPN'), ('...............................', 'PUNCT'), ('10', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Looking', 'ROOT'), ('Inside', 'prep'), ('Data', 'pobj'), ('...............................', 'punct'), ('10', 'nummod'), (' ', 'punct')]

>> Bigrams: 
[[Looking, Inside], [Inside, Data], [Data, ...............................], [..............................., 10], [10,  ]]

>> Trigrams: 
[[Looking, Inside, Data], [Inside, Data, ...............................], [Data, ..............................., 10], [..............................., 10,  ]]

>> Noun Phrases are: 
[the Data]

>> Named Entities are: 
[('10', 'CARDINAL')]


============================ Sentence 29 =============================

Tune First, Then Train:   Efficiency before Complexity ....................12   


>> Tokens are: 
[Tune, ,, Train, :,   , Efficiency, Complexity, ...................., 12,  ] 

>> PoS Tags are: 
[('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Efficiency', 'NOUN'), ('Complexity', 'PROPN'), ('....................', 'PUNCT'), ('12', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Tune', 'compound'), (',', 'punct'), ('Train', 'ROOT'), (':', 'punct'), ('  ', 'compound'), ('Efficiency', 'appos'), ('Complexity', 'pobj'), ('....................', 'punct'), ('12', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[Tune, ,], [,, Train], [Train, :], [:,   ], [  , Efficiency], [Efficiency, Complexity], [Complexity, ....................], [...................., 12], [12,  ]]

>> Trigrams: 
[[Tune, ,, Train], [,, Train, :], [Train, :,   ], [:,   , Efficiency], [  , Efficiency, Complexity], [Efficiency, Complexity, ....................], [Complexity, ...................., 12], [...................., 12,  ]]

>> Noun Phrases are: 
[Tune First, Then Train,   Efficiency, Complexity]

>> Named Entities are: 
[]


============================ Sentence 30 =============================

Summary/Conclusion .................................. 14  https://www.lexalytics.com/ https://www.lexalytics.com/ https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing   W H 


>> Tokens are: 
[Summary, /, Conclusion, .................................., 14,  , https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf, https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing,   , W, H] 

>> PoS Tags are: 
[('Summary', 'PROPN'), ('/', 'SYM'), ('Conclusion', 'PROPN'), ('..................................', 'PUNCT'), ('14', 'NUM'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf', 'PROPN'), ('https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing', 'VERB'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('Summary', 'nmod'), ('/', 'punct'), ('Conclusion', 'nsubj'), ('..................................', 'punct'), ('14', 'nummod'), (' ', 'appos'), ('https://www.lexalytics.com/', 'npadvmod'), ('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf', 'appos'), ('https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing', 'ROOT'), ('  ', 'punct'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[Summary, /], [/, Conclusion], [Conclusion, ..................................], [.................................., 14], [14,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf], [https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf, https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing], [https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing,   ], [  , W], [W, H]]

>> Trigrams: 
[[Summary, /, Conclusion], [/, Conclusion, ..................................], [Conclusion, .................................., 14], [.................................., 14,  ], [14,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf], [https://www.lexalytics.com/, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf, https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing], [https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf, https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing,   ], [https://www.lexalytics.com/lexablog/build-or-buy-text-analytics-natural-language-processing,   , W], [  , W, H]]

>> Noun Phrases are: 
[Summary/Conclusion, https://www.lexalytics.com/ https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf]

>> Named Entities are: 
[]


============================ Sentence 31 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 32 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 33 =============================

P A P E R  3|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 3|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('3|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'compound'), ('3|', 'compound'), ('      ', 'ROOT'), ('|', 'npadvmod'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 3|], [3|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 3|], [ , 3|,       ], [3|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[  Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 34 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 35 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 36 =============================

M A C H 


>> Tokens are: 
[M, C, H] 

>> PoS Tags are: 
[('M', 'PROPN'), ('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('M', 'compound'), ('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[M, C], [C, H]]

>> Trigrams: 
[[M, C, H]]

>> Noun Phrases are: 
[M A C H]

>> Named Entities are: 
[]


============================ Sentence 37 =============================

I N E  L E 


>> Tokens are: 
[N, E,  , L, E] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('L', 'NOUN'), ('E', 'PROPN')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[N, E], [E,  ], [ , L], [L, E]]

>> Trigrams: 
[[N, E,  ], [E,  , L], [ , L, E]]

>> Noun Phrases are: 
[I, N, E, L E]

>> Named Entities are: 
[]


============================ Sentence 38 =============================

A R N I N G    


>> Tokens are: 
[R, N, N, G,   ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'PROPN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), ('  ', 'ROOT')]

>> Bigrams: 
[[R, N], [N, N], [N, G], [G,   ]]

>> Trigrams: 
[[R, N, N], [N, N, G], [N, G,   ]]

>> Noun Phrases are: 
[A R N I, N G]

>> Named Entities are: 
[]


============================ Sentence 39 =============================

I 


>> Tokens are: 
[] 

>> PoS Tags are: 
[] 

>> Dependency Tags are: 
[]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I]

>> Named Entities are: 
[]


============================ Sentence 40 =============================

S   


>> Tokens are: 
[S,  ] 

>> PoS Tags are: 
[('S', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('S', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[S,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[S]

>> Named Entities are: 
[]


============================ Sentence 41 =============================

R E A L L Y   


>> Tokens are: 
[R, E, L, L, Y,  ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('E', 'NOUN'), ('L', 'PROPN'), ('L', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('E', 'compound'), ('L', 'compound'), ('L', 'compound'), ('Y', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[R, E], [E, L], [L, L], [L, Y], [Y,  ]]

>> Trigrams: 
[[R, E, L], [E, L, L], [L, L, Y], [L, Y,  ]]

>> Noun Phrases are: 
[R E A L L Y]

>> Named Entities are: 
[]


============================ Sentence 42 =============================

M A C H 


>> Tokens are: 
[M, C, H] 

>> PoS Tags are: 
[('M', 'PROPN'), ('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('M', 'compound'), ('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[M, C], [C, H]]

>> Trigrams: 
[[M, C, H]]

>> Noun Phrases are: 
[M A C H]

>> Named Entities are: 
[]


============================ Sentence 43 =============================

I N E   


>> Tokens are: 
[N, E,  ] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos')]

>> Bigrams: 
[[N, E], [E,  ]]

>> Trigrams: 
[[N, E,  ]]

>> Noun Phrases are: 
[I, N, E]

>> Named Entities are: 
[]


============================ Sentence 44 =============================

T E 


>> Tokens are: 
[T, E] 

>> PoS Tags are: 
[('T', 'NOUN'), ('E', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'compound'), ('E', 'ROOT')]

>> Bigrams: 
[[T, E]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[T E]

>> Named Entities are: 
[]


============================ Sentence 45 =============================

A C H 


>> Tokens are: 
[C, H] 

>> PoS Tags are: 
[('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[C, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[A C H]

>> Named Entities are: 
[]


============================ Sentence 46 =============================

I N G  Before we start delving into the different aspects of text analytics, let’s clarify  some basic machine learning concepts. 


>> Tokens are: 
[N, G,  , start, delving, different, aspects, text, analytics, ,, let, clarify,  , basic, machine, learning, concepts, .] 

>> PoS Tags are: 
[('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('start', 'VERB'), ('delving', 'VERB'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('clarify', 'VERB'), (' ', 'SPACE'), ('basic', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('concepts', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('N', 'compound'), ('G', 'appos'), (' ', 'nsubj'), ('start', 'advcl'), ('delving', 'xcomp'), ('different', 'amod'), ('aspects', 'pobj'), ('text', 'compound'), ('analytics', 'pobj'), (',', 'punct'), ('let', 'ROOT'), ('clarify', 'ccomp'), (' ', 'dobj'), ('basic', 'amod'), ('machine', 'compound'), ('learning', 'compound'), ('concepts', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[N, G], [G,  ], [ , start], [start, delving], [delving, different], [different, aspects], [aspects, text], [text, analytics], [analytics, ,], [,, let], [let, clarify], [clarify,  ], [ , basic], [basic, machine], [machine, learning], [learning, concepts], [concepts, .]]

>> Trigrams: 
[[N, G,  ], [G,  , start], [ , start, delving], [start, delving, different], [delving, different, aspects], [different, aspects, text], [aspects, text, analytics], [text, analytics, ,], [analytics, ,, let], [,, let, clarify], [let, clarify,  ], [clarify,  , basic], [ , basic, machine], [basic, machine, learning], [machine, learning, concepts], [learning, concepts, .]]

>> Noun Phrases are: 
[I, N G, we, the different aspects, text analytics, ’s, some basic machine learning concepts]

>> Named Entities are: 
[('’s', 'GPE')]


============================ Sentence 47 =============================

  Most importantly, “machine learning” really means “machine teaching.” 


>> Tokens are: 
[  , importantly, ,, “, machine, learning, ”, means, “, machine, teaching, ., ”] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('importantly', 'ADV'), (',', 'PUNCT'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('means', 'VERB'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('teaching', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('importantly', 'advmod'), (',', 'punct'), ('“', 'punct'), ('machine', 'compound'), ('learning', 'nsubj'), ('”', 'punct'), ('means', 'ROOT'), ('“', 'punct'), ('machine', 'compound'), ('teaching', 'dobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[  , importantly], [importantly, ,], [,, “], [“, machine], [machine, learning], [learning, ”], [”, means], [means, “], [“, machine], [machine, teaching], [teaching, .], [., ”]]

>> Trigrams: 
[[  , importantly, ,], [importantly, ,, “], [,, “, machine], [“, machine, learning], [machine, learning, ”], [learning, ”, means], [”, means, “], [means, “, machine], [“, machine, teaching], [machine, teaching, .], [teaching, ., ”]]

>> Noun Phrases are: 
[machine learning, machine teaching]

>> Named Entities are: 
[]


============================ Sentence 48 =============================

We  know what the machine needs to learn, so our task is to create a learning  framework and provide properly-formatted, relevant, clean data that the  machine can learn from. 


>> Tokens are: 
[ , know, machine, needs, learn, ,, task, create, learning,  , framework, provide, properly, -, formatted, ,, relevant, ,, clean, data,  , machine, learn, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('know', 'VERB'), ('machine', 'NOUN'), ('needs', 'VERB'), ('learn', 'VERB'), (',', 'PUNCT'), ('task', 'NOUN'), ('create', 'VERB'), ('learning', 'NOUN'), (' ', 'SPACE'), ('framework', 'NOUN'), ('provide', 'VERB'), ('properly', 'ADV'), ('-', 'PUNCT'), ('formatted', 'VERB'), (',', 'PUNCT'), ('relevant', 'ADJ'), (',', 'PUNCT'), ('clean', 'ADJ'), ('data', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learn', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'appos'), ('know', 'ccomp'), ('machine', 'nsubj'), ('needs', 'ccomp'), ('learn', 'xcomp'), (',', 'punct'), ('task', 'nsubj'), ('create', 'xcomp'), ('learning', 'nmod'), (' ', 'punct'), ('framework', 'dobj'), ('provide', 'conj'), ('properly', 'advmod'), ('-', 'punct'), ('formatted', 'amod'), (',', 'punct'), ('relevant', 'amod'), (',', 'punct'), ('clean', 'amod'), ('data', 'dobj'), (' ', 'compound'), ('machine', 'nsubj'), ('learn', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[ , know], [know, machine], [machine, needs], [needs, learn], [learn, ,], [,, task], [task, create], [create, learning], [learning,  ], [ , framework], [framework, provide], [provide, properly], [properly, -], [-, formatted], [formatted, ,], [,, relevant], [relevant, ,], [,, clean], [clean, data], [data,  ], [ , machine], [machine, learn], [learn, .]]

>> Trigrams: 
[[ , know, machine], [know, machine, needs], [machine, needs, learn], [needs, learn, ,], [learn, ,, task], [,, task, create], [task, create, learning], [create, learning,  ], [learning,  , framework], [ , framework, provide], [framework, provide, properly], [provide, properly, -], [properly, -, formatted], [-, formatted, ,], [formatted, ,, relevant], [,, relevant, ,], [relevant, ,, clean], [,, clean, data], [clean, data,  ], [data,  , machine], [ , machine, learn], [machine, learn, .]]

>> Noun Phrases are: 
[We, what, the machine, our task, a learning  framework, properly-formatted, relevant, clean data, the  machine]

>> Named Entities are: 
[]


============================ Sentence 49 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 50 =============================

The goal is to create a system where the model continuously improves  at the task you’ve set it. 


>> Tokens are: 
[goal, create, system, model, continuously, improves,  , task, set, .] 

>> PoS Tags are: 
[('goal', 'NOUN'), ('create', 'VERB'), ('system', 'NOUN'), ('model', 'NOUN'), ('continuously', 'ADV'), ('improves', 'VERB'), (' ', 'SPACE'), ('task', 'NOUN'), ('set', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('goal', 'nsubj'), ('create', 'xcomp'), ('system', 'dobj'), ('model', 'nsubj'), ('continuously', 'advmod'), ('improves', 'relcl'), (' ', 'dobj'), ('task', 'pobj'), ('set', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[goal, create], [create, system], [system, model], [model, continuously], [continuously, improves], [improves,  ], [ , task], [task, set], [set, .]]

>> Trigrams: 
[[goal, create, system], [create, system, model], [system, model, continuously], [model, continuously, improves], [continuously, improves,  ], [improves,  , task], [ , task, set], [task, set, .]]

>> Noun Phrases are: 
[The goal, a system, the model, the task, you, it]

>> Named Entities are: 
[]


============================ Sentence 51 =============================

Input is key. 


>> Tokens are: 
[Input, key, .] 

>> PoS Tags are: 
[('Input', 'NOUN'), ('key', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Input', 'nsubj'), ('key', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Input, key], [key, .]]

>> Trigrams: 
[[Input, key, .]]

>> Noun Phrases are: 
[Input]

>> Named Entities are: 
[]


============================ Sentence 52 =============================

Unlike algorithmic programming, a  machine learning model is able to generalize and deal with novel cases. 


>> Tokens are: 
[Unlike, algorithmic, programming, ,,  , machine, learning, model, able, generalize, deal, novel, cases, .] 

>> PoS Tags are: 
[('Unlike', 'ADP'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('able', 'ADJ'), ('generalize', 'VERB'), ('deal', 'VERB'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Unlike', 'prep'), ('algorithmic', 'amod'), ('programming', 'pobj'), (',', 'punct'), (' ', 'compound'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('able', 'acomp'), ('generalize', 'xcomp'), ('deal', 'conj'), ('novel', 'amod'), ('cases', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Unlike, algorithmic], [algorithmic, programming], [programming, ,], [,,  ], [ , machine], [machine, learning], [learning, model], [model, able], [able, generalize], [generalize, deal], [deal, novel], [novel, cases], [cases, .]]

>> Trigrams: 
[[Unlike, algorithmic, programming], [algorithmic, programming, ,], [programming, ,,  ], [,,  , machine], [ , machine, learning], [machine, learning, model], [learning, model, able], [model, able, generalize], [able, generalize, deal], [generalize, deal, novel], [deal, novel, cases], [novel, cases, .]]

>> Noun Phrases are: 
[algorithmic programming, a  machine learning model, novel cases]

>> Named Entities are: 
[]


============================ Sentence 53 =============================

If a  case resembles something the model has seen before, the model can use  this prior “learning” to evaluate the case. 


>> Tokens are: 
[ , case, resembles, model, seen, ,, model, use,  , prior, “, learning, ”, evaluate, case, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('case', 'NOUN'), ('resembles', 'VERB'), ('model', 'NOUN'), ('seen', 'VERB'), (',', 'PUNCT'), ('model', 'NOUN'), ('use', 'VERB'), (' ', 'SPACE'), ('prior', 'ADV'), ('“', 'PUNCT'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('evaluate', 'VERB'), ('case', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('case', 'nsubj'), ('resembles', 'advcl'), ('model', 'nsubj'), ('seen', 'relcl'), (',', 'punct'), ('model', 'nsubj'), ('use', 'ROOT'), (' ', 'dobj'), ('prior', 'amod'), ('“', 'punct'), ('learning', 'dobj'), ('”', 'punct'), ('evaluate', 'relcl'), ('case', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , case], [case, resembles], [resembles, model], [model, seen], [seen, ,], [,, model], [model, use], [use,  ], [ , prior], [prior, “], [“, learning], [learning, ”], [”, evaluate], [evaluate, case], [case, .]]

>> Trigrams: 
[[ , case, resembles], [case, resembles, model], [resembles, model, seen], [model, seen, ,], [seen, ,, model], [,, model, use], [model, use,  ], [use,  , prior], [ , prior, “], [prior, “, learning], [“, learning, ”], [learning, ”, evaluate], [”, evaluate, case], [evaluate, case, .]]

>> Noun Phrases are: 
[a  case, something, the model, the model, this prior “learning, the case]

>> Named Entities are: 
[]


============================ Sentence 54 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 55 =============================

When we talk about a “model,” we’re talking about a mathematical  representation. 


>> Tokens are: 
[talk, “, model, ,, ”, talking, mathematical,  , representation, .] 

>> PoS Tags are: 
[('talk', 'VERB'), ('“', 'PUNCT'), ('model', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('talking', 'VERB'), ('mathematical', 'ADJ'), (' ', 'SPACE'), ('representation', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('talk', 'advcl'), ('“', 'punct'), ('model', 'pobj'), (',', 'punct'), ('”', 'punct'), ('talking', 'ROOT'), ('mathematical', 'amod'), (' ', 'compound'), ('representation', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[talk, “], [“, model], [model, ,], [,, ”], [”, talking], [talking, mathematical], [mathematical,  ], [ , representation], [representation, .]]

>> Trigrams: 
[[talk, “, model], [“, model, ,], [model, ,, ”], [,, ”, talking], [”, talking, mathematical], [talking, mathematical,  ], [mathematical,  , representation], [ , representation, .]]

>> Noun Phrases are: 
[we, a “model, we, a mathematical  representation]

>> Named Entities are: 
[]


============================ Sentence 56 =============================

A machine learning model is the sum of the learning  that has been acquired from the training data. 


>> Tokens are: 
[machine, learning, model, sum, learning,  , acquired, training, data, .] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('sum', 'NOUN'), ('learning', 'NOUN'), (' ', 'SPACE'), ('acquired', 'VERB'), ('training', 'NOUN'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('sum', 'attr'), ('learning', 'amod'), (' ', 'pobj'), ('acquired', 'relcl'), ('training', 'compound'), ('data', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[machine, learning], [learning, model], [model, sum], [sum, learning], [learning,  ], [ , acquired], [acquired, training], [training, data], [data, .]]

>> Trigrams: 
[[machine, learning, model], [learning, model, sum], [model, sum, learning], [sum, learning,  ], [learning,  , acquired], [ , acquired, training], [acquired, training, data], [training, data, .]]

>> Noun Phrases are: 
[A machine learning model, the sum, the training data]

>> Named Entities are: 
[]


============================ Sentence 57 =============================

The model changes as  more learning is acquired. 


>> Tokens are: 
[model, changes,  , learning, acquired, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('changes', 'NOUN'), (' ', 'SPACE'), ('learning', 'NOUN'), ('acquired', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'compound'), ('changes', 'ROOT'), (' ', 'nsubj'), ('learning', 'nsubjpass'), ('acquired', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[model, changes], [changes,  ], [ , learning], [learning, acquired], [acquired, .]]

>> Trigrams: 
[[model, changes,  ], [changes,  , learning], [ , learning, acquired], [learning, acquired, .]]

>> Noun Phrases are: 
[The model changes,  more learning]

>> Named Entities are: 
[]


============================ Sentence 58 =============================

 3 MAJOR PARTS TO MACHINE LEARNING    


>> Tokens are: 
[ , 3, MAJOR, PARTS, MACHINE, LEARNING,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('3', 'NUM'), ('MAJOR', 'PROPN'), ('PARTS', 'PROPN'), ('MACHINE', 'PROPN'), ('LEARNING', 'PROPN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'nmod'), ('3', 'nummod'), ('MAJOR', 'compound'), ('PARTS', 'nmod'), ('MACHINE', 'compound'), ('LEARNING', 'ROOT'), ('  ', 'punct')]

>> Bigrams: 
[[ , 3], [3, MAJOR], [MAJOR, PARTS], [PARTS, MACHINE], [MACHINE, LEARNING], [LEARNING,   ]]

>> Trigrams: 
[[ , 3, MAJOR], [3, MAJOR, PARTS], [MAJOR, PARTS, MACHINE], [PARTS, MACHINE, LEARNING], [MACHINE, LEARNING,   ]]

>> Noun Phrases are: 
[ 3 MAJOR PARTS TO MACHINE LEARNING]

>> Named Entities are: 
[('3', 'CARDINAL')]


============================ Sentence 59 =============================

Training data    Model algorithm    Hyper-parameters  creates a learning framework    and provides data that the   machine can learn from. 


>> Tokens are: 
[Training, data,    , Model, algorithm,    , Hyper, -, parameters,  , creates, learning, framework,    , provides, data,   , machine, learn, .] 

>> PoS Tags are: 
[('Training', 'NOUN'), ('data', 'NOUN'), ('   ', 'SPACE'), ('Model', 'PROPN'), ('algorithm', 'NOUN'), ('   ', 'SPACE'), ('Hyper', 'PROPN'), ('-', 'PUNCT'), ('parameters', 'NOUN'), (' ', 'SPACE'), ('creates', 'VERB'), ('learning', 'VERB'), ('framework', 'NOUN'), ('   ', 'SPACE'), ('provides', 'VERB'), ('data', 'NOUN'), ('  ', 'SPACE'), ('machine', 'NOUN'), ('learn', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Training', 'compound'), ('data', 'nsubj'), ('   ', 'nummod'), ('Model', 'compound'), ('algorithm', 'appos'), ('   ', 'nummod'), ('Hyper', 'compound'), ('-', 'punct'), ('parameters', 'appos'), (' ', 'nsubj'), ('creates', 'ROOT'), ('learning', 'amod'), ('framework', 'dobj'), ('   ', 'nummod'), ('provides', 'conj'), ('data', 'dobj'), ('  ', 'compound'), ('machine', 'nsubj'), ('learn', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[Training, data], [data,    ], [   , Model], [Model, algorithm], [algorithm,    ], [   , Hyper], [Hyper, -], [-, parameters], [parameters,  ], [ , creates], [creates, learning], [learning, framework], [framework,    ], [   , provides], [provides, data], [data,   ], [  , machine], [machine, learn], [learn, .]]

>> Trigrams: 
[[Training, data,    ], [data,    , Model], [   , Model, algorithm], [Model, algorithm,    ], [algorithm,    , Hyper], [   , Hyper, -], [Hyper, -, parameters], [-, parameters,  ], [parameters,  , creates], [ , creates, learning], [creates, learning, framework], [learning, framework,    ], [framework,    , provides], [   , provides, data], [provides, data,   ], [data,   , machine], [  , machine, learn], [machine, learn, .]]

>> Noun Phrases are: 
[Training data,    Model algorithm,    Hyper-parameters, a learning framework, data, the   machine]

>> Named Entities are: 
[('Model', 'PRODUCT'), ('Hyper', 'GPE')]


============================ Sentence 60 =============================

 Machine  teaching    (aka learning)   


>> Tokens are: 
[ , Machine,  , teaching,    , (, aka, learning, ),  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Machine', 'NOUN'), (' ', 'SPACE'), ('teaching', 'VERB'), ('   ', 'SPACE'), ('(', 'PUNCT'), ('aka', 'ADV'), ('learning', 'VERB'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'dep'), ('Machine', 'compound'), (' ', 'nsubj'), ('teaching', 'ROOT'), ('   ', 'dobj'), ('(', 'punct'), ('aka', 'advmod'), ('learning', 'parataxis'), (')', 'punct'), (' ', 'dep')]

>> Bigrams: 
[[ , Machine], [Machine,  ], [ , teaching], [teaching,    ], [   , (], [(, aka], [aka, learning], [learning, )], [),  ]]

>> Trigrams: 
[[ , Machine,  ], [Machine,  , teaching], [ , teaching,    ], [teaching,    , (], [   , (, aka], [(, aka, learning], [aka, learning, )], [learning, ),  ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 61 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos'), ('W', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/, W H]

>> Named Entities are: 
[]


============================ Sentence 62 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 63 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 64 =============================

P A P E R  4|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 4|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('4|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'nsubj'), (' ', 'appos'), ('4|', 'nmod'), ('      ', 'dobj'), ('|', 'punct'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 4|], [4|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 4|], [ , 4|,       ], [4|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[P A P E R, 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 65 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 66 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'poss'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'ROOT'), ('  ', 'appos'), ('www.lexalytics.com', 'appos'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[  |   1-800-377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 67 =============================

The output of this system is a machine learning model. 


>> Tokens are: 
[output, system, machine, learning, model, .] 

>> PoS Tags are: 
[('output', 'NOUN'), ('system', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('output', 'nsubj'), ('system', 'pobj'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[output, system], [system, machine], [machine, learning], [learning, model], [model, .]]

>> Trigrams: 
[[output, system, machine], [system, machine, learning], [machine, learning, model], [learning, model, .]]

>> Noun Phrases are: 
[The output, this system, a machine learning model]

>> Named Entities are: 
[]


============================ Sentence 68 =============================

  If you were baking a cake:  • the training data would be the ingredients  • the time and temperature would be the hyper-parameters   


>> Tokens are: 
[  , baking, cake, :,  , •, training, data, ingredients,  , •, time, temperature, hyper, -, parameters,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('baking', 'VERB'), ('cake', 'NOUN'), (':', 'PUNCT'), (' ', 'SPACE'), ('•', 'CCONJ'), ('training', 'NOUN'), ('data', 'NOUN'), ('ingredients', 'NOUN'), (' ', 'SPACE'), ('•', 'X'), ('time', 'NOUN'), ('temperature', 'NOUN'), ('hyper', 'NOUN'), ('-', 'NOUN'), ('parameters', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('baking', 'advcl'), ('cake', 'dobj'), (':', 'punct'), (' ', 'dep'), ('•', 'prep'), ('training', 'compound'), ('data', 'conj'), ('ingredients', 'attr'), (' ', 'dep'), ('•', 'dep'), ('time', 'npadvmod'), ('temperature', 'conj'), ('hyper', 'attr'), ('-', 'nsubj'), ('parameters', 'attr'), (' ', 'attr')]

>> Bigrams: 
[[  , baking], [baking, cake], [cake, :], [:,  ], [ , •], [•, training], [training, data], [data, ingredients], [ingredients,  ], [ , •], [•, time], [time, temperature], [temperature, hyper], [hyper, -], [-, parameters], [parameters,  ]]

>> Trigrams: 
[[  , baking, cake], [baking, cake, :], [cake, :,  ], [:,  , •], [ , •, training], [•, training, data], [training, data, ingredients], [data, ingredients,  ], [ingredients,  , •], [ , •, time], [•, time, temperature], [time, temperature, hyper], [temperature, hyper, -], [hyper, -, parameters], [-, parameters,  ]]

>> Noun Phrases are: 
[you, a cake, the ingredients, the hyper, -, parameters]

>> Named Entities are: 
[]


============================ Sentence 69 =============================

• the cake 


>> Tokens are: 
[•, cake] 

>> PoS Tags are: 
[('•', 'CCONJ'), ('cake', 'NOUN')] 

>> Dependency Tags are: 
[('•', 'ROOT'), ('cake', 'pobj')]

>> Bigrams: 
[[•, cake]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the cake]

>> Named Entities are: 
[]


============================ Sentence 70 =============================

would be the model   Lexalytics Hyper-Parameter Optimization Video  |  3:35   


>> Tokens are: 
[model,   , Lexalytics, Hyper, -, Parameter, Optimization, Video,  , |,  , 3:35,  ] 

>> PoS Tags are: 
[('model', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), ('Hyper', 'PROPN'), ('-', 'PROPN'), ('Parameter', 'PROPN'), ('Optimization', 'PROPN'), ('Video', 'PROPN'), (' ', 'SPACE'), ('|', 'NOUN'), (' ', 'SPACE'), ('3:35', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('model', 'attr'), ('  ', 'appos'), ('Lexalytics', 'compound'), ('Hyper', 'compound'), ('-', 'punct'), ('Parameter', 'compound'), ('Optimization', 'compound'), ('Video', 'appos'), (' ', 'appos'), ('|', 'npadvmod'), (' ', 'dep'), ('3:35', 'nummod'), (' ', 'punct')]

>> Bigrams: 
[[model,   ], [  , Lexalytics], [Lexalytics, Hyper], [Hyper, -], [-, Parameter], [Parameter, Optimization], [Optimization, Video], [Video,  ], [ , |], [|,  ], [ , 3:35], [3:35,  ]]

>> Trigrams: 
[[model,   , Lexalytics], [  , Lexalytics, Hyper], [Lexalytics, Hyper, -], [Hyper, -, Parameter], [-, Parameter, Optimization], [Parameter, Optimization, Video], [Optimization, Video,  ], [Video,  , |], [ , |,  ], [|,  , 3:35], [ , 3:35,  ]]

>> Noun Phrases are: 
[the model, Lexalytics Hyper-Parameter Optimization Video]

>> Named Entities are: 
[('3:35  ', 'TIME')]


============================ Sentence 71 =============================

Once the model is created (baked), we can run it against new data  to evaluate what it’s learned, and whether further adjustments   are needed. 


>> Tokens are: 
[model, created, (, baked, ), ,, run, new, data,  , evaluate, learned, ,, adjustments,   , needed, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('created', 'VERB'), ('(', 'PUNCT'), ('baked', 'ADJ'), (')', 'PUNCT'), (',', 'PUNCT'), ('run', 'VERB'), ('new', 'ADJ'), ('data', 'NOUN'), (' ', 'SPACE'), ('evaluate', 'VERB'), ('learned', 'VERB'), (',', 'PUNCT'), ('adjustments', 'NOUN'), ('  ', 'SPACE'), ('needed', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'nsubjpass'), ('created', 'advcl'), ('(', 'punct'), ('baked', 'parataxis'), (')', 'punct'), (',', 'punct'), ('run', 'ROOT'), ('new', 'amod'), ('data', 'pobj'), (' ', 'nsubj'), ('evaluate', 'relcl'), ('learned', 'ccomp'), (',', 'punct'), ('adjustments', 'nsubjpass'), ('  ', 'nsubjpass'), ('needed', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[model, created], [created, (], [(, baked], [baked, )], [), ,], [,, run], [run, new], [new, data], [data,  ], [ , evaluate], [evaluate, learned], [learned, ,], [,, adjustments], [adjustments,   ], [  , needed], [needed, .]]

>> Trigrams: 
[[model, created, (], [created, (, baked], [(, baked, )], [baked, ), ,], [), ,, run], [,, run, new], [run, new, data], [new, data,  ], [data,  , evaluate], [ , evaluate, learned], [evaluate, learned, ,], [learned, ,, adjustments], [,, adjustments,   ], [adjustments,   , needed], [  , needed, .]]

>> Noun Phrases are: 
[the model, we, it, new data, what, it, further adjustments]

>> Named Entities are: 
[]


============================ Sentence 72 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 73 =============================

However, making adjustments isn’t just a matter of writing a line   of code that tells the model what to do. 


>> Tokens are: 
[,, making, adjustments, matter, writing, line,   , code, tells, model, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('making', 'VERB'), ('adjustments', 'NOUN'), ('matter', 'NOUN'), ('writing', 'VERB'), ('line', 'NOUN'), ('  ', 'SPACE'), ('code', 'NOUN'), ('tells', 'VERB'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('making', 'csubj'), ('adjustments', 'dobj'), ('matter', 'attr'), ('writing', 'pcomp'), ('line', 'compound'), ('  ', 'dobj'), ('code', 'pobj'), ('tells', 'relcl'), ('model', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[,, making], [making, adjustments], [adjustments, matter], [matter, writing], [writing, line], [line,   ], [  , code], [code, tells], [tells, model], [model, .]]

>> Trigrams: 
[[,, making, adjustments], [making, adjustments, matter], [adjustments, matter, writing], [matter, writing, line], [writing, line,   ], [line,   , code], [  , code, tells], [code, tells, model], [tells, model, .]]

>> Noun Phrases are: 
[adjustments, just a matter, code, the model, what]

>> Named Entities are: 
[]


============================ Sentence 74 =============================

That kind of direct approach is  known as “algorithmic programming” – what most people call “coding.” 


>> Tokens are: 
[kind, direct, approach,  , known, “, algorithmic, programming, ”, –, people, “, coding, ., ”] 

>> PoS Tags are: 
[('kind', 'NOUN'), ('direct', 'ADJ'), ('approach', 'NOUN'), (' ', 'SPACE'), ('known', 'VERB'), ('“', 'PUNCT'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), ('”', 'PUNCT'), ('–', 'PUNCT'), ('people', 'NOUN'), ('“', 'PUNCT'), ('coding', 'VERB'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('kind', 'nsubjpass'), ('direct', 'amod'), ('approach', 'pobj'), (' ', 'nsubjpass'), ('known', 'ROOT'), ('“', 'punct'), ('algorithmic', 'amod'), ('programming', 'pobj'), ('”', 'punct'), ('–', 'punct'), ('people', 'nsubj'), ('“', 'punct'), ('coding', 'oprd'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[kind, direct], [direct, approach], [approach,  ], [ , known], [known, “], [“, algorithmic], [algorithmic, programming], [programming, ”], [”, –], [–, people], [people, “], [“, coding], [coding, .], [., ”]]

>> Trigrams: 
[[kind, direct, approach], [direct, approach,  ], [approach,  , known], [ , known, “], [known, “, algorithmic], [“, algorithmic, programming], [algorithmic, programming, ”], [programming, ”, –], [”, –, people], [–, people, “], [people, “, coding], [“, coding, .], [coding, ., ”]]

>> Noun Phrases are: 
[That kind, direct approach, algorithmic programming, what, most people]

>> Named Entities are: 
[]


============================ Sentence 75 =============================

  With machine learning, we need to convince the model that it wants to do   what we want it to do. 


>> Tokens are: 
[  , machine, learning, ,, need, convince, model, wants,   , want, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('need', 'VERB'), ('convince', 'VERB'), ('model', 'NOUN'), ('wants', 'VERB'), ('  ', 'SPACE'), ('want', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('machine', 'compound'), ('learning', 'pobj'), (',', 'punct'), ('need', 'ROOT'), ('convince', 'xcomp'), ('model', 'dobj'), ('wants', 'relcl'), ('  ', 'dobj'), ('want', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[  , machine], [machine, learning], [learning, ,], [,, need], [need, convince], [convince, model], [model, wants], [wants,   ], [  , want], [want, .]]

>> Trigrams: 
[[  , machine, learning], [machine, learning, ,], [learning, ,, need], [,, need, convince], [need, convince, model], [convince, model, wants], [model, wants,   ], [wants,   , want], [  , want, .]]

>> Noun Phrases are: 
[machine learning, we, the model, it, what, we, it]

>> Named Entities are: 
[]


============================ Sentence 76 =============================

  Writing a line of code is clearly the more precise, concise approach –   and one that’s going to almost certainly be less work than machine   learning. 


>> Tokens are: 
[  , Writing, line, code, clearly, precise, ,, concise, approach, –,   , going, certainly, work, machine,   , learning, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Writing', 'VERB'), ('line', 'NOUN'), ('code', 'NOUN'), ('clearly', 'ADV'), ('precise', 'ADJ'), (',', 'PUNCT'), ('concise', 'ADJ'), ('approach', 'NOUN'), ('–', 'PUNCT'), ('  ', 'SPACE'), ('going', 'VERB'), ('certainly', 'ADV'), ('work', 'NOUN'), ('machine', 'NOUN'), ('  ', 'SPACE'), ('learning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('Writing', 'csubj'), ('line', 'dobj'), ('code', 'pobj'), ('clearly', 'advmod'), ('precise', 'amod'), (',', 'punct'), ('concise', 'amod'), ('approach', 'attr'), ('–', 'punct'), ('  ', 'appos'), ('going', 'relcl'), ('certainly', 'advmod'), ('work', 'attr'), ('machine', 'compound'), ('  ', 'nsubj'), ('learning', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[  , Writing], [Writing, line], [line, code], [code, clearly], [clearly, precise], [precise, ,], [,, concise], [concise, approach], [approach, –], [–,   ], [  , going], [going, certainly], [certainly, work], [work, machine], [machine,   ], [  , learning], [learning, .]]

>> Trigrams: 
[[  , Writing, line], [Writing, line, code], [line, code, clearly], [code, clearly, precise], [clearly, precise, ,], [precise, ,, concise], [,, concise, approach], [concise, approach, –], [approach, –,   ], [–,   , going], [  , going, certainly], [going, certainly, work], [certainly, work, machine], [work, machine,   ], [machine,   , learning], [  , learning, .]]

>> Noun Phrases are: 
[a line, code, the more precise, concise approach, less work]

>> Named Entities are: 
[]


============================ Sentence 77 =============================

We talk about this in the white paper “Tune First, Then Train.”   


>> Tokens are: 
[talk, white, paper, “, Tune, ,, Train, ., ”,  ] 

>> PoS Tags are: 
[('talk', 'VERB'), ('white', 'ADJ'), ('paper', 'NOUN'), ('“', 'PUNCT'), ('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'PROPN'), ('.', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('talk', 'ROOT'), ('white', 'amod'), ('paper', 'pobj'), ('“', 'punct'), ('Tune', 'compound'), (',', 'punct'), ('Train', 'appos'), ('.', 'punct'), ('”', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[talk, white], [white, paper], [paper, “], [“, Tune], [Tune, ,], [,, Train], [Train, .], [., ”], [”,  ]]

>> Trigrams: 
[[talk, white, paper], [white, paper, “], [paper, “, Tune], [“, Tune, ,], [Tune, ,, Train], [,, Train, .], [Train, ., ”], [., ”,  ]]

>> Noun Phrases are: 
[We, the white paper, Tune First, Train]

>> Named Entities are: 
[('Tune First, Then Train', 'WORK_OF_ART')]


============================ Sentence 78 =============================

However, coding isn’t always the right solution. 


>> Tokens are: 
[,, coding, right, solution, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('coding', 'NOUN'), ('right', 'ADJ'), ('solution', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('coding', 'nsubj'), ('right', 'amod'), ('solution', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[,, coding], [coding, right], [right, solution], [solution, .]]

>> Trigrams: 
[[,, coding, right], [coding, right, solution], [right, solution, .]]

>> Noun Phrases are: 
[coding, the right solution]

>> Named Entities are: 
[]


============================ Sentence 79 =============================

Machine learning is   much better than coding at dealing with novel cases and learning   from the experience. 


>> Tokens are: 
[Machine, learning,   , better, coding, dealing, novel, cases, learning,   , experience, .] 

>> PoS Tags are: 
[('Machine', 'NOUN'), ('learning', 'NOUN'), ('  ', 'SPACE'), ('better', 'ADJ'), ('coding', 'VERB'), ('dealing', 'VERB'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('learning', 'VERB'), ('  ', 'SPACE'), ('experience', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Machine', 'compound'), ('learning', 'nsubj'), ('  ', 'attr'), ('better', 'acomp'), ('coding', 'pcomp'), ('dealing', 'pcomp'), ('novel', 'amod'), ('cases', 'pobj'), ('learning', 'conj'), ('  ', 'dobj'), ('experience', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Machine, learning], [learning,   ], [  , better], [better, coding], [coding, dealing], [dealing, novel], [novel, cases], [cases, learning], [learning,   ], [  , experience], [experience, .]]

>> Trigrams: 
[[Machine, learning,   ], [learning,   , better], [  , better, coding], [better, coding, dealing], [coding, dealing, novel], [dealing, novel, cases], [novel, cases, learning], [cases, learning,   ], [learning,   , experience], [  , experience, .]]

>> Noun Phrases are: 
[Machine learning, novel cases, the experience]

>> Named Entities are: 
[]


============================ Sentence 80 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 81 =============================

In the next section we’ll review the main classes of machine learning. 


>> Tokens are: 
[section, review, main, classes, machine, learning, .] 

>> PoS Tags are: 
[('section', 'NOUN'), ('review', 'VERB'), ('main', 'ADJ'), ('classes', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('section', 'pobj'), ('review', 'ROOT'), ('main', 'amod'), ('classes', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[section, review], [review, main], [main, classes], [classes, machine], [machine, learning], [learning, .]]

>> Trigrams: 
[[section, review, main], [review, main, classes], [main, classes, machine], [classes, machine, learning], [machine, learning, .]]

>> Noun Phrases are: 
[the next section, we, the main classes, machine learning]

>> Named Entities are: 
[]


============================ Sentence 82 =============================

 is simply a matter of writing    a line of code that tells the    model what to do. 


>> Tokens are: 
[ , simply, matter, writing,    , line, code, tells,    , model, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('simply', 'ADV'), ('matter', 'NOUN'), ('writing', 'VERB'), ('   ', 'SPACE'), ('line', 'NOUN'), ('code', 'NOUN'), ('tells', 'VERB'), ('   ', 'SPACE'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('simply', 'advmod'), ('matter', 'attr'), ('writing', 'pcomp'), ('   ', 'dative'), ('line', 'dobj'), ('code', 'pobj'), ('tells', 'relcl'), ('   ', 'compound'), ('model', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , simply], [simply, matter], [matter, writing], [writing,    ], [   , line], [line, code], [code, tells], [tells,    ], [   , model], [model, .]]

>> Trigrams: 
[[ , simply, matter], [simply, matter, writing], [matter, writing,    ], [writing,    , line], [   , line, code], [line, code, tells], [code, tells,    ], [tells,    , model], [   , model, .]]

>> Noun Phrases are: 
[a matter, a line, code, the    model, what]

>> Named Entities are: 
[]


============================ Sentence 83 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 84 =============================

Algorithmic  programming  https://www.lexalytics.com/ https://www.lexalytics.com/ 


>> Tokens are: 
[Algorithmic,  , programming,  , https://www.lexalytics.com/, https://www.lexalytics.com/] 

>> PoS Tags are: 
[('Algorithmic', 'ADJ'), (' ', 'SPACE'), ('programming', 'NOUN'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN')] 

>> Dependency Tags are: 
[('Algorithmic', 'amod'), (' ', 'nsubj'), ('programming', 'nmod'), (' ', 'dobj'), ('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT')]

>> Bigrams: 
[[Algorithmic,  ], [ , programming], [programming,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/]]

>> Trigrams: 
[[Algorithmic,  , programming], [ , programming,  ], [programming,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/]]

>> Noun Phrases are: 
[Algorithmic  programming  https://www.lexalytics.com/ https://www.lexalytics.com/]

>> Named Entities are: 
[]


============================ Sentence 85 =============================

https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf   W H 


>> Tokens are: 
[https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf,   , W, H] 

>> PoS Tags are: 
[('https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ', 'NUM'), ('https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf', 'PROPN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ', 'ROOT'), ('https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf', 'compound'), ('  ', 'npadvmod'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf], [https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf,   ], [  , W], [W, H]]

>> Trigrams: 
[[https://www.lexalytics.com/resources/videos?id=EeTkMc1o1uQ, https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf,   ], [https://www.lexalytics.com/resources/wp-content/uploads/sites/3/2019/02/Lexalytics_Tune_First_Then_Train_Whitepaper.pdf,   , W], [  , W, H]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 86 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 87 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 88 =============================

P A P E R  5|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 5|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('5|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'appos'), ('5|', 'nummod'), ('      ', 'ROOT'), ('|', 'npadvmod'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 5|], [5|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 5|], [ , 5|,       ], [5|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[  Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 89 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 90 =============================

  |   1-800-377-8036 |   www.lexalytics.com  means feeding a    machine learning model    an annotated dataset. 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  , means, feeding,    , machine, learning, model,    , annotated, dataset, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE'), ('means', 'VERB'), ('feeding', 'VERB'), ('   ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('   ', 'SPACE'), ('annotated', 'ADJ'), ('dataset', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'nsubj'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'npadvmod'), ('means', 'ROOT'), ('feeding', 'xcomp'), ('   ', 'nummod'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'dobj'), ('   ', 'nummod'), ('annotated', 'amod'), ('dataset', 'appos'), ('.', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ], [ , means], [means, feeding], [feeding,    ], [   , machine], [machine, learning], [learning, model], [model,    ], [   , annotated], [annotated, dataset], [dataset, .]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ], [www.lexalytics.com,  , means], [ , means, feeding], [means, feeding,    ], [feeding,    , machine], [   , machine, learning], [machine, learning, model], [learning, model,    ], [model,    , annotated], [   , annotated, dataset], [annotated, dataset, .]]

>> Noun Phrases are: 
[377-8036 |, a    machine learning model, an annotated dataset]

>> Named Entities are: 
[]


============================ Sentence 91 =============================

 Supervised  learning   


>> Tokens are: 
[ , Supervised,  , learning,  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Supervised', 'VERB'), (' ', 'SPACE'), ('learning', 'VERB'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('Supervised', 'ROOT'), (' ', 'dobj'), ('learning', 'advcl'), (' ', 'punct')]

>> Bigrams: 
[[ , Supervised], [Supervised,  ], [ , learning], [learning,  ]]

>> Trigrams: 
[[ , Supervised,  ], [Supervised,  , learning], [ , learning,  ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 92 =============================

S U P E R V I S E D ,  U N S 


>> Tokens are: 
[S, U, P, E, R, V, S, E, D, ,,  , U, N, S] 

>> PoS Tags are: 
[('S', 'NOUN'), ('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), ('D', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('U', 'NOUN'), ('N', 'PROPN'), ('S', 'PROPN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'compound'), ('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), (',', 'punct'), (' ', 'punct'), ('U', 'compound'), ('N', 'compound'), ('S', 'appos')]

>> Bigrams: 
[[S, U], [U, P], [P, E], [E, R], [R, V], [V, S], [S, E], [E, D], [D, ,], [,,  ], [ , U], [U, N], [N, S]]

>> Trigrams: 
[[S, U, P], [U, P, E], [P, E, R], [E, R, V], [R, V, S], [V, S, E], [S, E, D], [E, D, ,], [D, ,,  ], [,,  , U], [ , U, N], [U, N, S]]

>> Noun Phrases are: 
[S U P E R V I S E D, U N S]

>> Named Entities are: 
[('U N S', 'ORG')]


============================ Sentence 93 =============================

U P E R V I S E D ,   A N D   


>> Tokens are: 
[U, P, E, R, V, S, E, D, ,,   , N, D,  ] 

>> PoS Tags are: 
[('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), ('D', 'PROPN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('N', 'PROPN'), ('D', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'compound'), ('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), (',', 'punct'), ('  ', 'appos'), ('N', 'nmod'), ('D', 'appos'), (' ', 'punct')]

>> Bigrams: 
[[U, P], [P, E], [E, R], [R, V], [V, S], [S, E], [E, D], [D, ,], [,,   ], [  , N], [N, D], [D,  ]]

>> Trigrams: 
[[U, P, E], [P, E, R], [E, R, V], [R, V, S], [V, S, E], [S, E, D], [E, D, ,], [D, ,,   ], [,,   , N], [  , N, D], [N, D,  ]]

>> Noun Phrases are: 
[U P E R V I S E D, A N D]

>> Named Entities are: 
[]


============================ Sentence 94 =============================

S E M I - S U P E R V 


>> Tokens are: 
[S, E, M, -, S, U, P, E, R, V] 

>> PoS Tags are: 
[('S', 'PROPN'), ('E', 'NOUN'), ('M', 'NOUN'), ('-', 'PUNCT'), ('S', 'PROPN'), ('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('E', 'compound'), ('M', 'compound'), ('-', 'punct'), ('S', 'compound'), ('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'ROOT')]

>> Bigrams: 
[[S, E], [E, M], [M, -], [-, S], [S, U], [U, P], [P, E], [E, R], [R, V]]

>> Trigrams: 
[[S, E, M], [E, M, -], [M, -, S], [-, S, U], [S, U, P], [U, P, E], [P, E, R], [E, R, V]]

>> Noun Phrases are: 
[S E M I - S U P E R V]

>> Named Entities are: 
[]


============================ Sentence 95 =============================

I S E D   M A 


>> Tokens are: 
[S, E, D,   , M] 

>> PoS Tags are: 
[('S', 'PROPN'), ('E', 'NOUN'), ('D', 'NOUN'), ('  ', 'SPACE'), ('M', 'NOUN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), ('  ', 'compound'), ('M', 'compound')]

>> Bigrams: 
[[S, E], [E, D], [D,   ], [  , M]]

>> Trigrams: 
[[S, E, D], [E, D,   ], [D,   , M]]

>> Noun Phrases are: 
[I S E D,   M A]

>> Named Entities are: 
[]


============================ Sentence 96 =============================

C H 


>> Tokens are: 
[C, H] 

>> PoS Tags are: 
[('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[C, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[C H]

>> Named Entities are: 
[]


============================ Sentence 97 =============================

I N E  L E 


>> Tokens are: 
[N, E,  , L, E] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('L', 'NOUN'), ('E', 'PROPN')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[N, E], [E,  ], [ , L], [L, E]]

>> Trigrams: 
[[N, E,  ], [E,  , L], [ , L, E]]

>> Noun Phrases are: 
[I, N, E, L E]

>> Named Entities are: 
[]


============================ Sentence 98 =============================

A R N I N G   


>> Tokens are: 
[R, N, N, G,  ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), (' ', 'appos')]

>> Bigrams: 
[[R, N], [N, N], [N, G], [G,  ]]

>> Trigrams: 
[[R, N, N], [N, N, G], [N, G,  ]]

>> Noun Phrases are: 
[A R N I, N G]

>> Named Entities are: 
[]


============================ Sentence 99 =============================

There are three relevant classes of machine learning: supervised learning,  unsupervised learning, and semi-supervised learning. 


>> Tokens are: 
[relevant, classes, machine, learning, :, supervised, learning, ,,  , unsupervised, learning, ,, semi, -, supervised, learning, .] 

>> PoS Tags are: 
[('relevant', 'ADJ'), ('classes', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), (':', 'PUNCT'), ('supervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), ('semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('relevant', 'amod'), ('classes', 'attr'), ('machine', 'compound'), ('learning', 'pobj'), (':', 'punct'), ('supervised', 'amod'), ('learning', 'appos'), (',', 'punct'), (' ', 'nmod'), ('unsupervised', 'amod'), ('learning', 'conj'), (',', 'punct'), ('semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[relevant, classes], [classes, machine], [machine, learning], [learning, :], [:, supervised], [supervised, learning], [learning, ,], [,,  ], [ , unsupervised], [unsupervised, learning], [learning, ,], [,, semi], [semi, -], [-, supervised], [supervised, learning], [learning, .]]

>> Trigrams: 
[[relevant, classes, machine], [classes, machine, learning], [machine, learning, :], [learning, :, supervised], [:, supervised, learning], [supervised, learning, ,], [learning, ,,  ], [,,  , unsupervised], [ , unsupervised, learning], [unsupervised, learning, ,], [learning, ,, semi], [,, semi, -], [semi, -, supervised], [-, supervised, learning], [supervised, learning, .]]

>> Noun Phrases are: 
[three relevant classes, machine learning, supervised learning,  unsupervised learning, semi-supervised learning]

>> Named Entities are: 
[('three', 'CARDINAL')]


============================ Sentence 100 =============================

Lexalytics uses all  three depending on the problem we’re trying to solve.   


>> Tokens are: 
[Lexalytics, uses,  , depending, problem, trying, solve, .,  ] 

>> PoS Tags are: 
[('Lexalytics', 'NOUN'), ('uses', 'VERB'), (' ', 'SPACE'), ('depending', 'VERB'), ('problem', 'NOUN'), ('trying', 'VERB'), ('solve', 'VERB'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('uses', 'ROOT'), (' ', 'dobj'), ('depending', 'xcomp'), ('problem', 'pobj'), ('trying', 'relcl'), ('solve', 'xcomp'), ('.', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[Lexalytics, uses], [uses,  ], [ , depending], [depending, problem], [problem, trying], [trying, solve], [solve, .], [.,  ]]

>> Trigrams: 
[[Lexalytics, uses,  ], [uses,  , depending], [ , depending, problem], [depending, problem, trying], [problem, trying, solve], [trying, solve, .], [solve, .,  ]]

>> Noun Phrases are: 
[Lexalytics, the problem, we]

>> Named Entities are: 
[('three', 'CARDINAL')]


============================ Sentence 101 =============================

Supervised learning   Supervised learning means feeding a machine learning model a dataset   that has been annotated in some way. 


>> Tokens are: 
[Supervised, learning,   , Supervised, learning, means, feeding, machine, learning, model, dataset,   , annotated, way, .] 

>> PoS Tags are: 
[('Supervised', 'VERB'), ('learning', 'VERB'), ('  ', 'SPACE'), ('Supervised', 'ADJ'), ('learning', 'NOUN'), ('means', 'VERB'), ('feeding', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('dataset', 'NOUN'), ('  ', 'SPACE'), ('annotated', 'VERB'), ('way', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Supervised', 'amod'), ('learning', 'csubj'), ('  ', 'det'), ('Supervised', 'amod'), ('learning', 'dobj'), ('means', 'ROOT'), ('feeding', 'xcomp'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'dobj'), ('dataset', 'compound'), ('  ', 'dobj'), ('annotated', 'relcl'), ('way', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Supervised, learning], [learning,   ], [  , Supervised], [Supervised, learning], [learning, means], [means, feeding], [feeding, machine], [machine, learning], [learning, model], [model, dataset], [dataset,   ], [  , annotated], [annotated, way], [way, .]]

>> Trigrams: 
[[Supervised, learning,   ], [learning,   , Supervised], [  , Supervised, learning], [Supervised, learning, means], [learning, means, feeding], [means, feeding, machine], [feeding, machine, learning], [machine, learning, model], [learning, model, dataset], [model, dataset,   ], [dataset,   , annotated], [  , annotated, way], [annotated, way, .]]

>> Noun Phrases are: 
[  Supervised learning, a machine learning model, some way]

>> Named Entities are: 
[]


============================ Sentence 102 =============================

For example, we might collect 10,000  customer support comments and mark them up based on which are  related to software and which are related to hardware. 


>> Tokens are: 
[example, ,, collect, 10,000,  , customer, support, comments, mark, based,  , related, software, related, hardware, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('collect', 'VERB'), ('10,000', 'NUM'), (' ', 'SPACE'), ('customer', 'NOUN'), ('support', 'NOUN'), ('comments', 'NOUN'), ('mark', 'VERB'), ('based', 'VERB'), (' ', 'SPACE'), ('related', 'VERB'), ('software', 'NOUN'), ('related', 'VERB'), ('hardware', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('collect', 'ROOT'), ('10,000', 'nummod'), (' ', 'compound'), ('customer', 'compound'), ('support', 'compound'), ('comments', 'dobj'), ('mark', 'conj'), ('based', 'prep'), (' ', 'nsubjpass'), ('related', 'acomp'), ('software', 'pobj'), ('related', 'conj'), ('hardware', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, collect], [collect, 10,000], [10,000,  ], [ , customer], [customer, support], [support, comments], [comments, mark], [mark, based], [based,  ], [ , related], [related, software], [software, related], [related, hardware], [hardware, .]]

>> Trigrams: 
[[example, ,, collect], [,, collect, 10,000], [collect, 10,000,  ], [10,000,  , customer], [ , customer, support], [customer, support, comments], [support, comments, mark], [comments, mark, based], [mark, based,  ], [based,  , related], [ , related, software], [related, software, related], [software, related, hardware], [related, hardware, .]]

>> Noun Phrases are: 
[example, we, 10,000  customer support comments, them, software, hardware]

>> Named Entities are: 
[('10,000', 'CARDINAL')]


============================ Sentence 103 =============================

In doing so, we’re  showing the machine what information it needs to evaluate each comment. 


>> Tokens are: 
[,,  , showing, machine, information, needs, evaluate, comment, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), (' ', 'SPACE'), ('showing', 'VERB'), ('machine', 'NOUN'), ('information', 'NOUN'), ('needs', 'VERB'), ('evaluate', 'VERB'), ('comment', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), (' ', 'dep'), ('showing', 'ROOT'), ('machine', 'dobj'), ('information', 'dobj'), ('needs', 'relcl'), ('evaluate', 'xcomp'), ('comment', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[,,  ], [ , showing], [showing, machine], [machine, information], [information, needs], [needs, evaluate], [evaluate, comment], [comment, .]]

>> Trigrams: 
[[,,  , showing], [ , showing, machine], [showing, machine, information], [machine, information, needs], [information, needs, evaluate], [needs, evaluate, comment], [evaluate, comment, .]]

>> Noun Phrases are: 
[we, the machine, what information, it, each comment]

>> Named Entities are: 
[]


============================ Sentence 104 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 105 =============================

This is the most direct way of teaching a model what you want it to do. 


>> Tokens are: 
[direct, way, teaching, model, want, .] 

>> PoS Tags are: 
[('direct', 'ADJ'), ('way', 'NOUN'), ('teaching', 'VERB'), ('model', 'NOUN'), ('want', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('direct', 'amod'), ('way', 'attr'), ('teaching', 'pcomp'), ('model', 'dobj'), ('want', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[direct, way], [way, teaching], [teaching, model], [model, want], [want, .]]

>> Trigrams: 
[[direct, way, teaching], [way, teaching, model], [teaching, model, want], [model, want, .]]

>> Noun Phrases are: 
[the most direct way, a model, what, you, it]

>> Named Entities are: 
[]


============================ Sentence 106 =============================

It’s  also the most work. 


>> Tokens are: 
[ , work, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('work', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('work', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[ , work], [work, .]]

>> Trigrams: 
[[ , work, .]]

>> Noun Phrases are: 
[It, also the most work]

>> Named Entities are: 
[]


============================ Sentence 107 =============================

At Lexalytics, we use supervised learning for NLP tasks  like sentiment analysis and for certain methods of categorization. 


>> Tokens are: 
[Lexalytics, ,, use, supervised, learning, NLP, tasks,  , like, sentiment, analysis, certain, methods, categorization, .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('use', 'VERB'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('NLP', 'PROPN'), ('tasks', 'NOUN'), (' ', 'SPACE'), ('like', 'ADP'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('certain', 'ADJ'), ('methods', 'NOUN'), ('categorization', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'pobj'), (',', 'punct'), ('use', 'ROOT'), ('supervised', 'amod'), ('learning', 'dobj'), ('NLP', 'compound'), ('tasks', 'pobj'), (' ', 'dobj'), ('like', 'prep'), ('sentiment', 'compound'), ('analysis', 'pobj'), ('certain', 'amod'), ('methods', 'pobj'), ('categorization', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, ,], [,, use], [use, supervised], [supervised, learning], [learning, NLP], [NLP, tasks], [tasks,  ], [ , like], [like, sentiment], [sentiment, analysis], [analysis, certain], [certain, methods], [methods, categorization], [categorization, .]]

>> Trigrams: 
[[Lexalytics, ,, use], [,, use, supervised], [use, supervised, learning], [supervised, learning, NLP], [learning, NLP, tasks], [NLP, tasks,  ], [tasks,  , like], [ , like, sentiment], [like, sentiment, analysis], [sentiment, analysis, certain], [analysis, certain, methods], [certain, methods, categorization], [methods, categorization, .]]

>> Noun Phrases are: 
[Lexalytics, we, supervised learning, NLP tasks, sentiment analysis, certain methods, categorization]

>> Named Entities are: 
[('Lexalytics', 'ORG'), ('NLP', 'ORG')]


============================ Sentence 108 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 109 =============================

For example, we train sentiment analysis models on hand-scored examples  because the perspective of the sentiment analysis can change based on  context. 


>> Tokens are: 
[example, ,, train, sentiment, analysis, models, hand, -, scored, examples,  , perspective, sentiment, analysis, change, based,  , context, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('train', 'VERB'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('models', 'NOUN'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('scored', 'VERB'), ('examples', 'NOUN'), (' ', 'SPACE'), ('perspective', 'NOUN'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('change', 'VERB'), ('based', 'VERB'), (' ', 'SPACE'), ('context', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('train', 'ROOT'), ('sentiment', 'compound'), ('analysis', 'compound'), ('models', 'dobj'), ('hand', 'npadvmod'), ('-', 'punct'), ('scored', 'amod'), ('examples', 'pobj'), (' ', 'dobj'), ('perspective', 'nsubj'), ('sentiment', 'compound'), ('analysis', 'pobj'), ('change', 'advcl'), ('based', 'prep'), (' ', 'compound'), ('context', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, train], [train, sentiment], [sentiment, analysis], [analysis, models], [models, hand], [hand, -], [-, scored], [scored, examples], [examples,  ], [ , perspective], [perspective, sentiment], [sentiment, analysis], [analysis, change], [change, based], [based,  ], [ , context], [context, .]]

>> Trigrams: 
[[example, ,, train], [,, train, sentiment], [train, sentiment, analysis], [sentiment, analysis, models], [analysis, models, hand], [models, hand, -], [hand, -, scored], [-, scored, examples], [scored, examples,  ], [examples,  , perspective], [ , perspective, sentiment], [perspective, sentiment, analysis], [sentiment, analysis, change], [analysis, change, based], [change, based,  ], [based,  , context], [ , context, .]]

>> Noun Phrases are: 
[example, we, sentiment analysis models, hand-scored examples, the perspective, the sentiment analysis,  context]

>> Named Entities are: 
[]


============================ Sentence 110 =============================

Consider the following:  “SuperBank lost US$100,000,000 last month.” 


>> Tokens are: 
[Consider, following, :,  , “, SuperBank, lost, US$, 100,000,000, month, ., ”] 

>> PoS Tags are: 
[('Consider', 'VERB'), ('following', 'NOUN'), (':', 'PUNCT'), (' ', 'SPACE'), ('“', 'PUNCT'), ('SuperBank', 'PROPN'), ('lost', 'VERB'), ('US$', 'SYM'), ('100,000,000', 'NUM'), ('month', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Consider', 'ROOT'), ('following', 'dobj'), (':', 'punct'), (' ', 'appos'), ('“', 'punct'), ('SuperBank', 'nsubj'), ('lost', 'ccomp'), ('US$', 'nmod'), ('100,000,000', 'dobj'), ('month', 'npadvmod'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Consider, following], [following, :], [:,  ], [ , “], [“, SuperBank], [SuperBank, lost], [lost, US$], [US$, 100,000,000], [100,000,000, month], [month, .], [., ”]]

>> Trigrams: 
[[Consider, following, :], [following, :,  ], [:,  , “], [ , “, SuperBank], [“, SuperBank, lost], [SuperBank, lost, US$], [lost, US$, 100,000,000], [US$, 100,000,000, month], [100,000,000, month, .], [month, ., ”]]

>> Noun Phrases are: 
[the following, SuperBank]

>> Named Entities are: 
[('SuperBank', 'ORG'), ('100,000,000', 'MONEY'), ('last month', 'DATE')]


============================ Sentence 111 =============================

 Well, were they expected to lose US$200,000,000? US$50,000,000? 


>> Tokens are: 
[ , ,, expected, lose, US$, 200,000,000, ?, US$, 50,000,000, ?] 

>> PoS Tags are: 
[(' ', 'SPACE'), (',', 'PUNCT'), ('expected', 'VERB'), ('lose', 'VERB'), ('US$', 'SYM'), ('200,000,000', 'NUM'), ('?', 'PUNCT'), ('US$', 'SYM'), ('50,000,000', 'NUM'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'dep'), (',', 'punct'), ('expected', 'ROOT'), ('lose', 'xcomp'), ('US$', 'nmod'), ('200,000,000', 'dobj'), ('?', 'punct'), ('US$', 'nmod'), ('50,000,000', 'dobj'), ('?', 'punct')]

>> Bigrams: 
[[ , ,], [,, expected], [expected, lose], [lose, US$], [US$, 200,000,000], [200,000,000, ?], [?, US$], [US$, 50,000,000], [50,000,000, ?]]

>> Trigrams: 
[[ , ,, expected], [,, expected, lose], [expected, lose, US$], [lose, US$, 200,000,000], [US$, 200,000,000, ?], [200,000,000, ?, US$], [?, US$, 50,000,000], [US$, 50,000,000, ?]]

>> Noun Phrases are: 
[they]

>> Named Entities are: 
[('US$200,000,000', 'MONEY'), ('50,000,000', 'MONEY')]


============================ Sentence 112 =============================

The  sentiment of this statement very much depends on who is looking at it. 


>> Tokens are: 
[ , sentiment, statement, depends, looking, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('sentiment', 'NOUN'), ('statement', 'NOUN'), ('depends', 'VERB'), ('looking', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('sentiment', 'nsubj'), ('statement', 'pobj'), ('depends', 'ROOT'), ('looking', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[ , sentiment], [sentiment, statement], [statement, depends], [depends, looking], [looking, .]]

>> Trigrams: 
[[ , sentiment, statement], [sentiment, statement, depends], [statement, depends, looking], [depends, looking, .]]

>> Noun Phrases are: 
[The  sentiment, this statement, who, it]

>> Named Entities are: 
[]


============================ Sentence 113 =============================

  Another example would be “This perfume smells like my grandmother.” 


>> Tokens are: 
[  , example, “, perfume, smells, like, grandmother, ., ”] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('example', 'NOUN'), ('“', 'PUNCT'), ('perfume', 'NOUN'), ('smells', 'VERB'), ('like', 'ADP'), ('grandmother', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nmod'), ('example', 'nsubj'), ('“', 'punct'), ('perfume', 'nsubj'), ('smells', 'ccomp'), ('like', 'prep'), ('grandmother', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[  , example], [example, “], [“, perfume], [perfume, smells], [smells, like], [like, grandmother], [grandmother, .], [., ”]]

>> Trigrams: 
[[  , example, “], [example, “, perfume], [“, perfume, smells], [perfume, smells, like], [smells, like, grandmother], [like, grandmother, .], [grandmother, ., ”]]

>> Noun Phrases are: 
[  Another example, This perfume, my grandmother]

>> Named Entities are: 
[]


============================ Sentence 114 =============================

  Do you love your grandmother? 


>> Tokens are: 
[  , love, grandmother, ?] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('love', 'VERB'), ('grandmother', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('love', 'ROOT'), ('grandmother', 'dobj'), ('?', 'punct')]

>> Bigrams: 
[[  , love], [love, grandmother], [grandmother, ?]]

>> Trigrams: 
[[  , love, grandmother], [love, grandmother, ?]]

>> Noun Phrases are: 
[you, your grandmother]

>> Named Entities are: 
[]


============================ Sentence 115 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 116 =============================

Ultimately, any extraction that requires that the machine understand   your perspective needs to be supervised somehow, and this requires   lots of work. 


>> Tokens are: 
[Ultimately, ,, extraction, requires, machine, understand,   , perspective, needs, supervised, ,, requires,   , lots, work, .] 

>> PoS Tags are: 
[('Ultimately', 'ADV'), (',', 'PUNCT'), ('extraction', 'NOUN'), ('requires', 'VERB'), ('machine', 'NOUN'), ('understand', 'VERB'), ('  ', 'SPACE'), ('perspective', 'NOUN'), ('needs', 'VERB'), ('supervised', 'VERB'), (',', 'PUNCT'), ('requires', 'VERB'), ('  ', 'SPACE'), ('lots', 'NOUN'), ('work', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Ultimately', 'advmod'), (',', 'punct'), ('extraction', 'nsubj'), ('requires', 'relcl'), ('machine', 'nsubj'), ('understand', 'ccomp'), ('  ', 'dobj'), ('perspective', 'nsubj'), ('needs', 'ccomp'), ('supervised', 'xcomp'), (',', 'punct'), ('requires', 'ROOT'), ('  ', 'dative'), ('lots', 'dobj'), ('work', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Ultimately, ,], [,, extraction], [extraction, requires], [requires, machine], [machine, understand], [understand,   ], [  , perspective], [perspective, needs], [needs, supervised], [supervised, ,], [,, requires], [requires,   ], [  , lots], [lots, work], [work, .]]

>> Trigrams: 
[[Ultimately, ,, extraction], [,, extraction, requires], [extraction, requires, machine], [requires, machine, understand], [machine, understand,   ], [understand,   , perspective], [  , perspective, needs], [perspective, needs, supervised], [needs, supervised, ,], [supervised, ,, requires], [,, requires,   ], [requires,   , lots], [  , lots, work], [lots, work, .]]

>> Noun Phrases are: 
[any extraction, the machine, your perspective, lots, work]

>> Named Entities are: 
[]


============================ Sentence 117 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 118 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/    


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   ] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/]

>> Named Entities are: 
[]


============================ Sentence 119 =============================

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[]


============================ Sentence 120 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 121 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 122 =============================

P A P E R   


>> Tokens are: 
[P, P, E, R,  ] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'compound'), (' ', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 123 =============================

6|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[6|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('6|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('6|', 'quantmod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[6|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[6|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[6|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 124 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 125 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 126 =============================

Unsupervised learning   


>> Tokens are: 
[Unsupervised, learning,  ] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('learning', 'VERB'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('learning', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[Unsupervised, learning], [learning,  ]]

>> Trigrams: 
[[Unsupervised, learning,  ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 127 =============================

Unsupervised learning is where we hand the machine a whole bunch  of content and tell it to find the patterns. 


>> Tokens are: 
[Unsupervised, learning, hand, machine, bunch,  , content, tell, find, patterns, .] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('learning', 'NOUN'), ('hand', 'VERB'), ('machine', 'NOUN'), ('bunch', 'NOUN'), (' ', 'SPACE'), ('content', 'NOUN'), ('tell', 'VERB'), ('find', 'VERB'), ('patterns', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('learning', 'nsubj'), ('hand', 'ccomp'), ('machine', 'dobj'), ('bunch', 'dobj'), (' ', 'appos'), ('content', 'pobj'), ('tell', 'conj'), ('find', 'xcomp'), ('patterns', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Unsupervised, learning], [learning, hand], [hand, machine], [machine, bunch], [bunch,  ], [ , content], [content, tell], [tell, find], [find, patterns], [patterns, .]]

>> Trigrams: 
[[Unsupervised, learning, hand], [learning, hand, machine], [hand, machine, bunch], [machine, bunch,  ], [bunch,  , content], [ , content, tell], [content, tell, find], [tell, find, patterns], [find, patterns, .]]

>> Noun Phrases are: 
[Unsupervised learning, we, the machine, a whole bunch, content, it, the patterns]

>> Named Entities are: 
[]


============================ Sentence 128 =============================

This is how we built the syntax parser in Salience: We took 40GB of text and had the parser analyze every  sentence to understand how subjects and verbs fit together. 


>> Tokens are: 
[built, syntax, parser, Salience, :, took, 40, GB, text, parser, analyze,  , sentence, understand, subjects, verbs, fit, .] 

>> PoS Tags are: 
[('built', 'VERB'), ('syntax', 'NOUN'), ('parser', 'NOUN'), ('Salience', 'PROPN'), (':', 'PUNCT'), ('took', 'VERB'), ('40', 'NUM'), ('GB', 'PROPN'), ('text', 'NOUN'), ('parser', 'NOUN'), ('analyze', 'VERB'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('understand', 'VERB'), ('subjects', 'NOUN'), ('verbs', 'NOUN'), ('fit', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('built', 'ccomp'), ('syntax', 'compound'), ('parser', 'dobj'), ('Salience', 'pobj'), (':', 'punct'), ('took', 'ROOT'), ('40', 'nummod'), ('GB', 'dobj'), ('text', 'pobj'), ('parser', 'nsubj'), ('analyze', 'ccomp'), (' ', 'compound'), ('sentence', 'nsubj'), ('understand', 'ccomp'), ('subjects', 'nsubj'), ('verbs', 'conj'), ('fit', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[built, syntax], [syntax, parser], [parser, Salience], [Salience, :], [:, took], [took, 40], [40, GB], [GB, text], [text, parser], [parser, analyze], [analyze,  ], [ , sentence], [sentence, understand], [understand, subjects], [subjects, verbs], [verbs, fit], [fit, .]]

>> Trigrams: 
[[built, syntax, parser], [syntax, parser, Salience], [parser, Salience, :], [Salience, :, took], [:, took, 40], [took, 40, GB], [40, GB, text], [GB, text, parser], [text, parser, analyze], [parser, analyze,  ], [analyze,  , sentence], [ , sentence, understand], [sentence, understand, subjects], [understand, subjects, verbs], [subjects, verbs, fit], [verbs, fit, .]]

>> Noun Phrases are: 
[we, the syntax parser, Salience, We, 40GB, text, the parser, every  sentence, subjects, verbs]

>> Named Entities are: 
[('Salience', 'PERSON')]


============================ Sentence 129 =============================

Consider   the following:   “I threw the ball over the mountain.” 


>> Tokens are: 
[Consider,   , following, :,   , “, threw, ball, mountain, ., ”] 

>> PoS Tags are: 
[('Consider', 'VERB'), ('  ', 'SPACE'), ('following', 'VERB'), (':', 'PUNCT'), ('  ', 'SPACE'), ('“', 'PUNCT'), ('threw', 'VERB'), ('ball', 'NOUN'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Consider', 'ROOT'), ('  ', 'dobj'), ('following', 'dobj'), (':', 'punct'), ('  ', 'dep'), ('“', 'punct'), ('threw', 'ccomp'), ('ball', 'dobj'), ('mountain', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Consider,   ], [  , following], [following, :], [:,   ], [  , “], [“, threw], [threw, ball], [ball, mountain], [mountain, .], [., ”]]

>> Trigrams: 
[[Consider,   , following], [  , following, :], [following, :,   ], [:,   , “], [  , “, threw], [“, threw, ball], [threw, ball, mountain], [ball, mountain, .], [mountain, ., ”]]

>> Noun Phrases are: 
[I, the ball, the mountain]

>> Named Entities are: 
[]


============================ Sentence 130 =============================

 One way to understand syntax is to parse the entire sentence, like   you’re doing a sentence diagram from 6th grade. 


>> Tokens are: 
[ , way, understand, syntax, parse, entire, sentence, ,, like,   , sentence, diagram, 6th, grade, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('way', 'NOUN'), ('understand', 'VERB'), ('syntax', 'NOUN'), ('parse', 'VERB'), ('entire', 'ADJ'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('diagram', 'NOUN'), ('6th', 'ADJ'), ('grade', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'dep'), ('way', 'nsubj'), ('understand', 'relcl'), ('syntax', 'dobj'), ('parse', 'xcomp'), ('entire', 'amod'), ('sentence', 'dobj'), (',', 'punct'), ('like', 'prep'), ('  ', 'pobj'), ('sentence', 'compound'), ('diagram', 'dobj'), ('6th', 'amod'), ('grade', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , way], [way, understand], [understand, syntax], [syntax, parse], [parse, entire], [entire, sentence], [sentence, ,], [,, like], [like,   ], [  , sentence], [sentence, diagram], [diagram, 6th], [6th, grade], [grade, .]]

>> Trigrams: 
[[ , way, understand], [way, understand, syntax], [understand, syntax, parse], [syntax, parse, entire], [parse, entire, sentence], [entire, sentence, ,], [sentence, ,, like], [,, like,   ], [like,   , sentence], [  , sentence, diagram], [sentence, diagram, 6th], [diagram, 6th, grade], [6th, grade, .]]

>> Noun Phrases are: 
[One way, syntax, the entire sentence, you, a sentence diagram, 6th grade]

>> Named Entities are: 
[('One', 'CARDINAL'), ('6th', 'ORDINAL')]


============================ Sentence 131 =============================

Those are quite  computationally intensive (along with being irritating for 6th graders),    


>> Tokens are: 
[ , computationally, intensive, (, irritating, 6th, graders, ), ,,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('computationally', 'ADV'), ('intensive', 'ADJ'), ('(', 'PUNCT'), ('irritating', 'VERB'), ('6th', 'ADJ'), ('graders', 'NOUN'), (')', 'PUNCT'), (',', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('computationally', 'advmod'), ('intensive', 'amod'), ('(', 'punct'), ('irritating', 'pcomp'), ('6th', 'amod'), ('graders', 'pobj'), (')', 'punct'), (',', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[ , computationally], [computationally, intensive], [intensive, (], [(, irritating], [irritating, 6th], [6th, graders], [graders, )], [), ,], [,,   ]]

>> Trigrams: 
[[ , computationally, intensive], [computationally, intensive, (], [intensive, (, irritating], [(, irritating, 6th], [irritating, 6th, graders], [6th, graders, )], [graders, ), ,], [), ,,   ]]

>> Noun Phrases are: 
[6th graders]

>> Named Entities are: 
[('6th', 'ORDINAL')]


============================ Sentence 132 =============================

and so you can’t do that for high-volume content – it just takes too long  for each document to process. 


>> Tokens are: 
[high, -, volume, content, –, takes, long,  , document, process, .] 

>> PoS Tags are: 
[('high', 'ADJ'), ('-', 'PUNCT'), ('volume', 'NOUN'), ('content', 'NOUN'), ('–', 'PUNCT'), ('takes', 'VERB'), ('long', 'ADJ'), (' ', 'SPACE'), ('document', 'NOUN'), ('process', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('high', 'amod'), ('-', 'punct'), ('volume', 'compound'), ('content', 'pobj'), ('–', 'punct'), ('takes', 'ROOT'), ('long', 'amod'), (' ', 'dobj'), ('document', 'pobj'), ('process', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[high, -], [-, volume], [volume, content], [content, –], [–, takes], [takes, long], [long,  ], [ , document], [document, process], [process, .]]

>> Trigrams: 
[[high, -, volume], [-, volume, content], [volume, content, –], [content, –, takes], [–, takes, long], [takes, long,  ], [long,  , document], [ , document, process], [document, process, .]]

>> Noun Phrases are: 
[you, high-volume content, it, each document]

>> Named Entities are: 
[]


============================ Sentence 133 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 134 =============================

But what if you were to process a bunch of content ahead of time to  come up with a set of relationships that shows how words like “ball,”  “threw” and “mountain” were typically related across millions and billions of  sentences. 


>> Tokens are: 
[process, bunch, content, ahead, time,  , come, set, relationships, shows, words, like, “, ball, ,, ”,  , “, threw, ”, “, mountain, ”, typically, related, millions, billions,  , sentences, .] 

>> PoS Tags are: 
[('process', 'VERB'), ('bunch', 'NOUN'), ('content', 'NOUN'), ('ahead', 'ADV'), ('time', 'NOUN'), (' ', 'SPACE'), ('come', 'VERB'), ('set', 'NOUN'), ('relationships', 'NOUN'), ('shows', 'VERB'), ('words', 'NOUN'), ('like', 'ADP'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('”', 'PUNCT'), ('typically', 'ADV'), ('related', 'VERB'), ('millions', 'NOUN'), ('billions', 'NOUN'), (' ', 'SPACE'), ('sentences', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('process', 'xcomp'), ('bunch', 'dobj'), ('content', 'pobj'), ('ahead', 'advmod'), ('time', 'pobj'), (' ', 'pobj'), ('come', 'advcl'), ('set', 'pobj'), ('relationships', 'pobj'), ('shows', 'relcl'), ('words', 'nsubj'), ('like', 'prep'), ('“', 'punct'), ('ball', 'pobj'), (',', 'punct'), ('”', 'punct'), (' ', 'appos'), ('“', 'punct'), ('threw', 'ccomp'), ('”', 'punct'), ('“', 'punct'), ('mountain', 'conj'), ('”', 'punct'), ('typically', 'advmod'), ('related', 'ROOT'), ('millions', 'pobj'), ('billions', 'conj'), (' ', 'compound'), ('sentences', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[process, bunch], [bunch, content], [content, ahead], [ahead, time], [time,  ], [ , come], [come, set], [set, relationships], [relationships, shows], [shows, words], [words, like], [like, “], [“, ball], [ball, ,], [,, ”], [”,  ], [ , “], [“, threw], [threw, ”], [”, “], [“, mountain], [mountain, ”], [”, typically], [typically, related], [related, millions], [millions, billions], [billions,  ], [ , sentences], [sentences, .]]

>> Trigrams: 
[[process, bunch, content], [bunch, content, ahead], [content, ahead, time], [ahead, time,  ], [time,  , come], [ , come, set], [come, set, relationships], [set, relationships, shows], [relationships, shows, words], [shows, words, like], [words, like, “], [like, “, ball], [“, ball, ,], [ball, ,, ”], [,, ”,  ], [”,  , “], [ , “, threw], [“, threw, ”], [threw, ”, “], [”, “, mountain], [“, mountain, ”], [mountain, ”, typically], [”, typically, related], [typically, related, millions], [related, millions, billions], [millions, billions,  ], [billions,  , sentences], [ , sentences, .]]

>> Noun Phrases are: 
[you, a bunch, content, time, a set, relationships, words, “ball, millions, billions,  sentences]

>> Named Entities are: 
[('millions and billions', 'MONEY')]


============================ Sentence 135 =============================

  As a human, you naturally know that it is far more likely that “threw”   is acting on “ball,” than it is likely that “threw” is acting on “mountain.” 


>> Tokens are: 
[  , human, ,, naturally, know, far, likely, “, threw, ”,   , acting, “, ball, ,, ”, likely, “, threw, ”, acting, “, mountain, ., ”] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('human', 'NOUN'), (',', 'PUNCT'), ('naturally', 'ADV'), ('know', 'VERB'), ('far', 'ADV'), ('likely', 'ADJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('  ', 'SPACE'), ('acting', 'VERB'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('likely', 'ADJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('acting', 'VERB'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('human', 'pobj'), (',', 'punct'), ('naturally', 'advmod'), ('know', 'ROOT'), ('far', 'advmod'), ('likely', 'acomp'), ('“', 'punct'), ('threw', 'nsubj'), ('”', 'punct'), ('  ', 'dobj'), ('acting', 'ccomp'), ('“', 'punct'), ('ball', 'pobj'), (',', 'punct'), ('”', 'punct'), ('likely', 'acomp'), ('“', 'punct'), ('threw', 'nsubj'), ('”', 'punct'), ('acting', 'ccomp'), ('“', 'punct'), ('mountain', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[  , human], [human, ,], [,, naturally], [naturally, know], [know, far], [far, likely], [likely, “], [“, threw], [threw, ”], [”,   ], [  , acting], [acting, “], [“, ball], [ball, ,], [,, ”], [”, likely], [likely, “], [“, threw], [threw, ”], [”, acting], [acting, “], [“, mountain], [mountain, .], [., ”]]

>> Trigrams: 
[[  , human, ,], [human, ,, naturally], [,, naturally, know], [naturally, know, far], [know, far, likely], [far, likely, “], [likely, “, threw], [“, threw, ”], [threw, ”,   ], [”,   , acting], [  , acting, “], [acting, “, ball], [“, ball, ,], [ball, ,, ”], [,, ”, likely], [”, likely, “], [likely, “, threw], [“, threw, ”], [threw, ”, acting], [”, acting, “], [acting, “, mountain], [“, mountain, .], [mountain, ., ”]]

>> Noun Phrases are: 
[a human, you, it, ball, it, mountain]

>> Named Entities are: 
[]


============================ Sentence 136 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 137 =============================

You don’t throw mountains, you throw balls. 


>> Tokens are: 
[throw, mountains, ,, throw, balls, .] 

>> PoS Tags are: 
[('throw', 'VERB'), ('mountains', 'NOUN'), (',', 'PUNCT'), ('throw', 'VERB'), ('balls', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('throw', 'ccomp'), ('mountains', 'dobj'), (',', 'punct'), ('throw', 'ROOT'), ('balls', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[throw, mountains], [mountains, ,], [,, throw], [throw, balls], [balls, .]]

>> Trigrams: 
[[throw, mountains, ,], [mountains, ,, throw], [,, throw, balls], [throw, balls, .]]

>> Noun Phrases are: 
[You, mountains, you, balls]

>> Named Entities are: 
[]


============================ Sentence 138 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 139 =============================

That sort of probabilistic relationship can be extracted using unsupervised  learning. 


>> Tokens are: 
[sort, probabilistic, relationship, extracted, unsupervised,  , learning, .] 

>> PoS Tags are: 
[('sort', 'NOUN'), ('probabilistic', 'ADJ'), ('relationship', 'NOUN'), ('extracted', 'VERB'), ('unsupervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('sort', 'nsubjpass'), ('probabilistic', 'amod'), ('relationship', 'pobj'), ('extracted', 'ROOT'), ('unsupervised', 'amod'), (' ', 'compound'), ('learning', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[sort, probabilistic], [probabilistic, relationship], [relationship, extracted], [extracted, unsupervised], [unsupervised,  ], [ , learning], [learning, .]]

>> Trigrams: 
[[sort, probabilistic, relationship], [probabilistic, relationship, extracted], [relationship, extracted, unsupervised], [extracted, unsupervised,  ], [unsupervised,  , learning], [ , learning, .]]

>> Noun Phrases are: 
[That sort, probabilistic relationship, unsupervised  learning]

>> Named Entities are: 
[]


============================ Sentence 140 =============================

The syntax matrix was an excellent candidate for unsupervised  learning, as it involved discovering generally applicable patterns from a very  large corpus of content. 


>> Tokens are: 
[syntax, matrix, excellent, candidate, unsupervised,  , learning, ,, involved, discovering, generally, applicable, patterns,  , large, corpus, content, .] 

>> PoS Tags are: 
[('syntax', 'NOUN'), ('matrix', 'NOUN'), ('excellent', 'ADJ'), ('candidate', 'NOUN'), ('unsupervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'NOUN'), (',', 'PUNCT'), ('involved', 'VERB'), ('discovering', 'VERB'), ('generally', 'ADV'), ('applicable', 'ADJ'), ('patterns', 'NOUN'), (' ', 'SPACE'), ('large', 'ADJ'), ('corpus', 'NOUN'), ('content', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('syntax', 'compound'), ('matrix', 'nsubj'), ('excellent', 'amod'), ('candidate', 'attr'), ('unsupervised', 'amod'), (' ', 'compound'), ('learning', 'pobj'), (',', 'punct'), ('involved', 'advcl'), ('discovering', 'xcomp'), ('generally', 'advmod'), ('applicable', 'amod'), ('patterns', 'dobj'), (' ', 'nmod'), ('large', 'amod'), ('corpus', 'pobj'), ('content', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[syntax, matrix], [matrix, excellent], [excellent, candidate], [candidate, unsupervised], [unsupervised,  ], [ , learning], [learning, ,], [,, involved], [involved, discovering], [discovering, generally], [generally, applicable], [applicable, patterns], [patterns,  ], [ , large], [large, corpus], [corpus, content], [content, .]]

>> Trigrams: 
[[syntax, matrix, excellent], [matrix, excellent, candidate], [excellent, candidate, unsupervised], [candidate, unsupervised,  ], [unsupervised,  , learning], [ , learning, ,], [learning, ,, involved], [,, involved, discovering], [involved, discovering, generally], [discovering, generally, applicable], [generally, applicable, patterns], [applicable, patterns,  ], [patterns,  , large], [ , large, corpus], [large, corpus, content], [corpus, content, .]]

>> Noun Phrases are: 
[The syntax matrix, an excellent candidate, unsupervised  learning, it, generally applicable patterns, a very  large corpus, content]

>> Named Entities are: 
[]


============================ Sentence 141 =============================

Because it is a matrix, it can be evaluated really fast  for each sentence, unlike a full parser. 


>> Tokens are: 
[matrix, ,, evaluated, fast,  , sentence, ,, unlike, parser, .] 

>> PoS Tags are: 
[('matrix', 'NOUN'), (',', 'PUNCT'), ('evaluated', 'VERB'), ('fast', 'ADJ'), (' ', 'SPACE'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('unlike', 'ADP'), ('parser', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('matrix', 'attr'), (',', 'punct'), ('evaluated', 'ROOT'), ('fast', 'amod'), (' ', 'dobj'), ('sentence', 'pobj'), (',', 'punct'), ('unlike', 'prep'), ('parser', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[matrix, ,], [,, evaluated], [evaluated, fast], [fast,  ], [ , sentence], [sentence, ,], [,, unlike], [unlike, parser], [parser, .]]

>> Trigrams: 
[[matrix, ,, evaluated], [,, evaluated, fast], [evaluated, fast,  ], [fast,  , sentence], [ , sentence, ,], [sentence, ,, unlike], [,, unlike, parser], [unlike, parser, .]]

>> Noun Phrases are: 
[it, a matrix, it, each sentence, a full parser]

>> Named Entities are: 
[]


============================ Sentence 142 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 143 =============================

As the amount of content created every day grows exponentially,  unsupervised techniques become more and more valuable. 


>> Tokens are: 
[content, created, day, grows, exponentially, ,,  , unsupervised, techniques, valuable, .] 

>> PoS Tags are: 
[('content', 'NOUN'), ('created', 'VERB'), ('day', 'NOUN'), ('grows', 'VERB'), ('exponentially', 'ADV'), (',', 'PUNCT'), (' ', 'SPACE'), ('unsupervised', 'ADJ'), ('techniques', 'NOUN'), ('valuable', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('content', 'pobj'), ('created', 'acl'), ('day', 'npadvmod'), ('grows', 'advcl'), ('exponentially', 'advmod'), (',', 'punct'), (' ', 'nmod'), ('unsupervised', 'amod'), ('techniques', 'nsubj'), ('valuable', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[content, created], [created, day], [day, grows], [grows, exponentially], [exponentially, ,], [,,  ], [ , unsupervised], [unsupervised, techniques], [techniques, valuable], [valuable, .]]

>> Trigrams: 
[[content, created, day], [created, day, grows], [day, grows, exponentially], [grows, exponentially, ,], [exponentially, ,,  ], [,,  , unsupervised], [ , unsupervised, techniques], [unsupervised, techniques, valuable], [techniques, valuable, .]]

>> Noun Phrases are: 
[the amount, content,  unsupervised techniques]

>> Named Entities are: 
[('every day', 'DATE')]


============================ Sentence 144 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 145 =============================

Semi-supervised learning   


>> Tokens are: 
[Semi, -, supervised, learning,  ] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised, learning], [learning,  ]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised, learning], [supervised, learning,  ]]

>> Noun Phrases are: 
[Semi-supervised learning]

>> Named Entities are: 
[]


============================ Sentence 146 =============================

Semi-supervised learning is a combination of unsupervised and supervised  learning techniques. 


>> Tokens are: 
[Semi, -, supervised, learning, combination, unsupervised, supervised,  , learning, techniques, .] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('combination', 'NOUN'), ('unsupervised', 'ADJ'), ('supervised', 'VERB'), (' ', 'SPACE'), ('learning', 'VERB'), ('techniques', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'nsubj'), ('combination', 'attr'), ('unsupervised', 'pobj'), ('supervised', 'conj'), (' ', 'dobj'), ('learning', 'xcomp'), ('techniques', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised, learning], [learning, combination], [combination, unsupervised], [unsupervised, supervised], [supervised,  ], [ , learning], [learning, techniques], [techniques, .]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised, learning], [supervised, learning, combination], [learning, combination, unsupervised], [combination, unsupervised, supervised], [unsupervised, supervised,  ], [supervised,  , learning], [ , learning, techniques], [learning, techniques, .]]

>> Noun Phrases are: 
[Semi-supervised learning, a combination, techniques]

>> Named Entities are: 
[]


============================ Sentence 147 =============================

With this approach we’ll have both marked-up  supervised content and un-marked data. 


>> Tokens are: 
[approach, marked, -,  , supervised, content, un, -, marked, data, .] 

>> PoS Tags are: 
[('approach', 'NOUN'), ('marked', 'VERB'), ('-', 'PUNCT'), (' ', 'SPACE'), ('supervised', 'ADJ'), ('content', 'NOUN'), ('un', 'ADJ'), ('-', 'ADJ'), ('marked', 'ADJ'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('approach', 'pobj'), ('marked', 'amod'), ('-', 'punct'), (' ', 'nmod'), ('supervised', 'amod'), ('content', 'dobj'), ('un', 'amod'), ('-', 'punct'), ('marked', 'amod'), ('data', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[approach, marked], [marked, -], [-,  ], [ , supervised], [supervised, content], [content, un], [un, -], [-, marked], [marked, data], [data, .]]

>> Trigrams: 
[[approach, marked, -], [marked, -,  ], [-,  , supervised], [ , supervised, content], [supervised, content, un], [content, un, -], [un, -, marked], [-, marked, data], [marked, data, .]]

>> Noun Phrases are: 
[this approach, we, both marked-up  supervised content, un-marked data]

>> Named Entities are: 
[]


============================ Sentence 148 =============================

The machine learning model   uses the marked-up content to generalize and make assertions about   the rest of the data. 


>> Tokens are: 
[machine, learning, model,   , uses, marked, -, content, generalize, assertions,   , rest, data, .] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('  ', 'SPACE'), ('uses', 'VERB'), ('marked', 'VERB'), ('-', 'PUNCT'), ('content', 'NOUN'), ('generalize', 'VERB'), ('assertions', 'NOUN'), ('  ', 'SPACE'), ('rest', 'NOUN'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('  ', 'nsubj'), ('uses', 'ROOT'), ('marked', 'amod'), ('-', 'punct'), ('content', 'dobj'), ('generalize', 'acl'), ('assertions', 'dobj'), ('  ', 'pobj'), ('rest', 'dobj'), ('data', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[machine, learning], [learning, model], [model,   ], [  , uses], [uses, marked], [marked, -], [-, content], [content, generalize], [generalize, assertions], [assertions,   ], [  , rest], [rest, data], [data, .]]

>> Trigrams: 
[[machine, learning, model], [learning, model,   ], [model,   , uses], [  , uses, marked], [uses, marked, -], [marked, -, content], [-, content, generalize], [content, generalize, assertions], [generalize, assertions,   ], [assertions,   , rest], [  , rest, data], [rest, data, .]]

>> Noun Phrases are: 
[The machine learning model, the marked-up content, assertions, the rest, the data]

>> Named Entities are: 
[]


============================ Sentence 149 =============================

  Now that we’ve reviewed the machine learning essentials, let’s look at  how to combine machine learning and algorithmic natural language  processing to build a high-performing text analytics AI. 


>> Tokens are: 
[  , reviewed, machine, learning, essentials, ,, let, look,  , combine, machine, learning, algorithmic, natural, language,  , processing, build, high, -, performing, text, analytics, AI, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('reviewed', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('essentials', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('look', 'VERB'), (' ', 'SPACE'), ('combine', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithmic', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), (' ', 'SPACE'), ('processing', 'NOUN'), ('build', 'VERB'), ('high', 'ADV'), ('-', 'PUNCT'), ('performing', 'VERB'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('AI', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('reviewed', 'ROOT'), ('machine', 'compound'), ('learning', 'compound'), ('essentials', 'dobj'), (',', 'punct'), ('let', 'conj'), ('look', 'ccomp'), (' ', 'pobj'), ('combine', 'advcl'), ('machine', 'compound'), ('learning', 'dobj'), ('algorithmic', 'amod'), ('natural', 'amod'), ('language', 'conj'), (' ', 'compound'), ('processing', 'advcl'), ('build', 'advcl'), ('high', 'advmod'), ('-', 'punct'), ('performing', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('AI', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[  , reviewed], [reviewed, machine], [machine, learning], [learning, essentials], [essentials, ,], [,, let], [let, look], [look,  ], [ , combine], [combine, machine], [machine, learning], [learning, algorithmic], [algorithmic, natural], [natural, language], [language,  ], [ , processing], [processing, build], [build, high], [high, -], [-, performing], [performing, text], [text, analytics], [analytics, AI], [AI, .]]

>> Trigrams: 
[[  , reviewed, machine], [reviewed, machine, learning], [machine, learning, essentials], [learning, essentials, ,], [essentials, ,, let], [,, let, look], [let, look,  ], [look,  , combine], [ , combine, machine], [combine, machine, learning], [machine, learning, algorithmic], [learning, algorithmic, natural], [algorithmic, natural, language], [natural, language,  ], [language,  , processing], [ , processing, build], [processing, build, high], [build, high, -], [high, -, performing], [-, performing, text], [performing, text, analytics], [text, analytics, AI], [analytics, AI, .]]

>> Noun Phrases are: 
[we, the machine learning essentials, ’s, machine learning, algorithmic natural language, a high-performing text analytics AI]

>> Named Entities are: 
[('AI', 'ORG')]


============================ Sentence 150 =============================

 is the combination    of unsupervised and   supervised learning. 


>> Tokens are: 
[ , combination,    , unsupervised,   , supervised, learning, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('combination', 'NOUN'), ('   ', 'SPACE'), ('unsupervised', 'ADJ'), ('  ', 'SPACE'), ('supervised', 'VERB'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('combination', 'attr'), ('   ', 'appos'), ('unsupervised', 'pcomp'), ('  ', 'nsubj'), ('supervised', 'amod'), ('learning', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[ , combination], [combination,    ], [   , unsupervised], [unsupervised,   ], [  , supervised], [supervised, learning], [learning, .]]

>> Trigrams: 
[[ , combination,    ], [combination,    , unsupervised], [   , unsupervised,   ], [unsupervised,   , supervised], [  , supervised, learning], [supervised, learning, .]]

>> Noun Phrases are: 
[the combination,   supervised learning]

>> Named Entities are: 
[]


============================ Sentence 151 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 152 =============================

Semi-supervised  learning  is where the machine    takes content and is told to   find patterns within it. 


>> Tokens are: 
[Semi, -, supervised,  , learning,  , machine,    , takes, content, told,   , find, patterns, .] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'VERB'), ('supervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'VERB'), (' ', 'SPACE'), ('machine', 'NOUN'), ('   ', 'SPACE'), ('takes', 'VERB'), ('content', 'NOUN'), ('told', 'VERB'), ('  ', 'SPACE'), ('find', 'VERB'), ('patterns', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Semi', 'advmod'), ('-', 'amod'), ('supervised', 'csubj'), (' ', 'nsubj'), ('learning', 'advcl'), (' ', 'dobj'), ('machine', 'nsubj'), ('   ', 'appos'), ('takes', 'ccomp'), ('content', 'dobj'), ('told', 'conj'), ('  ', 'pobj'), ('find', 'conj'), ('patterns', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised,  ], [ , learning], [learning,  ], [ , machine], [machine,    ], [   , takes], [takes, content], [content, told], [told,   ], [  , find], [find, patterns], [patterns, .]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised,  ], [supervised,  , learning], [ , learning,  ], [learning,  , machine], [ , machine,    ], [machine,    , takes], [   , takes, content], [takes, content, told], [content, told,   ], [told,   , find], [  , find, patterns], [find, patterns, .]]

>> Noun Phrases are: 
[the machine, content, patterns, it]

>> Named Entities are: 
[]


============================ Sentence 153 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 154 =============================

Unsupervised  learning  https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[Unsupervised,  , learning,  , https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('Unsupervised', 'VERB'), (' ', 'SPACE'), ('learning', 'VERB'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('Unsupervised', 'nmod'), (' ', 'appos'), ('learning', 'advcl'), (' ', 'dobj'), ('https://www.lexalytics.com/', 'appos'), ('https://www.lexalytics.com/', 'nsubj'), ('  ', 'ROOT'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[Unsupervised,  ], [ , learning], [learning,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[Unsupervised,  , learning], [ , learning,  ], [learning,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[https://www.lexalytics.com/]

>> Named Entities are: 
[]


============================ Sentence 155 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 156 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 157 =============================

P A P E R  7|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 7|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('7|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'appos'), ('7|', 'appos'), ('      ', 'appos'), ('|', 'appos'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 7|], [7|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 7|], [ , 7|,       ], [7|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[|, 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 158 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 159 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 160 =============================

H A P P I E R  B Y  T H 


>> Tokens are: 
[H, P, P, E, R,  , B, Y,  , T, H] 

>> PoS Tags are: 
[('H', 'NOUN'), ('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('B', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('H', 'compound'), ('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('Y', 'nmod'), (' ', 'appos'), ('T', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[H, P], [P, P], [P, E], [E, R], [R,  ], [ , B], [B, Y], [Y,  ], [ , T], [T, H]]

>> Trigrams: 
[[H, P, P], [P, P, E], [P, E, R], [E, R,  ], [R,  , B], [ , B, Y], [B, Y,  ], [Y,  , T], [ , T, H]]

>> Noun Phrases are: 
[H A P P I E R  B Y  T H]

>> Named Entities are: 
[('H A P P I E R', 'ORG')]


============================ Sentence 161 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 162 =============================

D O Z E N :   T H 


>> Tokens are: 
[D, O, Z, E, N, :,   , T, H] 

>> PoS Tags are: 
[('D', 'NOUN'), ('O', 'NOUN'), ('Z', 'NOUN'), ('E', 'NOUN'), ('N', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'compound'), ('O', 'compound'), ('Z', 'compound'), ('E', 'ROOT'), ('N', 'appos'), (':', 'punct'), ('  ', 'compound'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[D, O], [O, Z], [Z, E], [E, N], [N, :], [:,   ], [  , T], [T, H]]

>> Trigrams: 
[[D, O, Z], [O, Z, E], [Z, E, N], [E, N, :], [N, :,   ], [:,   , T], [  , T, H]]

>> Noun Phrases are: 
[D O Z E, N,   T H]

>> Named Entities are: 
[]


============================ Sentence 163 =============================

E  M O R E  M O D E L S ,  T H 


>> Tokens are: 
[E,  , M, O, R, E,  , M, O, D, E, L, S, ,,  , T, H] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('M', 'NOUN'), ('O', 'NOUN'), ('R', 'NOUN'), ('E', 'NOUN'), (' ', 'SPACE'), ('M', 'NOUN'), ('O', 'NOUN'), ('D', 'NOUN'), ('E', 'NOUN'), ('L', 'PROPN'), ('S', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'compound'), (' ', 'compound'), ('M', 'compound'), ('O', 'compound'), ('R', 'nmod'), ('E', 'nmod'), (' ', 'appos'), ('M', 'compound'), ('O', 'compound'), ('D', 'compound'), ('E', 'compound'), ('L', 'compound'), ('S', 'ROOT'), (',', 'punct'), (' ', 'appos'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[E,  ], [ , M], [M, O], [O, R], [R, E], [E,  ], [ , M], [M, O], [O, D], [D, E], [E, L], [L, S], [S, ,], [,,  ], [ , T], [T, H]]

>> Trigrams: 
[[E,  , M], [ , M, O], [M, O, R], [O, R, E], [R, E,  ], [E,  , M], [ , M, O], [M, O, D], [O, D, E], [D, E, L], [E, L, S], [L, S, ,], [S, ,,  ], [,,  , T], [ , T, H]]

>> Noun Phrases are: 
[E  M O R E  M O D E L S, T H]

>> Named Entities are: 
[]


============================ Sentence 164 =============================

E  M E R R I E R  Machine learning models are very good at performing single tasks, such   as determining the sentiment polarity of a document or the part-of-speech  for a given word. 


>> Tokens are: 
[E,  , M, E, R, R, E, R,  , Machine, learning, models, good, performing, single, tasks, ,,   , determining, sentiment, polarity, document, -, -, speech,  , given, word, .] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('M', 'PROPN'), ('E', 'NOUN'), ('R', 'NOUN'), ('R', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('good', 'ADJ'), ('performing', 'VERB'), ('single', 'ADJ'), ('tasks', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('determining', 'VERB'), ('sentiment', 'NOUN'), ('polarity', 'NOUN'), ('document', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('speech', 'NOUN'), (' ', 'SPACE'), ('given', 'VERB'), ('word', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'compound'), ('M', 'compound'), ('E', 'compound'), ('R', 'compound'), ('R', 'compound'), ('E', 'nmod'), ('R', 'compound'), (' ', 'nmod'), ('Machine', 'compound'), ('learning', 'compound'), ('models', 'nsubj'), ('good', 'acomp'), ('performing', 'pcomp'), ('single', 'amod'), ('tasks', 'dobj'), (',', 'punct'), ('  ', 'npadvmod'), ('determining', 'pcomp'), ('sentiment', 'compound'), ('polarity', 'dobj'), ('document', 'pobj'), ('-', 'punct'), ('-', 'punct'), ('speech', 'pobj'), (' ', 'dobj'), ('given', 'amod'), ('word', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[E,  ], [ , M], [M, E], [E, R], [R, R], [R, E], [E, R], [R,  ], [ , Machine], [Machine, learning], [learning, models], [models, good], [good, performing], [performing, single], [single, tasks], [tasks, ,], [,,   ], [  , determining], [determining, sentiment], [sentiment, polarity], [polarity, document], [document, -], [-, -], [-, speech], [speech,  ], [ , given], [given, word], [word, .]]

>> Trigrams: 
[[E,  , M], [ , M, E], [M, E, R], [E, R, R], [R, R, E], [R, E, R], [E, R,  ], [R,  , Machine], [ , Machine, learning], [Machine, learning, models], [learning, models, good], [models, good, performing], [good, performing, single], [performing, single, tasks], [single, tasks, ,], [tasks, ,,   ], [,,   , determining], [  , determining, sentiment], [determining, sentiment, polarity], [sentiment, polarity, document], [polarity, document, -], [document, -, -], [-, -, speech], [-, speech,  ], [speech,  , given], [ , given, word], [given, word, .]]

>> Noun Phrases are: 
[E  M E R R I E R  Machine learning models, single tasks, the sentiment polarity, a document, speech, a given word]

>> Named Entities are: 
[]


============================ Sentence 165 =============================

However, models are not good at tasks that require layers  of interpretation. 


>> Tokens are: 
[,, models, good, tasks, require, layers,  , interpretation, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('models', 'NOUN'), ('good', 'ADJ'), ('tasks', 'NOUN'), ('require', 'VERB'), ('layers', 'NOUN'), (' ', 'SPACE'), ('interpretation', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('models', 'nsubj'), ('good', 'acomp'), ('tasks', 'pobj'), ('require', 'relcl'), ('layers', 'dobj'), (' ', 'dobj'), ('interpretation', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, models], [models, good], [good, tasks], [tasks, require], [require, layers], [layers,  ], [ , interpretation], [interpretation, .]]

>> Trigrams: 
[[,, models, good], [models, good, tasks], [good, tasks, require], [tasks, require, layers], [require, layers,  ], [layers,  , interpretation], [ , interpretation, .]]

>> Noun Phrases are: 
[models, tasks, layers, interpretation]

>> Named Entities are: 
[]


============================ Sentence 166 =============================

Take the following sentence:  “Lexalytics is the best text analytics company ever.” 


>> Tokens are: 
[following, sentence, :,  , “, Lexalytics, best, text, analytics, company, ., ”] 

>> PoS Tags are: 
[('following', 'ADJ'), ('sentence', 'NOUN'), (':', 'PUNCT'), (' ', 'SPACE'), ('“', 'PUNCT'), ('Lexalytics', 'PROPN'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('following', 'amod'), ('sentence', 'dobj'), (':', 'punct'), (' ', 'attr'), ('“', 'punct'), ('Lexalytics', 'nsubj'), ('best', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('company', 'attr'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[following, sentence], [sentence, :], [:,  ], [ , “], [“, Lexalytics], [Lexalytics, best], [best, text], [text, analytics], [analytics, company], [company, .], [., ”]]

>> Trigrams: 
[[following, sentence, :], [sentence, :,  ], [:,  , “], [ , “, Lexalytics], [“, Lexalytics, best], [Lexalytics, best, text], [best, text, analytics], [text, analytics, company], [analytics, company, .], [company, ., ”]]

>> Noun Phrases are: 
[the following sentence, Lexalytics, the best text analytics company]

>> Named Entities are: 
[('Lexalytics', 'WORK_OF_ART')]


============================ Sentence 167 =============================

  Besides agreeing with its obvious truth, what might we want to know   about this sentence? 


>> Tokens are: 
[  , agreeing, obvious, truth, ,, want, know,   , sentence, ?] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('agreeing', 'VERB'), ('obvious', 'ADJ'), ('truth', 'NOUN'), (',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('agreeing', 'pcomp'), ('obvious', 'amod'), ('truth', 'pobj'), (',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('  ', 'dobj'), ('sentence', 'pobj'), ('?', 'punct')]

>> Bigrams: 
[[  , agreeing], [agreeing, obvious], [obvious, truth], [truth, ,], [,, want], [want, know], [know,   ], [  , sentence], [sentence, ?]]

>> Trigrams: 
[[  , agreeing, obvious], [agreeing, obvious, truth], [obvious, truth, ,], [truth, ,, want], [,, want, know], [want, know,   ], [know,   , sentence], [  , sentence, ?]]

>> Noun Phrases are: 
[its obvious truth, what, we, this sentence]

>> Named Entities are: 
[]


============================ Sentence 168 =============================

First, we want to know whether it contains any   entities (companies, people, products and so on). 


>> Tokens are: 
[,, want, know, contains,   , entities, (, companies, ,, people, ,, products, ), .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('contains', 'VERB'), ('  ', 'SPACE'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('companies', 'NOUN'), (',', 'PUNCT'), ('people', 'NOUN'), (',', 'PUNCT'), ('products', 'NOUN'), (')', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('contains', 'ccomp'), ('  ', 'compound'), ('entities', 'dobj'), ('(', 'punct'), ('companies', 'appos'), (',', 'punct'), ('people', 'conj'), (',', 'punct'), ('products', 'conj'), (')', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[,, want], [want, know], [know, contains], [contains,   ], [  , entities], [entities, (], [(, companies], [companies, ,], [,, people], [people, ,], [,, products], [products, )], [), .]]

>> Trigrams: 
[[,, want, know], [want, know, contains], [know, contains,   ], [contains,   , entities], [  , entities, (], [entities, (, companies], [(, companies, ,], [companies, ,, people], [,, people, ,], [people, ,, products], [,, products, )], [products, ), .]]

>> Noun Phrases are: 
[we, it, any   entities, companies, people, products]

>> Named Entities are: 
[('First', 'ORDINAL')]


============================ Sentence 169 =============================

Second, we want to   know whether there’s any sentiment associated with those entities. 


>> Tokens are: 
[Second, ,, want,   , know, sentiment, associated, entities, .] 

>> PoS Tags are: 
[('Second', 'ADV'), (',', 'PUNCT'), ('want', 'VERB'), ('  ', 'SPACE'), ('know', 'VERB'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('entities', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Second', 'advmod'), (',', 'punct'), ('want', 'ROOT'), ('  ', 'pobj'), ('know', 'ccomp'), ('sentiment', 'attr'), ('associated', 'acl'), ('entities', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Second, ,], [,, want], [want,   ], [  , know], [know, sentiment], [sentiment, associated], [associated, entities], [entities, .]]

>> Trigrams: 
[[Second, ,, want], [,, want,   ], [want,   , know], [  , know, sentiment], [know, sentiment, associated], [sentiment, associated, entities], [associated, entities, .]]

>> Noun Phrases are: 
[we, any sentiment, those entities]

>> Named Entities are: 
[('Second', 'ORDINAL')]


============================ Sentence 170 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 171 =============================

Third, we want to know whether a particular industry is being discussed. 


>> Tokens are: 
[,, want, know, particular, industry, discussed, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('particular', 'ADJ'), ('industry', 'NOUN'), ('discussed', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('particular', 'amod'), ('industry', 'nsubjpass'), ('discussed', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[,, want], [want, know], [know, particular], [particular, industry], [industry, discussed], [discussed, .]]

>> Trigrams: 
[[,, want, know], [want, know, particular], [know, particular, industry], [particular, industry, discussed], [industry, discussed, .]]

>> Noun Phrases are: 
[we, a particular industry]

>> Named Entities are: 
[('Third', 'ORDINAL')]


============================ Sentence 172 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 173 =============================

Finally, we might ask whether any sentiment is being expressed   towards that industry. 


>> Tokens are: 
[Finally, ,, ask, sentiment, expressed,   , industry, .] 

>> PoS Tags are: 
[('Finally', 'ADV'), (',', 'PUNCT'), ('ask', 'VERB'), ('sentiment', 'NOUN'), ('expressed', 'VERB'), ('  ', 'SPACE'), ('industry', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Finally', 'advmod'), (',', 'punct'), ('ask', 'ROOT'), ('sentiment', 'nsubjpass'), ('expressed', 'ccomp'), ('  ', 'dobj'), ('industry', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Finally, ,], [,, ask], [ask, sentiment], [sentiment, expressed], [expressed,   ], [  , industry], [industry, .]]

>> Trigrams: 
[[Finally, ,, ask], [,, ask, sentiment], [ask, sentiment, expressed], [sentiment, expressed,   ], [expressed,   , industry], [  , industry, .]]

>> Noun Phrases are: 
[we, any sentiment, that industry]

>> Named Entities are: 
[]


============================ Sentence 174 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 175 =============================

One single machine learning model can’t do all of that. 


>> Tokens are: 
[single, machine, learning, model, .] 

>> PoS Tags are: 
[('single', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('single', 'amod'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('.', 'punct')]

>> Bigrams: 
[[single, machine], [machine, learning], [learning, model], [model, .]]

>> Trigrams: 
[[single, machine, learning], [machine, learning, model], [learning, model, .]]

>> Noun Phrases are: 
[One single machine learning model]

>> Named Entities are: 
[('One', 'CARDINAL')]


============================ Sentence 176 =============================

You’ll need at least  four separate models:   Identify and name any entities (Lexalytics)    


>> Tokens are: 
[need,  , separate, models, :,   , Identify, entities, (, Lexalytics, ),   ] 

>> PoS Tags are: 
[('need', 'VERB'), (' ', 'SPACE'), ('separate', 'ADJ'), ('models', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Identify', 'VERB'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('Lexalytics', 'PROPN'), (')', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('need', 'ROOT'), (' ', 'dobj'), ('separate', 'amod'), ('models', 'dobj'), (':', 'punct'), ('  ', 'nsubj'), ('Identify', 'conj'), ('entities', 'dobj'), ('(', 'punct'), ('Lexalytics', 'appos'), (')', 'punct'), ('  ', 'punct')]

>> Bigrams: 
[[need,  ], [ , separate], [separate, models], [models, :], [:,   ], [  , Identify], [Identify, entities], [entities, (], [(, Lexalytics], [Lexalytics, )], [),   ]]

>> Trigrams: 
[[need,  , separate], [ , separate, models], [separate, models, :], [models, :,   ], [:,   , Identify], [  , Identify, entities], [Identify, entities, (], [entities, (, Lexalytics], [(, Lexalytics, )], [Lexalytics, ),   ]]

>> Noun Phrases are: 
[You, four separate models, any entities, Lexalytics]

>> Named Entities are: 
[('four', 'CARDINAL'), ('Lexalytics', 'ORG')]


============================ Sentence 177 =============================

Determine the sentiment associated with that entity (positive)   Industry classification (text analytics)   Industry sentiment (neutral)   


>> Tokens are: 
[Determine, sentiment, associated, entity, (, positive, ),   , Industry, classification, (, text, analytics, ),   , Industry, sentiment, (, neutral, ),  ] 

>> PoS Tags are: 
[('Determine', 'VERB'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('positive', 'ADJ'), (')', 'PUNCT'), ('  ', 'SPACE'), ('Industry', 'NOUN'), ('classification', 'NOUN'), ('(', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (')', 'PUNCT'), ('  ', 'SPACE'), ('Industry', 'PROPN'), ('sentiment', 'NOUN'), ('(', 'PUNCT'), ('neutral', 'ADJ'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Determine', 'ROOT'), ('sentiment', 'dobj'), ('associated', 'acl'), ('entity', 'pobj'), ('(', 'punct'), ('positive', 'appos'), (')', 'punct'), ('  ', 'compound'), ('Industry', 'compound'), ('classification', 'dobj'), ('(', 'punct'), ('text', 'compound'), ('analytics', 'appos'), (')', 'punct'), ('  ', 'compound'), ('Industry', 'compound'), ('sentiment', 'dobj'), ('(', 'punct'), ('neutral', 'amod'), (')', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[Determine, sentiment], [sentiment, associated], [associated, entity], [entity, (], [(, positive], [positive, )], [),   ], [  , Industry], [Industry, classification], [classification, (], [(, text], [text, analytics], [analytics, )], [),   ], [  , Industry], [Industry, sentiment], [sentiment, (], [(, neutral], [neutral, )], [),  ]]

>> Trigrams: 
[[Determine, sentiment, associated], [sentiment, associated, entity], [associated, entity, (], [entity, (, positive], [(, positive, )], [positive, ),   ], [),   , Industry], [  , Industry, classification], [Industry, classification, (], [classification, (, text], [(, text, analytics], [text, analytics, )], [analytics, ),   ], [),   , Industry], [  , Industry, sentiment], [Industry, sentiment, (], [sentiment, (, neutral], [(, neutral, )], [neutral, ),  ]]

>> Noun Phrases are: 
[the sentiment, that entity,   Industry classification, (text analytics,   Industry sentiment]

>> Named Entities are: 
[]


============================ Sentence 178 =============================

If you just train a single model, you can only solve #1 or #3. 


>> Tokens are: 
[train, single, model, ,, solve, #, 1, #, 3, .] 

>> PoS Tags are: 
[('train', 'VERB'), ('single', 'ADJ'), ('model', 'NOUN'), (',', 'PUNCT'), ('solve', 'VERB'), ('#', 'SYM'), ('1', 'NUM'), ('#', 'SYM'), ('3', 'NUM'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('train', 'advcl'), ('single', 'amod'), ('model', 'dobj'), (',', 'punct'), ('solve', 'ROOT'), ('#', 'quantmod'), ('1', 'dobj'), ('#', 'quantmod'), ('3', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[train, single], [single, model], [model, ,], [,, solve], [solve, #], [#, 1], [1, #], [#, 3], [3, .]]

>> Trigrams: 
[[train, single, model], [single, model, ,], [model, ,, solve], [,, solve, #], [solve, #, 1], [#, 1, #], [1, #, 3], [#, 3, .]]

>> Noun Phrases are: 
[you, a single model, you]

>> Named Entities are: 
[('3', 'MONEY')]


============================ Sentence 179 =============================

Calculating the  sentiment needed for #2 or #4 requires first knowing which entity you’re  trying to associate the sentiment with. 


>> Tokens are: 
[Calculating,  , sentiment, needed, #, 2, #, 4, requires, knowing, entity,  , trying, associate, sentiment, .] 

>> PoS Tags are: 
[('Calculating', 'VERB'), (' ', 'SPACE'), ('sentiment', 'NOUN'), ('needed', 'VERB'), ('#', 'SYM'), ('2', 'NUM'), ('#', 'SYM'), ('4', 'NUM'), ('requires', 'VERB'), ('knowing', 'VERB'), ('entity', 'NOUN'), (' ', 'SPACE'), ('trying', 'VERB'), ('associate', 'VERB'), ('sentiment', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Calculating', 'csubj'), (' ', 'compound'), ('sentiment', 'dobj'), ('needed', 'csubj'), ('#', 'quantmod'), ('2', 'pobj'), ('#', 'quantmod'), ('4', 'conj'), ('requires', 'ROOT'), ('knowing', 'xcomp'), ('entity', 'ccomp'), (' ', 'nsubj'), ('trying', 'ccomp'), ('associate', 'xcomp'), ('sentiment', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Calculating,  ], [ , sentiment], [sentiment, needed], [needed, #], [#, 2], [2, #], [#, 4], [4, requires], [requires, knowing], [knowing, entity], [entity,  ], [ , trying], [trying, associate], [associate, sentiment], [sentiment, .]]

>> Trigrams: 
[[Calculating,  , sentiment], [ , sentiment, needed], [sentiment, needed, #], [needed, #, 2], [#, 2, #], [2, #, 4], [#, 4, requires], [4, requires, knowing], [requires, knowing, entity], [knowing, entity,  ], [entity,  , trying], [ , trying, associate], [trying, associate, sentiment], [associate, sentiment, .]]

>> Noun Phrases are: 
[the  sentiment, you, the sentiment]

>> Named Entities are: 
[('first', 'ORDINAL')]


============================ Sentence 180 =============================

If you only have a single model for  sentiment, you’ll end up rating the whole sentence as positive. 


>> Tokens are: 
[single, model,  , sentiment, ,, end, rating, sentence, positive, .] 

>> PoS Tags are: 
[('single', 'ADJ'), ('model', 'NOUN'), (' ', 'SPACE'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('end', 'VERB'), ('rating', 'VERB'), ('sentence', 'NOUN'), ('positive', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('single', 'amod'), ('model', 'dobj'), (' ', 'compound'), ('sentiment', 'pobj'), (',', 'punct'), ('end', 'ROOT'), ('rating', 'xcomp'), ('sentence', 'dobj'), ('positive', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[single, model], [model,  ], [ , sentiment], [sentiment, ,], [,, end], [end, rating], [rating, sentence], [sentence, positive], [positive, .]]

>> Trigrams: 
[[single, model,  ], [model,  , sentiment], [ , sentiment, ,], [sentiment, ,, end], [,, end, rating], [end, rating, sentence], [rating, sentence, positive], [sentence, positive, .]]

>> Noun Phrases are: 
[you, a single model,  sentiment, you, the whole sentence]

>> Named Entities are: 
[]


============================ Sentence 181 =============================

Additionally,  if you’re only using keywords to look for the term “text analytics,” you’ll rate  this sentence as positive for that phrase, which isn’t true. 


>> Tokens are: 
[Additionally, ,,  , keywords, look, term, “, text, analytics, ,, ”, rate,  , sentence, positive, phrase, ,, true, .] 

>> PoS Tags are: 
[('Additionally', 'ADV'), (',', 'PUNCT'), (' ', 'SPACE'), ('keywords', 'NOUN'), ('look', 'VERB'), ('term', 'NOUN'), ('“', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('rate', 'VERB'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('positive', 'ADJ'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('true', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Additionally', 'advmod'), (',', 'punct'), (' ', 'npadvmod'), ('keywords', 'dobj'), ('look', 'xcomp'), ('term', 'nmod'), ('“', 'punct'), ('text', 'compound'), ('analytics', 'pobj'), (',', 'punct'), ('”', 'punct'), ('rate', 'ROOT'), (' ', 'dobj'), ('sentence', 'dobj'), ('positive', 'amod'), ('phrase', 'pobj'), (',', 'punct'), ('true', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Additionally, ,], [,,  ], [ , keywords], [keywords, look], [look, term], [term, “], [“, text], [text, analytics], [analytics, ,], [,, ”], [”, rate], [rate,  ], [ , sentence], [sentence, positive], [positive, phrase], [phrase, ,], [,, true], [true, .]]

>> Trigrams: 
[[Additionally, ,,  ], [,,  , keywords], [ , keywords, look], [keywords, look, term], [look, term, “], [term, “, text], [“, text, analytics], [text, analytics, ,], [analytics, ,, ”], [,, ”, rate], [”, rate,  ], [rate,  , sentence], [ , sentence, positive], [sentence, positive, phrase], [positive, phrase, ,], [phrase, ,, true], [,, true, .]]

>> Noun Phrases are: 
[you, keywords, the term “text analytics, you, this sentence, that phrase]

>> Named Entities are: 
[]


============================ Sentence 182 =============================

Depending on what’s optimal for   the language, each of these steps is  machine learning or NLP code. 


>> Tokens are: 
[Depending, optimal,   , language, ,, steps,  , machine, learning, NLP, code, .] 

>> PoS Tags are: 
[('Depending', 'VERB'), ('optimal', 'ADJ'), ('  ', 'SPACE'), ('language', 'NOUN'), (',', 'PUNCT'), ('steps', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Depending', 'prep'), ('optimal', 'acomp'), ('  ', 'pobj'), ('language', 'appos'), (',', 'punct'), ('steps', 'pobj'), (' ', 'attr'), ('machine', 'compound'), ('learning', 'attr'), ('NLP', 'compound'), ('code', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Depending, optimal], [optimal,   ], [  , language], [language, ,], [,, steps], [steps,  ], [ , machine], [machine, learning], [learning, NLP], [NLP, code], [code, .]]

>> Trigrams: 
[[Depending, optimal,   ], [optimal,   , language], [  , language, ,], [language, ,, steps], [,, steps,  ], [steps,  , machine], [ , machine, learning], [machine, learning, NLP], [learning, NLP, code], [NLP, code, .]]

>> Noun Phrases are: 
[what, the language, these steps, machine learning, NLP code]

>> Named Entities are: 
[('NLP', 'ORG')]


============================ Sentence 183 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 184 =============================

TOKENS  PHRASES  SYNTAX  TREES   


>> Tokens are: 
[TOKENS,  , PHRASES,  , SYNTAX,  , TREES,  ] 

>> PoS Tags are: 
[('TOKENS', 'ADJ'), (' ', 'SPACE'), ('PHRASES', 'NOUN'), (' ', 'SPACE'), ('SYNTAX', 'PROPN'), (' ', 'SPACE'), ('TREES', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('TOKENS', 'nmod'), (' ', 'appos'), ('PHRASES', 'ROOT'), (' ', 'punct'), ('SYNTAX', 'appos'), (' ', 'nummod'), ('TREES', 'appos'), (' ', 'appos')]

>> Bigrams: 
[[TOKENS,  ], [ , PHRASES], [PHRASES,  ], [ , SYNTAX], [SYNTAX,  ], [ , TREES], [TREES,  ]]

>> Trigrams: 
[[TOKENS,  , PHRASES], [ , PHRASES,  ], [PHRASES,  , SYNTAX], [ , SYNTAX,  ], [SYNTAX,  , TREES], [ , TREES,  ]]

>> Noun Phrases are: 
[TOKENS  PHRASES, SYNTAX, TREES]

>> Named Entities are: 
[]


============================ Sentence 185 =============================

SENTENCES  text  parsing (NLP)  PARTS  OF SPEECH  SEMANTIC  RELATIONSHIPS  https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[SENTENCES,  , text,  , parsing, (, NLP, ),  , PARTS,  , SPEECH,  , SEMANTIC,  , RELATIONSHIPS,  , https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('SENTENCES', 'PROPN'), (' ', 'SPACE'), ('text', 'NOUN'), (' ', 'SPACE'), ('parsing', 'VERB'), ('(', 'PUNCT'), ('NLP', 'PROPN'), (')', 'PUNCT'), (' ', 'SPACE'), ('PARTS', 'PROPN'), (' ', 'SPACE'), ('SPEECH', 'PROPN'), (' ', 'SPACE'), ('SEMANTIC', 'PROPN'), (' ', 'SPACE'), ('RELATIONSHIPS', 'NOUN'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('SENTENCES', 'nmod'), (' ', 'nummod'), ('text', 'npadvmod'), (' ', 'appos'), ('parsing', 'nmod'), ('(', 'punct'), ('NLP', 'appos'), (')', 'punct'), (' ', 'dobj'), ('PARTS', 'npadvmod'), (' ', 'nummod'), ('SPEECH', 'pobj'), (' ', 'punct'), ('SEMANTIC', 'nmod'), (' ', 'nummod'), ('RELATIONSHIPS', 'compound'), (' ', 'dobj'), ('https://www.lexalytics.com/', 'appos'), ('https://www.lexalytics.com/', 'nsubj'), ('  ', 'ROOT'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[SENTENCES,  ], [ , text], [text,  ], [ , parsing], [parsing, (], [(, NLP], [NLP, )], [),  ], [ , PARTS], [PARTS,  ], [ , SPEECH], [SPEECH,  ], [ , SEMANTIC], [SEMANTIC,  ], [ , RELATIONSHIPS], [RELATIONSHIPS,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[SENTENCES,  , text], [ , text,  ], [text,  , parsing], [ , parsing, (], [parsing, (, NLP], [(, NLP, )], [NLP, ),  ], [),  , PARTS], [ , PARTS,  ], [PARTS,  , SPEECH], [ , SPEECH,  ], [SPEECH,  , SEMANTIC], [ , SEMANTIC,  ], [SEMANTIC,  , RELATIONSHIPS], [ , RELATIONSHIPS,  ], [RELATIONSHIPS,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[NLP, SPEECH, https://www.lexalytics.com/]

>> Named Entities are: 
[('NLP', 'ORG')]


============================ Sentence 186 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 187 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 188 =============================

P A P E R  8|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 8|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('8|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'nsubj'), (' ', 'appos'), ('8|', 'compound'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 8|], [8|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 8|], [ , 8|,       ], [8|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[P E R,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 189 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 190 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 191 =============================

Not only do you need at least four models to solve this task, but these  models are interdependent and have to interact with each other. 


>> Tokens are: 
[need, models, solve, task, ,,  , models, interdependent, interact, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('models', 'NOUN'), ('solve', 'VERB'), ('task', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('models', 'NOUN'), ('interdependent', 'ADJ'), ('interact', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('models', 'dobj'), ('solve', 'relcl'), ('task', 'dobj'), (',', 'punct'), (' ', 'compound'), ('models', 'nsubj'), ('interdependent', 'acomp'), ('interact', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[need, models], [models, solve], [solve, task], [task, ,], [,,  ], [ , models], [models, interdependent], [interdependent, interact], [interact, .]]

>> Trigrams: 
[[need, models, solve], [models, solve, task], [solve, task, ,], [task, ,,  ], [,,  , models], [ , models, interdependent], [models, interdependent, interact], [interdependent, interact, .]]

>> Noun Phrases are: 
[you, at least four models, this task, these  models]

>> Named Entities are: 
[('at least four', 'CARDINAL')]


============================ Sentence 192 =============================

To   create this kind of multi-model solution, we developed proprietary   AI building software. 


>> Tokens are: 
[  , create, kind, multi, -, model, solution, ,, developed, proprietary,   , AI, building, software, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('create', 'VERB'), ('kind', 'NOUN'), ('multi', 'ADJ'), ('-', 'ADJ'), ('model', 'ADJ'), ('solution', 'NOUN'), (',', 'PUNCT'), ('developed', 'VERB'), ('proprietary', 'ADJ'), ('  ', 'SPACE'), ('AI', 'PROPN'), ('building', 'NOUN'), ('software', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'pobj'), ('create', 'advcl'), ('kind', 'dobj'), ('multi', 'amod'), ('-', 'amod'), ('model', 'amod'), ('solution', 'pobj'), (',', 'punct'), ('developed', 'ROOT'), ('proprietary', 'amod'), ('  ', 'nummod'), ('AI', 'compound'), ('building', 'compound'), ('software', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[  , create], [create, kind], [kind, multi], [multi, -], [-, model], [model, solution], [solution, ,], [,, developed], [developed, proprietary], [proprietary,   ], [  , AI], [AI, building], [building, software], [software, .]]

>> Trigrams: 
[[  , create, kind], [create, kind, multi], [kind, multi, -], [multi, -, model], [-, model, solution], [model, solution, ,], [solution, ,, developed], [,, developed, proprietary], [developed, proprietary,   ], [proprietary,   , AI], [  , AI, building], [AI, building, software], [building, software, .]]

>> Noun Phrases are: 
[this kind, multi-model solution, we, proprietary   AI building software]

>> Named Entities are: 
[]


============================ Sentence 193 =============================

  This tool, “AI Assembler,” is used to build our features like sentiment,   named entity extraction, intention analysis and more. 


>> Tokens are: 
[  , tool, ,, “, AI, Assembler, ,, ”, build, features, like, sentiment, ,,   , named, entity, extraction, ,, intention, analysis, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('tool', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('AI', 'PROPN'), ('Assembler', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('build', 'VERB'), ('features', 'NOUN'), ('like', 'ADP'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN'), (',', 'PUNCT'), ('intention', 'NOUN'), ('analysis', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nmod'), ('tool', 'nsubjpass'), (',', 'punct'), ('“', 'punct'), ('AI', 'compound'), ('Assembler', 'appos'), (',', 'punct'), ('”', 'punct'), ('build', 'xcomp'), ('features', 'dobj'), ('like', 'prep'), ('sentiment', 'pobj'), (',', 'punct'), ('  ', 'nsubj'), ('named', 'ROOT'), ('entity', 'compound'), ('extraction', 'dobj'), (',', 'punct'), ('intention', 'compound'), ('analysis', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[  , tool], [tool, ,], [,, “], [“, AI], [AI, Assembler], [Assembler, ,], [,, ”], [”, build], [build, features], [features, like], [like, sentiment], [sentiment, ,], [,,   ], [  , named], [named, entity], [entity, extraction], [extraction, ,], [,, intention], [intention, analysis], [analysis, .]]

>> Trigrams: 
[[  , tool, ,], [tool, ,, “], [,, “, AI], [“, AI, Assembler], [AI, Assembler, ,], [Assembler, ,, ”], [,, ”, build], [”, build, features], [build, features, like], [features, like, sentiment], [like, sentiment, ,], [sentiment, ,,   ], [,,   , named], [  , named, entity], [named, entity, extraction], [entity, extraction, ,], [extraction, ,, intention], [,, intention, analysis], [intention, analysis, .]]

>> Noun Phrases are: 
[  This tool, , “AI Assembler, our features, sentiment, entity extraction, intention analysis]

>> Named Entities are: 
[('AI Assembler', 'PERSON')]


============================ Sentence 194 =============================

We also use AI  Assembler to build custom machine learning models used by our customers  and partners. 


>> Tokens are: 
[use, AI,  , Assembler, build, custom, machine, learning, models, customers,  , partners, .] 

>> PoS Tags are: 
[('use', 'VERB'), ('AI', 'PROPN'), (' ', 'SPACE'), ('Assembler', 'PROPN'), ('build', 'VERB'), ('custom', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('customers', 'NOUN'), (' ', 'SPACE'), ('partners', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('use', 'ROOT'), ('AI', 'compound'), (' ', 'compound'), ('Assembler', 'dobj'), ('build', 'xcomp'), ('custom', 'compound'), ('machine', 'compound'), ('learning', 'compound'), ('models', 'dobj'), ('customers', 'pobj'), (' ', 'appos'), ('partners', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[use, AI], [AI,  ], [ , Assembler], [Assembler, build], [build, custom], [custom, machine], [machine, learning], [learning, models], [models, customers], [customers,  ], [ , partners], [partners, .]]

>> Trigrams: 
[[use, AI,  ], [AI,  , Assembler], [ , Assembler, build], [Assembler, build, custom], [build, custom, machine], [custom, machine, learning], [machine, learning, models], [learning, models, customers], [models, customers,  ], [customers,  , partners], [ , partners, .]]

>> Noun Phrases are: 
[We, AI  Assembler, custom machine learning models, our customers, partners]

>> Named Entities are: 
[('AI', 'ORG')]


============================ Sentence 195 =============================

Among other things, AI Assembler manages dependencies  between models, allowing us to easily upgrade one model and then   re-build other models as necessary. 


>> Tokens are: 
[things, ,, AI, Assembler, manages, dependencies,  , models, ,, allowing, easily, upgrade, model,   , -, build, models, necessary, .] 

>> PoS Tags are: 
[('things', 'NOUN'), (',', 'PUNCT'), ('AI', 'PROPN'), ('Assembler', 'PROPN'), ('manages', 'VERB'), ('dependencies', 'NOUN'), (' ', 'SPACE'), ('models', 'NOUN'), (',', 'PUNCT'), ('allowing', 'VERB'), ('easily', 'ADV'), ('upgrade', 'VERB'), ('model', 'NOUN'), ('  ', 'SPACE'), ('-', 'VERB'), ('build', 'VERB'), ('models', 'NOUN'), ('necessary', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('things', 'pobj'), (',', 'punct'), ('AI', 'compound'), ('Assembler', 'nsubj'), ('manages', 'ROOT'), ('dependencies', 'dobj'), (' ', 'nummod'), ('models', 'pobj'), (',', 'punct'), ('allowing', 'advcl'), ('easily', 'advmod'), ('upgrade', 'ccomp'), ('model', 'dobj'), ('  ', 'nsubj'), ('-', 'xcomp'), ('build', 'xcomp'), ('models', 'dobj'), ('necessary', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[things, ,], [,, AI], [AI, Assembler], [Assembler, manages], [manages, dependencies], [dependencies,  ], [ , models], [models, ,], [,, allowing], [allowing, easily], [easily, upgrade], [upgrade, model], [model,   ], [  , -], [-, build], [build, models], [models, necessary], [necessary, .]]

>> Trigrams: 
[[things, ,, AI], [,, AI, Assembler], [AI, Assembler, manages], [Assembler, manages, dependencies], [manages, dependencies,  ], [dependencies,  , models], [ , models, ,], [models, ,, allowing], [,, allowing, easily], [allowing, easily, upgrade], [easily, upgrade, model], [upgrade, model,   ], [model,   , -], [  , -, build], [-, build, models], [build, models, necessary], [models, necessary, .]]

>> Noun Phrases are: 
[other things, AI Assembler, dependencies, models, us, one model, other models]

>> Named Entities are: 
[('AI Assembler', 'ORG')]


============================ Sentence 196 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 197 =============================

Multi-level granular sentiment analysis is difficult due to the model complexity   and dependencies. 


>> Tokens are: 
[Multi, -, level, granular, sentiment, analysis, difficult, model, complexity,   , dependencies, .] 

>> PoS Tags are: 
[('Multi', 'ADJ'), ('-', 'ADJ'), ('level', 'ADJ'), ('granular', 'ADJ'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('difficult', 'ADJ'), ('model', 'NOUN'), ('complexity', 'NOUN'), ('  ', 'SPACE'), ('dependencies', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Multi', 'amod'), ('-', 'amod'), ('level', 'amod'), ('granular', 'amod'), ('sentiment', 'compound'), ('analysis', 'nsubj'), ('difficult', 'acomp'), ('model', 'compound'), ('complexity', 'compound'), ('  ', 'pobj'), ('dependencies', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Multi, -], [-, level], [level, granular], [granular, sentiment], [sentiment, analysis], [analysis, difficult], [difficult, model], [model, complexity], [complexity,   ], [  , dependencies], [dependencies, .]]

>> Trigrams: 
[[Multi, -, level], [-, level, granular], [level, granular, sentiment], [granular, sentiment, analysis], [sentiment, analysis, difficult], [analysis, difficult, model], [difficult, model, complexity], [model, complexity,   ], [complexity,   , dependencies], [  , dependencies, .]]

>> Noun Phrases are: 
[Multi-level granular sentiment analysis, dependencies]

>> Named Entities are: 
[]


============================ Sentence 198 =============================

Lexalytics is one of the few companies that actually  provides this service – most companies simply provide document sentiment  and call it done. 


>> Tokens are: 
[Lexalytics, companies, actually,  , provides, service, –, companies, simply, provide, document, sentiment,  , .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('companies', 'NOUN'), ('actually', 'ADV'), (' ', 'SPACE'), ('provides', 'VERB'), ('service', 'NOUN'), ('–', 'PUNCT'), ('companies', 'NOUN'), ('simply', 'ADV'), ('provide', 'VERB'), ('document', 'NOUN'), ('sentiment', 'NOUN'), (' ', 'SPACE'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('companies', 'pobj'), ('actually', 'advmod'), (' ', 'nsubj'), ('provides', 'relcl'), ('service', 'dobj'), ('–', 'punct'), ('companies', 'nsubj'), ('simply', 'advmod'), ('provide', 'ROOT'), ('document', 'compound'), ('sentiment', 'dobj'), (' ', 'appos'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, companies], [companies, actually], [actually,  ], [ , provides], [provides, service], [service, –], [–, companies], [companies, simply], [simply, provide], [provide, document], [document, sentiment], [sentiment,  ], [ , .]]

>> Trigrams: 
[[Lexalytics, companies, actually], [companies, actually,  ], [actually,  , provides], [ , provides, service], [provides, service, –], [service, –, companies], [–, companies, simply], [companies, simply, provide], [simply, provide, document], [provide, document, sentiment], [document, sentiment,  ], [sentiment,  , .]]

>> Noun Phrases are: 
[Lexalytics, the few companies, this service, most companies, document sentiment, it]

>> Named Entities are: 
[]


============================ Sentence 199 =============================

Truth is, solving for entity and category sentiment is very  difficult, and multiplies the amount of work required. 


>> Tokens are: 
[Truth, ,, solving, entity, category, sentiment,  , difficult, ,, multiplies, work, required, .] 

>> PoS Tags are: 
[('Truth', 'NOUN'), (',', 'PUNCT'), ('solving', 'VERB'), ('entity', 'NOUN'), ('category', 'NOUN'), ('sentiment', 'NOUN'), (' ', 'SPACE'), ('difficult', 'ADJ'), (',', 'PUNCT'), ('multiplies', 'VERB'), ('work', 'NOUN'), ('required', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Truth', 'nsubj'), (',', 'punct'), ('solving', 'advcl'), ('entity', 'nmod'), ('category', 'conj'), ('sentiment', 'pobj'), (' ', 'npadvmod'), ('difficult', 'acomp'), (',', 'punct'), ('multiplies', 'conj'), ('work', 'pobj'), ('required', 'acl'), ('.', 'punct')]

>> Bigrams: 
[[Truth, ,], [,, solving], [solving, entity], [entity, category], [category, sentiment], [sentiment,  ], [ , difficult], [difficult, ,], [,, multiplies], [multiplies, work], [work, required], [required, .]]

>> Trigrams: 
[[Truth, ,, solving], [,, solving, entity], [solving, entity, category], [entity, category, sentiment], [category, sentiment,  ], [sentiment,  , difficult], [ , difficult, ,], [difficult, ,, multiplies], [,, multiplies, work], [multiplies, work, required], [work, required, .]]

>> Noun Phrases are: 
[Truth, entity and category sentiment, the amount, work]

>> Named Entities are: 
[]


============================ Sentence 200 =============================

We do it because our  customers are making business critical decisions, and they need context-rich  insights to make informed decisions that drive business growth.   


>> Tokens are: 
[ , customers, making, business, critical, decisions, ,, need, context, -, rich,  , insights, informed, decisions, drive, business, growth, .,  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('customers', 'NOUN'), ('making', 'VERB'), ('business', 'NOUN'), ('critical', 'ADJ'), ('decisions', 'NOUN'), (',', 'PUNCT'), ('need', 'VERB'), ('context', 'NOUN'), ('-', 'PUNCT'), ('rich', 'ADJ'), (' ', 'SPACE'), ('insights', 'NOUN'), ('informed', 'ADJ'), ('decisions', 'NOUN'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('customers', 'nsubj'), ('making', 'advcl'), ('business', 'nmod'), ('critical', 'amod'), ('decisions', 'dobj'), (',', 'punct'), ('need', 'conj'), ('context', 'npadvmod'), ('-', 'punct'), ('rich', 'amod'), (' ', 'compound'), ('insights', 'dobj'), ('informed', 'amod'), ('decisions', 'dobj'), ('drive', 'relcl'), ('business', 'compound'), ('growth', 'dobj'), ('.', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[ , customers], [customers, making], [making, business], [business, critical], [critical, decisions], [decisions, ,], [,, need], [need, context], [context, -], [-, rich], [rich,  ], [ , insights], [insights, informed], [informed, decisions], [decisions, drive], [drive, business], [business, growth], [growth, .], [.,  ]]

>> Trigrams: 
[[ , customers, making], [customers, making, business], [making, business, critical], [business, critical, decisions], [critical, decisions, ,], [decisions, ,, need], [,, need, context], [need, context, -], [context, -, rich], [-, rich,  ], [rich,  , insights], [ , insights, informed], [insights, informed, decisions], [informed, decisions, drive], [decisions, drive, business], [drive, business, growth], [business, growth, .], [growth, .,  ]]

>> Noun Phrases are: 
[We, it, our  customers, business critical decisions, they, context-rich  insights, informed decisions, business growth]

>> Named Entities are: 
[]


============================ Sentence 201 =============================

To borrow from another industry, imagine if you have a wonderful spy  satellite. 


>> Tokens are: 
[borrow, industry, ,, imagine, wonderful, spy,  , satellite, .] 

>> PoS Tags are: 
[('borrow', 'VERB'), ('industry', 'NOUN'), (',', 'PUNCT'), ('imagine', 'VERB'), ('wonderful', 'ADJ'), ('spy', 'NOUN'), (' ', 'SPACE'), ('satellite', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('borrow', 'advcl'), ('industry', 'pobj'), (',', 'punct'), ('imagine', 'ROOT'), ('wonderful', 'amod'), ('spy', 'nmod'), (' ', 'nummod'), ('satellite', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[borrow, industry], [industry, ,], [,, imagine], [imagine, wonderful], [wonderful, spy], [spy,  ], [ , satellite], [satellite, .]]

>> Trigrams: 
[[borrow, industry, ,], [industry, ,, imagine], [,, imagine, wonderful], [imagine, wonderful, spy], [wonderful, spy,  ], [spy,  , satellite], [ , satellite, .]]

>> Noun Phrases are: 
[another industry, you, a wonderful spy  satellite]

>> Named Entities are: 
[]


============================ Sentence 202 =============================

Do you want to just be able to say, “There are a bunch of people  there” or, “There’s a known terrorist there, and he’s holding a gun?”  builds NLP machine    learning models and manages    dependencies between them. 


>> Tokens are: 
[want, able, ,, “, bunch, people,  , ”, ,, “, known, terrorist, ,, holding, gun, ?, ”,  , builds, NLP, machine,    , learning, models, manages,    , dependencies, .] 

>> PoS Tags are: 
[('want', 'VERB'), ('able', 'ADJ'), (',', 'PUNCT'), ('“', 'PUNCT'), ('bunch', 'NOUN'), ('people', 'NOUN'), (' ', 'SPACE'), ('”', 'PUNCT'), (',', 'PUNCT'), ('“', 'PUNCT'), ('known', 'VERB'), ('terrorist', 'NOUN'), (',', 'PUNCT'), ('holding', 'VERB'), ('gun', 'NOUN'), ('?', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('builds', 'VERB'), ('NLP', 'PROPN'), ('machine', 'NOUN'), ('   ', 'SPACE'), ('learning', 'NOUN'), ('models', 'NOUN'), ('manages', 'VERB'), ('   ', 'SPACE'), ('dependencies', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('want', 'ccomp'), ('able', 'acomp'), (',', 'punct'), ('“', 'punct'), ('bunch', 'attr'), ('people', 'pobj'), (' ', 'appos'), ('”', 'punct'), (',', 'punct'), ('“', 'punct'), ('known', 'amod'), ('terrorist', 'attr'), (',', 'punct'), ('holding', 'conj'), ('gun', 'dobj'), ('?', 'punct'), ('”', 'punct'), (' ', 'nsubj'), ('builds', 'ROOT'), ('NLP', 'compound'), ('machine', 'compound'), ('   ', 'nummod'), ('learning', 'compound'), ('models', 'dobj'), ('manages', 'conj'), ('   ', 'nummod'), ('dependencies', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[want, able], [able, ,], [,, “], [“, bunch], [bunch, people], [people,  ], [ , ”], [”, ,], [,, “], [“, known], [known, terrorist], [terrorist, ,], [,, holding], [holding, gun], [gun, ?], [?, ”], [”,  ], [ , builds], [builds, NLP], [NLP, machine], [machine,    ], [   , learning], [learning, models], [models, manages], [manages,    ], [   , dependencies], [dependencies, .]]

>> Trigrams: 
[[want, able, ,], [able, ,, “], [,, “, bunch], [“, bunch, people], [bunch, people,  ], [people,  , ”], [ , ”, ,], [”, ,, “], [,, “, known], [“, known, terrorist], [known, terrorist, ,], [terrorist, ,, holding], [,, holding, gun], [holding, gun, ?], [gun, ?, ”], [?, ”,  ], [”,  , builds], [ , builds, NLP], [builds, NLP, machine], [NLP, machine,    ], [machine,    , learning], [   , learning, models], [learning, models, manages], [models, manages,    ], [manages,    , dependencies], [   , dependencies, .]]

>> Noun Phrases are: 
[you, a bunch, people, a known terrorist, he, a gun, NLP machine    learning models,    dependencies, them]

>> Named Entities are: 
[('NLP', 'ORG')]


============================ Sentence 203 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 204 =============================

AI   Assembler   (our proprietary   software)   


>> Tokens are: 
[AI,   , Assembler,   , (, proprietary,   , software, ),  ] 

>> PoS Tags are: 
[('AI', 'PROPN'), ('  ', 'SPACE'), ('Assembler', 'PROPN'), ('  ', 'SPACE'), ('(', 'PUNCT'), ('proprietary', 'ADJ'), ('  ', 'SPACE'), ('software', 'NOUN'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('AI', 'compound'), ('  ', 'nmod'), ('Assembler', 'compound'), ('  ', 'ROOT'), ('(', 'punct'), ('proprietary', 'amod'), ('  ', 'compound'), ('software', 'appos'), (')', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[AI,   ], [  , Assembler], [Assembler,   ], [  , (], [(, proprietary], [proprietary,   ], [  , software], [software, )], [),  ]]

>> Trigrams: 
[[AI,   , Assembler], [  , Assembler,   ], [Assembler,   , (], [  , (, proprietary], [(, proprietary,   ], [proprietary,   , software], [  , software, )], [software, ),  ]]

>> Noun Phrases are: 
[our proprietary   software]

>> Named Entities are: 
[]


============================ Sentence 205 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos'), ('W', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/, W H]

>> Named Entities are: 
[]


============================ Sentence 206 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 207 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 208 =============================

P A P E R  9|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 9|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('9|', 'NOUN'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'compound'), ('9|', 'compound'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 9|], [9|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 9|], [ , 9|,       ], [9|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[P A P E R  9|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 209 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 210 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 211 =============================

C O D 


>> Tokens are: 
[C, O, D] 

>> PoS Tags are: 
[('C', 'NOUN'), ('O', 'NOUN'), ('D', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('O', 'compound'), ('D', 'ROOT')]

>> Bigrams: 
[[C, O], [O, D]]

>> Trigrams: 
[[C, O, D]]

>> Noun Phrases are: 
[C O D]

>> Named Entities are: 
[]


============================ Sentence 212 =============================

I N G  V S .   


>> Tokens are: 
[N, G,  , V, S, .,  ] 

>> PoS Tags are: 
[('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('V', 'PROPN'), ('S', 'PROPN'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('N', 'dep'), ('G', 'nmod'), (' ', 'compound'), ('V', 'compound'), ('S', 'appos'), ('.', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[N, G], [G,  ], [ , V], [V, S], [S, .], [.,  ]]

>> Trigrams: 
[[N, G,  ], [G,  , V], [ , V, S], [V, S, .], [S, .,  ]]

>> Noun Phrases are: 
[I, N G  V S]

>> Named Entities are: 
[]


============================ Sentence 213 =============================

L E A R N I N G :   M A 


>> Tokens are: 
[L, E, R, N, N, G, :,   , M] 

>> PoS Tags are: 
[('L', 'NOUN'), ('E', 'PROPN'), ('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('M', 'PROPN')] 

>> Dependency Tags are: 
[('L', 'compound'), ('E', 'compound'), ('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), (':', 'punct'), ('  ', 'compound'), ('M', 'compound')]

>> Bigrams: 
[[L, E], [E, R], [R, N], [N, N], [N, G], [G, :], [:,   ], [  , M]]

>> Trigrams: 
[[L, E, R], [E, R, N], [R, N, N], [N, N, G], [N, G, :], [G, :,   ], [:,   , M]]

>> Noun Phrases are: 
[L E A R N I, N G,   M A]

>> Named Entities are: 
[]


============================ Sentence 214 =============================

K I N G  T H 


>> Tokens are: 
[K, N, G,  , T, H] 

>> PoS Tags are: 
[('K', 'NOUN'), ('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('K', 'compound'), ('N', 'appos'), ('G', 'conj'), (' ', 'appos'), ('T', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[K, N], [N, G], [G,  ], [ , T], [T, H]]

>> Trigrams: 
[[K, N, G], [N, G,  ], [G,  , T], [ , T, H]]

>> Noun Phrases are: 
[K I, N, G]

>> Named Entities are: 
[]


============================ Sentence 215 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 216 =============================

C A S E   


>> Tokens are: 
[C, S, E,  ] 

>> PoS Tags are: 
[('C', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('C', 'compound'), ('S', 'ROOT'), ('E', 'compound'), (' ', 'punct')]

>> Bigrams: 
[[C, S], [S, E], [E,  ]]

>> Trigrams: 
[[C, S, E], [S, E,  ]]

>> Noun Phrases are: 
[C A S]

>> Named Entities are: 
[]


============================ Sentence 217 =============================

F O R  E A C H   


>> Tokens are: 
[F, O, R,  , E, C, H,  ] 

>> PoS Tags are: 
[('F', 'NOUN'), ('O', 'INTJ'), ('R', 'NOUN'), (' ', 'SPACE'), ('E', 'NOUN'), ('C', 'NOUN'), ('H', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('F', 'compound'), ('O', 'intj'), ('R', 'nmod'), (' ', 'compound'), ('E', 'nmod'), ('C', 'compound'), ('H', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[F, O], [O, R], [R,  ], [ , E], [E, C], [C, H], [H,  ]]

>> Trigrams: 
[[F, O, R], [O, R,  ], [R,  , E], [ , E, C], [E, C, H], [C, H,  ]]

>> Noun Phrases are: 
[F O R  E A C H]

>> Named Entities are: 
[]


============================ Sentence 218 =============================

Let’s use the same sentence for this next example. 


>> Tokens are: 
[Let, use, sentence, example, .] 

>> PoS Tags are: 
[('Let', 'VERB'), ('use', 'VERB'), ('sentence', 'NOUN'), ('example', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Let', 'ROOT'), ('use', 'ccomp'), ('sentence', 'dobj'), ('example', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Let, use], [use, sentence], [sentence, example], [example, .]]

>> Trigrams: 
[[Let, use, sentence], [use, sentence, example], [sentence, example, .]]

>> Noun Phrases are: 
[’s, the same sentence, this next example]

>> Named Entities are: 
[]


============================ Sentence 219 =============================

Let me hear you say:  “Lexalytics is the best text analytics company ever.” 


>> Tokens are: 
[Let, hear, :,  , “, Lexalytics, best, text, analytics, company, ., ”] 

>> PoS Tags are: 
[('Let', 'VERB'), ('hear', 'VERB'), (':', 'PUNCT'), (' ', 'SPACE'), ('“', 'PUNCT'), ('Lexalytics', 'PROPN'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Let', 'ROOT'), ('hear', 'ccomp'), (':', 'punct'), (' ', 'nsubj'), ('“', 'punct'), ('Lexalytics', 'nsubj'), ('best', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('company', 'attr'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Let, hear], [hear, :], [:,  ], [ , “], [“, Lexalytics], [Lexalytics, best], [best, text], [text, analytics], [analytics, company], [company, .], [., ”]]

>> Trigrams: 
[[Let, hear, :], [hear, :,  ], [:,  , “], [ , “, Lexalytics], [“, Lexalytics, best], [Lexalytics, best, text], [best, text, analytics], [text, analytics, company], [analytics, company, .], [company, ., ”]]

>> Noun Phrases are: 
[me, you, Lexalytics, the best text analytics company]

>> Named Entities are: 
[('Lexalytics', 'WORK_OF_ART')]


============================ Sentence 220 =============================

 Now look at the period at the end of the sentence. 


>> Tokens are: 
[ , look, period, end, sentence, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('look', 'VERB'), ('period', 'NOUN'), ('end', 'NOUN'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('look', 'ROOT'), ('period', 'pobj'), ('end', 'pobj'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , look], [look, period], [period, end], [end, sentence], [sentence, .]]

>> Trigrams: 
[[ , look, period], [look, period, end], [period, end, sentence], [end, sentence, .]]

>> Noun Phrases are: 
[the period, the end, the sentence]

>> Named Entities are: 
[]


============================ Sentence 221 =============================

Periods are important   in English because they frequently denote the end of a sentence. 


>> Tokens are: 
[Periods, important,   , English, frequently, denote, end, sentence, .] 

>> PoS Tags are: 
[('Periods', 'NOUN'), ('important', 'ADJ'), ('  ', 'SPACE'), ('English', 'PROPN'), ('frequently', 'ADV'), ('denote', 'VERB'), ('end', 'NOUN'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Periods', 'nsubj'), ('important', 'amod'), ('  ', 'attr'), ('English', 'pobj'), ('frequently', 'advmod'), ('denote', 'advcl'), ('end', 'dobj'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Periods, important], [important,   ], [  , English], [English, frequently], [frequently, denote], [denote, end], [end, sentence], [sentence, .]]

>> Trigrams: 
[[Periods, important,   ], [important,   , English], [  , English, frequently], [English, frequently, denote], [frequently, denote, end], [denote, end, sentence], [end, sentence, .]]

>> Noun Phrases are: 
[Periods, English, they, the end, a sentence]

>> Named Entities are: 
[('English', 'LANGUAGE')]


============================ Sentence 222 =============================

It’s  important to be able to break sentences apart so that you can figure out  which statements go together.    


>> Tokens are: 
[ , important, able, break, sentences, apart, figure,  , statements, .,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('important', 'ADJ'), ('able', 'ADJ'), ('break', 'VERB'), ('sentences', 'NOUN'), ('apart', 'ADV'), ('figure', 'VERB'), (' ', 'SPACE'), ('statements', 'NOUN'), ('.', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('important', 'acomp'), ('able', 'acomp'), ('break', 'xcomp'), ('sentences', 'dobj'), ('apart', 'advmod'), ('figure', 'advcl'), (' ', 'dobj'), ('statements', 'nsubj'), ('.', 'punct'), ('  ', 'punct')]

>> Bigrams: 
[[ , important], [important, able], [able, break], [break, sentences], [sentences, apart], [apart, figure], [figure,  ], [ , statements], [statements, .], [.,   ]]

>> Trigrams: 
[[ , important, able], [important, able, break], [able, break, sentences], [break, sentences, apart], [sentences, apart, figure], [apart, figure,  ], [figure,  , statements], [ , statements, .], [statements, .,   ]]

>> Noun Phrases are: 
[It, sentences, you, which statements]

>> Named Entities are: 
[]


============================ Sentence 223 =============================

However, periods also denote other things, like “Dr.” for doctor, or “Mr.”   for mister. 


>> Tokens are: 
[,, periods, denote, things, ,, like, “, Dr., ”, doctor, ,, “, Mr., ”,   , mister, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('periods', 'NOUN'), ('denote', 'VERB'), ('things', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('“', 'PUNCT'), ('Dr.', 'PROPN'), ('”', 'PUNCT'), ('doctor', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('Mr.', 'PROPN'), ('”', 'PUNCT'), ('  ', 'SPACE'), ('mister', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('periods', 'nsubj'), ('denote', 'ROOT'), ('things', 'dobj'), (',', 'punct'), ('like', 'prep'), ('“', 'punct'), ('Dr.', 'pobj'), ('”', 'punct'), ('doctor', 'pobj'), (',', 'punct'), ('“', 'punct'), ('Mr.', 'conj'), ('”', 'punct'), ('  ', 'appos'), ('mister', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, periods], [periods, denote], [denote, things], [things, ,], [,, like], [like, “], [“, Dr.], [Dr., ”], [”, doctor], [doctor, ,], [,, “], [“, Mr.], [Mr., ”], [”,   ], [  , mister], [mister, .]]

>> Trigrams: 
[[,, periods, denote], [periods, denote, things], [denote, things, ,], [things, ,, like], [,, like, “], [like, “, Dr.], [“, Dr., ”], [Dr., ”, doctor], [”, doctor, ,], [doctor, ,, “], [,, “, Mr.], [“, Mr., ”], [Mr., ”,   ], [”,   , mister], [  , mister, .]]

>> Noun Phrases are: 
[periods, other things, “Dr., doctor, “Mr., mister]

>> Named Entities are: 
[]


============================ Sentence 224 =============================

How can a machine tell whether the period is denoting the end   of a sentence or a form of address? 


>> Tokens are: 
[machine, tell, period, denoting, end,   , sentence, form, address, ?] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('tell', 'VERB'), ('period', 'NOUN'), ('denoting', 'VERB'), ('end', 'NOUN'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('form', 'NOUN'), ('address', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'nsubj'), ('tell', 'ROOT'), ('period', 'nsubj'), ('denoting', 'ccomp'), ('end', 'npadvmod'), ('  ', 'npadvmod'), ('sentence', 'pobj'), ('form', 'conj'), ('address', 'pobj'), ('?', 'punct')]

>> Bigrams: 
[[machine, tell], [tell, period], [period, denoting], [denoting, end], [end,   ], [  , sentence], [sentence, form], [form, address], [address, ?]]

>> Trigrams: 
[[machine, tell, period], [tell, period, denoting], [period, denoting, end], [denoting, end,   ], [end,   , sentence], [  , sentence, form], [sentence, form, address], [form, address, ?]]

>> Noun Phrases are: 
[a machine, the period, a sentence, address]

>> Named Entities are: 
[]


============================ Sentence 225 =============================

We could train a machine learning model  for this task by marking up examples of each. 


>> Tokens are: 
[train, machine, learning, model,  , task, marking, examples, .] 

>> PoS Tags are: 
[('train', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), (' ', 'SPACE'), ('task', 'NOUN'), ('marking', 'VERB'), ('examples', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('train', 'ROOT'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'dobj'), (' ', 'dobj'), ('task', 'pobj'), ('marking', 'pcomp'), ('examples', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[train, machine], [machine, learning], [learning, model], [model,  ], [ , task], [task, marking], [marking, examples], [examples, .]]

>> Trigrams: 
[[train, machine, learning], [machine, learning, model], [learning, model,  ], [model,  , task], [ , task, marking], [task, marking, examples], [marking, examples, .]]

>> Noun Phrases are: 
[We, a machine learning model, this task, examples]

>> Named Entities are: 
[]


============================ Sentence 226 =============================

But this isn’t necessarily the  most efficient approach. 


>> Tokens are: 
[necessarily,  , efficient, approach, .] 

>> PoS Tags are: 
[('necessarily', 'ADV'), (' ', 'SPACE'), ('efficient', 'ADJ'), ('approach', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('necessarily', 'advmod'), (' ', 'nmod'), ('efficient', 'amod'), ('approach', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[necessarily,  ], [ , efficient], [efficient, approach], [approach, .]]

>> Trigrams: 
[[necessarily,  , efficient], [ , efficient, approach], [efficient, approach, .]]

>> Noun Phrases are: 
[the  most efficient approach]

>> Named Entities are: 
[]


============================ Sentence 227 =============================

After all, there are only a few cases in the English  language where the period is used for anything other than denoting the end  of a sentence. 


>> Tokens are: 
[,, cases, English,  , language, period, denoting, end,  , sentence, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('cases', 'NOUN'), ('English', 'ADJ'), (' ', 'SPACE'), ('language', 'NOUN'), ('period', 'NOUN'), ('denoting', 'VERB'), ('end', 'NOUN'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('cases', 'attr'), ('English', 'amod'), (' ', 'compound'), ('language', 'pobj'), ('period', 'nsubjpass'), ('denoting', 'pcomp'), ('end', 'dobj'), (' ', 'appos'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, cases], [cases, English], [English,  ], [ , language], [language, period], [period, denoting], [denoting, end], [end,  ], [ , sentence], [sentence, .]]

>> Trigrams: 
[[,, cases, English], [cases, English,  ], [English,  , language], [ , language, period], [language, period, denoting], [period, denoting, end], [denoting, end,  ], [end,  , sentence], [ , sentence, .]]

>> Noun Phrases are: 
[only a few cases, the English  language, the period, anything, the end, a sentence]

>> Named Entities are: 
[('English', 'LANGUAGE')]


============================ Sentence 228 =============================

It is more efficient, faster computationally, and more precise  to just hard-code these cases using NLP code or other algorithms. 


>> Tokens are: 
[efficient, ,, faster, computationally, ,, precise,  , hard, -, code, cases, NLP, code, algorithms, .] 

>> PoS Tags are: 
[('efficient', 'ADJ'), (',', 'PUNCT'), ('faster', 'ADV'), ('computationally', 'ADV'), (',', 'PUNCT'), ('precise', 'ADJ'), (' ', 'SPACE'), ('hard', 'ADJ'), ('-', 'PUNCT'), ('code', 'VERB'), ('cases', 'NOUN'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('efficient', 'acomp'), (',', 'punct'), ('faster', 'advmod'), ('computationally', 'advmod'), (',', 'punct'), ('precise', 'amod'), (' ', 'punct'), ('hard', 'amod'), ('-', 'punct'), ('code', 'pobj'), ('cases', 'pobj'), ('NLP', 'compound'), ('code', 'dobj'), ('algorithms', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[efficient, ,], [,, faster], [faster, computationally], [computationally, ,], [,, precise], [precise,  ], [ , hard], [hard, -], [-, code], [code, cases], [cases, NLP], [NLP, code], [code, algorithms], [algorithms, .]]

>> Trigrams: 
[[efficient, ,, faster], [,, faster, computationally], [faster, computationally, ,], [computationally, ,, precise], [,, precise,  ], [precise,  , hard], [ , hard, -], [hard, -, code], [-, code, cases], [code, cases, NLP], [cases, NLP, code], [NLP, code, algorithms], [code, algorithms, .]]

>> Noun Phrases are: 
[It, these cases, NLP code, other algorithms]

>> Named Entities are: 
[('NLP', 'ORG')]


============================ Sentence 229 =============================

  Where there are cases that are best handled by NLP code, we write NLP  code or use rules. 


>> Tokens are: 
[  , cases, best, handled, NLP, code, ,, write, NLP,  , code, use, rules, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('cases', 'NOUN'), ('best', 'ADV'), ('handled', 'VERB'), ('NLP', 'PROPN'), ('code', 'NOUN'), (',', 'PUNCT'), ('write', 'VERB'), ('NLP', 'PROPN'), (' ', 'SPACE'), ('code', 'NOUN'), ('use', 'VERB'), ('rules', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('cases', 'attr'), ('best', 'advmod'), ('handled', 'relcl'), ('NLP', 'compound'), ('code', 'pobj'), (',', 'punct'), ('write', 'ROOT'), ('NLP', 'dobj'), (' ', 'compound'), ('code', 'appos'), ('use', 'conj'), ('rules', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[  , cases], [cases, best], [best, handled], [handled, NLP], [NLP, code], [code, ,], [,, write], [write, NLP], [NLP,  ], [ , code], [code, use], [use, rules], [rules, .]]

>> Trigrams: 
[[  , cases, best], [cases, best, handled], [best, handled, NLP], [handled, NLP, code], [NLP, code, ,], [code, ,, write], [,, write, NLP], [write, NLP,  ], [NLP,  , code], [ , code, use], [code, use, rules], [use, rules, .]]

>> Noun Phrases are: 
[cases, NLP code, we, NLP,  code, rules]

>> Named Entities are: 
[('NLP', 'ORG'), ('NLP', 'ORG')]


============================ Sentence 230 =============================

When we need to build models, we build models. 


>> Tokens are: 
[need, build, models, ,, build, models, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('build', 'VERB'), ('models', 'NOUN'), (',', 'PUNCT'), ('build', 'VERB'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'advcl'), ('build', 'xcomp'), ('models', 'dobj'), (',', 'punct'), ('build', 'ROOT'), ('models', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[need, build], [build, models], [models, ,], [,, build], [build, models], [models, .]]

>> Trigrams: 
[[need, build, models], [build, models, ,], [models, ,, build], [,, build, models], [build, models, .]]

>> Noun Phrases are: 
[we, models, we, models]

>> Named Entities are: 
[]


============================ Sentence 231 =============================

  When we need NLP code or rules,    we write them; when we need    models, we build them. 


>> Tokens are: 
[  , need, NLP, code, rules, ,,    , write, ;, need,    , models, ,, build, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('need', 'VERB'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('rules', 'NOUN'), (',', 'PUNCT'), ('   ', 'SPACE'), ('write', 'VERB'), (';', 'PUNCT'), ('need', 'VERB'), ('   ', 'SPACE'), ('models', 'NOUN'), (',', 'PUNCT'), ('build', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('need', 'relcl'), ('NLP', 'compound'), ('code', 'dobj'), ('rules', 'conj'), (',', 'punct'), ('   ', 'dep'), ('write', 'ccomp'), (';', 'punct'), ('need', 'advcl'), ('   ', 'nummod'), ('models', 'dobj'), (',', 'punct'), ('build', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[  , need], [need, NLP], [NLP, code], [code, rules], [rules, ,], [,,    ], [   , write], [write, ;], [;, need], [need,    ], [   , models], [models, ,], [,, build], [build, .]]

>> Trigrams: 
[[  , need, NLP], [need, NLP, code], [NLP, code, rules], [code, rules, ,], [rules, ,,    ], [,,    , write], [   , write, ;], [write, ;, need], [;, need,    ], [need,    , models], [   , models, ,], [models, ,, build], [,, build, .]]

>> Noun Phrases are: 
[we, NLP code, rules, we, them, we,    models, we, them]

>> Named Entities are: 
[('NLP', 'ORG')]


============================ Sentence 232 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 233 =============================

Practical   efficiencies:  https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[Practical,   , efficiencies, :,  , https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('Practical', 'ADJ'), ('  ', 'SPACE'), ('efficiencies', 'NOUN'), (':', 'PUNCT'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('Practical', 'amod'), ('  ', 'compound'), ('efficiencies', 'ROOT'), (':', 'punct'), (' ', 'appos'), ('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'appos'), ('  ', 'punct'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[Practical,   ], [  , efficiencies], [efficiencies, :], [:,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[Practical,   , efficiencies], [  , efficiencies, :], [efficiencies, :,  ], [:,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[Practical   efficiencies, https://www.lexalytics.com/ https://www.lexalytics.com/]

>> Named Entities are: 
[]


============================ Sentence 234 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 235 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 236 =============================

P A P E R  10|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com  B L A C K  B O X / C L E 


>> Tokens are: 
[P, P, E, R,  , 10|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA,   , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  , B, L, C, K,  , B, O, X, /, C, L, E] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('10|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE'), ('B', 'PROPN'), ('L', 'PROPN'), ('C', 'PROPN'), ('K', 'PROPN'), (' ', 'SPACE'), ('B', 'NOUN'), ('O', 'PROPN'), ('X', 'NOUN'), ('/', 'SYM'), ('C', 'PROPN'), ('L', 'PROPN'), ('E', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'compound'), ('R', 'compound'), (' ', 'compound'), ('10|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct'), ('USA', 'compound'), ('  ', 'compound'), ('|', 'punct'), ('  ', 'appos'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'compound'), ('B', 'compound'), ('L', 'compound'), ('C', 'nmod'), ('K', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('O', 'nmod'), ('X', 'nmod'), ('/', 'punct'), ('C', 'compound'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 10|], [10|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA,   ], [  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ], [ , B], [B, L], [L, C], [C, K], [K,  ], [ , B], [B, O], [O, X], [X, /], [/, C], [C, L], [L, E]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 10|], [ , 10|,       ], [10|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA,   ], [USA,   , |], [  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ], [www.lexalytics.com,  , B], [ , B, L], [B, L, C], [L, C, K], [C, K,  ], [K,  , B], [ , B, O], [B, O, X], [O, X, /], [X, /, C], [/, C, L], [C, L, E]]

>> Noun Phrases are: 
[P A P E R  10|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, 377-8036 |,  B L A C K  B O X / C L E]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 237 =============================

A R  B O X :    


>> Tokens are: 
[R,  , B, O, X, :,   ] 

>> PoS Tags are: 
[('R', 'NOUN'), (' ', 'SPACE'), ('B', 'NOUN'), ('O', 'NOUN'), ('X', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('O', 'compound'), ('X', 'ROOT'), (':', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[R,  ], [ , B], [B, O], [O, X], [X, :], [:,   ]]

>> Trigrams: 
[[R,  , B], [ , B, O], [B, O, X], [O, X, :], [X, :,   ]]

>> Noun Phrases are: 
[A R  B O X]

>> Named Entities are: 
[]


============================ Sentence 238 =============================

L O 


>> Tokens are: 
[L, O] 

>> PoS Tags are: 
[('L', 'NOUN'), ('O', 'NOUN')] 

>> Dependency Tags are: 
[('L', 'compound'), ('O', 'ROOT')]

>> Bigrams: 
[[L, O]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[L O]

>> Named Entities are: 
[]


============================ Sentence 239 =============================

O K I N G 


>> Tokens are: 
[O, K, N, G] 

>> PoS Tags are: 
[('O', 'INTJ'), ('K', 'NOUN'), ('N', 'PROPN'), ('G', 'PROPN')] 

>> Dependency Tags are: 
[('O', 'intj'), ('K', 'ROOT'), ('N', 'compound'), ('G', 'appos')]

>> Bigrams: 
[[O, K], [K, N], [N, G]]

>> Trigrams: 
[[O, K, N], [K, N, G]]

>> Noun Phrases are: 
[O K, I, N G]

>> Named Entities are: 
[]


============================ Sentence 240 =============================

 I 


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I]

>> Named Entities are: 
[]


============================ Sentence 241 =============================

N S 


>> Tokens are: 
[N, S] 

>> PoS Tags are: 
[('N', 'PROPN'), ('S', 'NOUN')] 

>> Dependency Tags are: 
[('N', 'compound'), ('S', 'ROOT')]

>> Bigrams: 
[[N, S]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[N S]

>> Named Entities are: 
[]


============================ Sentence 242 =============================

I D 


>> Tokens are: 
[D] 

>> PoS Tags are: 
[('D', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I D]

>> Named Entities are: 
[]


============================ Sentence 243 =============================

E  T H 


>> Tokens are: 
[E,  , T, H] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'compound'), ('T', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[E,  ], [ , T], [T, H]]

>> Trigrams: 
[[E,  , T], [ , T, H]]

>> Noun Phrases are: 
[E  T H]

>> Named Entities are: 
[]


============================ Sentence 244 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 245 =============================

D A T 


>> Tokens are: 
[D, T] 

>> PoS Tags are: 
[('D', 'NOUN'), ('T', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'compound'), ('T', 'ROOT')]

>> Bigrams: 
[[D, T]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[D A T]

>> Named Entities are: 
[]


============================ Sentence 246 =============================

A   


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'punct')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[A]

>> Named Entities are: 
[]


============================ Sentence 247 =============================

It is important to understand not just what decision a model has made,   but why it has made that decision. 


>> Tokens are: 
[important, understand, decision, model, ,,   , decision, .] 

>> PoS Tags are: 
[('important', 'ADJ'), ('understand', 'VERB'), ('decision', 'NOUN'), ('model', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('important', 'acomp'), ('understand', 'xcomp'), ('decision', 'dobj'), ('model', 'nsubj'), (',', 'punct'), ('  ', 'dep'), ('decision', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[important, understand], [understand, decision], [decision, model], [model, ,], [,,   ], [  , decision], [decision, .]]

>> Trigrams: 
[[important, understand, decision], [understand, decision, model], [decision, model, ,], [model, ,,   ], [,,   , decision], [  , decision, .]]

>> Noun Phrases are: 
[It, what decision, a model, it, that decision]

>> Named Entities are: 
[]


============================ Sentence 248 =============================

There are two reasons for this:   There’s often other business-relevant information encoded   in the “why.” 


>> Tokens are: 
[reasons, :,   , business, -, relevant, information, encoded,   , “, ., ”] 

>> PoS Tags are: 
[('reasons', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('business', 'NOUN'), ('-', 'PUNCT'), ('relevant', 'ADJ'), ('information', 'NOUN'), ('encoded', 'VERB'), ('  ', 'SPACE'), ('“', 'PUNCT'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('reasons', 'attr'), (':', 'punct'), ('  ', 'dep'), ('business', 'npadvmod'), ('-', 'punct'), ('relevant', 'amod'), ('information', 'attr'), ('encoded', 'acl'), ('  ', 'dobj'), ('“', 'punct'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[reasons, :], [:,   ], [  , business], [business, -], [-, relevant], [relevant, information], [information, encoded], [encoded,   ], [  , “], [“, .], [., ”]]

>> Trigrams: 
[[reasons, :,   ], [:,   , business], [  , business, -], [business, -, relevant], [-, relevant, information], [relevant, information, encoded], [information, encoded,   ], [encoded,   , “], [  , “, .], [“, ., ”]]

>> Noun Phrases are: 
[two reasons, other business-relevant information]

>> Named Entities are: 
[('two', 'CARDINAL')]


============================ Sentence 249 =============================

For example, knowing simply that certain survey  results are full of negative feedback is not particularly useful. 


>> Tokens are: 
[example, ,, knowing, simply, certain, survey,  , results, negative, feedback, particularly, useful, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('knowing', 'VERB'), ('simply', 'ADV'), ('certain', 'ADJ'), ('survey', 'NOUN'), (' ', 'SPACE'), ('results', 'NOUN'), ('negative', 'ADJ'), ('feedback', 'NOUN'), ('particularly', 'ADV'), ('useful', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('knowing', 'csubj'), ('simply', 'advmod'), ('certain', 'amod'), ('survey', 'nmod'), (' ', 'punct'), ('results', 'nsubj'), ('negative', 'amod'), ('feedback', 'pobj'), ('particularly', 'advmod'), ('useful', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, knowing], [knowing, simply], [simply, certain], [certain, survey], [survey,  ], [ , results], [results, negative], [negative, feedback], [feedback, particularly], [particularly, useful], [useful, .]]

>> Trigrams: 
[[example, ,, knowing], [,, knowing, simply], [knowing, simply, certain], [simply, certain, survey], [certain, survey,  ], [survey,  , results], [ , results, negative], [results, negative, feedback], [negative, feedback, particularly], [feedback, particularly, useful], [particularly, useful, .]]

>> Noun Phrases are: 
[example, certain survey  results, negative feedback]

>> Named Entities are: 
[]


============================ Sentence 250 =============================

  We want to know which phrases were scored negatively. 


>> Tokens are: 
[  , want, know, phrases, scored, negatively, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('want', 'VERB'), ('know', 'VERB'), ('phrases', 'NOUN'), ('scored', 'VERB'), ('negatively', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'npadvmod'), ('want', 'ROOT'), ('know', 'xcomp'), ('phrases', 'nsubjpass'), ('scored', 'ccomp'), ('negatively', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[  , want], [want, know], [know, phrases], [phrases, scored], [scored, negatively], [negatively, .]]

>> Trigrams: 
[[  , want, know], [want, know, phrases], [know, phrases, scored], [phrases, scored, negatively], [scored, negatively, .]]

>> Noun Phrases are: 
[We, which phrases]

>> Named Entities are: 
[]


============================ Sentence 251 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 252 =============================

We might want to adjust the scoring somehow. 


>> Tokens are: 
[want, adjust, scoring, .] 

>> PoS Tags are: 
[('want', 'VERB'), ('adjust', 'VERB'), ('scoring', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('want', 'ROOT'), ('adjust', 'xcomp'), ('scoring', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[want, adjust], [adjust, scoring], [scoring, .]]

>> Trigrams: 
[[want, adjust, scoring], [adjust, scoring, .]]

>> Noun Phrases are: 
[We, the scoring]

>> Named Entities are: 
[]


============================ Sentence 253 =============================

If we can’t   see why the model is making a decision, we can’t really affect   the decision and it can be hard to figure out what to do next.   


>> Tokens are: 
[  , model, making, decision, ,, affect,   , decision, hard, figure, .,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('model', 'NOUN'), ('making', 'VERB'), ('decision', 'NOUN'), (',', 'PUNCT'), ('affect', 'VERB'), ('  ', 'SPACE'), ('decision', 'NOUN'), ('hard', 'ADJ'), ('figure', 'VERB'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('model', 'nsubj'), ('making', 'ccomp'), ('decision', 'dobj'), (',', 'punct'), ('affect', 'ROOT'), ('  ', 'dobj'), ('decision', 'dobj'), ('hard', 'acomp'), ('figure', 'xcomp'), ('.', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , model], [model, making], [making, decision], [decision, ,], [,, affect], [affect,   ], [  , decision], [decision, hard], [hard, figure], [figure, .], [.,  ]]

>> Trigrams: 
[[  , model, making], [model, making, decision], [making, decision, ,], [decision, ,, affect], [,, affect,   ], [affect,   , decision], [  , decision, hard], [decision, hard, figure], [hard, figure, .], [figure, .,  ]]

>> Noun Phrases are: 
[we, the model, a decision, we, the decision, it, what]

>> Named Entities are: 
[]


============================ Sentence 254 =============================

It’s often difficult to see how or why a model is making a decision. 


>> Tokens are: 
[difficult, model, making, decision, .] 

>> PoS Tags are: 
[('difficult', 'ADJ'), ('model', 'NOUN'), ('making', 'VERB'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('difficult', 'acomp'), ('model', 'nsubj'), ('making', 'ccomp'), ('decision', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[difficult, model], [model, making], [making, decision], [decision, .]]

>> Trigrams: 
[[difficult, model, making], [model, making, decision], [making, decision, .]]

>> Noun Phrases are: 
[It, a model, a decision]

>> Named Entities are: 
[]


============================ Sentence 255 =============================

This is  particularly true of deep learning models. 


>> Tokens are: 
[ , particularly, true, deep, learning, models, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('particularly', 'ADV'), ('true', 'ADJ'), ('deep', 'ADJ'), ('learning', 'NOUN'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('particularly', 'advmod'), ('true', 'acomp'), ('deep', 'amod'), ('learning', 'compound'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , particularly], [particularly, true], [true, deep], [deep, learning], [learning, models], [models, .]]

>> Trigrams: 
[[ , particularly, true], [particularly, true, deep], [true, deep, learning], [deep, learning, models], [learning, models, .]]

>> Noun Phrases are: 
[deep learning models]

>> Named Entities are: 
[]


============================ Sentence 256 =============================

Despite their popularity, they   are profoundly black box algorithms. 


>> Tokens are: 
[Despite, popularity, ,,   , profoundly, black, box, algorithms, .] 

>> PoS Tags are: 
[('Despite', 'SCONJ'), ('popularity', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('profoundly', 'ADV'), ('black', 'ADJ'), ('box', 'NOUN'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Despite', 'prep'), ('popularity', 'pobj'), (',', 'punct'), ('  ', 'appos'), ('profoundly', 'advmod'), ('black', 'amod'), ('box', 'compound'), ('algorithms', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[Despite, popularity], [popularity, ,], [,,   ], [  , profoundly], [profoundly, black], [black, box], [box, algorithms], [algorithms, .]]

>> Trigrams: 
[[Despite, popularity, ,], [popularity, ,,   ], [,,   , profoundly], [  , profoundly, black], [profoundly, black, box], [black, box, algorithms], [box, algorithms, .]]

>> Noun Phrases are: 
[their popularity, they, profoundly black box algorithms]

>> Named Entities are: 
[]


============================ Sentence 257 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 258 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/    


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   ] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/]

>> Named Entities are: 
[]


============================ Sentence 259 =============================

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[]


============================ Sentence 260 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 261 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 262 =============================

P A P E R  1 1|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 1, 1|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('1', 'NUM'), ('1|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'appos'), ('1', 'nummod'), ('1|', 'appos'), ('      ', 'appos'), ('|', 'appos'), ('  ', 'prep'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 1], [1, 1|], [1|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 1], [ , 1, 1|], [1, 1|,       ], [1|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[|, 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('1 1|', 'CARDINAL'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 263 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 264 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'poss'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'ROOT'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[  |   1-800-377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 265 =============================

One solution to this black box problem is to break big, general models   into smaller, targeted models. 


>> Tokens are: 
[solution, black, box, problem, break, big, ,, general, models,   , smaller, ,, targeted, models, .] 

>> PoS Tags are: 
[('solution', 'NOUN'), ('black', 'ADJ'), ('box', 'NOUN'), ('problem', 'NOUN'), ('break', 'VERB'), ('big', 'ADJ'), (',', 'PUNCT'), ('general', 'ADJ'), ('models', 'NOUN'), ('  ', 'SPACE'), ('smaller', 'ADJ'), (',', 'PUNCT'), ('targeted', 'ADJ'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('solution', 'nsubj'), ('black', 'amod'), ('box', 'compound'), ('problem', 'pobj'), ('break', 'xcomp'), ('big', 'amod'), (',', 'punct'), ('general', 'amod'), ('models', 'dobj'), ('  ', 'appos'), ('smaller', 'amod'), (',', 'punct'), ('targeted', 'amod'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[solution, black], [black, box], [box, problem], [problem, break], [break, big], [big, ,], [,, general], [general, models], [models,   ], [  , smaller], [smaller, ,], [,, targeted], [targeted, models], [models, .]]

>> Trigrams: 
[[solution, black, box], [black, box, problem], [box, problem, break], [problem, break, big], [break, big, ,], [big, ,, general], [,, general, models], [general, models,   ], [models,   , smaller], [  , smaller, ,], [smaller, ,, targeted], [,, targeted, models], [targeted, models, .]]

>> Noun Phrases are: 
[One solution, this black box problem, big, general models, smaller, targeted models]

>> Named Entities are: 
[('One', 'CARDINAL')]


============================ Sentence 266 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 267 =============================

A model’s internal decisions are often hidden from view, so you should   make sure that the model isn’t doing too much in the first place. 


>> Tokens are: 
[model, internal, decisions, hidden, view, ,,   , sure, model, place, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('internal', 'ADJ'), ('decisions', 'NOUN'), ('hidden', 'VERB'), ('view', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('sure', 'ADJ'), ('model', 'NOUN'), ('place', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'poss'), ('internal', 'amod'), ('decisions', 'nsubjpass'), ('hidden', 'ccomp'), ('view', 'pobj'), (',', 'punct'), ('  ', 'nsubj'), ('sure', 'ccomp'), ('model', 'nsubj'), ('place', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[model, internal], [internal, decisions], [decisions, hidden], [hidden, view], [view, ,], [,,   ], [  , sure], [sure, model], [model, place], [place, .]]

>> Trigrams: 
[[model, internal, decisions], [internal, decisions, hidden], [decisions, hidden, view], [hidden, view, ,], [view, ,,   ], [,,   , sure], [  , sure, model], [sure, model, place], [model, place, .]]

>> Noun Phrases are: 
[A model’s internal decisions, view, you, the model, the first place]

>> Named Entities are: 
[('first', 'ORDINAL')]


============================ Sentence 268 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 269 =============================

For example, if we were using one big model that analyzes an entire  document at once, we’d only be able to work at the document level. 


>> Tokens are: 
[example, ,, big, model, analyzes, entire,  , document, ,, able, work, document, level, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('big', 'ADJ'), ('model', 'NOUN'), ('analyzes', 'VERB'), ('entire', 'ADJ'), (' ', 'SPACE'), ('document', 'NOUN'), (',', 'PUNCT'), ('able', 'ADJ'), ('work', 'VERB'), ('document', 'NOUN'), ('level', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('big', 'amod'), ('model', 'dobj'), ('analyzes', 'relcl'), ('entire', 'amod'), (' ', 'compound'), ('document', 'dobj'), (',', 'punct'), ('able', 'acomp'), ('work', 'xcomp'), ('document', 'compound'), ('level', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, big], [big, model], [model, analyzes], [analyzes, entire], [entire,  ], [ , document], [document, ,], [,, able], [able, work], [work, document], [document, level], [level, .]]

>> Trigrams: 
[[example, ,, big], [,, big, model], [big, model, analyzes], [model, analyzes, entire], [analyzes, entire,  ], [entire,  , document], [ , document, ,], [document, ,, able], [,, able, work], [able, work, document], [work, document, level], [document, level, .]]

>> Noun Phrases are: 
[example, we, one big model, an entire  document, we, the document level]

>> Named Entities are: 
[('one', 'CARDINAL')]


============================ Sentence 270 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 271 =============================

Instead, Lexalytics utilizes a pipeline interaction between our models. 


>> Tokens are: 
[Instead, ,, Lexalytics, utilizes, pipeline, interaction, models, .] 

>> PoS Tags are: 
[('Instead', 'ADV'), (',', 'PUNCT'), ('Lexalytics', 'PROPN'), ('utilizes', 'VERB'), ('pipeline', 'NOUN'), ('interaction', 'NOUN'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Instead', 'advmod'), (',', 'punct'), ('Lexalytics', 'nsubj'), ('utilizes', 'ROOT'), ('pipeline', 'compound'), ('interaction', 'dobj'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Instead, ,], [,, Lexalytics], [Lexalytics, utilizes], [utilizes, pipeline], [pipeline, interaction], [interaction, models], [models, .]]

>> Trigrams: 
[[Instead, ,, Lexalytics], [,, Lexalytics, utilizes], [Lexalytics, utilizes, pipeline], [utilizes, pipeline, interaction], [pipeline, interaction, models], [interaction, models, .]]

>> Noun Phrases are: 
[Lexalytics, a pipeline interaction, our models]

>> Named Entities are: 
[('Lexalytics', 'ORG')]


============================ Sentence 272 =============================

  We start with tokenization, move on to parts of speech, then to phrases,   and all the way up until we’ve deconstructed the document at every   level. 


>> Tokens are: 
[  , start, tokenization, ,, parts, speech, ,, phrases, ,,   , way, deconstructed, document,   , level, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('start', 'VERB'), ('tokenization', 'NOUN'), (',', 'PUNCT'), ('parts', 'NOUN'), ('speech', 'NOUN'), (',', 'PUNCT'), ('phrases', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('way', 'NOUN'), ('deconstructed', 'VERB'), ('document', 'NOUN'), ('  ', 'SPACE'), ('level', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'npadvmod'), ('start', 'ROOT'), ('tokenization', 'pobj'), (',', 'punct'), ('parts', 'pobj'), ('speech', 'pobj'), (',', 'punct'), ('phrases', 'pobj'), (',', 'punct'), ('  ', 'conj'), ('way', 'npadvmod'), ('deconstructed', 'advcl'), ('document', 'dobj'), ('  ', 'nummod'), ('level', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[  , start], [start, tokenization], [tokenization, ,], [,, parts], [parts, speech], [speech, ,], [,, phrases], [phrases, ,], [,,   ], [  , way], [way, deconstructed], [deconstructed, document], [document,   ], [  , level], [level, .]]

>> Trigrams: 
[[  , start, tokenization], [start, tokenization, ,], [tokenization, ,, parts], [,, parts, speech], [parts, speech, ,], [speech, ,, phrases], [,, phrases, ,], [phrases, ,,   ], [,,   , way], [  , way, deconstructed], [way, deconstructed, document], [deconstructed, document,   ], [document,   , level], [  , level, .]]

>> Noun Phrases are: 
[We, tokenization, parts, speech, phrases, we, the document, every   level]

>> Named Entities are: 
[]


============================ Sentence 273 =============================

When there’s an issue in the pipeline, this approach helps us  see exactly where it is. 


>> Tokens are: 
[issue, pipeline, ,, approach, helps,  , exactly, .] 

>> PoS Tags are: 
[('issue', 'NOUN'), ('pipeline', 'NOUN'), (',', 'PUNCT'), ('approach', 'NOUN'), ('helps', 'VERB'), (' ', 'SPACE'), ('exactly', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('issue', 'attr'), ('pipeline', 'pobj'), (',', 'punct'), ('approach', 'nsubj'), ('helps', 'ROOT'), (' ', 'nsubj'), ('exactly', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[issue, pipeline], [pipeline, ,], [,, approach], [approach, helps], [helps,  ], [ , exactly], [exactly, .]]

>> Trigrams: 
[[issue, pipeline, ,], [pipeline, ,, approach], [,, approach, helps], [approach, helps,  ], [helps,  , exactly], [ , exactly, .]]

>> Noun Phrases are: 
[an issue, the pipeline, this approach, us, it]

>> Named Entities are: 
[]


============================ Sentence 274 =============================

Then, we can make adjustments to individual  components, such as retraining the part of speech tagger or tuning  its configuration files. 


>> Tokens are: 
[,, adjustments, individual,  , components, ,, retraining, speech, tagger, tuning,  , configuration, files, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('adjustments', 'NOUN'), ('individual', 'ADJ'), (' ', 'SPACE'), ('components', 'NOUN'), (',', 'PUNCT'), ('retraining', 'VERB'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('tuning', 'VERB'), (' ', 'SPACE'), ('configuration', 'NOUN'), ('files', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('adjustments', 'dobj'), ('individual', 'amod'), (' ', 'compound'), ('components', 'pobj'), (',', 'punct'), ('retraining', 'pcomp'), ('speech', 'compound'), ('tagger', 'pobj'), ('tuning', 'conj'), (' ', 'dobj'), ('configuration', 'compound'), ('files', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[,, adjustments], [adjustments, individual], [individual,  ], [ , components], [components, ,], [,, retraining], [retraining, speech], [speech, tagger], [tagger, tuning], [tuning,  ], [ , configuration], [configuration, files], [files, .]]

>> Trigrams: 
[[,, adjustments, individual], [adjustments, individual,  ], [individual,  , components], [ , components, ,], [components, ,, retraining], [,, retraining, speech], [retraining, speech, tagger], [speech, tagger, tuning], [tagger, tuning,  ], [tuning,  , configuration], [ , configuration, files], [configuration, files, .]]

>> Noun Phrases are: 
[we, adjustments, individual  components, the part, speech tagger, its configuration files]

>> Named Entities are: 
[]


============================ Sentence 275 =============================

Using smaller models gives us more flexibility to  determine where an issue is, as well as how to fix it. 


>> Tokens are: 
[smaller, models, gives, flexibility,  , determine, issue, ,, fix, .] 

>> PoS Tags are: 
[('smaller', 'ADJ'), ('models', 'NOUN'), ('gives', 'VERB'), ('flexibility', 'NOUN'), (' ', 'SPACE'), ('determine', 'VERB'), ('issue', 'NOUN'), (',', 'PUNCT'), ('fix', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('smaller', 'amod'), ('models', 'dobj'), ('gives', 'ROOT'), ('flexibility', 'dobj'), (' ', 'pobj'), ('determine', 'conj'), ('issue', 'nsubj'), (',', 'punct'), ('fix', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[smaller, models], [models, gives], [gives, flexibility], [flexibility,  ], [ , determine], [determine, issue], [issue, ,], [,, fix], [fix, .]]

>> Trigrams: 
[[smaller, models, gives], [models, gives, flexibility], [gives, flexibility,  ], [flexibility,  , determine], [ , determine, issue], [determine, issue, ,], [issue, ,, fix], [,, fix, .]]

>> Noun Phrases are: 
[smaller models, us, more flexibility, an issue, it]

>> Named Entities are: 
[]


============================ Sentence 276 =============================

  Take the phrase “Good   Morning America.” 


>> Tokens are: 
[  , phrase, “, Good,   , Morning, America, ., ”] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'ADJ'), ('  ', 'SPACE'), ('Morning', 'PROPN'), ('America', 'PROPN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('phrase', 'dobj'), ('“', 'punct'), ('Good', 'amod'), ('  ', 'appos'), ('Morning', 'compound'), ('America', 'appos'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[  , phrase], [phrase, “], [“, Good], [Good,   ], [  , Morning], [Morning, America], [America, .], [., ”]]

>> Trigrams: 
[[  , phrase, “], [phrase, “, Good], [“, Good,   ], [Good,   , Morning], [  , Morning, America], [Morning, America, .], [America, ., ”]]

>> Noun Phrases are: 
[the phrase, Morning America]

>> Named Entities are: 
[]


============================ Sentence 277 =============================

It looks  innocuous, but it’s not. 


>> Tokens are: 
[looks,  , innocuous, ,, .] 

>> PoS Tags are: 
[('looks', 'VERB'), (' ', 'SPACE'), ('innocuous', 'ADJ'), (',', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('looks', 'ROOT'), (' ', 'dobj'), ('innocuous', 'acomp'), (',', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[looks,  ], [ , innocuous], [innocuous, ,], [,, .]]

>> Trigrams: 
[[looks,  , innocuous], [ , innocuous, ,], [innocuous, ,, .]]

>> Noun Phrases are: 
[It, it]

>> Named Entities are: 
[]


============================ Sentence 278 =============================

If your  part-of-speech tagger fails to  apply “proper noun” to the  phrase “Good Morning America,”  this phrase won’t be denoted   as being an entity. 


>> Tokens are: 
[ , -, -, speech, tagger, fails,  , apply, “, proper, noun, ”,  , phrase, “, Good, Morning, America, ,, ”,  , phrase, wo, denoted,   , entity, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('fails', 'VERB'), (' ', 'SPACE'), ('apply', 'VERB'), ('“', 'PUNCT'), ('proper', 'ADJ'), ('noun', 'NOUN'), ('”', 'PUNCT'), (' ', 'SPACE'), ('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'PROPN'), ('Morning', 'PROPN'), ('America', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('phrase', 'NOUN'), ('wo', 'AUX'), ('denoted', 'VERB'), ('  ', 'SPACE'), ('entity', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('-', 'punct'), ('-', 'punct'), ('speech', 'pobj'), ('tagger', 'nsubj'), ('fails', 'advcl'), (' ', 'nsubj'), ('apply', 'xcomp'), ('“', 'punct'), ('proper', 'amod'), ('noun', 'dobj'), ('”', 'punct'), (' ', 'compound'), ('phrase', 'pobj'), ('“', 'punct'), ('Good', 'compound'), ('Morning', 'compound'), ('America', 'appos'), (',', 'punct'), ('”', 'punct'), (' ', 'dep'), ('phrase', 'nsubjpass'), ('wo', 'aux'), ('denoted', 'ROOT'), ('  ', 'dobj'), ('entity', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[ , -], [-, -], [-, speech], [speech, tagger], [tagger, fails], [fails,  ], [ , apply], [apply, “], [“, proper], [proper, noun], [noun, ”], [”,  ], [ , phrase], [phrase, “], [“, Good], [Good, Morning], [Morning, America], [America, ,], [,, ”], [”,  ], [ , phrase], [phrase, wo], [wo, denoted], [denoted,   ], [  , entity], [entity, .]]

>> Trigrams: 
[[ , -, -], [-, -, speech], [-, speech, tagger], [speech, tagger, fails], [tagger, fails,  ], [fails,  , apply], [ , apply, “], [apply, “, proper], [“, proper, noun], [proper, noun, ”], [noun, ”,  ], [”,  , phrase], [ , phrase, “], [phrase, “, Good], [“, Good, Morning], [Good, Morning, America], [Morning, America, ,], [America, ,, ”], [,, ”,  ], [”,  , phrase], [ , phrase, wo], [phrase, wo, denoted], [wo, denoted,   ], [denoted,   , entity], [  , entity, .]]

>> Noun Phrases are: 
[speech, “proper noun, the  phrase, Good Morning America, this phrase, an entity]

>> Named Entities are: 
[('Good Morning America', 'WORK_OF_ART')]


============================ Sentence 279 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 280 =============================

You have to know that it’s an entity (TV Show) and not a greeting. 


>> Tokens are: 
[know, entity, (, TV, ), greeting, .] 

>> PoS Tags are: 
[('know', 'VERB'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('TV', 'PROPN'), (')', 'PUNCT'), ('greeting', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('know', 'xcomp'), ('entity', 'attr'), ('(', 'punct'), ('TV', 'compound'), (')', 'punct'), ('greeting', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[know, entity], [entity, (], [(, TV], [TV, )], [), greeting], [greeting, .]]

>> Trigrams: 
[[know, entity, (], [entity, (, TV], [(, TV, )], [TV, ), greeting], [), greeting, .]]

>> Noun Phrases are: 
[You, it, an entity, (TV Show, not a greeting]

>> Named Entities are: 
[]


============================ Sentence 281 =============================

If you   don’t, you might interpret “good” as being positive, rather than just part   of the entity name. 


>> Tokens are: 
[  , ,, interpret, “, good, ”, positive, ,,   , entity, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), (',', 'PUNCT'), ('interpret', 'VERB'), ('“', 'PUNCT'), ('good', 'ADJ'), ('”', 'PUNCT'), ('positive', 'ADJ'), (',', 'PUNCT'), ('  ', 'SPACE'), ('entity', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'appos'), (',', 'punct'), ('interpret', 'ROOT'), ('“', 'punct'), ('good', 'dobj'), ('”', 'punct'), ('positive', 'acomp'), (',', 'punct'), ('  ', 'dobj'), ('entity', 'compound'), ('.', 'punct')]

>> Bigrams: 
[[  , ,], [,, interpret], [interpret, “], [“, good], [good, ”], [”, positive], [positive, ,], [,,   ], [  , entity], [entity, .]]

>> Trigrams: 
[[  , ,, interpret], [,, interpret, “], [interpret, “, good], [“, good, ”], [good, ”, positive], [”, positive, ,], [positive, ,,   ], [,,   , entity], [  , entity, .]]

>> Noun Phrases are: 
[you, you, the entity name]

>> Named Entities are: 
[]


============================ Sentence 282 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 283 =============================

GOOD MORNING AMERICA is a registered trademark and brand of American Broadcasting Companies, Inc.  and is not affiliated with Lexalytics, 


>> Tokens are: 
[GOOD, MORNING, AMERICA, registered, trademark, brand, American, Broadcasting, Companies, ,, Inc.,  , affiliated, Lexalytics, ,] 

>> PoS Tags are: 
[('GOOD', 'ADJ'), ('MORNING', 'PROPN'), ('AMERICA', 'PROPN'), ('registered', 'VERB'), ('trademark', 'NOUN'), ('brand', 'NOUN'), ('American', 'PROPN'), ('Broadcasting', 'PROPN'), ('Companies', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (' ', 'SPACE'), ('affiliated', 'VERB'), ('Lexalytics', 'PROPN'), (',', 'PUNCT')] 

>> Dependency Tags are: 
[('GOOD', 'amod'), ('MORNING', 'compound'), ('AMERICA', 'nsubj'), ('registered', 'amod'), ('trademark', 'attr'), ('brand', 'conj'), ('American', 'compound'), ('Broadcasting', 'compound'), ('Companies', 'pobj'), (',', 'punct'), ('Inc.', 'appos'), (' ', 'conj'), ('affiliated', 'conj'), ('Lexalytics', 'pobj'), (',', 'punct')]

>> Bigrams: 
[[GOOD, MORNING], [MORNING, AMERICA], [AMERICA, registered], [registered, trademark], [trademark, brand], [brand, American], [American, Broadcasting], [Broadcasting, Companies], [Companies, ,], [,, Inc.], [Inc.,  ], [ , affiliated], [affiliated, Lexalytics], [Lexalytics, ,]]

>> Trigrams: 
[[GOOD, MORNING, AMERICA], [MORNING, AMERICA, registered], [AMERICA, registered, trademark], [registered, trademark, brand], [trademark, brand, American], [brand, American, Broadcasting], [American, Broadcasting, Companies], [Broadcasting, Companies, ,], [Companies, ,, Inc.], [,, Inc.,  ], [Inc.,  , affiliated], [ , affiliated, Lexalytics], [affiliated, Lexalytics, ,]]

>> Noun Phrases are: 
[GOOD MORNING AMERICA, a registered trademark, brand, American Broadcasting Companies, Inc., Lexalytics]

>> Named Entities are: 
[('American Broadcasting Companies, Inc.', 'ORG'), ('Lexalytics', 'ORG')]


============================ Sentence 284 =============================

Inc  https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[Inc,  , https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('Inc', 'PROPN'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('Inc', 'nmod'), (' ', 'compound'), ('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos'), ('W', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[Inc,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[Inc,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[Inc  https://www.lexalytics.com/ https://www.lexalytics.com/, W H]

>> Named Entities are: 
[('Inc  ', 'PERSON')]


============================ Sentence 285 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 286 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 287 =============================

P A P E R  12|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 12|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('12|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'compound'), (' ', 'compound'), ('12|', 'compound'), ('      ', 'ROOT'), ('|', 'punct'), ('  ', 'prep'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 12|], [12|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 12|], [ , 12|,       ], [12|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 288 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 289 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 290 =============================

T U N E  F I R S T ,  T H 


>> Tokens are: 
[T, U, N, E,  , F, R, S, T, ,,  , T, H] 

>> PoS Tags are: 
[('T', 'NOUN'), ('U', 'NOUN'), ('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('F', 'NOUN'), ('R', 'NOUN'), ('S', 'PROPN'), ('T', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'compound'), ('U', 'nmod'), ('N', 'compound'), ('E', 'appos'), (' ', 'appos'), ('F', 'compound'), ('R', 'compound'), ('S', 'compound'), ('T', 'ROOT'), (',', 'punct'), (' ', 'appos'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[T, U], [U, N], [N, E], [E,  ], [ , F], [F, R], [R, S], [S, T], [T, ,], [,,  ], [ , T], [T, H]]

>> Trigrams: 
[[T, U, N], [U, N, E], [N, E,  ], [E,  , F], [ , F, R], [F, R, S], [R, S, T], [S, T, ,], [T, ,,  ], [,,  , T], [ , T, H]]

>> Noun Phrases are: 
[N E, T H]

>> Named Entities are: 
[]


============================ Sentence 291 =============================

E N  T R A 


>> Tokens are: 
[E, N,  , T, R] 

>> PoS Tags are: 
[('E', 'NOUN'), ('N', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'ROOT'), ('N', 'npadvmod'), (' ', 'compound'), ('T', 'compound'), ('R', 'compound')]

>> Bigrams: 
[[E, N], [N,  ], [ , T], [T, R]]

>> Trigrams: 
[[E, N,  ], [N,  , T], [ , T, R]]

>> Noun Phrases are: 
[E,  T R A]

>> Named Entities are: 
[]


============================ Sentence 292 =============================

I N :   E F F I C 


>> Tokens are: 
[N, :,   , E, F, F, C] 

>> PoS Tags are: 
[('N', 'NUM'), (':', 'PUNCT'), ('  ', 'SPACE'), ('E', 'NOUN'), ('F', 'NOUN'), ('F', 'NOUN'), ('C', 'NOUN')] 

>> Dependency Tags are: 
[('N', 'appos'), (':', 'punct'), ('  ', 'appos'), ('E', 'compound'), ('F', 'compound'), ('F', 'appos'), ('C', 'appos')]

>> Bigrams: 
[[N, :], [:,   ], [  , E], [E, F], [F, F], [F, C]]

>> Trigrams: 
[[N, :,   ], [:,   , E], [  , E, F], [E, F, F], [F, F, C]]

>> Noun Phrases are: 
[I, E F F, I]

>> Named Entities are: 
[]


============================ Sentence 293 =============================

I E N C Y  B E F O R 


>> Tokens are: 
[E, N, C, Y,  , B, E, F, O, R] 

>> PoS Tags are: 
[('E', 'NOUN'), ('N', 'PROPN'), ('C', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('B', 'NOUN'), ('E', 'NOUN'), ('F', 'NOUN'), ('O', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'ROOT'), ('N', 'compound'), ('C', 'compound'), ('Y', 'compound'), (' ', 'compound'), ('B', 'compound'), ('E', 'compound'), ('F', 'compound'), ('O', 'compound'), ('R', 'appos')]

>> Bigrams: 
[[E, N], [N, C], [C, Y], [Y,  ], [ , B], [B, E], [E, F], [F, O], [O, R]]

>> Trigrams: 
[[E, N, C], [N, C, Y], [C, Y,  ], [Y,  , B], [ , B, E], [B, E, F], [E, F, O], [F, O, R]]

>> Noun Phrases are: 
[I E, N C Y  B E F O R]

>> Named Entities are: 
[]


============================ Sentence 294 =============================

E  C O M P L E X 


>> Tokens are: 
[E,  , C, O, M, P, L, E, X] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('C', 'NOUN'), ('O', 'NOUN'), ('M', 'NOUN'), ('P', 'NOUN'), ('L', 'PROPN'), ('E', 'PROPN'), ('X', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'appos'), ('C', 'compound'), ('O', 'compound'), ('M', 'compound'), ('P', 'compound'), ('L', 'compound'), ('E', 'compound'), ('X', 'ROOT')]

>> Bigrams: 
[[E,  ], [ , C], [C, O], [O, M], [M, P], [P, L], [L, E], [E, X]]

>> Trigrams: 
[[E,  , C], [ , C, O], [C, O, M], [O, M, P], [M, P, L], [P, L, E], [L, E, X]]

>> Noun Phrases are: 
[E  C O M P L E X]

>> Named Entities are: 
[]


============================ Sentence 295 =============================

I T Y   


>> Tokens are: 
[T, Y,  ] 

>> PoS Tags are: 
[('T', 'NOUN'), ('Y', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('T', 'compound'), ('Y', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[T, Y], [Y,  ]]

>> Trigrams: 
[[T, Y,  ]]

>> Noun Phrases are: 
[I T Y]

>> Named Entities are: 
[]


============================ Sentence 296 =============================

We have a whole white paper devoted to this discussion, but let’s review   the key points. 


>> Tokens are: 
[white, paper, devoted, discussion, ,, let, review,   , key, points, .] 

>> PoS Tags are: 
[('white', 'ADJ'), ('paper', 'NOUN'), ('devoted', 'VERB'), ('discussion', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('review', 'VERB'), ('  ', 'SPACE'), ('key', 'ADJ'), ('points', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('white', 'amod'), ('paper', 'dobj'), ('devoted', 'acl'), ('discussion', 'pobj'), (',', 'punct'), ('let', 'conj'), ('review', 'ccomp'), ('  ', 'dobj'), ('key', 'amod'), ('points', 'npadvmod'), ('.', 'punct')]

>> Bigrams: 
[[white, paper], [paper, devoted], [devoted, discussion], [discussion, ,], [,, let], [let, review], [review,   ], [  , key], [key, points], [points, .]]

>> Trigrams: 
[[white, paper, devoted], [paper, devoted, discussion], [devoted, discussion, ,], [discussion, ,, let], [,, let, review], [let, review,   ], [review,   , key], [  , key, points], [key, points, .]]

>> Noun Phrases are: 
[We, a whole white paper, this discussion, ’s]

>> Named Entities are: 
[('’s', 'GPE')]


============================ Sentence 297 =============================

We talked above about how machine learning is really  machine teaching, and how changing how a model interprets something  means having to convince it to do that. 


>> Tokens are: 
[talked, machine, learning,  , machine, teaching, ,, changing, model, interprets,  , means, having, convince, .] 

>> PoS Tags are: 
[('talked', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('teaching', 'NOUN'), (',', 'PUNCT'), ('changing', 'VERB'), ('model', 'NOUN'), ('interprets', 'VERB'), (' ', 'SPACE'), ('means', 'VERB'), ('having', 'VERB'), ('convince', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('talked', 'ROOT'), ('machine', 'compound'), ('learning', 'nsubj'), (' ', 'amod'), ('machine', 'compound'), ('teaching', 'attr'), (',', 'punct'), ('changing', 'conj'), ('model', 'nsubj'), ('interprets', 'ccomp'), (' ', 'nsubj'), ('means', 'relcl'), ('having', 'xcomp'), ('convince', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[talked, machine], [machine, learning], [learning,  ], [ , machine], [machine, teaching], [teaching, ,], [,, changing], [changing, model], [model, interprets], [interprets,  ], [ , means], [means, having], [having, convince], [convince, .]]

>> Trigrams: 
[[talked, machine, learning], [machine, learning,  ], [learning,  , machine], [ , machine, teaching], [machine, teaching, ,], [teaching, ,, changing], [,, changing, model], [changing, model, interprets], [model, interprets,  ], [interprets,  , means], [ , means, having], [means, having, convince], [having, convince, .]]

>> Noun Phrases are: 
[We, machine learning, really  machine teaching, a model, something, it]

>> Named Entities are: 
[]


============================ Sentence 298 =============================

To achieve this, you have to have   data, and enough of it, that supports the changes needed to make the  model behave differently. 


>> Tokens are: 
[achieve, ,,   , data, ,, ,, supports, changes, needed,  , model, behave, differently, .] 

>> PoS Tags are: 
[('achieve', 'VERB'), (',', 'PUNCT'), ('  ', 'SPACE'), ('data', 'NOUN'), (',', 'PUNCT'), (',', 'PUNCT'), ('supports', 'VERB'), ('changes', 'NOUN'), ('needed', 'VERB'), (' ', 'SPACE'), ('model', 'NOUN'), ('behave', 'VERB'), ('differently', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('achieve', 'advcl'), (',', 'punct'), ('  ', 'nummod'), ('data', 'dobj'), (',', 'punct'), (',', 'punct'), ('supports', 'conj'), ('changes', 'dobj'), ('needed', 'acl'), (' ', 'compound'), ('model', 'nsubj'), ('behave', 'ccomp'), ('differently', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[achieve, ,], [,,   ], [  , data], [data, ,], [,, ,], [,, supports], [supports, changes], [changes, needed], [needed,  ], [ , model], [model, behave], [behave, differently], [differently, .]]

>> Trigrams: 
[[achieve, ,,   ], [,,   , data], [  , data, ,], [data, ,, ,], [,, ,, supports], [,, supports, changes], [supports, changes, needed], [changes, needed,  ], [needed,  , model], [ , model, behave], [model, behave, differently], [behave, differently, .]]

>> Noun Phrases are: 
[you,   data, it, the changes, the  model]

>> Named Entities are: 
[]


============================ Sentence 299 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 300 =============================

This is different than tuning. 


>> Tokens are: 
[different, tuning, .] 

>> PoS Tags are: 
[('different', 'ADJ'), ('tuning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('different', 'acomp'), ('tuning', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[different, tuning], [tuning, .]]

>> Trigrams: 
[[different, tuning, .]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 301 =============================

Tuning is a type of written instruction. 


>> Tokens are: 
[Tuning, type, written, instruction, .] 

>> PoS Tags are: 
[('Tuning', 'NOUN'), ('type', 'NOUN'), ('written', 'VERB'), ('instruction', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Tuning', 'nsubj'), ('type', 'attr'), ('written', 'amod'), ('instruction', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Tuning, type], [type, written], [written, instruction], [instruction, .]]

>> Trigrams: 
[[Tuning, type, written], [type, written, instruction], [written, instruction, .]]

>> Noun Phrases are: 
[Tuning, a type, written instruction]

>> Named Entities are: 
[]


============================ Sentence 302 =============================

With  tuning, you might tell a model that the airport term “gate change” carries    -0.5 sentiment points, and that this value should be used every time the  model sees the phrase. 


>> Tokens are: 
[ , tuning, ,, tell, model, airport, term, “, gate, change, ”, carries,    , -0.5, sentiment, points, ,, value, time,  , model, sees, phrase, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('tuning', 'VERB'), (',', 'PUNCT'), ('tell', 'VERB'), ('model', 'NOUN'), ('airport', 'NOUN'), ('term', 'NOUN'), ('“', 'PUNCT'), ('gate', 'NOUN'), ('change', 'NOUN'), ('”', 'PUNCT'), ('carries', 'VERB'), ('   ', 'SPACE'), ('-0.5', 'NOUN'), ('sentiment', 'NOUN'), ('points', 'NOUN'), (',', 'PUNCT'), ('value', 'NOUN'), ('time', 'NOUN'), (' ', 'SPACE'), ('model', 'NOUN'), ('sees', 'VERB'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('tuning', 'pcomp'), (',', 'punct'), ('tell', 'ROOT'), ('model', 'dobj'), ('airport', 'nmod'), ('term', 'nmod'), ('“', 'punct'), ('gate', 'amod'), ('change', 'nsubj'), ('”', 'punct'), ('carries', 'ccomp'), ('   ', 'nummod'), ('-0.5', 'compound'), ('sentiment', 'compound'), ('points', 'dobj'), (',', 'punct'), ('value', 'nsubjpass'), ('time', 'npadvmod'), (' ', 'compound'), ('model', 'nsubj'), ('sees', 'relcl'), ('phrase', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , tuning], [tuning, ,], [,, tell], [tell, model], [model, airport], [airport, term], [term, “], [“, gate], [gate, change], [change, ”], [”, carries], [carries,    ], [   , -0.5], [-0.5, sentiment], [sentiment, points], [points, ,], [,, value], [value, time], [time,  ], [ , model], [model, sees], [sees, phrase], [phrase, .]]

>> Trigrams: 
[[ , tuning, ,], [tuning, ,, tell], [,, tell, model], [tell, model, airport], [model, airport, term], [airport, term, “], [term, “, gate], [“, gate, change], [gate, change, ”], [change, ”, carries], [”, carries,    ], [carries,    , -0.5], [   , -0.5, sentiment], [-0.5, sentiment, points], [sentiment, points, ,], [points, ,, value], [,, value, time], [value, time,  ], [time,  , model], [ , model, sees], [model, sees, phrase], [sees, phrase, .]]

>> Noun Phrases are: 
[you, a model, the airport term “gate change,    -0.5 sentiment points, this value, the  model, the phrase]

>> Named Entities are: 
[]


============================ Sentence 303 =============================

This new command will instantly apply to everything  that matches the entry. 


>> Tokens are: 
[new, command, instantly, apply,  , matches, entry, .] 

>> PoS Tags are: 
[('new', 'ADJ'), ('command', 'NOUN'), ('instantly', 'ADV'), ('apply', 'VERB'), (' ', 'SPACE'), ('matches', 'VERB'), ('entry', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('new', 'amod'), ('command', 'nsubj'), ('instantly', 'advmod'), ('apply', 'ROOT'), (' ', 'appos'), ('matches', 'relcl'), ('entry', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[new, command], [command, instantly], [instantly, apply], [apply,  ], [ , matches], [matches, entry], [entry, .]]

>> Trigrams: 
[[new, command, instantly], [command, instantly, apply], [instantly, apply,  ], [apply,  , matches], [ , matches, entry], [matches, entry, .]]

>> Noun Phrases are: 
[This new command, everything, the entry]

>> Named Entities are: 
[]


============================ Sentence 304 =============================

Training, on the other hand, requires the model  to parse a significant amount of data before it starts to apply (“learn”) the  change. 


>> Tokens are: 
[Training, ,, hand, ,, requires, model,  , parse, significant, data, starts, apply, (, “, learn, ”, ),  , change, .] 

>> PoS Tags are: 
[('Training', 'NOUN'), (',', 'PUNCT'), ('hand', 'NOUN'), (',', 'PUNCT'), ('requires', 'VERB'), ('model', 'NOUN'), (' ', 'SPACE'), ('parse', 'VERB'), ('significant', 'ADJ'), ('data', 'NOUN'), ('starts', 'VERB'), ('apply', 'VERB'), ('(', 'PUNCT'), ('“', 'PUNCT'), ('learn', 'VERB'), ('”', 'PUNCT'), (')', 'PUNCT'), (' ', 'SPACE'), ('change', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Training', 'nsubj'), (',', 'punct'), ('hand', 'pobj'), (',', 'punct'), ('requires', 'ROOT'), ('model', 'dobj'), (' ', 'appos'), ('parse', 'xcomp'), ('significant', 'amod'), ('data', 'pobj'), ('starts', 'advcl'), ('apply', 'xcomp'), ('(', 'punct'), ('“', 'punct'), ('learn', 'parataxis'), ('”', 'punct'), (')', 'punct'), (' ', 'compound'), ('change', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Training, ,], [,, hand], [hand, ,], [,, requires], [requires, model], [model,  ], [ , parse], [parse, significant], [significant, data], [data, starts], [starts, apply], [apply, (], [(, “], [“, learn], [learn, ”], [”, )], [),  ], [ , change], [change, .]]

>> Trigrams: 
[[Training, ,, hand], [,, hand, ,], [hand, ,, requires], [,, requires, model], [requires, model,  ], [model,  , parse], [ , parse, significant], [parse, significant, data], [significant, data, starts], [data, starts, apply], [starts, apply, (], [apply, (, “], [(, “, learn], [“, learn, ”], [learn, ”, )], [”, ),  ], [),  , change], [ , change, .]]

>> Noun Phrases are: 
[Training, the other hand, the model, a significant amount, data, it, the  change]

>> Named Entities are: 
[]


============================ Sentence 305 =============================

Additionally, the more the model “wants” to score something a  particular way, the more that you’re going to have to work to change it. 


>> Tokens are: 
[Additionally, ,, model, “, wants, ”, score,  , particular, way, ,, going, work, change, .] 

>> PoS Tags are: 
[('Additionally', 'ADV'), (',', 'PUNCT'), ('model', 'NOUN'), ('“', 'PUNCT'), ('wants', 'VERB'), ('”', 'PUNCT'), ('score', 'VERB'), (' ', 'SPACE'), ('particular', 'ADJ'), ('way', 'NOUN'), (',', 'PUNCT'), ('going', 'VERB'), ('work', 'VERB'), ('change', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Additionally', 'advmod'), (',', 'punct'), ('model', 'nsubj'), ('“', 'punct'), ('wants', 'ROOT'), ('”', 'punct'), ('score', 'xcomp'), (' ', 'nmod'), ('particular', 'amod'), ('way', 'npadvmod'), (',', 'punct'), ('going', 'relcl'), ('work', 'xcomp'), ('change', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[Additionally, ,], [,, model], [model, “], [“, wants], [wants, ”], [”, score], [score,  ], [ , particular], [particular, way], [way, ,], [,, going], [going, work], [work, change], [change, .]]

>> Trigrams: 
[[Additionally, ,, model], [,, model, “], [model, “, wants], [“, wants, ”], [wants, ”, score], [”, score,  ], [score,  , particular], [ , particular, way], [particular, way, ,], [way, ,, going], [,, going, work], [going, work, change], [work, change, .]]

>> Noun Phrases are: 
[the model, something, you, it]

>> Named Entities are: 
[]


============================ Sentence 306 =============================

  Old habits are hard to unlearn for machine learning systems, too. 


>> Tokens are: 
[  , Old, habits, hard, unlearn, machine, learning, systems, ,, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Old', 'ADJ'), ('habits', 'NOUN'), ('hard', 'ADJ'), ('unlearn', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('systems', 'NOUN'), (',', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nummod'), ('Old', 'amod'), ('habits', 'nsubj'), ('hard', 'acomp'), ('unlearn', 'xcomp'), ('machine', 'compound'), ('learning', 'compound'), ('systems', 'pobj'), (',', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[  , Old], [Old, habits], [habits, hard], [hard, unlearn], [unlearn, machine], [machine, learning], [learning, systems], [systems, ,], [,, .]]

>> Trigrams: 
[[  , Old, habits], [Old, habits, hard], [habits, hard, unlearn], [hard, unlearn, machine], [unlearn, machine, learning], [machine, learning, systems], [learning, systems, ,], [systems, ,, .]]

>> Noun Phrases are: 
[  Old habits, machine learning systems]

>> Named Entities are: 
[]


============================ Sentence 307 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 308 =============================

Assuming the right use case, tuning will always be faster. 


>> Tokens are: 
[Assuming, right, use, case, ,, tuning, faster, .] 

>> PoS Tags are: 
[('Assuming', 'VERB'), ('right', 'ADJ'), ('use', 'NOUN'), ('case', 'NOUN'), (',', 'PUNCT'), ('tuning', 'NOUN'), ('faster', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Assuming', 'advcl'), ('right', 'amod'), ('use', 'compound'), ('case', 'dobj'), (',', 'punct'), ('tuning', 'nsubj'), ('faster', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Assuming, right], [right, use], [use, case], [case, ,], [,, tuning], [tuning, faster], [faster, .]]

>> Trigrams: 
[[Assuming, right, use], [right, use, case], [use, case, ,], [case, ,, tuning], [,, tuning, faster], [tuning, faster, .]]

>> Noun Phrases are: 
[the right use case, tuning]

>> Named Entities are: 
[]


============================ Sentence 309 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 310 =============================

But there are many cases when the use of a particular word    is so multifaceted or ambiguous that the number of tuning     rules we’d have to put into place is prohibitive. 


>> Tokens are: 
[cases, use, particular, word,    , multifaceted, ambiguous, number, tuning,     , rules, place, prohibitive, .] 

>> PoS Tags are: 
[('cases', 'NOUN'), ('use', 'NOUN'), ('particular', 'ADJ'), ('word', 'NOUN'), ('   ', 'SPACE'), ('multifaceted', 'ADJ'), ('ambiguous', 'ADJ'), ('number', 'NOUN'), ('tuning', 'VERB'), ('    ', 'SPACE'), ('rules', 'NOUN'), ('place', 'NOUN'), ('prohibitive', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('cases', 'attr'), ('use', 'nsubj'), ('particular', 'amod'), ('word', 'pobj'), ('   ', 'nummod'), ('multifaceted', 'acomp'), ('ambiguous', 'conj'), ('number', 'nsubj'), ('tuning', 'pcomp'), ('    ', 'compound'), ('rules', 'dobj'), ('place', 'pobj'), ('prohibitive', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[cases, use], [use, particular], [particular, word], [word,    ], [   , multifaceted], [multifaceted, ambiguous], [ambiguous, number], [number, tuning], [tuning,     ], [    , rules], [rules, place], [place, prohibitive], [prohibitive, .]]

>> Trigrams: 
[[cases, use, particular], [use, particular, word], [particular, word,    ], [word,    , multifaceted], [   , multifaceted, ambiguous], [multifaceted, ambiguous, number], [ambiguous, number, tuning], [number, tuning,     ], [tuning,     , rules], [    , rules, place], [rules, place, prohibitive], [place, prohibitive, .]]

>> Noun Phrases are: 
[many cases, the use, a particular word, the number,     rules, we, place]

>> Named Entities are: 
[]


============================ Sentence 311 =============================

This is where       machine learning shines. 


>> Tokens are: 
[      , machine, learning, shines, .] 

>> PoS Tags are: 
[('      ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('shines', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('      ', 'compound'), ('machine', 'compound'), ('learning', 'nsubj'), ('shines', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[      , machine], [machine, learning], [learning, shines], [shines, .]]

>> Trigrams: 
[[      , machine, learning], [machine, learning, shines], [learning, shines, .]]

>> Noun Phrases are: 
[      machine learning]

>> Named Entities are: 
[]


============================ Sentence 312 =============================

Give the model enough examples,         and it figures out the rules for itself. 


>> Tokens are: 
[model, examples, ,,         , figures, rules, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('examples', 'NOUN'), (',', 'PUNCT'), ('        ', 'SPACE'), ('figures', 'VERB'), ('rules', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'dative'), ('examples', 'dobj'), (',', 'punct'), ('        ', 'conj'), ('figures', 'conj'), ('rules', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[model, examples], [examples, ,], [,,         ], [        , figures], [figures, rules], [rules, .]]

>> Trigrams: 
[[model, examples, ,], [examples, ,,         ], [,,         , figures], [        , figures, rules], [figures, rules, .]]

>> Noun Phrases are: 
[the model, enough examples, it, the rules, itself]

>> Named Entities are: 
[]


============================ Sentence 313 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 314 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos'), ('W', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/, W H]

>> Named Entities are: 
[]


============================ Sentence 315 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 316 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 317 =============================

P A P E R  13|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 13|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('13|', 'NOUN'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'nmod'), ('R', 'compound'), (' ', 'compound'), ('13|', 'compound'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'prep'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 13|], [13|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 13|], [ , 13|,       ], [13|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[P A P E R  13|       |, Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 318 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 319 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 320 =============================

There are more potential side-effects of training that you must be aware of. 


>> Tokens are: 
[potential, -, effects, training, aware, .] 

>> PoS Tags are: 
[('potential', 'ADJ'), ('-', 'PUNCT'), ('effects', 'NOUN'), ('training', 'NOUN'), ('aware', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('potential', 'amod'), ('-', 'punct'), ('effects', 'attr'), ('training', 'pobj'), ('aware', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[potential, -], [-, effects], [effects, training], [training, aware], [aware, .]]

>> Trigrams: 
[[potential, -, effects], [-, effects, training], [effects, training, aware], [training, aware, .]]

>> Noun Phrases are: 
[more potential side-effects, training, you]

>> Named Entities are: 
[]


============================ Sentence 321 =============================

  Say we’re scoring a bunch of documents to try to effect change on a  particular phrase. 


>> Tokens are: 
[  , scoring, bunch, documents, try, effect, change,  , particular, phrase, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('scoring', 'VERB'), ('bunch', 'NOUN'), ('documents', 'NOUN'), ('try', 'VERB'), ('effect', 'VERB'), ('change', 'NOUN'), (' ', 'SPACE'), ('particular', 'ADJ'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('scoring', 'ccomp'), ('bunch', 'dobj'), ('documents', 'pobj'), ('try', 'relcl'), ('effect', 'xcomp'), ('change', 'dobj'), (' ', 'nmod'), ('particular', 'amod'), ('phrase', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[  , scoring], [scoring, bunch], [bunch, documents], [documents, try], [try, effect], [effect, change], [change,  ], [ , particular], [particular, phrase], [phrase, .]]

>> Trigrams: 
[[  , scoring, bunch], [scoring, bunch, documents], [bunch, documents, try], [documents, try, effect], [try, effect, change], [effect, change,  ], [change,  , particular], [ , particular, phrase], [particular, phrase, .]]

>> Noun Phrases are: 
[we, a bunch, documents, change, a  particular phrase]

>> Named Entities are: 
[]


============================ Sentence 322 =============================

Each of those documents contains more than that one  phrase, and the other phrases in each document will also be affected by our  scoring and re-tuning. 


>> Tokens are: 
[documents, contains,  , phrase, ,, phrases, document, affected,  , scoring, -, tuning, .] 

>> PoS Tags are: 
[('documents', 'NOUN'), ('contains', 'VERB'), (' ', 'SPACE'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('phrases', 'NOUN'), ('document', 'NOUN'), ('affected', 'VERB'), (' ', 'SPACE'), ('scoring', 'NOUN'), ('-', 'NOUN'), ('tuning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('documents', 'pobj'), ('contains', 'ROOT'), (' ', 'compound'), ('phrase', 'pobj'), (',', 'punct'), ('phrases', 'nsubjpass'), ('document', 'pobj'), ('affected', 'conj'), (' ', 'compound'), ('scoring', 'pobj'), ('-', 'conj'), ('tuning', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[documents, contains], [contains,  ], [ , phrase], [phrase, ,], [,, phrases], [phrases, document], [document, affected], [affected,  ], [ , scoring], [scoring, -], [-, tuning], [tuning, .]]

>> Trigrams: 
[[documents, contains,  ], [contains,  , phrase], [ , phrase, ,], [phrase, ,, phrases], [,, phrases, document], [phrases, document, affected], [document, affected,  ], [affected,  , scoring], [ , scoring, -], [scoring, -, tuning], [-, tuning, .]]

>> Noun Phrases are: 
[those documents, that one  phrase, the other phrases, each document, our  scoring, re, -]

>> Named Entities are: 
[]


============================ Sentence 323 =============================

This is particularly true of common phrases, which  appear often enough that they end up influencing the model. 


>> Tokens are: 
[particularly, true, common, phrases, ,,  , appear, end, influencing, model, .] 

>> PoS Tags are: 
[('particularly', 'ADV'), ('true', 'ADJ'), ('common', 'ADJ'), ('phrases', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('appear', 'VERB'), ('end', 'VERB'), ('influencing', 'VERB'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('particularly', 'advmod'), ('true', 'acomp'), ('common', 'amod'), ('phrases', 'pobj'), (',', 'punct'), (' ', 'nsubj'), ('appear', 'relcl'), ('end', 'ccomp'), ('influencing', 'xcomp'), ('model', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[particularly, true], [true, common], [common, phrases], [phrases, ,], [,,  ], [ , appear], [appear, end], [end, influencing], [influencing, model], [model, .]]

>> Trigrams: 
[[particularly, true, common], [true, common, phrases], [common, phrases, ,], [phrases, ,,  ], [,,  , appear], [ , appear, end], [appear, end, influencing], [end, influencing, model], [influencing, model, .]]

>> Noun Phrases are: 
[common phrases, they, the model]

>> Named Entities are: 
[]


============================ Sentence 324 =============================

  Imagine that you’re scoring news stories from 2008. 


>> Tokens are: 
[  , Imagine, scoring, news, stories, 2008, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Imagine', 'VERB'), ('scoring', 'VERB'), ('news', 'NOUN'), ('stories', 'NOUN'), ('2008', 'NUM'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('Imagine', 'ROOT'), ('scoring', 'ccomp'), ('news', 'compound'), ('stories', 'dobj'), ('2008', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[  , Imagine], [Imagine, scoring], [scoring, news], [news, stories], [stories, 2008], [2008, .]]

>> Trigrams: 
[[  , Imagine, scoring], [Imagine, scoring, news], [scoring, news, stories], [news, stories, 2008], [stories, 2008, .]]

>> Noun Phrases are: 
[you, news stories]

>> Named Entities are: 
[('2008', 'DATE')]


============================ Sentence 325 =============================

2008 was truly awful for  business and economics as a whole. 


>> Tokens are: 
[2008, truly, awful,  , business, economics, .] 

>> PoS Tags are: 
[('2008', 'NUM'), ('truly', 'ADV'), ('awful', 'ADJ'), (' ', 'SPACE'), ('business', 'NOUN'), ('economics', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('2008', 'nsubj'), ('truly', 'advmod'), ('awful', 'acomp'), (' ', 'pobj'), ('business', 'pobj'), ('economics', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[2008, truly], [truly, awful], [awful,  ], [ , business], [business, economics], [economics, .]]

>> Trigrams: 
[[2008, truly, awful], [truly, awful,  ], [awful,  , business], [ , business, economics], [business, economics, .]]

>> Noun Phrases are: 
[business, economics, a whole]

>> Named Entities are: 
[]


============================ Sentence 326 =============================

If you are focused on scoring financial  results from businesses, you’ll be marking a lot of content as negative. 


>> Tokens are: 
[focused, scoring, financial,  , results, businesses, ,, marking, lot, content, negative, .] 

>> PoS Tags are: 
[('focused', 'ADJ'), ('scoring', 'VERB'), ('financial', 'ADJ'), (' ', 'SPACE'), ('results', 'NOUN'), ('businesses', 'NOUN'), (',', 'PUNCT'), ('marking', 'VERB'), ('lot', 'NOUN'), ('content', 'NOUN'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('focused', 'acomp'), ('scoring', 'pcomp'), ('financial', 'amod'), (' ', 'compound'), ('results', 'dobj'), ('businesses', 'pobj'), (',', 'punct'), ('marking', 'ROOT'), ('lot', 'dobj'), ('content', 'pobj'), ('negative', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[focused, scoring], [scoring, financial], [financial,  ], [ , results], [results, businesses], [businesses, ,], [,, marking], [marking, lot], [lot, content], [content, negative], [negative, .]]

>> Trigrams: 
[[focused, scoring, financial], [scoring, financial,  ], [financial,  , results], [ , results, businesses], [results, businesses, ,], [businesses, ,, marking], [,, marking, lot], [marking, lot, content], [lot, content, negative], [content, negative, .]]

>> Noun Phrases are: 
[you, financial  results, businesses, you, a lot, content]

>> Named Entities are: 
[]


============================ Sentence 327 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 328 =============================

Then, machine learning algorithms will weigh the phrases in the content in  proportion to their occurrence. 


>> Tokens are: 
[,, machine, learning, algorithms, weigh, phrases, content,  , proportion, occurrence, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'VERB'), ('algorithms', 'NOUN'), ('weigh', 'VERB'), ('phrases', 'NOUN'), ('content', 'NOUN'), (' ', 'SPACE'), ('proportion', 'NOUN'), ('occurrence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('machine', 'compound'), ('learning', 'amod'), ('algorithms', 'nsubj'), ('weigh', 'ROOT'), ('phrases', 'dobj'), ('content', 'pobj'), (' ', 'pobj'), ('proportion', 'dobj'), ('occurrence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, machine], [machine, learning], [learning, algorithms], [algorithms, weigh], [weigh, phrases], [phrases, content], [content,  ], [ , proportion], [proportion, occurrence], [occurrence, .]]

>> Trigrams: 
[[,, machine, learning], [machine, learning, algorithms], [learning, algorithms, weigh], [algorithms, weigh, phrases], [weigh, phrases, content], [phrases, content,  ], [content,  , proportion], [ , proportion, occurrence], [proportion, occurrence, .]]

>> Noun Phrases are: 
[machine learning algorithms, the phrases, the content, proportion, their occurrence]

>> Named Entities are: 
[]


============================ Sentence 329 =============================

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 330 =============================

Unfortunately, that leaves some collateral damage: “first quarter,” “second  quarter,” “third quarter,” and “fourth quarter.” 


>> Tokens are: 
[Unfortunately, ,, leaves, collateral, damage, :, “, quarter, ,, ”, “, second,  , quarter, ,, ”, “, quarter, ,, ”, “, fourth, quarter, ., ”] 

>> PoS Tags are: 
[('Unfortunately', 'ADV'), (',', 'PUNCT'), ('leaves', 'VERB'), ('collateral', 'ADJ'), ('damage', 'NOUN'), (':', 'PUNCT'), ('“', 'PUNCT'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('second', 'ADJ'), (' ', 'SPACE'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('fourth', 'ADJ'), ('quarter', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Unfortunately', 'advmod'), (',', 'punct'), ('leaves', 'ROOT'), ('collateral', 'amod'), ('damage', 'dobj'), (':', 'punct'), ('“', 'punct'), ('quarter', 'npadvmod'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('second', 'amod'), (' ', 'compound'), ('quarter', 'npadvmod'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('quarter', 'dobj'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('fourth', 'amod'), ('quarter', 'conj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Unfortunately, ,], [,, leaves], [leaves, collateral], [collateral, damage], [damage, :], [:, “], [“, quarter], [quarter, ,], [,, ”], [”, “], [“, second], [second,  ], [ , quarter], [quarter, ,], [,, ”], [”, “], [“, quarter], [quarter, ,], [,, ”], [”, “], [“, fourth], [fourth, quarter], [quarter, .], [., ”]]

>> Trigrams: 
[[Unfortunately, ,, leaves], [,, leaves, collateral], [leaves, collateral, damage], [collateral, damage, :], [damage, :, “], [:, “, quarter], [“, quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, second], [“, second,  ], [second,  , quarter], [ , quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, quarter], [“, quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, fourth], [“, fourth, quarter], [fourth, quarter, .], [quarter, ., ”]]

>> Noun Phrases are: 
[some collateral damage, ” “third quarter, “fourth quarter]

>> Named Entities are: 
[('second', 'ORDINAL'), ('third', 'ORDINAL'), ('fourth', 'ORDINAL')]


============================ Sentence 331 =============================

These are neutral terms, but  they occurred in frequent conjunction with negative financial news. 


>> Tokens are: 
[neutral, terms, ,,  , occurred, frequent, conjunction, negative, financial, news, .] 

>> PoS Tags are: 
[('neutral', 'ADJ'), ('terms', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('occurred', 'VERB'), ('frequent', 'ADJ'), ('conjunction', 'NOUN'), ('negative', 'ADJ'), ('financial', 'ADJ'), ('news', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('neutral', 'amod'), ('terms', 'attr'), (',', 'punct'), (' ', 'conj'), ('occurred', 'relcl'), ('frequent', 'amod'), ('conjunction', 'pobj'), ('negative', 'amod'), ('financial', 'amod'), ('news', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[neutral, terms], [terms, ,], [,,  ], [ , occurred], [occurred, frequent], [frequent, conjunction], [conjunction, negative], [negative, financial], [financial, news], [news, .]]

>> Trigrams: 
[[neutral, terms, ,], [terms, ,,  ], [,,  , occurred], [ , occurred, frequent], [occurred, frequent, conjunction], [frequent, conjunction, negative], [conjunction, negative, financial], [negative, financial, news], [financial, news, .]]

>> Noun Phrases are: 
[neutral terms, they, frequent conjunction, negative financial news]

>> Named Entities are: 
[]


============================ Sentence 332 =============================

So, the  machine learning algorithm will weight those phrases as being negative. 


>> Tokens are: 
[,,  , machine, learning, algorithm, weight, phrases, negative, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithm', 'NOUN'), ('weight', 'VERB'), ('phrases', 'NOUN'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), (' ', 'compound'), ('machine', 'compound'), ('learning', 'amod'), ('algorithm', 'nsubj'), ('weight', 'ROOT'), ('phrases', 'dobj'), ('negative', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[,,  ], [ , machine], [machine, learning], [learning, algorithm], [algorithm, weight], [weight, phrases], [phrases, negative], [negative, .]]

>> Trigrams: 
[[,,  , machine], [ , machine, learning], [machine, learning, algorithm], [learning, algorithm, weight], [algorithm, weight, phrases], [weight, phrases, negative], [phrases, negative, .]]

>> Noun Phrases are: 
[the  machine learning algorithm, those phrases]

>> Named Entities are: 
[]


============================ Sentence 333 =============================

  That will end up negatively impacting your results for years to come. 


>> Tokens are: 
[  , end, negatively, impacting, results, years, come, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('end', 'VERB'), ('negatively', 'ADV'), ('impacting', 'VERB'), ('results', 'NOUN'), ('years', 'NOUN'), ('come', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'ROOT'), ('end', 'relcl'), ('negatively', 'advmod'), ('impacting', 'xcomp'), ('results', 'dobj'), ('years', 'pobj'), ('come', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[  , end], [end, negatively], [negatively, impacting], [impacting, results], [results, years], [years, come], [come, .]]

>> Trigrams: 
[[  , end, negatively], [end, negatively, impacting], [negatively, impacting, results], [impacting, results, years], [results, years, come], [years, come, .]]

>> Noun Phrases are: 
[your results, years]

>> Named Entities are: 
[('years', 'DATE')]


============================ Sentence 334 =============================

 Lexalytics has put a number of checks and balances into our text analytics  system to handle situations like this. 


>> Tokens are: 
[ , Lexalytics, number, checks, balances, text, analytics,  , system, handle, situations, like, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Lexalytics', 'PROPN'), ('number', 'NOUN'), ('checks', 'NOUN'), ('balances', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), (' ', 'SPACE'), ('system', 'NOUN'), ('handle', 'VERB'), ('situations', 'NOUN'), ('like', 'ADP'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('Lexalytics', 'nsubj'), ('number', 'dobj'), ('checks', 'pobj'), ('balances', 'conj'), ('text', 'compound'), ('analytics', 'pobj'), (' ', 'compound'), ('system', 'dobj'), ('handle', 'advcl'), ('situations', 'dobj'), ('like', 'prep'), ('.', 'punct')]

>> Bigrams: 
[[ , Lexalytics], [Lexalytics, number], [number, checks], [checks, balances], [balances, text], [text, analytics], [analytics,  ], [ , system], [system, handle], [handle, situations], [situations, like], [like, .]]

>> Trigrams: 
[[ , Lexalytics, number], [Lexalytics, number, checks], [number, checks, balances], [checks, balances, text], [balances, text, analytics], [text, analytics,  ], [analytics,  , system], [ , system, handle], [system, handle, situations], [handle, situations, like], [situations, like, .]]

>> Noun Phrases are: 
[ Lexalytics, a number, checks, balances, our text analytics,  system, situations]

>> Named Entities are: 
[('Lexalytics', 'ORG')]


============================ Sentence 335 =============================

Sometimes you just need to be able   to reach in and tell the software that “first quarter” is really just neutral,   despite what it might think. 


>> Tokens are: 
[need, able,   , reach, tell, software, “, quarter, ”, neutral, ,,   , despite, think, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('able', 'ADJ'), ('  ', 'SPACE'), ('reach', 'VERB'), ('tell', 'VERB'), ('software', 'NOUN'), ('“', 'PUNCT'), ('quarter', 'NOUN'), ('”', 'PUNCT'), ('neutral', 'ADJ'), (',', 'PUNCT'), ('  ', 'SPACE'), ('despite', 'SCONJ'), ('think', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('able', 'acomp'), ('  ', 'nsubj'), ('reach', 'xcomp'), ('tell', 'conj'), ('software', 'dobj'), ('“', 'punct'), ('quarter', 'nsubj'), ('”', 'punct'), ('neutral', 'acomp'), (',', 'punct'), ('  ', 'npadvmod'), ('despite', 'prep'), ('think', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[need, able], [able,   ], [  , reach], [reach, tell], [tell, software], [software, “], [“, quarter], [quarter, ”], [”, neutral], [neutral, ,], [,,   ], [  , despite], [despite, think], [think, .]]

>> Trigrams: 
[[need, able,   ], [able,   , reach], [  , reach, tell], [reach, tell, software], [tell, software, “], [software, “, quarter], [“, quarter, ”], [quarter, ”, neutral], [”, neutral, ,], [neutral, ,,   ], [,,   , despite], [  , despite, think], [despite, think, .]]

>> Noun Phrases are: 
[you, the software, “first quarter, what, it]

>> Named Entities are: 
[]


============================ Sentence 336 =============================

 CHART SOURCE: ThomsonOne; Bullion Management Group Inc.,   http://bmg-group.com/2008-financial-crisis/  can have many    unforeseen side-effects. 


>> Tokens are: 
[ , CHART, SOURCE, :, ThomsonOne, ;, Bullion, Management, Group, Inc., ,,   , http://bmg-group.com/2008-financial-crisis/,  ,    , unforeseen, -, effects, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('CHART', 'PROPN'), ('SOURCE', 'NOUN'), (':', 'PUNCT'), ('ThomsonOne', 'PROPN'), (';', 'PUNCT'), ('Bullion', 'PROPN'), ('Management', 'PROPN'), ('Group', 'PROPN'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('http://bmg-group.com/2008-financial-crisis/', 'PROPN'), (' ', 'SPACE'), ('   ', 'SPACE'), ('unforeseen', 'ADJ'), ('-', 'PUNCT'), ('effects', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('CHART', 'compound'), ('SOURCE', 'dep'), (':', 'punct'), ('ThomsonOne', 'appos'), (';', 'punct'), ('Bullion', 'compound'), ('Management', 'compound'), ('Group', 'compound'), ('Inc.', 'conj'), (',', 'punct'), ('  ', 'nmod'), ('http://bmg-group.com/2008-financial-crisis/', 'compound'), (' ', 'nsubj'), ('   ', 'nummod'), ('unforeseen', 'amod'), ('-', 'punct'), ('effects', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , CHART], [CHART, SOURCE], [SOURCE, :], [:, ThomsonOne], [ThomsonOne, ;], [;, Bullion], [Bullion, Management], [Management, Group], [Group, Inc.], [Inc., ,], [,,   ], [  , http://bmg-group.com/2008-financial-crisis/], [http://bmg-group.com/2008-financial-crisis/,  ], [ ,    ], [   , unforeseen], [unforeseen, -], [-, effects], [effects, .]]

>> Trigrams: 
[[ , CHART, SOURCE], [CHART, SOURCE, :], [SOURCE, :, ThomsonOne], [:, ThomsonOne, ;], [ThomsonOne, ;, Bullion], [;, Bullion, Management], [Bullion, Management, Group], [Management, Group, Inc.], [Group, Inc., ,], [Inc., ,,   ], [,,   , http://bmg-group.com/2008-financial-crisis/], [  , http://bmg-group.com/2008-financial-crisis/,  ], [http://bmg-group.com/2008-financial-crisis/,  ,    ], [ ,    , unforeseen], [   , unforeseen, -], [unforeseen, -, effects], [-, effects, .]]

>> Noun Phrases are: 
[ThomsonOne, Bullion Management Group Inc., many    unforeseen side-effects]

>> Named Entities are: 
[('CHART', 'ORG'), ('ThomsonOne', 'ORG'), ('Bullion Management Group Inc.', 'ORG')]


============================ Sentence 337 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 338 =============================

Training  a model   


>> Tokens are: 
[Training,  , model,  ] 

>> PoS Tags are: 
[('Training', 'VERB'), (' ', 'SPACE'), ('model', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Training', 'ROOT'), (' ', 'dobj'), ('model', 'dobj'), (' ', 'punct')]

>> Bigrams: 
[[Training,  ], [ , model], [model,  ]]

>> Trigrams: 
[[Training,  , model], [ , model,  ]]

>> Noun Phrases are: 
[a model]

>> Named Entities are: 
[]


============================ Sentence 339 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/   W H 


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/,   , W, H] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('  ', 'appos'), ('W', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/,   ], [  , W], [W, H]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/,   ], [https://www.lexalytics.com/,   , W], [  , W, H]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/, W H]

>> Named Entities are: 
[]


============================ Sentence 340 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 341 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 342 =============================

P A P E R  14|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[P, P, E, R,  , 14|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('14|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'nsubj'), (' ', 'appos'), ('14|', 'ROOT'), ('      ', 'attr'), ('|', 'npadvmod'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'npadvmod'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 14|], [14|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 14|], [ , 14|,       ], [14|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[P A P E R, 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('14|', 'DATE'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')]


============================ Sentence 343 =============================

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[]


============================ Sentence 344 =============================

  |   1-800-377-8036 |   www.lexalytics.com   


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com,  ] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'poss'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'ROOT'), ('  ', 'appos'), ('www.lexalytics.com', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com], [  , www.lexalytics.com,  ]]

>> Noun Phrases are: 
[  |   1-800-377-8036 |]

>> Named Entities are: 
[]


============================ Sentence 345 =============================

S U M M A R Y  /   


>> Tokens are: 
[S, U, M, M, R, Y,  , /,  ] 

>> PoS Tags are: 
[('S', 'NOUN'), ('U', 'NOUN'), ('M', 'PROPN'), ('M', 'NOUN'), ('R', 'NOUN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('/', 'SYM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('S', 'compound'), ('U', 'compound'), ('M', 'compound'), ('M', 'compound'), ('R', 'compound'), ('Y', 'dative'), (' ', 'appos'), ('/', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[S, U], [U, M], [M, M], [M, R], [R, Y], [Y,  ], [ , /], [/,  ]]

>> Trigrams: 
[[S, U, M], [U, M, M], [M, M, R], [M, R, Y], [R, Y,  ], [Y,  , /], [ , /,  ]]

>> Noun Phrases are: 
[S U M M A, R Y]

>> Named Entities are: 
[]


============================ Sentence 346 =============================

C O N C L U S 


>> Tokens are: 
[C, O, N, C, L, U, S] 

>> PoS Tags are: 
[('C', 'NOUN'), ('O', 'PROPN'), ('N', 'PROPN'), ('C', 'PROPN'), ('L', 'NOUN'), ('U', 'NOUN'), ('S', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('O', 'nmod'), ('N', 'appos'), ('C', 'compound'), ('L', 'compound'), ('U', 'compound'), ('S', 'ROOT')]

>> Bigrams: 
[[C, O], [O, N], [N, C], [C, L], [L, U], [U, S]]

>> Trigrams: 
[[C, O, N], [O, N, C], [N, C, L], [C, L, U], [L, U, S]]

>> Noun Phrases are: 
[N]

>> Named Entities are: 
[]


============================ Sentence 347 =============================

I O N  Text analytics is arguably one of the most complex tasks for an AI. 


>> Tokens are: 
[O, N,  , Text, analytics, arguably, complex, tasks, AI, .] 

>> PoS Tags are: 
[('O', 'INTJ'), ('N', 'NOUN'), (' ', 'SPACE'), ('Text', 'PROPN'), ('analytics', 'NOUN'), ('arguably', 'ADV'), ('complex', 'ADJ'), ('tasks', 'NOUN'), ('AI', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('O', 'appos'), ('N', 'nmod'), (' ', 'compound'), ('Text', 'compound'), ('analytics', 'nsubj'), ('arguably', 'advmod'), ('complex', 'amod'), ('tasks', 'pobj'), ('AI', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[O, N], [N,  ], [ , Text], [Text, analytics], [analytics, arguably], [arguably, complex], [complex, tasks], [tasks, AI], [AI, .]]

>> Trigrams: 
[[O, N,  ], [N,  , Text], [ , Text, analytics], [Text, analytics, arguably], [analytics, arguably, complex], [arguably, complex, tasks], [complex, tasks, AI], [tasks, AI, .]]

>> Noun Phrases are: 
[I O N  Text analytics, the most complex tasks, an AI]

>> Named Entities are: 
[]


============================ Sentence 348 =============================

  Language is messy and complex. 


>> Tokens are: 
[  , Language, messy, complex, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Language', 'PROPN'), ('messy', 'ADJ'), ('complex', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('Language', 'nsubj'), ('messy', 'acomp'), ('complex', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[  , Language], [Language, messy], [messy, complex], [complex, .]]

>> Trigrams: 
[[  , Language, messy], [Language, messy, complex], [messy, complex, .]]

>> Noun Phrases are: 
[  Language]

>> Named Entities are: 
[]


============================ Sentence 349 =============================

Meaning varies from speaker to speaker  and listener to listener. 


>> Tokens are: 
[Meaning, varies, speaker, speaker,  , listener, listener, .] 

>> PoS Tags are: 
[('Meaning', 'VERB'), ('varies', 'NOUN'), ('speaker', 'NOUN'), ('speaker', 'NOUN'), (' ', 'SPACE'), ('listener', 'NOUN'), ('listener', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Meaning', 'ROOT'), ('varies', 'dobj'), ('speaker', 'pobj'), ('speaker', 'compound'), (' ', 'pobj'), ('listener', 'conj'), ('listener', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Meaning, varies], [varies, speaker], [speaker, speaker], [speaker,  ], [ , listener], [listener, listener], [listener, .]]

>> Trigrams: 
[[Meaning, varies, speaker], [varies, speaker, speaker], [speaker, speaker,  ], [speaker,  , listener], [ , listener, listener], [listener, listener, .]]

>> Noun Phrases are: 
[varies, speaker, listener, listener]

>> Named Entities are: 
[]


============================ Sentence 350 =============================

Machine learning provides a rich solution set for  handling this complexity, but must be implemented in a way that’s relevant  to the problem – and hand-in-hand with natural language processing code. 


>> Tokens are: 
[Machine, learning, provides, rich, solution, set,  , handling, complexity, ,, implemented, way, relevant,  , problem, –, hand, -, -, hand, natural, language, processing, code, .] 

>> PoS Tags are: 
[('Machine', 'NOUN'), ('learning', 'NOUN'), ('provides', 'VERB'), ('rich', 'ADJ'), ('solution', 'NOUN'), ('set', 'VERB'), (' ', 'SPACE'), ('handling', 'VERB'), ('complexity', 'NOUN'), (',', 'PUNCT'), ('implemented', 'VERB'), ('way', 'NOUN'), ('relevant', 'ADJ'), (' ', 'SPACE'), ('problem', 'NOUN'), ('–', 'PUNCT'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('hand', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Machine', 'compound'), ('learning', 'nsubj'), ('provides', 'ROOT'), ('rich', 'amod'), ('solution', 'dobj'), ('set', 'acl'), (' ', 'pobj'), ('handling', 'acl'), ('complexity', 'dobj'), (',', 'punct'), ('implemented', 'conj'), ('way', 'pobj'), ('relevant', 'amod'), (' ', 'attr'), ('problem', 'pobj'), ('–', 'punct'), ('hand', 'conj'), ('-', 'punct'), ('-', 'punct'), ('hand', 'pobj'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'compound'), ('code', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Machine, learning], [learning, provides], [provides, rich], [rich, solution], [solution, set], [set,  ], [ , handling], [handling, complexity], [complexity, ,], [,, implemented], [implemented, way], [way, relevant], [relevant,  ], [ , problem], [problem, –], [–, hand], [hand, -], [-, -], [-, hand], [hand, natural], [natural, language], [language, processing], [processing, code], [code, .]]

>> Trigrams: 
[[Machine, learning, provides], [learning, provides, rich], [provides, rich, solution], [rich, solution, set], [solution, set,  ], [set,  , handling], [ , handling, complexity], [handling, complexity, ,], [complexity, ,, implemented], [,, implemented, way], [implemented, way, relevant], [way, relevant,  ], [relevant,  , problem], [ , problem, –], [problem, –, hand], [–, hand, -], [hand, -, -], [-, -, hand], [-, hand, natural], [hand, natural, language], [natural, language, processing], [language, processing, code], [processing, code, .]]

>> Noun Phrases are: 
[Machine learning, a rich solution, this complexity, a way, the problem, hand, hand, natural language processing code]

>> Named Entities are: 
[]


============================ Sentence 351 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 352 =============================

Moreover, although it’s necessary to use machine learning, it’s not sufficient  to use a single type of model, like a big “unsupervised learning” system. 


>> Tokens are: 
[,, necessary, use, machine, learning, ,, sufficient,  , use, single, type, model, ,, like, big, “, unsupervised, learning, ”, system, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('necessary', 'ADJ'), ('use', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('sufficient', 'ADJ'), (' ', 'SPACE'), ('use', 'VERB'), ('single', 'ADJ'), ('type', 'NOUN'), ('model', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('big', 'ADJ'), ('“', 'PUNCT'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('system', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('necessary', 'acomp'), ('use', 'xcomp'), ('machine', 'compound'), ('learning', 'dobj'), (',', 'punct'), ('sufficient', 'amod'), (' ', 'attr'), ('use', 'xcomp'), ('single', 'amod'), ('type', 'dobj'), ('model', 'pobj'), (',', 'punct'), ('like', 'prep'), ('big', 'amod'), ('“', 'punct'), ('unsupervised', 'amod'), ('learning', 'nmod'), ('”', 'punct'), ('system', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, necessary], [necessary, use], [use, machine], [machine, learning], [learning, ,], [,, sufficient], [sufficient,  ], [ , use], [use, single], [single, type], [type, model], [model, ,], [,, like], [like, big], [big, “], [“, unsupervised], [unsupervised, learning], [learning, ”], [”, system], [system, .]]

>> Trigrams: 
[[,, necessary, use], [necessary, use, machine], [use, machine, learning], [machine, learning, ,], [learning, ,, sufficient], [,, sufficient,  ], [sufficient,  , use], [ , use, single], [use, single, type], [single, type, model], [type, model, ,], [model, ,, like], [,, like, big], [like, big, “], [big, “, unsupervised], [“, unsupervised, learning], [unsupervised, learning, ”], [learning, ”, system], [”, system, .]]

>> Noun Phrases are: 
[it, machine learning, it, a single type, model, a big “unsupervised learning” system]

>> Named Entities are: 
[]


============================ Sentence 353 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 354 =============================

Certain aspects of machine learning are very subjective, and need to be  trained or tuned to match your perspective. 


>> Tokens are: 
[Certain, aspects, machine, learning, subjective, ,, need,  , trained, tuned, match, perspective, .] 

>> PoS Tags are: 
[('Certain', 'ADJ'), ('aspects', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('subjective', 'ADJ'), (',', 'PUNCT'), ('need', 'VERB'), (' ', 'SPACE'), ('trained', 'VERB'), ('tuned', 'VERB'), ('match', 'VERB'), ('perspective', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Certain', 'amod'), ('aspects', 'nsubj'), ('machine', 'compound'), ('learning', 'pobj'), ('subjective', 'acomp'), (',', 'punct'), ('need', 'conj'), (' ', 'nsubjpass'), ('trained', 'xcomp'), ('tuned', 'conj'), ('match', 'advcl'), ('perspective', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Certain, aspects], [aspects, machine], [machine, learning], [learning, subjective], [subjective, ,], [,, need], [need,  ], [ , trained], [trained, tuned], [tuned, match], [match, perspective], [perspective, .]]

>> Trigrams: 
[[Certain, aspects, machine], [aspects, machine, learning], [machine, learning, subjective], [learning, subjective, ,], [subjective, ,, need], [,, need,  ], [need,  , trained], [ , trained, tuned], [trained, tuned, match], [tuned, match, perspective], [match, perspective, .]]

>> Noun Phrases are: 
[Certain aspects, machine learning, your perspective]

>> Named Entities are: 
[]


============================ Sentence 355 =============================

Lexalytics combines many   types of machine learning along with pure natural language processing code. 


>> Tokens are: 
[Lexalytics, combines,   , types, machine, learning, pure, natural, language, processing, code, .] 

>> PoS Tags are: 
[('Lexalytics', 'NOUN'), ('combines', 'VERB'), ('  ', 'SPACE'), ('types', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('pure', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('combines', 'ROOT'), ('  ', 'compound'), ('types', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('pure', 'amod'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'compound'), ('code', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, combines], [combines,   ], [  , types], [types, machine], [machine, learning], [learning, pure], [pure, natural], [natural, language], [language, processing], [processing, code], [code, .]]

>> Trigrams: 
[[Lexalytics, combines,   ], [combines,   , types], [  , types, machine], [types, machine, learning], [machine, learning, pure], [learning, pure, natural], [pure, natural, language], [natural, language, processing], [language, processing, code], [processing, code, .]]

>> Noun Phrases are: 
[Lexalytics, many   types, pure natural language processing code]

>> Named Entities are: 
[]


============================ Sentence 356 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 357 =============================

We have no prejudice for one algorithm over another except in how they  help us provide the best possible text analytics system to our customers. 


>> Tokens are: 
[prejudice, algorithm,  , help, provide, best, possible, text, analytics, system, customers, .] 

>> PoS Tags are: 
[('prejudice', 'NOUN'), ('algorithm', 'NOUN'), (' ', 'SPACE'), ('help', 'VERB'), ('provide', 'VERB'), ('best', 'ADJ'), ('possible', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('system', 'NOUN'), ('customers', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('prejudice', 'dobj'), ('algorithm', 'pobj'), (' ', 'nsubj'), ('help', 'pcomp'), ('provide', 'ccomp'), ('best', 'advmod'), ('possible', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('system', 'dobj'), ('customers', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[prejudice, algorithm], [algorithm,  ], [ , help], [help, provide], [provide, best], [best, possible], [possible, text], [text, analytics], [analytics, system], [system, customers], [customers, .]]

>> Trigrams: 
[[prejudice, algorithm,  ], [algorithm,  , help], [ , help, provide], [help, provide, best], [provide, best, possible], [best, possible, text], [possible, text, analytics], [text, analytics, system], [analytics, system, customers], [system, customers, .]]

>> Noun Phrases are: 
[We, no prejudice, one algorithm, they, us, the best possible text analytics system, our customers]

>> Named Entities are: 
[('one', 'CARDINAL')]


============================ Sentence 358 =============================

 to explore how Lexalytics    can help your business at   lexalytics.com/contact   


>> Tokens are: 
[ , explore, Lexalytics,    , help, business,   , lexalytics.com/contact,  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('explore', 'VERB'), ('Lexalytics', 'PROPN'), ('   ', 'SPACE'), ('help', 'VERB'), ('business', 'NOUN'), ('  ', 'SPACE'), ('lexalytics.com/contact', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('explore', 'ROOT'), ('Lexalytics', 'compound'), ('   ', 'nsubj'), ('help', 'ccomp'), ('business', 'dobj'), ('  ', 'pobj'), ('lexalytics.com/contact', 'punct'), (' ', 'prep')]

>> Bigrams: 
[[ , explore], [explore, Lexalytics], [Lexalytics,    ], [   , help], [help, business], [business,   ], [  , lexalytics.com/contact], [lexalytics.com/contact,  ]]

>> Trigrams: 
[[ , explore, Lexalytics], [explore, Lexalytics,    ], [Lexalytics,    , help], [   , help, business], [help, business,   ], [business,   , lexalytics.com/contact], [  , lexalytics.com/contact,  ]]

>> Noun Phrases are: 
[your business]

>> Named Entities are: 
[]


============================ Sentence 359 =============================

Contact  us  https://www.lexalytics.com/ https://www.lexalytics.com/ https://www.lexalytics.com/contact https://www.lexalytics.com/contact   ©   


>> Tokens are: 
[Contact,  ,  , https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/contact, https://www.lexalytics.com/contact,   , ©,  ] 

>> PoS Tags are: 
[('Contact', 'PROPN'), (' ', 'SPACE'), (' ', 'SPACE'), ('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('https://www.lexalytics.com/contact', 'PROPN'), ('https://www.lexalytics.com/contact', 'NUM'), ('  ', 'SPACE'), ('©', 'ADP'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Contact', 'ROOT'), (' ', 'nummod'), (' ', 'appos'), ('https://www.lexalytics.com/', 'appos'), ('https://www.lexalytics.com/', 'appos'), ('https://www.lexalytics.com/contact', 'appos'), ('https://www.lexalytics.com/contact', 'appos'), ('  ', 'appos'), ('©', 'prep'), (' ', 'punct')]

>> Bigrams: 
[[Contact,  ], [ ,  ], [ , https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/contact], [https://www.lexalytics.com/contact, https://www.lexalytics.com/contact], [https://www.lexalytics.com/contact,   ], [  , ©], [©,  ]]

>> Trigrams: 
[[Contact,  ,  ], [ ,  , https://www.lexalytics.com/], [ , https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/contact], [https://www.lexalytics.com/, https://www.lexalytics.com/contact, https://www.lexalytics.com/contact], [https://www.lexalytics.com/contact, https://www.lexalytics.com/contact,   ], [https://www.lexalytics.com/contact,   , ©], [  , ©,  ]]

>> Noun Phrases are: 
[Contact, us, https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/contact]

>> Named Entities are: 
[]


============================ Sentence 360 =============================

2019 Lexalytics, Inc. | M  achine Learning W hite Paper | v3c   


>> Tokens are: 
[2019, Lexalytics, ,, Inc., |, M,  , achine, Learning, W, hite, Paper, |, v3c,  ] 

>> PoS Tags are: 
[('2019', 'NUM'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), ('|', 'NOUN'), ('M', 'PROPN'), (' ', 'SPACE'), ('achine', 'ADJ'), ('Learning', 'PROPN'), ('W', 'PROPN'), ('hite', 'NOUN'), ('Paper', 'PROPN'), ('|', 'NOUN'), ('v3c', 'VERB'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('2019', 'nummod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'dep'), ('|', 'appos'), ('M', 'nmod'), (' ', 'npadvmod'), ('achine', 'amod'), ('Learning', 'compound'), ('W', 'compound'), ('hite', 'compound'), ('Paper', 'nsubj'), ('|', 'advmod'), ('v3c', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[2019, Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., |], [|, M], [M,  ], [ , achine], [achine, Learning], [Learning, W], [W, hite], [hite, Paper], [Paper, |], [|, v3c], [v3c,  ]]

>> Trigrams: 
[[2019, Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., |], [Inc., |, M], [|, M,  ], [M,  , achine], [ , achine, Learning], [achine, Learning, W], [Learning, W, hite], [W, hite, Paper], [hite, Paper, |], [Paper, |, v3c], [|, v3c,  ]]

>> Noun Phrases are: 
[|]

>> Named Entities are: 
[('2019', 'DATE'), ('Lexalytics, Inc.', 'ORG'), ('Learning W', 'PERSON')]


============================ Sentence 361 =============================

Lexalytics processes BILLIONS of   unstructured documents every day, GLOBALLY. 


>> Tokens are: 
[Lexalytics, processes, BILLIONS,   , unstructured, documents, day, ,, GLOBALLY, .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('processes', 'VERB'), ('BILLIONS', 'NOUN'), ('  ', 'SPACE'), ('unstructured', 'ADJ'), ('documents', 'NOUN'), ('day', 'NOUN'), (',', 'PUNCT'), ('GLOBALLY', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('processes', 'ROOT'), ('BILLIONS', 'dobj'), ('  ', 'nmod'), ('unstructured', 'amod'), ('documents', 'pobj'), ('day', 'npadvmod'), (',', 'punct'), ('GLOBALLY', 'npadvmod'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, processes], [processes, BILLIONS], [BILLIONS,   ], [  , unstructured], [unstructured, documents], [documents, day], [day, ,], [,, GLOBALLY], [GLOBALLY, .]]

>> Trigrams: 
[[Lexalytics, processes, BILLIONS], [processes, BILLIONS,   ], [BILLIONS,   , unstructured], [  , unstructured, documents], [unstructured, documents, day], [documents, day, ,], [day, ,, GLOBALLY], [,, GLOBALLY, .]]

>> Noun Phrases are: 
[Lexalytics, BILLIONS,   unstructured documents]

>> Named Entities are: 
[('Lexalytics', 'ORG'), ('BILLIONS', 'ORG'), ('every day', 'DATE'), ('GLOBALLY', 'ORG')]


============================ Sentence 362 =============================

We transform unstructured text into usable data and powerful stories. 


>> Tokens are: 
[transform, unstructured, text, usable, data, powerful, stories, .] 

>> PoS Tags are: 
[('transform', 'VERB'), ('unstructured', 'ADJ'), ('text', 'NOUN'), ('usable', 'ADJ'), ('data', 'NOUN'), ('powerful', 'ADJ'), ('stories', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('transform', 'ROOT'), ('unstructured', 'amod'), ('text', 'dobj'), ('usable', 'amod'), ('data', 'pobj'), ('powerful', 'amod'), ('stories', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[transform, unstructured], [unstructured, text], [text, usable], [usable, data], [data, powerful], [powerful, stories], [stories, .]]

>> Trigrams: 
[[transform, unstructured, text], [unstructured, text, usable], [text, usable, data], [usable, data, powerful], [data, powerful, stories], [powerful, stories, .]]

>> Noun Phrases are: 
[We, unstructured text, usable data, powerful stories]

>> Named Entities are: 
[]


============================ Sentence 363 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 364 =============================

Our on-premise Salience® engine, SaaS Semantria® API, and end-to-end Lexalytics   


>> Tokens are: 
[-, premise, Salience, ®, engine, ,, SaaS, Semantria, ®, API, ,, end, -, -, end, Lexalytics,  ] 

>> PoS Tags are: 
[('-', 'PUNCT'), ('premise', 'NOUN'), ('Salience', 'PROPN'), ('®', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('SaaS', 'PROPN'), ('Semantria', 'PROPN'), ('®', 'NOUN'), ('API', 'NOUN'), (',', 'PUNCT'), ('end', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('end', 'NOUN'), ('Lexalytics', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('-', 'punct'), ('premise', 'pobj'), ('Salience', 'compound'), ('®', 'compound'), ('engine', 'ROOT'), (',', 'punct'), ('SaaS', 'compound'), ('Semantria', 'compound'), ('®', 'compound'), ('API', 'appos'), (',', 'punct'), ('end', 'nmod'), ('-', 'punct'), ('-', 'punct'), ('end', 'pobj'), ('Lexalytics', 'compound'), (' ', 'punct')]

>> Bigrams: 
[[-, premise], [premise, Salience], [Salience, ®], [®, engine], [engine, ,], [,, SaaS], [SaaS, Semantria], [Semantria, ®], [®, API], [API, ,], [,, end], [end, -], [-, -], [-, end], [end, Lexalytics], [Lexalytics,  ]]

>> Trigrams: 
[[-, premise, Salience], [premise, Salience, ®], [Salience, ®, engine], [®, engine, ,], [engine, ,, SaaS], [,, SaaS, Semantria], [SaaS, Semantria, ®], [Semantria, ®, API], [®, API, ,], [API, ,, end], [,, end, -], [end, -, -], [-, -, end], [-, end, Lexalytics], [end, Lexalytics,  ]]

>> Noun Phrases are: 
[-premise, SaaS Semantria® API, end]

>> Named Entities are: 
[('Salience®', 'PRODUCT')]


============================ Sentence 365 =============================

Intelligence Platform® combine natural language processing with artificial intelligence  to reveal context-rich patterns and insights within comments, reviews, surveys, and   other text documents. 


>> Tokens are: 
[Intelligence, Platform, ®, combine, natural, language, processing, artificial, intelligence,  , reveal, context, -, rich, patterns, insights, comments, ,, reviews, ,, surveys, ,,   , text, documents, .] 

>> PoS Tags are: 
[('Intelligence', 'PROPN'), ('Platform', 'PROPN'), ('®', 'NOUN'), ('combine', 'VERB'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), (' ', 'SPACE'), ('reveal', 'VERB'), ('context', 'NOUN'), ('-', 'PUNCT'), ('rich', 'ADJ'), ('patterns', 'NOUN'), ('insights', 'NOUN'), ('comments', 'NOUN'), (',', 'PUNCT'), ('reviews', 'NOUN'), (',', 'PUNCT'), ('surveys', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('text', 'NOUN'), ('documents', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Intelligence', 'compound'), ('Platform', 'compound'), ('®', 'nsubj'), ('combine', 'ROOT'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'dobj'), ('artificial', 'amod'), ('intelligence', 'compound'), (' ', 'pobj'), ('reveal', 'advcl'), ('context', 'npadvmod'), ('-', 'punct'), ('rich', 'amod'), ('patterns', 'dobj'), ('insights', 'conj'), ('comments', 'pobj'), (',', 'punct'), ('reviews', 'conj'), (',', 'punct'), ('surveys', 'conj'), (',', 'punct'), ('  ', 'nmod'), ('text', 'compound'), ('documents', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Intelligence, Platform], [Platform, ®], [®, combine], [combine, natural], [natural, language], [language, processing], [processing, artificial], [artificial, intelligence], [intelligence,  ], [ , reveal], [reveal, context], [context, -], [-, rich], [rich, patterns], [patterns, insights], [insights, comments], [comments, ,], [,, reviews], [reviews, ,], [,, surveys], [surveys, ,], [,,   ], [  , text], [text, documents], [documents, .]]

>> Trigrams: 
[[Intelligence, Platform, ®], [Platform, ®, combine], [®, combine, natural], [combine, natural, language], [natural, language, processing], [language, processing, artificial], [processing, artificial, intelligence], [artificial, intelligence,  ], [intelligence,  , reveal], [ , reveal, context], [reveal, context, -], [context, -, rich], [-, rich, patterns], [rich, patterns, insights], [patterns, insights, comments], [insights, comments, ,], [comments, ,, reviews], [,, reviews, ,], [reviews, ,, surveys], [,, surveys, ,], [surveys, ,,   ], [,,   , text], [  , text, documents], [text, documents, .]]

>> Noun Phrases are: 
[Intelligence Platform®, natural language processing, context-rich patterns, insights, comments, reviews, surveys,   other text documents]

>> Named Entities are: 
[]


============================ Sentence 366 =============================

  Data analytics and data analyst companies rely on Lexalytics to build better  products, share insights between engineering, marketing, PR, and support teams,  and drive business growth. 


>> Tokens are: 
[  , Data, analytics, data, analyst, companies, rely, Lexalytics, build, better,  , products, ,, share, insights, engineering, ,, marketing, ,, PR, ,, support, teams, ,,  , drive, business, growth, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Data', 'PROPN'), ('analytics', 'NOUN'), ('data', 'NOUN'), ('analyst', 'NOUN'), ('companies', 'NOUN'), ('rely', 'VERB'), ('Lexalytics', 'PROPN'), ('build', 'VERB'), ('better', 'ADJ'), (' ', 'SPACE'), ('products', 'NOUN'), (',', 'PUNCT'), ('share', 'NOUN'), ('insights', 'NOUN'), ('engineering', 'NOUN'), (',', 'PUNCT'), ('marketing', 'NOUN'), (',', 'PUNCT'), ('PR', 'NOUN'), (',', 'PUNCT'), ('support', 'NOUN'), ('teams', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nummod'), ('Data', 'compound'), ('analytics', 'nmod'), ('data', 'compound'), ('analyst', 'conj'), ('companies', 'nsubj'), ('rely', 'ROOT'), ('Lexalytics', 'pobj'), ('build', 'advcl'), ('better', 'amod'), (' ', 'compound'), ('products', 'dobj'), (',', 'punct'), ('share', 'conj'), ('insights', 'dobj'), ('engineering', 'pobj'), (',', 'punct'), ('marketing', 'conj'), (',', 'punct'), ('PR', 'conj'), (',', 'punct'), ('support', 'compound'), ('teams', 'conj'), (',', 'punct'), (' ', 'conj'), ('drive', 'conj'), ('business', 'compound'), ('growth', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[  , Data], [Data, analytics], [analytics, data], [data, analyst], [analyst, companies], [companies, rely], [rely, Lexalytics], [Lexalytics, build], [build, better], [better,  ], [ , products], [products, ,], [,, share], [share, insights], [insights, engineering], [engineering, ,], [,, marketing], [marketing, ,], [,, PR], [PR, ,], [,, support], [support, teams], [teams, ,], [,,  ], [ , drive], [drive, business], [business, growth], [growth, .]]

>> Trigrams: 
[[  , Data, analytics], [Data, analytics, data], [analytics, data, analyst], [data, analyst, companies], [analyst, companies, rely], [companies, rely, Lexalytics], [rely, Lexalytics, build], [Lexalytics, build, better], [build, better,  ], [better,  , products], [ , products, ,], [products, ,, share], [,, share, insights], [share, insights, engineering], [insights, engineering, ,], [engineering, ,, marketing], [,, marketing, ,], [marketing, ,, PR], [,, PR, ,], [PR, ,, support], [,, support, teams], [support, teams, ,], [teams, ,,  ], [,,  , drive], [ , drive, business], [drive, business, growth], [business, growth, .]]

>> Noun Phrases are: 
[  Data analytics and data analyst companies, Lexalytics, better  products, share, insights, engineering, marketing, PR, support teams, business growth]

>> Named Entities are: 
[('Lexalytics', 'ORG')]


============================ Sentence 367 =============================

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[]


============================ Sentence 368 =============================

For more information, visit www.lexalytics.com or call 1-800-377-8036   W H 


>> Tokens are: 
[information, ,, visit, www.lexalytics.com, 1, -, 800, -, 377, -, 8036,   , W, H] 

>> PoS Tags are: 
[('information', 'NOUN'), (',', 'PUNCT'), ('visit', 'VERB'), ('www.lexalytics.com', 'X'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'NUM'), ('8036', 'NUM'), ('  ', 'SPACE'), ('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('information', 'pobj'), (',', 'punct'), ('visit', 'ROOT'), ('www.lexalytics.com', 'dobj'), ('1', 'dobj'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('  ', 'dobj'), ('W', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[information, ,], [,, visit], [visit, www.lexalytics.com], [www.lexalytics.com, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036,   ], [  , W], [W, H]]

>> Trigrams: 
[[information, ,, visit], [,, visit, www.lexalytics.com], [visit, www.lexalytics.com, 1], [www.lexalytics.com, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036,   ], [8036,   , W], [  , W, H]]

>> Noun Phrases are: 
[more information]

>> Named Entities are: 
[]


============================ Sentence 369 =============================

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[]


============================ Sentence 370 =============================

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[]


============================ Sentence 371 =============================

P A P E R  15|       | Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com   


>> Tokens are: 
[P, P, E, R,  , 15|,       , |, Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA, |, 1, -, 800, -, 377, -, 8036, |, www.lexalytics.com,  ] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('15|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'NOUN'), ('1', 'NUM'), ('-', 'NUM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('www.lexalytics.com', 'X'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), (' ', 'compound'), ('15|', 'compound'), ('      ', 'compound'), ('|', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct'), ('USA', 'appos'), ('|', 'punct'), ('1', 'nummod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('www.lexalytics.com', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[P, P], [P, E], [E, R], [R,  ], [ , 15|], [15|,       ], [      , |], [|, Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA, |], [|, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|, www.lexalytics.com], [www.lexalytics.com,  ]]

>> Trigrams: 
[[P, P, E], [P, E, R], [E, R,  ], [R,  , 15|], [ , 15|,       ], [15|,       , |], [      , |, Lexalytics], [|, Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA, |], [USA, |, 1], [|, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |, www.lexalytics.com], [|, www.lexalytics.com,  ]]

>> Noun Phrases are: 
[P A P E R  15|       | Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, USA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA 01002 USA | 1-800-377-8036', 'ORG')]


============================ Sentence 372 =============================

https://www.lexalytics.com/ https://www.lexalytics.com/ https://www.lexalytics.com/ https://www.facebook.com/lexalytics/ https://twitter.com/Lexalytics https://www.linkedin.com/company/lexalytics-inc/ 


>> Tokens are: 
[https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.facebook.com/lexalytics/, https://twitter.com/Lexalytics, https://www.linkedin.com/company/lexalytics-inc/] 

>> PoS Tags are: 
[('https://www.lexalytics.com/', 'PROPN'), ('https://www.lexalytics.com/', 'NOUN'), ('https://www.lexalytics.com/', 'NOUN'), ('https://www.facebook.com/lexalytics/', 'NOUN'), ('https://twitter.com/Lexalytics', 'NOUN'), ('https://www.linkedin.com/company/lexalytics-inc/', 'PUNCT')] 

>> Dependency Tags are: 
[('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'compound'), ('https://www.lexalytics.com/', 'ROOT'), ('https://www.facebook.com/lexalytics/', 'punct'), ('https://twitter.com/Lexalytics', 'appos'), ('https://www.linkedin.com/company/lexalytics-inc/', 'punct')]

>> Bigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.facebook.com/lexalytics/], [https://www.facebook.com/lexalytics/, https://twitter.com/Lexalytics], [https://twitter.com/Lexalytics, https://www.linkedin.com/company/lexalytics-inc/]]

>> Trigrams: 
[[https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.lexalytics.com/], [https://www.lexalytics.com/, https://www.lexalytics.com/, https://www.facebook.com/lexalytics/], [https://www.lexalytics.com/, https://www.facebook.com/lexalytics/, https://twitter.com/Lexalytics], [https://www.facebook.com/lexalytics/, https://twitter.com/Lexalytics, https://www.linkedin.com/company/lexalytics-inc/]]

>> Noun Phrases are: 
[https://www.lexalytics.com/ https://www.lexalytics.com/ https://www.lexalytics.com/, https://twitter.com/Lexalytics]

>> Named Entities are: 
[]
