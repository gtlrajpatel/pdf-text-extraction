				 *** Text Processing using NLTK *** 


============================ Sentence 1 =============================

Demystifying data science White paper | OpenText   WHITE PAPERWHITE PAPER  Demystifying data science How organizations can benefit from artificial intelligence and  advanced analytics    2/14Demystifying data science   Contents What is artificial intelligence and machine learning? 


>> Tokens are: 
 ['Demystifying', 'data', 'science', 'White', 'paper', '|', 'OpenText', 'WHITE', 'PAPERWHITE', 'PAPER', 'Demystifying', 'data', 'science', 'How', 'organizations', 'benefit', 'artificial', 'intelligence', 'advanced', 'analytics', '2/14Demystifying', 'data', 'science', 'Contents', 'What', 'artificial', 'intelligence', 'machine', 'learning', '?']

>> Bigrams are: 
 [('Demystifying', 'data'), ('data', 'science'), ('science', 'White'), ('White', 'paper'), ('paper', '|'), ('|', 'OpenText'), ('OpenText', 'WHITE'), ('WHITE', 'PAPERWHITE'), ('PAPERWHITE', 'PAPER'), ('PAPER', 'Demystifying'), ('Demystifying', 'data'), ('data', 'science'), ('science', 'How'), ('How', 'organizations'), ('organizations', 'benefit'), ('benefit', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'advanced'), ('advanced', 'analytics'), ('analytics', '2/14Demystifying'), ('2/14Demystifying', 'data'), ('data', 'science'), ('science', 'Contents'), ('Contents', 'What'), ('What', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'machine'), ('machine', 'learning'), ('learning', '?')]

>> Trigrams are: 
 [('Demystifying', 'data', 'science'), ('data', 'science', 'White'), ('science', 'White', 'paper'), ('White', 'paper', '|'), ('paper', '|', 'OpenText'), ('|', 'OpenText', 'WHITE'), ('OpenText', 'WHITE', 'PAPERWHITE'), ('WHITE', 'PAPERWHITE', 'PAPER'), ('PAPERWHITE', 'PAPER', 'Demystifying'), ('PAPER', 'Demystifying', 'data'), ('Demystifying', 'data', 'science'), ('data', 'science', 'How'), ('science', 'How', 'organizations'), ('How', 'organizations', 'benefit'), ('organizations', 'benefit', 'artificial'), ('benefit', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'advanced'), ('intelligence', 'advanced', 'analytics'), ('advanced', 'analytics', '2/14Demystifying'), ('analytics', '2/14Demystifying', 'data'), ('2/14Demystifying', 'data', 'science'), ('data', 'science', 'Contents'), ('science', 'Contents', 'What'), ('Contents', 'What', 'artificial'), ('What', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'machine'), ('intelligence', 'machine', 'learning'), ('machine', 'learning', '?')]

>> POS Tags are: 
 [('Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('White', 'NNP'), ('paper', 'NN'), ('|', 'NN'), ('OpenText', 'NNP'), ('WHITE', 'NNP'), ('PAPERWHITE', 'NNP'), ('PAPER', 'NNP'), ('Demystifying', 'NNP'), ('data', 'NNS'), ('science', 'NN'), ('How', 'NNP'), ('organizations', 'NNS'), ('benefit', 'VBP'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('advanced', 'VBD'), ('analytics', 'NNS'), ('2/14Demystifying', 'CD'), ('data', 'NNS'), ('science', 'NN'), ('Contents', 'NNPS'), ('What', 'WP'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('?', '.')]

 (S
  Demystifying/VBG
  (NP
    data/NNS
    science/NN
    White/NNP
    paper/NN
    |/NN
    OpenText/NNP
    WHITE/NNP
    PAPERWHITE/NNP
    PAPER/NNP
    Demystifying/NNP
    data/NNS
    science/NN
    How/NNP
    organizations/NNS)
  benefit/VBP
  (NP artificial/JJ intelligence/NN)
  advanced/VBD
  (NP analytics/NNS)
  2/14Demystifying/CD
  (NP data/NNS science/NN)
  Contents/NNPS
  What/WP
  (NP artificial/JJ intelligence/NN machine/NN learning/NN)
  ?/.) 


>> Noun Phrases are: 
 ['data science White paper | OpenText WHITE PAPERWHITE PAPER Demystifying data science How organizations', 'artificial intelligence', 'analytics', 'data science', 'artificial intelligence machine learning']

>> Named Entities are: 
 [('FACILITY', 'White'), ('ORGANIZATION', 'OpenText'), ('ORGANIZATION', 'WHITE'), ('ORGANIZATION', 'PAPERWHITE')] 

>> Stemming using Porter Stemmer: 
 [('Demystifying', 'demystifi'), ('data', 'data'), ('science', 'scienc'), ('White', 'white'), ('paper', 'paper'), ('|', '|'), ('OpenText', 'opentext'), ('WHITE', 'white'), ('PAPERWHITE', 'paperwhit'), ('PAPER', 'paper'), ('Demystifying', 'demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('organizations', 'organ'), ('benefit', 'benefit'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('2/14Demystifying', '2/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Contents', 'content'), ('What', 'what'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Demystifying', 'demystifi'), ('data', 'data'), ('science', 'scienc'), ('White', 'white'), ('paper', 'paper'), ('|', '|'), ('OpenText', 'opentext'), ('WHITE', 'white'), ('PAPERWHITE', 'paperwhit'), ('PAPER', 'paper'), ('Demystifying', 'demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('organizations', 'organ'), ('benefit', 'benefit'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('2/14Demystifying', '2/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Contents', 'content'), ('What', 'what'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('Demystifying', 'Demystifying'), ('data', 'data'), ('science', 'science'), ('White', 'White'), ('paper', 'paper'), ('|', '|'), ('OpenText', 'OpenText'), ('WHITE', 'WHITE'), ('PAPERWHITE', 'PAPERWHITE'), ('PAPER', 'PAPER'), ('Demystifying', 'Demystifying'), ('data', 'data'), ('science', 'science'), ('How', 'How'), ('organizations', 'organization'), ('benefit', 'benefit'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('advanced', 'advanced'), ('analytics', 'analytics'), ('2/14Demystifying', '2/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Contents', 'Contents'), ('What', 'What'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('machine', 'machine'), ('learning', 'learning'), ('?', '?')]



============================ Sentence 2 =============================

4   How can an organization derive business value from AI and analytics? 


>> Tokens are: 
 ['4', 'How', 'organization', 'derive', 'business', 'value', 'AI', 'analytics', '?']

>> Bigrams are: 
 [('4', 'How'), ('How', 'organization'), ('organization', 'derive'), ('derive', 'business'), ('business', 'value'), ('value', 'AI'), ('AI', 'analytics'), ('analytics', '?')]

>> Trigrams are: 
 [('4', 'How', 'organization'), ('How', 'organization', 'derive'), ('organization', 'derive', 'business'), ('derive', 'business', 'value'), ('business', 'value', 'AI'), ('value', 'AI', 'analytics'), ('AI', 'analytics', '?')]

>> POS Tags are: 
 [('4', 'CD'), ('How', 'WRB'), ('organization', 'NN'), ('derive', 'NN'), ('business', 'NN'), ('value', 'NN'), ('AI', 'NNP'), ('analytics', 'NNS'), ('?', '.')]

 (S
  4/CD
  How/WRB
  (NP
    organization/NN
    derive/NN
    business/NN
    value/NN
    AI/NNP
    analytics/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['organization derive business value AI analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('How', 'how'), ('organization', 'organ'), ('derive', 'deriv'), ('business', 'busi'), ('value', 'valu'), ('AI', 'ai'), ('analytics', 'analyt'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('How', 'how'), ('organization', 'organ'), ('derive', 'deriv'), ('business', 'busi'), ('value', 'valu'), ('AI', 'ai'), ('analytics', 'analyt'), ('?', '?')]

>> Lemmatization: 
 [('4', '4'), ('How', 'How'), ('organization', 'organization'), ('derive', 'derive'), ('business', 'business'), ('value', 'value'), ('AI', 'AI'), ('analytics', 'analytics'), ('?', '?')]



============================ Sentence 3 =============================

6  What are the requirements for adopting AI? 


>> Tokens are: 
 ['6', 'What', 'requirements', 'adopting', 'AI', '?']

>> Bigrams are: 
 [('6', 'What'), ('What', 'requirements'), ('requirements', 'adopting'), ('adopting', 'AI'), ('AI', '?')]

>> Trigrams are: 
 [('6', 'What', 'requirements'), ('What', 'requirements', 'adopting'), ('requirements', 'adopting', 'AI'), ('adopting', 'AI', '?')]

>> POS Tags are: 
 [('6', 'CD'), ('What', 'WP'), ('requirements', 'NNS'), ('adopting', 'VBG'), ('AI', 'NNP'), ('?', '.')]

 (S 6/CD What/WP (NP requirements/NNS) adopting/VBG (NP AI/NNP) ?/.) 


>> Noun Phrases are: 
 ['requirements', 'AI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('What', 'what'), ('requirements', 'requir'), ('adopting', 'adopt'), ('AI', 'ai'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('What', 'what'), ('requirements', 'requir'), ('adopting', 'adopt'), ('AI', 'ai'), ('?', '?')]

>> Lemmatization: 
 [('6', '6'), ('What', 'What'), ('requirements', 'requirement'), ('adopting', 'adopting'), ('AI', 'AI'), ('?', '?')]



============================ Sentence 4 =============================

7  How can data science, artificial intelligence  and analytics transform business processes? 


>> Tokens are: 
 ['7', 'How', 'data', 'science', ',', 'artificial', 'intelligence', 'analytics', 'transform', 'business', 'processes', '?']

>> Bigrams are: 
 [('7', 'How'), ('How', 'data'), ('data', 'science'), ('science', ','), (',', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'analytics'), ('analytics', 'transform'), ('transform', 'business'), ('business', 'processes'), ('processes', '?')]

>> Trigrams are: 
 [('7', 'How', 'data'), ('How', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'artificial'), (',', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'analytics'), ('intelligence', 'analytics', 'transform'), ('analytics', 'transform', 'business'), ('transform', 'business', 'processes'), ('business', 'processes', '?')]

>> POS Tags are: 
 [('7', 'CD'), ('How', 'NNP'), ('data', 'NNS'), ('science', 'NN'), (',', ','), ('artificial', 'JJ'), ('intelligence', 'NN'), ('analytics', 'NNS'), ('transform', 'NN'), ('business', 'NN'), ('processes', 'NNS'), ('?', '.')]

 (S
  7/CD
  (NP How/NNP data/NNS science/NN)
  ,/,
  (NP
    artificial/JJ
    intelligence/NN
    analytics/NNS
    transform/NN
    business/NN
    processes/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['How data science', 'artificial intelligence analytics transform business processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('How', 'how'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('transform', 'transform'), ('business', 'busi'), ('processes', 'process'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('How', 'how'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('transform', 'transform'), ('business', 'busi'), ('processes', 'process'), ('?', '?')]

>> Lemmatization: 
 [('7', '7'), ('How', 'How'), ('data', 'data'), ('science', 'science'), (',', ','), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), ('transform', 'transform'), ('business', 'business'), ('processes', 'process'), ('?', '?')]



============================ Sentence 5 =============================

9  Common techniques and methodologies 10  Machine learning 10  Supervised learning 11  Unsupervised learning 12  Natural language processing 13  Key questions to ask and how to define high value use-cases 13  Resources 14    3/14Demystifying data science   Summary By 2020, Forbes estimates that 85 percent of customer interactions will be  managed without a human.1 While many of us use AI technology, such as Alexa and  Siri, as part of our daily lives, we may not be aware of its greater uses. 


>> Tokens are: 
 ['9', 'Common', 'techniques', 'methodologies', '10', 'Machine', 'learning', '10', 'Supervised', 'learning', '11', 'Unsupervised', 'learning', '12', 'Natural', 'language', 'processing', '13', 'Key', 'questions', 'ask', 'define', 'high', 'value', 'use-cases', '13', 'Resources', '14', '3/14Demystifying', 'data', 'science', 'Summary', 'By', '2020', ',', 'Forbes', 'estimates', '85', 'percent', 'customer', 'interactions', 'managed', 'without', 'human.1', 'While', 'many', 'us', 'use', 'AI', 'technology', ',', 'Alexa', 'Siri', ',', 'part', 'daily', 'lives', ',', 'may', 'aware', 'greater', 'uses', '.']

>> Bigrams are: 
 [('9', 'Common'), ('Common', 'techniques'), ('techniques', 'methodologies'), ('methodologies', '10'), ('10', 'Machine'), ('Machine', 'learning'), ('learning', '10'), ('10', 'Supervised'), ('Supervised', 'learning'), ('learning', '11'), ('11', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', '12'), ('12', 'Natural'), ('Natural', 'language'), ('language', 'processing'), ('processing', '13'), ('13', 'Key'), ('Key', 'questions'), ('questions', 'ask'), ('ask', 'define'), ('define', 'high'), ('high', 'value'), ('value', 'use-cases'), ('use-cases', '13'), ('13', 'Resources'), ('Resources', '14'), ('14', '3/14Demystifying'), ('3/14Demystifying', 'data'), ('data', 'science'), ('science', 'Summary'), ('Summary', 'By'), ('By', '2020'), ('2020', ','), (',', 'Forbes'), ('Forbes', 'estimates'), ('estimates', '85'), ('85', 'percent'), ('percent', 'customer'), ('customer', 'interactions'), ('interactions', 'managed'), ('managed', 'without'), ('without', 'human.1'), ('human.1', 'While'), ('While', 'many'), ('many', 'us'), ('us', 'use'), ('use', 'AI'), ('AI', 'technology'), ('technology', ','), (',', 'Alexa'), ('Alexa', 'Siri'), ('Siri', ','), (',', 'part'), ('part', 'daily'), ('daily', 'lives'), ('lives', ','), (',', 'may'), ('may', 'aware'), ('aware', 'greater'), ('greater', 'uses'), ('uses', '.')]

>> Trigrams are: 
 [('9', 'Common', 'techniques'), ('Common', 'techniques', 'methodologies'), ('techniques', 'methodologies', '10'), ('methodologies', '10', 'Machine'), ('10', 'Machine', 'learning'), ('Machine', 'learning', '10'), ('learning', '10', 'Supervised'), ('10', 'Supervised', 'learning'), ('Supervised', 'learning', '11'), ('learning', '11', 'Unsupervised'), ('11', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', '12'), ('learning', '12', 'Natural'), ('12', 'Natural', 'language'), ('Natural', 'language', 'processing'), ('language', 'processing', '13'), ('processing', '13', 'Key'), ('13', 'Key', 'questions'), ('Key', 'questions', 'ask'), ('questions', 'ask', 'define'), ('ask', 'define', 'high'), ('define', 'high', 'value'), ('high', 'value', 'use-cases'), ('value', 'use-cases', '13'), ('use-cases', '13', 'Resources'), ('13', 'Resources', '14'), ('Resources', '14', '3/14Demystifying'), ('14', '3/14Demystifying', 'data'), ('3/14Demystifying', 'data', 'science'), ('data', 'science', 'Summary'), ('science', 'Summary', 'By'), ('Summary', 'By', '2020'), ('By', '2020', ','), ('2020', ',', 'Forbes'), (',', 'Forbes', 'estimates'), ('Forbes', 'estimates', '85'), ('estimates', '85', 'percent'), ('85', 'percent', 'customer'), ('percent', 'customer', 'interactions'), ('customer', 'interactions', 'managed'), ('interactions', 'managed', 'without'), ('managed', 'without', 'human.1'), ('without', 'human.1', 'While'), ('human.1', 'While', 'many'), ('While', 'many', 'us'), ('many', 'us', 'use'), ('us', 'use', 'AI'), ('use', 'AI', 'technology'), ('AI', 'technology', ','), ('technology', ',', 'Alexa'), (',', 'Alexa', 'Siri'), ('Alexa', 'Siri', ','), ('Siri', ',', 'part'), (',', 'part', 'daily'), ('part', 'daily', 'lives'), ('daily', 'lives', ','), ('lives', ',', 'may'), (',', 'may', 'aware'), ('may', 'aware', 'greater'), ('aware', 'greater', 'uses'), ('greater', 'uses', '.')]

>> POS Tags are: 
 [('9', 'CD'), ('Common', 'NNP'), ('techniques', 'NNS'), ('methodologies', 'NNS'), ('10', 'CD'), ('Machine', 'NNP'), ('learning', 'VBG'), ('10', 'CD'), ('Supervised', 'VBD'), ('learning', 'VBG'), ('11', 'CD'), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('12', 'CD'), ('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('13', 'CD'), ('Key', 'NNP'), ('questions', 'NNS'), ('ask', 'VBP'), ('define', 'JJ'), ('high', 'JJ'), ('value', 'NN'), ('use-cases', 'JJ'), ('13', 'CD'), ('Resources', 'NNPS'), ('14', 'CD'), ('3/14Demystifying', 'CD'), ('data', 'NNS'), ('science', 'NN'), ('Summary', 'NNP'), ('By', 'IN'), ('2020', 'CD'), (',', ','), ('Forbes', 'NNP'), ('estimates', 'VBZ'), ('85', 'CD'), ('percent', 'NN'), ('customer', 'NN'), ('interactions', 'NNS'), ('managed', 'VBD'), ('without', 'IN'), ('human.1', 'NN'), ('While', 'IN'), ('many', 'JJ'), ('us', 'PRP'), ('use', 'VBP'), ('AI', 'NNP'), ('technology', 'NN'), (',', ','), ('Alexa', 'NNP'), ('Siri', 'NNP'), (',', ','), ('part', 'NN'), ('daily', 'JJ'), ('lives', 'NNS'), (',', ','), ('may', 'MD'), ('aware', 'VB'), ('greater', 'JJR'), ('uses', 'NNS'), ('.', '.')]

 (S
  9/CD
  (NP Common/NNP techniques/NNS methodologies/NNS)
  10/CD
  (NP Machine/NNP)
  learning/VBG
  10/CD
  Supervised/VBD
  learning/VBG
  11/CD
  Unsupervised/VBD
  learning/VBG
  12/CD
  (NP Natural/JJ language/NN processing/NN)
  13/CD
  (NP Key/NNP questions/NNS)
  ask/VBP
  (NP define/JJ high/JJ value/NN)
  use-cases/JJ
  13/CD
  Resources/NNPS
  14/CD
  3/14Demystifying/CD
  (NP data/NNS science/NN Summary/NNP)
  By/IN
  2020/CD
  ,/,
  (NP Forbes/NNP)
  estimates/VBZ
  85/CD
  (NP percent/NN customer/NN interactions/NNS)
  managed/VBD
  without/IN
  (NP human.1/NN)
  While/IN
  many/JJ
  us/PRP
  use/VBP
  (NP AI/NNP technology/NN)
  ,/,
  (NP Alexa/NNP Siri/NNP)
  ,/,
  (NP part/NN)
  (NP daily/JJ lives/NNS)
  ,/,
  may/MD
  aware/VB
  greater/JJR
  (NP uses/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Common techniques methodologies', 'Machine', 'Natural language processing', 'Key questions', 'define high value', 'data science Summary', 'Forbes', 'percent customer interactions', 'human.1', 'AI technology', 'Alexa Siri', 'part', 'daily lives', 'uses']

>> Named Entities are: 
 [('ORGANIZATION', 'Forbes'), ('ORGANIZATION', 'AI'), ('PERSON', 'Alexa Siri')] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('Common', 'common'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), ('10', '10'), ('Machine', 'machin'), ('learning', 'learn'), ('10', '10'), ('Supervised', 'supervis'), ('learning', 'learn'), ('11', '11'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('12', '12'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('13', '13'), ('Key', 'key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'defin'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('13', '13'), ('Resources', 'resourc'), ('14', '14'), ('3/14Demystifying', '3/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Summary', 'summari'), ('By', 'by'), ('2020', '2020'), (',', ','), ('Forbes', 'forb'), ('estimates', 'estim'), ('85', '85'), ('percent', 'percent'), ('customer', 'custom'), ('interactions', 'interact'), ('managed', 'manag'), ('without', 'without'), ('human.1', 'human.1'), ('While', 'while'), ('many', 'mani'), ('us', 'us'), ('use', 'use'), ('AI', 'ai'), ('technology', 'technolog'), (',', ','), ('Alexa', 'alexa'), ('Siri', 'siri'), (',', ','), ('part', 'part'), ('daily', 'daili'), ('lives', 'live'), (',', ','), ('may', 'may'), ('aware', 'awar'), ('greater', 'greater'), ('uses', 'use'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('Common', 'common'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), ('10', '10'), ('Machine', 'machin'), ('learning', 'learn'), ('10', '10'), ('Supervised', 'supervis'), ('learning', 'learn'), ('11', '11'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('12', '12'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('13', '13'), ('Key', 'key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'defin'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('13', '13'), ('Resources', 'resourc'), ('14', '14'), ('3/14Demystifying', '3/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Summary', 'summari'), ('By', 'by'), ('2020', '2020'), (',', ','), ('Forbes', 'forb'), ('estimates', 'estim'), ('85', '85'), ('percent', 'percent'), ('customer', 'custom'), ('interactions', 'interact'), ('managed', 'manag'), ('without', 'without'), ('human.1', 'human.1'), ('While', 'while'), ('many', 'mani'), ('us', 'us'), ('use', 'use'), ('AI', 'ai'), ('technology', 'technolog'), (',', ','), ('Alexa', 'alexa'), ('Siri', 'siri'), (',', ','), ('part', 'part'), ('daily', 'daili'), ('lives', 'live'), (',', ','), ('may', 'may'), ('aware', 'awar'), ('greater', 'greater'), ('uses', 'use'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('Common', 'Common'), ('techniques', 'technique'), ('methodologies', 'methodology'), ('10', '10'), ('Machine', 'Machine'), ('learning', 'learning'), ('10', '10'), ('Supervised', 'Supervised'), ('learning', 'learning'), ('11', '11'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('12', '12'), ('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('13', '13'), ('Key', 'Key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'define'), ('high', 'high'), ('value', 'value'), ('use-cases', 'use-cases'), ('13', '13'), ('Resources', 'Resources'), ('14', '14'), ('3/14Demystifying', '3/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Summary', 'Summary'), ('By', 'By'), ('2020', '2020'), (',', ','), ('Forbes', 'Forbes'), ('estimates', 'estimate'), ('85', '85'), ('percent', 'percent'), ('customer', 'customer'), ('interactions', 'interaction'), ('managed', 'managed'), ('without', 'without'), ('human.1', 'human.1'), ('While', 'While'), ('many', 'many'), ('us', 'u'), ('use', 'use'), ('AI', 'AI'), ('technology', 'technology'), (',', ','), ('Alexa', 'Alexa'), ('Siri', 'Siri'), (',', ','), ('part', 'part'), ('daily', 'daily'), ('lives', 'life'), (',', ','), ('may', 'may'), ('aware', 'aware'), ('greater', 'greater'), ('uses', 'us'), ('.', '.')]



============================ Sentence 6 =============================

In fact, with  machine learning applied, AI can help teach computers, target ads and personalize  content for consumers to ensure better and more informed business decisions. 


>> Tokens are: 
 ['In', 'fact', ',', 'machine', 'learning', 'applied', ',', 'AI', 'help', 'teach', 'computers', ',', 'target', 'ads', 'personalize', 'content', 'consumers', 'ensure', 'better', 'informed', 'business', 'decisions', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'applied'), ('applied', ','), (',', 'AI'), ('AI', 'help'), ('help', 'teach'), ('teach', 'computers'), ('computers', ','), (',', 'target'), ('target', 'ads'), ('ads', 'personalize'), ('personalize', 'content'), ('content', 'consumers'), ('consumers', 'ensure'), ('ensure', 'better'), ('better', 'informed'), ('informed', 'business'), ('business', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'applied'), ('learning', 'applied', ','), ('applied', ',', 'AI'), (',', 'AI', 'help'), ('AI', 'help', 'teach'), ('help', 'teach', 'computers'), ('teach', 'computers', ','), ('computers', ',', 'target'), (',', 'target', 'ads'), ('target', 'ads', 'personalize'), ('ads', 'personalize', 'content'), ('personalize', 'content', 'consumers'), ('content', 'consumers', 'ensure'), ('consumers', 'ensure', 'better'), ('ensure', 'better', 'informed'), ('better', 'informed', 'business'), ('informed', 'business', 'decisions'), ('business', 'decisions', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('applied', 'VBN'), (',', ','), ('AI', 'NNP'), ('help', 'NN'), ('teach', 'NN'), ('computers', 'NNS'), (',', ','), ('target', 'NN'), ('ads', 'NNS'), ('personalize', 'VBP'), ('content', 'JJ'), ('consumers', 'NNS'), ('ensure', 'VB'), ('better', 'JJR'), ('informed', 'NN'), ('business', 'NN'), ('decisions', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP fact/NN)
  ,/,
  (NP machine/NN learning/NN)
  applied/VBN
  ,/,
  (NP AI/NNP help/NN teach/NN computers/NNS)
  ,/,
  (NP target/NN ads/NNS)
  personalize/VBP
  (NP content/JJ consumers/NNS)
  ensure/VB
  better/JJR
  (NP informed/NN business/NN decisions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'machine learning', 'AI help teach computers', 'target ads', 'content consumers', 'informed business decisions']

>> Named Entities are: 
 [('ORGANIZATION', 'AI')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('applied', 'appli'), (',', ','), ('AI', 'ai'), ('help', 'help'), ('teach', 'teach'), ('computers', 'comput'), (',', ','), ('target', 'target'), ('ads', 'ad'), ('personalize', 'person'), ('content', 'content'), ('consumers', 'consum'), ('ensure', 'ensur'), ('better', 'better'), ('informed', 'inform'), ('business', 'busi'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('applied', 'appli'), (',', ','), ('AI', 'ai'), ('help', 'help'), ('teach', 'teach'), ('computers', 'comput'), (',', ','), ('target', 'target'), ('ads', 'ad'), ('personalize', 'person'), ('content', 'content'), ('consumers', 'consum'), ('ensure', 'ensur'), ('better', 'better'), ('informed', 'inform'), ('business', 'busi'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('applied', 'applied'), (',', ','), ('AI', 'AI'), ('help', 'help'), ('teach', 'teach'), ('computers', 'computer'), (',', ','), ('target', 'target'), ('ads', 'ad'), ('personalize', 'personalize'), ('content', 'content'), ('consumers', 'consumer'), ('ensure', 'ensure'), ('better', 'better'), ('informed', 'informed'), ('business', 'business'), ('decisions', 'decision'), ('.', '.')]



============================ Sentence 7 =============================

This paper will clarify some key definitions around artificial intelligence and  machine learning. 


>> Tokens are: 
 ['This', 'paper', 'clarify', 'key', 'definitions', 'around', 'artificial', 'intelligence', 'machine', 'learning', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'clarify'), ('clarify', 'key'), ('key', 'definitions'), ('definitions', 'around'), ('around', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'paper', 'clarify'), ('paper', 'clarify', 'key'), ('clarify', 'key', 'definitions'), ('key', 'definitions', 'around'), ('definitions', 'around', 'artificial'), ('around', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'machine'), ('intelligence', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('clarify', 'VBZ'), ('key', 'JJ'), ('definitions', 'NNS'), ('around', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP This/DT paper/NN)
  clarify/VBZ
  (NP key/JJ definitions/NNS)
  around/IN
  (NP artificial/JJ intelligence/NN machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['This paper', 'key definitions', 'artificial intelligence machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('clarify', 'clarifi'), ('key', 'key'), ('definitions', 'definit'), ('around', 'around'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('clarify', 'clarifi'), ('key', 'key'), ('definitions', 'definit'), ('around', 'around'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('clarify', 'clarify'), ('key', 'key'), ('definitions', 'definition'), ('around', 'around'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 8 =============================

It will also simplify some common techniques in machine learning,  such as supervised learning, natural language processing and classification, and  identify the types of business questions these techniques can answer. 


>> Tokens are: 
 ['It', 'also', 'simplify', 'common', 'techniques', 'machine', 'learning', ',', 'supervised', 'learning', ',', 'natural', 'language', 'processing', 'classification', ',', 'identify', 'types', 'business', 'questions', 'techniques', 'answer', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'simplify'), ('simplify', 'common'), ('common', 'techniques'), ('techniques', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'supervised'), ('supervised', 'learning'), ('learning', ','), (',', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'classification'), ('classification', ','), (',', 'identify'), ('identify', 'types'), ('types', 'business'), ('business', 'questions'), ('questions', 'techniques'), ('techniques', 'answer'), ('answer', '.')]

>> Trigrams are: 
 [('It', 'also', 'simplify'), ('also', 'simplify', 'common'), ('simplify', 'common', 'techniques'), ('common', 'techniques', 'machine'), ('techniques', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'supervised'), (',', 'supervised', 'learning'), ('supervised', 'learning', ','), ('learning', ',', 'natural'), (',', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'classification'), ('processing', 'classification', ','), ('classification', ',', 'identify'), (',', 'identify', 'types'), ('identify', 'types', 'business'), ('types', 'business', 'questions'), ('business', 'questions', 'techniques'), ('questions', 'techniques', 'answer'), ('techniques', 'answer', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('simplify', 'VBD'), ('common', 'JJ'), ('techniques', 'NNS'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('supervised', 'VBD'), ('learning', 'NN'), (',', ','), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('classification', 'NN'), (',', ','), ('identify', 'VB'), ('types', 'NNS'), ('business', 'NN'), ('questions', 'NNS'), ('techniques', 'NNS'), ('answer', 'VBP'), ('.', '.')]

 (S
  It/PRP
  also/RB
  simplify/VBD
  (NP common/JJ techniques/NNS machine/NN learning/NN)
  ,/,
  supervised/VBD
  (NP learning/NN)
  ,/,
  (NP natural/JJ language/NN processing/NN classification/NN)
  ,/,
  identify/VB
  (NP types/NNS business/NN questions/NNS techniques/NNS)
  answer/VBP
  ./.) 


>> Noun Phrases are: 
 ['common techniques machine learning', 'learning', 'natural language processing classification', 'types business questions techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('simplify', 'simplifi'), ('common', 'common'), ('techniques', 'techniqu'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('classification', 'classif'), (',', ','), ('identify', 'identifi'), ('types', 'type'), ('business', 'busi'), ('questions', 'question'), ('techniques', 'techniqu'), ('answer', 'answer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('simplify', 'simplifi'), ('common', 'common'), ('techniques', 'techniqu'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('classification', 'classif'), (',', ','), ('identify', 'identifi'), ('types', 'type'), ('business', 'busi'), ('questions', 'question'), ('techniques', 'techniqu'), ('answer', 'answer'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('simplify', 'simplify'), ('common', 'common'), ('techniques', 'technique'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('supervised', 'supervised'), ('learning', 'learning'), (',', ','), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('classification', 'classification'), (',', ','), ('identify', 'identify'), ('types', 'type'), ('business', 'business'), ('questions', 'question'), ('techniques', 'technique'), ('answer', 'answer'), ('.', '.')]



============================ Sentence 9 =============================

While understanding a small number of customers may not pose a challenge,  keeping pace as organizations grow and expand their customer base can be  difficult. 


>> Tokens are: 
 ['While', 'understanding', 'small', 'number', 'customers', 'may', 'pose', 'challenge', ',', 'keeping', 'pace', 'organizations', 'grow', 'expand', 'customer', 'base', 'difficult', '.']

>> Bigrams are: 
 [('While', 'understanding'), ('understanding', 'small'), ('small', 'number'), ('number', 'customers'), ('customers', 'may'), ('may', 'pose'), ('pose', 'challenge'), ('challenge', ','), (',', 'keeping'), ('keeping', 'pace'), ('pace', 'organizations'), ('organizations', 'grow'), ('grow', 'expand'), ('expand', 'customer'), ('customer', 'base'), ('base', 'difficult'), ('difficult', '.')]

>> Trigrams are: 
 [('While', 'understanding', 'small'), ('understanding', 'small', 'number'), ('small', 'number', 'customers'), ('number', 'customers', 'may'), ('customers', 'may', 'pose'), ('may', 'pose', 'challenge'), ('pose', 'challenge', ','), ('challenge', ',', 'keeping'), (',', 'keeping', 'pace'), ('keeping', 'pace', 'organizations'), ('pace', 'organizations', 'grow'), ('organizations', 'grow', 'expand'), ('grow', 'expand', 'customer'), ('expand', 'customer', 'base'), ('customer', 'base', 'difficult'), ('base', 'difficult', '.')]

>> POS Tags are: 
 [('While', 'IN'), ('understanding', 'VBG'), ('small', 'JJ'), ('number', 'NN'), ('customers', 'NNS'), ('may', 'MD'), ('pose', 'VB'), ('challenge', 'NN'), (',', ','), ('keeping', 'VBG'), ('pace', 'NN'), ('organizations', 'NNS'), ('grow', 'VBP'), ('expand', 'VB'), ('customer', 'NN'), ('base', 'NN'), ('difficult', 'JJ'), ('.', '.')]

 (S
  While/IN
  understanding/VBG
  (NP small/JJ number/NN customers/NNS)
  may/MD
  pose/VB
  (NP challenge/NN)
  ,/,
  keeping/VBG
  (NP pace/NN organizations/NNS)
  grow/VBP
  expand/VB
  (NP customer/NN base/NN)
  difficult/JJ
  ./.) 


>> Noun Phrases are: 
 ['small number customers', 'challenge', 'pace organizations', 'customer base']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('understanding', 'understand'), ('small', 'small'), ('number', 'number'), ('customers', 'custom'), ('may', 'may'), ('pose', 'pose'), ('challenge', 'challeng'), (',', ','), ('keeping', 'keep'), ('pace', 'pace'), ('organizations', 'organ'), ('grow', 'grow'), ('expand', 'expand'), ('customer', 'custom'), ('base', 'base'), ('difficult', 'difficult'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('understanding', 'understand'), ('small', 'small'), ('number', 'number'), ('customers', 'custom'), ('may', 'may'), ('pose', 'pose'), ('challenge', 'challeng'), (',', ','), ('keeping', 'keep'), ('pace', 'pace'), ('organizations', 'organ'), ('grow', 'grow'), ('expand', 'expand'), ('customer', 'custom'), ('base', 'base'), ('difficult', 'difficult'), ('.', '.')]

>> Lemmatization: 
 [('While', 'While'), ('understanding', 'understanding'), ('small', 'small'), ('number', 'number'), ('customers', 'customer'), ('may', 'may'), ('pose', 'pose'), ('challenge', 'challenge'), (',', ','), ('keeping', 'keeping'), ('pace', 'pace'), ('organizations', 'organization'), ('grow', 'grow'), ('expand', 'expand'), ('customer', 'customer'), ('base', 'base'), ('difficult', 'difficult'), ('.', '.')]



============================ Sentence 10 =============================

Data analytics can help reveal trends and metrics that would otherwise  be lost among the masses of information. 


>> Tokens are: 
 ['Data', 'analytics', 'help', 'reveal', 'trends', 'metrics', 'would', 'otherwise', 'lost', 'among', 'masses', 'information', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'help'), ('help', 'reveal'), ('reveal', 'trends'), ('trends', 'metrics'), ('metrics', 'would'), ('would', 'otherwise'), ('otherwise', 'lost'), ('lost', 'among'), ('among', 'masses'), ('masses', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'help'), ('analytics', 'help', 'reveal'), ('help', 'reveal', 'trends'), ('reveal', 'trends', 'metrics'), ('trends', 'metrics', 'would'), ('metrics', 'would', 'otherwise'), ('would', 'otherwise', 'lost'), ('otherwise', 'lost', 'among'), ('lost', 'among', 'masses'), ('among', 'masses', 'information'), ('masses', 'information', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('help', 'VBP'), ('reveal', 'VB'), ('trends', 'NNS'), ('metrics', 'NNS'), ('would', 'MD'), ('otherwise', 'RB'), ('lost', 'VB'), ('among', 'IN'), ('masses', 'NNS'), ('information', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS)
  help/VBP
  reveal/VB
  (NP trends/NNS metrics/NNS)
  would/MD
  otherwise/RB
  lost/VB
  among/IN
  (NP masses/NNS information/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics', 'trends metrics', 'masses information']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwis'), ('lost', 'lost'), ('among', 'among'), ('masses', 'mass'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwis'), ('lost', 'lost'), ('among', 'among'), ('masses', 'mass'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('help', 'help'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwise'), ('lost', 'lost'), ('among', 'among'), ('masses', 'mass'), ('information', 'information'), ('.', '.')]



============================ Sentence 11 =============================

Organizations are now starting to  leverage descriptive, diagnostic, predictive and prescriptive analytics to address  the growing needs and demands of their customer base. 


>> Tokens are: 
 ['Organizations', 'starting', 'leverage', 'descriptive', ',', 'diagnostic', ',', 'predictive', 'prescriptive', 'analytics', 'address', 'growing', 'needs', 'demands', 'customer', 'base', '.']

>> Bigrams are: 
 [('Organizations', 'starting'), ('starting', 'leverage'), ('leverage', 'descriptive'), ('descriptive', ','), (',', 'diagnostic'), ('diagnostic', ','), (',', 'predictive'), ('predictive', 'prescriptive'), ('prescriptive', 'analytics'), ('analytics', 'address'), ('address', 'growing'), ('growing', 'needs'), ('needs', 'demands'), ('demands', 'customer'), ('customer', 'base'), ('base', '.')]

>> Trigrams are: 
 [('Organizations', 'starting', 'leverage'), ('starting', 'leverage', 'descriptive'), ('leverage', 'descriptive', ','), ('descriptive', ',', 'diagnostic'), (',', 'diagnostic', ','), ('diagnostic', ',', 'predictive'), (',', 'predictive', 'prescriptive'), ('predictive', 'prescriptive', 'analytics'), ('prescriptive', 'analytics', 'address'), ('analytics', 'address', 'growing'), ('address', 'growing', 'needs'), ('growing', 'needs', 'demands'), ('needs', 'demands', 'customer'), ('demands', 'customer', 'base'), ('customer', 'base', '.')]

>> POS Tags are: 
 [('Organizations', 'NNS'), ('starting', 'VBG'), ('leverage', 'NN'), ('descriptive', 'JJ'), (',', ','), ('diagnostic', 'JJ'), (',', ','), ('predictive', 'JJ'), ('prescriptive', 'JJ'), ('analytics', 'NNS'), ('address', 'IN'), ('growing', 'VBG'), ('needs', 'NNS'), ('demands', 'VBZ'), ('customer', 'NN'), ('base', 'NN'), ('.', '.')]

 (S
  (NP Organizations/NNS)
  starting/VBG
  (NP leverage/NN)
  descriptive/JJ
  ,/,
  diagnostic/JJ
  ,/,
  (NP predictive/JJ prescriptive/JJ analytics/NNS)
  address/IN
  growing/VBG
  (NP needs/NNS)
  demands/VBZ
  (NP customer/NN base/NN)
  ./.) 


>> Noun Phrases are: 
 ['Organizations', 'leverage', 'predictive prescriptive analytics', 'needs', 'customer base']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organizations', 'organ'), ('starting', 'start'), ('leverage', 'leverag'), ('descriptive', 'descript'), (',', ','), ('diagnostic', 'diagnost'), (',', ','), ('predictive', 'predict'), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('address', 'address'), ('growing', 'grow'), ('needs', 'need'), ('demands', 'demand'), ('customer', 'custom'), ('base', 'base'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organizations', 'organ'), ('starting', 'start'), ('leverage', 'leverag'), ('descriptive', 'descript'), (',', ','), ('diagnostic', 'diagnost'), (',', ','), ('predictive', 'predict'), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('address', 'address'), ('growing', 'grow'), ('needs', 'need'), ('demands', 'demand'), ('customer', 'custom'), ('base', 'base'), ('.', '.')]

>> Lemmatization: 
 [('Organizations', 'Organizations'), ('starting', 'starting'), ('leverage', 'leverage'), ('descriptive', 'descriptive'), (',', ','), ('diagnostic', 'diagnostic'), (',', ','), ('predictive', 'predictive'), ('prescriptive', 'prescriptive'), ('analytics', 'analytics'), ('address', 'address'), ('growing', 'growing'), ('needs', 'need'), ('demands', 'demand'), ('customer', 'customer'), ('base', 'base'), ('.', '.')]



============================ Sentence 12 =============================

The promise of artificial intelligence is exciting but before jumping in organizations  need the right data literacy, infrastructure and expertise. 


>> Tokens are: 
 ['The', 'promise', 'artificial', 'intelligence', 'exciting', 'jumping', 'organizations', 'need', 'right', 'data', 'literacy', ',', 'infrastructure', 'expertise', '.']

>> Bigrams are: 
 [('The', 'promise'), ('promise', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'exciting'), ('exciting', 'jumping'), ('jumping', 'organizations'), ('organizations', 'need'), ('need', 'right'), ('right', 'data'), ('data', 'literacy'), ('literacy', ','), (',', 'infrastructure'), ('infrastructure', 'expertise'), ('expertise', '.')]

>> Trigrams are: 
 [('The', 'promise', 'artificial'), ('promise', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'exciting'), ('intelligence', 'exciting', 'jumping'), ('exciting', 'jumping', 'organizations'), ('jumping', 'organizations', 'need'), ('organizations', 'need', 'right'), ('need', 'right', 'data'), ('right', 'data', 'literacy'), ('data', 'literacy', ','), ('literacy', ',', 'infrastructure'), (',', 'infrastructure', 'expertise'), ('infrastructure', 'expertise', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('promise', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('exciting', 'VBG'), ('jumping', 'VBG'), ('organizations', 'NNS'), ('need', 'VBP'), ('right', 'JJ'), ('data', 'NNS'), ('literacy', 'NN'), (',', ','), ('infrastructure', 'NN'), ('expertise', 'NN'), ('.', '.')]

 (S
  (NP The/DT promise/NN)
  (NP artificial/JJ intelligence/NN)
  exciting/VBG
  jumping/VBG
  (NP organizations/NNS)
  need/VBP
  (NP right/JJ data/NNS literacy/NN)
  ,/,
  (NP infrastructure/NN expertise/NN)
  ./.) 


>> Noun Phrases are: 
 ['The promise', 'artificial intelligence', 'organizations', 'right data literacy', 'infrastructure expertise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('promise', 'promis'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('exciting', 'excit'), ('jumping', 'jump'), ('organizations', 'organ'), ('need', 'need'), ('right', 'right'), ('data', 'data'), ('literacy', 'literaci'), (',', ','), ('infrastructure', 'infrastructur'), ('expertise', 'expertis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('promise', 'promis'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('exciting', 'excit'), ('jumping', 'jump'), ('organizations', 'organ'), ('need', 'need'), ('right', 'right'), ('data', 'data'), ('literacy', 'literaci'), (',', ','), ('infrastructure', 'infrastructur'), ('expertise', 'expertis'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('promise', 'promise'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('exciting', 'exciting'), ('jumping', 'jumping'), ('organizations', 'organization'), ('need', 'need'), ('right', 'right'), ('data', 'data'), ('literacy', 'literacy'), (',', ','), ('infrastructure', 'infrastructure'), ('expertise', 'expertise'), ('.', '.')]



============================ Sentence 13 =============================

This paper will also cover  key competencies organizations need to get started with AI and how to progress  from data collection, exploration and analytics to artificial intelligence. 


>> Tokens are: 
 ['This', 'paper', 'also', 'cover', 'key', 'competencies', 'organizations', 'need', 'get', 'started', 'AI', 'progress', 'data', 'collection', ',', 'exploration', 'analytics', 'artificial', 'intelligence', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'also'), ('also', 'cover'), ('cover', 'key'), ('key', 'competencies'), ('competencies', 'organizations'), ('organizations', 'need'), ('need', 'get'), ('get', 'started'), ('started', 'AI'), ('AI', 'progress'), ('progress', 'data'), ('data', 'collection'), ('collection', ','), (',', 'exploration'), ('exploration', 'analytics'), ('analytics', 'artificial'), ('artificial', 'intelligence'), ('intelligence', '.')]

>> Trigrams are: 
 [('This', 'paper', 'also'), ('paper', 'also', 'cover'), ('also', 'cover', 'key'), ('cover', 'key', 'competencies'), ('key', 'competencies', 'organizations'), ('competencies', 'organizations', 'need'), ('organizations', 'need', 'get'), ('need', 'get', 'started'), ('get', 'started', 'AI'), ('started', 'AI', 'progress'), ('AI', 'progress', 'data'), ('progress', 'data', 'collection'), ('data', 'collection', ','), ('collection', ',', 'exploration'), (',', 'exploration', 'analytics'), ('exploration', 'analytics', 'artificial'), ('analytics', 'artificial', 'intelligence'), ('artificial', 'intelligence', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('also', 'RB'), ('cover', 'RB'), ('key', 'JJ'), ('competencies', 'NNS'), ('organizations', 'NNS'), ('need', 'VBP'), ('get', 'VB'), ('started', 'VBN'), ('AI', 'NNP'), ('progress', 'NN'), ('data', 'NNS'), ('collection', 'NN'), (',', ','), ('exploration', 'NN'), ('analytics', 'NNS'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.')]

 (S
  (NP This/DT paper/NN)
  also/RB
  cover/RB
  (NP key/JJ competencies/NNS organizations/NNS)
  need/VBP
  get/VB
  started/VBN
  (NP AI/NNP progress/NN data/NNS collection/NN)
  ,/,
  (NP exploration/NN analytics/NNS)
  (NP artificial/JJ intelligence/NN)
  ./.) 


>> Noun Phrases are: 
 ['This paper', 'key competencies organizations', 'AI progress data collection', 'exploration analytics', 'artificial intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'AI')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('also', 'also'), ('cover', 'cover'), ('key', 'key'), ('competencies', 'compet'), ('organizations', 'organ'), ('need', 'need'), ('get', 'get'), ('started', 'start'), ('AI', 'ai'), ('progress', 'progress'), ('data', 'data'), ('collection', 'collect'), (',', ','), ('exploration', 'explor'), ('analytics', 'analyt'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('also', 'also'), ('cover', 'cover'), ('key', 'key'), ('competencies', 'compet'), ('organizations', 'organ'), ('need', 'need'), ('get', 'get'), ('started', 'start'), ('AI', 'ai'), ('progress', 'progress'), ('data', 'data'), ('collection', 'collect'), (',', ','), ('exploration', 'explor'), ('analytics', 'analyt'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('also', 'also'), ('cover', 'cover'), ('key', 'key'), ('competencies', 'competency'), ('organizations', 'organization'), ('need', 'need'), ('get', 'get'), ('started', 'started'), ('AI', 'AI'), ('progress', 'progress'), ('data', 'data'), ('collection', 'collection'), (',', ','), ('exploration', 'exploration'), ('analytics', 'analytics'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('.', '.')]



============================ Sentence 14 =============================

Finally, this paper will help define meaningful and high value use-cases with  a structured framework to gather and align business, technology and data  requirements for a successful artificial intelligence implementation. 


>> Tokens are: 
 ['Finally', ',', 'paper', 'help', 'define', 'meaningful', 'high', 'value', 'use-cases', 'structured', 'framework', 'gather', 'align', 'business', ',', 'technology', 'data', 'requirements', 'successful', 'artificial', 'intelligence', 'implementation', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'paper'), ('paper', 'help'), ('help', 'define'), ('define', 'meaningful'), ('meaningful', 'high'), ('high', 'value'), ('value', 'use-cases'), ('use-cases', 'structured'), ('structured', 'framework'), ('framework', 'gather'), ('gather', 'align'), ('align', 'business'), ('business', ','), (',', 'technology'), ('technology', 'data'), ('data', 'requirements'), ('requirements', 'successful'), ('successful', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'implementation'), ('implementation', '.')]

>> Trigrams are: 
 [('Finally', ',', 'paper'), (',', 'paper', 'help'), ('paper', 'help', 'define'), ('help', 'define', 'meaningful'), ('define', 'meaningful', 'high'), ('meaningful', 'high', 'value'), ('high', 'value', 'use-cases'), ('value', 'use-cases', 'structured'), ('use-cases', 'structured', 'framework'), ('structured', 'framework', 'gather'), ('framework', 'gather', 'align'), ('gather', 'align', 'business'), ('align', 'business', ','), ('business', ',', 'technology'), (',', 'technology', 'data'), ('technology', 'data', 'requirements'), ('data', 'requirements', 'successful'), ('requirements', 'successful', 'artificial'), ('successful', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'implementation'), ('intelligence', 'implementation', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('paper', 'NN'), ('help', 'NN'), ('define', 'VB'), ('meaningful', 'JJ'), ('high', 'JJ'), ('value', 'NN'), ('use-cases', 'NNS'), ('structured', 'VBD'), ('framework', 'NN'), ('gather', 'NN'), ('align', 'NN'), ('business', 'NN'), (',', ','), ('technology', 'NN'), ('data', 'NNS'), ('requirements', 'NNS'), ('successful', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('implementation', 'NN'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP paper/NN help/NN)
  define/VB
  (NP meaningful/JJ high/JJ value/NN use-cases/NNS)
  structured/VBD
  (NP framework/NN gather/NN align/NN business/NN)
  ,/,
  (NP technology/NN data/NNS requirements/NNS)
  (NP successful/JJ artificial/JJ intelligence/NN implementation/NN)
  ./.) 


>> Noun Phrases are: 
 ['paper help', 'meaningful high value use-cases', 'framework gather align business', 'technology data requirements', 'successful artificial intelligence implementation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('paper', 'paper'), ('help', 'help'), ('define', 'defin'), ('meaningful', 'meaning'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('structured', 'structur'), ('framework', 'framework'), ('gather', 'gather'), ('align', 'align'), ('business', 'busi'), (',', ','), ('technology', 'technolog'), ('data', 'data'), ('requirements', 'requir'), ('successful', 'success'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('implementation', 'implement'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('paper', 'paper'), ('help', 'help'), ('define', 'defin'), ('meaningful', 'meaning'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('structured', 'structur'), ('framework', 'framework'), ('gather', 'gather'), ('align', 'align'), ('business', 'busi'), (',', ','), ('technology', 'technolog'), ('data', 'data'), ('requirements', 'requir'), ('successful', 'success'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('implementation', 'implement'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('paper', 'paper'), ('help', 'help'), ('define', 'define'), ('meaningful', 'meaningful'), ('high', 'high'), ('value', 'value'), ('use-cases', 'use-cases'), ('structured', 'structured'), ('framework', 'framework'), ('gather', 'gather'), ('align', 'align'), ('business', 'business'), (',', ','), ('technology', 'technology'), ('data', 'data'), ('requirements', 'requirement'), ('successful', 'successful'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('implementation', 'implementation'), ('.', '.')]



============================ Sentence 15 =============================

4/14Demystifying data science   What is artificial intelligence and machine learning? 


>> Tokens are: 
 ['4/14Demystifying', 'data', 'science', 'What', 'artificial', 'intelligence', 'machine', 'learning', '?']

>> Bigrams are: 
 [('4/14Demystifying', 'data'), ('data', 'science'), ('science', 'What'), ('What', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'machine'), ('machine', 'learning'), ('learning', '?')]

>> Trigrams are: 
 [('4/14Demystifying', 'data', 'science'), ('data', 'science', 'What'), ('science', 'What', 'artificial'), ('What', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'machine'), ('intelligence', 'machine', 'learning'), ('machine', 'learning', '?')]

>> POS Tags are: 
 [('4/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('What', 'WP'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('?', '.')]

 (S
  4/14Demystifying/VBG
  (NP data/NNS science/NN)
  What/WP
  (NP artificial/JJ intelligence/NN machine/NN learning/NN)
  ?/.) 


>> Noun Phrases are: 
 ['data science', 'artificial intelligence machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4/14Demystifying', '4/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('What', 'what'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('4/14Demystifying', '4/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('What', 'what'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('4/14Demystifying', '4/14Demystifying'), ('data', 'data'), ('science', 'science'), ('What', 'What'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('machine', 'machine'), ('learning', 'learning'), ('?', '?')]



============================ Sentence 16 =============================

According to Gartner, artificial intelligence will generate $2.9 trillion USD in  business value and recover 6.2 billion hours of worker productivity by 2021.2  To realize the high growth potential and costs savings from analytics and AI  technology, we must demystify some key artificial intelligence, machine learning  and analytics concepts. 


>> Tokens are: 
 ['According', 'Gartner', ',', 'artificial', 'intelligence', 'generate', '$', '2.9', 'trillion', 'USD', 'business', 'value', 'recover', '6.2', 'billion', 'hours', 'worker', 'productivity', '2021.2', 'To', 'realize', 'high', 'growth', 'potential', 'costs', 'savings', 'analytics', 'AI', 'technology', ',', 'must', 'demystify', 'key', 'artificial', 'intelligence', ',', 'machine', 'learning', 'analytics', 'concepts', '.']

>> Bigrams are: 
 [('According', 'Gartner'), ('Gartner', ','), (',', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'generate'), ('generate', '$'), ('$', '2.9'), ('2.9', 'trillion'), ('trillion', 'USD'), ('USD', 'business'), ('business', 'value'), ('value', 'recover'), ('recover', '6.2'), ('6.2', 'billion'), ('billion', 'hours'), ('hours', 'worker'), ('worker', 'productivity'), ('productivity', '2021.2'), ('2021.2', 'To'), ('To', 'realize'), ('realize', 'high'), ('high', 'growth'), ('growth', 'potential'), ('potential', 'costs'), ('costs', 'savings'), ('savings', 'analytics'), ('analytics', 'AI'), ('AI', 'technology'), ('technology', ','), (',', 'must'), ('must', 'demystify'), ('demystify', 'key'), ('key', 'artificial'), ('artificial', 'intelligence'), ('intelligence', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'analytics'), ('analytics', 'concepts'), ('concepts', '.')]

>> Trigrams are: 
 [('According', 'Gartner', ','), ('Gartner', ',', 'artificial'), (',', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'generate'), ('intelligence', 'generate', '$'), ('generate', '$', '2.9'), ('$', '2.9', 'trillion'), ('2.9', 'trillion', 'USD'), ('trillion', 'USD', 'business'), ('USD', 'business', 'value'), ('business', 'value', 'recover'), ('value', 'recover', '6.2'), ('recover', '6.2', 'billion'), ('6.2', 'billion', 'hours'), ('billion', 'hours', 'worker'), ('hours', 'worker', 'productivity'), ('worker', 'productivity', '2021.2'), ('productivity', '2021.2', 'To'), ('2021.2', 'To', 'realize'), ('To', 'realize', 'high'), ('realize', 'high', 'growth'), ('high', 'growth', 'potential'), ('growth', 'potential', 'costs'), ('potential', 'costs', 'savings'), ('costs', 'savings', 'analytics'), ('savings', 'analytics', 'AI'), ('analytics', 'AI', 'technology'), ('AI', 'technology', ','), ('technology', ',', 'must'), (',', 'must', 'demystify'), ('must', 'demystify', 'key'), ('demystify', 'key', 'artificial'), ('key', 'artificial', 'intelligence'), ('artificial', 'intelligence', ','), ('intelligence', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'analytics'), ('learning', 'analytics', 'concepts'), ('analytics', 'concepts', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Gartner', 'NNP'), (',', ','), ('artificial', 'JJ'), ('intelligence', 'NN'), ('generate', 'VBP'), ('$', '$'), ('2.9', 'CD'), ('trillion', 'CD'), ('USD', 'NNP'), ('business', 'NN'), ('value', 'NN'), ('recover', 'VBZ'), ('6.2', 'CD'), ('billion', 'CD'), ('hours', 'NNS'), ('worker', 'NN'), ('productivity', 'NN'), ('2021.2', 'CD'), ('To', 'TO'), ('realize', 'VB'), ('high', 'JJ'), ('growth', 'NN'), ('potential', 'NN'), ('costs', 'NNS'), ('savings', 'VBP'), ('analytics', 'NNS'), ('AI', 'NNP'), ('technology', 'NN'), (',', ','), ('must', 'MD'), ('demystify', 'VB'), ('key', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('analytics', 'NNS'), ('concepts', 'NNS'), ('.', '.')]

 (S
  According/VBG
  (NP Gartner/NNP)
  ,/,
  (NP artificial/JJ intelligence/NN)
  generate/VBP
  $/$
  2.9/CD
  trillion/CD
  (NP USD/NNP business/NN value/NN)
  recover/VBZ
  6.2/CD
  billion/CD
  (NP hours/NNS worker/NN productivity/NN)
  2021.2/CD
  To/TO
  realize/VB
  (NP high/JJ growth/NN potential/NN costs/NNS)
  savings/VBP
  (NP analytics/NNS AI/NNP technology/NN)
  ,/,
  must/MD
  demystify/VB
  (NP key/JJ artificial/JJ intelligence/NN)
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP analytics/NNS concepts/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Gartner', 'artificial intelligence', 'USD business value', 'hours worker productivity', 'high growth potential costs', 'analytics AI technology', 'key artificial intelligence', 'machine', 'analytics concepts']

>> Named Entities are: 
 [('PERSON', 'Gartner')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Gartner', 'gartner'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('generate', 'gener'), ('$', '$'), ('2.9', '2.9'), ('trillion', 'trillion'), ('USD', 'usd'), ('business', 'busi'), ('value', 'valu'), ('recover', 'recov'), ('6.2', '6.2'), ('billion', 'billion'), ('hours', 'hour'), ('worker', 'worker'), ('productivity', 'product'), ('2021.2', '2021.2'), ('To', 'to'), ('realize', 'realiz'), ('high', 'high'), ('growth', 'growth'), ('potential', 'potenti'), ('costs', 'cost'), ('savings', 'save'), ('analytics', 'analyt'), ('AI', 'ai'), ('technology', 'technolog'), (',', ','), ('must', 'must'), ('demystify', 'demystifi'), ('key', 'key'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('analytics', 'analyt'), ('concepts', 'concept'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Gartner', 'gartner'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('generate', 'generat'), ('$', '$'), ('2.9', '2.9'), ('trillion', 'trillion'), ('USD', 'usd'), ('business', 'busi'), ('value', 'valu'), ('recover', 'recov'), ('6.2', '6.2'), ('billion', 'billion'), ('hours', 'hour'), ('worker', 'worker'), ('productivity', 'product'), ('2021.2', '2021.2'), ('To', 'to'), ('realize', 'realiz'), ('high', 'high'), ('growth', 'growth'), ('potential', 'potenti'), ('costs', 'cost'), ('savings', 'save'), ('analytics', 'analyt'), ('AI', 'ai'), ('technology', 'technolog'), (',', ','), ('must', 'must'), ('demystify', 'demystifi'), ('key', 'key'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('analytics', 'analyt'), ('concepts', 'concept'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Gartner', 'Gartner'), (',', ','), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('generate', 'generate'), ('$', '$'), ('2.9', '2.9'), ('trillion', 'trillion'), ('USD', 'USD'), ('business', 'business'), ('value', 'value'), ('recover', 'recover'), ('6.2', '6.2'), ('billion', 'billion'), ('hours', 'hour'), ('worker', 'worker'), ('productivity', 'productivity'), ('2021.2', '2021.2'), ('To', 'To'), ('realize', 'realize'), ('high', 'high'), ('growth', 'growth'), ('potential', 'potential'), ('costs', 'cost'), ('savings', 'saving'), ('analytics', 'analytics'), ('AI', 'AI'), ('technology', 'technology'), (',', ','), ('must', 'must'), ('demystify', 'demystify'), ('key', 'key'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('analytics', 'analytics'), ('concepts', 'concept'), ('.', '.')]



============================ Sentence 17 =============================

Simply put, artificial intelligence systems automate and simplify tasks, such as  recognizing objects, making sense of speech, etc. 


>> Tokens are: 
 ['Simply', 'put', ',', 'artificial', 'intelligence', 'systems', 'automate', 'simplify', 'tasks', ',', 'recognizing', 'objects', ',', 'making', 'sense', 'speech', ',', 'etc', '.']

>> Bigrams are: 
 [('Simply', 'put'), ('put', ','), (',', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'systems'), ('systems', 'automate'), ('automate', 'simplify'), ('simplify', 'tasks'), ('tasks', ','), (',', 'recognizing'), ('recognizing', 'objects'), ('objects', ','), (',', 'making'), ('making', 'sense'), ('sense', 'speech'), ('speech', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Simply', 'put', ','), ('put', ',', 'artificial'), (',', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'systems'), ('intelligence', 'systems', 'automate'), ('systems', 'automate', 'simplify'), ('automate', 'simplify', 'tasks'), ('simplify', 'tasks', ','), ('tasks', ',', 'recognizing'), (',', 'recognizing', 'objects'), ('recognizing', 'objects', ','), ('objects', ',', 'making'), (',', 'making', 'sense'), ('making', 'sense', 'speech'), ('sense', 'speech', ','), ('speech', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('Simply', 'NNP'), ('put', 'VBD'), (',', ','), ('artificial', 'JJ'), ('intelligence', 'NN'), ('systems', 'NNS'), ('automate', 'VBP'), ('simplify', 'JJ'), ('tasks', 'NNS'), (',', ','), ('recognizing', 'VBG'), ('objects', 'NNS'), (',', ','), ('making', 'VBG'), ('sense', 'NN'), ('speech', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  (NP Simply/NNP)
  put/VBD
  ,/,
  (NP artificial/JJ intelligence/NN systems/NNS)
  automate/VBP
  (NP simplify/JJ tasks/NNS)
  ,/,
  recognizing/VBG
  (NP objects/NNS)
  ,/,
  making/VBG
  (NP sense/NN speech/NN)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['Simply', 'artificial intelligence systems', 'simplify tasks', 'objects', 'sense speech']

>> Named Entities are: 
 [('PERSON', 'Simply')] 

>> Stemming using Porter Stemmer: 
 [('Simply', 'simpli'), ('put', 'put'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('systems', 'system'), ('automate', 'autom'), ('simplify', 'simplifi'), ('tasks', 'task'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Simply', 'simpli'), ('put', 'put'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('systems', 'system'), ('automate', 'autom'), ('simplify', 'simplifi'), ('tasks', 'task'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Simply', 'Simply'), ('put', 'put'), (',', ','), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('systems', 'system'), ('automate', 'automate'), ('simplify', 'simplify'), ('tasks', 'task'), (',', ','), ('recognizing', 'recognizing'), ('objects', 'object'), (',', ','), ('making', 'making'), ('sense', 'sense'), ('speech', 'speech'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 18 =============================

But, how does that lead to  learning how to drive a car? 


>> Tokens are: 
 ['But', ',', 'lead', 'learning', 'drive', 'car', '?']

>> Bigrams are: 
 [('But', ','), (',', 'lead'), ('lead', 'learning'), ('learning', 'drive'), ('drive', 'car'), ('car', '?')]

>> Trigrams are: 
 [('But', ',', 'lead'), (',', 'lead', 'learning'), ('lead', 'learning', 'drive'), ('learning', 'drive', 'car'), ('drive', 'car', '?')]

>> POS Tags are: 
 [('But', 'CC'), (',', ','), ('lead', 'JJ'), ('learning', 'VBG'), ('drive', 'JJ'), ('car', 'NN'), ('?', '.')]

 (S But/CC ,/, lead/JJ learning/VBG (NP drive/JJ car/NN) ?/.) 


>> Noun Phrases are: 
 ['drive car']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), (',', ','), ('lead', 'lead'), ('learning', 'learn'), ('drive', 'drive'), ('car', 'car'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), (',', ','), ('lead', 'lead'), ('learning', 'learn'), ('drive', 'drive'), ('car', 'car'), ('?', '?')]

>> Lemmatization: 
 [('But', 'But'), (',', ','), ('lead', 'lead'), ('learning', 'learning'), ('drive', 'drive'), ('car', 'car'), ('?', '?')]



============================ Sentence 19 =============================

A key concept of AI technology is the difference  between learning and training. 


>> Tokens are: 
 ['A', 'key', 'concept', 'AI', 'technology', 'difference', 'learning', 'training', '.']

>> Bigrams are: 
 [('A', 'key'), ('key', 'concept'), ('concept', 'AI'), ('AI', 'technology'), ('technology', 'difference'), ('difference', 'learning'), ('learning', 'training'), ('training', '.')]

>> Trigrams are: 
 [('A', 'key', 'concept'), ('key', 'concept', 'AI'), ('concept', 'AI', 'technology'), ('AI', 'technology', 'difference'), ('technology', 'difference', 'learning'), ('difference', 'learning', 'training'), ('learning', 'training', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('key', 'JJ'), ('concept', 'NN'), ('AI', 'NNP'), ('technology', 'NN'), ('difference', 'NN'), ('learning', 'VBG'), ('training', 'NN'), ('.', '.')]

 (S
  (NP A/DT key/JJ concept/NN AI/NNP technology/NN difference/NN)
  learning/VBG
  (NP training/NN)
  ./.) 


>> Noun Phrases are: 
 ['A key concept AI technology difference', 'training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('key', 'key'), ('concept', 'concept'), ('AI', 'ai'), ('technology', 'technolog'), ('difference', 'differ'), ('learning', 'learn'), ('training', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('key', 'key'), ('concept', 'concept'), ('AI', 'ai'), ('technology', 'technolog'), ('difference', 'differ'), ('learning', 'learn'), ('training', 'train'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('key', 'key'), ('concept', 'concept'), ('AI', 'AI'), ('technology', 'technology'), ('difference', 'difference'), ('learning', 'learning'), ('training', 'training'), ('.', '.')]



============================ Sentence 20 =============================

Just as a human goes through the process of  driver training to become proficient, a computer learns from experience or,  more specifically, data. 


>> Tokens are: 
 ['Just', 'human', 'goes', 'process', 'driver', 'training', 'become', 'proficient', ',', 'computer', 'learns', 'experience', ',', 'specifically', ',', 'data', '.']

>> Bigrams are: 
 [('Just', 'human'), ('human', 'goes'), ('goes', 'process'), ('process', 'driver'), ('driver', 'training'), ('training', 'become'), ('become', 'proficient'), ('proficient', ','), (',', 'computer'), ('computer', 'learns'), ('learns', 'experience'), ('experience', ','), (',', 'specifically'), ('specifically', ','), (',', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Just', 'human', 'goes'), ('human', 'goes', 'process'), ('goes', 'process', 'driver'), ('process', 'driver', 'training'), ('driver', 'training', 'become'), ('training', 'become', 'proficient'), ('become', 'proficient', ','), ('proficient', ',', 'computer'), (',', 'computer', 'learns'), ('computer', 'learns', 'experience'), ('learns', 'experience', ','), ('experience', ',', 'specifically'), (',', 'specifically', ','), ('specifically', ',', 'data'), (',', 'data', '.')]

>> POS Tags are: 
 [('Just', 'RB'), ('human', 'JJ'), ('goes', 'VBZ'), ('process', 'NN'), ('driver', 'NN'), ('training', 'NN'), ('become', 'JJ'), ('proficient', 'NN'), (',', ','), ('computer', 'NN'), ('learns', 'NNS'), ('experience', 'NN'), (',', ','), ('specifically', 'RB'), (',', ','), ('data', 'NNS'), ('.', '.')]

 (S
  Just/RB
  human/JJ
  goes/VBZ
  (NP process/NN driver/NN training/NN)
  (NP become/JJ proficient/NN)
  ,/,
  (NP computer/NN learns/NNS experience/NN)
  ,/,
  specifically/RB
  ,/,
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['process driver training', 'become proficient', 'computer learns experience', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Just', 'just'), ('human', 'human'), ('goes', 'goe'), ('process', 'process'), ('driver', 'driver'), ('training', 'train'), ('become', 'becom'), ('proficient', 'profici'), (',', ','), ('computer', 'comput'), ('learns', 'learn'), ('experience', 'experi'), (',', ','), ('specifically', 'specif'), (',', ','), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Just', 'just'), ('human', 'human'), ('goes', 'goe'), ('process', 'process'), ('driver', 'driver'), ('training', 'train'), ('become', 'becom'), ('proficient', 'profici'), (',', ','), ('computer', 'comput'), ('learns', 'learn'), ('experience', 'experi'), (',', ','), ('specifically', 'specif'), (',', ','), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Just', 'Just'), ('human', 'human'), ('goes', 'go'), ('process', 'process'), ('driver', 'driver'), ('training', 'training'), ('become', 'become'), ('proficient', 'proficient'), (',', ','), ('computer', 'computer'), ('learns', 'learns'), ('experience', 'experience'), (',', ','), ('specifically', 'specifically'), (',', ','), ('data', 'data'), ('.', '.')]



============================ Sentence 21 =============================

Once the system has data on good driving practices and  the rules of the road, it becomes intelligent enough to make decisions in the  real world. 


>> Tokens are: 
 ['Once', 'system', 'data', 'good', 'driving', 'practices', '', 'rules', 'road', '', ',', 'becomes', 'intelligent', 'enough', 'make', 'decisions', 'real', 'world', '.']

>> Bigrams are: 
 [('Once', 'system'), ('system', 'data'), ('data', 'good'), ('good', 'driving'), ('driving', 'practices'), ('practices', ''), ('', 'rules'), ('rules', 'road'), ('road', ''), ('', ','), (',', 'becomes'), ('becomes', 'intelligent'), ('intelligent', 'enough'), ('enough', 'make'), ('make', 'decisions'), ('decisions', 'real'), ('real', 'world'), ('world', '.')]

>> Trigrams are: 
 [('Once', 'system', 'data'), ('system', 'data', 'good'), ('data', 'good', 'driving'), ('good', 'driving', 'practices'), ('driving', 'practices', ''), ('practices', '', 'rules'), ('', 'rules', 'road'), ('rules', 'road', ''), ('road', '', ','), ('', ',', 'becomes'), (',', 'becomes', 'intelligent'), ('becomes', 'intelligent', 'enough'), ('intelligent', 'enough', 'make'), ('enough', 'make', 'decisions'), ('make', 'decisions', 'real'), ('decisions', 'real', 'world'), ('real', 'world', '.')]

>> POS Tags are: 
 [('Once', 'RB'), ('system', 'NN'), ('data', 'NNS'), ('good', 'JJ'), ('driving', 'NN'), ('practices', 'NNS'), ('', 'VBP'), ('rules', 'NNS'), ('road', 'NN'), ('', 'NN'), (',', ','), ('becomes', 'VBZ'), ('intelligent', 'JJ'), ('enough', 'RB'), ('make', 'VBP'), ('decisions', 'NNS'), ('real', 'JJ'), ('world', 'NN'), ('.', '.')]

 (S
  Once/RB
  (NP system/NN data/NNS)
  (NP good/JJ driving/NN practices/NNS)
  /VBP
  (NP rules/NNS road/NN /NN)
  ,/,
  becomes/VBZ
  intelligent/JJ
  enough/RB
  make/VBP
  (NP decisions/NNS)
  (NP real/JJ world/NN)
  ./.) 


>> Noun Phrases are: 
 ['system data', 'good driving practices', 'rules road ', 'decisions', 'real world']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Once', 'onc'), ('system', 'system'), ('data', 'data'), ('good', 'good'), ('driving', 'drive'), ('practices', 'practic'), ('', ''), ('rules', 'rule'), ('road', 'road'), ('', ''), (',', ','), ('becomes', 'becom'), ('intelligent', 'intellig'), ('enough', 'enough'), ('make', 'make'), ('decisions', 'decis'), ('real', 'real'), ('world', 'world'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Once', 'onc'), ('system', 'system'), ('data', 'data'), ('good', 'good'), ('driving', 'drive'), ('practices', 'practic'), ('', ''), ('rules', 'rule'), ('road', 'road'), ('', ''), (',', ','), ('becomes', 'becom'), ('intelligent', 'intellig'), ('enough', 'enough'), ('make', 'make'), ('decisions', 'decis'), ('real', 'real'), ('world', 'world'), ('.', '.')]

>> Lemmatization: 
 [('Once', 'Once'), ('system', 'system'), ('data', 'data'), ('good', 'good'), ('driving', 'driving'), ('practices', 'practice'), ('', ''), ('rules', 'rule'), ('road', 'road'), ('', ''), (',', ','), ('becomes', 'becomes'), ('intelligent', 'intelligent'), ('enough', 'enough'), ('make', 'make'), ('decisions', 'decision'), ('real', 'real'), ('world', 'world'), ('.', '.')]



============================ Sentence 22 =============================

While there are more complexities in the learning, management and  monitoring of such technology and solutions, this is the core of AI. 


>> Tokens are: 
 ['While', 'complexities', 'learning', ',', 'management', 'monitoring', 'technology', 'solutions', ',', 'core', 'AI', '.']

>> Bigrams are: 
 [('While', 'complexities'), ('complexities', 'learning'), ('learning', ','), (',', 'management'), ('management', 'monitoring'), ('monitoring', 'technology'), ('technology', 'solutions'), ('solutions', ','), (',', 'core'), ('core', 'AI'), ('AI', '.')]

>> Trigrams are: 
 [('While', 'complexities', 'learning'), ('complexities', 'learning', ','), ('learning', ',', 'management'), (',', 'management', 'monitoring'), ('management', 'monitoring', 'technology'), ('monitoring', 'technology', 'solutions'), ('technology', 'solutions', ','), ('solutions', ',', 'core'), (',', 'core', 'AI'), ('core', 'AI', '.')]

>> POS Tags are: 
 [('While', 'IN'), ('complexities', 'NNS'), ('learning', 'VBG'), (',', ','), ('management', 'NN'), ('monitoring', 'NN'), ('technology', 'NN'), ('solutions', 'NNS'), (',', ','), ('core', 'NN'), ('AI', 'NNP'), ('.', '.')]

 (S
  While/IN
  (NP complexities/NNS)
  learning/VBG
  ,/,
  (NP management/NN monitoring/NN technology/NN solutions/NNS)
  ,/,
  (NP core/NN AI/NNP)
  ./.) 


>> Noun Phrases are: 
 ['complexities', 'management monitoring technology solutions', 'core AI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('complexities', 'complex'), ('learning', 'learn'), (',', ','), ('management', 'manag'), ('monitoring', 'monitor'), ('technology', 'technolog'), ('solutions', 'solut'), (',', ','), ('core', 'core'), ('AI', 'ai'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('complexities', 'complex'), ('learning', 'learn'), (',', ','), ('management', 'manag'), ('monitoring', 'monitor'), ('technology', 'technolog'), ('solutions', 'solut'), (',', ','), ('core', 'core'), ('AI', 'ai'), ('.', '.')]

>> Lemmatization: 
 [('While', 'While'), ('complexities', 'complexity'), ('learning', 'learning'), (',', ','), ('management', 'management'), ('monitoring', 'monitoring'), ('technology', 'technology'), ('solutions', 'solution'), (',', ','), ('core', 'core'), ('AI', 'AI'), ('.', '.')]



============================ Sentence 23 =============================

Deep learning  Popular and powerful set of machine learning techniques, which mimic the brains  neuron activities, called  neural networks. 


>> Tokens are: 
 ['Deep', 'learning', 'Popular', 'powerful', 'set', 'machine', 'learning', 'techniques', ',', 'mimic', 'brain', '', 'neuron', 'activities', ',', 'called', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'Popular'), ('Popular', 'powerful'), ('powerful', 'set'), ('set', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'mimic'), ('mimic', 'brain'), ('brain', ''), ('', 'neuron'), ('neuron', 'activities'), ('activities', ','), (',', 'called'), ('called', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'Popular'), ('learning', 'Popular', 'powerful'), ('Popular', 'powerful', 'set'), ('powerful', 'set', 'machine'), ('set', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'mimic'), (',', 'mimic', 'brain'), ('mimic', 'brain', ''), ('brain', '', 'neuron'), ('', 'neuron', 'activities'), ('neuron', 'activities', ','), ('activities', ',', 'called'), (',', 'called', 'neural'), ('called', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('Popular', 'NNP'), ('powerful', 'JJ'), ('set', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('mimic', 'JJ'), ('brain', 'NN'), ('', 'NNP'), ('neuron', 'NN'), ('activities', 'NNS'), (',', ','), ('called', 'VBD'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP Deep/NNP learning/NN Popular/NNP)
  powerful/JJ
  set/VBN
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  (NP mimic/JJ brain/NN /NNP neuron/NN activities/NNS)
  ,/,
  called/VBD
  (NP neural/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning Popular', 'machine', 'techniques', 'mimic brain  neuron activities', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Deep'), ('PERSON', 'Popular')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Popular', 'popular'), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('called', 'call'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Popular', 'popular'), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('called', 'call'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('Popular', 'Popular'), ('powerful', 'powerful'), ('set', 'set'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activity'), (',', ','), ('called', 'called'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]



============================ Sentence 24 =============================

Machine learning  Field of AI that learns from historical data towards an end goal/outcome. 


>> Tokens are: 
 ['Machine', 'learning', 'Field', 'AI', 'learns', 'historical', 'data', 'towards', 'end', 'goal/outcome', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'Field'), ('Field', 'AI'), ('AI', 'learns'), ('learns', 'historical'), ('historical', 'data'), ('data', 'towards'), ('towards', 'end'), ('end', 'goal/outcome'), ('goal/outcome', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'Field'), ('learning', 'Field', 'AI'), ('Field', 'AI', 'learns'), ('AI', 'learns', 'historical'), ('learns', 'historical', 'data'), ('historical', 'data', 'towards'), ('data', 'towards', 'end'), ('towards', 'end', 'goal/outcome'), ('end', 'goal/outcome', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('Field', 'NNP'), ('AI', 'NNP'), ('learns', 'VBZ'), ('historical', 'JJ'), ('data', 'NNS'), ('towards', 'NNS'), ('end', 'VBP'), ('goal/outcome', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP Field/NNP AI/NNP)
  learns/VBZ
  (NP historical/JJ data/NNS towards/NNS)
  end/VBP
  (NP goal/outcome/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'Field AI', 'historical data towards', 'goal/outcome']

>> Named Entities are: 
 [('GPE', 'Machine'), ('PERSON', 'Field AI')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('Field', 'field'), ('AI', 'ai'), ('learns', 'learn'), ('historical', 'histor'), ('data', 'data'), ('towards', 'toward'), ('end', 'end'), ('goal/outcome', 'goal/outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('Field', 'field'), ('AI', 'ai'), ('learns', 'learn'), ('historical', 'histor'), ('data', 'data'), ('towards', 'toward'), ('end', 'end'), ('goal/outcome', 'goal/outcom'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('Field', 'Field'), ('AI', 'AI'), ('learns', 'learns'), ('historical', 'historical'), ('data', 'data'), ('towards', 'towards'), ('end', 'end'), ('goal/outcome', 'goal/outcome'), ('.', '.')]



============================ Sentence 25 =============================

For  example, the customers likely to default on their home loan. 


>> Tokens are: 
 ['For', 'example', ',', 'customers', 'likely', 'default', 'home', 'loan', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'customers'), ('customers', 'likely'), ('likely', 'default'), ('default', 'home'), ('home', 'loan'), ('loan', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'customers'), (',', 'customers', 'likely'), ('customers', 'likely', 'default'), ('likely', 'default', 'home'), ('default', 'home', 'loan'), ('home', 'loan', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('customers', 'NNS'), ('likely', 'JJ'), ('default', 'NN'), ('home', 'NN'), ('loan', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP customers/NNS)
  (NP likely/JJ default/NN home/NN loan/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'customers', 'likely default home loan']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customers', 'custom'), ('likely', 'like'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customers', 'custom'), ('likely', 'like'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('customers', 'customer'), ('likely', 'likely'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]



============================ Sentence 26 =============================

Artificial intelligence  Computing systems capable of performing tasks that humans are very good at,  such as recognizing objects, recognizing and making sense of speech, self-driving  cars. 


>> Tokens are: 
 ['Artificial', 'intelligence', 'Computing', 'systems', 'capable', 'performing', 'tasks', 'humans', 'good', ',', 'recognizing', 'objects', ',', 'recognizing', 'making', 'sense', 'speech', ',', 'self-driving', 'cars', '.']

>> Bigrams are: 
 [('Artificial', 'intelligence'), ('intelligence', 'Computing'), ('Computing', 'systems'), ('systems', 'capable'), ('capable', 'performing'), ('performing', 'tasks'), ('tasks', 'humans'), ('humans', 'good'), ('good', ','), (',', 'recognizing'), ('recognizing', 'objects'), ('objects', ','), (',', 'recognizing'), ('recognizing', 'making'), ('making', 'sense'), ('sense', 'speech'), ('speech', ','), (',', 'self-driving'), ('self-driving', 'cars'), ('cars', '.')]

>> Trigrams are: 
 [('Artificial', 'intelligence', 'Computing'), ('intelligence', 'Computing', 'systems'), ('Computing', 'systems', 'capable'), ('systems', 'capable', 'performing'), ('capable', 'performing', 'tasks'), ('performing', 'tasks', 'humans'), ('tasks', 'humans', 'good'), ('humans', 'good', ','), ('good', ',', 'recognizing'), (',', 'recognizing', 'objects'), ('recognizing', 'objects', ','), ('objects', ',', 'recognizing'), (',', 'recognizing', 'making'), ('recognizing', 'making', 'sense'), ('making', 'sense', 'speech'), ('sense', 'speech', ','), ('speech', ',', 'self-driving'), (',', 'self-driving', 'cars'), ('self-driving', 'cars', '.')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('intelligence', 'NN'), ('Computing', 'VBG'), ('systems', 'NNS'), ('capable', 'JJ'), ('performing', 'VBG'), ('tasks', 'NNS'), ('humans', 'NNS'), ('good', 'JJ'), (',', ','), ('recognizing', 'VBG'), ('objects', 'NNS'), (',', ','), ('recognizing', 'VBG'), ('making', 'VBG'), ('sense', 'NN'), ('speech', 'NN'), (',', ','), ('self-driving', 'JJ'), ('cars', 'NNS'), ('.', '.')]

 (S
  (NP Artificial/JJ intelligence/NN)
  Computing/VBG
  (NP systems/NNS)
  capable/JJ
  performing/VBG
  (NP tasks/NNS humans/NNS)
  good/JJ
  ,/,
  recognizing/VBG
  (NP objects/NNS)
  ,/,
  recognizing/VBG
  making/VBG
  (NP sense/NN speech/NN)
  ,/,
  (NP self-driving/JJ cars/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Artificial intelligence', 'systems', 'tasks humans', 'objects', 'sense speech', 'self-driving cars']

>> Named Entities are: 
 [('GPE', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('Computing', 'comput'), ('systems', 'system'), ('capable', 'capabl'), ('performing', 'perform'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('recognizing', 'recogn'), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('Computing', 'comput'), ('systems', 'system'), ('capable', 'capabl'), ('performing', 'perform'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('recognizing', 'recogn'), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('Computing', 'Computing'), ('systems', 'system'), ('capable', 'capable'), ('performing', 'performing'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recognizing'), ('objects', 'object'), (',', ','), ('recognizing', 'recognizing'), ('making', 'making'), ('sense', 'sense'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driving'), ('cars', 'car'), ('.', '.')]



============================ Sentence 27 =============================

Source: https://www.kdnuggets.com/2018/11/an-introduction-ai.html  Machine learning, a subset of artificial intelligence, enables users to learn from  historical data to achieve a desired outcome. 


>> Tokens are: 
 ['Source', ':', 'https', ':', '//www.kdnuggets.com/2018/11/an-introduction-ai.html', 'Machine', 'learning', ',', 'subset', 'artificial', 'intelligence', ',', 'enables', 'users', 'learn', 'historical', 'data', 'achieve', 'desired', 'outcome', '.']

>> Bigrams are: 
 [('Source', ':'), (':', 'https'), ('https', ':'), (':', '//www.kdnuggets.com/2018/11/an-introduction-ai.html'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', 'Machine'), ('Machine', 'learning'), ('learning', ','), (',', 'subset'), ('subset', 'artificial'), ('artificial', 'intelligence'), ('intelligence', ','), (',', 'enables'), ('enables', 'users'), ('users', 'learn'), ('learn', 'historical'), ('historical', 'data'), ('data', 'achieve'), ('achieve', 'desired'), ('desired', 'outcome'), ('outcome', '.')]

>> Trigrams are: 
 [('Source', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.kdnuggets.com/2018/11/an-introduction-ai.html'), (':', '//www.kdnuggets.com/2018/11/an-introduction-ai.html', 'Machine'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', 'Machine', 'learning'), ('Machine', 'learning', ','), ('learning', ',', 'subset'), (',', 'subset', 'artificial'), ('subset', 'artificial', 'intelligence'), ('artificial', 'intelligence', ','), ('intelligence', ',', 'enables'), (',', 'enables', 'users'), ('enables', 'users', 'learn'), ('users', 'learn', 'historical'), ('learn', 'historical', 'data'), ('historical', 'data', 'achieve'), ('data', 'achieve', 'desired'), ('achieve', 'desired', 'outcome'), ('desired', 'outcome', '.')]

>> POS Tags are: 
 [('Source', 'NN'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', 'JJ'), ('Machine', 'NNP'), ('learning', 'NN'), (',', ','), ('subset', 'VBN'), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('enables', 'VBZ'), ('users', 'NNS'), ('learn', 'VBP'), ('historical', 'JJ'), ('data', 'NNS'), ('achieve', 'RB'), ('desired', 'VBD'), ('outcome', 'NN'), ('.', '.')]

 (S
  (NP Source/NN)
  :/:
  (NP https/NN)
  :/:
  (NP
    //www.kdnuggets.com/2018/11/an-introduction-ai.html/JJ
    Machine/NNP
    learning/NN)
  ,/,
  subset/VBN
  (NP artificial/JJ intelligence/NN)
  ,/,
  enables/VBZ
  (NP users/NNS)
  learn/VBP
  (NP historical/JJ data/NNS)
  achieve/RB
  desired/VBD
  (NP outcome/NN)
  ./.) 


>> Noun Phrases are: 
 ['Source', 'https', '//www.kdnuggets.com/2018/11/an-introduction-ai.html Machine learning', 'artificial intelligence', 'users', 'historical data', 'outcome']

>> Named Entities are: 
 [('GPE', 'Source'), ('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Source', 'sourc'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', '//www.kdnuggets.com/2018/11/an-introduction-ai.html'), ('Machine', 'machin'), ('learning', 'learn'), (',', ','), ('subset', 'subset'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('enables', 'enabl'), ('users', 'user'), ('learn', 'learn'), ('historical', 'histor'), ('data', 'data'), ('achieve', 'achiev'), ('desired', 'desir'), ('outcome', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Source', 'sourc'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', '//www.kdnuggets.com/2018/11/an-introduction-ai.html'), ('Machine', 'machin'), ('learning', 'learn'), (',', ','), ('subset', 'subset'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('enables', 'enabl'), ('users', 'user'), ('learn', 'learn'), ('historical', 'histor'), ('data', 'data'), ('achieve', 'achiev'), ('desired', 'desir'), ('outcome', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('Source', 'Source'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.kdnuggets.com/2018/11/an-introduction-ai.html', '//www.kdnuggets.com/2018/11/an-introduction-ai.html'), ('Machine', 'Machine'), ('learning', 'learning'), (',', ','), ('subset', 'subset'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), (',', ','), ('enables', 'enables'), ('users', 'user'), ('learn', 'learn'), ('historical', 'historical'), ('data', 'data'), ('achieve', 'achieve'), ('desired', 'desired'), ('outcome', 'outcome'), ('.', '.')]



============================ Sentence 28 =============================

It powers targeted ads, personalized  content, song recommendations, predictive maintenance activities, virtual  assistants and more. 


>> Tokens are: 
 ['It', 'powers', 'targeted', 'ads', ',', 'personalized', 'content', ',', 'song', 'recommendations', ',', 'predictive', 'maintenance', 'activities', ',', 'virtual', 'assistants', '.']

>> Bigrams are: 
 [('It', 'powers'), ('powers', 'targeted'), ('targeted', 'ads'), ('ads', ','), (',', 'personalized'), ('personalized', 'content'), ('content', ','), (',', 'song'), ('song', 'recommendations'), ('recommendations', ','), (',', 'predictive'), ('predictive', 'maintenance'), ('maintenance', 'activities'), ('activities', ','), (',', 'virtual'), ('virtual', 'assistants'), ('assistants', '.')]

>> Trigrams are: 
 [('It', 'powers', 'targeted'), ('powers', 'targeted', 'ads'), ('targeted', 'ads', ','), ('ads', ',', 'personalized'), (',', 'personalized', 'content'), ('personalized', 'content', ','), ('content', ',', 'song'), (',', 'song', 'recommendations'), ('song', 'recommendations', ','), ('recommendations', ',', 'predictive'), (',', 'predictive', 'maintenance'), ('predictive', 'maintenance', 'activities'), ('maintenance', 'activities', ','), ('activities', ',', 'virtual'), (',', 'virtual', 'assistants'), ('virtual', 'assistants', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('powers', 'VBZ'), ('targeted', 'JJ'), ('ads', 'NNS'), (',', ','), ('personalized', 'VBN'), ('content', 'NN'), (',', ','), ('song', 'JJ'), ('recommendations', 'NNS'), (',', ','), ('predictive', 'JJ'), ('maintenance', 'NN'), ('activities', 'NNS'), (',', ','), ('virtual', 'JJ'), ('assistants', 'NNS'), ('.', '.')]

 (S
  It/PRP
  powers/VBZ
  (NP targeted/JJ ads/NNS)
  ,/,
  personalized/VBN
  (NP content/NN)
  ,/,
  (NP song/JJ recommendations/NNS)
  ,/,
  (NP predictive/JJ maintenance/NN activities/NNS)
  ,/,
  (NP virtual/JJ assistants/NNS)
  ./.) 


>> Noun Phrases are: 
 ['targeted ads', 'content', 'song recommendations', 'predictive maintenance activities', 'virtual assistants']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('powers', 'power'), ('targeted', 'target'), ('ads', 'ad'), (',', ','), ('personalized', 'person'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommend'), (',', ','), ('predictive', 'predict'), ('maintenance', 'mainten'), ('activities', 'activ'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('powers', 'power'), ('targeted', 'target'), ('ads', 'ad'), (',', ','), ('personalized', 'person'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommend'), (',', ','), ('predictive', 'predict'), ('maintenance', 'mainten'), ('activities', 'activ'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assist'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('powers', 'power'), ('targeted', 'targeted'), ('ads', 'ad'), (',', ','), ('personalized', 'personalized'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommendation'), (',', ','), ('predictive', 'predictive'), ('maintenance', 'maintenance'), ('activities', 'activity'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assistant'), ('.', '.')]



============================ Sentence 29 =============================

Machine learning can be broken down into two key phases, learning and predicting. 


>> Tokens are: 
 ['Machine', 'learning', 'broken', 'two', 'key', 'phases', ',', 'learning', 'predicting', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'broken'), ('broken', 'two'), ('two', 'key'), ('key', 'phases'), ('phases', ','), (',', 'learning'), ('learning', 'predicting'), ('predicting', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'broken'), ('learning', 'broken', 'two'), ('broken', 'two', 'key'), ('two', 'key', 'phases'), ('key', 'phases', ','), ('phases', ',', 'learning'), (',', 'learning', 'predicting'), ('learning', 'predicting', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('broken', 'JJ'), ('two', 'CD'), ('key', 'JJ'), ('phases', 'NNS'), (',', ','), ('learning', 'VBG'), ('predicting', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  broken/JJ
  two/CD
  (NP key/JJ phases/NNS)
  ,/,
  learning/VBG
  (NP predicting/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'key phases', 'predicting']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('broken', 'broken'), ('two', 'two'), ('key', 'key'), ('phases', 'phase'), (',', ','), ('learning', 'learn'), ('predicting', 'predict'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('broken', 'broken'), ('two', 'two'), ('key', 'key'), ('phases', 'phase'), (',', ','), ('learning', 'learn'), ('predicting', 'predict'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('broken', 'broken'), ('two', 'two'), ('key', 'key'), ('phases', 'phase'), (',', ','), ('learning', 'learning'), ('predicting', 'predicting'), ('.', '.')]



============================ Sentence 30 =============================

In the learning phase, certain statistical techniques or algorithms are applied to  historical data and/or previous business outcomes to generate a machine learning  model. 


>> Tokens are: 
 ['In', 'learning', 'phase', ',', 'certain', 'statistical', 'techniques', 'algorithms', 'applied', 'historical', 'data', 'and/or', 'previous', 'business', 'outcomes', 'generate', 'machine', 'learning', 'model', '.']

>> Bigrams are: 
 [('In', 'learning'), ('learning', 'phase'), ('phase', ','), (',', 'certain'), ('certain', 'statistical'), ('statistical', 'techniques'), ('techniques', 'algorithms'), ('algorithms', 'applied'), ('applied', 'historical'), ('historical', 'data'), ('data', 'and/or'), ('and/or', 'previous'), ('previous', 'business'), ('business', 'outcomes'), ('outcomes', 'generate'), ('generate', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', '.')]

>> Trigrams are: 
 [('In', 'learning', 'phase'), ('learning', 'phase', ','), ('phase', ',', 'certain'), (',', 'certain', 'statistical'), ('certain', 'statistical', 'techniques'), ('statistical', 'techniques', 'algorithms'), ('techniques', 'algorithms', 'applied'), ('algorithms', 'applied', 'historical'), ('applied', 'historical', 'data'), ('historical', 'data', 'and/or'), ('data', 'and/or', 'previous'), ('and/or', 'previous', 'business'), ('previous', 'business', 'outcomes'), ('business', 'outcomes', 'generate'), ('outcomes', 'generate', 'machine'), ('generate', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('learning', 'VBG'), ('phase', 'NN'), (',', ','), ('certain', 'JJ'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('algorithms', 'VBP'), ('applied', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('and/or', 'RB'), ('previous', 'JJ'), ('business', 'NN'), ('outcomes', 'NNS'), ('generate', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('.', '.')]

 (S
  In/IN
  learning/VBG
  (NP phase/NN)
  ,/,
  (NP certain/JJ statistical/JJ techniques/NNS)
  algorithms/VBP
  (NP applied/JJ historical/JJ data/NNS)
  and/or/RB
  (NP previous/JJ business/NN outcomes/NNS)
  generate/VBP
  (NP machine/NN learning/NN model/NN)
  ./.) 


>> Noun Phrases are: 
 ['phase', 'certain statistical techniques', 'applied historical data', 'previous business outcomes', 'machine learning model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('learning', 'learn'), ('phase', 'phase'), (',', ','), ('certain', 'certain'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('algorithms', 'algorithm'), ('applied', 'appli'), ('historical', 'histor'), ('data', 'data'), ('and/or', 'and/or'), ('previous', 'previou'), ('business', 'busi'), ('outcomes', 'outcom'), ('generate', 'gener'), ('machine', 'machin'), ('learning', 'learn'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('learning', 'learn'), ('phase', 'phase'), (',', ','), ('certain', 'certain'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('algorithms', 'algorithm'), ('applied', 'appli'), ('historical', 'histor'), ('data', 'data'), ('and/or', 'and/or'), ('previous', 'previous'), ('business', 'busi'), ('outcomes', 'outcom'), ('generate', 'generat'), ('machine', 'machin'), ('learning', 'learn'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('learning', 'learning'), ('phase', 'phase'), (',', ','), ('certain', 'certain'), ('statistical', 'statistical'), ('techniques', 'technique'), ('algorithms', 'algorithm'), ('applied', 'applied'), ('historical', 'historical'), ('data', 'data'), ('and/or', 'and/or'), ('previous', 'previous'), ('business', 'business'), ('outcomes', 'outcome'), ('generate', 'generate'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('.', '.')]



============================ Sentence 31 =============================

A model can be thought of as a set of rules or instructions, such as steps in  a recipe, that one must follow to make a business decision. 


>> Tokens are: 
 ['A', 'model', 'thought', 'set', 'rules', 'instructions', ',', 'steps', 'recipe', ',', 'one', 'must', 'follow', 'make', 'business', 'decision', '.']

>> Bigrams are: 
 [('A', 'model'), ('model', 'thought'), ('thought', 'set'), ('set', 'rules'), ('rules', 'instructions'), ('instructions', ','), (',', 'steps'), ('steps', 'recipe'), ('recipe', ','), (',', 'one'), ('one', 'must'), ('must', 'follow'), ('follow', 'make'), ('make', 'business'), ('business', 'decision'), ('decision', '.')]

>> Trigrams are: 
 [('A', 'model', 'thought'), ('model', 'thought', 'set'), ('thought', 'set', 'rules'), ('set', 'rules', 'instructions'), ('rules', 'instructions', ','), ('instructions', ',', 'steps'), (',', 'steps', 'recipe'), ('steps', 'recipe', ','), ('recipe', ',', 'one'), (',', 'one', 'must'), ('one', 'must', 'follow'), ('must', 'follow', 'make'), ('follow', 'make', 'business'), ('make', 'business', 'decision'), ('business', 'decision', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('model', 'NN'), ('thought', 'VBN'), ('set', 'VBN'), ('rules', 'NNS'), ('instructions', 'NNS'), (',', ','), ('steps', 'NNS'), ('recipe', 'VBP'), (',', ','), ('one', 'CD'), ('must', 'MD'), ('follow', 'VB'), ('make', 'NN'), ('business', 'NN'), ('decision', 'NN'), ('.', '.')]

 (S
  (NP A/DT model/NN)
  thought/VBN
  set/VBN
  (NP rules/NNS instructions/NNS)
  ,/,
  (NP steps/NNS)
  recipe/VBP
  ,/,
  one/CD
  must/MD
  follow/VB
  (NP make/NN business/NN decision/NN)
  ./.) 


>> Noun Phrases are: 
 ['A model', 'rules instructions', 'steps', 'make business decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('model', 'model'), ('thought', 'thought'), ('set', 'set'), ('rules', 'rule'), ('instructions', 'instruct'), (',', ','), ('steps', 'step'), ('recipe', 'recip'), (',', ','), ('one', 'one'), ('must', 'must'), ('follow', 'follow'), ('make', 'make'), ('business', 'busi'), ('decision', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('model', 'model'), ('thought', 'thought'), ('set', 'set'), ('rules', 'rule'), ('instructions', 'instruct'), (',', ','), ('steps', 'step'), ('recipe', 'recip'), (',', ','), ('one', 'one'), ('must', 'must'), ('follow', 'follow'), ('make', 'make'), ('business', 'busi'), ('decision', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('model', 'model'), ('thought', 'thought'), ('set', 'set'), ('rules', 'rule'), ('instructions', 'instruction'), (',', ','), ('steps', 'step'), ('recipe', 'recipe'), (',', ','), ('one', 'one'), ('must', 'must'), ('follow', 'follow'), ('make', 'make'), ('business', 'business'), ('decision', 'decision'), ('.', '.')]



============================ Sentence 32 =============================

For example, in order to approve a loan application, a loan officer will consider  income, age, net worth and many other factors before making a final decision. 


>> Tokens are: 
 ['For', 'example', ',', 'order', 'approve', 'loan', 'application', ',', 'loan', 'officer', 'consider', 'income', ',', 'age', ',', 'net', 'worth', 'many', 'factors', 'making', 'final', 'decision', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'order'), ('order', 'approve'), ('approve', 'loan'), ('loan', 'application'), ('application', ','), (',', 'loan'), ('loan', 'officer'), ('officer', 'consider'), ('consider', 'income'), ('income', ','), (',', 'age'), ('age', ','), (',', 'net'), ('net', 'worth'), ('worth', 'many'), ('many', 'factors'), ('factors', 'making'), ('making', 'final'), ('final', 'decision'), ('decision', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'order'), (',', 'order', 'approve'), ('order', 'approve', 'loan'), ('approve', 'loan', 'application'), ('loan', 'application', ','), ('application', ',', 'loan'), (',', 'loan', 'officer'), ('loan', 'officer', 'consider'), ('officer', 'consider', 'income'), ('consider', 'income', ','), ('income', ',', 'age'), (',', 'age', ','), ('age', ',', 'net'), (',', 'net', 'worth'), ('net', 'worth', 'many'), ('worth', 'many', 'factors'), ('many', 'factors', 'making'), ('factors', 'making', 'final'), ('making', 'final', 'decision'), ('final', 'decision', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('order', 'NN'), ('approve', 'VB'), ('loan', 'NN'), ('application', 'NN'), (',', ','), ('loan', 'NN'), ('officer', 'NN'), ('consider', 'VB'), ('income', 'NN'), (',', ','), ('age', 'NN'), (',', ','), ('net', 'JJ'), ('worth', 'NN'), ('many', 'JJ'), ('factors', 'NNS'), ('making', 'VBG'), ('final', 'JJ'), ('decision', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP order/NN)
  approve/VB
  (NP loan/NN application/NN)
  ,/,
  (NP loan/NN officer/NN)
  consider/VB
  (NP income/NN)
  ,/,
  (NP age/NN)
  ,/,
  (NP net/JJ worth/NN)
  (NP many/JJ factors/NNS)
  making/VBG
  (NP final/JJ decision/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'order', 'loan application', 'loan officer', 'income', 'age', 'net worth', 'many factors', 'final decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('order', 'order'), ('approve', 'approv'), ('loan', 'loan'), ('application', 'applic'), (',', ','), ('loan', 'loan'), ('officer', 'offic'), ('consider', 'consid'), ('income', 'incom'), (',', ','), ('age', 'age'), (',', ','), ('net', 'net'), ('worth', 'worth'), ('many', 'mani'), ('factors', 'factor'), ('making', 'make'), ('final', 'final'), ('decision', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('order', 'order'), ('approve', 'approv'), ('loan', 'loan'), ('application', 'applic'), (',', ','), ('loan', 'loan'), ('officer', 'offic'), ('consider', 'consid'), ('income', 'incom'), (',', ','), ('age', 'age'), (',', ','), ('net', 'net'), ('worth', 'worth'), ('many', 'mani'), ('factors', 'factor'), ('making', 'make'), ('final', 'final'), ('decision', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('order', 'order'), ('approve', 'approve'), ('loan', 'loan'), ('application', 'application'), (',', ','), ('loan', 'loan'), ('officer', 'officer'), ('consider', 'consider'), ('income', 'income'), (',', ','), ('age', 'age'), (',', ','), ('net', 'net'), ('worth', 'worth'), ('many', 'many'), ('factors', 'factor'), ('making', 'making'), ('final', 'final'), ('decision', 'decision'), ('.', '.')]



============================ Sentence 33 =============================

Each attribute of the application is a rule or factor that the officer must evaluate  to approve or reject the loan. 


>> Tokens are: 
 ['Each', 'attribute', 'application', 'rule', 'factor', 'officer', 'must', 'evaluate', 'approve', 'reject', 'loan', '.']

>> Bigrams are: 
 [('Each', 'attribute'), ('attribute', 'application'), ('application', 'rule'), ('rule', 'factor'), ('factor', 'officer'), ('officer', 'must'), ('must', 'evaluate'), ('evaluate', 'approve'), ('approve', 'reject'), ('reject', 'loan'), ('loan', '.')]

>> Trigrams are: 
 [('Each', 'attribute', 'application'), ('attribute', 'application', 'rule'), ('application', 'rule', 'factor'), ('rule', 'factor', 'officer'), ('factor', 'officer', 'must'), ('officer', 'must', 'evaluate'), ('must', 'evaluate', 'approve'), ('evaluate', 'approve', 'reject'), ('approve', 'reject', 'loan'), ('reject', 'loan', '.')]

>> POS Tags are: 
 [('Each', 'DT'), ('attribute', 'NN'), ('application', 'NN'), ('rule', 'NN'), ('factor', 'NN'), ('officer', 'NN'), ('must', 'MD'), ('evaluate', 'VB'), ('approve', 'VB'), ('reject', 'NN'), ('loan', 'NN'), ('.', '.')]

 (S
  (NP
    Each/DT
    attribute/NN
    application/NN
    rule/NN
    factor/NN
    officer/NN)
  must/MD
  evaluate/VB
  approve/VB
  (NP reject/NN loan/NN)
  ./.) 


>> Noun Phrases are: 
 ['Each attribute application rule factor officer', 'reject loan']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Each', 'each'), ('attribute', 'attribut'), ('application', 'applic'), ('rule', 'rule'), ('factor', 'factor'), ('officer', 'offic'), ('must', 'must'), ('evaluate', 'evalu'), ('approve', 'approv'), ('reject', 'reject'), ('loan', 'loan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Each', 'each'), ('attribute', 'attribut'), ('application', 'applic'), ('rule', 'rule'), ('factor', 'factor'), ('officer', 'offic'), ('must', 'must'), ('evaluate', 'evalu'), ('approve', 'approv'), ('reject', 'reject'), ('loan', 'loan'), ('.', '.')]

>> Lemmatization: 
 [('Each', 'Each'), ('attribute', 'attribute'), ('application', 'application'), ('rule', 'rule'), ('factor', 'factor'), ('officer', 'officer'), ('must', 'must'), ('evaluate', 'evaluate'), ('approve', 'approve'), ('reject', 'reject'), ('loan', 'loan'), ('.', '.')]



============================ Sentence 34 =============================

Machine learning techniques follow a similar  methodology, comparing various attributes, historical decisions and the outcome  of similar applicants to estimate the credit worthiness of the new applicant. 


>> Tokens are: 
 ['Machine', 'learning', 'techniques', 'follow', 'similar', 'methodology', ',', 'comparing', 'various', 'attributes', ',', 'historical', 'decisions', 'outcome', 'similar', 'applicants', 'estimate', 'credit', 'worthiness', 'new', 'applicant', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'techniques'), ('techniques', 'follow'), ('follow', 'similar'), ('similar', 'methodology'), ('methodology', ','), (',', 'comparing'), ('comparing', 'various'), ('various', 'attributes'), ('attributes', ','), (',', 'historical'), ('historical', 'decisions'), ('decisions', 'outcome'), ('outcome', 'similar'), ('similar', 'applicants'), ('applicants', 'estimate'), ('estimate', 'credit'), ('credit', 'worthiness'), ('worthiness', 'new'), ('new', 'applicant'), ('applicant', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'techniques'), ('learning', 'techniques', 'follow'), ('techniques', 'follow', 'similar'), ('follow', 'similar', 'methodology'), ('similar', 'methodology', ','), ('methodology', ',', 'comparing'), (',', 'comparing', 'various'), ('comparing', 'various', 'attributes'), ('various', 'attributes', ','), ('attributes', ',', 'historical'), (',', 'historical', 'decisions'), ('historical', 'decisions', 'outcome'), ('decisions', 'outcome', 'similar'), ('outcome', 'similar', 'applicants'), ('similar', 'applicants', 'estimate'), ('applicants', 'estimate', 'credit'), ('estimate', 'credit', 'worthiness'), ('credit', 'worthiness', 'new'), ('worthiness', 'new', 'applicant'), ('new', 'applicant', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), ('follow', 'VBP'), ('similar', 'JJ'), ('methodology', 'NN'), (',', ','), ('comparing', 'VBG'), ('various', 'JJ'), ('attributes', 'NNS'), (',', ','), ('historical', 'JJ'), ('decisions', 'NNS'), ('outcome', 'VBP'), ('similar', 'JJ'), ('applicants', 'NNS'), ('estimate', 'VB'), ('credit', 'NN'), ('worthiness', 'JJ'), ('new', 'JJ'), ('applicant', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP techniques/NNS)
  follow/VBP
  (NP similar/JJ methodology/NN)
  ,/,
  comparing/VBG
  (NP various/JJ attributes/NNS)
  ,/,
  (NP historical/JJ decisions/NNS)
  outcome/VBP
  (NP similar/JJ applicants/NNS)
  estimate/VB
  (NP credit/NN)
  (NP worthiness/JJ new/JJ applicant/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'techniques', 'similar methodology', 'various attributes', 'historical decisions', 'similar applicants', 'credit', 'worthiness new applicant']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('follow', 'follow'), ('similar', 'similar'), ('methodology', 'methodolog'), (',', ','), ('comparing', 'compar'), ('various', 'variou'), ('attributes', 'attribut'), (',', ','), ('historical', 'histor'), ('decisions', 'decis'), ('outcome', 'outcom'), ('similar', 'similar'), ('applicants', 'applic'), ('estimate', 'estim'), ('credit', 'credit'), ('worthiness', 'worthi'), ('new', 'new'), ('applicant', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('follow', 'follow'), ('similar', 'similar'), ('methodology', 'methodolog'), (',', ','), ('comparing', 'compar'), ('various', 'various'), ('attributes', 'attribut'), (',', ','), ('historical', 'histor'), ('decisions', 'decis'), ('outcome', 'outcom'), ('similar', 'similar'), ('applicants', 'applic'), ('estimate', 'estim'), ('credit', 'credit'), ('worthiness', 'worthi'), ('new', 'new'), ('applicant', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('techniques', 'technique'), ('follow', 'follow'), ('similar', 'similar'), ('methodology', 'methodology'), (',', ','), ('comparing', 'comparing'), ('various', 'various'), ('attributes', 'attribute'), (',', ','), ('historical', 'historical'), ('decisions', 'decision'), ('outcome', 'outcome'), ('similar', 'similar'), ('applicants', 'applicant'), ('estimate', 'estimate'), ('credit', 'credit'), ('worthiness', 'worthiness'), ('new', 'new'), ('applicant', 'applicant'), ('.', '.')]



============================ Sentence 35 =============================

Just as a human goes  through the process of  driver training to become  proficient, a computer  learns from experience or,  more specifically, data. 


>> Tokens are: 
 ['Just', 'human', 'goes', 'process', 'driver', 'training', 'become', 'proficient', ',', 'computer', 'learns', 'experience', ',', 'specifically', ',', 'data', '.']

>> Bigrams are: 
 [('Just', 'human'), ('human', 'goes'), ('goes', 'process'), ('process', 'driver'), ('driver', 'training'), ('training', 'become'), ('become', 'proficient'), ('proficient', ','), (',', 'computer'), ('computer', 'learns'), ('learns', 'experience'), ('experience', ','), (',', 'specifically'), ('specifically', ','), (',', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Just', 'human', 'goes'), ('human', 'goes', 'process'), ('goes', 'process', 'driver'), ('process', 'driver', 'training'), ('driver', 'training', 'become'), ('training', 'become', 'proficient'), ('become', 'proficient', ','), ('proficient', ',', 'computer'), (',', 'computer', 'learns'), ('computer', 'learns', 'experience'), ('learns', 'experience', ','), ('experience', ',', 'specifically'), (',', 'specifically', ','), ('specifically', ',', 'data'), (',', 'data', '.')]

>> POS Tags are: 
 [('Just', 'RB'), ('human', 'JJ'), ('goes', 'VBZ'), ('process', 'NN'), ('driver', 'NN'), ('training', 'NN'), ('become', 'JJ'), ('proficient', 'NN'), (',', ','), ('computer', 'NN'), ('learns', 'NNS'), ('experience', 'NN'), (',', ','), ('specifically', 'RB'), (',', ','), ('data', 'NNS'), ('.', '.')]

 (S
  Just/RB
  human/JJ
  goes/VBZ
  (NP process/NN driver/NN training/NN)
  (NP become/JJ proficient/NN)
  ,/,
  (NP computer/NN learns/NNS experience/NN)
  ,/,
  specifically/RB
  ,/,
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['process driver training', 'become proficient', 'computer learns experience', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Just', 'just'), ('human', 'human'), ('goes', 'goe'), ('process', 'process'), ('driver', 'driver'), ('training', 'train'), ('become', 'becom'), ('proficient', 'profici'), (',', ','), ('computer', 'comput'), ('learns', 'learn'), ('experience', 'experi'), (',', ','), ('specifically', 'specif'), (',', ','), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Just', 'just'), ('human', 'human'), ('goes', 'goe'), ('process', 'process'), ('driver', 'driver'), ('training', 'train'), ('become', 'becom'), ('proficient', 'profici'), (',', ','), ('computer', 'comput'), ('learns', 'learn'), ('experience', 'experi'), (',', ','), ('specifically', 'specif'), (',', ','), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Just', 'Just'), ('human', 'human'), ('goes', 'go'), ('process', 'process'), ('driver', 'driver'), ('training', 'training'), ('become', 'become'), ('proficient', 'proficient'), (',', ','), ('computer', 'computer'), ('learns', 'learns'), ('experience', 'experience'), (',', ','), ('specifically', 'specifically'), (',', ','), ('data', 'data'), ('.', '.')]



============================ Sentence 36 =============================

Machine learning, a subset  of artificial intelligence,  enables users to learn  from historical data to  achieve a desired outcome. 


>> Tokens are: 
 ['Machine', 'learning', ',', 'subset', 'artificial', 'intelligence', ',', 'enables', 'users', 'learn', 'historical', 'data', 'achieve', 'desired', 'outcome', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', ','), (',', 'subset'), ('subset', 'artificial'), ('artificial', 'intelligence'), ('intelligence', ','), (',', 'enables'), ('enables', 'users'), ('users', 'learn'), ('learn', 'historical'), ('historical', 'data'), ('data', 'achieve'), ('achieve', 'desired'), ('desired', 'outcome'), ('outcome', '.')]

>> Trigrams are: 
 [('Machine', 'learning', ','), ('learning', ',', 'subset'), (',', 'subset', 'artificial'), ('subset', 'artificial', 'intelligence'), ('artificial', 'intelligence', ','), ('intelligence', ',', 'enables'), (',', 'enables', 'users'), ('enables', 'users', 'learn'), ('users', 'learn', 'historical'), ('learn', 'historical', 'data'), ('historical', 'data', 'achieve'), ('data', 'achieve', 'desired'), ('achieve', 'desired', 'outcome'), ('desired', 'outcome', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'NN'), (',', ','), ('subset', 'VBN'), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('enables', 'VBZ'), ('users', 'NNS'), ('learn', 'VBP'), ('historical', 'JJ'), ('data', 'NNS'), ('achieve', 'RB'), ('desired', 'VBD'), ('outcome', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN learning/NN)
  ,/,
  subset/VBN
  (NP artificial/JJ intelligence/NN)
  ,/,
  enables/VBZ
  (NP users/NNS)
  learn/VBP
  (NP historical/JJ data/NNS)
  achieve/RB
  desired/VBD
  (NP outcome/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine learning', 'artificial intelligence', 'users', 'historical data', 'outcome']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), (',', ','), ('subset', 'subset'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('enables', 'enabl'), ('users', 'user'), ('learn', 'learn'), ('historical', 'histor'), ('data', 'data'), ('achieve', 'achiev'), ('desired', 'desir'), ('outcome', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), (',', ','), ('subset', 'subset'), ('artificial', 'artifici'), ('intelligence', 'intellig'), (',', ','), ('enables', 'enabl'), ('users', 'user'), ('learn', 'learn'), ('historical', 'histor'), ('data', 'data'), ('achieve', 'achiev'), ('desired', 'desir'), ('outcome', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), (',', ','), ('subset', 'subset'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), (',', ','), ('enables', 'enables'), ('users', 'user'), ('learn', 'learn'), ('historical', 'historical'), ('data', 'data'), ('achieve', 'achieve'), ('desired', 'desired'), ('outcome', 'outcome'), ('.', '.')]



============================ Sentence 37 =============================

It powers targeted ads,  personalized content,  song recommendations,  predictive maintenance  activities, virtual assistants  and more. 


>> Tokens are: 
 ['It', 'powers', 'targeted', 'ads', ',', 'personalized', 'content', ',', 'song', 'recommendations', ',', 'predictive', 'maintenance', 'activities', ',', 'virtual', 'assistants', '.']

>> Bigrams are: 
 [('It', 'powers'), ('powers', 'targeted'), ('targeted', 'ads'), ('ads', ','), (',', 'personalized'), ('personalized', 'content'), ('content', ','), (',', 'song'), ('song', 'recommendations'), ('recommendations', ','), (',', 'predictive'), ('predictive', 'maintenance'), ('maintenance', 'activities'), ('activities', ','), (',', 'virtual'), ('virtual', 'assistants'), ('assistants', '.')]

>> Trigrams are: 
 [('It', 'powers', 'targeted'), ('powers', 'targeted', 'ads'), ('targeted', 'ads', ','), ('ads', ',', 'personalized'), (',', 'personalized', 'content'), ('personalized', 'content', ','), ('content', ',', 'song'), (',', 'song', 'recommendations'), ('song', 'recommendations', ','), ('recommendations', ',', 'predictive'), (',', 'predictive', 'maintenance'), ('predictive', 'maintenance', 'activities'), ('maintenance', 'activities', ','), ('activities', ',', 'virtual'), (',', 'virtual', 'assistants'), ('virtual', 'assistants', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('powers', 'VBZ'), ('targeted', 'JJ'), ('ads', 'NNS'), (',', ','), ('personalized', 'VBN'), ('content', 'NN'), (',', ','), ('song', 'JJ'), ('recommendations', 'NNS'), (',', ','), ('predictive', 'JJ'), ('maintenance', 'NN'), ('activities', 'NNS'), (',', ','), ('virtual', 'JJ'), ('assistants', 'NNS'), ('.', '.')]

 (S
  It/PRP
  powers/VBZ
  (NP targeted/JJ ads/NNS)
  ,/,
  personalized/VBN
  (NP content/NN)
  ,/,
  (NP song/JJ recommendations/NNS)
  ,/,
  (NP predictive/JJ maintenance/NN activities/NNS)
  ,/,
  (NP virtual/JJ assistants/NNS)
  ./.) 


>> Noun Phrases are: 
 ['targeted ads', 'content', 'song recommendations', 'predictive maintenance activities', 'virtual assistants']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('powers', 'power'), ('targeted', 'target'), ('ads', 'ad'), (',', ','), ('personalized', 'person'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommend'), (',', ','), ('predictive', 'predict'), ('maintenance', 'mainten'), ('activities', 'activ'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('powers', 'power'), ('targeted', 'target'), ('ads', 'ad'), (',', ','), ('personalized', 'person'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommend'), (',', ','), ('predictive', 'predict'), ('maintenance', 'mainten'), ('activities', 'activ'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assist'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('powers', 'power'), ('targeted', 'targeted'), ('ads', 'ad'), (',', ','), ('personalized', 'personalized'), ('content', 'content'), (',', ','), ('song', 'song'), ('recommendations', 'recommendation'), (',', ','), ('predictive', 'predictive'), ('maintenance', 'maintenance'), ('activities', 'activity'), (',', ','), ('virtual', 'virtual'), ('assistants', 'assistant'), ('.', '.')]



============================ Sentence 38 =============================

Deep learning Machine learning Artificial intelligence  Popular and powerful  set of machine learning   techniques, which mimic  the brains neuron   activities, called  neural networks. 


>> Tokens are: 
 ['Deep', 'learning', 'Machine', 'learning', 'Artificial', 'intelligence', 'Popular', 'powerful', 'set', 'machine', 'learning', 'techniques', ',', 'mimic', 'brain', '', 'neuron', 'activities', ',', 'called', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'Machine'), ('Machine', 'learning'), ('learning', 'Artificial'), ('Artificial', 'intelligence'), ('intelligence', 'Popular'), ('Popular', 'powerful'), ('powerful', 'set'), ('set', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'mimic'), ('mimic', 'brain'), ('brain', ''), ('', 'neuron'), ('neuron', 'activities'), ('activities', ','), (',', 'called'), ('called', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'Machine'), ('learning', 'Machine', 'learning'), ('Machine', 'learning', 'Artificial'), ('learning', 'Artificial', 'intelligence'), ('Artificial', 'intelligence', 'Popular'), ('intelligence', 'Popular', 'powerful'), ('Popular', 'powerful', 'set'), ('powerful', 'set', 'machine'), ('set', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'mimic'), (',', 'mimic', 'brain'), ('mimic', 'brain', ''), ('brain', '', 'neuron'), ('', 'neuron', 'activities'), ('neuron', 'activities', ','), ('activities', ',', 'called'), (',', 'called', 'neural'), ('called', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('learning', 'NN'), ('Machine', 'NNP'), ('learning', 'VBG'), ('Artificial', 'JJ'), ('intelligence', 'NN'), ('Popular', 'NNP'), ('powerful', 'JJ'), ('set', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('mimic', 'JJ'), ('brain', 'NN'), ('', 'NNP'), ('neuron', 'NN'), ('activities', 'NNS'), (',', ','), ('called', 'VBD'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP Deep/JJ learning/NN Machine/NNP)
  learning/VBG
  (NP Artificial/JJ intelligence/NN Popular/NNP)
  powerful/JJ
  set/VBN
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  (NP mimic/JJ brain/NN /NNP neuron/NN activities/NNS)
  ,/,
  called/VBD
  (NP neural/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning Machine', 'Artificial intelligence Popular', 'machine', 'techniques', 'mimic brain  neuron activities', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Deep'), ('PERSON', 'Machine'), ('ORGANIZATION', 'Artificial'), ('PERSON', 'Popular')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('Artificial', 'artifici'), ('intelligence', 'intellig'), ('Popular', 'popular'), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('called', 'call'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('Artificial', 'artifici'), ('intelligence', 'intellig'), ('Popular', 'popular'), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('called', 'call'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('Machine', 'Machine'), ('learning', 'learning'), ('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('Popular', 'Popular'), ('powerful', 'powerful'), ('set', 'set'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activity'), (',', ','), ('called', 'called'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]



============================ Sentence 39 =============================

Field of AI that learns from  historical data towards an   end goal/outcome. 


>> Tokens are: 
 ['Field', 'AI', 'learns', 'historical', 'data', 'towards', 'end', 'goal/outcome', '.']

>> Bigrams are: 
 [('Field', 'AI'), ('AI', 'learns'), ('learns', 'historical'), ('historical', 'data'), ('data', 'towards'), ('towards', 'end'), ('end', 'goal/outcome'), ('goal/outcome', '.')]

>> Trigrams are: 
 [('Field', 'AI', 'learns'), ('AI', 'learns', 'historical'), ('learns', 'historical', 'data'), ('historical', 'data', 'towards'), ('data', 'towards', 'end'), ('towards', 'end', 'goal/outcome'), ('end', 'goal/outcome', '.')]

>> POS Tags are: 
 [('Field', 'NNP'), ('AI', 'NNP'), ('learns', 'VBZ'), ('historical', 'JJ'), ('data', 'NNS'), ('towards', 'NNS'), ('end', 'VBP'), ('goal/outcome', 'NN'), ('.', '.')]

 (S
  (NP Field/NNP AI/NNP)
  learns/VBZ
  (NP historical/JJ data/NNS towards/NNS)
  end/VBP
  (NP goal/outcome/NN)
  ./.) 


>> Noun Phrases are: 
 ['Field AI', 'historical data towards', 'goal/outcome']

>> Named Entities are: 
 [('PERSON', 'Field')] 

>> Stemming using Porter Stemmer: 
 [('Field', 'field'), ('AI', 'ai'), ('learns', 'learn'), ('historical', 'histor'), ('data', 'data'), ('towards', 'toward'), ('end', 'end'), ('goal/outcome', 'goal/outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Field', 'field'), ('AI', 'ai'), ('learns', 'learn'), ('historical', 'histor'), ('data', 'data'), ('towards', 'toward'), ('end', 'end'), ('goal/outcome', 'goal/outcom'), ('.', '.')]

>> Lemmatization: 
 [('Field', 'Field'), ('AI', 'AI'), ('learns', 'learns'), ('historical', 'historical'), ('data', 'data'), ('towards', 'towards'), ('end', 'end'), ('goal/outcome', 'goal/outcome'), ('.', '.')]



============================ Sentence 40 =============================

For  example, the customers  likely to default on their   home loan. 


>> Tokens are: 
 ['For', 'example', ',', 'customers', 'likely', 'default', 'home', 'loan', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'customers'), ('customers', 'likely'), ('likely', 'default'), ('default', 'home'), ('home', 'loan'), ('loan', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'customers'), (',', 'customers', 'likely'), ('customers', 'likely', 'default'), ('likely', 'default', 'home'), ('default', 'home', 'loan'), ('home', 'loan', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('customers', 'NNS'), ('likely', 'JJ'), ('default', 'NN'), ('home', 'NN'), ('loan', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP customers/NNS)
  (NP likely/JJ default/NN home/NN loan/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'customers', 'likely default home loan']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customers', 'custom'), ('likely', 'like'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customers', 'custom'), ('likely', 'like'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('customers', 'customer'), ('likely', 'likely'), ('default', 'default'), ('home', 'home'), ('loan', 'loan'), ('.', '.')]



============================ Sentence 41 =============================

Computing systems  capable of performing   tasks that humans are very  good at, such as   recognizing objects,  recognizing and making   sense of speech,  self-driving cars. 


>> Tokens are: 
 ['Computing', 'systems', 'capable', 'performing', 'tasks', 'humans', 'good', ',', 'recognizing', 'objects', ',', 'recognizing', 'making', 'sense', 'speech', ',', 'self-driving', 'cars', '.']

>> Bigrams are: 
 [('Computing', 'systems'), ('systems', 'capable'), ('capable', 'performing'), ('performing', 'tasks'), ('tasks', 'humans'), ('humans', 'good'), ('good', ','), (',', 'recognizing'), ('recognizing', 'objects'), ('objects', ','), (',', 'recognizing'), ('recognizing', 'making'), ('making', 'sense'), ('sense', 'speech'), ('speech', ','), (',', 'self-driving'), ('self-driving', 'cars'), ('cars', '.')]

>> Trigrams are: 
 [('Computing', 'systems', 'capable'), ('systems', 'capable', 'performing'), ('capable', 'performing', 'tasks'), ('performing', 'tasks', 'humans'), ('tasks', 'humans', 'good'), ('humans', 'good', ','), ('good', ',', 'recognizing'), (',', 'recognizing', 'objects'), ('recognizing', 'objects', ','), ('objects', ',', 'recognizing'), (',', 'recognizing', 'making'), ('recognizing', 'making', 'sense'), ('making', 'sense', 'speech'), ('sense', 'speech', ','), ('speech', ',', 'self-driving'), (',', 'self-driving', 'cars'), ('self-driving', 'cars', '.')]

>> POS Tags are: 
 [('Computing', 'VBG'), ('systems', 'NNS'), ('capable', 'JJ'), ('performing', 'VBG'), ('tasks', 'NNS'), ('humans', 'NNS'), ('good', 'JJ'), (',', ','), ('recognizing', 'VBG'), ('objects', 'NNS'), (',', ','), ('recognizing', 'VBG'), ('making', 'VBG'), ('sense', 'NN'), ('speech', 'NN'), (',', ','), ('self-driving', 'JJ'), ('cars', 'NNS'), ('.', '.')]

 (S
  Computing/VBG
  (NP systems/NNS)
  capable/JJ
  performing/VBG
  (NP tasks/NNS humans/NNS)
  good/JJ
  ,/,
  recognizing/VBG
  (NP objects/NNS)
  ,/,
  recognizing/VBG
  making/VBG
  (NP sense/NN speech/NN)
  ,/,
  (NP self-driving/JJ cars/NNS)
  ./.) 


>> Noun Phrases are: 
 ['systems', 'tasks humans', 'objects', 'sense speech', 'self-driving cars']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computing', 'comput'), ('systems', 'system'), ('capable', 'capabl'), ('performing', 'perform'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('recognizing', 'recogn'), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computing', 'comput'), ('systems', 'system'), ('capable', 'capabl'), ('performing', 'perform'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recogn'), ('objects', 'object'), (',', ','), ('recognizing', 'recogn'), ('making', 'make'), ('sense', 'sens'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Lemmatization: 
 [('Computing', 'Computing'), ('systems', 'system'), ('capable', 'capable'), ('performing', 'performing'), ('tasks', 'task'), ('humans', 'human'), ('good', 'good'), (',', ','), ('recognizing', 'recognizing'), ('objects', 'object'), (',', ','), ('recognizing', 'recognizing'), ('making', 'making'), ('sense', 'sense'), ('speech', 'speech'), (',', ','), ('self-driving', 'self-driving'), ('cars', 'car'), ('.', '.')]



============================ Sentence 42 =============================

5/14Demystifying data science   In the predicting phase, patterns identified during the learning phase are applied  to new data or business processes to score or predict the likelihood of outcomes. 


>> Tokens are: 
 ['5/14Demystifying', 'data', 'science', 'In', 'predicting', 'phase', ',', 'patterns', 'identified', 'learning', 'phase', 'applied', 'new', 'data', 'business', 'processes', 'score', 'predict', 'likelihood', 'outcomes', '.']

>> Bigrams are: 
 [('5/14Demystifying', 'data'), ('data', 'science'), ('science', 'In'), ('In', 'predicting'), ('predicting', 'phase'), ('phase', ','), (',', 'patterns'), ('patterns', 'identified'), ('identified', 'learning'), ('learning', 'phase'), ('phase', 'applied'), ('applied', 'new'), ('new', 'data'), ('data', 'business'), ('business', 'processes'), ('processes', 'score'), ('score', 'predict'), ('predict', 'likelihood'), ('likelihood', 'outcomes'), ('outcomes', '.')]

>> Trigrams are: 
 [('5/14Demystifying', 'data', 'science'), ('data', 'science', 'In'), ('science', 'In', 'predicting'), ('In', 'predicting', 'phase'), ('predicting', 'phase', ','), ('phase', ',', 'patterns'), (',', 'patterns', 'identified'), ('patterns', 'identified', 'learning'), ('identified', 'learning', 'phase'), ('learning', 'phase', 'applied'), ('phase', 'applied', 'new'), ('applied', 'new', 'data'), ('new', 'data', 'business'), ('data', 'business', 'processes'), ('business', 'processes', 'score'), ('processes', 'score', 'predict'), ('score', 'predict', 'likelihood'), ('predict', 'likelihood', 'outcomes'), ('likelihood', 'outcomes', '.')]

>> POS Tags are: 
 [('5/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('In', 'IN'), ('predicting', 'VBG'), ('phase', 'NN'), (',', ','), ('patterns', 'NNS'), ('identified', 'VBD'), ('learning', 'VBG'), ('phase', 'NN'), ('applied', 'VBD'), ('new', 'JJ'), ('data', 'NNS'), ('business', 'NN'), ('processes', 'VBZ'), ('score', 'JJR'), ('predict', 'JJ'), ('likelihood', 'NN'), ('outcomes', 'NNS'), ('.', '.')]

 (S
  5/14Demystifying/VBG
  (NP data/NNS science/NN)
  In/IN
  predicting/VBG
  (NP phase/NN)
  ,/,
  (NP patterns/NNS)
  identified/VBD
  learning/VBG
  (NP phase/NN)
  applied/VBD
  (NP new/JJ data/NNS business/NN)
  processes/VBZ
  score/JJR
  (NP predict/JJ likelihood/NN outcomes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data science', 'phase', 'patterns', 'phase', 'new data business', 'predict likelihood outcomes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5/14Demystifying', '5/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('In', 'in'), ('predicting', 'predict'), ('phase', 'phase'), (',', ','), ('patterns', 'pattern'), ('identified', 'identifi'), ('learning', 'learn'), ('phase', 'phase'), ('applied', 'appli'), ('new', 'new'), ('data', 'data'), ('business', 'busi'), ('processes', 'process'), ('score', 'score'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('outcomes', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5/14Demystifying', '5/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('In', 'in'), ('predicting', 'predict'), ('phase', 'phase'), (',', ','), ('patterns', 'pattern'), ('identified', 'identifi'), ('learning', 'learn'), ('phase', 'phase'), ('applied', 'appli'), ('new', 'new'), ('data', 'data'), ('business', 'busi'), ('processes', 'process'), ('score', 'score'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('outcomes', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('5/14Demystifying', '5/14Demystifying'), ('data', 'data'), ('science', 'science'), ('In', 'In'), ('predicting', 'predicting'), ('phase', 'phase'), (',', ','), ('patterns', 'pattern'), ('identified', 'identified'), ('learning', 'learning'), ('phase', 'phase'), ('applied', 'applied'), ('new', 'new'), ('data', 'data'), ('business', 'business'), ('processes', 'process'), ('score', 'score'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('outcomes', 'outcome'), ('.', '.')]



============================ Sentence 43 =============================

Scoring outcomes enables organizations to optimize resource allocation and  decision-making activities, make more intelligent decisions and automate key  business processes at scale. 


>> Tokens are: 
 ['Scoring', 'outcomes', 'enables', 'organizations', 'optimize', 'resource', 'allocation', 'decision-making', 'activities', ',', 'make', 'intelligent', 'decisions', 'automate', 'key', 'business', 'processes', 'scale', '.']

>> Bigrams are: 
 [('Scoring', 'outcomes'), ('outcomes', 'enables'), ('enables', 'organizations'), ('organizations', 'optimize'), ('optimize', 'resource'), ('resource', 'allocation'), ('allocation', 'decision-making'), ('decision-making', 'activities'), ('activities', ','), (',', 'make'), ('make', 'intelligent'), ('intelligent', 'decisions'), ('decisions', 'automate'), ('automate', 'key'), ('key', 'business'), ('business', 'processes'), ('processes', 'scale'), ('scale', '.')]

>> Trigrams are: 
 [('Scoring', 'outcomes', 'enables'), ('outcomes', 'enables', 'organizations'), ('enables', 'organizations', 'optimize'), ('organizations', 'optimize', 'resource'), ('optimize', 'resource', 'allocation'), ('resource', 'allocation', 'decision-making'), ('allocation', 'decision-making', 'activities'), ('decision-making', 'activities', ','), ('activities', ',', 'make'), (',', 'make', 'intelligent'), ('make', 'intelligent', 'decisions'), ('intelligent', 'decisions', 'automate'), ('decisions', 'automate', 'key'), ('automate', 'key', 'business'), ('key', 'business', 'processes'), ('business', 'processes', 'scale'), ('processes', 'scale', '.')]

>> POS Tags are: 
 [('Scoring', 'VBG'), ('outcomes', 'NNS'), ('enables', 'JJ'), ('organizations', 'NNS'), ('optimize', 'VBP'), ('resource', 'JJ'), ('allocation', 'NN'), ('decision-making', 'NN'), ('activities', 'NNS'), (',', ','), ('make', 'VBP'), ('intelligent', 'JJ'), ('decisions', 'NNS'), ('automate', 'VBP'), ('key', 'JJ'), ('business', 'NN'), ('processes', 'NNS'), ('scale', 'NN'), ('.', '.')]

 (S
  Scoring/VBG
  (NP outcomes/NNS)
  (NP enables/JJ organizations/NNS)
  optimize/VBP
  (NP resource/JJ allocation/NN decision-making/NN activities/NNS)
  ,/,
  make/VBP
  (NP intelligent/JJ decisions/NNS)
  automate/VBP
  (NP key/JJ business/NN processes/NNS scale/NN)
  ./.) 


>> Noun Phrases are: 
 ['outcomes', 'enables organizations', 'resource allocation decision-making activities', 'intelligent decisions', 'key business processes scale']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Scoring', 'score'), ('outcomes', 'outcom'), ('enables', 'enabl'), ('organizations', 'organ'), ('optimize', 'optim'), ('resource', 'resourc'), ('allocation', 'alloc'), ('decision-making', 'decision-mak'), ('activities', 'activ'), (',', ','), ('make', 'make'), ('intelligent', 'intellig'), ('decisions', 'decis'), ('automate', 'autom'), ('key', 'key'), ('business', 'busi'), ('processes', 'process'), ('scale', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scoring', 'score'), ('outcomes', 'outcom'), ('enables', 'enabl'), ('organizations', 'organ'), ('optimize', 'optim'), ('resource', 'resourc'), ('allocation', 'alloc'), ('decision-making', 'decision-mak'), ('activities', 'activ'), (',', ','), ('make', 'make'), ('intelligent', 'intellig'), ('decisions', 'decis'), ('automate', 'autom'), ('key', 'key'), ('business', 'busi'), ('processes', 'process'), ('scale', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('Scoring', 'Scoring'), ('outcomes', 'outcome'), ('enables', 'enables'), ('organizations', 'organization'), ('optimize', 'optimize'), ('resource', 'resource'), ('allocation', 'allocation'), ('decision-making', 'decision-making'), ('activities', 'activity'), (',', ','), ('make', 'make'), ('intelligent', 'intelligent'), ('decisions', 'decision'), ('automate', 'automate'), ('key', 'key'), ('business', 'business'), ('processes', 'process'), ('scale', 'scale'), ('.', '.')]



============================ Sentence 44 =============================

Some key business questions that machine learning  techniques can help answer include:  1. 


>> Tokens are: 
 ['Some', 'key', 'business', 'questions', 'machine', 'learning', 'techniques', 'help', 'answer', 'include', ':', '1', '.']

>> Bigrams are: 
 [('Some', 'key'), ('key', 'business'), ('business', 'questions'), ('questions', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', 'help'), ('help', 'answer'), ('answer', 'include'), ('include', ':'), (':', '1'), ('1', '.')]

>> Trigrams are: 
 [('Some', 'key', 'business'), ('key', 'business', 'questions'), ('business', 'questions', 'machine'), ('questions', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', 'help'), ('techniques', 'help', 'answer'), ('help', 'answer', 'include'), ('answer', 'include', ':'), ('include', ':', '1'), (':', '1', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('key', 'JJ'), ('business', 'NN'), ('questions', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), ('help', 'VBP'), ('answer', 'VB'), ('include', 'NN'), (':', ':'), ('1', 'CD'), ('.', '.')]

 (S
  (NP Some/DT key/JJ business/NN questions/NNS machine/NN)
  learning/VBG
  (NP techniques/NNS)
  help/VBP
  answer/VB
  (NP include/NN)
  :/:
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Some key business questions machine', 'techniques', 'include']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('key', 'key'), ('business', 'busi'), ('questions', 'question'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('help', 'help'), ('answer', 'answer'), ('include', 'includ'), (':', ':'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('key', 'key'), ('business', 'busi'), ('questions', 'question'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('help', 'help'), ('answer', 'answer'), ('include', 'includ'), (':', ':'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('key', 'key'), ('business', 'business'), ('questions', 'question'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), ('help', 'help'), ('answer', 'answer'), ('include', 'include'), (':', ':'), ('1', '1'), ('.', '.')]



============================ Sentence 45 =============================

Will my customer purchase product X? 


>> Tokens are: 
 ['Will', 'customer', 'purchase', 'product', 'X', '?']

>> Bigrams are: 
 [('Will', 'customer'), ('customer', 'purchase'), ('purchase', 'product'), ('product', 'X'), ('X', '?')]

>> Trigrams are: 
 [('Will', 'customer', 'purchase'), ('customer', 'purchase', 'product'), ('purchase', 'product', 'X'), ('product', 'X', '?')]

>> POS Tags are: 
 [('Will', 'MD'), ('customer', 'NN'), ('purchase', 'NN'), ('product', 'NN'), ('X', 'NNP'), ('?', '.')]

 (S Will/MD (NP customer/NN purchase/NN product/NN X/NNP) ?/.) 


>> Noun Phrases are: 
 ['customer purchase product X']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Will', 'will'), ('customer', 'custom'), ('purchase', 'purchas'), ('product', 'product'), ('X', 'x'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Will', 'will'), ('customer', 'custom'), ('purchase', 'purchas'), ('product', 'product'), ('X', 'x'), ('?', '?')]

>> Lemmatization: 
 [('Will', 'Will'), ('customer', 'customer'), ('purchase', 'purchase'), ('product', 'product'), ('X', 'X'), ('?', '?')]



============================ Sentence 46 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 47 =============================

Will my customer like a recommended song? 


>> Tokens are: 
 ['Will', 'customer', 'like', 'recommended', 'song', '?']

>> Bigrams are: 
 [('Will', 'customer'), ('customer', 'like'), ('like', 'recommended'), ('recommended', 'song'), ('song', '?')]

>> Trigrams are: 
 [('Will', 'customer', 'like'), ('customer', 'like', 'recommended'), ('like', 'recommended', 'song'), ('recommended', 'song', '?')]

>> POS Tags are: 
 [('Will', 'MD'), ('customer', 'NN'), ('like', 'IN'), ('recommended', 'VBN'), ('song', 'NN'), ('?', '.')]

 (S Will/MD (NP customer/NN) like/IN recommended/VBN (NP song/NN) ?/.) 


>> Noun Phrases are: 
 ['customer', 'song']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Will', 'will'), ('customer', 'custom'), ('like', 'like'), ('recommended', 'recommend'), ('song', 'song'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Will', 'will'), ('customer', 'custom'), ('like', 'like'), ('recommended', 'recommend'), ('song', 'song'), ('?', '?')]

>> Lemmatization: 
 [('Will', 'Will'), ('customer', 'customer'), ('like', 'like'), ('recommended', 'recommended'), ('song', 'song'), ('?', '?')]



============================ Sentence 48 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 49 =============================

Which of my customers are likely to switch to a competitor or cancel their contract? 


>> Tokens are: 
 ['Which', 'customers', 'likely', 'switch', 'competitor', 'cancel', 'contract', '?']

>> Bigrams are: 
 [('Which', 'customers'), ('customers', 'likely'), ('likely', 'switch'), ('switch', 'competitor'), ('competitor', 'cancel'), ('cancel', 'contract'), ('contract', '?')]

>> Trigrams are: 
 [('Which', 'customers', 'likely'), ('customers', 'likely', 'switch'), ('likely', 'switch', 'competitor'), ('switch', 'competitor', 'cancel'), ('competitor', 'cancel', 'contract'), ('cancel', 'contract', '?')]

>> POS Tags are: 
 [('Which', 'JJ'), ('customers', 'NNS'), ('likely', 'JJ'), ('switch', 'JJ'), ('competitor', 'NN'), ('cancel', 'NN'), ('contract', 'NN'), ('?', '.')]

 (S
  (NP Which/JJ customers/NNS)
  (NP likely/JJ switch/JJ competitor/NN cancel/NN contract/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Which customers', 'likely switch competitor cancel contract']

>> Named Entities are: 
 [('GPE', 'Which')] 

>> Stemming using Porter Stemmer: 
 [('Which', 'which'), ('customers', 'custom'), ('likely', 'like'), ('switch', 'switch'), ('competitor', 'competitor'), ('cancel', 'cancel'), ('contract', 'contract'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Which', 'which'), ('customers', 'custom'), ('likely', 'like'), ('switch', 'switch'), ('competitor', 'competitor'), ('cancel', 'cancel'), ('contract', 'contract'), ('?', '?')]

>> Lemmatization: 
 [('Which', 'Which'), ('customers', 'customer'), ('likely', 'likely'), ('switch', 'switch'), ('competitor', 'competitor'), ('cancel', 'cancel'), ('contract', 'contract'), ('?', '?')]



============================ Sentence 50 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 51 =============================

Of all recently submitted claims, which ones are likely to require an additional  fraud investigation unit review? 


>> Tokens are: 
 ['Of', 'recently', 'submitted', 'claims', ',', 'ones', 'likely', 'require', 'additional', 'fraud', 'investigation', 'unit', 'review', '?']

>> Bigrams are: 
 [('Of', 'recently'), ('recently', 'submitted'), ('submitted', 'claims'), ('claims', ','), (',', 'ones'), ('ones', 'likely'), ('likely', 'require'), ('require', 'additional'), ('additional', 'fraud'), ('fraud', 'investigation'), ('investigation', 'unit'), ('unit', 'review'), ('review', '?')]

>> Trigrams are: 
 [('Of', 'recently', 'submitted'), ('recently', 'submitted', 'claims'), ('submitted', 'claims', ','), ('claims', ',', 'ones'), (',', 'ones', 'likely'), ('ones', 'likely', 'require'), ('likely', 'require', 'additional'), ('require', 'additional', 'fraud'), ('additional', 'fraud', 'investigation'), ('fraud', 'investigation', 'unit'), ('investigation', 'unit', 'review'), ('unit', 'review', '?')]

>> POS Tags are: 
 [('Of', 'IN'), ('recently', 'RB'), ('submitted', 'VBN'), ('claims', 'NNS'), (',', ','), ('ones', 'NNS'), ('likely', 'RB'), ('require', 'VBP'), ('additional', 'JJ'), ('fraud', 'NN'), ('investigation', 'NN'), ('unit', 'NN'), ('review', 'NN'), ('?', '.')]

 (S
  Of/IN
  recently/RB
  submitted/VBN
  (NP claims/NNS)
  ,/,
  (NP ones/NNS)
  likely/RB
  require/VBP
  (NP additional/JJ fraud/NN investigation/NN unit/NN review/NN)
  ?/.) 


>> Noun Phrases are: 
 ['claims', 'ones', 'additional fraud investigation unit review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Of', 'of'), ('recently', 'recent'), ('submitted', 'submit'), ('claims', 'claim'), (',', ','), ('ones', 'one'), ('likely', 'like'), ('require', 'requir'), ('additional', 'addit'), ('fraud', 'fraud'), ('investigation', 'investig'), ('unit', 'unit'), ('review', 'review'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Of', 'of'), ('recently', 'recent'), ('submitted', 'submit'), ('claims', 'claim'), (',', ','), ('ones', 'one'), ('likely', 'like'), ('require', 'requir'), ('additional', 'addit'), ('fraud', 'fraud'), ('investigation', 'investig'), ('unit', 'unit'), ('review', 'review'), ('?', '?')]

>> Lemmatization: 
 [('Of', 'Of'), ('recently', 'recently'), ('submitted', 'submitted'), ('claims', 'claim'), (',', ','), ('ones', 'one'), ('likely', 'likely'), ('require', 'require'), ('additional', 'additional'), ('fraud', 'fraud'), ('investigation', 'investigation'), ('unit', 'unit'), ('review', 'review'), ('?', '?')]



============================ Sentence 52 =============================

5. 


>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

 (S 5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



============================ Sentence 53 =============================

Is this applicant likely to default on their car loan in the future? 


>> Tokens are: 
 ['Is', 'applicant', 'likely', 'default', 'car', 'loan', 'future', '?']

>> Bigrams are: 
 [('Is', 'applicant'), ('applicant', 'likely'), ('likely', 'default'), ('default', 'car'), ('car', 'loan'), ('loan', 'future'), ('future', '?')]

>> Trigrams are: 
 [('Is', 'applicant', 'likely'), ('applicant', 'likely', 'default'), ('likely', 'default', 'car'), ('default', 'car', 'loan'), ('car', 'loan', 'future'), ('loan', 'future', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('applicant', 'JJ'), ('likely', 'JJ'), ('default', 'NN'), ('car', 'NN'), ('loan', 'NN'), ('future', 'NN'), ('?', '.')]

 (S
  Is/VBZ
  (NP applicant/JJ likely/JJ default/NN car/NN loan/NN future/NN)
  ?/.) 


>> Noun Phrases are: 
 ['applicant likely default car loan future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('applicant', 'applic'), ('likely', 'like'), ('default', 'default'), ('car', 'car'), ('loan', 'loan'), ('future', 'futur'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('applicant', 'applic'), ('likely', 'like'), ('default', 'default'), ('car', 'car'), ('loan', 'loan'), ('future', 'futur'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('applicant', 'applicant'), ('likely', 'likely'), ('default', 'default'), ('car', 'car'), ('loan', 'loan'), ('future', 'future'), ('?', '?')]



============================ Sentence 54 =============================

What do algorithms do? 


>> Tokens are: 
 ['What', 'algorithms', '?']

>> Bigrams are: 
 [('What', 'algorithms'), ('algorithms', '?')]

>> Trigrams are: 
 [('What', 'algorithms', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('algorithms', 'NN'), ('?', '.')]

 (S What/WP (NP algorithms/NN) ?/.) 


>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('algorithms', 'algorithm'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('algorithms', 'algorithm'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('algorithms', 'algorithm'), ('?', '?')]



============================ Sentence 55 =============================

Task Main objective Insight/ result  An algorithm is a step- by-step instruction set  or formula for solving a  problem or completing a  task  Minimize errors or  some sort of loss  function to attain the  best approach to solve  a task  The algorithm learns from  its mistakes/errors, finds  the best approach and  generates insights and  rules that can be used to  make predictions  1. 


>> Tokens are: 
 ['Task', 'Main', 'objective', 'Insight/', 'result', 'An', 'algorithm', 'step-', 'by-step', 'instruction', 'set', 'formula', 'solving', 'problem', 'completing', 'task', 'Minimize', 'errors', 'sort', '', 'loss', 'function', '', 'attain', 'best', 'approach', 'solve', 'task', 'The', 'algorithm', 'learns', 'mistakes/errors', ',', 'finds', 'best', 'approach', 'generates', 'insights', 'rules', 'used', 'make', 'predictions', '1', '.']

>> Bigrams are: 
 [('Task', 'Main'), ('Main', 'objective'), ('objective', 'Insight/'), ('Insight/', 'result'), ('result', 'An'), ('An', 'algorithm'), ('algorithm', 'step-'), ('step-', 'by-step'), ('by-step', 'instruction'), ('instruction', 'set'), ('set', 'formula'), ('formula', 'solving'), ('solving', 'problem'), ('problem', 'completing'), ('completing', 'task'), ('task', 'Minimize'), ('Minimize', 'errors'), ('errors', 'sort'), ('sort', ''), ('', 'loss'), ('loss', 'function'), ('function', ''), ('', 'attain'), ('attain', 'best'), ('best', 'approach'), ('approach', 'solve'), ('solve', 'task'), ('task', 'The'), ('The', 'algorithm'), ('algorithm', 'learns'), ('learns', 'mistakes/errors'), ('mistakes/errors', ','), (',', 'finds'), ('finds', 'best'), ('best', 'approach'), ('approach', 'generates'), ('generates', 'insights'), ('insights', 'rules'), ('rules', 'used'), ('used', 'make'), ('make', 'predictions'), ('predictions', '1'), ('1', '.')]

>> Trigrams are: 
 [('Task', 'Main', 'objective'), ('Main', 'objective', 'Insight/'), ('objective', 'Insight/', 'result'), ('Insight/', 'result', 'An'), ('result', 'An', 'algorithm'), ('An', 'algorithm', 'step-'), ('algorithm', 'step-', 'by-step'), ('step-', 'by-step', 'instruction'), ('by-step', 'instruction', 'set'), ('instruction', 'set', 'formula'), ('set', 'formula', 'solving'), ('formula', 'solving', 'problem'), ('solving', 'problem', 'completing'), ('problem', 'completing', 'task'), ('completing', 'task', 'Minimize'), ('task', 'Minimize', 'errors'), ('Minimize', 'errors', 'sort'), ('errors', 'sort', ''), ('sort', '', 'loss'), ('', 'loss', 'function'), ('loss', 'function', ''), ('function', '', 'attain'), ('', 'attain', 'best'), ('attain', 'best', 'approach'), ('best', 'approach', 'solve'), ('approach', 'solve', 'task'), ('solve', 'task', 'The'), ('task', 'The', 'algorithm'), ('The', 'algorithm', 'learns'), ('algorithm', 'learns', 'mistakes/errors'), ('learns', 'mistakes/errors', ','), ('mistakes/errors', ',', 'finds'), (',', 'finds', 'best'), ('finds', 'best', 'approach'), ('best', 'approach', 'generates'), ('approach', 'generates', 'insights'), ('generates', 'insights', 'rules'), ('insights', 'rules', 'used'), ('rules', 'used', 'make'), ('used', 'make', 'predictions'), ('make', 'predictions', '1'), ('predictions', '1', '.')]

>> POS Tags are: 
 [('Task', 'NN'), ('Main', 'NNP'), ('objective', 'JJ'), ('Insight/', 'NNP'), ('result', 'NN'), ('An', 'DT'), ('algorithm', 'JJ'), ('step-', 'JJ'), ('by-step', 'JJ'), ('instruction', 'NN'), ('set', 'VBN'), ('formula', 'NN'), ('solving', 'VBG'), ('problem', 'NN'), ('completing', 'VBG'), ('task', 'NN'), ('Minimize', 'NNP'), ('errors', 'NNS'), ('sort', 'VBP'), ('', 'JJ'), ('loss', 'NN'), ('function', 'NN'), ('', 'NNP'), ('attain', 'NN'), ('best', 'JJS'), ('approach', 'NN'), ('solve', 'NN'), ('task', 'VBD'), ('The', 'DT'), ('algorithm', 'NN'), ('learns', 'VBZ'), ('mistakes/errors', 'NNS'), (',', ','), ('finds', 'VBZ'), ('best', 'JJS'), ('approach', 'NN'), ('generates', 'VBZ'), ('insights', 'NNS'), ('rules', 'NNS'), ('used', 'VBN'), ('make', 'VBP'), ('predictions', 'NNS'), ('1', 'CD'), ('.', '.')]

 (S
  (NP Task/NN Main/NNP)
  (NP objective/JJ Insight//NNP result/NN)
  (NP An/DT algorithm/JJ step-/JJ by-step/JJ instruction/NN)
  set/VBN
  (NP formula/NN)
  solving/VBG
  (NP problem/NN)
  completing/VBG
  (NP task/NN Minimize/NNP errors/NNS)
  sort/VBP
  (NP /JJ loss/NN function/NN /NNP attain/NN)
  best/JJS
  (NP approach/NN solve/NN)
  task/VBD
  (NP The/DT algorithm/NN)
  learns/VBZ
  (NP mistakes/errors/NNS)
  ,/,
  finds/VBZ
  best/JJS
  (NP approach/NN)
  generates/VBZ
  (NP insights/NNS rules/NNS)
  used/VBN
  make/VBP
  (NP predictions/NNS)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Task Main', 'objective Insight/ result', 'An algorithm step- by-step instruction', 'formula', 'problem', 'task Minimize errors', ' loss function  attain', 'approach solve', 'The algorithm', 'mistakes/errors', 'approach', 'insights rules', 'predictions']

>> Named Entities are: 
 [('PERSON', 'Task Main')] 

>> Stemming using Porter Stemmer: 
 [('Task', 'task'), ('Main', 'main'), ('objective', 'object'), ('Insight/', 'insight/'), ('result', 'result'), ('An', 'an'), ('algorithm', 'algorithm'), ('step-', 'step-'), ('by-step', 'by-step'), ('instruction', 'instruct'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solv'), ('problem', 'problem'), ('completing', 'complet'), ('task', 'task'), ('Minimize', 'minim'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solv'), ('task', 'task'), ('The', 'the'), ('algorithm', 'algorithm'), ('learns', 'learn'), ('mistakes/errors', 'mistakes/error'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'gener'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Task', 'task'), ('Main', 'main'), ('objective', 'object'), ('Insight/', 'insight/'), ('result', 'result'), ('An', 'an'), ('algorithm', 'algorithm'), ('step-', 'step-'), ('by-step', 'by-step'), ('instruction', 'instruct'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solv'), ('problem', 'problem'), ('completing', 'complet'), ('task', 'task'), ('Minimize', 'minim'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solv'), ('task', 'task'), ('The', 'the'), ('algorithm', 'algorithm'), ('learns', 'learn'), ('mistakes/errors', 'mistakes/error'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'generat'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Task', 'Task'), ('Main', 'Main'), ('objective', 'objective'), ('Insight/', 'Insight/'), ('result', 'result'), ('An', 'An'), ('algorithm', 'algorithm'), ('step-', 'step-'), ('by-step', 'by-step'), ('instruction', 'instruction'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solving'), ('problem', 'problem'), ('completing', 'completing'), ('task', 'task'), ('Minimize', 'Minimize'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solve'), ('task', 'task'), ('The', 'The'), ('algorithm', 'algorithm'), ('learns', 'learns'), ('mistakes/errors', 'mistakes/errors'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'generates'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'used'), ('make', 'make'), ('predictions', 'prediction'), ('1', '1'), ('.', '.')]



============================ Sentence 56 =============================

Take	the	chicken	out  2. 


>> Tokens are: 
 ['Take', 'chicken', '2', '.']

>> Bigrams are: 
 [('Take', 'chicken'), ('chicken', '2'), ('2', '.')]

>> Trigrams are: 
 [('Take', 'chicken', '2'), ('chicken', '2', '.')]

>> POS Tags are: 
 [('Take', 'VB'), ('chicken', 'NN'), ('2', 'CD'), ('.', '.')]

 (S Take/VB (NP chicken/NN) 2/CD ./.) 


>> Noun Phrases are: 
 ['chicken']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Take', 'take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Take', 'take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Take', 'Take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]



============================ Sentence 57 =============================

Salt	and	season  3. 


>> Tokens are: 
 ['Salt', 'season', '3', '.']

>> Bigrams are: 
 [('Salt', 'season'), ('season', '3'), ('3', '.')]

>> Trigrams are: 
 [('Salt', 'season', '3'), ('season', '3', '.')]

>> POS Tags are: 
 [('Salt', 'NNP'), ('season', 'NN'), ('3', 'CD'), ('.', '.')]

 (S (NP Salt/NNP season/NN) 3/CD ./.) 


>> Noun Phrases are: 
 ['Salt season']

>> Named Entities are: 
 [('GPE', 'Salt')] 

>> Stemming using Porter Stemmer: 
 [('Salt', 'salt'), ('season', 'season'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Salt', 'salt'), ('season', 'season'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Salt', 'Salt'), ('season', 'season'), ('3', '3'), ('.', '.')]



============================ Sentence 58 =============================

Bake	it  Minimize	the	number	 of	things/steps	needed	 to	take	in	order	to	 serve	the	dish  Learn	from	your	mistakes	 	the	next	time	you	attempt	 	the	recipe  With the growth of data, the invention of advanced algorithms and cheaper  commodity hardware to process big data at scale, deep learning, a powerful set  of machine learning techniques, has become prominent in the industry. 


>> Tokens are: 
 ['Bake', 'Minimize', 'number', 'things/steps', 'needed', 'take', 'order', 'serve', 'dish', 'Learn', 'mistakes', 'next', 'time', 'attempt', 'recipe', 'With', 'growth', 'data', ',', 'invention', 'advanced', 'algorithms', 'cheaper', 'commodity', 'hardware', 'process', 'big', 'data', 'scale', ',', 'deep', 'learning', ',', 'powerful', 'set', 'machine', 'learning', 'techniques', ',', 'become', 'prominent', 'industry', '.']

>> Bigrams are: 
 [('Bake', 'Minimize'), ('Minimize', 'number'), ('number', 'things/steps'), ('things/steps', 'needed'), ('needed', 'take'), ('take', 'order'), ('order', 'serve'), ('serve', 'dish'), ('dish', 'Learn'), ('Learn', 'mistakes'), ('mistakes', 'next'), ('next', 'time'), ('time', 'attempt'), ('attempt', 'recipe'), ('recipe', 'With'), ('With', 'growth'), ('growth', 'data'), ('data', ','), (',', 'invention'), ('invention', 'advanced'), ('advanced', 'algorithms'), ('algorithms', 'cheaper'), ('cheaper', 'commodity'), ('commodity', 'hardware'), ('hardware', 'process'), ('process', 'big'), ('big', 'data'), ('data', 'scale'), ('scale', ','), (',', 'deep'), ('deep', 'learning'), ('learning', ','), (',', 'powerful'), ('powerful', 'set'), ('set', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'become'), ('become', 'prominent'), ('prominent', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('Bake', 'Minimize', 'number'), ('Minimize', 'number', 'things/steps'), ('number', 'things/steps', 'needed'), ('things/steps', 'needed', 'take'), ('needed', 'take', 'order'), ('take', 'order', 'serve'), ('order', 'serve', 'dish'), ('serve', 'dish', 'Learn'), ('dish', 'Learn', 'mistakes'), ('Learn', 'mistakes', 'next'), ('mistakes', 'next', 'time'), ('next', 'time', 'attempt'), ('time', 'attempt', 'recipe'), ('attempt', 'recipe', 'With'), ('recipe', 'With', 'growth'), ('With', 'growth', 'data'), ('growth', 'data', ','), ('data', ',', 'invention'), (',', 'invention', 'advanced'), ('invention', 'advanced', 'algorithms'), ('advanced', 'algorithms', 'cheaper'), ('algorithms', 'cheaper', 'commodity'), ('cheaper', 'commodity', 'hardware'), ('commodity', 'hardware', 'process'), ('hardware', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', 'scale'), ('data', 'scale', ','), ('scale', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', ','), ('learning', ',', 'powerful'), (',', 'powerful', 'set'), ('powerful', 'set', 'machine'), ('set', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'become'), (',', 'become', 'prominent'), ('become', 'prominent', 'industry'), ('prominent', 'industry', '.')]

>> POS Tags are: 
 [('Bake', 'NNP'), ('Minimize', 'NNP'), ('number', 'NN'), ('things/steps', 'NNS'), ('needed', 'VBD'), ('take', 'NN'), ('order', 'NN'), ('serve', 'VBP'), ('dish', 'NN'), ('Learn', 'NNP'), ('mistakes', 'NNS'), ('next', 'IN'), ('time', 'NN'), ('attempt', 'NN'), ('recipe', 'NN'), ('With', 'IN'), ('growth', 'NN'), ('data', 'NNS'), (',', ','), ('invention', 'NN'), ('advanced', 'VBD'), ('algorithms', 'JJ'), ('cheaper', 'JJR'), ('commodity', 'NN'), ('hardware', 'NN'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('scale', 'NN'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), (',', ','), ('powerful', 'JJ'), ('set', 'FW'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('become', 'VB'), ('prominent', 'JJ'), ('industry', 'NN'), ('.', '.')]

 (S
  (NP Bake/NNP Minimize/NNP number/NN things/steps/NNS)
  needed/VBD
  (NP take/NN order/NN)
  serve/VBP
  (NP dish/NN Learn/NNP mistakes/NNS)
  next/IN
  (NP time/NN attempt/NN recipe/NN)
  With/IN
  (NP growth/NN data/NNS)
  ,/,
  (NP invention/NN)
  advanced/VBD
  algorithms/JJ
  cheaper/JJR
  (NP commodity/NN hardware/NN process/NN)
  (NP big/JJ data/NNS scale/NN)
  ,/,
  (NP deep/JJ learning/NN)
  ,/,
  powerful/JJ
  set/FW
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  become/VB
  (NP prominent/JJ industry/NN)
  ./.) 


>> Noun Phrases are: 
 ['Bake Minimize number things/steps', 'take order', 'dish Learn mistakes', 'time attempt recipe', 'growth data', 'invention', 'commodity hardware process', 'big data scale', 'deep learning', 'machine', 'techniques', 'prominent industry']

>> Named Entities are: 
 [('PERSON', 'Bake'), ('ORGANIZATION', 'Minimize')] 

>> Stemming using Porter Stemmer: 
 [('Bake', 'bake'), ('Minimize', 'minim'), ('number', 'number'), ('things/steps', 'things/step'), ('needed', 'need'), ('take', 'take'), ('order', 'order'), ('serve', 'serv'), ('dish', 'dish'), ('Learn', 'learn'), ('mistakes', 'mistak'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recip'), ('With', 'with'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invent'), ('advanced', 'advanc'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commod'), ('hardware', 'hardwar'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('become', 'becom'), ('prominent', 'promin'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bake', 'bake'), ('Minimize', 'minim'), ('number', 'number'), ('things/steps', 'things/step'), ('needed', 'need'), ('take', 'take'), ('order', 'order'), ('serve', 'serv'), ('dish', 'dish'), ('Learn', 'learn'), ('mistakes', 'mistak'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recip'), ('With', 'with'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invent'), ('advanced', 'advanc'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commod'), ('hardware', 'hardwar'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('become', 'becom'), ('prominent', 'promin'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('Bake', 'Bake'), ('Minimize', 'Minimize'), ('number', 'number'), ('things/steps', 'things/steps'), ('needed', 'needed'), ('take', 'take'), ('order', 'order'), ('serve', 'serve'), ('dish', 'dish'), ('Learn', 'Learn'), ('mistakes', 'mistake'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recipe'), ('With', 'With'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invention'), ('advanced', 'advanced'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commodity'), ('hardware', 'hardware'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), (',', ','), ('powerful', 'powerful'), ('set', 'set'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('become', 'become'), ('prominent', 'prominent'), ('industry', 'industry'), ('.', '.')]



============================ Sentence 59 =============================

Deep  learning techniques mimic the brains neuron activities, which is why they are also  referred to as neural networks. 


>> Tokens are: 
 ['Deep', 'learning', 'techniques', 'mimic', 'brain', '', 'neuron', 'activities', ',', 'also', 'referred', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'techniques'), ('techniques', 'mimic'), ('mimic', 'brain'), ('brain', ''), ('', 'neuron'), ('neuron', 'activities'), ('activities', ','), (',', 'also'), ('also', 'referred'), ('referred', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'techniques'), ('learning', 'techniques', 'mimic'), ('techniques', 'mimic', 'brain'), ('mimic', 'brain', ''), ('brain', '', 'neuron'), ('', 'neuron', 'activities'), ('neuron', 'activities', ','), ('activities', ',', 'also'), (',', 'also', 'referred'), ('also', 'referred', 'neural'), ('referred', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('learning', 'NN'), ('techniques', 'NNS'), ('mimic', 'VBP'), ('brain', 'NN'), ('', 'NN'), ('neuron', 'NN'), ('activities', 'NNS'), (',', ','), ('also', 'RB'), ('referred', 'VBD'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP Deep/JJ learning/NN techniques/NNS)
  mimic/VBP
  (NP brain/NN /NN neuron/NN activities/NNS)
  ,/,
  also/RB
  referred/VBD
  (NP neural/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning techniques', 'brain  neuron activities', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('techniques', 'techniqu'), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('also', 'also'), ('referred', 'refer'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('techniques', 'techniqu'), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activ'), (',', ','), ('also', 'also'), ('referred', 'refer'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('techniques', 'technique'), ('mimic', 'mimic'), ('brain', 'brain'), ('', ''), ('neuron', 'neuron'), ('activities', 'activity'), (',', ','), ('also', 'also'), ('referred', 'referred'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]



============================ Sentence 60 =============================

Some common applications include natural language  processing, image recognition, realistic photo and video generation. 


>> Tokens are: 
 ['Some', 'common', 'applications', 'include', 'natural', 'language', 'processing', ',', 'image', 'recognition', ',', 'realistic', 'photo', 'video', 'generation', '.']

>> Bigrams are: 
 [('Some', 'common'), ('common', 'applications'), ('applications', 'include'), ('include', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', ','), (',', 'image'), ('image', 'recognition'), ('recognition', ','), (',', 'realistic'), ('realistic', 'photo'), ('photo', 'video'), ('video', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('Some', 'common', 'applications'), ('common', 'applications', 'include'), ('applications', 'include', 'natural'), ('include', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', ','), ('processing', ',', 'image'), (',', 'image', 'recognition'), ('image', 'recognition', ','), ('recognition', ',', 'realistic'), (',', 'realistic', 'photo'), ('realistic', 'photo', 'video'), ('photo', 'video', 'generation'), ('video', 'generation', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('common', 'JJ'), ('applications', 'NNS'), ('include', 'VBP'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), (',', ','), ('image', 'NN'), ('recognition', 'NN'), (',', ','), ('realistic', 'JJ'), ('photo', 'NN'), ('video', 'NN'), ('generation', 'NN'), ('.', '.')]

 (S
  (NP Some/DT common/JJ applications/NNS)
  include/VBP
  (NP natural/JJ language/NN processing/NN)
  ,/,
  (NP image/NN recognition/NN)
  ,/,
  (NP realistic/JJ photo/NN video/NN generation/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some common applications', 'natural language processing', 'image recognition', 'realistic photo video generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('common', 'common'), ('applications', 'applic'), ('include', 'includ'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), (',', ','), ('image', 'imag'), ('recognition', 'recognit'), (',', ','), ('realistic', 'realist'), ('photo', 'photo'), ('video', 'video'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('common', 'common'), ('applications', 'applic'), ('include', 'includ'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), (',', ','), ('image', 'imag'), ('recognition', 'recognit'), (',', ','), ('realistic', 'realist'), ('photo', 'photo'), ('video', 'video'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('common', 'common'), ('applications', 'application'), ('include', 'include'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), (',', ','), ('image', 'image'), ('recognition', 'recognition'), (',', ','), ('realistic', 'realistic'), ('photo', 'photo'), ('video', 'video'), ('generation', 'generation'), ('.', '.')]



============================ Sentence 61 =============================

With the growth of data,  the invention of advanced  algorithms and cheaper  commodity hardware to  process big data at scale,  deep learning, a powerful  set of machine learning  techniques, has become  prominent in the industry. 


>> Tokens are: 
 ['With', 'growth', 'data', ',', 'invention', 'advanced', 'algorithms', 'cheaper', 'commodity', 'hardware', 'process', 'big', 'data', 'scale', ',', 'deep', 'learning', ',', 'powerful', 'set', 'machine', 'learning', 'techniques', ',', 'become', 'prominent', 'industry', '.']

>> Bigrams are: 
 [('With', 'growth'), ('growth', 'data'), ('data', ','), (',', 'invention'), ('invention', 'advanced'), ('advanced', 'algorithms'), ('algorithms', 'cheaper'), ('cheaper', 'commodity'), ('commodity', 'hardware'), ('hardware', 'process'), ('process', 'big'), ('big', 'data'), ('data', 'scale'), ('scale', ','), (',', 'deep'), ('deep', 'learning'), ('learning', ','), (',', 'powerful'), ('powerful', 'set'), ('set', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'become'), ('become', 'prominent'), ('prominent', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('With', 'growth', 'data'), ('growth', 'data', ','), ('data', ',', 'invention'), (',', 'invention', 'advanced'), ('invention', 'advanced', 'algorithms'), ('advanced', 'algorithms', 'cheaper'), ('algorithms', 'cheaper', 'commodity'), ('cheaper', 'commodity', 'hardware'), ('commodity', 'hardware', 'process'), ('hardware', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', 'scale'), ('data', 'scale', ','), ('scale', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', ','), ('learning', ',', 'powerful'), (',', 'powerful', 'set'), ('powerful', 'set', 'machine'), ('set', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'become'), (',', 'become', 'prominent'), ('become', 'prominent', 'industry'), ('prominent', 'industry', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('growth', 'NN'), ('data', 'NNS'), (',', ','), ('invention', 'NN'), ('advanced', 'VBD'), ('algorithms', 'JJ'), ('cheaper', 'JJR'), ('commodity', 'NN'), ('hardware', 'NN'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('scale', 'NN'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), (',', ','), ('powerful', 'JJ'), ('set', 'FW'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('become', 'VB'), ('prominent', 'JJ'), ('industry', 'NN'), ('.', '.')]

 (S
  With/IN
  (NP growth/NN data/NNS)
  ,/,
  (NP invention/NN)
  advanced/VBD
  algorithms/JJ
  cheaper/JJR
  (NP commodity/NN hardware/NN process/NN)
  (NP big/JJ data/NNS scale/NN)
  ,/,
  (NP deep/JJ learning/NN)
  ,/,
  powerful/JJ
  set/FW
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  become/VB
  (NP prominent/JJ industry/NN)
  ./.) 


>> Noun Phrases are: 
 ['growth data', 'invention', 'commodity hardware process', 'big data scale', 'deep learning', 'machine', 'techniques', 'prominent industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invent'), ('advanced', 'advanc'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commod'), ('hardware', 'hardwar'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('become', 'becom'), ('prominent', 'promin'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invent'), ('advanced', 'advanc'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commod'), ('hardware', 'hardwar'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('powerful', 'power'), ('set', 'set'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('become', 'becom'), ('prominent', 'promin'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('growth', 'growth'), ('data', 'data'), (',', ','), ('invention', 'invention'), ('advanced', 'advanced'), ('algorithms', 'algorithm'), ('cheaper', 'cheaper'), ('commodity', 'commodity'), ('hardware', 'hardware'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), (',', ','), ('powerful', 'powerful'), ('set', 'set'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('become', 'become'), ('prominent', 'prominent'), ('industry', 'industry'), ('.', '.')]



============================ Sentence 62 =============================

Task An algorithm is a   step-by-step instruction set  or formula for solving a   problem or completing a task  1. 


>> Tokens are: 
 ['Task', 'An', 'algorithm', 'step-by-step', 'instruction', 'set', 'formula', 'solving', 'problem', 'completing', 'task', '1', '.']

>> Bigrams are: 
 [('Task', 'An'), ('An', 'algorithm'), ('algorithm', 'step-by-step'), ('step-by-step', 'instruction'), ('instruction', 'set'), ('set', 'formula'), ('formula', 'solving'), ('solving', 'problem'), ('problem', 'completing'), ('completing', 'task'), ('task', '1'), ('1', '.')]

>> Trigrams are: 
 [('Task', 'An', 'algorithm'), ('An', 'algorithm', 'step-by-step'), ('algorithm', 'step-by-step', 'instruction'), ('step-by-step', 'instruction', 'set'), ('instruction', 'set', 'formula'), ('set', 'formula', 'solving'), ('formula', 'solving', 'problem'), ('solving', 'problem', 'completing'), ('problem', 'completing', 'task'), ('completing', 'task', '1'), ('task', '1', '.')]

>> POS Tags are: 
 [('Task', 'NNP'), ('An', 'DT'), ('algorithm', 'JJ'), ('step-by-step', 'JJ'), ('instruction', 'NN'), ('set', 'VBN'), ('formula', 'NN'), ('solving', 'VBG'), ('problem', 'NN'), ('completing', 'VBG'), ('task', 'NN'), ('1', 'CD'), ('.', '.')]

 (S
  (NP Task/NNP)
  (NP An/DT algorithm/JJ step-by-step/JJ instruction/NN)
  set/VBN
  (NP formula/NN)
  solving/VBG
  (NP problem/NN)
  completing/VBG
  (NP task/NN)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Task', 'An algorithm step-by-step instruction', 'formula', 'problem', 'task']

>> Named Entities are: 
 [('GPE', 'Task')] 

>> Stemming using Porter Stemmer: 
 [('Task', 'task'), ('An', 'an'), ('algorithm', 'algorithm'), ('step-by-step', 'step-by-step'), ('instruction', 'instruct'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solv'), ('problem', 'problem'), ('completing', 'complet'), ('task', 'task'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Task', 'task'), ('An', 'an'), ('algorithm', 'algorithm'), ('step-by-step', 'step-by-step'), ('instruction', 'instruct'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solv'), ('problem', 'problem'), ('completing', 'complet'), ('task', 'task'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Task', 'Task'), ('An', 'An'), ('algorithm', 'algorithm'), ('step-by-step', 'step-by-step'), ('instruction', 'instruction'), ('set', 'set'), ('formula', 'formula'), ('solving', 'solving'), ('problem', 'problem'), ('completing', 'completing'), ('task', 'task'), ('1', '1'), ('.', '.')]



============================ Sentence 63 =============================

Take the chicken out 2. 


>> Tokens are: 
 ['Take', 'chicken', '2', '.']

>> Bigrams are: 
 [('Take', 'chicken'), ('chicken', '2'), ('2', '.')]

>> Trigrams are: 
 [('Take', 'chicken', '2'), ('chicken', '2', '.')]

>> POS Tags are: 
 [('Take', 'VB'), ('chicken', 'NN'), ('2', 'CD'), ('.', '.')]

 (S Take/VB (NP chicken/NN) 2/CD ./.) 


>> Noun Phrases are: 
 ['chicken']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Take', 'take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Take', 'take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Take', 'Take'), ('chicken', 'chicken'), ('2', '2'), ('.', '.')]



============================ Sentence 64 =============================

Salt and season 3. 


>> Tokens are: 
 ['Salt', 'season', '3', '.']

>> Bigrams are: 
 [('Salt', 'season'), ('season', '3'), ('3', '.')]

>> Trigrams are: 
 [('Salt', 'season', '3'), ('season', '3', '.')]

>> POS Tags are: 
 [('Salt', 'NNP'), ('season', 'NN'), ('3', 'CD'), ('.', '.')]

 (S (NP Salt/NNP season/NN) 3/CD ./.) 


>> Noun Phrases are: 
 ['Salt season']

>> Named Entities are: 
 [('GPE', 'Salt')] 

>> Stemming using Porter Stemmer: 
 [('Salt', 'salt'), ('season', 'season'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Salt', 'salt'), ('season', 'season'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Salt', 'Salt'), ('season', 'season'), ('3', '3'), ('.', '.')]



============================ Sentence 65 =============================

Bake it  Minimize errors or some sort  of loss function to attain the  best approach to solve a task  Minimize the number of  things/steps needed to take   in order to serve the dish  The algorithm learns from its  mistakes/errors, finds the   best approach and generates  insights and rules that can be   used to make predictions  Learn from your mistakes  the next time you attempt   the recipe  Main objective  Insight/ result  Machine learning Recipe Analogy    6/14Demystifying data science   How can an organization derive business value from AI   and analytics? 


>> Tokens are: 
 ['Bake', 'Minimize', 'errors', 'sort', '', 'loss', 'function', '', 'attain', 'best', 'approach', 'solve', 'task', 'Minimize', 'number', 'things/steps', 'needed', 'take', 'order', 'serve', 'dish', 'The', 'algorithm', 'learns', 'mistakes/errors', ',', 'finds', 'best', 'approach', 'generates', 'insights', 'rules', 'used', 'make', 'predictions', 'Learn', 'mistakes', 'next', 'time', 'attempt', 'recipe', 'Main', 'objective', 'Insight/', 'result', 'Machine', 'learning', 'Recipe', 'Analogy', '6/14Demystifying', 'data', 'science', 'How', 'organization', 'derive', 'business', 'value', 'AI', 'analytics', '?']

>> Bigrams are: 
 [('Bake', 'Minimize'), ('Minimize', 'errors'), ('errors', 'sort'), ('sort', ''), ('', 'loss'), ('loss', 'function'), ('function', ''), ('', 'attain'), ('attain', 'best'), ('best', 'approach'), ('approach', 'solve'), ('solve', 'task'), ('task', 'Minimize'), ('Minimize', 'number'), ('number', 'things/steps'), ('things/steps', 'needed'), ('needed', 'take'), ('take', 'order'), ('order', 'serve'), ('serve', 'dish'), ('dish', 'The'), ('The', 'algorithm'), ('algorithm', 'learns'), ('learns', 'mistakes/errors'), ('mistakes/errors', ','), (',', 'finds'), ('finds', 'best'), ('best', 'approach'), ('approach', 'generates'), ('generates', 'insights'), ('insights', 'rules'), ('rules', 'used'), ('used', 'make'), ('make', 'predictions'), ('predictions', 'Learn'), ('Learn', 'mistakes'), ('mistakes', 'next'), ('next', 'time'), ('time', 'attempt'), ('attempt', 'recipe'), ('recipe', 'Main'), ('Main', 'objective'), ('objective', 'Insight/'), ('Insight/', 'result'), ('result', 'Machine'), ('Machine', 'learning'), ('learning', 'Recipe'), ('Recipe', 'Analogy'), ('Analogy', '6/14Demystifying'), ('6/14Demystifying', 'data'), ('data', 'science'), ('science', 'How'), ('How', 'organization'), ('organization', 'derive'), ('derive', 'business'), ('business', 'value'), ('value', 'AI'), ('AI', 'analytics'), ('analytics', '?')]

>> Trigrams are: 
 [('Bake', 'Minimize', 'errors'), ('Minimize', 'errors', 'sort'), ('errors', 'sort', ''), ('sort', '', 'loss'), ('', 'loss', 'function'), ('loss', 'function', ''), ('function', '', 'attain'), ('', 'attain', 'best'), ('attain', 'best', 'approach'), ('best', 'approach', 'solve'), ('approach', 'solve', 'task'), ('solve', 'task', 'Minimize'), ('task', 'Minimize', 'number'), ('Minimize', 'number', 'things/steps'), ('number', 'things/steps', 'needed'), ('things/steps', 'needed', 'take'), ('needed', 'take', 'order'), ('take', 'order', 'serve'), ('order', 'serve', 'dish'), ('serve', 'dish', 'The'), ('dish', 'The', 'algorithm'), ('The', 'algorithm', 'learns'), ('algorithm', 'learns', 'mistakes/errors'), ('learns', 'mistakes/errors', ','), ('mistakes/errors', ',', 'finds'), (',', 'finds', 'best'), ('finds', 'best', 'approach'), ('best', 'approach', 'generates'), ('approach', 'generates', 'insights'), ('generates', 'insights', 'rules'), ('insights', 'rules', 'used'), ('rules', 'used', 'make'), ('used', 'make', 'predictions'), ('make', 'predictions', 'Learn'), ('predictions', 'Learn', 'mistakes'), ('Learn', 'mistakes', 'next'), ('mistakes', 'next', 'time'), ('next', 'time', 'attempt'), ('time', 'attempt', 'recipe'), ('attempt', 'recipe', 'Main'), ('recipe', 'Main', 'objective'), ('Main', 'objective', 'Insight/'), ('objective', 'Insight/', 'result'), ('Insight/', 'result', 'Machine'), ('result', 'Machine', 'learning'), ('Machine', 'learning', 'Recipe'), ('learning', 'Recipe', 'Analogy'), ('Recipe', 'Analogy', '6/14Demystifying'), ('Analogy', '6/14Demystifying', 'data'), ('6/14Demystifying', 'data', 'science'), ('data', 'science', 'How'), ('science', 'How', 'organization'), ('How', 'organization', 'derive'), ('organization', 'derive', 'business'), ('derive', 'business', 'value'), ('business', 'value', 'AI'), ('value', 'AI', 'analytics'), ('AI', 'analytics', '?')]

>> POS Tags are: 
 [('Bake', 'NNP'), ('Minimize', 'NNP'), ('errors', 'NNS'), ('sort', 'VBP'), ('', 'JJ'), ('loss', 'NN'), ('function', 'NN'), ('', 'NNP'), ('attain', 'NN'), ('best', 'JJS'), ('approach', 'NN'), ('solve', 'NN'), ('task', 'NN'), ('Minimize', 'NNP'), ('number', 'NN'), ('things/steps', 'NNS'), ('needed', 'VBD'), ('take', 'NN'), ('order', 'NN'), ('serve', 'VBP'), ('dish', 'VB'), ('The', 'DT'), ('algorithm', 'NN'), ('learns', 'VBZ'), ('mistakes/errors', 'NNS'), (',', ','), ('finds', 'VBZ'), ('best', 'JJS'), ('approach', 'NN'), ('generates', 'VBZ'), ('insights', 'NNS'), ('rules', 'NNS'), ('used', 'VBN'), ('make', 'VBP'), ('predictions', 'NNS'), ('Learn', 'NNP'), ('mistakes', 'NNS'), ('next', 'IN'), ('time', 'NN'), ('attempt', 'NN'), ('recipe', 'NN'), ('Main', 'NNP'), ('objective', 'NN'), ('Insight/', 'NNP'), ('result', 'NN'), ('Machine', 'NNP'), ('learning', 'NN'), ('Recipe', 'NNP'), ('Analogy', 'NNP'), ('6/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('How', 'NNP'), ('organization', 'NN'), ('derive', 'NN'), ('business', 'NN'), ('value', 'NN'), ('AI', 'NNP'), ('analytics', 'NNS'), ('?', '.')]

 (S
  (NP Bake/NNP Minimize/NNP errors/NNS)
  sort/VBP
  (NP /JJ loss/NN function/NN /NNP attain/NN)
  best/JJS
  (NP
    approach/NN
    solve/NN
    task/NN
    Minimize/NNP
    number/NN
    things/steps/NNS)
  needed/VBD
  (NP take/NN order/NN)
  serve/VBP
  dish/VB
  (NP The/DT algorithm/NN)
  learns/VBZ
  (NP mistakes/errors/NNS)
  ,/,
  finds/VBZ
  best/JJS
  (NP approach/NN)
  generates/VBZ
  (NP insights/NNS rules/NNS)
  used/VBN
  make/VBP
  (NP predictions/NNS Learn/NNP mistakes/NNS)
  next/IN
  (NP
    time/NN
    attempt/NN
    recipe/NN
    Main/NNP
    objective/NN
    Insight//NNP
    result/NN
    Machine/NNP
    learning/NN
    Recipe/NNP
    Analogy/NNP)
  6/14Demystifying/VBG
  (NP
    data/NNS
    science/NN
    How/NNP
    organization/NN
    derive/NN
    business/NN
    value/NN
    AI/NNP
    analytics/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['Bake Minimize errors', ' loss function  attain', 'approach solve task Minimize number things/steps', 'take order', 'The algorithm', 'mistakes/errors', 'approach', 'insights rules', 'predictions Learn mistakes', 'time attempt recipe Main objective Insight/ result Machine learning Recipe Analogy', 'data science How organization derive business value AI analytics']

>> Named Entities are: 
 [('PERSON', 'Bake'), ('ORGANIZATION', 'Minimize'), ('GPE', 'Main'), ('PERSON', 'Machine'), ('PERSON', 'Recipe Analogy')] 

>> Stemming using Porter Stemmer: 
 [('Bake', 'bake'), ('Minimize', 'minim'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solv'), ('task', 'task'), ('Minimize', 'minim'), ('number', 'number'), ('things/steps', 'things/step'), ('needed', 'need'), ('take', 'take'), ('order', 'order'), ('serve', 'serv'), ('dish', 'dish'), ('The', 'the'), ('algorithm', 'algorithm'), ('learns', 'learn'), ('mistakes/errors', 'mistakes/error'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'gener'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), ('Learn', 'learn'), ('mistakes', 'mistak'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recip'), ('Main', 'main'), ('objective', 'object'), ('Insight/', 'insight/'), ('result', 'result'), ('Machine', 'machin'), ('learning', 'learn'), ('Recipe', 'recip'), ('Analogy', 'analog'), ('6/14Demystifying', '6/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('organization', 'organ'), ('derive', 'deriv'), ('business', 'busi'), ('value', 'valu'), ('AI', 'ai'), ('analytics', 'analyt'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Bake', 'bake'), ('Minimize', 'minim'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solv'), ('task', 'task'), ('Minimize', 'minim'), ('number', 'number'), ('things/steps', 'things/step'), ('needed', 'need'), ('take', 'take'), ('order', 'order'), ('serve', 'serv'), ('dish', 'dish'), ('The', 'the'), ('algorithm', 'algorithm'), ('learns', 'learn'), ('mistakes/errors', 'mistakes/error'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'generat'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), ('Learn', 'learn'), ('mistakes', 'mistak'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recip'), ('Main', 'main'), ('objective', 'object'), ('Insight/', 'insight/'), ('result', 'result'), ('Machine', 'machin'), ('learning', 'learn'), ('Recipe', 'recip'), ('Analogy', 'analog'), ('6/14Demystifying', '6/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('organization', 'organ'), ('derive', 'deriv'), ('business', 'busi'), ('value', 'valu'), ('AI', 'ai'), ('analytics', 'analyt'), ('?', '?')]

>> Lemmatization: 
 [('Bake', 'Bake'), ('Minimize', 'Minimize'), ('errors', 'error'), ('sort', 'sort'), ('', ''), ('loss', 'loss'), ('function', 'function'), ('', ''), ('attain', 'attain'), ('best', 'best'), ('approach', 'approach'), ('solve', 'solve'), ('task', 'task'), ('Minimize', 'Minimize'), ('number', 'number'), ('things/steps', 'things/steps'), ('needed', 'needed'), ('take', 'take'), ('order', 'order'), ('serve', 'serve'), ('dish', 'dish'), ('The', 'The'), ('algorithm', 'algorithm'), ('learns', 'learns'), ('mistakes/errors', 'mistakes/errors'), (',', ','), ('finds', 'find'), ('best', 'best'), ('approach', 'approach'), ('generates', 'generates'), ('insights', 'insight'), ('rules', 'rule'), ('used', 'used'), ('make', 'make'), ('predictions', 'prediction'), ('Learn', 'Learn'), ('mistakes', 'mistake'), ('next', 'next'), ('time', 'time'), ('attempt', 'attempt'), ('recipe', 'recipe'), ('Main', 'Main'), ('objective', 'objective'), ('Insight/', 'Insight/'), ('result', 'result'), ('Machine', 'Machine'), ('learning', 'learning'), ('Recipe', 'Recipe'), ('Analogy', 'Analogy'), ('6/14Demystifying', '6/14Demystifying'), ('data', 'data'), ('science', 'science'), ('How', 'How'), ('organization', 'organization'), ('derive', 'derive'), ('business', 'business'), ('value', 'value'), ('AI', 'AI'), ('analytics', 'analytics'), ('?', '?')]



============================ Sentence 66 =============================

There are some common questions organizations consider when appealing  to their customer base: Who are the customers? 


>> Tokens are: 
 ['There', 'common', 'questions', 'organizations', 'consider', 'appealing', 'customer', 'base', ':', 'Who', 'customers', '?']

>> Bigrams are: 
 [('There', 'common'), ('common', 'questions'), ('questions', 'organizations'), ('organizations', 'consider'), ('consider', 'appealing'), ('appealing', 'customer'), ('customer', 'base'), ('base', ':'), (':', 'Who'), ('Who', 'customers'), ('customers', '?')]

>> Trigrams are: 
 [('There', 'common', 'questions'), ('common', 'questions', 'organizations'), ('questions', 'organizations', 'consider'), ('organizations', 'consider', 'appealing'), ('consider', 'appealing', 'customer'), ('appealing', 'customer', 'base'), ('customer', 'base', ':'), ('base', ':', 'Who'), (':', 'Who', 'customers'), ('Who', 'customers', '?')]

>> POS Tags are: 
 [('There', 'EX'), ('common', 'JJ'), ('questions', 'NNS'), ('organizations', 'NNS'), ('consider', 'VBP'), ('appealing', 'VBG'), ('customer', 'NN'), ('base', 'NN'), (':', ':'), ('Who', 'WP'), ('customers', 'NNS'), ('?', '.')]

 (S
  There/EX
  (NP common/JJ questions/NNS organizations/NNS)
  consider/VBP
  appealing/VBG
  (NP customer/NN base/NN)
  :/:
  Who/WP
  (NP customers/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['common questions organizations', 'customer base', 'customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('common', 'common'), ('questions', 'question'), ('organizations', 'organ'), ('consider', 'consid'), ('appealing', 'appeal'), ('customer', 'custom'), ('base', 'base'), (':', ':'), ('Who', 'who'), ('customers', 'custom'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('common', 'common'), ('questions', 'question'), ('organizations', 'organ'), ('consider', 'consid'), ('appealing', 'appeal'), ('customer', 'custom'), ('base', 'base'), (':', ':'), ('Who', 'who'), ('customers', 'custom'), ('?', '?')]

>> Lemmatization: 
 [('There', 'There'), ('common', 'common'), ('questions', 'question'), ('organizations', 'organization'), ('consider', 'consider'), ('appealing', 'appealing'), ('customer', 'customer'), ('base', 'base'), (':', ':'), ('Who', 'Who'), ('customers', 'customer'), ('?', '?')]



============================ Sentence 67 =============================

What do they want? 


>> Tokens are: 
 ['What', 'want', '?']

>> Bigrams are: 
 [('What', 'want'), ('want', '?')]

>> Trigrams are: 
 [('What', 'want', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('want', 'NN'), ('?', '.')]

 (S What/WP (NP want/NN) ?/.) 


>> Noun Phrases are: 
 ['want']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('want', 'want'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('want', 'want'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('want', 'want'), ('?', '?')]



============================ Sentence 68 =============================

How can  the organization provide the best customer experience to gain a competitive  advantage? 


>> Tokens are: 
 ['How', 'organization', 'provide', 'best', 'customer', 'experience', 'gain', 'competitive', 'advantage', '?']

>> Bigrams are: 
 [('How', 'organization'), ('organization', 'provide'), ('provide', 'best'), ('best', 'customer'), ('customer', 'experience'), ('experience', 'gain'), ('gain', 'competitive'), ('competitive', 'advantage'), ('advantage', '?')]

>> Trigrams are: 
 [('How', 'organization', 'provide'), ('organization', 'provide', 'best'), ('provide', 'best', 'customer'), ('best', 'customer', 'experience'), ('customer', 'experience', 'gain'), ('experience', 'gain', 'competitive'), ('gain', 'competitive', 'advantage'), ('competitive', 'advantage', '?')]

>> POS Tags are: 
 [('How', 'WRB'), ('organization', 'NN'), ('provide', 'RB'), ('best', 'JJS'), ('customer', 'NN'), ('experience', 'NN'), ('gain', 'NN'), ('competitive', 'JJ'), ('advantage', 'NN'), ('?', '.')]

 (S
  How/WRB
  (NP organization/NN)
  provide/RB
  best/JJS
  (NP customer/NN experience/NN gain/NN)
  (NP competitive/JJ advantage/NN)
  ?/.) 


>> Noun Phrases are: 
 ['organization', 'customer experience gain', 'competitive advantage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('organization', 'organ'), ('provide', 'provid'), ('best', 'best'), ('customer', 'custom'), ('experience', 'experi'), ('gain', 'gain'), ('competitive', 'competit'), ('advantage', 'advantag'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('organization', 'organ'), ('provide', 'provid'), ('best', 'best'), ('customer', 'custom'), ('experience', 'experi'), ('gain', 'gain'), ('competitive', 'competit'), ('advantage', 'advantag'), ('?', '?')]

>> Lemmatization: 
 [('How', 'How'), ('organization', 'organization'), ('provide', 'provide'), ('best', 'best'), ('customer', 'customer'), ('experience', 'experience'), ('gain', 'gain'), ('competitive', 'competitive'), ('advantage', 'advantage'), ('?', '?')]



============================ Sentence 69 =============================

Data analytics help answer these business questions. 


>> Tokens are: 
 ['Data', 'analytics', 'help', 'answer', 'business', 'questions', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'help'), ('help', 'answer'), ('answer', 'business'), ('business', 'questions'), ('questions', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'help'), ('analytics', 'help', 'answer'), ('help', 'answer', 'business'), ('answer', 'business', 'questions'), ('business', 'questions', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('help', 'VBP'), ('answer', 'VB'), ('business', 'NN'), ('questions', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS)
  help/VBP
  answer/VB
  (NP business/NN questions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics', 'business questions']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('answer', 'answer'), ('business', 'busi'), ('questions', 'question'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('answer', 'answer'), ('business', 'busi'), ('questions', 'question'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('help', 'help'), ('answer', 'answer'), ('business', 'business'), ('questions', 'question'), ('.', '.')]



============================ Sentence 70 =============================

Data analytics is the science of analyzing raw data to draw conclusions from that  information. 


>> Tokens are: 
 ['Data', 'analytics', 'science', 'analyzing', 'raw', 'data', 'draw', 'conclusions', 'information', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'science'), ('science', 'analyzing'), ('analyzing', 'raw'), ('raw', 'data'), ('data', 'draw'), ('draw', 'conclusions'), ('conclusions', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'science'), ('analytics', 'science', 'analyzing'), ('science', 'analyzing', 'raw'), ('analyzing', 'raw', 'data'), ('raw', 'data', 'draw'), ('data', 'draw', 'conclusions'), ('draw', 'conclusions', 'information'), ('conclusions', 'information', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('science', 'NN'), ('analyzing', 'VBG'), ('raw', 'JJ'), ('data', 'NNS'), ('draw', 'JJ'), ('conclusions', 'NNS'), ('information', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS science/NN)
  analyzing/VBG
  (NP raw/JJ data/NNS)
  (NP draw/JJ conclusions/NNS information/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics science', 'raw data', 'draw conclusions information']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('science', 'scienc'), ('analyzing', 'analyz'), ('raw', 'raw'), ('data', 'data'), ('draw', 'draw'), ('conclusions', 'conclus'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('science', 'scienc'), ('analyzing', 'analyz'), ('raw', 'raw'), ('data', 'data'), ('draw', 'draw'), ('conclusions', 'conclus'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('science', 'science'), ('analyzing', 'analyzing'), ('raw', 'raw'), ('data', 'data'), ('draw', 'draw'), ('conclusions', 'conclusion'), ('information', 'information'), ('.', '.')]



============================ Sentence 71 =============================

Data analytics techniques can reveal trends and metrics that would  otherwise be lost in a mass of information. 


>> Tokens are: 
 ['Data', 'analytics', 'techniques', 'reveal', 'trends', 'metrics', 'would', 'otherwise', 'lost', 'mass', 'information', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'techniques'), ('techniques', 'reveal'), ('reveal', 'trends'), ('trends', 'metrics'), ('metrics', 'would'), ('would', 'otherwise'), ('otherwise', 'lost'), ('lost', 'mass'), ('mass', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'techniques'), ('analytics', 'techniques', 'reveal'), ('techniques', 'reveal', 'trends'), ('reveal', 'trends', 'metrics'), ('trends', 'metrics', 'would'), ('metrics', 'would', 'otherwise'), ('would', 'otherwise', 'lost'), ('otherwise', 'lost', 'mass'), ('lost', 'mass', 'information'), ('mass', 'information', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('reveal', 'VBP'), ('trends', 'NNS'), ('metrics', 'NNS'), ('would', 'MD'), ('otherwise', 'RB'), ('lost', 'VB'), ('mass', 'NN'), ('information', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS techniques/NNS)
  reveal/VBP
  (NP trends/NNS metrics/NNS)
  would/MD
  otherwise/RB
  lost/VB
  (NP mass/NN information/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics techniques', 'trends metrics', 'mass information']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwis'), ('lost', 'lost'), ('mass', 'mass'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwis'), ('lost', 'lost'), ('mass', 'mass'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('techniques', 'technique'), ('reveal', 'reveal'), ('trends', 'trend'), ('metrics', 'metric'), ('would', 'would'), ('otherwise', 'otherwise'), ('lost', 'lost'), ('mass', 'mass'), ('information', 'information'), ('.', '.')]



============================ Sentence 72 =============================

This information can then be utilized  to optimize processes to increase the overall efficiency of a business or system. 


>> Tokens are: 
 ['This', 'information', 'utilized', 'optimize', 'processes', 'increase', 'overall', 'efficiency', 'business', 'system', '.']

>> Bigrams are: 
 [('This', 'information'), ('information', 'utilized'), ('utilized', 'optimize'), ('optimize', 'processes'), ('processes', 'increase'), ('increase', 'overall'), ('overall', 'efficiency'), ('efficiency', 'business'), ('business', 'system'), ('system', '.')]

>> Trigrams are: 
 [('This', 'information', 'utilized'), ('information', 'utilized', 'optimize'), ('utilized', 'optimize', 'processes'), ('optimize', 'processes', 'increase'), ('processes', 'increase', 'overall'), ('increase', 'overall', 'efficiency'), ('overall', 'efficiency', 'business'), ('efficiency', 'business', 'system'), ('business', 'system', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('information', 'NN'), ('utilized', 'JJ'), ('optimize', 'NN'), ('processes', 'VBZ'), ('increase', 'VB'), ('overall', 'JJ'), ('efficiency', 'NN'), ('business', 'NN'), ('system', 'NN'), ('.', '.')]

 (S
  (NP This/DT information/NN)
  (NP utilized/JJ optimize/NN)
  processes/VBZ
  increase/VB
  (NP overall/JJ efficiency/NN business/NN system/NN)
  ./.) 


>> Noun Phrases are: 
 ['This information', 'utilized optimize', 'overall efficiency business system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('information', 'inform'), ('utilized', 'util'), ('optimize', 'optim'), ('processes', 'process'), ('increase', 'increas'), ('overall', 'overal'), ('efficiency', 'effici'), ('business', 'busi'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('information', 'inform'), ('utilized', 'util'), ('optimize', 'optim'), ('processes', 'process'), ('increase', 'increas'), ('overall', 'overal'), ('efficiency', 'effici'), ('business', 'busi'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('information', 'information'), ('utilized', 'utilized'), ('optimize', 'optimize'), ('processes', 'process'), ('increase', 'increase'), ('overall', 'overall'), ('efficiency', 'efficiency'), ('business', 'business'), ('system', 'system'), ('.', '.')]



============================ Sentence 73 =============================

Data analytics techniques can be broken down into four main types based on the  difficulty of analysis and business value. 


>> Tokens are: 
 ['Data', 'analytics', 'techniques', 'broken', 'four', 'main', 'types', 'based', 'difficulty', 'analysis', 'business', 'value', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'techniques'), ('techniques', 'broken'), ('broken', 'four'), ('four', 'main'), ('main', 'types'), ('types', 'based'), ('based', 'difficulty'), ('difficulty', 'analysis'), ('analysis', 'business'), ('business', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'techniques'), ('analytics', 'techniques', 'broken'), ('techniques', 'broken', 'four'), ('broken', 'four', 'main'), ('four', 'main', 'types'), ('main', 'types', 'based'), ('types', 'based', 'difficulty'), ('based', 'difficulty', 'analysis'), ('difficulty', 'analysis', 'business'), ('analysis', 'business', 'value'), ('business', 'value', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('broken', 'VBP'), ('four', 'CD'), ('main', 'JJ'), ('types', 'NNS'), ('based', 'VBN'), ('difficulty', 'NN'), ('analysis', 'NN'), ('business', 'NN'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS techniques/NNS)
  broken/VBP
  four/CD
  (NP main/JJ types/NNS)
  based/VBN
  (NP difficulty/NN analysis/NN business/NN value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics techniques', 'main types', 'difficulty analysis business value']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'base'), ('difficulty', 'difficulti'), ('analysis', 'analysi'), ('business', 'busi'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'base'), ('difficulty', 'difficulti'), ('analysis', 'analysi'), ('business', 'busi'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('techniques', 'technique'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'based'), ('difficulty', 'difficulty'), ('analysis', 'analysis'), ('business', 'business'), ('value', 'value'), ('.', '.')]



============================ Sentence 74 =============================

a.  Descriptive analytics parses raw historical data and draws conclusion that help  managers, investors and others determine why business changes occurred. 


>> Tokens are: 
 ['a.', 'Descriptive', 'analytics', 'parses', 'raw', 'historical', 'data', 'draws', 'conclusion', 'help', 'managers', ',', 'investors', 'others', 'determine', 'business', 'changes', 'occurred', '.']

>> Bigrams are: 
 [('a.', 'Descriptive'), ('Descriptive', 'analytics'), ('analytics', 'parses'), ('parses', 'raw'), ('raw', 'historical'), ('historical', 'data'), ('data', 'draws'), ('draws', 'conclusion'), ('conclusion', 'help'), ('help', 'managers'), ('managers', ','), (',', 'investors'), ('investors', 'others'), ('others', 'determine'), ('determine', 'business'), ('business', 'changes'), ('changes', 'occurred'), ('occurred', '.')]

>> Trigrams are: 
 [('a.', 'Descriptive', 'analytics'), ('Descriptive', 'analytics', 'parses'), ('analytics', 'parses', 'raw'), ('parses', 'raw', 'historical'), ('raw', 'historical', 'data'), ('historical', 'data', 'draws'), ('data', 'draws', 'conclusion'), ('draws', 'conclusion', 'help'), ('conclusion', 'help', 'managers'), ('help', 'managers', ','), ('managers', ',', 'investors'), (',', 'investors', 'others'), ('investors', 'others', 'determine'), ('others', 'determine', 'business'), ('determine', 'business', 'changes'), ('business', 'changes', 'occurred'), ('changes', 'occurred', '.')]

>> POS Tags are: 
 [('a.', 'NN'), ('Descriptive', 'NNP'), ('analytics', 'NNS'), ('parses', 'VBZ'), ('raw', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('draws', 'NNS'), ('conclusion', 'NN'), ('help', 'NN'), ('managers', 'NNS'), (',', ','), ('investors', 'NNS'), ('others', 'NNS'), ('determine', 'VBP'), ('business', 'NN'), ('changes', 'NNS'), ('occurred', 'VBD'), ('.', '.')]

 (S
  (NP a./NN Descriptive/NNP analytics/NNS)
  parses/VBZ
  (NP
    raw/JJ
    historical/JJ
    data/NNS
    draws/NNS
    conclusion/NN
    help/NN
    managers/NNS)
  ,/,
  (NP investors/NNS others/NNS)
  determine/VBP
  (NP business/NN changes/NNS)
  occurred/VBD
  ./.) 


>> Noun Phrases are: 
 ['a. Descriptive analytics', 'raw historical data draws conclusion help managers', 'investors others', 'business changes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a.', 'a.'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('parses', 'pars'), ('raw', 'raw'), ('historical', 'histor'), ('data', 'data'), ('draws', 'draw'), ('conclusion', 'conclus'), ('help', 'help'), ('managers', 'manag'), (',', ','), ('investors', 'investor'), ('others', 'other'), ('determine', 'determin'), ('business', 'busi'), ('changes', 'chang'), ('occurred', 'occur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('a.', 'a.'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('parses', 'pars'), ('raw', 'raw'), ('historical', 'histor'), ('data', 'data'), ('draws', 'draw'), ('conclusion', 'conclus'), ('help', 'help'), ('managers', 'manag'), (',', ','), ('investors', 'investor'), ('others', 'other'), ('determine', 'determin'), ('business', 'busi'), ('changes', 'chang'), ('occurred', 'occur'), ('.', '.')]

>> Lemmatization: 
 [('a.', 'a.'), ('Descriptive', 'Descriptive'), ('analytics', 'analytics'), ('parses', 'par'), ('raw', 'raw'), ('historical', 'historical'), ('data', 'data'), ('draws', 'draw'), ('conclusion', 'conclusion'), ('help', 'help'), ('managers', 'manager'), (',', ','), ('investors', 'investor'), ('others', 'others'), ('determine', 'determine'), ('business', 'business'), ('changes', 'change'), ('occurred', 'occurred'), ('.', '.')]



============================ Sentence 75 =============================

b. 


>> Tokens are: 
 ['b', '.']

>> Bigrams are: 
 [('b', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('b', 'NN'), ('.', '.')]

 (S (NP b/NN) ./.) 


>> Noun Phrases are: 
 ['b']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), ('.', '.')]



============================ Sentence 76 =============================

Diagnostic analytics provides an understanding of why events took place  by examining data. 


>> Tokens are: 
 ['Diagnostic', 'analytics', 'provides', 'understanding', 'events', 'took', 'place', 'examining', 'data', '.']

>> Bigrams are: 
 [('Diagnostic', 'analytics'), ('analytics', 'provides'), ('provides', 'understanding'), ('understanding', 'events'), ('events', 'took'), ('took', 'place'), ('place', 'examining'), ('examining', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Diagnostic', 'analytics', 'provides'), ('analytics', 'provides', 'understanding'), ('provides', 'understanding', 'events'), ('understanding', 'events', 'took'), ('events', 'took', 'place'), ('took', 'place', 'examining'), ('place', 'examining', 'data'), ('examining', 'data', '.')]

>> POS Tags are: 
 [('Diagnostic', 'JJ'), ('analytics', 'NNS'), ('provides', 'VBZ'), ('understanding', 'JJ'), ('events', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('examining', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Diagnostic/JJ analytics/NNS)
  provides/VBZ
  (NP understanding/JJ events/NNS)
  took/VBD
  (NP place/NN)
  examining/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Diagnostic analytics', 'understanding events', 'place', 'data']

>> Named Entities are: 
 [('GPE', 'Diagnostic')] 

>> Stemming using Porter Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('provides', 'provid'), ('understanding', 'understand'), ('events', 'event'), ('took', 'took'), ('place', 'place'), ('examining', 'examin'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('provides', 'provid'), ('understanding', 'understand'), ('events', 'event'), ('took', 'took'), ('place', 'place'), ('examining', 'examin'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Diagnostic', 'Diagnostic'), ('analytics', 'analytics'), ('provides', 'provides'), ('understanding', 'understanding'), ('events', 'event'), ('took', 'took'), ('place', 'place'), ('examining', 'examining'), ('data', 'data'), ('.', '.')]



============================ Sentence 77 =============================

A type of advanced analytics, techniques include data  discovery and mining, correlation analysis and drill-down. 


>> Tokens are: 
 ['A', 'type', 'advanced', 'analytics', ',', 'techniques', 'include', 'data', 'discovery', 'mining', ',', 'correlation', 'analysis', 'drill-down', '.']

>> Bigrams are: 
 [('A', 'type'), ('type', 'advanced'), ('advanced', 'analytics'), ('analytics', ','), (',', 'techniques'), ('techniques', 'include'), ('include', 'data'), ('data', 'discovery'), ('discovery', 'mining'), ('mining', ','), (',', 'correlation'), ('correlation', 'analysis'), ('analysis', 'drill-down'), ('drill-down', '.')]

>> Trigrams are: 
 [('A', 'type', 'advanced'), ('type', 'advanced', 'analytics'), ('advanced', 'analytics', ','), ('analytics', ',', 'techniques'), (',', 'techniques', 'include'), ('techniques', 'include', 'data'), ('include', 'data', 'discovery'), ('data', 'discovery', 'mining'), ('discovery', 'mining', ','), ('mining', ',', 'correlation'), (',', 'correlation', 'analysis'), ('correlation', 'analysis', 'drill-down'), ('analysis', 'drill-down', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('type', 'NN'), ('advanced', 'JJ'), ('analytics', 'NNS'), (',', ','), ('techniques', 'NNS'), ('include', 'VBP'), ('data', 'NNS'), ('discovery', 'NN'), ('mining', 'NN'), (',', ','), ('correlation', 'NN'), ('analysis', 'NN'), ('drill-down', 'NN'), ('.', '.')]

 (S
  (NP A/DT type/NN)
  (NP advanced/JJ analytics/NNS)
  ,/,
  (NP techniques/NNS)
  include/VBP
  (NP data/NNS discovery/NN mining/NN)
  ,/,
  (NP correlation/NN analysis/NN drill-down/NN)
  ./.) 


>> Noun Phrases are: 
 ['A type', 'advanced analytics', 'techniques', 'data discovery mining', 'correlation analysis drill-down']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('type', 'type'), ('advanced', 'advanc'), ('analytics', 'analyt'), (',', ','), ('techniques', 'techniqu'), ('include', 'includ'), ('data', 'data'), ('discovery', 'discoveri'), ('mining', 'mine'), (',', ','), ('correlation', 'correl'), ('analysis', 'analysi'), ('drill-down', 'drill-down'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('type', 'type'), ('advanced', 'advanc'), ('analytics', 'analyt'), (',', ','), ('techniques', 'techniqu'), ('include', 'includ'), ('data', 'data'), ('discovery', 'discoveri'), ('mining', 'mine'), (',', ','), ('correlation', 'correl'), ('analysis', 'analysi'), ('drill-down', 'drill-down'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('type', 'type'), ('advanced', 'advanced'), ('analytics', 'analytics'), (',', ','), ('techniques', 'technique'), ('include', 'include'), ('data', 'data'), ('discovery', 'discovery'), ('mining', 'mining'), (',', ','), ('correlation', 'correlation'), ('analysis', 'analysis'), ('drill-down', 'drill-down'), ('.', '.')]



============================ Sentence 78 =============================

c.  Predictive analytics uses statistics and modeling to predict future behavior. 


>> Tokens are: 
 ['c.', 'Predictive', 'analytics', 'uses', 'statistics', 'modeling', 'predict', 'future', 'behavior', '.']

>> Bigrams are: 
 [('c.', 'Predictive'), ('Predictive', 'analytics'), ('analytics', 'uses'), ('uses', 'statistics'), ('statistics', 'modeling'), ('modeling', 'predict'), ('predict', 'future'), ('future', 'behavior'), ('behavior', '.')]

>> Trigrams are: 
 [('c.', 'Predictive', 'analytics'), ('Predictive', 'analytics', 'uses'), ('analytics', 'uses', 'statistics'), ('uses', 'statistics', 'modeling'), ('statistics', 'modeling', 'predict'), ('modeling', 'predict', 'future'), ('predict', 'future', 'behavior'), ('future', 'behavior', '.')]

>> POS Tags are: 
 [('c.', 'NN'), ('Predictive', 'NNP'), ('analytics', 'NNS'), ('uses', 'VBZ'), ('statistics', 'NNS'), ('modeling', 'VBG'), ('predict', 'JJ'), ('future', 'JJ'), ('behavior', 'NN'), ('.', '.')]

 (S
  (NP c./NN Predictive/NNP analytics/NNS)
  uses/VBZ
  (NP statistics/NNS)
  modeling/VBG
  (NP predict/JJ future/JJ behavior/NN)
  ./.) 


>> Noun Phrases are: 
 ['c. Predictive analytics', 'statistics', 'predict future behavior']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('c.', 'c.'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('uses', 'use'), ('statistics', 'statist'), ('modeling', 'model'), ('predict', 'predict'), ('future', 'futur'), ('behavior', 'behavior'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('c.', 'c.'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('uses', 'use'), ('statistics', 'statist'), ('modeling', 'model'), ('predict', 'predict'), ('future', 'futur'), ('behavior', 'behavior'), ('.', '.')]

>> Lemmatization: 
 [('c.', 'c.'), ('Predictive', 'Predictive'), ('analytics', 'analytics'), ('uses', 'us'), ('statistics', 'statistic'), ('modeling', 'modeling'), ('predict', 'predict'), ('future', 'future'), ('behavior', 'behavior'), ('.', '.')]



============================ Sentence 79 =============================

Using  data patterns, predictive analytics identifies when patterns are likely to reoccur  to identify and prevent potential risks, take advantage of future opportunities or  advantageously reallocate resources. 


>> Tokens are: 
 ['Using', 'data', 'patterns', ',', 'predictive', 'analytics', 'identifies', 'patterns', 'likely', 'reoccur', 'identify', 'prevent', 'potential', 'risks', ',', 'take', 'advantage', 'future', 'opportunities', 'advantageously', 'reallocate', 'resources', '.']

>> Bigrams are: 
 [('Using', 'data'), ('data', 'patterns'), ('patterns', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', 'identifies'), ('identifies', 'patterns'), ('patterns', 'likely'), ('likely', 'reoccur'), ('reoccur', 'identify'), ('identify', 'prevent'), ('prevent', 'potential'), ('potential', 'risks'), ('risks', ','), (',', 'take'), ('take', 'advantage'), ('advantage', 'future'), ('future', 'opportunities'), ('opportunities', 'advantageously'), ('advantageously', 'reallocate'), ('reallocate', 'resources'), ('resources', '.')]

>> Trigrams are: 
 [('Using', 'data', 'patterns'), ('data', 'patterns', ','), ('patterns', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', 'identifies'), ('analytics', 'identifies', 'patterns'), ('identifies', 'patterns', 'likely'), ('patterns', 'likely', 'reoccur'), ('likely', 'reoccur', 'identify'), ('reoccur', 'identify', 'prevent'), ('identify', 'prevent', 'potential'), ('prevent', 'potential', 'risks'), ('potential', 'risks', ','), ('risks', ',', 'take'), (',', 'take', 'advantage'), ('take', 'advantage', 'future'), ('advantage', 'future', 'opportunities'), ('future', 'opportunities', 'advantageously'), ('opportunities', 'advantageously', 'reallocate'), ('advantageously', 'reallocate', 'resources'), ('reallocate', 'resources', '.')]

>> POS Tags are: 
 [('Using', 'VBG'), ('data', 'NNS'), ('patterns', 'NNS'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), ('identifies', 'NNS'), ('patterns', 'VBP'), ('likely', 'JJ'), ('reoccur', 'NN'), ('identify', 'VB'), ('prevent', 'JJ'), ('potential', 'JJ'), ('risks', 'NNS'), (',', ','), ('take', 'VBP'), ('advantage', 'JJ'), ('future', 'NN'), ('opportunities', 'NNS'), ('advantageously', 'RB'), ('reallocate', 'JJ'), ('resources', 'NNS'), ('.', '.')]

 (S
  Using/VBG
  (NP data/NNS patterns/NNS)
  ,/,
  (NP predictive/JJ analytics/NNS identifies/NNS)
  patterns/VBP
  (NP likely/JJ reoccur/NN)
  identify/VB
  (NP prevent/JJ potential/JJ risks/NNS)
  ,/,
  take/VBP
  (NP advantage/JJ future/NN opportunities/NNS)
  advantageously/RB
  (NP reallocate/JJ resources/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data patterns', 'predictive analytics identifies', 'likely reoccur', 'prevent potential risks', 'advantage future opportunities', 'reallocate resources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('data', 'data'), ('patterns', 'pattern'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), ('identifies', 'identifi'), ('patterns', 'pattern'), ('likely', 'like'), ('reoccur', 'reoccur'), ('identify', 'identifi'), ('prevent', 'prevent'), ('potential', 'potenti'), ('risks', 'risk'), (',', ','), ('take', 'take'), ('advantage', 'advantag'), ('future', 'futur'), ('opportunities', 'opportun'), ('advantageously', 'advantag'), ('reallocate', 'realloc'), ('resources', 'resourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('data', 'data'), ('patterns', 'pattern'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), ('identifies', 'identifi'), ('patterns', 'pattern'), ('likely', 'like'), ('reoccur', 'reoccur'), ('identify', 'identifi'), ('prevent', 'prevent'), ('potential', 'potenti'), ('risks', 'risk'), (',', ','), ('take', 'take'), ('advantage', 'advantag'), ('future', 'futur'), ('opportunities', 'opportun'), ('advantageously', 'advantag'), ('reallocate', 'realloc'), ('resources', 'resourc'), ('.', '.')]

>> Lemmatization: 
 [('Using', 'Using'), ('data', 'data'), ('patterns', 'pattern'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), ('identifies', 'identifies'), ('patterns', 'pattern'), ('likely', 'likely'), ('reoccur', 'reoccur'), ('identify', 'identify'), ('prevent', 'prevent'), ('potential', 'potential'), ('risks', 'risk'), (',', ','), ('take', 'take'), ('advantage', 'advantage'), ('future', 'future'), ('opportunities', 'opportunity'), ('advantageously', 'advantageously'), ('reallocate', 'reallocate'), ('resources', 'resource'), ('.', '.')]



============================ Sentence 80 =============================

d.  Prescriptive analytics uses machine learning to analyze raw data to help  organizations make better decision and take a proper course of action. 


>> Tokens are: 
 ['d.', 'Prescriptive', 'analytics', 'uses', 'machine', 'learning', 'analyze', 'raw', 'data', 'help', 'organizations', 'make', 'better', 'decision', 'take', 'proper', 'course', 'action', '.']

>> Bigrams are: 
 [('d.', 'Prescriptive'), ('Prescriptive', 'analytics'), ('analytics', 'uses'), ('uses', 'machine'), ('machine', 'learning'), ('learning', 'analyze'), ('analyze', 'raw'), ('raw', 'data'), ('data', 'help'), ('help', 'organizations'), ('organizations', 'make'), ('make', 'better'), ('better', 'decision'), ('decision', 'take'), ('take', 'proper'), ('proper', 'course'), ('course', 'action'), ('action', '.')]

>> Trigrams are: 
 [('d.', 'Prescriptive', 'analytics'), ('Prescriptive', 'analytics', 'uses'), ('analytics', 'uses', 'machine'), ('uses', 'machine', 'learning'), ('machine', 'learning', 'analyze'), ('learning', 'analyze', 'raw'), ('analyze', 'raw', 'data'), ('raw', 'data', 'help'), ('data', 'help', 'organizations'), ('help', 'organizations', 'make'), ('organizations', 'make', 'better'), ('make', 'better', 'decision'), ('better', 'decision', 'take'), ('decision', 'take', 'proper'), ('take', 'proper', 'course'), ('proper', 'course', 'action'), ('course', 'action', '.')]

>> POS Tags are: 
 [('d.', 'RB'), ('Prescriptive', 'JJ'), ('analytics', 'NNS'), ('uses', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('analyze', 'JJ'), ('raw', 'JJ'), ('data', 'NN'), ('help', 'NN'), ('organizations', 'NNS'), ('make', 'VBP'), ('better', 'JJR'), ('decision', 'NN'), ('take', 'VB'), ('proper', 'JJ'), ('course', 'NN'), ('action', 'NN'), ('.', '.')]

 (S
  d./RB
  (NP Prescriptive/JJ analytics/NNS)
  uses/VBZ
  (NP machine/NN)
  learning/VBG
  (NP analyze/JJ raw/JJ data/NN help/NN organizations/NNS)
  make/VBP
  better/JJR
  (NP decision/NN)
  take/VB
  (NP proper/JJ course/NN action/NN)
  ./.) 


>> Noun Phrases are: 
 ['Prescriptive analytics', 'machine', 'analyze raw data help organizations', 'decision', 'proper course action']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('d.', 'd.'), ('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('uses', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('analyze', 'analyz'), ('raw', 'raw'), ('data', 'data'), ('help', 'help'), ('organizations', 'organ'), ('make', 'make'), ('better', 'better'), ('decision', 'decis'), ('take', 'take'), ('proper', 'proper'), ('course', 'cours'), ('action', 'action'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('d.', 'd.'), ('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('uses', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('analyze', 'analyz'), ('raw', 'raw'), ('data', 'data'), ('help', 'help'), ('organizations', 'organ'), ('make', 'make'), ('better', 'better'), ('decision', 'decis'), ('take', 'take'), ('proper', 'proper'), ('course', 'cours'), ('action', 'action'), ('.', '.')]

>> Lemmatization: 
 [('d.', 'd.'), ('Prescriptive', 'Prescriptive'), ('analytics', 'analytics'), ('uses', 'us'), ('machine', 'machine'), ('learning', 'learning'), ('analyze', 'analyze'), ('raw', 'raw'), ('data', 'data'), ('help', 'help'), ('organizations', 'organization'), ('make', 'make'), ('better', 'better'), ('decision', 'decision'), ('take', 'take'), ('proper', 'proper'), ('course', 'course'), ('action', 'action'), ('.', '.')]



============================ Sentence 81 =============================

Factoring  in possible scenarios, available resources, past performance and current  performance, prescriptive analytics help determine the best course of action in  a situation. 


>> Tokens are: 
 ['Factoring', 'possible', 'scenarios', ',', 'available', 'resources', ',', 'past', 'performance', 'current', 'performance', ',', 'prescriptive', 'analytics', 'help', 'determine', 'best', 'course', 'action', 'situation', '.']

>> Bigrams are: 
 [('Factoring', 'possible'), ('possible', 'scenarios'), ('scenarios', ','), (',', 'available'), ('available', 'resources'), ('resources', ','), (',', 'past'), ('past', 'performance'), ('performance', 'current'), ('current', 'performance'), ('performance', ','), (',', 'prescriptive'), ('prescriptive', 'analytics'), ('analytics', 'help'), ('help', 'determine'), ('determine', 'best'), ('best', 'course'), ('course', 'action'), ('action', 'situation'), ('situation', '.')]

>> Trigrams are: 
 [('Factoring', 'possible', 'scenarios'), ('possible', 'scenarios', ','), ('scenarios', ',', 'available'), (',', 'available', 'resources'), ('available', 'resources', ','), ('resources', ',', 'past'), (',', 'past', 'performance'), ('past', 'performance', 'current'), ('performance', 'current', 'performance'), ('current', 'performance', ','), ('performance', ',', 'prescriptive'), (',', 'prescriptive', 'analytics'), ('prescriptive', 'analytics', 'help'), ('analytics', 'help', 'determine'), ('help', 'determine', 'best'), ('determine', 'best', 'course'), ('best', 'course', 'action'), ('course', 'action', 'situation'), ('action', 'situation', '.')]

>> POS Tags are: 
 [('Factoring', 'VBG'), ('possible', 'JJ'), ('scenarios', 'NNS'), (',', ','), ('available', 'JJ'), ('resources', 'NNS'), (',', ','), ('past', 'JJ'), ('performance', 'NN'), ('current', 'JJ'), ('performance', 'NN'), (',', ','), ('prescriptive', 'JJ'), ('analytics', 'NNS'), ('help', 'VBP'), ('determine', 'VB'), ('best', 'JJS'), ('course', 'NN'), ('action', 'NN'), ('situation', 'NN'), ('.', '.')]

 (S
  Factoring/VBG
  (NP possible/JJ scenarios/NNS)
  ,/,
  (NP available/JJ resources/NNS)
  ,/,
  (NP past/JJ performance/NN)
  (NP current/JJ performance/NN)
  ,/,
  (NP prescriptive/JJ analytics/NNS)
  help/VBP
  determine/VB
  best/JJS
  (NP course/NN action/NN situation/NN)
  ./.) 


>> Noun Phrases are: 
 ['possible scenarios', 'available resources', 'past performance', 'current performance', 'prescriptive analytics', 'course action situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Factoring', 'factor'), ('possible', 'possibl'), ('scenarios', 'scenario'), (',', ','), ('available', 'avail'), ('resources', 'resourc'), (',', ','), ('past', 'past'), ('performance', 'perform'), ('current', 'current'), ('performance', 'perform'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('help', 'help'), ('determine', 'determin'), ('best', 'best'), ('course', 'cours'), ('action', 'action'), ('situation', 'situat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Factoring', 'factor'), ('possible', 'possibl'), ('scenarios', 'scenario'), (',', ','), ('available', 'avail'), ('resources', 'resourc'), (',', ','), ('past', 'past'), ('performance', 'perform'), ('current', 'current'), ('performance', 'perform'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('help', 'help'), ('determine', 'determin'), ('best', 'best'), ('course', 'cours'), ('action', 'action'), ('situation', 'situat'), ('.', '.')]

>> Lemmatization: 
 [('Factoring', 'Factoring'), ('possible', 'possible'), ('scenarios', 'scenario'), (',', ','), ('available', 'available'), ('resources', 'resource'), (',', ','), ('past', 'past'), ('performance', 'performance'), ('current', 'current'), ('performance', 'performance'), (',', ','), ('prescriptive', 'prescriptive'), ('analytics', 'analytics'), ('help', 'help'), ('determine', 'determine'), ('best', 'best'), ('course', 'course'), ('action', 'action'), ('situation', 'situation'), ('.', '.')]



============================ Sentence 82 =============================

Data analytics techniques can be broken down  into four main types based on the difficulty of  analysis and business value:  a.  Descriptive analytics. 


>> Tokens are: 
 ['Data', 'analytics', 'techniques', 'broken', 'four', 'main', 'types', 'based', 'difficulty', 'analysis', 'business', 'value', ':', 'a.', 'Descriptive', 'analytics', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'techniques'), ('techniques', 'broken'), ('broken', 'four'), ('four', 'main'), ('main', 'types'), ('types', 'based'), ('based', 'difficulty'), ('difficulty', 'analysis'), ('analysis', 'business'), ('business', 'value'), ('value', ':'), (':', 'a.'), ('a.', 'Descriptive'), ('Descriptive', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'techniques'), ('analytics', 'techniques', 'broken'), ('techniques', 'broken', 'four'), ('broken', 'four', 'main'), ('four', 'main', 'types'), ('main', 'types', 'based'), ('types', 'based', 'difficulty'), ('based', 'difficulty', 'analysis'), ('difficulty', 'analysis', 'business'), ('analysis', 'business', 'value'), ('business', 'value', ':'), ('value', ':', 'a.'), (':', 'a.', 'Descriptive'), ('a.', 'Descriptive', 'analytics'), ('Descriptive', 'analytics', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('broken', 'VBP'), ('four', 'CD'), ('main', 'JJ'), ('types', 'NNS'), ('based', 'VBN'), ('difficulty', 'NN'), ('analysis', 'NN'), ('business', 'NN'), ('value', 'NN'), (':', ':'), ('a.', 'NN'), ('Descriptive', 'NNP'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP analytics/NNS techniques/NNS)
  broken/VBP
  four/CD
  (NP main/JJ types/NNS)
  based/VBN
  (NP difficulty/NN analysis/NN business/NN value/NN)
  :/:
  (NP a./NN Descriptive/NNP analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data analytics techniques', 'main types', 'difficulty analysis business value', 'a. Descriptive analytics']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'base'), ('difficulty', 'difficulti'), ('analysis', 'analysi'), ('business', 'busi'), ('value', 'valu'), (':', ':'), ('a.', 'a.'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'base'), ('difficulty', 'difficulti'), ('analysis', 'analysi'), ('business', 'busi'), ('value', 'valu'), (':', ':'), ('a.', 'a.'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('techniques', 'technique'), ('broken', 'broken'), ('four', 'four'), ('main', 'main'), ('types', 'type'), ('based', 'based'), ('difficulty', 'difficulty'), ('analysis', 'analysis'), ('business', 'business'), ('value', 'value'), (':', ':'), ('a.', 'a.'), ('Descriptive', 'Descriptive'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 83 =============================

What happened? 


>> Tokens are: 
 ['What', 'happened', '?']

>> Bigrams are: 
 [('What', 'happened'), ('happened', '?')]

>> Trigrams are: 
 [('What', 'happened', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('happened', 'VBD'), ('?', '.')]

 (S What/WP happened/VBD ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('happened', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('happened', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('happened', 'happened'), ('?', '?')]



============================ Sentence 84 =============================

b. 


>> Tokens are: 
 ['b', '.']

>> Bigrams are: 
 [('b', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('b', 'NN'), ('.', '.')]

 (S (NP b/NN) ./.) 


>> Noun Phrases are: 
 ['b']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), ('.', '.')]



============================ Sentence 85 =============================

Diagnostic analytics. 


>> Tokens are: 
 ['Diagnostic', 'analytics', '.']

>> Bigrams are: 
 [('Diagnostic', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Diagnostic', 'analytics', '.')]

>> POS Tags are: 
 [('Diagnostic', 'JJ'), ('analytics', 'NNS'), ('.', '.')]

 (S (NP Diagnostic/JJ analytics/NNS) ./.) 


>> Noun Phrases are: 
 ['Diagnostic analytics']

>> Named Entities are: 
 [('GPE', 'Diagnostic')] 

>> Stemming using Porter Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Diagnostic', 'Diagnostic'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 86 =============================

Why did it happen? 


>> Tokens are: 
 ['Why', 'happen', '?']

>> Bigrams are: 
 [('Why', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('Why', 'happen', '?')]

>> POS Tags are: 
 [('Why', 'WRB'), ('happen', 'VB'), ('?', '.')]

 (S Why/WRB happen/VB ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Why', 'whi'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Why', 'whi'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('Why', 'Why'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 87 =============================

c.  Predictive analytics. 


>> Tokens are: 
 ['c.', 'Predictive', 'analytics', '.']

>> Bigrams are: 
 [('c.', 'Predictive'), ('Predictive', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('c.', 'Predictive', 'analytics'), ('Predictive', 'analytics', '.')]

>> POS Tags are: 
 [('c.', 'NN'), ('Predictive', 'NNP'), ('analytics', 'NNS'), ('.', '.')]

 (S (NP c./NN Predictive/NNP analytics/NNS) ./.) 


>> Noun Phrases are: 
 ['c. Predictive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('c.', 'c.'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('c.', 'c.'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('c.', 'c.'), ('Predictive', 'Predictive'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 88 =============================

What will happen? 


>> Tokens are: 
 ['What', 'happen', '?']

>> Bigrams are: 
 [('What', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('What', 'happen', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('happen', 'VB'), ('?', '.')]

 (S What/WP happen/VB ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 89 =============================

d.  Prescriptive analytics. 


>> Tokens are: 
 ['d.', 'Prescriptive', 'analytics', '.']

>> Bigrams are: 
 [('d.', 'Prescriptive'), ('Prescriptive', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('d.', 'Prescriptive', 'analytics'), ('Prescriptive', 'analytics', '.')]

>> POS Tags are: 
 [('d.', 'RB'), ('Prescriptive', 'JJ'), ('analytics', 'NNS'), ('.', '.')]

 (S d./RB (NP Prescriptive/JJ analytics/NNS) ./.) 


>> Noun Phrases are: 
 ['Prescriptive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('d.', 'd.'), ('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('d.', 'd.'), ('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('d.', 'd.'), ('Prescriptive', 'Prescriptive'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 90 =============================

How can we make it  happen? 


>> Tokens are: 
 ['How', 'make', 'happen', '?']

>> Bigrams are: 
 [('How', 'make'), ('make', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('How', 'make', 'happen'), ('make', 'happen', '?')]

>> POS Tags are: 
 [('How', 'WRB'), ('make', 'VB'), ('happen', 'VB'), ('?', '.')]

 (S How/WRB make/VB happen/VB ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('How', 'How'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 91 =============================

Business value  Difficulty  Predictive analytics What will happen? 


>> Tokens are: 
 ['Business', 'value', 'Difficulty', 'Predictive', 'analytics', 'What', 'happen', '?']

>> Bigrams are: 
 [('Business', 'value'), ('value', 'Difficulty'), ('Difficulty', 'Predictive'), ('Predictive', 'analytics'), ('analytics', 'What'), ('What', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('Business', 'value', 'Difficulty'), ('value', 'Difficulty', 'Predictive'), ('Difficulty', 'Predictive', 'analytics'), ('Predictive', 'analytics', 'What'), ('analytics', 'What', 'happen'), ('What', 'happen', '?')]

>> POS Tags are: 
 [('Business', 'NN'), ('value', 'NN'), ('Difficulty', 'NNP'), ('Predictive', 'NNP'), ('analytics', 'NNS'), ('What', 'WP'), ('happen', 'VB'), ('?', '.')]

 (S
  (NP
    Business/NN
    value/NN
    Difficulty/NNP
    Predictive/NNP
    analytics/NNS)
  What/WP
  happen/VB
  ?/.) 


>> Noun Phrases are: 
 ['Business value Difficulty Predictive analytics']

>> Named Entities are: 
 [('GPE', 'Business'), ('PERSON', 'Difficulty')] 

>> Stemming using Porter Stemmer: 
 [('Business', 'busi'), ('value', 'valu'), ('Difficulty', 'difficulti'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('What', 'what'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Business', 'busi'), ('value', 'valu'), ('Difficulty', 'difficulti'), ('Predictive', 'predict'), ('analytics', 'analyt'), ('What', 'what'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('Business', 'Business'), ('value', 'value'), ('Difficulty', 'Difficulty'), ('Predictive', 'Predictive'), ('analytics', 'analytics'), ('What', 'What'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 92 =============================

Prescriptive  analytics  How can we  make it happen? 


>> Tokens are: 
 ['Prescriptive', 'analytics', 'How', 'make', 'happen', '?']

>> Bigrams are: 
 [('Prescriptive', 'analytics'), ('analytics', 'How'), ('How', 'make'), ('make', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('Prescriptive', 'analytics', 'How'), ('analytics', 'How', 'make'), ('How', 'make', 'happen'), ('make', 'happen', '?')]

>> POS Tags are: 
 [('Prescriptive', 'JJ'), ('analytics', 'NNS'), ('How', 'WRB'), ('make', 'VB'), ('happen', 'VB'), ('?', '.')]

 (S (NP Prescriptive/JJ analytics/NNS) How/WRB make/VB happen/VB ?/.) 


>> Noun Phrases are: 
 ['Prescriptive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('How', 'how'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Prescriptive', 'prescript'), ('analytics', 'analyt'), ('How', 'how'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('Prescriptive', 'Prescriptive'), ('analytics', 'analytics'), ('How', 'How'), ('make', 'make'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 93 =============================

Diagnostic analytics   Why did it happen? 


>> Tokens are: 
 ['Diagnostic', 'analytics', 'Why', 'happen', '?']

>> Bigrams are: 
 [('Diagnostic', 'analytics'), ('analytics', 'Why'), ('Why', 'happen'), ('happen', '?')]

>> Trigrams are: 
 [('Diagnostic', 'analytics', 'Why'), ('analytics', 'Why', 'happen'), ('Why', 'happen', '?')]

>> POS Tags are: 
 [('Diagnostic', 'JJ'), ('analytics', 'NNS'), ('Why', 'WRB'), ('happen', 'VB'), ('?', '.')]

 (S (NP Diagnostic/JJ analytics/NNS) Why/WRB happen/VB ?/.) 


>> Noun Phrases are: 
 ['Diagnostic analytics']

>> Named Entities are: 
 [('GPE', 'Diagnostic')] 

>> Stemming using Porter Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('Why', 'whi'), ('happen', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Diagnostic', 'diagnost'), ('analytics', 'analyt'), ('Why', 'whi'), ('happen', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('Diagnostic', 'Diagnostic'), ('analytics', 'analytics'), ('Why', 'Why'), ('happen', 'happen'), ('?', '?')]



============================ Sentence 94 =============================

Descriptive analytics  What happened? 


>> Tokens are: 
 ['Descriptive', 'analytics', 'What', 'happened', '?']

>> Bigrams are: 
 [('Descriptive', 'analytics'), ('analytics', 'What'), ('What', 'happened'), ('happened', '?')]

>> Trigrams are: 
 [('Descriptive', 'analytics', 'What'), ('analytics', 'What', 'happened'), ('What', 'happened', '?')]

>> POS Tags are: 
 [('Descriptive', 'JJ'), ('analytics', 'NNS'), ('What', 'WP'), ('happened', 'VBD'), ('?', '.')]

 (S (NP Descriptive/JJ analytics/NNS) What/WP happened/VBD ?/.) 


>> Noun Phrases are: 
 ['Descriptive analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Descriptive', 'descript'), ('analytics', 'analyt'), ('What', 'what'), ('happened', 'happen'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Descriptive', 'descript'), ('analytics', 'analyt'), ('What', 'what'), ('happened', 'happen'), ('?', '?')]

>> Lemmatization: 
 [('Descriptive', 'Descriptive'), ('analytics', 'analytics'), ('What', 'What'), ('happened', 'happened'), ('?', '?')]



============================ Sentence 95 =============================

7/14Demystifying data science   What are the requirements for adopting AI? 


>> Tokens are: 
 ['7/14Demystifying', 'data', 'science', 'What', 'requirements', 'adopting', 'AI', '?']

>> Bigrams are: 
 [('7/14Demystifying', 'data'), ('data', 'science'), ('science', 'What'), ('What', 'requirements'), ('requirements', 'adopting'), ('adopting', 'AI'), ('AI', '?')]

>> Trigrams are: 
 [('7/14Demystifying', 'data', 'science'), ('data', 'science', 'What'), ('science', 'What', 'requirements'), ('What', 'requirements', 'adopting'), ('requirements', 'adopting', 'AI'), ('adopting', 'AI', '?')]

>> POS Tags are: 
 [('7/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('What', 'WP'), ('requirements', 'NNS'), ('adopting', 'VBG'), ('AI', 'NNP'), ('?', '.')]

 (S
  7/14Demystifying/VBG
  (NP data/NNS science/NN)
  What/WP
  (NP requirements/NNS)
  adopting/VBG
  (NP AI/NNP)
  ?/.) 


>> Noun Phrases are: 
 ['data science', 'requirements', 'AI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7/14Demystifying', '7/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('What', 'what'), ('requirements', 'requir'), ('adopting', 'adopt'), ('AI', 'ai'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('7/14Demystifying', '7/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('What', 'what'), ('requirements', 'requir'), ('adopting', 'adopt'), ('AI', 'ai'), ('?', '?')]

>> Lemmatization: 
 [('7/14Demystifying', '7/14Demystifying'), ('data', 'data'), ('science', 'science'), ('What', 'What'), ('requirements', 'requirement'), ('adopting', 'adopting'), ('AI', 'AI'), ('?', '?')]



============================ Sentence 96 =============================

This hierarchical pyramid explains the competencies every organization requires   to ensure a successful AI implementation. 


>> Tokens are: 
 ['This', 'hierarchical', 'pyramid', 'explains', 'competencies', 'every', 'organization', 'requires', 'ensure', 'successful', 'AI', 'implementation', '.']

>> Bigrams are: 
 [('This', 'hierarchical'), ('hierarchical', 'pyramid'), ('pyramid', 'explains'), ('explains', 'competencies'), ('competencies', 'every'), ('every', 'organization'), ('organization', 'requires'), ('requires', 'ensure'), ('ensure', 'successful'), ('successful', 'AI'), ('AI', 'implementation'), ('implementation', '.')]

>> Trigrams are: 
 [('This', 'hierarchical', 'pyramid'), ('hierarchical', 'pyramid', 'explains'), ('pyramid', 'explains', 'competencies'), ('explains', 'competencies', 'every'), ('competencies', 'every', 'organization'), ('every', 'organization', 'requires'), ('organization', 'requires', 'ensure'), ('requires', 'ensure', 'successful'), ('ensure', 'successful', 'AI'), ('successful', 'AI', 'implementation'), ('AI', 'implementation', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('hierarchical', 'JJ'), ('pyramid', 'NN'), ('explains', 'VBZ'), ('competencies', 'NNS'), ('every', 'DT'), ('organization', 'NN'), ('requires', 'VBZ'), ('ensure', 'VB'), ('successful', 'JJ'), ('AI', 'NNP'), ('implementation', 'NN'), ('.', '.')]

 (S
  (NP This/DT hierarchical/JJ pyramid/NN)
  explains/VBZ
  (NP competencies/NNS)
  (NP every/DT organization/NN)
  requires/VBZ
  ensure/VB
  (NP successful/JJ AI/NNP implementation/NN)
  ./.) 


>> Noun Phrases are: 
 ['This hierarchical pyramid', 'competencies', 'every organization', 'successful AI implementation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('hierarchical', 'hierarch'), ('pyramid', 'pyramid'), ('explains', 'explain'), ('competencies', 'compet'), ('every', 'everi'), ('organization', 'organ'), ('requires', 'requir'), ('ensure', 'ensur'), ('successful', 'success'), ('AI', 'ai'), ('implementation', 'implement'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('hierarchical', 'hierarch'), ('pyramid', 'pyramid'), ('explains', 'explain'), ('competencies', 'compet'), ('every', 'everi'), ('organization', 'organ'), ('requires', 'requir'), ('ensure', 'ensur'), ('successful', 'success'), ('AI', 'ai'), ('implementation', 'implement'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('hierarchical', 'hierarchical'), ('pyramid', 'pyramid'), ('explains', 'explains'), ('competencies', 'competency'), ('every', 'every'), ('organization', 'organization'), ('requires', 'requires'), ('ensure', 'ensure'), ('successful', 'successful'), ('AI', 'AI'), ('implementation', 'implementation'), ('.', '.')]



============================ Sentence 97 =============================

AI,  deep learning  Machine learning  and benchmarking:  A/B testing,  experimentation  BI or analytics:  Metrics, segmentation,  aggregation, data labelling  Explore and transform:  Data preparation, cleaning  and exploratory data analysis  Data flow:  Infrastructure, pipelines, ETL,  structured and unstructured data storage  Data collection:  External data, logging, sensors,  user generated content  AI,  deep   learning  Machine learning  and benchmarking:   A/B testing,  experimentation  BI or analytics:  Metrics, segmentation,   aggregation, data labelling  Explore and transform:  Data preparation, cleaning   and exploratory data analysis  Data flow:  Infrastructure, pipelines, ETL,   structured and unstructured data storage  Data collection:  External data, logging, sensors,   user generated content  Data collection. 


>> Tokens are: 
 ['AI', ',', 'deep', 'learning', 'Machine', 'learning', 'benchmarking', ':', 'A/B', 'testing', ',', 'experimentation', 'BI', 'analytics', ':', 'Metrics', ',', 'segmentation', ',', 'aggregation', ',', 'data', 'labelling', 'Explore', 'transform', ':', 'Data', 'preparation', ',', 'cleaning', 'exploratory', 'data', 'analysis', 'Data', 'flow', ':', 'Infrastructure', ',', 'pipelines', ',', 'ETL', ',', 'structured', 'unstructured', 'data', 'storage', 'Data', 'collection', ':', 'External', 'data', ',', 'logging', ',', 'sensors', ',', 'user', 'generated', 'content', 'AI', ',', 'deep', 'learning', 'Machine', 'learning', 'benchmarking', ':', 'A/B', 'testing', ',', 'experimentation', 'BI', 'analytics', ':', 'Metrics', ',', 'segmentation', ',', 'aggregation', ',', 'data', 'labelling', 'Explore', 'transform', ':', 'Data', 'preparation', ',', 'cleaning', 'exploratory', 'data', 'analysis', 'Data', 'flow', ':', 'Infrastructure', ',', 'pipelines', ',', 'ETL', ',', 'structured', 'unstructured', 'data', 'storage', 'Data', 'collection', ':', 'External', 'data', ',', 'logging', ',', 'sensors', ',', 'user', 'generated', 'content', 'Data', 'collection', '.']

>> Bigrams are: 
 [('AI', ','), (',', 'deep'), ('deep', 'learning'), ('learning', 'Machine'), ('Machine', 'learning'), ('learning', 'benchmarking'), ('benchmarking', ':'), (':', 'A/B'), ('A/B', 'testing'), ('testing', ','), (',', 'experimentation'), ('experimentation', 'BI'), ('BI', 'analytics'), ('analytics', ':'), (':', 'Metrics'), ('Metrics', ','), (',', 'segmentation'), ('segmentation', ','), (',', 'aggregation'), ('aggregation', ','), (',', 'data'), ('data', 'labelling'), ('labelling', 'Explore'), ('Explore', 'transform'), ('transform', ':'), (':', 'Data'), ('Data', 'preparation'), ('preparation', ','), (',', 'cleaning'), ('cleaning', 'exploratory'), ('exploratory', 'data'), ('data', 'analysis'), ('analysis', 'Data'), ('Data', 'flow'), ('flow', ':'), (':', 'Infrastructure'), ('Infrastructure', ','), (',', 'pipelines'), ('pipelines', ','), (',', 'ETL'), ('ETL', ','), (',', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'storage'), ('storage', 'Data'), ('Data', 'collection'), ('collection', ':'), (':', 'External'), ('External', 'data'), ('data', ','), (',', 'logging'), ('logging', ','), (',', 'sensors'), ('sensors', ','), (',', 'user'), ('user', 'generated'), ('generated', 'content'), ('content', 'AI'), ('AI', ','), (',', 'deep'), ('deep', 'learning'), ('learning', 'Machine'), ('Machine', 'learning'), ('learning', 'benchmarking'), ('benchmarking', ':'), (':', 'A/B'), ('A/B', 'testing'), ('testing', ','), (',', 'experimentation'), ('experimentation', 'BI'), ('BI', 'analytics'), ('analytics', ':'), (':', 'Metrics'), ('Metrics', ','), (',', 'segmentation'), ('segmentation', ','), (',', 'aggregation'), ('aggregation', ','), (',', 'data'), ('data', 'labelling'), ('labelling', 'Explore'), ('Explore', 'transform'), ('transform', ':'), (':', 'Data'), ('Data', 'preparation'), ('preparation', ','), (',', 'cleaning'), ('cleaning', 'exploratory'), ('exploratory', 'data'), ('data', 'analysis'), ('analysis', 'Data'), ('Data', 'flow'), ('flow', ':'), (':', 'Infrastructure'), ('Infrastructure', ','), (',', 'pipelines'), ('pipelines', ','), (',', 'ETL'), ('ETL', ','), (',', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'storage'), ('storage', 'Data'), ('Data', 'collection'), ('collection', ':'), (':', 'External'), ('External', 'data'), ('data', ','), (',', 'logging'), ('logging', ','), (',', 'sensors'), ('sensors', ','), (',', 'user'), ('user', 'generated'), ('generated', 'content'), ('content', 'Data'), ('Data', 'collection'), ('collection', '.')]

>> Trigrams are: 
 [('AI', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', 'Machine'), ('learning', 'Machine', 'learning'), ('Machine', 'learning', 'benchmarking'), ('learning', 'benchmarking', ':'), ('benchmarking', ':', 'A/B'), (':', 'A/B', 'testing'), ('A/B', 'testing', ','), ('testing', ',', 'experimentation'), (',', 'experimentation', 'BI'), ('experimentation', 'BI', 'analytics'), ('BI', 'analytics', ':'), ('analytics', ':', 'Metrics'), (':', 'Metrics', ','), ('Metrics', ',', 'segmentation'), (',', 'segmentation', ','), ('segmentation', ',', 'aggregation'), (',', 'aggregation', ','), ('aggregation', ',', 'data'), (',', 'data', 'labelling'), ('data', 'labelling', 'Explore'), ('labelling', 'Explore', 'transform'), ('Explore', 'transform', ':'), ('transform', ':', 'Data'), (':', 'Data', 'preparation'), ('Data', 'preparation', ','), ('preparation', ',', 'cleaning'), (',', 'cleaning', 'exploratory'), ('cleaning', 'exploratory', 'data'), ('exploratory', 'data', 'analysis'), ('data', 'analysis', 'Data'), ('analysis', 'Data', 'flow'), ('Data', 'flow', ':'), ('flow', ':', 'Infrastructure'), (':', 'Infrastructure', ','), ('Infrastructure', ',', 'pipelines'), (',', 'pipelines', ','), ('pipelines', ',', 'ETL'), (',', 'ETL', ','), ('ETL', ',', 'structured'), (',', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', 'storage'), ('data', 'storage', 'Data'), ('storage', 'Data', 'collection'), ('Data', 'collection', ':'), ('collection', ':', 'External'), (':', 'External', 'data'), ('External', 'data', ','), ('data', ',', 'logging'), (',', 'logging', ','), ('logging', ',', 'sensors'), (',', 'sensors', ','), ('sensors', ',', 'user'), (',', 'user', 'generated'), ('user', 'generated', 'content'), ('generated', 'content', 'AI'), ('content', 'AI', ','), ('AI', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', 'Machine'), ('learning', 'Machine', 'learning'), ('Machine', 'learning', 'benchmarking'), ('learning', 'benchmarking', ':'), ('benchmarking', ':', 'A/B'), (':', 'A/B', 'testing'), ('A/B', 'testing', ','), ('testing', ',', 'experimentation'), (',', 'experimentation', 'BI'), ('experimentation', 'BI', 'analytics'), ('BI', 'analytics', ':'), ('analytics', ':', 'Metrics'), (':', 'Metrics', ','), ('Metrics', ',', 'segmentation'), (',', 'segmentation', ','), ('segmentation', ',', 'aggregation'), (',', 'aggregation', ','), ('aggregation', ',', 'data'), (',', 'data', 'labelling'), ('data', 'labelling', 'Explore'), ('labelling', 'Explore', 'transform'), ('Explore', 'transform', ':'), ('transform', ':', 'Data'), (':', 'Data', 'preparation'), ('Data', 'preparation', ','), ('preparation', ',', 'cleaning'), (',', 'cleaning', 'exploratory'), ('cleaning', 'exploratory', 'data'), ('exploratory', 'data', 'analysis'), ('data', 'analysis', 'Data'), ('analysis', 'Data', 'flow'), ('Data', 'flow', ':'), ('flow', ':', 'Infrastructure'), (':', 'Infrastructure', ','), ('Infrastructure', ',', 'pipelines'), (',', 'pipelines', ','), ('pipelines', ',', 'ETL'), (',', 'ETL', ','), ('ETL', ',', 'structured'), (',', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', 'storage'), ('data', 'storage', 'Data'), ('storage', 'Data', 'collection'), ('Data', 'collection', ':'), ('collection', ':', 'External'), (':', 'External', 'data'), ('External', 'data', ','), ('data', ',', 'logging'), (',', 'logging', ','), ('logging', ',', 'sensors'), (',', 'sensors', ','), ('sensors', ',', 'user'), (',', 'user', 'generated'), ('user', 'generated', 'content'), ('generated', 'content', 'Data'), ('content', 'Data', 'collection'), ('Data', 'collection', '.')]

>> POS Tags are: 
 [('AI', 'NNP'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), ('Machine', 'NNP'), ('learning', 'VBG'), ('benchmarking', 'NN'), (':', ':'), ('A/B', 'NNP'), ('testing', 'VBG'), (',', ','), ('experimentation', 'NN'), ('BI', 'NNP'), ('analytics', 'NNS'), (':', ':'), ('Metrics', 'NNS'), (',', ','), ('segmentation', 'NN'), (',', ','), ('aggregation', 'NN'), (',', ','), ('data', 'NNS'), ('labelling', 'VBG'), ('Explore', 'NNP'), ('transform', 'NN'), (':', ':'), ('Data', 'NNP'), ('preparation', 'NN'), (',', ','), ('cleaning', 'VBG'), ('exploratory', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('Data', 'NNP'), ('flow', 'NN'), (':', ':'), ('Infrastructure', 'NN'), (',', ','), ('pipelines', 'NNS'), (',', ','), ('ETL', 'NNP'), (',', ','), ('structured', 'VBD'), ('unstructured', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('Data', 'NNP'), ('collection', 'NN'), (':', ':'), ('External', 'NNP'), ('data', 'NNS'), (',', ','), ('logging', 'NN'), (',', ','), ('sensors', 'NNS'), (',', ','), ('user', 'RB'), ('generated', 'VBD'), ('content', 'JJ'), ('AI', 'NNP'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), ('Machine', 'NNP'), ('learning', 'VBG'), ('benchmarking', 'NN'), (':', ':'), ('A/B', 'NNP'), ('testing', 'VBG'), (',', ','), ('experimentation', 'NN'), ('BI', 'NNP'), ('analytics', 'NNS'), (':', ':'), ('Metrics', 'NNS'), (',', ','), ('segmentation', 'NN'), (',', ','), ('aggregation', 'NN'), (',', ','), ('data', 'NNS'), ('labelling', 'VBG'), ('Explore', 'NNP'), ('transform', 'NN'), (':', ':'), ('Data', 'NNP'), ('preparation', 'NN'), (',', ','), ('cleaning', 'VBG'), ('exploratory', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('Data', 'NNP'), ('flow', 'NN'), (':', ':'), ('Infrastructure', 'NN'), (',', ','), ('pipelines', 'NNS'), (',', ','), ('ETL', 'NNP'), (',', ','), ('structured', 'VBD'), ('unstructured', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('Data', 'NNP'), ('collection', 'NN'), (':', ':'), ('External', 'NNP'), ('data', 'NNS'), (',', ','), ('logging', 'NN'), (',', ','), ('sensors', 'NNS'), (',', ','), ('user', 'RB'), ('generated', 'VBD'), ('content', 'JJ'), ('Data', 'NNP'), ('collection', 'NN'), ('.', '.')]

 (S
  (NP AI/NNP)
  ,/,
  (NP deep/JJ learning/NN Machine/NNP)
  learning/VBG
  (NP benchmarking/NN)
  :/:
  (NP A/B/NNP)
  testing/VBG
  ,/,
  (NP experimentation/NN BI/NNP analytics/NNS)
  :/:
  (NP Metrics/NNS)
  ,/,
  (NP segmentation/NN)
  ,/,
  (NP aggregation/NN)
  ,/,
  (NP data/NNS)
  labelling/VBG
  (NP Explore/NNP transform/NN)
  :/:
  (NP Data/NNP preparation/NN)
  ,/,
  cleaning/VBG
  (NP exploratory/NN data/NNS analysis/NN Data/NNP flow/NN)
  :/:
  (NP Infrastructure/NN)
  ,/,
  (NP pipelines/NNS)
  ,/,
  (NP ETL/NNP)
  ,/,
  structured/VBD
  (NP unstructured/JJ data/NNS storage/NN Data/NNP collection/NN)
  :/:
  (NP External/NNP data/NNS)
  ,/,
  (NP logging/NN)
  ,/,
  (NP sensors/NNS)
  ,/,
  user/RB
  generated/VBD
  (NP content/JJ AI/NNP)
  ,/,
  (NP deep/JJ learning/NN Machine/NNP)
  learning/VBG
  (NP benchmarking/NN)
  :/:
  (NP A/B/NNP)
  testing/VBG
  ,/,
  (NP experimentation/NN BI/NNP analytics/NNS)
  :/:
  (NP Metrics/NNS)
  ,/,
  (NP segmentation/NN)
  ,/,
  (NP aggregation/NN)
  ,/,
  (NP data/NNS)
  labelling/VBG
  (NP Explore/NNP transform/NN)
  :/:
  (NP Data/NNP preparation/NN)
  ,/,
  cleaning/VBG
  (NP exploratory/NN data/NNS analysis/NN Data/NNP flow/NN)
  :/:
  (NP Infrastructure/NN)
  ,/,
  (NP pipelines/NNS)
  ,/,
  (NP ETL/NNP)
  ,/,
  structured/VBD
  (NP unstructured/JJ data/NNS storage/NN Data/NNP collection/NN)
  :/:
  (NP External/NNP data/NNS)
  ,/,
  (NP logging/NN)
  ,/,
  (NP sensors/NNS)
  ,/,
  user/RB
  generated/VBD
  (NP content/JJ Data/NNP collection/NN)
  ./.) 


>> Noun Phrases are: 
 ['AI', 'deep learning Machine', 'benchmarking', 'A/B', 'experimentation BI analytics', 'Metrics', 'segmentation', 'aggregation', 'data', 'Explore transform', 'Data preparation', 'exploratory data analysis Data flow', 'Infrastructure', 'pipelines', 'ETL', 'unstructured data storage Data collection', 'External data', 'logging', 'sensors', 'content AI', 'deep learning Machine', 'benchmarking', 'A/B', 'experimentation BI analytics', 'Metrics', 'segmentation', 'aggregation', 'data', 'Explore transform', 'Data preparation', 'exploratory data analysis Data flow', 'Infrastructure', 'pipelines', 'ETL', 'unstructured data storage Data collection', 'External data', 'logging', 'sensors', 'content Data collection']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('GPE', 'Explore'), ('PERSON', 'Data'), ('ORGANIZATION', 'ETL'), ('PERSON', 'Data'), ('PERSON', 'Machine'), ('GPE', 'Explore'), ('PERSON', 'Data'), ('ORGANIZATION', 'ETL'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('AI', 'ai'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), (':', ':'), ('A/B', 'a/b'), ('testing', 'test'), (',', ','), ('experimentation', 'experiment'), ('BI', 'bi'), ('analytics', 'analyt'), (':', ':'), ('Metrics', 'metric'), (',', ','), ('segmentation', 'segment'), (',', ','), ('aggregation', 'aggreg'), (',', ','), ('data', 'data'), ('labelling', 'label'), ('Explore', 'explor'), ('transform', 'transform'), (':', ':'), ('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('exploratory', 'exploratori'), ('data', 'data'), ('analysis', 'analysi'), ('Data', 'data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'infrastructur'), (',', ','), ('pipelines', 'pipelin'), (',', ','), ('ETL', 'etl'), (',', ','), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('storage', 'storag'), ('Data', 'data'), ('collection', 'collect'), (':', ':'), ('External', 'extern'), ('data', 'data'), (',', ','), ('logging', 'log'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'gener'), ('content', 'content'), ('AI', 'ai'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), (':', ':'), ('A/B', 'a/b'), ('testing', 'test'), (',', ','), ('experimentation', 'experiment'), ('BI', 'bi'), ('analytics', 'analyt'), (':', ':'), ('Metrics', 'metric'), (',', ','), ('segmentation', 'segment'), (',', ','), ('aggregation', 'aggreg'), (',', ','), ('data', 'data'), ('labelling', 'label'), ('Explore', 'explor'), ('transform', 'transform'), (':', ':'), ('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('exploratory', 'exploratori'), ('data', 'data'), ('analysis', 'analysi'), ('Data', 'data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'infrastructur'), (',', ','), ('pipelines', 'pipelin'), (',', ','), ('ETL', 'etl'), (',', ','), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('storage', 'storag'), ('Data', 'data'), ('collection', 'collect'), (':', ':'), ('External', 'extern'), ('data', 'data'), (',', ','), ('logging', 'log'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'gener'), ('content', 'content'), ('Data', 'data'), ('collection', 'collect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('AI', 'ai'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), (':', ':'), ('A/B', 'a/b'), ('testing', 'test'), (',', ','), ('experimentation', 'experiment'), ('BI', 'bi'), ('analytics', 'analyt'), (':', ':'), ('Metrics', 'metric'), (',', ','), ('segmentation', 'segment'), (',', ','), ('aggregation', 'aggreg'), (',', ','), ('data', 'data'), ('labelling', 'label'), ('Explore', 'explor'), ('transform', 'transform'), (':', ':'), ('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('exploratory', 'exploratori'), ('data', 'data'), ('analysis', 'analysi'), ('Data', 'data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'infrastructur'), (',', ','), ('pipelines', 'pipelin'), (',', ','), ('ETL', 'etl'), (',', ','), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('storage', 'storag'), ('Data', 'data'), ('collection', 'collect'), (':', ':'), ('External', 'extern'), ('data', 'data'), (',', ','), ('logging', 'log'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'generat'), ('content', 'content'), ('AI', 'ai'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), (':', ':'), ('A/B', 'a/b'), ('testing', 'test'), (',', ','), ('experimentation', 'experiment'), ('BI', 'bi'), ('analytics', 'analyt'), (':', ':'), ('Metrics', 'metric'), (',', ','), ('segmentation', 'segment'), (',', ','), ('aggregation', 'aggreg'), (',', ','), ('data', 'data'), ('labelling', 'label'), ('Explore', 'explor'), ('transform', 'transform'), (':', ':'), ('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('exploratory', 'exploratori'), ('data', 'data'), ('analysis', 'analysi'), ('Data', 'data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'infrastructur'), (',', ','), ('pipelines', 'pipelin'), (',', ','), ('ETL', 'etl'), (',', ','), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('storage', 'storag'), ('Data', 'data'), ('collection', 'collect'), (':', ':'), ('External', 'extern'), ('data', 'data'), (',', ','), ('logging', 'log'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'generat'), ('content', 'content'), ('Data', 'data'), ('collection', 'collect'), ('.', '.')]

>> Lemmatization: 
 [('AI', 'AI'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), ('Machine', 'Machine'), ('learning', 'learning'), ('benchmarking', 'benchmarking'), (':', ':'), ('A/B', 'A/B'), ('testing', 'testing'), (',', ','), ('experimentation', 'experimentation'), ('BI', 'BI'), ('analytics', 'analytics'), (':', ':'), ('Metrics', 'Metrics'), (',', ','), ('segmentation', 'segmentation'), (',', ','), ('aggregation', 'aggregation'), (',', ','), ('data', 'data'), ('labelling', 'labelling'), ('Explore', 'Explore'), ('transform', 'transform'), (':', ':'), ('Data', 'Data'), ('preparation', 'preparation'), (',', ','), ('cleaning', 'cleaning'), ('exploratory', 'exploratory'), ('data', 'data'), ('analysis', 'analysis'), ('Data', 'Data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'Infrastructure'), (',', ','), ('pipelines', 'pipeline'), (',', ','), ('ETL', 'ETL'), (',', ','), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('storage', 'storage'), ('Data', 'Data'), ('collection', 'collection'), (':', ':'), ('External', 'External'), ('data', 'data'), (',', ','), ('logging', 'logging'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'generated'), ('content', 'content'), ('AI', 'AI'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), ('Machine', 'Machine'), ('learning', 'learning'), ('benchmarking', 'benchmarking'), (':', ':'), ('A/B', 'A/B'), ('testing', 'testing'), (',', ','), ('experimentation', 'experimentation'), ('BI', 'BI'), ('analytics', 'analytics'), (':', ':'), ('Metrics', 'Metrics'), (',', ','), ('segmentation', 'segmentation'), (',', ','), ('aggregation', 'aggregation'), (',', ','), ('data', 'data'), ('labelling', 'labelling'), ('Explore', 'Explore'), ('transform', 'transform'), (':', ':'), ('Data', 'Data'), ('preparation', 'preparation'), (',', ','), ('cleaning', 'cleaning'), ('exploratory', 'exploratory'), ('data', 'data'), ('analysis', 'analysis'), ('Data', 'Data'), ('flow', 'flow'), (':', ':'), ('Infrastructure', 'Infrastructure'), (',', ','), ('pipelines', 'pipeline'), (',', ','), ('ETL', 'ETL'), (',', ','), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('storage', 'storage'), ('Data', 'Data'), ('collection', 'collection'), (':', ':'), ('External', 'External'), ('data', 'data'), (',', ','), ('logging', 'logging'), (',', ','), ('sensors', 'sensor'), (',', ','), ('user', 'user'), ('generated', 'generated'), ('content', 'content'), ('Data', 'Data'), ('collection', 'collection'), ('.', '.')]



============================ Sentence 98 =============================

At the bottom of the pyramid is data collection. 


>> Tokens are: 
 ['At', 'bottom', 'pyramid', 'data', 'collection', '.']

>> Bigrams are: 
 [('At', 'bottom'), ('bottom', 'pyramid'), ('pyramid', 'data'), ('data', 'collection'), ('collection', '.')]

>> Trigrams are: 
 [('At', 'bottom', 'pyramid'), ('bottom', 'pyramid', 'data'), ('pyramid', 'data', 'collection'), ('data', 'collection', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('bottom', 'JJ'), ('pyramid', 'NN'), ('data', 'NNS'), ('collection', 'NN'), ('.', '.')]

 (S At/IN (NP bottom/JJ pyramid/NN data/NNS collection/NN) ./.) 


>> Noun Phrases are: 
 ['bottom pyramid data collection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('bottom', 'bottom'), ('pyramid', 'pyramid'), ('data', 'data'), ('collection', 'collect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('bottom', 'bottom'), ('pyramid', 'pyramid'), ('data', 'data'), ('collection', 'collect'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('bottom', 'bottom'), ('pyramid', 'pyramid'), ('data', 'data'), ('collection', 'collection'), ('.', '.')]



============================ Sentence 99 =============================

At this stage, the  goal is to identify what data is needed and what is available. 


>> Tokens are: 
 ['At', 'stage', ',', 'goal', 'identify', 'data', 'needed', 'available', '.']

>> Bigrams are: 
 [('At', 'stage'), ('stage', ','), (',', 'goal'), ('goal', 'identify'), ('identify', 'data'), ('data', 'needed'), ('needed', 'available'), ('available', '.')]

>> Trigrams are: 
 [('At', 'stage', ','), ('stage', ',', 'goal'), (',', 'goal', 'identify'), ('goal', 'identify', 'data'), ('identify', 'data', 'needed'), ('data', 'needed', 'available'), ('needed', 'available', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('stage', 'NN'), (',', ','), ('goal', 'NN'), ('identify', 'VB'), ('data', 'NNS'), ('needed', 'VBN'), ('available', 'JJ'), ('.', '.')]

 (S
  At/IN
  (NP stage/NN)
  ,/,
  (NP goal/NN)
  identify/VB
  (NP data/NNS)
  needed/VBN
  available/JJ
  ./.) 


>> Noun Phrases are: 
 ['stage', 'goal', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('stage', 'stage'), (',', ','), ('goal', 'goal'), ('identify', 'identifi'), ('data', 'data'), ('needed', 'need'), ('available', 'avail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('stage', 'stage'), (',', ','), ('goal', 'goal'), ('identify', 'identifi'), ('data', 'data'), ('needed', 'need'), ('available', 'avail'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('stage', 'stage'), (',', ','), ('goal', 'goal'), ('identify', 'identify'), ('data', 'data'), ('needed', 'needed'), ('available', 'available'), ('.', '.')]



============================ Sentence 100 =============================

If it is a user-facing  product, are all relevant interactions logged? 


>> Tokens are: 
 ['If', 'user-facing', 'product', ',', 'relevant', 'interactions', 'logged', '?']

>> Bigrams are: 
 [('If', 'user-facing'), ('user-facing', 'product'), ('product', ','), (',', 'relevant'), ('relevant', 'interactions'), ('interactions', 'logged'), ('logged', '?')]

>> Trigrams are: 
 [('If', 'user-facing', 'product'), ('user-facing', 'product', ','), ('product', ',', 'relevant'), (',', 'relevant', 'interactions'), ('relevant', 'interactions', 'logged'), ('interactions', 'logged', '?')]

>> POS Tags are: 
 [('If', 'IN'), ('user-facing', 'JJ'), ('product', 'NN'), (',', ','), ('relevant', 'JJ'), ('interactions', 'NNS'), ('logged', 'VBN'), ('?', '.')]

 (S
  If/IN
  (NP user-facing/JJ product/NN)
  ,/,
  (NP relevant/JJ interactions/NNS)
  logged/VBN
  ?/.) 


>> Noun Phrases are: 
 ['user-facing product', 'relevant interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('user-facing', 'user-fac'), ('product', 'product'), (',', ','), ('relevant', 'relev'), ('interactions', 'interact'), ('logged', 'log'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('user-facing', 'user-fac'), ('product', 'product'), (',', ','), ('relevant', 'relev'), ('interactions', 'interact'), ('logged', 'log'), ('?', '?')]

>> Lemmatization: 
 [('If', 'If'), ('user-facing', 'user-facing'), ('product', 'product'), (',', ','), ('relevant', 'relevant'), ('interactions', 'interaction'), ('logged', 'logged'), ('?', '?')]



============================ Sentence 101 =============================

If it is a sensor, what data is coming  through and how? 


>> Tokens are: 
 ['If', 'sensor', ',', 'data', 'coming', '?']

>> Bigrams are: 
 [('If', 'sensor'), ('sensor', ','), (',', 'data'), ('data', 'coming'), ('coming', '?')]

>> Trigrams are: 
 [('If', 'sensor', ','), ('sensor', ',', 'data'), (',', 'data', 'coming'), ('data', 'coming', '?')]

>> POS Tags are: 
 [('If', 'IN'), ('sensor', 'NN'), (',', ','), ('data', 'NNS'), ('coming', 'VBG'), ('?', '.')]

 (S If/IN (NP sensor/NN) ,/, (NP data/NNS) coming/VBG ?/.) 


>> Noun Phrases are: 
 ['sensor', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('sensor', 'sensor'), (',', ','), ('data', 'data'), ('coming', 'come'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('sensor', 'sensor'), (',', ','), ('data', 'data'), ('coming', 'come'), ('?', '?')]

>> Lemmatization: 
 [('If', 'If'), ('sensor', 'sensor'), (',', ','), ('data', 'data'), ('coming', 'coming'), ('?', '?')]



============================ Sentence 102 =============================

Without data, no machine learning or AI solution can learn or  predict outcomes. 


>> Tokens are: 
 ['Without', 'data', ',', 'machine', 'learning', 'AI', 'solution', 'learn', 'predict', 'outcomes', '.']

>> Bigrams are: 
 [('Without', 'data'), ('data', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'AI'), ('AI', 'solution'), ('solution', 'learn'), ('learn', 'predict'), ('predict', 'outcomes'), ('outcomes', '.')]

>> Trigrams are: 
 [('Without', 'data', ','), ('data', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'AI'), ('learning', 'AI', 'solution'), ('AI', 'solution', 'learn'), ('solution', 'learn', 'predict'), ('learn', 'predict', 'outcomes'), ('predict', 'outcomes', '.')]

>> POS Tags are: 
 [('Without', 'IN'), ('data', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('AI', 'NNP'), ('solution', 'NN'), ('learn', 'NN'), ('predict', 'NN'), ('outcomes', 'NNS'), ('.', '.')]

 (S
  Without/IN
  (NP data/NNS)
  ,/,
  (NP
    machine/NN
    learning/NN
    AI/NNP
    solution/NN
    learn/NN
    predict/NN
    outcomes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data', 'machine learning AI solution learn predict outcomes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Without', 'without'), ('data', 'data'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('AI', 'ai'), ('solution', 'solut'), ('learn', 'learn'), ('predict', 'predict'), ('outcomes', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Without', 'without'), ('data', 'data'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('AI', 'ai'), ('solution', 'solut'), ('learn', 'learn'), ('predict', 'predict'), ('outcomes', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('Without', 'Without'), ('data', 'data'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('AI', 'AI'), ('solution', 'solution'), ('learn', 'learn'), ('predict', 'predict'), ('outcomes', 'outcome'), ('.', '.')]



============================ Sentence 103 =============================

Data flow. 


>> Tokens are: 
 ['Data', 'flow', '.']

>> Bigrams are: 
 [('Data', 'flow'), ('flow', '.')]

>> Trigrams are: 
 [('Data', 'flow', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('flow', 'NN'), ('.', '.')]

 (S (NP Data/NNP flow/NN) ./.) 


>> Noun Phrases are: 
 ['Data flow']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('flow', 'flow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('flow', 'flow'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('flow', 'flow'), ('.', '.')]



============================ Sentence 104 =============================

Identify how the data flows through the system. 


>> Tokens are: 
 ['Identify', 'data', 'flows', 'system', '.']

>> Bigrams are: 
 [('Identify', 'data'), ('data', 'flows'), ('flows', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Identify', 'data', 'flows'), ('data', 'flows', 'system'), ('flows', 'system', '.')]

>> POS Tags are: 
 [('Identify', 'NNP'), ('data', 'NN'), ('flows', 'NNS'), ('system', 'NN'), ('.', '.')]

 (S (NP Identify/NNP data/NN flows/NNS system/NN) ./.) 


>> Noun Phrases are: 
 ['Identify data flows system']

>> Named Entities are: 
 [('GPE', 'Identify')] 

>> Stemming using Porter Stemmer: 
 [('Identify', 'identifi'), ('data', 'data'), ('flows', 'flow'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Identify', 'identifi'), ('data', 'data'), ('flows', 'flow'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Identify', 'Identify'), ('data', 'data'), ('flows', 'flow'), ('system', 'system'), ('.', '.')]



============================ Sentence 105 =============================

Is there a reliable  stream/ETL process established? 


>> Tokens are: 
 ['Is', 'reliable', 'stream/ETL', 'process', 'established', '?']

>> Bigrams are: 
 [('Is', 'reliable'), ('reliable', 'stream/ETL'), ('stream/ETL', 'process'), ('process', 'established'), ('established', '?')]

>> Trigrams are: 
 [('Is', 'reliable', 'stream/ETL'), ('reliable', 'stream/ETL', 'process'), ('stream/ETL', 'process', 'established'), ('process', 'established', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('reliable', 'JJ'), ('stream/ETL', 'JJ'), ('process', 'NN'), ('established', 'VBN'), ('?', '.')]

 (S
  Is/VBZ
  (NP reliable/JJ stream/ETL/JJ process/NN)
  established/VBN
  ?/.) 


>> Noun Phrases are: 
 ['reliable stream/ETL process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('reliable', 'reliabl'), ('stream/ETL', 'stream/etl'), ('process', 'process'), ('established', 'establish'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('reliable', 'reliabl'), ('stream/ETL', 'stream/etl'), ('process', 'process'), ('established', 'establish'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('reliable', 'reliable'), ('stream/ETL', 'stream/ETL'), ('process', 'process'), ('established', 'established'), ('?', '?')]



============================ Sentence 106 =============================

Where is the data stored, and how easy is it to  access and analyze? 


>> Tokens are: 
 ['Where', 'data', 'stored', ',', 'easy', 'access', 'analyze', '?']

>> Bigrams are: 
 [('Where', 'data'), ('data', 'stored'), ('stored', ','), (',', 'easy'), ('easy', 'access'), ('access', 'analyze'), ('analyze', '?')]

>> Trigrams are: 
 [('Where', 'data', 'stored'), ('data', 'stored', ','), ('stored', ',', 'easy'), (',', 'easy', 'access'), ('easy', 'access', 'analyze'), ('access', 'analyze', '?')]

>> POS Tags are: 
 [('Where', 'WRB'), ('data', 'NNS'), ('stored', 'VBD'), (',', ','), ('easy', 'JJ'), ('access', 'NN'), ('analyze', 'NN'), ('?', '.')]

 (S
  Where/WRB
  (NP data/NNS)
  stored/VBD
  ,/,
  (NP easy/JJ access/NN analyze/NN)
  ?/.) 


>> Noun Phrases are: 
 ['data', 'easy access analyze']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('stored', 'store'), (',', ','), ('easy', 'easi'), ('access', 'access'), ('analyze', 'analyz'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('stored', 'store'), (',', ','), ('easy', 'easi'), ('access', 'access'), ('analyze', 'analyz'), ('?', '?')]

>> Lemmatization: 
 [('Where', 'Where'), ('data', 'data'), ('stored', 'stored'), (',', ','), ('easy', 'easy'), ('access', 'access'), ('analyze', 'analyze'), ('?', '?')]



============================ Sentence 107 =============================

Explore and transform. 


>> Tokens are: 
 ['Explore', 'transform', '.']

>> Bigrams are: 
 [('Explore', 'transform'), ('transform', '.')]

>> Trigrams are: 
 [('Explore', 'transform', '.')]

>> POS Tags are: 
 [('Explore', 'RB'), ('transform', 'NN'), ('.', '.')]

 (S Explore/RB (NP transform/NN) ./.) 


>> Noun Phrases are: 
 ['transform']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Explore', 'explor'), ('transform', 'transform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Explore', 'explor'), ('transform', 'transform'), ('.', '.')]

>> Lemmatization: 
 [('Explore', 'Explore'), ('transform', 'transform'), ('.', '.')]



============================ Sentence 108 =============================

Only when data is accessible can it be explored and  transformed for modelling. 


>> Tokens are: 
 ['Only', 'data', 'accessible', 'explored', 'transformed', 'modelling', '.']

>> Bigrams are: 
 [('Only', 'data'), ('data', 'accessible'), ('accessible', 'explored'), ('explored', 'transformed'), ('transformed', 'modelling'), ('modelling', '.')]

>> Trigrams are: 
 [('Only', 'data', 'accessible'), ('data', 'accessible', 'explored'), ('accessible', 'explored', 'transformed'), ('explored', 'transformed', 'modelling'), ('transformed', 'modelling', '.')]

>> POS Tags are: 
 [('Only', 'RB'), ('data', 'NNS'), ('accessible', 'RB'), ('explored', 'VBD'), ('transformed', 'JJ'), ('modelling', 'NN'), ('.', '.')]

 (S
  Only/RB
  (NP data/NNS)
  accessible/RB
  explored/VBD
  (NP transformed/JJ modelling/NN)
  ./.) 


>> Noun Phrases are: 
 ['data', 'transformed modelling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Only', 'onli'), ('data', 'data'), ('accessible', 'access'), ('explored', 'explor'), ('transformed', 'transform'), ('modelling', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Only', 'onli'), ('data', 'data'), ('accessible', 'access'), ('explored', 'explor'), ('transformed', 'transform'), ('modelling', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Only', 'Only'), ('data', 'data'), ('accessible', 'accessible'), ('explored', 'explored'), ('transformed', 'transformed'), ('modelling', 'modelling'), ('.', '.')]



============================ Sentence 109 =============================

This stage is one of the most time-consuming and  underestimated of the data science project lifecycle. 


>> Tokens are: 
 ['This', 'stage', 'one', 'time-consuming', 'underestimated', 'data', 'science', 'project', 'lifecycle', '.']

>> Bigrams are: 
 [('This', 'stage'), ('stage', 'one'), ('one', 'time-consuming'), ('time-consuming', 'underestimated'), ('underestimated', 'data'), ('data', 'science'), ('science', 'project'), ('project', 'lifecycle'), ('lifecycle', '.')]

>> Trigrams are: 
 [('This', 'stage', 'one'), ('stage', 'one', 'time-consuming'), ('one', 'time-consuming', 'underestimated'), ('time-consuming', 'underestimated', 'data'), ('underestimated', 'data', 'science'), ('data', 'science', 'project'), ('science', 'project', 'lifecycle'), ('project', 'lifecycle', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('stage', 'NN'), ('one', 'CD'), ('time-consuming', 'NN'), ('underestimated', 'JJ'), ('data', 'NNS'), ('science', 'NN'), ('project', 'NN'), ('lifecycle', 'NN'), ('.', '.')]

 (S
  (NP This/DT stage/NN)
  one/CD
  (NP time-consuming/NN)
  (NP underestimated/JJ data/NNS science/NN project/NN lifecycle/NN)
  ./.) 


>> Noun Phrases are: 
 ['This stage', 'time-consuming', 'underestimated data science project lifecycle']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('stage', 'stage'), ('one', 'one'), ('time-consuming', 'time-consum'), ('underestimated', 'underestim'), ('data', 'data'), ('science', 'scienc'), ('project', 'project'), ('lifecycle', 'lifecycl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('stage', 'stage'), ('one', 'one'), ('time-consuming', 'time-consum'), ('underestimated', 'underestim'), ('data', 'data'), ('science', 'scienc'), ('project', 'project'), ('lifecycle', 'lifecycl'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('stage', 'stage'), ('one', 'one'), ('time-consuming', 'time-consuming'), ('underestimated', 'underestimated'), ('data', 'data'), ('science', 'science'), ('project', 'project'), ('lifecycle', 'lifecycle'), ('.', '.')]



============================ Sentence 110 =============================

It is at this stage that teams  and organizations realize that they are missing data, their machine sensors are  unreliable, they are not tracking relevant information about customers and other  key issues. 


>> Tokens are: 
 ['It', 'stage', 'teams', 'organizations', 'realize', 'missing', 'data', ',', 'machine', 'sensors', 'unreliable', ',', 'tracking', 'relevant', 'information', 'customers', 'key', 'issues', '.']

>> Bigrams are: 
 [('It', 'stage'), ('stage', 'teams'), ('teams', 'organizations'), ('organizations', 'realize'), ('realize', 'missing'), ('missing', 'data'), ('data', ','), (',', 'machine'), ('machine', 'sensors'), ('sensors', 'unreliable'), ('unreliable', ','), (',', 'tracking'), ('tracking', 'relevant'), ('relevant', 'information'), ('information', 'customers'), ('customers', 'key'), ('key', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('It', 'stage', 'teams'), ('stage', 'teams', 'organizations'), ('teams', 'organizations', 'realize'), ('organizations', 'realize', 'missing'), ('realize', 'missing', 'data'), ('missing', 'data', ','), ('data', ',', 'machine'), (',', 'machine', 'sensors'), ('machine', 'sensors', 'unreliable'), ('sensors', 'unreliable', ','), ('unreliable', ',', 'tracking'), (',', 'tracking', 'relevant'), ('tracking', 'relevant', 'information'), ('relevant', 'information', 'customers'), ('information', 'customers', 'key'), ('customers', 'key', 'issues'), ('key', 'issues', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('stage', 'NN'), ('teams', 'JJ'), ('organizations', 'NNS'), ('realize', 'VBP'), ('missing', 'VBG'), ('data', 'NNS'), (',', ','), ('machine', 'NN'), ('sensors', 'NNS'), ('unreliable', 'JJ'), (',', ','), ('tracking', 'VBG'), ('relevant', 'JJ'), ('information', 'NN'), ('customers', 'NNS'), ('key', 'JJ'), ('issues', 'NNS'), ('.', '.')]

 (S
  It/PRP
  (NP stage/NN)
  (NP teams/JJ organizations/NNS)
  realize/VBP
  missing/VBG
  (NP data/NNS)
  ,/,
  (NP machine/NN sensors/NNS)
  unreliable/JJ
  ,/,
  tracking/VBG
  (NP relevant/JJ information/NN customers/NNS)
  (NP key/JJ issues/NNS)
  ./.) 


>> Noun Phrases are: 
 ['stage', 'teams organizations', 'data', 'machine sensors', 'relevant information customers', 'key issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('stage', 'stage'), ('teams', 'team'), ('organizations', 'organ'), ('realize', 'realiz'), ('missing', 'miss'), ('data', 'data'), (',', ','), ('machine', 'machin'), ('sensors', 'sensor'), ('unreliable', 'unreli'), (',', ','), ('tracking', 'track'), ('relevant', 'relev'), ('information', 'inform'), ('customers', 'custom'), ('key', 'key'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('stage', 'stage'), ('teams', 'team'), ('organizations', 'organ'), ('realize', 'realiz'), ('missing', 'miss'), ('data', 'data'), (',', ','), ('machine', 'machin'), ('sensors', 'sensor'), ('unreliable', 'unreli'), (',', ','), ('tracking', 'track'), ('relevant', 'relev'), ('information', 'inform'), ('customers', 'custom'), ('key', 'key'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('stage', 'stage'), ('teams', 'team'), ('organizations', 'organization'), ('realize', 'realize'), ('missing', 'missing'), ('data', 'data'), (',', ','), ('machine', 'machine'), ('sensors', 'sensor'), ('unreliable', 'unreliable'), (',', ','), ('tracking', 'tracking'), ('relevant', 'relevant'), ('information', 'information'), ('customers', 'customer'), ('key', 'key'), ('issues', 'issue'), ('.', '.')]



============================ Sentence 111 =============================

It forces them to return to data collection and ensure the foundation is  solid before moving forward. 


>> Tokens are: 
 ['It', 'forces', 'return', 'data', 'collection', 'ensure', 'foundation', 'solid', 'moving', 'forward', '.']

>> Bigrams are: 
 [('It', 'forces'), ('forces', 'return'), ('return', 'data'), ('data', 'collection'), ('collection', 'ensure'), ('ensure', 'foundation'), ('foundation', 'solid'), ('solid', 'moving'), ('moving', 'forward'), ('forward', '.')]

>> Trigrams are: 
 [('It', 'forces', 'return'), ('forces', 'return', 'data'), ('return', 'data', 'collection'), ('data', 'collection', 'ensure'), ('collection', 'ensure', 'foundation'), ('ensure', 'foundation', 'solid'), ('foundation', 'solid', 'moving'), ('solid', 'moving', 'forward'), ('moving', 'forward', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('forces', 'VBZ'), ('return', 'NN'), ('data', 'NNS'), ('collection', 'NN'), ('ensure', 'VB'), ('foundation', 'NN'), ('solid', 'JJ'), ('moving', 'VBG'), ('forward', 'RB'), ('.', '.')]

 (S
  It/PRP
  forces/VBZ
  (NP return/NN data/NNS collection/NN)
  ensure/VB
  (NP foundation/NN)
  solid/JJ
  moving/VBG
  forward/RB
  ./.) 


>> Noun Phrases are: 
 ['return data collection', 'foundation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('forces', 'forc'), ('return', 'return'), ('data', 'data'), ('collection', 'collect'), ('ensure', 'ensur'), ('foundation', 'foundat'), ('solid', 'solid'), ('moving', 'move'), ('forward', 'forward'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('forces', 'forc'), ('return', 'return'), ('data', 'data'), ('collection', 'collect'), ('ensure', 'ensur'), ('foundation', 'foundat'), ('solid', 'solid'), ('moving', 'move'), ('forward', 'forward'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('forces', 'force'), ('return', 'return'), ('data', 'data'), ('collection', 'collection'), ('ensure', 'ensure'), ('foundation', 'foundation'), ('solid', 'solid'), ('moving', 'moving'), ('forward', 'forward'), ('.', '.')]



============================ Sentence 112 =============================

Not going to the top is like  an insight engine working  at half capacity, not using  all its potential.    8/14Demystifying data science   Business intelligence and analytics. 


>> Tokens are: 
 ['', 'Not', 'going', 'top', 'like', 'insight', 'engine', 'working', 'half', 'capacity', ',', 'using', 'potential.', '', '8/14Demystifying', 'data', 'science', 'Business', 'intelligence', 'analytics', '.']

>> Bigrams are: 
 [('', 'Not'), ('Not', 'going'), ('going', 'top'), ('top', 'like'), ('like', 'insight'), ('insight', 'engine'), ('engine', 'working'), ('working', 'half'), ('half', 'capacity'), ('capacity', ','), (',', 'using'), ('using', 'potential.'), ('potential.', ''), ('', '8/14Demystifying'), ('8/14Demystifying', 'data'), ('data', 'science'), ('science', 'Business'), ('Business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('', 'Not', 'going'), ('Not', 'going', 'top'), ('going', 'top', 'like'), ('top', 'like', 'insight'), ('like', 'insight', 'engine'), ('insight', 'engine', 'working'), ('engine', 'working', 'half'), ('working', 'half', 'capacity'), ('half', 'capacity', ','), ('capacity', ',', 'using'), (',', 'using', 'potential.'), ('using', 'potential.', ''), ('potential.', '', '8/14Demystifying'), ('', '8/14Demystifying', 'data'), ('8/14Demystifying', 'data', 'science'), ('data', 'science', 'Business'), ('science', 'Business', 'intelligence'), ('Business', 'intelligence', 'analytics'), ('intelligence', 'analytics', '.')]

>> POS Tags are: 
 [('', 'NN'), ('Not', 'RB'), ('going', 'VBG'), ('top', 'JJ'), ('like', 'IN'), ('insight', 'JJ'), ('engine', 'NN'), ('working', 'VBG'), ('half', 'NN'), ('capacity', 'NN'), (',', ','), ('using', 'VBG'), ('potential.', 'JJ'), ('', '$'), ('8/14Demystifying', 'CD'), ('data', 'NNS'), ('science', 'NN'), ('Business', 'NNP'), ('intelligence', 'NN'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP /NN)
  Not/RB
  going/VBG
  top/JJ
  like/IN
  (NP insight/JJ engine/NN)
  working/VBG
  (NP half/NN capacity/NN)
  ,/,
  using/VBG
  potential./JJ
  /$
  8/14Demystifying/CD
  (NP data/NNS science/NN Business/NNP intelligence/NN analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['', 'insight engine', 'half capacity', 'data science Business intelligence analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'Business')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Not', 'not'), ('going', 'go'), ('top', 'top'), ('like', 'like'), ('insight', 'insight'), ('engine', 'engin'), ('working', 'work'), ('half', 'half'), ('capacity', 'capac'), (',', ','), ('using', 'use'), ('potential.', 'potential.'), ('', ''), ('8/14Demystifying', '8/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Not', 'not'), ('going', 'go'), ('top', 'top'), ('like', 'like'), ('insight', 'insight'), ('engine', 'engin'), ('working', 'work'), ('half', 'half'), ('capacity', 'capac'), (',', ','), ('using', 'use'), ('potential.', 'potential.'), ('', ''), ('8/14Demystifying', '8/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('', ''), ('Not', 'Not'), ('going', 'going'), ('top', 'top'), ('like', 'like'), ('insight', 'insight'), ('engine', 'engine'), ('working', 'working'), ('half', 'half'), ('capacity', 'capacity'), (',', ','), ('using', 'using'), ('potential.', 'potential.'), ('', ''), ('8/14Demystifying', '8/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Business', 'Business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 113 =============================

When teams can reliably explore and clean  data, organizations can start building what is traditionally thought of as business  intelligence or analytics, which includes defining key metrics to track, identifying  how seasonality impacts product sales and operations, segmenting users based on  demographic factors, etc. 


>> Tokens are: 
 ['When', 'teams', 'reliably', 'explore', 'clean', 'data', ',', 'organizations', 'start', 'building', 'traditionally', 'thought', 'business', 'intelligence', 'analytics', ',', 'includes', 'defining', 'key', 'metrics', 'track', ',', 'identifying', 'seasonality', 'impacts', 'product', 'sales', 'operations', ',', 'segmenting', 'users', 'based', 'demographic', 'factors', ',', 'etc', '.']

>> Bigrams are: 
 [('When', 'teams'), ('teams', 'reliably'), ('reliably', 'explore'), ('explore', 'clean'), ('clean', 'data'), ('data', ','), (',', 'organizations'), ('organizations', 'start'), ('start', 'building'), ('building', 'traditionally'), ('traditionally', 'thought'), ('thought', 'business'), ('business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', ','), (',', 'includes'), ('includes', 'defining'), ('defining', 'key'), ('key', 'metrics'), ('metrics', 'track'), ('track', ','), (',', 'identifying'), ('identifying', 'seasonality'), ('seasonality', 'impacts'), ('impacts', 'product'), ('product', 'sales'), ('sales', 'operations'), ('operations', ','), (',', 'segmenting'), ('segmenting', 'users'), ('users', 'based'), ('based', 'demographic'), ('demographic', 'factors'), ('factors', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('When', 'teams', 'reliably'), ('teams', 'reliably', 'explore'), ('reliably', 'explore', 'clean'), ('explore', 'clean', 'data'), ('clean', 'data', ','), ('data', ',', 'organizations'), (',', 'organizations', 'start'), ('organizations', 'start', 'building'), ('start', 'building', 'traditionally'), ('building', 'traditionally', 'thought'), ('traditionally', 'thought', 'business'), ('thought', 'business', 'intelligence'), ('business', 'intelligence', 'analytics'), ('intelligence', 'analytics', ','), ('analytics', ',', 'includes'), (',', 'includes', 'defining'), ('includes', 'defining', 'key'), ('defining', 'key', 'metrics'), ('key', 'metrics', 'track'), ('metrics', 'track', ','), ('track', ',', 'identifying'), (',', 'identifying', 'seasonality'), ('identifying', 'seasonality', 'impacts'), ('seasonality', 'impacts', 'product'), ('impacts', 'product', 'sales'), ('product', 'sales', 'operations'), ('sales', 'operations', ','), ('operations', ',', 'segmenting'), (',', 'segmenting', 'users'), ('segmenting', 'users', 'based'), ('users', 'based', 'demographic'), ('based', 'demographic', 'factors'), ('demographic', 'factors', ','), ('factors', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('teams', 'NNS'), ('reliably', 'RB'), ('explore', 'VBP'), ('clean', 'JJ'), ('data', 'NNS'), (',', ','), ('organizations', 'NNS'), ('start', 'VBP'), ('building', 'VBG'), ('traditionally', 'RB'), ('thought', 'VBN'), ('business', 'NN'), ('intelligence', 'NN'), ('analytics', 'NNS'), (',', ','), ('includes', 'VBZ'), ('defining', 'VBG'), ('key', 'JJ'), ('metrics', 'NNS'), ('track', 'NN'), (',', ','), ('identifying', 'VBG'), ('seasonality', 'NN'), ('impacts', 'NNS'), ('product', 'NN'), ('sales', 'NNS'), ('operations', 'NNS'), (',', ','), ('segmenting', 'VBG'), ('users', 'NNS'), ('based', 'VBN'), ('demographic', 'JJ'), ('factors', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  When/WRB
  (NP teams/NNS)
  reliably/RB
  explore/VBP
  (NP clean/JJ data/NNS)
  ,/,
  (NP organizations/NNS)
  start/VBP
  building/VBG
  traditionally/RB
  thought/VBN
  (NP business/NN intelligence/NN analytics/NNS)
  ,/,
  includes/VBZ
  defining/VBG
  (NP key/JJ metrics/NNS track/NN)
  ,/,
  identifying/VBG
  (NP seasonality/NN impacts/NNS product/NN sales/NNS operations/NNS)
  ,/,
  segmenting/VBG
  (NP users/NNS)
  based/VBN
  (NP demographic/JJ factors/NNS)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['teams', 'clean data', 'organizations', 'business intelligence analytics', 'key metrics track', 'seasonality impacts product sales operations', 'users', 'demographic factors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('teams', 'team'), ('reliably', 'reliabl'), ('explore', 'explor'), ('clean', 'clean'), ('data', 'data'), (',', ','), ('organizations', 'organ'), ('start', 'start'), ('building', 'build'), ('traditionally', 'tradit'), ('thought', 'thought'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (',', ','), ('includes', 'includ'), ('defining', 'defin'), ('key', 'key'), ('metrics', 'metric'), ('track', 'track'), (',', ','), ('identifying', 'identifi'), ('seasonality', 'season'), ('impacts', 'impact'), ('product', 'product'), ('sales', 'sale'), ('operations', 'oper'), (',', ','), ('segmenting', 'segment'), ('users', 'user'), ('based', 'base'), ('demographic', 'demograph'), ('factors', 'factor'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('teams', 'team'), ('reliably', 'reliabl'), ('explore', 'explor'), ('clean', 'clean'), ('data', 'data'), (',', ','), ('organizations', 'organ'), ('start', 'start'), ('building', 'build'), ('traditionally', 'tradit'), ('thought', 'thought'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (',', ','), ('includes', 'includ'), ('defining', 'defin'), ('key', 'key'), ('metrics', 'metric'), ('track', 'track'), (',', ','), ('identifying', 'identifi'), ('seasonality', 'season'), ('impacts', 'impact'), ('product', 'product'), ('sales', 'sale'), ('operations', 'oper'), (',', ','), ('segmenting', 'segment'), ('users', 'user'), ('based', 'base'), ('demographic', 'demograph'), ('factors', 'factor'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('teams', 'team'), ('reliably', 'reliably'), ('explore', 'explore'), ('clean', 'clean'), ('data', 'data'), (',', ','), ('organizations', 'organization'), ('start', 'start'), ('building', 'building'), ('traditionally', 'traditionally'), ('thought', 'thought'), ('business', 'business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), (',', ','), ('includes', 'includes'), ('defining', 'defining'), ('key', 'key'), ('metrics', 'metric'), ('track', 'track'), (',', ','), ('identifying', 'identifying'), ('seasonality', 'seasonality'), ('impacts', 'impact'), ('product', 'product'), ('sales', 'sale'), ('operations', 'operation'), (',', ','), ('segmenting', 'segmenting'), ('users', 'user'), ('based', 'based'), ('demographic', 'demographic'), ('factors', 'factor'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 114 =============================

However, as the goal is to build an artificial intelligence  solution, it is important to start thinking about the features or attributes to include  in machine learning models, what training data the machine will need to learn, what  to predict and automate and how to create the labels from which the machine will  learn. 


>> Tokens are: 
 ['However', ',', 'goal', 'build', 'artificial', 'intelligence', 'solution', ',', 'important', 'start', 'thinking', 'features', 'attributes', 'include', 'machine', 'learning', 'models', ',', 'training', 'data', 'machine', 'need', 'learn', ',', 'predict', 'automate', 'create', 'labels', 'machine', 'learn', '.']

>> Bigrams are: 
 [('However', ','), (',', 'goal'), ('goal', 'build'), ('build', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'solution'), ('solution', ','), (',', 'important'), ('important', 'start'), ('start', 'thinking'), ('thinking', 'features'), ('features', 'attributes'), ('attributes', 'include'), ('include', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', ','), (',', 'training'), ('training', 'data'), ('data', 'machine'), ('machine', 'need'), ('need', 'learn'), ('learn', ','), (',', 'predict'), ('predict', 'automate'), ('automate', 'create'), ('create', 'labels'), ('labels', 'machine'), ('machine', 'learn'), ('learn', '.')]

>> Trigrams are: 
 [('However', ',', 'goal'), (',', 'goal', 'build'), ('goal', 'build', 'artificial'), ('build', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'solution'), ('intelligence', 'solution', ','), ('solution', ',', 'important'), (',', 'important', 'start'), ('important', 'start', 'thinking'), ('start', 'thinking', 'features'), ('thinking', 'features', 'attributes'), ('features', 'attributes', 'include'), ('attributes', 'include', 'machine'), ('include', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', ','), ('models', ',', 'training'), (',', 'training', 'data'), ('training', 'data', 'machine'), ('data', 'machine', 'need'), ('machine', 'need', 'learn'), ('need', 'learn', ','), ('learn', ',', 'predict'), (',', 'predict', 'automate'), ('predict', 'automate', 'create'), ('automate', 'create', 'labels'), ('create', 'labels', 'machine'), ('labels', 'machine', 'learn'), ('machine', 'learn', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('goal', 'NN'), ('build', 'VBP'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('solution', 'NN'), (',', ','), ('important', 'JJ'), ('start', 'NN'), ('thinking', 'NN'), ('features', 'NNS'), ('attributes', 'VBZ'), ('include', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('models', 'NNS'), (',', ','), ('training', 'VBG'), ('data', 'NNS'), ('machine', 'NN'), ('need', 'NN'), ('learn', 'NN'), (',', ','), ('predict', 'VBP'), ('automate', 'JJ'), ('create', 'NN'), ('labels', 'NNS'), ('machine', 'NN'), ('learn', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP goal/NN)
  build/VBP
  (NP artificial/JJ intelligence/NN solution/NN)
  ,/,
  (NP important/JJ start/NN thinking/NN features/NNS)
  attributes/VBZ
  include/VBP
  (NP machine/NN learning/NN models/NNS)
  ,/,
  training/VBG
  (NP data/NNS machine/NN need/NN learn/NN)
  ,/,
  predict/VBP
  (NP automate/JJ create/NN labels/NNS machine/NN learn/NN)
  ./.) 


>> Noun Phrases are: 
 ['goal', 'artificial intelligence solution', 'important start thinking features', 'machine learning models', 'data machine need learn', 'automate create labels machine learn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('goal', 'goal'), ('build', 'build'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('solution', 'solut'), (',', ','), ('important', 'import'), ('start', 'start'), ('thinking', 'think'), ('features', 'featur'), ('attributes', 'attribut'), ('include', 'includ'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), (',', ','), ('training', 'train'), ('data', 'data'), ('machine', 'machin'), ('need', 'need'), ('learn', 'learn'), (',', ','), ('predict', 'predict'), ('automate', 'autom'), ('create', 'creat'), ('labels', 'label'), ('machine', 'machin'), ('learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('goal', 'goal'), ('build', 'build'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('solution', 'solut'), (',', ','), ('important', 'import'), ('start', 'start'), ('thinking', 'think'), ('features', 'featur'), ('attributes', 'attribut'), ('include', 'includ'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), (',', ','), ('training', 'train'), ('data', 'data'), ('machine', 'machin'), ('need', 'need'), ('learn', 'learn'), (',', ','), ('predict', 'predict'), ('automate', 'autom'), ('create', 'creat'), ('labels', 'label'), ('machine', 'machin'), ('learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('goal', 'goal'), ('build', 'build'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('solution', 'solution'), (',', ','), ('important', 'important'), ('start', 'start'), ('thinking', 'thinking'), ('features', 'feature'), ('attributes', 'attribute'), ('include', 'include'), ('machine', 'machine'), ('learning', 'learning'), ('models', 'model'), (',', ','), ('training', 'training'), ('data', 'data'), ('machine', 'machine'), ('need', 'need'), ('learn', 'learn'), (',', ','), ('predict', 'predict'), ('automate', 'automate'), ('create', 'create'), ('labels', 'label'), ('machine', 'machine'), ('learn', 'learn'), ('.', '.')]



============================ Sentence 115 =============================

Label creation can be done automatically, such as when the machine breaks  down and it automatically registers an event in the back-end system. 


>> Tokens are: 
 ['Label', 'creation', 'done', 'automatically', ',', 'machine', 'breaks', 'automatically', 'registers', 'event', 'back-end', 'system', '.']

>> Bigrams are: 
 [('Label', 'creation'), ('creation', 'done'), ('done', 'automatically'), ('automatically', ','), (',', 'machine'), ('machine', 'breaks'), ('breaks', 'automatically'), ('automatically', 'registers'), ('registers', 'event'), ('event', 'back-end'), ('back-end', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Label', 'creation', 'done'), ('creation', 'done', 'automatically'), ('done', 'automatically', ','), ('automatically', ',', 'machine'), (',', 'machine', 'breaks'), ('machine', 'breaks', 'automatically'), ('breaks', 'automatically', 'registers'), ('automatically', 'registers', 'event'), ('registers', 'event', 'back-end'), ('event', 'back-end', 'system'), ('back-end', 'system', '.')]

>> POS Tags are: 
 [('Label', 'NNP'), ('creation', 'NN'), ('done', 'VBN'), ('automatically', 'RB'), (',', ','), ('machine', 'NN'), ('breaks', 'NNS'), ('automatically', 'RB'), ('registers', 'NNS'), ('event', 'NN'), ('back-end', 'NN'), ('system', 'NN'), ('.', '.')]

 (S
  (NP Label/NNP creation/NN)
  done/VBN
  automatically/RB
  ,/,
  (NP machine/NN breaks/NNS)
  automatically/RB
  (NP registers/NNS event/NN back-end/NN system/NN)
  ./.) 


>> Noun Phrases are: 
 ['Label creation', 'machine breaks', 'registers event back-end system']

>> Named Entities are: 
 [('GPE', 'Label')] 

>> Stemming using Porter Stemmer: 
 [('Label', 'label'), ('creation', 'creation'), ('done', 'done'), ('automatically', 'automat'), (',', ','), ('machine', 'machin'), ('breaks', 'break'), ('automatically', 'automat'), ('registers', 'regist'), ('event', 'event'), ('back-end', 'back-end'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Label', 'label'), ('creation', 'creation'), ('done', 'done'), ('automatically', 'automat'), (',', ','), ('machine', 'machin'), ('breaks', 'break'), ('automatically', 'automat'), ('registers', 'regist'), ('event', 'event'), ('back-end', 'back-end'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Label', 'Label'), ('creation', 'creation'), ('done', 'done'), ('automatically', 'automatically'), (',', ','), ('machine', 'machine'), ('breaks', 'break'), ('automatically', 'automatically'), ('registers', 'register'), ('event', 'event'), ('back-end', 'back-end'), ('system', 'system'), ('.', '.')]



============================ Sentence 116 =============================

Or, it can  be done by introducing humans. 


>> Tokens are: 
 ['Or', ',', 'done', 'introducing', 'humans', '.']

>> Bigrams are: 
 [('Or', ','), (',', 'done'), ('done', 'introducing'), ('introducing', 'humans'), ('humans', '.')]

>> Trigrams are: 
 [('Or', ',', 'done'), (',', 'done', 'introducing'), ('done', 'introducing', 'humans'), ('introducing', 'humans', '.')]

>> POS Tags are: 
 [('Or', 'CC'), (',', ','), ('done', 'VBN'), ('introducing', 'NN'), ('humans', 'NNS'), ('.', '.')]

 (S Or/CC ,/, done/VBN (NP introducing/NN humans/NNS) ./.) 


>> Noun Phrases are: 
 ['introducing humans']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Or', 'or'), (',', ','), ('done', 'done'), ('introducing', 'introduc'), ('humans', 'human'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Or', 'or'), (',', ','), ('done', 'done'), ('introducing', 'introduc'), ('humans', 'human'), ('.', '.')]

>> Lemmatization: 
 [('Or', 'Or'), (',', ','), ('done', 'done'), ('introducing', 'introducing'), ('humans', 'human'), ('.', '.')]



============================ Sentence 117 =============================

For example, an engineer reports an issue when  a machine part seems to be faulty during a routine inspection and the result is  manually added to the data. 


>> Tokens are: 
 ['For', 'example', ',', 'engineer', 'reports', 'issue', 'machine', 'part', 'seems', 'faulty', 'routine', 'inspection', 'result', 'manually', 'added', 'data', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'engineer'), ('engineer', 'reports'), ('reports', 'issue'), ('issue', 'machine'), ('machine', 'part'), ('part', 'seems'), ('seems', 'faulty'), ('faulty', 'routine'), ('routine', 'inspection'), ('inspection', 'result'), ('result', 'manually'), ('manually', 'added'), ('added', 'data'), ('data', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'engineer'), (',', 'engineer', 'reports'), ('engineer', 'reports', 'issue'), ('reports', 'issue', 'machine'), ('issue', 'machine', 'part'), ('machine', 'part', 'seems'), ('part', 'seems', 'faulty'), ('seems', 'faulty', 'routine'), ('faulty', 'routine', 'inspection'), ('routine', 'inspection', 'result'), ('inspection', 'result', 'manually'), ('result', 'manually', 'added'), ('manually', 'added', 'data'), ('added', 'data', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('engineer', 'VB'), ('reports', 'NNS'), ('issue', 'NN'), ('machine', 'NN'), ('part', 'NN'), ('seems', 'VBZ'), ('faulty', 'JJ'), ('routine', 'JJ'), ('inspection', 'NN'), ('result', 'NN'), ('manually', 'RB'), ('added', 'VBD'), ('data', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  engineer/VB
  (NP reports/NNS issue/NN machine/NN part/NN)
  seems/VBZ
  (NP faulty/JJ routine/JJ inspection/NN result/NN)
  manually/RB
  added/VBD
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['example', 'reports issue machine part', 'faulty routine inspection result', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('engineer', 'engin'), ('reports', 'report'), ('issue', 'issu'), ('machine', 'machin'), ('part', 'part'), ('seems', 'seem'), ('faulty', 'faulti'), ('routine', 'routin'), ('inspection', 'inspect'), ('result', 'result'), ('manually', 'manual'), ('added', 'ad'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('engineer', 'engin'), ('reports', 'report'), ('issue', 'issu'), ('machine', 'machin'), ('part', 'part'), ('seems', 'seem'), ('faulty', 'faulti'), ('routine', 'routin'), ('inspection', 'inspect'), ('result', 'result'), ('manually', 'manual'), ('added', 'ad'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('engineer', 'engineer'), ('reports', 'report'), ('issue', 'issue'), ('machine', 'machine'), ('part', 'part'), ('seems', 'seems'), ('faulty', 'faulty'), ('routine', 'routine'), ('inspection', 'inspection'), ('result', 'result'), ('manually', 'manually'), ('added', 'added'), ('data', 'data'), ('.', '.')]



============================ Sentence 118 =============================

Machine learning and benchmarking. 


>> Tokens are: 
 ['Machine', 'learning', 'benchmarking', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'benchmarking'), ('benchmarking', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'benchmarking'), ('learning', 'benchmarking', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('benchmarking', 'NN'), ('.', '.')]

 (S (NP Machine/NN) learning/VBG (NP benchmarking/NN) ./.) 


>> Noun Phrases are: 
 ['Machine', 'benchmarking']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('benchmarking', 'benchmark'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('benchmarking', 'benchmarking'), ('.', '.')]



============================ Sentence 119 =============================

Although there is sample datathat can be  used to make predictions, work is not complete. 


>> Tokens are: 
 ['Although', 'sample', 'data', 'used', 'make', 'predictions', ',', 'work', 'complete', '.']

>> Bigrams are: 
 [('Although', 'sample'), ('sample', 'data'), ('data', 'used'), ('used', 'make'), ('make', 'predictions'), ('predictions', ','), (',', 'work'), ('work', 'complete'), ('complete', '.')]

>> Trigrams are: 
 [('Although', 'sample', 'data'), ('sample', 'data', 'used'), ('data', 'used', 'make'), ('used', 'make', 'predictions'), ('make', 'predictions', ','), ('predictions', ',', 'work'), (',', 'work', 'complete'), ('work', 'complete', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('sample', 'NN'), ('data', 'NNS'), ('used', 'VBD'), ('make', 'JJ'), ('predictions', 'NNS'), (',', ','), ('work', 'NN'), ('complete', 'NN'), ('.', '.')]

 (S
  Although/IN
  (NP sample/NN data/NNS)
  used/VBD
  (NP make/JJ predictions/NNS)
  ,/,
  (NP work/NN complete/NN)
  ./.) 


>> Noun Phrases are: 
 ['sample data', 'make predictions', 'work complete']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('sample', 'sampl'), ('data', 'data'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), (',', ','), ('work', 'work'), ('complete', 'complet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('sample', 'sampl'), ('data', 'data'), ('used', 'use'), ('make', 'make'), ('predictions', 'predict'), (',', ','), ('work', 'work'), ('complete', 'complet'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('sample', 'sample'), ('data', 'data'), ('used', 'used'), ('make', 'make'), ('predictions', 'prediction'), (',', ','), ('work', 'work'), ('complete', 'complete'), ('.', '.')]



============================ Sentence 120 =============================

A/B testing or experimentation  framework needs to be in place to deploy models incrementally and avoid real  world disasters. 


>> Tokens are: 
 ['A/B', 'testing', 'experimentation', 'framework', 'needs', 'place', 'deploy', 'models', 'incrementally', 'avoid', 'real', 'world', 'disasters', '.']

>> Bigrams are: 
 [('A/B', 'testing'), ('testing', 'experimentation'), ('experimentation', 'framework'), ('framework', 'needs'), ('needs', 'place'), ('place', 'deploy'), ('deploy', 'models'), ('models', 'incrementally'), ('incrementally', 'avoid'), ('avoid', 'real'), ('real', 'world'), ('world', 'disasters'), ('disasters', '.')]

>> Trigrams are: 
 [('A/B', 'testing', 'experimentation'), ('testing', 'experimentation', 'framework'), ('experimentation', 'framework', 'needs'), ('framework', 'needs', 'place'), ('needs', 'place', 'deploy'), ('place', 'deploy', 'models'), ('deploy', 'models', 'incrementally'), ('models', 'incrementally', 'avoid'), ('incrementally', 'avoid', 'real'), ('avoid', 'real', 'world'), ('real', 'world', 'disasters'), ('world', 'disasters', '.')]

>> POS Tags are: 
 [('A/B', 'NNP'), ('testing', 'VBG'), ('experimentation', 'NN'), ('framework', 'NN'), ('needs', 'VBZ'), ('place', 'NN'), ('deploy', 'NN'), ('models', 'NNS'), ('incrementally', 'RB'), ('avoid', 'VBP'), ('real', 'JJ'), ('world', 'NN'), ('disasters', 'NNS'), ('.', '.')]

 (S
  (NP A/B/NNP)
  testing/VBG
  (NP experimentation/NN framework/NN)
  needs/VBZ
  (NP place/NN deploy/NN models/NNS)
  incrementally/RB
  avoid/VBP
  (NP real/JJ world/NN disasters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A/B', 'experimentation framework', 'place deploy models', 'real world disasters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A/B', 'a/b'), ('testing', 'test'), ('experimentation', 'experiment'), ('framework', 'framework'), ('needs', 'need'), ('place', 'place'), ('deploy', 'deploy'), ('models', 'model'), ('incrementally', 'increment'), ('avoid', 'avoid'), ('real', 'real'), ('world', 'world'), ('disasters', 'disast'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A/B', 'a/b'), ('testing', 'test'), ('experimentation', 'experiment'), ('framework', 'framework'), ('needs', 'need'), ('place', 'place'), ('deploy', 'deploy'), ('models', 'model'), ('incrementally', 'increment'), ('avoid', 'avoid'), ('real', 'real'), ('world', 'world'), ('disasters', 'disast'), ('.', '.')]

>> Lemmatization: 
 [('A/B', 'A/B'), ('testing', 'testing'), ('experimentation', 'experimentation'), ('framework', 'framework'), ('needs', 'need'), ('place', 'place'), ('deploy', 'deploy'), ('models', 'model'), ('incrementally', 'incrementally'), ('avoid', 'avoid'), ('real', 'real'), ('world', 'world'), ('disasters', 'disaster'), ('.', '.')]



============================ Sentence 121 =============================

Model validation and experimentation approaches provide a  rough estimate of the effects of changes before practical implementation. 


>> Tokens are: 
 ['Model', 'validation', 'experimentation', 'approaches', 'provide', 'rough', 'estimate', 'effects', 'changes', 'practical', 'implementation', '.']

>> Bigrams are: 
 [('Model', 'validation'), ('validation', 'experimentation'), ('experimentation', 'approaches'), ('approaches', 'provide'), ('provide', 'rough'), ('rough', 'estimate'), ('estimate', 'effects'), ('effects', 'changes'), ('changes', 'practical'), ('practical', 'implementation'), ('implementation', '.')]

>> Trigrams are: 
 [('Model', 'validation', 'experimentation'), ('validation', 'experimentation', 'approaches'), ('experimentation', 'approaches', 'provide'), ('approaches', 'provide', 'rough'), ('provide', 'rough', 'estimate'), ('rough', 'estimate', 'effects'), ('estimate', 'effects', 'changes'), ('effects', 'changes', 'practical'), ('changes', 'practical', 'implementation'), ('practical', 'implementation', '.')]

>> POS Tags are: 
 [('Model', 'NNP'), ('validation', 'NN'), ('experimentation', 'NN'), ('approaches', 'NNS'), ('provide', 'VBP'), ('rough', 'JJ'), ('estimate', 'NN'), ('effects', 'NNS'), ('changes', 'NNS'), ('practical', 'JJ'), ('implementation', 'NN'), ('.', '.')]

 (S
  (NP Model/NNP validation/NN experimentation/NN approaches/NNS)
  provide/VBP
  (NP rough/JJ estimate/NN effects/NNS changes/NNS)
  (NP practical/JJ implementation/NN)
  ./.) 


>> Noun Phrases are: 
 ['Model validation experimentation approaches', 'rough estimate effects changes', 'practical implementation']

>> Named Entities are: 
 [('GPE', 'Model')] 

>> Stemming using Porter Stemmer: 
 [('Model', 'model'), ('validation', 'valid'), ('experimentation', 'experiment'), ('approaches', 'approach'), ('provide', 'provid'), ('rough', 'rough'), ('estimate', 'estim'), ('effects', 'effect'), ('changes', 'chang'), ('practical', 'practic'), ('implementation', 'implement'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Model', 'model'), ('validation', 'valid'), ('experimentation', 'experiment'), ('approaches', 'approach'), ('provide', 'provid'), ('rough', 'rough'), ('estimate', 'estim'), ('effects', 'effect'), ('changes', 'chang'), ('practical', 'practic'), ('implementation', 'implement'), ('.', '.')]

>> Lemmatization: 
 [('Model', 'Model'), ('validation', 'validation'), ('experimentation', 'experimentation'), ('approaches', 'approach'), ('provide', 'provide'), ('rough', 'rough'), ('estimate', 'estimate'), ('effects', 'effect'), ('changes', 'change'), ('practical', 'practical'), ('implementation', 'implementation'), ('.', '.')]



============================ Sentence 122 =============================

At  this stage, a very simple baseline or benchmark for performance tracking should  be established. 


>> Tokens are: 
 ['At', 'stage', ',', 'simple', 'baseline', 'benchmark', 'performance', 'tracking', 'established', '.']

>> Bigrams are: 
 [('At', 'stage'), ('stage', ','), (',', 'simple'), ('simple', 'baseline'), ('baseline', 'benchmark'), ('benchmark', 'performance'), ('performance', 'tracking'), ('tracking', 'established'), ('established', '.')]

>> Trigrams are: 
 [('At', 'stage', ','), ('stage', ',', 'simple'), (',', 'simple', 'baseline'), ('simple', 'baseline', 'benchmark'), ('baseline', 'benchmark', 'performance'), ('benchmark', 'performance', 'tracking'), ('performance', 'tracking', 'established'), ('tracking', 'established', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('stage', 'NN'), (',', ','), ('simple', 'JJ'), ('baseline', 'NN'), ('benchmark', 'NN'), ('performance', 'NN'), ('tracking', 'VBG'), ('established', 'VBN'), ('.', '.')]

 (S
  At/IN
  (NP stage/NN)
  ,/,
  (NP simple/JJ baseline/NN benchmark/NN performance/NN)
  tracking/VBG
  established/VBN
  ./.) 


>> Noun Phrases are: 
 ['stage', 'simple baseline benchmark performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('stage', 'stage'), (',', ','), ('simple', 'simpl'), ('baseline', 'baselin'), ('benchmark', 'benchmark'), ('performance', 'perform'), ('tracking', 'track'), ('established', 'establish'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('stage', 'stage'), (',', ','), ('simple', 'simpl'), ('baseline', 'baselin'), ('benchmark', 'benchmark'), ('performance', 'perform'), ('tracking', 'track'), ('established', 'establish'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('stage', 'stage'), (',', ','), ('simple', 'simple'), ('baseline', 'baseline'), ('benchmark', 'benchmark'), ('performance', 'performance'), ('tracking', 'tracking'), ('established', 'established'), ('.', '.')]



============================ Sentence 123 =============================

An example fraud detection system includes monitoring high  risk credit card transactions that were proved to be fraudulent and comparing  them with the current operational performance of machine learning models to  accurately detect fraud. 


>> Tokens are: 
 ['An', 'example', 'fraud', 'detection', 'system', 'includes', 'monitoring', 'high', 'risk', 'credit', 'card', 'transactions', 'proved', 'fraudulent', 'comparing', 'current', 'operational', 'performance', 'machine', 'learning', 'models', 'accurately', 'detect', 'fraud', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', 'fraud'), ('fraud', 'detection'), ('detection', 'system'), ('system', 'includes'), ('includes', 'monitoring'), ('monitoring', 'high'), ('high', 'risk'), ('risk', 'credit'), ('credit', 'card'), ('card', 'transactions'), ('transactions', 'proved'), ('proved', 'fraudulent'), ('fraudulent', 'comparing'), ('comparing', 'current'), ('current', 'operational'), ('operational', 'performance'), ('performance', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'accurately'), ('accurately', 'detect'), ('detect', 'fraud'), ('fraud', '.')]

>> Trigrams are: 
 [('An', 'example', 'fraud'), ('example', 'fraud', 'detection'), ('fraud', 'detection', 'system'), ('detection', 'system', 'includes'), ('system', 'includes', 'monitoring'), ('includes', 'monitoring', 'high'), ('monitoring', 'high', 'risk'), ('high', 'risk', 'credit'), ('risk', 'credit', 'card'), ('credit', 'card', 'transactions'), ('card', 'transactions', 'proved'), ('transactions', 'proved', 'fraudulent'), ('proved', 'fraudulent', 'comparing'), ('fraudulent', 'comparing', 'current'), ('comparing', 'current', 'operational'), ('current', 'operational', 'performance'), ('operational', 'performance', 'machine'), ('performance', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'accurately'), ('models', 'accurately', 'detect'), ('accurately', 'detect', 'fraud'), ('detect', 'fraud', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('fraud', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('includes', 'VBZ'), ('monitoring', 'VBG'), ('high', 'JJ'), ('risk', 'NN'), ('credit', 'NN'), ('card', 'NN'), ('transactions', 'NNS'), ('proved', 'VBD'), ('fraudulent', 'JJ'), ('comparing', 'VBG'), ('current', 'JJ'), ('operational', 'JJ'), ('performance', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('models', 'NNS'), ('accurately', 'RB'), ('detect', 'JJ'), ('fraud', 'NN'), ('.', '.')]

 (S
  (NP An/DT example/NN fraud/NN detection/NN system/NN)
  includes/VBZ
  monitoring/VBG
  (NP high/JJ risk/NN credit/NN card/NN transactions/NNS)
  proved/VBD
  fraudulent/JJ
  comparing/VBG
  (NP current/JJ operational/JJ performance/NN machine/NN)
  learning/VBG
  (NP models/NNS)
  accurately/RB
  (NP detect/JJ fraud/NN)
  ./.) 


>> Noun Phrases are: 
 ['An example fraud detection system', 'high risk credit card transactions', 'current operational performance machine', 'models', 'detect fraud']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('fraud', 'fraud'), ('detection', 'detect'), ('system', 'system'), ('includes', 'includ'), ('monitoring', 'monitor'), ('high', 'high'), ('risk', 'risk'), ('credit', 'credit'), ('card', 'card'), ('transactions', 'transact'), ('proved', 'prove'), ('fraudulent', 'fraudul'), ('comparing', 'compar'), ('current', 'current'), ('operational', 'oper'), ('performance', 'perform'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), ('accurately', 'accur'), ('detect', 'detect'), ('fraud', 'fraud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('fraud', 'fraud'), ('detection', 'detect'), ('system', 'system'), ('includes', 'includ'), ('monitoring', 'monitor'), ('high', 'high'), ('risk', 'risk'), ('credit', 'credit'), ('card', 'card'), ('transactions', 'transact'), ('proved', 'prove'), ('fraudulent', 'fraudul'), ('comparing', 'compar'), ('current', 'current'), ('operational', 'oper'), ('performance', 'perform'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), ('accurately', 'accur'), ('detect', 'detect'), ('fraud', 'fraud'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('fraud', 'fraud'), ('detection', 'detection'), ('system', 'system'), ('includes', 'includes'), ('monitoring', 'monitoring'), ('high', 'high'), ('risk', 'risk'), ('credit', 'credit'), ('card', 'card'), ('transactions', 'transaction'), ('proved', 'proved'), ('fraudulent', 'fraudulent'), ('comparing', 'comparing'), ('current', 'current'), ('operational', 'operational'), ('performance', 'performance'), ('machine', 'machine'), ('learning', 'learning'), ('models', 'model'), ('accurately', 'accurately'), ('detect', 'detect'), ('fraud', 'fraud'), ('.', '.')]



============================ Sentence 124 =============================

Artificial intelligence. 


>> Tokens are: 
 ['Artificial', 'intelligence', '.']

>> Bigrams are: 
 [('Artificial', 'intelligence'), ('intelligence', '.')]

>> Trigrams are: 
 [('Artificial', 'intelligence', '.')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.')]

 (S (NP Artificial/JJ intelligence/NN) ./.) 


>> Noun Phrases are: 
 ['Artificial intelligence']

>> Named Entities are: 
 [('GPE', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('.', '.')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('.', '.')]



============================ Sentence 125 =============================

At this stage a team might be looking to make  improvements in production. 


>> Tokens are: 
 ['At', 'stage', 'team', 'might', 'looking', 'make', 'improvements', 'production', '.']

>> Bigrams are: 
 [('At', 'stage'), ('stage', 'team'), ('team', 'might'), ('might', 'looking'), ('looking', 'make'), ('make', 'improvements'), ('improvements', 'production'), ('production', '.')]

>> Trigrams are: 
 [('At', 'stage', 'team'), ('stage', 'team', 'might'), ('team', 'might', 'looking'), ('might', 'looking', 'make'), ('looking', 'make', 'improvements'), ('make', 'improvements', 'production'), ('improvements', 'production', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('stage', 'NN'), ('team', 'NN'), ('might', 'MD'), ('looking', 'VBG'), ('make', 'VB'), ('improvements', 'NNS'), ('production', 'NN'), ('.', '.')]

 (S
  At/IN
  (NP stage/NN team/NN)
  might/MD
  looking/VBG
  make/VB
  (NP improvements/NNS production/NN)
  ./.) 


>> Noun Phrases are: 
 ['stage team', 'improvements production']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('stage', 'stage'), ('team', 'team'), ('might', 'might'), ('looking', 'look'), ('make', 'make'), ('improvements', 'improv'), ('production', 'product'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('stage', 'stage'), ('team', 'team'), ('might', 'might'), ('looking', 'look'), ('make', 'make'), ('improvements', 'improv'), ('production', 'product'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('stage', 'stage'), ('team', 'team'), ('might', 'might'), ('looking', 'looking'), ('make', 'make'), ('improvements', 'improvement'), ('production', 'production'), ('.', '.')]



============================ Sentence 126 =============================

This can be achieved by learning new methods  and techniques in machine learning and deep learning to improve processes,  predictions, outcomes and insights. 


>> Tokens are: 
 ['This', 'achieved', 'learning', 'new', 'methods', 'techniques', 'machine', 'learning', 'deep', 'learning', 'improve', 'processes', ',', 'predictions', ',', 'outcomes', 'insights', '.']

>> Bigrams are: 
 [('This', 'achieved'), ('achieved', 'learning'), ('learning', 'new'), ('new', 'methods'), ('methods', 'techniques'), ('techniques', 'machine'), ('machine', 'learning'), ('learning', 'deep'), ('deep', 'learning'), ('learning', 'improve'), ('improve', 'processes'), ('processes', ','), (',', 'predictions'), ('predictions', ','), (',', 'outcomes'), ('outcomes', 'insights'), ('insights', '.')]

>> Trigrams are: 
 [('This', 'achieved', 'learning'), ('achieved', 'learning', 'new'), ('learning', 'new', 'methods'), ('new', 'methods', 'techniques'), ('methods', 'techniques', 'machine'), ('techniques', 'machine', 'learning'), ('machine', 'learning', 'deep'), ('learning', 'deep', 'learning'), ('deep', 'learning', 'improve'), ('learning', 'improve', 'processes'), ('improve', 'processes', ','), ('processes', ',', 'predictions'), (',', 'predictions', ','), ('predictions', ',', 'outcomes'), (',', 'outcomes', 'insights'), ('outcomes', 'insights', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('achieved', 'VBD'), ('learning', 'VBG'), ('new', 'JJ'), ('methods', 'NNS'), ('techniques', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('deep', 'JJ'), ('learning', 'NN'), ('improve', 'VB'), ('processes', 'NNS'), (',', ','), ('predictions', 'NNS'), (',', ','), ('outcomes', 'RB'), ('insights', 'NNS'), ('.', '.')]

 (S
  This/DT
  achieved/VBD
  learning/VBG
  (NP new/JJ methods/NNS techniques/NNS machine/NN)
  learning/VBG
  (NP deep/JJ learning/NN)
  improve/VB
  (NP processes/NNS)
  ,/,
  (NP predictions/NNS)
  ,/,
  outcomes/RB
  (NP insights/NNS)
  ./.) 


>> Noun Phrases are: 
 ['new methods techniques machine', 'deep learning', 'processes', 'predictions', 'insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('achieved', 'achiev'), ('learning', 'learn'), ('new', 'new'), ('methods', 'method'), ('techniques', 'techniqu'), ('machine', 'machin'), ('learning', 'learn'), ('deep', 'deep'), ('learning', 'learn'), ('improve', 'improv'), ('processes', 'process'), (',', ','), ('predictions', 'predict'), (',', ','), ('outcomes', 'outcom'), ('insights', 'insight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('achieved', 'achiev'), ('learning', 'learn'), ('new', 'new'), ('methods', 'method'), ('techniques', 'techniqu'), ('machine', 'machin'), ('learning', 'learn'), ('deep', 'deep'), ('learning', 'learn'), ('improve', 'improv'), ('processes', 'process'), (',', ','), ('predictions', 'predict'), (',', ','), ('outcomes', 'outcom'), ('insights', 'insight'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('achieved', 'achieved'), ('learning', 'learning'), ('new', 'new'), ('methods', 'method'), ('techniques', 'technique'), ('machine', 'machine'), ('learning', 'learning'), ('deep', 'deep'), ('learning', 'learning'), ('improve', 'improve'), ('processes', 'process'), (',', ','), ('predictions', 'prediction'), (',', ','), ('outcomes', 'outcome'), ('insights', 'insight'), ('.', '.')]



============================ Sentence 127 =============================

By leveraging advanced and new techniques,  teams can gain an Information Advantage from massive amounts of data, explore  and model it faster and build solutions, such as voice assistants. 


>> Tokens are: 
 ['By', 'leveraging', 'advanced', 'new', 'techniques', ',', 'teams', 'gain', 'Information', 'Advantage', 'massive', 'amounts', 'data', ',', 'explore', 'model', 'faster', 'build', 'solutions', ',', 'voice', 'assistants', '.']

>> Bigrams are: 
 [('By', 'leveraging'), ('leveraging', 'advanced'), ('advanced', 'new'), ('new', 'techniques'), ('techniques', ','), (',', 'teams'), ('teams', 'gain'), ('gain', 'Information'), ('Information', 'Advantage'), ('Advantage', 'massive'), ('massive', 'amounts'), ('amounts', 'data'), ('data', ','), (',', 'explore'), ('explore', 'model'), ('model', 'faster'), ('faster', 'build'), ('build', 'solutions'), ('solutions', ','), (',', 'voice'), ('voice', 'assistants'), ('assistants', '.')]

>> Trigrams are: 
 [('By', 'leveraging', 'advanced'), ('leveraging', 'advanced', 'new'), ('advanced', 'new', 'techniques'), ('new', 'techniques', ','), ('techniques', ',', 'teams'), (',', 'teams', 'gain'), ('teams', 'gain', 'Information'), ('gain', 'Information', 'Advantage'), ('Information', 'Advantage', 'massive'), ('Advantage', 'massive', 'amounts'), ('massive', 'amounts', 'data'), ('amounts', 'data', ','), ('data', ',', 'explore'), (',', 'explore', 'model'), ('explore', 'model', 'faster'), ('model', 'faster', 'build'), ('faster', 'build', 'solutions'), ('build', 'solutions', ','), ('solutions', ',', 'voice'), (',', 'voice', 'assistants'), ('voice', 'assistants', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('leveraging', 'VBG'), ('advanced', 'JJ'), ('new', 'JJ'), ('techniques', 'NNS'), (',', ','), ('teams', 'NNS'), ('gain', 'VBP'), ('Information', 'NNP'), ('Advantage', 'NNP'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), (',', ','), ('explore', 'RB'), ('model', 'NN'), ('faster', 'RBR'), ('build', 'JJ'), ('solutions', 'NNS'), (',', ','), ('voice', 'NN'), ('assistants', 'NNS'), ('.', '.')]

 (S
  By/IN
  leveraging/VBG
  (NP advanced/JJ new/JJ techniques/NNS)
  ,/,
  (NP teams/NNS)
  gain/VBP
  (NP Information/NNP Advantage/NNP)
  (NP massive/JJ amounts/NNS data/NNS)
  ,/,
  explore/RB
  (NP model/NN)
  faster/RBR
  (NP build/JJ solutions/NNS)
  ,/,
  (NP voice/NN assistants/NNS)
  ./.) 


>> Noun Phrases are: 
 ['advanced new techniques', 'teams', 'Information Advantage', 'massive amounts data', 'model', 'build solutions', 'voice assistants']

>> Named Entities are: 
 [('ORGANIZATION', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('leveraging', 'leverag'), ('advanced', 'advanc'), ('new', 'new'), ('techniques', 'techniqu'), (',', ','), ('teams', 'team'), ('gain', 'gain'), ('Information', 'inform'), ('Advantage', 'advantag'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), (',', ','), ('explore', 'explor'), ('model', 'model'), ('faster', 'faster'), ('build', 'build'), ('solutions', 'solut'), (',', ','), ('voice', 'voic'), ('assistants', 'assist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('leveraging', 'leverag'), ('advanced', 'advanc'), ('new', 'new'), ('techniques', 'techniqu'), (',', ','), ('teams', 'team'), ('gain', 'gain'), ('Information', 'inform'), ('Advantage', 'advantag'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), (',', ','), ('explore', 'explor'), ('model', 'model'), ('faster', 'faster'), ('build', 'build'), ('solutions', 'solut'), (',', ','), ('voice', 'voic'), ('assistants', 'assist'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('leveraging', 'leveraging'), ('advanced', 'advanced'), ('new', 'new'), ('techniques', 'technique'), (',', ','), ('teams', 'team'), ('gain', 'gain'), ('Information', 'Information'), ('Advantage', 'Advantage'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), (',', ','), ('explore', 'explore'), ('model', 'model'), ('faster', 'faster'), ('build', 'build'), ('solutions', 'solution'), (',', ','), ('voice', 'voice'), ('assistants', 'assistant'), ('.', '.')]



============================ Sentence 128 =============================

9/14Demystifying data science   How can data science, artificial intelligence and analytics  help transform business processes? 


>> Tokens are: 
 ['9/14Demystifying', 'data', 'science', 'How', 'data', 'science', ',', 'artificial', 'intelligence', 'analytics', 'help', 'transform', 'business', 'processes', '?']

>> Bigrams are: 
 [('9/14Demystifying', 'data'), ('data', 'science'), ('science', 'How'), ('How', 'data'), ('data', 'science'), ('science', ','), (',', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'analytics'), ('analytics', 'help'), ('help', 'transform'), ('transform', 'business'), ('business', 'processes'), ('processes', '?')]

>> Trigrams are: 
 [('9/14Demystifying', 'data', 'science'), ('data', 'science', 'How'), ('science', 'How', 'data'), ('How', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'artificial'), (',', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'analytics'), ('intelligence', 'analytics', 'help'), ('analytics', 'help', 'transform'), ('help', 'transform', 'business'), ('transform', 'business', 'processes'), ('business', 'processes', '?')]

>> POS Tags are: 
 [('9/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('How', 'NNP'), ('data', 'VBZ'), ('science', 'NN'), (',', ','), ('artificial', 'JJ'), ('intelligence', 'NN'), ('analytics', 'NNS'), ('help', 'VBP'), ('transform', 'VB'), ('business', 'NN'), ('processes', 'NNS'), ('?', '.')]

 (S
  9/14Demystifying/VBG
  (NP data/NNS science/NN How/NNP)
  data/VBZ
  (NP science/NN)
  ,/,
  (NP artificial/JJ intelligence/NN analytics/NNS)
  help/VBP
  transform/VB
  (NP business/NN processes/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['data science How', 'science', 'artificial intelligence analytics', 'business processes']

>> Named Entities are: 
 [('PERSON', 'How')] 

>> Stemming using Porter Stemmer: 
 [('9/14Demystifying', '9/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('help', 'help'), ('transform', 'transform'), ('business', 'busi'), ('processes', 'process'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('9/14Demystifying', '9/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('How', 'how'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('help', 'help'), ('transform', 'transform'), ('business', 'busi'), ('processes', 'process'), ('?', '?')]

>> Lemmatization: 
 [('9/14Demystifying', '9/14Demystifying'), ('data', 'data'), ('science', 'science'), ('How', 'How'), ('data', 'data'), ('science', 'science'), (',', ','), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), ('help', 'help'), ('transform', 'transform'), ('business', 'business'), ('processes', 'process'), ('?', '?')]



============================ Sentence 129 =============================

Data science is a multi-disciplinary field that uses scientific methods, processes,  algorithms and systems to extract knowledge and insights from structured and  unstructured data. 


>> Tokens are: 
 ['Data', 'science', 'multi-disciplinary', 'field', 'uses', 'scientific', 'methods', ',', 'processes', ',', 'algorithms', 'systems', 'extract', 'knowledge', 'insights', 'structured', 'unstructured', 'data', '.']

>> Bigrams are: 
 [('Data', 'science'), ('science', 'multi-disciplinary'), ('multi-disciplinary', 'field'), ('field', 'uses'), ('uses', 'scientific'), ('scientific', 'methods'), ('methods', ','), (',', 'processes'), ('processes', ','), (',', 'algorithms'), ('algorithms', 'systems'), ('systems', 'extract'), ('extract', 'knowledge'), ('knowledge', 'insights'), ('insights', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Data', 'science', 'multi-disciplinary'), ('science', 'multi-disciplinary', 'field'), ('multi-disciplinary', 'field', 'uses'), ('field', 'uses', 'scientific'), ('uses', 'scientific', 'methods'), ('scientific', 'methods', ','), ('methods', ',', 'processes'), (',', 'processes', ','), ('processes', ',', 'algorithms'), (',', 'algorithms', 'systems'), ('algorithms', 'systems', 'extract'), ('systems', 'extract', 'knowledge'), ('extract', 'knowledge', 'insights'), ('knowledge', 'insights', 'structured'), ('insights', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('science', 'NN'), ('multi-disciplinary', 'JJ'), ('field', 'NN'), ('uses', 'VBZ'), ('scientific', 'JJ'), ('methods', 'NNS'), (',', ','), ('processes', 'NNS'), (',', ','), ('algorithms', 'JJ'), ('systems', 'NNS'), ('extract', 'JJ'), ('knowledge', 'JJ'), ('insights', 'NNS'), ('structured', 'VBN'), ('unstructured', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP science/NN)
  (NP multi-disciplinary/JJ field/NN)
  uses/VBZ
  (NP scientific/JJ methods/NNS)
  ,/,
  (NP processes/NNS)
  ,/,
  (NP algorithms/JJ systems/NNS)
  (NP extract/JJ knowledge/JJ insights/NNS)
  structured/VBN
  (NP unstructured/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data science', 'multi-disciplinary field', 'scientific methods', 'processes', 'algorithms systems', 'extract knowledge insights', 'unstructured data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('multi-disciplinary', 'multi-disciplinari'), ('field', 'field'), ('uses', 'use'), ('scientific', 'scientif'), ('methods', 'method'), (',', ','), ('processes', 'process'), (',', ','), ('algorithms', 'algorithm'), ('systems', 'system'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('insights', 'insight'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('multi-disciplinary', 'multi-disciplinari'), ('field', 'field'), ('uses', 'use'), ('scientific', 'scientif'), ('methods', 'method'), (',', ','), ('processes', 'process'), (',', ','), ('algorithms', 'algorithm'), ('systems', 'system'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('insights', 'insight'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('science', 'science'), ('multi-disciplinary', 'multi-disciplinary'), ('field', 'field'), ('uses', 'us'), ('scientific', 'scientific'), ('methods', 'method'), (',', ','), ('processes', 'process'), (',', ','), ('algorithms', 'algorithm'), ('systems', 'system'), ('extract', 'extract'), ('knowledge', 'knowledge'), ('insights', 'insight'), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('.', '.')]



============================ Sentence 130 =============================

Because there are a number of different techniques and  methodologies, it is often difficult to narrow down the scope of how data science  can impact business performance, operations, customer experience and costs. 


>> Tokens are: 
 ['Because', 'number', 'different', 'techniques', 'methodologies', ',', 'often', 'difficult', 'narrow', 'scope', 'data', 'science', 'impact', 'business', 'performance', ',', 'operations', ',', 'customer', 'experience', 'costs', '.']

>> Bigrams are: 
 [('Because', 'number'), ('number', 'different'), ('different', 'techniques'), ('techniques', 'methodologies'), ('methodologies', ','), (',', 'often'), ('often', 'difficult'), ('difficult', 'narrow'), ('narrow', 'scope'), ('scope', 'data'), ('data', 'science'), ('science', 'impact'), ('impact', 'business'), ('business', 'performance'), ('performance', ','), (',', 'operations'), ('operations', ','), (',', 'customer'), ('customer', 'experience'), ('experience', 'costs'), ('costs', '.')]

>> Trigrams are: 
 [('Because', 'number', 'different'), ('number', 'different', 'techniques'), ('different', 'techniques', 'methodologies'), ('techniques', 'methodologies', ','), ('methodologies', ',', 'often'), (',', 'often', 'difficult'), ('often', 'difficult', 'narrow'), ('difficult', 'narrow', 'scope'), ('narrow', 'scope', 'data'), ('scope', 'data', 'science'), ('data', 'science', 'impact'), ('science', 'impact', 'business'), ('impact', 'business', 'performance'), ('business', 'performance', ','), ('performance', ',', 'operations'), (',', 'operations', ','), ('operations', ',', 'customer'), (',', 'customer', 'experience'), ('customer', 'experience', 'costs'), ('experience', 'costs', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('number', 'NN'), ('different', 'JJ'), ('techniques', 'NNS'), ('methodologies', 'NNS'), (',', ','), ('often', 'RB'), ('difficult', 'JJ'), ('narrow', 'JJ'), ('scope', 'NN'), ('data', 'NNS'), ('science', 'NN'), ('impact', 'NN'), ('business', 'NN'), ('performance', 'NN'), (',', ','), ('operations', 'NNS'), (',', ','), ('customer', 'NN'), ('experience', 'NN'), ('costs', 'NNS'), ('.', '.')]

 (S
  Because/IN
  (NP number/NN)
  (NP different/JJ techniques/NNS methodologies/NNS)
  ,/,
  often/RB
  (NP
    difficult/JJ
    narrow/JJ
    scope/NN
    data/NNS
    science/NN
    impact/NN
    business/NN
    performance/NN)
  ,/,
  (NP operations/NNS)
  ,/,
  (NP customer/NN experience/NN costs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['number', 'different techniques methodologies', 'difficult narrow scope data science impact business performance', 'operations', 'customer experience costs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('number', 'number'), ('different', 'differ'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), (',', ','), ('often', 'often'), ('difficult', 'difficult'), ('narrow', 'narrow'), ('scope', 'scope'), ('data', 'data'), ('science', 'scienc'), ('impact', 'impact'), ('business', 'busi'), ('performance', 'perform'), (',', ','), ('operations', 'oper'), (',', ','), ('customer', 'custom'), ('experience', 'experi'), ('costs', 'cost'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('number', 'number'), ('different', 'differ'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), (',', ','), ('often', 'often'), ('difficult', 'difficult'), ('narrow', 'narrow'), ('scope', 'scope'), ('data', 'data'), ('science', 'scienc'), ('impact', 'impact'), ('business', 'busi'), ('performance', 'perform'), (',', ','), ('operations', 'oper'), (',', ','), ('customer', 'custom'), ('experience', 'experi'), ('costs', 'cost'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('number', 'number'), ('different', 'different'), ('techniques', 'technique'), ('methodologies', 'methodology'), (',', ','), ('often', 'often'), ('difficult', 'difficult'), ('narrow', 'narrow'), ('scope', 'scope'), ('data', 'data'), ('science', 'science'), ('impact', 'impact'), ('business', 'business'), ('performance', 'performance'), (',', ','), ('operations', 'operation'), (',', ','), ('customer', 'customer'), ('experience', 'experience'), ('costs', 'cost'), ('.', '.')]



============================ Sentence 131 =============================

Here  are just a few ways data science can be leveraged. 


>> Tokens are: 
 ['Here', 'ways', 'data', 'science', 'leveraged', '.']

>> Bigrams are: 
 [('Here', 'ways'), ('ways', 'data'), ('data', 'science'), ('science', 'leveraged'), ('leveraged', '.')]

>> Trigrams are: 
 [('Here', 'ways', 'data'), ('ways', 'data', 'science'), ('data', 'science', 'leveraged'), ('science', 'leveraged', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('ways', 'NNS'), ('data', 'VBP'), ('science', 'NN'), ('leveraged', 'NN'), ('.', '.')]

 (S Here/RB (NP ways/NNS) data/VBP (NP science/NN leveraged/NN) ./.) 


>> Noun Phrases are: 
 ['ways', 'science leveraged']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('ways', 'way'), ('data', 'data'), ('science', 'scienc'), ('leveraged', 'leverag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('ways', 'way'), ('data', 'data'), ('science', 'scienc'), ('leveraged', 'leverag'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('ways', 'way'), ('data', 'data'), ('science', 'science'), ('leveraged', 'leveraged'), ('.', '.')]



============================ Sentence 132 =============================

Augment employee decisions with data-driven insights and intelligence   Utilize subject matter experts knowledge of how employees make business  decisions and transform the steps into data point, applying machine learning  techniques to identify the decision making pattern from this historical data to  predict future business outcomes. 


>> Tokens are: 
 ['Augment', 'employee', 'decisions', 'data-driven', 'insights', 'intelligence', 'Utilize', 'subject', 'matter', 'experts', '', 'knowledge', 'employees', 'make', 'business', 'decisions', 'transform', 'steps', 'data', 'point', ',', 'applying', 'machine', 'learning', 'techniques', 'identify', 'decision', 'making', 'pattern', 'historical', 'data', 'predict', 'future', 'business', 'outcomes', '.']

>> Bigrams are: 
 [('Augment', 'employee'), ('employee', 'decisions'), ('decisions', 'data-driven'), ('data-driven', 'insights'), ('insights', 'intelligence'), ('intelligence', 'Utilize'), ('Utilize', 'subject'), ('subject', 'matter'), ('matter', 'experts'), ('experts', ''), ('', 'knowledge'), ('knowledge', 'employees'), ('employees', 'make'), ('make', 'business'), ('business', 'decisions'), ('decisions', 'transform'), ('transform', 'steps'), ('steps', 'data'), ('data', 'point'), ('point', ','), (',', 'applying'), ('applying', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', 'identify'), ('identify', 'decision'), ('decision', 'making'), ('making', 'pattern'), ('pattern', 'historical'), ('historical', 'data'), ('data', 'predict'), ('predict', 'future'), ('future', 'business'), ('business', 'outcomes'), ('outcomes', '.')]

>> Trigrams are: 
 [('Augment', 'employee', 'decisions'), ('employee', 'decisions', 'data-driven'), ('decisions', 'data-driven', 'insights'), ('data-driven', 'insights', 'intelligence'), ('insights', 'intelligence', 'Utilize'), ('intelligence', 'Utilize', 'subject'), ('Utilize', 'subject', 'matter'), ('subject', 'matter', 'experts'), ('matter', 'experts', ''), ('experts', '', 'knowledge'), ('', 'knowledge', 'employees'), ('knowledge', 'employees', 'make'), ('employees', 'make', 'business'), ('make', 'business', 'decisions'), ('business', 'decisions', 'transform'), ('decisions', 'transform', 'steps'), ('transform', 'steps', 'data'), ('steps', 'data', 'point'), ('data', 'point', ','), ('point', ',', 'applying'), (',', 'applying', 'machine'), ('applying', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', 'identify'), ('techniques', 'identify', 'decision'), ('identify', 'decision', 'making'), ('decision', 'making', 'pattern'), ('making', 'pattern', 'historical'), ('pattern', 'historical', 'data'), ('historical', 'data', 'predict'), ('data', 'predict', 'future'), ('predict', 'future', 'business'), ('future', 'business', 'outcomes'), ('business', 'outcomes', '.')]

>> POS Tags are: 
 [('Augment', 'NNP'), ('employee', 'NN'), ('decisions', 'NNS'), ('data-driven', 'JJ'), ('insights', 'NNS'), ('intelligence', 'NN'), ('Utilize', 'NNP'), ('subject', 'JJ'), ('matter', 'NN'), ('experts', 'NNS'), ('', 'VBP'), ('knowledge', 'NN'), ('employees', 'NNS'), ('make', 'VBP'), ('business', 'NN'), ('decisions', 'NNS'), ('transform', 'VBP'), ('steps', 'NNS'), ('data', 'NNS'), ('point', 'NN'), (',', ','), ('applying', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), ('identify', 'VB'), ('decision', 'NN'), ('making', 'VBG'), ('pattern', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('predict', 'VBP'), ('future', 'JJ'), ('business', 'NN'), ('outcomes', 'NNS'), ('.', '.')]

 (S
  (NP Augment/NNP employee/NN decisions/NNS)
  (NP data-driven/JJ insights/NNS intelligence/NN Utilize/NNP)
  (NP subject/JJ matter/NN experts/NNS)
  /VBP
  (NP knowledge/NN employees/NNS)
  make/VBP
  (NP business/NN decisions/NNS)
  transform/VBP
  (NP steps/NNS data/NNS point/NN)
  ,/,
  applying/VBG
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  identify/VB
  (NP decision/NN)
  making/VBG
  (NP pattern/JJ historical/JJ data/NNS)
  predict/VBP
  (NP future/JJ business/NN outcomes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Augment employee decisions', 'data-driven insights intelligence Utilize', 'subject matter experts', 'knowledge employees', 'business decisions', 'steps data point', 'machine', 'techniques', 'decision', 'pattern historical data', 'future business outcomes']

>> Named Entities are: 
 [('PERSON', 'Utilize')] 

>> Stemming using Porter Stemmer: 
 [('Augment', 'augment'), ('employee', 'employe'), ('decisions', 'decis'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('intelligence', 'intellig'), ('Utilize', 'util'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('', ''), ('knowledge', 'knowledg'), ('employees', 'employe'), ('make', 'make'), ('business', 'busi'), ('decisions', 'decis'), ('transform', 'transform'), ('steps', 'step'), ('data', 'data'), ('point', 'point'), (',', ','), ('applying', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('identify', 'identifi'), ('decision', 'decis'), ('making', 'make'), ('pattern', 'pattern'), ('historical', 'histor'), ('data', 'data'), ('predict', 'predict'), ('future', 'futur'), ('business', 'busi'), ('outcomes', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Augment', 'augment'), ('employee', 'employe'), ('decisions', 'decis'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('intelligence', 'intellig'), ('Utilize', 'util'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('', ''), ('knowledge', 'knowledg'), ('employees', 'employe'), ('make', 'make'), ('business', 'busi'), ('decisions', 'decis'), ('transform', 'transform'), ('steps', 'step'), ('data', 'data'), ('point', 'point'), (',', ','), ('applying', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), ('identify', 'identifi'), ('decision', 'decis'), ('making', 'make'), ('pattern', 'pattern'), ('historical', 'histor'), ('data', 'data'), ('predict', 'predict'), ('future', 'futur'), ('business', 'busi'), ('outcomes', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('Augment', 'Augment'), ('employee', 'employee'), ('decisions', 'decision'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('intelligence', 'intelligence'), ('Utilize', 'Utilize'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('', ''), ('knowledge', 'knowledge'), ('employees', 'employee'), ('make', 'make'), ('business', 'business'), ('decisions', 'decision'), ('transform', 'transform'), ('steps', 'step'), ('data', 'data'), ('point', 'point'), (',', ','), ('applying', 'applying'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), ('identify', 'identify'), ('decision', 'decision'), ('making', 'making'), ('pattern', 'pattern'), ('historical', 'historical'), ('data', 'data'), ('predict', 'predict'), ('future', 'future'), ('business', 'business'), ('outcomes', 'outcome'), ('.', '.')]



============================ Sentence 133 =============================

Organizations can design an intelligent system  that can handle complex requests or tasks, provide intelligent/best fit decisions  for individual scenarios and empower employees to make decisions quickly and  more effectively. 


>> Tokens are: 
 ['Organizations', 'design', 'intelligent', 'system', 'handle', 'complex', 'requests', 'tasks', ',', 'provide', 'intelligent/best', 'fit', 'decisions', 'individual', 'scenarios', 'empower', 'employees', 'make', 'decisions', 'quickly', 'effectively', '.']

>> Bigrams are: 
 [('Organizations', 'design'), ('design', 'intelligent'), ('intelligent', 'system'), ('system', 'handle'), ('handle', 'complex'), ('complex', 'requests'), ('requests', 'tasks'), ('tasks', ','), (',', 'provide'), ('provide', 'intelligent/best'), ('intelligent/best', 'fit'), ('fit', 'decisions'), ('decisions', 'individual'), ('individual', 'scenarios'), ('scenarios', 'empower'), ('empower', 'employees'), ('employees', 'make'), ('make', 'decisions'), ('decisions', 'quickly'), ('quickly', 'effectively'), ('effectively', '.')]

>> Trigrams are: 
 [('Organizations', 'design', 'intelligent'), ('design', 'intelligent', 'system'), ('intelligent', 'system', 'handle'), ('system', 'handle', 'complex'), ('handle', 'complex', 'requests'), ('complex', 'requests', 'tasks'), ('requests', 'tasks', ','), ('tasks', ',', 'provide'), (',', 'provide', 'intelligent/best'), ('provide', 'intelligent/best', 'fit'), ('intelligent/best', 'fit', 'decisions'), ('fit', 'decisions', 'individual'), ('decisions', 'individual', 'scenarios'), ('individual', 'scenarios', 'empower'), ('scenarios', 'empower', 'employees'), ('empower', 'employees', 'make'), ('employees', 'make', 'decisions'), ('make', 'decisions', 'quickly'), ('decisions', 'quickly', 'effectively'), ('quickly', 'effectively', '.')]

>> POS Tags are: 
 [('Organizations', 'NNS'), ('design', 'VBP'), ('intelligent', 'JJ'), ('system', 'NN'), ('handle', 'VB'), ('complex', 'JJ'), ('requests', 'NNS'), ('tasks', 'NNS'), (',', ','), ('provide', 'VBP'), ('intelligent/best', 'JJS'), ('fit', 'NN'), ('decisions', 'NNS'), ('individual', 'JJ'), ('scenarios', 'NNS'), ('empower', 'VBP'), ('employees', 'NNS'), ('make', 'VBP'), ('decisions', 'NNS'), ('quickly', 'RB'), ('effectively', 'RB'), ('.', '.')]

 (S
  (NP Organizations/NNS)
  design/VBP
  (NP intelligent/JJ system/NN)
  handle/VB
  (NP complex/JJ requests/NNS tasks/NNS)
  ,/,
  provide/VBP
  intelligent/best/JJS
  (NP fit/NN decisions/NNS)
  (NP individual/JJ scenarios/NNS)
  empower/VBP
  (NP employees/NNS)
  make/VBP
  (NP decisions/NNS)
  quickly/RB
  effectively/RB
  ./.) 


>> Noun Phrases are: 
 ['Organizations', 'intelligent system', 'complex requests tasks', 'fit decisions', 'individual scenarios', 'employees', 'decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organizations', 'organ'), ('design', 'design'), ('intelligent', 'intellig'), ('system', 'system'), ('handle', 'handl'), ('complex', 'complex'), ('requests', 'request'), ('tasks', 'task'), (',', ','), ('provide', 'provid'), ('intelligent/best', 'intelligent/best'), ('fit', 'fit'), ('decisions', 'decis'), ('individual', 'individu'), ('scenarios', 'scenario'), ('empower', 'empow'), ('employees', 'employe'), ('make', 'make'), ('decisions', 'decis'), ('quickly', 'quickli'), ('effectively', 'effect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organizations', 'organ'), ('design', 'design'), ('intelligent', 'intellig'), ('system', 'system'), ('handle', 'handl'), ('complex', 'complex'), ('requests', 'request'), ('tasks', 'task'), (',', ','), ('provide', 'provid'), ('intelligent/best', 'intelligent/best'), ('fit', 'fit'), ('decisions', 'decis'), ('individual', 'individu'), ('scenarios', 'scenario'), ('empower', 'empow'), ('employees', 'employe'), ('make', 'make'), ('decisions', 'decis'), ('quickly', 'quick'), ('effectively', 'effect'), ('.', '.')]

>> Lemmatization: 
 [('Organizations', 'Organizations'), ('design', 'design'), ('intelligent', 'intelligent'), ('system', 'system'), ('handle', 'handle'), ('complex', 'complex'), ('requests', 'request'), ('tasks', 'task'), (',', ','), ('provide', 'provide'), ('intelligent/best', 'intelligent/best'), ('fit', 'fit'), ('decisions', 'decision'), ('individual', 'individual'), ('scenarios', 'scenario'), ('empower', 'empower'), ('employees', 'employee'), ('make', 'make'), ('decisions', 'decision'), ('quickly', 'quickly'), ('effectively', 'effectively'), ('.', '.')]



============================ Sentence 134 =============================

Some example uses include credit risk scoring, automated  underwriting, wealth management fund assistants and customer service chatbots. 


>> Tokens are: 
 ['Some', 'example', 'uses', 'include', 'credit', 'risk', 'scoring', ',', 'automated', 'underwriting', ',', 'wealth', 'management', 'fund', 'assistants', 'customer', 'service', 'chatbots', '.']

>> Bigrams are: 
 [('Some', 'example'), ('example', 'uses'), ('uses', 'include'), ('include', 'credit'), ('credit', 'risk'), ('risk', 'scoring'), ('scoring', ','), (',', 'automated'), ('automated', 'underwriting'), ('underwriting', ','), (',', 'wealth'), ('wealth', 'management'), ('management', 'fund'), ('fund', 'assistants'), ('assistants', 'customer'), ('customer', 'service'), ('service', 'chatbots'), ('chatbots', '.')]

>> Trigrams are: 
 [('Some', 'example', 'uses'), ('example', 'uses', 'include'), ('uses', 'include', 'credit'), ('include', 'credit', 'risk'), ('credit', 'risk', 'scoring'), ('risk', 'scoring', ','), ('scoring', ',', 'automated'), (',', 'automated', 'underwriting'), ('automated', 'underwriting', ','), ('underwriting', ',', 'wealth'), (',', 'wealth', 'management'), ('wealth', 'management', 'fund'), ('management', 'fund', 'assistants'), ('fund', 'assistants', 'customer'), ('assistants', 'customer', 'service'), ('customer', 'service', 'chatbots'), ('service', 'chatbots', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('example', 'NN'), ('uses', 'VBZ'), ('include', 'VBP'), ('credit', 'NN'), ('risk', 'NN'), ('scoring', 'NN'), (',', ','), ('automated', 'VBD'), ('underwriting', 'NN'), (',', ','), ('wealth', 'NN'), ('management', 'NN'), ('fund', 'NN'), ('assistants', 'NNS'), ('customer', 'NN'), ('service', 'NN'), ('chatbots', 'NNS'), ('.', '.')]

 (S
  (NP Some/DT example/NN)
  uses/VBZ
  include/VBP
  (NP credit/NN risk/NN scoring/NN)
  ,/,
  automated/VBD
  (NP underwriting/NN)
  ,/,
  (NP
    wealth/NN
    management/NN
    fund/NN
    assistants/NNS
    customer/NN
    service/NN
    chatbots/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Some example', 'credit risk scoring', 'underwriting', 'wealth management fund assistants customer service chatbots']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('example', 'exampl'), ('uses', 'use'), ('include', 'includ'), ('credit', 'credit'), ('risk', 'risk'), ('scoring', 'score'), (',', ','), ('automated', 'autom'), ('underwriting', 'underwrit'), (',', ','), ('wealth', 'wealth'), ('management', 'manag'), ('fund', 'fund'), ('assistants', 'assist'), ('customer', 'custom'), ('service', 'servic'), ('chatbots', 'chatbot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('example', 'exampl'), ('uses', 'use'), ('include', 'includ'), ('credit', 'credit'), ('risk', 'risk'), ('scoring', 'score'), (',', ','), ('automated', 'autom'), ('underwriting', 'underwrit'), (',', ','), ('wealth', 'wealth'), ('management', 'manag'), ('fund', 'fund'), ('assistants', 'assist'), ('customer', 'custom'), ('service', 'servic'), ('chatbots', 'chatbot'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('example', 'example'), ('uses', 'us'), ('include', 'include'), ('credit', 'credit'), ('risk', 'risk'), ('scoring', 'scoring'), (',', ','), ('automated', 'automated'), ('underwriting', 'underwriting'), (',', ','), ('wealth', 'wealth'), ('management', 'management'), ('fund', 'fund'), ('assistants', 'assistant'), ('customer', 'customer'), ('service', 'service'), ('chatbots', 'chatbots'), ('.', '.')]



============================ Sentence 135 =============================

Automate and improve the efficiency of operations with intelligent,   data-driven decisions  Leverage AI and analytics techniques to drive operational efficiency. 


>> Tokens are: 
 ['Automate', 'improve', 'efficiency', 'operations', 'intelligent', ',', 'data-driven', 'decisions', 'Leverage', 'AI', 'analytics', 'techniques', 'drive', 'operational', 'efficiency', '.']

>> Bigrams are: 
 [('Automate', 'improve'), ('improve', 'efficiency'), ('efficiency', 'operations'), ('operations', 'intelligent'), ('intelligent', ','), (',', 'data-driven'), ('data-driven', 'decisions'), ('decisions', 'Leverage'), ('Leverage', 'AI'), ('AI', 'analytics'), ('analytics', 'techniques'), ('techniques', 'drive'), ('drive', 'operational'), ('operational', 'efficiency'), ('efficiency', '.')]

>> Trigrams are: 
 [('Automate', 'improve', 'efficiency'), ('improve', 'efficiency', 'operations'), ('efficiency', 'operations', 'intelligent'), ('operations', 'intelligent', ','), ('intelligent', ',', 'data-driven'), (',', 'data-driven', 'decisions'), ('data-driven', 'decisions', 'Leverage'), ('decisions', 'Leverage', 'AI'), ('Leverage', 'AI', 'analytics'), ('AI', 'analytics', 'techniques'), ('analytics', 'techniques', 'drive'), ('techniques', 'drive', 'operational'), ('drive', 'operational', 'efficiency'), ('operational', 'efficiency', '.')]

>> POS Tags are: 
 [('Automate', 'NNP'), ('improve', 'VB'), ('efficiency', 'NN'), ('operations', 'NNS'), ('intelligent', 'JJ'), (',', ','), ('data-driven', 'JJ'), ('decisions', 'NNS'), ('Leverage', 'NNP'), ('AI', 'NNP'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('drive', 'VBP'), ('operational', 'JJ'), ('efficiency', 'NN'), ('.', '.')]

 (S
  (NP Automate/NNP)
  improve/VB
  (NP efficiency/NN operations/NNS)
  intelligent/JJ
  ,/,
  (NP
    data-driven/JJ
    decisions/NNS
    Leverage/NNP
    AI/NNP
    analytics/NNS
    techniques/NNS)
  drive/VBP
  (NP operational/JJ efficiency/NN)
  ./.) 


>> Noun Phrases are: 
 ['Automate', 'efficiency operations', 'data-driven decisions Leverage AI analytics techniques', 'operational efficiency']

>> Named Entities are: 
 [('GPE', 'Automate'), ('PERSON', 'Leverage AI')] 

>> Stemming using Porter Stemmer: 
 [('Automate', 'autom'), ('improve', 'improv'), ('efficiency', 'effici'), ('operations', 'oper'), ('intelligent', 'intellig'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('Leverage', 'leverag'), ('AI', 'ai'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('drive', 'drive'), ('operational', 'oper'), ('efficiency', 'effici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Automate', 'autom'), ('improve', 'improv'), ('efficiency', 'effici'), ('operations', 'oper'), ('intelligent', 'intellig'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('Leverage', 'leverag'), ('AI', 'ai'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('drive', 'drive'), ('operational', 'oper'), ('efficiency', 'effici'), ('.', '.')]

>> Lemmatization: 
 [('Automate', 'Automate'), ('improve', 'improve'), ('efficiency', 'efficiency'), ('operations', 'operation'), ('intelligent', 'intelligent'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decision'), ('Leverage', 'Leverage'), ('AI', 'AI'), ('analytics', 'analytics'), ('techniques', 'technique'), ('drive', 'drive'), ('operational', 'operational'), ('efficiency', 'efficiency'), ('.', '.')]



============================ Sentence 136 =============================

By utilizing  sensor information from machines, machine learning can help predict when a  specific machine is likely to require maintenance, allowing technicians to be  proactive rather than reactive in maintenance efforts. 


>> Tokens are: 
 ['By', 'utilizing', 'sensor', 'information', 'machines', ',', 'machine', 'learning', 'help', 'predict', 'specific', 'machine', 'likely', 'require', 'maintenance', ',', 'allowing', 'technicians', 'proactive', 'rather', 'reactive', 'maintenance', 'efforts', '.']

>> Bigrams are: 
 [('By', 'utilizing'), ('utilizing', 'sensor'), ('sensor', 'information'), ('information', 'machines'), ('machines', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'help'), ('help', 'predict'), ('predict', 'specific'), ('specific', 'machine'), ('machine', 'likely'), ('likely', 'require'), ('require', 'maintenance'), ('maintenance', ','), (',', 'allowing'), ('allowing', 'technicians'), ('technicians', 'proactive'), ('proactive', 'rather'), ('rather', 'reactive'), ('reactive', 'maintenance'), ('maintenance', 'efforts'), ('efforts', '.')]

>> Trigrams are: 
 [('By', 'utilizing', 'sensor'), ('utilizing', 'sensor', 'information'), ('sensor', 'information', 'machines'), ('information', 'machines', ','), ('machines', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'help'), ('learning', 'help', 'predict'), ('help', 'predict', 'specific'), ('predict', 'specific', 'machine'), ('specific', 'machine', 'likely'), ('machine', 'likely', 'require'), ('likely', 'require', 'maintenance'), ('require', 'maintenance', ','), ('maintenance', ',', 'allowing'), (',', 'allowing', 'technicians'), ('allowing', 'technicians', 'proactive'), ('technicians', 'proactive', 'rather'), ('proactive', 'rather', 'reactive'), ('rather', 'reactive', 'maintenance'), ('reactive', 'maintenance', 'efforts'), ('maintenance', 'efforts', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('utilizing', 'VBG'), ('sensor', 'JJ'), ('information', 'NN'), ('machines', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('help', 'NN'), ('predict', 'NN'), ('specific', 'JJ'), ('machine', 'NN'), ('likely', 'JJ'), ('require', 'NN'), ('maintenance', 'NN'), (',', ','), ('allowing', 'VBG'), ('technicians', 'NNS'), ('proactive', 'VBP'), ('rather', 'RB'), ('reactive', 'JJ'), ('maintenance', 'NN'), ('efforts', 'NNS'), ('.', '.')]

 (S
  By/IN
  utilizing/VBG
  (NP sensor/JJ information/NN machines/NNS)
  ,/,
  (NP machine/NN learning/NN help/NN predict/NN)
  (NP specific/JJ machine/NN)
  (NP likely/JJ require/NN maintenance/NN)
  ,/,
  allowing/VBG
  (NP technicians/NNS)
  proactive/VBP
  rather/RB
  (NP reactive/JJ maintenance/NN efforts/NNS)
  ./.) 


>> Noun Phrases are: 
 ['sensor information machines', 'machine learning help predict', 'specific machine', 'likely require maintenance', 'technicians', 'reactive maintenance efforts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('utilizing', 'util'), ('sensor', 'sensor'), ('information', 'inform'), ('machines', 'machin'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('help', 'help'), ('predict', 'predict'), ('specific', 'specif'), ('machine', 'machin'), ('likely', 'like'), ('require', 'requir'), ('maintenance', 'mainten'), (',', ','), ('allowing', 'allow'), ('technicians', 'technician'), ('proactive', 'proactiv'), ('rather', 'rather'), ('reactive', 'reactiv'), ('maintenance', 'mainten'), ('efforts', 'effort'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('utilizing', 'util'), ('sensor', 'sensor'), ('information', 'inform'), ('machines', 'machin'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('help', 'help'), ('predict', 'predict'), ('specific', 'specif'), ('machine', 'machin'), ('likely', 'like'), ('require', 'requir'), ('maintenance', 'mainten'), (',', ','), ('allowing', 'allow'), ('technicians', 'technician'), ('proactive', 'proactiv'), ('rather', 'rather'), ('reactive', 'reactiv'), ('maintenance', 'mainten'), ('efforts', 'effort'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('utilizing', 'utilizing'), ('sensor', 'sensor'), ('information', 'information'), ('machines', 'machine'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('help', 'help'), ('predict', 'predict'), ('specific', 'specific'), ('machine', 'machine'), ('likely', 'likely'), ('require', 'require'), ('maintenance', 'maintenance'), (',', ','), ('allowing', 'allowing'), ('technicians', 'technician'), ('proactive', 'proactive'), ('rather', 'rather'), ('reactive', 'reactive'), ('maintenance', 'maintenance'), ('efforts', 'effort'), ('.', '.')]



============================ Sentence 137 =============================

Some AI applications in this  context include predictive maintenance, recommender systems, robotic process  automation and airline scheduling. 


>> Tokens are: 
 ['Some', 'AI', 'applications', 'context', 'include', 'predictive', 'maintenance', ',', 'recommender', 'systems', ',', 'robotic', 'process', 'automation', 'airline', 'scheduling', '.']

>> Bigrams are: 
 [('Some', 'AI'), ('AI', 'applications'), ('applications', 'context'), ('context', 'include'), ('include', 'predictive'), ('predictive', 'maintenance'), ('maintenance', ','), (',', 'recommender'), ('recommender', 'systems'), ('systems', ','), (',', 'robotic'), ('robotic', 'process'), ('process', 'automation'), ('automation', 'airline'), ('airline', 'scheduling'), ('scheduling', '.')]

>> Trigrams are: 
 [('Some', 'AI', 'applications'), ('AI', 'applications', 'context'), ('applications', 'context', 'include'), ('context', 'include', 'predictive'), ('include', 'predictive', 'maintenance'), ('predictive', 'maintenance', ','), ('maintenance', ',', 'recommender'), (',', 'recommender', 'systems'), ('recommender', 'systems', ','), ('systems', ',', 'robotic'), (',', 'robotic', 'process'), ('robotic', 'process', 'automation'), ('process', 'automation', 'airline'), ('automation', 'airline', 'scheduling'), ('airline', 'scheduling', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('AI', 'NNP'), ('applications', 'NNS'), ('context', 'VBP'), ('include', 'VBP'), ('predictive', 'JJ'), ('maintenance', 'NN'), (',', ','), ('recommender', 'NN'), ('systems', 'NNS'), (',', ','), ('robotic', 'JJ'), ('process', 'NN'), ('automation', 'NN'), ('airline', 'NN'), ('scheduling', 'NN'), ('.', '.')]

 (S
  (NP Some/DT AI/NNP applications/NNS)
  context/VBP
  include/VBP
  (NP predictive/JJ maintenance/NN)
  ,/,
  (NP recommender/NN systems/NNS)
  ,/,
  (NP robotic/JJ process/NN automation/NN airline/NN scheduling/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some AI applications', 'predictive maintenance', 'recommender systems', 'robotic process automation airline scheduling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('AI', 'ai'), ('applications', 'applic'), ('context', 'context'), ('include', 'includ'), ('predictive', 'predict'), ('maintenance', 'mainten'), (',', ','), ('recommender', 'recommend'), ('systems', 'system'), (',', ','), ('robotic', 'robot'), ('process', 'process'), ('automation', 'autom'), ('airline', 'airlin'), ('scheduling', 'schedul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('AI', 'ai'), ('applications', 'applic'), ('context', 'context'), ('include', 'includ'), ('predictive', 'predict'), ('maintenance', 'mainten'), (',', ','), ('recommender', 'recommend'), ('systems', 'system'), (',', ','), ('robotic', 'robot'), ('process', 'process'), ('automation', 'autom'), ('airline', 'airlin'), ('scheduling', 'schedul'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('AI', 'AI'), ('applications', 'application'), ('context', 'context'), ('include', 'include'), ('predictive', 'predictive'), ('maintenance', 'maintenance'), (',', ','), ('recommender', 'recommender'), ('systems', 'system'), (',', ','), ('robotic', 'robotic'), ('process', 'process'), ('automation', 'automation'), ('airline', 'airline'), ('scheduling', 'scheduling'), ('.', '.')]



============================ Sentence 138 =============================

Apply data driven insights to make timely and consequential tactical   and strategic decisions  Better inform management and strategic decisions by leveraging machine learning  and advanced analytics. 


>> Tokens are: 
 ['Apply', 'data', 'driven', 'insights', 'make', 'timely', 'consequential', 'tactical', 'strategic', 'decisions', 'Better', 'inform', 'management', 'strategic', 'decisions', 'leveraging', 'machine', 'learning', 'advanced', 'analytics', '.']

>> Bigrams are: 
 [('Apply', 'data'), ('data', 'driven'), ('driven', 'insights'), ('insights', 'make'), ('make', 'timely'), ('timely', 'consequential'), ('consequential', 'tactical'), ('tactical', 'strategic'), ('strategic', 'decisions'), ('decisions', 'Better'), ('Better', 'inform'), ('inform', 'management'), ('management', 'strategic'), ('strategic', 'decisions'), ('decisions', 'leveraging'), ('leveraging', 'machine'), ('machine', 'learning'), ('learning', 'advanced'), ('advanced', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Apply', 'data', 'driven'), ('data', 'driven', 'insights'), ('driven', 'insights', 'make'), ('insights', 'make', 'timely'), ('make', 'timely', 'consequential'), ('timely', 'consequential', 'tactical'), ('consequential', 'tactical', 'strategic'), ('tactical', 'strategic', 'decisions'), ('strategic', 'decisions', 'Better'), ('decisions', 'Better', 'inform'), ('Better', 'inform', 'management'), ('inform', 'management', 'strategic'), ('management', 'strategic', 'decisions'), ('strategic', 'decisions', 'leveraging'), ('decisions', 'leveraging', 'machine'), ('leveraging', 'machine', 'learning'), ('machine', 'learning', 'advanced'), ('learning', 'advanced', 'analytics'), ('advanced', 'analytics', '.')]

>> POS Tags are: 
 [('Apply', 'NNP'), ('data', 'NNS'), ('driven', 'RB'), ('insights', 'NNS'), ('make', 'VBP'), ('timely', 'JJ'), ('consequential', 'JJ'), ('tactical', 'JJ'), ('strategic', 'JJ'), ('decisions', 'NNS'), ('Better', 'RBR'), ('inform', 'NN'), ('management', 'NN'), ('strategic', 'JJ'), ('decisions', 'NNS'), ('leveraging', 'VBG'), ('machine', 'NN'), ('learning', 'NN'), ('advanced', 'JJ'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Apply/NNP data/NNS)
  driven/RB
  (NP insights/NNS)
  make/VBP
  (NP
    timely/JJ
    consequential/JJ
    tactical/JJ
    strategic/JJ
    decisions/NNS)
  Better/RBR
  (NP inform/NN management/NN)
  (NP strategic/JJ decisions/NNS)
  leveraging/VBG
  (NP machine/NN learning/NN)
  (NP advanced/JJ analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Apply data', 'insights', 'timely consequential tactical strategic decisions', 'inform management', 'strategic decisions', 'machine learning', 'advanced analytics']

>> Named Entities are: 
 [('GPE', 'Apply')] 

>> Stemming using Porter Stemmer: 
 [('Apply', 'appli'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('make', 'make'), ('timely', 'time'), ('consequential', 'consequenti'), ('tactical', 'tactic'), ('strategic', 'strateg'), ('decisions', 'decis'), ('Better', 'better'), ('inform', 'inform'), ('management', 'manag'), ('strategic', 'strateg'), ('decisions', 'decis'), ('leveraging', 'leverag'), ('machine', 'machin'), ('learning', 'learn'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apply', 'appli'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('make', 'make'), ('timely', 'time'), ('consequential', 'consequenti'), ('tactical', 'tactic'), ('strategic', 'strateg'), ('decisions', 'decis'), ('Better', 'better'), ('inform', 'inform'), ('management', 'manag'), ('strategic', 'strateg'), ('decisions', 'decis'), ('leveraging', 'leverag'), ('machine', 'machin'), ('learning', 'learn'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Apply', 'Apply'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('make', 'make'), ('timely', 'timely'), ('consequential', 'consequential'), ('tactical', 'tactical'), ('strategic', 'strategic'), ('decisions', 'decision'), ('Better', 'Better'), ('inform', 'inform'), ('management', 'management'), ('strategic', 'strategic'), ('decisions', 'decision'), ('leveraging', 'leveraging'), ('machine', 'machine'), ('learning', 'learning'), ('advanced', 'advanced'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 139 =============================

These tend to be ad hoc projects or solutions, where  the goal is to apply statistical techniques to gain key insights around business  processes. 


>> Tokens are: 
 ['These', 'tend', 'ad', 'hoc', 'projects', 'solutions', ',', 'goal', 'apply', 'statistical', 'techniques', 'gain', 'key', 'insights', 'around', 'business', 'processes', '.']

>> Bigrams are: 
 [('These', 'tend'), ('tend', 'ad'), ('ad', 'hoc'), ('hoc', 'projects'), ('projects', 'solutions'), ('solutions', ','), (',', 'goal'), ('goal', 'apply'), ('apply', 'statistical'), ('statistical', 'techniques'), ('techniques', 'gain'), ('gain', 'key'), ('key', 'insights'), ('insights', 'around'), ('around', 'business'), ('business', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('These', 'tend', 'ad'), ('tend', 'ad', 'hoc'), ('ad', 'hoc', 'projects'), ('hoc', 'projects', 'solutions'), ('projects', 'solutions', ','), ('solutions', ',', 'goal'), (',', 'goal', 'apply'), ('goal', 'apply', 'statistical'), ('apply', 'statistical', 'techniques'), ('statistical', 'techniques', 'gain'), ('techniques', 'gain', 'key'), ('gain', 'key', 'insights'), ('key', 'insights', 'around'), ('insights', 'around', 'business'), ('around', 'business', 'processes'), ('business', 'processes', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('tend', 'VBP'), ('ad', 'NN'), ('hoc', 'NN'), ('projects', 'NNS'), ('solutions', 'NNS'), (',', ','), ('goal', 'NN'), ('apply', 'RB'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('gain', 'VBP'), ('key', 'JJ'), ('insights', 'NNS'), ('around', 'IN'), ('business', 'NN'), ('processes', 'NNS'), ('.', '.')]

 (S
  These/DT
  tend/VBP
  (NP ad/NN hoc/NN projects/NNS solutions/NNS)
  ,/,
  (NP goal/NN)
  apply/RB
  (NP statistical/JJ techniques/NNS)
  gain/VBP
  (NP key/JJ insights/NNS)
  around/IN
  (NP business/NN processes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['ad hoc projects solutions', 'goal', 'statistical techniques', 'key insights', 'business processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('tend', 'tend'), ('ad', 'ad'), ('hoc', 'hoc'), ('projects', 'project'), ('solutions', 'solut'), (',', ','), ('goal', 'goal'), ('apply', 'appli'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('gain', 'gain'), ('key', 'key'), ('insights', 'insight'), ('around', 'around'), ('business', 'busi'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('tend', 'tend'), ('ad', 'ad'), ('hoc', 'hoc'), ('projects', 'project'), ('solutions', 'solut'), (',', ','), ('goal', 'goal'), ('apply', 'appli'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('gain', 'gain'), ('key', 'key'), ('insights', 'insight'), ('around', 'around'), ('business', 'busi'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('tend', 'tend'), ('ad', 'ad'), ('hoc', 'hoc'), ('projects', 'project'), ('solutions', 'solution'), (',', ','), ('goal', 'goal'), ('apply', 'apply'), ('statistical', 'statistical'), ('techniques', 'technique'), ('gain', 'gain'), ('key', 'key'), ('insights', 'insight'), ('around', 'around'), ('business', 'business'), ('processes', 'process'), ('.', '.')]



============================ Sentence 140 =============================

For example, by measuring analytics related to cleanliness, customer  service, overall satisfaction, etc., an amusement park operations manager can  determine the likelihood of repeat customers, identify key gaps in operations and  better market the value of the park to the right demographics. 


>> Tokens are: 
 ['For', 'example', ',', 'measuring', 'analytics', 'related', 'cleanliness', ',', 'customer', 'service', ',', 'overall', 'satisfaction', ',', 'etc.', ',', 'amusement', 'park', 'operations', 'manager', 'determine', 'likelihood', 'repeat', 'customers', ',', 'identify', 'key', 'gaps', 'operations', 'better', 'market', 'value', 'park', 'right', 'demographics', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'measuring'), ('measuring', 'analytics'), ('analytics', 'related'), ('related', 'cleanliness'), ('cleanliness', ','), (',', 'customer'), ('customer', 'service'), ('service', ','), (',', 'overall'), ('overall', 'satisfaction'), ('satisfaction', ','), (',', 'etc.'), ('etc.', ','), (',', 'amusement'), ('amusement', 'park'), ('park', 'operations'), ('operations', 'manager'), ('manager', 'determine'), ('determine', 'likelihood'), ('likelihood', 'repeat'), ('repeat', 'customers'), ('customers', ','), (',', 'identify'), ('identify', 'key'), ('key', 'gaps'), ('gaps', 'operations'), ('operations', 'better'), ('better', 'market'), ('market', 'value'), ('value', 'park'), ('park', 'right'), ('right', 'demographics'), ('demographics', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'measuring'), (',', 'measuring', 'analytics'), ('measuring', 'analytics', 'related'), ('analytics', 'related', 'cleanliness'), ('related', 'cleanliness', ','), ('cleanliness', ',', 'customer'), (',', 'customer', 'service'), ('customer', 'service', ','), ('service', ',', 'overall'), (',', 'overall', 'satisfaction'), ('overall', 'satisfaction', ','), ('satisfaction', ',', 'etc.'), (',', 'etc.', ','), ('etc.', ',', 'amusement'), (',', 'amusement', 'park'), ('amusement', 'park', 'operations'), ('park', 'operations', 'manager'), ('operations', 'manager', 'determine'), ('manager', 'determine', 'likelihood'), ('determine', 'likelihood', 'repeat'), ('likelihood', 'repeat', 'customers'), ('repeat', 'customers', ','), ('customers', ',', 'identify'), (',', 'identify', 'key'), ('identify', 'key', 'gaps'), ('key', 'gaps', 'operations'), ('gaps', 'operations', 'better'), ('operations', 'better', 'market'), ('better', 'market', 'value'), ('market', 'value', 'park'), ('value', 'park', 'right'), ('park', 'right', 'demographics'), ('right', 'demographics', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('measuring', 'VBG'), ('analytics', 'NNS'), ('related', 'JJ'), ('cleanliness', 'NN'), (',', ','), ('customer', 'NN'), ('service', 'NN'), (',', ','), ('overall', 'JJ'), ('satisfaction', 'NN'), (',', ','), ('etc.', 'FW'), (',', ','), ('amusement', 'NN'), ('park', 'NN'), ('operations', 'NNS'), ('manager', 'NN'), ('determine', 'VBP'), ('likelihood', 'NN'), ('repeat', 'NN'), ('customers', 'NNS'), (',', ','), ('identify', 'VB'), ('key', 'JJ'), ('gaps', 'NNS'), ('operations', 'NNS'), ('better', 'VBP'), ('market', 'NN'), ('value', 'NN'), ('park', 'NN'), ('right', 'JJ'), ('demographics', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  measuring/VBG
  (NP analytics/NNS)
  (NP related/JJ cleanliness/NN)
  ,/,
  (NP customer/NN service/NN)
  ,/,
  (NP overall/JJ satisfaction/NN)
  ,/,
  etc./FW
  ,/,
  (NP amusement/NN park/NN operations/NNS manager/NN)
  determine/VBP
  (NP likelihood/NN repeat/NN customers/NNS)
  ,/,
  identify/VB
  (NP key/JJ gaps/NNS operations/NNS)
  better/VBP
  (NP market/NN value/NN park/NN)
  (NP right/JJ demographics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['example', 'analytics', 'related cleanliness', 'customer service', 'overall satisfaction', 'amusement park operations manager', 'likelihood repeat customers', 'key gaps operations', 'market value park', 'right demographics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('measuring', 'measur'), ('analytics', 'analyt'), ('related', 'relat'), ('cleanliness', 'cleanli'), (',', ','), ('customer', 'custom'), ('service', 'servic'), (',', ','), ('overall', 'overal'), ('satisfaction', 'satisfact'), (',', ','), ('etc.', 'etc.'), (',', ','), ('amusement', 'amus'), ('park', 'park'), ('operations', 'oper'), ('manager', 'manag'), ('determine', 'determin'), ('likelihood', 'likelihood'), ('repeat', 'repeat'), ('customers', 'custom'), (',', ','), ('identify', 'identifi'), ('key', 'key'), ('gaps', 'gap'), ('operations', 'oper'), ('better', 'better'), ('market', 'market'), ('value', 'valu'), ('park', 'park'), ('right', 'right'), ('demographics', 'demograph'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('measuring', 'measur'), ('analytics', 'analyt'), ('related', 'relat'), ('cleanliness', 'cleanli'), (',', ','), ('customer', 'custom'), ('service', 'servic'), (',', ','), ('overall', 'overal'), ('satisfaction', 'satisfact'), (',', ','), ('etc.', 'etc.'), (',', ','), ('amusement', 'amus'), ('park', 'park'), ('operations', 'oper'), ('manager', 'manag'), ('determine', 'determin'), ('likelihood', 'likelihood'), ('repeat', 'repeat'), ('customers', 'custom'), (',', ','), ('identify', 'identifi'), ('key', 'key'), ('gaps', 'gap'), ('operations', 'oper'), ('better', 'better'), ('market', 'market'), ('value', 'valu'), ('park', 'park'), ('right', 'right'), ('demographics', 'demograph'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('measuring', 'measuring'), ('analytics', 'analytics'), ('related', 'related'), ('cleanliness', 'cleanliness'), (',', ','), ('customer', 'customer'), ('service', 'service'), (',', ','), ('overall', 'overall'), ('satisfaction', 'satisfaction'), (',', ','), ('etc.', 'etc.'), (',', ','), ('amusement', 'amusement'), ('park', 'park'), ('operations', 'operation'), ('manager', 'manager'), ('determine', 'determine'), ('likelihood', 'likelihood'), ('repeat', 'repeat'), ('customers', 'customer'), (',', ','), ('identify', 'identify'), ('key', 'key'), ('gaps', 'gap'), ('operations', 'operation'), ('better', 'better'), ('market', 'market'), ('value', 'value'), ('park', 'park'), ('right', 'right'), ('demographics', 'demographic'), ('.', '.')]



============================ Sentence 141 =============================

Personalize customer experiences  Identify and recommend personalized products at scale with recommender  systems. 


>> Tokens are: 
 ['Personalize', 'customer', 'experiences', 'Identify', 'recommend', 'personalized', 'products', 'scale', 'recommender', 'systems', '.']

>> Bigrams are: 
 [('Personalize', 'customer'), ('customer', 'experiences'), ('experiences', 'Identify'), ('Identify', 'recommend'), ('recommend', 'personalized'), ('personalized', 'products'), ('products', 'scale'), ('scale', 'recommender'), ('recommender', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Personalize', 'customer', 'experiences'), ('customer', 'experiences', 'Identify'), ('experiences', 'Identify', 'recommend'), ('Identify', 'recommend', 'personalized'), ('recommend', 'personalized', 'products'), ('personalized', 'products', 'scale'), ('products', 'scale', 'recommender'), ('scale', 'recommender', 'systems'), ('recommender', 'systems', '.')]

>> POS Tags are: 
 [('Personalize', 'VB'), ('customer', 'NN'), ('experiences', 'NNS'), ('Identify', 'NNP'), ('recommend', 'VBP'), ('personalized', 'VBN'), ('products', 'NNS'), ('scale', 'JJ'), ('recommender', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  Personalize/VB
  (NP customer/NN experiences/NNS Identify/NNP)
  recommend/VBP
  personalized/VBN
  (NP products/NNS)
  (NP scale/JJ recommender/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['customer experiences Identify', 'products', 'scale recommender systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Personalize', 'person'), ('customer', 'custom'), ('experiences', 'experi'), ('Identify', 'identifi'), ('recommend', 'recommend'), ('personalized', 'person'), ('products', 'product'), ('scale', 'scale'), ('recommender', 'recommend'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Personalize', 'person'), ('customer', 'custom'), ('experiences', 'experi'), ('Identify', 'identifi'), ('recommend', 'recommend'), ('personalized', 'person'), ('products', 'product'), ('scale', 'scale'), ('recommender', 'recommend'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Personalize', 'Personalize'), ('customer', 'customer'), ('experiences', 'experience'), ('Identify', 'Identify'), ('recommend', 'recommend'), ('personalized', 'personalized'), ('products', 'product'), ('scale', 'scale'), ('recommender', 'recommender'), ('systems', 'system'), ('.', '.')]



============================ Sentence 142 =============================

The likes of Google, Amazon, Facebook and Apple have made  personalization an expectation. 


>> Tokens are: 
 ['The', 'likes', 'Google', ',', 'Amazon', ',', 'Facebook', 'Apple', 'made', 'personalization', 'expectation', '.']

>> Bigrams are: 
 [('The', 'likes'), ('likes', 'Google'), ('Google', ','), (',', 'Amazon'), ('Amazon', ','), (',', 'Facebook'), ('Facebook', 'Apple'), ('Apple', 'made'), ('made', 'personalization'), ('personalization', 'expectation'), ('expectation', '.')]

>> Trigrams are: 
 [('The', 'likes', 'Google'), ('likes', 'Google', ','), ('Google', ',', 'Amazon'), (',', 'Amazon', ','), ('Amazon', ',', 'Facebook'), (',', 'Facebook', 'Apple'), ('Facebook', 'Apple', 'made'), ('Apple', 'made', 'personalization'), ('made', 'personalization', 'expectation'), ('personalization', 'expectation', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('likes', 'NNS'), ('Google', 'NNP'), (',', ','), ('Amazon', 'NNP'), (',', ','), ('Facebook', 'NNP'), ('Apple', 'NNP'), ('made', 'VBD'), ('personalization', 'NN'), ('expectation', 'NN'), ('.', '.')]

 (S
  (NP The/DT likes/NNS Google/NNP)
  ,/,
  (NP Amazon/NNP)
  ,/,
  (NP Facebook/NNP Apple/NNP)
  made/VBD
  (NP personalization/NN expectation/NN)
  ./.) 


>> Noun Phrases are: 
 ['The likes Google', 'Amazon', 'Facebook Apple', 'personalization expectation']

>> Named Entities are: 
 [('PERSON', 'Google'), ('GPE', 'Amazon'), ('PERSON', 'Facebook Apple')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('likes', 'like'), ('Google', 'googl'), (',', ','), ('Amazon', 'amazon'), (',', ','), ('Facebook', 'facebook'), ('Apple', 'appl'), ('made', 'made'), ('personalization', 'person'), ('expectation', 'expect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('likes', 'like'), ('Google', 'googl'), (',', ','), ('Amazon', 'amazon'), (',', ','), ('Facebook', 'facebook'), ('Apple', 'appl'), ('made', 'made'), ('personalization', 'person'), ('expectation', 'expect'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('likes', 'like'), ('Google', 'Google'), (',', ','), ('Amazon', 'Amazon'), (',', ','), ('Facebook', 'Facebook'), ('Apple', 'Apple'), ('made', 'made'), ('personalization', 'personalization'), ('expectation', 'expectation'), ('.', '.')]



============================ Sentence 143 =============================

Recommender systems are one of the more  popular examples of how machine learning can be leveraged to analyze data  across millions of users to accomplish this. 


>> Tokens are: 
 ['Recommender', 'systems', 'one', 'popular', 'examples', 'machine', 'learning', 'leveraged', 'analyze', 'data', 'across', 'millions', 'users', 'accomplish', '.']

>> Bigrams are: 
 [('Recommender', 'systems'), ('systems', 'one'), ('one', 'popular'), ('popular', 'examples'), ('examples', 'machine'), ('machine', 'learning'), ('learning', 'leveraged'), ('leveraged', 'analyze'), ('analyze', 'data'), ('data', 'across'), ('across', 'millions'), ('millions', 'users'), ('users', 'accomplish'), ('accomplish', '.')]

>> Trigrams are: 
 [('Recommender', 'systems', 'one'), ('systems', 'one', 'popular'), ('one', 'popular', 'examples'), ('popular', 'examples', 'machine'), ('examples', 'machine', 'learning'), ('machine', 'learning', 'leveraged'), ('learning', 'leveraged', 'analyze'), ('leveraged', 'analyze', 'data'), ('analyze', 'data', 'across'), ('data', 'across', 'millions'), ('across', 'millions', 'users'), ('millions', 'users', 'accomplish'), ('users', 'accomplish', '.')]

>> POS Tags are: 
 [('Recommender', 'NNP'), ('systems', 'NNS'), ('one', 'CD'), ('popular', 'JJ'), ('examples', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('leveraged', 'JJ'), ('analyze', 'NN'), ('data', 'NNS'), ('across', 'IN'), ('millions', 'NNS'), ('users', 'NNS'), ('accomplish', 'VBP'), ('.', '.')]

 (S
  (NP Recommender/NNP systems/NNS)
  one/CD
  (NP popular/JJ examples/NNS machine/NN)
  learning/VBG
  (NP leveraged/JJ analyze/NN data/NNS)
  across/IN
  (NP millions/NNS users/NNS)
  accomplish/VBP
  ./.) 


>> Noun Phrases are: 
 ['Recommender systems', 'popular examples machine', 'leveraged analyze data', 'millions users']

>> Named Entities are: 
 [('GPE', 'Recommender')] 

>> Stemming using Porter Stemmer: 
 [('Recommender', 'recommend'), ('systems', 'system'), ('one', 'one'), ('popular', 'popular'), ('examples', 'exampl'), ('machine', 'machin'), ('learning', 'learn'), ('leveraged', 'leverag'), ('analyze', 'analyz'), ('data', 'data'), ('across', 'across'), ('millions', 'million'), ('users', 'user'), ('accomplish', 'accomplish'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recommender', 'recommend'), ('systems', 'system'), ('one', 'one'), ('popular', 'popular'), ('examples', 'exampl'), ('machine', 'machin'), ('learning', 'learn'), ('leveraged', 'leverag'), ('analyze', 'analyz'), ('data', 'data'), ('across', 'across'), ('millions', 'million'), ('users', 'user'), ('accomplish', 'accomplish'), ('.', '.')]

>> Lemmatization: 
 [('Recommender', 'Recommender'), ('systems', 'system'), ('one', 'one'), ('popular', 'popular'), ('examples', 'example'), ('machine', 'machine'), ('learning', 'learning'), ('leveraged', 'leveraged'), ('analyze', 'analyze'), ('data', 'data'), ('across', 'across'), ('millions', 'million'), ('users', 'user'), ('accomplish', 'accomplish'), ('.', '.')]



============================ Sentence 144 =============================

By analyzing and tracking various  customer touchpoints, some retailers are now able to predict the likelihood  of users buying future products. 


>> Tokens are: 
 ['By', 'analyzing', 'tracking', 'various', 'customer', 'touchpoints', ',', 'retailers', 'able', 'predict', 'likelihood', 'users', 'buying', 'future', 'products', '.']

>> Bigrams are: 
 [('By', 'analyzing'), ('analyzing', 'tracking'), ('tracking', 'various'), ('various', 'customer'), ('customer', 'touchpoints'), ('touchpoints', ','), (',', 'retailers'), ('retailers', 'able'), ('able', 'predict'), ('predict', 'likelihood'), ('likelihood', 'users'), ('users', 'buying'), ('buying', 'future'), ('future', 'products'), ('products', '.')]

>> Trigrams are: 
 [('By', 'analyzing', 'tracking'), ('analyzing', 'tracking', 'various'), ('tracking', 'various', 'customer'), ('various', 'customer', 'touchpoints'), ('customer', 'touchpoints', ','), ('touchpoints', ',', 'retailers'), (',', 'retailers', 'able'), ('retailers', 'able', 'predict'), ('able', 'predict', 'likelihood'), ('predict', 'likelihood', 'users'), ('likelihood', 'users', 'buying'), ('users', 'buying', 'future'), ('buying', 'future', 'products'), ('future', 'products', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('analyzing', 'VBG'), ('tracking', 'VBG'), ('various', 'JJ'), ('customer', 'NN'), ('touchpoints', 'NNS'), (',', ','), ('retailers', 'NNS'), ('able', 'JJ'), ('predict', 'JJ'), ('likelihood', 'NN'), ('users', 'NNS'), ('buying', 'VBG'), ('future', 'JJ'), ('products', 'NNS'), ('.', '.')]

 (S
  By/IN
  analyzing/VBG
  tracking/VBG
  (NP various/JJ customer/NN touchpoints/NNS)
  ,/,
  (NP retailers/NNS)
  (NP able/JJ predict/JJ likelihood/NN users/NNS)
  buying/VBG
  (NP future/JJ products/NNS)
  ./.) 


>> Noun Phrases are: 
 ['various customer touchpoints', 'retailers', 'able predict likelihood users', 'future products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('analyzing', 'analyz'), ('tracking', 'track'), ('various', 'variou'), ('customer', 'custom'), ('touchpoints', 'touchpoint'), (',', ','), ('retailers', 'retail'), ('able', 'abl'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('users', 'user'), ('buying', 'buy'), ('future', 'futur'), ('products', 'product'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('analyzing', 'analyz'), ('tracking', 'track'), ('various', 'various'), ('customer', 'custom'), ('touchpoints', 'touchpoint'), (',', ','), ('retailers', 'retail'), ('able', 'abl'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('users', 'user'), ('buying', 'buy'), ('future', 'futur'), ('products', 'product'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('analyzing', 'analyzing'), ('tracking', 'tracking'), ('various', 'various'), ('customer', 'customer'), ('touchpoints', 'touchpoints'), (',', ','), ('retailers', 'retailer'), ('able', 'able'), ('predict', 'predict'), ('likelihood', 'likelihood'), ('users', 'user'), ('buying', 'buying'), ('future', 'future'), ('products', 'product'), ('.', '.')]



============================ Sentence 145 =============================

It is important to note that machine learning  solutions need not be 100 percent accurate to realize business value and ROI. 


>> Tokens are: 
 ['It', 'important', 'note', 'machine', 'learning', 'solutions', 'need', '100', 'percent', 'accurate', 'realize', 'business', 'value', 'ROI', '.']

>> Bigrams are: 
 [('It', 'important'), ('important', 'note'), ('note', 'machine'), ('machine', 'learning'), ('learning', 'solutions'), ('solutions', 'need'), ('need', '100'), ('100', 'percent'), ('percent', 'accurate'), ('accurate', 'realize'), ('realize', 'business'), ('business', 'value'), ('value', 'ROI'), ('ROI', '.')]

>> Trigrams are: 
 [('It', 'important', 'note'), ('important', 'note', 'machine'), ('note', 'machine', 'learning'), ('machine', 'learning', 'solutions'), ('learning', 'solutions', 'need'), ('solutions', 'need', '100'), ('need', '100', 'percent'), ('100', 'percent', 'accurate'), ('percent', 'accurate', 'realize'), ('accurate', 'realize', 'business'), ('realize', 'business', 'value'), ('business', 'value', 'ROI'), ('value', 'ROI', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('important', 'JJ'), ('note', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('solutions', 'NNS'), ('need', 'VBP'), ('100', 'CD'), ('percent', 'JJ'), ('accurate', 'JJ'), ('realize', 'NN'), ('business', 'NN'), ('value', 'NN'), ('ROI', 'NNP'), ('.', '.')]

 (S
  It/PRP
  (NP important/JJ note/NN machine/NN)
  learning/VBG
  (NP solutions/NNS)
  need/VBP
  100/CD
  (NP percent/JJ accurate/JJ realize/NN business/NN value/NN ROI/NNP)
  ./.) 


>> Noun Phrases are: 
 ['important note machine', 'solutions', 'percent accurate realize business value ROI']

>> Named Entities are: 
 [('ORGANIZATION', 'ROI')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('important', 'import'), ('note', 'note'), ('machine', 'machin'), ('learning', 'learn'), ('solutions', 'solut'), ('need', 'need'), ('100', '100'), ('percent', 'percent'), ('accurate', 'accur'), ('realize', 'realiz'), ('business', 'busi'), ('value', 'valu'), ('ROI', 'roi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('important', 'import'), ('note', 'note'), ('machine', 'machin'), ('learning', 'learn'), ('solutions', 'solut'), ('need', 'need'), ('100', '100'), ('percent', 'percent'), ('accurate', 'accur'), ('realize', 'realiz'), ('business', 'busi'), ('value', 'valu'), ('ROI', 'roi'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('important', 'important'), ('note', 'note'), ('machine', 'machine'), ('learning', 'learning'), ('solutions', 'solution'), ('need', 'need'), ('100', '100'), ('percent', 'percent'), ('accurate', 'accurate'), ('realize', 'realize'), ('business', 'business'), ('value', 'value'), ('ROI', 'ROI'), ('.', '.')]



============================ Sentence 146 =============================

The goal should be to conduct data-driven decision making at scale to reduce  operational costs and optimize resources and targeting efforts. 


>> Tokens are: 
 ['The', 'goal', 'conduct', 'data-driven', 'decision', 'making', 'scale', 'reduce', 'operational', 'costs', 'optimize', 'resources', 'targeting', 'efforts', '.']

>> Bigrams are: 
 [('The', 'goal'), ('goal', 'conduct'), ('conduct', 'data-driven'), ('data-driven', 'decision'), ('decision', 'making'), ('making', 'scale'), ('scale', 'reduce'), ('reduce', 'operational'), ('operational', 'costs'), ('costs', 'optimize'), ('optimize', 'resources'), ('resources', 'targeting'), ('targeting', 'efforts'), ('efforts', '.')]

>> Trigrams are: 
 [('The', 'goal', 'conduct'), ('goal', 'conduct', 'data-driven'), ('conduct', 'data-driven', 'decision'), ('data-driven', 'decision', 'making'), ('decision', 'making', 'scale'), ('making', 'scale', 'reduce'), ('scale', 'reduce', 'operational'), ('reduce', 'operational', 'costs'), ('operational', 'costs', 'optimize'), ('costs', 'optimize', 'resources'), ('optimize', 'resources', 'targeting'), ('resources', 'targeting', 'efforts'), ('targeting', 'efforts', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('goal', 'NN'), ('conduct', 'NN'), ('data-driven', 'JJ'), ('decision', 'NN'), ('making', 'VBG'), ('scale', 'JJ'), ('reduce', 'VB'), ('operational', 'JJ'), ('costs', 'NNS'), ('optimize', 'VBP'), ('resources', 'NNS'), ('targeting', 'VBG'), ('efforts', 'NNS'), ('.', '.')]

 (S
  (NP The/DT goal/NN conduct/NN)
  (NP data-driven/JJ decision/NN)
  making/VBG
  scale/JJ
  reduce/VB
  (NP operational/JJ costs/NNS)
  optimize/VBP
  (NP resources/NNS)
  targeting/VBG
  (NP efforts/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The goal conduct', 'data-driven decision', 'operational costs', 'resources', 'efforts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('conduct', 'conduct'), ('data-driven', 'data-driven'), ('decision', 'decis'), ('making', 'make'), ('scale', 'scale'), ('reduce', 'reduc'), ('operational', 'oper'), ('costs', 'cost'), ('optimize', 'optim'), ('resources', 'resourc'), ('targeting', 'target'), ('efforts', 'effort'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('conduct', 'conduct'), ('data-driven', 'data-driven'), ('decision', 'decis'), ('making', 'make'), ('scale', 'scale'), ('reduce', 'reduc'), ('operational', 'oper'), ('costs', 'cost'), ('optimize', 'optim'), ('resources', 'resourc'), ('targeting', 'target'), ('efforts', 'effort'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('goal', 'goal'), ('conduct', 'conduct'), ('data-driven', 'data-driven'), ('decision', 'decision'), ('making', 'making'), ('scale', 'scale'), ('reduce', 'reduce'), ('operational', 'operational'), ('costs', 'cost'), ('optimize', 'optimize'), ('resources', 'resource'), ('targeting', 'targeting'), ('efforts', 'effort'), ('.', '.')]



============================ Sentence 147 =============================

10/14Demystifying data science   Utilize data driven insights and intelligence to accelerate new product  development  Convert massive amounts of big data into meaningful and actionable insights. 


>> Tokens are: 
 ['10/14Demystifying', 'data', 'science', 'Utilize', 'data', 'driven', 'insights', 'intelligence', 'accelerate', 'new', 'product', 'development', 'Convert', 'massive', 'amounts', 'big', 'data', 'meaningful', 'actionable', 'insights', '.']

>> Bigrams are: 
 [('10/14Demystifying', 'data'), ('data', 'science'), ('science', 'Utilize'), ('Utilize', 'data'), ('data', 'driven'), ('driven', 'insights'), ('insights', 'intelligence'), ('intelligence', 'accelerate'), ('accelerate', 'new'), ('new', 'product'), ('product', 'development'), ('development', 'Convert'), ('Convert', 'massive'), ('massive', 'amounts'), ('amounts', 'big'), ('big', 'data'), ('data', 'meaningful'), ('meaningful', 'actionable'), ('actionable', 'insights'), ('insights', '.')]

>> Trigrams are: 
 [('10/14Demystifying', 'data', 'science'), ('data', 'science', 'Utilize'), ('science', 'Utilize', 'data'), ('Utilize', 'data', 'driven'), ('data', 'driven', 'insights'), ('driven', 'insights', 'intelligence'), ('insights', 'intelligence', 'accelerate'), ('intelligence', 'accelerate', 'new'), ('accelerate', 'new', 'product'), ('new', 'product', 'development'), ('product', 'development', 'Convert'), ('development', 'Convert', 'massive'), ('Convert', 'massive', 'amounts'), ('massive', 'amounts', 'big'), ('amounts', 'big', 'data'), ('big', 'data', 'meaningful'), ('data', 'meaningful', 'actionable'), ('meaningful', 'actionable', 'insights'), ('actionable', 'insights', '.')]

>> POS Tags are: 
 [('10/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('Utilize', 'NNP'), ('data', 'NNS'), ('driven', 'RB'), ('insights', 'NNS'), ('intelligence', 'NN'), ('accelerate', 'VBP'), ('new', 'JJ'), ('product', 'NN'), ('development', 'NN'), ('Convert', 'NNP'), ('massive', 'JJ'), ('amounts', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('meaningful', 'NN'), ('actionable', 'JJ'), ('insights', 'NNS'), ('.', '.')]

 (S
  10/14Demystifying/VBG
  (NP data/NNS science/NN Utilize/NNP data/NNS)
  driven/RB
  (NP insights/NNS intelligence/NN)
  accelerate/VBP
  (NP new/JJ product/NN development/NN Convert/NNP)
  (NP massive/JJ amounts/NNS)
  (NP big/JJ data/NNS meaningful/NN)
  (NP actionable/JJ insights/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data science Utilize data', 'insights intelligence', 'new product development Convert', 'massive amounts', 'big data meaningful', 'actionable insights']

>> Named Entities are: 
 [('PERSON', 'Convert')] 

>> Stemming using Porter Stemmer: 
 [('10/14Demystifying', '10/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Utilize', 'util'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('intelligence', 'intellig'), ('accelerate', 'acceler'), ('new', 'new'), ('product', 'product'), ('development', 'develop'), ('Convert', 'convert'), ('massive', 'massiv'), ('amounts', 'amount'), ('big', 'big'), ('data', 'data'), ('meaningful', 'meaning'), ('actionable', 'action'), ('insights', 'insight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10/14Demystifying', '10/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Utilize', 'util'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('intelligence', 'intellig'), ('accelerate', 'acceler'), ('new', 'new'), ('product', 'product'), ('development', 'develop'), ('Convert', 'convert'), ('massive', 'massiv'), ('amounts', 'amount'), ('big', 'big'), ('data', 'data'), ('meaningful', 'meaning'), ('actionable', 'action'), ('insights', 'insight'), ('.', '.')]

>> Lemmatization: 
 [('10/14Demystifying', '10/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Utilize', 'Utilize'), ('data', 'data'), ('driven', 'driven'), ('insights', 'insight'), ('intelligence', 'intelligence'), ('accelerate', 'accelerate'), ('new', 'new'), ('product', 'product'), ('development', 'development'), ('Convert', 'Convert'), ('massive', 'massive'), ('amounts', 'amount'), ('big', 'big'), ('data', 'data'), ('meaningful', 'meaningful'), ('actionable', 'actionable'), ('insights', 'insight'), ('.', '.')]



============================ Sentence 148 =============================

Voice  assistants, autopilot features and smart home devices have become part of day- to-day life. 


>> Tokens are: 
 ['Voice', 'assistants', ',', 'autopilot', 'features', 'smart', 'home', 'devices', 'become', 'part', 'day-', 'to-day', 'life', '.']

>> Bigrams are: 
 [('Voice', 'assistants'), ('assistants', ','), (',', 'autopilot'), ('autopilot', 'features'), ('features', 'smart'), ('smart', 'home'), ('home', 'devices'), ('devices', 'become'), ('become', 'part'), ('part', 'day-'), ('day-', 'to-day'), ('to-day', 'life'), ('life', '.')]

>> Trigrams are: 
 [('Voice', 'assistants', ','), ('assistants', ',', 'autopilot'), (',', 'autopilot', 'features'), ('autopilot', 'features', 'smart'), ('features', 'smart', 'home'), ('smart', 'home', 'devices'), ('home', 'devices', 'become'), ('devices', 'become', 'part'), ('become', 'part', 'day-'), ('part', 'day-', 'to-day'), ('day-', 'to-day', 'life'), ('to-day', 'life', '.')]

>> POS Tags are: 
 [('Voice', 'NN'), ('assistants', 'NNS'), (',', ','), ('autopilot', 'NN'), ('features', 'NNS'), ('smart', 'VBP'), ('home', 'NN'), ('devices', 'NNS'), ('become', 'VBP'), ('part', 'NN'), ('day-', 'JJ'), ('to-day', 'JJ'), ('life', 'NN'), ('.', '.')]

 (S
  (NP Voice/NN assistants/NNS)
  ,/,
  (NP autopilot/NN features/NNS)
  smart/VBP
  (NP home/NN devices/NNS)
  become/VBP
  (NP part/NN)
  (NP day-/JJ to-day/JJ life/NN)
  ./.) 


>> Noun Phrases are: 
 ['Voice assistants', 'autopilot features', 'home devices', 'part', 'day- to-day life']

>> Named Entities are: 
 [('GPE', 'Voice')] 

>> Stemming using Porter Stemmer: 
 [('Voice', 'voic'), ('assistants', 'assist'), (',', ','), ('autopilot', 'autopilot'), ('features', 'featur'), ('smart', 'smart'), ('home', 'home'), ('devices', 'devic'), ('become', 'becom'), ('part', 'part'), ('day-', 'day-'), ('to-day', 'to-day'), ('life', 'life'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Voice', 'voic'), ('assistants', 'assist'), (',', ','), ('autopilot', 'autopilot'), ('features', 'featur'), ('smart', 'smart'), ('home', 'home'), ('devices', 'devic'), ('become', 'becom'), ('part', 'part'), ('day-', 'day-'), ('to-day', 'to-day'), ('life', 'life'), ('.', '.')]

>> Lemmatization: 
 [('Voice', 'Voice'), ('assistants', 'assistant'), (',', ','), ('autopilot', 'autopilot'), ('features', 'feature'), ('smart', 'smart'), ('home', 'home'), ('devices', 'device'), ('become', 'become'), ('part', 'part'), ('day-', 'day-'), ('to-day', 'to-day'), ('life', 'life'), ('.', '.')]



============================ Sentence 149 =============================

This new class of AI-driven products are powered by machine learning  and advanced analytics techniques, allowing organizations and teams to better  understand consumer needs and wants, feature requests and usage patterns. 


>> Tokens are: 
 ['This', 'new', 'class', 'AI-driven', 'products', 'powered', 'machine', 'learning', 'advanced', 'analytics', 'techniques', ',', 'allowing', 'organizations', 'teams', 'better', 'understand', 'consumer', 'needs', 'wants', ',', 'feature', 'requests', 'usage', 'patterns', '.']

>> Bigrams are: 
 [('This', 'new'), ('new', 'class'), ('class', 'AI-driven'), ('AI-driven', 'products'), ('products', 'powered'), ('powered', 'machine'), ('machine', 'learning'), ('learning', 'advanced'), ('advanced', 'analytics'), ('analytics', 'techniques'), ('techniques', ','), (',', 'allowing'), ('allowing', 'organizations'), ('organizations', 'teams'), ('teams', 'better'), ('better', 'understand'), ('understand', 'consumer'), ('consumer', 'needs'), ('needs', 'wants'), ('wants', ','), (',', 'feature'), ('feature', 'requests'), ('requests', 'usage'), ('usage', 'patterns'), ('patterns', '.')]

>> Trigrams are: 
 [('This', 'new', 'class'), ('new', 'class', 'AI-driven'), ('class', 'AI-driven', 'products'), ('AI-driven', 'products', 'powered'), ('products', 'powered', 'machine'), ('powered', 'machine', 'learning'), ('machine', 'learning', 'advanced'), ('learning', 'advanced', 'analytics'), ('advanced', 'analytics', 'techniques'), ('analytics', 'techniques', ','), ('techniques', ',', 'allowing'), (',', 'allowing', 'organizations'), ('allowing', 'organizations', 'teams'), ('organizations', 'teams', 'better'), ('teams', 'better', 'understand'), ('better', 'understand', 'consumer'), ('understand', 'consumer', 'needs'), ('consumer', 'needs', 'wants'), ('needs', 'wants', ','), ('wants', ',', 'feature'), (',', 'feature', 'requests'), ('feature', 'requests', 'usage'), ('requests', 'usage', 'patterns'), ('usage', 'patterns', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('new', 'JJ'), ('class', 'NN'), ('AI-driven', 'JJ'), ('products', 'NNS'), ('powered', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('advanced', 'JJ'), ('analytics', 'NNS'), ('techniques', 'NNS'), (',', ','), ('allowing', 'VBG'), ('organizations', 'NNS'), ('teams', 'NNS'), ('better', 'RBR'), ('understand', 'JJ'), ('consumer', 'NN'), ('needs', 'NNS'), ('wants', 'VBZ'), (',', ','), ('feature', 'NN'), ('requests', 'NNS'), ('usage', 'JJ'), ('patterns', 'NNS'), ('.', '.')]

 (S
  (NP This/DT new/JJ class/NN)
  (NP AI-driven/JJ products/NNS)
  powered/VBN
  (NP machine/NN)
  learning/VBG
  (NP advanced/JJ analytics/NNS techniques/NNS)
  ,/,
  allowing/VBG
  (NP organizations/NNS teams/NNS)
  better/RBR
  (NP understand/JJ consumer/NN needs/NNS)
  wants/VBZ
  ,/,
  (NP feature/NN requests/NNS)
  (NP usage/JJ patterns/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This new class', 'AI-driven products', 'machine', 'advanced analytics techniques', 'organizations teams', 'understand consumer needs', 'feature requests', 'usage patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('new', 'new'), ('class', 'class'), ('AI-driven', 'ai-driven'), ('products', 'product'), ('powered', 'power'), ('machine', 'machin'), ('learning', 'learn'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('techniques', 'techniqu'), (',', ','), ('allowing', 'allow'), ('organizations', 'organ'), ('teams', 'team'), ('better', 'better'), ('understand', 'understand'), ('consumer', 'consum'), ('needs', 'need'), ('wants', 'want'), (',', ','), ('feature', 'featur'), ('requests', 'request'), ('usage', 'usag'), ('patterns', 'pattern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('new', 'new'), ('class', 'class'), ('AI-driven', 'ai-driven'), ('products', 'product'), ('powered', 'power'), ('machine', 'machin'), ('learning', 'learn'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('techniques', 'techniqu'), (',', ','), ('allowing', 'allow'), ('organizations', 'organ'), ('teams', 'team'), ('better', 'better'), ('understand', 'understand'), ('consumer', 'consum'), ('needs', 'need'), ('wants', 'want'), (',', ','), ('feature', 'featur'), ('requests', 'request'), ('usage', 'usag'), ('patterns', 'pattern'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('new', 'new'), ('class', 'class'), ('AI-driven', 'AI-driven'), ('products', 'product'), ('powered', 'powered'), ('machine', 'machine'), ('learning', 'learning'), ('advanced', 'advanced'), ('analytics', 'analytics'), ('techniques', 'technique'), (',', ','), ('allowing', 'allowing'), ('organizations', 'organization'), ('teams', 'team'), ('better', 'better'), ('understand', 'understand'), ('consumer', 'consumer'), ('needs', 'need'), ('wants', 'want'), (',', ','), ('feature', 'feature'), ('requests', 'request'), ('usage', 'usage'), ('patterns', 'pattern'), ('.', '.')]



============================ Sentence 150 =============================

Common techniques and methodologies in machine learning Machine learning takes what comes naturally to humans and applies it at scale. 


>> Tokens are: 
 ['Common', 'techniques', 'methodologies', 'machine', 'learning', 'Machine', 'learning', 'takes', 'comes', 'naturally', 'humans', 'applies', 'scale', '.']

>> Bigrams are: 
 [('Common', 'techniques'), ('techniques', 'methodologies'), ('methodologies', 'machine'), ('machine', 'learning'), ('learning', 'Machine'), ('Machine', 'learning'), ('learning', 'takes'), ('takes', 'comes'), ('comes', 'naturally'), ('naturally', 'humans'), ('humans', 'applies'), ('applies', 'scale'), ('scale', '.')]

>> Trigrams are: 
 [('Common', 'techniques', 'methodologies'), ('techniques', 'methodologies', 'machine'), ('methodologies', 'machine', 'learning'), ('machine', 'learning', 'Machine'), ('learning', 'Machine', 'learning'), ('Machine', 'learning', 'takes'), ('learning', 'takes', 'comes'), ('takes', 'comes', 'naturally'), ('comes', 'naturally', 'humans'), ('naturally', 'humans', 'applies'), ('humans', 'applies', 'scale'), ('applies', 'scale', '.')]

>> POS Tags are: 
 [('Common', 'JJ'), ('techniques', 'NNS'), ('methodologies', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('Machine', 'NNP'), ('learning', 'VBG'), ('takes', 'VBZ'), ('comes', 'VBZ'), ('naturally', 'RB'), ('humans', 'JJ'), ('applies', 'NNS'), ('scale', 'NN'), ('.', '.')]

 (S
  (NP Common/JJ techniques/NNS methodologies/NNS machine/NN)
  learning/VBG
  (NP Machine/NNP)
  learning/VBG
  takes/VBZ
  comes/VBZ
  naturally/RB
  (NP humans/JJ applies/NNS scale/NN)
  ./.) 


>> Noun Phrases are: 
 ['Common techniques methodologies machine', 'Machine', 'humans applies scale']

>> Named Entities are: 
 [('PERSON', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Common', 'common'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), ('machine', 'machin'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('takes', 'take'), ('comes', 'come'), ('naturally', 'natur'), ('humans', 'human'), ('applies', 'appli'), ('scale', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Common', 'common'), ('techniques', 'techniqu'), ('methodologies', 'methodolog'), ('machine', 'machin'), ('learning', 'learn'), ('Machine', 'machin'), ('learning', 'learn'), ('takes', 'take'), ('comes', 'come'), ('naturally', 'natur'), ('humans', 'human'), ('applies', 'appli'), ('scale', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('Common', 'Common'), ('techniques', 'technique'), ('methodologies', 'methodology'), ('machine', 'machine'), ('learning', 'learning'), ('Machine', 'Machine'), ('learning', 'learning'), ('takes', 'take'), ('comes', 'come'), ('naturally', 'naturally'), ('humans', 'human'), ('applies', 'applies'), ('scale', 'scale'), ('.', '.')]



============================ Sentence 151 =============================

For example, when machine learning reviews a loan application, it can review  5,000 credit transactions, three credit reports, 10 incidents, the five-year income  history of Joe Adams in seconds. 


>> Tokens are: 
 ['For', 'example', ',', 'machine', 'learning', 'reviews', 'loan', 'application', ',', 'review', '5,000', 'credit', 'transactions', ',', 'three', 'credit', 'reports', ',', '10', 'incidents', ',', 'five-year', 'income', 'history', 'Joe', 'Adams', 'seconds', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'reviews'), ('reviews', 'loan'), ('loan', 'application'), ('application', ','), (',', 'review'), ('review', '5,000'), ('5,000', 'credit'), ('credit', 'transactions'), ('transactions', ','), (',', 'three'), ('three', 'credit'), ('credit', 'reports'), ('reports', ','), (',', '10'), ('10', 'incidents'), ('incidents', ','), (',', 'five-year'), ('five-year', 'income'), ('income', 'history'), ('history', 'Joe'), ('Joe', 'Adams'), ('Adams', 'seconds'), ('seconds', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'reviews'), ('learning', 'reviews', 'loan'), ('reviews', 'loan', 'application'), ('loan', 'application', ','), ('application', ',', 'review'), (',', 'review', '5,000'), ('review', '5,000', 'credit'), ('5,000', 'credit', 'transactions'), ('credit', 'transactions', ','), ('transactions', ',', 'three'), (',', 'three', 'credit'), ('three', 'credit', 'reports'), ('credit', 'reports', ','), ('reports', ',', '10'), (',', '10', 'incidents'), ('10', 'incidents', ','), ('incidents', ',', 'five-year'), (',', 'five-year', 'income'), ('five-year', 'income', 'history'), ('income', 'history', 'Joe'), ('history', 'Joe', 'Adams'), ('Joe', 'Adams', 'seconds'), ('Adams', 'seconds', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('reviews', 'JJ'), ('loan', 'NN'), ('application', 'NN'), (',', ','), ('review', 'VB'), ('5,000', 'CD'), ('credit', 'NN'), ('transactions', 'NNS'), (',', ','), ('three', 'CD'), ('credit', 'NN'), ('reports', 'NNS'), (',', ','), ('10', 'CD'), ('incidents', 'NNS'), (',', ','), ('five-year', 'JJ'), ('income', 'NN'), ('history', 'NN'), ('Joe', 'NNP'), ('Adams', 'NNP'), ('seconds', 'VBZ'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP reviews/JJ loan/NN application/NN)
  ,/,
  review/VB
  5,000/CD
  (NP credit/NN transactions/NNS)
  ,/,
  three/CD
  (NP credit/NN reports/NNS)
  ,/,
  10/CD
  (NP incidents/NNS)
  ,/,
  (NP five-year/JJ income/NN history/NN Joe/NNP Adams/NNP)
  seconds/VBZ
  ./.) 


>> Noun Phrases are: 
 ['example', 'machine', 'reviews loan application', 'credit transactions', 'credit reports', 'incidents', 'five-year income history Joe Adams']

>> Named Entities are: 
 [('PERSON', 'Joe Adams')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('reviews', 'review'), ('loan', 'loan'), ('application', 'applic'), (',', ','), ('review', 'review'), ('5,000', '5,000'), ('credit', 'credit'), ('transactions', 'transact'), (',', ','), ('three', 'three'), ('credit', 'credit'), ('reports', 'report'), (',', ','), ('10', '10'), ('incidents', 'incid'), (',', ','), ('five-year', 'five-year'), ('income', 'incom'), ('history', 'histori'), ('Joe', 'joe'), ('Adams', 'adam'), ('seconds', 'second'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('reviews', 'review'), ('loan', 'loan'), ('application', 'applic'), (',', ','), ('review', 'review'), ('5,000', '5,000'), ('credit', 'credit'), ('transactions', 'transact'), (',', ','), ('three', 'three'), ('credit', 'credit'), ('reports', 'report'), (',', ','), ('10', '10'), ('incidents', 'incid'), (',', ','), ('five-year', 'five-year'), ('income', 'incom'), ('history', 'histori'), ('Joe', 'joe'), ('Adams', 'adam'), ('seconds', 'second'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('reviews', 'review'), ('loan', 'loan'), ('application', 'application'), (',', ','), ('review', 'review'), ('5,000', '5,000'), ('credit', 'credit'), ('transactions', 'transaction'), (',', ','), ('three', 'three'), ('credit', 'credit'), ('reports', 'report'), (',', ','), ('10', '10'), ('incidents', 'incident'), (',', ','), ('five-year', 'five-year'), ('income', 'income'), ('history', 'history'), ('Joe', 'Joe'), ('Adams', 'Adams'), ('seconds', 'second'), ('.', '.')]



============================ Sentence 152 =============================

This would not be possible by a domain expert. 


>> Tokens are: 
 ['This', 'would', 'possible', 'domain', 'expert', '.']

>> Bigrams are: 
 [('This', 'would'), ('would', 'possible'), ('possible', 'domain'), ('domain', 'expert'), ('expert', '.')]

>> Trigrams are: 
 [('This', 'would', 'possible'), ('would', 'possible', 'domain'), ('possible', 'domain', 'expert'), ('domain', 'expert', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('would', 'MD'), ('possible', 'JJ'), ('domain', 'NN'), ('expert', 'NN'), ('.', '.')]

 (S This/DT would/MD (NP possible/JJ domain/NN expert/NN) ./.) 


>> Noun Phrases are: 
 ['possible domain expert']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('would', 'would'), ('possible', 'possibl'), ('domain', 'domain'), ('expert', 'expert'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('would', 'would'), ('possible', 'possibl'), ('domain', 'domain'), ('expert', 'expert'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('would', 'would'), ('possible', 'possible'), ('domain', 'domain'), ('expert', 'expert'), ('.', '.')]



============================ Sentence 153 =============================

They simply do not have the capacity to reviews with the speed of a machine and  provide a decision on his loan as soon as it is submitted. 


>> Tokens are: 
 ['They', 'simply', 'capacity', 'reviews', 'speed', 'machine', 'provide', 'decision', 'loan', 'soon', 'submitted', '.']

>> Bigrams are: 
 [('They', 'simply'), ('simply', 'capacity'), ('capacity', 'reviews'), ('reviews', 'speed'), ('speed', 'machine'), ('machine', 'provide'), ('provide', 'decision'), ('decision', 'loan'), ('loan', 'soon'), ('soon', 'submitted'), ('submitted', '.')]

>> Trigrams are: 
 [('They', 'simply', 'capacity'), ('simply', 'capacity', 'reviews'), ('capacity', 'reviews', 'speed'), ('reviews', 'speed', 'machine'), ('speed', 'machine', 'provide'), ('machine', 'provide', 'decision'), ('provide', 'decision', 'loan'), ('decision', 'loan', 'soon'), ('loan', 'soon', 'submitted'), ('soon', 'submitted', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('simply', 'RB'), ('capacity', 'NN'), ('reviews', 'NNS'), ('speed', 'VBP'), ('machine', 'NN'), ('provide', 'VBP'), ('decision', 'NN'), ('loan', 'NN'), ('soon', 'RB'), ('submitted', 'VBD'), ('.', '.')]

 (S
  They/PRP
  simply/RB
  (NP capacity/NN reviews/NNS)
  speed/VBP
  (NP machine/NN)
  provide/VBP
  (NP decision/NN loan/NN)
  soon/RB
  submitted/VBD
  ./.) 


>> Noun Phrases are: 
 ['capacity reviews', 'machine', 'decision loan']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('simply', 'simpli'), ('capacity', 'capac'), ('reviews', 'review'), ('speed', 'speed'), ('machine', 'machin'), ('provide', 'provid'), ('decision', 'decis'), ('loan', 'loan'), ('soon', 'soon'), ('submitted', 'submit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('simply', 'simpli'), ('capacity', 'capac'), ('reviews', 'review'), ('speed', 'speed'), ('machine', 'machin'), ('provide', 'provid'), ('decision', 'decis'), ('loan', 'loan'), ('soon', 'soon'), ('submitted', 'submit'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('simply', 'simply'), ('capacity', 'capacity'), ('reviews', 'review'), ('speed', 'speed'), ('machine', 'machine'), ('provide', 'provide'), ('decision', 'decision'), ('loan', 'loan'), ('soon', 'soon'), ('submitted', 'submitted'), ('.', '.')]



============================ Sentence 154 =============================

Even if the expert is highly  experienced and efficient, it takes considerable time to review application details  and there is still room for human error. 


>> Tokens are: 
 ['Even', 'expert', 'highly', 'experienced', 'efficient', ',', 'takes', 'considerable', 'time', 'review', 'application', 'details', 'still', 'room', 'human', 'error', '.']

>> Bigrams are: 
 [('Even', 'expert'), ('expert', 'highly'), ('highly', 'experienced'), ('experienced', 'efficient'), ('efficient', ','), (',', 'takes'), ('takes', 'considerable'), ('considerable', 'time'), ('time', 'review'), ('review', 'application'), ('application', 'details'), ('details', 'still'), ('still', 'room'), ('room', 'human'), ('human', 'error'), ('error', '.')]

>> Trigrams are: 
 [('Even', 'expert', 'highly'), ('expert', 'highly', 'experienced'), ('highly', 'experienced', 'efficient'), ('experienced', 'efficient', ','), ('efficient', ',', 'takes'), (',', 'takes', 'considerable'), ('takes', 'considerable', 'time'), ('considerable', 'time', 'review'), ('time', 'review', 'application'), ('review', 'application', 'details'), ('application', 'details', 'still'), ('details', 'still', 'room'), ('still', 'room', 'human'), ('room', 'human', 'error'), ('human', 'error', '.')]

>> POS Tags are: 
 [('Even', 'RB'), ('expert', 'VBZ'), ('highly', 'RB'), ('experienced', 'JJ'), ('efficient', 'NN'), (',', ','), ('takes', 'VBZ'), ('considerable', 'JJ'), ('time', 'NN'), ('review', 'NN'), ('application', 'NN'), ('details', 'NNS'), ('still', 'RB'), ('room', 'NN'), ('human', 'JJ'), ('error', 'NN'), ('.', '.')]

 (S
  Even/RB
  expert/VBZ
  highly/RB
  (NP experienced/JJ efficient/NN)
  ,/,
  takes/VBZ
  (NP considerable/JJ time/NN review/NN application/NN details/NNS)
  still/RB
  (NP room/NN)
  (NP human/JJ error/NN)
  ./.) 


>> Noun Phrases are: 
 ['experienced efficient', 'considerable time review application details', 'room', 'human error']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Even', 'even'), ('expert', 'expert'), ('highly', 'highli'), ('experienced', 'experienc'), ('efficient', 'effici'), (',', ','), ('takes', 'take'), ('considerable', 'consider'), ('time', 'time'), ('review', 'review'), ('application', 'applic'), ('details', 'detail'), ('still', 'still'), ('room', 'room'), ('human', 'human'), ('error', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Even', 'even'), ('expert', 'expert'), ('highly', 'high'), ('experienced', 'experienc'), ('efficient', 'effici'), (',', ','), ('takes', 'take'), ('considerable', 'consider'), ('time', 'time'), ('review', 'review'), ('application', 'applic'), ('details', 'detail'), ('still', 'still'), ('room', 'room'), ('human', 'human'), ('error', 'error'), ('.', '.')]

>> Lemmatization: 
 [('Even', 'Even'), ('expert', 'expert'), ('highly', 'highly'), ('experienced', 'experienced'), ('efficient', 'efficient'), (',', ','), ('takes', 'take'), ('considerable', 'considerable'), ('time', 'time'), ('review', 'review'), ('application', 'application'), ('details', 'detail'), ('still', 'still'), ('room', 'room'), ('human', 'human'), ('error', 'error'), ('.', '.')]



============================ Sentence 155 =============================

Machine learning uses past experience and  trends in historical data related to customers in both good standing and those that  defaulted on loans to make a decision. 


>> Tokens are: 
 ['Machine', 'learning', 'uses', 'past', 'experience', 'trends', 'historical', 'data', 'related', 'customers', 'good', 'standing', 'defaulted', 'loans', 'make', 'decision', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'uses'), ('uses', 'past'), ('past', 'experience'), ('experience', 'trends'), ('trends', 'historical'), ('historical', 'data'), ('data', 'related'), ('related', 'customers'), ('customers', 'good'), ('good', 'standing'), ('standing', 'defaulted'), ('defaulted', 'loans'), ('loans', 'make'), ('make', 'decision'), ('decision', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'uses'), ('learning', 'uses', 'past'), ('uses', 'past', 'experience'), ('past', 'experience', 'trends'), ('experience', 'trends', 'historical'), ('trends', 'historical', 'data'), ('historical', 'data', 'related'), ('data', 'related', 'customers'), ('related', 'customers', 'good'), ('customers', 'good', 'standing'), ('good', 'standing', 'defaulted'), ('standing', 'defaulted', 'loans'), ('defaulted', 'loans', 'make'), ('loans', 'make', 'decision'), ('make', 'decision', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'NN'), ('uses', 'VBZ'), ('past', 'JJ'), ('experience', 'NN'), ('trends', 'NNS'), ('historical', 'JJ'), ('data', 'NNS'), ('related', 'JJ'), ('customers', 'NNS'), ('good', 'JJ'), ('standing', 'VBG'), ('defaulted', 'JJ'), ('loans', 'NNS'), ('make', 'VBP'), ('decision', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN learning/NN)
  uses/VBZ
  (NP past/JJ experience/NN trends/NNS)
  (NP historical/JJ data/NNS)
  (NP related/JJ customers/NNS)
  good/JJ
  standing/VBG
  (NP defaulted/JJ loans/NNS)
  make/VBP
  (NP decision/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine learning', 'past experience trends', 'historical data', 'related customers', 'defaulted loans', 'decision']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('uses', 'use'), ('past', 'past'), ('experience', 'experi'), ('trends', 'trend'), ('historical', 'histor'), ('data', 'data'), ('related', 'relat'), ('customers', 'custom'), ('good', 'good'), ('standing', 'stand'), ('defaulted', 'default'), ('loans', 'loan'), ('make', 'make'), ('decision', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('uses', 'use'), ('past', 'past'), ('experience', 'experi'), ('trends', 'trend'), ('historical', 'histor'), ('data', 'data'), ('related', 'relat'), ('customers', 'custom'), ('good', 'good'), ('standing', 'stand'), ('defaulted', 'default'), ('loans', 'loan'), ('make', 'make'), ('decision', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('uses', 'us'), ('past', 'past'), ('experience', 'experience'), ('trends', 'trend'), ('historical', 'historical'), ('data', 'data'), ('related', 'related'), ('customers', 'customer'), ('good', 'good'), ('standing', 'standing'), ('defaulted', 'defaulted'), ('loans', 'loan'), ('make', 'make'), ('decision', 'decision'), ('.', '.')]



============================ Sentence 156 =============================

With the combination of machine learning  and good quality data, organizations can quickly make unbiased, data-driven  decisions at scale in seconds. 


>> Tokens are: 
 ['With', 'combination', 'machine', 'learning', 'good', 'quality', 'data', ',', 'organizations', 'quickly', 'make', 'unbiased', ',', 'data-driven', 'decisions', 'scale', 'seconds', '.']

>> Bigrams are: 
 [('With', 'combination'), ('combination', 'machine'), ('machine', 'learning'), ('learning', 'good'), ('good', 'quality'), ('quality', 'data'), ('data', ','), (',', 'organizations'), ('organizations', 'quickly'), ('quickly', 'make'), ('make', 'unbiased'), ('unbiased', ','), (',', 'data-driven'), ('data-driven', 'decisions'), ('decisions', 'scale'), ('scale', 'seconds'), ('seconds', '.')]

>> Trigrams are: 
 [('With', 'combination', 'machine'), ('combination', 'machine', 'learning'), ('machine', 'learning', 'good'), ('learning', 'good', 'quality'), ('good', 'quality', 'data'), ('quality', 'data', ','), ('data', ',', 'organizations'), (',', 'organizations', 'quickly'), ('organizations', 'quickly', 'make'), ('quickly', 'make', 'unbiased'), ('make', 'unbiased', ','), ('unbiased', ',', 'data-driven'), (',', 'data-driven', 'decisions'), ('data-driven', 'decisions', 'scale'), ('decisions', 'scale', 'seconds'), ('scale', 'seconds', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('combination', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('good', 'JJ'), ('quality', 'NN'), ('data', 'NNS'), (',', ','), ('organizations', 'NNS'), ('quickly', 'RB'), ('make', 'VBP'), ('unbiased', 'JJ'), (',', ','), ('data-driven', 'JJ'), ('decisions', 'NNS'), ('scale', 'JJ'), ('seconds', 'NNS'), ('.', '.')]

 (S
  With/IN
  (NP combination/NN machine/NN)
  learning/VBG
  (NP good/JJ quality/NN data/NNS)
  ,/,
  (NP organizations/NNS)
  quickly/RB
  make/VBP
  unbiased/JJ
  ,/,
  (NP data-driven/JJ decisions/NNS)
  (NP scale/JJ seconds/NNS)
  ./.) 


>> Noun Phrases are: 
 ['combination machine', 'good quality data', 'organizations', 'data-driven decisions', 'scale seconds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('combination', 'combin'), ('machine', 'machin'), ('learning', 'learn'), ('good', 'good'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('organizations', 'organ'), ('quickly', 'quickli'), ('make', 'make'), ('unbiased', 'unbias'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('scale', 'scale'), ('seconds', 'second'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('combination', 'combin'), ('machine', 'machin'), ('learning', 'learn'), ('good', 'good'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('organizations', 'organ'), ('quickly', 'quick'), ('make', 'make'), ('unbiased', 'unbias'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('scale', 'scale'), ('seconds', 'second'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('combination', 'combination'), ('machine', 'machine'), ('learning', 'learning'), ('good', 'good'), ('quality', 'quality'), ('data', 'data'), (',', ','), ('organizations', 'organization'), ('quickly', 'quickly'), ('make', 'make'), ('unbiased', 'unbiased'), (',', ','), ('data-driven', 'data-driven'), ('decisions', 'decision'), ('scale', 'scale'), ('seconds', 'second'), ('.', '.')]



============================ Sentence 157 =============================

Machine learning offers various approaches to solve business problems. 


>> Tokens are: 
 ['Machine', 'learning', 'offers', 'various', 'approaches', 'solve', 'business', 'problems', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'offers'), ('offers', 'various'), ('various', 'approaches'), ('approaches', 'solve'), ('solve', 'business'), ('business', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'offers'), ('learning', 'offers', 'various'), ('offers', 'various', 'approaches'), ('various', 'approaches', 'solve'), ('approaches', 'solve', 'business'), ('solve', 'business', 'problems'), ('business', 'problems', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('offers', 'NNS'), ('various', 'JJ'), ('approaches', 'NNS'), ('solve', 'VBP'), ('business', 'NN'), ('problems', 'NNS'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP offers/NNS)
  (NP various/JJ approaches/NNS)
  solve/VBP
  (NP business/NN problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'offers', 'various approaches', 'business problems']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('offers', 'offer'), ('various', 'variou'), ('approaches', 'approach'), ('solve', 'solv'), ('business', 'busi'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('offers', 'offer'), ('various', 'various'), ('approaches', 'approach'), ('solve', 'solv'), ('business', 'busi'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('offers', 'offer'), ('various', 'various'), ('approaches', 'approach'), ('solve', 'solve'), ('business', 'business'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 158 =============================

The first  approach is based on whether there is data related to the outcome of a process. 


>> Tokens are: 
 ['The', 'first', 'approach', 'based', 'whether', 'data', 'related', 'outcome', 'process', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'approach'), ('approach', 'based'), ('based', 'whether'), ('whether', 'data'), ('data', 'related'), ('related', 'outcome'), ('outcome', 'process'), ('process', '.')]

>> Trigrams are: 
 [('The', 'first', 'approach'), ('first', 'approach', 'based'), ('approach', 'based', 'whether'), ('based', 'whether', 'data'), ('whether', 'data', 'related'), ('data', 'related', 'outcome'), ('related', 'outcome', 'process'), ('outcome', 'process', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('approach', 'NN'), ('based', 'VBN'), ('whether', 'IN'), ('data', 'NNS'), ('related', 'JJ'), ('outcome', 'JJ'), ('process', 'NN'), ('.', '.')]

 (S
  (NP The/DT first/JJ approach/NN)
  based/VBN
  whether/IN
  (NP data/NNS)
  (NP related/JJ outcome/JJ process/NN)
  ./.) 


>> Noun Phrases are: 
 ['The first approach', 'data', 'related outcome process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('approach', 'approach'), ('based', 'base'), ('whether', 'whether'), ('data', 'data'), ('related', 'relat'), ('outcome', 'outcom'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('approach', 'approach'), ('based', 'base'), ('whether', 'whether'), ('data', 'data'), ('related', 'relat'), ('outcome', 'outcom'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('approach', 'approach'), ('based', 'based'), ('whether', 'whether'), ('data', 'data'), ('related', 'related'), ('outcome', 'outcome'), ('process', 'process'), ('.', '.')]



============================ Sentence 159 =============================

Did the machine stop working? 


>> Tokens are: 
 ['Did', 'machine', 'stop', 'working', '?']

>> Bigrams are: 
 [('Did', 'machine'), ('machine', 'stop'), ('stop', 'working'), ('working', '?')]

>> Trigrams are: 
 [('Did', 'machine', 'stop'), ('machine', 'stop', 'working'), ('stop', 'working', '?')]

>> POS Tags are: 
 [('Did', 'NNP'), ('machine', 'NN'), ('stop', 'NN'), ('working', 'NN'), ('?', '.')]

 (S (NP Did/NNP machine/NN stop/NN working/NN) ?/.) 


>> Noun Phrases are: 
 ['Did machine stop working']

>> Named Entities are: 
 [('GPE', 'Did')] 

>> Stemming using Porter Stemmer: 
 [('Did', 'did'), ('machine', 'machin'), ('stop', 'stop'), ('working', 'work'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Did', 'did'), ('machine', 'machin'), ('stop', 'stop'), ('working', 'work'), ('?', '?')]

>> Lemmatization: 
 [('Did', 'Did'), ('machine', 'machine'), ('stop', 'stop'), ('working', 'working'), ('?', '?')]



============================ Sentence 160 =============================

Did the customer leave? 


>> Tokens are: 
 ['Did', 'customer', 'leave', '?']

>> Bigrams are: 
 [('Did', 'customer'), ('customer', 'leave'), ('leave', '?')]

>> Trigrams are: 
 [('Did', 'customer', 'leave'), ('customer', 'leave', '?')]

>> POS Tags are: 
 [('Did', 'NNP'), ('customer', 'NN'), ('leave', 'NN'), ('?', '.')]

 (S (NP Did/NNP customer/NN leave/NN) ?/.) 


>> Noun Phrases are: 
 ['Did customer leave']

>> Named Entities are: 
 [('GPE', 'Did')] 

>> Stemming using Porter Stemmer: 
 [('Did', 'did'), ('customer', 'custom'), ('leave', 'leav'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Did', 'did'), ('customer', 'custom'), ('leave', 'leav'), ('?', '?')]

>> Lemmatization: 
 [('Did', 'Did'), ('customer', 'customer'), ('leave', 'leave'), ('?', '?')]



============================ Sentence 161 =============================

Did the employee quit? 


>> Tokens are: 
 ['Did', 'employee', 'quit', '?']

>> Bigrams are: 
 [('Did', 'employee'), ('employee', 'quit'), ('quit', '?')]

>> Trigrams are: 
 [('Did', 'employee', 'quit'), ('employee', 'quit', '?')]

>> POS Tags are: 
 [('Did', 'NNP'), ('employee', 'NN'), ('quit', 'NN'), ('?', '.')]

 (S (NP Did/NNP employee/NN quit/NN) ?/.) 


>> Noun Phrases are: 
 ['Did employee quit']

>> Named Entities are: 
 [('GPE', 'Did')] 

>> Stemming using Porter Stemmer: 
 [('Did', 'did'), ('employee', 'employe'), ('quit', 'quit'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Did', 'did'), ('employee', 'employe'), ('quit', 'quit'), ('?', '?')]

>> Lemmatization: 
 [('Did', 'Did'), ('employee', 'employee'), ('quit', 'quit'), ('?', '?')]



============================ Sentence 162 =============================

It is important to understand and model how behavior and fluctuations in data  lead to a certain business outcome. 


>> Tokens are: 
 ['It', 'important', 'understand', 'model', 'behavior', 'fluctuations', 'data', 'lead', 'certain', 'business', 'outcome', '.']

>> Bigrams are: 
 [('It', 'important'), ('important', 'understand'), ('understand', 'model'), ('model', 'behavior'), ('behavior', 'fluctuations'), ('fluctuations', 'data'), ('data', 'lead'), ('lead', 'certain'), ('certain', 'business'), ('business', 'outcome'), ('outcome', '.')]

>> Trigrams are: 
 [('It', 'important', 'understand'), ('important', 'understand', 'model'), ('understand', 'model', 'behavior'), ('model', 'behavior', 'fluctuations'), ('behavior', 'fluctuations', 'data'), ('fluctuations', 'data', 'lead'), ('data', 'lead', 'certain'), ('lead', 'certain', 'business'), ('certain', 'business', 'outcome'), ('business', 'outcome', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('important', 'JJ'), ('understand', 'JJ'), ('model', 'NN'), ('behavior', 'JJ'), ('fluctuations', 'NNS'), ('data', 'NNS'), ('lead', 'VBP'), ('certain', 'JJ'), ('business', 'NN'), ('outcome', 'NN'), ('.', '.')]

 (S
  It/PRP
  (NP important/JJ understand/JJ model/NN)
  (NP behavior/JJ fluctuations/NNS data/NNS)
  lead/VBP
  (NP certain/JJ business/NN outcome/NN)
  ./.) 


>> Noun Phrases are: 
 ['important understand model', 'behavior fluctuations data', 'certain business outcome']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('important', 'import'), ('understand', 'understand'), ('model', 'model'), ('behavior', 'behavior'), ('fluctuations', 'fluctuat'), ('data', 'data'), ('lead', 'lead'), ('certain', 'certain'), ('business', 'busi'), ('outcome', 'outcom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('important', 'import'), ('understand', 'understand'), ('model', 'model'), ('behavior', 'behavior'), ('fluctuations', 'fluctuat'), ('data', 'data'), ('lead', 'lead'), ('certain', 'certain'), ('business', 'busi'), ('outcome', 'outcom'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('important', 'important'), ('understand', 'understand'), ('model', 'model'), ('behavior', 'behavior'), ('fluctuations', 'fluctuation'), ('data', 'data'), ('lead', 'lead'), ('certain', 'certain'), ('business', 'business'), ('outcome', 'outcome'), ('.', '.')]



============================ Sentence 163 =============================

This type of machine learning is known as  supervised learning. 


>> Tokens are: 
 ['This', 'type', 'machine', 'learning', 'known', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('This', 'type'), ('type', 'machine'), ('machine', 'learning'), ('learning', 'known'), ('known', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'type', 'machine'), ('type', 'machine', 'learning'), ('machine', 'learning', 'known'), ('learning', 'known', 'supervised'), ('known', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('type', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('known', 'VBN'), ('supervised', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP This/DT type/NN machine/NN)
  learning/VBG
  known/VBN
  (NP supervised/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['This type machine', 'supervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('type', 'type'), ('machine', 'machin'), ('learning', 'learn'), ('known', 'known'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('type', 'type'), ('machine', 'machin'), ('learning', 'learn'), ('known', 'known'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('type', 'type'), ('machine', 'machine'), ('learning', 'learning'), ('known', 'known'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 164 =============================

Machine learning  Unsupervised learning Supervised learning  	Data	does	not	contain	 a	category/response	to	 predict  	The	goal	here	is	to	learn	 about	the	underlying	 structure	or	distribution	 of	the	data,	and	discover	 inherent	patterns	from	 within	it	in	order	to	draw	 inferences  		We	know	the	outcome/ response  	Takes	known	set	of	input	 data	and	responses	to	it,	and						 trains	a	model	to	generate	 reasonable	predictions	for						 the	response	to	new	dataMachine  learning  Unsupervised learning    Data does not contain a category/response to predict    The goal here is to learn about the underlying structure        or distribution of the data, and discover inherent      patterns from within it in order to draw inferences  Supervised learning    We know the outcome/response    Takes known set of input data and responses to it, and      trains a model to generate reasonable predictions for      the response to new data    11/14Demystifying data science   If there is no response or category to predict, the goal is to learn the underlying  structure of the data and discover patterns to draw real world inferences. 


>> Tokens are: 
 ['Machine', 'learning', 'Unsupervised', 'learning', 'Supervised', 'learning', '', 'Data', 'contain', 'category/response', 'predict', '', 'The', 'goal', 'learn', 'underlying', 'structure', 'distribution', 'data', ',', 'discover', 'inherent', 'patterns', 'within', 'order', 'draw', 'inferences', '', 'We', 'know', 'outcome/', 'response', '', 'Takes', 'known', 'set', 'input', 'data', 'responses', ',', 'trains', 'model', 'generate', 'reasonable', 'predictions', 'response', 'new', 'dataMachine', 'learning', 'Unsupervised', 'learning', '', 'Data', 'contain', 'category/response', 'predict', '', 'The', 'goal', 'learn', 'underlying', 'structure', 'distribution', 'data', ',', 'discover', 'inherent', 'patterns', 'within', 'order', 'draw', 'inferences', 'Supervised', 'learning', '', 'We', 'know', 'outcome/response', '', 'Takes', 'known', 'set', 'input', 'data', 'responses', ',', 'trains', 'model', 'generate', 'reasonable', 'predictions', 'response', 'new', 'data', '11/14Demystifying', 'data', 'science', 'If', 'response', 'category', 'predict', ',', 'goal', 'learn', 'underlying', 'structure', 'data', 'discover', 'patterns', 'draw', 'real', 'world', 'inferences', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', 'Supervised'), ('Supervised', 'learning'), ('learning', ''), ('', 'Data'), ('Data', 'contain'), ('contain', 'category/response'), ('category/response', 'predict'), ('predict', ''), ('', 'The'), ('The', 'goal'), ('goal', 'learn'), ('learn', 'underlying'), ('underlying', 'structure'), ('structure', 'distribution'), ('distribution', 'data'), ('data', ','), (',', 'discover'), ('discover', 'inherent'), ('inherent', 'patterns'), ('patterns', 'within'), ('within', 'order'), ('order', 'draw'), ('draw', 'inferences'), ('inferences', ''), ('', 'We'), ('We', 'know'), ('know', 'outcome/'), ('outcome/', 'response'), ('response', ''), ('', 'Takes'), ('Takes', 'known'), ('known', 'set'), ('set', 'input'), ('input', 'data'), ('data', 'responses'), ('responses', ','), (',', 'trains'), ('trains', 'model'), ('model', 'generate'), ('generate', 'reasonable'), ('reasonable', 'predictions'), ('predictions', 'response'), ('response', 'new'), ('new', 'dataMachine'), ('dataMachine', 'learning'), ('learning', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', ''), ('', 'Data'), ('Data', 'contain'), ('contain', 'category/response'), ('category/response', 'predict'), ('predict', ''), ('', 'The'), ('The', 'goal'), ('goal', 'learn'), ('learn', 'underlying'), ('underlying', 'structure'), ('structure', 'distribution'), ('distribution', 'data'), ('data', ','), (',', 'discover'), ('discover', 'inherent'), ('inherent', 'patterns'), ('patterns', 'within'), ('within', 'order'), ('order', 'draw'), ('draw', 'inferences'), ('inferences', 'Supervised'), ('Supervised', 'learning'), ('learning', ''), ('', 'We'), ('We', 'know'), ('know', 'outcome/response'), ('outcome/response', ''), ('', 'Takes'), ('Takes', 'known'), ('known', 'set'), ('set', 'input'), ('input', 'data'), ('data', 'responses'), ('responses', ','), (',', 'trains'), ('trains', 'model'), ('model', 'generate'), ('generate', 'reasonable'), ('reasonable', 'predictions'), ('predictions', 'response'), ('response', 'new'), ('new', 'data'), ('data', '11/14Demystifying'), ('11/14Demystifying', 'data'), ('data', 'science'), ('science', 'If'), ('If', 'response'), ('response', 'category'), ('category', 'predict'), ('predict', ','), (',', 'goal'), ('goal', 'learn'), ('learn', 'underlying'), ('underlying', 'structure'), ('structure', 'data'), ('data', 'discover'), ('discover', 'patterns'), ('patterns', 'draw'), ('draw', 'real'), ('real', 'world'), ('world', 'inferences'), ('inferences', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'Unsupervised'), ('learning', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', 'Supervised'), ('learning', 'Supervised', 'learning'), ('Supervised', 'learning', ''), ('learning', '', 'Data'), ('', 'Data', 'contain'), ('Data', 'contain', 'category/response'), ('contain', 'category/response', 'predict'), ('category/response', 'predict', ''), ('predict', '', 'The'), ('', 'The', 'goal'), ('The', 'goal', 'learn'), ('goal', 'learn', 'underlying'), ('learn', 'underlying', 'structure'), ('underlying', 'structure', 'distribution'), ('structure', 'distribution', 'data'), ('distribution', 'data', ','), ('data', ',', 'discover'), (',', 'discover', 'inherent'), ('discover', 'inherent', 'patterns'), ('inherent', 'patterns', 'within'), ('patterns', 'within', 'order'), ('within', 'order', 'draw'), ('order', 'draw', 'inferences'), ('draw', 'inferences', ''), ('inferences', '', 'We'), ('', 'We', 'know'), ('We', 'know', 'outcome/'), ('know', 'outcome/', 'response'), ('outcome/', 'response', ''), ('response', '', 'Takes'), ('', 'Takes', 'known'), ('Takes', 'known', 'set'), ('known', 'set', 'input'), ('set', 'input', 'data'), ('input', 'data', 'responses'), ('data', 'responses', ','), ('responses', ',', 'trains'), (',', 'trains', 'model'), ('trains', 'model', 'generate'), ('model', 'generate', 'reasonable'), ('generate', 'reasonable', 'predictions'), ('reasonable', 'predictions', 'response'), ('predictions', 'response', 'new'), ('response', 'new', 'dataMachine'), ('new', 'dataMachine', 'learning'), ('dataMachine', 'learning', 'Unsupervised'), ('learning', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', ''), ('learning', '', 'Data'), ('', 'Data', 'contain'), ('Data', 'contain', 'category/response'), ('contain', 'category/response', 'predict'), ('category/response', 'predict', ''), ('predict', '', 'The'), ('', 'The', 'goal'), ('The', 'goal', 'learn'), ('goal', 'learn', 'underlying'), ('learn', 'underlying', 'structure'), ('underlying', 'structure', 'distribution'), ('structure', 'distribution', 'data'), ('distribution', 'data', ','), ('data', ',', 'discover'), (',', 'discover', 'inherent'), ('discover', 'inherent', 'patterns'), ('inherent', 'patterns', 'within'), ('patterns', 'within', 'order'), ('within', 'order', 'draw'), ('order', 'draw', 'inferences'), ('draw', 'inferences', 'Supervised'), ('inferences', 'Supervised', 'learning'), ('Supervised', 'learning', ''), ('learning', '', 'We'), ('', 'We', 'know'), ('We', 'know', 'outcome/response'), ('know', 'outcome/response', ''), ('outcome/response', '', 'Takes'), ('', 'Takes', 'known'), ('Takes', 'known', 'set'), ('known', 'set', 'input'), ('set', 'input', 'data'), ('input', 'data', 'responses'), ('data', 'responses', ','), ('responses', ',', 'trains'), (',', 'trains', 'model'), ('trains', 'model', 'generate'), ('model', 'generate', 'reasonable'), ('generate', 'reasonable', 'predictions'), ('reasonable', 'predictions', 'response'), ('predictions', 'response', 'new'), ('response', 'new', 'data'), ('new', 'data', '11/14Demystifying'), ('data', '11/14Demystifying', 'data'), ('11/14Demystifying', 'data', 'science'), ('data', 'science', 'If'), ('science', 'If', 'response'), ('If', 'response', 'category'), ('response', 'category', 'predict'), ('category', 'predict', ','), ('predict', ',', 'goal'), (',', 'goal', 'learn'), ('goal', 'learn', 'underlying'), ('learn', 'underlying', 'structure'), ('underlying', 'structure', 'data'), ('structure', 'data', 'discover'), ('data', 'discover', 'patterns'), ('discover', 'patterns', 'draw'), ('patterns', 'draw', 'real'), ('draw', 'real', 'world'), ('real', 'world', 'inferences'), ('world', 'inferences', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('Supervised', 'VBN'), ('learning', 'VBG'), ('', 'NNP'), ('Data', 'NNP'), ('contain', 'NN'), ('category/response', 'NN'), ('predict', 'NN'), ('', 'VBD'), ('The', 'DT'), ('goal', 'NN'), ('learn', 'VBP'), ('underlying', 'JJ'), ('structure', 'NN'), ('distribution', 'NN'), ('data', 'NNS'), (',', ','), ('discover', 'NN'), ('inherent', 'JJ'), ('patterns', 'NNS'), ('within', 'IN'), ('order', 'NN'), ('draw', 'NN'), ('inferences', 'NNS'), ('', 'VBP'), ('We', 'PRP'), ('know', 'VBP'), ('outcome/', 'JJ'), ('response', 'NN'), ('', 'NNP'), ('Takes', 'NNP'), ('known', 'VBN'), ('set', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('responses', 'NNS'), (',', ','), ('trains', 'NNS'), ('model', 'VBP'), ('generate', 'NN'), ('reasonable', 'JJ'), ('predictions', 'NNS'), ('response', 'NN'), ('new', 'JJ'), ('dataMachine', 'NN'), ('learning', 'NN'), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('', 'NNP'), ('Data', 'NNP'), ('contain', 'NN'), ('category/response', 'NN'), ('predict', 'NN'), ('', 'VBD'), ('The', 'DT'), ('goal', 'NN'), ('learn', 'VBP'), ('underlying', 'JJ'), ('structure', 'NN'), ('distribution', 'NN'), ('data', 'NNS'), (',', ','), ('discover', 'NN'), ('inherent', 'JJ'), ('patterns', 'NNS'), ('within', 'IN'), ('order', 'NN'), ('draw', 'NN'), ('inferences', 'NNS'), ('Supervised', 'VBD'), ('learning', 'VBG'), ('', 'IN'), ('We', 'PRP'), ('know', 'VBP'), ('outcome/response', 'JJ'), ('', 'NNP'), ('Takes', 'NNP'), ('known', 'VBN'), ('set', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('responses', 'NNS'), (',', ','), ('trains', 'NNS'), ('model', 'VBP'), ('generate', 'NN'), ('reasonable', 'JJ'), ('predictions', 'NNS'), ('response', 'NN'), ('new', 'JJ'), ('data', 'NNS'), ('11/14Demystifying', 'CD'), ('data', 'NNS'), ('science', 'NN'), ('If', 'IN'), ('response', 'NN'), ('category', 'NN'), ('predict', 'NN'), (',', ','), ('goal', 'NN'), ('learn', 'NN'), ('underlying', 'JJ'), ('structure', 'NN'), ('data', 'NNS'), ('discover', 'NN'), ('patterns', 'NNS'), ('draw', 'VB'), ('real', 'JJ'), ('world', 'NN'), ('inferences', 'NNS'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  Unsupervised/VBD
  learning/VBG
  Supervised/VBN
  learning/VBG
  (NP /NNP Data/NNP contain/NN category/response/NN predict/NN)
  /VBD
  (NP The/DT goal/NN)
  learn/VBP
  (NP underlying/JJ structure/NN distribution/NN data/NNS)
  ,/,
  (NP discover/NN)
  (NP inherent/JJ patterns/NNS)
  within/IN
  (NP order/NN draw/NN inferences/NNS)
  /VBP
  We/PRP
  know/VBP
  (NP outcome//JJ response/NN /NNP Takes/NNP)
  known/VBN
  (NP set/NN input/NN data/NNS responses/NNS)
  ,/,
  (NP trains/NNS)
  model/VBP
  (NP generate/NN)
  (NP reasonable/JJ predictions/NNS response/NN)
  (NP new/JJ dataMachine/NN learning/NN)
  Unsupervised/VBD
  learning/VBG
  (NP /NNP Data/NNP contain/NN category/response/NN predict/NN)
  /VBD
  (NP The/DT goal/NN)
  learn/VBP
  (NP underlying/JJ structure/NN distribution/NN data/NNS)
  ,/,
  (NP discover/NN)
  (NP inherent/JJ patterns/NNS)
  within/IN
  (NP order/NN draw/NN inferences/NNS)
  Supervised/VBD
  learning/VBG
  /IN
  We/PRP
  know/VBP
  (NP outcome/response/JJ /NNP Takes/NNP)
  known/VBN
  (NP set/NN input/NN data/NNS responses/NNS)
  ,/,
  (NP trains/NNS)
  model/VBP
  (NP generate/NN)
  (NP reasonable/JJ predictions/NNS response/NN)
  (NP new/JJ data/NNS)
  11/14Demystifying/CD
  (NP data/NNS science/NN)
  If/IN
  (NP response/NN category/NN predict/NN)
  ,/,
  (NP goal/NN learn/NN)
  (NP underlying/JJ structure/NN data/NNS discover/NN patterns/NNS)
  draw/VB
  (NP real/JJ world/NN inferences/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Machine', ' Data contain category/response predict', 'The goal', 'underlying structure distribution data', 'discover', 'inherent patterns', 'order draw inferences', 'outcome/ response  Takes', 'set input data responses', 'trains', 'generate', 'reasonable predictions response', 'new dataMachine learning', ' Data contain category/response predict', 'The goal', 'underlying structure distribution data', 'discover', 'inherent patterns', 'order draw inferences', 'outcome/response  Takes', 'set input data responses', 'trains', 'generate', 'reasonable predictions response', 'new data', 'data science', 'response category predict', 'goal learn', 'underlying structure data discover patterns', 'real world inferences']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Supervised', 'supervis'), ('learning', 'learn'), ('', ''), ('Data', 'data'), ('contain', 'contain'), ('category/response', 'category/respons'), ('predict', 'predict'), ('', ''), ('The', 'the'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underli'), ('structure', 'structur'), ('distribution', 'distribut'), ('data', 'data'), (',', ','), ('discover', 'discov'), ('inherent', 'inher'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'infer'), ('', ''), ('We', 'we'), ('know', 'know'), ('outcome/', 'outcome/'), ('response', 'respons'), ('', ''), ('Takes', 'take'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'respons'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'gener'), ('reasonable', 'reason'), ('predictions', 'predict'), ('response', 'respons'), ('new', 'new'), ('dataMachine', 'datamachin'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('', ''), ('Data', 'data'), ('contain', 'contain'), ('category/response', 'category/respons'), ('predict', 'predict'), ('', ''), ('The', 'the'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underli'), ('structure', 'structur'), ('distribution', 'distribut'), ('data', 'data'), (',', ','), ('discover', 'discov'), ('inherent', 'inher'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'infer'), ('Supervised', 'supervis'), ('learning', 'learn'), ('', ''), ('We', 'we'), ('know', 'know'), ('outcome/response', 'outcome/respons'), ('', ''), ('Takes', 'take'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'respons'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'gener'), ('reasonable', 'reason'), ('predictions', 'predict'), ('response', 'respons'), ('new', 'new'), ('data', 'data'), ('11/14Demystifying', '11/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('If', 'if'), ('response', 'respons'), ('category', 'categori'), ('predict', 'predict'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underli'), ('structure', 'structur'), ('data', 'data'), ('discover', 'discov'), ('patterns', 'pattern'), ('draw', 'draw'), ('real', 'real'), ('world', 'world'), ('inferences', 'infer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Supervised', 'supervis'), ('learning', 'learn'), ('', ''), ('Data', 'data'), ('contain', 'contain'), ('category/response', 'category/respons'), ('predict', 'predict'), ('', ''), ('The', 'the'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'under'), ('structure', 'structur'), ('distribution', 'distribut'), ('data', 'data'), (',', ','), ('discover', 'discov'), ('inherent', 'inher'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'infer'), ('', ''), ('We', 'we'), ('know', 'know'), ('outcome/', 'outcome/'), ('response', 'respons'), ('', ''), ('Takes', 'take'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'respons'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'generat'), ('reasonable', 'reason'), ('predictions', 'predict'), ('response', 'respons'), ('new', 'new'), ('dataMachine', 'datamachin'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('', ''), ('Data', 'data'), ('contain', 'contain'), ('category/response', 'category/respons'), ('predict', 'predict'), ('', ''), ('The', 'the'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'under'), ('structure', 'structur'), ('distribution', 'distribut'), ('data', 'data'), (',', ','), ('discover', 'discov'), ('inherent', 'inher'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'infer'), ('Supervised', 'supervis'), ('learning', 'learn'), ('', ''), ('We', 'we'), ('know', 'know'), ('outcome/response', 'outcome/respons'), ('', ''), ('Takes', 'take'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'respons'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'generat'), ('reasonable', 'reason'), ('predictions', 'predict'), ('response', 'respons'), ('new', 'new'), ('data', 'data'), ('11/14Demystifying', '11/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('If', 'if'), ('response', 'respons'), ('category', 'categori'), ('predict', 'predict'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'under'), ('structure', 'structur'), ('data', 'data'), ('discover', 'discov'), ('patterns', 'pattern'), ('draw', 'draw'), ('real', 'real'), ('world', 'world'), ('inferences', 'infer'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('Supervised', 'Supervised'), ('learning', 'learning'), ('', ''), ('Data', 'Data'), ('contain', 'contain'), ('category/response', 'category/response'), ('predict', 'predict'), ('', ''), ('The', 'The'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underlying'), ('structure', 'structure'), ('distribution', 'distribution'), ('data', 'data'), (',', ','), ('discover', 'discover'), ('inherent', 'inherent'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'inference'), ('', ''), ('We', 'We'), ('know', 'know'), ('outcome/', 'outcome/'), ('response', 'response'), ('', ''), ('Takes', 'Takes'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'response'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'generate'), ('reasonable', 'reasonable'), ('predictions', 'prediction'), ('response', 'response'), ('new', 'new'), ('dataMachine', 'dataMachine'), ('learning', 'learning'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('', ''), ('Data', 'Data'), ('contain', 'contain'), ('category/response', 'category/response'), ('predict', 'predict'), ('', ''), ('The', 'The'), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underlying'), ('structure', 'structure'), ('distribution', 'distribution'), ('data', 'data'), (',', ','), ('discover', 'discover'), ('inherent', 'inherent'), ('patterns', 'pattern'), ('within', 'within'), ('order', 'order'), ('draw', 'draw'), ('inferences', 'inference'), ('Supervised', 'Supervised'), ('learning', 'learning'), ('', ''), ('We', 'We'), ('know', 'know'), ('outcome/response', 'outcome/response'), ('', ''), ('Takes', 'Takes'), ('known', 'known'), ('set', 'set'), ('input', 'input'), ('data', 'data'), ('responses', 'response'), (',', ','), ('trains', 'train'), ('model', 'model'), ('generate', 'generate'), ('reasonable', 'reasonable'), ('predictions', 'prediction'), ('response', 'response'), ('new', 'new'), ('data', 'data'), ('11/14Demystifying', '11/14Demystifying'), ('data', 'data'), ('science', 'science'), ('If', 'If'), ('response', 'response'), ('category', 'category'), ('predict', 'predict'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('underlying', 'underlying'), ('structure', 'structure'), ('data', 'data'), ('discover', 'discover'), ('patterns', 'pattern'), ('draw', 'draw'), ('real', 'real'), ('world', 'world'), ('inferences', 'inference'), ('.', '.')]



============================ Sentence 165 =============================

For  example, unsupervised learning approaches are commonly used to segment  customers based on demographic, behavior and past product purchase history. 


>> Tokens are: 
 ['For', 'example', ',', 'unsupervised', 'learning', 'approaches', 'commonly', 'used', 'segment', 'customers', 'based', 'demographic', ',', 'behavior', 'past', 'product', 'purchase', 'history', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'approaches'), ('approaches', 'commonly'), ('commonly', 'used'), ('used', 'segment'), ('segment', 'customers'), ('customers', 'based'), ('based', 'demographic'), ('demographic', ','), (',', 'behavior'), ('behavior', 'past'), ('past', 'product'), ('product', 'purchase'), ('purchase', 'history'), ('history', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'unsupervised'), (',', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'approaches'), ('learning', 'approaches', 'commonly'), ('approaches', 'commonly', 'used'), ('commonly', 'used', 'segment'), ('used', 'segment', 'customers'), ('segment', 'customers', 'based'), ('customers', 'based', 'demographic'), ('based', 'demographic', ','), ('demographic', ',', 'behavior'), (',', 'behavior', 'past'), ('behavior', 'past', 'product'), ('past', 'product', 'purchase'), ('product', 'purchase', 'history'), ('purchase', 'history', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('approaches', 'NNS'), ('commonly', 'RB'), ('used', 'VBD'), ('segment', 'NN'), ('customers', 'NNS'), ('based', 'VBN'), ('demographic', 'JJ'), (',', ','), ('behavior', 'JJ'), ('past', 'JJ'), ('product', 'NN'), ('purchase', 'NN'), ('history', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  unsupervised/VBD
  learning/VBG
  (NP approaches/NNS)
  commonly/RB
  used/VBD
  (NP segment/NN customers/NNS)
  based/VBN
  demographic/JJ
  ,/,
  (NP behavior/JJ past/JJ product/NN purchase/NN history/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'approaches', 'segment customers', 'behavior past product purchase history']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approaches', 'approach'), ('commonly', 'commonli'), ('used', 'use'), ('segment', 'segment'), ('customers', 'custom'), ('based', 'base'), ('demographic', 'demograph'), (',', ','), ('behavior', 'behavior'), ('past', 'past'), ('product', 'product'), ('purchase', 'purchas'), ('history', 'histori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approaches', 'approach'), ('commonly', 'common'), ('used', 'use'), ('segment', 'segment'), ('customers', 'custom'), ('based', 'base'), ('demographic', 'demograph'), (',', ','), ('behavior', 'behavior'), ('past', 'past'), ('product', 'product'), ('purchase', 'purchas'), ('history', 'histori'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('approaches', 'approach'), ('commonly', 'commonly'), ('used', 'used'), ('segment', 'segment'), ('customers', 'customer'), ('based', 'based'), ('demographic', 'demographic'), (',', ','), ('behavior', 'behavior'), ('past', 'past'), ('product', 'product'), ('purchase', 'purchase'), ('history', 'history'), ('.', '.')]



============================ Sentence 166 =============================

This allows an organization to learn more about their customers, which products  are frequently bought together and how different groups prefer certain services  and products over others. 


>> Tokens are: 
 ['This', 'allows', 'organization', 'learn', 'customers', ',', 'products', 'frequently', 'bought', 'together', 'different', 'groups', 'prefer', 'certain', 'services', 'products', 'others', '.']

>> Bigrams are: 
 [('This', 'allows'), ('allows', 'organization'), ('organization', 'learn'), ('learn', 'customers'), ('customers', ','), (',', 'products'), ('products', 'frequently'), ('frequently', 'bought'), ('bought', 'together'), ('together', 'different'), ('different', 'groups'), ('groups', 'prefer'), ('prefer', 'certain'), ('certain', 'services'), ('services', 'products'), ('products', 'others'), ('others', '.')]

>> Trigrams are: 
 [('This', 'allows', 'organization'), ('allows', 'organization', 'learn'), ('organization', 'learn', 'customers'), ('learn', 'customers', ','), ('customers', ',', 'products'), (',', 'products', 'frequently'), ('products', 'frequently', 'bought'), ('frequently', 'bought', 'together'), ('bought', 'together', 'different'), ('together', 'different', 'groups'), ('different', 'groups', 'prefer'), ('groups', 'prefer', 'certain'), ('prefer', 'certain', 'services'), ('certain', 'services', 'products'), ('services', 'products', 'others'), ('products', 'others', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('allows', 'VBZ'), ('organization', 'NN'), ('learn', 'NN'), ('customers', 'NNS'), (',', ','), ('products', 'NNS'), ('frequently', 'RB'), ('bought', 'VBD'), ('together', 'RB'), ('different', 'JJ'), ('groups', 'NNS'), ('prefer', 'VBP'), ('certain', 'JJ'), ('services', 'NNS'), ('products', 'NNS'), ('others', 'NNS'), ('.', '.')]

 (S
  This/DT
  allows/VBZ
  (NP organization/NN learn/NN customers/NNS)
  ,/,
  (NP products/NNS)
  frequently/RB
  bought/VBD
  together/RB
  (NP different/JJ groups/NNS)
  prefer/VBP
  (NP certain/JJ services/NNS products/NNS others/NNS)
  ./.) 


>> Noun Phrases are: 
 ['organization learn customers', 'products', 'different groups', 'certain services products others']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('allows', 'allow'), ('organization', 'organ'), ('learn', 'learn'), ('customers', 'custom'), (',', ','), ('products', 'product'), ('frequently', 'frequent'), ('bought', 'bought'), ('together', 'togeth'), ('different', 'differ'), ('groups', 'group'), ('prefer', 'prefer'), ('certain', 'certain'), ('services', 'servic'), ('products', 'product'), ('others', 'other'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('allows', 'allow'), ('organization', 'organ'), ('learn', 'learn'), ('customers', 'custom'), (',', ','), ('products', 'product'), ('frequently', 'frequent'), ('bought', 'bought'), ('together', 'togeth'), ('different', 'differ'), ('groups', 'group'), ('prefer', 'prefer'), ('certain', 'certain'), ('services', 'servic'), ('products', 'product'), ('others', 'other'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('allows', 'allows'), ('organization', 'organization'), ('learn', 'learn'), ('customers', 'customer'), (',', ','), ('products', 'product'), ('frequently', 'frequently'), ('bought', 'bought'), ('together', 'together'), ('different', 'different'), ('groups', 'group'), ('prefer', 'prefer'), ('certain', 'certain'), ('services', 'service'), ('products', 'product'), ('others', 'others'), ('.', '.')]



============================ Sentence 167 =============================

It may not immediately understand that Emily from  Philadelphia falls within customer segment X, but the organization can learn how  many of its customers are similar to Emily based on behavior and consumption  characteristics. 


>> Tokens are: 
 ['It', 'may', 'immediately', 'understand', 'Emily', 'Philadelphia', 'falls', 'within', 'customer', 'segment', 'X', ',', 'organization', 'learn', 'many', 'customers', 'similar', 'Emily', 'based', 'behavior', 'consumption', 'characteristics', '.']

>> Bigrams are: 
 [('It', 'may'), ('may', 'immediately'), ('immediately', 'understand'), ('understand', 'Emily'), ('Emily', 'Philadelphia'), ('Philadelphia', 'falls'), ('falls', 'within'), ('within', 'customer'), ('customer', 'segment'), ('segment', 'X'), ('X', ','), (',', 'organization'), ('organization', 'learn'), ('learn', 'many'), ('many', 'customers'), ('customers', 'similar'), ('similar', 'Emily'), ('Emily', 'based'), ('based', 'behavior'), ('behavior', 'consumption'), ('consumption', 'characteristics'), ('characteristics', '.')]

>> Trigrams are: 
 [('It', 'may', 'immediately'), ('may', 'immediately', 'understand'), ('immediately', 'understand', 'Emily'), ('understand', 'Emily', 'Philadelphia'), ('Emily', 'Philadelphia', 'falls'), ('Philadelphia', 'falls', 'within'), ('falls', 'within', 'customer'), ('within', 'customer', 'segment'), ('customer', 'segment', 'X'), ('segment', 'X', ','), ('X', ',', 'organization'), (',', 'organization', 'learn'), ('organization', 'learn', 'many'), ('learn', 'many', 'customers'), ('many', 'customers', 'similar'), ('customers', 'similar', 'Emily'), ('similar', 'Emily', 'based'), ('Emily', 'based', 'behavior'), ('based', 'behavior', 'consumption'), ('behavior', 'consumption', 'characteristics'), ('consumption', 'characteristics', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('may', 'MD'), ('immediately', 'RB'), ('understand', 'VB'), ('Emily', 'NNP'), ('Philadelphia', 'NNP'), ('falls', 'VBZ'), ('within', 'IN'), ('customer', 'NN'), ('segment', 'NN'), ('X', 'NNP'), (',', ','), ('organization', 'NN'), ('learn', 'VBD'), ('many', 'JJ'), ('customers', 'NNS'), ('similar', 'JJ'), ('Emily', 'RB'), ('based', 'VBN'), ('behavior', 'JJ'), ('consumption', 'NN'), ('characteristics', 'NNS'), ('.', '.')]

 (S
  It/PRP
  may/MD
  immediately/RB
  understand/VB
  (NP Emily/NNP Philadelphia/NNP)
  falls/VBZ
  within/IN
  (NP customer/NN segment/NN X/NNP)
  ,/,
  (NP organization/NN)
  learn/VBD
  (NP many/JJ customers/NNS)
  similar/JJ
  Emily/RB
  based/VBN
  (NP behavior/JJ consumption/NN characteristics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Emily Philadelphia', 'customer segment X', 'organization', 'many customers', 'behavior consumption characteristics']

>> Named Entities are: 
 [('PERSON', 'Emily Philadelphia')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('may', 'may'), ('immediately', 'immedi'), ('understand', 'understand'), ('Emily', 'emili'), ('Philadelphia', 'philadelphia'), ('falls', 'fall'), ('within', 'within'), ('customer', 'custom'), ('segment', 'segment'), ('X', 'x'), (',', ','), ('organization', 'organ'), ('learn', 'learn'), ('many', 'mani'), ('customers', 'custom'), ('similar', 'similar'), ('Emily', 'emili'), ('based', 'base'), ('behavior', 'behavior'), ('consumption', 'consumpt'), ('characteristics', 'characterist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('may', 'may'), ('immediately', 'immedi'), ('understand', 'understand'), ('Emily', 'emili'), ('Philadelphia', 'philadelphia'), ('falls', 'fall'), ('within', 'within'), ('customer', 'custom'), ('segment', 'segment'), ('X', 'x'), (',', ','), ('organization', 'organ'), ('learn', 'learn'), ('many', 'mani'), ('customers', 'custom'), ('similar', 'similar'), ('Emily', 'emili'), ('based', 'base'), ('behavior', 'behavior'), ('consumption', 'consumpt'), ('characteristics', 'characterist'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('may', 'may'), ('immediately', 'immediately'), ('understand', 'understand'), ('Emily', 'Emily'), ('Philadelphia', 'Philadelphia'), ('falls', 'fall'), ('within', 'within'), ('customer', 'customer'), ('segment', 'segment'), ('X', 'X'), (',', ','), ('organization', 'organization'), ('learn', 'learn'), ('many', 'many'), ('customers', 'customer'), ('similar', 'similar'), ('Emily', 'Emily'), ('based', 'based'), ('behavior', 'behavior'), ('consumption', 'consumption'), ('characteristics', 'characteristic'), ('.', '.')]



============================ Sentence 168 =============================

Are they active on mobile? 


>> Tokens are: 
 ['Are', 'active', 'mobile', '?']

>> Bigrams are: 
 [('Are', 'active'), ('active', 'mobile'), ('mobile', '?')]

>> Trigrams are: 
 [('Are', 'active', 'mobile'), ('active', 'mobile', '?')]

>> POS Tags are: 
 [('Are', 'NNP'), ('active', 'JJ'), ('mobile', 'NN'), ('?', '.')]

 (S (NP Are/NNP) (NP active/JJ mobile/NN) ?/.) 


>> Noun Phrases are: 
 ['Are', 'active mobile']

>> Named Entities are: 
 [('GPE', 'Are')] 

>> Stemming using Porter Stemmer: 
 [('Are', 'are'), ('active', 'activ'), ('mobile', 'mobil'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Are', 'are'), ('active', 'activ'), ('mobile', 'mobil'), ('?', '?')]

>> Lemmatization: 
 [('Are', 'Are'), ('active', 'active'), ('mobile', 'mobile'), ('?', '?')]



============================ Sentence 169 =============================

Do they use social media? 


>> Tokens are: 
 ['Do', 'use', 'social', 'media', '?']

>> Bigrams are: 
 [('Do', 'use'), ('use', 'social'), ('social', 'media'), ('media', '?')]

>> Trigrams are: 
 [('Do', 'use', 'social'), ('use', 'social', 'media'), ('social', 'media', '?')]

>> POS Tags are: 
 [('Do', 'VB'), ('use', 'VB'), ('social', 'JJ'), ('media', 'NNS'), ('?', '.')]

 (S Do/VB use/VB (NP social/JJ media/NNS) ?/.) 


>> Noun Phrases are: 
 ['social media']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Do', 'do'), ('use', 'use'), ('social', 'social'), ('media', 'media'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Do', 'do'), ('use', 'use'), ('social', 'social'), ('media', 'media'), ('?', '?')]

>> Lemmatization: 
 [('Do', 'Do'), ('use', 'use'), ('social', 'social'), ('media', 'medium'), ('?', '?')]



============================ Sentence 170 =============================

Do they  visit retail stores for purchases? 


>> Tokens are: 
 ['Do', 'visit', 'retail', 'stores', 'purchases', '?']

>> Bigrams are: 
 [('Do', 'visit'), ('visit', 'retail'), ('retail', 'stores'), ('stores', 'purchases'), ('purchases', '?')]

>> Trigrams are: 
 [('Do', 'visit', 'retail'), ('visit', 'retail', 'stores'), ('retail', 'stores', 'purchases'), ('stores', 'purchases', '?')]

>> POS Tags are: 
 [('Do', 'VB'), ('visit', 'NNS'), ('retail', 'VB'), ('stores', 'NNS'), ('purchases', 'NNS'), ('?', '.')]

 (S Do/VB (NP visit/NNS) retail/VB (NP stores/NNS purchases/NNS) ?/.) 


>> Noun Phrases are: 
 ['visit', 'stores purchases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Do', 'do'), ('visit', 'visit'), ('retail', 'retail'), ('stores', 'store'), ('purchases', 'purchas'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Do', 'do'), ('visit', 'visit'), ('retail', 'retail'), ('stores', 'store'), ('purchases', 'purchas'), ('?', '?')]

>> Lemmatization: 
 [('Do', 'Do'), ('visit', 'visit'), ('retail', 'retail'), ('stores', 'store'), ('purchases', 'purchase'), ('?', '?')]



============================ Sentence 171 =============================

Are they affluent? 


>> Tokens are: 
 ['Are', 'affluent', '?']

>> Bigrams are: 
 [('Are', 'affluent'), ('affluent', '?')]

>> Trigrams are: 
 [('Are', 'affluent', '?')]

>> POS Tags are: 
 [('Are', 'NNP'), ('affluent', 'JJ'), ('?', '.')]

 (S (NP Are/NNP) affluent/JJ ?/.) 


>> Noun Phrases are: 
 ['Are']

>> Named Entities are: 
 [('GPE', 'Are')] 

>> Stemming using Porter Stemmer: 
 [('Are', 'are'), ('affluent', 'affluent'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Are', 'are'), ('affluent', 'affluent'), ('?', '?')]

>> Lemmatization: 
 [('Are', 'Are'), ('affluent', 'affluent'), ('?', '?')]



============================ Sentence 172 =============================

These insights can allow  organizations to make data-driven decisions for future marketing campaigns,  product development, etc. 


>> Tokens are: 
 ['These', 'insights', 'allow', 'organizations', 'make', 'data-driven', 'decisions', 'future', 'marketing', 'campaigns', ',', 'product', 'development', ',', 'etc', '.']

>> Bigrams are: 
 [('These', 'insights'), ('insights', 'allow'), ('allow', 'organizations'), ('organizations', 'make'), ('make', 'data-driven'), ('data-driven', 'decisions'), ('decisions', 'future'), ('future', 'marketing'), ('marketing', 'campaigns'), ('campaigns', ','), (',', 'product'), ('product', 'development'), ('development', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('These', 'insights', 'allow'), ('insights', 'allow', 'organizations'), ('allow', 'organizations', 'make'), ('organizations', 'make', 'data-driven'), ('make', 'data-driven', 'decisions'), ('data-driven', 'decisions', 'future'), ('decisions', 'future', 'marketing'), ('future', 'marketing', 'campaigns'), ('marketing', 'campaigns', ','), ('campaigns', ',', 'product'), (',', 'product', 'development'), ('product', 'development', ','), ('development', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('insights', 'NNS'), ('allow', 'VBP'), ('organizations', 'NNS'), ('make', 'VBP'), ('data-driven', 'JJ'), ('decisions', 'NNS'), ('future', 'JJ'), ('marketing', 'NN'), ('campaigns', 'NNS'), (',', ','), ('product', 'NN'), ('development', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  (NP These/DT insights/NNS)
  allow/VBP
  (NP organizations/NNS)
  make/VBP
  (NP data-driven/JJ decisions/NNS)
  (NP future/JJ marketing/NN campaigns/NNS)
  ,/,
  (NP product/NN development/NN)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['These insights', 'organizations', 'data-driven decisions', 'future marketing campaigns', 'product development']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('insights', 'insight'), ('allow', 'allow'), ('organizations', 'organ'), ('make', 'make'), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('future', 'futur'), ('marketing', 'market'), ('campaigns', 'campaign'), (',', ','), ('product', 'product'), ('development', 'develop'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('insights', 'insight'), ('allow', 'allow'), ('organizations', 'organ'), ('make', 'make'), ('data-driven', 'data-driven'), ('decisions', 'decis'), ('future', 'futur'), ('marketing', 'market'), ('campaigns', 'campaign'), (',', ','), ('product', 'product'), ('development', 'develop'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('insights', 'insight'), ('allow', 'allow'), ('organizations', 'organization'), ('make', 'make'), ('data-driven', 'data-driven'), ('decisions', 'decision'), ('future', 'future'), ('marketing', 'marketing'), ('campaigns', 'campaign'), (',', ','), ('product', 'product'), ('development', 'development'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 173 =============================

Supervised learning  Supervised learning can be broken down into two categories based on what it is  trying to predict. 


>> Tokens are: 
 ['Supervised', 'learning', 'Supervised', 'learning', 'broken', 'two', 'categories', 'based', 'trying', 'predict', '.']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'Supervised'), ('Supervised', 'learning'), ('learning', 'broken'), ('broken', 'two'), ('two', 'categories'), ('categories', 'based'), ('based', 'trying'), ('trying', 'predict'), ('predict', '.')]

>> Trigrams are: 
 [('Supervised', 'learning', 'Supervised'), ('learning', 'Supervised', 'learning'), ('Supervised', 'learning', 'broken'), ('learning', 'broken', 'two'), ('broken', 'two', 'categories'), ('two', 'categories', 'based'), ('categories', 'based', 'trying'), ('based', 'trying', 'predict'), ('trying', 'predict', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'NN'), ('Supervised', 'VBD'), ('learning', 'VBG'), ('broken', 'JJ'), ('two', 'CD'), ('categories', 'NNS'), ('based', 'VBN'), ('trying', 'VBG'), ('predict', 'NN'), ('.', '.')]

 (S
  Supervised/VBN
  (NP learning/NN)
  Supervised/VBD
  learning/VBG
  broken/JJ
  two/CD
  (NP categories/NNS)
  based/VBN
  trying/VBG
  (NP predict/NN)
  ./.) 


>> Noun Phrases are: 
 ['learning', 'categories', 'predict']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('Supervised', 'supervis'), ('learning', 'learn'), ('broken', 'broken'), ('two', 'two'), ('categories', 'categori'), ('based', 'base'), ('trying', 'tri'), ('predict', 'predict'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('Supervised', 'supervis'), ('learning', 'learn'), ('broken', 'broken'), ('two', 'two'), ('categories', 'categori'), ('based', 'base'), ('trying', 'tri'), ('predict', 'predict'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('Supervised', 'Supervised'), ('learning', 'learning'), ('broken', 'broken'), ('two', 'two'), ('categories', 'category'), ('based', 'based'), ('trying', 'trying'), ('predict', 'predict'), ('.', '.')]



============================ Sentence 174 =============================

Supervised learning  Classification  (categories) Regression (numbers)  Use	if	data	can	be	tagged,	 categorized	or	separated	 into	specific	groups		or	 classes  Use	if	the	response	being	 predicted	is	a	real	number  Supervised learning  Classification  (categories)  Regression (numbers)  Use if data can be tagged,  categorized or separated   into specific groups  or classes  Use if the response being  predicted is a real number  Classification algorithms or approaches are used when asking questions regarding  categories. 


>> Tokens are: 
 ['Supervised', 'learning', 'Classification', '(', 'categories', ')', 'Regression', '(', 'numbers', ')', 'Use', 'data', 'tagged', ',', 'categorized', 'separated', 'specific', 'groups', 'classes', 'Use', 'response', 'predicted', 'real', 'number', 'Supervised', 'learning', 'Classification', '(', 'categories', ')', 'Regression', '(', 'numbers', ')', 'Use', 'data', 'tagged', ',', 'categorized', 'separated', 'specific', 'groups', 'classes', 'Use', 'response', 'predicted', 'real', 'number', 'Classification', 'algorithms', 'approaches', 'used', 'asking', 'questions', 'regarding', 'categories', '.']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'Classification'), ('Classification', '('), ('(', 'categories'), ('categories', ')'), (')', 'Regression'), ('Regression', '('), ('(', 'numbers'), ('numbers', ')'), (')', 'Use'), ('Use', 'data'), ('data', 'tagged'), ('tagged', ','), (',', 'categorized'), ('categorized', 'separated'), ('separated', 'specific'), ('specific', 'groups'), ('groups', 'classes'), ('classes', 'Use'), ('Use', 'response'), ('response', 'predicted'), ('predicted', 'real'), ('real', 'number'), ('number', 'Supervised'), ('Supervised', 'learning'), ('learning', 'Classification'), ('Classification', '('), ('(', 'categories'), ('categories', ')'), (')', 'Regression'), ('Regression', '('), ('(', 'numbers'), ('numbers', ')'), (')', 'Use'), ('Use', 'data'), ('data', 'tagged'), ('tagged', ','), (',', 'categorized'), ('categorized', 'separated'), ('separated', 'specific'), ('specific', 'groups'), ('groups', 'classes'), ('classes', 'Use'), ('Use', 'response'), ('response', 'predicted'), ('predicted', 'real'), ('real', 'number'), ('number', 'Classification'), ('Classification', 'algorithms'), ('algorithms', 'approaches'), ('approaches', 'used'), ('used', 'asking'), ('asking', 'questions'), ('questions', 'regarding'), ('regarding', 'categories'), ('categories', '.')]

>> Trigrams are: 
 [('Supervised', 'learning', 'Classification'), ('learning', 'Classification', '('), ('Classification', '(', 'categories'), ('(', 'categories', ')'), ('categories', ')', 'Regression'), (')', 'Regression', '('), ('Regression', '(', 'numbers'), ('(', 'numbers', ')'), ('numbers', ')', 'Use'), (')', 'Use', 'data'), ('Use', 'data', 'tagged'), ('data', 'tagged', ','), ('tagged', ',', 'categorized'), (',', 'categorized', 'separated'), ('categorized', 'separated', 'specific'), ('separated', 'specific', 'groups'), ('specific', 'groups', 'classes'), ('groups', 'classes', 'Use'), ('classes', 'Use', 'response'), ('Use', 'response', 'predicted'), ('response', 'predicted', 'real'), ('predicted', 'real', 'number'), ('real', 'number', 'Supervised'), ('number', 'Supervised', 'learning'), ('Supervised', 'learning', 'Classification'), ('learning', 'Classification', '('), ('Classification', '(', 'categories'), ('(', 'categories', ')'), ('categories', ')', 'Regression'), (')', 'Regression', '('), ('Regression', '(', 'numbers'), ('(', 'numbers', ')'), ('numbers', ')', 'Use'), (')', 'Use', 'data'), ('Use', 'data', 'tagged'), ('data', 'tagged', ','), ('tagged', ',', 'categorized'), (',', 'categorized', 'separated'), ('categorized', 'separated', 'specific'), ('separated', 'specific', 'groups'), ('specific', 'groups', 'classes'), ('groups', 'classes', 'Use'), ('classes', 'Use', 'response'), ('Use', 'response', 'predicted'), ('response', 'predicted', 'real'), ('predicted', 'real', 'number'), ('real', 'number', 'Classification'), ('number', 'Classification', 'algorithms'), ('Classification', 'algorithms', 'approaches'), ('algorithms', 'approaches', 'used'), ('approaches', 'used', 'asking'), ('used', 'asking', 'questions'), ('asking', 'questions', 'regarding'), ('questions', 'regarding', 'categories'), ('regarding', 'categories', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'JJ'), ('Classification', 'NNP'), ('(', '('), ('categories', 'NNS'), (')', ')'), ('Regression', 'NNP'), ('(', '('), ('numbers', 'NNS'), (')', ')'), ('Use', 'NNP'), ('data', 'NNS'), ('tagged', 'VBD'), (',', ','), ('categorized', 'VBN'), ('separated', 'VBN'), ('specific', 'JJ'), ('groups', 'NNS'), ('classes', 'NNS'), ('Use', 'NNP'), ('response', 'NN'), ('predicted', 'VBD'), ('real', 'JJ'), ('number', 'NN'), ('Supervised', 'VBD'), ('learning', 'JJ'), ('Classification', 'NNP'), ('(', '('), ('categories', 'NNS'), (')', ')'), ('Regression', 'NNP'), ('(', '('), ('numbers', 'NNS'), (')', ')'), ('Use', 'NNP'), ('data', 'NNS'), ('tagged', 'VBD'), (',', ','), ('categorized', 'VBN'), ('separated', 'VBN'), ('specific', 'JJ'), ('groups', 'NNS'), ('classes', 'NNS'), ('Use', 'NNP'), ('response', 'NN'), ('predicted', 'VBD'), ('real', 'JJ'), ('number', 'NN'), ('Classification', 'NNP'), ('algorithms', 'NN'), ('approaches', 'NNS'), ('used', 'VBD'), ('asking', 'VBG'), ('questions', 'NNS'), ('regarding', 'VBG'), ('categories', 'NNS'), ('.', '.')]

 (S
  Supervised/VBN
  (NP learning/JJ Classification/NNP)
  (/(
  (NP categories/NNS)
  )/)
  (NP Regression/NNP)
  (/(
  (NP numbers/NNS)
  )/)
  (NP Use/NNP data/NNS)
  tagged/VBD
  ,/,
  categorized/VBN
  separated/VBN
  (NP specific/JJ groups/NNS classes/NNS Use/NNP response/NN)
  predicted/VBD
  (NP real/JJ number/NN)
  Supervised/VBD
  (NP learning/JJ Classification/NNP)
  (/(
  (NP categories/NNS)
  )/)
  (NP Regression/NNP)
  (/(
  (NP numbers/NNS)
  )/)
  (NP Use/NNP data/NNS)
  tagged/VBD
  ,/,
  categorized/VBN
  separated/VBN
  (NP specific/JJ groups/NNS classes/NNS Use/NNP response/NN)
  predicted/VBD
  (NP
    real/JJ
    number/NN
    Classification/NNP
    algorithms/NN
    approaches/NNS)
  used/VBD
  asking/VBG
  (NP questions/NNS)
  regarding/VBG
  (NP categories/NNS)
  ./.) 


>> Noun Phrases are: 
 ['learning Classification', 'categories', 'Regression', 'numbers', 'Use data', 'specific groups classes Use response', 'real number', 'learning Classification', 'categories', 'Regression', 'numbers', 'Use data', 'specific groups classes Use response', 'real number Classification algorithms approaches', 'questions', 'categories']

>> Named Entities are: 
 [('ORGANIZATION', 'Use'), ('ORGANIZATION', 'Use')] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('Classification', 'classif'), ('(', '('), ('categories', 'categori'), (')', ')'), ('Regression', 'regress'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'use'), ('data', 'data'), ('tagged', 'tag'), (',', ','), ('categorized', 'categor'), ('separated', 'separ'), ('specific', 'specif'), ('groups', 'group'), ('classes', 'class'), ('Use', 'use'), ('response', 'respons'), ('predicted', 'predict'), ('real', 'real'), ('number', 'number'), ('Supervised', 'supervis'), ('learning', 'learn'), ('Classification', 'classif'), ('(', '('), ('categories', 'categori'), (')', ')'), ('Regression', 'regress'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'use'), ('data', 'data'), ('tagged', 'tag'), (',', ','), ('categorized', 'categor'), ('separated', 'separ'), ('specific', 'specif'), ('groups', 'group'), ('classes', 'class'), ('Use', 'use'), ('response', 'respons'), ('predicted', 'predict'), ('real', 'real'), ('number', 'number'), ('Classification', 'classif'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'use'), ('asking', 'ask'), ('questions', 'question'), ('regarding', 'regard'), ('categories', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('Classification', 'classif'), ('(', '('), ('categories', 'categori'), (')', ')'), ('Regression', 'regress'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'use'), ('data', 'data'), ('tagged', 'tag'), (',', ','), ('categorized', 'categor'), ('separated', 'separ'), ('specific', 'specif'), ('groups', 'group'), ('classes', 'class'), ('Use', 'use'), ('response', 'respons'), ('predicted', 'predict'), ('real', 'real'), ('number', 'number'), ('Supervised', 'supervis'), ('learning', 'learn'), ('Classification', 'classif'), ('(', '('), ('categories', 'categori'), (')', ')'), ('Regression', 'regress'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'use'), ('data', 'data'), ('tagged', 'tag'), (',', ','), ('categorized', 'categor'), ('separated', 'separ'), ('specific', 'specif'), ('groups', 'group'), ('classes', 'class'), ('Use', 'use'), ('response', 'respons'), ('predicted', 'predict'), ('real', 'real'), ('number', 'number'), ('Classification', 'classif'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'use'), ('asking', 'ask'), ('questions', 'question'), ('regarding', 'regard'), ('categories', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('Classification', 'Classification'), ('(', '('), ('categories', 'category'), (')', ')'), ('Regression', 'Regression'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'Use'), ('data', 'data'), ('tagged', 'tagged'), (',', ','), ('categorized', 'categorized'), ('separated', 'separated'), ('specific', 'specific'), ('groups', 'group'), ('classes', 'class'), ('Use', 'Use'), ('response', 'response'), ('predicted', 'predicted'), ('real', 'real'), ('number', 'number'), ('Supervised', 'Supervised'), ('learning', 'learning'), ('Classification', 'Classification'), ('(', '('), ('categories', 'category'), (')', ')'), ('Regression', 'Regression'), ('(', '('), ('numbers', 'number'), (')', ')'), ('Use', 'Use'), ('data', 'data'), ('tagged', 'tagged'), (',', ','), ('categorized', 'categorized'), ('separated', 'separated'), ('specific', 'specific'), ('groups', 'group'), ('classes', 'class'), ('Use', 'Use'), ('response', 'response'), ('predicted', 'predicted'), ('real', 'real'), ('number', 'number'), ('Classification', 'Classification'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'used'), ('asking', 'asking'), ('questions', 'question'), ('regarding', 'regarding'), ('categories', 'category'), ('.', '.')]



============================ Sentence 175 =============================

Examples include:    Will this customer switch to another competitor in the next month? 


>> Tokens are: 
 ['Examples', 'include', ':', '', 'Will', 'customer', 'switch', 'another', 'competitor', 'next', 'month', '?']

>> Bigrams are: 
 [('Examples', 'include'), ('include', ':'), (':', ''), ('', 'Will'), ('Will', 'customer'), ('customer', 'switch'), ('switch', 'another'), ('another', 'competitor'), ('competitor', 'next'), ('next', 'month'), ('month', '?')]

>> Trigrams are: 
 [('Examples', 'include', ':'), ('include', ':', ''), (':', '', 'Will'), ('', 'Will', 'customer'), ('Will', 'customer', 'switch'), ('customer', 'switch', 'another'), ('switch', 'another', 'competitor'), ('another', 'competitor', 'next'), ('competitor', 'next', 'month'), ('next', 'month', '?')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('include', 'VBP'), (':', ':'), ('', 'NN'), ('Will', 'MD'), ('customer', 'NN'), ('switch', 'VB'), ('another', 'DT'), ('competitor', 'NN'), ('next', 'IN'), ('month', 'NN'), ('?', '.')]

 (S
  (NP Examples/NNS)
  include/VBP
  :/:
  (NP /NN)
  Will/MD
  (NP customer/NN)
  switch/VB
  (NP another/DT competitor/NN)
  next/IN
  (NP month/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Examples', '', 'customer', 'another competitor', 'month']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('include', 'includ'), (':', ':'), ('', ''), ('Will', 'will'), ('customer', 'custom'), ('switch', 'switch'), ('another', 'anoth'), ('competitor', 'competitor'), ('next', 'next'), ('month', 'month'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('include', 'includ'), (':', ':'), ('', ''), ('Will', 'will'), ('customer', 'custom'), ('switch', 'switch'), ('another', 'anoth'), ('competitor', 'competitor'), ('next', 'next'), ('month', 'month'), ('?', '?')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('include', 'include'), (':', ':'), ('', ''), ('Will', 'Will'), ('customer', 'customer'), ('switch', 'switch'), ('another', 'another'), ('competitor', 'competitor'), ('next', 'next'), ('month', 'month'), ('?', '?')]



============================ Sentence 176 =============================

 Will this customer default in the next month, six months or year? 


>> Tokens are: 
 ['', 'Will', 'customer', 'default', 'next', 'month', ',', 'six', 'months', 'year', '?']

>> Bigrams are: 
 [('', 'Will'), ('Will', 'customer'), ('customer', 'default'), ('default', 'next'), ('next', 'month'), ('month', ','), (',', 'six'), ('six', 'months'), ('months', 'year'), ('year', '?')]

>> Trigrams are: 
 [('', 'Will', 'customer'), ('Will', 'customer', 'default'), ('customer', 'default', 'next'), ('default', 'next', 'month'), ('next', 'month', ','), ('month', ',', 'six'), (',', 'six', 'months'), ('six', 'months', 'year'), ('months', 'year', '?')]

>> POS Tags are: 
 [('', 'NN'), ('Will', 'NNP'), ('customer', 'NN'), ('default', 'NN'), ('next', 'JJ'), ('month', 'NN'), (',', ','), ('six', 'CD'), ('months', 'NNS'), ('year', 'NN'), ('?', '.')]

 (S
  (NP /NN Will/NNP customer/NN default/NN)
  (NP next/JJ month/NN)
  ,/,
  six/CD
  (NP months/NNS year/NN)
  ?/.) 


>> Noun Phrases are: 
 [' Will customer default', 'next month', 'months year']

>> Named Entities are: 
 [('PERSON', 'Will')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Will', 'will'), ('customer', 'custom'), ('default', 'default'), ('next', 'next'), ('month', 'month'), (',', ','), ('six', 'six'), ('months', 'month'), ('year', 'year'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Will', 'will'), ('customer', 'custom'), ('default', 'default'), ('next', 'next'), ('month', 'month'), (',', ','), ('six', 'six'), ('months', 'month'), ('year', 'year'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Will', 'Will'), ('customer', 'customer'), ('default', 'default'), ('next', 'next'), ('month', 'month'), (',', ','), ('six', 'six'), ('months', 'month'), ('year', 'year'), ('?', '?')]



============================ Sentence 177 =============================

 Is an email spam or genuine? 


>> Tokens are: 
 ['', 'Is', 'email', 'spam', 'genuine', '?']

>> Bigrams are: 
 [('', 'Is'), ('Is', 'email'), ('email', 'spam'), ('spam', 'genuine'), ('genuine', '?')]

>> Trigrams are: 
 [('', 'Is', 'email'), ('Is', 'email', 'spam'), ('email', 'spam', 'genuine'), ('spam', 'genuine', '?')]

>> POS Tags are: 
 [('', 'NN'), ('Is', 'VBZ'), ('email', 'JJ'), ('spam', 'NN'), ('genuine', 'NN'), ('?', '.')]

 (S (NP /NN) Is/VBZ (NP email/JJ spam/NN genuine/NN) ?/.) 


>> Noun Phrases are: 
 ['', 'email spam genuine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Is', 'is'), ('email', 'email'), ('spam', 'spam'), ('genuine', 'genuin'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Is', 'is'), ('email', 'email'), ('spam', 'spam'), ('genuine', 'genuin'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Is', 'Is'), ('email', 'email'), ('spam', 'spam'), ('genuine', 'genuine'), ('?', '?')]



============================ Sentence 178 =============================

 Is this document for compliance, legal or customer support? 


>> Tokens are: 
 ['', 'Is', 'document', 'compliance', ',', 'legal', 'customer', 'support', '?']

>> Bigrams are: 
 [('', 'Is'), ('Is', 'document'), ('document', 'compliance'), ('compliance', ','), (',', 'legal'), ('legal', 'customer'), ('customer', 'support'), ('support', '?')]

>> Trigrams are: 
 [('', 'Is', 'document'), ('Is', 'document', 'compliance'), ('document', 'compliance', ','), ('compliance', ',', 'legal'), (',', 'legal', 'customer'), ('legal', 'customer', 'support'), ('customer', 'support', '?')]

>> POS Tags are: 
 [('', 'NN'), ('Is', 'VBZ'), ('document', 'JJ'), ('compliance', 'NN'), (',', ','), ('legal', 'JJ'), ('customer', 'NN'), ('support', 'NN'), ('?', '.')]

 (S
  (NP /NN)
  Is/VBZ
  (NP document/JJ compliance/NN)
  ,/,
  (NP legal/JJ customer/NN support/NN)
  ?/.) 


>> Noun Phrases are: 
 ['', 'document compliance', 'legal customer support']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Is', 'is'), ('document', 'document'), ('compliance', 'complianc'), (',', ','), ('legal', 'legal'), ('customer', 'custom'), ('support', 'support'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Is', 'is'), ('document', 'document'), ('compliance', 'complianc'), (',', ','), ('legal', 'legal'), ('customer', 'custom'), ('support', 'support'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Is', 'Is'), ('document', 'document'), ('compliance', 'compliance'), (',', ','), ('legal', 'legal'), ('customer', 'customer'), ('support', 'support'), ('?', '?')]



============================ Sentence 179 =============================

Regression algorithms or approaches are used when asking questions with   numerical outcomes:   What will the temperature be at 6:00 pm today? 


>> Tokens are: 
 ['Regression', 'algorithms', 'approaches', 'used', 'asking', 'questions', 'numerical', 'outcomes', ':', '', 'What', 'temperature', '6:00', 'pm', 'today', '?']

>> Bigrams are: 
 [('Regression', 'algorithms'), ('algorithms', 'approaches'), ('approaches', 'used'), ('used', 'asking'), ('asking', 'questions'), ('questions', 'numerical'), ('numerical', 'outcomes'), ('outcomes', ':'), (':', ''), ('', 'What'), ('What', 'temperature'), ('temperature', '6:00'), ('6:00', 'pm'), ('pm', 'today'), ('today', '?')]

>> Trigrams are: 
 [('Regression', 'algorithms', 'approaches'), ('algorithms', 'approaches', 'used'), ('approaches', 'used', 'asking'), ('used', 'asking', 'questions'), ('asking', 'questions', 'numerical'), ('questions', 'numerical', 'outcomes'), ('numerical', 'outcomes', ':'), ('outcomes', ':', ''), (':', '', 'What'), ('', 'What', 'temperature'), ('What', 'temperature', '6:00'), ('temperature', '6:00', 'pm'), ('6:00', 'pm', 'today'), ('pm', 'today', '?')]

>> POS Tags are: 
 [('Regression', 'NNP'), ('algorithms', 'NN'), ('approaches', 'NNS'), ('used', 'VBD'), ('asking', 'VBG'), ('questions', 'NNS'), ('numerical', 'JJ'), ('outcomes', 'NNS'), (':', ':'), ('', 'VB'), ('What', 'WP'), ('temperature', 'NN'), ('6:00', 'CD'), ('pm', 'NN'), ('today', 'NN'), ('?', '.')]

 (S
  (NP Regression/NNP algorithms/NN approaches/NNS)
  used/VBD
  asking/VBG
  (NP questions/NNS)
  (NP numerical/JJ outcomes/NNS)
  :/:
  /VB
  What/WP
  (NP temperature/NN)
  6:00/CD
  (NP pm/NN today/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Regression algorithms approaches', 'questions', 'numerical outcomes', 'temperature', 'pm today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Regression', 'regress'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'use'), ('asking', 'ask'), ('questions', 'question'), ('numerical', 'numer'), ('outcomes', 'outcom'), (':', ':'), ('', ''), ('What', 'what'), ('temperature', 'temperatur'), ('6:00', '6:00'), ('pm', 'pm'), ('today', 'today'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Regression', 'regress'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'use'), ('asking', 'ask'), ('questions', 'question'), ('numerical', 'numer'), ('outcomes', 'outcom'), (':', ':'), ('', ''), ('What', 'what'), ('temperature', 'temperatur'), ('6:00', '6:00'), ('pm', 'pm'), ('today', 'today'), ('?', '?')]

>> Lemmatization: 
 [('Regression', 'Regression'), ('algorithms', 'algorithm'), ('approaches', 'approach'), ('used', 'used'), ('asking', 'asking'), ('questions', 'question'), ('numerical', 'numerical'), ('outcomes', 'outcome'), (':', ':'), ('', ''), ('What', 'What'), ('temperature', 'temperature'), ('6:00', '6:00'), ('pm', 'pm'), ('today', 'today'), ('?', '?')]



============================ Sentence 180 =============================

 In how many days will this machine stop working? 


>> Tokens are: 
 ['', 'In', 'many', 'days', 'machine', 'stop', 'working', '?']

>> Bigrams are: 
 [('', 'In'), ('In', 'many'), ('many', 'days'), ('days', 'machine'), ('machine', 'stop'), ('stop', 'working'), ('working', '?')]

>> Trigrams are: 
 [('', 'In', 'many'), ('In', 'many', 'days'), ('many', 'days', 'machine'), ('days', 'machine', 'stop'), ('machine', 'stop', 'working'), ('stop', 'working', '?')]

>> POS Tags are: 
 [('', 'NN'), ('In', 'IN'), ('many', 'JJ'), ('days', 'NNS'), ('machine', 'NN'), ('stop', 'NN'), ('working', 'NN'), ('?', '.')]

 (S
  (NP /NN)
  In/IN
  (NP many/JJ days/NNS machine/NN stop/NN working/NN)
  ?/.) 


>> Noun Phrases are: 
 ['', 'many days machine stop working']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('In', 'in'), ('many', 'mani'), ('days', 'day'), ('machine', 'machin'), ('stop', 'stop'), ('working', 'work'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('In', 'in'), ('many', 'mani'), ('days', 'day'), ('machine', 'machin'), ('stop', 'stop'), ('working', 'work'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('In', 'In'), ('many', 'many'), ('days', 'day'), ('machine', 'machine'), ('stop', 'stop'), ('working', 'working'), ('?', '?')]



============================ Sentence 181 =============================

 What should be the price of a property based on size, number of rooms and location? 


>> Tokens are: 
 ['', 'What', 'price', 'property', 'based', 'size', ',', 'number', 'rooms', 'location', '?']

>> Bigrams are: 
 [('', 'What'), ('What', 'price'), ('price', 'property'), ('property', 'based'), ('based', 'size'), ('size', ','), (',', 'number'), ('number', 'rooms'), ('rooms', 'location'), ('location', '?')]

>> Trigrams are: 
 [('', 'What', 'price'), ('What', 'price', 'property'), ('price', 'property', 'based'), ('property', 'based', 'size'), ('based', 'size', ','), ('size', ',', 'number'), (',', 'number', 'rooms'), ('number', 'rooms', 'location'), ('rooms', 'location', '?')]

>> POS Tags are: 
 [('', 'VB'), ('What', 'WP'), ('price', 'NN'), ('property', 'NN'), ('based', 'VBN'), ('size', 'NN'), (',', ','), ('number', 'NN'), ('rooms', 'NNS'), ('location', 'NN'), ('?', '.')]

 (S
  /VB
  What/WP
  (NP price/NN property/NN)
  based/VBN
  (NP size/NN)
  ,/,
  (NP number/NN rooms/NNS location/NN)
  ?/.) 


>> Noun Phrases are: 
 ['price property', 'size', 'number rooms location']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('What', 'what'), ('price', 'price'), ('property', 'properti'), ('based', 'base'), ('size', 'size'), (',', ','), ('number', 'number'), ('rooms', 'room'), ('location', 'locat'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('What', 'what'), ('price', 'price'), ('property', 'properti'), ('based', 'base'), ('size', 'size'), (',', ','), ('number', 'number'), ('rooms', 'room'), ('location', 'locat'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('What', 'What'), ('price', 'price'), ('property', 'property'), ('based', 'based'), ('size', 'size'), (',', ','), ('number', 'number'), ('rooms', 'room'), ('location', 'location'), ('?', '?')]



============================ Sentence 182 =============================

 How many orders am I likely to receive in the next three months for my product? 


>> Tokens are: 
 ['', 'How', 'many', 'orders', 'I', 'likely', 'receive', 'next', 'three', 'months', 'product', '?']

>> Bigrams are: 
 [('', 'How'), ('How', 'many'), ('many', 'orders'), ('orders', 'I'), ('I', 'likely'), ('likely', 'receive'), ('receive', 'next'), ('next', 'three'), ('three', 'months'), ('months', 'product'), ('product', '?')]

>> Trigrams are: 
 [('', 'How', 'many'), ('How', 'many', 'orders'), ('many', 'orders', 'I'), ('orders', 'I', 'likely'), ('I', 'likely', 'receive'), ('likely', 'receive', 'next'), ('receive', 'next', 'three'), ('next', 'three', 'months'), ('three', 'months', 'product'), ('months', 'product', '?')]

>> POS Tags are: 
 [('', 'VB'), ('How', 'NNP'), ('many', 'JJ'), ('orders', 'NNS'), ('I', 'PRP'), ('likely', 'RB'), ('receive', 'VBP'), ('next', 'JJ'), ('three', 'CD'), ('months', 'NNS'), ('product', 'NN'), ('?', '.')]

 (S
  /VB
  (NP How/NNP)
  (NP many/JJ orders/NNS)
  I/PRP
  likely/RB
  receive/VBP
  next/JJ
  three/CD
  (NP months/NNS product/NN)
  ?/.) 


>> Noun Phrases are: 
 ['How', 'many orders', 'months product']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('How', 'how'), ('many', 'mani'), ('orders', 'order'), ('I', 'i'), ('likely', 'like'), ('receive', 'receiv'), ('next', 'next'), ('three', 'three'), ('months', 'month'), ('product', 'product'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('How', 'how'), ('many', 'mani'), ('orders', 'order'), ('I', 'i'), ('likely', 'like'), ('receive', 'receiv'), ('next', 'next'), ('three', 'three'), ('months', 'month'), ('product', 'product'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('How', 'How'), ('many', 'many'), ('orders', 'order'), ('I', 'I'), ('likely', 'likely'), ('receive', 'receive'), ('next', 'next'), ('three', 'three'), ('months', 'month'), ('product', 'product'), ('?', '?')]



============================ Sentence 183 =============================

12/14Demystifying data science   Unsupervised learning  There are multiple unsupervised learning approaches and techniques that can  be utilized to gain meaningful insights. 


>> Tokens are: 
 ['12/14Demystifying', 'data', 'science', 'Unsupervised', 'learning', 'There', 'multiple', 'unsupervised', 'learning', 'approaches', 'techniques', 'utilized', 'gain', 'meaningful', 'insights', '.']

>> Bigrams are: 
 [('12/14Demystifying', 'data'), ('data', 'science'), ('science', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', 'There'), ('There', 'multiple'), ('multiple', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'approaches'), ('approaches', 'techniques'), ('techniques', 'utilized'), ('utilized', 'gain'), ('gain', 'meaningful'), ('meaningful', 'insights'), ('insights', '.')]

>> Trigrams are: 
 [('12/14Demystifying', 'data', 'science'), ('data', 'science', 'Unsupervised'), ('science', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', 'There'), ('learning', 'There', 'multiple'), ('There', 'multiple', 'unsupervised'), ('multiple', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'approaches'), ('learning', 'approaches', 'techniques'), ('approaches', 'techniques', 'utilized'), ('techniques', 'utilized', 'gain'), ('utilized', 'gain', 'meaningful'), ('gain', 'meaningful', 'insights'), ('meaningful', 'insights', '.')]

>> POS Tags are: 
 [('12/14Demystifying', 'VBG'), ('data', 'NNS'), ('science', 'NN'), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('There', 'EX'), ('multiple', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('approaches', 'NNS'), ('techniques', 'NNS'), ('utilized', 'JJ'), ('gain', 'NN'), ('meaningful', 'JJ'), ('insights', 'NNS'), ('.', '.')]

 (S
  12/14Demystifying/VBG
  (NP data/NNS science/NN)
  Unsupervised/VBD
  learning/VBG
  There/EX
  (NP multiple/NNS)
  unsupervised/VBD
  learning/VBG
  (NP approaches/NNS techniques/NNS)
  (NP utilized/JJ gain/NN)
  (NP meaningful/JJ insights/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data science', 'multiple', 'approaches techniques', 'utilized gain', 'meaningful insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12/14Demystifying', '12/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('There', 'there'), ('multiple', 'multipl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approaches', 'approach'), ('techniques', 'techniqu'), ('utilized', 'util'), ('gain', 'gain'), ('meaningful', 'meaning'), ('insights', 'insight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12/14Demystifying', '12/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('There', 'there'), ('multiple', 'multipl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approaches', 'approach'), ('techniques', 'techniqu'), ('utilized', 'util'), ('gain', 'gain'), ('meaningful', 'meaning'), ('insights', 'insight'), ('.', '.')]

>> Lemmatization: 
 [('12/14Demystifying', '12/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('There', 'There'), ('multiple', 'multiple'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('approaches', 'approach'), ('techniques', 'technique'), ('utilized', 'utilized'), ('gain', 'gain'), ('meaningful', 'meaningful'), ('insights', 'insight'), ('.', '.')]



============================ Sentence 184 =============================

One of the more popular techniques is  clustering, which groups things that are similar or have features in common. 


>> Tokens are: 
 ['One', 'popular', 'techniques', 'clustering', ',', 'groups', 'things', 'similar', 'features', 'common', '.']

>> Bigrams are: 
 [('One', 'popular'), ('popular', 'techniques'), ('techniques', 'clustering'), ('clustering', ','), (',', 'groups'), ('groups', 'things'), ('things', 'similar'), ('similar', 'features'), ('features', 'common'), ('common', '.')]

>> Trigrams are: 
 [('One', 'popular', 'techniques'), ('popular', 'techniques', 'clustering'), ('techniques', 'clustering', ','), ('clustering', ',', 'groups'), (',', 'groups', 'things'), ('groups', 'things', 'similar'), ('things', 'similar', 'features'), ('similar', 'features', 'common'), ('features', 'common', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('popular', 'JJ'), ('techniques', 'NNS'), ('clustering', 'VBG'), (',', ','), ('groups', 'NNS'), ('things', 'NNS'), ('similar', 'JJ'), ('features', 'NNS'), ('common', 'JJ'), ('.', '.')]

 (S
  One/CD
  (NP popular/JJ techniques/NNS)
  clustering/VBG
  ,/,
  (NP groups/NNS things/NNS)
  (NP similar/JJ features/NNS)
  common/JJ
  ./.) 


>> Noun Phrases are: 
 ['popular techniques', 'groups things', 'similar features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('popular', 'popular'), ('techniques', 'techniqu'), ('clustering', 'cluster'), (',', ','), ('groups', 'group'), ('things', 'thing'), ('similar', 'similar'), ('features', 'featur'), ('common', 'common'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('popular', 'popular'), ('techniques', 'techniqu'), ('clustering', 'cluster'), (',', ','), ('groups', 'group'), ('things', 'thing'), ('similar', 'similar'), ('features', 'featur'), ('common', 'common'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('popular', 'popular'), ('techniques', 'technique'), ('clustering', 'clustering'), (',', ','), ('groups', 'group'), ('things', 'thing'), ('similar', 'similar'), ('features', 'feature'), ('common', 'common'), ('.', '.')]



============================ Sentence 185 =============================

Organizations use clustering techniques to answer business questions, such as:   How many distinct customer groups exist for my products? 


>> Tokens are: 
 ['Organizations', 'use', 'clustering', 'techniques', 'answer', 'business', 'questions', ',', ':', '', 'How', 'many', 'distinct', 'customer', 'groups', 'exist', 'products', '?']

>> Bigrams are: 
 [('Organizations', 'use'), ('use', 'clustering'), ('clustering', 'techniques'), ('techniques', 'answer'), ('answer', 'business'), ('business', 'questions'), ('questions', ','), (',', ':'), (':', ''), ('', 'How'), ('How', 'many'), ('many', 'distinct'), ('distinct', 'customer'), ('customer', 'groups'), ('groups', 'exist'), ('exist', 'products'), ('products', '?')]

>> Trigrams are: 
 [('Organizations', 'use', 'clustering'), ('use', 'clustering', 'techniques'), ('clustering', 'techniques', 'answer'), ('techniques', 'answer', 'business'), ('answer', 'business', 'questions'), ('business', 'questions', ','), ('questions', ',', ':'), (',', ':', ''), (':', '', 'How'), ('', 'How', 'many'), ('How', 'many', 'distinct'), ('many', 'distinct', 'customer'), ('distinct', 'customer', 'groups'), ('customer', 'groups', 'exist'), ('groups', 'exist', 'products'), ('exist', 'products', '?')]

>> POS Tags are: 
 [('Organizations', 'NNS'), ('use', 'VBP'), ('clustering', 'VBG'), ('techniques', 'NNS'), ('answer', 'VBP'), ('business', 'NN'), ('questions', 'NNS'), (',', ','), (':', ':'), ('', 'VB'), ('How', 'NNP'), ('many', 'JJ'), ('distinct', 'JJ'), ('customer', 'NN'), ('groups', 'NNS'), ('exist', 'VBP'), ('products', 'NNS'), ('?', '.')]

 (S
  (NP Organizations/NNS)
  use/VBP
  clustering/VBG
  (NP techniques/NNS)
  answer/VBP
  (NP business/NN questions/NNS)
  ,/,
  :/:
  /VB
  (NP How/NNP)
  (NP many/JJ distinct/JJ customer/NN groups/NNS)
  exist/VBP
  (NP products/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['Organizations', 'techniques', 'business questions', 'How', 'many distinct customer groups', 'products']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organizations', 'organ'), ('use', 'use'), ('clustering', 'cluster'), ('techniques', 'techniqu'), ('answer', 'answer'), ('business', 'busi'), ('questions', 'question'), (',', ','), (':', ':'), ('', ''), ('How', 'how'), ('many', 'mani'), ('distinct', 'distinct'), ('customer', 'custom'), ('groups', 'group'), ('exist', 'exist'), ('products', 'product'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Organizations', 'organ'), ('use', 'use'), ('clustering', 'cluster'), ('techniques', 'techniqu'), ('answer', 'answer'), ('business', 'busi'), ('questions', 'question'), (',', ','), (':', ':'), ('', ''), ('How', 'how'), ('many', 'mani'), ('distinct', 'distinct'), ('customer', 'custom'), ('groups', 'group'), ('exist', 'exist'), ('products', 'product'), ('?', '?')]

>> Lemmatization: 
 [('Organizations', 'Organizations'), ('use', 'use'), ('clustering', 'clustering'), ('techniques', 'technique'), ('answer', 'answer'), ('business', 'business'), ('questions', 'question'), (',', ','), (':', ':'), ('', ''), ('How', 'How'), ('many', 'many'), ('distinct', 'distinct'), ('customer', 'customer'), ('groups', 'group'), ('exist', 'exist'), ('products', 'product'), ('?', '?')]



============================ Sentence 186 =============================

Who belongs to   which group? 


>> Tokens are: 
 ['Who', 'belongs', 'group', '?']

>> Bigrams are: 
 [('Who', 'belongs'), ('belongs', 'group'), ('group', '?')]

>> Trigrams are: 
 [('Who', 'belongs', 'group'), ('belongs', 'group', '?')]

>> POS Tags are: 
 [('Who', 'WP'), ('belongs', 'VBZ'), ('group', 'NN'), ('?', '.')]

 (S Who/WP belongs/VBZ (NP group/NN) ?/.) 


>> Noun Phrases are: 
 ['group']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Who', 'who'), ('belongs', 'belong'), ('group', 'group'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Who', 'who'), ('belongs', 'belong'), ('group', 'group'), ('?', '?')]

>> Lemmatization: 
 [('Who', 'Who'), ('belongs', 'belongs'), ('group', 'group'), ('?', '?')]



============================ Sentence 187 =============================

 To which customer subgroups should I market my product and how should I target  them? 


>> Tokens are: 
 ['', 'To', 'customer', 'subgroups', 'I', 'market', 'product', 'I', 'target', '?']

>> Bigrams are: 
 [('', 'To'), ('To', 'customer'), ('customer', 'subgroups'), ('subgroups', 'I'), ('I', 'market'), ('market', 'product'), ('product', 'I'), ('I', 'target'), ('target', '?')]

>> Trigrams are: 
 [('', 'To', 'customer'), ('To', 'customer', 'subgroups'), ('customer', 'subgroups', 'I'), ('subgroups', 'I', 'market'), ('I', 'market', 'product'), ('market', 'product', 'I'), ('product', 'I', 'target'), ('I', 'target', '?')]

>> POS Tags are: 
 [('', 'NN'), ('To', 'TO'), ('customer', 'NN'), ('subgroups', 'NNS'), ('I', 'PRP'), ('market', 'NN'), ('product', 'NN'), ('I', 'PRP'), ('target', 'VBP'), ('?', '.')]

 (S
  (NP /NN)
  To/TO
  (NP customer/NN subgroups/NNS)
  I/PRP
  (NP market/NN product/NN)
  I/PRP
  target/VBP
  ?/.) 


>> Noun Phrases are: 
 ['', 'customer subgroups', 'market product']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('To', 'to'), ('customer', 'custom'), ('subgroups', 'subgroup'), ('I', 'i'), ('market', 'market'), ('product', 'product'), ('I', 'i'), ('target', 'target'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('To', 'to'), ('customer', 'custom'), ('subgroups', 'subgroup'), ('I', 'i'), ('market', 'market'), ('product', 'product'), ('I', 'i'), ('target', 'target'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('To', 'To'), ('customer', 'customer'), ('subgroups', 'subgroup'), ('I', 'I'), ('market', 'market'), ('product', 'product'), ('I', 'I'), ('target', 'target'), ('?', '?')]



============================ Sentence 188 =============================

What are the key characteristics of each group? 


>> Tokens are: 
 ['What', 'key', 'characteristics', 'group', '?']

>> Bigrams are: 
 [('What', 'key'), ('key', 'characteristics'), ('characteristics', 'group'), ('group', '?')]

>> Trigrams are: 
 [('What', 'key', 'characteristics'), ('key', 'characteristics', 'group'), ('characteristics', 'group', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('key', 'JJ'), ('characteristics', 'NNS'), ('group', 'NN'), ('?', '.')]

 (S What/WP (NP key/JJ characteristics/NNS group/NN) ?/.) 


>> Noun Phrases are: 
 ['key characteristics group']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('key', 'key'), ('characteristics', 'characterist'), ('group', 'group'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('key', 'key'), ('characteristics', 'characterist'), ('group', 'group'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('key', 'key'), ('characteristics', 'characteristic'), ('group', 'group'), ('?', '?')]



============================ Sentence 189 =============================

 How can I group my documents into distinct categories? 


>> Tokens are: 
 ['', 'How', 'I', 'group', 'documents', 'distinct', 'categories', '?']

>> Bigrams are: 
 [('', 'How'), ('How', 'I'), ('I', 'group'), ('group', 'documents'), ('documents', 'distinct'), ('distinct', 'categories'), ('categories', '?')]

>> Trigrams are: 
 [('', 'How', 'I'), ('How', 'I', 'group'), ('I', 'group', 'documents'), ('group', 'documents', 'distinct'), ('documents', 'distinct', 'categories'), ('distinct', 'categories', '?')]

>> POS Tags are: 
 [('', 'VB'), ('How', 'WRB'), ('I', 'PRP'), ('group', 'NN'), ('documents', 'NNS'), ('distinct', 'JJ'), ('categories', 'NNS'), ('?', '.')]

 (S
  /VB
  How/WRB
  I/PRP
  (NP group/NN documents/NNS)
  (NP distinct/JJ categories/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['group documents', 'distinct categories']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('How', 'how'), ('I', 'i'), ('group', 'group'), ('documents', 'document'), ('distinct', 'distinct'), ('categories', 'categori'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('How', 'how'), ('I', 'i'), ('group', 'group'), ('documents', 'document'), ('distinct', 'distinct'), ('categories', 'categori'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('How', 'How'), ('I', 'I'), ('group', 'group'), ('documents', 'document'), ('distinct', 'distinct'), ('categories', 'category'), ('?', '?')]



============================ Sentence 190 =============================

If a business is looking to answer questions around the identification of anomalies  or rare behavior and occurrences, anomaly detection techniques are utilized to  identify unusual patterns that do not conform to expected behavior, called outliers. 


>> Tokens are: 
 ['If', 'business', 'looking', 'answer', 'questions', 'around', 'identification', 'anomalies', 'rare', 'behavior', 'occurrences', ',', 'anomaly', 'detection', 'techniques', 'utilized', 'identify', 'unusual', 'patterns', 'conform', 'expected', 'behavior', ',', 'called', 'outliers', '.']

>> Bigrams are: 
 [('If', 'business'), ('business', 'looking'), ('looking', 'answer'), ('answer', 'questions'), ('questions', 'around'), ('around', 'identification'), ('identification', 'anomalies'), ('anomalies', 'rare'), ('rare', 'behavior'), ('behavior', 'occurrences'), ('occurrences', ','), (',', 'anomaly'), ('anomaly', 'detection'), ('detection', 'techniques'), ('techniques', 'utilized'), ('utilized', 'identify'), ('identify', 'unusual'), ('unusual', 'patterns'), ('patterns', 'conform'), ('conform', 'expected'), ('expected', 'behavior'), ('behavior', ','), (',', 'called'), ('called', 'outliers'), ('outliers', '.')]

>> Trigrams are: 
 [('If', 'business', 'looking'), ('business', 'looking', 'answer'), ('looking', 'answer', 'questions'), ('answer', 'questions', 'around'), ('questions', 'around', 'identification'), ('around', 'identification', 'anomalies'), ('identification', 'anomalies', 'rare'), ('anomalies', 'rare', 'behavior'), ('rare', 'behavior', 'occurrences'), ('behavior', 'occurrences', ','), ('occurrences', ',', 'anomaly'), (',', 'anomaly', 'detection'), ('anomaly', 'detection', 'techniques'), ('detection', 'techniques', 'utilized'), ('techniques', 'utilized', 'identify'), ('utilized', 'identify', 'unusual'), ('identify', 'unusual', 'patterns'), ('unusual', 'patterns', 'conform'), ('patterns', 'conform', 'expected'), ('conform', 'expected', 'behavior'), ('expected', 'behavior', ','), ('behavior', ',', 'called'), (',', 'called', 'outliers'), ('called', 'outliers', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('business', 'NN'), ('looking', 'VBG'), ('answer', 'JJR'), ('questions', 'NNS'), ('around', 'IN'), ('identification', 'NN'), ('anomalies', 'NNS'), ('rare', 'VBP'), ('behavior', 'JJ'), ('occurrences', 'NNS'), (',', ','), ('anomaly', 'JJ'), ('detection', 'NN'), ('techniques', 'NNS'), ('utilized', 'JJ'), ('identify', 'VBP'), ('unusual', 'JJ'), ('patterns', 'NNS'), ('conform', 'VB'), ('expected', 'VBN'), ('behavior', 'NN'), (',', ','), ('called', 'VBD'), ('outliers', 'NNS'), ('.', '.')]

 (S
  If/IN
  (NP business/NN)
  looking/VBG
  answer/JJR
  (NP questions/NNS)
  around/IN
  (NP identification/NN anomalies/NNS)
  rare/VBP
  (NP behavior/JJ occurrences/NNS)
  ,/,
  (NP anomaly/JJ detection/NN techniques/NNS)
  utilized/JJ
  identify/VBP
  (NP unusual/JJ patterns/NNS)
  conform/VB
  expected/VBN
  (NP behavior/NN)
  ,/,
  called/VBD
  (NP outliers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['business', 'questions', 'identification anomalies', 'behavior occurrences', 'anomaly detection techniques', 'unusual patterns', 'behavior', 'outliers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('business', 'busi'), ('looking', 'look'), ('answer', 'answer'), ('questions', 'question'), ('around', 'around'), ('identification', 'identif'), ('anomalies', 'anomali'), ('rare', 'rare'), ('behavior', 'behavior'), ('occurrences', 'occurr'), (',', ','), ('anomaly', 'anomali'), ('detection', 'detect'), ('techniques', 'techniqu'), ('utilized', 'util'), ('identify', 'identifi'), ('unusual', 'unusu'), ('patterns', 'pattern'), ('conform', 'conform'), ('expected', 'expect'), ('behavior', 'behavior'), (',', ','), ('called', 'call'), ('outliers', 'outlier'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('business', 'busi'), ('looking', 'look'), ('answer', 'answer'), ('questions', 'question'), ('around', 'around'), ('identification', 'identif'), ('anomalies', 'anomali'), ('rare', 'rare'), ('behavior', 'behavior'), ('occurrences', 'occurr'), (',', ','), ('anomaly', 'anomali'), ('detection', 'detect'), ('techniques', 'techniqu'), ('utilized', 'util'), ('identify', 'identifi'), ('unusual', 'unusu'), ('patterns', 'pattern'), ('conform', 'conform'), ('expected', 'expect'), ('behavior', 'behavior'), (',', ','), ('called', 'call'), ('outliers', 'outlier'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('business', 'business'), ('looking', 'looking'), ('answer', 'answer'), ('questions', 'question'), ('around', 'around'), ('identification', 'identification'), ('anomalies', 'anomaly'), ('rare', 'rare'), ('behavior', 'behavior'), ('occurrences', 'occurrence'), (',', ','), ('anomaly', 'anomaly'), ('detection', 'detection'), ('techniques', 'technique'), ('utilized', 'utilized'), ('identify', 'identify'), ('unusual', 'unusual'), ('patterns', 'pattern'), ('conform', 'conform'), ('expected', 'expected'), ('behavior', 'behavior'), (',', ','), ('called', 'called'), ('outliers', 'outlier'), ('.', '.')]



============================ Sentence 191 =============================

It has many applications in business, from intrusion detection, such as identifying  strange patterns in network traffic, to system health monitoring, including spotting  a malignant tumor in an MRI scan. 


>> Tokens are: 
 ['It', 'many', 'applications', 'business', ',', 'intrusion', 'detection', ',', 'identifying', 'strange', 'patterns', 'network', 'traffic', ',', 'system', 'health', 'monitoring', ',', 'including', 'spotting', 'malignant', 'tumor', 'MRI', 'scan', '.']

>> Bigrams are: 
 [('It', 'many'), ('many', 'applications'), ('applications', 'business'), ('business', ','), (',', 'intrusion'), ('intrusion', 'detection'), ('detection', ','), (',', 'identifying'), ('identifying', 'strange'), ('strange', 'patterns'), ('patterns', 'network'), ('network', 'traffic'), ('traffic', ','), (',', 'system'), ('system', 'health'), ('health', 'monitoring'), ('monitoring', ','), (',', 'including'), ('including', 'spotting'), ('spotting', 'malignant'), ('malignant', 'tumor'), ('tumor', 'MRI'), ('MRI', 'scan'), ('scan', '.')]

>> Trigrams are: 
 [('It', 'many', 'applications'), ('many', 'applications', 'business'), ('applications', 'business', ','), ('business', ',', 'intrusion'), (',', 'intrusion', 'detection'), ('intrusion', 'detection', ','), ('detection', ',', 'identifying'), (',', 'identifying', 'strange'), ('identifying', 'strange', 'patterns'), ('strange', 'patterns', 'network'), ('patterns', 'network', 'traffic'), ('network', 'traffic', ','), ('traffic', ',', 'system'), (',', 'system', 'health'), ('system', 'health', 'monitoring'), ('health', 'monitoring', ','), ('monitoring', ',', 'including'), (',', 'including', 'spotting'), ('including', 'spotting', 'malignant'), ('spotting', 'malignant', 'tumor'), ('malignant', 'tumor', 'MRI'), ('tumor', 'MRI', 'scan'), ('MRI', 'scan', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('many', 'JJ'), ('applications', 'NNS'), ('business', 'NN'), (',', ','), ('intrusion', 'NN'), ('detection', 'NN'), (',', ','), ('identifying', 'VBG'), ('strange', 'NN'), ('patterns', 'NNS'), ('network', 'NN'), ('traffic', 'NN'), (',', ','), ('system', 'NN'), ('health', 'NN'), ('monitoring', 'NN'), (',', ','), ('including', 'VBG'), ('spotting', 'VBG'), ('malignant', 'JJ'), ('tumor', 'NN'), ('MRI', 'NNP'), ('scan', 'NN'), ('.', '.')]

 (S
  It/PRP
  (NP many/JJ applications/NNS business/NN)
  ,/,
  (NP intrusion/NN detection/NN)
  ,/,
  identifying/VBG
  (NP strange/NN patterns/NNS network/NN traffic/NN)
  ,/,
  (NP system/NN health/NN monitoring/NN)
  ,/,
  including/VBG
  spotting/VBG
  (NP malignant/JJ tumor/NN MRI/NNP scan/NN)
  ./.) 


>> Noun Phrases are: 
 ['many applications business', 'intrusion detection', 'strange patterns network traffic', 'system health monitoring', 'malignant tumor MRI scan']

>> Named Entities are: 
 [('ORGANIZATION', 'MRI')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('many', 'mani'), ('applications', 'applic'), ('business', 'busi'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), (',', ','), ('identifying', 'identifi'), ('strange', 'strang'), ('patterns', 'pattern'), ('network', 'network'), ('traffic', 'traffic'), (',', ','), ('system', 'system'), ('health', 'health'), ('monitoring', 'monitor'), (',', ','), ('including', 'includ'), ('spotting', 'spot'), ('malignant', 'malign'), ('tumor', 'tumor'), ('MRI', 'mri'), ('scan', 'scan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('many', 'mani'), ('applications', 'applic'), ('business', 'busi'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), (',', ','), ('identifying', 'identifi'), ('strange', 'strang'), ('patterns', 'pattern'), ('network', 'network'), ('traffic', 'traffic'), (',', ','), ('system', 'system'), ('health', 'health'), ('monitoring', 'monitor'), (',', ','), ('including', 'includ'), ('spotting', 'spot'), ('malignant', 'malign'), ('tumor', 'tumor'), ('MRI', 'mri'), ('scan', 'scan'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('many', 'many'), ('applications', 'application'), ('business', 'business'), (',', ','), ('intrusion', 'intrusion'), ('detection', 'detection'), (',', ','), ('identifying', 'identifying'), ('strange', 'strange'), ('patterns', 'pattern'), ('network', 'network'), ('traffic', 'traffic'), (',', ','), ('system', 'system'), ('health', 'health'), ('monitoring', 'monitoring'), (',', ','), ('including', 'including'), ('spotting', 'spotting'), ('malignant', 'malignant'), ('tumor', 'tumor'), ('MRI', 'MRI'), ('scan', 'scan'), ('.', '.')]



============================ Sentence 192 =============================

Some additional questions that can be answered  using these techniques include:    Given a massive database of financial data, which transactions are suspicious  and likely to be fraudulent? 


>> Tokens are: 
 ['Some', 'additional', 'questions', 'answered', 'using', 'techniques', 'include', ':', '', 'Given', 'massive', 'database', 'financial', 'data', ',', 'transactions', 'suspicious', 'likely', 'fraudulent', '?']

>> Bigrams are: 
 [('Some', 'additional'), ('additional', 'questions'), ('questions', 'answered'), ('answered', 'using'), ('using', 'techniques'), ('techniques', 'include'), ('include', ':'), (':', ''), ('', 'Given'), ('Given', 'massive'), ('massive', 'database'), ('database', 'financial'), ('financial', 'data'), ('data', ','), (',', 'transactions'), ('transactions', 'suspicious'), ('suspicious', 'likely'), ('likely', 'fraudulent'), ('fraudulent', '?')]

>> Trigrams are: 
 [('Some', 'additional', 'questions'), ('additional', 'questions', 'answered'), ('questions', 'answered', 'using'), ('answered', 'using', 'techniques'), ('using', 'techniques', 'include'), ('techniques', 'include', ':'), ('include', ':', ''), (':', '', 'Given'), ('', 'Given', 'massive'), ('Given', 'massive', 'database'), ('massive', 'database', 'financial'), ('database', 'financial', 'data'), ('financial', 'data', ','), ('data', ',', 'transactions'), (',', 'transactions', 'suspicious'), ('transactions', 'suspicious', 'likely'), ('suspicious', 'likely', 'fraudulent'), ('likely', 'fraudulent', '?')]

>> POS Tags are: 
 [('Some', 'DT'), ('additional', 'JJ'), ('questions', 'NNS'), ('answered', 'VBD'), ('using', 'VBG'), ('techniques', 'NNS'), ('include', 'VBP'), (':', ':'), ('', 'VB'), ('Given', 'NNP'), ('massive', 'JJ'), ('database', 'NN'), ('financial', 'JJ'), ('data', 'NNS'), (',', ','), ('transactions', 'NNS'), ('suspicious', 'VBP'), ('likely', 'JJ'), ('fraudulent', 'NN'), ('?', '.')]

 (S
  (NP Some/DT additional/JJ questions/NNS)
  answered/VBD
  using/VBG
  (NP techniques/NNS)
  include/VBP
  :/:
  /VB
  (NP Given/NNP)
  (NP massive/JJ database/NN)
  (NP financial/JJ data/NNS)
  ,/,
  (NP transactions/NNS)
  suspicious/VBP
  (NP likely/JJ fraudulent/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Some additional questions', 'techniques', 'Given', 'massive database', 'financial data', 'transactions', 'likely fraudulent']

>> Named Entities are: 
 [('PERSON', 'Given')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('additional', 'addit'), ('questions', 'question'), ('answered', 'answer'), ('using', 'use'), ('techniques', 'techniqu'), ('include', 'includ'), (':', ':'), ('', ''), ('Given', 'given'), ('massive', 'massiv'), ('database', 'databas'), ('financial', 'financi'), ('data', 'data'), (',', ','), ('transactions', 'transact'), ('suspicious', 'suspici'), ('likely', 'like'), ('fraudulent', 'fraudul'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('additional', 'addit'), ('questions', 'question'), ('answered', 'answer'), ('using', 'use'), ('techniques', 'techniqu'), ('include', 'includ'), (':', ':'), ('', ''), ('Given', 'given'), ('massive', 'massiv'), ('database', 'databas'), ('financial', 'financi'), ('data', 'data'), (',', ','), ('transactions', 'transact'), ('suspicious', 'suspici'), ('likely', 'like'), ('fraudulent', 'fraudul'), ('?', '?')]

>> Lemmatization: 
 [('Some', 'Some'), ('additional', 'additional'), ('questions', 'question'), ('answered', 'answered'), ('using', 'using'), ('techniques', 'technique'), ('include', 'include'), (':', ':'), ('', ''), ('Given', 'Given'), ('massive', 'massive'), ('database', 'database'), ('financial', 'financial'), ('data', 'data'), (',', ','), ('transactions', 'transaction'), ('suspicious', 'suspicious'), ('likely', 'likely'), ('fraudulent', 'fraudulent'), ('?', '?')]



============================ Sentence 193 =============================

 Given the huge number of container shipments arriving at a countrys ports every  day, which should be opened by customs to prevent smuggling, terrorism, etc.? 


>> Tokens are: 
 ['', 'Given', 'huge', 'number', 'container', 'shipments', 'arriving', 'country', '', 'ports', 'every', 'day', ',', 'opened', 'customs', 'prevent', 'smuggling', ',', 'terrorism', ',', 'etc', '.', '?']

>> Bigrams are: 
 [('', 'Given'), ('Given', 'huge'), ('huge', 'number'), ('number', 'container'), ('container', 'shipments'), ('shipments', 'arriving'), ('arriving', 'country'), ('country', ''), ('', 'ports'), ('ports', 'every'), ('every', 'day'), ('day', ','), (',', 'opened'), ('opened', 'customs'), ('customs', 'prevent'), ('prevent', 'smuggling'), ('smuggling', ','), (',', 'terrorism'), ('terrorism', ','), (',', 'etc'), ('etc', '.'), ('.', '?')]

>> Trigrams are: 
 [('', 'Given', 'huge'), ('Given', 'huge', 'number'), ('huge', 'number', 'container'), ('number', 'container', 'shipments'), ('container', 'shipments', 'arriving'), ('shipments', 'arriving', 'country'), ('arriving', 'country', ''), ('country', '', 'ports'), ('', 'ports', 'every'), ('ports', 'every', 'day'), ('every', 'day', ','), ('day', ',', 'opened'), (',', 'opened', 'customs'), ('opened', 'customs', 'prevent'), ('customs', 'prevent', 'smuggling'), ('prevent', 'smuggling', ','), ('smuggling', ',', 'terrorism'), (',', 'terrorism', ','), ('terrorism', ',', 'etc'), (',', 'etc', '.'), ('etc', '.', '?')]

>> POS Tags are: 
 [('', 'VB'), ('Given', 'NNP'), ('huge', 'JJ'), ('number', 'NN'), ('container', 'NN'), ('shipments', 'NNS'), ('arriving', 'VBG'), ('country', 'NN'), ('', 'VBD'), ('ports', 'NNS'), ('every', 'DT'), ('day', 'NN'), (',', ','), ('opened', 'VBD'), ('customs', 'NNS'), ('prevent', 'JJ'), ('smuggling', 'NN'), (',', ','), ('terrorism', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.'), ('?', '.')]

 (S
  /VB
  (NP Given/NNP)
  (NP huge/JJ number/NN container/NN shipments/NNS)
  arriving/VBG
  (NP country/NN)
  /VBD
  (NP ports/NNS)
  (NP every/DT day/NN)
  ,/,
  opened/VBD
  (NP customs/NNS)
  (NP prevent/JJ smuggling/NN)
  ,/,
  (NP terrorism/NN)
  ,/,
  etc/FW
  ./.
  ?/.) 


>> Noun Phrases are: 
 ['Given', 'huge number container shipments', 'country', 'ports', 'every day', 'customs', 'prevent smuggling', 'terrorism']

>> Named Entities are: 
 [('PERSON', 'Given')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Given', 'given'), ('huge', 'huge'), ('number', 'number'), ('container', 'contain'), ('shipments', 'shipment'), ('arriving', 'arriv'), ('country', 'countri'), ('', ''), ('ports', 'port'), ('every', 'everi'), ('day', 'day'), (',', ','), ('opened', 'open'), ('customs', 'custom'), ('prevent', 'prevent'), ('smuggling', 'smuggl'), (',', ','), ('terrorism', 'terror'), (',', ','), ('etc', 'etc'), ('.', '.'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Given', 'given'), ('huge', 'huge'), ('number', 'number'), ('container', 'contain'), ('shipments', 'shipment'), ('arriving', 'arriv'), ('country', 'countri'), ('', ''), ('ports', 'port'), ('every', 'everi'), ('day', 'day'), (',', ','), ('opened', 'open'), ('customs', 'custom'), ('prevent', 'prevent'), ('smuggling', 'smuggl'), (',', ','), ('terrorism', 'terror'), (',', ','), ('etc', 'etc'), ('.', '.'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Given', 'Given'), ('huge', 'huge'), ('number', 'number'), ('container', 'container'), ('shipments', 'shipment'), ('arriving', 'arriving'), ('country', 'country'), ('', ''), ('ports', 'port'), ('every', 'every'), ('day', 'day'), (',', ','), ('opened', 'opened'), ('customs', 'custom'), ('prevent', 'prevent'), ('smuggling', 'smuggling'), (',', ','), ('terrorism', 'terrorism'), (',', ','), ('etc', 'etc'), ('.', '.'), ('?', '?')]



============================ Sentence 194 =============================

  Given a log of all the traffic on a computer network, which sessions represent  attempted intrusions? 


>> Tokens are: 
 ['', 'Given', 'log', 'traffic', 'computer', 'network', ',', 'sessions', 'represent', 'attempted', 'intrusions', '?']

>> Bigrams are: 
 [('', 'Given'), ('Given', 'log'), ('log', 'traffic'), ('traffic', 'computer'), ('computer', 'network'), ('network', ','), (',', 'sessions'), ('sessions', 'represent'), ('represent', 'attempted'), ('attempted', 'intrusions'), ('intrusions', '?')]

>> Trigrams are: 
 [('', 'Given', 'log'), ('Given', 'log', 'traffic'), ('log', 'traffic', 'computer'), ('traffic', 'computer', 'network'), ('computer', 'network', ','), ('network', ',', 'sessions'), (',', 'sessions', 'represent'), ('sessions', 'represent', 'attempted'), ('represent', 'attempted', 'intrusions'), ('attempted', 'intrusions', '?')]

>> POS Tags are: 
 [('', 'VB'), ('Given', 'NNP'), ('log', 'NN'), ('traffic', 'NN'), ('computer', 'NN'), ('network', 'NN'), (',', ','), ('sessions', 'NNS'), ('represent', 'VBP'), ('attempted', 'VBN'), ('intrusions', 'NNS'), ('?', '.')]

 (S
  /VB
  (NP Given/NNP log/NN traffic/NN computer/NN network/NN)
  ,/,
  (NP sessions/NNS)
  represent/VBP
  attempted/VBN
  (NP intrusions/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['Given log traffic computer network', 'sessions', 'intrusions']

>> Named Entities are: 
 [('PERSON', 'Given')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Given', 'given'), ('log', 'log'), ('traffic', 'traffic'), ('computer', 'comput'), ('network', 'network'), (',', ','), ('sessions', 'session'), ('represent', 'repres'), ('attempted', 'attempt'), ('intrusions', 'intrus'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Given', 'given'), ('log', 'log'), ('traffic', 'traffic'), ('computer', 'comput'), ('network', 'network'), (',', ','), ('sessions', 'session'), ('represent', 'repres'), ('attempted', 'attempt'), ('intrusions', 'intrus'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Given', 'Given'), ('log', 'log'), ('traffic', 'traffic'), ('computer', 'computer'), ('network', 'network'), (',', ','), ('sessions', 'session'), ('represent', 'represent'), ('attempted', 'attempted'), ('intrusions', 'intrusion'), ('?', '?')]



============================ Sentence 195 =============================

Association mining, another set of techniques, can help find correlations  between different products or factors in an organizations data. 


>> Tokens are: 
 ['Association', 'mining', ',', 'another', 'set', 'techniques', ',', 'help', 'find', 'correlations', 'different', 'products', 'factors', 'organization', '', 'data', '.']

>> Bigrams are: 
 [('Association', 'mining'), ('mining', ','), (',', 'another'), ('another', 'set'), ('set', 'techniques'), ('techniques', ','), (',', 'help'), ('help', 'find'), ('find', 'correlations'), ('correlations', 'different'), ('different', 'products'), ('products', 'factors'), ('factors', 'organization'), ('organization', ''), ('', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Association', 'mining', ','), ('mining', ',', 'another'), (',', 'another', 'set'), ('another', 'set', 'techniques'), ('set', 'techniques', ','), ('techniques', ',', 'help'), (',', 'help', 'find'), ('help', 'find', 'correlations'), ('find', 'correlations', 'different'), ('correlations', 'different', 'products'), ('different', 'products', 'factors'), ('products', 'factors', 'organization'), ('factors', 'organization', ''), ('organization', '', 'data'), ('', 'data', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('mining', 'NN'), (',', ','), ('another', 'DT'), ('set', 'NN'), ('techniques', 'NNS'), (',', ','), ('help', 'NN'), ('find', 'VB'), ('correlations', 'NNS'), ('different', 'JJ'), ('products', 'NNS'), ('factors', 'NNS'), ('organization', 'NN'), ('', 'NNP'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Association/NNP mining/NN)
  ,/,
  (NP another/DT set/NN techniques/NNS)
  ,/,
  (NP help/NN)
  find/VB
  (NP correlations/NNS)
  (NP
    different/JJ
    products/NNS
    factors/NNS
    organization/NN
    /NNP
    data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Association mining', 'another set techniques', 'help', 'correlations', 'different products factors organization  data']

>> Named Entities are: 
 [('GPE', 'Association')] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('mining', 'mine'), (',', ','), ('another', 'anoth'), ('set', 'set'), ('techniques', 'techniqu'), (',', ','), ('help', 'help'), ('find', 'find'), ('correlations', 'correl'), ('different', 'differ'), ('products', 'product'), ('factors', 'factor'), ('organization', 'organ'), ('', ''), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('mining', 'mine'), (',', ','), ('another', 'anoth'), ('set', 'set'), ('techniques', 'techniqu'), (',', ','), ('help', 'help'), ('find', 'find'), ('correlations', 'correl'), ('different', 'differ'), ('products', 'product'), ('factors', 'factor'), ('organization', 'organ'), ('', ''), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('mining', 'mining'), (',', ','), ('another', 'another'), ('set', 'set'), ('techniques', 'technique'), (',', ','), ('help', 'help'), ('find', 'find'), ('correlations', 'correlation'), ('different', 'different'), ('products', 'product'), ('factors', 'factor'), ('organization', 'organization'), ('', ''), ('data', 'data'), ('.', '.')]



============================ Sentence 196 =============================

For example, if a  customer purchases baby diapers, he or she has a 60 percent chance of purchasing  baby lotion within the next month. 


>> Tokens are: 
 ['For', 'example', ',', 'customer', 'purchases', 'baby', 'diapers', ',', '60', 'percent', 'chance', 'purchasing', 'baby', 'lotion', 'within', 'next', 'month', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'customer'), ('customer', 'purchases'), ('purchases', 'baby'), ('baby', 'diapers'), ('diapers', ','), (',', '60'), ('60', 'percent'), ('percent', 'chance'), ('chance', 'purchasing'), ('purchasing', 'baby'), ('baby', 'lotion'), ('lotion', 'within'), ('within', 'next'), ('next', 'month'), ('month', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'customer'), (',', 'customer', 'purchases'), ('customer', 'purchases', 'baby'), ('purchases', 'baby', 'diapers'), ('baby', 'diapers', ','), ('diapers', ',', '60'), (',', '60', 'percent'), ('60', 'percent', 'chance'), ('percent', 'chance', 'purchasing'), ('chance', 'purchasing', 'baby'), ('purchasing', 'baby', 'lotion'), ('baby', 'lotion', 'within'), ('lotion', 'within', 'next'), ('within', 'next', 'month'), ('next', 'month', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('customer', 'NN'), ('purchases', 'NNS'), ('baby', 'NN'), ('diapers', 'NNS'), (',', ','), ('60', 'CD'), ('percent', 'NN'), ('chance', 'NN'), ('purchasing', 'VBG'), ('baby', 'JJ'), ('lotion', 'NN'), ('within', 'IN'), ('next', 'JJ'), ('month', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP customer/NN purchases/NNS baby/NN diapers/NNS)
  ,/,
  60/CD
  (NP percent/NN chance/NN)
  purchasing/VBG
  (NP baby/JJ lotion/NN)
  within/IN
  (NP next/JJ month/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'customer purchases baby diapers', 'percent chance', 'baby lotion', 'next month']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customer', 'custom'), ('purchases', 'purchas'), ('baby', 'babi'), ('diapers', 'diaper'), (',', ','), ('60', '60'), ('percent', 'percent'), ('chance', 'chanc'), ('purchasing', 'purchas'), ('baby', 'babi'), ('lotion', 'lotion'), ('within', 'within'), ('next', 'next'), ('month', 'month'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('customer', 'custom'), ('purchases', 'purchas'), ('baby', 'babi'), ('diapers', 'diaper'), (',', ','), ('60', '60'), ('percent', 'percent'), ('chance', 'chanc'), ('purchasing', 'purchas'), ('baby', 'babi'), ('lotion', 'lotion'), ('within', 'within'), ('next', 'next'), ('month', 'month'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('customer', 'customer'), ('purchases', 'purchase'), ('baby', 'baby'), ('diapers', 'diaper'), (',', ','), ('60', '60'), ('percent', 'percent'), ('chance', 'chance'), ('purchasing', 'purchasing'), ('baby', 'baby'), ('lotion', 'lotion'), ('within', 'within'), ('next', 'next'), ('month', 'month'), ('.', '.')]



============================ Sentence 197 =============================

By identifying such insights using association  mining, retailers can predict the need for new products and target customers with  coupons and offers before the customer even realizes they are running out of baby  lotion. 


>> Tokens are: 
 ['By', 'identifying', 'insights', 'using', 'association', 'mining', ',', 'retailers', 'predict', 'need', 'new', 'products', 'target', 'customers', 'coupons', 'offers', 'customer', 'even', 'realizes', 'running', 'baby', 'lotion', '.']

>> Bigrams are: 
 [('By', 'identifying'), ('identifying', 'insights'), ('insights', 'using'), ('using', 'association'), ('association', 'mining'), ('mining', ','), (',', 'retailers'), ('retailers', 'predict'), ('predict', 'need'), ('need', 'new'), ('new', 'products'), ('products', 'target'), ('target', 'customers'), ('customers', 'coupons'), ('coupons', 'offers'), ('offers', 'customer'), ('customer', 'even'), ('even', 'realizes'), ('realizes', 'running'), ('running', 'baby'), ('baby', 'lotion'), ('lotion', '.')]

>> Trigrams are: 
 [('By', 'identifying', 'insights'), ('identifying', 'insights', 'using'), ('insights', 'using', 'association'), ('using', 'association', 'mining'), ('association', 'mining', ','), ('mining', ',', 'retailers'), (',', 'retailers', 'predict'), ('retailers', 'predict', 'need'), ('predict', 'need', 'new'), ('need', 'new', 'products'), ('new', 'products', 'target'), ('products', 'target', 'customers'), ('target', 'customers', 'coupons'), ('customers', 'coupons', 'offers'), ('coupons', 'offers', 'customer'), ('offers', 'customer', 'even'), ('customer', 'even', 'realizes'), ('even', 'realizes', 'running'), ('realizes', 'running', 'baby'), ('running', 'baby', 'lotion'), ('baby', 'lotion', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('identifying', 'VBG'), ('insights', 'NNS'), ('using', 'VBG'), ('association', 'NN'), ('mining', 'NN'), (',', ','), ('retailers', 'NNS'), ('predict', 'VBP'), ('need', 'VBP'), ('new', 'JJ'), ('products', 'NNS'), ('target', 'NN'), ('customers', 'NNS'), ('coupons', 'NNS'), ('offers', 'NNS'), ('customer', 'NN'), ('even', 'RB'), ('realizes', 'VBZ'), ('running', 'VBG'), ('baby', 'JJ'), ('lotion', 'NN'), ('.', '.')]

 (S
  By/IN
  identifying/VBG
  (NP insights/NNS)
  using/VBG
  (NP association/NN mining/NN)
  ,/,
  (NP retailers/NNS)
  predict/VBP
  need/VBP
  (NP
    new/JJ
    products/NNS
    target/NN
    customers/NNS
    coupons/NNS
    offers/NNS
    customer/NN)
  even/RB
  realizes/VBZ
  running/VBG
  (NP baby/JJ lotion/NN)
  ./.) 


>> Noun Phrases are: 
 ['insights', 'association mining', 'retailers', 'new products target customers coupons offers customer', 'baby lotion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('identifying', 'identifi'), ('insights', 'insight'), ('using', 'use'), ('association', 'associ'), ('mining', 'mine'), (',', ','), ('retailers', 'retail'), ('predict', 'predict'), ('need', 'need'), ('new', 'new'), ('products', 'product'), ('target', 'target'), ('customers', 'custom'), ('coupons', 'coupon'), ('offers', 'offer'), ('customer', 'custom'), ('even', 'even'), ('realizes', 'realiz'), ('running', 'run'), ('baby', 'babi'), ('lotion', 'lotion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('identifying', 'identifi'), ('insights', 'insight'), ('using', 'use'), ('association', 'associ'), ('mining', 'mine'), (',', ','), ('retailers', 'retail'), ('predict', 'predict'), ('need', 'need'), ('new', 'new'), ('products', 'product'), ('target', 'target'), ('customers', 'custom'), ('coupons', 'coupon'), ('offers', 'offer'), ('customer', 'custom'), ('even', 'even'), ('realizes', 'realiz'), ('running', 'run'), ('baby', 'babi'), ('lotion', 'lotion'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('identifying', 'identifying'), ('insights', 'insight'), ('using', 'using'), ('association', 'association'), ('mining', 'mining'), (',', ','), ('retailers', 'retailer'), ('predict', 'predict'), ('need', 'need'), ('new', 'new'), ('products', 'product'), ('target', 'target'), ('customers', 'customer'), ('coupons', 'coupon'), ('offers', 'offer'), ('customer', 'customer'), ('even', 'even'), ('realizes', 'realizes'), ('running', 'running'), ('baby', 'baby'), ('lotion', 'lotion'), ('.', '.')]



============================ Sentence 198 =============================

The most common application of association mining algorithms is in market  basket analysis. 


>> Tokens are: 
 ['The', 'common', 'application', 'association', 'mining', 'algorithms', 'market', 'basket', 'analysis', '.']

>> Bigrams are: 
 [('The', 'common'), ('common', 'application'), ('application', 'association'), ('association', 'mining'), ('mining', 'algorithms'), ('algorithms', 'market'), ('market', 'basket'), ('basket', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('The', 'common', 'application'), ('common', 'application', 'association'), ('application', 'association', 'mining'), ('association', 'mining', 'algorithms'), ('mining', 'algorithms', 'market'), ('algorithms', 'market', 'basket'), ('market', 'basket', 'analysis'), ('basket', 'analysis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('common', 'JJ'), ('application', 'NN'), ('association', 'NN'), ('mining', 'VBG'), ('algorithms', 'JJ'), ('market', 'NN'), ('basket', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP The/DT common/JJ application/NN association/NN)
  mining/VBG
  (NP algorithms/JJ market/NN basket/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['The common application association', 'algorithms market basket analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('common', 'common'), ('application', 'applic'), ('association', 'associ'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('market', 'market'), ('basket', 'basket'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('common', 'common'), ('application', 'applic'), ('association', 'associ'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('market', 'market'), ('basket', 'basket'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('common', 'common'), ('application', 'application'), ('association', 'association'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('market', 'market'), ('basket', 'basket'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 199 =============================

Unsupervised learning  Clustering Anomaly detection Association mining  Partition	the	data	 set	into	X	groups	 so	that	records		in	 the	same	group	 are	similar	to	each	 other,	and		records	 in	different	groups	 are	dissimilar  Identification	 of	rare	items,	 events	or	 observations	which	 raise	suspicion	 by	differing	 significantly	from	 	the	majority	of	the	 data  Find	frequent	 patterns,	 correlations	and	 	associations	 among	a	set	of	 items	in	relational	 	and	transaction	 databases  U ns  up er  vi se  d  le  ar ni  ng  Clustering  Anomaly detection  Association mining  Partition the data set into X groups so that records  in the same group are similar to each other, and  records in different groups are dissimilar  Identification of rare items, events or observations which raise suspicion by differing significantly from  the majority of the data  Find frequent patterns, correlations and  associations among a set of items in relational  and transaction databases    13/14Demystifying data science   Natural language processing (NLP)  Natural language processing is a set of systematic processes for intelligently  and efficiently analyzing, understanding and deriving information from text data. 


>> Tokens are: 
 ['Unsupervised', 'learning', 'Clustering', 'Anomaly', 'detection', 'Association', 'mining', 'Partition', 'data', 'set', 'X', 'groups', 'records', 'group', 'similar', ',', 'records', 'different', 'groups', 'dissimilar', 'Identification', 'rare', 'items', ',', 'events', 'observations', 'raise', 'suspicion', 'differing', 'significantly', 'majority', 'data', 'Find', 'frequent', 'patterns', ',', 'correlations', 'associations', 'among', 'set', 'items', 'relational', 'transaction', 'databases', 'U', 'ns', 'er', 'vi', 'se', 'le', 'ar', 'ni', 'ng', 'Clustering', 'Anomaly', 'detection', 'Association', 'mining', 'Partition', 'data', 'set', 'X', 'groups', 'records', 'group', 'similar', ',', 'records', 'different', 'groups', 'dissimilar', 'Identification', 'rare', 'items', ',', 'events', 'observations', 'raise', 'suspicion', 'differing', 'significantly', 'majority', 'data', 'Find', 'frequent', 'patterns', ',', 'correlations', 'associations', 'among', 'set', 'items', 'relational', 'transaction', 'databases', '13/14Demystifying', 'data', 'science', 'Natural', 'language', 'processing', '(', 'NLP', ')', 'Natural', 'language', 'processing', 'set', 'systematic', 'processes', 'intelligently', 'efficiently', 'analyzing', ',', 'understanding', 'deriving', 'information', 'text', 'data', '.']

>> Bigrams are: 
 [('Unsupervised', 'learning'), ('learning', 'Clustering'), ('Clustering', 'Anomaly'), ('Anomaly', 'detection'), ('detection', 'Association'), ('Association', 'mining'), ('mining', 'Partition'), ('Partition', 'data'), ('data', 'set'), ('set', 'X'), ('X', 'groups'), ('groups', 'records'), ('records', 'group'), ('group', 'similar'), ('similar', ','), (',', 'records'), ('records', 'different'), ('different', 'groups'), ('groups', 'dissimilar'), ('dissimilar', 'Identification'), ('Identification', 'rare'), ('rare', 'items'), ('items', ','), (',', 'events'), ('events', 'observations'), ('observations', 'raise'), ('raise', 'suspicion'), ('suspicion', 'differing'), ('differing', 'significantly'), ('significantly', 'majority'), ('majority', 'data'), ('data', 'Find'), ('Find', 'frequent'), ('frequent', 'patterns'), ('patterns', ','), (',', 'correlations'), ('correlations', 'associations'), ('associations', 'among'), ('among', 'set'), ('set', 'items'), ('items', 'relational'), ('relational', 'transaction'), ('transaction', 'databases'), ('databases', 'U'), ('U', 'ns'), ('ns', 'er'), ('er', 'vi'), ('vi', 'se'), ('se', 'le'), ('le', 'ar'), ('ar', 'ni'), ('ni', 'ng'), ('ng', 'Clustering'), ('Clustering', 'Anomaly'), ('Anomaly', 'detection'), ('detection', 'Association'), ('Association', 'mining'), ('mining', 'Partition'), ('Partition', 'data'), ('data', 'set'), ('set', 'X'), ('X', 'groups'), ('groups', 'records'), ('records', 'group'), ('group', 'similar'), ('similar', ','), (',', 'records'), ('records', 'different'), ('different', 'groups'), ('groups', 'dissimilar'), ('dissimilar', 'Identification'), ('Identification', 'rare'), ('rare', 'items'), ('items', ','), (',', 'events'), ('events', 'observations'), ('observations', 'raise'), ('raise', 'suspicion'), ('suspicion', 'differing'), ('differing', 'significantly'), ('significantly', 'majority'), ('majority', 'data'), ('data', 'Find'), ('Find', 'frequent'), ('frequent', 'patterns'), ('patterns', ','), (',', 'correlations'), ('correlations', 'associations'), ('associations', 'among'), ('among', 'set'), ('set', 'items'), ('items', 'relational'), ('relational', 'transaction'), ('transaction', 'databases'), ('databases', '13/14Demystifying'), ('13/14Demystifying', 'data'), ('data', 'science'), ('science', 'Natural'), ('Natural', 'language'), ('language', 'processing'), ('processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'Natural'), ('Natural', 'language'), ('language', 'processing'), ('processing', 'set'), ('set', 'systematic'), ('systematic', 'processes'), ('processes', 'intelligently'), ('intelligently', 'efficiently'), ('efficiently', 'analyzing'), ('analyzing', ','), (',', 'understanding'), ('understanding', 'deriving'), ('deriving', 'information'), ('information', 'text'), ('text', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unsupervised', 'learning', 'Clustering'), ('learning', 'Clustering', 'Anomaly'), ('Clustering', 'Anomaly', 'detection'), ('Anomaly', 'detection', 'Association'), ('detection', 'Association', 'mining'), ('Association', 'mining', 'Partition'), ('mining', 'Partition', 'data'), ('Partition', 'data', 'set'), ('data', 'set', 'X'), ('set', 'X', 'groups'), ('X', 'groups', 'records'), ('groups', 'records', 'group'), ('records', 'group', 'similar'), ('group', 'similar', ','), ('similar', ',', 'records'), (',', 'records', 'different'), ('records', 'different', 'groups'), ('different', 'groups', 'dissimilar'), ('groups', 'dissimilar', 'Identification'), ('dissimilar', 'Identification', 'rare'), ('Identification', 'rare', 'items'), ('rare', 'items', ','), ('items', ',', 'events'), (',', 'events', 'observations'), ('events', 'observations', 'raise'), ('observations', 'raise', 'suspicion'), ('raise', 'suspicion', 'differing'), ('suspicion', 'differing', 'significantly'), ('differing', 'significantly', 'majority'), ('significantly', 'majority', 'data'), ('majority', 'data', 'Find'), ('data', 'Find', 'frequent'), ('Find', 'frequent', 'patterns'), ('frequent', 'patterns', ','), ('patterns', ',', 'correlations'), (',', 'correlations', 'associations'), ('correlations', 'associations', 'among'), ('associations', 'among', 'set'), ('among', 'set', 'items'), ('set', 'items', 'relational'), ('items', 'relational', 'transaction'), ('relational', 'transaction', 'databases'), ('transaction', 'databases', 'U'), ('databases', 'U', 'ns'), ('U', 'ns', 'er'), ('ns', 'er', 'vi'), ('er', 'vi', 'se'), ('vi', 'se', 'le'), ('se', 'le', 'ar'), ('le', 'ar', 'ni'), ('ar', 'ni', 'ng'), ('ni', 'ng', 'Clustering'), ('ng', 'Clustering', 'Anomaly'), ('Clustering', 'Anomaly', 'detection'), ('Anomaly', 'detection', 'Association'), ('detection', 'Association', 'mining'), ('Association', 'mining', 'Partition'), ('mining', 'Partition', 'data'), ('Partition', 'data', 'set'), ('data', 'set', 'X'), ('set', 'X', 'groups'), ('X', 'groups', 'records'), ('groups', 'records', 'group'), ('records', 'group', 'similar'), ('group', 'similar', ','), ('similar', ',', 'records'), (',', 'records', 'different'), ('records', 'different', 'groups'), ('different', 'groups', 'dissimilar'), ('groups', 'dissimilar', 'Identification'), ('dissimilar', 'Identification', 'rare'), ('Identification', 'rare', 'items'), ('rare', 'items', ','), ('items', ',', 'events'), (',', 'events', 'observations'), ('events', 'observations', 'raise'), ('observations', 'raise', 'suspicion'), ('raise', 'suspicion', 'differing'), ('suspicion', 'differing', 'significantly'), ('differing', 'significantly', 'majority'), ('significantly', 'majority', 'data'), ('majority', 'data', 'Find'), ('data', 'Find', 'frequent'), ('Find', 'frequent', 'patterns'), ('frequent', 'patterns', ','), ('patterns', ',', 'correlations'), (',', 'correlations', 'associations'), ('correlations', 'associations', 'among'), ('associations', 'among', 'set'), ('among', 'set', 'items'), ('set', 'items', 'relational'), ('items', 'relational', 'transaction'), ('relational', 'transaction', 'databases'), ('transaction', 'databases', '13/14Demystifying'), ('databases', '13/14Demystifying', 'data'), ('13/14Demystifying', 'data', 'science'), ('data', 'science', 'Natural'), ('science', 'Natural', 'language'), ('Natural', 'language', 'processing'), ('language', 'processing', '('), ('processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'Natural'), (')', 'Natural', 'language'), ('Natural', 'language', 'processing'), ('language', 'processing', 'set'), ('processing', 'set', 'systematic'), ('set', 'systematic', 'processes'), ('systematic', 'processes', 'intelligently'), ('processes', 'intelligently', 'efficiently'), ('intelligently', 'efficiently', 'analyzing'), ('efficiently', 'analyzing', ','), ('analyzing', ',', 'understanding'), (',', 'understanding', 'deriving'), ('understanding', 'deriving', 'information'), ('deriving', 'information', 'text'), ('information', 'text', 'data'), ('text', 'data', '.')]

>> POS Tags are: 
 [('Unsupervised', 'VBN'), ('learning', 'VBG'), ('Clustering', 'NNP'), ('Anomaly', 'NNP'), ('detection', 'NN'), ('Association', 'NNP'), ('mining', 'NN'), ('Partition', 'NNP'), ('data', 'NN'), ('set', 'NN'), ('X', 'NNP'), ('groups', 'NNS'), ('records', 'NNS'), ('group', 'NN'), ('similar', 'JJ'), (',', ','), ('records', 'NNS'), ('different', 'JJ'), ('groups', 'NNS'), ('dissimilar', 'JJ'), ('Identification', 'NNP'), ('rare', 'NN'), ('items', 'NNS'), (',', ','), ('events', 'NNS'), ('observations', 'NNS'), ('raise', 'VBP'), ('suspicion', 'NN'), ('differing', 'VBG'), ('significantly', 'RB'), ('majority', 'NN'), ('data', 'NNS'), ('Find', 'NNP'), ('frequent', 'JJ'), ('patterns', 'NNS'), (',', ','), ('correlations', 'NNS'), ('associations', 'NNS'), ('among', 'IN'), ('set', 'JJ'), ('items', 'NNS'), ('relational', 'JJ'), ('transaction', 'NN'), ('databases', 'VBZ'), ('U', 'NNP'), ('ns', 'JJ'), ('er', 'NN'), ('vi', 'NN'), ('se', 'NN'), ('le', 'NN'), ('ar', 'NN'), ('ni', 'JJ'), ('ng', 'JJ'), ('Clustering', 'NNP'), ('Anomaly', 'NNP'), ('detection', 'NN'), ('Association', 'NNP'), ('mining', 'NN'), ('Partition', 'NNP'), ('data', 'NN'), ('set', 'NN'), ('X', 'NNP'), ('groups', 'NNS'), ('records', 'NNS'), ('group', 'NN'), ('similar', 'JJ'), (',', ','), ('records', 'NNS'), ('different', 'JJ'), ('groups', 'NNS'), ('dissimilar', 'JJ'), ('Identification', 'NNP'), ('rare', 'NN'), ('items', 'NNS'), (',', ','), ('events', 'NNS'), ('observations', 'NNS'), ('raise', 'VBP'), ('suspicion', 'NN'), ('differing', 'VBG'), ('significantly', 'RB'), ('majority', 'NN'), ('data', 'NNS'), ('Find', 'NNP'), ('frequent', 'JJ'), ('patterns', 'NNS'), (',', ','), ('correlations', 'NNS'), ('associations', 'NNS'), ('among', 'IN'), ('set', 'JJ'), ('items', 'NNS'), ('relational', 'JJ'), ('transaction', 'NN'), ('databases', 'VBZ'), ('13/14Demystifying', 'CD'), ('data', 'NNS'), ('science', 'NN'), ('Natural', 'NNP'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('Natural', 'NNP'), ('language', 'NN'), ('processing', 'NN'), ('set', 'VBN'), ('systematic', 'JJ'), ('processes', 'NNS'), ('intelligently', 'RB'), ('efficiently', 'RB'), ('analyzing', 'VBG'), (',', ','), ('understanding', 'VBG'), ('deriving', 'VBG'), ('information', 'NN'), ('text', 'NN'), ('data', 'NN'), ('.', '.')]

 (S
  Unsupervised/VBN
  learning/VBG
  (NP
    Clustering/NNP
    Anomaly/NNP
    detection/NN
    Association/NNP
    mining/NN
    Partition/NNP
    data/NN
    set/NN
    X/NNP
    groups/NNS
    records/NNS
    group/NN)
  similar/JJ
  ,/,
  (NP records/NNS)
  (NP different/JJ groups/NNS)
  (NP dissimilar/JJ Identification/NNP rare/NN items/NNS)
  ,/,
  (NP events/NNS observations/NNS)
  raise/VBP
  (NP suspicion/NN)
  differing/VBG
  significantly/RB
  (NP majority/NN data/NNS Find/NNP)
  (NP frequent/JJ patterns/NNS)
  ,/,
  (NP correlations/NNS associations/NNS)
  among/IN
  (NP set/JJ items/NNS)
  (NP relational/JJ transaction/NN)
  databases/VBZ
  (NP U/NNP)
  (NP ns/JJ er/NN vi/NN se/NN le/NN ar/NN)
  (NP
    ni/JJ
    ng/JJ
    Clustering/NNP
    Anomaly/NNP
    detection/NN
    Association/NNP
    mining/NN
    Partition/NNP
    data/NN
    set/NN
    X/NNP
    groups/NNS
    records/NNS
    group/NN)
  similar/JJ
  ,/,
  (NP records/NNS)
  (NP different/JJ groups/NNS)
  (NP dissimilar/JJ Identification/NNP rare/NN items/NNS)
  ,/,
  (NP events/NNS observations/NNS)
  raise/VBP
  (NP suspicion/NN)
  differing/VBG
  significantly/RB
  (NP majority/NN data/NNS Find/NNP)
  (NP frequent/JJ patterns/NNS)
  ,/,
  (NP correlations/NNS associations/NNS)
  among/IN
  (NP set/JJ items/NNS)
  (NP relational/JJ transaction/NN)
  databases/VBZ
  13/14Demystifying/CD
  (NP data/NNS science/NN Natural/NNP language/NN processing/NN)
  (/(
  (NP NLP/NNP)
  )/)
  (NP Natural/NNP language/NN processing/NN)
  set/VBN
  (NP systematic/JJ processes/NNS)
  intelligently/RB
  efficiently/RB
  analyzing/VBG
  ,/,
  understanding/VBG
  deriving/VBG
  (NP information/NN text/NN data/NN)
  ./.) 


>> Noun Phrases are: 
 ['Clustering Anomaly detection Association mining Partition data set X groups records group', 'records', 'different groups', 'dissimilar Identification rare items', 'events observations', 'suspicion', 'majority data Find', 'frequent patterns', 'correlations associations', 'set items', 'relational transaction', 'U', 'ns er vi se le ar', 'ni ng Clustering Anomaly detection Association mining Partition data set X groups records group', 'records', 'different groups', 'dissimilar Identification rare items', 'events observations', 'suspicion', 'majority data Find', 'frequent patterns', 'correlations associations', 'set items', 'relational transaction', 'data science Natural language processing', 'NLP', 'Natural language processing', 'systematic processes', 'information text data']

>> Named Entities are: 
 [('ORGANIZATION', 'Clustering Anomaly'), ('ORGANIZATION', 'Partition'), ('ORGANIZATION', 'Partition'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Clustering', 'cluster'), ('Anomaly', 'anomali'), ('detection', 'detect'), ('Association', 'associ'), ('mining', 'mine'), ('Partition', 'partit'), ('data', 'data'), ('set', 'set'), ('X', 'x'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'differ'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'identif'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observ'), ('raise', 'rais'), ('suspicion', 'suspicion'), ('differing', 'differ'), ('significantly', 'significantli'), ('majority', 'major'), ('data', 'data'), ('Find', 'find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correl'), ('associations', 'associ'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relat'), ('transaction', 'transact'), ('databases', 'databas'), ('U', 'u'), ('ns', 'ns'), ('er', 'er'), ('vi', 'vi'), ('se', 'se'), ('le', 'le'), ('ar', 'ar'), ('ni', 'ni'), ('ng', 'ng'), ('Clustering', 'cluster'), ('Anomaly', 'anomali'), ('detection', 'detect'), ('Association', 'associ'), ('mining', 'mine'), ('Partition', 'partit'), ('data', 'data'), ('set', 'set'), ('X', 'x'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'differ'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'identif'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observ'), ('raise', 'rais'), ('suspicion', 'suspicion'), ('differing', 'differ'), ('significantly', 'significantli'), ('majority', 'major'), ('data', 'data'), ('Find', 'find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correl'), ('associations', 'associ'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relat'), ('transaction', 'transact'), ('databases', 'databas'), ('13/14Demystifying', '13/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('set', 'set'), ('systematic', 'systemat'), ('processes', 'process'), ('intelligently', 'intellig'), ('efficiently', 'effici'), ('analyzing', 'analyz'), (',', ','), ('understanding', 'understand'), ('deriving', 'deriv'), ('information', 'inform'), ('text', 'text'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('Clustering', 'cluster'), ('Anomaly', 'anomali'), ('detection', 'detect'), ('Association', 'associ'), ('mining', 'mine'), ('Partition', 'partit'), ('data', 'data'), ('set', 'set'), ('X', 'x'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'differ'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'identif'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observ'), ('raise', 'rais'), ('suspicion', 'suspicion'), ('differing', 'differ'), ('significantly', 'signific'), ('majority', 'major'), ('data', 'data'), ('Find', 'find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correl'), ('associations', 'associ'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relat'), ('transaction', 'transact'), ('databases', 'databas'), ('U', 'u'), ('ns', 'ns'), ('er', 'er'), ('vi', 'vi'), ('se', 'se'), ('le', 'le'), ('ar', 'ar'), ('ni', 'ni'), ('ng', 'ng'), ('Clustering', 'cluster'), ('Anomaly', 'anomali'), ('detection', 'detect'), ('Association', 'associ'), ('mining', 'mine'), ('Partition', 'partit'), ('data', 'data'), ('set', 'set'), ('X', 'x'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'differ'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'identif'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observ'), ('raise', 'rais'), ('suspicion', 'suspicion'), ('differing', 'differ'), ('significantly', 'signific'), ('majority', 'major'), ('data', 'data'), ('Find', 'find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correl'), ('associations', 'associ'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relat'), ('transaction', 'transact'), ('databases', 'databas'), ('13/14Demystifying', '13/14demystifi'), ('data', 'data'), ('science', 'scienc'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('set', 'set'), ('systematic', 'systemat'), ('processes', 'process'), ('intelligently', 'intellig'), ('efficiently', 'effici'), ('analyzing', 'analyz'), (',', ','), ('understanding', 'understand'), ('deriving', 'deriv'), ('information', 'inform'), ('text', 'text'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('Clustering', 'Clustering'), ('Anomaly', 'Anomaly'), ('detection', 'detection'), ('Association', 'Association'), ('mining', 'mining'), ('Partition', 'Partition'), ('data', 'data'), ('set', 'set'), ('X', 'X'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'different'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'Identification'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observation'), ('raise', 'raise'), ('suspicion', 'suspicion'), ('differing', 'differing'), ('significantly', 'significantly'), ('majority', 'majority'), ('data', 'data'), ('Find', 'Find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correlation'), ('associations', 'association'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relational'), ('transaction', 'transaction'), ('databases', 'database'), ('U', 'U'), ('ns', 'n'), ('er', 'er'), ('vi', 'vi'), ('se', 'se'), ('le', 'le'), ('ar', 'ar'), ('ni', 'ni'), ('ng', 'ng'), ('Clustering', 'Clustering'), ('Anomaly', 'Anomaly'), ('detection', 'detection'), ('Association', 'Association'), ('mining', 'mining'), ('Partition', 'Partition'), ('data', 'data'), ('set', 'set'), ('X', 'X'), ('groups', 'group'), ('records', 'record'), ('group', 'group'), ('similar', 'similar'), (',', ','), ('records', 'record'), ('different', 'different'), ('groups', 'group'), ('dissimilar', 'dissimilar'), ('Identification', 'Identification'), ('rare', 'rare'), ('items', 'item'), (',', ','), ('events', 'event'), ('observations', 'observation'), ('raise', 'raise'), ('suspicion', 'suspicion'), ('differing', 'differing'), ('significantly', 'significantly'), ('majority', 'majority'), ('data', 'data'), ('Find', 'Find'), ('frequent', 'frequent'), ('patterns', 'pattern'), (',', ','), ('correlations', 'correlation'), ('associations', 'association'), ('among', 'among'), ('set', 'set'), ('items', 'item'), ('relational', 'relational'), ('transaction', 'transaction'), ('databases', 'database'), ('13/14Demystifying', '13/14Demystifying'), ('data', 'data'), ('science', 'science'), ('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('(', '('), ('NLP', 'NLP'), (')', ')'), ('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('set', 'set'), ('systematic', 'systematic'), ('processes', 'process'), ('intelligently', 'intelligently'), ('efficiently', 'efficiently'), ('analyzing', 'analyzing'), (',', ','), ('understanding', 'understanding'), ('deriving', 'deriving'), ('information', 'information'), ('text', 'text'), ('data', 'data'), ('.', '.')]



============================ Sentence 200 =============================

It can organize massive amounts of text data and perform numerous automated  tasks, such as automatic summarization, machine translation, named entity  recognition, relationship extraction, sentiment analysis, speech recognition and  topic segmentation. 


>> Tokens are: 
 ['It', 'organize', 'massive', 'amounts', 'text', 'data', 'perform', 'numerous', 'automated', 'tasks', ',', 'automatic', 'summarization', ',', 'machine', 'translation', ',', 'named', 'entity', 'recognition', ',', 'relationship', 'extraction', ',', 'sentiment', 'analysis', ',', 'speech', 'recognition', 'topic', 'segmentation', '.']

>> Bigrams are: 
 [('It', 'organize'), ('organize', 'massive'), ('massive', 'amounts'), ('amounts', 'text'), ('text', 'data'), ('data', 'perform'), ('perform', 'numerous'), ('numerous', 'automated'), ('automated', 'tasks'), ('tasks', ','), (',', 'automatic'), ('automatic', 'summarization'), ('summarization', ','), (',', 'machine'), ('machine', 'translation'), ('translation', ','), (',', 'named'), ('named', 'entity'), ('entity', 'recognition'), ('recognition', ','), (',', 'relationship'), ('relationship', 'extraction'), ('extraction', ','), (',', 'sentiment'), ('sentiment', 'analysis'), ('analysis', ','), (',', 'speech'), ('speech', 'recognition'), ('recognition', 'topic'), ('topic', 'segmentation'), ('segmentation', '.')]

>> Trigrams are: 
 [('It', 'organize', 'massive'), ('organize', 'massive', 'amounts'), ('massive', 'amounts', 'text'), ('amounts', 'text', 'data'), ('text', 'data', 'perform'), ('data', 'perform', 'numerous'), ('perform', 'numerous', 'automated'), ('numerous', 'automated', 'tasks'), ('automated', 'tasks', ','), ('tasks', ',', 'automatic'), (',', 'automatic', 'summarization'), ('automatic', 'summarization', ','), ('summarization', ',', 'machine'), (',', 'machine', 'translation'), ('machine', 'translation', ','), ('translation', ',', 'named'), (',', 'named', 'entity'), ('named', 'entity', 'recognition'), ('entity', 'recognition', ','), ('recognition', ',', 'relationship'), (',', 'relationship', 'extraction'), ('relationship', 'extraction', ','), ('extraction', ',', 'sentiment'), (',', 'sentiment', 'analysis'), ('sentiment', 'analysis', ','), ('analysis', ',', 'speech'), (',', 'speech', 'recognition'), ('speech', 'recognition', 'topic'), ('recognition', 'topic', 'segmentation'), ('topic', 'segmentation', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('organize', 'RB'), ('massive', 'JJ'), ('amounts', 'NNS'), ('text', 'JJ'), ('data', 'NNS'), ('perform', 'RB'), ('numerous', 'JJ'), ('automated', 'VBN'), ('tasks', 'NNS'), (',', ','), ('automatic', 'JJ'), ('summarization', 'NN'), (',', ','), ('machine', 'NN'), ('translation', 'NN'), (',', ','), ('named', 'VBN'), ('entity', 'NN'), ('recognition', 'NN'), (',', ','), ('relationship', 'NN'), ('extraction', 'NN'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), ('topic', 'NN'), ('segmentation', 'NN'), ('.', '.')]

 (S
  It/PRP
  organize/RB
  (NP massive/JJ amounts/NNS)
  (NP text/JJ data/NNS)
  perform/RB
  numerous/JJ
  automated/VBN
  (NP tasks/NNS)
  ,/,
  (NP automatic/JJ summarization/NN)
  ,/,
  (NP machine/NN translation/NN)
  ,/,
  named/VBN
  (NP entity/NN recognition/NN)
  ,/,
  (NP relationship/NN extraction/NN)
  ,/,
  (NP sentiment/NN analysis/NN)
  ,/,
  (NP speech/NN recognition/NN topic/NN segmentation/NN)
  ./.) 


>> Noun Phrases are: 
 ['massive amounts', 'text data', 'tasks', 'automatic summarization', 'machine translation', 'entity recognition', 'relationship extraction', 'sentiment analysis', 'speech recognition topic segmentation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('organize', 'organ'), ('massive', 'massiv'), ('amounts', 'amount'), ('text', 'text'), ('data', 'data'), ('perform', 'perform'), ('numerous', 'numer'), ('automated', 'autom'), ('tasks', 'task'), (',', ','), ('automatic', 'automat'), ('summarization', 'summar'), (',', ','), ('machine', 'machin'), ('translation', 'translat'), (',', ','), ('named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), (',', ','), ('relationship', 'relationship'), ('extraction', 'extract'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('topic', 'topic'), ('segmentation', 'segment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('organize', 'organ'), ('massive', 'massiv'), ('amounts', 'amount'), ('text', 'text'), ('data', 'data'), ('perform', 'perform'), ('numerous', 'numer'), ('automated', 'autom'), ('tasks', 'task'), (',', ','), ('automatic', 'automat'), ('summarization', 'summar'), (',', ','), ('machine', 'machin'), ('translation', 'translat'), (',', ','), ('named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), (',', ','), ('relationship', 'relationship'), ('extraction', 'extract'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('topic', 'topic'), ('segmentation', 'segment'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('organize', 'organize'), ('massive', 'massive'), ('amounts', 'amount'), ('text', 'text'), ('data', 'data'), ('perform', 'perform'), ('numerous', 'numerous'), ('automated', 'automated'), ('tasks', 'task'), (',', ','), ('automatic', 'automatic'), ('summarization', 'summarization'), (',', ','), ('machine', 'machine'), ('translation', 'translation'), (',', ','), ('named', 'named'), ('entity', 'entity'), ('recognition', 'recognition'), (',', ','), ('relationship', 'relationship'), ('extraction', 'extraction'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysis'), (',', ','), ('speech', 'speech'), ('recognition', 'recognition'), ('topic', 'topic'), ('segmentation', 'segmentation'), ('.', '.')]



============================ Sentence 201 =============================

Key questions to ask and how to define high value use-cases To identify meaningful and high value use-cases for teams and organizations, it is  important to gather relevant information and requirements on three key pillars. 


>> Tokens are: 
 ['Key', 'questions', 'ask', 'define', 'high', 'value', 'use-cases', 'To', 'identify', 'meaningful', 'high', 'value', 'use-cases', 'teams', 'organizations', ',', 'important', 'gather', 'relevant', 'information', 'requirements', 'three', 'key', 'pillars', '.']

>> Bigrams are: 
 [('Key', 'questions'), ('questions', 'ask'), ('ask', 'define'), ('define', 'high'), ('high', 'value'), ('value', 'use-cases'), ('use-cases', 'To'), ('To', 'identify'), ('identify', 'meaningful'), ('meaningful', 'high'), ('high', 'value'), ('value', 'use-cases'), ('use-cases', 'teams'), ('teams', 'organizations'), ('organizations', ','), (',', 'important'), ('important', 'gather'), ('gather', 'relevant'), ('relevant', 'information'), ('information', 'requirements'), ('requirements', 'three'), ('three', 'key'), ('key', 'pillars'), ('pillars', '.')]

>> Trigrams are: 
 [('Key', 'questions', 'ask'), ('questions', 'ask', 'define'), ('ask', 'define', 'high'), ('define', 'high', 'value'), ('high', 'value', 'use-cases'), ('value', 'use-cases', 'To'), ('use-cases', 'To', 'identify'), ('To', 'identify', 'meaningful'), ('identify', 'meaningful', 'high'), ('meaningful', 'high', 'value'), ('high', 'value', 'use-cases'), ('value', 'use-cases', 'teams'), ('use-cases', 'teams', 'organizations'), ('teams', 'organizations', ','), ('organizations', ',', 'important'), (',', 'important', 'gather'), ('important', 'gather', 'relevant'), ('gather', 'relevant', 'information'), ('relevant', 'information', 'requirements'), ('information', 'requirements', 'three'), ('requirements', 'three', 'key'), ('three', 'key', 'pillars'), ('key', 'pillars', '.')]

>> POS Tags are: 
 [('Key', 'JJ'), ('questions', 'NNS'), ('ask', 'VBP'), ('define', 'JJ'), ('high', 'JJ'), ('value', 'NN'), ('use-cases', 'NNS'), ('To', 'TO'), ('identify', 'VB'), ('meaningful', 'JJ'), ('high', 'JJ'), ('value', 'NN'), ('use-cases', 'JJ'), ('teams', 'NNS'), ('organizations', 'NNS'), (',', ','), ('important', 'JJ'), ('gather', 'NN'), ('relevant', 'JJ'), ('information', 'NN'), ('requirements', 'NNS'), ('three', 'CD'), ('key', 'JJ'), ('pillars', 'NNS'), ('.', '.')]

 (S
  (NP Key/JJ questions/NNS)
  ask/VBP
  (NP define/JJ high/JJ value/NN use-cases/NNS)
  To/TO
  identify/VB
  (NP meaningful/JJ high/JJ value/NN)
  (NP use-cases/JJ teams/NNS organizations/NNS)
  ,/,
  (NP important/JJ gather/NN)
  (NP relevant/JJ information/NN requirements/NNS)
  three/CD
  (NP key/JJ pillars/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Key questions', 'define high value use-cases', 'meaningful high value', 'use-cases teams organizations', 'important gather', 'relevant information requirements', 'key pillars']

>> Named Entities are: 
 [('GPE', 'Key')] 

>> Stemming using Porter Stemmer: 
 [('Key', 'key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'defin'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('To', 'to'), ('identify', 'identifi'), ('meaningful', 'meaning'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('teams', 'team'), ('organizations', 'organ'), (',', ','), ('important', 'import'), ('gather', 'gather'), ('relevant', 'relev'), ('information', 'inform'), ('requirements', 'requir'), ('three', 'three'), ('key', 'key'), ('pillars', 'pillar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Key', 'key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'defin'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('To', 'to'), ('identify', 'identifi'), ('meaningful', 'meaning'), ('high', 'high'), ('value', 'valu'), ('use-cases', 'use-cas'), ('teams', 'team'), ('organizations', 'organ'), (',', ','), ('important', 'import'), ('gather', 'gather'), ('relevant', 'relev'), ('information', 'inform'), ('requirements', 'requir'), ('three', 'three'), ('key', 'key'), ('pillars', 'pillar'), ('.', '.')]

>> Lemmatization: 
 [('Key', 'Key'), ('questions', 'question'), ('ask', 'ask'), ('define', 'define'), ('high', 'high'), ('value', 'value'), ('use-cases', 'use-cases'), ('To', 'To'), ('identify', 'identify'), ('meaningful', 'meaningful'), ('high', 'high'), ('value', 'value'), ('use-cases', 'use-cases'), ('teams', 'team'), ('organizations', 'organization'), (',', ','), ('important', 'important'), ('gather', 'gather'), ('relevant', 'relevant'), ('information', 'information'), ('requirements', 'requirement'), ('three', 'three'), ('key', 'key'), ('pillars', 'pillar'), ('.', '.')]



============================ Sentence 202 =============================

1. Business knowledge  What is the current business process? 


>> Tokens are: 
 ['1.', 'Business', 'knowledge', '', 'What', 'current', 'business', 'process', '?']

>> Bigrams are: 
 [('1.', 'Business'), ('Business', 'knowledge'), ('knowledge', ''), ('', 'What'), ('What', 'current'), ('current', 'business'), ('business', 'process'), ('process', '?')]

>> Trigrams are: 
 [('1.', 'Business', 'knowledge'), ('Business', 'knowledge', ''), ('knowledge', '', 'What'), ('', 'What', 'current'), ('What', 'current', 'business'), ('current', 'business', 'process'), ('business', 'process', '?')]

>> POS Tags are: 
 [('1.', 'CD'), ('Business', 'NNP'), ('knowledge', 'NN'), ('', 'NNP'), ('What', 'WP'), ('current', 'JJ'), ('business', 'NN'), ('process', 'NN'), ('?', '.')]

 (S
  1./CD
  (NP Business/NNP knowledge/NN /NNP)
  What/WP
  (NP current/JJ business/NN process/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Business knowledge ', 'current business process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1.', '1.'), ('Business', 'busi'), ('knowledge', 'knowledg'), ('', ''), ('What', 'what'), ('current', 'current'), ('business', 'busi'), ('process', 'process'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('1.', '1.'), ('Business', 'busi'), ('knowledge', 'knowledg'), ('', ''), ('What', 'what'), ('current', 'current'), ('business', 'busi'), ('process', 'process'), ('?', '?')]

>> Lemmatization: 
 [('1.', '1.'), ('Business', 'Business'), ('knowledge', 'knowledge'), ('', ''), ('What', 'What'), ('current', 'current'), ('business', 'business'), ('process', 'process'), ('?', '?')]



============================ Sentence 203 =============================

How are things done currently? 


>> Tokens are: 
 ['How', 'things', 'done', 'currently', '?']

>> Bigrams are: 
 [('How', 'things'), ('things', 'done'), ('done', 'currently'), ('currently', '?')]

>> Trigrams are: 
 [('How', 'things', 'done'), ('things', 'done', 'currently'), ('done', 'currently', '?')]

>> POS Tags are: 
 [('How', 'WRB'), ('things', 'NNS'), ('done', 'VBN'), ('currently', 'RB'), ('?', '.')]

 (S How/WRB (NP things/NNS) done/VBN currently/RB ?/.) 


>> Noun Phrases are: 
 ['things']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('things', 'thing'), ('done', 'done'), ('currently', 'current'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('things', 'thing'), ('done', 'done'), ('currently', 'current'), ('?', '?')]

>> Lemmatization: 
 [('How', 'How'), ('things', 'thing'), ('done', 'done'), ('currently', 'currently'), ('?', '?')]



============================ Sentence 204 =============================

Does  someone manually identify which products to recommend to each customer? 


>> Tokens are: 
 ['Does', 'someone', 'manually', 'identify', 'products', 'recommend', 'customer', '?']

>> Bigrams are: 
 [('Does', 'someone'), ('someone', 'manually'), ('manually', 'identify'), ('identify', 'products'), ('products', 'recommend'), ('recommend', 'customer'), ('customer', '?')]

>> Trigrams are: 
 [('Does', 'someone', 'manually'), ('someone', 'manually', 'identify'), ('manually', 'identify', 'products'), ('identify', 'products', 'recommend'), ('products', 'recommend', 'customer'), ('recommend', 'customer', '?')]

>> POS Tags are: 
 [('Does', 'NNP'), ('someone', 'NN'), ('manually', 'RB'), ('identify', 'JJ'), ('products', 'NNS'), ('recommend', 'VBP'), ('customer', 'NN'), ('?', '.')]

 (S
  (NP Does/NNP someone/NN)
  manually/RB
  (NP identify/JJ products/NNS)
  recommend/VBP
  (NP customer/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Does someone', 'identify products', 'customer']

>> Named Entities are: 
 [('GPE', 'Does')] 

>> Stemming using Porter Stemmer: 
 [('Does', 'doe'), ('someone', 'someon'), ('manually', 'manual'), ('identify', 'identifi'), ('products', 'product'), ('recommend', 'recommend'), ('customer', 'custom'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Does', 'doe'), ('someone', 'someon'), ('manually', 'manual'), ('identify', 'identifi'), ('products', 'product'), ('recommend', 'recommend'), ('customer', 'custom'), ('?', '?')]

>> Lemmatization: 
 [('Does', 'Does'), ('someone', 'someone'), ('manually', 'manually'), ('identify', 'identify'), ('products', 'product'), ('recommend', 'recommend'), ('customer', 'customer'), ('?', '?')]



============================ Sentence 205 =============================

Does someone manually review each loan application for fraud or risk? 


>> Tokens are: 
 ['Does', 'someone', 'manually', 'review', 'loan', 'application', 'fraud', 'risk', '?']

>> Bigrams are: 
 [('Does', 'someone'), ('someone', 'manually'), ('manually', 'review'), ('review', 'loan'), ('loan', 'application'), ('application', 'fraud'), ('fraud', 'risk'), ('risk', '?')]

>> Trigrams are: 
 [('Does', 'someone', 'manually'), ('someone', 'manually', 'review'), ('manually', 'review', 'loan'), ('review', 'loan', 'application'), ('loan', 'application', 'fraud'), ('application', 'fraud', 'risk'), ('fraud', 'risk', '?')]

>> POS Tags are: 
 [('Does', 'NNP'), ('someone', 'NN'), ('manually', 'RB'), ('review', 'JJ'), ('loan', 'NN'), ('application', 'NN'), ('fraud', 'NN'), ('risk', 'NN'), ('?', '.')]

 (S
  (NP Does/NNP someone/NN)
  manually/RB
  (NP review/JJ loan/NN application/NN fraud/NN risk/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Does someone', 'review loan application fraud risk']

>> Named Entities are: 
 [('GPE', 'Does')] 

>> Stemming using Porter Stemmer: 
 [('Does', 'doe'), ('someone', 'someon'), ('manually', 'manual'), ('review', 'review'), ('loan', 'loan'), ('application', 'applic'), ('fraud', 'fraud'), ('risk', 'risk'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Does', 'doe'), ('someone', 'someon'), ('manually', 'manual'), ('review', 'review'), ('loan', 'loan'), ('application', 'applic'), ('fraud', 'fraud'), ('risk', 'risk'), ('?', '?')]

>> Lemmatization: 
 [('Does', 'Does'), ('someone', 'someone'), ('manually', 'manually'), ('review', 'review'), ('loan', 'loan'), ('application', 'application'), ('fraud', 'fraud'), ('risk', 'risk'), ('?', '?')]



============================ Sentence 206 =============================

Does an  engineer manually inspect all machinery each week for failure? 


>> Tokens are: 
 ['Does', 'engineer', 'manually', 'inspect', 'machinery', 'week', 'failure', '?']

>> Bigrams are: 
 [('Does', 'engineer'), ('engineer', 'manually'), ('manually', 'inspect'), ('inspect', 'machinery'), ('machinery', 'week'), ('week', 'failure'), ('failure', '?')]

>> Trigrams are: 
 [('Does', 'engineer', 'manually'), ('engineer', 'manually', 'inspect'), ('manually', 'inspect', 'machinery'), ('inspect', 'machinery', 'week'), ('machinery', 'week', 'failure'), ('week', 'failure', '?')]

>> POS Tags are: 
 [('Does', 'NNP'), ('engineer', 'VB'), ('manually', 'RB'), ('inspect', 'JJ'), ('machinery', 'NN'), ('week', 'NN'), ('failure', 'NN'), ('?', '.')]

 (S
  (NP Does/NNP)
  engineer/VB
  manually/RB
  (NP inspect/JJ machinery/NN week/NN failure/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Does', 'inspect machinery week failure']

>> Named Entities are: 
 [('GPE', 'Does')] 

>> Stemming using Porter Stemmer: 
 [('Does', 'doe'), ('engineer', 'engin'), ('manually', 'manual'), ('inspect', 'inspect'), ('machinery', 'machineri'), ('week', 'week'), ('failure', 'failur'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Does', 'doe'), ('engineer', 'engin'), ('manually', 'manual'), ('inspect', 'inspect'), ('machinery', 'machineri'), ('week', 'week'), ('failure', 'failur'), ('?', '?')]

>> Lemmatization: 
 [('Does', 'Does'), ('engineer', 'engineer'), ('manually', 'manually'), ('inspect', 'inspect'), ('machinery', 'machinery'), ('week', 'week'), ('failure', 'failure'), ('?', '?')]



============================ Sentence 207 =============================

Be as specific and  detailed as possible in defining the current process. 


>> Tokens are: 
 ['Be', 'specific', 'detailed', 'possible', 'defining', 'current', 'process', '.']

>> Bigrams are: 
 [('Be', 'specific'), ('specific', 'detailed'), ('detailed', 'possible'), ('possible', 'defining'), ('defining', 'current'), ('current', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Be', 'specific', 'detailed'), ('specific', 'detailed', 'possible'), ('detailed', 'possible', 'defining'), ('possible', 'defining', 'current'), ('defining', 'current', 'process'), ('current', 'process', '.')]

>> POS Tags are: 
 [('Be', 'NNP'), ('specific', 'JJ'), ('detailed', 'VBN'), ('possible', 'JJ'), ('defining', 'VBG'), ('current', 'JJ'), ('process', 'NN'), ('.', '.')]

 (S
  (NP Be/NNP)
  specific/JJ
  detailed/VBN
  possible/JJ
  defining/VBG
  (NP current/JJ process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Be', 'current process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Be', 'be'), ('specific', 'specif'), ('detailed', 'detail'), ('possible', 'possibl'), ('defining', 'defin'), ('current', 'current'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Be', 'be'), ('specific', 'specif'), ('detailed', 'detail'), ('possible', 'possibl'), ('defining', 'defin'), ('current', 'current'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Be', 'Be'), ('specific', 'specific'), ('detailed', 'detailed'), ('possible', 'possible'), ('defining', 'defining'), ('current', 'current'), ('process', 'process'), ('.', '.')]



============================ Sentence 208 =============================

 Define measurable goals and objectives. 


>> Tokens are: 
 ['', 'Define', 'measurable', 'goals', 'objectives', '.']

>> Bigrams are: 
 [('', 'Define'), ('Define', 'measurable'), ('measurable', 'goals'), ('goals', 'objectives'), ('objectives', '.')]

>> Trigrams are: 
 [('', 'Define', 'measurable'), ('Define', 'measurable', 'goals'), ('measurable', 'goals', 'objectives'), ('goals', 'objectives', '.')]

>> POS Tags are: 
 [('', 'JJ'), ('Define', 'NNP'), ('measurable', 'JJ'), ('goals', 'NNS'), ('objectives', 'NNS'), ('.', '.')]

 (S
  (NP /JJ Define/NNP)
  (NP measurable/JJ goals/NNS objectives/NNS)
  ./.) 


>> Noun Phrases are: 
 [' Define', 'measurable goals objectives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Define', 'defin'), ('measurable', 'measur'), ('goals', 'goal'), ('objectives', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Define', 'defin'), ('measurable', 'measur'), ('goals', 'goal'), ('objectives', 'object'), ('.', '.')]

>> Lemmatization: 
 [('', ''), ('Define', 'Define'), ('measurable', 'measurable'), ('goals', 'goal'), ('objectives', 'objective'), ('.', '.')]



============================ Sentence 209 =============================

Is it to replace or enhance an existing  process? 


>> Tokens are: 
 ['Is', 'replace', 'enhance', 'existing', 'process', '?']

>> Bigrams are: 
 [('Is', 'replace'), ('replace', 'enhance'), ('enhance', 'existing'), ('existing', 'process'), ('process', '?')]

>> Trigrams are: 
 [('Is', 'replace', 'enhance'), ('replace', 'enhance', 'existing'), ('enhance', 'existing', 'process'), ('existing', 'process', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('replace', 'VB'), ('enhance', 'JJ'), ('existing', 'VBG'), ('process', 'NN'), ('?', '.')]

 (S Is/VBZ replace/VB enhance/JJ existing/VBG (NP process/NN) ?/.) 


>> Noun Phrases are: 
 ['process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('replace', 'replac'), ('enhance', 'enhanc'), ('existing', 'exist'), ('process', 'process'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('replace', 'replac'), ('enhance', 'enhanc'), ('existing', 'exist'), ('process', 'process'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('replace', 'replace'), ('enhance', 'enhance'), ('existing', 'existing'), ('process', 'process'), ('?', '?')]



============================ Sentence 210 =============================

Is it to increase revenue and conversions from product upsell and cross sell  opportunities or to increase software subscriptions by three percent this quarter? 


>> Tokens are: 
 ['Is', 'increase', 'revenue', 'conversions', 'product', 'upsell', 'cross', 'sell', 'opportunities', 'increase', 'software', 'subscriptions', 'three', 'percent', 'quarter', '?']

>> Bigrams are: 
 [('Is', 'increase'), ('increase', 'revenue'), ('revenue', 'conversions'), ('conversions', 'product'), ('product', 'upsell'), ('upsell', 'cross'), ('cross', 'sell'), ('sell', 'opportunities'), ('opportunities', 'increase'), ('increase', 'software'), ('software', 'subscriptions'), ('subscriptions', 'three'), ('three', 'percent'), ('percent', 'quarter'), ('quarter', '?')]

>> Trigrams are: 
 [('Is', 'increase', 'revenue'), ('increase', 'revenue', 'conversions'), ('revenue', 'conversions', 'product'), ('conversions', 'product', 'upsell'), ('product', 'upsell', 'cross'), ('upsell', 'cross', 'sell'), ('cross', 'sell', 'opportunities'), ('sell', 'opportunities', 'increase'), ('opportunities', 'increase', 'software'), ('increase', 'software', 'subscriptions'), ('software', 'subscriptions', 'three'), ('subscriptions', 'three', 'percent'), ('three', 'percent', 'quarter'), ('percent', 'quarter', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('increase', 'JJ'), ('revenue', 'NN'), ('conversions', 'NNS'), ('product', 'NN'), ('upsell', 'VBP'), ('cross', 'NN'), ('sell', 'NN'), ('opportunities', 'NNS'), ('increase', 'VBP'), ('software', 'NN'), ('subscriptions', 'NNS'), ('three', 'CD'), ('percent', 'JJ'), ('quarter', 'NN'), ('?', '.')]

 (S
  Is/VBZ
  (NP increase/JJ revenue/NN conversions/NNS product/NN)
  upsell/VBP
  (NP cross/NN sell/NN opportunities/NNS)
  increase/VBP
  (NP software/NN subscriptions/NNS)
  three/CD
  (NP percent/JJ quarter/NN)
  ?/.) 


>> Noun Phrases are: 
 ['increase revenue conversions product', 'cross sell opportunities', 'software subscriptions', 'percent quarter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('increase', 'increas'), ('revenue', 'revenu'), ('conversions', 'convers'), ('product', 'product'), ('upsell', 'upsel'), ('cross', 'cross'), ('sell', 'sell'), ('opportunities', 'opportun'), ('increase', 'increas'), ('software', 'softwar'), ('subscriptions', 'subscript'), ('three', 'three'), ('percent', 'percent'), ('quarter', 'quarter'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('increase', 'increas'), ('revenue', 'revenu'), ('conversions', 'convers'), ('product', 'product'), ('upsell', 'upsel'), ('cross', 'cross'), ('sell', 'sell'), ('opportunities', 'opportun'), ('increase', 'increas'), ('software', 'softwar'), ('subscriptions', 'subscript'), ('three', 'three'), ('percent', 'percent'), ('quarter', 'quarter'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('increase', 'increase'), ('revenue', 'revenue'), ('conversions', 'conversion'), ('product', 'product'), ('upsell', 'upsell'), ('cross', 'cross'), ('sell', 'sell'), ('opportunities', 'opportunity'), ('increase', 'increase'), ('software', 'software'), ('subscriptions', 'subscription'), ('three', 'three'), ('percent', 'percent'), ('quarter', 'quarter'), ('?', '?')]



============================ Sentence 211 =============================

 What areas can be improved? 


>> Tokens are: 
 ['', 'What', 'areas', 'improved', '?']

>> Bigrams are: 
 [('', 'What'), ('What', 'areas'), ('areas', 'improved'), ('improved', '?')]

>> Trigrams are: 
 [('', 'What', 'areas'), ('What', 'areas', 'improved'), ('areas', 'improved', '?')]

>> POS Tags are: 
 [('', 'VB'), ('What', 'WP'), ('areas', 'NNS'), ('improved', 'VBN'), ('?', '.')]

 (S /VB What/WP (NP areas/NNS) improved/VBN ?/.) 


>> Noun Phrases are: 
 ['areas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('What', 'what'), ('areas', 'area'), ('improved', 'improv'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('What', 'what'), ('areas', 'area'), ('improved', 'improv'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('What', 'What'), ('areas', 'area'), ('improved', 'improved'), ('?', '?')]



============================ Sentence 212 =============================

What is the business question to be answered  with analytics? 


>> Tokens are: 
 ['What', 'business', 'question', 'answered', 'analytics', '?']

>> Bigrams are: 
 [('What', 'business'), ('business', 'question'), ('question', 'answered'), ('answered', 'analytics'), ('analytics', '?')]

>> Trigrams are: 
 [('What', 'business', 'question'), ('business', 'question', 'answered'), ('question', 'answered', 'analytics'), ('answered', 'analytics', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('business', 'NN'), ('question', 'NN'), ('answered', 'VBD'), ('analytics', 'NNS'), ('?', '.')]

 (S
  What/WP
  (NP business/NN question/NN)
  answered/VBD
  (NP analytics/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['business question', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('business', 'busi'), ('question', 'question'), ('answered', 'answer'), ('analytics', 'analyt'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('business', 'busi'), ('question', 'question'), ('answered', 'answer'), ('analytics', 'analyt'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('business', 'business'), ('question', 'question'), ('answered', 'answered'), ('analytics', 'analytics'), ('?', '?')]



============================ Sentence 213 =============================

Leverage subject matter experts to identify key pain points and  gaps in the current business process. 


>> Tokens are: 
 ['Leverage', 'subject', 'matter', 'experts', 'identify', 'key', 'pain', 'points', 'gaps', 'current', 'business', 'process', '.']

>> Bigrams are: 
 [('Leverage', 'subject'), ('subject', 'matter'), ('matter', 'experts'), ('experts', 'identify'), ('identify', 'key'), ('key', 'pain'), ('pain', 'points'), ('points', 'gaps'), ('gaps', 'current'), ('current', 'business'), ('business', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Leverage', 'subject', 'matter'), ('subject', 'matter', 'experts'), ('matter', 'experts', 'identify'), ('experts', 'identify', 'key'), ('identify', 'key', 'pain'), ('key', 'pain', 'points'), ('pain', 'points', 'gaps'), ('points', 'gaps', 'current'), ('gaps', 'current', 'business'), ('current', 'business', 'process'), ('business', 'process', '.')]

>> POS Tags are: 
 [('Leverage', 'NN'), ('subject', 'JJ'), ('matter', 'NN'), ('experts', 'NNS'), ('identify', 'VBP'), ('key', 'JJ'), ('pain', 'NN'), ('points', 'NNS'), ('gaps', 'VBP'), ('current', 'JJ'), ('business', 'NN'), ('process', 'NN'), ('.', '.')]

 (S
  (NP Leverage/NN)
  (NP subject/JJ matter/NN experts/NNS)
  identify/VBP
  (NP key/JJ pain/NN points/NNS)
  gaps/VBP
  (NP current/JJ business/NN process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Leverage', 'subject matter experts', 'key pain points', 'current business process']

>> Named Entities are: 
 [('GPE', 'Leverage')] 

>> Stemming using Porter Stemmer: 
 [('Leverage', 'leverag'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('identify', 'identifi'), ('key', 'key'), ('pain', 'pain'), ('points', 'point'), ('gaps', 'gap'), ('current', 'current'), ('business', 'busi'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Leverage', 'leverag'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('identify', 'identifi'), ('key', 'key'), ('pain', 'pain'), ('points', 'point'), ('gaps', 'gap'), ('current', 'current'), ('business', 'busi'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Leverage', 'Leverage'), ('subject', 'subject'), ('matter', 'matter'), ('experts', 'expert'), ('identify', 'identify'), ('key', 'key'), ('pain', 'pain'), ('points', 'point'), ('gaps', 'gap'), ('current', 'current'), ('business', 'business'), ('process', 'process'), ('.', '.')]



============================ Sentence 214 =============================

Determine what part of the process can  be enhanced. 


>> Tokens are: 
 ['Determine', 'part', 'process', 'enhanced', '.']

>> Bigrams are: 
 [('Determine', 'part'), ('part', 'process'), ('process', 'enhanced'), ('enhanced', '.')]

>> Trigrams are: 
 [('Determine', 'part', 'process'), ('part', 'process', 'enhanced'), ('process', 'enhanced', '.')]

>> POS Tags are: 
 [('Determine', 'NNP'), ('part', 'NN'), ('process', 'NN'), ('enhanced', 'VBD'), ('.', '.')]

 (S (NP Determine/NNP part/NN process/NN) enhanced/VBD ./.) 


>> Noun Phrases are: 
 ['Determine part process']

>> Named Entities are: 
 [('GPE', 'Determine')] 

>> Stemming using Porter Stemmer: 
 [('Determine', 'determin'), ('part', 'part'), ('process', 'process'), ('enhanced', 'enhanc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Determine', 'determin'), ('part', 'part'), ('process', 'process'), ('enhanced', 'enhanc'), ('.', '.')]

>> Lemmatization: 
 [('Determine', 'Determine'), ('part', 'part'), ('process', 'process'), ('enhanced', 'enhanced'), ('.', '.')]



============================ Sentence 215 =============================

Where can data-driven insights be used? 


>> Tokens are: 
 ['Where', 'data-driven', 'insights', 'used', '?']

>> Bigrams are: 
 [('Where', 'data-driven'), ('data-driven', 'insights'), ('insights', 'used'), ('used', '?')]

>> Trigrams are: 
 [('Where', 'data-driven', 'insights'), ('data-driven', 'insights', 'used'), ('insights', 'used', '?')]

>> POS Tags are: 
 [('Where', 'WRB'), ('data-driven', 'JJ'), ('insights', 'NNS'), ('used', 'VBN'), ('?', '.')]

 (S Where/WRB (NP data-driven/JJ insights/NNS) used/VBN ?/.) 


>> Noun Phrases are: 
 ['data-driven insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('used', 'use'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('used', 'use'), ('?', '?')]

>> Lemmatization: 
 [('Where', 'Where'), ('data-driven', 'data-driven'), ('insights', 'insight'), ('used', 'used'), ('?', '?')]



============================ Sentence 216 =============================

Is the objective to speed  up loan application processing? 


>> Tokens are: 
 ['Is', 'objective', 'speed', 'loan', 'application', 'processing', '?']

>> Bigrams are: 
 [('Is', 'objective'), ('objective', 'speed'), ('speed', 'loan'), ('loan', 'application'), ('application', 'processing'), ('processing', '?')]

>> Trigrams are: 
 [('Is', 'objective', 'speed'), ('objective', 'speed', 'loan'), ('speed', 'loan', 'application'), ('loan', 'application', 'processing'), ('application', 'processing', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('objective', 'JJ'), ('speed', 'NN'), ('loan', 'NN'), ('application', 'NN'), ('processing', 'NN'), ('?', '.')]

 (S
  Is/VBZ
  (NP objective/JJ speed/NN loan/NN application/NN processing/NN)
  ?/.) 


>> Noun Phrases are: 
 ['objective speed loan application processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('objective', 'object'), ('speed', 'speed'), ('loan', 'loan'), ('application', 'applic'), ('processing', 'process'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('objective', 'object'), ('speed', 'speed'), ('loan', 'loan'), ('application', 'applic'), ('processing', 'process'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('objective', 'objective'), ('speed', 'speed'), ('loan', 'loan'), ('application', 'application'), ('processing', 'processing'), ('?', '?')]



============================ Sentence 217 =============================

Identify high risk transactions on credit cards? 


>> Tokens are: 
 ['Identify', 'high', 'risk', 'transactions', 'credit', 'cards', '?']

>> Bigrams are: 
 [('Identify', 'high'), ('high', 'risk'), ('risk', 'transactions'), ('transactions', 'credit'), ('credit', 'cards'), ('cards', '?')]

>> Trigrams are: 
 [('Identify', 'high', 'risk'), ('high', 'risk', 'transactions'), ('risk', 'transactions', 'credit'), ('transactions', 'credit', 'cards'), ('credit', 'cards', '?')]

>> POS Tags are: 
 [('Identify', 'NNP'), ('high', 'JJ'), ('risk', 'NN'), ('transactions', 'NNS'), ('credit', 'NN'), ('cards', 'NNS'), ('?', '.')]

 (S
  (NP Identify/NNP)
  (NP high/JJ risk/NN transactions/NNS credit/NN cards/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['Identify', 'high risk transactions credit cards']

>> Named Entities are: 
 [('GPE', 'Identify')] 

>> Stemming using Porter Stemmer: 
 [('Identify', 'identifi'), ('high', 'high'), ('risk', 'risk'), ('transactions', 'transact'), ('credit', 'credit'), ('cards', 'card'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Identify', 'identifi'), ('high', 'high'), ('risk', 'risk'), ('transactions', 'transact'), ('credit', 'credit'), ('cards', 'card'), ('?', '?')]

>> Lemmatization: 
 [('Identify', 'Identify'), ('high', 'high'), ('risk', 'risk'), ('transactions', 'transaction'), ('credit', 'credit'), ('cards', 'card'), ('?', '?')]



============================ Sentence 218 =============================

Understand customers better? 


>> Tokens are: 
 ['Understand', 'customers', 'better', '?']

>> Bigrams are: 
 [('Understand', 'customers'), ('customers', 'better'), ('better', '?')]

>> Trigrams are: 
 [('Understand', 'customers', 'better'), ('customers', 'better', '?')]

>> POS Tags are: 
 [('Understand', 'NN'), ('customers', 'NNS'), ('better', 'RBR'), ('?', '.')]

 (S (NP Understand/NN customers/NNS) better/RBR ?/.) 


>> Noun Phrases are: 
 ['Understand customers']

>> Named Entities are: 
 [('GPE', 'Understand')] 

>> Stemming using Porter Stemmer: 
 [('Understand', 'understand'), ('customers', 'custom'), ('better', 'better'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Understand', 'understand'), ('customers', 'custom'), ('better', 'better'), ('?', '?')]

>> Lemmatization: 
 [('Understand', 'Understand'), ('customers', 'customer'), ('better', 'better'), ('?', '?')]



============================ Sentence 219 =============================

Specify key challenges and areas for improvement. 


>> Tokens are: 
 ['Specify', 'key', 'challenges', 'areas', 'improvement', '.']

>> Bigrams are: 
 [('Specify', 'key'), ('key', 'challenges'), ('challenges', 'areas'), ('areas', 'improvement'), ('improvement', '.')]

>> Trigrams are: 
 [('Specify', 'key', 'challenges'), ('key', 'challenges', 'areas'), ('challenges', 'areas', 'improvement'), ('areas', 'improvement', '.')]

>> POS Tags are: 
 [('Specify', 'NNP'), ('key', 'JJ'), ('challenges', 'NNS'), ('areas', 'NNS'), ('improvement', 'NN'), ('.', '.')]

 (S
  (NP Specify/NNP)
  (NP key/JJ challenges/NNS areas/NNS improvement/NN)
  ./.) 


>> Noun Phrases are: 
 ['Specify', 'key challenges areas improvement']

>> Named Entities are: 
 [('GPE', 'Specify')] 

>> Stemming using Porter Stemmer: 
 [('Specify', 'specifi'), ('key', 'key'), ('challenges', 'challeng'), ('areas', 'area'), ('improvement', 'improv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Specify', 'specifi'), ('key', 'key'), ('challenges', 'challeng'), ('areas', 'area'), ('improvement', 'improv'), ('.', '.')]

>> Lemmatization: 
 [('Specify', 'Specify'), ('key', 'key'), ('challenges', 'challenge'), ('areas', 'area'), ('improvement', 'improvement'), ('.', '.')]



============================ Sentence 220 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 221 =============================

Solution vision  Why is it important to solve the current business problem/use-case? 


>> Tokens are: 
 ['Solution', 'vision', '', 'Why', 'important', 'solve', 'current', 'business', 'problem/use-case', '?']

>> Bigrams are: 
 [('Solution', 'vision'), ('vision', ''), ('', 'Why'), ('Why', 'important'), ('important', 'solve'), ('solve', 'current'), ('current', 'business'), ('business', 'problem/use-case'), ('problem/use-case', '?')]

>> Trigrams are: 
 [('Solution', 'vision', ''), ('vision', '', 'Why'), ('', 'Why', 'important'), ('Why', 'important', 'solve'), ('important', 'solve', 'current'), ('solve', 'current', 'business'), ('current', 'business', 'problem/use-case'), ('business', 'problem/use-case', '?')]

>> POS Tags are: 
 [('Solution', 'NNP'), ('vision', 'NN'), ('', 'NNP'), ('Why', 'WRB'), ('important', 'JJ'), ('solve', 'NN'), ('current', 'JJ'), ('business', 'NN'), ('problem/use-case', 'NN'), ('?', '.')]

 (S
  (NP Solution/NNP vision/NN /NNP)
  Why/WRB
  (NP important/JJ solve/NN)
  (NP current/JJ business/NN problem/use-case/NN)
  ?/.) 


>> Noun Phrases are: 
 ['Solution vision ', 'important solve', 'current business problem/use-case']

>> Named Entities are: 
 [('GPE', 'Solution')] 

>> Stemming using Porter Stemmer: 
 [('Solution', 'solut'), ('vision', 'vision'), ('', ''), ('Why', 'whi'), ('important', 'import'), ('solve', 'solv'), ('current', 'current'), ('business', 'busi'), ('problem/use-case', 'problem/use-cas'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Solution', 'solut'), ('vision', 'vision'), ('', ''), ('Why', 'whi'), ('important', 'import'), ('solve', 'solv'), ('current', 'current'), ('business', 'busi'), ('problem/use-case', 'problem/use-cas'), ('?', '?')]

>> Lemmatization: 
 [('Solution', 'Solution'), ('vision', 'vision'), ('', ''), ('Why', 'Why'), ('important', 'important'), ('solve', 'solve'), ('current', 'current'), ('business', 'business'), ('problem/use-case', 'problem/use-case'), ('?', '?')]



============================ Sentence 222 =============================

Define  what success would look like. 


>> Tokens are: 
 ['Define', 'success', 'would', 'look', 'like', '.']

>> Bigrams are: 
 [('Define', 'success'), ('success', 'would'), ('would', 'look'), ('look', 'like'), ('like', '.')]

>> Trigrams are: 
 [('Define', 'success', 'would'), ('success', 'would', 'look'), ('would', 'look', 'like'), ('look', 'like', '.')]

>> POS Tags are: 
 [('Define', 'NNP'), ('success', 'NN'), ('would', 'MD'), ('look', 'VB'), ('like', 'IN'), ('.', '.')]

 (S (NP Define/NNP success/NN) would/MD look/VB like/IN ./.) 


>> Noun Phrases are: 
 ['Define success']

>> Named Entities are: 
 [('GPE', 'Define')] 

>> Stemming using Porter Stemmer: 
 [('Define', 'defin'), ('success', 'success'), ('would', 'would'), ('look', 'look'), ('like', 'like'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Define', 'defin'), ('success', 'success'), ('would', 'would'), ('look', 'look'), ('like', 'like'), ('.', '.')]

>> Lemmatization: 
 [('Define', 'Define'), ('success', 'success'), ('would', 'would'), ('look', 'look'), ('like', 'like'), ('.', '.')]



============================ Sentence 223 =============================

Specifically, in order to execute a successful  project, what are the minimum requirements and success criteria? 


>> Tokens are: 
 ['Specifically', ',', 'order', 'execute', 'successful', 'project', ',', 'minimum', 'requirements', 'success', 'criteria', '?']

>> Bigrams are: 
 [('Specifically', ','), (',', 'order'), ('order', 'execute'), ('execute', 'successful'), ('successful', 'project'), ('project', ','), (',', 'minimum'), ('minimum', 'requirements'), ('requirements', 'success'), ('success', 'criteria'), ('criteria', '?')]

>> Trigrams are: 
 [('Specifically', ',', 'order'), (',', 'order', 'execute'), ('order', 'execute', 'successful'), ('execute', 'successful', 'project'), ('successful', 'project', ','), ('project', ',', 'minimum'), (',', 'minimum', 'requirements'), ('minimum', 'requirements', 'success'), ('requirements', 'success', 'criteria'), ('success', 'criteria', '?')]

>> POS Tags are: 
 [('Specifically', 'RB'), (',', ','), ('order', 'NN'), ('execute', 'NN'), ('successful', 'JJ'), ('project', 'NN'), (',', ','), ('minimum', 'NN'), ('requirements', 'NNS'), ('success', 'NN'), ('criteria', 'NNS'), ('?', '.')]

 (S
  Specifically/RB
  ,/,
  (NP order/NN execute/NN)
  (NP successful/JJ project/NN)
  ,/,
  (NP minimum/NN requirements/NNS success/NN criteria/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['order execute', 'successful project', 'minimum requirements success criteria']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Specifically', 'specif'), (',', ','), ('order', 'order'), ('execute', 'execut'), ('successful', 'success'), ('project', 'project'), (',', ','), ('minimum', 'minimum'), ('requirements', 'requir'), ('success', 'success'), ('criteria', 'criteria'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Specifically', 'specif'), (',', ','), ('order', 'order'), ('execute', 'execut'), ('successful', 'success'), ('project', 'project'), (',', ','), ('minimum', 'minimum'), ('requirements', 'requir'), ('success', 'success'), ('criteria', 'criteria'), ('?', '?')]

>> Lemmatization: 
 [('Specifically', 'Specifically'), (',', ','), ('order', 'order'), ('execute', 'execute'), ('successful', 'successful'), ('project', 'project'), (',', ','), ('minimum', 'minimum'), ('requirements', 'requirement'), ('success', 'success'), ('criteria', 'criterion'), ('?', '?')]



============================ Sentence 224 =============================

 Define what decision or business process will be affected by the analytical  solution. 


>> Tokens are: 
 ['', 'Define', 'decision', 'business', 'process', 'affected', 'analytical', 'solution', '.']

>> Bigrams are: 
 [('', 'Define'), ('Define', 'decision'), ('decision', 'business'), ('business', 'process'), ('process', 'affected'), ('affected', 'analytical'), ('analytical', 'solution'), ('solution', '.')]

>> Trigrams are: 
 [('', 'Define', 'decision'), ('Define', 'decision', 'business'), ('decision', 'business', 'process'), ('business', 'process', 'affected'), ('process', 'affected', 'analytical'), ('affected', 'analytical', 'solution'), ('analytical', 'solution', '.')]

>> POS Tags are: 
 [('', 'JJ'), ('Define', 'NNP'), ('decision', 'NN'), ('business', 'NN'), ('process', 'NN'), ('affected', 'VBD'), ('analytical', 'JJ'), ('solution', 'NN'), ('.', '.')]

 (S
  (NP /JJ Define/NNP decision/NN business/NN process/NN)
  affected/VBD
  (NP analytical/JJ solution/NN)
  ./.) 


>> Noun Phrases are: 
 [' Define decision business process', 'analytical solution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Define', 'defin'), ('decision', 'decis'), ('business', 'busi'), ('process', 'process'), ('affected', 'affect'), ('analytical', 'analyt'), ('solution', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Define', 'defin'), ('decision', 'decis'), ('business', 'busi'), ('process', 'process'), ('affected', 'affect'), ('analytical', 'analyt'), ('solution', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('', ''), ('Define', 'Define'), ('decision', 'decision'), ('business', 'business'), ('process', 'process'), ('affected', 'affected'), ('analytical', 'analytical'), ('solution', 'solution'), ('.', '.')]



============================ Sentence 225 =============================

Who will be affected by this tool? 


>> Tokens are: 
 ['Who', 'affected', 'tool', '?']

>> Bigrams are: 
 [('Who', 'affected'), ('affected', 'tool'), ('tool', '?')]

>> Trigrams are: 
 [('Who', 'affected', 'tool'), ('affected', 'tool', '?')]

>> POS Tags are: 
 [('Who', 'WP'), ('affected', 'VBD'), ('tool', 'NN'), ('?', '.')]

 (S Who/WP affected/VBD (NP tool/NN) ?/.) 


>> Noun Phrases are: 
 ['tool']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Who', 'who'), ('affected', 'affect'), ('tool', 'tool'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Who', 'who'), ('affected', 'affect'), ('tool', 'tool'), ('?', '?')]

>> Lemmatization: 
 [('Who', 'Who'), ('affected', 'affected'), ('tool', 'tool'), ('?', '?')]



============================ Sentence 226 =============================

Who are the users of this tool? 


>> Tokens are: 
 ['Who', 'users', 'tool', '?']

>> Bigrams are: 
 [('Who', 'users'), ('users', 'tool'), ('tool', '?')]

>> Trigrams are: 
 [('Who', 'users', 'tool'), ('users', 'tool', '?')]

>> POS Tags are: 
 [('Who', 'WP'), ('users', 'VBZ'), ('tool', 'NN'), ('?', '.')]

 (S Who/WP users/VBZ (NP tool/NN) ?/.) 


>> Noun Phrases are: 
 ['tool']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Who', 'who'), ('users', 'user'), ('tool', 'tool'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Who', 'who'), ('users', 'user'), ('tool', 'tool'), ('?', '?')]

>> Lemmatization: 
 [('Who', 'Who'), ('users', 'user'), ('tool', 'tool'), ('?', '?')]



============================ Sentence 227 =============================

Will  this impact the marketing department and analysts? 


>> Tokens are: 
 ['Will', 'impact', 'marketing', 'department', 'analysts', '?']

>> Bigrams are: 
 [('Will', 'impact'), ('impact', 'marketing'), ('marketing', 'department'), ('department', 'analysts'), ('analysts', '?')]

>> Trigrams are: 
 [('Will', 'impact', 'marketing'), ('impact', 'marketing', 'department'), ('marketing', 'department', 'analysts'), ('department', 'analysts', '?')]

>> POS Tags are: 
 [('Will', 'MD'), ('impact', 'VB'), ('marketing', 'NN'), ('department', 'NN'), ('analysts', 'NNS'), ('?', '.')]

 (S
  Will/MD
  impact/VB
  (NP marketing/NN department/NN analysts/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['marketing department analysts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('marketing', 'market'), ('department', 'depart'), ('analysts', 'analyst'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('marketing', 'market'), ('department', 'depart'), ('analysts', 'analyst'), ('?', '?')]

>> Lemmatization: 
 [('Will', 'Will'), ('impact', 'impact'), ('marketing', 'marketing'), ('department', 'department'), ('analysts', 'analyst'), ('?', '?')]



============================ Sentence 228 =============================

Will it impact planning and  maintenance personnel? 


>> Tokens are: 
 ['Will', 'impact', 'planning', 'maintenance', 'personnel', '?']

>> Bigrams are: 
 [('Will', 'impact'), ('impact', 'planning'), ('planning', 'maintenance'), ('maintenance', 'personnel'), ('personnel', '?')]

>> Trigrams are: 
 [('Will', 'impact', 'planning'), ('impact', 'planning', 'maintenance'), ('planning', 'maintenance', 'personnel'), ('maintenance', 'personnel', '?')]

>> POS Tags are: 
 [('Will', 'MD'), ('impact', 'VB'), ('planning', 'VBG'), ('maintenance', 'NN'), ('personnel', 'NNS'), ('?', '.')]

 (S
  Will/MD
  impact/VB
  planning/VBG
  (NP maintenance/NN personnel/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['maintenance personnel']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('planning', 'plan'), ('maintenance', 'mainten'), ('personnel', 'personnel'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('planning', 'plan'), ('maintenance', 'mainten'), ('personnel', 'personnel'), ('?', '?')]

>> Lemmatization: 
 [('Will', 'Will'), ('impact', 'impact'), ('planning', 'planning'), ('maintenance', 'maintenance'), ('personnel', 'personnel'), ('?', '?')]



============================ Sentence 229 =============================

Will it impact the claims processing unit of an insurance  company that is responsible for mitigating fraud? 


>> Tokens are: 
 ['Will', 'impact', 'claims', 'processing', 'unit', 'insurance', 'company', 'responsible', 'mitigating', 'fraud', '?']

>> Bigrams are: 
 [('Will', 'impact'), ('impact', 'claims'), ('claims', 'processing'), ('processing', 'unit'), ('unit', 'insurance'), ('insurance', 'company'), ('company', 'responsible'), ('responsible', 'mitigating'), ('mitigating', 'fraud'), ('fraud', '?')]

>> Trigrams are: 
 [('Will', 'impact', 'claims'), ('impact', 'claims', 'processing'), ('claims', 'processing', 'unit'), ('processing', 'unit', 'insurance'), ('unit', 'insurance', 'company'), ('insurance', 'company', 'responsible'), ('company', 'responsible', 'mitigating'), ('responsible', 'mitigating', 'fraud'), ('mitigating', 'fraud', '?')]

>> POS Tags are: 
 [('Will', 'MD'), ('impact', 'VB'), ('claims', 'NNS'), ('processing', 'VBG'), ('unit', 'NN'), ('insurance', 'NN'), ('company', 'NN'), ('responsible', 'JJ'), ('mitigating', 'VBG'), ('fraud', 'NN'), ('?', '.')]

 (S
  Will/MD
  impact/VB
  (NP claims/NNS)
  processing/VBG
  (NP unit/NN insurance/NN company/NN)
  responsible/JJ
  mitigating/VBG
  (NP fraud/NN)
  ?/.) 


>> Noun Phrases are: 
 ['claims', 'unit insurance company', 'fraud']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('claims', 'claim'), ('processing', 'process'), ('unit', 'unit'), ('insurance', 'insur'), ('company', 'compani'), ('responsible', 'respons'), ('mitigating', 'mitig'), ('fraud', 'fraud'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Will', 'will'), ('impact', 'impact'), ('claims', 'claim'), ('processing', 'process'), ('unit', 'unit'), ('insurance', 'insur'), ('company', 'compani'), ('responsible', 'respons'), ('mitigating', 'mitig'), ('fraud', 'fraud'), ('?', '?')]

>> Lemmatization: 
 [('Will', 'Will'), ('impact', 'impact'), ('claims', 'claim'), ('processing', 'processing'), ('unit', 'unit'), ('insurance', 'insurance'), ('company', 'company'), ('responsible', 'responsible'), ('mitigating', 'mitigating'), ('fraud', 'fraud'), ('?', '?')]



============================ Sentence 230 =============================

 How is the ROI of AI and analytics measured? 


>> Tokens are: 
 ['', 'How', 'ROI', 'AI', 'analytics', 'measured', '?']

>> Bigrams are: 
 [('', 'How'), ('How', 'ROI'), ('ROI', 'AI'), ('AI', 'analytics'), ('analytics', 'measured'), ('measured', '?')]

>> Trigrams are: 
 [('', 'How', 'ROI'), ('How', 'ROI', 'AI'), ('ROI', 'AI', 'analytics'), ('AI', 'analytics', 'measured'), ('analytics', 'measured', '?')]

>> POS Tags are: 
 [('', 'VB'), ('How', 'WRB'), ('ROI', 'NNP'), ('AI', 'NNP'), ('analytics', 'NNS'), ('measured', 'VBD'), ('?', '.')]

 (S /VB How/WRB (NP ROI/NNP AI/NNP analytics/NNS) measured/VBD ?/.) 


>> Noun Phrases are: 
 ['ROI AI analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'ROI')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('How', 'how'), ('ROI', 'roi'), ('AI', 'ai'), ('analytics', 'analyt'), ('measured', 'measur'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('How', 'how'), ('ROI', 'roi'), ('AI', 'ai'), ('analytics', 'analyt'), ('measured', 'measur'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('How', 'How'), ('ROI', 'ROI'), ('AI', 'AI'), ('analytics', 'analytics'), ('measured', 'measured'), ('?', '?')]



============================ Sentence 231 =============================

Is there any current method to  track/benchmark the performance of current business processes and outcomes? 


>> Tokens are: 
 ['Is', 'current', 'method', 'track/benchmark', 'performance', 'current', 'business', 'processes', 'outcomes', '?']

>> Bigrams are: 
 [('Is', 'current'), ('current', 'method'), ('method', 'track/benchmark'), ('track/benchmark', 'performance'), ('performance', 'current'), ('current', 'business'), ('business', 'processes'), ('processes', 'outcomes'), ('outcomes', '?')]

>> Trigrams are: 
 [('Is', 'current', 'method'), ('current', 'method', 'track/benchmark'), ('method', 'track/benchmark', 'performance'), ('track/benchmark', 'performance', 'current'), ('performance', 'current', 'business'), ('current', 'business', 'processes'), ('business', 'processes', 'outcomes'), ('processes', 'outcomes', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('current', 'JJ'), ('method', 'NN'), ('track/benchmark', 'NN'), ('performance', 'NN'), ('current', 'JJ'), ('business', 'NN'), ('processes', 'NNS'), ('outcomes', 'RB'), ('?', '.')]

 (S
  Is/VBZ
  (NP current/JJ method/NN track/benchmark/NN performance/NN)
  (NP current/JJ business/NN processes/NNS)
  outcomes/RB
  ?/.) 


>> Noun Phrases are: 
 ['current method track/benchmark performance', 'current business processes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('current', 'current'), ('method', 'method'), ('track/benchmark', 'track/benchmark'), ('performance', 'perform'), ('current', 'current'), ('business', 'busi'), ('processes', 'process'), ('outcomes', 'outcom'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('current', 'current'), ('method', 'method'), ('track/benchmark', 'track/benchmark'), ('performance', 'perform'), ('current', 'current'), ('business', 'busi'), ('processes', 'process'), ('outcomes', 'outcom'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('current', 'current'), ('method', 'method'), ('track/benchmark', 'track/benchmark'), ('performance', 'performance'), ('current', 'current'), ('business', 'business'), ('processes', 'process'), ('outcomes', 'outcome'), ('?', '?')]



============================ Sentence 232 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 233 =============================

Data adequacy  What data is available? 


>> Tokens are: 
 ['Data', 'adequacy', '', 'What', 'data', 'available', '?']

>> Bigrams are: 
 [('Data', 'adequacy'), ('adequacy', ''), ('', 'What'), ('What', 'data'), ('data', 'available'), ('available', '?')]

>> Trigrams are: 
 [('Data', 'adequacy', ''), ('adequacy', '', 'What'), ('', 'What', 'data'), ('What', 'data', 'available'), ('data', 'available', '?')]

>> POS Tags are: 
 [('Data', 'NNP'), ('adequacy', 'NN'), ('', 'VBD'), ('What', 'WP'), ('data', 'NN'), ('available', 'JJ'), ('?', '.')]

 (S
  (NP Data/NNP adequacy/NN)
  /VBD
  What/WP
  (NP data/NN)
  available/JJ
  ?/.) 


>> Noun Phrases are: 
 ['Data adequacy', 'data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('adequacy', 'adequaci'), ('', ''), ('What', 'what'), ('data', 'data'), ('available', 'avail'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('adequacy', 'adequaci'), ('', ''), ('What', 'what'), ('data', 'data'), ('available', 'avail'), ('?', '?')]

>> Lemmatization: 
 [('Data', 'Data'), ('adequacy', 'adequacy'), ('', ''), ('What', 'What'), ('data', 'data'), ('available', 'available'), ('?', '?')]



============================ Sentence 234 =============================

Is it structured or unstructured? 


>> Tokens are: 
 ['Is', 'structured', 'unstructured', '?']

>> Bigrams are: 
 [('Is', 'structured'), ('structured', 'unstructured'), ('unstructured', '?')]

>> Trigrams are: 
 [('Is', 'structured', 'unstructured'), ('structured', 'unstructured', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('structured', 'VBN'), ('unstructured', 'JJ'), ('?', '.')]

 (S Is/VBZ structured/VBN unstructured/JJ ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('structured', 'structured'), ('unstructured', 'unstructured'), ('?', '?')]



============================ Sentence 235 =============================

Is there data relevant to  answering the business problem? 


>> Tokens are: 
 ['Is', 'data', 'relevant', 'answering', 'business', 'problem', '?']

>> Bigrams are: 
 [('Is', 'data'), ('data', 'relevant'), ('relevant', 'answering'), ('answering', 'business'), ('business', 'problem'), ('problem', '?')]

>> Trigrams are: 
 [('Is', 'data', 'relevant'), ('data', 'relevant', 'answering'), ('relevant', 'answering', 'business'), ('answering', 'business', 'problem'), ('business', 'problem', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('data', 'NNS'), ('relevant', 'JJ'), ('answering', 'VBG'), ('business', 'NN'), ('problem', 'NN'), ('?', '.')]

 (S
  Is/VBZ
  (NP data/NNS)
  relevant/JJ
  answering/VBG
  (NP business/NN problem/NN)
  ?/.) 


>> Noun Phrases are: 
 ['data', 'business problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('data', 'data'), ('relevant', 'relev'), ('answering', 'answer'), ('business', 'busi'), ('problem', 'problem'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('data', 'data'), ('relevant', 'relev'), ('answering', 'answer'), ('business', 'busi'), ('problem', 'problem'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('data', 'data'), ('relevant', 'relevant'), ('answering', 'answering'), ('business', 'business'), ('problem', 'problem'), ('?', '?')]



============================ Sentence 236 =============================

Example: Operational data is required to predict  when a machine will fail. 


>> Tokens are: 
 ['Example', ':', 'Operational', 'data', 'required', 'predict', 'machine', 'fail', '.']

>> Bigrams are: 
 [('Example', ':'), (':', 'Operational'), ('Operational', 'data'), ('data', 'required'), ('required', 'predict'), ('predict', 'machine'), ('machine', 'fail'), ('fail', '.')]

>> Trigrams are: 
 [('Example', ':', 'Operational'), (':', 'Operational', 'data'), ('Operational', 'data', 'required'), ('data', 'required', 'predict'), ('required', 'predict', 'machine'), ('predict', 'machine', 'fail'), ('machine', 'fail', '.')]

>> POS Tags are: 
 [('Example', 'NN'), (':', ':'), ('Operational', 'NNP'), ('data', 'NNS'), ('required', 'VBD'), ('predict', 'JJ'), ('machine', 'NN'), ('fail', 'NN'), ('.', '.')]

 (S
  (NP Example/NN)
  :/:
  (NP Operational/NNP data/NNS)
  required/VBD
  (NP predict/JJ machine/NN fail/NN)
  ./.) 


>> Noun Phrases are: 
 ['Example', 'Operational data', 'predict machine fail']

>> Named Entities are: 
 [('GPE', 'Example')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), (':', ':'), ('Operational', 'oper'), ('data', 'data'), ('required', 'requir'), ('predict', 'predict'), ('machine', 'machin'), ('fail', 'fail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), (':', ':'), ('Operational', 'oper'), ('data', 'data'), ('required', 'requir'), ('predict', 'predict'), ('machine', 'machin'), ('fail', 'fail'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), (':', ':'), ('Operational', 'Operational'), ('data', 'data'), ('required', 'required'), ('predict', 'predict'), ('machine', 'machine'), ('fail', 'fail'), ('.', '.')]



============================ Sentence 237 =============================

 How much data does the organization have? 


>> Tokens are: 
 ['', 'How', 'much', 'data', 'organization', '?']

>> Bigrams are: 
 [('', 'How'), ('How', 'much'), ('much', 'data'), ('data', 'organization'), ('organization', '?')]

>> Trigrams are: 
 [('', 'How', 'much'), ('How', 'much', 'data'), ('much', 'data', 'organization'), ('data', 'organization', '?')]

>> POS Tags are: 
 [('', 'VB'), ('How', 'WRB'), ('much', 'JJ'), ('data', 'NNS'), ('organization', 'NN'), ('?', '.')]

 (S /VB How/WRB (NP much/JJ data/NNS organization/NN) ?/.) 


>> Noun Phrases are: 
 ['much data organization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('How', 'how'), ('much', 'much'), ('data', 'data'), ('organization', 'organ'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('How', 'how'), ('much', 'much'), ('data', 'data'), ('organization', 'organ'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('How', 'How'), ('much', 'much'), ('data', 'data'), ('organization', 'organization'), ('?', '?')]



============================ Sentence 238 =============================

Where is the data stored? 


>> Tokens are: 
 ['Where', 'data', 'stored', '?']

>> Bigrams are: 
 [('Where', 'data'), ('data', 'stored'), ('stored', '?')]

>> Trigrams are: 
 [('Where', 'data', 'stored'), ('data', 'stored', '?')]

>> POS Tags are: 
 [('Where', 'WRB'), ('data', 'NNS'), ('stored', 'VBD'), ('?', '.')]

 (S Where/WRB (NP data/NNS) stored/VBD ?/.) 


>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('stored', 'store'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('stored', 'store'), ('?', '?')]

>> Lemmatization: 
 [('Where', 'Where'), ('data', 'data'), ('stored', 'stored'), ('?', '?')]



============================ Sentence 239 =============================

 Is data readily accessible for analysis and modelling? 


>> Tokens are: 
 ['', 'Is', 'data', 'readily', 'accessible', 'analysis', 'modelling', '?']

>> Bigrams are: 
 [('', 'Is'), ('Is', 'data'), ('data', 'readily'), ('readily', 'accessible'), ('accessible', 'analysis'), ('analysis', 'modelling'), ('modelling', '?')]

>> Trigrams are: 
 [('', 'Is', 'data'), ('Is', 'data', 'readily'), ('data', 'readily', 'accessible'), ('readily', 'accessible', 'analysis'), ('accessible', 'analysis', 'modelling'), ('analysis', 'modelling', '?')]

>> POS Tags are: 
 [('', 'NN'), ('Is', 'VBZ'), ('data', 'VBN'), ('readily', 'RB'), ('accessible', 'JJ'), ('analysis', 'NN'), ('modelling', 'NN'), ('?', '.')]

 (S
  (NP /NN)
  Is/VBZ
  data/VBN
  readily/RB
  (NP accessible/JJ analysis/NN modelling/NN)
  ?/.) 


>> Noun Phrases are: 
 ['', 'accessible analysis modelling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Is', 'is'), ('data', 'data'), ('readily', 'readili'), ('accessible', 'access'), ('analysis', 'analysi'), ('modelling', 'model'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Is', 'is'), ('data', 'data'), ('readily', 'readili'), ('accessible', 'access'), ('analysis', 'analysi'), ('modelling', 'model'), ('?', '?')]

>> Lemmatization: 
 [('', ''), ('Is', 'Is'), ('data', 'data'), ('readily', 'readily'), ('accessible', 'accessible'), ('analysis', 'analysis'), ('modelling', 'modelling'), ('?', '?')]



============================ Sentence 240 =============================

14/14  Copyright  2021 Open Text. 


>> Tokens are: 
 ['14/14', 'Copyright', '', '2021', 'Open', 'Text', '.']

>> Bigrams are: 
 [('14/14', 'Copyright'), ('Copyright', ''), ('', '2021'), ('2021', 'Open'), ('Open', 'Text'), ('Text', '.')]

>> Trigrams are: 
 [('14/14', 'Copyright', ''), ('Copyright', '', '2021'), ('', '2021', 'Open'), ('2021', 'Open', 'Text'), ('Open', 'Text', '.')]

>> POS Tags are: 
 [('14/14', 'CD'), ('Copyright', 'NNP'), ('', 'NN'), ('2021', 'CD'), ('Open', 'NNP'), ('Text', 'NNP'), ('.', '.')]

 (S
  14/14/CD
  (NP Copyright/NNP /NN)
  2021/CD
  (NP Open/NNP Text/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Copyright ', 'Open Text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14/14', '14/14'), ('Copyright', 'copyright'), ('', ''), ('2021', '2021'), ('Open', 'open'), ('Text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14/14', '14/14'), ('Copyright', 'copyright'), ('', ''), ('2021', '2021'), ('Open', 'open'), ('Text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('14/14', '14/14'), ('Copyright', 'Copyright'), ('', ''), ('2021', '2021'), ('Open', 'Open'), ('Text', 'Text'), ('.', '.')]



============================ Sentence 241 =============================

All Rights Reserved. 


>> Tokens are: 
 ['All', 'Rights', 'Reserved', '.']

>> Bigrams are: 
 [('All', 'Rights'), ('Rights', 'Reserved'), ('Reserved', '.')]

>> Trigrams are: 
 [('All', 'Rights', 'Reserved'), ('Rights', 'Reserved', '.')]

>> POS Tags are: 
 [('All', 'DT'), ('Rights', 'NNPS'), ('Reserved', 'NNP'), ('.', '.')]

 (S All/DT Rights/NNPS (NP Reserved/NNP) ./.) 


>> Noun Phrases are: 
 ['Reserved']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('Rights', 'right'), ('Reserved', 'reserv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('Rights', 'right'), ('Reserved', 'reserv'), ('.', '.')]

>> Lemmatization: 
 [('All', 'All'), ('Rights', 'Rights'), ('Reserved', 'Reserved'), ('.', '.')]



============================ Sentence 242 =============================

Trademarks owned by Open Text. 


>> Tokens are: 
 ['Trademarks', 'owned', 'Open', 'Text', '.']

>> Bigrams are: 
 [('Trademarks', 'owned'), ('owned', 'Open'), ('Open', 'Text'), ('Text', '.')]

>> Trigrams are: 
 [('Trademarks', 'owned', 'Open'), ('owned', 'Open', 'Text'), ('Open', 'Text', '.')]

>> POS Tags are: 
 [('Trademarks', 'NNS'), ('owned', 'VBD'), ('Open', 'NNP'), ('Text', 'NNP'), ('.', '.')]

 (S (NP Trademarks/NNS) owned/VBD (NP Open/NNP Text/NNP) ./.) 


>> Noun Phrases are: 
 ['Trademarks', 'Open Text']

>> Named Entities are: 
 [('PERSON', 'Open Text')] 

>> Stemming using Porter Stemmer: 
 [('Trademarks', 'trademark'), ('owned', 'own'), ('Open', 'open'), ('Text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Trademarks', 'trademark'), ('owned', 'own'), ('Open', 'open'), ('Text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('Trademarks', 'Trademarks'), ('owned', 'owned'), ('Open', 'Open'), ('Text', 'Text'), ('.', '.')]



============================ Sentence 243 =============================

For more information, visit: https://www.opentext.com/about/copyright-information  (23.04.21)17629.EN#  opentext.com/contact  Use-case evaluation worksheet Section 1: Business knowledge                                                                       Section 2: Solution vision                                                                     Section 3: Data adequacy                                                                     Tips and tricks  Framing the right business question is key to success. 


>> Tokens are: 
 ['For', 'information', ',', 'visit', ':', 'https', ':', '//www.opentext.com/about/copyright-information', '', '(', '23.04.21', ')', '17629.EN', '#', 'opentext.com/contact', 'Use-case', 'evaluation', 'worksheet', 'Section', '1', ':', 'Business', 'knowledge', 'Section', '2', ':', 'Solution', 'vision', 'Section', '3', ':', 'Data', 'adequacy', 'Tips', 'tricks', '', 'Framing', 'right', 'business', 'question', 'key', 'success', '.']

>> Bigrams are: 
 [('For', 'information'), ('information', ','), (',', 'visit'), ('visit', ':'), (':', 'https'), ('https', ':'), (':', '//www.opentext.com/about/copyright-information'), ('//www.opentext.com/about/copyright-information', ''), ('', '('), ('(', '23.04.21'), ('23.04.21', ')'), (')', '17629.EN'), ('17629.EN', '#'), ('#', 'opentext.com/contact'), ('opentext.com/contact', 'Use-case'), ('Use-case', 'evaluation'), ('evaluation', 'worksheet'), ('worksheet', 'Section'), ('Section', '1'), ('1', ':'), (':', 'Business'), ('Business', 'knowledge'), ('knowledge', 'Section'), ('Section', '2'), ('2', ':'), (':', 'Solution'), ('Solution', 'vision'), ('vision', 'Section'), ('Section', '3'), ('3', ':'), (':', 'Data'), ('Data', 'adequacy'), ('adequacy', 'Tips'), ('Tips', 'tricks'), ('tricks', ''), ('', 'Framing'), ('Framing', 'right'), ('right', 'business'), ('business', 'question'), ('question', 'key'), ('key', 'success'), ('success', '.')]

>> Trigrams are: 
 [('For', 'information', ','), ('information', ',', 'visit'), (',', 'visit', ':'), ('visit', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.opentext.com/about/copyright-information'), (':', '//www.opentext.com/about/copyright-information', ''), ('//www.opentext.com/about/copyright-information', '', '('), ('', '(', '23.04.21'), ('(', '23.04.21', ')'), ('23.04.21', ')', '17629.EN'), (')', '17629.EN', '#'), ('17629.EN', '#', 'opentext.com/contact'), ('#', 'opentext.com/contact', 'Use-case'), ('opentext.com/contact', 'Use-case', 'evaluation'), ('Use-case', 'evaluation', 'worksheet'), ('evaluation', 'worksheet', 'Section'), ('worksheet', 'Section', '1'), ('Section', '1', ':'), ('1', ':', 'Business'), (':', 'Business', 'knowledge'), ('Business', 'knowledge', 'Section'), ('knowledge', 'Section', '2'), ('Section', '2', ':'), ('2', ':', 'Solution'), (':', 'Solution', 'vision'), ('Solution', 'vision', 'Section'), ('vision', 'Section', '3'), ('Section', '3', ':'), ('3', ':', 'Data'), (':', 'Data', 'adequacy'), ('Data', 'adequacy', 'Tips'), ('adequacy', 'Tips', 'tricks'), ('Tips', 'tricks', ''), ('tricks', '', 'Framing'), ('', 'Framing', 'right'), ('Framing', 'right', 'business'), ('right', 'business', 'question'), ('business', 'question', 'key'), ('question', 'key', 'success'), ('key', 'success', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('information', 'NN'), (',', ','), ('visit', 'NN'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.opentext.com/about/copyright-information', 'NN'), ('', 'NN'), ('(', '('), ('23.04.21', 'CD'), (')', ')'), ('17629.EN', 'CD'), ('#', '#'), ('opentext.com/contact', 'JJ'), ('Use-case', 'JJ'), ('evaluation', 'NN'), ('worksheet', 'NN'), ('Section', 'NN'), ('1', 'CD'), (':', ':'), ('Business', 'NN'), ('knowledge', 'NN'), ('Section', 'NN'), ('2', 'CD'), (':', ':'), ('Solution', 'NN'), ('vision', 'NN'), ('Section', 'NN'), ('3', 'CD'), (':', ':'), ('Data', 'NNS'), ('adequacy', 'NN'), ('Tips', 'NNP'), ('tricks', 'VBZ'), ('', 'VBP'), ('Framing', 'VBG'), ('right', 'NN'), ('business', 'NN'), ('question', 'NN'), ('key', 'NN'), ('success', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP information/NN)
  ,/,
  (NP visit/NN)
  :/:
  (NP https/NN)
  :/:
  (NP //www.opentext.com/about/copyright-information/NN /NN)
  (/(
  23.04.21/CD
  )/)
  17629.EN/CD
  #/#
  (NP
    opentext.com/contact/JJ
    Use-case/JJ
    evaluation/NN
    worksheet/NN
    Section/NN)
  1/CD
  :/:
  (NP Business/NN knowledge/NN Section/NN)
  2/CD
  :/:
  (NP Solution/NN vision/NN Section/NN)
  3/CD
  :/:
  (NP Data/NNS adequacy/NN Tips/NNP)
  tricks/VBZ
  /VBP
  Framing/VBG
  (NP right/NN business/NN question/NN key/NN success/NN)
  ./.) 


>> Noun Phrases are: 
 ['information', 'visit', 'https', '//www.opentext.com/about/copyright-information ', 'opentext.com/contact Use-case evaluation worksheet Section', 'Business knowledge Section', 'Solution vision Section', 'Data adequacy Tips', 'right business question key success']

>> Named Entities are: 
 [('PERSON', 'Tips')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('information', 'inform'), (',', ','), ('visit', 'visit'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.opentext.com/about/copyright-information', '//www.opentext.com/about/copyright-inform'), ('', ''), ('(', '('), ('23.04.21', '23.04.21'), (')', ')'), ('17629.EN', '17629.en'), ('#', '#'), ('opentext.com/contact', 'opentext.com/contact'), ('Use-case', 'use-cas'), ('evaluation', 'evalu'), ('worksheet', 'worksheet'), ('Section', 'section'), ('1', '1'), (':', ':'), ('Business', 'busi'), ('knowledge', 'knowledg'), ('Section', 'section'), ('2', '2'), (':', ':'), ('Solution', 'solut'), ('vision', 'vision'), ('Section', 'section'), ('3', '3'), (':', ':'), ('Data', 'data'), ('adequacy', 'adequaci'), ('Tips', 'tip'), ('tricks', 'trick'), ('', ''), ('Framing', 'frame'), ('right', 'right'), ('business', 'busi'), ('question', 'question'), ('key', 'key'), ('success', 'success'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('information', 'inform'), (',', ','), ('visit', 'visit'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.opentext.com/about/copyright-information', '//www.opentext.com/about/copyright-inform'), ('', ''), ('(', '('), ('23.04.21', '23.04.21'), (')', ')'), ('17629.EN', '17629.en'), ('#', '#'), ('opentext.com/contact', 'opentext.com/contact'), ('Use-case', 'use-cas'), ('evaluation', 'evalu'), ('worksheet', 'worksheet'), ('Section', 'section'), ('1', '1'), (':', ':'), ('Business', 'busi'), ('knowledge', 'knowledg'), ('Section', 'section'), ('2', '2'), (':', ':'), ('Solution', 'solut'), ('vision', 'vision'), ('Section', 'section'), ('3', '3'), (':', ':'), ('Data', 'data'), ('adequacy', 'adequaci'), ('Tips', 'tip'), ('tricks', 'trick'), ('', ''), ('Framing', 'frame'), ('right', 'right'), ('business', 'busi'), ('question', 'question'), ('key', 'key'), ('success', 'success'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('information', 'information'), (',', ','), ('visit', 'visit'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.opentext.com/about/copyright-information', '//www.opentext.com/about/copyright-information'), ('', ''), ('(', '('), ('23.04.21', '23.04.21'), (')', ')'), ('17629.EN', '17629.EN'), ('#', '#'), ('opentext.com/contact', 'opentext.com/contact'), ('Use-case', 'Use-case'), ('evaluation', 'evaluation'), ('worksheet', 'worksheet'), ('Section', 'Section'), ('1', '1'), (':', ':'), ('Business', 'Business'), ('knowledge', 'knowledge'), ('Section', 'Section'), ('2', '2'), (':', ':'), ('Solution', 'Solution'), ('vision', 'vision'), ('Section', 'Section'), ('3', '3'), (':', ':'), ('Data', 'Data'), ('adequacy', 'adequacy'), ('Tips', 'Tips'), ('tricks', 'trick'), ('', ''), ('Framing', 'Framing'), ('right', 'right'), ('business', 'business'), ('question', 'question'), ('key', 'key'), ('success', 'success'), ('.', '.')]



============================ Sentence 244 =============================

 Identify what success means and what the end solution will look like at the start. 


>> Tokens are: 
 ['', 'Identify', 'success', 'means', 'end', 'solution', 'look', 'like', 'start', '.']

>> Bigrams are: 
 [('', 'Identify'), ('Identify', 'success'), ('success', 'means'), ('means', 'end'), ('end', 'solution'), ('solution', 'look'), ('look', 'like'), ('like', 'start'), ('start', '.')]

>> Trigrams are: 
 [('', 'Identify', 'success'), ('Identify', 'success', 'means'), ('success', 'means', 'end'), ('means', 'end', 'solution'), ('end', 'solution', 'look'), ('solution', 'look', 'like'), ('look', 'like', 'start'), ('like', 'start', '.')]

>> POS Tags are: 
 [('', 'JJ'), ('Identify', 'NNP'), ('success', 'NN'), ('means', 'VBZ'), ('end', 'JJ'), ('solution', 'NN'), ('look', 'NN'), ('like', 'IN'), ('start', 'NN'), ('.', '.')]

 (S
  (NP /JJ Identify/NNP success/NN)
  means/VBZ
  (NP end/JJ solution/NN look/NN)
  like/IN
  (NP start/NN)
  ./.) 


>> Noun Phrases are: 
 [' Identify success', 'end solution look', 'start']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Identify', 'identifi'), ('success', 'success'), ('means', 'mean'), ('end', 'end'), ('solution', 'solut'), ('look', 'look'), ('like', 'like'), ('start', 'start'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Identify', 'identifi'), ('success', 'success'), ('means', 'mean'), ('end', 'end'), ('solution', 'solut'), ('look', 'look'), ('like', 'like'), ('start', 'start'), ('.', '.')]

>> Lemmatization: 
 [('', ''), ('Identify', 'Identify'), ('success', 'success'), ('means', 'mean'), ('end', 'end'), ('solution', 'solution'), ('look', 'look'), ('like', 'like'), ('start', 'start'), ('.', '.')]



============================ Sentence 245 =============================

 Remember that AI applications have a very different lifecycletraining, testing,  modelling, experimenting and creating. 


>> Tokens are: 
 ['', 'Remember', 'AI', 'applications', 'different', 'lifecycletraining', ',', 'testing', ',', 'modelling', ',', 'experimenting', 'creating', '.']

>> Bigrams are: 
 [('', 'Remember'), ('Remember', 'AI'), ('AI', 'applications'), ('applications', 'different'), ('different', 'lifecycletraining'), ('lifecycletraining', ','), (',', 'testing'), ('testing', ','), (',', 'modelling'), ('modelling', ','), (',', 'experimenting'), ('experimenting', 'creating'), ('creating', '.')]

>> Trigrams are: 
 [('', 'Remember', 'AI'), ('Remember', 'AI', 'applications'), ('AI', 'applications', 'different'), ('applications', 'different', 'lifecycletraining'), ('different', 'lifecycletraining', ','), ('lifecycletraining', ',', 'testing'), (',', 'testing', ','), ('testing', ',', 'modelling'), (',', 'modelling', ','), ('modelling', ',', 'experimenting'), (',', 'experimenting', 'creating'), ('experimenting', 'creating', '.')]

>> POS Tags are: 
 [('', 'JJ'), ('Remember', 'NNP'), ('AI', 'NNP'), ('applications', 'NNS'), ('different', 'JJ'), ('lifecycletraining', 'NN'), (',', ','), ('testing', 'VBG'), (',', ','), ('modelling', 'VBG'), (',', ','), ('experimenting', 'VBG'), ('creating', 'VBG'), ('.', '.')]

 (S
  (NP /JJ Remember/NNP AI/NNP applications/NNS)
  (NP different/JJ lifecycletraining/NN)
  ,/,
  testing/VBG
  ,/,
  modelling/VBG
  ,/,
  experimenting/VBG
  creating/VBG
  ./.) 


>> Noun Phrases are: 
 [' Remember AI applications', 'different lifecycletraining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Remember', 'rememb'), ('AI', 'ai'), ('applications', 'applic'), ('different', 'differ'), ('lifecycletraining', 'lifecycletrain'), (',', ','), ('testing', 'test'), (',', ','), ('modelling', 'model'), (',', ','), ('experimenting', 'experi'), ('creating', 'creat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Remember', 'rememb'), ('AI', 'ai'), ('applications', 'applic'), ('different', 'differ'), ('lifecycletraining', 'lifecycletrain'), (',', ','), ('testing', 'test'), (',', ','), ('modelling', 'model'), (',', ','), ('experimenting', 'experi'), ('creating', 'creat'), ('.', '.')]

>> Lemmatization: 
 [('', ''), ('Remember', 'Remember'), ('AI', 'AI'), ('applications', 'application'), ('different', 'different'), ('lifecycletraining', 'lifecycletraining'), (',', ','), ('testing', 'testing'), (',', ','), ('modelling', 'modelling'), (',', ','), ('experimenting', 'experimenting'), ('creating', 'creating'), ('.', '.')]



============================ Sentence 246 =============================

 Start small, start early! 


>> Tokens are: 
 ['', 'Start', 'small', ',', 'start', 'early', '!']

>> Bigrams are: 
 [('', 'Start'), ('Start', 'small'), ('small', ','), (',', 'start'), ('start', 'early'), ('early', '!')]

>> Trigrams are: 
 [('', 'Start', 'small'), ('Start', 'small', ','), ('small', ',', 'start'), (',', 'start', 'early'), ('start', 'early', '!')]

>> POS Tags are: 
 [('', 'JJ'), ('Start', 'NNP'), ('small', 'JJ'), (',', ','), ('start', 'JJ'), ('early', 'JJ'), ('!', '.')]

 (S (NP /JJ Start/NNP) small/JJ ,/, start/JJ early/JJ !/.) 


>> Noun Phrases are: 
 [' Start']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Start', 'start'), ('small', 'small'), (',', ','), ('start', 'start'), ('early', 'earli'), ('!', '!')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Start', 'start'), ('small', 'small'), (',', ','), ('start', 'start'), ('early', 'earli'), ('!', '!')]

>> Lemmatization: 
 [('', ''), ('Start', 'Start'), ('small', 'small'), (',', ','), ('start', 'start'), ('early', 'early'), ('!', '!')]



============================ Sentence 247 =============================

 Iterate, iterate, iterate! 


>> Tokens are: 
 ['', 'Iterate', ',', 'iterate', ',', 'iterate', '!']

>> Bigrams are: 
 [('', 'Iterate'), ('Iterate', ','), (',', 'iterate'), ('iterate', ','), (',', 'iterate'), ('iterate', '!')]

>> Trigrams are: 
 [('', 'Iterate', ','), ('Iterate', ',', 'iterate'), (',', 'iterate', ','), ('iterate', ',', 'iterate'), (',', 'iterate', '!')]

>> POS Tags are: 
 [('', 'JJ'), ('Iterate', 'NNP'), (',', ','), ('iterate', 'NN'), (',', ','), ('iterate', 'NN'), ('!', '.')]

 (S (NP /JJ Iterate/NNP) ,/, (NP iterate/NN) ,/, (NP iterate/NN) !/.) 


>> Noun Phrases are: 
 [' Iterate', 'iterate', 'iterate']

>> Named Entities are: 
 [('ORGANIZATION', 'Iterate')] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('Iterate', 'iter'), (',', ','), ('iterate', 'iter'), (',', ','), ('iterate', 'iter'), ('!', '!')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('Iterate', 'iter'), (',', ','), ('iterate', 'iter'), (',', ','), ('iterate', 'iter'), ('!', '!')]

>> Lemmatization: 
 [('', ''), ('Iterate', 'Iterate'), (',', ','), ('iterate', 'iterate'), (',', ','), ('iterate', 'iterate'), ('!', '!')]



============================ Sentence 248 =============================

About OpenText OpenText, The Information Company, enables organizations to gain insight through  market leading information management solutions, on-premises or in the cloud. 


>> Tokens are: 
 ['About', 'OpenText', 'OpenText', ',', 'The', 'Information', 'Company', ',', 'enables', 'organizations', 'gain', 'insight', 'market', 'leading', 'information', 'management', 'solutions', ',', 'on-premises', 'cloud', '.']

>> Bigrams are: 
 [('About', 'OpenText'), ('OpenText', 'OpenText'), ('OpenText', ','), (',', 'The'), ('The', 'Information'), ('Information', 'Company'), ('Company', ','), (',', 'enables'), ('enables', 'organizations'), ('organizations', 'gain'), ('gain', 'insight'), ('insight', 'market'), ('market', 'leading'), ('leading', 'information'), ('information', 'management'), ('management', 'solutions'), ('solutions', ','), (',', 'on-premises'), ('on-premises', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('About', 'OpenText', 'OpenText'), ('OpenText', 'OpenText', ','), ('OpenText', ',', 'The'), (',', 'The', 'Information'), ('The', 'Information', 'Company'), ('Information', 'Company', ','), ('Company', ',', 'enables'), (',', 'enables', 'organizations'), ('enables', 'organizations', 'gain'), ('organizations', 'gain', 'insight'), ('gain', 'insight', 'market'), ('insight', 'market', 'leading'), ('market', 'leading', 'information'), ('leading', 'information', 'management'), ('information', 'management', 'solutions'), ('management', 'solutions', ','), ('solutions', ',', 'on-premises'), (',', 'on-premises', 'cloud'), ('on-premises', 'cloud', '.')]

>> POS Tags are: 
 [('About', 'IN'), ('OpenText', 'NNP'), ('OpenText', 'NNP'), (',', ','), ('The', 'DT'), ('Information', 'NNP'), ('Company', 'NNP'), (',', ','), ('enables', 'VBZ'), ('organizations', 'NNS'), ('gain', 'VB'), ('insight', 'JJ'), ('market', 'NN'), ('leading', 'VBG'), ('information', 'NN'), ('management', 'NN'), ('solutions', 'NNS'), (',', ','), ('on-premises', 'JJ'), ('cloud', 'NN'), ('.', '.')]

 (S
  About/IN
  (NP OpenText/NNP OpenText/NNP)
  ,/,
  (NP The/DT Information/NNP Company/NNP)
  ,/,
  enables/VBZ
  (NP organizations/NNS)
  gain/VB
  (NP insight/JJ market/NN)
  leading/VBG
  (NP information/NN management/NN solutions/NNS)
  ,/,
  (NP on-premises/JJ cloud/NN)
  ./.) 


>> Noun Phrases are: 
 ['OpenText OpenText', 'The Information Company', 'organizations', 'insight market', 'information management solutions', 'on-premises cloud']

>> Named Entities are: 
 [('ORGANIZATION', 'OpenText'), ('ORGANIZATION', 'Information Company')] 

>> Stemming using Porter Stemmer: 
 [('About', 'about'), ('OpenText', 'opentext'), ('OpenText', 'opentext'), (',', ','), ('The', 'the'), ('Information', 'inform'), ('Company', 'compani'), (',', ','), ('enables', 'enabl'), ('organizations', 'organ'), ('gain', 'gain'), ('insight', 'insight'), ('market', 'market'), ('leading', 'lead'), ('information', 'inform'), ('management', 'manag'), ('solutions', 'solut'), (',', ','), ('on-premises', 'on-premis'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('About', 'about'), ('OpenText', 'opentext'), ('OpenText', 'opentext'), (',', ','), ('The', 'the'), ('Information', 'inform'), ('Company', 'compani'), (',', ','), ('enables', 'enabl'), ('organizations', 'organ'), ('gain', 'gain'), ('insight', 'insight'), ('market', 'market'), ('leading', 'lead'), ('information', 'inform'), ('management', 'manag'), ('solutions', 'solut'), (',', ','), ('on-premises', 'on-premis'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('About', 'About'), ('OpenText', 'OpenText'), ('OpenText', 'OpenText'), (',', ','), ('The', 'The'), ('Information', 'Information'), ('Company', 'Company'), (',', ','), ('enables', 'enables'), ('organizations', 'organization'), ('gain', 'gain'), ('insight', 'insight'), ('market', 'market'), ('leading', 'leading'), ('information', 'information'), ('management', 'management'), ('solutions', 'solution'), (',', ','), ('on-premises', 'on-premises'), ('cloud', 'cloud'), ('.', '.')]



============================ Sentence 249 =============================

For  more information about OpenText (NASDAQ: OTEX, TSX: OTEX) visit: opentext.com. 


>> Tokens are: 
 ['For', 'information', 'OpenText', '(', 'NASDAQ', ':', 'OTEX', ',', 'TSX', ':', 'OTEX', ')', 'visit', ':', 'opentext.com', '.']

>> Bigrams are: 
 [('For', 'information'), ('information', 'OpenText'), ('OpenText', '('), ('(', 'NASDAQ'), ('NASDAQ', ':'), (':', 'OTEX'), ('OTEX', ','), (',', 'TSX'), ('TSX', ':'), (':', 'OTEX'), ('OTEX', ')'), (')', 'visit'), ('visit', ':'), (':', 'opentext.com'), ('opentext.com', '.')]

>> Trigrams are: 
 [('For', 'information', 'OpenText'), ('information', 'OpenText', '('), ('OpenText', '(', 'NASDAQ'), ('(', 'NASDAQ', ':'), ('NASDAQ', ':', 'OTEX'), (':', 'OTEX', ','), ('OTEX', ',', 'TSX'), (',', 'TSX', ':'), ('TSX', ':', 'OTEX'), (':', 'OTEX', ')'), ('OTEX', ')', 'visit'), (')', 'visit', ':'), ('visit', ':', 'opentext.com'), (':', 'opentext.com', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('information', 'NN'), ('OpenText', 'NNP'), ('(', '('), ('NASDAQ', 'NNP'), (':', ':'), ('OTEX', 'NNP'), (',', ','), ('TSX', 'NNP'), (':', ':'), ('OTEX', 'NNP'), (')', ')'), ('visit', 'NN'), (':', ':'), ('opentext.com', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP information/NN OpenText/NNP)
  (/(
  (NP NASDAQ/NNP)
  :/:
  (NP OTEX/NNP)
  ,/,
  (NP TSX/NNP)
  :/:
  (NP OTEX/NNP)
  )/)
  (NP visit/NN)
  :/:
  (NP opentext.com/NN)
  ./.) 


>> Noun Phrases are: 
 ['information OpenText', 'NASDAQ', 'OTEX', 'TSX', 'OTEX', 'visit', 'opentext.com']

>> Named Entities are: 
 [('ORGANIZATION', 'NASDAQ'), ('ORGANIZATION', 'TSX')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('information', 'inform'), ('OpenText', 'opentext'), ('(', '('), ('NASDAQ', 'nasdaq'), (':', ':'), ('OTEX', 'otex'), (',', ','), ('TSX', 'tsx'), (':', ':'), ('OTEX', 'otex'), (')', ')'), ('visit', 'visit'), (':', ':'), ('opentext.com', 'opentext.com'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('information', 'inform'), ('OpenText', 'opentext'), ('(', '('), ('NASDAQ', 'nasdaq'), (':', ':'), ('OTEX', 'otex'), (',', ','), ('TSX', 'tsx'), (':', ':'), ('OTEX', 'otex'), (')', ')'), ('visit', 'visit'), (':', ':'), ('opentext.com', 'opentext.com'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('information', 'information'), ('OpenText', 'OpenText'), ('(', '('), ('NASDAQ', 'NASDAQ'), (':', ':'), ('OTEX', 'OTEX'), (',', ','), ('TSX', 'TSX'), (':', ':'), ('OTEX', 'OTEX'), (')', ')'), ('visit', 'visit'), (':', ':'), ('opentext.com', 'opentext.com'), ('.', '.')]



============================ Sentence 250 =============================

Connect with us:  OpenText CEO Mark Barrenecheas blog  Twitter | LinkedIn   Learn more   OpenText Magellan    OpenText Magellan    product overview    OpenText AI white paper     OpenText Magellan infographic   Join the conversation   Keep up to date   Watch the videos  1	Forbes,	5 Ways AI Is Transforming The Customer Experience,	April	16,	2019. 


>> Tokens are: 
 ['Connect', 'us', ':', '', 'OpenText', 'CEO', 'Mark', 'Barrenechea', '', 'blog', '', 'Twitter', '|', 'LinkedIn', 'Learn', 'OpenText', 'Magellan', 'OpenText', 'Magellan', 'product', 'overview', 'OpenText', 'AI', 'white', 'paper', 'OpenText', 'Magellan', 'infographic', 'Join', 'conversation', 'Keep', 'date', 'Watch', 'videos', '1', 'Forbes', ',', '5', 'Ways', 'AI', 'Is', 'Transforming', 'The', 'Customer', 'Experience', ',', 'April', '16', ',', '2019', '.']

>> Bigrams are: 
 [('Connect', 'us'), ('us', ':'), (':', ''), ('', 'OpenText'), ('OpenText', 'CEO'), ('CEO', 'Mark'), ('Mark', 'Barrenechea'), ('Barrenechea', ''), ('', 'blog'), ('blog', ''), ('', 'Twitter'), ('Twitter', '|'), ('|', 'LinkedIn'), ('LinkedIn', 'Learn'), ('Learn', 'OpenText'), ('OpenText', 'Magellan'), ('Magellan', 'OpenText'), ('OpenText', 'Magellan'), ('Magellan', 'product'), ('product', 'overview'), ('overview', 'OpenText'), ('OpenText', 'AI'), ('AI', 'white'), ('white', 'paper'), ('paper', 'OpenText'), ('OpenText', 'Magellan'), ('Magellan', 'infographic'), ('infographic', 'Join'), ('Join', 'conversation'), ('conversation', 'Keep'), ('Keep', 'date'), ('date', 'Watch'), ('Watch', 'videos'), ('videos', '1'), ('1', 'Forbes'), ('Forbes', ','), (',', '5'), ('5', 'Ways'), ('Ways', 'AI'), ('AI', 'Is'), ('Is', 'Transforming'), ('Transforming', 'The'), ('The', 'Customer'), ('Customer', 'Experience'), ('Experience', ','), (',', 'April'), ('April', '16'), ('16', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Connect', 'us', ':'), ('us', ':', ''), (':', '', 'OpenText'), ('', 'OpenText', 'CEO'), ('OpenText', 'CEO', 'Mark'), ('CEO', 'Mark', 'Barrenechea'), ('Mark', 'Barrenechea', ''), ('Barrenechea', '', 'blog'), ('', 'blog', ''), ('blog', '', 'Twitter'), ('', 'Twitter', '|'), ('Twitter', '|', 'LinkedIn'), ('|', 'LinkedIn', 'Learn'), ('LinkedIn', 'Learn', 'OpenText'), ('Learn', 'OpenText', 'Magellan'), ('OpenText', 'Magellan', 'OpenText'), ('Magellan', 'OpenText', 'Magellan'), ('OpenText', 'Magellan', 'product'), ('Magellan', 'product', 'overview'), ('product', 'overview', 'OpenText'), ('overview', 'OpenText', 'AI'), ('OpenText', 'AI', 'white'), ('AI', 'white', 'paper'), ('white', 'paper', 'OpenText'), ('paper', 'OpenText', 'Magellan'), ('OpenText', 'Magellan', 'infographic'), ('Magellan', 'infographic', 'Join'), ('infographic', 'Join', 'conversation'), ('Join', 'conversation', 'Keep'), ('conversation', 'Keep', 'date'), ('Keep', 'date', 'Watch'), ('date', 'Watch', 'videos'), ('Watch', 'videos', '1'), ('videos', '1', 'Forbes'), ('1', 'Forbes', ','), ('Forbes', ',', '5'), (',', '5', 'Ways'), ('5', 'Ways', 'AI'), ('Ways', 'AI', 'Is'), ('AI', 'Is', 'Transforming'), ('Is', 'Transforming', 'The'), ('Transforming', 'The', 'Customer'), ('The', 'Customer', 'Experience'), ('Customer', 'Experience', ','), ('Experience', ',', 'April'), (',', 'April', '16'), ('April', '16', ','), ('16', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Connect', 'JJ'), ('us', 'PRP'), (':', ':'), ('', 'NN'), ('OpenText', 'NNP'), ('CEO', 'NNP'), ('Mark', 'NNP'), ('Barrenechea', 'NNP'), ('', 'NNP'), ('blog', 'NN'), ('', 'NNP'), ('Twitter', 'NNP'), ('|', 'NNP'), ('LinkedIn', 'NNP'), ('Learn', 'NNP'), ('OpenText', 'NNP'), ('Magellan', 'NNP'), ('OpenText', 'NNP'), ('Magellan', 'NNP'), ('product', 'NN'), ('overview', 'NN'), ('OpenText', 'NNP'), ('AI', 'NNP'), ('white', 'JJ'), ('paper', 'NN'), ('OpenText', 'NNP'), ('Magellan', 'NNP'), ('infographic', 'JJ'), ('Join', 'NNP'), ('conversation', 'NN'), ('Keep', 'NNP'), ('date', 'NN'), ('Watch', 'NNP'), ('videos', 'VBZ'), ('1', 'CD'), ('Forbes', 'NNP'), (',', ','), ('5', 'CD'), ('Ways', 'NNP'), ('AI', 'NNP'), ('Is', 'VBZ'), ('Transforming', 'VBG'), ('The', 'DT'), ('Customer', 'NNP'), ('Experience', 'NNP'), (',', ','), ('April', 'NNP'), ('16', 'CD'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  Connect/JJ
  us/PRP
  :/:
  (NP
    /NN
    OpenText/NNP
    CEO/NNP
    Mark/NNP
    Barrenechea/NNP
    /NNP
    blog/NN
    /NNP
    Twitter/NNP
    |/NNP
    LinkedIn/NNP
    Learn/NNP
    OpenText/NNP
    Magellan/NNP
    OpenText/NNP
    Magellan/NNP
    product/NN
    overview/NN
    OpenText/NNP
    AI/NNP)
  (NP white/JJ paper/NN OpenText/NNP Magellan/NNP)
  (NP
    infographic/JJ
    Join/NNP
    conversation/NN
    Keep/NNP
    date/NN
    Watch/NNP)
  videos/VBZ
  1/CD
  (NP Forbes/NNP)
  ,/,
  5/CD
  (NP Ways/NNP AI/NNP)
  Is/VBZ
  Transforming/VBG
  (NP The/DT Customer/NNP Experience/NNP)
  ,/,
  (NP April/NNP)
  16/CD
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 [' OpenText CEO Mark Barrenechea  blog  Twitter | LinkedIn Learn OpenText Magellan OpenText Magellan product overview OpenText AI', 'white paper OpenText Magellan', 'infographic Join conversation Keep date Watch', 'Forbes', 'Ways AI', 'The Customer Experience', 'April']

>> Named Entities are: 
 [('ORGANIZATION', 'OpenText'), ('PERSON', 'Mark Barrenechea'), ('ORGANIZATION', 'OpenText'), ('PERSON', 'Watch'), ('ORGANIZATION', 'Customer Experience')] 

>> Stemming using Porter Stemmer: 
 [('Connect', 'connect'), ('us', 'us'), (':', ':'), ('', ''), ('OpenText', 'opentext'), ('CEO', 'ceo'), ('Mark', 'mark'), ('Barrenechea', 'barrenechea'), ('', ''), ('blog', 'blog'), ('', ''), ('Twitter', 'twitter'), ('|', '|'), ('LinkedIn', 'linkedin'), ('Learn', 'learn'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('product', 'product'), ('overview', 'overview'), ('OpenText', 'opentext'), ('AI', 'ai'), ('white', 'white'), ('paper', 'paper'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('infographic', 'infograph'), ('Join', 'join'), ('conversation', 'convers'), ('Keep', 'keep'), ('date', 'date'), ('Watch', 'watch'), ('videos', 'video'), ('1', '1'), ('Forbes', 'forb'), (',', ','), ('5', '5'), ('Ways', 'way'), ('AI', 'ai'), ('Is', 'is'), ('Transforming', 'transform'), ('The', 'the'), ('Customer', 'custom'), ('Experience', 'experi'), (',', ','), ('April', 'april'), ('16', '16'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Connect', 'connect'), ('us', 'us'), (':', ':'), ('', ''), ('OpenText', 'opentext'), ('CEO', 'ceo'), ('Mark', 'mark'), ('Barrenechea', 'barrenechea'), ('', ''), ('blog', 'blog'), ('', ''), ('Twitter', 'twitter'), ('|', '|'), ('LinkedIn', 'linkedin'), ('Learn', 'learn'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('product', 'product'), ('overview', 'overview'), ('OpenText', 'opentext'), ('AI', 'ai'), ('white', 'white'), ('paper', 'paper'), ('OpenText', 'opentext'), ('Magellan', 'magellan'), ('infographic', 'infograph'), ('Join', 'join'), ('conversation', 'convers'), ('Keep', 'keep'), ('date', 'date'), ('Watch', 'watch'), ('videos', 'video'), ('1', '1'), ('Forbes', 'forb'), (',', ','), ('5', '5'), ('Ways', 'way'), ('AI', 'ai'), ('Is', 'is'), ('Transforming', 'transform'), ('The', 'the'), ('Customer', 'custom'), ('Experience', 'experi'), (',', ','), ('April', 'april'), ('16', '16'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Connect', 'Connect'), ('us', 'u'), (':', ':'), ('', ''), ('OpenText', 'OpenText'), ('CEO', 'CEO'), ('Mark', 'Mark'), ('Barrenechea', 'Barrenechea'), ('', ''), ('blog', 'blog'), ('', ''), ('Twitter', 'Twitter'), ('|', '|'), ('LinkedIn', 'LinkedIn'), ('Learn', 'Learn'), ('OpenText', 'OpenText'), ('Magellan', 'Magellan'), ('OpenText', 'OpenText'), ('Magellan', 'Magellan'), ('product', 'product'), ('overview', 'overview'), ('OpenText', 'OpenText'), ('AI', 'AI'), ('white', 'white'), ('paper', 'paper'), ('OpenText', 'OpenText'), ('Magellan', 'Magellan'), ('infographic', 'infographic'), ('Join', 'Join'), ('conversation', 'conversation'), ('Keep', 'Keep'), ('date', 'date'), ('Watch', 'Watch'), ('videos', 'video'), ('1', '1'), ('Forbes', 'Forbes'), (',', ','), ('5', '5'), ('Ways', 'Ways'), ('AI', 'AI'), ('Is', 'Is'), ('Transforming', 'Transforming'), ('The', 'The'), ('Customer', 'Customer'), ('Experience', 'Experience'), (',', ','), ('April', 'April'), ('16', '16'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 251 =============================

2	Gartner,	Gartner Says AI Augmentation Will Create $2.9 Trillion of Business Value in 2021,	August	5,	2019. 


>> Tokens are: 
 ['2', 'Gartner', ',', 'Gartner', 'Says', 'AI', 'Augmentation', 'Will', 'Create', '$', '2.9', 'Trillion', 'Business', 'Value', '2021', ',', 'August', '5', ',', '2019', '.']

>> Bigrams are: 
 [('2', 'Gartner'), ('Gartner', ','), (',', 'Gartner'), ('Gartner', 'Says'), ('Says', 'AI'), ('AI', 'Augmentation'), ('Augmentation', 'Will'), ('Will', 'Create'), ('Create', '$'), ('$', '2.9'), ('2.9', 'Trillion'), ('Trillion', 'Business'), ('Business', 'Value'), ('Value', '2021'), ('2021', ','), (',', 'August'), ('August', '5'), ('5', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('2', 'Gartner', ','), ('Gartner', ',', 'Gartner'), (',', 'Gartner', 'Says'), ('Gartner', 'Says', 'AI'), ('Says', 'AI', 'Augmentation'), ('AI', 'Augmentation', 'Will'), ('Augmentation', 'Will', 'Create'), ('Will', 'Create', '$'), ('Create', '$', '2.9'), ('$', '2.9', 'Trillion'), ('2.9', 'Trillion', 'Business'), ('Trillion', 'Business', 'Value'), ('Business', 'Value', '2021'), ('Value', '2021', ','), ('2021', ',', 'August'), (',', 'August', '5'), ('August', '5', ','), ('5', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('2', 'CD'), ('Gartner', 'NNP'), (',', ','), ('Gartner', 'NNP'), ('Says', 'NNP'), ('AI', 'NNP'), ('Augmentation', 'NNP'), ('Will', 'NNP'), ('Create', 'NNP'), ('$', '$'), ('2.9', 'CD'), ('Trillion', 'NNP'), ('Business', 'NNP'), ('Value', 'NNP'), ('2021', 'CD'), (',', ','), ('August', 'NNP'), ('5', 'CD'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  2/CD
  (NP Gartner/NNP)
  ,/,
  (NP
    Gartner/NNP
    Says/NNP
    AI/NNP
    Augmentation/NNP
    Will/NNP
    Create/NNP)
  $/$
  2.9/CD
  (NP Trillion/NNP Business/NNP Value/NNP)
  2021/CD
  ,/,
  (NP August/NNP)
  5/CD
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Gartner', 'Gartner Says AI Augmentation Will Create', 'Trillion Business Value', 'August']

>> Named Entities are: 
 [('PERSON', 'Gartner'), ('PERSON', 'Gartner Says AI'), ('PERSON', 'Will Create')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('Gartner', 'gartner'), (',', ','), ('Gartner', 'gartner'), ('Says', 'say'), ('AI', 'ai'), ('Augmentation', 'augment'), ('Will', 'will'), ('Create', 'creat'), ('$', '$'), ('2.9', '2.9'), ('Trillion', 'trillion'), ('Business', 'busi'), ('Value', 'valu'), ('2021', '2021'), (',', ','), ('August', 'august'), ('5', '5'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('Gartner', 'gartner'), (',', ','), ('Gartner', 'gartner'), ('Says', 'say'), ('AI', 'ai'), ('Augmentation', 'augment'), ('Will', 'will'), ('Create', 'creat'), ('$', '$'), ('2.9', '2.9'), ('Trillion', 'trillion'), ('Business', 'busi'), ('Value', 'valu'), ('2021', '2021'), (',', ','), ('August', 'august'), ('5', '5'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('Gartner', 'Gartner'), (',', ','), ('Gartner', 'Gartner'), ('Says', 'Says'), ('AI', 'AI'), ('Augmentation', 'Augmentation'), ('Will', 'Will'), ('Create', 'Create'), ('$', '$'), ('2.9', '2.9'), ('Trillion', 'Trillion'), ('Business', 'Business'), ('Value', 'Value'), ('2021', '2021'), (',', ','), ('August', 'August'), ('5', '5'), (',', ','), ('2019', '2019'), ('.', '.')]

