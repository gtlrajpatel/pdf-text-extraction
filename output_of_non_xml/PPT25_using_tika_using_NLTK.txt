				 *** Text Processing using NLTK *** 


============================ Sentence 1 =============================

W5 of Computer Engineering (Why, What, When, Where, How)   Prof. Naimish R. Vadodariya      8866215253      naimish.vadodariya@darshan.ac.in         2170715 – Data Mining & Business Intelligence Unit-4 Data Pre-processing      Outline Why to preprocess data? 


>> Tokens are: 
 ['W5', 'Computer', 'Engineering', '(', 'Why', ',', 'What', ',', 'When', ',', 'Where', ',', 'How', ')', 'Prof.', 'Naimish', 'R.', 'Vadodariya', '8866215253', 'naimish.vadodariya', '@', 'darshan.ac.in', '2170715', '–', 'Data', 'Mining', '&', 'Business', 'Intelligence', 'Unit-4', 'Data', 'Pre-processing', 'Outline', 'Why', 'preprocess', 'data', '?']

>> Bigrams are: 
 [('W5', 'Computer'), ('Computer', 'Engineering'), ('Engineering', '('), ('(', 'Why'), ('Why', ','), (',', 'What'), ('What', ','), (',', 'When'), ('When', ','), (',', 'Where'), ('Where', ','), (',', 'How'), ('How', ')'), (')', 'Prof.'), ('Prof.', 'Naimish'), ('Naimish', 'R.'), ('R.', 'Vadodariya'), ('Vadodariya', '8866215253'), ('8866215253', 'naimish.vadodariya'), ('naimish.vadodariya', '@'), ('@', 'darshan.ac.in'), ('darshan.ac.in', '2170715'), ('2170715', '–'), ('–', 'Data'), ('Data', 'Mining'), ('Mining', '&'), ('&', 'Business'), ('Business', 'Intelligence'), ('Intelligence', 'Unit-4'), ('Unit-4', 'Data'), ('Data', 'Pre-processing'), ('Pre-processing', 'Outline'), ('Outline', 'Why'), ('Why', 'preprocess'), ('preprocess', 'data'), ('data', '?')]

>> Trigrams are: 
 [('W5', 'Computer', 'Engineering'), ('Computer', 'Engineering', '('), ('Engineering', '(', 'Why'), ('(', 'Why', ','), ('Why', ',', 'What'), (',', 'What', ','), ('What', ',', 'When'), (',', 'When', ','), ('When', ',', 'Where'), (',', 'Where', ','), ('Where', ',', 'How'), (',', 'How', ')'), ('How', ')', 'Prof.'), (')', 'Prof.', 'Naimish'), ('Prof.', 'Naimish', 'R.'), ('Naimish', 'R.', 'Vadodariya'), ('R.', 'Vadodariya', '8866215253'), ('Vadodariya', '8866215253', 'naimish.vadodariya'), ('8866215253', 'naimish.vadodariya', '@'), ('naimish.vadodariya', '@', 'darshan.ac.in'), ('@', 'darshan.ac.in', '2170715'), ('darshan.ac.in', '2170715', '–'), ('2170715', '–', 'Data'), ('–', 'Data', 'Mining'), ('Data', 'Mining', '&'), ('Mining', '&', 'Business'), ('&', 'Business', 'Intelligence'), ('Business', 'Intelligence', 'Unit-4'), ('Intelligence', 'Unit-4', 'Data'), ('Unit-4', 'Data', 'Pre-processing'), ('Data', 'Pre-processing', 'Outline'), ('Pre-processing', 'Outline', 'Why'), ('Outline', 'Why', 'preprocess'), ('Why', 'preprocess', 'data'), ('preprocess', 'data', '?')]

>> POS Tags are: 
 [('W5', 'NNP'), ('Computer', 'NNP'), ('Engineering', 'NNP'), ('(', '('), ('Why', 'WRB'), (',', ','), ('What', 'WP'), (',', ','), ('When', 'WRB'), (',', ','), ('Where', 'NNP'), (',', ','), ('How', 'NNP'), (')', ')'), ('Prof.', 'NNP'), ('Naimish', 'NNP'), ('R.', 'NNP'), ('Vadodariya', 'NNP'), ('8866215253', 'CD'), ('naimish.vadodariya', 'NN'), ('@', 'NNP'), ('darshan.ac.in', 'VBZ'), ('2170715', 'CD'), ('–', 'NN'), ('Data', 'NNP'), ('Mining', 'NNP'), ('&', 'CC'), ('Business', 'NNP'), ('Intelligence', 'NNP'), ('Unit-4', 'NNP'), ('Data', 'NNP'), ('Pre-processing', 'NNP'), ('Outline', 'NNP'), ('Why', 'WRB'), ('preprocess', 'NN'), ('data', 'NNS'), ('?', '.')]

 (S
  (NP W5/NNP Computer/NNP Engineering/NNP)
  (/(
  Why/WRB
  ,/,
  What/WP
  ,/,
  When/WRB
  ,/,
  (NP Where/NNP)
  ,/,
  (NP How/NNP)
  )/)
  (NP Prof./NNP Naimish/NNP R./NNP Vadodariya/NNP)
  8866215253/CD
  (NP naimish.vadodariya/NN @/NNP)
  darshan.ac.in/VBZ
  2170715/CD
  (NP –/NN Data/NNP Mining/NNP)
  &/CC
  (NP
    Business/NNP
    Intelligence/NNP
    Unit-4/NNP
    Data/NNP
    Pre-processing/NNP
    Outline/NNP)
  Why/WRB
  (NP preprocess/NN data/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['W5 Computer Engineering', 'Where', 'How', 'Prof. Naimish R. Vadodariya', 'naimish.vadodariya @', '– Data Mining', 'Business Intelligence Unit-4 Data Pre-processing Outline', 'preprocess data']

>> Named Entities are: 
 [('PERSON', 'Where'), ('GPE', 'How'), ('PERSON', 'Naimish R. Vadodariya'), ('PERSON', 'Data Mining'), ('ORGANIZATION', 'Business Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('W5', 'w5'), ('Computer', 'comput'), ('Engineering', 'engin'), ('(', '('), ('Why', 'whi'), (',', ','), ('What', 'what'), (',', ','), ('When', 'when'), (',', ','), ('Where', 'where'), (',', ','), ('How', 'how'), (')', ')'), ('Prof.', 'prof.'), ('Naimish', 'naimish'), ('R.', 'r.'), ('Vadodariya', 'vadodariya'), ('8866215253', '8866215253'), ('naimish.vadodariya', 'naimish.vadodariya'), ('@', '@'), ('darshan.ac.in', 'darshan.ac.in'), ('2170715', '2170715'), ('–', '–'), ('Data', 'data'), ('Mining', 'mine'), ('&', '&'), ('Business', 'busi'), ('Intelligence', 'intellig'), ('Unit-4', 'unit-4'), ('Data', 'data'), ('Pre-processing', 'pre-process'), ('Outline', 'outlin'), ('Why', 'whi'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('W5', 'w5'), ('Computer', 'comput'), ('Engineering', 'engin'), ('(', '('), ('Why', 'whi'), (',', ','), ('What', 'what'), (',', ','), ('When', 'when'), (',', ','), ('Where', 'where'), (',', ','), ('How', 'how'), (')', ')'), ('Prof.', 'prof.'), ('Naimish', 'naimish'), ('R.', 'r.'), ('Vadodariya', 'vadodariya'), ('8866215253', '8866215253'), ('naimish.vadodariya', 'naimish.vadodariya'), ('@', '@'), ('darshan.ac.in', 'darshan.ac.in'), ('2170715', '2170715'), ('–', '–'), ('Data', 'data'), ('Mining', 'mine'), ('&', '&'), ('Business', 'busi'), ('Intelligence', 'intellig'), ('Unit-4', 'unit-4'), ('Data', 'data'), ('Pre-processing', 'pre-process'), ('Outline', 'outlin'), ('Why', 'whi'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]

>> Lemmatization: 
 [('W5', 'W5'), ('Computer', 'Computer'), ('Engineering', 'Engineering'), ('(', '('), ('Why', 'Why'), (',', ','), ('What', 'What'), (',', ','), ('When', 'When'), (',', ','), ('Where', 'Where'), (',', ','), ('How', 'How'), (')', ')'), ('Prof.', 'Prof.'), ('Naimish', 'Naimish'), ('R.', 'R.'), ('Vadodariya', 'Vadodariya'), ('8866215253', '8866215253'), ('naimish.vadodariya', 'naimish.vadodariya'), ('@', '@'), ('darshan.ac.in', 'darshan.ac.in'), ('2170715', '2170715'), ('–', '–'), ('Data', 'Data'), ('Mining', 'Mining'), ('&', '&'), ('Business', 'Business'), ('Intelligence', 'Intelligence'), ('Unit-4', 'Unit-4'), ('Data', 'Data'), ('Pre-processing', 'Pre-processing'), ('Outline', 'Outline'), ('Why', 'Why'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]



============================ Sentence 2 =============================

Mean, median, mode & range Attribute types Data preprocessing tasks Data cleaning 	 Data integration  Data transformation 	 Data reduction 	 Data mining task primitives 	         	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Why to preprocess data? 


>> Tokens are: 
 ['Mean', ',', 'median', ',', 'mode', '&', 'range', 'Attribute', 'types', 'Data', 'preprocessing', 'tasks', 'Data', 'cleaning', 'Data', 'integration', 'Data', 'transformation', 'Data', 'reduction', 'Data', 'mining', 'task', 'primitives', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Why', 'preprocess', 'data', '?']

>> Bigrams are: 
 [('Mean', ','), (',', 'median'), ('median', ','), (',', 'mode'), ('mode', '&'), ('&', 'range'), ('range', 'Attribute'), ('Attribute', 'types'), ('types', 'Data'), ('Data', 'preprocessing'), ('preprocessing', 'tasks'), ('tasks', 'Data'), ('Data', 'cleaning'), ('cleaning', 'Data'), ('Data', 'integration'), ('integration', 'Data'), ('Data', 'transformation'), ('transformation', 'Data'), ('Data', 'reduction'), ('reduction', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Why'), ('Why', 'preprocess'), ('preprocess', 'data'), ('data', '?')]

>> Trigrams are: 
 [('Mean', ',', 'median'), (',', 'median', ','), ('median', ',', 'mode'), (',', 'mode', '&'), ('mode', '&', 'range'), ('&', 'range', 'Attribute'), ('range', 'Attribute', 'types'), ('Attribute', 'types', 'Data'), ('types', 'Data', 'preprocessing'), ('Data', 'preprocessing', 'tasks'), ('preprocessing', 'tasks', 'Data'), ('tasks', 'Data', 'cleaning'), ('Data', 'cleaning', 'Data'), ('cleaning', 'Data', 'integration'), ('Data', 'integration', 'Data'), ('integration', 'Data', 'transformation'), ('Data', 'transformation', 'Data'), ('transformation', 'Data', 'reduction'), ('Data', 'reduction', 'Data'), ('reduction', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', 'Unit'), ('primitives', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Why'), ('›', 'Why', 'preprocess'), ('Why', 'preprocess', 'data'), ('preprocess', 'data', '?')]

>> POS Tags are: 
 [('Mean', 'NNP'), (',', ','), ('median', 'NN'), (',', ','), ('mode', 'NN'), ('&', 'CC'), ('range', 'NN'), ('Attribute', 'NNP'), ('types', 'VBZ'), ('Data', 'NNP'), ('preprocessing', 'NN'), ('tasks', 'NNS'), ('Data', 'NNP'), ('cleaning', 'NN'), ('Data', 'NNP'), ('integration', 'NN'), ('Data', 'NNP'), ('transformation', 'NN'), ('Data', 'NNP'), ('reduction', 'NN'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Why', 'WRB'), ('preprocess', 'NN'), ('data', 'NNS'), ('?', '.')]

 (S
  (NP Mean/NNP)
  ,/,
  (NP median/NN)
  ,/,
  (NP mode/NN)
  &/CC
  (NP range/NN Attribute/NNP)
  types/VBZ
  (NP
    Data/NNP
    preprocessing/NN
    tasks/NNS
    Data/NNP
    cleaning/NN
    Data/NNP
    integration/NN
    Data/NNP
    transformation/NN
    Data/NNP
    reduction/NN
    Data/NNP
    mining/NN
    task/NN
    primitives/NNS
    Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  Why/WRB
  (NP preprocess/NN data/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['Mean', 'median', 'mode', 'range Attribute', 'Data preprocessing tasks Data cleaning Data integration Data transformation Data reduction Data mining task primitives Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'preprocess data']

>> Named Entities are: 
 [('GPE', 'Mean'), ('PERSON', 'Attribute'), ('PERSON', 'Data'), ('PERSON', 'Data'), ('PERSON', 'Data'), ('PERSON', 'Data'), ('PERSON', 'Data'), ('PERSON', 'Data'), ('PERSON', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Mean', 'mean'), (',', ','), ('median', 'median'), (',', ','), ('mode', 'mode'), ('&', '&'), ('range', 'rang'), ('Attribute', 'attribut'), ('types', 'type'), ('Data', 'data'), ('preprocessing', 'preprocess'), ('tasks', 'task'), ('Data', 'data'), ('cleaning', 'clean'), ('Data', 'data'), ('integration', 'integr'), ('Data', 'data'), ('transformation', 'transform'), ('Data', 'data'), ('reduction', 'reduct'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'whi'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Mean', 'mean'), (',', ','), ('median', 'median'), (',', ','), ('mode', 'mode'), ('&', '&'), ('range', 'rang'), ('Attribute', 'attribut'), ('types', 'type'), ('Data', 'data'), ('preprocessing', 'preprocess'), ('tasks', 'task'), ('Data', 'data'), ('cleaning', 'clean'), ('Data', 'data'), ('integration', 'integr'), ('Data', 'data'), ('transformation', 'transform'), ('Data', 'data'), ('reduction', 'reduct'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'whi'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]

>> Lemmatization: 
 [('Mean', 'Mean'), (',', ','), ('median', 'median'), (',', ','), ('mode', 'mode'), ('&', '&'), ('range', 'range'), ('Attribute', 'Attribute'), ('types', 'type'), ('Data', 'Data'), ('preprocessing', 'preprocessing'), ('tasks', 'task'), ('Data', 'Data'), ('cleaning', 'cleaning'), ('Data', 'Data'), ('integration', 'integration'), ('Data', 'Data'), ('transformation', 'transformation'), ('Data', 'Data'), ('reduction', 'reduction'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'Why'), ('preprocess', 'preprocess'), ('data', 'data'), ('?', '?')]



============================ Sentence 3 =============================

Real world data are generally “dirty” Incomplete: Missing attribute values, lack of certain attributes of interest, or containing only aggregate data. 


>> Tokens are: 
 ['Real', 'world', 'data', 'generally', '“', 'dirty', '”', 'Incomplete', ':', 'Missing', 'attribute', 'values', ',', 'lack', 'certain', 'attributes', 'interest', ',', 'containing', 'aggregate', 'data', '.']

>> Bigrams are: 
 [('Real', 'world'), ('world', 'data'), ('data', 'generally'), ('generally', '“'), ('“', 'dirty'), ('dirty', '”'), ('”', 'Incomplete'), ('Incomplete', ':'), (':', 'Missing'), ('Missing', 'attribute'), ('attribute', 'values'), ('values', ','), (',', 'lack'), ('lack', 'certain'), ('certain', 'attributes'), ('attributes', 'interest'), ('interest', ','), (',', 'containing'), ('containing', 'aggregate'), ('aggregate', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Real', 'world', 'data'), ('world', 'data', 'generally'), ('data', 'generally', '“'), ('generally', '“', 'dirty'), ('“', 'dirty', '”'), ('dirty', '”', 'Incomplete'), ('”', 'Incomplete', ':'), ('Incomplete', ':', 'Missing'), (':', 'Missing', 'attribute'), ('Missing', 'attribute', 'values'), ('attribute', 'values', ','), ('values', ',', 'lack'), (',', 'lack', 'certain'), ('lack', 'certain', 'attributes'), ('certain', 'attributes', 'interest'), ('attributes', 'interest', ','), ('interest', ',', 'containing'), (',', 'containing', 'aggregate'), ('containing', 'aggregate', 'data'), ('aggregate', 'data', '.')]

>> POS Tags are: 
 [('Real', 'JJ'), ('world', 'NN'), ('data', 'NNS'), ('generally', 'RB'), ('“', 'NNP'), ('dirty', 'NN'), ('”', 'NNP'), ('Incomplete', 'NNP'), (':', ':'), ('Missing', 'VBG'), ('attribute', 'NN'), ('values', 'NNS'), (',', ','), ('lack', 'VBP'), ('certain', 'JJ'), ('attributes', 'NNS'), ('interest', 'NN'), (',', ','), ('containing', 'VBG'), ('aggregate', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Real/JJ world/NN data/NNS)
  generally/RB
  (NP “/NNP dirty/NN ”/NNP Incomplete/NNP)
  :/:
  Missing/VBG
  (NP attribute/NN values/NNS)
  ,/,
  lack/VBP
  (NP certain/JJ attributes/NNS interest/NN)
  ,/,
  containing/VBG
  (NP aggregate/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Real world data', '“ dirty ” Incomplete', 'attribute values', 'certain attributes interest', 'aggregate data']

>> Named Entities are: 
 [('GPE', 'Real')] 

>> Stemming using Porter Stemmer: 
 [('Real', 'real'), ('world', 'world'), ('data', 'data'), ('generally', 'gener'), ('“', '“'), ('dirty', 'dirti'), ('”', '”'), ('Incomplete', 'incomplet'), (':', ':'), ('Missing', 'miss'), ('attribute', 'attribut'), ('values', 'valu'), (',', ','), ('lack', 'lack'), ('certain', 'certain'), ('attributes', 'attribut'), ('interest', 'interest'), (',', ','), ('containing', 'contain'), ('aggregate', 'aggreg'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Real', 'real'), ('world', 'world'), ('data', 'data'), ('generally', 'general'), ('“', '“'), ('dirty', 'dirti'), ('”', '”'), ('Incomplete', 'incomplet'), (':', ':'), ('Missing', 'miss'), ('attribute', 'attribut'), ('values', 'valu'), (',', ','), ('lack', 'lack'), ('certain', 'certain'), ('attributes', 'attribut'), ('interest', 'interest'), (',', ','), ('containing', 'contain'), ('aggregate', 'aggreg'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Real', 'Real'), ('world', 'world'), ('data', 'data'), ('generally', 'generally'), ('“', '“'), ('dirty', 'dirty'), ('”', '”'), ('Incomplete', 'Incomplete'), (':', ':'), ('Missing', 'Missing'), ('attribute', 'attribute'), ('values', 'value'), (',', ','), ('lack', 'lack'), ('certain', 'certain'), ('attributes', 'attribute'), ('interest', 'interest'), (',', ','), ('containing', 'containing'), ('aggregate', 'aggregate'), ('data', 'data'), ('.', '.')]



============================ Sentence 4 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 5 =============================

Occupation=“ ”  Noisy: Containing errors or outliers. 


>> Tokens are: 
 ['Occupation=', '“', '”', 'Noisy', ':', 'Containing', 'errors', 'outliers', '.']

>> Bigrams are: 
 [('Occupation=', '“'), ('“', '”'), ('”', 'Noisy'), ('Noisy', ':'), (':', 'Containing'), ('Containing', 'errors'), ('errors', 'outliers'), ('outliers', '.')]

>> Trigrams are: 
 [('Occupation=', '“', '”'), ('“', '”', 'Noisy'), ('”', 'Noisy', ':'), ('Noisy', ':', 'Containing'), (':', 'Containing', 'errors'), ('Containing', 'errors', 'outliers'), ('errors', 'outliers', '.')]

>> POS Tags are: 
 [('Occupation=', 'NNP'), ('“', 'NNP'), ('”', 'NNP'), ('Noisy', 'NNP'), (':', ':'), ('Containing', 'JJ'), ('errors', 'NNS'), ('outliers', 'NNS'), ('.', '.')]

 (S
  (NP Occupation=/NNP “/NNP ”/NNP Noisy/NNP)
  :/:
  (NP Containing/JJ errors/NNS outliers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Occupation= “ ” Noisy', 'Containing errors outliers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Occupation=', 'occupation='), ('“', '“'), ('”', '”'), ('Noisy', 'noisi'), (':', ':'), ('Containing', 'contain'), ('errors', 'error'), ('outliers', 'outlier'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Occupation=', 'occupation='), ('“', '“'), ('”', '”'), ('Noisy', 'noisi'), (':', ':'), ('Containing', 'contain'), ('errors', 'error'), ('outliers', 'outlier'), ('.', '.')]

>> Lemmatization: 
 [('Occupation=', 'Occupation='), ('“', '“'), ('”', '”'), ('Noisy', 'Noisy'), (':', ':'), ('Containing', 'Containing'), ('errors', 'error'), ('outliers', 'outlier'), ('.', '.')]



============================ Sentence 6 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 7 =============================

Salary=“abcxy” Inconsistent: Containing similarity in codes or names. 


>> Tokens are: 
 ['Salary=', '“', 'abcxy', '”', 'Inconsistent', ':', 'Containing', 'similarity', 'codes', 'names', '.']

>> Bigrams are: 
 [('Salary=', '“'), ('“', 'abcxy'), ('abcxy', '”'), ('”', 'Inconsistent'), ('Inconsistent', ':'), (':', 'Containing'), ('Containing', 'similarity'), ('similarity', 'codes'), ('codes', 'names'), ('names', '.')]

>> Trigrams are: 
 [('Salary=', '“', 'abcxy'), ('“', 'abcxy', '”'), ('abcxy', '”', 'Inconsistent'), ('”', 'Inconsistent', ':'), ('Inconsistent', ':', 'Containing'), (':', 'Containing', 'similarity'), ('Containing', 'similarity', 'codes'), ('similarity', 'codes', 'names'), ('codes', 'names', '.')]

>> POS Tags are: 
 [('Salary=', 'NNP'), ('“', 'NNP'), ('abcxy', 'VBZ'), ('”', 'JJ'), ('Inconsistent', 'NN'), (':', ':'), ('Containing', 'NNP'), ('similarity', 'NN'), ('codes', 'NNS'), ('names', 'NNS'), ('.', '.')]

 (S
  (NP Salary=/NNP “/NNP)
  abcxy/VBZ
  (NP ”/JJ Inconsistent/NN)
  :/:
  (NP Containing/NNP similarity/NN codes/NNS names/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Salary= “', '” Inconsistent', 'Containing similarity codes names']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Salary=', 'salary='), ('“', '“'), ('abcxy', 'abcxi'), ('”', '”'), ('Inconsistent', 'inconsist'), (':', ':'), ('Containing', 'contain'), ('similarity', 'similar'), ('codes', 'code'), ('names', 'name'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Salary=', 'salary='), ('“', '“'), ('abcxy', 'abcxi'), ('”', '”'), ('Inconsistent', 'inconsist'), (':', ':'), ('Containing', 'contain'), ('similarity', 'similar'), ('codes', 'code'), ('names', 'name'), ('.', '.')]

>> Lemmatization: 
 [('Salary=', 'Salary='), ('“', '“'), ('abcxy', 'abcxy'), ('”', '”'), ('Inconsistent', 'Inconsistent'), (':', ':'), ('Containing', 'Containing'), ('similarity', 'similarity'), ('codes', 'code'), ('names', 'name'), ('.', '.')]



============================ Sentence 8 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 9 =============================

“Gujarat” & “Gujrat” (Common mistakes like spelling, grammar, articles)   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Why data preprocessing is important? 


>> Tokens are: 
 ['“', 'Gujarat', '”', '&', '“', 'Gujrat', '”', '(', 'Common', 'mistakes', 'like', 'spelling', ',', 'grammar', ',', 'articles', ')', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Why', 'data', 'preprocessing', 'important', '?']

>> Bigrams are: 
 [('“', 'Gujarat'), ('Gujarat', '”'), ('”', '&'), ('&', '“'), ('“', 'Gujrat'), ('Gujrat', '”'), ('”', '('), ('(', 'Common'), ('Common', 'mistakes'), ('mistakes', 'like'), ('like', 'spelling'), ('spelling', ','), (',', 'grammar'), ('grammar', ','), (',', 'articles'), ('articles', ')'), (')', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Why'), ('Why', 'data'), ('data', 'preprocessing'), ('preprocessing', 'important'), ('important', '?')]

>> Trigrams are: 
 [('“', 'Gujarat', '”'), ('Gujarat', '”', '&'), ('”', '&', '“'), ('&', '“', 'Gujrat'), ('“', 'Gujrat', '”'), ('Gujrat', '”', '('), ('”', '(', 'Common'), ('(', 'Common', 'mistakes'), ('Common', 'mistakes', 'like'), ('mistakes', 'like', 'spelling'), ('like', 'spelling', ','), ('spelling', ',', 'grammar'), (',', 'grammar', ','), ('grammar', ',', 'articles'), (',', 'articles', ')'), ('articles', ')', 'Unit'), (')', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Why'), ('›', 'Why', 'data'), ('Why', 'data', 'preprocessing'), ('data', 'preprocessing', 'important'), ('preprocessing', 'important', '?')]

>> POS Tags are: 
 [('“', 'JJ'), ('Gujarat', 'NNP'), ('”', 'NNP'), ('&', 'CC'), ('“', 'NNP'), ('Gujrat', 'NNP'), ('”', 'NNP'), ('(', '('), ('Common', 'NNP'), ('mistakes', 'NNS'), ('like', 'IN'), ('spelling', 'VBG'), (',', ','), ('grammar', 'NN'), (',', ','), ('articles', 'NNS'), (')', ')'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Why', 'WRB'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('important', 'JJ'), ('?', '.')]

 (S
  (NP “/JJ Gujarat/NNP ”/NNP)
  &/CC
  (NP “/NNP Gujrat/NNP ”/NNP)
  (/(
  (NP Common/NNP mistakes/NNS)
  like/IN
  spelling/VBG
  ,/,
  (NP grammar/NN)
  ,/,
  (NP articles/NNS)
  )/)
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  Why/WRB
  (NP data/NNS)
  preprocessing/VBG
  important/JJ
  ?/.) 


>> Noun Phrases are: 
 ['“ Gujarat ”', '“ Gujrat ”', 'Common mistakes', 'grammar', 'articles', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'data']

>> Named Entities are: 
 [('PERSON', 'Gujarat'), ('ORGANIZATION', 'Common'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('Gujarat', 'gujarat'), ('”', '”'), ('&', '&'), ('“', '“'), ('Gujrat', 'gujrat'), ('”', '”'), ('(', '('), ('Common', 'common'), ('mistakes', 'mistak'), ('like', 'like'), ('spelling', 'spell'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'articl'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'whi'), ('data', 'data'), ('preprocessing', 'preprocess'), ('important', 'import'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('Gujarat', 'gujarat'), ('”', '”'), ('&', '&'), ('“', '“'), ('Gujrat', 'gujrat'), ('”', '”'), ('(', '('), ('Common', 'common'), ('mistakes', 'mistak'), ('like', 'like'), ('spelling', 'spell'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'articl'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'whi'), ('data', 'data'), ('preprocessing', 'preprocess'), ('important', 'import'), ('?', '?')]

>> Lemmatization: 
 [('“', '“'), ('Gujarat', 'Gujarat'), ('”', '”'), ('&', '&'), ('“', '“'), ('Gujrat', 'Gujrat'), ('”', '”'), ('(', '('), ('Common', 'Common'), ('mistakes', 'mistake'), ('like', 'like'), ('spelling', 'spelling'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'article'), (')', ')'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Why', 'Why'), ('data', 'data'), ('preprocessing', 'preprocessing'), ('important', 'important'), ('?', '?')]



============================ Sentence 10 =============================

“No quality data, No quality results” It looks like Garbage In Garbage Out (GIGO). 


>> Tokens are: 
 ['“', 'No', 'quality', 'data', ',', 'No', 'quality', 'results', '”', 'It', 'looks', 'like', 'Garbage', 'In', 'Garbage', 'Out', '(', 'GIGO', ')', '.']

>> Bigrams are: 
 [('“', 'No'), ('No', 'quality'), ('quality', 'data'), ('data', ','), (',', 'No'), ('No', 'quality'), ('quality', 'results'), ('results', '”'), ('”', 'It'), ('It', 'looks'), ('looks', 'like'), ('like', 'Garbage'), ('Garbage', 'In'), ('In', 'Garbage'), ('Garbage', 'Out'), ('Out', '('), ('(', 'GIGO'), ('GIGO', ')'), (')', '.')]

>> Trigrams are: 
 [('“', 'No', 'quality'), ('No', 'quality', 'data'), ('quality', 'data', ','), ('data', ',', 'No'), (',', 'No', 'quality'), ('No', 'quality', 'results'), ('quality', 'results', '”'), ('results', '”', 'It'), ('”', 'It', 'looks'), ('It', 'looks', 'like'), ('looks', 'like', 'Garbage'), ('like', 'Garbage', 'In'), ('Garbage', 'In', 'Garbage'), ('In', 'Garbage', 'Out'), ('Garbage', 'Out', '('), ('Out', '(', 'GIGO'), ('(', 'GIGO', ')'), ('GIGO', ')', '.')]

>> POS Tags are: 
 [('“', 'NN'), ('No', 'DT'), ('quality', 'NN'), ('data', 'NNS'), (',', ','), ('No', 'DT'), ('quality', 'NN'), ('results', 'NNS'), ('”', 'VBP'), ('It', 'PRP'), ('looks', 'VBZ'), ('like', 'IN'), ('Garbage', 'NNP'), ('In', 'IN'), ('Garbage', 'NNP'), ('Out', 'NNP'), ('(', '('), ('GIGO', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP “/NN)
  (NP No/DT quality/NN data/NNS)
  ,/,
  (NP No/DT quality/NN results/NNS)
  ”/VBP
  It/PRP
  looks/VBZ
  like/IN
  (NP Garbage/NNP)
  In/IN
  (NP Garbage/NNP Out/NNP)
  (/(
  (NP GIGO/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['“', 'No quality data', 'No quality results', 'Garbage', 'Garbage Out', 'GIGO']

>> Named Entities are: 
 [('ORGANIZATION', 'No'), ('PERSON', 'Garbage'), ('GPE', 'Garbage'), ('ORGANIZATION', 'GIGO')] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('No', 'no'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('No', 'no'), ('quality', 'qualiti'), ('results', 'result'), ('”', '”'), ('It', 'it'), ('looks', 'look'), ('like', 'like'), ('Garbage', 'garbag'), ('In', 'in'), ('Garbage', 'garbag'), ('Out', 'out'), ('(', '('), ('GIGO', 'gigo'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('No', 'no'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('No', 'no'), ('quality', 'qualiti'), ('results', 'result'), ('”', '”'), ('It', 'it'), ('looks', 'look'), ('like', 'like'), ('Garbage', 'garbag'), ('In', 'in'), ('Garbage', 'garbag'), ('Out', 'out'), ('(', '('), ('GIGO', 'gigo'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('No', 'No'), ('quality', 'quality'), ('data', 'data'), (',', ','), ('No', 'No'), ('quality', 'quality'), ('results', 'result'), ('”', '”'), ('It', 'It'), ('looks', 'look'), ('like', 'like'), ('Garbage', 'Garbage'), ('In', 'In'), ('Garbage', 'Garbage'), ('Out', 'Out'), ('(', '('), ('GIGO', 'GIGO'), (')', ')'), ('.', '.')]



============================ Sentence 11 =============================

Quality decisions must be based on quality data. 


>> Tokens are: 
 ['Quality', 'decisions', 'must', 'based', 'quality', 'data', '.']

>> Bigrams are: 
 [('Quality', 'decisions'), ('decisions', 'must'), ('must', 'based'), ('based', 'quality'), ('quality', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Quality', 'decisions', 'must'), ('decisions', 'must', 'based'), ('must', 'based', 'quality'), ('based', 'quality', 'data'), ('quality', 'data', '.')]

>> POS Tags are: 
 [('Quality', 'NN'), ('decisions', 'NNS'), ('must', 'MD'), ('based', 'VBN'), ('quality', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Quality/NN decisions/NNS)
  must/MD
  based/VBN
  (NP quality/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Quality decisions', 'quality data']

>> Named Entities are: 
 [('GPE', 'Quality')] 

>> Stemming using Porter Stemmer: 
 [('Quality', 'qualiti'), ('decisions', 'decis'), ('must', 'must'), ('based', 'base'), ('quality', 'qualiti'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Quality', 'qualiti'), ('decisions', 'decis'), ('must', 'must'), ('based', 'base'), ('quality', 'qualiti'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Quality', 'Quality'), ('decisions', 'decision'), ('must', 'must'), ('based', 'based'), ('quality', 'quality'), ('data', 'data'), ('.', '.')]



============================ Sentence 12 =============================

Duplicate or missing data may cause incorrect or even misleading statistics. 


>> Tokens are: 
 ['Duplicate', 'missing', 'data', 'may', 'cause', 'incorrect', 'even', 'misleading', 'statistics', '.']

>> Bigrams are: 
 [('Duplicate', 'missing'), ('missing', 'data'), ('data', 'may'), ('may', 'cause'), ('cause', 'incorrect'), ('incorrect', 'even'), ('even', 'misleading'), ('misleading', 'statistics'), ('statistics', '.')]

>> Trigrams are: 
 [('Duplicate', 'missing', 'data'), ('missing', 'data', 'may'), ('data', 'may', 'cause'), ('may', 'cause', 'incorrect'), ('cause', 'incorrect', 'even'), ('incorrect', 'even', 'misleading'), ('even', 'misleading', 'statistics'), ('misleading', 'statistics', '.')]

>> POS Tags are: 
 [('Duplicate', 'NNP'), ('missing', 'VBG'), ('data', 'NNS'), ('may', 'MD'), ('cause', 'VB'), ('incorrect', 'VB'), ('even', 'RB'), ('misleading', 'VBG'), ('statistics', 'NNS'), ('.', '.')]

 (S
  (NP Duplicate/NNP)
  missing/VBG
  (NP data/NNS)
  may/MD
  cause/VB
  incorrect/VB
  even/RB
  misleading/VBG
  (NP statistics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Duplicate', 'data', 'statistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Duplicate', 'duplic'), ('missing', 'miss'), ('data', 'data'), ('may', 'may'), ('cause', 'caus'), ('incorrect', 'incorrect'), ('even', 'even'), ('misleading', 'mislead'), ('statistics', 'statist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Duplicate', 'duplic'), ('missing', 'miss'), ('data', 'data'), ('may', 'may'), ('cause', 'caus'), ('incorrect', 'incorrect'), ('even', 'even'), ('misleading', 'mislead'), ('statistics', 'statist'), ('.', '.')]

>> Lemmatization: 
 [('Duplicate', 'Duplicate'), ('missing', 'missing'), ('data', 'data'), ('may', 'may'), ('cause', 'cause'), ('incorrect', 'incorrect'), ('even', 'even'), ('misleading', 'misleading'), ('statistics', 'statistic'), ('.', '.')]



============================ Sentence 13 =============================

Data preparation, cleaning and transformation are the majority task in data mining. 


>> Tokens are: 
 ['Data', 'preparation', ',', 'cleaning', 'transformation', 'majority', 'task', 'data', 'mining', '.']

>> Bigrams are: 
 [('Data', 'preparation'), ('preparation', ','), (',', 'cleaning'), ('cleaning', 'transformation'), ('transformation', 'majority'), ('majority', 'task'), ('task', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('Data', 'preparation', ','), ('preparation', ',', 'cleaning'), (',', 'cleaning', 'transformation'), ('cleaning', 'transformation', 'majority'), ('transformation', 'majority', 'task'), ('majority', 'task', 'data'), ('task', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('preparation', 'NN'), (',', ','), ('cleaning', 'VBG'), ('transformation', 'NN'), ('majority', 'NN'), ('task', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP preparation/NN)
  ,/,
  cleaning/VBG
  (NP transformation/NN majority/NN task/NN data/NNS mining/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data preparation', 'transformation majority task data mining']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('transformation', 'transform'), ('majority', 'major'), ('task', 'task'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('preparation', 'prepar'), (',', ','), ('cleaning', 'clean'), ('transformation', 'transform'), ('majority', 'major'), ('task', 'task'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('preparation', 'preparation'), (',', ','), ('cleaning', 'cleaning'), ('transformation', 'transformation'), ('majority', 'majority'), ('task', 'task'), ('data', 'data'), ('mining', 'mining'), ('.', '.')]



============================ Sentence 14 =============================

(could be as high as 90%). 


>> Tokens are: 
 ['(', 'could', 'high', '90', '%', ')', '.']

>> Bigrams are: 
 [('(', 'could'), ('could', 'high'), ('high', '90'), ('90', '%'), ('%', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'could', 'high'), ('could', 'high', '90'), ('high', '90', '%'), ('90', '%', ')'), ('%', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('could', 'MD'), ('high', 'VB'), ('90', 'CD'), ('%', 'NN'), (')', ')'), ('.', '.')]

 (S (/( could/MD high/VB 90/CD (NP %/NN) )/) ./.) 


>> Noun Phrases are: 
 ['%']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('could', 'could'), ('high', 'high'), ('90', '90'), ('%', '%'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('could', 'could'), ('high', 'high'), ('90', '90'), ('%', '%'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('could', 'could'), ('high', 'high'), ('90', '90'), ('%', '%'), (')', ')'), ('.', '.')]



============================ Sentence 15 =============================

Data preprocessing prepares raw data for further processing. 


>> Tokens are: 
 ['Data', 'preprocessing', 'prepares', 'raw', 'data', 'processing', '.']

>> Bigrams are: 
 [('Data', 'preprocessing'), ('preprocessing', 'prepares'), ('prepares', 'raw'), ('raw', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Data', 'preprocessing', 'prepares'), ('preprocessing', 'prepares', 'raw'), ('prepares', 'raw', 'data'), ('raw', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('preprocessing', 'NN'), ('prepares', 'NNS'), ('raw', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP preprocessing/NN prepares/NNS)
  (NP raw/JJ data/NNS processing/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data preprocessing prepares', 'raw data processing']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('preprocessing', 'preprocess'), ('prepares', 'prepar'), ('raw', 'raw'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('preprocessing', 'preprocess'), ('prepares', 'prepar'), ('raw', 'raw'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('preprocessing', 'preprocessing'), ('prepares', 'prepares'), ('raw', 'raw'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]



============================ Sentence 16 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›   4  Mean Mean is the average of a dataset. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '4', 'Mean', 'Mean', 'average', 'dataset', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '4'), ('4', 'Mean'), ('Mean', 'Mean'), ('Mean', 'average'), ('average', 'dataset'), ('dataset', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '4'), ('›', '4', 'Mean'), ('4', 'Mean', 'Mean'), ('Mean', 'Mean', 'average'), ('Mean', 'average', 'dataset'), ('average', 'dataset', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', '$'), ('4', 'CD'), ('Mean', 'NNP'), ('Mean', 'NNP'), ('average', 'JJ'), ('dataset', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  ›/$
  4/CD
  (NP Mean/NNP Mean/NNP)
  (NP average/JJ dataset/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', 'Mean Mean', 'average dataset']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), ('Mean', 'mean'), ('Mean', 'mean'), ('average', 'averag'), ('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), ('Mean', 'mean'), ('Mean', 'mean'), ('average', 'averag'), ('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), ('Mean', 'Mean'), ('Mean', 'Mean'), ('average', 'average'), ('dataset', 'dataset'), ('.', '.')]



============================ Sentence 17 =============================

To find the mean, calculate the sum of all the data and then divide by the total number of data. 


>> Tokens are: 
 ['To', 'find', 'mean', ',', 'calculate', 'sum', 'data', 'divide', 'total', 'number', 'data', '.']

>> Bigrams are: 
 [('To', 'find'), ('find', 'mean'), ('mean', ','), (',', 'calculate'), ('calculate', 'sum'), ('sum', 'data'), ('data', 'divide'), ('divide', 'total'), ('total', 'number'), ('number', 'data'), ('data', '.')]

>> Trigrams are: 
 [('To', 'find', 'mean'), ('find', 'mean', ','), ('mean', ',', 'calculate'), (',', 'calculate', 'sum'), ('calculate', 'sum', 'data'), ('sum', 'data', 'divide'), ('data', 'divide', 'total'), ('divide', 'total', 'number'), ('total', 'number', 'data'), ('number', 'data', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('find', 'VB'), ('mean', 'JJ'), (',', ','), ('calculate', 'JJ'), ('sum', 'NN'), ('data', 'NNS'), ('divide', 'VBP'), ('total', 'JJ'), ('number', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  To/TO
  find/VB
  mean/JJ
  ,/,
  (NP calculate/JJ sum/NN data/NNS)
  divide/VBP
  (NP total/JJ number/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['calculate sum data', 'total number data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('find', 'find'), ('mean', 'mean'), (',', ','), ('calculate', 'calcul'), ('sum', 'sum'), ('data', 'data'), ('divide', 'divid'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('find', 'find'), ('mean', 'mean'), (',', ','), ('calculate', 'calcul'), ('sum', 'sum'), ('data', 'data'), ('divide', 'divid'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('find', 'find'), ('mean', 'mean'), (',', ','), ('calculate', 'calculate'), ('sum', 'sum'), ('data', 'data'), ('divide', 'divide'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]



============================ Sentence 18 =============================

Example  Find out mean for 12, 15, 11, 11, 7, 13     First, find the sum of the data. 


>> Tokens are: 
 ['Example', 'Find', 'mean', '12', ',', '15', ',', '11', ',', '11', ',', '7', ',', '13', 'First', ',', 'find', 'sum', 'data', '.']

>> Bigrams are: 
 [('Example', 'Find'), ('Find', 'mean'), ('mean', '12'), ('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '13'), ('13', 'First'), ('First', ','), (',', 'find'), ('find', 'sum'), ('sum', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Example', 'Find', 'mean'), ('Find', 'mean', '12'), ('mean', '12', ','), ('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '13'), (',', '13', 'First'), ('13', 'First', ','), ('First', ',', 'find'), (',', 'find', 'sum'), ('find', 'sum', 'data'), ('sum', 'data', '.')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Find', 'NNP'), ('mean', 'NN'), ('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('13', 'CD'), ('First', 'NNP'), (',', ','), ('find', 'VBP'), ('sum', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Example/JJ Find/NNP mean/NN)
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  13/CD
  (NP First/NNP)
  ,/,
  find/VBP
  (NP sum/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Example Find mean', 'First', 'sum data']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Find')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('mean', 'mean'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('First', 'first'), (',', ','), ('find', 'find'), ('sum', 'sum'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('mean', 'mean'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('First', 'first'), (',', ','), ('find', 'find'), ('sum', 'sum'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Find', 'Find'), ('mean', 'mean'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('First', 'First'), (',', ','), ('find', 'find'), ('sum', 'sum'), ('data', 'data'), ('.', '.')]



============================ Sentence 19 =============================

12 + 15 +11 + 11 + 7 + 13 = 69 Then divide by the total number of data. 


>> Tokens are: 
 ['12', '+', '15', '+11', '+', '11', '+', '7', '+', '13', '=', '69', 'Then', 'divide', 'total', 'number', 'data', '.']

>> Bigrams are: 
 [('12', '+'), ('+', '15'), ('15', '+11'), ('+11', '+'), ('+', '11'), ('11', '+'), ('+', '7'), ('7', '+'), ('+', '13'), ('13', '='), ('=', '69'), ('69', 'Then'), ('Then', 'divide'), ('divide', 'total'), ('total', 'number'), ('number', 'data'), ('data', '.')]

>> Trigrams are: 
 [('12', '+', '15'), ('+', '15', '+11'), ('15', '+11', '+'), ('+11', '+', '11'), ('+', '11', '+'), ('11', '+', '7'), ('+', '7', '+'), ('7', '+', '13'), ('+', '13', '='), ('13', '=', '69'), ('=', '69', 'Then'), ('69', 'Then', 'divide'), ('Then', 'divide', 'total'), ('divide', 'total', 'number'), ('total', 'number', 'data'), ('number', 'data', '.')]

>> POS Tags are: 
 [('12', 'CD'), ('+', 'JJ'), ('15', 'CD'), ('+11', 'JJ'), ('+', '$'), ('11', 'CD'), ('+', '$'), ('7', 'CD'), ('+', '$'), ('13', 'CD'), ('=', '$'), ('69', 'CD'), ('Then', 'RB'), ('divide', 'JJ'), ('total', 'JJ'), ('number', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  12/CD
  +/JJ
  15/CD
  +11/JJ
  +/$
  11/CD
  +/$
  7/CD
  +/$
  13/CD
  =/$
  69/CD
  Then/RB
  (NP divide/JJ total/JJ number/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['divide total number data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('+', '+'), ('15', '15'), ('+11', '+11'), ('+', '+'), ('11', '11'), ('+', '+'), ('7', '7'), ('+', '+'), ('13', '13'), ('=', '='), ('69', '69'), ('Then', 'then'), ('divide', 'divid'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('+', '+'), ('15', '15'), ('+11', '+11'), ('+', '+'), ('11', '11'), ('+', '+'), ('7', '7'), ('+', '+'), ('13', '13'), ('=', '='), ('69', '69'), ('Then', 'then'), ('divide', 'divid'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('+', '+'), ('15', '15'), ('+11', '+11'), ('+', '+'), ('11', '11'), ('+', '+'), ('7', '7'), ('+', '+'), ('13', '13'), ('=', '='), ('69', '69'), ('Then', 'Then'), ('divide', 'divide'), ('total', 'total'), ('number', 'number'), ('data', 'data'), ('.', '.')]



============================ Sentence 20 =============================

69 / 6 = 11.5   Mean    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›   5  Median Median is the middle number in a dataset when the data is arranged in numerical order (Sorted Order). 


>> Tokens are: 
 ['69', '/', '6', '=', '11.5', 'Mean', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '5', 'Median', 'Median', 'middle', 'number', 'dataset', 'data', 'arranged', 'numerical', 'order', '(', 'Sorted', 'Order', ')', '.']

>> Bigrams are: 
 [('69', '/'), ('/', '6'), ('6', '='), ('=', '11.5'), ('11.5', 'Mean'), ('Mean', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '5'), ('5', 'Median'), ('Median', 'Median'), ('Median', 'middle'), ('middle', 'number'), ('number', 'dataset'), ('dataset', 'data'), ('data', 'arranged'), ('arranged', 'numerical'), ('numerical', 'order'), ('order', '('), ('(', 'Sorted'), ('Sorted', 'Order'), ('Order', ')'), (')', '.')]

>> Trigrams are: 
 [('69', '/', '6'), ('/', '6', '='), ('6', '=', '11.5'), ('=', '11.5', 'Mean'), ('11.5', 'Mean', 'Unit'), ('Mean', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '5'), ('›', '5', 'Median'), ('5', 'Median', 'Median'), ('Median', 'Median', 'middle'), ('Median', 'middle', 'number'), ('middle', 'number', 'dataset'), ('number', 'dataset', 'data'), ('dataset', 'data', 'arranged'), ('data', 'arranged', 'numerical'), ('arranged', 'numerical', 'order'), ('numerical', 'order', '('), ('order', '(', 'Sorted'), ('(', 'Sorted', 'Order'), ('Sorted', 'Order', ')'), ('Order', ')', '.')]

>> POS Tags are: 
 [('69', 'CD'), ('/', 'JJ'), ('6', 'CD'), ('=', 'JJ'), ('11.5', 'CD'), ('Mean', 'JJ'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', '$'), ('5', 'CD'), ('Median', 'JJ'), ('Median', 'NNP'), ('middle', 'NN'), ('number', 'NN'), ('dataset', 'VBN'), ('data', 'NNS'), ('arranged', 'VBD'), ('numerical', 'JJ'), ('order', 'NN'), ('(', '('), ('Sorted', 'JJ'), ('Order', 'NNP'), (')', ')'), ('.', '.')]

 (S
  69/CD
  //JJ
  6/CD
  =/JJ
  11.5/CD
  (NP Mean/JJ Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  ›/$
  5/CD
  (NP Median/JJ Median/NNP middle/NN number/NN)
  dataset/VBN
  (NP data/NNS)
  arranged/VBD
  (NP numerical/JJ order/NN)
  (/(
  (NP Sorted/JJ Order/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Mean Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', 'Median Median middle number', 'data', 'numerical order', 'Sorted Order']

>> Named Entities are: 
 [('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Median'), ('GPE', 'Median'), ('ORGANIZATION', 'Sorted Order')] 

>> Stemming using Porter Stemmer: 
 [('69', '69'), ('/', '/'), ('6', '6'), ('=', '='), ('11.5', '11.5'), ('Mean', 'mean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('5', '5'), ('Median', 'median'), ('Median', 'median'), ('middle', 'middl'), ('number', 'number'), ('dataset', 'dataset'), ('data', 'data'), ('arranged', 'arrang'), ('numerical', 'numer'), ('order', 'order'), ('(', '('), ('Sorted', 'sort'), ('Order', 'order'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('69', '69'), ('/', '/'), ('6', '6'), ('=', '='), ('11.5', '11.5'), ('Mean', 'mean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('5', '5'), ('Median', 'median'), ('Median', 'median'), ('middle', 'middl'), ('number', 'number'), ('dataset', 'dataset'), ('data', 'data'), ('arranged', 'arrang'), ('numerical', 'numer'), ('order', 'order'), ('(', '('), ('Sorted', 'sort'), ('Order', 'order'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('69', '69'), ('/', '/'), ('6', '6'), ('=', '='), ('11.5', '11.5'), ('Mean', 'Mean'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('5', '5'), ('Median', 'Median'), ('Median', 'Median'), ('middle', 'middle'), ('number', 'number'), ('dataset', 'dataset'), ('data', 'data'), ('arranged', 'arranged'), ('numerical', 'numerical'), ('order', 'order'), ('(', '('), ('Sorted', 'Sorted'), ('Order', 'Order'), (')', ')'), ('.', '.')]



============================ Sentence 21 =============================

If count is Odd then middle number is Median If count is Even then take average of middle two numbers that is Median   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›   6  Median - Odd  (Cont..) Example Find out Median for 12, 15, 11, 11, 7, 13, 15   In above example, count of data is 7. 


>> Tokens are: 
 ['If', 'count', 'Odd', 'middle', 'number', 'Median', 'If', 'count', 'Even', 'take', 'average', 'middle', 'two', 'numbers', 'Median', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '6', 'Median', '-', 'Odd', '(', 'Cont', '..', ')', 'Example', 'Find', 'Median', '12', ',', '15', ',', '11', ',', '11', ',', '7', ',', '13', ',', '15', 'In', 'example', ',', 'count', 'data', '7', '.']

>> Bigrams are: 
 [('If', 'count'), ('count', 'Odd'), ('Odd', 'middle'), ('middle', 'number'), ('number', 'Median'), ('Median', 'If'), ('If', 'count'), ('count', 'Even'), ('Even', 'take'), ('take', 'average'), ('average', 'middle'), ('middle', 'two'), ('two', 'numbers'), ('numbers', 'Median'), ('Median', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '6'), ('6', 'Median'), ('Median', '-'), ('-', 'Odd'), ('Odd', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Example'), ('Example', 'Find'), ('Find', 'Median'), ('Median', '12'), ('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '13'), ('13', ','), (',', '15'), ('15', 'In'), ('In', 'example'), ('example', ','), (',', 'count'), ('count', 'data'), ('data', '7'), ('7', '.')]

>> Trigrams are: 
 [('If', 'count', 'Odd'), ('count', 'Odd', 'middle'), ('Odd', 'middle', 'number'), ('middle', 'number', 'Median'), ('number', 'Median', 'If'), ('Median', 'If', 'count'), ('If', 'count', 'Even'), ('count', 'Even', 'take'), ('Even', 'take', 'average'), ('take', 'average', 'middle'), ('average', 'middle', 'two'), ('middle', 'two', 'numbers'), ('two', 'numbers', 'Median'), ('numbers', 'Median', 'Unit'), ('Median', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '6'), ('›', '6', 'Median'), ('6', 'Median', '-'), ('Median', '-', 'Odd'), ('-', 'Odd', '('), ('Odd', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Example'), (')', 'Example', 'Find'), ('Example', 'Find', 'Median'), ('Find', 'Median', '12'), ('Median', '12', ','), ('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '13'), (',', '13', ','), ('13', ',', '15'), (',', '15', 'In'), ('15', 'In', 'example'), ('In', 'example', ','), ('example', ',', 'count'), (',', 'count', 'data'), ('count', 'data', '7'), ('data', '7', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('count', 'NN'), ('Odd', 'NNP'), ('middle', 'VBZ'), ('number', 'NN'), ('Median', 'JJ'), ('If', 'IN'), ('count', 'NN'), ('Even', 'RB'), ('take', 'VBP'), ('average', 'JJ'), ('middle', 'JJ'), ('two', 'CD'), ('numbers', 'NNS'), ('Median', 'JJ'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', '$'), ('6', 'CD'), ('Median', 'NNP'), ('-', ':'), ('Odd', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Example', 'NNP'), ('Find', 'NNP'), ('Median', 'JJ'), ('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('15', 'CD'), ('In', 'IN'), ('example', 'NN'), (',', ','), ('count', 'NN'), ('data', 'NNS'), ('7', 'CD'), ('.', '.')]

 (S
  If/IN
  (NP count/NN Odd/NNP)
  middle/VBZ
  (NP number/NN)
  Median/JJ
  If/IN
  (NP count/NN)
  Even/RB
  take/VBP
  average/JJ
  middle/JJ
  two/CD
  (NP numbers/NNS)
  (NP Median/JJ Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  ›/$
  6/CD
  (NP Median/NNP)
  -/:
  (NP Odd/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Example/NNP Find/NNP)
  Median/JJ
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  13/CD
  ,/,
  15/CD
  In/IN
  (NP example/NN)
  ,/,
  (NP count/NN data/NNS)
  7/CD
  ./.) 


>> Noun Phrases are: 
 ['count Odd', 'number', 'count', 'numbers', 'Median Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', 'Median', 'Odd', 'Cont ..', 'Example Find', 'example', 'count data']

>> Named Entities are: 
 [('PERSON', 'Odd'), ('GPE', 'Median'), ('PERSON', 'Median Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Median'), ('GPE', 'Odd'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Example Find')] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('count', 'count'), ('Odd', 'odd'), ('middle', 'middl'), ('number', 'number'), ('Median', 'median'), ('If', 'if'), ('count', 'count'), ('Even', 'even'), ('take', 'take'), ('average', 'averag'), ('middle', 'middl'), ('two', 'two'), ('numbers', 'number'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('6', '6'), ('Median', 'median'), ('-', '-'), ('Odd', 'odd'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('Median', 'median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('In', 'in'), ('example', 'exampl'), (',', ','), ('count', 'count'), ('data', 'data'), ('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('count', 'count'), ('Odd', 'odd'), ('middle', 'middl'), ('number', 'number'), ('Median', 'median'), ('If', 'if'), ('count', 'count'), ('Even', 'even'), ('take', 'take'), ('average', 'averag'), ('middle', 'middl'), ('two', 'two'), ('numbers', 'number'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('6', '6'), ('Median', 'median'), ('-', '-'), ('Odd', 'odd'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('Median', 'median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('In', 'in'), ('example', 'exampl'), (',', ','), ('count', 'count'), ('data', 'data'), ('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('count', 'count'), ('Odd', 'Odd'), ('middle', 'middle'), ('number', 'number'), ('Median', 'Median'), ('If', 'If'), ('count', 'count'), ('Even', 'Even'), ('take', 'take'), ('average', 'average'), ('middle', 'middle'), ('two', 'two'), ('numbers', 'number'), ('Median', 'Median'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('6', '6'), ('Median', 'Median'), ('-', '-'), ('Odd', 'Odd'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Example', 'Example'), ('Find', 'Find'), ('Median', 'Median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('In', 'In'), ('example', 'example'), (',', ','), ('count', 'count'), ('data', 'data'), ('7', '7'), ('.', '.')]



============================ Sentence 22 =============================

(Odd)  First, arrange the data in ascending order. 


>> Tokens are: 
 ['(', 'Odd', ')', 'First', ',', 'arrange', 'data', 'ascending', 'order', '.']

>> Bigrams are: 
 [('(', 'Odd'), ('Odd', ')'), (')', 'First'), ('First', ','), (',', 'arrange'), ('arrange', 'data'), ('data', 'ascending'), ('ascending', 'order'), ('order', '.')]

>> Trigrams are: 
 [('(', 'Odd', ')'), ('Odd', ')', 'First'), (')', 'First', ','), ('First', ',', 'arrange'), (',', 'arrange', 'data'), ('arrange', 'data', 'ascending'), ('data', 'ascending', 'order'), ('ascending', 'order', '.')]

>> POS Tags are: 
 [('(', '('), ('Odd', 'NNP'), (')', ')'), ('First', 'NNP'), (',', ','), ('arrange', 'NN'), ('data', 'NNS'), ('ascending', 'VBG'), ('order', 'NN'), ('.', '.')]

 (S
  (/(
  (NP Odd/NNP)
  )/)
  (NP First/NNP)
  ,/,
  (NP arrange/NN data/NNS)
  ascending/VBG
  (NP order/NN)
  ./.) 


>> Noun Phrases are: 
 ['Odd', 'First', 'arrange data', 'order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Odd', 'odd'), (')', ')'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Odd', 'odd'), (')', ')'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Odd', 'Odd'), (')', ')'), ('First', 'First'), (',', ','), ('arrange', 'arrange'), ('data', 'data'), ('ascending', 'ascending'), ('order', 'order'), ('.', '.')]



============================ Sentence 23 =============================

7, 11, 11, 12, 13, 15, 15  Partitioning data into equal halfs  7, 11, 11, 12, 13, 15, 15   12       Median       	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›   7  Median - Even (Cont..) Example Find out median for 12, 15, 11, 11, 7, 13   In above example, count of data is 6. 


>> Tokens are: 
 ['7', ',', '11', ',', '11', ',', '12', ',', '13', ',', '15', ',', '15', 'Partitioning', 'data', 'equal', 'halfs', '7', ',', '11', ',', '11', ',', '12', ',', '13', ',', '15', ',', '15', '12', 'Median', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '7', 'Median', '-', 'Even', '(', 'Cont', '..', ')', 'Example', 'Find', 'median', '12', ',', '15', ',', '11', ',', '11', ',', '7', ',', '13', 'In', 'example', ',', 'count', 'data', '6', '.']

>> Bigrams are: 
 [('7', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '12'), ('12', ','), (',', '13'), ('13', ','), (',', '15'), ('15', ','), (',', '15'), ('15', 'Partitioning'), ('Partitioning', 'data'), ('data', 'equal'), ('equal', 'halfs'), ('halfs', '7'), ('7', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '12'), ('12', ','), (',', '13'), ('13', ','), (',', '15'), ('15', ','), (',', '15'), ('15', '12'), ('12', 'Median'), ('Median', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '7'), ('7', 'Median'), ('Median', '-'), ('-', 'Even'), ('Even', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Example'), ('Example', 'Find'), ('Find', 'median'), ('median', '12'), ('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '13'), ('13', 'In'), ('In', 'example'), ('example', ','), (',', 'count'), ('count', 'data'), ('data', '6'), ('6', '.')]

>> Trigrams are: 
 [('7', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '12'), (',', '12', ','), ('12', ',', '13'), (',', '13', ','), ('13', ',', '15'), (',', '15', ','), ('15', ',', '15'), (',', '15', 'Partitioning'), ('15', 'Partitioning', 'data'), ('Partitioning', 'data', 'equal'), ('data', 'equal', 'halfs'), ('equal', 'halfs', '7'), ('halfs', '7', ','), ('7', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '12'), (',', '12', ','), ('12', ',', '13'), (',', '13', ','), ('13', ',', '15'), (',', '15', ','), ('15', ',', '15'), (',', '15', '12'), ('15', '12', 'Median'), ('12', 'Median', 'Unit'), ('Median', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '7'), ('›', '7', 'Median'), ('7', 'Median', '-'), ('Median', '-', 'Even'), ('-', 'Even', '('), ('Even', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Example'), (')', 'Example', 'Find'), ('Example', 'Find', 'median'), ('Find', 'median', '12'), ('median', '12', ','), ('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '13'), (',', '13', 'In'), ('13', 'In', 'example'), ('In', 'example', ','), ('example', ',', 'count'), (',', 'count', 'data'), ('count', 'data', '6'), ('data', '6', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('15', 'CD'), ('Partitioning', 'NNP'), ('data', 'NNS'), ('equal', 'JJ'), ('halfs', 'NN'), ('7', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('15', 'CD'), ('12', 'CD'), ('Median', 'JJ'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', '$'), ('7', 'CD'), ('Median', 'NNP'), ('-', ':'), ('Even', 'RB'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Example', 'NNP'), ('Find', 'NNP'), ('median', 'JJ'), ('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('13', 'CD'), ('In', 'IN'), ('example', 'NN'), (',', ','), ('count', 'NN'), ('data', 'NNS'), ('6', 'CD'), ('.', '.')]

 (S
  7/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  12/CD
  ,/,
  13/CD
  ,/,
  15/CD
  ,/,
  15/CD
  (NP Partitioning/NNP data/NNS)
  (NP equal/JJ halfs/NN)
  7/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  12/CD
  ,/,
  13/CD
  ,/,
  15/CD
  ,/,
  15/CD
  12/CD
  (NP Median/JJ Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  ›/$
  7/CD
  (NP Median/NNP)
  -/:
  Even/RB
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Example/NNP Find/NNP)
  median/JJ
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  13/CD
  In/IN
  (NP example/NN)
  ,/,
  (NP count/NN data/NNS)
  6/CD
  ./.) 


>> Noun Phrases are: 
 ['Partitioning data', 'equal halfs', 'Median Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', 'Median', 'Cont ..', 'Example Find', 'example', 'count data']

>> Named Entities are: 
 [('GPE', 'Median'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Median'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Example Find')] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('Partitioning', 'partit'), ('data', 'data'), ('equal', 'equal'), ('halfs', 'half'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('12', '12'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('7', '7'), ('Median', 'median'), ('-', '-'), ('Even', 'even'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('median', 'median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('In', 'in'), ('example', 'exampl'), (',', ','), ('count', 'count'), ('data', 'data'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('Partitioning', 'partit'), ('data', 'data'), ('equal', 'equal'), ('halfs', 'half'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('12', '12'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('7', '7'), ('Median', 'median'), ('-', '-'), ('Even', 'even'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('median', 'median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('In', 'in'), ('example', 'exampl'), (',', ','), ('count', 'count'), ('data', 'data'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('Partitioning', 'Partitioning'), ('data', 'data'), ('equal', 'equal'), ('halfs', 'half'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), (',', ','), ('15', '15'), ('12', '12'), ('Median', 'Median'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('7', '7'), ('Median', 'Median'), ('-', '-'), ('Even', 'Even'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Example', 'Example'), ('Find', 'Find'), ('median', 'median'), ('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('In', 'In'), ('example', 'example'), (',', ','), ('count', 'count'), ('data', 'data'), ('6', '6'), ('.', '.')]



============================ Sentence 24 =============================

(Even)  First, arrange the data in ascending order. 


>> Tokens are: 
 ['(', 'Even', ')', 'First', ',', 'arrange', 'data', 'ascending', 'order', '.']

>> Bigrams are: 
 [('(', 'Even'), ('Even', ')'), (')', 'First'), ('First', ','), (',', 'arrange'), ('arrange', 'data'), ('data', 'ascending'), ('ascending', 'order'), ('order', '.')]

>> Trigrams are: 
 [('(', 'Even', ')'), ('Even', ')', 'First'), (')', 'First', ','), ('First', ',', 'arrange'), (',', 'arrange', 'data'), ('arrange', 'data', 'ascending'), ('data', 'ascending', 'order'), ('ascending', 'order', '.')]

>> POS Tags are: 
 [('(', '('), ('Even', 'RB'), (')', ')'), ('First', 'NNP'), (',', ','), ('arrange', 'NN'), ('data', 'NNS'), ('ascending', 'VBG'), ('order', 'NN'), ('.', '.')]

 (S
  (/(
  Even/RB
  )/)
  (NP First/NNP)
  ,/,
  (NP arrange/NN data/NNS)
  ascending/VBG
  (NP order/NN)
  ./.) 


>> Noun Phrases are: 
 ['First', 'arrange data', 'order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Even', 'even'), (')', ')'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Even', 'even'), (')', ')'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Even', 'Even'), (')', ')'), ('First', 'First'), (',', ','), ('arrange', 'arrange'), ('data', 'data'), ('ascending', 'ascending'), ('order', 'order'), ('.', '.')]



============================ Sentence 25 =============================

7, 11, 11, 12, 13, 15  Calculate an average of the two numbers in the middle. 


>> Tokens are: 
 ['7', ',', '11', ',', '11', ',', '12', ',', '13', ',', '15', 'Calculate', 'average', 'two', 'numbers', 'middle', '.']

>> Bigrams are: 
 [('7', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '12'), ('12', ','), (',', '13'), ('13', ','), (',', '15'), ('15', 'Calculate'), ('Calculate', 'average'), ('average', 'two'), ('two', 'numbers'), ('numbers', 'middle'), ('middle', '.')]

>> Trigrams are: 
 [('7', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '12'), (',', '12', ','), ('12', ',', '13'), (',', '13', ','), ('13', ',', '15'), (',', '15', 'Calculate'), ('15', 'Calculate', 'average'), ('Calculate', 'average', 'two'), ('average', 'two', 'numbers'), ('two', 'numbers', 'middle'), ('numbers', 'middle', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('15', 'CD'), ('Calculate', 'NNP'), ('average', 'JJ'), ('two', 'CD'), ('numbers', 'NNS'), ('middle', 'VBP'), ('.', '.')]

 (S
  7/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  12/CD
  ,/,
  13/CD
  ,/,
  15/CD
  (NP Calculate/NNP)
  average/JJ
  two/CD
  (NP numbers/NNS)
  middle/VBP
  ./.) 


>> Noun Phrases are: 
 ['Calculate', 'numbers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('Calculate', 'calcul'), ('average', 'averag'), ('two', 'two'), ('numbers', 'number'), ('middle', 'middl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('Calculate', 'calcul'), ('average', 'averag'), ('two', 'two'), ('numbers', 'number'), ('middle', 'middl'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('Calculate', 'Calculate'), ('average', 'average'), ('two', 'two'), ('numbers', 'number'), ('middle', 'middle'), ('.', '.')]



============================ Sentence 26 =============================

7, 11, 11, 12, 13, 15   (11 + 12)/2  = 11.5       Median     	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›   8  Mode The mode is the number that occurs most often within a set of numbers. 


>> Tokens are: 
 ['7', ',', '11', ',', '11', ',', '12', ',', '13', ',', '15', '(', '11', '+', '12', ')', '/2', '=', '11.5', 'Median', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '8', 'Mode', 'The', 'mode', 'number', 'occurs', 'often', 'within', 'set', 'numbers', '.']

>> Bigrams are: 
 [('7', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '12'), ('12', ','), (',', '13'), ('13', ','), (',', '15'), ('15', '('), ('(', '11'), ('11', '+'), ('+', '12'), ('12', ')'), (')', '/2'), ('/2', '='), ('=', '11.5'), ('11.5', 'Median'), ('Median', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '8'), ('8', 'Mode'), ('Mode', 'The'), ('The', 'mode'), ('mode', 'number'), ('number', 'occurs'), ('occurs', 'often'), ('often', 'within'), ('within', 'set'), ('set', 'numbers'), ('numbers', '.')]

>> Trigrams are: 
 [('7', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '12'), (',', '12', ','), ('12', ',', '13'), (',', '13', ','), ('13', ',', '15'), (',', '15', '('), ('15', '(', '11'), ('(', '11', '+'), ('11', '+', '12'), ('+', '12', ')'), ('12', ')', '/2'), (')', '/2', '='), ('/2', '=', '11.5'), ('=', '11.5', 'Median'), ('11.5', 'Median', 'Unit'), ('Median', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '8'), ('›', '8', 'Mode'), ('8', 'Mode', 'The'), ('Mode', 'The', 'mode'), ('The', 'mode', 'number'), ('mode', 'number', 'occurs'), ('number', 'occurs', 'often'), ('occurs', 'often', 'within'), ('often', 'within', 'set'), ('within', 'set', 'numbers'), ('set', 'numbers', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('15', 'CD'), ('(', '('), ('11', 'CD'), ('+', 'RB'), ('12', 'CD'), (')', ')'), ('/2', 'NN'), ('=', '$'), ('11.5', 'CD'), ('Median', 'JJ'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', '$'), ('8', 'CD'), ('Mode', 'NNP'), ('The', 'DT'), ('mode', 'NN'), ('number', 'NN'), ('occurs', 'VBZ'), ('often', 'RB'), ('within', 'IN'), ('set', 'VBN'), ('numbers', 'NNS'), ('.', '.')]

 (S
  7/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  12/CD
  ,/,
  13/CD
  ,/,
  15/CD
  (/(
  11/CD
  +/RB
  12/CD
  )/)
  (NP /2/NN)
  =/$
  11.5/CD
  (NP Median/JJ Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  ›/$
  8/CD
  (NP Mode/NNP)
  (NP The/DT mode/NN number/NN)
  occurs/VBZ
  often/RB
  within/IN
  set/VBN
  (NP numbers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['/2', 'Median Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', 'Mode', 'The mode number', 'numbers']

>> Named Entities are: 
 [('GPE', 'Median'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('(', '('), ('11', '11'), ('+', '+'), ('12', '12'), (')', ')'), ('/2', '/2'), ('=', '='), ('11.5', '11.5'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('8', '8'), ('Mode', 'mode'), ('The', 'the'), ('mode', 'mode'), ('number', 'number'), ('occurs', 'occur'), ('often', 'often'), ('within', 'within'), ('set', 'set'), ('numbers', 'number'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('(', '('), ('11', '11'), ('+', '+'), ('12', '12'), (')', ')'), ('/2', '/2'), ('=', '='), ('11.5', '11.5'), ('Median', 'median'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('8', '8'), ('Mode', 'mode'), ('The', 'the'), ('mode', 'mode'), ('number', 'number'), ('occurs', 'occur'), ('often', 'often'), ('within', 'within'), ('set', 'set'), ('numbers', 'number'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), (',', ','), ('15', '15'), ('(', '('), ('11', '11'), ('+', '+'), ('12', '12'), (')', ')'), ('/2', '/2'), ('=', '='), ('11.5', '11.5'), ('Median', 'Median'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('8', '8'), ('Mode', 'Mode'), ('The', 'The'), ('mode', 'mode'), ('number', 'number'), ('occurs', 'occurs'), ('often', 'often'), ('within', 'within'), ('set', 'set'), ('numbers', 'number'), ('.', '.')]



============================ Sentence 27 =============================

Example   Find mode. 


>> Tokens are: 
 ['Example', 'Find', 'mode', '.']

>> Bigrams are: 
 [('Example', 'Find'), ('Find', 'mode'), ('mode', '.')]

>> Trigrams are: 
 [('Example', 'Find', 'mode'), ('Find', 'mode', '.')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Find', 'NNP'), ('mode', 'NN'), ('.', '.')]

 (S (NP Example/JJ Find/NNP mode/NN) ./.) 


>> Noun Phrases are: 
 ['Example Find mode']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Find')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Find', 'Find'), ('mode', 'mode'), ('.', '.')]



============================ Sentence 28 =============================

12, 15, 11, 11, 7, 13 11         Mode (Unimodal)    Find mode. 


>> Tokens are: 
 ['12', ',', '15', ',', '11', ',', '11', ',', '7', ',', '13', '11', 'Mode', '(', 'Unimodal', ')', 'Find', 'mode', '.']

>> Bigrams are: 
 [('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '13'), ('13', '11'), ('11', 'Mode'), ('Mode', '('), ('(', 'Unimodal'), ('Unimodal', ')'), (')', 'Find'), ('Find', 'mode'), ('mode', '.')]

>> Trigrams are: 
 [('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '13'), (',', '13', '11'), ('13', '11', 'Mode'), ('11', 'Mode', '('), ('Mode', '(', 'Unimodal'), ('(', 'Unimodal', ')'), ('Unimodal', ')', 'Find'), (')', 'Find', 'mode'), ('Find', 'mode', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('13', 'CD'), ('11', 'CD'), ('Mode', 'NNP'), ('(', '('), ('Unimodal', 'NNP'), (')', ')'), ('Find', 'NNP'), ('mode', 'NN'), ('.', '.')]

 (S
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  13/CD
  11/CD
  (NP Mode/NNP)
  (/(
  (NP Unimodal/NNP)
  )/)
  (NP Find/NNP mode/NN)
  ./.) 


>> Noun Phrases are: 
 ['Mode', 'Unimodal', 'Find mode']

>> Named Entities are: 
 [('ORGANIZATION', 'Unimodal')] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('11', '11'), ('Mode', 'mode'), ('(', '('), ('Unimodal', 'unimod'), (')', ')'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('11', '11'), ('Mode', 'mode'), ('(', '('), ('Unimodal', 'unimod'), (')', ')'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), ('11', '11'), ('Mode', 'Mode'), ('(', '('), ('Unimodal', 'Unimodal'), (')', ')'), ('Find', 'Find'), ('mode', 'mode'), ('.', '.')]



============================ Sentence 29 =============================

12, 15, 11, 11, 7, 12, 13 11, 12         Mode (Bimodal)           	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Mode (Cont..) Example   Find mode. 


>> Tokens are: 
 ['12', ',', '15', ',', '11', ',', '11', ',', '7', ',', '12', ',', '13', '11', ',', '12', 'Mode', '(', 'Bimodal', ')', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Mode', '(', 'Cont', '..', ')', 'Example', 'Find', 'mode', '.']

>> Bigrams are: 
 [('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '12'), ('12', ','), (',', '13'), ('13', '11'), ('11', ','), (',', '12'), ('12', 'Mode'), ('Mode', '('), ('(', 'Bimodal'), ('Bimodal', ')'), (')', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Mode'), ('Mode', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Example'), ('Example', 'Find'), ('Find', 'mode'), ('mode', '.')]

>> Trigrams are: 
 [('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '12'), (',', '12', ','), ('12', ',', '13'), (',', '13', '11'), ('13', '11', ','), ('11', ',', '12'), (',', '12', 'Mode'), ('12', 'Mode', '('), ('Mode', '(', 'Bimodal'), ('(', 'Bimodal', ')'), ('Bimodal', ')', 'Unit'), (')', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Mode'), ('›', 'Mode', '('), ('Mode', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Example'), (')', 'Example', 'Find'), ('Example', 'Find', 'mode'), ('Find', 'mode', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), ('11', 'CD'), (',', ','), ('12', 'CD'), ('Mode', 'NNP'), ('(', '('), ('Bimodal', 'NNP'), (')', ')'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Mode', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Example', 'NNP'), ('Find', 'NNP'), ('mode', 'NN'), ('.', '.')]

 (S
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  12/CD
  ,/,
  13/CD
  11/CD
  ,/,
  12/CD
  (NP Mode/NNP)
  (/(
  (NP Bimodal/NNP)
  )/)
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Mode/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Example/NNP Find/NNP mode/NN)
  ./.) 


>> Noun Phrases are: 
 ['Mode', 'Bimodal', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Mode', 'Cont ..', 'Example Find mode']

>> Named Entities are: 
 [('ORGANIZATION', 'Bimodal'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Example Find')] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'mode'), ('(', '('), ('Bimodal', 'bimod'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Mode', 'mode'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'mode'), ('(', '('), ('Bimodal', 'bimod'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Mode', 'mode'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Example', 'exampl'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('12', '12'), (',', ','), ('13', '13'), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'Mode'), ('(', '('), ('Bimodal', 'Bimodal'), (')', ')'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Mode', 'Mode'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Example', 'Example'), ('Find', 'Find'), ('mode', 'mode'), ('.', '.')]



============================ Sentence 30 =============================

12, 12 15, 11, 11, 7, 13, 7 7, 11, 12         Mode (Trimodal)    Find mode. 


>> Tokens are: 
 ['12', ',', '12', '15', ',', '11', ',', '11', ',', '7', ',', '13', ',', '7', '7', ',', '11', ',', '12', 'Mode', '(', 'Trimodal', ')', 'Find', 'mode', '.']

>> Bigrams are: 
 [('12', ','), (',', '12'), ('12', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '11'), ('11', ','), (',', '7'), ('7', ','), (',', '13'), ('13', ','), (',', '7'), ('7', '7'), ('7', ','), (',', '11'), ('11', ','), (',', '12'), ('12', 'Mode'), ('Mode', '('), ('(', 'Trimodal'), ('Trimodal', ')'), (')', 'Find'), ('Find', 'mode'), ('mode', '.')]

>> Trigrams are: 
 [('12', ',', '12'), (',', '12', '15'), ('12', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '11'), (',', '11', ','), ('11', ',', '7'), (',', '7', ','), ('7', ',', '13'), (',', '13', ','), ('13', ',', '7'), (',', '7', '7'), ('7', '7', ','), ('7', ',', '11'), (',', '11', ','), ('11', ',', '12'), (',', '12', 'Mode'), ('12', 'Mode', '('), ('Mode', '(', 'Trimodal'), ('(', 'Trimodal', ')'), ('Trimodal', ')', 'Find'), (')', 'Find', 'mode'), ('Find', 'mode', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('12', 'CD'), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('7', 'CD'), ('7', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('12', 'CD'), ('Mode', 'NNP'), ('(', '('), ('Trimodal', 'NNP'), (')', ')'), ('Find', 'NNP'), ('mode', 'NN'), ('.', '.')]

 (S
  12/CD
  ,/,
  12/CD
  15/CD
  ,/,
  11/CD
  ,/,
  11/CD
  ,/,
  7/CD
  ,/,
  13/CD
  ,/,
  7/CD
  7/CD
  ,/,
  11/CD
  ,/,
  12/CD
  (NP Mode/NNP)
  (/(
  (NP Trimodal/NNP)
  )/)
  (NP Find/NNP mode/NN)
  ./.) 


>> Noun Phrases are: 
 ['Mode', 'Trimodal', 'Find mode']

>> Named Entities are: 
 [('ORGANIZATION', 'Trimodal')] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('12', '12'), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('7', '7'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'mode'), ('(', '('), ('Trimodal', 'trimod'), (')', ')'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('12', '12'), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('7', '7'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'mode'), ('(', '('), ('Trimodal', 'trimod'), (')', ')'), ('Find', 'find'), ('mode', 'mode'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('12', '12'), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('11', '11'), (',', ','), ('7', '7'), (',', ','), ('13', '13'), (',', ','), ('7', '7'), ('7', '7'), (',', ','), ('11', '11'), (',', ','), ('12', '12'), ('Mode', 'Mode'), ('(', '('), ('Trimodal', 'Trimodal'), (')', ')'), ('Find', 'Find'), ('mode', 'mode'), ('.', '.')]



============================ Sentence 31 =============================

12, 15, 11, 10, 7, 14, 13 No Mode           	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Range The range of a set of data is the difference between the largest and the smallest number in the set. 


>> Tokens are: 
 ['12', ',', '15', ',', '11', ',', '10', ',', '7', ',', '14', ',', '13', 'No', 'Mode', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Range', 'The', 'range', 'set', 'data', 'difference', 'largest', 'smallest', 'number', 'set', '.']

>> Bigrams are: 
 [('12', ','), (',', '15'), ('15', ','), (',', '11'), ('11', ','), (',', '10'), ('10', ','), (',', '7'), ('7', ','), (',', '14'), ('14', ','), (',', '13'), ('13', 'No'), ('No', 'Mode'), ('Mode', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Range'), ('Range', 'The'), ('The', 'range'), ('range', 'set'), ('set', 'data'), ('data', 'difference'), ('difference', 'largest'), ('largest', 'smallest'), ('smallest', 'number'), ('number', 'set'), ('set', '.')]

>> Trigrams are: 
 [('12', ',', '15'), (',', '15', ','), ('15', ',', '11'), (',', '11', ','), ('11', ',', '10'), (',', '10', ','), ('10', ',', '7'), (',', '7', ','), ('7', ',', '14'), (',', '14', ','), ('14', ',', '13'), (',', '13', 'No'), ('13', 'No', 'Mode'), ('No', 'Mode', 'Unit'), ('Mode', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Range'), ('›', 'Range', 'The'), ('Range', 'The', 'range'), ('The', 'range', 'set'), ('range', 'set', 'data'), ('set', 'data', 'difference'), ('data', 'difference', 'largest'), ('difference', 'largest', 'smallest'), ('largest', 'smallest', 'number'), ('smallest', 'number', 'set'), ('number', 'set', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('11', 'CD'), (',', ','), ('10', 'CD'), (',', ','), ('7', 'CD'), (',', ','), ('14', 'CD'), (',', ','), ('13', 'CD'), ('No', 'NNP'), ('Mode', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Range', 'NNP'), ('The', 'DT'), ('range', 'NN'), ('set', 'VBN'), ('data', 'NNS'), ('difference', 'NN'), ('largest', 'JJS'), ('smallest', 'JJS'), ('number', 'NN'), ('set', 'VBN'), ('.', '.')]

 (S
  12/CD
  ,/,
  15/CD
  ,/,
  11/CD
  ,/,
  10/CD
  ,/,
  7/CD
  ,/,
  14/CD
  ,/,
  13/CD
  (NP No/NNP Mode/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Range/NNP)
  (NP The/DT range/NN)
  set/VBN
  (NP data/NNS difference/NN)
  largest/JJS
  smallest/JJS
  (NP number/NN)
  set/VBN
  ./.) 


>> Noun Phrases are: 
 ['No Mode Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Range', 'The range', 'data difference', 'number']

>> Named Entities are: 
 [('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('10', '10'), (',', ','), ('7', '7'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), ('No', 'no'), ('Mode', 'mode'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Range', 'rang'), ('The', 'the'), ('range', 'rang'), ('set', 'set'), ('data', 'data'), ('difference', 'differ'), ('largest', 'largest'), ('smallest', 'smallest'), ('number', 'number'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('10', '10'), (',', ','), ('7', '7'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), ('No', 'no'), ('Mode', 'mode'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Range', 'rang'), ('The', 'the'), ('range', 'rang'), ('set', 'set'), ('data', 'data'), ('difference', 'differ'), ('largest', 'largest'), ('smallest', 'smallest'), ('number', 'number'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('15', '15'), (',', ','), ('11', '11'), (',', ','), ('10', '10'), (',', ','), ('7', '7'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), ('No', 'No'), ('Mode', 'Mode'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Range', 'Range'), ('The', 'The'), ('range', 'range'), ('set', 'set'), ('data', 'data'), ('difference', 'difference'), ('largest', 'largest'), ('smallest', 'smallest'), ('number', 'number'), ('set', 'set'), ('.', '.')]



============================ Sentence 32 =============================

Example Find range for given data 40, 30, 43, 48, 26, 50, 55, 40, 34, 42, 47, 50    In our example largest number is 55, and subtract the smallest number is 26. 


>> Tokens are: 
 ['Example', 'Find', 'range', 'given', 'data', '40', ',', '30', ',', '43', ',', '48', ',', '26', ',', '50', ',', '55', ',', '40', ',', '34', ',', '42', ',', '47', ',', '50', 'In', 'example', 'largest', 'number', '55', ',', 'subtract', 'smallest', 'number', '26', '.']

>> Bigrams are: 
 [('Example', 'Find'), ('Find', 'range'), ('range', 'given'), ('given', 'data'), ('data', '40'), ('40', ','), (',', '30'), ('30', ','), (',', '43'), ('43', ','), (',', '48'), ('48', ','), (',', '26'), ('26', ','), (',', '50'), ('50', ','), (',', '55'), ('55', ','), (',', '40'), ('40', ','), (',', '34'), ('34', ','), (',', '42'), ('42', ','), (',', '47'), ('47', ','), (',', '50'), ('50', 'In'), ('In', 'example'), ('example', 'largest'), ('largest', 'number'), ('number', '55'), ('55', ','), (',', 'subtract'), ('subtract', 'smallest'), ('smallest', 'number'), ('number', '26'), ('26', '.')]

>> Trigrams are: 
 [('Example', 'Find', 'range'), ('Find', 'range', 'given'), ('range', 'given', 'data'), ('given', 'data', '40'), ('data', '40', ','), ('40', ',', '30'), (',', '30', ','), ('30', ',', '43'), (',', '43', ','), ('43', ',', '48'), (',', '48', ','), ('48', ',', '26'), (',', '26', ','), ('26', ',', '50'), (',', '50', ','), ('50', ',', '55'), (',', '55', ','), ('55', ',', '40'), (',', '40', ','), ('40', ',', '34'), (',', '34', ','), ('34', ',', '42'), (',', '42', ','), ('42', ',', '47'), (',', '47', ','), ('47', ',', '50'), (',', '50', 'In'), ('50', 'In', 'example'), ('In', 'example', 'largest'), ('example', 'largest', 'number'), ('largest', 'number', '55'), ('number', '55', ','), ('55', ',', 'subtract'), (',', 'subtract', 'smallest'), ('subtract', 'smallest', 'number'), ('smallest', 'number', '26'), ('number', '26', '.')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Find', 'NNP'), ('range', 'NN'), ('given', 'VBN'), ('data', 'NNS'), ('40', 'CD'), (',', ','), ('30', 'CD'), (',', ','), ('43', 'CD'), (',', ','), ('48', 'CD'), (',', ','), ('26', 'CD'), (',', ','), ('50', 'CD'), (',', ','), ('55', 'CD'), (',', ','), ('40', 'CD'), (',', ','), ('34', 'CD'), (',', ','), ('42', 'CD'), (',', ','), ('47', 'CD'), (',', ','), ('50', 'CD'), ('In', 'IN'), ('example', 'NN'), ('largest', 'JJS'), ('number', 'NN'), ('55', 'CD'), (',', ','), ('subtract', 'JJ'), ('smallest', 'JJS'), ('number', 'NN'), ('26', 'CD'), ('.', '.')]

 (S
  (NP Example/JJ Find/NNP range/NN)
  given/VBN
  (NP data/NNS)
  40/CD
  ,/,
  30/CD
  ,/,
  43/CD
  ,/,
  48/CD
  ,/,
  26/CD
  ,/,
  50/CD
  ,/,
  55/CD
  ,/,
  40/CD
  ,/,
  34/CD
  ,/,
  42/CD
  ,/,
  47/CD
  ,/,
  50/CD
  In/IN
  (NP example/NN)
  largest/JJS
  (NP number/NN)
  55/CD
  ,/,
  subtract/JJ
  smallest/JJS
  (NP number/NN)
  26/CD
  ./.) 


>> Noun Phrases are: 
 ['Example Find range', 'data', 'example', 'number', 'number']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Find')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('range', 'rang'), ('given', 'given'), ('data', 'data'), ('40', '40'), (',', ','), ('30', '30'), (',', ','), ('43', '43'), (',', ','), ('48', '48'), (',', ','), ('26', '26'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), (',', ','), ('40', '40'), (',', ','), ('34', '34'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('50', '50'), ('In', 'in'), ('example', 'exampl'), ('largest', 'largest'), ('number', 'number'), ('55', '55'), (',', ','), ('subtract', 'subtract'), ('smallest', 'smallest'), ('number', 'number'), ('26', '26'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Find', 'find'), ('range', 'rang'), ('given', 'given'), ('data', 'data'), ('40', '40'), (',', ','), ('30', '30'), (',', ','), ('43', '43'), (',', ','), ('48', '48'), (',', ','), ('26', '26'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), (',', ','), ('40', '40'), (',', ','), ('34', '34'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('50', '50'), ('In', 'in'), ('example', 'exampl'), ('largest', 'largest'), ('number', 'number'), ('55', '55'), (',', ','), ('subtract', 'subtract'), ('smallest', 'smallest'), ('number', 'number'), ('26', '26'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Find', 'Find'), ('range', 'range'), ('given', 'given'), ('data', 'data'), ('40', '40'), (',', ','), ('30', '30'), (',', ','), ('43', '43'), (',', ','), ('48', '48'), (',', ','), ('26', '26'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), (',', ','), ('40', '40'), (',', ','), ('34', '34'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('50', '50'), ('In', 'In'), ('example', 'example'), ('largest', 'largest'), ('number', 'number'), ('55', '55'), (',', ','), ('subtract', 'subtract'), ('smallest', 'smallest'), ('number', 'number'), ('26', '26'), ('.', '.')]



============================ Sentence 33 =============================

55 – 26 = 29      Range First, arrange the data in ascending order. 


>> Tokens are: 
 ['55', '–', '26', '=', '29', 'Range', 'First', ',', 'arrange', 'data', 'ascending', 'order', '.']

>> Bigrams are: 
 [('55', '–'), ('–', '26'), ('26', '='), ('=', '29'), ('29', 'Range'), ('Range', 'First'), ('First', ','), (',', 'arrange'), ('arrange', 'data'), ('data', 'ascending'), ('ascending', 'order'), ('order', '.')]

>> Trigrams are: 
 [('55', '–', '26'), ('–', '26', '='), ('26', '=', '29'), ('=', '29', 'Range'), ('29', 'Range', 'First'), ('Range', 'First', ','), ('First', ',', 'arrange'), (',', 'arrange', 'data'), ('arrange', 'data', 'ascending'), ('data', 'ascending', 'order'), ('ascending', 'order', '.')]

>> POS Tags are: 
 [('55', 'CD'), ('–', 'JJ'), ('26', 'CD'), ('=', '$'), ('29', 'CD'), ('Range', 'NNP'), ('First', 'NNP'), (',', ','), ('arrange', 'NN'), ('data', 'NNS'), ('ascending', 'VBG'), ('order', 'NN'), ('.', '.')]

 (S
  55/CD
  –/JJ
  26/CD
  =/$
  29/CD
  (NP Range/NNP First/NNP)
  ,/,
  (NP arrange/NN data/NNS)
  ascending/VBG
  (NP order/NN)
  ./.) 


>> Noun Phrases are: 
 ['Range First', 'arrange data', 'order']

>> Named Entities are: 
 [('PERSON', 'Range First')] 

>> Stemming using Porter Stemmer: 
 [('55', '55'), ('–', '–'), ('26', '26'), ('=', '='), ('29', '29'), ('Range', 'rang'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('55', '55'), ('–', '–'), ('26', '26'), ('=', '='), ('29', '29'), ('Range', 'rang'), ('First', 'first'), (',', ','), ('arrange', 'arrang'), ('data', 'data'), ('ascending', 'ascend'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('55', '55'), ('–', '–'), ('26', '26'), ('=', '='), ('29', '29'), ('Range', 'Range'), ('First', 'First'), (',', ','), ('arrange', 'arrange'), ('data', 'data'), ('ascending', 'ascending'), ('order', 'order'), ('.', '.')]



============================ Sentence 34 =============================

26, 30, 34, 40, 40, 42, 43, 47, 48, 50, 50, 55    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Standard deviation The Standard Deviation is a measure of how spread out any data are. 


>> Tokens are: 
 ['26', ',', '30', ',', '34', ',', '40', ',', '40', ',', '42', ',', '43', ',', '47', ',', '48', ',', '50', ',', '50', ',', '55', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Standard', 'deviation', 'The', 'Standard', 'Deviation', 'measure', 'spread', 'data', '.']

>> Bigrams are: 
 [('26', ','), (',', '30'), ('30', ','), (',', '34'), ('34', ','), (',', '40'), ('40', ','), (',', '40'), ('40', ','), (',', '42'), ('42', ','), (',', '43'), ('43', ','), (',', '47'), ('47', ','), (',', '48'), ('48', ','), (',', '50'), ('50', ','), (',', '50'), ('50', ','), (',', '55'), ('55', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Standard'), ('Standard', 'deviation'), ('deviation', 'The'), ('The', 'Standard'), ('Standard', 'Deviation'), ('Deviation', 'measure'), ('measure', 'spread'), ('spread', 'data'), ('data', '.')]

>> Trigrams are: 
 [('26', ',', '30'), (',', '30', ','), ('30', ',', '34'), (',', '34', ','), ('34', ',', '40'), (',', '40', ','), ('40', ',', '40'), (',', '40', ','), ('40', ',', '42'), (',', '42', ','), ('42', ',', '43'), (',', '43', ','), ('43', ',', '47'), (',', '47', ','), ('47', ',', '48'), (',', '48', ','), ('48', ',', '50'), (',', '50', ','), ('50', ',', '50'), (',', '50', ','), ('50', ',', '55'), (',', '55', 'Unit'), ('55', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Standard'), ('›', 'Standard', 'deviation'), ('Standard', 'deviation', 'The'), ('deviation', 'The', 'Standard'), ('The', 'Standard', 'Deviation'), ('Standard', 'Deviation', 'measure'), ('Deviation', 'measure', 'spread'), ('measure', 'spread', 'data'), ('spread', 'data', '.')]

>> POS Tags are: 
 [('26', 'CD'), (',', ','), ('30', 'CD'), (',', ','), ('34', 'CD'), (',', ','), ('40', 'CD'), (',', ','), ('40', 'CD'), (',', ','), ('42', 'CD'), (',', ','), ('43', 'CD'), (',', ','), ('47', 'CD'), (',', ','), ('48', 'CD'), (',', ','), ('50', 'CD'), (',', ','), ('50', 'CD'), (',', ','), ('55', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Standard', 'NNP'), ('deviation', 'NN'), ('The', 'DT'), ('Standard', 'NNP'), ('Deviation', 'NNP'), ('measure', 'NN'), ('spread', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  26/CD
  ,/,
  30/CD
  ,/,
  34/CD
  ,/,
  40/CD
  ,/,
  40/CD
  ,/,
  42/CD
  ,/,
  43/CD
  ,/,
  47/CD
  ,/,
  48/CD
  ,/,
  50/CD
  ,/,
  50/CD
  ,/,
  55/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Standard/NNP deviation/NN)
  (NP
    The/DT
    Standard/NNP
    Deviation/NNP
    measure/NN
    spread/NN
    data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Standard deviation', 'The Standard Deviation measure spread data']

>> Named Entities are: 
 [('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Standard Deviation')] 

>> Stemming using Porter Stemmer: 
 [('26', '26'), (',', ','), ('30', '30'), (',', ','), ('34', '34'), (',', ','), ('40', '40'), (',', ','), ('40', '40'), (',', ','), ('42', '42'), (',', ','), ('43', '43'), (',', ','), ('47', '47'), (',', ','), ('48', '48'), (',', ','), ('50', '50'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('The', 'the'), ('Standard', 'standard'), ('Deviation', 'deviat'), ('measure', 'measur'), ('spread', 'spread'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26', '26'), (',', ','), ('30', '30'), (',', ','), ('34', '34'), (',', ','), ('40', '40'), (',', ','), ('40', '40'), (',', ','), ('42', '42'), (',', ','), ('43', '43'), (',', ','), ('47', '47'), (',', ','), ('48', '48'), (',', ','), ('50', '50'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('The', 'the'), ('Standard', 'standard'), ('Deviation', 'deviat'), ('measure', 'measur'), ('spread', 'spread'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('26', '26'), (',', ','), ('30', '30'), (',', ','), ('34', '34'), (',', ','), ('40', '40'), (',', ','), ('40', '40'), (',', ','), ('42', '42'), (',', ','), ('43', '43'), (',', ','), ('47', '47'), (',', ','), ('48', '48'), (',', ','), ('50', '50'), (',', ','), ('50', '50'), (',', ','), ('55', '55'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('The', 'The'), ('Standard', 'Standard'), ('Deviation', 'Deviation'), ('measure', 'measure'), ('spread', 'spread'), ('data', 'data'), ('.', '.')]



============================ Sentence 35 =============================

Its symbol is σ (the Greek letter sigma). 


>> Tokens are: 
 ['Its', 'symbol', 'σ', '(', 'Greek', 'letter', 'sigma', ')', '.']

>> Bigrams are: 
 [('Its', 'symbol'), ('symbol', 'σ'), ('σ', '('), ('(', 'Greek'), ('Greek', 'letter'), ('letter', 'sigma'), ('sigma', ')'), (')', '.')]

>> Trigrams are: 
 [('Its', 'symbol', 'σ'), ('symbol', 'σ', '('), ('σ', '(', 'Greek'), ('(', 'Greek', 'letter'), ('Greek', 'letter', 'sigma'), ('letter', 'sigma', ')'), ('sigma', ')', '.')]

>> POS Tags are: 
 [('Its', 'PRP$'), ('symbol', 'NN'), ('σ', 'NN'), ('(', '('), ('Greek', 'JJ'), ('letter', 'NN'), ('sigma', 'NN'), (')', ')'), ('.', '.')]

 (S
  Its/PRP$
  (NP symbol/NN σ/NN)
  (/(
  (NP Greek/JJ letter/NN sigma/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['symbol σ', 'Greek letter sigma']

>> Named Entities are: 
 [('GPE', 'Greek')] 

>> Stemming using Porter Stemmer: 
 [('Its', 'it'), ('symbol', 'symbol'), ('σ', 'σ'), ('(', '('), ('Greek', 'greek'), ('letter', 'letter'), ('sigma', 'sigma'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Its', 'it'), ('symbol', 'symbol'), ('σ', 'σ'), ('(', '('), ('Greek', 'greek'), ('letter', 'letter'), ('sigma', 'sigma'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Its', 'Its'), ('symbol', 'symbol'), ('σ', 'σ'), ('(', '('), ('Greek', 'Greek'), ('letter', 'letter'), ('sigma', 'sigma'), (')', ')'), ('.', '.')]



============================ Sentence 36 =============================

Standard Deviation is Square root of sample variance. 


>> Tokens are: 
 ['Standard', 'Deviation', 'Square', 'root', 'sample', 'variance', '.']

>> Bigrams are: 
 [('Standard', 'Deviation'), ('Deviation', 'Square'), ('Square', 'root'), ('root', 'sample'), ('sample', 'variance'), ('variance', '.')]

>> Trigrams are: 
 [('Standard', 'Deviation', 'Square'), ('Deviation', 'Square', 'root'), ('Square', 'root', 'sample'), ('root', 'sample', 'variance'), ('sample', 'variance', '.')]

>> POS Tags are: 
 [('Standard', 'NNP'), ('Deviation', 'NNP'), ('Square', 'NNP'), ('root', 'NN'), ('sample', 'NN'), ('variance', 'NN'), ('.', '.')]

 (S
  (NP
    Standard/NNP
    Deviation/NNP
    Square/NNP
    root/NN
    sample/NN
    variance/NN)
  ./.) 


>> Noun Phrases are: 
 ['Standard Deviation Square root sample variance']

>> Named Entities are: 
 [('PERSON', 'Standard'), ('PERSON', 'Deviation Square')] 

>> Stemming using Porter Stemmer: 
 [('Standard', 'standard'), ('Deviation', 'deviat'), ('Square', 'squar'), ('root', 'root'), ('sample', 'sampl'), ('variance', 'varianc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Standard', 'standard'), ('Deviation', 'deviat'), ('Square', 'squar'), ('root', 'root'), ('sample', 'sampl'), ('variance', 'varianc'), ('.', '.')]

>> Lemmatization: 
 [('Standard', 'Standard'), ('Deviation', 'Deviation'), ('Square', 'Square'), ('root', 'root'), ('sample', 'sample'), ('variance', 'variance'), ('.', '.')]



============================ Sentence 37 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Standard deviation (Cont..) The Variance is defined as: The average of the squared differences from the Mean. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Standard', 'deviation', '(', 'Cont', '..', ')', 'The', 'Variance', 'defined', ':', 'The', 'average', 'squared', 'differences', 'Mean', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Standard'), ('Standard', 'deviation'), ('deviation', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'The'), ('The', 'Variance'), ('Variance', 'defined'), ('defined', ':'), (':', 'The'), ('The', 'average'), ('average', 'squared'), ('squared', 'differences'), ('differences', 'Mean'), ('Mean', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Standard'), ('›', 'Standard', 'deviation'), ('Standard', 'deviation', '('), ('deviation', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'The'), (')', 'The', 'Variance'), ('The', 'Variance', 'defined'), ('Variance', 'defined', ':'), ('defined', ':', 'The'), (':', 'The', 'average'), ('The', 'average', 'squared'), ('average', 'squared', 'differences'), ('squared', 'differences', 'Mean'), ('differences', 'Mean', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Standard', 'NNP'), ('deviation', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('The', 'DT'), ('Variance', 'NN'), ('defined', 'VBD'), (':', ':'), ('The', 'DT'), ('average', 'NN'), ('squared', 'VBD'), ('differences', 'NNS'), ('Mean', 'NNP'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Standard/NNP deviation/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP The/DT Variance/NN)
  defined/VBD
  :/:
  (NP The/DT average/NN)
  squared/VBD
  (NP differences/NNS Mean/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Standard deviation', 'Cont ..', 'The Variance', 'The average', 'differences Mean']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('ORGANIZATION', 'Variance')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('Variance', 'varianc'), ('defined', 'defin'), (':', ':'), ('The', 'the'), ('average', 'averag'), ('squared', 'squar'), ('differences', 'differ'), ('Mean', 'mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('Variance', 'varianc'), ('defined', 'defin'), (':', ':'), ('The', 'the'), ('average', 'averag'), ('squared', 'squar'), ('differences', 'differ'), ('Mean', 'mean'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('The', 'The'), ('Variance', 'Variance'), ('defined', 'defined'), (':', ':'), ('The', 'The'), ('average', 'average'), ('squared', 'squared'), ('differences', 'difference'), ('Mean', 'Mean'), ('.', '.')]



============================ Sentence 38 =============================

To calculate the variance follow these steps: Calculate the mean, x. 


>> Tokens are: 
 ['To', 'calculate', 'variance', 'follow', 'steps', ':', 'Calculate', 'mean', ',', 'x', '.']

>> Bigrams are: 
 [('To', 'calculate'), ('calculate', 'variance'), ('variance', 'follow'), ('follow', 'steps'), ('steps', ':'), (':', 'Calculate'), ('Calculate', 'mean'), ('mean', ','), (',', 'x'), ('x', '.')]

>> Trigrams are: 
 [('To', 'calculate', 'variance'), ('calculate', 'variance', 'follow'), ('variance', 'follow', 'steps'), ('follow', 'steps', ':'), ('steps', ':', 'Calculate'), (':', 'Calculate', 'mean'), ('Calculate', 'mean', ','), ('mean', ',', 'x'), (',', 'x', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('calculate', 'VB'), ('variance', 'NN'), ('follow', 'JJ'), ('steps', 'NNS'), (':', ':'), ('Calculate', 'NNP'), ('mean', 'NN'), (',', ','), ('x', 'NN'), ('.', '.')]

 (S
  To/TO
  calculate/VB
  (NP variance/NN)
  (NP follow/JJ steps/NNS)
  :/:
  (NP Calculate/NNP mean/NN)
  ,/,
  (NP x/NN)
  ./.) 


>> Noun Phrases are: 
 ['variance', 'follow steps', 'Calculate mean', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('calculate', 'calcul'), ('variance', 'varianc'), ('follow', 'follow'), ('steps', 'step'), (':', ':'), ('Calculate', 'calcul'), ('mean', 'mean'), (',', ','), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('calculate', 'calcul'), ('variance', 'varianc'), ('follow', 'follow'), ('steps', 'step'), (':', ':'), ('Calculate', 'calcul'), ('mean', 'mean'), (',', ','), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('calculate', 'calculate'), ('variance', 'variance'), ('follow', 'follow'), ('steps', 'step'), (':', ':'), ('Calculate', 'Calculate'), ('mean', 'mean'), (',', ','), ('x', 'x'), ('.', '.')]



============================ Sentence 39 =============================

Write a table that subtracts the mean from each observed value. 


>> Tokens are: 
 ['Write', 'table', 'subtracts', 'mean', 'observed', 'value', '.']

>> Bigrams are: 
 [('Write', 'table'), ('table', 'subtracts'), ('subtracts', 'mean'), ('mean', 'observed'), ('observed', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Write', 'table', 'subtracts'), ('table', 'subtracts', 'mean'), ('subtracts', 'mean', 'observed'), ('mean', 'observed', 'value'), ('observed', 'value', '.')]

>> POS Tags are: 
 [('Write', 'NNP'), ('table', 'JJ'), ('subtracts', 'NNS'), ('mean', 'VBP'), ('observed', 'JJ'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Write/NNP)
  (NP table/JJ subtracts/NNS)
  mean/VBP
  (NP observed/JJ value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Write', 'table subtracts', 'observed value']

>> Named Entities are: 
 [('GPE', 'Write')] 

>> Stemming using Porter Stemmer: 
 [('Write', 'write'), ('table', 'tabl'), ('subtracts', 'subtract'), ('mean', 'mean'), ('observed', 'observ'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Write', 'write'), ('table', 'tabl'), ('subtracts', 'subtract'), ('mean', 'mean'), ('observed', 'observ'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Write', 'Write'), ('table', 'table'), ('subtracts', 'subtracts'), ('mean', 'mean'), ('observed', 'observed'), ('value', 'value'), ('.', '.')]



============================ Sentence 40 =============================

Square each of the differences, add this column. 


>> Tokens are: 
 ['Square', 'differences', ',', 'add', 'column', '.']

>> Bigrams are: 
 [('Square', 'differences'), ('differences', ','), (',', 'add'), ('add', 'column'), ('column', '.')]

>> Trigrams are: 
 [('Square', 'differences', ','), ('differences', ',', 'add'), (',', 'add', 'column'), ('add', 'column', '.')]

>> POS Tags are: 
 [('Square', 'NNP'), ('differences', 'NNS'), (',', ','), ('add', 'JJ'), ('column', 'NN'), ('.', '.')]

 (S (NP Square/NNP differences/NNS) ,/, (NP add/JJ column/NN) ./.) 


>> Noun Phrases are: 
 ['Square differences', 'add column']

>> Named Entities are: 
 [('GPE', 'Square')] 

>> Stemming using Porter Stemmer: 
 [('Square', 'squar'), ('differences', 'differ'), (',', ','), ('add', 'add'), ('column', 'column'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Square', 'squar'), ('differences', 'differ'), (',', ','), ('add', 'add'), ('column', 'column'), ('.', '.')]

>> Lemmatization: 
 [('Square', 'Square'), ('differences', 'difference'), (',', ','), ('add', 'add'), ('column', 'column'), ('.', '.')]



============================ Sentence 41 =============================

Divide by n -1 where n is the number of items in the sample, this is the variance (In actual case take n). 


>> Tokens are: 
 ['Divide', 'n', '-1', 'n', 'number', 'items', 'sample', ',', 'variance', '(', 'In', 'actual', 'case', 'take', 'n', ')', '.']

>> Bigrams are: 
 [('Divide', 'n'), ('n', '-1'), ('-1', 'n'), ('n', 'number'), ('number', 'items'), ('items', 'sample'), ('sample', ','), (',', 'variance'), ('variance', '('), ('(', 'In'), ('In', 'actual'), ('actual', 'case'), ('case', 'take'), ('take', 'n'), ('n', ')'), (')', '.')]

>> Trigrams are: 
 [('Divide', 'n', '-1'), ('n', '-1', 'n'), ('-1', 'n', 'number'), ('n', 'number', 'items'), ('number', 'items', 'sample'), ('items', 'sample', ','), ('sample', ',', 'variance'), (',', 'variance', '('), ('variance', '(', 'In'), ('(', 'In', 'actual'), ('In', 'actual', 'case'), ('actual', 'case', 'take'), ('case', 'take', 'n'), ('take', 'n', ')'), ('n', ')', '.')]

>> POS Tags are: 
 [('Divide', 'NNP'), ('n', 'CC'), ('-1', 'NNP'), ('n', 'IN'), ('number', 'NN'), ('items', 'NNS'), ('sample', 'JJ'), (',', ','), ('variance', 'NN'), ('(', '('), ('In', 'IN'), ('actual', 'JJ'), ('case', 'NN'), ('take', 'VB'), ('n', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Divide/NNP)
  n/CC
  (NP -1/NNP)
  n/IN
  (NP number/NN items/NNS)
  sample/JJ
  ,/,
  (NP variance/NN)
  (/(
  In/IN
  (NP actual/JJ case/NN)
  take/VB
  (NP n/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Divide', '-1', 'number items', 'variance', 'actual case', 'n']

>> Named Entities are: 
 [('GPE', 'Divide')] 

>> Stemming using Porter Stemmer: 
 [('Divide', 'divid'), ('n', 'n'), ('-1', '-1'), ('n', 'n'), ('number', 'number'), ('items', 'item'), ('sample', 'sampl'), (',', ','), ('variance', 'varianc'), ('(', '('), ('In', 'in'), ('actual', 'actual'), ('case', 'case'), ('take', 'take'), ('n', 'n'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Divide', 'divid'), ('n', 'n'), ('-1', '-1'), ('n', 'n'), ('number', 'number'), ('items', 'item'), ('sample', 'sampl'), (',', ','), ('variance', 'varianc'), ('(', '('), ('In', 'in'), ('actual', 'actual'), ('case', 'case'), ('take', 'take'), ('n', 'n'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Divide', 'Divide'), ('n', 'n'), ('-1', '-1'), ('n', 'n'), ('number', 'number'), ('items', 'item'), ('sample', 'sample'), (',', ','), ('variance', 'variance'), ('(', '('), ('In', 'In'), ('actual', 'actual'), ('case', 'case'), ('take', 'take'), ('n', 'n'), (')', ')'), ('.', '.')]



============================ Sentence 42 =============================

To get the standard deviation we take the square root of the variance. 


>> Tokens are: 
 ['To', 'get', 'standard', 'deviation', 'take', 'square', 'root', 'variance', '.']

>> Bigrams are: 
 [('To', 'get'), ('get', 'standard'), ('standard', 'deviation'), ('deviation', 'take'), ('take', 'square'), ('square', 'root'), ('root', 'variance'), ('variance', '.')]

>> Trigrams are: 
 [('To', 'get', 'standard'), ('get', 'standard', 'deviation'), ('standard', 'deviation', 'take'), ('deviation', 'take', 'square'), ('take', 'square', 'root'), ('square', 'root', 'variance'), ('root', 'variance', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('get', 'VB'), ('standard', 'JJ'), ('deviation', 'NN'), ('take', 'VB'), ('square', 'JJ'), ('root', 'NN'), ('variance', 'NN'), ('.', '.')]

 (S
  To/TO
  get/VB
  (NP standard/JJ deviation/NN)
  take/VB
  (NP square/JJ root/NN variance/NN)
  ./.) 


>> Noun Phrases are: 
 ['standard deviation', 'square root variance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('get', 'get'), ('standard', 'standard'), ('deviation', 'deviat'), ('take', 'take'), ('square', 'squar'), ('root', 'root'), ('variance', 'varianc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('get', 'get'), ('standard', 'standard'), ('deviation', 'deviat'), ('take', 'take'), ('square', 'squar'), ('root', 'root'), ('variance', 'varianc'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('get', 'get'), ('standard', 'standard'), ('deviation', 'deviation'), ('take', 'take'), ('square', 'square'), ('root', 'root'), ('variance', 'variance'), ('.', '.')]



============================ Sentence 43 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Standard deviation - example The owner of the Indian restaurant is interested in how much people spend at the restaurant. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Standard', 'deviation', '-', 'example', 'The', 'owner', 'Indian', 'restaurant', 'interested', 'much', 'people', 'spend', 'restaurant', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Standard'), ('Standard', 'deviation'), ('deviation', '-'), ('-', 'example'), ('example', 'The'), ('The', 'owner'), ('owner', 'Indian'), ('Indian', 'restaurant'), ('restaurant', 'interested'), ('interested', 'much'), ('much', 'people'), ('people', 'spend'), ('spend', 'restaurant'), ('restaurant', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Standard'), ('›', 'Standard', 'deviation'), ('Standard', 'deviation', '-'), ('deviation', '-', 'example'), ('-', 'example', 'The'), ('example', 'The', 'owner'), ('The', 'owner', 'Indian'), ('owner', 'Indian', 'restaurant'), ('Indian', 'restaurant', 'interested'), ('restaurant', 'interested', 'much'), ('interested', 'much', 'people'), ('much', 'people', 'spend'), ('people', 'spend', 'restaurant'), ('spend', 'restaurant', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Standard', 'NNP'), ('deviation', 'NN'), ('-', ':'), ('example', 'NN'), ('The', 'DT'), ('owner', 'NN'), ('Indian', 'JJ'), ('restaurant', 'NN'), ('interested', 'JJ'), ('much', 'JJ'), ('people', 'NNS'), ('spend', 'VBP'), ('restaurant', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Standard/NNP deviation/NN)
  -/:
  (NP example/NN)
  (NP The/DT owner/NN)
  (NP Indian/JJ restaurant/NN)
  (NP interested/JJ much/JJ people/NNS)
  spend/VBP
  (NP restaurant/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Standard deviation', 'example', 'The owner', 'Indian restaurant', 'interested much people', 'restaurant']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Indian')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('-', '-'), ('example', 'exampl'), ('The', 'the'), ('owner', 'owner'), ('Indian', 'indian'), ('restaurant', 'restaur'), ('interested', 'interest'), ('much', 'much'), ('people', 'peopl'), ('spend', 'spend'), ('restaurant', 'restaur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('-', '-'), ('example', 'exampl'), ('The', 'the'), ('owner', 'owner'), ('Indian', 'indian'), ('restaurant', 'restaur'), ('interested', 'interest'), ('much', 'much'), ('people', 'peopl'), ('spend', 'spend'), ('restaurant', 'restaur'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('-', '-'), ('example', 'example'), ('The', 'The'), ('owner', 'owner'), ('Indian', 'Indian'), ('restaurant', 'restaurant'), ('interested', 'interested'), ('much', 'much'), ('people', 'people'), ('spend', 'spend'), ('restaurant', 'restaurant'), ('.', '.')]



============================ Sentence 44 =============================

He examines 10 randomly selected receipts for parties and writes down the following data. 


>> Tokens are: 
 ['He', 'examines', '10', 'randomly', 'selected', 'receipts', 'parties', 'writes', 'following', 'data', '.']

>> Bigrams are: 
 [('He', 'examines'), ('examines', '10'), ('10', 'randomly'), ('randomly', 'selected'), ('selected', 'receipts'), ('receipts', 'parties'), ('parties', 'writes'), ('writes', 'following'), ('following', 'data'), ('data', '.')]

>> Trigrams are: 
 [('He', 'examines', '10'), ('examines', '10', 'randomly'), ('10', 'randomly', 'selected'), ('randomly', 'selected', 'receipts'), ('selected', 'receipts', 'parties'), ('receipts', 'parties', 'writes'), ('parties', 'writes', 'following'), ('writes', 'following', 'data'), ('following', 'data', '.')]

>> POS Tags are: 
 [('He', 'PRP'), ('examines', 'VBZ'), ('10', 'CD'), ('randomly', 'RB'), ('selected', 'VBN'), ('receipts', 'NNS'), ('parties', 'NNS'), ('writes', 'VBZ'), ('following', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  He/PRP
  examines/VBZ
  10/CD
  randomly/RB
  selected/VBN
  (NP receipts/NNS parties/NNS)
  writes/VBZ
  following/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['receipts parties', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('He', 'he'), ('examines', 'examin'), ('10', '10'), ('randomly', 'randomli'), ('selected', 'select'), ('receipts', 'receipt'), ('parties', 'parti'), ('writes', 'write'), ('following', 'follow'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('He', 'he'), ('examines', 'examin'), ('10', '10'), ('randomly', 'random'), ('selected', 'select'), ('receipts', 'receipt'), ('parties', 'parti'), ('writes', 'write'), ('following', 'follow'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('He', 'He'), ('examines', 'examines'), ('10', '10'), ('randomly', 'randomly'), ('selected', 'selected'), ('receipts', 'receipt'), ('parties', 'party'), ('writes', 'writes'), ('following', 'following'), ('data', 'data'), ('.', '.')]



============================ Sentence 45 =============================

44, 50, 38, 96, 42, 47, 40, 39, 46, 50  Find out Mean (1st step) Mean is 49.2 Write a table that subtracts the mean from each observed value. 


>> Tokens are: 
 ['44', ',', '50', ',', '38', ',', '96', ',', '42', ',', '47', ',', '40', ',', '39', ',', '46', ',', '50', 'Find', 'Mean', '(', '1st', 'step', ')', 'Mean', '49.2', 'Write', 'table', 'subtracts', 'mean', 'observed', 'value', '.']

>> Bigrams are: 
 [('44', ','), (',', '50'), ('50', ','), (',', '38'), ('38', ','), (',', '96'), ('96', ','), (',', '42'), ('42', ','), (',', '47'), ('47', ','), (',', '40'), ('40', ','), (',', '39'), ('39', ','), (',', '46'), ('46', ','), (',', '50'), ('50', 'Find'), ('Find', 'Mean'), ('Mean', '('), ('(', '1st'), ('1st', 'step'), ('step', ')'), (')', 'Mean'), ('Mean', '49.2'), ('49.2', 'Write'), ('Write', 'table'), ('table', 'subtracts'), ('subtracts', 'mean'), ('mean', 'observed'), ('observed', 'value'), ('value', '.')]

>> Trigrams are: 
 [('44', ',', '50'), (',', '50', ','), ('50', ',', '38'), (',', '38', ','), ('38', ',', '96'), (',', '96', ','), ('96', ',', '42'), (',', '42', ','), ('42', ',', '47'), (',', '47', ','), ('47', ',', '40'), (',', '40', ','), ('40', ',', '39'), (',', '39', ','), ('39', ',', '46'), (',', '46', ','), ('46', ',', '50'), (',', '50', 'Find'), ('50', 'Find', 'Mean'), ('Find', 'Mean', '('), ('Mean', '(', '1st'), ('(', '1st', 'step'), ('1st', 'step', ')'), ('step', ')', 'Mean'), (')', 'Mean', '49.2'), ('Mean', '49.2', 'Write'), ('49.2', 'Write', 'table'), ('Write', 'table', 'subtracts'), ('table', 'subtracts', 'mean'), ('subtracts', 'mean', 'observed'), ('mean', 'observed', 'value'), ('observed', 'value', '.')]

>> POS Tags are: 
 [('44', 'CD'), (',', ','), ('50', 'CD'), (',', ','), ('38', 'CD'), (',', ','), ('96', 'CD'), (',', ','), ('42', 'CD'), (',', ','), ('47', 'CD'), (',', ','), ('40', 'CD'), (',', ','), ('39', 'CD'), (',', ','), ('46', 'CD'), (',', ','), ('50', 'CD'), ('Find', 'NNP'), ('Mean', 'NNP'), ('(', '('), ('1st', 'CD'), ('step', 'NN'), (')', ')'), ('Mean', '$'), ('49.2', 'CD'), ('Write', 'NNP'), ('table', 'JJ'), ('subtracts', 'NNS'), ('mean', 'VBP'), ('observed', 'JJ'), ('value', 'NN'), ('.', '.')]

 (S
  44/CD
  ,/,
  50/CD
  ,/,
  38/CD
  ,/,
  96/CD
  ,/,
  42/CD
  ,/,
  47/CD
  ,/,
  40/CD
  ,/,
  39/CD
  ,/,
  46/CD
  ,/,
  50/CD
  (NP Find/NNP Mean/NNP)
  (/(
  1st/CD
  (NP step/NN)
  )/)
  Mean/$
  49.2/CD
  (NP Write/NNP)
  (NP table/JJ subtracts/NNS)
  mean/VBP
  (NP observed/JJ value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Find Mean', 'step', 'Write', 'table subtracts', 'observed value']

>> Named Entities are: 
 [('FACILITY', 'Write')] 

>> Stemming using Porter Stemmer: 
 [('44', '44'), (',', ','), ('50', '50'), (',', ','), ('38', '38'), (',', ','), ('96', '96'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('40', '40'), (',', ','), ('39', '39'), (',', ','), ('46', '46'), (',', ','), ('50', '50'), ('Find', 'find'), ('Mean', 'mean'), ('(', '('), ('1st', '1st'), ('step', 'step'), (')', ')'), ('Mean', 'mean'), ('49.2', '49.2'), ('Write', 'write'), ('table', 'tabl'), ('subtracts', 'subtract'), ('mean', 'mean'), ('observed', 'observ'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('44', '44'), (',', ','), ('50', '50'), (',', ','), ('38', '38'), (',', ','), ('96', '96'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('40', '40'), (',', ','), ('39', '39'), (',', ','), ('46', '46'), (',', ','), ('50', '50'), ('Find', 'find'), ('Mean', 'mean'), ('(', '('), ('1st', '1st'), ('step', 'step'), (')', ')'), ('Mean', 'mean'), ('49.2', '49.2'), ('Write', 'write'), ('table', 'tabl'), ('subtracts', 'subtract'), ('mean', 'mean'), ('observed', 'observ'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('44', '44'), (',', ','), ('50', '50'), (',', ','), ('38', '38'), (',', ','), ('96', '96'), (',', ','), ('42', '42'), (',', ','), ('47', '47'), (',', ','), ('40', '40'), (',', ','), ('39', '39'), (',', ','), ('46', '46'), (',', ','), ('50', '50'), ('Find', 'Find'), ('Mean', 'Mean'), ('(', '('), ('1st', '1st'), ('step', 'step'), (')', ')'), ('Mean', 'Mean'), ('49.2', '49.2'), ('Write', 'Write'), ('table', 'table'), ('subtracts', 'subtracts'), ('mean', 'mean'), ('observed', 'observed'), ('value', 'value'), ('.', '.')]



============================ Sentence 46 =============================

(2nd step)     	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Standard deviation – example (Cont..) 	X	X – Mean	( X – Mean )2 	44	-5.2	27.04 	50	0.8	0.64 	38	11.2	125.44 	96	46.8	2190.24 	42	-7.2	51.84 	47	-2.2	4.84 	40	-9.2	84.64 	39	-10.2	104.04 	46	-3.2	10.24 	50	0.8	0.64 	Total		2600.4  Step : 3  Step : 4    S2 288.7 ~ 289 Step : 5  S   S   17    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Standard deviation – example (Cont..) Standard deviation can be thought of measuring how far the data values lie from the mean, we take the mean and move on standard deviation in either direction. 


>> Tokens are: 
 ['(', '2nd', 'step', ')', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Standard', 'deviation', '–', 'example', '(', 'Cont', '..', ')', 'X', 'X', '–', 'Mean', '(', 'X', '–', 'Mean', ')', '2', '44', '-5.2', '27.04', '50', '0.8', '0.64', '38', '11.2', '125.44', '96', '46.8', '2190.24', '42', '-7.2', '51.84', '47', '-2.2', '4.84', '40', '-9.2', '84.64', '39', '-10.2', '104.04', '46', '-3.2', '10.24', '50', '0.8', '0.64', 'Total', '2600.4', 'Step', ':', '3', 'Step', ':', '4', 'S2', '288.7', '~', '289', 'Step', ':', '5', 'S', 'S', '17', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Standard', 'deviation', '–', 'example', '(', 'Cont', '..', ')', 'Standard', 'deviation', 'thought', 'measuring', 'far', 'data', 'values', 'lie', 'mean', ',', 'take', 'mean', 'move', 'standard', 'deviation', 'either', 'direction', '.']

>> Bigrams are: 
 [('(', '2nd'), ('2nd', 'step'), ('step', ')'), (')', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Standard'), ('Standard', 'deviation'), ('deviation', '–'), ('–', 'example'), ('example', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'X'), ('X', 'X'), ('X', '–'), ('–', 'Mean'), ('Mean', '('), ('(', 'X'), ('X', '–'), ('–', 'Mean'), ('Mean', ')'), (')', '2'), ('2', '44'), ('44', '-5.2'), ('-5.2', '27.04'), ('27.04', '50'), ('50', '0.8'), ('0.8', '0.64'), ('0.64', '38'), ('38', '11.2'), ('11.2', '125.44'), ('125.44', '96'), ('96', '46.8'), ('46.8', '2190.24'), ('2190.24', '42'), ('42', '-7.2'), ('-7.2', '51.84'), ('51.84', '47'), ('47', '-2.2'), ('-2.2', '4.84'), ('4.84', '40'), ('40', '-9.2'), ('-9.2', '84.64'), ('84.64', '39'), ('39', '-10.2'), ('-10.2', '104.04'), ('104.04', '46'), ('46', '-3.2'), ('-3.2', '10.24'), ('10.24', '50'), ('50', '0.8'), ('0.8', '0.64'), ('0.64', 'Total'), ('Total', '2600.4'), ('2600.4', 'Step'), ('Step', ':'), (':', '3'), ('3', 'Step'), ('Step', ':'), (':', '4'), ('4', 'S2'), ('S2', '288.7'), ('288.7', '~'), ('~', '289'), ('289', 'Step'), ('Step', ':'), (':', '5'), ('5', 'S'), ('S', 'S'), ('S', '17'), ('17', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Standard'), ('Standard', 'deviation'), ('deviation', '–'), ('–', 'example'), ('example', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Standard'), ('Standard', 'deviation'), ('deviation', 'thought'), ('thought', 'measuring'), ('measuring', 'far'), ('far', 'data'), ('data', 'values'), ('values', 'lie'), ('lie', 'mean'), ('mean', ','), (',', 'take'), ('take', 'mean'), ('mean', 'move'), ('move', 'standard'), ('standard', 'deviation'), ('deviation', 'either'), ('either', 'direction'), ('direction', '.')]

>> Trigrams are: 
 [('(', '2nd', 'step'), ('2nd', 'step', ')'), ('step', ')', 'Unit'), (')', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Standard'), ('›', 'Standard', 'deviation'), ('Standard', 'deviation', '–'), ('deviation', '–', 'example'), ('–', 'example', '('), ('example', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'X'), (')', 'X', 'X'), ('X', 'X', '–'), ('X', '–', 'Mean'), ('–', 'Mean', '('), ('Mean', '(', 'X'), ('(', 'X', '–'), ('X', '–', 'Mean'), ('–', 'Mean', ')'), ('Mean', ')', '2'), (')', '2', '44'), ('2', '44', '-5.2'), ('44', '-5.2', '27.04'), ('-5.2', '27.04', '50'), ('27.04', '50', '0.8'), ('50', '0.8', '0.64'), ('0.8', '0.64', '38'), ('0.64', '38', '11.2'), ('38', '11.2', '125.44'), ('11.2', '125.44', '96'), ('125.44', '96', '46.8'), ('96', '46.8', '2190.24'), ('46.8', '2190.24', '42'), ('2190.24', '42', '-7.2'), ('42', '-7.2', '51.84'), ('-7.2', '51.84', '47'), ('51.84', '47', '-2.2'), ('47', '-2.2', '4.84'), ('-2.2', '4.84', '40'), ('4.84', '40', '-9.2'), ('40', '-9.2', '84.64'), ('-9.2', '84.64', '39'), ('84.64', '39', '-10.2'), ('39', '-10.2', '104.04'), ('-10.2', '104.04', '46'), ('104.04', '46', '-3.2'), ('46', '-3.2', '10.24'), ('-3.2', '10.24', '50'), ('10.24', '50', '0.8'), ('50', '0.8', '0.64'), ('0.8', '0.64', 'Total'), ('0.64', 'Total', '2600.4'), ('Total', '2600.4', 'Step'), ('2600.4', 'Step', ':'), ('Step', ':', '3'), (':', '3', 'Step'), ('3', 'Step', ':'), ('Step', ':', '4'), (':', '4', 'S2'), ('4', 'S2', '288.7'), ('S2', '288.7', '~'), ('288.7', '~', '289'), ('~', '289', 'Step'), ('289', 'Step', ':'), ('Step', ':', '5'), (':', '5', 'S'), ('5', 'S', 'S'), ('S', 'S', '17'), ('S', '17', 'Unit'), ('17', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Standard'), ('›', 'Standard', 'deviation'), ('Standard', 'deviation', '–'), ('deviation', '–', 'example'), ('–', 'example', '('), ('example', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Standard'), (')', 'Standard', 'deviation'), ('Standard', 'deviation', 'thought'), ('deviation', 'thought', 'measuring'), ('thought', 'measuring', 'far'), ('measuring', 'far', 'data'), ('far', 'data', 'values'), ('data', 'values', 'lie'), ('values', 'lie', 'mean'), ('lie', 'mean', ','), ('mean', ',', 'take'), (',', 'take', 'mean'), ('take', 'mean', 'move'), ('mean', 'move', 'standard'), ('move', 'standard', 'deviation'), ('standard', 'deviation', 'either'), ('deviation', 'either', 'direction'), ('either', 'direction', '.')]

>> POS Tags are: 
 [('(', '('), ('2nd', 'CD'), ('step', 'NN'), (')', ')'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Standard', 'NNP'), ('deviation', 'NN'), ('–', 'NNP'), ('example', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('X', 'NNP'), ('X', 'NNP'), ('–', 'NNP'), ('Mean', 'NNP'), ('(', '('), ('X', 'NNP'), ('–', 'NNP'), ('Mean', 'NNP'), (')', ')'), ('2', 'CD'), ('44', 'CD'), ('-5.2', 'NN'), ('27.04', 'CD'), ('50', 'CD'), ('0.8', 'CD'), ('0.64', 'CD'), ('38', 'CD'), ('11.2', 'CD'), ('125.44', 'CD'), ('96', 'CD'), ('46.8', 'CD'), ('2190.24', 'CD'), ('42', 'CD'), ('-7.2', 'NN'), ('51.84', 'CD'), ('47', 'CD'), ('-2.2', 'NN'), ('4.84', 'CD'), ('40', 'CD'), ('-9.2', 'NN'), ('84.64', 'CD'), ('39', 'CD'), ('-10.2', 'NN'), ('104.04', 'CD'), ('46', 'CD'), ('-3.2', 'NN'), ('10.24', 'CD'), ('50', 'CD'), ('0.8', 'CD'), ('0.64', 'CD'), ('Total', 'JJ'), ('2600.4', 'CD'), ('Step', 'NN'), (':', ':'), ('3', 'CD'), ('Step', 'NN'), (':', ':'), ('4', 'CD'), ('S2', 'NNP'), ('288.7', 'CD'), ('~', 'VBD'), ('289', 'CD'), ('Step', 'NN'), (':', ':'), ('5', 'CD'), ('S', 'NNP'), ('S', 'NNP'), ('17', 'CD'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Standard', 'NNP'), ('deviation', 'NN'), ('–', 'NNP'), ('example', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Standard', 'NNP'), ('deviation', 'NN'), ('thought', 'VBD'), ('measuring', 'VBG'), ('far', 'RB'), ('data', 'NNS'), ('values', 'NNS'), ('lie', 'VBP'), ('mean', 'JJ'), (',', ','), ('take', 'VB'), ('mean', 'JJ'), ('move', 'VB'), ('standard', 'JJ'), ('deviation', 'NN'), ('either', 'DT'), ('direction', 'NN'), ('.', '.')]

 (S
  (/(
  2nd/CD
  (NP step/NN)
  )/)
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Standard/NNP deviation/NN –/NNP example/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP X/NNP X/NNP –/NNP Mean/NNP)
  (/(
  (NP X/NNP –/NNP Mean/NNP)
  )/)
  2/CD
  44/CD
  (NP -5.2/NN)
  27.04/CD
  50/CD
  0.8/CD
  0.64/CD
  38/CD
  11.2/CD
  125.44/CD
  96/CD
  46.8/CD
  2190.24/CD
  42/CD
  (NP -7.2/NN)
  51.84/CD
  47/CD
  (NP -2.2/NN)
  4.84/CD
  40/CD
  (NP -9.2/NN)
  84.64/CD
  39/CD
  (NP -10.2/NN)
  104.04/CD
  46/CD
  (NP -3.2/NN)
  10.24/CD
  50/CD
  0.8/CD
  0.64/CD
  Total/JJ
  2600.4/CD
  (NP Step/NN)
  :/:
  3/CD
  (NP Step/NN)
  :/:
  4/CD
  (NP S2/NNP)
  288.7/CD
  ~/VBD
  289/CD
  (NP Step/NN)
  :/:
  5/CD
  (NP S/NNP S/NNP)
  17/CD
  (NP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Standard/NNP deviation/NN –/NNP example/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Standard/NNP deviation/NN)
  thought/VBD
  measuring/VBG
  far/RB
  (NP data/NNS values/NNS)
  lie/VBP
  mean/JJ
  ,/,
  take/VB
  mean/JJ
  move/VB
  (NP standard/JJ deviation/NN)
  (NP either/DT direction/NN)
  ./.) 


>> Noun Phrases are: 
 ['step', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Standard deviation – example', 'Cont ..', 'X X – Mean', 'X – Mean', '-5.2', '-7.2', '-2.2', '-9.2', '-10.2', '-3.2', 'Step', 'Step', 'S2', 'Step', 'S S', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Standard deviation – example', 'Cont ..', 'Standard deviation', 'data values', 'standard deviation', 'either direction']

>> Named Entities are: 
 [('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Standard')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2nd', '2nd'), ('step', 'step'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('–', '–'), ('example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('X', 'x'), ('X', 'x'), ('–', '–'), ('Mean', 'mean'), ('(', '('), ('X', 'x'), ('–', '–'), ('Mean', 'mean'), (')', ')'), ('2', '2'), ('44', '44'), ('-5.2', '-5.2'), ('27.04', '27.04'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('38', '38'), ('11.2', '11.2'), ('125.44', '125.44'), ('96', '96'), ('46.8', '46.8'), ('2190.24', '2190.24'), ('42', '42'), ('-7.2', '-7.2'), ('51.84', '51.84'), ('47', '47'), ('-2.2', '-2.2'), ('4.84', '4.84'), ('40', '40'), ('-9.2', '-9.2'), ('84.64', '84.64'), ('39', '39'), ('-10.2', '-10.2'), ('104.04', '104.04'), ('46', '46'), ('-3.2', '-3.2'), ('10.24', '10.24'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('Total', 'total'), ('2600.4', '2600.4'), ('Step', 'step'), (':', ':'), ('3', '3'), ('Step', 'step'), (':', ':'), ('4', '4'), ('S2', 's2'), ('288.7', '288.7'), ('~', '~'), ('289', '289'), ('Step', 'step'), (':', ':'), ('5', '5'), ('S', 's'), ('S', 's'), ('17', '17'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('–', '–'), ('example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Standard', 'standard'), ('deviation', 'deviat'), ('thought', 'thought'), ('measuring', 'measur'), ('far', 'far'), ('data', 'data'), ('values', 'valu'), ('lie', 'lie'), ('mean', 'mean'), (',', ','), ('take', 'take'), ('mean', 'mean'), ('move', 'move'), ('standard', 'standard'), ('deviation', 'deviat'), ('either', 'either'), ('direction', 'direct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2nd', '2nd'), ('step', 'step'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('–', '–'), ('example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('X', 'x'), ('X', 'x'), ('–', '–'), ('Mean', 'mean'), ('(', '('), ('X', 'x'), ('–', '–'), ('Mean', 'mean'), (')', ')'), ('2', '2'), ('44', '44'), ('-5.2', '-5.2'), ('27.04', '27.04'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('38', '38'), ('11.2', '11.2'), ('125.44', '125.44'), ('96', '96'), ('46.8', '46.8'), ('2190.24', '2190.24'), ('42', '42'), ('-7.2', '-7.2'), ('51.84', '51.84'), ('47', '47'), ('-2.2', '-2.2'), ('4.84', '4.84'), ('40', '40'), ('-9.2', '-9.2'), ('84.64', '84.64'), ('39', '39'), ('-10.2', '-10.2'), ('104.04', '104.04'), ('46', '46'), ('-3.2', '-3.2'), ('10.24', '10.24'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('Total', 'total'), ('2600.4', '2600.4'), ('Step', 'step'), (':', ':'), ('3', '3'), ('Step', 'step'), (':', ':'), ('4', '4'), ('S2', 's2'), ('288.7', '288.7'), ('~', '~'), ('289', '289'), ('Step', 'step'), (':', ':'), ('5', '5'), ('S', 's'), ('S', 's'), ('17', '17'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'standard'), ('deviation', 'deviat'), ('–', '–'), ('example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Standard', 'standard'), ('deviation', 'deviat'), ('thought', 'thought'), ('measuring', 'measur'), ('far', 'far'), ('data', 'data'), ('values', 'valu'), ('lie', 'lie'), ('mean', 'mean'), (',', ','), ('take', 'take'), ('mean', 'mean'), ('move', 'move'), ('standard', 'standard'), ('deviation', 'deviat'), ('either', 'either'), ('direction', 'direct'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2nd', '2nd'), ('step', 'step'), (')', ')'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('–', '–'), ('example', 'example'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('X', 'X'), ('X', 'X'), ('–', '–'), ('Mean', 'Mean'), ('(', '('), ('X', 'X'), ('–', '–'), ('Mean', 'Mean'), (')', ')'), ('2', '2'), ('44', '44'), ('-5.2', '-5.2'), ('27.04', '27.04'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('38', '38'), ('11.2', '11.2'), ('125.44', '125.44'), ('96', '96'), ('46.8', '46.8'), ('2190.24', '2190.24'), ('42', '42'), ('-7.2', '-7.2'), ('51.84', '51.84'), ('47', '47'), ('-2.2', '-2.2'), ('4.84', '4.84'), ('40', '40'), ('-9.2', '-9.2'), ('84.64', '84.64'), ('39', '39'), ('-10.2', '-10.2'), ('104.04', '104.04'), ('46', '46'), ('-3.2', '-3.2'), ('10.24', '10.24'), ('50', '50'), ('0.8', '0.8'), ('0.64', '0.64'), ('Total', 'Total'), ('2600.4', '2600.4'), ('Step', 'Step'), (':', ':'), ('3', '3'), ('Step', 'Step'), (':', ':'), ('4', '4'), ('S2', 'S2'), ('288.7', '288.7'), ('~', '~'), ('289', '289'), ('Step', 'Step'), (':', ':'), ('5', '5'), ('S', 'S'), ('S', 'S'), ('17', '17'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('–', '–'), ('example', 'example'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('thought', 'thought'), ('measuring', 'measuring'), ('far', 'far'), ('data', 'data'), ('values', 'value'), ('lie', 'lie'), ('mean', 'mean'), (',', ','), ('take', 'take'), ('mean', 'mean'), ('move', 'move'), ('standard', 'standard'), ('deviation', 'deviation'), ('either', 'either'), ('direction', 'direction'), ('.', '.')]



============================ Sentence 47 =============================

The mean for this example is 49.2 and the standard deviation is 17. 


>> Tokens are: 
 ['The', 'mean', 'example', '49.2', 'standard', 'deviation', '17', '.']

>> Bigrams are: 
 [('The', 'mean'), ('mean', 'example'), ('example', '49.2'), ('49.2', 'standard'), ('standard', 'deviation'), ('deviation', '17'), ('17', '.')]

>> Trigrams are: 
 [('The', 'mean', 'example'), ('mean', 'example', '49.2'), ('example', '49.2', 'standard'), ('49.2', 'standard', 'deviation'), ('standard', 'deviation', '17'), ('deviation', '17', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('mean', 'JJ'), ('example', 'NN'), ('49.2', 'CD'), ('standard', 'JJ'), ('deviation', 'NN'), ('17', 'CD'), ('.', '.')]

 (S
  (NP The/DT mean/JJ example/NN)
  49.2/CD
  (NP standard/JJ deviation/NN)
  17/CD
  ./.) 


>> Noun Phrases are: 
 ['The mean example', 'standard deviation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('mean', 'mean'), ('example', 'exampl'), ('49.2', '49.2'), ('standard', 'standard'), ('deviation', 'deviat'), ('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('mean', 'mean'), ('example', 'exampl'), ('49.2', '49.2'), ('standard', 'standard'), ('deviation', 'deviat'), ('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('mean', 'mean'), ('example', 'example'), ('49.2', '49.2'), ('standard', 'standard'), ('deviation', 'deviation'), ('17', '17'), ('.', '.')]



============================ Sentence 48 =============================

Now, 49.2 - 17 = 32.2 and 49.2 + 17 = 66.2  This means that most of the data probably spend between 32.2 and 66.2. 


>> Tokens are: 
 ['Now', ',', '49.2', '-', '17', '=', '32.2', '49.2', '+', '17', '=', '66.2', 'This', 'means', 'data', 'probably', 'spend', '32.2', '66.2', '.']

>> Bigrams are: 
 [('Now', ','), (',', '49.2'), ('49.2', '-'), ('-', '17'), ('17', '='), ('=', '32.2'), ('32.2', '49.2'), ('49.2', '+'), ('+', '17'), ('17', '='), ('=', '66.2'), ('66.2', 'This'), ('This', 'means'), ('means', 'data'), ('data', 'probably'), ('probably', 'spend'), ('spend', '32.2'), ('32.2', '66.2'), ('66.2', '.')]

>> Trigrams are: 
 [('Now', ',', '49.2'), (',', '49.2', '-'), ('49.2', '-', '17'), ('-', '17', '='), ('17', '=', '32.2'), ('=', '32.2', '49.2'), ('32.2', '49.2', '+'), ('49.2', '+', '17'), ('+', '17', '='), ('17', '=', '66.2'), ('=', '66.2', 'This'), ('66.2', 'This', 'means'), ('This', 'means', 'data'), ('means', 'data', 'probably'), ('data', 'probably', 'spend'), ('probably', 'spend', '32.2'), ('spend', '32.2', '66.2'), ('32.2', '66.2', '.')]

>> POS Tags are: 
 [('Now', 'RB'), (',', ','), ('49.2', 'CD'), ('-', ':'), ('17', 'CD'), ('=', 'JJ'), ('32.2', 'CD'), ('49.2', 'CD'), ('+', 'JJ'), ('17', 'CD'), ('=', 'RB'), ('66.2', 'CD'), ('This', 'DT'), ('means', 'VBZ'), ('data', 'NN'), ('probably', 'RB'), ('spend', 'VBD'), ('32.2', 'CD'), ('66.2', 'CD'), ('.', '.')]

 (S
  Now/RB
  ,/,
  49.2/CD
  -/:
  17/CD
  =/JJ
  32.2/CD
  49.2/CD
  +/JJ
  17/CD
  =/RB
  66.2/CD
  This/DT
  means/VBZ
  (NP data/NN)
  probably/RB
  spend/VBD
  32.2/CD
  66.2/CD
  ./.) 


>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Now', 'now'), (',', ','), ('49.2', '49.2'), ('-', '-'), ('17', '17'), ('=', '='), ('32.2', '32.2'), ('49.2', '49.2'), ('+', '+'), ('17', '17'), ('=', '='), ('66.2', '66.2'), ('This', 'thi'), ('means', 'mean'), ('data', 'data'), ('probably', 'probabl'), ('spend', 'spend'), ('32.2', '32.2'), ('66.2', '66.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Now', 'now'), (',', ','), ('49.2', '49.2'), ('-', '-'), ('17', '17'), ('=', '='), ('32.2', '32.2'), ('49.2', '49.2'), ('+', '+'), ('17', '17'), ('=', '='), ('66.2', '66.2'), ('This', 'this'), ('means', 'mean'), ('data', 'data'), ('probably', 'probabl'), ('spend', 'spend'), ('32.2', '32.2'), ('66.2', '66.2'), ('.', '.')]

>> Lemmatization: 
 [('Now', 'Now'), (',', ','), ('49.2', '49.2'), ('-', '-'), ('17', '17'), ('=', '='), ('32.2', '32.2'), ('49.2', '49.2'), ('+', '+'), ('17', '17'), ('=', '='), ('66.2', '66.2'), ('This', 'This'), ('means', 'mean'), ('data', 'data'), ('probably', 'probably'), ('spend', 'spend'), ('32.2', '32.2'), ('66.2', '66.2'), ('.', '.')]



============================ Sentence 49 =============================

If all data are same then variance & standard deviation is 0 (zero). 


>> Tokens are: 
 ['If', 'data', 'variance', '&', 'standard', 'deviation', '0', '(', 'zero', ')', '.']

>> Bigrams are: 
 [('If', 'data'), ('data', 'variance'), ('variance', '&'), ('&', 'standard'), ('standard', 'deviation'), ('deviation', '0'), ('0', '('), ('(', 'zero'), ('zero', ')'), (')', '.')]

>> Trigrams are: 
 [('If', 'data', 'variance'), ('data', 'variance', '&'), ('variance', '&', 'standard'), ('&', 'standard', 'deviation'), ('standard', 'deviation', '0'), ('deviation', '0', '('), ('0', '(', 'zero'), ('(', 'zero', ')'), ('zero', ')', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('data', 'NNS'), ('variance', 'NN'), ('&', 'CC'), ('standard', 'JJ'), ('deviation', 'NN'), ('0', 'CD'), ('(', '('), ('zero', 'NN'), (')', ')'), ('.', '.')]

 (S
  If/IN
  (NP data/NNS variance/NN)
  &/CC
  (NP standard/JJ deviation/NN)
  0/CD
  (/(
  (NP zero/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['data variance', 'standard deviation', 'zero']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('data', 'data'), ('variance', 'varianc'), ('&', '&'), ('standard', 'standard'), ('deviation', 'deviat'), ('0', '0'), ('(', '('), ('zero', 'zero'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('data', 'data'), ('variance', 'varianc'), ('&', '&'), ('standard', 'standard'), ('deviation', 'deviat'), ('0', '0'), ('(', '('), ('zero', 'zero'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('data', 'data'), ('variance', 'variance'), ('&', '&'), ('standard', 'standard'), ('deviation', 'deviation'), ('0', '0'), ('(', '('), ('zero', 'zero'), (')', ')'), ('.', '.')]



============================ Sentence 50 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Example (Try it)	 Calculate Mean, Median, Mode, Range, Variance & Standard deviation . 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Example', '(', 'Try', ')', 'Calculate', 'Mean', ',', 'Median', ',', 'Mode', ',', 'Range', ',', 'Variance', '&', 'Standard', 'deviation', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Example'), ('Example', '('), ('(', 'Try'), ('Try', ')'), (')', 'Calculate'), ('Calculate', 'Mean'), ('Mean', ','), (',', 'Median'), ('Median', ','), (',', 'Mode'), ('Mode', ','), (',', 'Range'), ('Range', ','), (',', 'Variance'), ('Variance', '&'), ('&', 'Standard'), ('Standard', 'deviation'), ('deviation', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Example'), ('›', 'Example', '('), ('Example', '(', 'Try'), ('(', 'Try', ')'), ('Try', ')', 'Calculate'), (')', 'Calculate', 'Mean'), ('Calculate', 'Mean', ','), ('Mean', ',', 'Median'), (',', 'Median', ','), ('Median', ',', 'Mode'), (',', 'Mode', ','), ('Mode', ',', 'Range'), (',', 'Range', ','), ('Range', ',', 'Variance'), (',', 'Variance', '&'), ('Variance', '&', 'Standard'), ('&', 'Standard', 'deviation'), ('Standard', 'deviation', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'JJ'), ('Example', 'NNP'), ('(', '('), ('Try', 'NNP'), (')', ')'), ('Calculate', 'NNP'), ('Mean', 'NNP'), (',', ','), ('Median', 'NNP'), (',', ','), ('Mode', 'NNP'), (',', ','), ('Range', 'NNP'), (',', ','), ('Variance', 'NNP'), ('&', 'CC'), ('Standard', 'NNP'), ('deviation', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/JJ Example/NNP)
  (/(
  (NP Try/NNP)
  )/)
  (NP Calculate/NNP Mean/NNP)
  ,/,
  (NP Median/NNP)
  ,/,
  (NP Mode/NNP)
  ,/,
  (NP Range/NNP)
  ,/,
  (NP Variance/NNP)
  &/CC
  (NP Standard/NNP deviation/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Example', 'Try', 'Calculate Mean', 'Median', 'Mode', 'Range', 'Variance', 'Standard deviation']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Try'), ('ORGANIZATION', 'Calculate Mean'), ('GPE', 'Median'), ('PERSON', 'Mode'), ('PERSON', 'Range'), ('GPE', 'Variance'), ('PERSON', 'Standard')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Example', 'exampl'), ('(', '('), ('Try', 'tri'), (')', ')'), ('Calculate', 'calcul'), ('Mean', 'mean'), (',', ','), ('Median', 'median'), (',', ','), ('Mode', 'mode'), (',', ','), ('Range', 'rang'), (',', ','), ('Variance', 'varianc'), ('&', '&'), ('Standard', 'standard'), ('deviation', 'deviat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Example', 'exampl'), ('(', '('), ('Try', 'tri'), (')', ')'), ('Calculate', 'calcul'), ('Mean', 'mean'), (',', ','), ('Median', 'median'), (',', ','), ('Mode', 'mode'), (',', ','), ('Range', 'rang'), (',', ','), ('Variance', 'varianc'), ('&', '&'), ('Standard', 'standard'), ('deviation', 'deviat'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Example', 'Example'), ('(', '('), ('Try', 'Try'), (')', ')'), ('Calculate', 'Calculate'), ('Mean', 'Mean'), (',', ','), ('Median', 'Median'), (',', ','), ('Mode', 'Mode'), (',', ','), ('Range', 'Range'), (',', ','), ('Variance', 'Variance'), ('&', '&'), ('Standard', 'Standard'), ('deviation', 'deviation'), ('.', '.')]



============================ Sentence 51 =============================

13, 18, 13, 14, 13, 16, 14, 21, 13 Mean is 15. 


>> Tokens are: 
 ['13', ',', '18', ',', '13', ',', '14', ',', '13', ',', '16', ',', '14', ',', '21', ',', '13', 'Mean', '15', '.']

>> Bigrams are: 
 [('13', ','), (',', '18'), ('18', ','), (',', '13'), ('13', ','), (',', '14'), ('14', ','), (',', '13'), ('13', ','), (',', '16'), ('16', ','), (',', '14'), ('14', ','), (',', '21'), ('21', ','), (',', '13'), ('13', 'Mean'), ('Mean', '15'), ('15', '.')]

>> Trigrams are: 
 [('13', ',', '18'), (',', '18', ','), ('18', ',', '13'), (',', '13', ','), ('13', ',', '14'), (',', '14', ','), ('14', ',', '13'), (',', '13', ','), ('13', ',', '16'), (',', '16', ','), ('16', ',', '14'), (',', '14', ','), ('14', ',', '21'), (',', '21', ','), ('21', ',', '13'), (',', '13', 'Mean'), ('13', 'Mean', '15'), ('Mean', '15', '.')]

>> POS Tags are: 
 [('13', 'CD'), (',', ','), ('18', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('14', 'CD'), (',', ','), ('13', 'CD'), (',', ','), ('16', 'CD'), (',', ','), ('14', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('13', 'CD'), ('Mean', 'JJ'), ('15', 'CD'), ('.', '.')]

 (S
  13/CD
  ,/,
  18/CD
  ,/,
  13/CD
  ,/,
  14/CD
  ,/,
  13/CD
  ,/,
  16/CD
  ,/,
  14/CD
  ,/,
  21/CD
  ,/,
  13/CD
  Mean/JJ
  15/CD
  ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (',', ','), ('18', '18'), (',', ','), ('13', '13'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), (',', ','), ('16', '16'), (',', ','), ('14', '14'), (',', ','), ('21', '21'), (',', ','), ('13', '13'), ('Mean', 'mean'), ('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (',', ','), ('18', '18'), (',', ','), ('13', '13'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), (',', ','), ('16', '16'), (',', ','), ('14', '14'), (',', ','), ('21', '21'), (',', ','), ('13', '13'), ('Mean', 'mean'), ('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), (',', ','), ('18', '18'), (',', ','), ('13', '13'), (',', ','), ('14', '14'), (',', ','), ('13', '13'), (',', ','), ('16', '16'), (',', ','), ('14', '14'), (',', ','), ('21', '21'), (',', ','), ('13', '13'), ('Mean', 'Mean'), ('15', '15'), ('.', '.')]



============================ Sentence 52 =============================

Median is 14. 


>> Tokens are: 
 ['Median', '14', '.']

>> Bigrams are: 
 [('Median', '14'), ('14', '.')]

>> Trigrams are: 
 [('Median', '14', '.')]

>> POS Tags are: 
 [('Median', 'JJ'), ('14', 'CD'), ('.', '.')]

 (S Median/JJ 14/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Median')] 

>> Stemming using Porter Stemmer: 
 [('Median', 'median'), ('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Median', 'median'), ('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('Median', 'Median'), ('14', '14'), ('.', '.')]



============================ Sentence 53 =============================

Mode is 13 & 14 (Bimodal). 


>> Tokens are: 
 ['Mode', '13', '&', '14', '(', 'Bimodal', ')', '.']

>> Bigrams are: 
 [('Mode', '13'), ('13', '&'), ('&', '14'), ('14', '('), ('(', 'Bimodal'), ('Bimodal', ')'), (')', '.')]

>> Trigrams are: 
 [('Mode', '13', '&'), ('13', '&', '14'), ('&', '14', '('), ('14', '(', 'Bimodal'), ('(', 'Bimodal', ')'), ('Bimodal', ')', '.')]

>> POS Tags are: 
 [('Mode', 'NNP'), ('13', 'CD'), ('&', 'CC'), ('14', 'CD'), ('(', '('), ('Bimodal', 'NNP'), (')', ')'), ('.', '.')]

 (S (NP Mode/NNP) 13/CD &/CC 14/CD (/( (NP Bimodal/NNP) )/) ./.) 


>> Noun Phrases are: 
 ['Mode', 'Bimodal']

>> Named Entities are: 
 [('ORGANIZATION', 'Bimodal')] 

>> Stemming using Porter Stemmer: 
 [('Mode', 'mode'), ('13', '13'), ('&', '&'), ('14', '14'), ('(', '('), ('Bimodal', 'bimod'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mode', 'mode'), ('13', '13'), ('&', '&'), ('14', '14'), ('(', '('), ('Bimodal', 'bimod'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Mode', 'Mode'), ('13', '13'), ('&', '&'), ('14', '14'), ('(', '('), ('Bimodal', 'Bimodal'), (')', ')'), ('.', '.')]



============================ Sentence 54 =============================

Range is 8. 


>> Tokens are: 
 ['Range', '8', '.']

>> Bigrams are: 
 [('Range', '8'), ('8', '.')]

>> Trigrams are: 
 [('Range', '8', '.')]

>> POS Tags are: 
 [('Range', 'NNP'), ('8', 'CD'), ('.', '.')]

 (S (NP Range/NNP) 8/CD ./.) 


>> Noun Phrases are: 
 ['Range']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Range', 'rang'), ('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Range', 'rang'), ('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('Range', 'Range'), ('8', '8'), ('.', '.')]



============================ Sentence 55 =============================

Variance is 289. 


>> Tokens are: 
 ['Variance', '289', '.']

>> Bigrams are: 
 [('Variance', '289'), ('289', '.')]

>> Trigrams are: 
 [('Variance', '289', '.')]

>> POS Tags are: 
 [('Variance', 'NN'), ('289', 'CD'), ('.', '.')]

 (S (NP Variance/NN) 289/CD ./.) 


>> Noun Phrases are: 
 ['Variance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Variance', 'varianc'), ('289', '289'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Variance', 'varianc'), ('289', '289'), ('.', '.')]

>> Lemmatization: 
 [('Variance', 'Variance'), ('289', '289'), ('.', '.')]



============================ Sentence 56 =============================

Standard deviation is 17. 


>> Tokens are: 
 ['Standard', 'deviation', '17', '.']

>> Bigrams are: 
 [('Standard', 'deviation'), ('deviation', '17'), ('17', '.')]

>> Trigrams are: 
 [('Standard', 'deviation', '17'), ('deviation', '17', '.')]

>> POS Tags are: 
 [('Standard', 'NNP'), ('deviation', 'NN'), ('17', 'CD'), ('.', '.')]

 (S (NP Standard/NNP deviation/NN) 17/CD ./.) 


>> Noun Phrases are: 
 ['Standard deviation']

>> Named Entities are: 
 [('PERSON', 'Standard')] 

>> Stemming using Porter Stemmer: 
 [('Standard', 'standard'), ('deviation', 'deviat'), ('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Standard', 'standard'), ('deviation', 'deviat'), ('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('Standard', 'Standard'), ('deviation', 'deviation'), ('17', '17'), ('.', '.')]



============================ Sentence 57 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Attribute Types An attribute is a property of the object. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Attribute', 'Types', 'An', 'attribute', 'property', 'object', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Attribute'), ('Attribute', 'Types'), ('Types', 'An'), ('An', 'attribute'), ('attribute', 'property'), ('property', 'object'), ('object', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Attribute'), ('›', 'Attribute', 'Types'), ('Attribute', 'Types', 'An'), ('Types', 'An', 'attribute'), ('An', 'attribute', 'property'), ('attribute', 'property', 'object'), ('property', 'object', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Attribute', 'NNP'), ('Types', 'NNP'), ('An', 'DT'), ('attribute', 'NN'), ('property', 'NN'), ('object', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Attribute/NNP Types/NNP)
  (NP An/DT attribute/NN property/NN object/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Attribute Types', 'An attribute property object']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Attribute', 'attribut'), ('Types', 'type'), ('An', 'an'), ('attribute', 'attribut'), ('property', 'properti'), ('object', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Attribute', 'attribut'), ('Types', 'type'), ('An', 'an'), ('attribute', 'attribut'), ('property', 'properti'), ('object', 'object'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Attribute', 'Attribute'), ('Types', 'Types'), ('An', 'An'), ('attribute', 'attribute'), ('property', 'property'), ('object', 'object'), ('.', '.')]



============================ Sentence 58 =============================

It also represents different features of the object. 


>> Tokens are: 
 ['It', 'also', 'represents', 'different', 'features', 'object', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'represents'), ('represents', 'different'), ('different', 'features'), ('features', 'object'), ('object', '.')]

>> Trigrams are: 
 [('It', 'also', 'represents'), ('also', 'represents', 'different'), ('represents', 'different', 'features'), ('different', 'features', 'object'), ('features', 'object', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('represents', 'VBZ'), ('different', 'JJ'), ('features', 'NNS'), ('object', 'VBP'), ('.', '.')]

 (S
  It/PRP
  also/RB
  represents/VBZ
  (NP different/JJ features/NNS)
  object/VBP
  ./.) 


>> Noun Phrases are: 
 ['different features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('represents', 'repres'), ('different', 'differ'), ('features', 'featur'), ('object', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('represents', 'repres'), ('different', 'differ'), ('features', 'featur'), ('object', 'object'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('represents', 'represents'), ('different', 'different'), ('features', 'feature'), ('object', 'object'), ('.', '.')]



============================ Sentence 59 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 60 =============================

Person   Name, Age, Qualification etc. 


>> Tokens are: 
 ['Person', '\uf0e0', 'Name', ',', 'Age', ',', 'Qualification', 'etc', '.']

>> Bigrams are: 
 [('Person', '\uf0e0'), ('\uf0e0', 'Name'), ('Name', ','), (',', 'Age'), ('Age', ','), (',', 'Qualification'), ('Qualification', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Person', '\uf0e0', 'Name'), ('\uf0e0', 'Name', ','), ('Name', ',', 'Age'), (',', 'Age', ','), ('Age', ',', 'Qualification'), (',', 'Qualification', 'etc'), ('Qualification', 'etc', '.')]

>> POS Tags are: 
 [('Person', 'NNP'), ('\uf0e0', 'NNP'), ('Name', 'NNP'), (',', ','), ('Age', 'NNP'), (',', ','), ('Qualification', 'NNP'), ('etc', 'FW'), ('.', '.')]

 (S
  (NP Person/NNP /NNP Name/NNP)
  ,/,
  (NP Age/NNP)
  ,/,
  (NP Qualification/NNP)
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['Person \uf0e0 Name', 'Age', 'Qualification']

>> Named Entities are: 
 [('PERSON', 'Person'), ('PERSON', 'Age')] 

>> Stemming using Porter Stemmer: 
 [('Person', 'person'), ('\uf0e0', '\uf0e0'), ('Name', 'name'), (',', ','), ('Age', 'age'), (',', ','), ('Qualification', 'qualif'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Person', 'person'), ('\uf0e0', '\uf0e0'), ('Name', 'name'), (',', ','), ('Age', 'age'), (',', ','), ('Qualification', 'qualif'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Person', 'Person'), ('\uf0e0', '\uf0e0'), ('Name', 'Name'), (',', ','), ('Age', 'Age'), (',', ','), ('Qualification', 'Qualification'), ('etc', 'etc'), ('.', '.')]



============================ Sentence 61 =============================

Attribute types can be divided into four categories. 


>> Tokens are: 
 ['Attribute', 'types', 'divided', 'four', 'categories', '.']

>> Bigrams are: 
 [('Attribute', 'types'), ('types', 'divided'), ('divided', 'four'), ('four', 'categories'), ('categories', '.')]

>> Trigrams are: 
 [('Attribute', 'types', 'divided'), ('types', 'divided', 'four'), ('divided', 'four', 'categories'), ('four', 'categories', '.')]

>> POS Tags are: 
 [('Attribute', 'NNP'), ('types', 'NNS'), ('divided', 'VBD'), ('four', 'CD'), ('categories', 'NNS'), ('.', '.')]

 (S
  (NP Attribute/NNP types/NNS)
  divided/VBD
  four/CD
  (NP categories/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Attribute types', 'categories']

>> Named Entities are: 
 [('GPE', 'Attribute')] 

>> Stemming using Porter Stemmer: 
 [('Attribute', 'attribut'), ('types', 'type'), ('divided', 'divid'), ('four', 'four'), ('categories', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Attribute', 'attribut'), ('types', 'type'), ('divided', 'divid'), ('four', 'four'), ('categories', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('Attribute', 'Attribute'), ('types', 'type'), ('divided', 'divided'), ('four', 'four'), ('categories', 'category'), ('.', '.')]



============================ Sentence 62 =============================

Nominal Ordinal Interval Ratio     	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Nominal Attribute Nominal attributes are named attributes which can be separated into discrete (individual) categories which do not overlap. 


>> Tokens are: 
 ['Nominal', 'Ordinal', 'Interval', 'Ratio', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Nominal', 'Attribute', 'Nominal', 'attributes', 'named', 'attributes', 'separated', 'discrete', '(', 'individual', ')', 'categories', 'overlap', '.']

>> Bigrams are: 
 [('Nominal', 'Ordinal'), ('Ordinal', 'Interval'), ('Interval', 'Ratio'), ('Ratio', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Nominal'), ('Nominal', 'Attribute'), ('Attribute', 'Nominal'), ('Nominal', 'attributes'), ('attributes', 'named'), ('named', 'attributes'), ('attributes', 'separated'), ('separated', 'discrete'), ('discrete', '('), ('(', 'individual'), ('individual', ')'), (')', 'categories'), ('categories', 'overlap'), ('overlap', '.')]

>> Trigrams are: 
 [('Nominal', 'Ordinal', 'Interval'), ('Ordinal', 'Interval', 'Ratio'), ('Interval', 'Ratio', 'Unit'), ('Ratio', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Nominal'), (')', 'Nominal', 'Attribute'), ('Nominal', 'Attribute', 'Nominal'), ('Attribute', 'Nominal', 'attributes'), ('Nominal', 'attributes', 'named'), ('attributes', 'named', 'attributes'), ('named', 'attributes', 'separated'), ('attributes', 'separated', 'discrete'), ('separated', 'discrete', '('), ('discrete', '(', 'individual'), ('(', 'individual', ')'), ('individual', ')', 'categories'), (')', 'categories', 'overlap'), ('categories', 'overlap', '.')]

>> POS Tags are: 
 [('Nominal', 'JJ'), ('Ordinal', 'NNP'), ('Interval', 'NNP'), ('Ratio', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Nominal', 'NNP'), ('Attribute', 'NNP'), ('Nominal', 'NNP'), ('attributes', 'VBZ'), ('named', 'VBN'), ('attributes', 'NNS'), ('separated', 'VBD'), ('discrete', 'JJ'), ('(', '('), ('individual', 'JJ'), (')', ')'), ('categories', 'NNS'), ('overlap', 'VBP'), ('.', '.')]

 (S
  (NP Nominal/JJ Ordinal/NNP Interval/NNP Ratio/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Nominal/NNP Attribute/NNP Nominal/NNP)
  attributes/VBZ
  named/VBN
  (NP attributes/NNS)
  separated/VBD
  discrete/JJ
  (/(
  individual/JJ
  )/)
  (NP categories/NNS)
  overlap/VBP
  ./.) 


>> Noun Phrases are: 
 ['Nominal Ordinal Interval Ratio Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Nominal Attribute Nominal', 'attributes', 'categories']

>> Named Entities are: 
 [('ORGANIZATION', 'Ordinal Interval Ratio Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Nominal Attribute Nominal')] 

>> Stemming using Porter Stemmer: 
 [('Nominal', 'nomin'), ('Ordinal', 'ordin'), ('Interval', 'interv'), ('Ratio', 'ratio'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Nominal', 'nomin'), ('Attribute', 'attribut'), ('Nominal', 'nomin'), ('attributes', 'attribut'), ('named', 'name'), ('attributes', 'attribut'), ('separated', 'separ'), ('discrete', 'discret'), ('(', '('), ('individual', 'individu'), (')', ')'), ('categories', 'categori'), ('overlap', 'overlap'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nominal', 'nomin'), ('Ordinal', 'ordin'), ('Interval', 'interv'), ('Ratio', 'ratio'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Nominal', 'nomin'), ('Attribute', 'attribut'), ('Nominal', 'nomin'), ('attributes', 'attribut'), ('named', 'name'), ('attributes', 'attribut'), ('separated', 'separ'), ('discrete', 'discret'), ('(', '('), ('individual', 'individu'), (')', ')'), ('categories', 'categori'), ('overlap', 'overlap'), ('.', '.')]

>> Lemmatization: 
 [('Nominal', 'Nominal'), ('Ordinal', 'Ordinal'), ('Interval', 'Interval'), ('Ratio', 'Ratio'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Nominal', 'Nominal'), ('Attribute', 'Attribute'), ('Nominal', 'Nominal'), ('attributes', 'attribute'), ('named', 'named'), ('attributes', 'attribute'), ('separated', 'separated'), ('discrete', 'discrete'), ('(', '('), ('individual', 'individual'), (')', ')'), ('categories', 'category'), ('overlap', 'overlap'), ('.', '.')]



============================ Sentence 63 =============================

Nominal attributes values also called as distinct values. 


>> Tokens are: 
 ['Nominal', 'attributes', 'values', 'also', 'called', 'distinct', 'values', '.']

>> Bigrams are: 
 [('Nominal', 'attributes'), ('attributes', 'values'), ('values', 'also'), ('also', 'called'), ('called', 'distinct'), ('distinct', 'values'), ('values', '.')]

>> Trigrams are: 
 [('Nominal', 'attributes', 'values'), ('attributes', 'values', 'also'), ('values', 'also', 'called'), ('also', 'called', 'distinct'), ('called', 'distinct', 'values'), ('distinct', 'values', '.')]

>> POS Tags are: 
 [('Nominal', 'JJ'), ('attributes', 'NNS'), ('values', 'NNS'), ('also', 'RB'), ('called', 'VBD'), ('distinct', 'JJ'), ('values', 'NNS'), ('.', '.')]

 (S
  (NP Nominal/JJ attributes/NNS values/NNS)
  also/RB
  called/VBD
  (NP distinct/JJ values/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Nominal attributes values', 'distinct values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nominal', 'nomin'), ('attributes', 'attribut'), ('values', 'valu'), ('also', 'also'), ('called', 'call'), ('distinct', 'distinct'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nominal', 'nomin'), ('attributes', 'attribut'), ('values', 'valu'), ('also', 'also'), ('called', 'call'), ('distinct', 'distinct'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Nominal', 'Nominal'), ('attributes', 'attribute'), ('values', 'value'), ('also', 'also'), ('called', 'called'), ('distinct', 'distinct'), ('values', 'value'), ('.', '.')]



============================ Sentence 64 =============================

Example   Attribute Types     	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  2) Ordinal Attribute Ordinal attribute is the order of the values, that’s important and significant, but the differences between each one is not really known. 


>> Tokens are: 
 ['Example', 'Attribute', 'Types', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '2', ')', 'Ordinal', 'Attribute', 'Ordinal', 'attribute', 'order', 'values', ',', '’', 'important', 'significant', ',', 'differences', 'one', 'really', 'known', '.']

>> Bigrams are: 
 [('Example', 'Attribute'), ('Attribute', 'Types'), ('Types', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '2'), ('2', ')'), (')', 'Ordinal'), ('Ordinal', 'Attribute'), ('Attribute', 'Ordinal'), ('Ordinal', 'attribute'), ('attribute', 'order'), ('order', 'values'), ('values', ','), (',', '’'), ('’', 'important'), ('important', 'significant'), ('significant', ','), (',', 'differences'), ('differences', 'one'), ('one', 'really'), ('really', 'known'), ('known', '.')]

>> Trigrams are: 
 [('Example', 'Attribute', 'Types'), ('Attribute', 'Types', 'Unit'), ('Types', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '2'), ('›', '2', ')'), ('2', ')', 'Ordinal'), (')', 'Ordinal', 'Attribute'), ('Ordinal', 'Attribute', 'Ordinal'), ('Attribute', 'Ordinal', 'attribute'), ('Ordinal', 'attribute', 'order'), ('attribute', 'order', 'values'), ('order', 'values', ','), ('values', ',', '’'), (',', '’', 'important'), ('’', 'important', 'significant'), ('important', 'significant', ','), ('significant', ',', 'differences'), (',', 'differences', 'one'), ('differences', 'one', 'really'), ('one', 'really', 'known'), ('really', 'known', '.')]

>> POS Tags are: 
 [('Example', 'NNP'), ('Attribute', 'NNP'), ('Types', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('2', 'CD'), (')', ')'), ('Ordinal', 'NNP'), ('Attribute', 'NNP'), ('Ordinal', 'NNP'), ('attribute', 'NN'), ('order', 'NN'), ('values', 'NNS'), (',', ','), ('’', 'NNP'), ('important', 'JJ'), ('significant', 'JJ'), (',', ','), ('differences', 'VBZ'), ('one', 'CD'), ('really', 'RB'), ('known', 'VBN'), ('.', '.')]

 (S
  (NP Example/NNP Attribute/NNP Types/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  2/CD
  )/)
  (NP
    Ordinal/NNP
    Attribute/NNP
    Ordinal/NNP
    attribute/NN
    order/NN
    values/NNS)
  ,/,
  (NP ’/NNP)
  important/JJ
  significant/JJ
  ,/,
  differences/VBZ
  one/CD
  really/RB
  known/VBN
  ./.) 


>> Noun Phrases are: 
 ['Example Attribute Types Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Ordinal Attribute Ordinal attribute order values', '’']

>> Named Entities are: 
 [('PERSON', 'Example'), ('PERSON', 'Attribute Types Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Ordinal Attribute Ordinal')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Ordinal', 'ordin'), ('Attribute', 'attribut'), ('Ordinal', 'ordin'), ('attribute', 'attribut'), ('order', 'order'), ('values', 'valu'), (',', ','), ('’', '’'), ('important', 'import'), ('significant', 'signific'), (',', ','), ('differences', 'differ'), ('one', 'one'), ('really', 'realli'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Ordinal', 'ordin'), ('Attribute', 'attribut'), ('Ordinal', 'ordin'), ('attribute', 'attribut'), ('order', 'order'), ('values', 'valu'), (',', ','), ('’', '’'), ('important', 'import'), ('significant', 'signific'), (',', ','), ('differences', 'differ'), ('one', 'one'), ('really', 'realli'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Attribute', 'Attribute'), ('Types', 'Types'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Ordinal', 'Ordinal'), ('Attribute', 'Attribute'), ('Ordinal', 'Ordinal'), ('attribute', 'attribute'), ('order', 'order'), ('values', 'value'), (',', ','), ('’', '’'), ('important', 'important'), ('significant', 'significant'), (',', ','), ('differences', 'difference'), ('one', 'one'), ('really', 'really'), ('known', 'known'), ('.', '.')]



============================ Sentence 65 =============================

Example Rankings  1st, 2nd, 3rd  Ratings   We know that a 5 star is better than a 2 star or 3 star, but we don’t know and cannot quantify–how much better it is? 


>> Tokens are: 
 ['Example', 'Rankings', '\uf0e0', '1st', ',', '2nd', ',', '3rd', 'Ratings', '\uf0e0', 'We', 'know', '5', 'star', 'better', '2', 'star', '3', 'star', ',', '’', 'know', 'quantify–how', 'much', 'better', '?']

>> Bigrams are: 
 [('Example', 'Rankings'), ('Rankings', '\uf0e0'), ('\uf0e0', '1st'), ('1st', ','), (',', '2nd'), ('2nd', ','), (',', '3rd'), ('3rd', 'Ratings'), ('Ratings', '\uf0e0'), ('\uf0e0', 'We'), ('We', 'know'), ('know', '5'), ('5', 'star'), ('star', 'better'), ('better', '2'), ('2', 'star'), ('star', '3'), ('3', 'star'), ('star', ','), (',', '’'), ('’', 'know'), ('know', 'quantify–how'), ('quantify–how', 'much'), ('much', 'better'), ('better', '?')]

>> Trigrams are: 
 [('Example', 'Rankings', '\uf0e0'), ('Rankings', '\uf0e0', '1st'), ('\uf0e0', '1st', ','), ('1st', ',', '2nd'), (',', '2nd', ','), ('2nd', ',', '3rd'), (',', '3rd', 'Ratings'), ('3rd', 'Ratings', '\uf0e0'), ('Ratings', '\uf0e0', 'We'), ('\uf0e0', 'We', 'know'), ('We', 'know', '5'), ('know', '5', 'star'), ('5', 'star', 'better'), ('star', 'better', '2'), ('better', '2', 'star'), ('2', 'star', '3'), ('star', '3', 'star'), ('3', 'star', ','), ('star', ',', '’'), (',', '’', 'know'), ('’', 'know', 'quantify–how'), ('know', 'quantify–how', 'much'), ('quantify–how', 'much', 'better'), ('much', 'better', '?')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Rankings', 'NNP'), ('\uf0e0', 'NNP'), ('1st', 'CD'), (',', ','), ('2nd', 'CD'), (',', ','), ('3rd', 'CD'), ('Ratings', 'NNS'), ('\uf0e0', 'IN'), ('We', 'PRP'), ('know', 'VBP'), ('5', 'CD'), ('star', 'NN'), ('better', 'RBR'), ('2', 'CD'), ('star', 'NN'), ('3', 'CD'), ('star', 'NN'), (',', ','), ('’', 'NNP'), ('know', 'VBP'), ('quantify–how', 'RB'), ('much', 'JJ'), ('better', 'JJR'), ('?', '.')]

 (S
  (NP Example/JJ Rankings/NNP /NNP)
  1st/CD
  ,/,
  2nd/CD
  ,/,
  3rd/CD
  (NP Ratings/NNS)
  /IN
  We/PRP
  know/VBP
  5/CD
  (NP star/NN)
  better/RBR
  2/CD
  (NP star/NN)
  3/CD
  (NP star/NN)
  ,/,
  (NP ’/NNP)
  know/VBP
  quantify–how/RB
  much/JJ
  better/JJR
  ?/.) 


>> Noun Phrases are: 
 ['Example Rankings \uf0e0', 'Ratings', 'star', 'star', 'star', '’']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Rankings')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Rankings', 'rank'), ('\uf0e0', '\uf0e0'), ('1st', '1st'), (',', ','), ('2nd', '2nd'), (',', ','), ('3rd', '3rd'), ('Ratings', 'rate'), ('\uf0e0', '\uf0e0'), ('We', 'we'), ('know', 'know'), ('5', '5'), ('star', 'star'), ('better', 'better'), ('2', '2'), ('star', 'star'), ('3', '3'), ('star', 'star'), (',', ','), ('’', '’'), ('know', 'know'), ('quantify–how', 'quantify–how'), ('much', 'much'), ('better', 'better'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Rankings', 'rank'), ('\uf0e0', '\uf0e0'), ('1st', '1st'), (',', ','), ('2nd', '2nd'), (',', ','), ('3rd', '3rd'), ('Ratings', 'rate'), ('\uf0e0', '\uf0e0'), ('We', 'we'), ('know', 'know'), ('5', '5'), ('star', 'star'), ('better', 'better'), ('2', '2'), ('star', 'star'), ('3', '3'), ('star', 'star'), (',', ','), ('’', '’'), ('know', 'know'), ('quantify–how', 'quantify–how'), ('much', 'much'), ('better', 'better'), ('?', '?')]

>> Lemmatization: 
 [('Example', 'Example'), ('Rankings', 'Rankings'), ('\uf0e0', '\uf0e0'), ('1st', '1st'), (',', ','), ('2nd', '2nd'), (',', ','), ('3rd', '3rd'), ('Ratings', 'Ratings'), ('\uf0e0', '\uf0e0'), ('We', 'We'), ('know', 'know'), ('5', '5'), ('star', 'star'), ('better', 'better'), ('2', '2'), ('star', 'star'), ('3', '3'), ('star', 'star'), (',', ','), ('’', '’'), ('know', 'know'), ('quantify–how', 'quantify–how'), ('much', 'much'), ('better', 'better'), ('?', '?')]



============================ Sentence 66 =============================

Attribute Types         ,   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  3) Interval Attribute Interval attribute comes in the form of a numerical value where the difference between points is meaningful. 


>> Tokens are: 
 ['Attribute', 'Types', ',', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '3', ')', 'Interval', 'Attribute', 'Interval', 'attribute', 'comes', 'form', 'numerical', 'value', 'difference', 'points', 'meaningful', '.']

>> Bigrams are: 
 [('Attribute', 'Types'), ('Types', ','), (',', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '3'), ('3', ')'), (')', 'Interval'), ('Interval', 'Attribute'), ('Attribute', 'Interval'), ('Interval', 'attribute'), ('attribute', 'comes'), ('comes', 'form'), ('form', 'numerical'), ('numerical', 'value'), ('value', 'difference'), ('difference', 'points'), ('points', 'meaningful'), ('meaningful', '.')]

>> Trigrams are: 
 [('Attribute', 'Types', ','), ('Types', ',', 'Unit'), (',', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '3'), ('›', '3', ')'), ('3', ')', 'Interval'), (')', 'Interval', 'Attribute'), ('Interval', 'Attribute', 'Interval'), ('Attribute', 'Interval', 'attribute'), ('Interval', 'attribute', 'comes'), ('attribute', 'comes', 'form'), ('comes', 'form', 'numerical'), ('form', 'numerical', 'value'), ('numerical', 'value', 'difference'), ('value', 'difference', 'points'), ('difference', 'points', 'meaningful'), ('points', 'meaningful', '.')]

>> POS Tags are: 
 [('Attribute', 'NNP'), ('Types', 'NNP'), (',', ','), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('3', 'CD'), (')', ')'), ('Interval', 'NNP'), ('Attribute', 'NNP'), ('Interval', 'NNP'), ('attribute', 'NN'), ('comes', 'VBZ'), ('form', 'RB'), ('numerical', 'JJ'), ('value', 'NN'), ('difference', 'NN'), ('points', 'NNS'), ('meaningful', 'JJ'), ('.', '.')]

 (S
  (NP Attribute/NNP Types/NNP)
  ,/,
  (NP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  3/CD
  )/)
  (NP Interval/NNP Attribute/NNP Interval/NNP attribute/NN)
  comes/VBZ
  form/RB
  (NP numerical/JJ value/NN difference/NN points/NNS)
  meaningful/JJ
  ./.) 


>> Noun Phrases are: 
 ['Attribute Types', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Interval Attribute Interval attribute', 'numerical value difference points']

>> Named Entities are: 
 [('PERSON', 'Attribute'), ('GPE', 'Types'), ('PERSON', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Interval Attribute Interval')] 

>> Stemming using Porter Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), (',', ','), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Interval', 'interv'), ('Attribute', 'attribut'), ('Interval', 'interv'), ('attribute', 'attribut'), ('comes', 'come'), ('form', 'form'), ('numerical', 'numer'), ('value', 'valu'), ('difference', 'differ'), ('points', 'point'), ('meaningful', 'meaning'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), (',', ','), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Interval', 'interv'), ('Attribute', 'attribut'), ('Interval', 'interv'), ('attribute', 'attribut'), ('comes', 'come'), ('form', 'form'), ('numerical', 'numer'), ('value', 'valu'), ('difference', 'differ'), ('points', 'point'), ('meaningful', 'meaning'), ('.', '.')]

>> Lemmatization: 
 [('Attribute', 'Attribute'), ('Types', 'Types'), (',', ','), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Interval', 'Interval'), ('Attribute', 'Attribute'), ('Interval', 'Interval'), ('attribute', 'attribute'), ('comes', 'come'), ('form', 'form'), ('numerical', 'numerical'), ('value', 'value'), ('difference', 'difference'), ('points', 'point'), ('meaningful', 'meaningful'), ('.', '.')]



============================ Sentence 67 =============================

Example Temperature  10°-20°, 30°-50°, 35°-45° Calendar Dates  15th – 22nd, 10th – 30th  We can not find true zero (absolute) value with interval attributes. 


>> Tokens are: 
 ['Example', 'Temperature', '\uf0e0', '10°-20°', ',', '30°-50°', ',', '35°-45°', 'Calendar', 'Dates', '\uf0e0', '15th', '–', '22nd', ',', '10th', '–', '30th', 'We', 'find', 'true', 'zero', '(', 'absolute', ')', 'value', 'interval', 'attributes', '.']

>> Bigrams are: 
 [('Example', 'Temperature'), ('Temperature', '\uf0e0'), ('\uf0e0', '10°-20°'), ('10°-20°', ','), (',', '30°-50°'), ('30°-50°', ','), (',', '35°-45°'), ('35°-45°', 'Calendar'), ('Calendar', 'Dates'), ('Dates', '\uf0e0'), ('\uf0e0', '15th'), ('15th', '–'), ('–', '22nd'), ('22nd', ','), (',', '10th'), ('10th', '–'), ('–', '30th'), ('30th', 'We'), ('We', 'find'), ('find', 'true'), ('true', 'zero'), ('zero', '('), ('(', 'absolute'), ('absolute', ')'), (')', 'value'), ('value', 'interval'), ('interval', 'attributes'), ('attributes', '.')]

>> Trigrams are: 
 [('Example', 'Temperature', '\uf0e0'), ('Temperature', '\uf0e0', '10°-20°'), ('\uf0e0', '10°-20°', ','), ('10°-20°', ',', '30°-50°'), (',', '30°-50°', ','), ('30°-50°', ',', '35°-45°'), (',', '35°-45°', 'Calendar'), ('35°-45°', 'Calendar', 'Dates'), ('Calendar', 'Dates', '\uf0e0'), ('Dates', '\uf0e0', '15th'), ('\uf0e0', '15th', '–'), ('15th', '–', '22nd'), ('–', '22nd', ','), ('22nd', ',', '10th'), (',', '10th', '–'), ('10th', '–', '30th'), ('–', '30th', 'We'), ('30th', 'We', 'find'), ('We', 'find', 'true'), ('find', 'true', 'zero'), ('true', 'zero', '('), ('zero', '(', 'absolute'), ('(', 'absolute', ')'), ('absolute', ')', 'value'), (')', 'value', 'interval'), ('value', 'interval', 'attributes'), ('interval', 'attributes', '.')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Temperature', 'NNP'), ('\uf0e0', 'NNP'), ('10°-20°', 'JJ'), (',', ','), ('30°-50°', 'JJ'), (',', ','), ('35°-45°', 'JJ'), ('Calendar', 'NNP'), ('Dates', 'NNP'), ('\uf0e0', 'VBD'), ('15th', 'CD'), ('–', 'NN'), ('22nd', 'CD'), (',', ','), ('10th', 'CD'), ('–', 'JJ'), ('30th', 'CD'), ('We', 'PRP'), ('find', 'VBP'), ('true', 'JJ'), ('zero', 'NN'), ('(', '('), ('absolute', 'NN'), (')', ')'), ('value', 'NN'), ('interval', 'JJ'), ('attributes', 'NNS'), ('.', '.')]

 (S
  (NP Example/JJ Temperature/NNP /NNP)
  10°-20°/JJ
  ,/,
  30°-50°/JJ
  ,/,
  (NP 35°-45°/JJ Calendar/NNP Dates/NNP)
  /VBD
  15th/CD
  (NP –/NN)
  22nd/CD
  ,/,
  10th/CD
  –/JJ
  30th/CD
  We/PRP
  find/VBP
  (NP true/JJ zero/NN)
  (/(
  (NP absolute/NN)
  )/)
  (NP value/NN)
  (NP interval/JJ attributes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Example Temperature \uf0e0', '35°-45° Calendar Dates', '–', 'true zero', 'absolute', 'value', 'interval attributes']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Temperature'), ('PERSON', 'Calendar Dates')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Temperature', 'temperatur'), ('\uf0e0', '\uf0e0'), ('10°-20°', '10°-20°'), (',', ','), ('30°-50°', '30°-50°'), (',', ','), ('35°-45°', '35°-45°'), ('Calendar', 'calendar'), ('Dates', 'date'), ('\uf0e0', '\uf0e0'), ('15th', '15th'), ('–', '–'), ('22nd', '22nd'), (',', ','), ('10th', '10th'), ('–', '–'), ('30th', '30th'), ('We', 'we'), ('find', 'find'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), ('value', 'valu'), ('interval', 'interv'), ('attributes', 'attribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Temperature', 'temperatur'), ('\uf0e0', '\uf0e0'), ('10°-20°', '10°-20°'), (',', ','), ('30°-50°', '30°-50°'), (',', ','), ('35°-45°', '35°-45°'), ('Calendar', 'calendar'), ('Dates', 'date'), ('\uf0e0', '\uf0e0'), ('15th', '15th'), ('–', '–'), ('22nd', '22nd'), (',', ','), ('10th', '10th'), ('–', '–'), ('30th', '30th'), ('We', 'we'), ('find', 'find'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), ('value', 'valu'), ('interval', 'interv'), ('attributes', 'attribut'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Temperature', 'Temperature'), ('\uf0e0', '\uf0e0'), ('10°-20°', '10°-20°'), (',', ','), ('30°-50°', '30°-50°'), (',', ','), ('35°-45°', '35°-45°'), ('Calendar', 'Calendar'), ('Dates', 'Dates'), ('\uf0e0', '\uf0e0'), ('15th', '15th'), ('–', '–'), ('22nd', '22nd'), (',', ','), ('10th', '10th'), ('–', '–'), ('30th', '30th'), ('We', 'We'), ('find', 'find'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolute'), (')', ')'), ('value', 'value'), ('interval', 'interval'), ('attributes', 'attribute'), ('.', '.')]



============================ Sentence 68 =============================

Attribute Types   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  4) Ratio Attribute Ratio attribute is looks like interval attribute, but it must have a true zero (absolute) value. 


>> Tokens are: 
 ['Attribute', 'Types', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '4', ')', 'Ratio', 'Attribute', 'Ratio', 'attribute', 'looks', 'like', 'interval', 'attribute', ',', 'must', 'true', 'zero', '(', 'absolute', ')', 'value', '.']

>> Bigrams are: 
 [('Attribute', 'Types'), ('Types', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '4'), ('4', ')'), (')', 'Ratio'), ('Ratio', 'Attribute'), ('Attribute', 'Ratio'), ('Ratio', 'attribute'), ('attribute', 'looks'), ('looks', 'like'), ('like', 'interval'), ('interval', 'attribute'), ('attribute', ','), (',', 'must'), ('must', 'true'), ('true', 'zero'), ('zero', '('), ('(', 'absolute'), ('absolute', ')'), (')', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Attribute', 'Types', 'Unit'), ('Types', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '4'), ('›', '4', ')'), ('4', ')', 'Ratio'), (')', 'Ratio', 'Attribute'), ('Ratio', 'Attribute', 'Ratio'), ('Attribute', 'Ratio', 'attribute'), ('Ratio', 'attribute', 'looks'), ('attribute', 'looks', 'like'), ('looks', 'like', 'interval'), ('like', 'interval', 'attribute'), ('interval', 'attribute', ','), ('attribute', ',', 'must'), (',', 'must', 'true'), ('must', 'true', 'zero'), ('true', 'zero', '('), ('zero', '(', 'absolute'), ('(', 'absolute', ')'), ('absolute', ')', 'value'), (')', 'value', '.')]

>> POS Tags are: 
 [('Attribute', 'NNP'), ('Types', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('4', 'CD'), (')', ')'), ('Ratio', 'NNP'), ('Attribute', 'NNP'), ('Ratio', 'NNP'), ('attribute', 'VBP'), ('looks', 'VBZ'), ('like', 'IN'), ('interval', 'JJ'), ('attribute', 'NN'), (',', ','), ('must', 'MD'), ('true', 'JJ'), ('zero', 'NN'), ('(', '('), ('absolute', 'NN'), (')', ')'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Attribute/NNP Types/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  4/CD
  )/)
  (NP Ratio/NNP Attribute/NNP Ratio/NNP)
  attribute/VBP
  looks/VBZ
  like/IN
  (NP interval/JJ attribute/NN)
  ,/,
  must/MD
  (NP true/JJ zero/NN)
  (/(
  (NP absolute/NN)
  )/)
  (NP value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Attribute Types Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Ratio Attribute Ratio', 'interval attribute', 'true zero', 'absolute', 'value']

>> Named Entities are: 
 [('PERSON', 'Attribute'), ('PERSON', 'Types Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Ratio Attribute Ratio')] 

>> Stemming using Porter Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Ratio', 'ratio'), ('Attribute', 'attribut'), ('Ratio', 'ratio'), ('attribute', 'attribut'), ('looks', 'look'), ('like', 'like'), ('interval', 'interv'), ('attribute', 'attribut'), (',', ','), ('must', 'must'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Ratio', 'ratio'), ('Attribute', 'attribut'), ('Ratio', 'ratio'), ('attribute', 'attribut'), ('looks', 'look'), ('like', 'like'), ('interval', 'interv'), ('attribute', 'attribut'), (',', ','), ('must', 'must'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Attribute', 'Attribute'), ('Types', 'Types'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Ratio', 'Ratio'), ('Attribute', 'Attribute'), ('Ratio', 'Ratio'), ('attribute', 'attribute'), ('looks', 'look'), ('like', 'like'), ('interval', 'interval'), ('attribute', 'attribute'), (',', ','), ('must', 'must'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolute'), (')', ')'), ('value', 'value'), ('.', '.')]



============================ Sentence 69 =============================

It tells us about the order and the exact value between units or data. 


>> Tokens are: 
 ['It', 'tells', 'us', 'order', 'exact', 'value', 'units', 'data', '.']

>> Bigrams are: 
 [('It', 'tells'), ('tells', 'us'), ('us', 'order'), ('order', 'exact'), ('exact', 'value'), ('value', 'units'), ('units', 'data'), ('data', '.')]

>> Trigrams are: 
 [('It', 'tells', 'us'), ('tells', 'us', 'order'), ('us', 'order', 'exact'), ('order', 'exact', 'value'), ('exact', 'value', 'units'), ('value', 'units', 'data'), ('units', 'data', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('tells', 'VBZ'), ('us', 'PRP'), ('order', 'NN'), ('exact', 'JJ'), ('value', 'NN'), ('units', 'NNS'), ('data', 'NNS'), ('.', '.')]

 (S
  It/PRP
  tells/VBZ
  us/PRP
  (NP order/NN)
  (NP exact/JJ value/NN units/NNS data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['order', 'exact value units data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('tells', 'tell'), ('us', 'us'), ('order', 'order'), ('exact', 'exact'), ('value', 'valu'), ('units', 'unit'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('tells', 'tell'), ('us', 'us'), ('order', 'order'), ('exact', 'exact'), ('value', 'valu'), ('units', 'unit'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('tells', 'tell'), ('us', 'u'), ('order', 'order'), ('exact', 'exact'), ('value', 'value'), ('units', 'unit'), ('data', 'data'), ('.', '.')]



============================ Sentence 70 =============================

Example Age Group  10-20, 30-50, 35-45 (In years) Mass  20-30 kg, 10-15 kg It does have a true zero (absolute) so, it is possible to compute ratios. 


>> Tokens are: 
 ['Example', 'Age', 'Group', '\uf0e0', '10-20', ',', '30-50', ',', '35-45', '(', 'In', 'years', ')', 'Mass', '\uf0e0', '20-30', 'kg', ',', '10-15', 'kg', 'It', 'true', 'zero', '(', 'absolute', ')', ',', 'possible', 'compute', 'ratios', '.']

>> Bigrams are: 
 [('Example', 'Age'), ('Age', 'Group'), ('Group', '\uf0e0'), ('\uf0e0', '10-20'), ('10-20', ','), (',', '30-50'), ('30-50', ','), (',', '35-45'), ('35-45', '('), ('(', 'In'), ('In', 'years'), ('years', ')'), (')', 'Mass'), ('Mass', '\uf0e0'), ('\uf0e0', '20-30'), ('20-30', 'kg'), ('kg', ','), (',', '10-15'), ('10-15', 'kg'), ('kg', 'It'), ('It', 'true'), ('true', 'zero'), ('zero', '('), ('(', 'absolute'), ('absolute', ')'), (')', ','), (',', 'possible'), ('possible', 'compute'), ('compute', 'ratios'), ('ratios', '.')]

>> Trigrams are: 
 [('Example', 'Age', 'Group'), ('Age', 'Group', '\uf0e0'), ('Group', '\uf0e0', '10-20'), ('\uf0e0', '10-20', ','), ('10-20', ',', '30-50'), (',', '30-50', ','), ('30-50', ',', '35-45'), (',', '35-45', '('), ('35-45', '(', 'In'), ('(', 'In', 'years'), ('In', 'years', ')'), ('years', ')', 'Mass'), (')', 'Mass', '\uf0e0'), ('Mass', '\uf0e0', '20-30'), ('\uf0e0', '20-30', 'kg'), ('20-30', 'kg', ','), ('kg', ',', '10-15'), (',', '10-15', 'kg'), ('10-15', 'kg', 'It'), ('kg', 'It', 'true'), ('It', 'true', 'zero'), ('true', 'zero', '('), ('zero', '(', 'absolute'), ('(', 'absolute', ')'), ('absolute', ')', ','), (')', ',', 'possible'), (',', 'possible', 'compute'), ('possible', 'compute', 'ratios'), ('compute', 'ratios', '.')]

>> POS Tags are: 
 [('Example', 'NNP'), ('Age', 'NNP'), ('Group', 'NNP'), ('\uf0e0', 'NNP'), ('10-20', 'CD'), (',', ','), ('30-50', 'CD'), (',', ','), ('35-45', 'CD'), ('(', '('), ('In', 'IN'), ('years', 'NNS'), (')', ')'), ('Mass', 'NNP'), ('\uf0e0', 'NNP'), ('20-30', 'JJ'), ('kg', 'NN'), (',', ','), ('10-15', 'JJ'), ('kg', 'NN'), ('It', 'PRP'), ('true', 'JJ'), ('zero', 'NN'), ('(', '('), ('absolute', 'NN'), (')', ')'), (',', ','), ('possible', 'JJ'), ('compute', 'NN'), ('ratios', 'NNS'), ('.', '.')]

 (S
  (NP Example/NNP Age/NNP Group/NNP /NNP)
  10-20/CD
  ,/,
  30-50/CD
  ,/,
  35-45/CD
  (/(
  In/IN
  (NP years/NNS)
  )/)
  (NP Mass/NNP /NNP)
  (NP 20-30/JJ kg/NN)
  ,/,
  (NP 10-15/JJ kg/NN)
  It/PRP
  (NP true/JJ zero/NN)
  (/(
  (NP absolute/NN)
  )/)
  ,/,
  (NP possible/JJ compute/NN ratios/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Example Age Group \uf0e0', 'years', 'Mass \uf0e0', '20-30 kg', '10-15 kg', 'true zero', 'absolute', 'possible compute ratios']

>> Named Entities are: 
 [('PERSON', 'Example'), ('ORGANIZATION', 'Age Group'), ('PERSON', 'Mass')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Age', 'age'), ('Group', 'group'), ('\uf0e0', '\uf0e0'), ('10-20', '10-20'), (',', ','), ('30-50', '30-50'), (',', ','), ('35-45', '35-45'), ('(', '('), ('In', 'in'), ('years', 'year'), (')', ')'), ('Mass', 'mass'), ('\uf0e0', '\uf0e0'), ('20-30', '20-30'), ('kg', 'kg'), (',', ','), ('10-15', '10-15'), ('kg', 'kg'), ('It', 'it'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), (',', ','), ('possible', 'possibl'), ('compute', 'comput'), ('ratios', 'ratio'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Age', 'age'), ('Group', 'group'), ('\uf0e0', '\uf0e0'), ('10-20', '10-20'), (',', ','), ('30-50', '30-50'), (',', ','), ('35-45', '35-45'), ('(', '('), ('In', 'in'), ('years', 'year'), (')', ')'), ('Mass', 'mass'), ('\uf0e0', '\uf0e0'), ('20-30', '20-30'), ('kg', 'kg'), (',', ','), ('10-15', '10-15'), ('kg', 'kg'), ('It', 'it'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolut'), (')', ')'), (',', ','), ('possible', 'possibl'), ('compute', 'comput'), ('ratios', 'ratio'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Age', 'Age'), ('Group', 'Group'), ('\uf0e0', '\uf0e0'), ('10-20', '10-20'), (',', ','), ('30-50', '30-50'), (',', ','), ('35-45', '35-45'), ('(', '('), ('In', 'In'), ('years', 'year'), (')', ')'), ('Mass', 'Mass'), ('\uf0e0', '\uf0e0'), ('20-30', '20-30'), ('kg', 'kg'), (',', ','), ('10-15', '10-15'), ('kg', 'kg'), ('It', 'It'), ('true', 'true'), ('zero', 'zero'), ('(', '('), ('absolute', 'absolute'), (')', ')'), (',', ','), ('possible', 'possible'), ('compute', 'compute'), ('ratios', 'ratio'), ('.', '.')]



============================ Sentence 71 =============================

Attribute Types   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Preprocessing Tasks Data  Cleaning Data  Integration Data  Transformation Data  Reduction    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Data Cleaning Fill in missing values Ignore the tuple Fill missing value manually Fill in the missing value automatically Use a global constant to fill in the missing value Identify outliers and smooth out noisy data Binning Method Clustering Correct inconsistent data Resolve redundancy caused by data integration   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Fill missing values Ignore the tuple (record/row):  Usually done when class label is missing. 


>> Tokens are: 
 ['Attribute', 'Types', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Preprocessing', 'Tasks', 'Data', 'Cleaning', 'Data', 'Integration', 'Data', 'Transformation', 'Data', 'Reduction', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Data', 'Cleaning', 'Fill', 'missing', 'values', 'Ignore', 'tuple', 'Fill', 'missing', 'value', 'manually', 'Fill', 'missing', 'value', 'automatically', 'Use', 'global', 'constant', 'fill', 'missing', 'value', 'Identify', 'outliers', 'smooth', 'noisy', 'data', 'Binning', 'Method', 'Clustering', 'Correct', 'inconsistent', 'data', 'Resolve', 'redundancy', 'caused', 'data', 'integration', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Fill', 'missing', 'values', 'Ignore', 'tuple', '(', 'record/row', ')', ':', 'Usually', 'done', 'class', 'label', 'missing', '.']

>> Bigrams are: 
 [('Attribute', 'Types'), ('Types', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Tasks'), ('Tasks', 'Data'), ('Data', 'Cleaning'), ('Cleaning', 'Data'), ('Data', 'Integration'), ('Integration', 'Data'), ('Data', 'Transformation'), ('Transformation', 'Data'), ('Data', 'Reduction'), ('Reduction', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Data'), ('Data', 'Cleaning'), ('Cleaning', 'Fill'), ('Fill', 'missing'), ('missing', 'values'), ('values', 'Ignore'), ('Ignore', 'tuple'), ('tuple', 'Fill'), ('Fill', 'missing'), ('missing', 'value'), ('value', 'manually'), ('manually', 'Fill'), ('Fill', 'missing'), ('missing', 'value'), ('value', 'automatically'), ('automatically', 'Use'), ('Use', 'global'), ('global', 'constant'), ('constant', 'fill'), ('fill', 'missing'), ('missing', 'value'), ('value', 'Identify'), ('Identify', 'outliers'), ('outliers', 'smooth'), ('smooth', 'noisy'), ('noisy', 'data'), ('data', 'Binning'), ('Binning', 'Method'), ('Method', 'Clustering'), ('Clustering', 'Correct'), ('Correct', 'inconsistent'), ('inconsistent', 'data'), ('data', 'Resolve'), ('Resolve', 'redundancy'), ('redundancy', 'caused'), ('caused', 'data'), ('data', 'integration'), ('integration', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Fill'), ('Fill', 'missing'), ('missing', 'values'), ('values', 'Ignore'), ('Ignore', 'tuple'), ('tuple', '('), ('(', 'record/row'), ('record/row', ')'), (')', ':'), (':', 'Usually'), ('Usually', 'done'), ('done', 'class'), ('class', 'label'), ('label', 'missing'), ('missing', '.')]

>> Trigrams are: 
 [('Attribute', 'Types', 'Unit'), ('Types', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Tasks'), ('Preprocessing', 'Tasks', 'Data'), ('Tasks', 'Data', 'Cleaning'), ('Data', 'Cleaning', 'Data'), ('Cleaning', 'Data', 'Integration'), ('Data', 'Integration', 'Data'), ('Integration', 'Data', 'Transformation'), ('Data', 'Transformation', 'Data'), ('Transformation', 'Data', 'Reduction'), ('Data', 'Reduction', 'Unit'), ('Reduction', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Data'), (')', 'Data', 'Cleaning'), ('Data', 'Cleaning', 'Fill'), ('Cleaning', 'Fill', 'missing'), ('Fill', 'missing', 'values'), ('missing', 'values', 'Ignore'), ('values', 'Ignore', 'tuple'), ('Ignore', 'tuple', 'Fill'), ('tuple', 'Fill', 'missing'), ('Fill', 'missing', 'value'), ('missing', 'value', 'manually'), ('value', 'manually', 'Fill'), ('manually', 'Fill', 'missing'), ('Fill', 'missing', 'value'), ('missing', 'value', 'automatically'), ('value', 'automatically', 'Use'), ('automatically', 'Use', 'global'), ('Use', 'global', 'constant'), ('global', 'constant', 'fill'), ('constant', 'fill', 'missing'), ('fill', 'missing', 'value'), ('missing', 'value', 'Identify'), ('value', 'Identify', 'outliers'), ('Identify', 'outliers', 'smooth'), ('outliers', 'smooth', 'noisy'), ('smooth', 'noisy', 'data'), ('noisy', 'data', 'Binning'), ('data', 'Binning', 'Method'), ('Binning', 'Method', 'Clustering'), ('Method', 'Clustering', 'Correct'), ('Clustering', 'Correct', 'inconsistent'), ('Correct', 'inconsistent', 'data'), ('inconsistent', 'data', 'Resolve'), ('data', 'Resolve', 'redundancy'), ('Resolve', 'redundancy', 'caused'), ('redundancy', 'caused', 'data'), ('caused', 'data', 'integration'), ('data', 'integration', 'Unit'), ('integration', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Fill'), (')', 'Fill', 'missing'), ('Fill', 'missing', 'values'), ('missing', 'values', 'Ignore'), ('values', 'Ignore', 'tuple'), ('Ignore', 'tuple', '('), ('tuple', '(', 'record/row'), ('(', 'record/row', ')'), ('record/row', ')', ':'), (')', ':', 'Usually'), (':', 'Usually', 'done'), ('Usually', 'done', 'class'), ('done', 'class', 'label'), ('class', 'label', 'missing'), ('label', 'missing', '.')]

>> POS Tags are: 
 [('Attribute', 'NNP'), ('Types', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Tasks', 'NNP'), ('Data', 'NNP'), ('Cleaning', 'NNP'), ('Data', 'NNP'), ('Integration', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('Data', 'NNP'), ('Reduction', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Data', 'NNPS'), ('Cleaning', 'NNP'), ('Fill', 'NNP'), ('missing', 'VBG'), ('values', 'NNS'), ('Ignore', 'NNP'), ('tuple', 'NN'), ('Fill', 'NNP'), ('missing', 'VBG'), ('value', 'NN'), ('manually', 'RB'), ('Fill', 'NNP'), ('missing', 'VBG'), ('value', 'NN'), ('automatically', 'RB'), ('Use', 'NNP'), ('global', 'JJ'), ('constant', 'NN'), ('fill', 'NN'), ('missing', 'VBG'), ('value', 'NN'), ('Identify', 'NNP'), ('outliers', 'NNS'), ('smooth', 'VBP'), ('noisy', 'JJ'), ('data', 'NNS'), ('Binning', 'NNP'), ('Method', 'NNP'), ('Clustering', 'NNP'), ('Correct', 'NNP'), ('inconsistent', 'NN'), ('data', 'NNS'), ('Resolve', 'NNP'), ('redundancy', 'NN'), ('caused', 'VBD'), ('data', 'NNS'), ('integration', 'NN'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Fill', 'NNP'), ('missing', 'VBG'), ('values', 'NNS'), ('Ignore', 'NNP'), ('tuple', 'NN'), ('(', '('), ('record/row', 'NN'), (')', ')'), (':', ':'), ('Usually', 'RB'), ('done', 'VBN'), ('class', 'NN'), ('label', 'NN'), ('missing', 'VBG'), ('.', '.')]

 (S
  (NP Attribute/NNP Types/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP
    ›/NNP
    Data/NNP
    Preprocessing/NNP
    Tasks/NNP
    Data/NNP
    Cleaning/NNP
    Data/NNP
    Integration/NNP
    Data/NNP
    Transformation/NNP
    Data/NNP
    Reduction/NNP
    Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  Data/NNPS
  (NP Cleaning/NNP Fill/NNP)
  missing/VBG
  (NP values/NNS Ignore/NNP tuple/NN Fill/NNP)
  missing/VBG
  (NP value/NN)
  manually/RB
  (NP Fill/NNP)
  missing/VBG
  (NP value/NN)
  automatically/RB
  (NP Use/NNP)
  (NP global/JJ constant/NN fill/NN)
  missing/VBG
  (NP value/NN Identify/NNP outliers/NNS)
  smooth/VBP
  (NP
    noisy/JJ
    data/NNS
    Binning/NNP
    Method/NNP
    Clustering/NNP
    Correct/NNP
    inconsistent/NN
    data/NNS
    Resolve/NNP
    redundancy/NN)
  caused/VBD
  (NP data/NNS integration/NN Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Fill/NNP)
  missing/VBG
  (NP values/NNS Ignore/NNP tuple/NN)
  (/(
  (NP record/row/NN)
  )/)
  :/:
  Usually/RB
  done/VBN
  (NP class/NN label/NN)
  missing/VBG
  ./.) 


>> Noun Phrases are: 
 ['Attribute Types Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Preprocessing Tasks Data Cleaning Data Integration Data Transformation Data Reduction Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Cleaning Fill', 'values Ignore tuple Fill', 'value', 'Fill', 'value', 'Use', 'global constant fill', 'value Identify outliers', 'noisy data Binning Method Clustering Correct inconsistent data Resolve redundancy', 'data integration Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Fill', 'values Ignore tuple', 'record/row', 'class label']

>> Named Entities are: 
 [('PERSON', 'Attribute'), ('PERSON', 'Types Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Data Cleaning'), ('GPE', 'Ignore'), ('ORGANIZATION', 'Use'), ('PERSON', 'Method Clustering Correct'), ('PERSON', 'Resolve'), ('PERSON', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Ignore')] 

>> Stemming using Porter Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Tasks', 'task'), ('Data', 'data'), ('Cleaning', 'clean'), ('Data', 'data'), ('Integration', 'integr'), ('Data', 'data'), ('Transformation', 'transform'), ('Data', 'data'), ('Reduction', 'reduct'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Data', 'data'), ('Cleaning', 'clean'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('Ignore', 'ignor'), ('tuple', 'tupl'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('manually', 'manual'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('automatically', 'automat'), ('Use', 'use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('Identify', 'identifi'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisi'), ('data', 'data'), ('Binning', 'bin'), ('Method', 'method'), ('Clustering', 'cluster'), ('Correct', 'correct'), ('inconsistent', 'inconsist'), ('data', 'data'), ('Resolve', 'resolv'), ('redundancy', 'redund'), ('caused', 'caus'), ('data', 'data'), ('integration', 'integr'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('Ignore', 'ignor'), ('tuple', 'tupl'), ('(', '('), ('record/row', 'record/row'), (')', ')'), (':', ':'), ('Usually', 'usual'), ('done', 'done'), ('class', 'class'), ('label', 'label'), ('missing', 'miss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Attribute', 'attribut'), ('Types', 'type'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Tasks', 'task'), ('Data', 'data'), ('Cleaning', 'clean'), ('Data', 'data'), ('Integration', 'integr'), ('Data', 'data'), ('Transformation', 'transform'), ('Data', 'data'), ('Reduction', 'reduct'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Data', 'data'), ('Cleaning', 'clean'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('Ignore', 'ignor'), ('tuple', 'tupl'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('manually', 'manual'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('automatically', 'automat'), ('Use', 'use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('Identify', 'identifi'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisi'), ('data', 'data'), ('Binning', 'bin'), ('Method', 'method'), ('Clustering', 'cluster'), ('Correct', 'correct'), ('inconsistent', 'inconsist'), ('data', 'data'), ('Resolve', 'resolv'), ('redundancy', 'redund'), ('caused', 'caus'), ('data', 'data'), ('integration', 'integr'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('Ignore', 'ignor'), ('tuple', 'tupl'), ('(', '('), ('record/row', 'record/row'), (')', ')'), (':', ':'), ('Usually', 'usual'), ('done', 'done'), ('class', 'class'), ('label', 'label'), ('missing', 'miss'), ('.', '.')]

>> Lemmatization: 
 [('Attribute', 'Attribute'), ('Types', 'Types'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Tasks', 'Tasks'), ('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Data', 'Data'), ('Integration', 'Integration'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('Data', 'Data'), ('Reduction', 'Reduction'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Fill', 'Fill'), ('missing', 'missing'), ('values', 'value'), ('Ignore', 'Ignore'), ('tuple', 'tuple'), ('Fill', 'Fill'), ('missing', 'missing'), ('value', 'value'), ('manually', 'manually'), ('Fill', 'Fill'), ('missing', 'missing'), ('value', 'value'), ('automatically', 'automatically'), ('Use', 'Use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'missing'), ('value', 'value'), ('Identify', 'Identify'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisy'), ('data', 'data'), ('Binning', 'Binning'), ('Method', 'Method'), ('Clustering', 'Clustering'), ('Correct', 'Correct'), ('inconsistent', 'inconsistent'), ('data', 'data'), ('Resolve', 'Resolve'), ('redundancy', 'redundancy'), ('caused', 'caused'), ('data', 'data'), ('integration', 'integration'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'Fill'), ('missing', 'missing'), ('values', 'value'), ('Ignore', 'Ignore'), ('tuple', 'tuple'), ('(', '('), ('record/row', 'record/row'), (')', ')'), (':', ':'), ('Usually', 'Usually'), ('done', 'done'), ('class', 'class'), ('label', 'label'), ('missing', 'missing'), ('.', '.')]



============================ Sentence 72 =============================

Example The task is to distinguish between two types of emails, “spam” and “non-spam” (Ham). 


>> Tokens are: 
 ['Example', 'The', 'task', 'distinguish', 'two', 'types', 'emails', ',', '“', 'spam', '”', '“', 'non-spam', '”', '(', 'Ham', ')', '.']

>> Bigrams are: 
 [('Example', 'The'), ('The', 'task'), ('task', 'distinguish'), ('distinguish', 'two'), ('two', 'types'), ('types', 'emails'), ('emails', ','), (',', '“'), ('“', 'spam'), ('spam', '”'), ('”', '“'), ('“', 'non-spam'), ('non-spam', '”'), ('”', '('), ('(', 'Ham'), ('Ham', ')'), (')', '.')]

>> Trigrams are: 
 [('Example', 'The', 'task'), ('The', 'task', 'distinguish'), ('task', 'distinguish', 'two'), ('distinguish', 'two', 'types'), ('two', 'types', 'emails'), ('types', 'emails', ','), ('emails', ',', '“'), (',', '“', 'spam'), ('“', 'spam', '”'), ('spam', '”', '“'), ('”', '“', 'non-spam'), ('“', 'non-spam', '”'), ('non-spam', '”', '('), ('”', '(', 'Ham'), ('(', 'Ham', ')'), ('Ham', ')', '.')]

>> POS Tags are: 
 [('Example', 'VB'), ('The', 'DT'), ('task', 'NN'), ('distinguish', 'JJ'), ('two', 'CD'), ('types', 'NNS'), ('emails', 'NNS'), (',', ','), ('“', 'NNP'), ('spam', 'VBD'), ('”', 'JJ'), ('“', 'NNP'), ('non-spam', 'JJ'), ('”', 'NNP'), ('(', '('), ('Ham', 'NNP'), (')', ')'), ('.', '.')]

 (S
  Example/VB
  (NP The/DT task/NN)
  distinguish/JJ
  two/CD
  (NP types/NNS emails/NNS)
  ,/,
  (NP “/NNP)
  spam/VBD
  (NP ”/JJ “/NNP)
  (NP non-spam/JJ ”/NNP)
  (/(
  (NP Ham/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The task', 'types emails', '“', '” “', 'non-spam ”', 'Ham']

>> Named Entities are: 
 [('ORGANIZATION', 'Ham')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('The', 'the'), ('task', 'task'), ('distinguish', 'distinguish'), ('two', 'two'), ('types', 'type'), ('emails', 'email'), (',', ','), ('“', '“'), ('spam', 'spam'), ('”', '”'), ('“', '“'), ('non-spam', 'non-spam'), ('”', '”'), ('(', '('), ('Ham', 'ham'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('The', 'the'), ('task', 'task'), ('distinguish', 'distinguish'), ('two', 'two'), ('types', 'type'), ('emails', 'email'), (',', ','), ('“', '“'), ('spam', 'spam'), ('”', '”'), ('“', '“'), ('non-spam', 'non-spam'), ('”', '”'), ('(', '('), ('Ham', 'ham'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('The', 'The'), ('task', 'task'), ('distinguish', 'distinguish'), ('two', 'two'), ('types', 'type'), ('emails', 'email'), (',', ','), ('“', '“'), ('spam', 'spam'), ('”', '”'), ('“', '“'), ('non-spam', 'non-spam'), ('”', '”'), ('(', '('), ('Ham', 'Ham'), (')', ')'), ('.', '.')]



============================ Sentence 73 =============================

Spam & non-spam are called as class label. 


>> Tokens are: 
 ['Spam', '&', 'non-spam', 'called', 'class', 'label', '.']

>> Bigrams are: 
 [('Spam', '&'), ('&', 'non-spam'), ('non-spam', 'called'), ('called', 'class'), ('class', 'label'), ('label', '.')]

>> Trigrams are: 
 [('Spam', '&', 'non-spam'), ('&', 'non-spam', 'called'), ('non-spam', 'called', 'class'), ('called', 'class', 'label'), ('class', 'label', '.')]

>> POS Tags are: 
 [('Spam', 'NNP'), ('&', 'CC'), ('non-spam', 'JJ'), ('called', 'VBN'), ('class', 'NN'), ('label', 'NN'), ('.', '.')]

 (S
  (NP Spam/NNP)
  &/CC
  non-spam/JJ
  called/VBN
  (NP class/NN label/NN)
  ./.) 


>> Noun Phrases are: 
 ['Spam', 'class label']

>> Named Entities are: 
 [('GPE', 'Spam')] 

>> Stemming using Porter Stemmer: 
 [('Spam', 'spam'), ('&', '&'), ('non-spam', 'non-spam'), ('called', 'call'), ('class', 'class'), ('label', 'label'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spam', 'spam'), ('&', '&'), ('non-spam', 'non-spam'), ('called', 'call'), ('class', 'class'), ('label', 'label'), ('.', '.')]

>> Lemmatization: 
 [('Spam', 'Spam'), ('&', '&'), ('non-spam', 'non-spam'), ('called', 'called'), ('class', 'class'), ('label', 'label'), ('.', '.')]



============================ Sentence 74 =============================

If an email comes to you, in which class label is missing then it is discarded. 


>> Tokens are: 
 ['If', 'email', 'comes', ',', 'class', 'label', 'missing', 'discarded', '.']

>> Bigrams are: 
 [('If', 'email'), ('email', 'comes'), ('comes', ','), (',', 'class'), ('class', 'label'), ('label', 'missing'), ('missing', 'discarded'), ('discarded', '.')]

>> Trigrams are: 
 [('If', 'email', 'comes'), ('email', 'comes', ','), ('comes', ',', 'class'), (',', 'class', 'label'), ('class', 'label', 'missing'), ('label', 'missing', 'discarded'), ('missing', 'discarded', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('email', 'VBN'), ('comes', 'VBZ'), (',', ','), ('class', 'NN'), ('label', 'NN'), ('missing', 'VBG'), ('discarded', 'VBD'), ('.', '.')]

 (S
  If/IN
  email/VBN
  comes/VBZ
  ,/,
  (NP class/NN label/NN)
  missing/VBG
  discarded/VBD
  ./.) 


>> Noun Phrases are: 
 ['class label']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('email', 'email'), ('comes', 'come'), (',', ','), ('class', 'class'), ('label', 'label'), ('missing', 'miss'), ('discarded', 'discard'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('email', 'email'), ('comes', 'come'), (',', ','), ('class', 'class'), ('label', 'label'), ('missing', 'miss'), ('discarded', 'discard'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('email', 'email'), ('comes', 'come'), (',', ','), ('class', 'class'), ('label', 'label'), ('missing', 'missing'), ('discarded', 'discarded'), ('.', '.')]



============================ Sentence 75 =============================

Fill missing value manually: Use the attribute mean (average) to fill in the missing value and also use the attribute mean (average) for all samples belonging to the same class. 


>> Tokens are: 
 ['Fill', 'missing', 'value', 'manually', ':', 'Use', 'attribute', 'mean', '(', 'average', ')', 'fill', 'missing', 'value', 'also', 'use', 'attribute', 'mean', '(', 'average', ')', 'samples', 'belonging', 'class', '.']

>> Bigrams are: 
 [('Fill', 'missing'), ('missing', 'value'), ('value', 'manually'), ('manually', ':'), (':', 'Use'), ('Use', 'attribute'), ('attribute', 'mean'), ('mean', '('), ('(', 'average'), ('average', ')'), (')', 'fill'), ('fill', 'missing'), ('missing', 'value'), ('value', 'also'), ('also', 'use'), ('use', 'attribute'), ('attribute', 'mean'), ('mean', '('), ('(', 'average'), ('average', ')'), (')', 'samples'), ('samples', 'belonging'), ('belonging', 'class'), ('class', '.')]

>> Trigrams are: 
 [('Fill', 'missing', 'value'), ('missing', 'value', 'manually'), ('value', 'manually', ':'), ('manually', ':', 'Use'), (':', 'Use', 'attribute'), ('Use', 'attribute', 'mean'), ('attribute', 'mean', '('), ('mean', '(', 'average'), ('(', 'average', ')'), ('average', ')', 'fill'), (')', 'fill', 'missing'), ('fill', 'missing', 'value'), ('missing', 'value', 'also'), ('value', 'also', 'use'), ('also', 'use', 'attribute'), ('use', 'attribute', 'mean'), ('attribute', 'mean', '('), ('mean', '(', 'average'), ('(', 'average', ')'), ('average', ')', 'samples'), (')', 'samples', 'belonging'), ('samples', 'belonging', 'class'), ('belonging', 'class', '.')]

>> POS Tags are: 
 [('Fill', 'NNP'), ('missing', 'VBG'), ('value', 'NN'), ('manually', 'RB'), (':', ':'), ('Use', 'NNP'), ('attribute', 'JJ'), ('mean', 'NN'), ('(', '('), ('average', 'JJ'), (')', ')'), ('fill', 'NN'), ('missing', 'VBG'), ('value', 'NN'), ('also', 'RB'), ('use', 'VBP'), ('attribute', 'JJ'), ('mean', 'NN'), ('(', '('), ('average', 'JJ'), (')', ')'), ('samples', 'VBZ'), ('belonging', 'VBG'), ('class', 'NN'), ('.', '.')]

 (S
  (NP Fill/NNP)
  missing/VBG
  (NP value/NN)
  manually/RB
  :/:
  (NP Use/NNP)
  (NP attribute/JJ mean/NN)
  (/(
  average/JJ
  )/)
  (NP fill/NN)
  missing/VBG
  (NP value/NN)
  also/RB
  use/VBP
  (NP attribute/JJ mean/NN)
  (/(
  average/JJ
  )/)
  samples/VBZ
  belonging/VBG
  (NP class/NN)
  ./.) 


>> Noun Phrases are: 
 ['Fill', 'value', 'Use', 'attribute mean', 'fill', 'value', 'attribute mean', 'class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('manually', 'manual'), (':', ':'), ('Use', 'use'), ('attribute', 'attribut'), ('mean', 'mean'), ('(', '('), ('average', 'averag'), (')', ')'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('also', 'also'), ('use', 'use'), ('attribute', 'attribut'), ('mean', 'mean'), ('(', '('), ('average', 'averag'), (')', ')'), ('samples', 'sampl'), ('belonging', 'belong'), ('class', 'class'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('manually', 'manual'), (':', ':'), ('Use', 'use'), ('attribute', 'attribut'), ('mean', 'mean'), ('(', '('), ('average', 'averag'), (')', ')'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('also', 'also'), ('use', 'use'), ('attribute', 'attribut'), ('mean', 'mean'), ('(', '('), ('average', 'averag'), (')', ')'), ('samples', 'sampl'), ('belonging', 'belong'), ('class', 'class'), ('.', '.')]

>> Lemmatization: 
 [('Fill', 'Fill'), ('missing', 'missing'), ('value', 'value'), ('manually', 'manually'), (':', ':'), ('Use', 'Use'), ('attribute', 'attribute'), ('mean', 'mean'), ('(', '('), ('average', 'average'), (')', ')'), ('fill', 'fill'), ('missing', 'missing'), ('value', 'value'), ('also', 'also'), ('use', 'use'), ('attribute', 'attribute'), ('mean', 'mean'), ('(', '('), ('average', 'average'), (')', ')'), ('samples', 'sample'), ('belonging', 'belonging'), ('class', 'class'), ('.', '.')]



============================ Sentence 76 =============================

Data Cleaning   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Fill missing values (Cont..) Fill in the missing value automatically: Predict the missing value by using a learning algorithm:  Consider the attribute with the missing value as a dependent variable and run a learning algorithm (usually Naive Bayes or Decision tree) to predict the missing value. 


>> Tokens are: 
 ['Data', 'Cleaning', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Fill', 'missing', 'values', '(', 'Cont', '..', ')', 'Fill', 'missing', 'value', 'automatically', ':', 'Predict', 'missing', 'value', 'using', 'learning', 'algorithm', ':', 'Consider', 'attribute', 'missing', 'value', 'dependent', 'variable', 'run', 'learning', 'algorithm', '(', 'usually', 'Naive', 'Bayes', 'Decision', 'tree', ')', 'predict', 'missing', 'value', '.']

>> Bigrams are: 
 [('Data', 'Cleaning'), ('Cleaning', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Fill'), ('Fill', 'missing'), ('missing', 'values'), ('values', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Fill'), ('Fill', 'missing'), ('missing', 'value'), ('value', 'automatically'), ('automatically', ':'), (':', 'Predict'), ('Predict', 'missing'), ('missing', 'value'), ('value', 'using'), ('using', 'learning'), ('learning', 'algorithm'), ('algorithm', ':'), (':', 'Consider'), ('Consider', 'attribute'), ('attribute', 'missing'), ('missing', 'value'), ('value', 'dependent'), ('dependent', 'variable'), ('variable', 'run'), ('run', 'learning'), ('learning', 'algorithm'), ('algorithm', '('), ('(', 'usually'), ('usually', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'Decision'), ('Decision', 'tree'), ('tree', ')'), (')', 'predict'), ('predict', 'missing'), ('missing', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Data', 'Cleaning', 'Unit'), ('Cleaning', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Fill'), (')', 'Fill', 'missing'), ('Fill', 'missing', 'values'), ('missing', 'values', '('), ('values', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Fill'), (')', 'Fill', 'missing'), ('Fill', 'missing', 'value'), ('missing', 'value', 'automatically'), ('value', 'automatically', ':'), ('automatically', ':', 'Predict'), (':', 'Predict', 'missing'), ('Predict', 'missing', 'value'), ('missing', 'value', 'using'), ('value', 'using', 'learning'), ('using', 'learning', 'algorithm'), ('learning', 'algorithm', ':'), ('algorithm', ':', 'Consider'), (':', 'Consider', 'attribute'), ('Consider', 'attribute', 'missing'), ('attribute', 'missing', 'value'), ('missing', 'value', 'dependent'), ('value', 'dependent', 'variable'), ('dependent', 'variable', 'run'), ('variable', 'run', 'learning'), ('run', 'learning', 'algorithm'), ('learning', 'algorithm', '('), ('algorithm', '(', 'usually'), ('(', 'usually', 'Naive'), ('usually', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'Decision'), ('Bayes', 'Decision', 'tree'), ('Decision', 'tree', ')'), ('tree', ')', 'predict'), (')', 'predict', 'missing'), ('predict', 'missing', 'value'), ('missing', 'value', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Cleaning', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Fill', 'NNP'), ('missing', 'VBG'), ('values', 'NNS'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Fill', 'NNP'), ('missing', 'VBG'), ('value', 'NN'), ('automatically', 'RB'), (':', ':'), ('Predict', 'NNP'), ('missing', 'VBG'), ('value', 'NN'), ('using', 'VBG'), ('learning', 'VBG'), ('algorithm', 'NN'), (':', ':'), ('Consider', 'VB'), ('attribute', 'NN'), ('missing', 'VBG'), ('value', 'NN'), ('dependent', 'NN'), ('variable', 'JJ'), ('run', 'NN'), ('learning', 'VBG'), ('algorithm', 'NNS'), ('(', '('), ('usually', 'RB'), ('Naive', 'NNP'), ('Bayes', 'NNP'), ('Decision', 'NNP'), ('tree', 'NN'), (')', ')'), ('predict', 'VBP'), ('missing', 'VBG'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP Cleaning/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Fill/NNP)
  missing/VBG
  (NP values/NNS)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Fill/NNP)
  missing/VBG
  (NP value/NN)
  automatically/RB
  :/:
  (NP Predict/NNP)
  missing/VBG
  (NP value/NN)
  using/VBG
  learning/VBG
  (NP algorithm/NN)
  :/:
  Consider/VB
  (NP attribute/NN)
  missing/VBG
  (NP value/NN dependent/NN)
  (NP variable/JJ run/NN)
  learning/VBG
  (NP algorithm/NNS)
  (/(
  usually/RB
  (NP Naive/NNP Bayes/NNP Decision/NNP tree/NN)
  )/)
  predict/VBP
  missing/VBG
  (NP value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data Cleaning Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Fill', 'values', 'Cont ..', 'Fill', 'value', 'Predict', 'value', 'algorithm', 'attribute', 'value dependent', 'variable run', 'algorithm', 'Naive Bayes Decision tree', 'value']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('automatically', 'automat'), (':', ':'), ('Predict', 'predict'), ('missing', 'miss'), ('value', 'valu'), ('using', 'use'), ('learning', 'learn'), ('algorithm', 'algorithm'), (':', ':'), ('Consider', 'consid'), ('attribute', 'attribut'), ('missing', 'miss'), ('value', 'valu'), ('dependent', 'depend'), ('variable', 'variabl'), ('run', 'run'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('(', '('), ('usually', 'usual'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Decision', 'decis'), ('tree', 'tree'), (')', ')'), ('predict', 'predict'), ('missing', 'miss'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('values', 'valu'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('automatically', 'automat'), (':', ':'), ('Predict', 'predict'), ('missing', 'miss'), ('value', 'valu'), ('using', 'use'), ('learning', 'learn'), ('algorithm', 'algorithm'), (':', ':'), ('Consider', 'consid'), ('attribute', 'attribut'), ('missing', 'miss'), ('value', 'valu'), ('dependent', 'depend'), ('variable', 'variabl'), ('run', 'run'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('(', '('), ('usually', 'usual'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Decision', 'decis'), ('tree', 'tree'), (')', ')'), ('predict', 'predict'), ('missing', 'miss'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Fill', 'Fill'), ('missing', 'missing'), ('values', 'value'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Fill', 'Fill'), ('missing', 'missing'), ('value', 'value'), ('automatically', 'automatically'), (':', ':'), ('Predict', 'Predict'), ('missing', 'missing'), ('value', 'value'), ('using', 'using'), ('learning', 'learning'), ('algorithm', 'algorithm'), (':', ':'), ('Consider', 'Consider'), ('attribute', 'attribute'), ('missing', 'missing'), ('value', 'value'), ('dependent', 'dependent'), ('variable', 'variable'), ('run', 'run'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('(', '('), ('usually', 'usually'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('Decision', 'Decision'), ('tree', 'tree'), (')', ')'), ('predict', 'predict'), ('missing', 'missing'), ('value', 'value'), ('.', '.')]



============================ Sentence 77 =============================

Use a global constant to fill in the missing value Replace all missing attribute values by the same constant such as a label like “Unknown”. 


>> Tokens are: 
 ['Use', 'global', 'constant', 'fill', 'missing', 'value', 'Replace', 'missing', 'attribute', 'values', 'constant', 'label', 'like', '“', 'Unknown', '”', '.']

>> Bigrams are: 
 [('Use', 'global'), ('global', 'constant'), ('constant', 'fill'), ('fill', 'missing'), ('missing', 'value'), ('value', 'Replace'), ('Replace', 'missing'), ('missing', 'attribute'), ('attribute', 'values'), ('values', 'constant'), ('constant', 'label'), ('label', 'like'), ('like', '“'), ('“', 'Unknown'), ('Unknown', '”'), ('”', '.')]

>> Trigrams are: 
 [('Use', 'global', 'constant'), ('global', 'constant', 'fill'), ('constant', 'fill', 'missing'), ('fill', 'missing', 'value'), ('missing', 'value', 'Replace'), ('value', 'Replace', 'missing'), ('Replace', 'missing', 'attribute'), ('missing', 'attribute', 'values'), ('attribute', 'values', 'constant'), ('values', 'constant', 'label'), ('constant', 'label', 'like'), ('label', 'like', '“'), ('like', '“', 'Unknown'), ('“', 'Unknown', '”'), ('Unknown', '”', '.')]

>> POS Tags are: 
 [('Use', 'NNP'), ('global', 'JJ'), ('constant', 'NN'), ('fill', 'NN'), ('missing', 'VBG'), ('value', 'NN'), ('Replace', 'NNP'), ('missing', 'VBG'), ('attribute', 'NN'), ('values', 'NNS'), ('constant', 'VBP'), ('label', 'NN'), ('like', 'IN'), ('“', 'NNP'), ('Unknown', 'NNP'), ('”', 'NNP'), ('.', '.')]

 (S
  (NP Use/NNP)
  (NP global/JJ constant/NN fill/NN)
  missing/VBG
  (NP value/NN Replace/NNP)
  missing/VBG
  (NP attribute/NN values/NNS)
  constant/VBP
  (NP label/NN)
  like/IN
  (NP “/NNP Unknown/NNP ”/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Use', 'global constant fill', 'value Replace', 'attribute values', 'label', '“ Unknown ”']

>> Named Entities are: 
 [('PERSON', 'Unknown')] 

>> Stemming using Porter Stemmer: 
 [('Use', 'use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('Replace', 'replac'), ('missing', 'miss'), ('attribute', 'attribut'), ('values', 'valu'), ('constant', 'constant'), ('label', 'label'), ('like', 'like'), ('“', '“'), ('Unknown', 'unknown'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Use', 'use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'miss'), ('value', 'valu'), ('Replace', 'replac'), ('missing', 'miss'), ('attribute', 'attribut'), ('values', 'valu'), ('constant', 'constant'), ('label', 'label'), ('like', 'like'), ('“', '“'), ('Unknown', 'unknown'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('Use', 'Use'), ('global', 'global'), ('constant', 'constant'), ('fill', 'fill'), ('missing', 'missing'), ('value', 'value'), ('Replace', 'Replace'), ('missing', 'missing'), ('attribute', 'attribute'), ('values', 'value'), ('constant', 'constant'), ('label', 'label'), ('like', 'like'), ('“', '“'), ('Unknown', 'Unknown'), ('”', '”'), ('.', '.')]



============================ Sentence 78 =============================

Data Cleaning   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  2) Identify outliers and smooth out noisy data Binning method Clustering Data Cleaning   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Binning method Data binning or bucketing is a data pre-processing technique used to reduce the effects of minor observation errors. 


>> Tokens are: 
 ['Data', 'Cleaning', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '2', ')', 'Identify', 'outliers', 'smooth', 'noisy', 'data', 'Binning', 'method', 'Clustering', 'Data', 'Cleaning', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Binning', 'method', 'Data', 'binning', 'bucketing', 'data', 'pre-processing', 'technique', 'used', 'reduce', 'effects', 'minor', 'observation', 'errors', '.']

>> Bigrams are: 
 [('Data', 'Cleaning'), ('Cleaning', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '2'), ('2', ')'), (')', 'Identify'), ('Identify', 'outliers'), ('outliers', 'smooth'), ('smooth', 'noisy'), ('noisy', 'data'), ('data', 'Binning'), ('Binning', 'method'), ('method', 'Clustering'), ('Clustering', 'Data'), ('Data', 'Cleaning'), ('Cleaning', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Binning'), ('Binning', 'method'), ('method', 'Data'), ('Data', 'binning'), ('binning', 'bucketing'), ('bucketing', 'data'), ('data', 'pre-processing'), ('pre-processing', 'technique'), ('technique', 'used'), ('used', 'reduce'), ('reduce', 'effects'), ('effects', 'minor'), ('minor', 'observation'), ('observation', 'errors'), ('errors', '.')]

>> Trigrams are: 
 [('Data', 'Cleaning', 'Unit'), ('Cleaning', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '2'), ('›', '2', ')'), ('2', ')', 'Identify'), (')', 'Identify', 'outliers'), ('Identify', 'outliers', 'smooth'), ('outliers', 'smooth', 'noisy'), ('smooth', 'noisy', 'data'), ('noisy', 'data', 'Binning'), ('data', 'Binning', 'method'), ('Binning', 'method', 'Clustering'), ('method', 'Clustering', 'Data'), ('Clustering', 'Data', 'Cleaning'), ('Data', 'Cleaning', 'Unit'), ('Cleaning', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Binning'), (')', 'Binning', 'method'), ('Binning', 'method', 'Data'), ('method', 'Data', 'binning'), ('Data', 'binning', 'bucketing'), ('binning', 'bucketing', 'data'), ('bucketing', 'data', 'pre-processing'), ('data', 'pre-processing', 'technique'), ('pre-processing', 'technique', 'used'), ('technique', 'used', 'reduce'), ('used', 'reduce', 'effects'), ('reduce', 'effects', 'minor'), ('effects', 'minor', 'observation'), ('minor', 'observation', 'errors'), ('observation', 'errors', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Cleaning', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('2', 'CD'), (')', ')'), ('Identify', 'NNP'), ('outliers', 'NNS'), ('smooth', 'VBP'), ('noisy', 'JJ'), ('data', 'NNS'), ('Binning', 'NNP'), ('method', 'NN'), ('Clustering', 'NNP'), ('Data', 'NNP'), ('Cleaning', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Binning', 'NNP'), ('method', 'NN'), ('Data', 'NNP'), ('binning', 'NN'), ('bucketing', 'VBG'), ('data', 'NNS'), ('pre-processing', 'NN'), ('technique', 'NN'), ('used', 'VBN'), ('reduce', 'VB'), ('effects', 'NNS'), ('minor', 'JJ'), ('observation', 'NN'), ('errors', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP Cleaning/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  2/CD
  )/)
  (NP Identify/NNP outliers/NNS)
  smooth/VBP
  (NP
    noisy/JJ
    data/NNS
    Binning/NNP
    method/NN
    Clustering/NNP
    Data/NNP
    Cleaning/NNP
    Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Binning/NNP method/NN Data/NNP binning/NN)
  bucketing/VBG
  (NP data/NNS pre-processing/NN technique/NN)
  used/VBN
  reduce/VB
  (NP effects/NNS)
  (NP minor/JJ observation/NN errors/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data Cleaning Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Identify outliers', 'noisy data Binning method Clustering Data Cleaning Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Binning method Data binning', 'data pre-processing technique', 'effects', 'minor observation errors']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Identify', 'identifi'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisi'), ('data', 'data'), ('Binning', 'bin'), ('method', 'method'), ('Clustering', 'cluster'), ('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('Data', 'data'), ('binning', 'bin'), ('bucketing', 'bucket'), ('data', 'data'), ('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('used', 'use'), ('reduce', 'reduc'), ('effects', 'effect'), ('minor', 'minor'), ('observation', 'observ'), ('errors', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Identify', 'identifi'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisi'), ('data', 'data'), ('Binning', 'bin'), ('method', 'method'), ('Clustering', 'cluster'), ('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('Data', 'data'), ('binning', 'bin'), ('bucketing', 'bucket'), ('data', 'data'), ('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('used', 'use'), ('reduce', 'reduc'), ('effects', 'effect'), ('minor', 'minor'), ('observation', 'observ'), ('errors', 'error'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Identify', 'Identify'), ('outliers', 'outlier'), ('smooth', 'smooth'), ('noisy', 'noisy'), ('data', 'data'), ('Binning', 'Binning'), ('method', 'method'), ('Clustering', 'Clustering'), ('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'Binning'), ('method', 'method'), ('Data', 'Data'), ('binning', 'binning'), ('bucketing', 'bucketing'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('technique', 'technique'), ('used', 'used'), ('reduce', 'reduce'), ('effects', 'effect'), ('minor', 'minor'), ('observation', 'observation'), ('errors', 'error'), ('.', '.')]



============================ Sentence 79 =============================

The original data values which fall in a given small interval called as a bin are replaced by a value which represents that interval, often called the central value. 


>> Tokens are: 
 ['The', 'original', 'data', 'values', 'fall', 'given', 'small', 'interval', 'called', 'bin', 'replaced', 'value', 'represents', 'interval', ',', 'often', 'called', 'central', 'value', '.']

>> Bigrams are: 
 [('The', 'original'), ('original', 'data'), ('data', 'values'), ('values', 'fall'), ('fall', 'given'), ('given', 'small'), ('small', 'interval'), ('interval', 'called'), ('called', 'bin'), ('bin', 'replaced'), ('replaced', 'value'), ('value', 'represents'), ('represents', 'interval'), ('interval', ','), (',', 'often'), ('often', 'called'), ('called', 'central'), ('central', 'value'), ('value', '.')]

>> Trigrams are: 
 [('The', 'original', 'data'), ('original', 'data', 'values'), ('data', 'values', 'fall'), ('values', 'fall', 'given'), ('fall', 'given', 'small'), ('given', 'small', 'interval'), ('small', 'interval', 'called'), ('interval', 'called', 'bin'), ('called', 'bin', 'replaced'), ('bin', 'replaced', 'value'), ('replaced', 'value', 'represents'), ('value', 'represents', 'interval'), ('represents', 'interval', ','), ('interval', ',', 'often'), (',', 'often', 'called'), ('often', 'called', 'central'), ('called', 'central', 'value'), ('central', 'value', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('original', 'JJ'), ('data', 'NNS'), ('values', 'NNS'), ('fall', 'VB'), ('given', 'VBN'), ('small', 'JJ'), ('interval', 'NN'), ('called', 'VBN'), ('bin', 'NN'), ('replaced', 'VBD'), ('value', 'NN'), ('represents', 'VBZ'), ('interval', 'JJ'), (',', ','), ('often', 'RB'), ('called', 'VBD'), ('central', 'JJ'), ('value', 'NN'), ('.', '.')]

 (S
  (NP The/DT original/JJ data/NNS values/NNS)
  fall/VB
  given/VBN
  (NP small/JJ interval/NN)
  called/VBN
  (NP bin/NN)
  replaced/VBD
  (NP value/NN)
  represents/VBZ
  interval/JJ
  ,/,
  often/RB
  called/VBD
  (NP central/JJ value/NN)
  ./.) 


>> Noun Phrases are: 
 ['The original data values', 'small interval', 'bin', 'value', 'central value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('original', 'origin'), ('data', 'data'), ('values', 'valu'), ('fall', 'fall'), ('given', 'given'), ('small', 'small'), ('interval', 'interv'), ('called', 'call'), ('bin', 'bin'), ('replaced', 'replac'), ('value', 'valu'), ('represents', 'repres'), ('interval', 'interv'), (',', ','), ('often', 'often'), ('called', 'call'), ('central', 'central'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('original', 'origin'), ('data', 'data'), ('values', 'valu'), ('fall', 'fall'), ('given', 'given'), ('small', 'small'), ('interval', 'interv'), ('called', 'call'), ('bin', 'bin'), ('replaced', 'replac'), ('value', 'valu'), ('represents', 'repres'), ('interval', 'interv'), (',', ','), ('often', 'often'), ('called', 'call'), ('central', 'central'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('original', 'original'), ('data', 'data'), ('values', 'value'), ('fall', 'fall'), ('given', 'given'), ('small', 'small'), ('interval', 'interval'), ('called', 'called'), ('bin', 'bin'), ('replaced', 'replaced'), ('value', 'value'), ('represents', 'represents'), ('interval', 'interval'), (',', ','), ('often', 'often'), ('called', 'called'), ('central', 'central'), ('value', 'value'), ('.', '.')]



============================ Sentence 80 =============================

Steps of Binning method Sort the attribute values and partition them into bins. 


>> Tokens are: 
 ['Steps', 'Binning', 'method', 'Sort', 'attribute', 'values', 'partition', 'bins', '.']

>> Bigrams are: 
 [('Steps', 'Binning'), ('Binning', 'method'), ('method', 'Sort'), ('Sort', 'attribute'), ('attribute', 'values'), ('values', 'partition'), ('partition', 'bins'), ('bins', '.')]

>> Trigrams are: 
 [('Steps', 'Binning', 'method'), ('Binning', 'method', 'Sort'), ('method', 'Sort', 'attribute'), ('Sort', 'attribute', 'values'), ('attribute', 'values', 'partition'), ('values', 'partition', 'bins'), ('partition', 'bins', '.')]

>> POS Tags are: 
 [('Steps', 'NNS'), ('Binning', 'VBG'), ('method', 'NN'), ('Sort', 'NNP'), ('attribute', 'NN'), ('values', 'NNS'), ('partition', 'NN'), ('bins', 'NNS'), ('.', '.')]

 (S
  (NP Steps/NNS)
  Binning/VBG
  (NP
    method/NN
    Sort/NNP
    attribute/NN
    values/NNS
    partition/NN
    bins/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Steps', 'method Sort attribute values partition bins']

>> Named Entities are: 
 [('PERSON', 'Sort')] 

>> Stemming using Porter Stemmer: 
 [('Steps', 'step'), ('Binning', 'bin'), ('method', 'method'), ('Sort', 'sort'), ('attribute', 'attribut'), ('values', 'valu'), ('partition', 'partit'), ('bins', 'bin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Steps', 'step'), ('Binning', 'bin'), ('method', 'method'), ('Sort', 'sort'), ('attribute', 'attribut'), ('values', 'valu'), ('partition', 'partit'), ('bins', 'bin'), ('.', '.')]

>> Lemmatization: 
 [('Steps', 'Steps'), ('Binning', 'Binning'), ('method', 'method'), ('Sort', 'Sort'), ('attribute', 'attribute'), ('values', 'value'), ('partition', 'partition'), ('bins', 'bin'), ('.', '.')]



============================ Sentence 81 =============================

Then smooth by bin means, bin median or bin boundaries. 


>> Tokens are: 
 ['Then', 'smooth', 'bin', 'means', ',', 'bin', 'median', 'bin', 'boundaries', '.']

>> Bigrams are: 
 [('Then', 'smooth'), ('smooth', 'bin'), ('bin', 'means'), ('means', ','), (',', 'bin'), ('bin', 'median'), ('median', 'bin'), ('bin', 'boundaries'), ('boundaries', '.')]

>> Trigrams are: 
 [('Then', 'smooth', 'bin'), ('smooth', 'bin', 'means'), ('bin', 'means', ','), ('means', ',', 'bin'), (',', 'bin', 'median'), ('bin', 'median', 'bin'), ('median', 'bin', 'boundaries'), ('bin', 'boundaries', '.')]

>> POS Tags are: 
 [('Then', 'RB'), ('smooth', 'CC'), ('bin', 'JJ'), ('means', 'NNS'), (',', ','), ('bin', 'NN'), ('median', 'JJ'), ('bin', 'NN'), ('boundaries', 'NNS'), ('.', '.')]

 (S
  Then/RB
  smooth/CC
  (NP bin/JJ means/NNS)
  ,/,
  (NP bin/NN)
  (NP median/JJ bin/NN boundaries/NNS)
  ./.) 


>> Noun Phrases are: 
 ['bin means', 'bin', 'median bin boundaries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), ('smooth', 'smooth'), ('bin', 'bin'), ('means', 'mean'), (',', ','), ('bin', 'bin'), ('median', 'median'), ('bin', 'bin'), ('boundaries', 'boundari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), ('smooth', 'smooth'), ('bin', 'bin'), ('means', 'mean'), (',', ','), ('bin', 'bin'), ('median', 'median'), ('bin', 'bin'), ('boundaries', 'boundari'), ('.', '.')]

>> Lemmatization: 
 [('Then', 'Then'), ('smooth', 'smooth'), ('bin', 'bin'), ('means', 'mean'), (',', ','), ('bin', 'bin'), ('median', 'median'), ('bin', 'bin'), ('boundaries', 'boundary'), ('.', '.')]



============================ Sentence 82 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Binning method - Example Given data: 4, 8, 9, 15, 21, 21, 24, 25, 26, 28, 29, 34 Step: 1 Partition into equal-depth [n=4]: Bin 1: 4, 8, 9, 15 Bin 2: 21, 21, 24, 25 Bin 3: 26, 28, 29, 34 Step: 2  Smoothing by bin means: 	Bin 1: 9, 9, 9, 9 	Bin 2: 23, 23, 23, 23 	Bin 3: 29, 29, 29, 29 (4 + 8 + 9 + 15)/4 = 9 (21 + 21 + 24 + 25)/4 =  23 (26 + 28 + 29 + 34)/4 =  29        	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Binning method - Example (Cont..) Given data: 4, 8, 9, 15, 21, 21, 24, 25, 26, 28, 29, 34 Step: 1 Partition into equal-depth [n=4]: Bin 1: 4, 8, 9, 15 Bin 2: 21, 21, 24, 25 Bin 3: 26, 28, 29, 34 Step: 2  Smoothing by bin boundaries: 	Bin 1: 4, 4, 4, 15 	Bin 2: 21, 21, 25, 25 	Bin 3: 26, 26, 26, 34      	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Binning method (Cont..) Binning method is a top-down splitting technique based on a specified number of bins. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Binning', 'method', '-', 'Example', 'Given', 'data', ':', '4', ',', '8', ',', '9', ',', '15', ',', '21', ',', '21', ',', '24', ',', '25', ',', '26', ',', '28', ',', '29', ',', '34', 'Step', ':', '1', 'Partition', 'equal-depth', '[', 'n=4', ']', ':', 'Bin', '1', ':', '4', ',', '8', ',', '9', ',', '15', 'Bin', '2', ':', '21', ',', '21', ',', '24', ',', '25', 'Bin', '3', ':', '26', ',', '28', ',', '29', ',', '34', 'Step', ':', '2', 'Smoothing', 'bin', 'means', ':', 'Bin', '1', ':', '9', ',', '9', ',', '9', ',', '9', 'Bin', '2', ':', '23', ',', '23', ',', '23', ',', '23', 'Bin', '3', ':', '29', ',', '29', ',', '29', ',', '29', '(', '4', '+', '8', '+', '9', '+', '15', ')', '/4', '=', '9', '(', '21', '+', '21', '+', '24', '+', '25', ')', '/4', '=', '23', '(', '26', '+', '28', '+', '29', '+', '34', ')', '/4', '=', '29', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Binning', 'method', '-', 'Example', '(', 'Cont', '..', ')', 'Given', 'data', ':', '4', ',', '8', ',', '9', ',', '15', ',', '21', ',', '21', ',', '24', ',', '25', ',', '26', ',', '28', ',', '29', ',', '34', 'Step', ':', '1', 'Partition', 'equal-depth', '[', 'n=4', ']', ':', 'Bin', '1', ':', '4', ',', '8', ',', '9', ',', '15', 'Bin', '2', ':', '21', ',', '21', ',', '24', ',', '25', 'Bin', '3', ':', '26', ',', '28', ',', '29', ',', '34', 'Step', ':', '2', 'Smoothing', 'bin', 'boundaries', ':', 'Bin', '1', ':', '4', ',', '4', ',', '4', ',', '15', 'Bin', '2', ':', '21', ',', '21', ',', '25', ',', '25', 'Bin', '3', ':', '26', ',', '26', ',', '26', ',', '34', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Binning', 'method', '(', 'Cont', '..', ')', 'Binning', 'method', 'top-down', 'splitting', 'technique', 'based', 'specified', 'number', 'bins', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Binning'), ('Binning', 'method'), ('method', '-'), ('-', 'Example'), ('Example', 'Given'), ('Given', 'data'), ('data', ':'), (':', '4'), ('4', ','), (',', '8'), ('8', ','), (',', '9'), ('9', ','), (',', '15'), ('15', ','), (',', '21'), ('21', ','), (',', '21'), ('21', ','), (',', '24'), ('24', ','), (',', '25'), ('25', ','), (',', '26'), ('26', ','), (',', '28'), ('28', ','), (',', '29'), ('29', ','), (',', '34'), ('34', 'Step'), ('Step', ':'), (':', '1'), ('1', 'Partition'), ('Partition', 'equal-depth'), ('equal-depth', '['), ('[', 'n=4'), ('n=4', ']'), (']', ':'), (':', 'Bin'), ('Bin', '1'), ('1', ':'), (':', '4'), ('4', ','), (',', '8'), ('8', ','), (',', '9'), ('9', ','), (',', '15'), ('15', 'Bin'), ('Bin', '2'), ('2', ':'), (':', '21'), ('21', ','), (',', '21'), ('21', ','), (',', '24'), ('24', ','), (',', '25'), ('25', 'Bin'), ('Bin', '3'), ('3', ':'), (':', '26'), ('26', ','), (',', '28'), ('28', ','), (',', '29'), ('29', ','), (',', '34'), ('34', 'Step'), ('Step', ':'), (':', '2'), ('2', 'Smoothing'), ('Smoothing', 'bin'), ('bin', 'means'), ('means', ':'), (':', 'Bin'), ('Bin', '1'), ('1', ':'), (':', '9'), ('9', ','), (',', '9'), ('9', ','), (',', '9'), ('9', ','), (',', '9'), ('9', 'Bin'), ('Bin', '2'), ('2', ':'), (':', '23'), ('23', ','), (',', '23'), ('23', ','), (',', '23'), ('23', ','), (',', '23'), ('23', 'Bin'), ('Bin', '3'), ('3', ':'), (':', '29'), ('29', ','), (',', '29'), ('29', ','), (',', '29'), ('29', ','), (',', '29'), ('29', '('), ('(', '4'), ('4', '+'), ('+', '8'), ('8', '+'), ('+', '9'), ('9', '+'), ('+', '15'), ('15', ')'), (')', '/4'), ('/4', '='), ('=', '9'), ('9', '('), ('(', '21'), ('21', '+'), ('+', '21'), ('21', '+'), ('+', '24'), ('24', '+'), ('+', '25'), ('25', ')'), (')', '/4'), ('/4', '='), ('=', '23'), ('23', '('), ('(', '26'), ('26', '+'), ('+', '28'), ('28', '+'), ('+', '29'), ('29', '+'), ('+', '34'), ('34', ')'), (')', '/4'), ('/4', '='), ('=', '29'), ('29', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Binning'), ('Binning', 'method'), ('method', '-'), ('-', 'Example'), ('Example', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Given'), ('Given', 'data'), ('data', ':'), (':', '4'), ('4', ','), (',', '8'), ('8', ','), (',', '9'), ('9', ','), (',', '15'), ('15', ','), (',', '21'), ('21', ','), (',', '21'), ('21', ','), (',', '24'), ('24', ','), (',', '25'), ('25', ','), (',', '26'), ('26', ','), (',', '28'), ('28', ','), (',', '29'), ('29', ','), (',', '34'), ('34', 'Step'), ('Step', ':'), (':', '1'), ('1', 'Partition'), ('Partition', 'equal-depth'), ('equal-depth', '['), ('[', 'n=4'), ('n=4', ']'), (']', ':'), (':', 'Bin'), ('Bin', '1'), ('1', ':'), (':', '4'), ('4', ','), (',', '8'), ('8', ','), (',', '9'), ('9', ','), (',', '15'), ('15', 'Bin'), ('Bin', '2'), ('2', ':'), (':', '21'), ('21', ','), (',', '21'), ('21', ','), (',', '24'), ('24', ','), (',', '25'), ('25', 'Bin'), ('Bin', '3'), ('3', ':'), (':', '26'), ('26', ','), (',', '28'), ('28', ','), (',', '29'), ('29', ','), (',', '34'), ('34', 'Step'), ('Step', ':'), (':', '2'), ('2', 'Smoothing'), ('Smoothing', 'bin'), ('bin', 'boundaries'), ('boundaries', ':'), (':', 'Bin'), ('Bin', '1'), ('1', ':'), (':', '4'), ('4', ','), (',', '4'), ('4', ','), (',', '4'), ('4', ','), (',', '15'), ('15', 'Bin'), ('Bin', '2'), ('2', ':'), (':', '21'), ('21', ','), (',', '21'), ('21', ','), (',', '25'), ('25', ','), (',', '25'), ('25', 'Bin'), ('Bin', '3'), ('3', ':'), (':', '26'), ('26', ','), (',', '26'), ('26', ','), (',', '26'), ('26', ','), (',', '34'), ('34', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Binning'), ('Binning', 'method'), ('method', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Binning'), ('Binning', 'method'), ('method', 'top-down'), ('top-down', 'splitting'), ('splitting', 'technique'), ('technique', 'based'), ('based', 'specified'), ('specified', 'number'), ('number', 'bins'), ('bins', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Binning'), ('›', 'Binning', 'method'), ('Binning', 'method', '-'), ('method', '-', 'Example'), ('-', 'Example', 'Given'), ('Example', 'Given', 'data'), ('Given', 'data', ':'), ('data', ':', '4'), (':', '4', ','), ('4', ',', '8'), (',', '8', ','), ('8', ',', '9'), (',', '9', ','), ('9', ',', '15'), (',', '15', ','), ('15', ',', '21'), (',', '21', ','), ('21', ',', '21'), (',', '21', ','), ('21', ',', '24'), (',', '24', ','), ('24', ',', '25'), (',', '25', ','), ('25', ',', '26'), (',', '26', ','), ('26', ',', '28'), (',', '28', ','), ('28', ',', '29'), (',', '29', ','), ('29', ',', '34'), (',', '34', 'Step'), ('34', 'Step', ':'), ('Step', ':', '1'), (':', '1', 'Partition'), ('1', 'Partition', 'equal-depth'), ('Partition', 'equal-depth', '['), ('equal-depth', '[', 'n=4'), ('[', 'n=4', ']'), ('n=4', ']', ':'), (']', ':', 'Bin'), (':', 'Bin', '1'), ('Bin', '1', ':'), ('1', ':', '4'), (':', '4', ','), ('4', ',', '8'), (',', '8', ','), ('8', ',', '9'), (',', '9', ','), ('9', ',', '15'), (',', '15', 'Bin'), ('15', 'Bin', '2'), ('Bin', '2', ':'), ('2', ':', '21'), (':', '21', ','), ('21', ',', '21'), (',', '21', ','), ('21', ',', '24'), (',', '24', ','), ('24', ',', '25'), (',', '25', 'Bin'), ('25', 'Bin', '3'), ('Bin', '3', ':'), ('3', ':', '26'), (':', '26', ','), ('26', ',', '28'), (',', '28', ','), ('28', ',', '29'), (',', '29', ','), ('29', ',', '34'), (',', '34', 'Step'), ('34', 'Step', ':'), ('Step', ':', '2'), (':', '2', 'Smoothing'), ('2', 'Smoothing', 'bin'), ('Smoothing', 'bin', 'means'), ('bin', 'means', ':'), ('means', ':', 'Bin'), (':', 'Bin', '1'), ('Bin', '1', ':'), ('1', ':', '9'), (':', '9', ','), ('9', ',', '9'), (',', '9', ','), ('9', ',', '9'), (',', '9', ','), ('9', ',', '9'), (',', '9', 'Bin'), ('9', 'Bin', '2'), ('Bin', '2', ':'), ('2', ':', '23'), (':', '23', ','), ('23', ',', '23'), (',', '23', ','), ('23', ',', '23'), (',', '23', ','), ('23', ',', '23'), (',', '23', 'Bin'), ('23', 'Bin', '3'), ('Bin', '3', ':'), ('3', ':', '29'), (':', '29', ','), ('29', ',', '29'), (',', '29', ','), ('29', ',', '29'), (',', '29', ','), ('29', ',', '29'), (',', '29', '('), ('29', '(', '4'), ('(', '4', '+'), ('4', '+', '8'), ('+', '8', '+'), ('8', '+', '9'), ('+', '9', '+'), ('9', '+', '15'), ('+', '15', ')'), ('15', ')', '/4'), (')', '/4', '='), ('/4', '=', '9'), ('=', '9', '('), ('9', '(', '21'), ('(', '21', '+'), ('21', '+', '21'), ('+', '21', '+'), ('21', '+', '24'), ('+', '24', '+'), ('24', '+', '25'), ('+', '25', ')'), ('25', ')', '/4'), (')', '/4', '='), ('/4', '=', '23'), ('=', '23', '('), ('23', '(', '26'), ('(', '26', '+'), ('26', '+', '28'), ('+', '28', '+'), ('28', '+', '29'), ('+', '29', '+'), ('29', '+', '34'), ('+', '34', ')'), ('34', ')', '/4'), (')', '/4', '='), ('/4', '=', '29'), ('=', '29', 'Unit'), ('29', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Binning'), ('›', 'Binning', 'method'), ('Binning', 'method', '-'), ('method', '-', 'Example'), ('-', 'Example', '('), ('Example', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Given'), (')', 'Given', 'data'), ('Given', 'data', ':'), ('data', ':', '4'), (':', '4', ','), ('4', ',', '8'), (',', '8', ','), ('8', ',', '9'), (',', '9', ','), ('9', ',', '15'), (',', '15', ','), ('15', ',', '21'), (',', '21', ','), ('21', ',', '21'), (',', '21', ','), ('21', ',', '24'), (',', '24', ','), ('24', ',', '25'), (',', '25', ','), ('25', ',', '26'), (',', '26', ','), ('26', ',', '28'), (',', '28', ','), ('28', ',', '29'), (',', '29', ','), ('29', ',', '34'), (',', '34', 'Step'), ('34', 'Step', ':'), ('Step', ':', '1'), (':', '1', 'Partition'), ('1', 'Partition', 'equal-depth'), ('Partition', 'equal-depth', '['), ('equal-depth', '[', 'n=4'), ('[', 'n=4', ']'), ('n=4', ']', ':'), (']', ':', 'Bin'), (':', 'Bin', '1'), ('Bin', '1', ':'), ('1', ':', '4'), (':', '4', ','), ('4', ',', '8'), (',', '8', ','), ('8', ',', '9'), (',', '9', ','), ('9', ',', '15'), (',', '15', 'Bin'), ('15', 'Bin', '2'), ('Bin', '2', ':'), ('2', ':', '21'), (':', '21', ','), ('21', ',', '21'), (',', '21', ','), ('21', ',', '24'), (',', '24', ','), ('24', ',', '25'), (',', '25', 'Bin'), ('25', 'Bin', '3'), ('Bin', '3', ':'), ('3', ':', '26'), (':', '26', ','), ('26', ',', '28'), (',', '28', ','), ('28', ',', '29'), (',', '29', ','), ('29', ',', '34'), (',', '34', 'Step'), ('34', 'Step', ':'), ('Step', ':', '2'), (':', '2', 'Smoothing'), ('2', 'Smoothing', 'bin'), ('Smoothing', 'bin', 'boundaries'), ('bin', 'boundaries', ':'), ('boundaries', ':', 'Bin'), (':', 'Bin', '1'), ('Bin', '1', ':'), ('1', ':', '4'), (':', '4', ','), ('4', ',', '4'), (',', '4', ','), ('4', ',', '4'), (',', '4', ','), ('4', ',', '15'), (',', '15', 'Bin'), ('15', 'Bin', '2'), ('Bin', '2', ':'), ('2', ':', '21'), (':', '21', ','), ('21', ',', '21'), (',', '21', ','), ('21', ',', '25'), (',', '25', ','), ('25', ',', '25'), (',', '25', 'Bin'), ('25', 'Bin', '3'), ('Bin', '3', ':'), ('3', ':', '26'), (':', '26', ','), ('26', ',', '26'), (',', '26', ','), ('26', ',', '26'), (',', '26', ','), ('26', ',', '34'), (',', '34', 'Unit'), ('34', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Binning'), (')', 'Binning', 'method'), ('Binning', 'method', '('), ('method', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Binning'), (')', 'Binning', 'method'), ('Binning', 'method', 'top-down'), ('method', 'top-down', 'splitting'), ('top-down', 'splitting', 'technique'), ('splitting', 'technique', 'based'), ('technique', 'based', 'specified'), ('based', 'specified', 'number'), ('specified', 'number', 'bins'), ('number', 'bins', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Binning', 'NNP'), ('method', 'SYM'), ('-', ':'), ('Example', 'JJ'), ('Given', 'NNP'), ('data', 'NNS'), (':', ':'), ('4', 'CD'), (',', ','), ('8', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('24', 'CD'), (',', ','), ('25', 'CD'), (',', ','), ('26', 'CD'), (',', ','), ('28', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('34', 'CD'), ('Step', 'NN'), (':', ':'), ('1', 'CD'), ('Partition', 'NNP'), ('equal-depth', 'JJ'), ('[', 'NNP'), ('n=4', 'NN'), (']', 'NN'), (':', ':'), ('Bin', 'JJ'), ('1', 'CD'), (':', ':'), ('4', 'CD'), (',', ','), ('8', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('15', 'CD'), ('Bin', 'NNP'), ('2', 'CD'), (':', ':'), ('21', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('24', 'CD'), (',', ','), ('25', 'CD'), ('Bin', 'NNP'), ('3', 'CD'), (':', ':'), ('26', 'CD'), (',', ','), ('28', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('34', 'CD'), ('Step', 'NN'), (':', ':'), ('2', 'CD'), ('Smoothing', 'VBG'), ('bin', 'NN'), ('means', 'NNS'), (':', ':'), ('Bin', 'NNP'), ('1', 'CD'), (':', ':'), ('9', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('9', 'CD'), ('Bin', 'NNP'), ('2', 'CD'), (':', ':'), ('23', 'CD'), (',', ','), ('23', 'CD'), (',', ','), ('23', 'CD'), (',', ','), ('23', 'CD'), ('Bin', 'NNP'), ('3', 'CD'), (':', ':'), ('29', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('29', 'CD'), ('(', '('), ('4', 'CD'), ('+', 'RB'), ('8', 'CD'), ('+', 'JJ'), ('9', 'CD'), ('+', '$'), ('15', 'CD'), (')', ')'), ('/4', 'NN'), ('=', '$'), ('9', 'CD'), ('(', '('), ('21', 'CD'), ('+', 'RB'), ('21', 'CD'), ('+', 'JJ'), ('24', 'CD'), ('+', '$'), ('25', 'CD'), (')', ')'), ('/4', 'NN'), ('=', '$'), ('23', 'CD'), ('(', '('), ('26', 'CD'), ('+', 'RB'), ('28', 'CD'), ('+', 'JJ'), ('29', 'CD'), ('+', '$'), ('34', 'CD'), (')', ')'), ('/4', 'NN'), ('=', '$'), ('29', 'CD'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Binning', 'NNP'), ('method', 'SYM'), ('-', ':'), ('Example', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Given', 'NNP'), ('data', 'NNS'), (':', ':'), ('4', 'CD'), (',', ','), ('8', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('15', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('24', 'CD'), (',', ','), ('25', 'CD'), (',', ','), ('26', 'CD'), (',', ','), ('28', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('34', 'CD'), ('Step', 'NN'), (':', ':'), ('1', 'CD'), ('Partition', 'NNP'), ('equal-depth', 'JJ'), ('[', 'NNP'), ('n=4', 'NN'), (']', 'NN'), (':', ':'), ('Bin', 'JJ'), ('1', 'CD'), (':', ':'), ('4', 'CD'), (',', ','), ('8', 'CD'), (',', ','), ('9', 'CD'), (',', ','), ('15', 'CD'), ('Bin', 'NNP'), ('2', 'CD'), (':', ':'), ('21', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('24', 'CD'), (',', ','), ('25', 'CD'), ('Bin', 'NNP'), ('3', 'CD'), (':', ':'), ('26', 'CD'), (',', ','), ('28', 'CD'), (',', ','), ('29', 'CD'), (',', ','), ('34', 'CD'), ('Step', 'NN'), (':', ':'), ('2', 'CD'), ('Smoothing', 'VBG'), ('bin', 'NN'), ('boundaries', 'NNS'), (':', ':'), ('Bin', 'NNP'), ('1', 'CD'), (':', ':'), ('4', 'CD'), (',', ','), ('4', 'CD'), (',', ','), ('4', 'CD'), (',', ','), ('15', 'CD'), ('Bin', 'NNP'), ('2', 'CD'), (':', ':'), ('21', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('25', 'CD'), (',', ','), ('25', 'CD'), ('Bin', 'NNP'), ('3', 'CD'), (':', ':'), ('26', 'CD'), (',', ','), ('26', 'CD'), (',', ','), ('26', 'CD'), (',', ','), ('34', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Binning', 'NNP'), ('method', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Binning', 'NNP'), ('method', 'JJ'), ('top-down', 'JJ'), ('splitting', 'NN'), ('technique', 'NN'), ('based', 'VBN'), ('specified', 'JJ'), ('number', 'NN'), ('bins', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Binning/NNP)
  method/SYM
  -/:
  (NP Example/JJ Given/NNP data/NNS)
  :/:
  4/CD
  ,/,
  8/CD
  ,/,
  9/CD
  ,/,
  15/CD
  ,/,
  21/CD
  ,/,
  21/CD
  ,/,
  24/CD
  ,/,
  25/CD
  ,/,
  26/CD
  ,/,
  28/CD
  ,/,
  29/CD
  ,/,
  34/CD
  (NP Step/NN)
  :/:
  1/CD
  (NP Partition/NNP)
  (NP equal-depth/JJ [/NNP n=4/NN ]/NN)
  :/:
  Bin/JJ
  1/CD
  :/:
  4/CD
  ,/,
  8/CD
  ,/,
  9/CD
  ,/,
  15/CD
  (NP Bin/NNP)
  2/CD
  :/:
  21/CD
  ,/,
  21/CD
  ,/,
  24/CD
  ,/,
  25/CD
  (NP Bin/NNP)
  3/CD
  :/:
  26/CD
  ,/,
  28/CD
  ,/,
  29/CD
  ,/,
  34/CD
  (NP Step/NN)
  :/:
  2/CD
  Smoothing/VBG
  (NP bin/NN means/NNS)
  :/:
  (NP Bin/NNP)
  1/CD
  :/:
  9/CD
  ,/,
  9/CD
  ,/,
  9/CD
  ,/,
  9/CD
  (NP Bin/NNP)
  2/CD
  :/:
  23/CD
  ,/,
  23/CD
  ,/,
  23/CD
  ,/,
  23/CD
  (NP Bin/NNP)
  3/CD
  :/:
  29/CD
  ,/,
  29/CD
  ,/,
  29/CD
  ,/,
  29/CD
  (/(
  4/CD
  +/RB
  8/CD
  +/JJ
  9/CD
  +/$
  15/CD
  )/)
  (NP /4/NN)
  =/$
  9/CD
  (/(
  21/CD
  +/RB
  21/CD
  +/JJ
  24/CD
  +/$
  25/CD
  )/)
  (NP /4/NN)
  =/$
  23/CD
  (/(
  26/CD
  +/RB
  28/CD
  +/JJ
  29/CD
  +/$
  34/CD
  )/)
  (NP /4/NN)
  =/$
  29/CD
  (NP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Binning/NNP)
  method/SYM
  -/:
  (NP Example/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Given/NNP data/NNS)
  :/:
  4/CD
  ,/,
  8/CD
  ,/,
  9/CD
  ,/,
  15/CD
  ,/,
  21/CD
  ,/,
  21/CD
  ,/,
  24/CD
  ,/,
  25/CD
  ,/,
  26/CD
  ,/,
  28/CD
  ,/,
  29/CD
  ,/,
  34/CD
  (NP Step/NN)
  :/:
  1/CD
  (NP Partition/NNP)
  (NP equal-depth/JJ [/NNP n=4/NN ]/NN)
  :/:
  Bin/JJ
  1/CD
  :/:
  4/CD
  ,/,
  8/CD
  ,/,
  9/CD
  ,/,
  15/CD
  (NP Bin/NNP)
  2/CD
  :/:
  21/CD
  ,/,
  21/CD
  ,/,
  24/CD
  ,/,
  25/CD
  (NP Bin/NNP)
  3/CD
  :/:
  26/CD
  ,/,
  28/CD
  ,/,
  29/CD
  ,/,
  34/CD
  (NP Step/NN)
  :/:
  2/CD
  Smoothing/VBG
  (NP bin/NN boundaries/NNS)
  :/:
  (NP Bin/NNP)
  1/CD
  :/:
  4/CD
  ,/,
  4/CD
  ,/,
  4/CD
  ,/,
  15/CD
  (NP Bin/NNP)
  2/CD
  :/:
  21/CD
  ,/,
  21/CD
  ,/,
  25/CD
  ,/,
  25/CD
  (NP Bin/NNP)
  3/CD
  :/:
  26/CD
  ,/,
  26/CD
  ,/,
  26/CD
  ,/,
  34/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Binning/NNP method/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Binning/NNP)
  (NP method/JJ top-down/JJ splitting/NN technique/NN)
  based/VBN
  (NP specified/JJ number/NN bins/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Binning', 'Example Given data', 'Step', 'Partition', 'equal-depth [ n=4 ]', 'Bin', 'Bin', 'Step', 'bin means', 'Bin', 'Bin', 'Bin', '/4', '/4', '/4', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Binning', 'Example', 'Cont ..', 'Given data', 'Step', 'Partition', 'equal-depth [ n=4 ]', 'Bin', 'Bin', 'Step', 'bin boundaries', 'Bin', 'Bin', 'Bin', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Binning method', 'Cont ..', 'Binning', 'method top-down splitting technique', 'specified number bins']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Example Given'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('GPE', 'Example'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('-', '-'), ('Example', 'exampl'), ('Given', 'given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('1', '1'), ('Partition', 'partit'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('2', '2'), ('Smoothing', 'smooth'), ('bin', 'bin'), ('means', 'mean'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), ('(', '('), ('4', '4'), ('+', '+'), ('8', '8'), ('+', '+'), ('9', '9'), ('+', '+'), ('15', '15'), (')', ')'), ('/4', '/4'), ('=', '='), ('9', '9'), ('(', '('), ('21', '21'), ('+', '+'), ('21', '21'), ('+', '+'), ('24', '24'), ('+', '+'), ('25', '25'), (')', ')'), ('/4', '/4'), ('=', '='), ('23', '23'), ('(', '('), ('26', '26'), ('+', '+'), ('28', '28'), ('+', '+'), ('29', '29'), ('+', '+'), ('34', '34'), (')', ')'), ('/4', '/4'), ('=', '='), ('29', '29'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('-', '-'), ('Example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Given', 'given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('1', '1'), ('Partition', 'partit'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('2', '2'), ('Smoothing', 'smooth'), ('bin', 'bin'), ('boundaries', 'boundari'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('25', '25'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('34', '34'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('top-down', 'top-down'), ('splitting', 'split'), ('technique', 'techniqu'), ('based', 'base'), ('specified', 'specifi'), ('number', 'number'), ('bins', 'bin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('-', '-'), ('Example', 'exampl'), ('Given', 'given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('1', '1'), ('Partition', 'partit'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('2', '2'), ('Smoothing', 'smooth'), ('bin', 'bin'), ('means', 'mean'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), ('(', '('), ('4', '4'), ('+', '+'), ('8', '8'), ('+', '+'), ('9', '9'), ('+', '+'), ('15', '15'), (')', ')'), ('/4', '/4'), ('=', '='), ('9', '9'), ('(', '('), ('21', '21'), ('+', '+'), ('21', '21'), ('+', '+'), ('24', '24'), ('+', '+'), ('25', '25'), (')', ')'), ('/4', '/4'), ('=', '='), ('23', '23'), ('(', '('), ('26', '26'), ('+', '+'), ('28', '28'), ('+', '+'), ('29', '29'), ('+', '+'), ('34', '34'), (')', ')'), ('/4', '/4'), ('=', '='), ('29', '29'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('-', '-'), ('Example', 'exampl'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Given', 'given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('1', '1'), ('Partition', 'partit'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'step'), (':', ':'), ('2', '2'), ('Smoothing', 'smooth'), ('bin', 'bin'), ('boundaries', 'boundari'), (':', ':'), ('Bin', 'bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('15', '15'), ('Bin', 'bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('25', '25'), (',', ','), ('25', '25'), ('Bin', 'bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('34', '34'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Binning', 'bin'), ('method', 'method'), ('top-down', 'top-down'), ('splitting', 'split'), ('technique', 'techniqu'), ('based', 'base'), ('specified', 'specifi'), ('number', 'number'), ('bins', 'bin'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'Binning'), ('method', 'method'), ('-', '-'), ('Example', 'Example'), ('Given', 'Given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'Step'), (':', ':'), ('1', '1'), ('Partition', 'Partition'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'Bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'Bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'Bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'Step'), (':', ':'), ('2', '2'), ('Smoothing', 'Smoothing'), ('bin', 'bin'), ('means', 'mean'), (':', ':'), ('Bin', 'Bin'), ('1', '1'), (':', ':'), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), (',', ','), ('9', '9'), ('Bin', 'Bin'), ('2', '2'), (':', ':'), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), (',', ','), ('23', '23'), ('Bin', 'Bin'), ('3', '3'), (':', ':'), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), (',', ','), ('29', '29'), ('(', '('), ('4', '4'), ('+', '+'), ('8', '8'), ('+', '+'), ('9', '9'), ('+', '+'), ('15', '15'), (')', ')'), ('/4', '/4'), ('=', '='), ('9', '9'), ('(', '('), ('21', '21'), ('+', '+'), ('21', '21'), ('+', '+'), ('24', '24'), ('+', '+'), ('25', '25'), (')', ')'), ('/4', '/4'), ('=', '='), ('23', '23'), ('(', '('), ('26', '26'), ('+', '+'), ('28', '28'), ('+', '+'), ('29', '29'), ('+', '+'), ('34', '34'), (')', ')'), ('/4', '/4'), ('=', '='), ('29', '29'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'Binning'), ('method', 'method'), ('-', '-'), ('Example', 'Example'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Given', 'Given'), ('data', 'data'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), (',', ','), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), (',', ','), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'Step'), (':', ':'), ('1', '1'), ('Partition', 'Partition'), ('equal-depth', 'equal-depth'), ('[', '['), ('n=4', 'n=4'), (']', ']'), (':', ':'), ('Bin', 'Bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('8', '8'), (',', ','), ('9', '9'), (',', ','), ('15', '15'), ('Bin', 'Bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('24', '24'), (',', ','), ('25', '25'), ('Bin', 'Bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('28', '28'), (',', ','), ('29', '29'), (',', ','), ('34', '34'), ('Step', 'Step'), (':', ':'), ('2', '2'), ('Smoothing', 'Smoothing'), ('bin', 'bin'), ('boundaries', 'boundary'), (':', ':'), ('Bin', 'Bin'), ('1', '1'), (':', ':'), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('4', '4'), (',', ','), ('15', '15'), ('Bin', 'Bin'), ('2', '2'), (':', ':'), ('21', '21'), (',', ','), ('21', '21'), (',', ','), ('25', '25'), (',', ','), ('25', '25'), ('Bin', 'Bin'), ('3', '3'), (':', ':'), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('26', '26'), (',', ','), ('34', '34'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Binning', 'Binning'), ('method', 'method'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Binning', 'Binning'), ('method', 'method'), ('top-down', 'top-down'), ('splitting', 'splitting'), ('technique', 'technique'), ('based', 'based'), ('specified', 'specified'), ('number', 'number'), ('bins', 'bin'), ('.', '.')]



============================ Sentence 83 =============================

It is also used as discretization method for data reduction and concept hierarchy generation. 


>> Tokens are: 
 ['It', 'also', 'used', 'discretization', 'method', 'data', 'reduction', 'concept', 'hierarchy', 'generation', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'used'), ('used', 'discretization'), ('discretization', 'method'), ('method', 'data'), ('data', 'reduction'), ('reduction', 'concept'), ('concept', 'hierarchy'), ('hierarchy', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('It', 'also', 'used'), ('also', 'used', 'discretization'), ('used', 'discretization', 'method'), ('discretization', 'method', 'data'), ('method', 'data', 'reduction'), ('data', 'reduction', 'concept'), ('reduction', 'concept', 'hierarchy'), ('concept', 'hierarchy', 'generation'), ('hierarchy', 'generation', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('used', 'VBD'), ('discretization', 'NN'), ('method', 'NN'), ('data', 'NNS'), ('reduction', 'NN'), ('concept', 'NN'), ('hierarchy', 'NN'), ('generation', 'NN'), ('.', '.')]

 (S
  It/PRP
  also/RB
  used/VBD
  (NP
    discretization/NN
    method/NN
    data/NNS
    reduction/NN
    concept/NN
    hierarchy/NN
    generation/NN)
  ./.) 


>> Noun Phrases are: 
 ['discretization method data reduction concept hierarchy generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('used', 'use'), ('discretization', 'discret'), ('method', 'method'), ('data', 'data'), ('reduction', 'reduct'), ('concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('used', 'use'), ('discretization', 'discret'), ('method', 'method'), ('data', 'data'), ('reduction', 'reduct'), ('concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('used', 'used'), ('discretization', 'discretization'), ('method', 'method'), ('data', 'data'), ('reduction', 'reduction'), ('concept', 'concept'), ('hierarchy', 'hierarchy'), ('generation', 'generation'), ('.', '.')]



============================ Sentence 84 =============================

For example, attribute values can be discretized (separated) by applying equal-width or equal-frequency binning, and then replacing each value by the bin mean or median. 


>> Tokens are: 
 ['For', 'example', ',', 'attribute', 'values', 'discretized', '(', 'separated', ')', 'applying', 'equal-width', 'equal-frequency', 'binning', ',', 'replacing', 'value', 'bin', 'mean', 'median', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'attribute'), ('attribute', 'values'), ('values', 'discretized'), ('discretized', '('), ('(', 'separated'), ('separated', ')'), (')', 'applying'), ('applying', 'equal-width'), ('equal-width', 'equal-frequency'), ('equal-frequency', 'binning'), ('binning', ','), (',', 'replacing'), ('replacing', 'value'), ('value', 'bin'), ('bin', 'mean'), ('mean', 'median'), ('median', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'attribute'), (',', 'attribute', 'values'), ('attribute', 'values', 'discretized'), ('values', 'discretized', '('), ('discretized', '(', 'separated'), ('(', 'separated', ')'), ('separated', ')', 'applying'), (')', 'applying', 'equal-width'), ('applying', 'equal-width', 'equal-frequency'), ('equal-width', 'equal-frequency', 'binning'), ('equal-frequency', 'binning', ','), ('binning', ',', 'replacing'), (',', 'replacing', 'value'), ('replacing', 'value', 'bin'), ('value', 'bin', 'mean'), ('bin', 'mean', 'median'), ('mean', 'median', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('attribute', 'NN'), ('values', 'NNS'), ('discretized', 'VBN'), ('(', '('), ('separated', 'VBN'), (')', ')'), ('applying', 'VBG'), ('equal-width', 'JJ'), ('equal-frequency', 'NN'), ('binning', 'NN'), (',', ','), ('replacing', 'VBG'), ('value', 'NN'), ('bin', 'NN'), ('mean', 'JJ'), ('median', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP attribute/NN values/NNS)
  discretized/VBN
  (/(
  separated/VBN
  )/)
  applying/VBG
  (NP equal-width/JJ equal-frequency/NN binning/NN)
  ,/,
  replacing/VBG
  (NP value/NN bin/NN)
  (NP mean/JJ median/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'attribute values', 'equal-width equal-frequency binning', 'value bin', 'mean median']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('attribute', 'attribut'), ('values', 'valu'), ('discretized', 'discret'), ('(', '('), ('separated', 'separ'), (')', ')'), ('applying', 'appli'), ('equal-width', 'equal-width'), ('equal-frequency', 'equal-frequ'), ('binning', 'bin'), (',', ','), ('replacing', 'replac'), ('value', 'valu'), ('bin', 'bin'), ('mean', 'mean'), ('median', 'median'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('attribute', 'attribut'), ('values', 'valu'), ('discretized', 'discret'), ('(', '('), ('separated', 'separ'), (')', ')'), ('applying', 'appli'), ('equal-width', 'equal-width'), ('equal-frequency', 'equal-frequ'), ('binning', 'bin'), (',', ','), ('replacing', 'replac'), ('value', 'valu'), ('bin', 'bin'), ('mean', 'mean'), ('median', 'median'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('attribute', 'attribute'), ('values', 'value'), ('discretized', 'discretized'), ('(', '('), ('separated', 'separated'), (')', ')'), ('applying', 'applying'), ('equal-width', 'equal-width'), ('equal-frequency', 'equal-frequency'), ('binning', 'binning'), (',', ','), ('replacing', 'replacing'), ('value', 'value'), ('bin', 'bin'), ('mean', 'mean'), ('median', 'median'), ('.', '.')]



============================ Sentence 85 =============================

It can be applied recursively to the resulting partitions to generate concept hierarchies. 


>> Tokens are: 
 ['It', 'applied', 'recursively', 'resulting', 'partitions', 'generate', 'concept', 'hierarchies', '.']

>> Bigrams are: 
 [('It', 'applied'), ('applied', 'recursively'), ('recursively', 'resulting'), ('resulting', 'partitions'), ('partitions', 'generate'), ('generate', 'concept'), ('concept', 'hierarchies'), ('hierarchies', '.')]

>> Trigrams are: 
 [('It', 'applied', 'recursively'), ('applied', 'recursively', 'resulting'), ('recursively', 'resulting', 'partitions'), ('resulting', 'partitions', 'generate'), ('partitions', 'generate', 'concept'), ('generate', 'concept', 'hierarchies'), ('concept', 'hierarchies', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('applied', 'VBD'), ('recursively', 'RB'), ('resulting', 'VBG'), ('partitions', 'NNS'), ('generate', 'VBP'), ('concept', 'NN'), ('hierarchies', 'NNS'), ('.', '.')]

 (S
  It/PRP
  applied/VBD
  recursively/RB
  resulting/VBG
  (NP partitions/NNS)
  generate/VBP
  (NP concept/NN hierarchies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['partitions', 'concept hierarchies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('applied', 'appli'), ('recursively', 'recurs'), ('resulting', 'result'), ('partitions', 'partit'), ('generate', 'gener'), ('concept', 'concept'), ('hierarchies', 'hierarchi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('applied', 'appli'), ('recursively', 'recurs'), ('resulting', 'result'), ('partitions', 'partit'), ('generate', 'generat'), ('concept', 'concept'), ('hierarchies', 'hierarchi'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('applied', 'applied'), ('recursively', 'recursively'), ('resulting', 'resulting'), ('partitions', 'partition'), ('generate', 'generate'), ('concept', 'concept'), ('hierarchies', 'hierarchy'), ('.', '.')]



============================ Sentence 86 =============================

It does not use class information, therefore it is an unsupervised discretization technique. 


>> Tokens are: 
 ['It', 'use', 'class', 'information', ',', 'therefore', 'unsupervised', 'discretization', 'technique', '.']

>> Bigrams are: 
 [('It', 'use'), ('use', 'class'), ('class', 'information'), ('information', ','), (',', 'therefore'), ('therefore', 'unsupervised'), ('unsupervised', 'discretization'), ('discretization', 'technique'), ('technique', '.')]

>> Trigrams are: 
 [('It', 'use', 'class'), ('use', 'class', 'information'), ('class', 'information', ','), ('information', ',', 'therefore'), (',', 'therefore', 'unsupervised'), ('therefore', 'unsupervised', 'discretization'), ('unsupervised', 'discretization', 'technique'), ('discretization', 'technique', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('use', 'VBP'), ('class', 'NN'), ('information', 'NN'), (',', ','), ('therefore', 'RB'), ('unsupervised', 'JJ'), ('discretization', 'NN'), ('technique', 'NN'), ('.', '.')]

 (S
  It/PRP
  use/VBP
  (NP class/NN information/NN)
  ,/,
  therefore/RB
  (NP unsupervised/JJ discretization/NN technique/NN)
  ./.) 


>> Noun Phrases are: 
 ['class information', 'unsupervised discretization technique']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('use', 'use'), ('class', 'class'), ('information', 'inform'), (',', ','), ('therefore', 'therefor'), ('unsupervised', 'unsupervis'), ('discretization', 'discret'), ('technique', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('use', 'use'), ('class', 'class'), ('information', 'inform'), (',', ','), ('therefore', 'therefor'), ('unsupervised', 'unsupervis'), ('discretization', 'discret'), ('technique', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('use', 'use'), ('class', 'class'), ('information', 'information'), (',', ','), ('therefore', 'therefore'), ('unsupervised', 'unsupervised'), ('discretization', 'discretization'), ('technique', 'technique'), ('.', '.')]



============================ Sentence 87 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Binning method (Try it!) 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Binning', 'method', '(', 'Try', '!', ')']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Binning'), ('Binning', 'method'), ('method', '('), ('(', 'Try'), ('Try', '!'), ('!', ')')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Binning'), ('›', 'Binning', 'method'), ('Binning', 'method', '('), ('method', '(', 'Try'), ('(', 'Try', '!'), ('Try', '!', ')')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Binning', 'NNP'), ('method', 'NN'), ('(', '('), ('Try', 'NNP'), ('!', '.'), (')', ')')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Binning/NNP method/NN)
  (/(
  (NP Try/NNP)
  !/.
  )/)) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Binning method', 'Try']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Try')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('(', '('), ('Try', 'tri'), ('!', '!'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'bin'), ('method', 'method'), ('(', '('), ('Try', 'tri'), ('!', '!'), (')', ')')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Binning', 'Binning'), ('method', 'method'), ('(', '('), ('Try', 'Try'), ('!', '!'), (')', ')')]



============================ Sentence 88 =============================

0,4,12,16,16,18,24,26,28    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  2) Clustering Clustering is a process of partitioning a set of data (or objects) into a set of meaningful sub-classes, called clusters. 


>> Tokens are: 
 ['0,4,12,16,16,18,24,26,28', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '2', ')', 'Clustering', 'Clustering', 'process', 'partitioning', 'set', 'data', '(', 'objects', ')', 'set', 'meaningful', 'sub-classes', ',', 'called', 'clusters', '.']

>> Bigrams are: 
 [('0,4,12,16,16,18,24,26,28', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '2'), ('2', ')'), (')', 'Clustering'), ('Clustering', 'Clustering'), ('Clustering', 'process'), ('process', 'partitioning'), ('partitioning', 'set'), ('set', 'data'), ('data', '('), ('(', 'objects'), ('objects', ')'), (')', 'set'), ('set', 'meaningful'), ('meaningful', 'sub-classes'), ('sub-classes', ','), (',', 'called'), ('called', 'clusters'), ('clusters', '.')]

>> Trigrams are: 
 [('0,4,12,16,16,18,24,26,28', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '2'), ('›', '2', ')'), ('2', ')', 'Clustering'), (')', 'Clustering', 'Clustering'), ('Clustering', 'Clustering', 'process'), ('Clustering', 'process', 'partitioning'), ('process', 'partitioning', 'set'), ('partitioning', 'set', 'data'), ('set', 'data', '('), ('data', '(', 'objects'), ('(', 'objects', ')'), ('objects', ')', 'set'), (')', 'set', 'meaningful'), ('set', 'meaningful', 'sub-classes'), ('meaningful', 'sub-classes', ','), ('sub-classes', ',', 'called'), (',', 'called', 'clusters'), ('called', 'clusters', '.')]

>> POS Tags are: 
 [('0,4,12,16,16,18,24,26,28', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('2', 'CD'), (')', ')'), ('Clustering', 'VBG'), ('Clustering', 'VBG'), ('process', 'NN'), ('partitioning', 'VBG'), ('set', 'VBN'), ('data', 'NNS'), ('(', '('), ('objects', 'NNS'), (')', ')'), ('set', 'VBP'), ('meaningful', 'JJ'), ('sub-classes', 'NNS'), (',', ','), ('called', 'VBD'), ('clusters', 'NNS'), ('.', '.')]

 (S
  0,4,12,16,16,18,24,26,28/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  2/CD
  )/)
  Clustering/VBG
  Clustering/VBG
  (NP process/NN)
  partitioning/VBG
  set/VBN
  (NP data/NNS)
  (/(
  (NP objects/NNS)
  )/)
  set/VBP
  (NP meaningful/JJ sub-classes/NNS)
  ,/,
  called/VBD
  (NP clusters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'process', 'data', 'objects', 'meaningful sub-classes', 'clusters']

>> Named Entities are: 
 [('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('0,4,12,16,16,18,24,26,28', '0,4,12,16,16,18,24,26,28'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Clustering', 'cluster'), ('Clustering', 'cluster'), ('process', 'process'), ('partitioning', 'partit'), ('set', 'set'), ('data', 'data'), ('(', '('), ('objects', 'object'), (')', ')'), ('set', 'set'), ('meaningful', 'meaning'), ('sub-classes', 'sub-class'), (',', ','), ('called', 'call'), ('clusters', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('0,4,12,16,16,18,24,26,28', '0,4,12,16,16,18,24,26,28'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Clustering', 'cluster'), ('Clustering', 'cluster'), ('process', 'process'), ('partitioning', 'partit'), ('set', 'set'), ('data', 'data'), ('(', '('), ('objects', 'object'), (')', ')'), ('set', 'set'), ('meaningful', 'meaning'), ('sub-classes', 'sub-class'), (',', ','), ('called', 'call'), ('clusters', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('0,4,12,16,16,18,24,26,28', '0,4,12,16,16,18,24,26,28'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Clustering', 'Clustering'), ('Clustering', 'Clustering'), ('process', 'process'), ('partitioning', 'partitioning'), ('set', 'set'), ('data', 'data'), ('(', '('), ('objects', 'object'), (')', ')'), ('set', 'set'), ('meaningful', 'meaningful'), ('sub-classes', 'sub-classes'), (',', ','), ('called', 'called'), ('clusters', 'cluster'), ('.', '.')]



============================ Sentence 89 =============================

It enables the abstraction of large amounts data by forming meaningful groups or categories of objects. 


>> Tokens are: 
 ['It', 'enables', 'abstraction', 'large', 'amounts', 'data', 'forming', 'meaningful', 'groups', 'categories', 'objects', '.']

>> Bigrams are: 
 [('It', 'enables'), ('enables', 'abstraction'), ('abstraction', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', 'forming'), ('forming', 'meaningful'), ('meaningful', 'groups'), ('groups', 'categories'), ('categories', 'objects'), ('objects', '.')]

>> Trigrams are: 
 [('It', 'enables', 'abstraction'), ('enables', 'abstraction', 'large'), ('abstraction', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', 'forming'), ('data', 'forming', 'meaningful'), ('forming', 'meaningful', 'groups'), ('meaningful', 'groups', 'categories'), ('groups', 'categories', 'objects'), ('categories', 'objects', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('enables', 'VBZ'), ('abstraction', 'NN'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('forming', 'VBG'), ('meaningful', 'JJ'), ('groups', 'NNS'), ('categories', 'NNS'), ('objects', 'NNS'), ('.', '.')]

 (S
  It/PRP
  enables/VBZ
  (NP abstraction/NN)
  (NP large/JJ amounts/NNS data/NNS)
  forming/VBG
  (NP meaningful/JJ groups/NNS categories/NNS objects/NNS)
  ./.) 


>> Noun Phrases are: 
 ['abstraction', 'large amounts data', 'meaningful groups categories objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('enables', 'enabl'), ('abstraction', 'abstract'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('forming', 'form'), ('meaningful', 'meaning'), ('groups', 'group'), ('categories', 'categori'), ('objects', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('enables', 'enabl'), ('abstraction', 'abstract'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('forming', 'form'), ('meaningful', 'meaning'), ('groups', 'group'), ('categories', 'categori'), ('objects', 'object'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('enables', 'enables'), ('abstraction', 'abstraction'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('forming', 'forming'), ('meaningful', 'meaningful'), ('groups', 'group'), ('categories', 'category'), ('objects', 'object'), ('.', '.')]



============================ Sentence 90 =============================

In clustering, objects in the same cluster are similar to each other and those in different clusters are dissimilar. 


>> Tokens are: 
 ['In', 'clustering', ',', 'objects', 'cluster', 'similar', 'different', 'clusters', 'dissimilar', '.']

>> Bigrams are: 
 [('In', 'clustering'), ('clustering', ','), (',', 'objects'), ('objects', 'cluster'), ('cluster', 'similar'), ('similar', 'different'), ('different', 'clusters'), ('clusters', 'dissimilar'), ('dissimilar', '.')]

>> Trigrams are: 
 [('In', 'clustering', ','), ('clustering', ',', 'objects'), (',', 'objects', 'cluster'), ('objects', 'cluster', 'similar'), ('cluster', 'similar', 'different'), ('similar', 'different', 'clusters'), ('different', 'clusters', 'dissimilar'), ('clusters', 'dissimilar', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('clustering', 'NN'), (',', ','), ('objects', 'VBZ'), ('cluster', 'JJR'), ('similar', 'JJ'), ('different', 'JJ'), ('clusters', 'NNS'), ('dissimilar', 'VBP'), ('.', '.')]

 (S
  In/IN
  (NP clustering/NN)
  ,/,
  objects/VBZ
  cluster/JJR
  (NP similar/JJ different/JJ clusters/NNS)
  dissimilar/VBP
  ./.) 


>> Noun Phrases are: 
 ['clustering', 'similar different clusters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('clustering', 'cluster'), (',', ','), ('objects', 'object'), ('cluster', 'cluster'), ('similar', 'similar'), ('different', 'differ'), ('clusters', 'cluster'), ('dissimilar', 'dissimilar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('clustering', 'cluster'), (',', ','), ('objects', 'object'), ('cluster', 'cluster'), ('similar', 'similar'), ('different', 'differ'), ('clusters', 'cluster'), ('dissimilar', 'dissimilar'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('clustering', 'clustering'), (',', ','), ('objects', 'object'), ('cluster', 'cluster'), ('similar', 'similar'), ('different', 'different'), ('clusters', 'cluster'), ('dissimilar', 'dissimilar'), ('.', '.')]



============================ Sentence 91 =============================

Example Library (Group of Books based on different categories) Cloths (By size S, M, L, XL, XXL etc.) 


>> Tokens are: 
 ['Example', 'Library', '(', 'Group', 'Books', 'based', 'different', 'categories', ')', 'Cloths', '(', 'By', 'size', 'S', ',', 'M', ',', 'L', ',', 'XL', ',', 'XXL', 'etc', '.', ')']

>> Bigrams are: 
 [('Example', 'Library'), ('Library', '('), ('(', 'Group'), ('Group', 'Books'), ('Books', 'based'), ('based', 'different'), ('different', 'categories'), ('categories', ')'), (')', 'Cloths'), ('Cloths', '('), ('(', 'By'), ('By', 'size'), ('size', 'S'), ('S', ','), (',', 'M'), ('M', ','), (',', 'L'), ('L', ','), (',', 'XL'), ('XL', ','), (',', 'XXL'), ('XXL', 'etc'), ('etc', '.'), ('.', ')')]

>> Trigrams are: 
 [('Example', 'Library', '('), ('Library', '(', 'Group'), ('(', 'Group', 'Books'), ('Group', 'Books', 'based'), ('Books', 'based', 'different'), ('based', 'different', 'categories'), ('different', 'categories', ')'), ('categories', ')', 'Cloths'), (')', 'Cloths', '('), ('Cloths', '(', 'By'), ('(', 'By', 'size'), ('By', 'size', 'S'), ('size', 'S', ','), ('S', ',', 'M'), (',', 'M', ','), ('M', ',', 'L'), (',', 'L', ','), ('L', ',', 'XL'), (',', 'XL', ','), ('XL', ',', 'XXL'), (',', 'XXL', 'etc'), ('XXL', 'etc', '.'), ('etc', '.', ')')]

>> POS Tags are: 
 [('Example', 'JJ'), ('Library', 'NNP'), ('(', '('), ('Group', 'NNP'), ('Books', 'NNP'), ('based', 'VBN'), ('different', 'JJ'), ('categories', 'NNS'), (')', ')'), ('Cloths', 'NNP'), ('(', '('), ('By', 'IN'), ('size', 'NN'), ('S', 'NNP'), (',', ','), ('M', 'NNP'), (',', ','), ('L', 'NNP'), (',', ','), ('XL', 'NNP'), (',', ','), ('XXL', 'NNP'), ('etc', 'FW'), ('.', '.'), (')', ')')]

 (S
  (NP Example/JJ Library/NNP)
  (/(
  (NP Group/NNP Books/NNP)
  based/VBN
  (NP different/JJ categories/NNS)
  )/)
  (NP Cloths/NNP)
  (/(
  By/IN
  (NP size/NN S/NNP)
  ,/,
  (NP M/NNP)
  ,/,
  (NP L/NNP)
  ,/,
  (NP XL/NNP)
  ,/,
  (NP XXL/NNP)
  etc/FW
  ./.
  )/)) 


>> Noun Phrases are: 
 ['Example Library', 'Group Books', 'different categories', 'Cloths', 'size S', 'M', 'L', 'XL', 'XXL']

>> Named Entities are: 
 [('PERSON', 'Example Library'), ('PERSON', 'Group Books'), ('GPE', 'Cloths'), ('GPE', 'L'), ('ORGANIZATION', 'XL'), ('ORGANIZATION', 'XXL')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Library', 'librari'), ('(', '('), ('Group', 'group'), ('Books', 'book'), ('based', 'base'), ('different', 'differ'), ('categories', 'categori'), (')', ')'), ('Cloths', 'cloth'), ('(', '('), ('By', 'by'), ('size', 'size'), ('S', 's'), (',', ','), ('M', 'm'), (',', ','), ('L', 'l'), (',', ','), ('XL', 'xl'), (',', ','), ('XXL', 'xxl'), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Library', 'librari'), ('(', '('), ('Group', 'group'), ('Books', 'book'), ('based', 'base'), ('different', 'differ'), ('categories', 'categori'), (')', ')'), ('Cloths', 'cloth'), ('(', '('), ('By', 'by'), ('size', 'size'), ('S', 's'), (',', ','), ('M', 'm'), (',', ','), ('L', 'l'), (',', ','), ('XL', 'xl'), (',', ','), ('XXL', 'xxl'), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('Example', 'Example'), ('Library', 'Library'), ('(', '('), ('Group', 'Group'), ('Books', 'Books'), ('based', 'based'), ('different', 'different'), ('categories', 'category'), (')', ')'), ('Cloths', 'Cloths'), ('(', '('), ('By', 'By'), ('size', 'size'), ('S', 'S'), (',', ','), ('M', 'M'), (',', ','), ('L', 'L'), (',', ','), ('XL', 'XL'), (',', ','), ('XXL', 'XXL'), ('etc', 'etc'), ('.', '.'), (')', ')')]



============================ Sentence 92 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  3) Correct inconsistent data If you have inconsistencies in your data, it can cause major problems later on. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '3', ')', 'Correct', 'inconsistent', 'data', 'If', 'inconsistencies', 'data', ',', 'cause', 'major', 'problems', 'later', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '3'), ('3', ')'), (')', 'Correct'), ('Correct', 'inconsistent'), ('inconsistent', 'data'), ('data', 'If'), ('If', 'inconsistencies'), ('inconsistencies', 'data'), ('data', ','), (',', 'cause'), ('cause', 'major'), ('major', 'problems'), ('problems', 'later'), ('later', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '3'), ('›', '3', ')'), ('3', ')', 'Correct'), (')', 'Correct', 'inconsistent'), ('Correct', 'inconsistent', 'data'), ('inconsistent', 'data', 'If'), ('data', 'If', 'inconsistencies'), ('If', 'inconsistencies', 'data'), ('inconsistencies', 'data', ','), ('data', ',', 'cause'), (',', 'cause', 'major'), ('cause', 'major', 'problems'), ('major', 'problems', 'later'), ('problems', 'later', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('3', 'CD'), (')', ')'), ('Correct', 'NNP'), ('inconsistent', 'NN'), ('data', 'NNS'), ('If', 'IN'), ('inconsistencies', 'NNS'), ('data', 'NNS'), (',', ','), ('cause', 'NN'), ('major', 'JJ'), ('problems', 'NNS'), ('later', 'RB'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  3/CD
  )/)
  (NP Correct/NNP inconsistent/NN data/NNS)
  If/IN
  (NP inconsistencies/NNS data/NNS)
  ,/,
  (NP cause/NN)
  (NP major/JJ problems/NNS)
  later/RB
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Correct inconsistent data', 'inconsistencies data', 'cause', 'major problems']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Correct', 'correct'), ('inconsistent', 'inconsist'), ('data', 'data'), ('If', 'if'), ('inconsistencies', 'inconsist'), ('data', 'data'), (',', ','), ('cause', 'caus'), ('major', 'major'), ('problems', 'problem'), ('later', 'later'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Correct', 'correct'), ('inconsistent', 'inconsist'), ('data', 'data'), ('If', 'if'), ('inconsistencies', 'inconsist'), ('data', 'data'), (',', ','), ('cause', 'caus'), ('major', 'major'), ('problems', 'problem'), ('later', 'later'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('3', '3'), (')', ')'), ('Correct', 'Correct'), ('inconsistent', 'inconsistent'), ('data', 'data'), ('If', 'If'), ('inconsistencies', 'inconsistency'), ('data', 'data'), (',', ','), ('cause', 'cause'), ('major', 'major'), ('problems', 'problem'), ('later', 'later'), ('.', '.')]



============================ Sentence 93 =============================

But with larger datasets, it can be difficult to find all of the inconsistencies. 


>> Tokens are: 
 ['But', 'larger', 'datasets', ',', 'difficult', 'find', 'inconsistencies', '.']

>> Bigrams are: 
 [('But', 'larger'), ('larger', 'datasets'), ('datasets', ','), (',', 'difficult'), ('difficult', 'find'), ('find', 'inconsistencies'), ('inconsistencies', '.')]

>> Trigrams are: 
 [('But', 'larger', 'datasets'), ('larger', 'datasets', ','), ('datasets', ',', 'difficult'), (',', 'difficult', 'find'), ('difficult', 'find', 'inconsistencies'), ('find', 'inconsistencies', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('larger', 'JJR'), ('datasets', 'NNS'), (',', ','), ('difficult', 'JJ'), ('find', 'NN'), ('inconsistencies', 'NNS'), ('.', '.')]

 (S
  But/CC
  larger/JJR
  (NP datasets/NNS)
  ,/,
  (NP difficult/JJ find/NN inconsistencies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['datasets', 'difficult find inconsistencies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('larger', 'larger'), ('datasets', 'dataset'), (',', ','), ('difficult', 'difficult'), ('find', 'find'), ('inconsistencies', 'inconsist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('larger', 'larger'), ('datasets', 'dataset'), (',', ','), ('difficult', 'difficult'), ('find', 'find'), ('inconsistencies', 'inconsist'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('larger', 'larger'), ('datasets', 'datasets'), (',', ','), ('difficult', 'difficult'), ('find', 'find'), ('inconsistencies', 'inconsistency'), ('.', '.')]



============================ Sentence 94 =============================

It contains similarity in codes or names. 


>> Tokens are: 
 ['It', 'contains', 'similarity', 'codes', 'names', '.']

>> Bigrams are: 
 [('It', 'contains'), ('contains', 'similarity'), ('similarity', 'codes'), ('codes', 'names'), ('names', '.')]

>> Trigrams are: 
 [('It', 'contains', 'similarity'), ('contains', 'similarity', 'codes'), ('similarity', 'codes', 'names'), ('codes', 'names', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('contains', 'VBZ'), ('similarity', 'NN'), ('codes', 'NNS'), ('names', 'NNS'), ('.', '.')]

 (S It/PRP contains/VBZ (NP similarity/NN codes/NNS names/NNS) ./.) 


>> Noun Phrases are: 
 ['similarity codes names']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('similarity', 'similar'), ('codes', 'code'), ('names', 'name'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('similarity', 'similar'), ('codes', 'code'), ('names', 'name'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('contains', 'contains'), ('similarity', 'similarity'), ('codes', 'code'), ('names', 'name'), ('.', '.')]



============================ Sentence 95 =============================

We can manually solve common mistakes like spelling, grammar, articles or use other tools for it. 


>> Tokens are: 
 ['We', 'manually', 'solve', 'common', 'mistakes', 'like', 'spelling', ',', 'grammar', ',', 'articles', 'use', 'tools', '.']

>> Bigrams are: 
 [('We', 'manually'), ('manually', 'solve'), ('solve', 'common'), ('common', 'mistakes'), ('mistakes', 'like'), ('like', 'spelling'), ('spelling', ','), (',', 'grammar'), ('grammar', ','), (',', 'articles'), ('articles', 'use'), ('use', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('We', 'manually', 'solve'), ('manually', 'solve', 'common'), ('solve', 'common', 'mistakes'), ('common', 'mistakes', 'like'), ('mistakes', 'like', 'spelling'), ('like', 'spelling', ','), ('spelling', ',', 'grammar'), (',', 'grammar', ','), ('grammar', ',', 'articles'), (',', 'articles', 'use'), ('articles', 'use', 'tools'), ('use', 'tools', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('manually', 'RB'), ('solve', 'VBP'), ('common', 'JJ'), ('mistakes', 'NNS'), ('like', 'IN'), ('spelling', 'VBG'), (',', ','), ('grammar', 'NN'), (',', ','), ('articles', 'NNS'), ('use', 'VBP'), ('tools', 'NNS'), ('.', '.')]

 (S
  We/PRP
  manually/RB
  solve/VBP
  (NP common/JJ mistakes/NNS)
  like/IN
  spelling/VBG
  ,/,
  (NP grammar/NN)
  ,/,
  (NP articles/NNS)
  use/VBP
  (NP tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['common mistakes', 'grammar', 'articles', 'tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('manually', 'manual'), ('solve', 'solv'), ('common', 'common'), ('mistakes', 'mistak'), ('like', 'like'), ('spelling', 'spell'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'articl'), ('use', 'use'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('manually', 'manual'), ('solve', 'solv'), ('common', 'common'), ('mistakes', 'mistak'), ('like', 'like'), ('spelling', 'spell'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'articl'), ('use', 'use'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('manually', 'manually'), ('solve', 'solve'), ('common', 'common'), ('mistakes', 'mistake'), ('like', 'like'), ('spelling', 'spelling'), (',', ','), ('grammar', 'grammar'), (',', ','), ('articles', 'article'), ('use', 'use'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 96 =============================

Data Cleaning   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  4) Resolve redundancy caused by data integration Data redundancy occurs in database systems which have a field that is repeated in two or more tables. 


>> Tokens are: 
 ['Data', 'Cleaning', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '4', ')', 'Resolve', 'redundancy', 'caused', 'data', 'integration', 'Data', 'redundancy', 'occurs', 'database', 'systems', 'field', 'repeated', 'two', 'tables', '.']

>> Bigrams are: 
 [('Data', 'Cleaning'), ('Cleaning', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '4'), ('4', ')'), (')', 'Resolve'), ('Resolve', 'redundancy'), ('redundancy', 'caused'), ('caused', 'data'), ('data', 'integration'), ('integration', 'Data'), ('Data', 'redundancy'), ('redundancy', 'occurs'), ('occurs', 'database'), ('database', 'systems'), ('systems', 'field'), ('field', 'repeated'), ('repeated', 'two'), ('two', 'tables'), ('tables', '.')]

>> Trigrams are: 
 [('Data', 'Cleaning', 'Unit'), ('Cleaning', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '4'), ('›', '4', ')'), ('4', ')', 'Resolve'), (')', 'Resolve', 'redundancy'), ('Resolve', 'redundancy', 'caused'), ('redundancy', 'caused', 'data'), ('caused', 'data', 'integration'), ('data', 'integration', 'Data'), ('integration', 'Data', 'redundancy'), ('Data', 'redundancy', 'occurs'), ('redundancy', 'occurs', 'database'), ('occurs', 'database', 'systems'), ('database', 'systems', 'field'), ('systems', 'field', 'repeated'), ('field', 'repeated', 'two'), ('repeated', 'two', 'tables'), ('two', 'tables', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Cleaning', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('4', 'CD'), (')', ')'), ('Resolve', 'NNP'), ('redundancy', 'NN'), ('caused', 'VBD'), ('data', 'NNS'), ('integration', 'NN'), ('Data', 'NNP'), ('redundancy', 'NN'), ('occurs', 'VBZ'), ('database', 'JJ'), ('systems', 'NNS'), ('field', 'NN'), ('repeated', 'VBD'), ('two', 'CD'), ('tables', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP Cleaning/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  4/CD
  )/)
  (NP Resolve/NNP redundancy/NN)
  caused/VBD
  (NP data/NNS integration/NN Data/NNP redundancy/NN)
  occurs/VBZ
  (NP database/JJ systems/NNS field/NN)
  repeated/VBD
  two/CD
  (NP tables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data Cleaning Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Resolve redundancy', 'data integration Data redundancy', 'database systems field', 'tables']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Resolve', 'resolv'), ('redundancy', 'redund'), ('caused', 'caus'), ('data', 'data'), ('integration', 'integr'), ('Data', 'data'), ('redundancy', 'redund'), ('occurs', 'occur'), ('database', 'databas'), ('systems', 'system'), ('field', 'field'), ('repeated', 'repeat'), ('two', 'two'), ('tables', 'tabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Resolve', 'resolv'), ('redundancy', 'redund'), ('caused', 'caus'), ('data', 'data'), ('integration', 'integr'), ('Data', 'data'), ('redundancy', 'redund'), ('occurs', 'occur'), ('database', 'databas'), ('systems', 'system'), ('field', 'field'), ('repeated', 'repeat'), ('two', 'two'), ('tables', 'tabl'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('4', '4'), (')', ')'), ('Resolve', 'Resolve'), ('redundancy', 'redundancy'), ('caused', 'caused'), ('data', 'data'), ('integration', 'integration'), ('Data', 'Data'), ('redundancy', 'redundancy'), ('occurs', 'occurs'), ('database', 'database'), ('systems', 'system'), ('field', 'field'), ('repeated', 'repeated'), ('two', 'two'), ('tables', 'table'), ('.', '.')]



============================ Sentence 97 =============================

When customer data is duplicated and attached with each product bought, then redundancy of data is known as inconsistency. 


>> Tokens are: 
 ['When', 'customer', 'data', 'duplicated', 'attached', 'product', 'bought', ',', 'redundancy', 'data', 'known', 'inconsistency', '.']

>> Bigrams are: 
 [('When', 'customer'), ('customer', 'data'), ('data', 'duplicated'), ('duplicated', 'attached'), ('attached', 'product'), ('product', 'bought'), ('bought', ','), (',', 'redundancy'), ('redundancy', 'data'), ('data', 'known'), ('known', 'inconsistency'), ('inconsistency', '.')]

>> Trigrams are: 
 [('When', 'customer', 'data'), ('customer', 'data', 'duplicated'), ('data', 'duplicated', 'attached'), ('duplicated', 'attached', 'product'), ('attached', 'product', 'bought'), ('product', 'bought', ','), ('bought', ',', 'redundancy'), (',', 'redundancy', 'data'), ('redundancy', 'data', 'known'), ('data', 'known', 'inconsistency'), ('known', 'inconsistency', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('customer', 'NN'), ('data', 'NNS'), ('duplicated', 'VBN'), ('attached', 'JJ'), ('product', 'NN'), ('bought', 'VBD'), (',', ','), ('redundancy', 'NN'), ('data', 'NNS'), ('known', 'VBN'), ('inconsistency', 'NN'), ('.', '.')]

 (S
  When/WRB
  (NP customer/NN data/NNS)
  duplicated/VBN
  (NP attached/JJ product/NN)
  bought/VBD
  ,/,
  (NP redundancy/NN data/NNS)
  known/VBN
  (NP inconsistency/NN)
  ./.) 


>> Noun Phrases are: 
 ['customer data', 'attached product', 'redundancy data', 'inconsistency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('customer', 'custom'), ('data', 'data'), ('duplicated', 'duplic'), ('attached', 'attach'), ('product', 'product'), ('bought', 'bought'), (',', ','), ('redundancy', 'redund'), ('data', 'data'), ('known', 'known'), ('inconsistency', 'inconsist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('customer', 'custom'), ('data', 'data'), ('duplicated', 'duplic'), ('attached', 'attach'), ('product', 'product'), ('bought', 'bought'), (',', ','), ('redundancy', 'redund'), ('data', 'data'), ('known', 'known'), ('inconsistency', 'inconsist'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('customer', 'customer'), ('data', 'data'), ('duplicated', 'duplicated'), ('attached', 'attached'), ('product', 'product'), ('bought', 'bought'), (',', ','), ('redundancy', 'redundancy'), ('data', 'data'), ('known', 'known'), ('inconsistency', 'inconsistency'), ('.', '.')]



============================ Sentence 98 =============================

So, the entity "customer" might appear with different values. 


>> Tokens are: 
 ['So', ',', 'entity', '``', 'customer', "''", 'might', 'appear', 'different', 'values', '.']

>> Bigrams are: 
 [('So', ','), (',', 'entity'), ('entity', '``'), ('``', 'customer'), ('customer', "''"), ("''", 'might'), ('might', 'appear'), ('appear', 'different'), ('different', 'values'), ('values', '.')]

>> Trigrams are: 
 [('So', ',', 'entity'), (',', 'entity', '``'), ('entity', '``', 'customer'), ('``', 'customer', "''"), ('customer', "''", 'might'), ("''", 'might', 'appear'), ('might', 'appear', 'different'), ('appear', 'different', 'values'), ('different', 'values', '.')]

>> POS Tags are: 
 [('So', 'RB'), (',', ','), ('entity', 'NN'), ('``', '``'), ('customer', 'NN'), ("''", "''"), ('might', 'MD'), ('appear', 'VB'), ('different', 'JJ'), ('values', 'NNS'), ('.', '.')]

 (S
  So/RB
  ,/,
  (NP entity/NN)
  ``/``
  (NP customer/NN)
  ''/''
  might/MD
  appear/VB
  (NP different/JJ values/NNS)
  ./.) 


>> Noun Phrases are: 
 ['entity', 'customer', 'different values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('So', 'so'), (',', ','), ('entity', 'entiti'), ('``', '``'), ('customer', 'custom'), ("''", "''"), ('might', 'might'), ('appear', 'appear'), ('different', 'differ'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('So', 'so'), (',', ','), ('entity', 'entiti'), ('``', '``'), ('customer', 'custom'), ("''", "''"), ('might', 'might'), ('appear', 'appear'), ('different', 'differ'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('So', 'So'), (',', ','), ('entity', 'entity'), ('``', '``'), ('customer', 'customer'), ("''", "''"), ('might', 'might'), ('appear', 'appear'), ('different', 'different'), ('values', 'value'), ('.', '.')]



============================ Sentence 99 =============================

Database normalization prevents redundancy and makes the best possible usage of storage. 


>> Tokens are: 
 ['Database', 'normalization', 'prevents', 'redundancy', 'makes', 'best', 'possible', 'usage', 'storage', '.']

>> Bigrams are: 
 [('Database', 'normalization'), ('normalization', 'prevents'), ('prevents', 'redundancy'), ('redundancy', 'makes'), ('makes', 'best'), ('best', 'possible'), ('possible', 'usage'), ('usage', 'storage'), ('storage', '.')]

>> Trigrams are: 
 [('Database', 'normalization', 'prevents'), ('normalization', 'prevents', 'redundancy'), ('prevents', 'redundancy', 'makes'), ('redundancy', 'makes', 'best'), ('makes', 'best', 'possible'), ('best', 'possible', 'usage'), ('possible', 'usage', 'storage'), ('usage', 'storage', '.')]

>> POS Tags are: 
 [('Database', 'NNP'), ('normalization', 'NN'), ('prevents', 'NNS'), ('redundancy', 'NN'), ('makes', 'VBZ'), ('best', 'RBS'), ('possible', 'JJ'), ('usage', 'JJ'), ('storage', 'NN'), ('.', '.')]

 (S
  (NP Database/NNP normalization/NN prevents/NNS redundancy/NN)
  makes/VBZ
  best/RBS
  (NP possible/JJ usage/JJ storage/NN)
  ./.) 


>> Noun Phrases are: 
 ['Database normalization prevents redundancy', 'possible usage storage']

>> Named Entities are: 
 [('GPE', 'Database')] 

>> Stemming using Porter Stemmer: 
 [('Database', 'databas'), ('normalization', 'normal'), ('prevents', 'prevent'), ('redundancy', 'redund'), ('makes', 'make'), ('best', 'best'), ('possible', 'possibl'), ('usage', 'usag'), ('storage', 'storag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Database', 'databas'), ('normalization', 'normal'), ('prevents', 'prevent'), ('redundancy', 'redund'), ('makes', 'make'), ('best', 'best'), ('possible', 'possibl'), ('usage', 'usag'), ('storage', 'storag'), ('.', '.')]

>> Lemmatization: 
 [('Database', 'Database'), ('normalization', 'normalization'), ('prevents', 'prevents'), ('redundancy', 'redundancy'), ('makes', 'make'), ('best', 'best'), ('possible', 'possible'), ('usage', 'usage'), ('storage', 'storage'), ('.', '.')]



============================ Sentence 100 =============================

The proper use of foreign keys can minimize data redundancy and reduce the chance of destructive anomalies appearing. 


>> Tokens are: 
 ['The', 'proper', 'use', 'foreign', 'keys', 'minimize', 'data', 'redundancy', 'reduce', 'chance', 'destructive', 'anomalies', 'appearing', '.']

>> Bigrams are: 
 [('The', 'proper'), ('proper', 'use'), ('use', 'foreign'), ('foreign', 'keys'), ('keys', 'minimize'), ('minimize', 'data'), ('data', 'redundancy'), ('redundancy', 'reduce'), ('reduce', 'chance'), ('chance', 'destructive'), ('destructive', 'anomalies'), ('anomalies', 'appearing'), ('appearing', '.')]

>> Trigrams are: 
 [('The', 'proper', 'use'), ('proper', 'use', 'foreign'), ('use', 'foreign', 'keys'), ('foreign', 'keys', 'minimize'), ('keys', 'minimize', 'data'), ('minimize', 'data', 'redundancy'), ('data', 'redundancy', 'reduce'), ('redundancy', 'reduce', 'chance'), ('reduce', 'chance', 'destructive'), ('chance', 'destructive', 'anomalies'), ('destructive', 'anomalies', 'appearing'), ('anomalies', 'appearing', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('proper', 'JJ'), ('use', 'NN'), ('foreign', 'JJ'), ('keys', 'NNS'), ('minimize', 'VBP'), ('data', 'NNS'), ('redundancy', 'NN'), ('reduce', 'VB'), ('chance', 'NN'), ('destructive', 'JJ'), ('anomalies', 'NNS'), ('appearing', 'VBG'), ('.', '.')]

 (S
  (NP The/DT proper/JJ use/NN)
  (NP foreign/JJ keys/NNS)
  minimize/VBP
  (NP data/NNS redundancy/NN)
  reduce/VB
  (NP chance/NN)
  (NP destructive/JJ anomalies/NNS)
  appearing/VBG
  ./.) 


>> Noun Phrases are: 
 ['The proper use', 'foreign keys', 'data redundancy', 'chance', 'destructive anomalies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('proper', 'proper'), ('use', 'use'), ('foreign', 'foreign'), ('keys', 'key'), ('minimize', 'minim'), ('data', 'data'), ('redundancy', 'redund'), ('reduce', 'reduc'), ('chance', 'chanc'), ('destructive', 'destruct'), ('anomalies', 'anomali'), ('appearing', 'appear'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('proper', 'proper'), ('use', 'use'), ('foreign', 'foreign'), ('keys', 'key'), ('minimize', 'minim'), ('data', 'data'), ('redundancy', 'redund'), ('reduce', 'reduc'), ('chance', 'chanc'), ('destructive', 'destruct'), ('anomalies', 'anomali'), ('appearing', 'appear'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('proper', 'proper'), ('use', 'use'), ('foreign', 'foreign'), ('keys', 'key'), ('minimize', 'minimize'), ('data', 'data'), ('redundancy', 'redundancy'), ('reduce', 'reduce'), ('chance', 'chance'), ('destructive', 'destructive'), ('anomalies', 'anomaly'), ('appearing', 'appearing'), ('.', '.')]



============================ Sentence 101 =============================

Data Cleaning   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Integration Data integration involves combining data residing in different sources and providing users with a unified view of these all data. 


>> Tokens are: 
 ['Data', 'Cleaning', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Integration', 'Data', 'integration', 'involves', 'combining', 'data', 'residing', 'different', 'sources', 'providing', 'users', 'unified', 'view', 'data', '.']

>> Bigrams are: 
 [('Data', 'Cleaning'), ('Cleaning', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Integration'), ('Integration', 'Data'), ('Data', 'integration'), ('integration', 'involves'), ('involves', 'combining'), ('combining', 'data'), ('data', 'residing'), ('residing', 'different'), ('different', 'sources'), ('sources', 'providing'), ('providing', 'users'), ('users', 'unified'), ('unified', 'view'), ('view', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Data', 'Cleaning', 'Unit'), ('Cleaning', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Integration'), ('Data', 'Integration', 'Data'), ('Integration', 'Data', 'integration'), ('Data', 'integration', 'involves'), ('integration', 'involves', 'combining'), ('involves', 'combining', 'data'), ('combining', 'data', 'residing'), ('data', 'residing', 'different'), ('residing', 'different', 'sources'), ('different', 'sources', 'providing'), ('sources', 'providing', 'users'), ('providing', 'users', 'unified'), ('users', 'unified', 'view'), ('unified', 'view', 'data'), ('view', 'data', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Cleaning', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Integration', 'NNP'), ('Data', 'NNP'), ('integration', 'NN'), ('involves', 'VBZ'), ('combining', 'VBG'), ('data', 'NNS'), ('residing', 'VBG'), ('different', 'JJ'), ('sources', 'NNS'), ('providing', 'VBG'), ('users', 'NNS'), ('unified', 'JJ'), ('view', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP Cleaning/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Integration/NNP Data/NNP integration/NN)
  involves/VBZ
  combining/VBG
  (NP data/NNS)
  residing/VBG
  (NP different/JJ sources/NNS)
  providing/VBG
  (NP users/NNS)
  (NP unified/JJ view/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data Cleaning Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Integration Data integration', 'data', 'different sources', 'users', 'unified view data']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Integration', 'integr'), ('Data', 'data'), ('integration', 'integr'), ('involves', 'involv'), ('combining', 'combin'), ('data', 'data'), ('residing', 'resid'), ('different', 'differ'), ('sources', 'sourc'), ('providing', 'provid'), ('users', 'user'), ('unified', 'unifi'), ('view', 'view'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Cleaning', 'clean'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Integration', 'integr'), ('Data', 'data'), ('integration', 'integr'), ('involves', 'involv'), ('combining', 'combin'), ('data', 'data'), ('residing', 'resid'), ('different', 'differ'), ('sources', 'sourc'), ('providing', 'provid'), ('users', 'user'), ('unified', 'unifi'), ('view', 'view'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Cleaning', 'Cleaning'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Integration', 'Integration'), ('Data', 'Data'), ('integration', 'integration'), ('involves', 'involves'), ('combining', 'combining'), ('data', 'data'), ('residing', 'residing'), ('different', 'different'), ('sources', 'source'), ('providing', 'providing'), ('users', 'user'), ('unified', 'unified'), ('view', 'view'), ('data', 'data'), ('.', '.')]



============================ Sentence 102 =============================

In relational databases we also combine schemas like A.CustomerID = B.CustomerID. 


>> Tokens are: 
 ['In', 'relational', 'databases', 'also', 'combine', 'schemas', 'like', 'A.CustomerID', '=', 'B.CustomerID', '.']

>> Bigrams are: 
 [('In', 'relational'), ('relational', 'databases'), ('databases', 'also'), ('also', 'combine'), ('combine', 'schemas'), ('schemas', 'like'), ('like', 'A.CustomerID'), ('A.CustomerID', '='), ('=', 'B.CustomerID'), ('B.CustomerID', '.')]

>> Trigrams are: 
 [('In', 'relational', 'databases'), ('relational', 'databases', 'also'), ('databases', 'also', 'combine'), ('also', 'combine', 'schemas'), ('combine', 'schemas', 'like'), ('schemas', 'like', 'A.CustomerID'), ('like', 'A.CustomerID', '='), ('A.CustomerID', '=', 'B.CustomerID'), ('=', 'B.CustomerID', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('relational', 'JJ'), ('databases', 'NNS'), ('also', 'RB'), ('combine', 'VBP'), ('schemas', 'NNS'), ('like', 'IN'), ('A.CustomerID', 'NNP'), ('=', 'NNP'), ('B.CustomerID', 'NNP'), ('.', '.')]

 (S
  In/IN
  (NP relational/JJ databases/NNS)
  also/RB
  combine/VBP
  (NP schemas/NNS)
  like/IN
  (NP A.CustomerID/NNP =/NNP B.CustomerID/NNP)
  ./.) 


>> Noun Phrases are: 
 ['relational databases', 'schemas', 'A.CustomerID = B.CustomerID']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('relational', 'relat'), ('databases', 'databas'), ('also', 'also'), ('combine', 'combin'), ('schemas', 'schema'), ('like', 'like'), ('A.CustomerID', 'a.customerid'), ('=', '='), ('B.CustomerID', 'b.customerid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('relational', 'relat'), ('databases', 'databas'), ('also', 'also'), ('combine', 'combin'), ('schemas', 'schema'), ('like', 'like'), ('A.CustomerID', 'a.customerid'), ('=', '='), ('B.CustomerID', 'b.customerid'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('relational', 'relational'), ('databases', 'database'), ('also', 'also'), ('combine', 'combine'), ('schemas', 'schema'), ('like', 'like'), ('A.CustomerID', 'A.CustomerID'), ('=', '='), ('B.CustomerID', 'B.CustomerID'), ('.', '.')]



============================ Sentence 103 =============================

In real world, attribute values from different sources are different. 


>> Tokens are: 
 ['In', 'real', 'world', ',', 'attribute', 'values', 'different', 'sources', 'different', '.']

>> Bigrams are: 
 [('In', 'real'), ('real', 'world'), ('world', ','), (',', 'attribute'), ('attribute', 'values'), ('values', 'different'), ('different', 'sources'), ('sources', 'different'), ('different', '.')]

>> Trigrams are: 
 [('In', 'real', 'world'), ('real', 'world', ','), ('world', ',', 'attribute'), (',', 'attribute', 'values'), ('attribute', 'values', 'different'), ('values', 'different', 'sources'), ('different', 'sources', 'different'), ('sources', 'different', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('real', 'JJ'), ('world', 'NN'), (',', ','), ('attribute', 'VBP'), ('values', 'NNS'), ('different', 'JJ'), ('sources', 'NNS'), ('different', 'JJ'), ('.', '.')]

 (S
  In/IN
  (NP real/JJ world/NN)
  ,/,
  attribute/VBP
  (NP values/NNS)
  (NP different/JJ sources/NNS)
  different/JJ
  ./.) 


>> Noun Phrases are: 
 ['real world', 'values', 'different sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('real', 'real'), ('world', 'world'), (',', ','), ('attribute', 'attribut'), ('values', 'valu'), ('different', 'differ'), ('sources', 'sourc'), ('different', 'differ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('real', 'real'), ('world', 'world'), (',', ','), ('attribute', 'attribut'), ('values', 'valu'), ('different', 'differ'), ('sources', 'sourc'), ('different', 'differ'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('real', 'real'), ('world', 'world'), (',', ','), ('attribute', 'attribute'), ('values', 'value'), ('different', 'different'), ('sources', 'source'), ('different', 'different'), ('.', '.')]



============================ Sentence 104 =============================

Data Integration may involve inconsistent data and therefore needs data cleaning also. 


>> Tokens are: 
 ['Data', 'Integration', 'may', 'involve', 'inconsistent', 'data', 'therefore', 'needs', 'data', 'cleaning', 'also', '.']

>> Bigrams are: 
 [('Data', 'Integration'), ('Integration', 'may'), ('may', 'involve'), ('involve', 'inconsistent'), ('inconsistent', 'data'), ('data', 'therefore'), ('therefore', 'needs'), ('needs', 'data'), ('data', 'cleaning'), ('cleaning', 'also'), ('also', '.')]

>> Trigrams are: 
 [('Data', 'Integration', 'may'), ('Integration', 'may', 'involve'), ('may', 'involve', 'inconsistent'), ('involve', 'inconsistent', 'data'), ('inconsistent', 'data', 'therefore'), ('data', 'therefore', 'needs'), ('therefore', 'needs', 'data'), ('needs', 'data', 'cleaning'), ('data', 'cleaning', 'also'), ('cleaning', 'also', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Integration', 'NNP'), ('may', 'MD'), ('involve', 'VB'), ('inconsistent', 'NN'), ('data', 'NNS'), ('therefore', 'RB'), ('needs', 'VBZ'), ('data', 'NN'), ('cleaning', 'NN'), ('also', 'RB'), ('.', '.')]

 (S
  (NP Data/NNP Integration/NNP)
  may/MD
  involve/VB
  (NP inconsistent/NN data/NNS)
  therefore/RB
  needs/VBZ
  (NP data/NN cleaning/NN)
  also/RB
  ./.) 


>> Noun Phrases are: 
 ['Data Integration', 'inconsistent data', 'data cleaning']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Integration', 'integr'), ('may', 'may'), ('involve', 'involv'), ('inconsistent', 'inconsist'), ('data', 'data'), ('therefore', 'therefor'), ('needs', 'need'), ('data', 'data'), ('cleaning', 'clean'), ('also', 'also'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Integration', 'integr'), ('may', 'may'), ('involve', 'involv'), ('inconsistent', 'inconsist'), ('data', 'data'), ('therefore', 'therefor'), ('needs', 'need'), ('data', 'data'), ('cleaning', 'clean'), ('also', 'also'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Integration', 'Integration'), ('may', 'may'), ('involve', 'involve'), ('inconsistent', 'inconsistent'), ('data', 'data'), ('therefore', 'therefore'), ('needs', 'need'), ('data', 'data'), ('cleaning', 'cleaning'), ('also', 'also'), ('.', '.')]



============================ Sentence 105 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Transformation Data transformation is the process of converting data from one form to another form. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Transformation', 'Data', 'transformation', 'process', 'converting', 'data', 'one', 'form', 'another', 'form', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Transformation'), ('Transformation', 'Data'), ('Data', 'transformation'), ('transformation', 'process'), ('process', 'converting'), ('converting', 'data'), ('data', 'one'), ('one', 'form'), ('form', 'another'), ('another', 'form'), ('form', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Transformation'), ('Data', 'Transformation', 'Data'), ('Transformation', 'Data', 'transformation'), ('Data', 'transformation', 'process'), ('transformation', 'process', 'converting'), ('process', 'converting', 'data'), ('converting', 'data', 'one'), ('data', 'one', 'form'), ('one', 'form', 'another'), ('form', 'another', 'form'), ('another', 'form', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('Data', 'NNP'), ('transformation', 'NN'), ('process', 'NN'), ('converting', 'VBG'), ('data', 'NNS'), ('one', 'CD'), ('form', 'NN'), ('another', 'DT'), ('form', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP
    ›/NNP
    Data/NNP
    Transformation/NNP
    Data/NNP
    transformation/NN
    process/NN)
  converting/VBG
  (NP data/NNS)
  one/CD
  (NP form/NN)
  (NP another/DT form/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Transformation Data transformation process', 'data', 'form', 'another form']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('Data', 'data'), ('transformation', 'transform'), ('process', 'process'), ('converting', 'convert'), ('data', 'data'), ('one', 'one'), ('form', 'form'), ('another', 'anoth'), ('form', 'form'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('Data', 'data'), ('transformation', 'transform'), ('process', 'process'), ('converting', 'convert'), ('data', 'data'), ('one', 'one'), ('form', 'form'), ('another', 'anoth'), ('form', 'form'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('Data', 'Data'), ('transformation', 'transformation'), ('process', 'process'), ('converting', 'converting'), ('data', 'data'), ('one', 'one'), ('form', 'form'), ('another', 'another'), ('form', 'form'), ('.', '.')]



============================ Sentence 106 =============================

Data often resides in different locations across the storage and also differs in format. 


>> Tokens are: 
 ['Data', 'often', 'resides', 'different', 'locations', 'across', 'storage', 'also', 'differs', 'format', '.']

>> Bigrams are: 
 [('Data', 'often'), ('often', 'resides'), ('resides', 'different'), ('different', 'locations'), ('locations', 'across'), ('across', 'storage'), ('storage', 'also'), ('also', 'differs'), ('differs', 'format'), ('format', '.')]

>> Trigrams are: 
 [('Data', 'often', 'resides'), ('often', 'resides', 'different'), ('resides', 'different', 'locations'), ('different', 'locations', 'across'), ('locations', 'across', 'storage'), ('across', 'storage', 'also'), ('storage', 'also', 'differs'), ('also', 'differs', 'format'), ('differs', 'format', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('often', 'RB'), ('resides', 'VBZ'), ('different', 'JJ'), ('locations', 'NNS'), ('across', 'IN'), ('storage', 'NN'), ('also', 'RB'), ('differs', 'VBZ'), ('format', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP)
  often/RB
  resides/VBZ
  (NP different/JJ locations/NNS)
  across/IN
  (NP storage/NN)
  also/RB
  differs/VBZ
  (NP format/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data', 'different locations', 'storage', 'format']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('often', 'often'), ('resides', 'resid'), ('different', 'differ'), ('locations', 'locat'), ('across', 'across'), ('storage', 'storag'), ('also', 'also'), ('differs', 'differ'), ('format', 'format'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('often', 'often'), ('resides', 'resid'), ('different', 'differ'), ('locations', 'locat'), ('across', 'across'), ('storage', 'storag'), ('also', 'also'), ('differs', 'differ'), ('format', 'format'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('often', 'often'), ('resides', 'resides'), ('different', 'different'), ('locations', 'location'), ('across', 'across'), ('storage', 'storage'), ('also', 'also'), ('differs', 'differs'), ('format', 'format'), ('.', '.')]



============================ Sentence 107 =============================

Data transformation is necessary to ensure that data from one application or database is understandable to other applications and databases also. 


>> Tokens are: 
 ['Data', 'transformation', 'necessary', 'ensure', 'data', 'one', 'application', 'database', 'understandable', 'applications', 'databases', 'also', '.']

>> Bigrams are: 
 [('Data', 'transformation'), ('transformation', 'necessary'), ('necessary', 'ensure'), ('ensure', 'data'), ('data', 'one'), ('one', 'application'), ('application', 'database'), ('database', 'understandable'), ('understandable', 'applications'), ('applications', 'databases'), ('databases', 'also'), ('also', '.')]

>> Trigrams are: 
 [('Data', 'transformation', 'necessary'), ('transformation', 'necessary', 'ensure'), ('necessary', 'ensure', 'data'), ('ensure', 'data', 'one'), ('data', 'one', 'application'), ('one', 'application', 'database'), ('application', 'database', 'understandable'), ('database', 'understandable', 'applications'), ('understandable', 'applications', 'databases'), ('applications', 'databases', 'also'), ('databases', 'also', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('transformation', 'NN'), ('necessary', 'JJ'), ('ensure', 'VB'), ('data', 'NNS'), ('one', 'CD'), ('application', 'NN'), ('database', 'NN'), ('understandable', 'JJ'), ('applications', 'NNS'), ('databases', 'NNS'), ('also', 'RB'), ('.', '.')]

 (S
  (NP Data/NNP transformation/NN)
  necessary/JJ
  ensure/VB
  (NP data/NNS)
  one/CD
  (NP application/NN database/NN)
  (NP understandable/JJ applications/NNS databases/NNS)
  also/RB
  ./.) 


>> Noun Phrases are: 
 ['Data transformation', 'data', 'application database', 'understandable applications databases']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('transformation', 'transform'), ('necessary', 'necessari'), ('ensure', 'ensur'), ('data', 'data'), ('one', 'one'), ('application', 'applic'), ('database', 'databas'), ('understandable', 'understand'), ('applications', 'applic'), ('databases', 'databas'), ('also', 'also'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('transformation', 'transform'), ('necessary', 'necessari'), ('ensure', 'ensur'), ('data', 'data'), ('one', 'one'), ('application', 'applic'), ('database', 'databas'), ('understandable', 'understand'), ('applications', 'applic'), ('databases', 'databas'), ('also', 'also'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('transformation', 'transformation'), ('necessary', 'necessary'), ('ensure', 'ensure'), ('data', 'data'), ('one', 'one'), ('application', 'application'), ('database', 'database'), ('understandable', 'understandable'), ('applications', 'application'), ('databases', 'database'), ('also', 'also'), ('.', '.')]



============================ Sentence 108 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Transformation (Cont..) Data transformation strategies includes the following: Smoothing Attribute construction Aggregation Normalization Discretization Concept hierarchy generation for nominal data    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Transformation (Cont..) Smoothing It works to remove noise from the data. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Transformation', '(', 'Cont', '..', ')', 'Data', 'transformation', 'strategies', 'includes', 'following', ':', 'Smoothing', 'Attribute', 'construction', 'Aggregation', 'Normalization', 'Discretization', 'Concept', 'hierarchy', 'generation', 'nominal', 'data', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Transformation', '(', 'Cont', '..', ')', 'Smoothing', 'It', 'works', 'remove', 'noise', 'data', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Transformation'), ('Transformation', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Data'), ('Data', 'transformation'), ('transformation', 'strategies'), ('strategies', 'includes'), ('includes', 'following'), ('following', ':'), (':', 'Smoothing'), ('Smoothing', 'Attribute'), ('Attribute', 'construction'), ('construction', 'Aggregation'), ('Aggregation', 'Normalization'), ('Normalization', 'Discretization'), ('Discretization', 'Concept'), ('Concept', 'hierarchy'), ('hierarchy', 'generation'), ('generation', 'nominal'), ('nominal', 'data'), ('data', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Transformation'), ('Transformation', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Smoothing'), ('Smoothing', 'It'), ('It', 'works'), ('works', 'remove'), ('remove', 'noise'), ('noise', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Transformation'), ('Data', 'Transformation', '('), ('Transformation', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Data'), (')', 'Data', 'transformation'), ('Data', 'transformation', 'strategies'), ('transformation', 'strategies', 'includes'), ('strategies', 'includes', 'following'), ('includes', 'following', ':'), ('following', ':', 'Smoothing'), (':', 'Smoothing', 'Attribute'), ('Smoothing', 'Attribute', 'construction'), ('Attribute', 'construction', 'Aggregation'), ('construction', 'Aggregation', 'Normalization'), ('Aggregation', 'Normalization', 'Discretization'), ('Normalization', 'Discretization', 'Concept'), ('Discretization', 'Concept', 'hierarchy'), ('Concept', 'hierarchy', 'generation'), ('hierarchy', 'generation', 'nominal'), ('generation', 'nominal', 'data'), ('nominal', 'data', 'Unit'), ('data', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Transformation'), ('Data', 'Transformation', '('), ('Transformation', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Smoothing'), (')', 'Smoothing', 'It'), ('Smoothing', 'It', 'works'), ('It', 'works', 'remove'), ('works', 'remove', 'noise'), ('remove', 'noise', 'data'), ('noise', 'data', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Data', 'NNP'), ('transformation', 'NN'), ('strategies', 'NNS'), ('includes', 'VBZ'), ('following', 'VBG'), (':', ':'), ('Smoothing', 'VBG'), ('Attribute', 'NNP'), ('construction', 'NN'), ('Aggregation', 'NNP'), ('Normalization', 'NNP'), ('Discretization', 'NNP'), ('Concept', 'NNP'), ('hierarchy', 'NN'), ('generation', 'NN'), ('nominal', 'JJ'), ('data', 'NNS'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Smoothing', 'VBG'), ('It', 'PRP'), ('works', 'VBZ'), ('remove', 'VB'), ('noise', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Transformation/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Data/NNP transformation/NN strategies/NNS)
  includes/VBZ
  following/VBG
  :/:
  Smoothing/VBG
  (NP
    Attribute/NNP
    construction/NN
    Aggregation/NNP
    Normalization/NNP
    Discretization/NNP
    Concept/NNP
    hierarchy/NN
    generation/NN)
  (NP nominal/JJ data/NNS Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Transformation/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  Smoothing/VBG
  It/PRP
  works/VBZ
  remove/VB
  (NP noise/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Transformation', 'Cont ..', 'Data transformation strategies', 'Attribute construction Aggregation Normalization Discretization Concept hierarchy generation', 'nominal data Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Transformation', 'Cont ..', 'noise data']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Attribute'), ('PERSON', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Data', 'data'), ('transformation', 'transform'), ('strategies', 'strategi'), ('includes', 'includ'), ('following', 'follow'), (':', ':'), ('Smoothing', 'smooth'), ('Attribute', 'attribut'), ('construction', 'construct'), ('Aggregation', 'aggreg'), ('Normalization', 'normal'), ('Discretization', 'discret'), ('Concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'gener'), ('nominal', 'nomin'), ('data', 'data'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Smoothing', 'smooth'), ('It', 'it'), ('works', 'work'), ('remove', 'remov'), ('noise', 'nois'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Data', 'data'), ('transformation', 'transform'), ('strategies', 'strategi'), ('includes', 'includ'), ('following', 'follow'), (':', ':'), ('Smoothing', 'smooth'), ('Attribute', 'attribut'), ('construction', 'construct'), ('Aggregation', 'aggreg'), ('Normalization', 'normal'), ('Discretization', 'discret'), ('Concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'generat'), ('nominal', 'nomin'), ('data', 'data'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Smoothing', 'smooth'), ('It', 'it'), ('works', 'work'), ('remove', 'remov'), ('noise', 'nois'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Data', 'Data'), ('transformation', 'transformation'), ('strategies', 'strategy'), ('includes', 'includes'), ('following', 'following'), (':', ':'), ('Smoothing', 'Smoothing'), ('Attribute', 'Attribute'), ('construction', 'construction'), ('Aggregation', 'Aggregation'), ('Normalization', 'Normalization'), ('Discretization', 'Discretization'), ('Concept', 'Concept'), ('hierarchy', 'hierarchy'), ('generation', 'generation'), ('nominal', 'nominal'), ('data', 'data'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Smoothing', 'Smoothing'), ('It', 'It'), ('works', 'work'), ('remove', 'remove'), ('noise', 'noise'), ('data', 'data'), ('.', '.')]



============================ Sentence 109 =============================

It is a form of data cleaning where users specify transformations to correct data inconsistencies. 


>> Tokens are: 
 ['It', 'form', 'data', 'cleaning', 'users', 'specify', 'transformations', 'correct', 'data', 'inconsistencies', '.']

>> Bigrams are: 
 [('It', 'form'), ('form', 'data'), ('data', 'cleaning'), ('cleaning', 'users'), ('users', 'specify'), ('specify', 'transformations'), ('transformations', 'correct'), ('correct', 'data'), ('data', 'inconsistencies'), ('inconsistencies', '.')]

>> Trigrams are: 
 [('It', 'form', 'data'), ('form', 'data', 'cleaning'), ('data', 'cleaning', 'users'), ('cleaning', 'users', 'specify'), ('users', 'specify', 'transformations'), ('specify', 'transformations', 'correct'), ('transformations', 'correct', 'data'), ('correct', 'data', 'inconsistencies'), ('data', 'inconsistencies', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('form', 'VBZ'), ('data', 'NNS'), ('cleaning', 'VBG'), ('users', 'NNS'), ('specify', 'VBP'), ('transformations', 'NNS'), ('correct', 'VBP'), ('data', 'NN'), ('inconsistencies', 'NNS'), ('.', '.')]

 (S
  It/PRP
  form/VBZ
  (NP data/NNS)
  cleaning/VBG
  (NP users/NNS)
  specify/VBP
  (NP transformations/NNS)
  correct/VBP
  (NP data/NN inconsistencies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data', 'users', 'transformations', 'data inconsistencies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('form', 'form'), ('data', 'data'), ('cleaning', 'clean'), ('users', 'user'), ('specify', 'specifi'), ('transformations', 'transform'), ('correct', 'correct'), ('data', 'data'), ('inconsistencies', 'inconsist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('form', 'form'), ('data', 'data'), ('cleaning', 'clean'), ('users', 'user'), ('specify', 'specifi'), ('transformations', 'transform'), ('correct', 'correct'), ('data', 'data'), ('inconsistencies', 'inconsist'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('form', 'form'), ('data', 'data'), ('cleaning', 'cleaning'), ('users', 'user'), ('specify', 'specify'), ('transformations', 'transformation'), ('correct', 'correct'), ('data', 'data'), ('inconsistencies', 'inconsistency'), ('.', '.')]



============================ Sentence 110 =============================

Such techniques include binning, regression and clustering. 


>> Tokens are: 
 ['Such', 'techniques', 'include', 'binning', ',', 'regression', 'clustering', '.']

>> Bigrams are: 
 [('Such', 'techniques'), ('techniques', 'include'), ('include', 'binning'), ('binning', ','), (',', 'regression'), ('regression', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Such', 'techniques', 'include'), ('techniques', 'include', 'binning'), ('include', 'binning', ','), ('binning', ',', 'regression'), (',', 'regression', 'clustering'), ('regression', 'clustering', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('techniques', 'NNS'), ('include', 'VBP'), ('binning', 'NN'), (',', ','), ('regression', 'NN'), ('clustering', 'NN'), ('.', '.')]

 (S
  (NP Such/JJ techniques/NNS)
  include/VBP
  (NP binning/NN)
  ,/,
  (NP regression/NN clustering/NN)
  ./.) 


>> Noun Phrases are: 
 ['Such techniques', 'binning', 'regression clustering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('techniques', 'techniqu'), ('include', 'includ'), ('binning', 'bin'), (',', ','), ('regression', 'regress'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('techniques', 'techniqu'), ('include', 'includ'), ('binning', 'bin'), (',', ','), ('regression', 'regress'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('techniques', 'technique'), ('include', 'include'), ('binning', 'binning'), (',', ','), ('regression', 'regression'), ('clustering', 'clustering'), ('.', '.')]



============================ Sentence 111 =============================

Attribute construction It is referred as new attributes are constructed and added from the given set of attributes to help the mining process. 


>> Tokens are: 
 ['Attribute', 'construction', 'It', 'referred', 'new', 'attributes', 'constructed', 'added', 'given', 'set', 'attributes', 'help', 'mining', 'process', '.']

>> Bigrams are: 
 [('Attribute', 'construction'), ('construction', 'It'), ('It', 'referred'), ('referred', 'new'), ('new', 'attributes'), ('attributes', 'constructed'), ('constructed', 'added'), ('added', 'given'), ('given', 'set'), ('set', 'attributes'), ('attributes', 'help'), ('help', 'mining'), ('mining', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Attribute', 'construction', 'It'), ('construction', 'It', 'referred'), ('It', 'referred', 'new'), ('referred', 'new', 'attributes'), ('new', 'attributes', 'constructed'), ('attributes', 'constructed', 'added'), ('constructed', 'added', 'given'), ('added', 'given', 'set'), ('given', 'set', 'attributes'), ('set', 'attributes', 'help'), ('attributes', 'help', 'mining'), ('help', 'mining', 'process'), ('mining', 'process', '.')]

>> POS Tags are: 
 [('Attribute', 'JJ'), ('construction', 'NN'), ('It', 'PRP'), ('referred', 'VBD'), ('new', 'JJ'), ('attributes', 'NNS'), ('constructed', 'VBD'), ('added', 'VBD'), ('given', 'VBN'), ('set', 'VBN'), ('attributes', 'NNS'), ('help', 'VBP'), ('mining', 'NN'), ('process', 'NN'), ('.', '.')]

 (S
  (NP Attribute/JJ construction/NN)
  It/PRP
  referred/VBD
  (NP new/JJ attributes/NNS)
  constructed/VBD
  added/VBD
  given/VBN
  set/VBN
  (NP attributes/NNS)
  help/VBP
  (NP mining/NN process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Attribute construction', 'new attributes', 'attributes', 'mining process']

>> Named Entities are: 
 [('GPE', 'Attribute')] 

>> Stemming using Porter Stemmer: 
 [('Attribute', 'attribut'), ('construction', 'construct'), ('It', 'it'), ('referred', 'refer'), ('new', 'new'), ('attributes', 'attribut'), ('constructed', 'construct'), ('added', 'ad'), ('given', 'given'), ('set', 'set'), ('attributes', 'attribut'), ('help', 'help'), ('mining', 'mine'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Attribute', 'attribut'), ('construction', 'construct'), ('It', 'it'), ('referred', 'refer'), ('new', 'new'), ('attributes', 'attribut'), ('constructed', 'construct'), ('added', 'ad'), ('given', 'given'), ('set', 'set'), ('attributes', 'attribut'), ('help', 'help'), ('mining', 'mine'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Attribute', 'Attribute'), ('construction', 'construction'), ('It', 'It'), ('referred', 'referred'), ('new', 'new'), ('attributes', 'attribute'), ('constructed', 'constructed'), ('added', 'added'), ('given', 'given'), ('set', 'set'), ('attributes', 'attribute'), ('help', 'help'), ('mining', 'mining'), ('process', 'process'), ('.', '.')]



============================ Sentence 112 =============================

Aggregation In this, summary or aggregation operations are applied to the data. 


>> Tokens are: 
 ['Aggregation', 'In', ',', 'summary', 'aggregation', 'operations', 'applied', 'data', '.']

>> Bigrams are: 
 [('Aggregation', 'In'), ('In', ','), (',', 'summary'), ('summary', 'aggregation'), ('aggregation', 'operations'), ('operations', 'applied'), ('applied', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Aggregation', 'In', ','), ('In', ',', 'summary'), (',', 'summary', 'aggregation'), ('summary', 'aggregation', 'operations'), ('aggregation', 'operations', 'applied'), ('operations', 'applied', 'data'), ('applied', 'data', '.')]

>> POS Tags are: 
 [('Aggregation', 'NN'), ('In', 'IN'), (',', ','), ('summary', 'JJ'), ('aggregation', 'NN'), ('operations', 'NNS'), ('applied', 'VBN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Aggregation/NN)
  In/IN
  ,/,
  (NP summary/JJ aggregation/NN operations/NNS)
  applied/VBN
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Aggregation', 'summary aggregation operations', 'data']

>> Named Entities are: 
 [('GPE', 'Aggregation'), ('ORGANIZATION', 'In')] 

>> Stemming using Porter Stemmer: 
 [('Aggregation', 'aggreg'), ('In', 'in'), (',', ','), ('summary', 'summari'), ('aggregation', 'aggreg'), ('operations', 'oper'), ('applied', 'appli'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aggregation', 'aggreg'), ('In', 'in'), (',', ','), ('summary', 'summari'), ('aggregation', 'aggreg'), ('operations', 'oper'), ('applied', 'appli'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Aggregation', 'Aggregation'), ('In', 'In'), (',', ','), ('summary', 'summary'), ('aggregation', 'aggregation'), ('operations', 'operation'), ('applied', 'applied'), ('data', 'data'), ('.', '.')]



============================ Sentence 113 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 114 =============================

Daily sales data are aggregated at individual source so sales manager can compute monthly and annually total amounts. 


>> Tokens are: 
 ['Daily', 'sales', 'data', 'aggregated', 'individual', 'source', 'sales', 'manager', 'compute', 'monthly', 'annually', 'total', 'amounts', '.']

>> Bigrams are: 
 [('Daily', 'sales'), ('sales', 'data'), ('data', 'aggregated'), ('aggregated', 'individual'), ('individual', 'source'), ('source', 'sales'), ('sales', 'manager'), ('manager', 'compute'), ('compute', 'monthly'), ('monthly', 'annually'), ('annually', 'total'), ('total', 'amounts'), ('amounts', '.')]

>> Trigrams are: 
 [('Daily', 'sales', 'data'), ('sales', 'data', 'aggregated'), ('data', 'aggregated', 'individual'), ('aggregated', 'individual', 'source'), ('individual', 'source', 'sales'), ('source', 'sales', 'manager'), ('sales', 'manager', 'compute'), ('manager', 'compute', 'monthly'), ('compute', 'monthly', 'annually'), ('monthly', 'annually', 'total'), ('annually', 'total', 'amounts'), ('total', 'amounts', '.')]

>> POS Tags are: 
 [('Daily', 'JJ'), ('sales', 'NNS'), ('data', 'NNS'), ('aggregated', 'VBD'), ('individual', 'JJ'), ('source', 'NN'), ('sales', 'NNS'), ('manager', 'NN'), ('compute', 'VBP'), ('monthly', 'RB'), ('annually', 'RB'), ('total', 'JJ'), ('amounts', 'NNS'), ('.', '.')]

 (S
  (NP Daily/JJ sales/NNS data/NNS)
  aggregated/VBD
  (NP individual/JJ source/NN sales/NNS manager/NN)
  compute/VBP
  monthly/RB
  annually/RB
  (NP total/JJ amounts/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Daily sales data', 'individual source sales manager', 'total amounts']

>> Named Entities are: 
 [('GPE', 'Daily')] 

>> Stemming using Porter Stemmer: 
 [('Daily', 'daili'), ('sales', 'sale'), ('data', 'data'), ('aggregated', 'aggreg'), ('individual', 'individu'), ('source', 'sourc'), ('sales', 'sale'), ('manager', 'manag'), ('compute', 'comput'), ('monthly', 'monthli'), ('annually', 'annual'), ('total', 'total'), ('amounts', 'amount'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Daily', 'daili'), ('sales', 'sale'), ('data', 'data'), ('aggregated', 'aggreg'), ('individual', 'individu'), ('source', 'sourc'), ('sales', 'sale'), ('manager', 'manag'), ('compute', 'comput'), ('monthly', 'month'), ('annually', 'annual'), ('total', 'total'), ('amounts', 'amount'), ('.', '.')]

>> Lemmatization: 
 [('Daily', 'Daily'), ('sales', 'sale'), ('data', 'data'), ('aggregated', 'aggregated'), ('individual', 'individual'), ('source', 'source'), ('sales', 'sale'), ('manager', 'manager'), ('compute', 'compute'), ('monthly', 'monthly'), ('annually', 'annually'), ('total', 'total'), ('amounts', 'amount'), ('.', '.')]



============================ Sentence 115 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Transformation (Cont..) Normalization Normalization is scaling technique or a mapping technique. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Transformation', '(', 'Cont', '..', ')', 'Normalization', 'Normalization', 'scaling', 'technique', 'mapping', 'technique', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Transformation'), ('Transformation', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Normalization'), ('Normalization', 'Normalization'), ('Normalization', 'scaling'), ('scaling', 'technique'), ('technique', 'mapping'), ('mapping', 'technique'), ('technique', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Transformation'), ('Data', 'Transformation', '('), ('Transformation', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Normalization'), (')', 'Normalization', 'Normalization'), ('Normalization', 'Normalization', 'scaling'), ('Normalization', 'scaling', 'technique'), ('scaling', 'technique', 'mapping'), ('technique', 'mapping', 'technique'), ('mapping', 'technique', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Normalization', 'NNP'), ('Normalization', 'NNP'), ('scaling', 'VBG'), ('technique', 'NN'), ('mapping', 'NN'), ('technique', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Transformation/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Normalization/NNP Normalization/NNP)
  scaling/VBG
  (NP technique/NN mapping/NN technique/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Transformation', 'Cont ..', 'Normalization Normalization', 'technique mapping technique']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Normalization', 'normal'), ('Normalization', 'normal'), ('scaling', 'scale'), ('technique', 'techniqu'), ('mapping', 'map'), ('technique', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Normalization', 'normal'), ('Normalization', 'normal'), ('scaling', 'scale'), ('technique', 'techniqu'), ('mapping', 'map'), ('technique', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Normalization', 'Normalization'), ('Normalization', 'Normalization'), ('scaling', 'scaling'), ('technique', 'technique'), ('mapping', 'mapping'), ('technique', 'technique'), ('.', '.')]



============================ Sentence 116 =============================

With normalization, we can find new range from an existing range. 


>> Tokens are: 
 ['With', 'normalization', ',', 'find', 'new', 'range', 'existing', 'range', '.']

>> Bigrams are: 
 [('With', 'normalization'), ('normalization', ','), (',', 'find'), ('find', 'new'), ('new', 'range'), ('range', 'existing'), ('existing', 'range'), ('range', '.')]

>> Trigrams are: 
 [('With', 'normalization', ','), ('normalization', ',', 'find'), (',', 'find', 'new'), ('find', 'new', 'range'), ('new', 'range', 'existing'), ('range', 'existing', 'range'), ('existing', 'range', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('normalization', 'NN'), (',', ','), ('find', 'VBP'), ('new', 'JJ'), ('range', 'NN'), ('existing', 'VBG'), ('range', 'NN'), ('.', '.')]

 (S
  With/IN
  (NP normalization/NN)
  ,/,
  find/VBP
  (NP new/JJ range/NN)
  existing/VBG
  (NP range/NN)
  ./.) 


>> Noun Phrases are: 
 ['normalization', 'new range', 'range']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('normalization', 'normal'), (',', ','), ('find', 'find'), ('new', 'new'), ('range', 'rang'), ('existing', 'exist'), ('range', 'rang'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('normalization', 'normal'), (',', ','), ('find', 'find'), ('new', 'new'), ('range', 'rang'), ('existing', 'exist'), ('range', 'rang'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('normalization', 'normalization'), (',', ','), ('find', 'find'), ('new', 'new'), ('range', 'range'), ('existing', 'existing'), ('range', 'range'), ('.', '.')]



============================ Sentence 117 =============================

There are three techniques for normalization. 


>> Tokens are: 
 ['There', 'three', 'techniques', 'normalization', '.']

>> Bigrams are: 
 [('There', 'three'), ('three', 'techniques'), ('techniques', 'normalization'), ('normalization', '.')]

>> Trigrams are: 
 [('There', 'three', 'techniques'), ('three', 'techniques', 'normalization'), ('techniques', 'normalization', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('three', 'CD'), ('techniques', 'NNS'), ('normalization', 'NN'), ('.', '.')]

 (S There/EX three/CD (NP techniques/NNS normalization/NN) ./.) 


>> Noun Phrases are: 
 ['techniques normalization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('three', 'three'), ('techniques', 'techniqu'), ('normalization', 'normal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('three', 'three'), ('techniques', 'techniqu'), ('normalization', 'normal'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('three', 'three'), ('techniques', 'technique'), ('normalization', 'normalization'), ('.', '.')]



============================ Sentence 118 =============================

Min-Max Normalization  This is a simple normalization technique in which we fit given data in a pre-defined boundary, or a pre-defined interval [0,1]. 


>> Tokens are: 
 ['Min-Max', 'Normalization', 'This', 'simple', 'normalization', 'technique', 'fit', 'given', 'data', 'pre-defined', 'boundary', ',', 'pre-defined', 'interval', '[', '0,1', ']', '.']

>> Bigrams are: 
 [('Min-Max', 'Normalization'), ('Normalization', 'This'), ('This', 'simple'), ('simple', 'normalization'), ('normalization', 'technique'), ('technique', 'fit'), ('fit', 'given'), ('given', 'data'), ('data', 'pre-defined'), ('pre-defined', 'boundary'), ('boundary', ','), (',', 'pre-defined'), ('pre-defined', 'interval'), ('interval', '['), ('[', '0,1'), ('0,1', ']'), (']', '.')]

>> Trigrams are: 
 [('Min-Max', 'Normalization', 'This'), ('Normalization', 'This', 'simple'), ('This', 'simple', 'normalization'), ('simple', 'normalization', 'technique'), ('normalization', 'technique', 'fit'), ('technique', 'fit', 'given'), ('fit', 'given', 'data'), ('given', 'data', 'pre-defined'), ('data', 'pre-defined', 'boundary'), ('pre-defined', 'boundary', ','), ('boundary', ',', 'pre-defined'), (',', 'pre-defined', 'interval'), ('pre-defined', 'interval', '['), ('interval', '[', '0,1'), ('[', '0,1', ']'), ('0,1', ']', '.')]

>> POS Tags are: 
 [('Min-Max', 'JJ'), ('Normalization', 'NNP'), ('This', 'DT'), ('simple', 'JJ'), ('normalization', 'NN'), ('technique', 'NN'), ('fit', 'JJ'), ('given', 'VBN'), ('data', 'NNS'), ('pre-defined', 'JJ'), ('boundary', 'JJ'), (',', ','), ('pre-defined', 'JJ'), ('interval', 'NN'), ('[', 'VBD'), ('0,1', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Min-Max/JJ Normalization/NNP)
  (NP This/DT simple/JJ normalization/NN technique/NN)
  fit/JJ
  given/VBN
  (NP data/NNS)
  pre-defined/JJ
  boundary/JJ
  ,/,
  (NP pre-defined/JJ interval/NN)
  [/VBD
  0,1/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Min-Max Normalization', 'This simple normalization technique', 'data', 'pre-defined interval', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Min-Max', 'min-max'), ('Normalization', 'normal'), ('This', 'thi'), ('simple', 'simpl'), ('normalization', 'normal'), ('technique', 'techniqu'), ('fit', 'fit'), ('given', 'given'), ('data', 'data'), ('pre-defined', 'pre-defin'), ('boundary', 'boundari'), (',', ','), ('pre-defined', 'pre-defin'), ('interval', 'interv'), ('[', '['), ('0,1', '0,1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Min-Max', 'min-max'), ('Normalization', 'normal'), ('This', 'this'), ('simple', 'simpl'), ('normalization', 'normal'), ('technique', 'techniqu'), ('fit', 'fit'), ('given', 'given'), ('data', 'data'), ('pre-defined', 'pre-defin'), ('boundary', 'boundari'), (',', ','), ('pre-defined', 'pre-defin'), ('interval', 'interv'), ('[', '['), ('0,1', '0,1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Min-Max', 'Min-Max'), ('Normalization', 'Normalization'), ('This', 'This'), ('simple', 'simple'), ('normalization', 'normalization'), ('technique', 'technique'), ('fit', 'fit'), ('given', 'given'), ('data', 'data'), ('pre-defined', 'pre-defined'), ('boundary', 'boundary'), (',', ','), ('pre-defined', 'pre-defined'), ('interval', 'interval'), ('[', '['), ('0,1', '0,1'), (']', ']'), ('.', '.')]



============================ Sentence 119 =============================

Decimal scaling In this technique we move the decimal point of values of the attribute. 


>> Tokens are: 
 ['Decimal', 'scaling', 'In', 'technique', 'move', 'decimal', 'point', 'values', 'attribute', '.']

>> Bigrams are: 
 [('Decimal', 'scaling'), ('scaling', 'In'), ('In', 'technique'), ('technique', 'move'), ('move', 'decimal'), ('decimal', 'point'), ('point', 'values'), ('values', 'attribute'), ('attribute', '.')]

>> Trigrams are: 
 [('Decimal', 'scaling', 'In'), ('scaling', 'In', 'technique'), ('In', 'technique', 'move'), ('technique', 'move', 'decimal'), ('move', 'decimal', 'point'), ('decimal', 'point', 'values'), ('point', 'values', 'attribute'), ('values', 'attribute', '.')]

>> POS Tags are: 
 [('Decimal', 'JJ'), ('scaling', 'NN'), ('In', 'IN'), ('technique', 'NN'), ('move', 'NN'), ('decimal', 'JJ'), ('point', 'NN'), ('values', 'NNS'), ('attribute', 'VBP'), ('.', '.')]

 (S
  (NP Decimal/JJ scaling/NN)
  In/IN
  (NP technique/NN move/NN)
  (NP decimal/JJ point/NN values/NNS)
  attribute/VBP
  ./.) 


>> Noun Phrases are: 
 ['Decimal scaling', 'technique move', 'decimal point values']

>> Named Entities are: 
 [('GPE', 'Decimal')] 

>> Stemming using Porter Stemmer: 
 [('Decimal', 'decim'), ('scaling', 'scale'), ('In', 'in'), ('technique', 'techniqu'), ('move', 'move'), ('decimal', 'decim'), ('point', 'point'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Decimal', 'decim'), ('scaling', 'scale'), ('In', 'in'), ('technique', 'techniqu'), ('move', 'move'), ('decimal', 'decim'), ('point', 'point'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Lemmatization: 
 [('Decimal', 'Decimal'), ('scaling', 'scaling'), ('In', 'In'), ('technique', 'technique'), ('move', 'move'), ('decimal', 'decimal'), ('point', 'point'), ('values', 'value'), ('attribute', 'attribute'), ('.', '.')]



============================ Sentence 120 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Min-max normalization Min max is a technique that helps to normalizing the data. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Min-max', 'normalization', 'Min', 'max', 'technique', 'helps', 'normalizing', 'data', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Min-max'), ('Min-max', 'normalization'), ('normalization', 'Min'), ('Min', 'max'), ('max', 'technique'), ('technique', 'helps'), ('helps', 'normalizing'), ('normalizing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Min-max'), (')', 'Min-max', 'normalization'), ('Min-max', 'normalization', 'Min'), ('normalization', 'Min', 'max'), ('Min', 'max', 'technique'), ('max', 'technique', 'helps'), ('technique', 'helps', 'normalizing'), ('helps', 'normalizing', 'data'), ('normalizing', 'data', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Min-max', 'NNP'), ('normalization', 'NN'), ('Min', 'NNP'), ('max', 'NN'), ('technique', 'NN'), ('helps', 'VBZ'), ('normalizing', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Min-max/NNP normalization/NN Min/NNP max/NN technique/NN)
  helps/VBZ
  normalizing/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Min-max normalization Min max technique', 'data']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('Min', 'min'), ('max', 'max'), ('technique', 'techniqu'), ('helps', 'help'), ('normalizing', 'normal'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('Min', 'min'), ('max', 'max'), ('technique', 'techniqu'), ('helps', 'help'), ('normalizing', 'normal'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'Min-max'), ('normalization', 'normalization'), ('Min', 'Min'), ('max', 'max'), ('technique', 'technique'), ('helps', 'help'), ('normalizing', 'normalizing'), ('data', 'data'), ('.', '.')]



============================ Sentence 121 =============================

It will scale the data between 0 and 1. 


>> Tokens are: 
 ['It', 'scale', 'data', '0', '1', '.']

>> Bigrams are: 
 [('It', 'scale'), ('scale', 'data'), ('data', '0'), ('0', '1'), ('1', '.')]

>> Trigrams are: 
 [('It', 'scale', 'data'), ('scale', 'data', '0'), ('data', '0', '1'), ('0', '1', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('scale', 'VBZ'), ('data', 'NNS'), ('0', 'CD'), ('1', 'CD'), ('.', '.')]

 (S It/PRP scale/VBZ (NP data/NNS) 0/CD 1/CD ./.) 


>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('scale', 'scale'), ('data', 'data'), ('0', '0'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('scale', 'scale'), ('data', 'data'), ('0', '0'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('scale', 'scale'), ('data', 'data'), ('0', '0'), ('1', '1'), ('.', '.')]



============================ Sentence 122 =============================

Example   	Age 	16 	20 	30 	40    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Min-max normalization (Cont..) Min : Minimum value = 16 Max : Maximum value = 40 V = Respective value of attributes. 


>> Tokens are: 
 ['Example', 'Age', '16', '20', '30', '40', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Min-max', 'normalization', '(', 'Cont', '..', ')', 'Min', ':', 'Minimum', 'value', '=', '16', 'Max', ':', 'Maximum', 'value', '=', '40', 'V', '=', 'Respective', 'value', 'attributes', '.']

>> Bigrams are: 
 [('Example', 'Age'), ('Age', '16'), ('16', '20'), ('20', '30'), ('30', '40'), ('40', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Min-max'), ('Min-max', 'normalization'), ('normalization', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Min'), ('Min', ':'), (':', 'Minimum'), ('Minimum', 'value'), ('value', '='), ('=', '16'), ('16', 'Max'), ('Max', ':'), (':', 'Maximum'), ('Maximum', 'value'), ('value', '='), ('=', '40'), ('40', 'V'), ('V', '='), ('=', 'Respective'), ('Respective', 'value'), ('value', 'attributes'), ('attributes', '.')]

>> Trigrams are: 
 [('Example', 'Age', '16'), ('Age', '16', '20'), ('16', '20', '30'), ('20', '30', '40'), ('30', '40', 'Unit'), ('40', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Min-max'), (')', 'Min-max', 'normalization'), ('Min-max', 'normalization', '('), ('normalization', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Min'), (')', 'Min', ':'), ('Min', ':', 'Minimum'), (':', 'Minimum', 'value'), ('Minimum', 'value', '='), ('value', '=', '16'), ('=', '16', 'Max'), ('16', 'Max', ':'), ('Max', ':', 'Maximum'), (':', 'Maximum', 'value'), ('Maximum', 'value', '='), ('value', '=', '40'), ('=', '40', 'V'), ('40', 'V', '='), ('V', '=', 'Respective'), ('=', 'Respective', 'value'), ('Respective', 'value', 'attributes'), ('value', 'attributes', '.')]

>> POS Tags are: 
 [('Example', 'NNP'), ('Age', 'NNP'), ('16', 'CD'), ('20', 'CD'), ('30', 'CD'), ('40', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Min-max', 'NNP'), ('normalization', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Min', 'NNP'), (':', ':'), ('Minimum', 'NNP'), ('value', 'NN'), ('=', 'VBD'), ('16', 'CD'), ('Max', 'NNP'), (':', ':'), ('Maximum', 'JJ'), ('value', 'NN'), ('=', 'VBD'), ('40', 'CD'), ('V', 'NNP'), ('=', 'NNP'), ('Respective', 'NNP'), ('value', 'NN'), ('attributes', 'VBZ'), ('.', '.')]

 (S
  (NP Example/NNP Age/NNP)
  16/CD
  20/CD
  30/CD
  40/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Min-max/NNP normalization/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Min/NNP)
  :/:
  (NP Minimum/NNP value/NN)
  =/VBD
  16/CD
  (NP Max/NNP)
  :/:
  (NP Maximum/JJ value/NN)
  =/VBD
  40/CD
  (NP V/NNP =/NNP Respective/NNP value/NN)
  attributes/VBZ
  ./.) 


>> Noun Phrases are: 
 ['Example Age', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Min-max normalization', 'Cont ..', 'Min', 'Minimum value', 'Max', 'Maximum value', 'V = Respective value']

>> Named Entities are: 
 [('PERSON', 'Example'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('Age', 'age'), ('16', '16'), ('20', '20'), ('30', '30'), ('40', '40'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Min', 'min'), (':', ':'), ('Minimum', 'minimum'), ('value', 'valu'), ('=', '='), ('16', '16'), ('Max', 'max'), (':', ':'), ('Maximum', 'maximum'), ('value', 'valu'), ('=', '='), ('40', '40'), ('V', 'v'), ('=', '='), ('Respective', 'respect'), ('value', 'valu'), ('attributes', 'attribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('Age', 'age'), ('16', '16'), ('20', '20'), ('30', '30'), ('40', '40'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Min', 'min'), (':', ':'), ('Minimum', 'minimum'), ('value', 'valu'), ('=', '='), ('16', '16'), ('Max', 'max'), (':', ':'), ('Maximum', 'maximum'), ('value', 'valu'), ('=', '='), ('40', '40'), ('V', 'v'), ('=', '='), ('Respective', 'respect'), ('value', 'valu'), ('attributes', 'attribut'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('Age', 'Age'), ('16', '16'), ('20', '20'), ('30', '30'), ('40', '40'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'Min-max'), ('normalization', 'normalization'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Min', 'Min'), (':', ':'), ('Minimum', 'Minimum'), ('value', 'value'), ('=', '='), ('16', '16'), ('Max', 'Max'), (':', ':'), ('Maximum', 'Maximum'), ('value', 'value'), ('=', '='), ('40', '40'), ('V', 'V'), ('=', '='), ('Respective', 'Respective'), ('value', 'value'), ('attributes', 'attribute'), ('.', '.')]



============================ Sentence 123 =============================

In our example V1= 16, V2=20, V3=30 & V4=40. 


>> Tokens are: 
 ['In', 'example', 'V1=', '16', ',', 'V2=20', ',', 'V3=30', '&', 'V4=40', '.']

>> Bigrams are: 
 [('In', 'example'), ('example', 'V1='), ('V1=', '16'), ('16', ','), (',', 'V2=20'), ('V2=20', ','), (',', 'V3=30'), ('V3=30', '&'), ('&', 'V4=40'), ('V4=40', '.')]

>> Trigrams are: 
 [('In', 'example', 'V1='), ('example', 'V1=', '16'), ('V1=', '16', ','), ('16', ',', 'V2=20'), (',', 'V2=20', ','), ('V2=20', ',', 'V3=30'), (',', 'V3=30', '&'), ('V3=30', '&', 'V4=40'), ('&', 'V4=40', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('example', 'NN'), ('V1=', 'NNP'), ('16', 'CD'), (',', ','), ('V2=20', 'NNP'), (',', ','), ('V3=30', 'NNP'), ('&', 'CC'), ('V4=40', 'NNP'), ('.', '.')]

 (S
  In/IN
  (NP example/NN V1=/NNP)
  16/CD
  ,/,
  (NP V2=20/NNP)
  ,/,
  (NP V3=30/NNP)
  &/CC
  (NP V4=40/NNP)
  ./.) 


>> Noun Phrases are: 
 ['example V1=', 'V2=20', 'V3=30', 'V4=40']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('example', 'exampl'), ('V1=', 'v1='), ('16', '16'), (',', ','), ('V2=20', 'v2=20'), (',', ','), ('V3=30', 'v3=30'), ('&', '&'), ('V4=40', 'v4=40'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('example', 'exampl'), ('V1=', 'v1='), ('16', '16'), (',', ','), ('V2=20', 'v2=20'), (',', ','), ('V3=30', 'v3=30'), ('&', '&'), ('V4=40', 'v4=40'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('example', 'example'), ('V1=', 'V1='), ('16', '16'), (',', ','), ('V2=20', 'V2=20'), (',', ','), ('V3=30', 'V3=30'), ('&', '&'), ('V4=40', 'V4=40'), ('.', '.')]



============================ Sentence 124 =============================

NewMax = 1 NewMin = 0  Formula : V’    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Min-max normalization (Cont..) For Age 16 : 	 MinMax (v’) = (16 – 16)/(40-16) * (1 – 0) + 0                       = 0 / 24 * 1                       = 0 For Age 20 : 	 MinMax (v’) = (20 – 16)/(40-16) * (1 – 0) + 0                        = 4 / 24 * 1                        = 0.16 Formula : V’    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  1) Min-max normalization (Cont..) 	Age 	After Min-max normalization 	16	0 	20	0.16 	30	0.58 	40	1  For Age 30 :  MinMax (v’) = (30 – 16)/(40-16) * (1 – 0) + 0                       = 14 / 24 * 1                       = 0.58 For Age 40 :  MinMax (v’) = (40 – 16)/(40-16) * (1 – 0) + 0                       = 24 / 24 * 1                       = 1   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  2) Decimal scaling In this technique we move the decimal point of values of the attribute. 


>> Tokens are: 
 ['NewMax', '=', '1', 'NewMin', '=', '0', 'Formula', ':', 'V', '’', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Min-max', 'normalization', '(', 'Cont', '..', ')', 'For', 'Age', '16', ':', 'MinMax', '(', 'v', '’', ')', '=', '(', '16', '–', '16', ')', '/', '(', '40-16', ')', '*', '(', '1', '–', '0', ')', '+', '0', '=', '0', '/', '24', '*', '1', '=', '0', 'For', 'Age', '20', ':', 'MinMax', '(', 'v', '’', ')', '=', '(', '20', '–', '16', ')', '/', '(', '40-16', ')', '*', '(', '1', '–', '0', ')', '+', '0', '=', '4', '/', '24', '*', '1', '=', '0.16', 'Formula', ':', 'V', '’', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '1', ')', 'Min-max', 'normalization', '(', 'Cont', '..', ')', 'Age', 'After', 'Min-max', 'normalization', '16', '0', '20', '0.16', '30', '0.58', '40', '1', 'For', 'Age', '30', ':', 'MinMax', '(', 'v', '’', ')', '=', '(', '30', '–', '16', ')', '/', '(', '40-16', ')', '*', '(', '1', '–', '0', ')', '+', '0', '=', '14', '/', '24', '*', '1', '=', '0.58', 'For', 'Age', '40', ':', 'MinMax', '(', 'v', '’', ')', '=', '(', '40', '–', '16', ')', '/', '(', '40-16', ')', '*', '(', '1', '–', '0', ')', '+', '0', '=', '24', '/', '24', '*', '1', '=', '1', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', '2', ')', 'Decimal', 'scaling', 'In', 'technique', 'move', 'decimal', 'point', 'values', 'attribute', '.']

>> Bigrams are: 
 [('NewMax', '='), ('=', '1'), ('1', 'NewMin'), ('NewMin', '='), ('=', '0'), ('0', 'Formula'), ('Formula', ':'), (':', 'V'), ('V', '’'), ('’', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Min-max'), ('Min-max', 'normalization'), ('normalization', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'For'), ('For', 'Age'), ('Age', '16'), ('16', ':'), (':', 'MinMax'), ('MinMax', '('), ('(', 'v'), ('v', '’'), ('’', ')'), (')', '='), ('=', '('), ('(', '16'), ('16', '–'), ('–', '16'), ('16', ')'), (')', '/'), ('/', '('), ('(', '40-16'), ('40-16', ')'), (')', '*'), ('*', '('), ('(', '1'), ('1', '–'), ('–', '0'), ('0', ')'), (')', '+'), ('+', '0'), ('0', '='), ('=', '0'), ('0', '/'), ('/', '24'), ('24', '*'), ('*', '1'), ('1', '='), ('=', '0'), ('0', 'For'), ('For', 'Age'), ('Age', '20'), ('20', ':'), (':', 'MinMax'), ('MinMax', '('), ('(', 'v'), ('v', '’'), ('’', ')'), (')', '='), ('=', '('), ('(', '20'), ('20', '–'), ('–', '16'), ('16', ')'), (')', '/'), ('/', '('), ('(', '40-16'), ('40-16', ')'), (')', '*'), ('*', '('), ('(', '1'), ('1', '–'), ('–', '0'), ('0', ')'), (')', '+'), ('+', '0'), ('0', '='), ('=', '4'), ('4', '/'), ('/', '24'), ('24', '*'), ('*', '1'), ('1', '='), ('=', '0.16'), ('0.16', 'Formula'), ('Formula', ':'), (':', 'V'), ('V', '’'), ('’', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '1'), ('1', ')'), (')', 'Min-max'), ('Min-max', 'normalization'), ('normalization', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Age'), ('Age', 'After'), ('After', 'Min-max'), ('Min-max', 'normalization'), ('normalization', '16'), ('16', '0'), ('0', '20'), ('20', '0.16'), ('0.16', '30'), ('30', '0.58'), ('0.58', '40'), ('40', '1'), ('1', 'For'), ('For', 'Age'), ('Age', '30'), ('30', ':'), (':', 'MinMax'), ('MinMax', '('), ('(', 'v'), ('v', '’'), ('’', ')'), (')', '='), ('=', '('), ('(', '30'), ('30', '–'), ('–', '16'), ('16', ')'), (')', '/'), ('/', '('), ('(', '40-16'), ('40-16', ')'), (')', '*'), ('*', '('), ('(', '1'), ('1', '–'), ('–', '0'), ('0', ')'), (')', '+'), ('+', '0'), ('0', '='), ('=', '14'), ('14', '/'), ('/', '24'), ('24', '*'), ('*', '1'), ('1', '='), ('=', '0.58'), ('0.58', 'For'), ('For', 'Age'), ('Age', '40'), ('40', ':'), (':', 'MinMax'), ('MinMax', '('), ('(', 'v'), ('v', '’'), ('’', ')'), (')', '='), ('=', '('), ('(', '40'), ('40', '–'), ('–', '16'), ('16', ')'), (')', '/'), ('/', '('), ('(', '40-16'), ('40-16', ')'), (')', '*'), ('*', '('), ('(', '1'), ('1', '–'), ('–', '0'), ('0', ')'), (')', '+'), ('+', '0'), ('0', '='), ('=', '24'), ('24', '/'), ('/', '24'), ('24', '*'), ('*', '1'), ('1', '='), ('=', '1'), ('1', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', '2'), ('2', ')'), (')', 'Decimal'), ('Decimal', 'scaling'), ('scaling', 'In'), ('In', 'technique'), ('technique', 'move'), ('move', 'decimal'), ('decimal', 'point'), ('point', 'values'), ('values', 'attribute'), ('attribute', '.')]

>> Trigrams are: 
 [('NewMax', '=', '1'), ('=', '1', 'NewMin'), ('1', 'NewMin', '='), ('NewMin', '=', '0'), ('=', '0', 'Formula'), ('0', 'Formula', ':'), ('Formula', ':', 'V'), (':', 'V', '’'), ('V', '’', 'Unit'), ('’', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Min-max'), (')', 'Min-max', 'normalization'), ('Min-max', 'normalization', '('), ('normalization', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'For'), (')', 'For', 'Age'), ('For', 'Age', '16'), ('Age', '16', ':'), ('16', ':', 'MinMax'), (':', 'MinMax', '('), ('MinMax', '(', 'v'), ('(', 'v', '’'), ('v', '’', ')'), ('’', ')', '='), (')', '=', '('), ('=', '(', '16'), ('(', '16', '–'), ('16', '–', '16'), ('–', '16', ')'), ('16', ')', '/'), (')', '/', '('), ('/', '(', '40-16'), ('(', '40-16', ')'), ('40-16', ')', '*'), (')', '*', '('), ('*', '(', '1'), ('(', '1', '–'), ('1', '–', '0'), ('–', '0', ')'), ('0', ')', '+'), (')', '+', '0'), ('+', '0', '='), ('0', '=', '0'), ('=', '0', '/'), ('0', '/', '24'), ('/', '24', '*'), ('24', '*', '1'), ('*', '1', '='), ('1', '=', '0'), ('=', '0', 'For'), ('0', 'For', 'Age'), ('For', 'Age', '20'), ('Age', '20', ':'), ('20', ':', 'MinMax'), (':', 'MinMax', '('), ('MinMax', '(', 'v'), ('(', 'v', '’'), ('v', '’', ')'), ('’', ')', '='), (')', '=', '('), ('=', '(', '20'), ('(', '20', '–'), ('20', '–', '16'), ('–', '16', ')'), ('16', ')', '/'), (')', '/', '('), ('/', '(', '40-16'), ('(', '40-16', ')'), ('40-16', ')', '*'), (')', '*', '('), ('*', '(', '1'), ('(', '1', '–'), ('1', '–', '0'), ('–', '0', ')'), ('0', ')', '+'), (')', '+', '0'), ('+', '0', '='), ('0', '=', '4'), ('=', '4', '/'), ('4', '/', '24'), ('/', '24', '*'), ('24', '*', '1'), ('*', '1', '='), ('1', '=', '0.16'), ('=', '0.16', 'Formula'), ('0.16', 'Formula', ':'), ('Formula', ':', 'V'), (':', 'V', '’'), ('V', '’', 'Unit'), ('’', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '1'), ('›', '1', ')'), ('1', ')', 'Min-max'), (')', 'Min-max', 'normalization'), ('Min-max', 'normalization', '('), ('normalization', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Age'), (')', 'Age', 'After'), ('Age', 'After', 'Min-max'), ('After', 'Min-max', 'normalization'), ('Min-max', 'normalization', '16'), ('normalization', '16', '0'), ('16', '0', '20'), ('0', '20', '0.16'), ('20', '0.16', '30'), ('0.16', '30', '0.58'), ('30', '0.58', '40'), ('0.58', '40', '1'), ('40', '1', 'For'), ('1', 'For', 'Age'), ('For', 'Age', '30'), ('Age', '30', ':'), ('30', ':', 'MinMax'), (':', 'MinMax', '('), ('MinMax', '(', 'v'), ('(', 'v', '’'), ('v', '’', ')'), ('’', ')', '='), (')', '=', '('), ('=', '(', '30'), ('(', '30', '–'), ('30', '–', '16'), ('–', '16', ')'), ('16', ')', '/'), (')', '/', '('), ('/', '(', '40-16'), ('(', '40-16', ')'), ('40-16', ')', '*'), (')', '*', '('), ('*', '(', '1'), ('(', '1', '–'), ('1', '–', '0'), ('–', '0', ')'), ('0', ')', '+'), (')', '+', '0'), ('+', '0', '='), ('0', '=', '14'), ('=', '14', '/'), ('14', '/', '24'), ('/', '24', '*'), ('24', '*', '1'), ('*', '1', '='), ('1', '=', '0.58'), ('=', '0.58', 'For'), ('0.58', 'For', 'Age'), ('For', 'Age', '40'), ('Age', '40', ':'), ('40', ':', 'MinMax'), (':', 'MinMax', '('), ('MinMax', '(', 'v'), ('(', 'v', '’'), ('v', '’', ')'), ('’', ')', '='), (')', '=', '('), ('=', '(', '40'), ('(', '40', '–'), ('40', '–', '16'), ('–', '16', ')'), ('16', ')', '/'), (')', '/', '('), ('/', '(', '40-16'), ('(', '40-16', ')'), ('40-16', ')', '*'), (')', '*', '('), ('*', '(', '1'), ('(', '1', '–'), ('1', '–', '0'), ('–', '0', ')'), ('0', ')', '+'), (')', '+', '0'), ('+', '0', '='), ('0', '=', '24'), ('=', '24', '/'), ('24', '/', '24'), ('/', '24', '*'), ('24', '*', '1'), ('*', '1', '='), ('1', '=', '1'), ('=', '1', 'Unit'), ('1', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', '2'), ('›', '2', ')'), ('2', ')', 'Decimal'), (')', 'Decimal', 'scaling'), ('Decimal', 'scaling', 'In'), ('scaling', 'In', 'technique'), ('In', 'technique', 'move'), ('technique', 'move', 'decimal'), ('move', 'decimal', 'point'), ('decimal', 'point', 'values'), ('point', 'values', 'attribute'), ('values', 'attribute', '.')]

>> POS Tags are: 
 [('NewMax', 'NNP'), ('=', 'VBD'), ('1', 'CD'), ('NewMin', 'NNP'), ('=', 'VBD'), ('0', 'CD'), ('Formula', 'NN'), (':', ':'), ('V', 'NNP'), ('’', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Min-max', 'NNP'), ('normalization', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('For', 'IN'), ('Age', '$'), ('16', 'CD'), (':', ':'), ('MinMax', 'NNP'), ('(', '('), ('v', 'FW'), ('’', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('16', 'CD'), ('–', 'RB'), ('16', 'CD'), (')', ')'), ('/', 'NN'), ('(', '('), ('40-16', 'JJ'), (')', ')'), ('*', 'NN'), ('(', '('), ('1', 'CD'), ('–', 'RB'), ('0', 'CD'), (')', ')'), ('+', 'VBD'), ('0', 'CD'), ('=', 'JJ'), ('0', 'CD'), ('/', 'JJ'), ('24', 'CD'), ('*', 'JJ'), ('1', 'CD'), ('=', '$'), ('0', 'CD'), ('For', 'IN'), ('Age', 'NNP'), ('20', 'CD'), (':', ':'), ('MinMax', 'NNP'), ('(', '('), ('v', 'FW'), ('’', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('20', 'CD'), ('–', 'RB'), ('16', 'CD'), (')', ')'), ('/', 'NN'), ('(', '('), ('40-16', 'JJ'), (')', ')'), ('*', 'NN'), ('(', '('), ('1', 'CD'), ('–', 'RB'), ('0', 'CD'), (')', ')'), ('+', 'VBD'), ('0', 'CD'), ('=', 'JJ'), ('4', 'CD'), ('/', 'JJ'), ('24', 'CD'), ('*', 'JJ'), ('1', 'CD'), ('=', 'JJ'), ('0.16', 'CD'), ('Formula', 'NN'), (':', ':'), ('V', 'NNP'), ('’', 'NNP'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('1', 'CD'), (')', ')'), ('Min-max', 'NNP'), ('normalization', 'NN'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Age', 'NNP'), ('After', 'IN'), ('Min-max', 'NNP'), ('normalization', 'NN'), ('16', 'CD'), ('0', 'CD'), ('20', 'CD'), ('0.16', 'CD'), ('30', 'CD'), ('0.58', 'CD'), ('40', 'CD'), ('1', 'CD'), ('For', 'IN'), ('Age', 'NNP'), ('30', 'CD'), (':', ':'), ('MinMax', 'NNP'), ('(', '('), ('v', 'FW'), ('’', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('30', 'CD'), ('–', 'RB'), ('16', 'CD'), (')', ')'), ('/', 'NN'), ('(', '('), ('40-16', 'JJ'), (')', ')'), ('*', 'NN'), ('(', '('), ('1', 'CD'), ('–', 'RB'), ('0', 'CD'), (')', ')'), ('+', 'VBD'), ('0', 'CD'), ('=', 'JJ'), ('14', 'CD'), ('/', 'JJ'), ('24', 'CD'), ('*', 'JJ'), ('1', 'CD'), ('=', '$'), ('0.58', 'CD'), ('For', 'IN'), ('Age', 'NNP'), ('40', 'CD'), (':', ':'), ('MinMax', 'NNP'), ('(', '('), ('v', 'FW'), ('’', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('40', 'CD'), ('–', 'RB'), ('16', 'CD'), (')', ')'), ('/', 'NN'), ('(', '('), ('40-16', 'JJ'), (')', ')'), ('*', 'NN'), ('(', '('), ('1', 'CD'), ('–', 'RB'), ('0', 'CD'), (')', ')'), ('+', 'VBD'), ('0', 'CD'), ('=', 'JJ'), ('24', 'CD'), ('/', 'JJ'), ('24', 'CD'), ('*', 'JJ'), ('1', 'CD'), ('=', 'JJ'), ('1', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('2', 'CD'), (')', ')'), ('Decimal', 'NNP'), ('scaling', 'VBG'), ('In', 'IN'), ('technique', 'NN'), ('move', 'NN'), ('decimal', 'JJ'), ('point', 'NN'), ('values', 'NNS'), ('attribute', 'VBP'), ('.', '.')]

 (S
  (NP NewMax/NNP)
  =/VBD
  1/CD
  (NP NewMin/NNP)
  =/VBD
  0/CD
  (NP Formula/NN)
  :/:
  (NP V/NNP ’/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Min-max/NNP normalization/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  For/IN
  Age/$
  16/CD
  :/:
  (NP MinMax/NNP)
  (/(
  v/FW
  (NP ’/NN)
  )/)
  (NP =/NN)
  (/(
  16/CD
  –/RB
  16/CD
  )/)
  (NP //NN)
  (/(
  40-16/JJ
  )/)
  (NP */NN)
  (/(
  1/CD
  –/RB
  0/CD
  )/)
  +/VBD
  0/CD
  =/JJ
  0/CD
  //JJ
  24/CD
  */JJ
  1/CD
  =/$
  0/CD
  For/IN
  (NP Age/NNP)
  20/CD
  :/:
  (NP MinMax/NNP)
  (/(
  v/FW
  (NP ’/NN)
  )/)
  (NP =/NN)
  (/(
  20/CD
  –/RB
  16/CD
  )/)
  (NP //NN)
  (/(
  40-16/JJ
  )/)
  (NP */NN)
  (/(
  1/CD
  –/RB
  0/CD
  )/)
  +/VBD
  0/CD
  =/JJ
  4/CD
  //JJ
  24/CD
  */JJ
  1/CD
  =/JJ
  0.16/CD
  (NP Formula/NN)
  :/:
  (NP V/NNP ’/NNP Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  1/CD
  )/)
  (NP Min-max/NNP normalization/NN)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Age/NNP)
  After/IN
  (NP Min-max/NNP normalization/NN)
  16/CD
  0/CD
  20/CD
  0.16/CD
  30/CD
  0.58/CD
  40/CD
  1/CD
  For/IN
  (NP Age/NNP)
  30/CD
  :/:
  (NP MinMax/NNP)
  (/(
  v/FW
  (NP ’/NN)
  )/)
  (NP =/NN)
  (/(
  30/CD
  –/RB
  16/CD
  )/)
  (NP //NN)
  (/(
  40-16/JJ
  )/)
  (NP */NN)
  (/(
  1/CD
  –/RB
  0/CD
  )/)
  +/VBD
  0/CD
  =/JJ
  14/CD
  //JJ
  24/CD
  */JJ
  1/CD
  =/$
  0.58/CD
  For/IN
  (NP Age/NNP)
  40/CD
  :/:
  (NP MinMax/NNP)
  (/(
  v/FW
  (NP ’/NN)
  )/)
  (NP =/NN)
  (/(
  40/CD
  –/RB
  16/CD
  )/)
  (NP //NN)
  (/(
  40-16/JJ
  )/)
  (NP */NN)
  (/(
  1/CD
  –/RB
  0/CD
  )/)
  +/VBD
  0/CD
  =/JJ
  24/CD
  //JJ
  24/CD
  */JJ
  1/CD
  =/JJ
  1/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP)
  2/CD
  )/)
  (NP Decimal/NNP)
  scaling/VBG
  In/IN
  (NP technique/NN move/NN)
  (NP decimal/JJ point/NN values/NNS)
  attribute/VBP
  ./.) 


>> Noun Phrases are: 
 ['NewMax', 'NewMin', 'Formula', 'V ’ Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Min-max normalization', 'Cont ..', 'MinMax', '’', '=', '/', '*', 'Age', 'MinMax', '’', '=', '/', '*', 'Formula', 'V ’ Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Min-max normalization', 'Cont ..', 'Age', 'Min-max normalization', 'Age', 'MinMax', '’', '=', '/', '*', 'Age', 'MinMax', '’', '=', '/', '*', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›', 'Decimal', 'technique move', 'decimal point values']

>> Named Entities are: 
 [('GPE', 'NewMax'), ('ORGANIZATION', 'NewMin'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('NewMax', 'newmax'), ('=', '='), ('1', '1'), ('NewMin', 'newmin'), ('=', '='), ('0', '0'), ('Formula', 'formula'), (':', ':'), ('V', 'v'), ('’', '’'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('For', 'for'), ('Age', 'age'), ('16', '16'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('16', '16'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('0', '0'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0', '0'), ('For', 'for'), ('Age', 'age'), ('20', '20'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('20', '20'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('4', '4'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.16', '0.16'), ('Formula', 'formula'), (':', ':'), ('V', 'v'), ('’', '’'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Age', 'age'), ('After', 'after'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('16', '16'), ('0', '0'), ('20', '20'), ('0.16', '0.16'), ('30', '30'), ('0.58', '0.58'), ('40', '40'), ('1', '1'), ('For', 'for'), ('Age', 'age'), ('30', '30'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('30', '30'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('14', '14'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.58', '0.58'), ('For', 'for'), ('Age', 'age'), ('40', '40'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('40', '40'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('24', '24'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('1', '1'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Decimal', 'decim'), ('scaling', 'scale'), ('In', 'in'), ('technique', 'techniqu'), ('move', 'move'), ('decimal', 'decim'), ('point', 'point'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NewMax', 'newmax'), ('=', '='), ('1', '1'), ('NewMin', 'newmin'), ('=', '='), ('0', '0'), ('Formula', 'formula'), (':', ':'), ('V', 'v'), ('’', '’'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('For', 'for'), ('Age', 'age'), ('16', '16'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('16', '16'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('0', '0'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0', '0'), ('For', 'for'), ('Age', 'age'), ('20', '20'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('20', '20'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('4', '4'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.16', '0.16'), ('Formula', 'formula'), (':', ':'), ('V', 'v'), ('’', '’'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Age', 'age'), ('After', 'after'), ('Min-max', 'min-max'), ('normalization', 'normal'), ('16', '16'), ('0', '0'), ('20', '20'), ('0.16', '0.16'), ('30', '30'), ('0.58', '0.58'), ('40', '40'), ('1', '1'), ('For', 'for'), ('Age', 'age'), ('30', '30'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('30', '30'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('14', '14'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.58', '0.58'), ('For', 'for'), ('Age', 'age'), ('40', '40'), (':', ':'), ('MinMax', 'minmax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('40', '40'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('24', '24'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('1', '1'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Decimal', 'decim'), ('scaling', 'scale'), ('In', 'in'), ('technique', 'techniqu'), ('move', 'move'), ('decimal', 'decim'), ('point', 'point'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Lemmatization: 
 [('NewMax', 'NewMax'), ('=', '='), ('1', '1'), ('NewMin', 'NewMin'), ('=', '='), ('0', '0'), ('Formula', 'Formula'), (':', ':'), ('V', 'V'), ('’', '’'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'Min-max'), ('normalization', 'normalization'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('For', 'For'), ('Age', 'Age'), ('16', '16'), (':', ':'), ('MinMax', 'MinMax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('16', '16'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('0', '0'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0', '0'), ('For', 'For'), ('Age', 'Age'), ('20', '20'), (':', ':'), ('MinMax', 'MinMax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('20', '20'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('4', '4'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.16', '0.16'), ('Formula', 'Formula'), (':', ':'), ('V', 'V'), ('’', '’'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('1', '1'), (')', ')'), ('Min-max', 'Min-max'), ('normalization', 'normalization'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Age', 'Age'), ('After', 'After'), ('Min-max', 'Min-max'), ('normalization', 'normalization'), ('16', '16'), ('0', '0'), ('20', '20'), ('0.16', '0.16'), ('30', '30'), ('0.58', '0.58'), ('40', '40'), ('1', '1'), ('For', 'For'), ('Age', 'Age'), ('30', '30'), (':', ':'), ('MinMax', 'MinMax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('30', '30'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('14', '14'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('0.58', '0.58'), ('For', 'For'), ('Age', 'Age'), ('40', '40'), (':', ':'), ('MinMax', 'MinMax'), ('(', '('), ('v', 'v'), ('’', '’'), (')', ')'), ('=', '='), ('(', '('), ('40', '40'), ('–', '–'), ('16', '16'), (')', ')'), ('/', '/'), ('(', '('), ('40-16', '40-16'), (')', ')'), ('*', '*'), ('(', '('), ('1', '1'), ('–', '–'), ('0', '0'), (')', ')'), ('+', '+'), ('0', '0'), ('=', '='), ('24', '24'), ('/', '/'), ('24', '24'), ('*', '*'), ('1', '1'), ('=', '='), ('1', '1'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('2', '2'), (')', ')'), ('Decimal', 'Decimal'), ('scaling', 'scaling'), ('In', 'In'), ('technique', 'technique'), ('move', 'move'), ('decimal', 'decimal'), ('point', 'point'), ('values', 'value'), ('attribute', 'attribute'), ('.', '.')]



============================ Sentence 125 =============================

This movement of decimal points totally depends on the maximum value among all values in the attribute. 


>> Tokens are: 
 ['This', 'movement', 'decimal', 'points', 'totally', 'depends', 'maximum', 'value', 'among', 'values', 'attribute', '.']

>> Bigrams are: 
 [('This', 'movement'), ('movement', 'decimal'), ('decimal', 'points'), ('points', 'totally'), ('totally', 'depends'), ('depends', 'maximum'), ('maximum', 'value'), ('value', 'among'), ('among', 'values'), ('values', 'attribute'), ('attribute', '.')]

>> Trigrams are: 
 [('This', 'movement', 'decimal'), ('movement', 'decimal', 'points'), ('decimal', 'points', 'totally'), ('points', 'totally', 'depends'), ('totally', 'depends', 'maximum'), ('depends', 'maximum', 'value'), ('maximum', 'value', 'among'), ('value', 'among', 'values'), ('among', 'values', 'attribute'), ('values', 'attribute', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('movement', 'NN'), ('decimal', 'JJ'), ('points', 'NNS'), ('totally', 'RB'), ('depends', 'VBZ'), ('maximum', 'JJ'), ('value', 'NN'), ('among', 'IN'), ('values', 'NNS'), ('attribute', 'VBP'), ('.', '.')]

 (S
  (NP This/DT movement/NN)
  (NP decimal/JJ points/NNS)
  totally/RB
  depends/VBZ
  (NP maximum/JJ value/NN)
  among/IN
  (NP values/NNS)
  attribute/VBP
  ./.) 


>> Noun Phrases are: 
 ['This movement', 'decimal points', 'maximum value', 'values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('movement', 'movement'), ('decimal', 'decim'), ('points', 'point'), ('totally', 'total'), ('depends', 'depend'), ('maximum', 'maximum'), ('value', 'valu'), ('among', 'among'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('movement', 'movement'), ('decimal', 'decim'), ('points', 'point'), ('totally', 'total'), ('depends', 'depend'), ('maximum', 'maximum'), ('value', 'valu'), ('among', 'among'), ('values', 'valu'), ('attribute', 'attribut'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('movement', 'movement'), ('decimal', 'decimal'), ('points', 'point'), ('totally', 'totally'), ('depends', 'depends'), ('maximum', 'maximum'), ('value', 'value'), ('among', 'among'), ('values', 'value'), ('attribute', 'attribute'), ('.', '.')]



============================ Sentence 126 =============================

Value V of attribute A can be normalized by the following formula 		Normalized value of attribute = (vi / 10j)     	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Decimal scaling  - Example 	CGPA	Formula	After Decimal Scaling 	2	2 / 10 	0.2 	3	3 / 10 	0.3  We will check maximum value among our attribute CGPA. 


>> Tokens are: 
 ['Value', 'V', 'attribute', 'A', 'normalized', 'following', 'formula', 'Normalized', 'value', 'attribute', '=', '(', 'vi', '/', '10j', ')', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Decimal', 'scaling', '-', 'Example', 'CGPA', 'Formula', 'After', 'Decimal', 'Scaling', '2', '2', '/', '10', '0.2', '3', '3', '/', '10', '0.3', 'We', 'check', 'maximum', 'value', 'among', 'attribute', 'CGPA', '.']

>> Bigrams are: 
 [('Value', 'V'), ('V', 'attribute'), ('attribute', 'A'), ('A', 'normalized'), ('normalized', 'following'), ('following', 'formula'), ('formula', 'Normalized'), ('Normalized', 'value'), ('value', 'attribute'), ('attribute', '='), ('=', '('), ('(', 'vi'), ('vi', '/'), ('/', '10j'), ('10j', ')'), (')', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Decimal'), ('Decimal', 'scaling'), ('scaling', '-'), ('-', 'Example'), ('Example', 'CGPA'), ('CGPA', 'Formula'), ('Formula', 'After'), ('After', 'Decimal'), ('Decimal', 'Scaling'), ('Scaling', '2'), ('2', '2'), ('2', '/'), ('/', '10'), ('10', '0.2'), ('0.2', '3'), ('3', '3'), ('3', '/'), ('/', '10'), ('10', '0.3'), ('0.3', 'We'), ('We', 'check'), ('check', 'maximum'), ('maximum', 'value'), ('value', 'among'), ('among', 'attribute'), ('attribute', 'CGPA'), ('CGPA', '.')]

>> Trigrams are: 
 [('Value', 'V', 'attribute'), ('V', 'attribute', 'A'), ('attribute', 'A', 'normalized'), ('A', 'normalized', 'following'), ('normalized', 'following', 'formula'), ('following', 'formula', 'Normalized'), ('formula', 'Normalized', 'value'), ('Normalized', 'value', 'attribute'), ('value', 'attribute', '='), ('attribute', '=', '('), ('=', '(', 'vi'), ('(', 'vi', '/'), ('vi', '/', '10j'), ('/', '10j', ')'), ('10j', ')', 'Unit'), (')', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Decimal'), ('›', 'Decimal', 'scaling'), ('Decimal', 'scaling', '-'), ('scaling', '-', 'Example'), ('-', 'Example', 'CGPA'), ('Example', 'CGPA', 'Formula'), ('CGPA', 'Formula', 'After'), ('Formula', 'After', 'Decimal'), ('After', 'Decimal', 'Scaling'), ('Decimal', 'Scaling', '2'), ('Scaling', '2', '2'), ('2', '2', '/'), ('2', '/', '10'), ('/', '10', '0.2'), ('10', '0.2', '3'), ('0.2', '3', '3'), ('3', '3', '/'), ('3', '/', '10'), ('/', '10', '0.3'), ('10', '0.3', 'We'), ('0.3', 'We', 'check'), ('We', 'check', 'maximum'), ('check', 'maximum', 'value'), ('maximum', 'value', 'among'), ('value', 'among', 'attribute'), ('among', 'attribute', 'CGPA'), ('attribute', 'CGPA', '.')]

>> POS Tags are: 
 [('Value', 'NNP'), ('V', 'NNP'), ('attribute', 'VB'), ('A', 'NNP'), ('normalized', 'JJ'), ('following', 'VBG'), ('formula', 'NN'), ('Normalized', 'NNP'), ('value', 'NN'), ('attribute', 'NN'), ('=', 'NNP'), ('(', '('), ('vi', 'JJ'), ('/', 'NNP'), ('10j', 'CD'), (')', ')'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Decimal', 'NNP'), ('scaling', 'VBG'), ('-', ':'), ('Example', 'NN'), ('CGPA', 'NNP'), ('Formula', 'NNP'), ('After', 'IN'), ('Decimal', 'NNP'), ('Scaling', 'VBG'), ('2', 'CD'), ('2', 'CD'), ('/', 'NN'), ('10', 'CD'), ('0.2', 'CD'), ('3', 'CD'), ('3', 'CD'), ('/', 'NN'), ('10', 'CD'), ('0.3', 'CD'), ('We', 'PRP'), ('check', 'VBP'), ('maximum', 'JJ'), ('value', 'NN'), ('among', 'IN'), ('attribute', 'JJ'), ('CGPA', 'NNP'), ('.', '.')]

 (S
  (NP Value/NNP V/NNP)
  attribute/VB
  (NP A/NNP)
  normalized/JJ
  following/VBG
  (NP formula/NN Normalized/NNP value/NN attribute/NN =/NNP)
  (/(
  (NP vi/JJ //NNP)
  10j/CD
  )/)
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Decimal/NNP)
  scaling/VBG
  -/:
  (NP Example/NN CGPA/NNP Formula/NNP)
  After/IN
  (NP Decimal/NNP)
  Scaling/VBG
  2/CD
  2/CD
  (NP //NN)
  10/CD
  0.2/CD
  3/CD
  3/CD
  (NP //NN)
  10/CD
  0.3/CD
  We/PRP
  check/VBP
  (NP maximum/JJ value/NN)
  among/IN
  (NP attribute/JJ CGPA/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Value V', 'A', 'formula Normalized value attribute =', 'vi /', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Decimal', 'Example CGPA Formula', 'Decimal', '/', '/', 'maximum value', 'attribute CGPA']

>> Named Entities are: 
 [('PERSON', 'Value'), ('GPE', 'Normalized'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Example CGPA Formula'), ('ORGANIZATION', 'CGPA')] 

>> Stemming using Porter Stemmer: 
 [('Value', 'valu'), ('V', 'v'), ('attribute', 'attribut'), ('A', 'a'), ('normalized', 'normal'), ('following', 'follow'), ('formula', 'formula'), ('Normalized', 'normal'), ('value', 'valu'), ('attribute', 'attribut'), ('=', '='), ('(', '('), ('vi', 'vi'), ('/', '/'), ('10j', '10j'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'decim'), ('scaling', 'scale'), ('-', '-'), ('Example', 'exampl'), ('CGPA', 'cgpa'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('2', '2'), ('2', '2'), ('/', '/'), ('10', '10'), ('0.2', '0.2'), ('3', '3'), ('3', '3'), ('/', '/'), ('10', '10'), ('0.3', '0.3'), ('We', 'we'), ('check', 'check'), ('maximum', 'maximum'), ('value', 'valu'), ('among', 'among'), ('attribute', 'attribut'), ('CGPA', 'cgpa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Value', 'valu'), ('V', 'v'), ('attribute', 'attribut'), ('A', 'a'), ('normalized', 'normal'), ('following', 'follow'), ('formula', 'formula'), ('Normalized', 'normal'), ('value', 'valu'), ('attribute', 'attribut'), ('=', '='), ('(', '('), ('vi', 'vi'), ('/', '/'), ('10j', '10j'), (')', ')'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'decim'), ('scaling', 'scale'), ('-', '-'), ('Example', 'exampl'), ('CGPA', 'cgpa'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('2', '2'), ('2', '2'), ('/', '/'), ('10', '10'), ('0.2', '0.2'), ('3', '3'), ('3', '3'), ('/', '/'), ('10', '10'), ('0.3', '0.3'), ('We', 'we'), ('check', 'check'), ('maximum', 'maximum'), ('value', 'valu'), ('among', 'among'), ('attribute', 'attribut'), ('CGPA', 'cgpa'), ('.', '.')]

>> Lemmatization: 
 [('Value', 'Value'), ('V', 'V'), ('attribute', 'attribute'), ('A', 'A'), ('normalized', 'normalized'), ('following', 'following'), ('formula', 'formula'), ('Normalized', 'Normalized'), ('value', 'value'), ('attribute', 'attribute'), ('=', '='), ('(', '('), ('vi', 'vi'), ('/', '/'), ('10j', '10j'), (')', ')'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'Decimal'), ('scaling', 'scaling'), ('-', '-'), ('Example', 'Example'), ('CGPA', 'CGPA'), ('Formula', 'Formula'), ('After', 'After'), ('Decimal', 'Decimal'), ('Scaling', 'Scaling'), ('2', '2'), ('2', '2'), ('/', '/'), ('10', '10'), ('0.2', '0.2'), ('3', '3'), ('3', '3'), ('/', '/'), ('10', '10'), ('0.3', '0.3'), ('We', 'We'), ('check', 'check'), ('maximum', 'maximum'), ('value', 'value'), ('among', 'among'), ('attribute', 'attribute'), ('CGPA', 'CGPA'), ('.', '.')]



============================ Sentence 127 =============================

Maximum value is 3 so, we can convert it into decimal by dividing with 10. why 10? 


>> Tokens are: 
 ['Maximum', 'value', '3', ',', 'convert', 'decimal', 'dividing', '10.', '10', '?']

>> Bigrams are: 
 [('Maximum', 'value'), ('value', '3'), ('3', ','), (',', 'convert'), ('convert', 'decimal'), ('decimal', 'dividing'), ('dividing', '10.'), ('10.', '10'), ('10', '?')]

>> Trigrams are: 
 [('Maximum', 'value', '3'), ('value', '3', ','), ('3', ',', 'convert'), (',', 'convert', 'decimal'), ('convert', 'decimal', 'dividing'), ('decimal', 'dividing', '10.'), ('dividing', '10.', '10'), ('10.', '10', '?')]

>> POS Tags are: 
 [('Maximum', 'NNP'), ('value', 'NN'), ('3', 'CD'), (',', ','), ('convert', 'VBP'), ('decimal', 'JJ'), ('dividing', 'VBG'), ('10.', 'CD'), ('10', 'CD'), ('?', '.')]

 (S
  (NP Maximum/NNP value/NN)
  3/CD
  ,/,
  convert/VBP
  decimal/JJ
  dividing/VBG
  10./CD
  10/CD
  ?/.) 


>> Noun Phrases are: 
 ['Maximum value']

>> Named Entities are: 
 [('GPE', 'Maximum')] 

>> Stemming using Porter Stemmer: 
 [('Maximum', 'maximum'), ('value', 'valu'), ('3', '3'), (',', ','), ('convert', 'convert'), ('decimal', 'decim'), ('dividing', 'divid'), ('10.', '10.'), ('10', '10'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Maximum', 'maximum'), ('value', 'valu'), ('3', '3'), (',', ','), ('convert', 'convert'), ('decimal', 'decim'), ('dividing', 'divid'), ('10.', '10.'), ('10', '10'), ('?', '?')]

>> Lemmatization: 
 [('Maximum', 'Maximum'), ('value', 'value'), ('3', '3'), (',', ','), ('convert', 'convert'), ('decimal', 'decimal'), ('dividing', 'dividing'), ('10.', '10.'), ('10', '10'), ('?', '?')]



============================ Sentence 128 =============================

We will count total digits in our maximum value and then put 1. 


>> Tokens are: 
 ['We', 'count', 'total', 'digits', 'maximum', 'value', 'put', '1', '.']

>> Bigrams are: 
 [('We', 'count'), ('count', 'total'), ('total', 'digits'), ('digits', 'maximum'), ('maximum', 'value'), ('value', 'put'), ('put', '1'), ('1', '.')]

>> Trigrams are: 
 [('We', 'count', 'total'), ('count', 'total', 'digits'), ('total', 'digits', 'maximum'), ('digits', 'maximum', 'value'), ('maximum', 'value', 'put'), ('value', 'put', '1'), ('put', '1', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('count', 'VBP'), ('total', 'JJ'), ('digits', 'NNS'), ('maximum', 'JJ'), ('value', 'NN'), ('put', 'VBD'), ('1', 'CD'), ('.', '.')]

 (S
  We/PRP
  count/VBP
  (NP total/JJ digits/NNS)
  (NP maximum/JJ value/NN)
  put/VBD
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['total digits', 'maximum value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('count', 'count'), ('total', 'total'), ('digits', 'digit'), ('maximum', 'maximum'), ('value', 'valu'), ('put', 'put'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('count', 'count'), ('total', 'total'), ('digits', 'digit'), ('maximum', 'maximum'), ('value', 'valu'), ('put', 'put'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('count', 'count'), ('total', 'total'), ('digits', 'digit'), ('maximum', 'maximum'), ('value', 'value'), ('put', 'put'), ('1', '1'), ('.', '.')]



============================ Sentence 129 =============================

After 1 we can put zeros equal to the length of maximum value. 


>> Tokens are: 
 ['After', '1', 'put', 'zeros', 'equal', 'length', 'maximum', 'value', '.']

>> Bigrams are: 
 [('After', '1'), ('1', 'put'), ('put', 'zeros'), ('zeros', 'equal'), ('equal', 'length'), ('length', 'maximum'), ('maximum', 'value'), ('value', '.')]

>> Trigrams are: 
 [('After', '1', 'put'), ('1', 'put', 'zeros'), ('put', 'zeros', 'equal'), ('zeros', 'equal', 'length'), ('equal', 'length', 'maximum'), ('length', 'maximum', 'value'), ('maximum', 'value', '.')]

>> POS Tags are: 
 [('After', 'IN'), ('1', 'CD'), ('put', 'VBD'), ('zeros', 'CD'), ('equal', 'JJ'), ('length', 'NN'), ('maximum', 'NN'), ('value', 'NN'), ('.', '.')]

 (S
  After/IN
  1/CD
  put/VBD
  zeros/CD
  (NP equal/JJ length/NN maximum/NN value/NN)
  ./.) 


>> Noun Phrases are: 
 ['equal length maximum value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), ('1', '1'), ('put', 'put'), ('zeros', 'zero'), ('equal', 'equal'), ('length', 'length'), ('maximum', 'maximum'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), ('1', '1'), ('put', 'put'), ('zeros', 'zero'), ('equal', 'equal'), ('length', 'length'), ('maximum', 'maximum'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), ('1', '1'), ('put', 'put'), ('zeros', 'zero'), ('equal', 'equal'), ('length', 'length'), ('maximum', 'maximum'), ('value', 'value'), ('.', '.')]



============================ Sentence 130 =============================

Here 3 is maximum value and total digits in this value is only 1 so, we will put one zero after 1. 


>> Tokens are: 
 ['Here', '3', 'maximum', 'value', 'total', 'digits', 'value', '1', ',', 'put', 'one', 'zero', '1', '.']

>> Bigrams are: 
 [('Here', '3'), ('3', 'maximum'), ('maximum', 'value'), ('value', 'total'), ('total', 'digits'), ('digits', 'value'), ('value', '1'), ('1', ','), (',', 'put'), ('put', 'one'), ('one', 'zero'), ('zero', '1'), ('1', '.')]

>> Trigrams are: 
 [('Here', '3', 'maximum'), ('3', 'maximum', 'value'), ('maximum', 'value', 'total'), ('value', 'total', 'digits'), ('total', 'digits', 'value'), ('digits', 'value', '1'), ('value', '1', ','), ('1', ',', 'put'), (',', 'put', 'one'), ('put', 'one', 'zero'), ('one', 'zero', '1'), ('zero', '1', '.')]

>> POS Tags are: 
 [('Here', 'RB'), ('3', 'CD'), ('maximum', 'JJ'), ('value', 'NN'), ('total', 'JJ'), ('digits', 'VBZ'), ('value', 'NN'), ('1', 'CD'), (',', ','), ('put', 'VBD'), ('one', 'CD'), ('zero', 'NN'), ('1', 'CD'), ('.', '.')]

 (S
  Here/RB
  3/CD
  (NP maximum/JJ value/NN)
  total/JJ
  digits/VBZ
  (NP value/NN)
  1/CD
  ,/,
  put/VBD
  one/CD
  (NP zero/NN)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['maximum value', 'value', 'zero']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('3', '3'), ('maximum', 'maximum'), ('value', 'valu'), ('total', 'total'), ('digits', 'digit'), ('value', 'valu'), ('1', '1'), (',', ','), ('put', 'put'), ('one', 'one'), ('zero', 'zero'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('3', '3'), ('maximum', 'maximum'), ('value', 'valu'), ('total', 'total'), ('digits', 'digit'), ('value', 'valu'), ('1', '1'), (',', ','), ('put', 'put'), ('one', 'one'), ('zero', 'zero'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), ('3', '3'), ('maximum', 'maximum'), ('value', 'value'), ('total', 'total'), ('digits', 'digit'), ('value', 'value'), ('1', '1'), (',', ','), ('put', 'put'), ('one', 'one'), ('zero', 'zero'), ('1', '1'), ('.', '.')]



============================ Sentence 131 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Decimal scaling (Try it!) 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Decimal', 'scaling', '(', 'Try', '!', ')']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Decimal'), ('Decimal', 'scaling'), ('scaling', '('), ('(', 'Try'), ('Try', '!'), ('!', ')')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Decimal'), ('›', 'Decimal', 'scaling'), ('Decimal', 'scaling', '('), ('scaling', '(', 'Try'), ('(', 'Try', '!'), ('Try', '!', ')')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Decimal', 'NNP'), ('scaling', 'NN'), ('(', '('), ('Try', 'NNP'), ('!', '.'), (')', ')')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Decimal/NNP scaling/NN)
  (/(
  (NP Try/NNP)
  !/.
  )/)) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Decimal scaling', 'Try']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Try')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'decim'), ('scaling', 'scale'), ('(', '('), ('Try', 'tri'), ('!', '!'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'decim'), ('scaling', 'scale'), ('(', '('), ('Try', 'tri'), ('!', '!'), (')', ')')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Decimal', 'Decimal'), ('scaling', 'scaling'), ('(', '('), ('Try', 'Try'), ('!', '!'), (')', ')')]



============================ Sentence 132 =============================

Bonus	Formula	After Decimal Scaling 	400	400/1000	0.4 	310	310/1000	0.31  	Salary	Formula	After Decimal Scaling 	40,000	40000/100000	0.4 	31,000	31000/100000	0.31    	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Transformation (Cont..) Discretization Discretization techniques can be categorized based on how the separation is performed, such as whether it uses class information or which direction it proceeds (top-down or bottom-up). 


>> Tokens are: 
 ['Bonus', 'Formula', 'After', 'Decimal', 'Scaling', '400', '400/1000', '0.4', '310', '310/1000', '0.31', 'Salary', 'Formula', 'After', 'Decimal', 'Scaling', '40,000', '40000/100000', '0.4', '31,000', '31000/100000', '0.31', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Transformation', '(', 'Cont', '..', ')', 'Discretization', 'Discretization', 'techniques', 'categorized', 'based', 'separation', 'performed', ',', 'whether', 'uses', 'class', 'information', 'direction', 'proceeds', '(', 'top-down', 'bottom-up', ')', '.']

>> Bigrams are: 
 [('Bonus', 'Formula'), ('Formula', 'After'), ('After', 'Decimal'), ('Decimal', 'Scaling'), ('Scaling', '400'), ('400', '400/1000'), ('400/1000', '0.4'), ('0.4', '310'), ('310', '310/1000'), ('310/1000', '0.31'), ('0.31', 'Salary'), ('Salary', 'Formula'), ('Formula', 'After'), ('After', 'Decimal'), ('Decimal', 'Scaling'), ('Scaling', '40,000'), ('40,000', '40000/100000'), ('40000/100000', '0.4'), ('0.4', '31,000'), ('31,000', '31000/100000'), ('31000/100000', '0.31'), ('0.31', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Transformation'), ('Transformation', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Discretization'), ('Discretization', 'Discretization'), ('Discretization', 'techniques'), ('techniques', 'categorized'), ('categorized', 'based'), ('based', 'separation'), ('separation', 'performed'), ('performed', ','), (',', 'whether'), ('whether', 'uses'), ('uses', 'class'), ('class', 'information'), ('information', 'direction'), ('direction', 'proceeds'), ('proceeds', '('), ('(', 'top-down'), ('top-down', 'bottom-up'), ('bottom-up', ')'), (')', '.')]

>> Trigrams are: 
 [('Bonus', 'Formula', 'After'), ('Formula', 'After', 'Decimal'), ('After', 'Decimal', 'Scaling'), ('Decimal', 'Scaling', '400'), ('Scaling', '400', '400/1000'), ('400', '400/1000', '0.4'), ('400/1000', '0.4', '310'), ('0.4', '310', '310/1000'), ('310', '310/1000', '0.31'), ('310/1000', '0.31', 'Salary'), ('0.31', 'Salary', 'Formula'), ('Salary', 'Formula', 'After'), ('Formula', 'After', 'Decimal'), ('After', 'Decimal', 'Scaling'), ('Decimal', 'Scaling', '40,000'), ('Scaling', '40,000', '40000/100000'), ('40,000', '40000/100000', '0.4'), ('40000/100000', '0.4', '31,000'), ('0.4', '31,000', '31000/100000'), ('31,000', '31000/100000', '0.31'), ('31000/100000', '0.31', 'Unit'), ('0.31', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Transformation'), ('Data', 'Transformation', '('), ('Transformation', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Discretization'), (')', 'Discretization', 'Discretization'), ('Discretization', 'Discretization', 'techniques'), ('Discretization', 'techniques', 'categorized'), ('techniques', 'categorized', 'based'), ('categorized', 'based', 'separation'), ('based', 'separation', 'performed'), ('separation', 'performed', ','), ('performed', ',', 'whether'), (',', 'whether', 'uses'), ('whether', 'uses', 'class'), ('uses', 'class', 'information'), ('class', 'information', 'direction'), ('information', 'direction', 'proceeds'), ('direction', 'proceeds', '('), ('proceeds', '(', 'top-down'), ('(', 'top-down', 'bottom-up'), ('top-down', 'bottom-up', ')'), ('bottom-up', ')', '.')]

>> POS Tags are: 
 [('Bonus', 'NNP'), ('Formula', 'NNP'), ('After', 'IN'), ('Decimal', 'NNP'), ('Scaling', 'VBG'), ('400', 'CD'), ('400/1000', 'CD'), ('0.4', 'CD'), ('310', 'CD'), ('310/1000', 'CD'), ('0.31', 'CD'), ('Salary', 'NNP'), ('Formula', 'NNP'), ('After', 'IN'), ('Decimal', 'NNP'), ('Scaling', 'VBG'), ('40,000', 'CD'), ('40000/100000', 'CD'), ('0.4', 'CD'), ('31,000', 'CD'), ('31000/100000', 'CD'), ('0.31', 'CD'), ('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Transformation', 'NNP'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Discretization', 'NNP'), ('Discretization', 'NNP'), ('techniques', 'NNS'), ('categorized', 'VBD'), ('based', 'VBN'), ('separation', 'NN'), ('performed', 'VBN'), (',', ','), ('whether', 'IN'), ('uses', 'JJ'), ('class', 'NN'), ('information', 'NN'), ('direction', 'NN'), ('proceeds', 'NNS'), ('(', '('), ('top-down', 'JJ'), ('bottom-up', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Bonus/NNP Formula/NNP)
  After/IN
  (NP Decimal/NNP)
  Scaling/VBG
  400/CD
  400/1000/CD
  0.4/CD
  310/CD
  310/1000/CD
  0.31/CD
  (NP Salary/NNP Formula/NNP)
  After/IN
  (NP Decimal/NNP)
  Scaling/VBG
  40,000/CD
  40000/100000/CD
  0.4/CD
  31,000/CD
  31000/100000/CD
  0.31/CD
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Transformation/NNP)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Discretization/NNP Discretization/NNP techniques/NNS)
  categorized/VBD
  based/VBN
  (NP separation/NN)
  performed/VBN
  ,/,
  whether/IN
  (NP uses/JJ class/NN information/NN direction/NN proceeds/NNS)
  (/(
  (NP top-down/JJ bottom-up/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Bonus Formula', 'Decimal', 'Salary Formula', 'Decimal', 'Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Transformation', 'Cont ..', 'Discretization Discretization techniques', 'separation', 'uses class information direction proceeds', 'top-down bottom-up']

>> Named Entities are: 
 [('PERSON', 'Bonus'), ('ORGANIZATION', 'Formula'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('ORGANIZATION', 'Discretization Discretization')] 

>> Stemming using Porter Stemmer: 
 [('Bonus', 'bonu'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('400', '400'), ('400/1000', '400/1000'), ('0.4', '0.4'), ('310', '310'), ('310/1000', '310/1000'), ('0.31', '0.31'), ('Salary', 'salari'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('40,000', '40,000'), ('40000/100000', '40000/100000'), ('0.4', '0.4'), ('31,000', '31,000'), ('31000/100000', '31000/100000'), ('0.31', '0.31'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Discretization', 'discret'), ('Discretization', 'discret'), ('techniques', 'techniqu'), ('categorized', 'categor'), ('based', 'base'), ('separation', 'separ'), ('performed', 'perform'), (',', ','), ('whether', 'whether'), ('uses', 'use'), ('class', 'class'), ('information', 'inform'), ('direction', 'direct'), ('proceeds', 'proce'), ('(', '('), ('top-down', 'top-down'), ('bottom-up', 'bottom-up'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bonus', 'bonus'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('400', '400'), ('400/1000', '400/1000'), ('0.4', '0.4'), ('310', '310'), ('310/1000', '310/1000'), ('0.31', '0.31'), ('Salary', 'salari'), ('Formula', 'formula'), ('After', 'after'), ('Decimal', 'decim'), ('Scaling', 'scale'), ('40,000', '40,000'), ('40000/100000', '40000/100000'), ('0.4', '0.4'), ('31,000', '31,000'), ('31000/100000', '31000/100000'), ('0.31', '0.31'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Transformation', 'transform'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Discretization', 'discret'), ('Discretization', 'discret'), ('techniques', 'techniqu'), ('categorized', 'categor'), ('based', 'base'), ('separation', 'separ'), ('performed', 'perform'), (',', ','), ('whether', 'whether'), ('uses', 'use'), ('class', 'class'), ('information', 'inform'), ('direction', 'direct'), ('proceeds', 'proceed'), ('(', '('), ('top-down', 'top-down'), ('bottom-up', 'bottom-up'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Bonus', 'Bonus'), ('Formula', 'Formula'), ('After', 'After'), ('Decimal', 'Decimal'), ('Scaling', 'Scaling'), ('400', '400'), ('400/1000', '400/1000'), ('0.4', '0.4'), ('310', '310'), ('310/1000', '310/1000'), ('0.31', '0.31'), ('Salary', 'Salary'), ('Formula', 'Formula'), ('After', 'After'), ('Decimal', 'Decimal'), ('Scaling', 'Scaling'), ('40,000', '40,000'), ('40000/100000', '40000/100000'), ('0.4', '0.4'), ('31,000', '31,000'), ('31000/100000', '31000/100000'), ('0.31', '0.31'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Transformation', 'Transformation'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Discretization', 'Discretization'), ('Discretization', 'Discretization'), ('techniques', 'technique'), ('categorized', 'categorized'), ('based', 'based'), ('separation', 'separation'), ('performed', 'performed'), (',', ','), ('whether', 'whether'), ('uses', 'us'), ('class', 'class'), ('information', 'information'), ('direction', 'direction'), ('proceeds', 'proceeds'), ('(', '('), ('top-down', 'top-down'), ('bottom-up', 'bottom-up'), (')', ')'), ('.', '.')]



============================ Sentence 133 =============================

The raw values of a numeric attribute (e.g.-.- age) are replaced by interval labels (e.g.-.- 0-10, 11-20 etc.) 


>> Tokens are: 
 ['The', 'raw', 'values', 'numeric', 'attribute', '(', 'e.g.-.-', 'age', ')', 'replaced', 'interval', 'labels', '(', 'e.g.-.-', '0-10', ',', '11-20', 'etc', '.', ')']

>> Bigrams are: 
 [('The', 'raw'), ('raw', 'values'), ('values', 'numeric'), ('numeric', 'attribute'), ('attribute', '('), ('(', 'e.g.-.-'), ('e.g.-.-', 'age'), ('age', ')'), (')', 'replaced'), ('replaced', 'interval'), ('interval', 'labels'), ('labels', '('), ('(', 'e.g.-.-'), ('e.g.-.-', '0-10'), ('0-10', ','), (',', '11-20'), ('11-20', 'etc'), ('etc', '.'), ('.', ')')]

>> Trigrams are: 
 [('The', 'raw', 'values'), ('raw', 'values', 'numeric'), ('values', 'numeric', 'attribute'), ('numeric', 'attribute', '('), ('attribute', '(', 'e.g.-.-'), ('(', 'e.g.-.-', 'age'), ('e.g.-.-', 'age', ')'), ('age', ')', 'replaced'), (')', 'replaced', 'interval'), ('replaced', 'interval', 'labels'), ('interval', 'labels', '('), ('labels', '(', 'e.g.-.-'), ('(', 'e.g.-.-', '0-10'), ('e.g.-.-', '0-10', ','), ('0-10', ',', '11-20'), (',', '11-20', 'etc'), ('11-20', 'etc', '.'), ('etc', '.', ')')]

>> POS Tags are: 
 [('The', 'DT'), ('raw', 'JJ'), ('values', 'NNS'), ('numeric', 'JJ'), ('attribute', 'NN'), ('(', '('), ('e.g.-.-', 'JJ'), ('age', 'NN'), (')', ')'), ('replaced', 'VBD'), ('interval', 'JJ'), ('labels', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), ('0-10', 'NN'), (',', ','), ('11-20', 'JJ'), ('etc', 'NN'), ('.', '.'), (')', ')')]

 (S
  (NP The/DT raw/JJ values/NNS)
  (NP numeric/JJ attribute/NN)
  (/(
  (NP e.g.-.-/JJ age/NN)
  )/)
  replaced/VBD
  (NP interval/JJ labels/NNS)
  (/(
  (NP e.g.-.-/JJ 0-10/NN)
  ,/,
  (NP 11-20/JJ etc/NN)
  ./.
  )/)) 


>> Noun Phrases are: 
 ['The raw values', 'numeric attribute', 'e.g.-.- age', 'interval labels', 'e.g.-.- 0-10', '11-20 etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('raw', 'raw'), ('values', 'valu'), ('numeric', 'numer'), ('attribute', 'attribut'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('age', 'age'), (')', ')'), ('replaced', 'replac'), ('interval', 'interv'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('0-10', '0-10'), (',', ','), ('11-20', '11-20'), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('raw', 'raw'), ('values', 'valu'), ('numeric', 'numer'), ('attribute', 'attribut'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('age', 'age'), (')', ')'), ('replaced', 'replac'), ('interval', 'interv'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('0-10', '0-10'), (',', ','), ('11-20', '11-20'), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('The', 'The'), ('raw', 'raw'), ('values', 'value'), ('numeric', 'numeric'), ('attribute', 'attribute'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('age', 'age'), (')', ')'), ('replaced', 'replaced'), ('interval', 'interval'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('0-10', '0-10'), (',', ','), ('11-20', '11-20'), ('etc', 'etc'), ('.', '.'), (')', ')')]



============================ Sentence 134 =============================

or conceptual labels (e.g.-.- youth, adult, senior). 


>> Tokens are: 
 ['conceptual', 'labels', '(', 'e.g.-.-', 'youth', ',', 'adult', ',', 'senior', ')', '.']

>> Bigrams are: 
 [('conceptual', 'labels'), ('labels', '('), ('(', 'e.g.-.-'), ('e.g.-.-', 'youth'), ('youth', ','), (',', 'adult'), ('adult', ','), (',', 'senior'), ('senior', ')'), (')', '.')]

>> Trigrams are: 
 [('conceptual', 'labels', '('), ('labels', '(', 'e.g.-.-'), ('(', 'e.g.-.-', 'youth'), ('e.g.-.-', 'youth', ','), ('youth', ',', 'adult'), (',', 'adult', ','), ('adult', ',', 'senior'), (',', 'senior', ')'), ('senior', ')', '.')]

>> POS Tags are: 
 [('conceptual', 'JJ'), ('labels', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), ('youth', 'NN'), (',', ','), ('adult', 'NN'), (',', ','), ('senior', 'JJ'), (')', ')'), ('.', '.')]

 (S
  (NP conceptual/JJ labels/NNS)
  (/(
  (NP e.g.-.-/JJ youth/NN)
  ,/,
  (NP adult/NN)
  ,/,
  senior/JJ
  )/)
  ./.) 


>> Noun Phrases are: 
 ['conceptual labels', 'e.g.-.- youth', 'adult']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conceptual', 'conceptu'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('youth', 'youth'), (',', ','), ('adult', 'adult'), (',', ','), ('senior', 'senior'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conceptual', 'conceptu'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('youth', 'youth'), (',', ','), ('adult', 'adult'), (',', ','), ('senior', 'senior'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('conceptual', 'conceptual'), ('labels', 'label'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), ('youth', 'youth'), (',', ','), ('adult', 'adult'), (',', ','), ('senior', 'senior'), (')', ')'), ('.', '.')]



============================ Sentence 135 =============================

Concept hierarchy generation for nominal data In this, attributes such as address can be generalized to higher-level concepts, like street or city or state or country. 


>> Tokens are: 
 ['Concept', 'hierarchy', 'generation', 'nominal', 'data', 'In', ',', 'attributes', 'address', 'generalized', 'higher-level', 'concepts', ',', 'like', 'street', 'city', 'state', 'country', '.']

>> Bigrams are: 
 [('Concept', 'hierarchy'), ('hierarchy', 'generation'), ('generation', 'nominal'), ('nominal', 'data'), ('data', 'In'), ('In', ','), (',', 'attributes'), ('attributes', 'address'), ('address', 'generalized'), ('generalized', 'higher-level'), ('higher-level', 'concepts'), ('concepts', ','), (',', 'like'), ('like', 'street'), ('street', 'city'), ('city', 'state'), ('state', 'country'), ('country', '.')]

>> Trigrams are: 
 [('Concept', 'hierarchy', 'generation'), ('hierarchy', 'generation', 'nominal'), ('generation', 'nominal', 'data'), ('nominal', 'data', 'In'), ('data', 'In', ','), ('In', ',', 'attributes'), (',', 'attributes', 'address'), ('attributes', 'address', 'generalized'), ('address', 'generalized', 'higher-level'), ('generalized', 'higher-level', 'concepts'), ('higher-level', 'concepts', ','), ('concepts', ',', 'like'), (',', 'like', 'street'), ('like', 'street', 'city'), ('street', 'city', 'state'), ('city', 'state', 'country'), ('state', 'country', '.')]

>> POS Tags are: 
 [('Concept', 'NNP'), ('hierarchy', 'NN'), ('generation', 'NN'), ('nominal', 'JJ'), ('data', 'NNS'), ('In', 'IN'), (',', ','), ('attributes', 'VBZ'), ('address', 'JJ'), ('generalized', 'VBN'), ('higher-level', 'JJ'), ('concepts', 'NNS'), (',', ','), ('like', 'IN'), ('street', 'NN'), ('city', 'NN'), ('state', 'NN'), ('country', 'NN'), ('.', '.')]

 (S
  (NP Concept/NNP hierarchy/NN generation/NN)
  (NP nominal/JJ data/NNS)
  In/IN
  ,/,
  attributes/VBZ
  address/JJ
  generalized/VBN
  (NP higher-level/JJ concepts/NNS)
  ,/,
  like/IN
  (NP street/NN city/NN state/NN country/NN)
  ./.) 


>> Noun Phrases are: 
 ['Concept hierarchy generation', 'nominal data', 'higher-level concepts', 'street city state country']

>> Named Entities are: 
 [('GSP', 'Concept')] 

>> Stemming using Porter Stemmer: 
 [('Concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'gener'), ('nominal', 'nomin'), ('data', 'data'), ('In', 'in'), (',', ','), ('attributes', 'attribut'), ('address', 'address'), ('generalized', 'gener'), ('higher-level', 'higher-level'), ('concepts', 'concept'), (',', ','), ('like', 'like'), ('street', 'street'), ('city', 'citi'), ('state', 'state'), ('country', 'countri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Concept', 'concept'), ('hierarchy', 'hierarchi'), ('generation', 'generat'), ('nominal', 'nomin'), ('data', 'data'), ('In', 'in'), (',', ','), ('attributes', 'attribut'), ('address', 'address'), ('generalized', 'general'), ('higher-level', 'higher-level'), ('concepts', 'concept'), (',', ','), ('like', 'like'), ('street', 'street'), ('city', 'citi'), ('state', 'state'), ('country', 'countri'), ('.', '.')]

>> Lemmatization: 
 [('Concept', 'Concept'), ('hierarchy', 'hierarchy'), ('generation', 'generation'), ('nominal', 'nominal'), ('data', 'data'), ('In', 'In'), (',', ','), ('attributes', 'attribute'), ('address', 'address'), ('generalized', 'generalized'), ('higher-level', 'higher-level'), ('concepts', 'concept'), (',', ','), ('like', 'like'), ('street', 'street'), ('city', 'city'), ('state', 'state'), ('country', 'country'), ('.', '.')]



============================ Sentence 136 =============================

Many hierarchies for nominal attributes are implicit within the database schema. 


>> Tokens are: 
 ['Many', 'hierarchies', 'nominal', 'attributes', 'implicit', 'within', 'database', 'schema', '.']

>> Bigrams are: 
 [('Many', 'hierarchies'), ('hierarchies', 'nominal'), ('nominal', 'attributes'), ('attributes', 'implicit'), ('implicit', 'within'), ('within', 'database'), ('database', 'schema'), ('schema', '.')]

>> Trigrams are: 
 [('Many', 'hierarchies', 'nominal'), ('hierarchies', 'nominal', 'attributes'), ('nominal', 'attributes', 'implicit'), ('attributes', 'implicit', 'within'), ('implicit', 'within', 'database'), ('within', 'database', 'schema'), ('database', 'schema', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('hierarchies', 'NNS'), ('nominal', 'JJ'), ('attributes', 'NNS'), ('implicit', 'VBP'), ('within', 'IN'), ('database', 'NN'), ('schema', 'NN'), ('.', '.')]

 (S
  (NP Many/JJ hierarchies/NNS)
  (NP nominal/JJ attributes/NNS)
  implicit/VBP
  within/IN
  (NP database/NN schema/NN)
  ./.) 


>> Noun Phrases are: 
 ['Many hierarchies', 'nominal attributes', 'database schema']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('hierarchies', 'hierarchi'), ('nominal', 'nomin'), ('attributes', 'attribut'), ('implicit', 'implicit'), ('within', 'within'), ('database', 'databas'), ('schema', 'schema'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('hierarchies', 'hierarchi'), ('nominal', 'nomin'), ('attributes', 'attribut'), ('implicit', 'implicit'), ('within', 'within'), ('database', 'databas'), ('schema', 'schema'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('hierarchies', 'hierarchy'), ('nominal', 'nominal'), ('attributes', 'attribute'), ('implicit', 'implicit'), ('within', 'within'), ('database', 'database'), ('schema', 'schema'), ('.', '.')]



============================ Sentence 137 =============================

E.g. 


>> Tokens are: 
 ['E.g', '.']

>> Bigrams are: 
 [('E.g', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E.g', 'NNP'), ('.', '.')]

 (S (NP E.g/NNP) ./.) 


>> Noun Phrases are: 
 ['E.g']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.g', 'e.g'), ('.', '.')]

>> Lemmatization: 
 [('E.g', 'E.g'), ('.', '.')]



============================ Sentence 138 =============================

city, country or state table in RDBMS. 


>> Tokens are: 
 ['city', ',', 'country', 'state', 'table', 'RDBMS', '.']

>> Bigrams are: 
 [('city', ','), (',', 'country'), ('country', 'state'), ('state', 'table'), ('table', 'RDBMS'), ('RDBMS', '.')]

>> Trigrams are: 
 [('city', ',', 'country'), (',', 'country', 'state'), ('country', 'state', 'table'), ('state', 'table', 'RDBMS'), ('table', 'RDBMS', '.')]

>> POS Tags are: 
 [('city', 'NN'), (',', ','), ('country', 'NN'), ('state', 'NN'), ('table', 'JJ'), ('RDBMS', 'NNP'), ('.', '.')]

 (S
  (NP city/NN)
  ,/,
  (NP country/NN state/NN)
  (NP table/JJ RDBMS/NNP)
  ./.) 


>> Noun Phrases are: 
 ['city', 'country state', 'table RDBMS']

>> Named Entities are: 
 [('ORGANIZATION', 'RDBMS')] 

>> Stemming using Porter Stemmer: 
 [('city', 'citi'), (',', ','), ('country', 'countri'), ('state', 'state'), ('table', 'tabl'), ('RDBMS', 'rdbm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('city', 'citi'), (',', ','), ('country', 'countri'), ('state', 'state'), ('table', 'tabl'), ('RDBMS', 'rdbms'), ('.', '.')]

>> Lemmatization: 
 [('city', 'city'), (',', ','), ('country', 'country'), ('state', 'state'), ('table', 'table'), ('RDBMS', 'RDBMS'), ('.', '.')]



============================ Sentence 139 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data Reduction Reducing the number of attributes Data cube aggregation: applying roll-up, slice or dice operations. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'Reduction', 'Reducing', 'number', 'attributes', 'Data', 'cube', 'aggregation', ':', 'applying', 'roll-up', ',', 'slice', 'dice', 'operations', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'Reduction'), ('Reduction', 'Reducing'), ('Reducing', 'number'), ('number', 'attributes'), ('attributes', 'Data'), ('Data', 'cube'), ('cube', 'aggregation'), ('aggregation', ':'), (':', 'applying'), ('applying', 'roll-up'), ('roll-up', ','), (',', 'slice'), ('slice', 'dice'), ('dice', 'operations'), ('operations', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'Reduction'), ('Data', 'Reduction', 'Reducing'), ('Reduction', 'Reducing', 'number'), ('Reducing', 'number', 'attributes'), ('number', 'attributes', 'Data'), ('attributes', 'Data', 'cube'), ('Data', 'cube', 'aggregation'), ('cube', 'aggregation', ':'), ('aggregation', ':', 'applying'), (':', 'applying', 'roll-up'), ('applying', 'roll-up', ','), ('roll-up', ',', 'slice'), (',', 'slice', 'dice'), ('slice', 'dice', 'operations'), ('dice', 'operations', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('Reduction', 'NNP'), ('Reducing', 'NNP'), ('number', 'NN'), ('attributes', 'VBZ'), ('Data', 'NNP'), ('cube', 'NN'), ('aggregation', 'NN'), (':', ':'), ('applying', 'VBG'), ('roll-up', 'NN'), (',', ','), ('slice', 'NN'), ('dice', 'NN'), ('operations', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP Reduction/NNP Reducing/NNP number/NN)
  attributes/VBZ
  (NP Data/NNP cube/NN aggregation/NN)
  :/:
  applying/VBG
  (NP roll-up/NN)
  ,/,
  (NP slice/NN dice/NN operations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data Reduction Reducing number', 'Data cube aggregation', 'roll-up', 'slice dice operations']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Reduction', 'reduct'), ('Reducing', 'reduc'), ('number', 'number'), ('attributes', 'attribut'), ('Data', 'data'), ('cube', 'cube'), ('aggregation', 'aggreg'), (':', ':'), ('applying', 'appli'), ('roll-up', 'roll-up'), (',', ','), ('slice', 'slice'), ('dice', 'dice'), ('operations', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('Reduction', 'reduct'), ('Reducing', 'reduc'), ('number', 'number'), ('attributes', 'attribut'), ('Data', 'data'), ('cube', 'cube'), ('aggregation', 'aggreg'), (':', ':'), ('applying', 'appli'), ('roll-up', 'roll-up'), (',', ','), ('slice', 'slice'), ('dice', 'dice'), ('operations', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('Reduction', 'Reduction'), ('Reducing', 'Reducing'), ('number', 'number'), ('attributes', 'attribute'), ('Data', 'Data'), ('cube', 'cube'), ('aggregation', 'aggregation'), (':', ':'), ('applying', 'applying'), ('roll-up', 'roll-up'), (',', ','), ('slice', 'slice'), ('dice', 'dice'), ('operations', 'operation'), ('.', '.')]



============================ Sentence 140 =============================

Removing irrelevant attributes: attribute selection, searching the attribute space  Reducing the number of attribute values Binning: Reducing the number of attributes by grouping them into intervals (bins). 


>> Tokens are: 
 ['Removing', 'irrelevant', 'attributes', ':', 'attribute', 'selection', ',', 'searching', 'attribute', 'space', 'Reducing', 'number', 'attribute', 'values', 'Binning', ':', 'Reducing', 'number', 'attributes', 'grouping', 'intervals', '(', 'bins', ')', '.']

>> Bigrams are: 
 [('Removing', 'irrelevant'), ('irrelevant', 'attributes'), ('attributes', ':'), (':', 'attribute'), ('attribute', 'selection'), ('selection', ','), (',', 'searching'), ('searching', 'attribute'), ('attribute', 'space'), ('space', 'Reducing'), ('Reducing', 'number'), ('number', 'attribute'), ('attribute', 'values'), ('values', 'Binning'), ('Binning', ':'), (':', 'Reducing'), ('Reducing', 'number'), ('number', 'attributes'), ('attributes', 'grouping'), ('grouping', 'intervals'), ('intervals', '('), ('(', 'bins'), ('bins', ')'), (')', '.')]

>> Trigrams are: 
 [('Removing', 'irrelevant', 'attributes'), ('irrelevant', 'attributes', ':'), ('attributes', ':', 'attribute'), (':', 'attribute', 'selection'), ('attribute', 'selection', ','), ('selection', ',', 'searching'), (',', 'searching', 'attribute'), ('searching', 'attribute', 'space'), ('attribute', 'space', 'Reducing'), ('space', 'Reducing', 'number'), ('Reducing', 'number', 'attribute'), ('number', 'attribute', 'values'), ('attribute', 'values', 'Binning'), ('values', 'Binning', ':'), ('Binning', ':', 'Reducing'), (':', 'Reducing', 'number'), ('Reducing', 'number', 'attributes'), ('number', 'attributes', 'grouping'), ('attributes', 'grouping', 'intervals'), ('grouping', 'intervals', '('), ('intervals', '(', 'bins'), ('(', 'bins', ')'), ('bins', ')', '.')]

>> POS Tags are: 
 [('Removing', 'VBG'), ('irrelevant', 'JJ'), ('attributes', 'NNS'), (':', ':'), ('attribute', 'NN'), ('selection', 'NN'), (',', ','), ('searching', 'VBG'), ('attribute', 'JJ'), ('space', 'NN'), ('Reducing', 'NNP'), ('number', 'NN'), ('attribute', 'NN'), ('values', 'NNS'), ('Binning', 'NNP'), (':', ':'), ('Reducing', 'VBG'), ('number', 'NN'), ('attributes', 'NNS'), ('grouping', 'VBG'), ('intervals', 'NNS'), ('(', '('), ('bins', 'NNS'), (')', ')'), ('.', '.')]

 (S
  Removing/VBG
  (NP irrelevant/JJ attributes/NNS)
  :/:
  (NP attribute/NN selection/NN)
  ,/,
  searching/VBG
  (NP
    attribute/JJ
    space/NN
    Reducing/NNP
    number/NN
    attribute/NN
    values/NNS
    Binning/NNP)
  :/:
  Reducing/VBG
  (NP number/NN attributes/NNS)
  grouping/VBG
  (NP intervals/NNS)
  (/(
  (NP bins/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['irrelevant attributes', 'attribute selection', 'attribute space Reducing number attribute values Binning', 'number attributes', 'intervals', 'bins']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Removing', 'remov'), ('irrelevant', 'irrelev'), ('attributes', 'attribut'), (':', ':'), ('attribute', 'attribut'), ('selection', 'select'), (',', ','), ('searching', 'search'), ('attribute', 'attribut'), ('space', 'space'), ('Reducing', 'reduc'), ('number', 'number'), ('attribute', 'attribut'), ('values', 'valu'), ('Binning', 'bin'), (':', ':'), ('Reducing', 'reduc'), ('number', 'number'), ('attributes', 'attribut'), ('grouping', 'group'), ('intervals', 'interv'), ('(', '('), ('bins', 'bin'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Removing', 'remov'), ('irrelevant', 'irrelev'), ('attributes', 'attribut'), (':', ':'), ('attribute', 'attribut'), ('selection', 'select'), (',', ','), ('searching', 'search'), ('attribute', 'attribut'), ('space', 'space'), ('Reducing', 'reduc'), ('number', 'number'), ('attribute', 'attribut'), ('values', 'valu'), ('Binning', 'bin'), (':', ':'), ('Reducing', 'reduc'), ('number', 'number'), ('attributes', 'attribut'), ('grouping', 'group'), ('intervals', 'interv'), ('(', '('), ('bins', 'bin'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Removing', 'Removing'), ('irrelevant', 'irrelevant'), ('attributes', 'attribute'), (':', ':'), ('attribute', 'attribute'), ('selection', 'selection'), (',', ','), ('searching', 'searching'), ('attribute', 'attribute'), ('space', 'space'), ('Reducing', 'Reducing'), ('number', 'number'), ('attribute', 'attribute'), ('values', 'value'), ('Binning', 'Binning'), (':', ':'), ('Reducing', 'Reducing'), ('number', 'number'), ('attributes', 'attribute'), ('grouping', 'grouping'), ('intervals', 'interval'), ('(', '('), ('bins', 'bin'), (')', ')'), ('.', '.')]



============================ Sentence 141 =============================

Clustering: Grouping similar values in a clusters. 


>> Tokens are: 
 ['Clustering', ':', 'Grouping', 'similar', 'values', 'clusters', '.']

>> Bigrams are: 
 [('Clustering', ':'), (':', 'Grouping'), ('Grouping', 'similar'), ('similar', 'values'), ('values', 'clusters'), ('clusters', '.')]

>> Trigrams are: 
 [('Clustering', ':', 'Grouping'), (':', 'Grouping', 'similar'), ('Grouping', 'similar', 'values'), ('similar', 'values', 'clusters'), ('values', 'clusters', '.')]

>> POS Tags are: 
 [('Clustering', 'NN'), (':', ':'), ('Grouping', 'VBG'), ('similar', 'JJ'), ('values', 'NNS'), ('clusters', 'NNS'), ('.', '.')]

 (S
  (NP Clustering/NN)
  :/:
  Grouping/VBG
  (NP similar/JJ values/NNS clusters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Clustering', 'similar values clusters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Clustering', 'cluster'), (':', ':'), ('Grouping', 'group'), ('similar', 'similar'), ('values', 'valu'), ('clusters', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clustering', 'cluster'), (':', ':'), ('Grouping', 'group'), ('similar', 'similar'), ('values', 'valu'), ('clusters', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Clustering', 'Clustering'), (':', ':'), ('Grouping', 'Grouping'), ('similar', 'similar'), ('values', 'value'), ('clusters', 'cluster'), ('.', '.')]



============================ Sentence 142 =============================

Aggregation or Generalization Reducing the number of tuples Sampling :  Only sample data are used for mining purpose. 


>> Tokens are: 
 ['Aggregation', 'Generalization', 'Reducing', 'number', 'tuples', 'Sampling', ':', 'Only', 'sample', 'data', 'used', 'mining', 'purpose', '.']

>> Bigrams are: 
 [('Aggregation', 'Generalization'), ('Generalization', 'Reducing'), ('Reducing', 'number'), ('number', 'tuples'), ('tuples', 'Sampling'), ('Sampling', ':'), (':', 'Only'), ('Only', 'sample'), ('sample', 'data'), ('data', 'used'), ('used', 'mining'), ('mining', 'purpose'), ('purpose', '.')]

>> Trigrams are: 
 [('Aggregation', 'Generalization', 'Reducing'), ('Generalization', 'Reducing', 'number'), ('Reducing', 'number', 'tuples'), ('number', 'tuples', 'Sampling'), ('tuples', 'Sampling', ':'), ('Sampling', ':', 'Only'), (':', 'Only', 'sample'), ('Only', 'sample', 'data'), ('sample', 'data', 'used'), ('data', 'used', 'mining'), ('used', 'mining', 'purpose'), ('mining', 'purpose', '.')]

>> POS Tags are: 
 [('Aggregation', 'NNP'), ('Generalization', 'NNP'), ('Reducing', 'NNP'), ('number', 'NN'), ('tuples', 'NNS'), ('Sampling', 'VBG'), (':', ':'), ('Only', 'RB'), ('sample', 'NN'), ('data', 'NNS'), ('used', 'VBD'), ('mining', 'NN'), ('purpose', 'NN'), ('.', '.')]

 (S
  (NP
    Aggregation/NNP
    Generalization/NNP
    Reducing/NNP
    number/NN
    tuples/NNS)
  Sampling/VBG
  :/:
  Only/RB
  (NP sample/NN data/NNS)
  used/VBD
  (NP mining/NN purpose/NN)
  ./.) 


>> Noun Phrases are: 
 ['Aggregation Generalization Reducing number tuples', 'sample data', 'mining purpose']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Aggregation', 'aggreg'), ('Generalization', 'gener'), ('Reducing', 'reduc'), ('number', 'number'), ('tuples', 'tupl'), ('Sampling', 'sampl'), (':', ':'), ('Only', 'onli'), ('sample', 'sampl'), ('data', 'data'), ('used', 'use'), ('mining', 'mine'), ('purpose', 'purpos'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aggregation', 'aggreg'), ('Generalization', 'general'), ('Reducing', 'reduc'), ('number', 'number'), ('tuples', 'tupl'), ('Sampling', 'sampl'), (':', ':'), ('Only', 'onli'), ('sample', 'sampl'), ('data', 'data'), ('used', 'use'), ('mining', 'mine'), ('purpose', 'purpos'), ('.', '.')]

>> Lemmatization: 
 [('Aggregation', 'Aggregation'), ('Generalization', 'Generalization'), ('Reducing', 'Reducing'), ('number', 'number'), ('tuples', 'tuples'), ('Sampling', 'Sampling'), (':', ':'), ('Only', 'Only'), ('sample', 'sample'), ('data', 'data'), ('used', 'used'), ('mining', 'mining'), ('purpose', 'purpose'), ('.', '.')]



============================ Sentence 143 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data mining task primitives A data mining task can be specified in the form of a data mining query, which is input to the data mining system. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'mining', 'task', 'primitives', 'A', 'data', 'mining', 'task', 'specified', 'form', 'data', 'mining', 'query', ',', 'input', 'data', 'mining', 'system', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', 'A'), ('A', 'data'), ('data', 'mining'), ('mining', 'task'), ('task', 'specified'), ('specified', 'form'), ('form', 'data'), ('data', 'mining'), ('mining', 'query'), ('query', ','), (',', 'input'), ('input', 'data'), ('data', 'mining'), ('mining', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', 'A'), ('primitives', 'A', 'data'), ('A', 'data', 'mining'), ('data', 'mining', 'task'), ('mining', 'task', 'specified'), ('task', 'specified', 'form'), ('specified', 'form', 'data'), ('form', 'data', 'mining'), ('data', 'mining', 'query'), ('mining', 'query', ','), ('query', ',', 'input'), (',', 'input', 'data'), ('input', 'data', 'mining'), ('data', 'mining', 'system'), ('mining', 'system', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'VBZ'), ('A', 'NNP'), ('data', 'NN'), ('mining', 'NN'), ('task', 'NN'), ('specified', 'VBN'), ('form', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('query', 'NN'), (',', ','), ('input', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('system', 'NN'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP mining/NN task/NN)
  primitives/VBZ
  (NP A/NNP data/NN mining/NN task/NN)
  specified/VBN
  (NP form/NN data/NNS mining/NN query/NN)
  ,/,
  (NP input/NN data/NNS mining/NN system/NN)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data mining task', 'A data mining task', 'form data mining query', 'input data mining system']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('specified', 'specifi'), ('form', 'form'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), (',', ','), ('input', 'input'), ('data', 'data'), ('mining', 'mine'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('specified', 'specifi'), ('form', 'form'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), (',', ','), ('input', 'input'), ('data', 'data'), ('mining', 'mine'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('A', 'A'), ('data', 'data'), ('mining', 'mining'), ('task', 'task'), ('specified', 'specified'), ('form', 'form'), ('data', 'data'), ('mining', 'mining'), ('query', 'query'), (',', ','), ('input', 'input'), ('data', 'data'), ('mining', 'mining'), ('system', 'system'), ('.', '.')]



============================ Sentence 144 =============================

A data mining query is defined in terms of data mining task primitives. 


>> Tokens are: 
 ['A', 'data', 'mining', 'query', 'defined', 'terms', 'data', 'mining', 'task', 'primitives', '.']

>> Bigrams are: 
 [('A', 'data'), ('data', 'mining'), ('mining', 'query'), ('query', 'defined'), ('defined', 'terms'), ('terms', 'data'), ('data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', '.')]

>> Trigrams are: 
 [('A', 'data', 'mining'), ('data', 'mining', 'query'), ('mining', 'query', 'defined'), ('query', 'defined', 'terms'), ('defined', 'terms', 'data'), ('terms', 'data', 'mining'), ('data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('data', 'NN'), ('mining', 'NN'), ('query', 'NN'), ('defined', 'VBD'), ('terms', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('.', '.')]

 (S
  (NP A/DT data/NN mining/NN query/NN)
  defined/VBD
  (NP terms/NNS data/NNS mining/NN task/NN primitives/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A data mining query', 'terms data mining task primitives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), ('defined', 'defin'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), ('defined', 'defin'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('data', 'data'), ('mining', 'mining'), ('query', 'query'), ('defined', 'defined'), ('terms', 'term'), ('data', 'data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('.', '.')]



============================ Sentence 145 =============================

These primitives allow the user to inter-actively communicate with the data mining system during discovery of knowledge. 


>> Tokens are: 
 ['These', 'primitives', 'allow', 'user', 'inter-actively', 'communicate', 'data', 'mining', 'system', 'discovery', 'knowledge', '.']

>> Bigrams are: 
 [('These', 'primitives'), ('primitives', 'allow'), ('allow', 'user'), ('user', 'inter-actively'), ('inter-actively', 'communicate'), ('communicate', 'data'), ('data', 'mining'), ('mining', 'system'), ('system', 'discovery'), ('discovery', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('These', 'primitives', 'allow'), ('primitives', 'allow', 'user'), ('allow', 'user', 'inter-actively'), ('user', 'inter-actively', 'communicate'), ('inter-actively', 'communicate', 'data'), ('communicate', 'data', 'mining'), ('data', 'mining', 'system'), ('mining', 'system', 'discovery'), ('system', 'discovery', 'knowledge'), ('discovery', 'knowledge', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('primitives', 'NNS'), ('allow', 'VBP'), ('user', 'JJ'), ('inter-actively', 'JJ'), ('communicate', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('system', 'NN'), ('discovery', 'NN'), ('knowledge', 'NN'), ('.', '.')]

 (S
  (NP These/DT primitives/NNS)
  allow/VBP
  (NP
    user/JJ
    inter-actively/JJ
    communicate/NN
    data/NNS
    mining/NN
    system/NN
    discovery/NN
    knowledge/NN)
  ./.) 


>> Noun Phrases are: 
 ['These primitives', 'user inter-actively communicate data mining system discovery knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('primitives', 'primit'), ('allow', 'allow'), ('user', 'user'), ('inter-actively', 'inter-act'), ('communicate', 'commun'), ('data', 'data'), ('mining', 'mine'), ('system', 'system'), ('discovery', 'discoveri'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('primitives', 'primit'), ('allow', 'allow'), ('user', 'user'), ('inter-actively', 'inter-act'), ('communicate', 'communic'), ('data', 'data'), ('mining', 'mine'), ('system', 'system'), ('discovery', 'discoveri'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('primitives', 'primitive'), ('allow', 'allow'), ('user', 'user'), ('inter-actively', 'inter-actively'), ('communicate', 'communicate'), ('data', 'data'), ('mining', 'mining'), ('system', 'system'), ('discovery', 'discovery'), ('knowledge', 'knowledge'), ('.', '.')]



============================ Sentence 146 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data mining task primitives (Cont..) The data mining task primitives includes the following: Task-relevant data Kind of knowledge to be mined Background knowledge Interestingness measurement Presentation for visualizing the discovered patterns   	Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data mining task primitives (Cont..) Task-relevant data This specifies the portions of the database or the dataset of data in which the user is interested. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'mining', 'task', 'primitives', '(', 'Cont', '..', ')', 'The', 'data', 'mining', 'task', 'primitives', 'includes', 'following', ':', 'Task-relevant', 'data', 'Kind', 'knowledge', 'mined', 'Background', 'knowledge', 'Interestingness', 'measurement', 'Presentation', 'visualizing', 'discovered', 'patterns', 'Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'mining', 'task', 'primitives', '(', 'Cont', '..', ')', 'Task-relevant', 'data', 'This', 'specifies', 'portions', 'database', 'dataset', 'data', 'user', 'interested', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'The'), ('The', 'data'), ('data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', 'includes'), ('includes', 'following'), ('following', ':'), (':', 'Task-relevant'), ('Task-relevant', 'data'), ('data', 'Kind'), ('Kind', 'knowledge'), ('knowledge', 'mined'), ('mined', 'Background'), ('Background', 'knowledge'), ('knowledge', 'Interestingness'), ('Interestingness', 'measurement'), ('measurement', 'Presentation'), ('Presentation', 'visualizing'), ('visualizing', 'discovered'), ('discovered', 'patterns'), ('patterns', 'Unit'), ('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'Task-relevant'), ('Task-relevant', 'data'), ('data', 'This'), ('This', 'specifies'), ('specifies', 'portions'), ('portions', 'database'), ('database', 'dataset'), ('dataset', 'data'), ('data', 'user'), ('user', 'interested'), ('interested', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', '('), ('primitives', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'The'), (')', 'The', 'data'), ('The', 'data', 'mining'), ('data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', 'includes'), ('primitives', 'includes', 'following'), ('includes', 'following', ':'), ('following', ':', 'Task-relevant'), (':', 'Task-relevant', 'data'), ('Task-relevant', 'data', 'Kind'), ('data', 'Kind', 'knowledge'), ('Kind', 'knowledge', 'mined'), ('knowledge', 'mined', 'Background'), ('mined', 'Background', 'knowledge'), ('Background', 'knowledge', 'Interestingness'), ('knowledge', 'Interestingness', 'measurement'), ('Interestingness', 'measurement', 'Presentation'), ('measurement', 'Presentation', 'visualizing'), ('Presentation', 'visualizing', 'discovered'), ('visualizing', 'discovered', 'patterns'), ('discovered', 'patterns', 'Unit'), ('patterns', 'Unit', ':'), ('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', '('), ('primitives', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'Task-relevant'), (')', 'Task-relevant', 'data'), ('Task-relevant', 'data', 'This'), ('data', 'This', 'specifies'), ('This', 'specifies', 'portions'), ('specifies', 'portions', 'database'), ('portions', 'database', 'dataset'), ('database', 'dataset', 'data'), ('dataset', 'data', 'user'), ('data', 'user', 'interested'), ('user', 'interested', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('The', 'DT'), ('data', 'NN'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'VBZ'), ('includes', 'VBZ'), ('following', 'VBG'), (':', ':'), ('Task-relevant', 'JJ'), ('data', 'NNS'), ('Kind', 'NNP'), ('knowledge', 'NN'), ('mined', 'VBD'), ('Background', 'NNP'), ('knowledge', 'NNP'), ('Interestingness', 'NNP'), ('measurement', 'NN'), ('Presentation', 'NNP'), ('visualizing', 'NN'), ('discovered', 'VBD'), ('patterns', 'NNS'), ('Unit', 'NNP'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('Task-relevant', 'NNP'), ('data', 'NN'), ('This', 'DT'), ('specifies', 'VBZ'), ('portions', 'NNS'), ('database', 'NN'), ('dataset', 'VBN'), ('data', 'NNS'), ('user', 'RB'), ('interested', 'JJ'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP mining/NN task/NN primitives/NNS)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP The/DT data/NN mining/NN task/NN)
  primitives/VBZ
  includes/VBZ
  following/VBG
  :/:
  (NP Task-relevant/JJ data/NNS Kind/NNP knowledge/NN)
  mined/VBD
  (NP
    Background/NNP
    knowledge/NNP
    Interestingness/NNP
    measurement/NN
    Presentation/NNP
    visualizing/NN)
  discovered/VBD
  (NP patterns/NNS Unit/NNP)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP mining/NN task/NN primitives/NNS)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP Task-relevant/NNP data/NN)
  This/DT
  specifies/VBZ
  (NP portions/NNS database/NN)
  dataset/VBN
  (NP data/NNS)
  user/RB
  interested/JJ
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data mining task primitives', 'Cont ..', 'The data mining task', 'Task-relevant data Kind knowledge', 'Background knowledge Interestingness measurement Presentation visualizing', 'patterns Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data mining task primitives', 'Cont ..', 'Task-relevant data', 'portions database', 'data']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont'), ('PERSON', 'Kind'), ('PERSON', 'Background'), ('PERSON', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('includes', 'includ'), ('following', 'follow'), (':', ':'), ('Task-relevant', 'task-relev'), ('data', 'data'), ('Kind', 'kind'), ('knowledge', 'knowledg'), ('mined', 'mine'), ('Background', 'background'), ('knowledge', 'knowledg'), ('Interestingness', 'interesting'), ('measurement', 'measur'), ('Presentation', 'present'), ('visualizing', 'visual'), ('discovered', 'discov'), ('patterns', 'pattern'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Task-relevant', 'task-relev'), ('data', 'data'), ('This', 'thi'), ('specifies', 'specifi'), ('portions', 'portion'), ('database', 'databas'), ('dataset', 'dataset'), ('data', 'data'), ('user', 'user'), ('interested', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('includes', 'includ'), ('following', 'follow'), (':', ':'), ('Task-relevant', 'task-relev'), ('data', 'data'), ('Kind', 'kind'), ('knowledge', 'knowledg'), ('mined', 'mine'), ('Background', 'background'), ('knowledge', 'knowledg'), ('Interestingness', 'interesting'), ('measurement', 'measur'), ('Presentation', 'present'), ('visualizing', 'visual'), ('discovered', 'discov'), ('patterns', 'pattern'), ('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('Task-relevant', 'task-relev'), ('data', 'data'), ('This', 'this'), ('specifies', 'specifi'), ('portions', 'portion'), ('database', 'databas'), ('dataset', 'dataset'), ('data', 'data'), ('user', 'user'), ('interested', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('The', 'The'), ('data', 'data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('includes', 'includes'), ('following', 'following'), (':', ':'), ('Task-relevant', 'Task-relevant'), ('data', 'data'), ('Kind', 'Kind'), ('knowledge', 'knowledge'), ('mined', 'mined'), ('Background', 'Background'), ('knowledge', 'knowledge'), ('Interestingness', 'Interestingness'), ('measurement', 'measurement'), ('Presentation', 'Presentation'), ('visualizing', 'visualizing'), ('discovered', 'discovered'), ('patterns', 'pattern'), ('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('Task-relevant', 'Task-relevant'), ('data', 'data'), ('This', 'This'), ('specifies', 'specifies'), ('portions', 'portion'), ('database', 'database'), ('dataset', 'dataset'), ('data', 'data'), ('user', 'user'), ('interested', 'interested'), ('.', '.')]



============================ Sentence 147 =============================

This includes the database attributes or data warehouse dimensions of interest (referred to as the relevant attributes or dimensions). 


>> Tokens are: 
 ['This', 'includes', 'database', 'attributes', 'data', 'warehouse', 'dimensions', 'interest', '(', 'referred', 'relevant', 'attributes', 'dimensions', ')', '.']

>> Bigrams are: 
 [('This', 'includes'), ('includes', 'database'), ('database', 'attributes'), ('attributes', 'data'), ('data', 'warehouse'), ('warehouse', 'dimensions'), ('dimensions', 'interest'), ('interest', '('), ('(', 'referred'), ('referred', 'relevant'), ('relevant', 'attributes'), ('attributes', 'dimensions'), ('dimensions', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'includes', 'database'), ('includes', 'database', 'attributes'), ('database', 'attributes', 'data'), ('attributes', 'data', 'warehouse'), ('data', 'warehouse', 'dimensions'), ('warehouse', 'dimensions', 'interest'), ('dimensions', 'interest', '('), ('interest', '(', 'referred'), ('(', 'referred', 'relevant'), ('referred', 'relevant', 'attributes'), ('relevant', 'attributes', 'dimensions'), ('attributes', 'dimensions', ')'), ('dimensions', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('includes', 'VBZ'), ('database', 'NN'), ('attributes', 'VBZ'), ('data', 'NNS'), ('warehouse', 'NN'), ('dimensions', 'NNS'), ('interest', 'NN'), ('(', '('), ('referred', 'VBN'), ('relevant', 'NN'), ('attributes', 'VBZ'), ('dimensions', 'NNS'), (')', ')'), ('.', '.')]

 (S
  This/DT
  includes/VBZ
  (NP database/NN)
  attributes/VBZ
  (NP data/NNS warehouse/NN dimensions/NNS interest/NN)
  (/(
  referred/VBN
  (NP relevant/NN)
  attributes/VBZ
  (NP dimensions/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['database', 'data warehouse dimensions interest', 'relevant', 'dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('includes', 'includ'), ('database', 'databas'), ('attributes', 'attribut'), ('data', 'data'), ('warehouse', 'warehous'), ('dimensions', 'dimens'), ('interest', 'interest'), ('(', '('), ('referred', 'refer'), ('relevant', 'relev'), ('attributes', 'attribut'), ('dimensions', 'dimens'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('includes', 'includ'), ('database', 'databas'), ('attributes', 'attribut'), ('data', 'data'), ('warehouse', 'warehous'), ('dimensions', 'dimens'), ('interest', 'interest'), ('(', '('), ('referred', 'refer'), ('relevant', 'relev'), ('attributes', 'attribut'), ('dimensions', 'dimens'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('includes', 'includes'), ('database', 'database'), ('attributes', 'attribute'), ('data', 'data'), ('warehouse', 'warehouse'), ('dimensions', 'dimension'), ('interest', 'interest'), ('(', '('), ('referred', 'referred'), ('relevant', 'relevant'), ('attributes', 'attribute'), ('dimensions', 'dimension'), (')', ')'), ('.', '.')]



============================ Sentence 148 =============================

The kind of knowledge to be mined This specifies the data mining functions to be performed. 


>> Tokens are: 
 ['The', 'kind', 'knowledge', 'mined', 'This', 'specifies', 'data', 'mining', 'functions', 'performed', '.']

>> Bigrams are: 
 [('The', 'kind'), ('kind', 'knowledge'), ('knowledge', 'mined'), ('mined', 'This'), ('This', 'specifies'), ('specifies', 'data'), ('data', 'mining'), ('mining', 'functions'), ('functions', 'performed'), ('performed', '.')]

>> Trigrams are: 
 [('The', 'kind', 'knowledge'), ('kind', 'knowledge', 'mined'), ('knowledge', 'mined', 'This'), ('mined', 'This', 'specifies'), ('This', 'specifies', 'data'), ('specifies', 'data', 'mining'), ('data', 'mining', 'functions'), ('mining', 'functions', 'performed'), ('functions', 'performed', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('kind', 'NN'), ('knowledge', 'NN'), ('mined', 'VBD'), ('This', 'DT'), ('specifies', 'NNS'), ('data', 'VBP'), ('mining', 'NN'), ('functions', 'NNS'), ('performed', 'VBD'), ('.', '.')]

 (S
  (NP The/DT kind/NN knowledge/NN)
  mined/VBD
  (NP This/DT specifies/NNS)
  data/VBP
  (NP mining/NN functions/NNS)
  performed/VBD
  ./.) 


>> Noun Phrases are: 
 ['The kind knowledge', 'This specifies', 'mining functions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('kind', 'kind'), ('knowledge', 'knowledg'), ('mined', 'mine'), ('This', 'thi'), ('specifies', 'specifi'), ('data', 'data'), ('mining', 'mine'), ('functions', 'function'), ('performed', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('kind', 'kind'), ('knowledge', 'knowledg'), ('mined', 'mine'), ('This', 'this'), ('specifies', 'specifi'), ('data', 'data'), ('mining', 'mine'), ('functions', 'function'), ('performed', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('kind', 'kind'), ('knowledge', 'knowledge'), ('mined', 'mined'), ('This', 'This'), ('specifies', 'specifies'), ('data', 'data'), ('mining', 'mining'), ('functions', 'function'), ('performed', 'performed'), ('.', '.')]



============================ Sentence 149 =============================

Such as characterization, discrimination, association or correlation analysis, classification, prediction, clustering, outlier analysis, or evolution analysis. 


>> Tokens are: 
 ['Such', 'characterization', ',', 'discrimination', ',', 'association', 'correlation', 'analysis', ',', 'classification', ',', 'prediction', ',', 'clustering', ',', 'outlier', 'analysis', ',', 'evolution', 'analysis', '.']

>> Bigrams are: 
 [('Such', 'characterization'), ('characterization', ','), (',', 'discrimination'), ('discrimination', ','), (',', 'association'), ('association', 'correlation'), ('correlation', 'analysis'), ('analysis', ','), (',', 'classification'), ('classification', ','), (',', 'prediction'), ('prediction', ','), (',', 'clustering'), ('clustering', ','), (',', 'outlier'), ('outlier', 'analysis'), ('analysis', ','), (',', 'evolution'), ('evolution', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Such', 'characterization', ','), ('characterization', ',', 'discrimination'), (',', 'discrimination', ','), ('discrimination', ',', 'association'), (',', 'association', 'correlation'), ('association', 'correlation', 'analysis'), ('correlation', 'analysis', ','), ('analysis', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'prediction'), (',', 'prediction', ','), ('prediction', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'outlier'), (',', 'outlier', 'analysis'), ('outlier', 'analysis', ','), ('analysis', ',', 'evolution'), (',', 'evolution', 'analysis'), ('evolution', 'analysis', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('characterization', 'NN'), (',', ','), ('discrimination', 'NN'), (',', ','), ('association', 'NN'), ('correlation', 'NN'), ('analysis', 'NN'), (',', ','), ('classification', 'NN'), (',', ','), ('prediction', 'NN'), (',', ','), ('clustering', 'VBG'), (',', ','), ('outlier', 'JJR'), ('analysis', 'NN'), (',', ','), ('evolution', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP Such/JJ characterization/NN)
  ,/,
  (NP discrimination/NN)
  ,/,
  (NP association/NN correlation/NN analysis/NN)
  ,/,
  (NP classification/NN)
  ,/,
  (NP prediction/NN)
  ,/,
  clustering/VBG
  ,/,
  outlier/JJR
  (NP analysis/NN)
  ,/,
  (NP evolution/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['Such characterization', 'discrimination', 'association correlation analysis', 'classification', 'prediction', 'analysis', 'evolution analysis']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('characterization', 'character'), (',', ','), ('discrimination', 'discrimin'), (',', ','), ('association', 'associ'), ('correlation', 'correl'), ('analysis', 'analysi'), (',', ','), ('classification', 'classif'), (',', ','), ('prediction', 'predict'), (',', ','), ('clustering', 'cluster'), (',', ','), ('outlier', 'outlier'), ('analysis', 'analysi'), (',', ','), ('evolution', 'evolut'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('characterization', 'character'), (',', ','), ('discrimination', 'discrimin'), (',', ','), ('association', 'associ'), ('correlation', 'correl'), ('analysis', 'analysi'), (',', ','), ('classification', 'classif'), (',', ','), ('prediction', 'predict'), (',', ','), ('clustering', 'cluster'), (',', ','), ('outlier', 'outlier'), ('analysis', 'analysi'), (',', ','), ('evolution', 'evolut'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('characterization', 'characterization'), (',', ','), ('discrimination', 'discrimination'), (',', ','), ('association', 'association'), ('correlation', 'correlation'), ('analysis', 'analysis'), (',', ','), ('classification', 'classification'), (',', ','), ('prediction', 'prediction'), (',', ','), ('clustering', 'clustering'), (',', ','), ('outlier', 'outlier'), ('analysis', 'analysis'), (',', ','), ('evolution', 'evolution'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 150 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data mining task primitives (Cont..) The background knowledge to be used in the discovery process The knowledge about the domain is useful for guiding the knowledge discovery process for evaluating the interesting patterns. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'mining', 'task', 'primitives', '(', 'Cont', '..', ')', 'The', 'background', 'knowledge', 'used', 'discovery', 'process', 'The', 'knowledge', 'domain', 'useful', 'guiding', 'knowledge', 'discovery', 'process', 'evaluating', 'interesting', 'patterns', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'The'), ('The', 'background'), ('background', 'knowledge'), ('knowledge', 'used'), ('used', 'discovery'), ('discovery', 'process'), ('process', 'The'), ('The', 'knowledge'), ('knowledge', 'domain'), ('domain', 'useful'), ('useful', 'guiding'), ('guiding', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'process'), ('process', 'evaluating'), ('evaluating', 'interesting'), ('interesting', 'patterns'), ('patterns', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', '('), ('primitives', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'The'), (')', 'The', 'background'), ('The', 'background', 'knowledge'), ('background', 'knowledge', 'used'), ('knowledge', 'used', 'discovery'), ('used', 'discovery', 'process'), ('discovery', 'process', 'The'), ('process', 'The', 'knowledge'), ('The', 'knowledge', 'domain'), ('knowledge', 'domain', 'useful'), ('domain', 'useful', 'guiding'), ('useful', 'guiding', 'knowledge'), ('guiding', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'process'), ('discovery', 'process', 'evaluating'), ('process', 'evaluating', 'interesting'), ('evaluating', 'interesting', 'patterns'), ('interesting', 'patterns', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('The', 'DT'), ('background', 'NN'), ('knowledge', 'NN'), ('used', 'VBN'), ('discovery', 'NN'), ('process', 'NN'), ('The', 'DT'), ('knowledge', 'NN'), ('domain', 'NN'), ('useful', 'JJ'), ('guiding', 'VBG'), ('knowledge', 'NN'), ('discovery', 'NN'), ('process', 'NN'), ('evaluating', 'VBG'), ('interesting', 'JJ'), ('patterns', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP mining/NN task/NN primitives/NNS)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP The/DT background/NN knowledge/NN)
  used/VBN
  (NP discovery/NN process/NN)
  (NP The/DT knowledge/NN domain/NN)
  useful/JJ
  guiding/VBG
  (NP knowledge/NN discovery/NN process/NN)
  evaluating/VBG
  (NP interesting/JJ patterns/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data mining task primitives', 'Cont ..', 'The background knowledge', 'discovery process', 'The knowledge domain', 'knowledge discovery process', 'interesting patterns']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('background', 'background'), ('knowledge', 'knowledg'), ('used', 'use'), ('discovery', 'discoveri'), ('process', 'process'), ('The', 'the'), ('knowledge', 'knowledg'), ('domain', 'domain'), ('useful', 'use'), ('guiding', 'guid'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('evaluating', 'evalu'), ('interesting', 'interest'), ('patterns', 'pattern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('background', 'background'), ('knowledge', 'knowledg'), ('used', 'use'), ('discovery', 'discoveri'), ('process', 'process'), ('The', 'the'), ('knowledge', 'knowledg'), ('domain', 'domain'), ('useful', 'use'), ('guiding', 'guid'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('evaluating', 'evalu'), ('interesting', 'interest'), ('patterns', 'pattern'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('The', 'The'), ('background', 'background'), ('knowledge', 'knowledge'), ('used', 'used'), ('discovery', 'discovery'), ('process', 'process'), ('The', 'The'), ('knowledge', 'knowledge'), ('domain', 'domain'), ('useful', 'useful'), ('guiding', 'guiding'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('process', 'process'), ('evaluating', 'evaluating'), ('interesting', 'interesting'), ('patterns', 'pattern'), ('.', '.')]



============================ Sentence 151 =============================

Concept hierarchies are a popular form of background knowledge, which allow data to be mined at multiple levels of abstraction. 


>> Tokens are: 
 ['Concept', 'hierarchies', 'popular', 'form', 'background', 'knowledge', ',', 'allow', 'data', 'mined', 'multiple', 'levels', 'abstraction', '.']

>> Bigrams are: 
 [('Concept', 'hierarchies'), ('hierarchies', 'popular'), ('popular', 'form'), ('form', 'background'), ('background', 'knowledge'), ('knowledge', ','), (',', 'allow'), ('allow', 'data'), ('data', 'mined'), ('mined', 'multiple'), ('multiple', 'levels'), ('levels', 'abstraction'), ('abstraction', '.')]

>> Trigrams are: 
 [('Concept', 'hierarchies', 'popular'), ('hierarchies', 'popular', 'form'), ('popular', 'form', 'background'), ('form', 'background', 'knowledge'), ('background', 'knowledge', ','), ('knowledge', ',', 'allow'), (',', 'allow', 'data'), ('allow', 'data', 'mined'), ('data', 'mined', 'multiple'), ('mined', 'multiple', 'levels'), ('multiple', 'levels', 'abstraction'), ('levels', 'abstraction', '.')]

>> POS Tags are: 
 [('Concept', 'NNP'), ('hierarchies', 'NNS'), ('popular', 'JJ'), ('form', 'NN'), ('background', 'NN'), ('knowledge', 'NN'), (',', ','), ('allow', 'VB'), ('data', 'NNS'), ('mined', 'VBN'), ('multiple', 'JJ'), ('levels', 'NNS'), ('abstraction', 'NN'), ('.', '.')]

 (S
  (NP Concept/NNP hierarchies/NNS)
  (NP popular/JJ form/NN background/NN knowledge/NN)
  ,/,
  allow/VB
  (NP data/NNS)
  mined/VBN
  (NP multiple/JJ levels/NNS abstraction/NN)
  ./.) 


>> Noun Phrases are: 
 ['Concept hierarchies', 'popular form background knowledge', 'data', 'multiple levels abstraction']

>> Named Entities are: 
 [('GSP', 'Concept')] 

>> Stemming using Porter Stemmer: 
 [('Concept', 'concept'), ('hierarchies', 'hierarchi'), ('popular', 'popular'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledg'), (',', ','), ('allow', 'allow'), ('data', 'data'), ('mined', 'mine'), ('multiple', 'multipl'), ('levels', 'level'), ('abstraction', 'abstract'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Concept', 'concept'), ('hierarchies', 'hierarchi'), ('popular', 'popular'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledg'), (',', ','), ('allow', 'allow'), ('data', 'data'), ('mined', 'mine'), ('multiple', 'multipl'), ('levels', 'level'), ('abstraction', 'abstract'), ('.', '.')]

>> Lemmatization: 
 [('Concept', 'Concept'), ('hierarchies', 'hierarchy'), ('popular', 'popular'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledge'), (',', ','), ('allow', 'allow'), ('data', 'data'), ('mined', 'mined'), ('multiple', 'multiple'), ('levels', 'level'), ('abstraction', 'abstraction'), ('.', '.')]



============================ Sentence 152 =============================

An example of a concept hierarchy for the attribute (or dimension) age is shown in user beliefs regarding relationships in the data are another form of background knowledge. 


>> Tokens are: 
 ['An', 'example', 'concept', 'hierarchy', 'attribute', '(', 'dimension', ')', 'age', 'shown', 'user', 'beliefs', 'regarding', 'relationships', 'data', 'another', 'form', 'background', 'knowledge', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', 'concept'), ('concept', 'hierarchy'), ('hierarchy', 'attribute'), ('attribute', '('), ('(', 'dimension'), ('dimension', ')'), (')', 'age'), ('age', 'shown'), ('shown', 'user'), ('user', 'beliefs'), ('beliefs', 'regarding'), ('regarding', 'relationships'), ('relationships', 'data'), ('data', 'another'), ('another', 'form'), ('form', 'background'), ('background', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('An', 'example', 'concept'), ('example', 'concept', 'hierarchy'), ('concept', 'hierarchy', 'attribute'), ('hierarchy', 'attribute', '('), ('attribute', '(', 'dimension'), ('(', 'dimension', ')'), ('dimension', ')', 'age'), (')', 'age', 'shown'), ('age', 'shown', 'user'), ('shown', 'user', 'beliefs'), ('user', 'beliefs', 'regarding'), ('beliefs', 'regarding', 'relationships'), ('regarding', 'relationships', 'data'), ('relationships', 'data', 'another'), ('data', 'another', 'form'), ('another', 'form', 'background'), ('form', 'background', 'knowledge'), ('background', 'knowledge', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('concept', 'NN'), ('hierarchy', 'NN'), ('attribute', 'NN'), ('(', '('), ('dimension', 'NN'), (')', ')'), ('age', 'NN'), ('shown', 'VBN'), ('user', 'JJ'), ('beliefs', 'NNS'), ('regarding', 'VBG'), ('relationships', 'NNS'), ('data', 'NNS'), ('another', 'DT'), ('form', 'NN'), ('background', 'NN'), ('knowledge', 'NN'), ('.', '.')]

 (S
  (NP An/DT example/NN concept/NN hierarchy/NN attribute/NN)
  (/(
  (NP dimension/NN)
  )/)
  (NP age/NN)
  shown/VBN
  (NP user/JJ beliefs/NNS)
  regarding/VBG
  (NP relationships/NNS data/NNS)
  (NP another/DT form/NN background/NN knowledge/NN)
  ./.) 


>> Noun Phrases are: 
 ['An example concept hierarchy attribute', 'dimension', 'age', 'user beliefs', 'relationships data', 'another form background knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('concept', 'concept'), ('hierarchy', 'hierarchi'), ('attribute', 'attribut'), ('(', '('), ('dimension', 'dimens'), (')', ')'), ('age', 'age'), ('shown', 'shown'), ('user', 'user'), ('beliefs', 'belief'), ('regarding', 'regard'), ('relationships', 'relationship'), ('data', 'data'), ('another', 'anoth'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('concept', 'concept'), ('hierarchy', 'hierarchi'), ('attribute', 'attribut'), ('(', '('), ('dimension', 'dimens'), (')', ')'), ('age', 'age'), ('shown', 'shown'), ('user', 'user'), ('beliefs', 'belief'), ('regarding', 'regard'), ('relationships', 'relationship'), ('data', 'data'), ('another', 'anoth'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('concept', 'concept'), ('hierarchy', 'hierarchy'), ('attribute', 'attribute'), ('(', '('), ('dimension', 'dimension'), (')', ')'), ('age', 'age'), ('shown', 'shown'), ('user', 'user'), ('beliefs', 'belief'), ('regarding', 'regarding'), ('relationships', 'relationship'), ('data', 'data'), ('another', 'another'), ('form', 'form'), ('background', 'background'), ('knowledge', 'knowledge'), ('.', '.')]



============================ Sentence 153 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#›  Data mining task primitives (Cont..) The interestingness measures and thresholds for pattern evaluation Different kinds of knowledge may have different interestingness measures. 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›', 'Data', 'mining', 'task', 'primitives', '(', 'Cont', '..', ')', 'The', 'interestingness', 'measures', 'thresholds', 'pattern', 'evaluation', 'Different', 'kinds', 'knowledge', 'may', 'different', 'interestingness', 'measures', '.']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›'), ('›', 'Data'), ('Data', 'mining'), ('mining', 'task'), ('task', 'primitives'), ('primitives', '('), ('(', 'Cont'), ('Cont', '..'), ('..', ')'), (')', 'The'), ('The', 'interestingness'), ('interestingness', 'measures'), ('measures', 'thresholds'), ('thresholds', 'pattern'), ('pattern', 'evaluation'), ('evaluation', 'Different'), ('Different', 'kinds'), ('kinds', 'knowledge'), ('knowledge', 'may'), ('may', 'different'), ('different', 'interestingness'), ('interestingness', 'measures'), ('measures', '.')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›'), ('#', '›', 'Data'), ('›', 'Data', 'mining'), ('Data', 'mining', 'task'), ('mining', 'task', 'primitives'), ('task', 'primitives', '('), ('primitives', '(', 'Cont'), ('(', 'Cont', '..'), ('Cont', '..', ')'), ('..', ')', 'The'), (')', 'The', 'interestingness'), ('The', 'interestingness', 'measures'), ('interestingness', 'measures', 'thresholds'), ('measures', 'thresholds', 'pattern'), ('thresholds', 'pattern', 'evaluation'), ('pattern', 'evaluation', 'Different'), ('evaluation', 'Different', 'kinds'), ('Different', 'kinds', 'knowledge'), ('kinds', 'knowledge', 'may'), ('knowledge', 'may', 'different'), ('may', 'different', 'interestingness'), ('different', 'interestingness', 'measures'), ('interestingness', 'measures', '.')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('task', 'NN'), ('primitives', 'NNS'), ('(', '('), ('Cont', 'NNP'), ('..', 'NNP'), (')', ')'), ('The', 'DT'), ('interestingness', 'NN'), ('measures', 'VBZ'), ('thresholds', 'NNS'), ('pattern', 'JJ'), ('evaluation', 'NN'), ('Different', 'NNP'), ('kinds', 'NNS'), ('knowledge', 'VBP'), ('may', 'MD'), ('different', 'JJ'), ('interestingness', 'NN'), ('measures', 'NNS'), ('.', '.')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NNP Data/NNP mining/NN task/NN primitives/NNS)
  (/(
  (NP Cont/NNP ../NNP)
  )/)
  (NP The/DT interestingness/NN)
  measures/VBZ
  (NP thresholds/NNS)
  (NP pattern/JJ evaluation/NN Different/NNP kinds/NNS)
  knowledge/VBP
  may/MD
  (NP different/JJ interestingness/NN measures/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '› Data mining task primitives', 'Cont ..', 'The interestingness', 'thresholds', 'pattern evaluation Different kinds', 'different interestingness measures']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology'), ('ORGANIZATION', 'Cont')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('interestingness', 'interesting'), ('measures', 'measur'), ('thresholds', 'threshold'), ('pattern', 'pattern'), ('evaluation', 'evalu'), ('Different', 'differ'), ('kinds', 'kind'), ('knowledge', 'knowledg'), ('may', 'may'), ('different', 'differ'), ('interestingness', 'interesting'), ('measures', 'measur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'data'), ('mining', 'mine'), ('task', 'task'), ('primitives', 'primit'), ('(', '('), ('Cont', 'cont'), ('..', '..'), (')', ')'), ('The', 'the'), ('interestingness', 'interesting'), ('measures', 'measur'), ('thresholds', 'threshold'), ('pattern', 'pattern'), ('evaluation', 'evalu'), ('Different', 'differ'), ('kinds', 'kind'), ('knowledge', 'knowledg'), ('may', 'may'), ('different', 'differ'), ('interestingness', 'interesting'), ('measures', 'measur'), ('.', '.')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›'), ('Data', 'Data'), ('mining', 'mining'), ('task', 'task'), ('primitives', 'primitive'), ('(', '('), ('Cont', 'Cont'), ('..', '..'), (')', ')'), ('The', 'The'), ('interestingness', 'interestingness'), ('measures', 'measure'), ('thresholds', 'threshold'), ('pattern', 'pattern'), ('evaluation', 'evaluation'), ('Different', 'Different'), ('kinds', 'kind'), ('knowledge', 'knowledge'), ('may', 'may'), ('different', 'different'), ('interestingness', 'interestingness'), ('measures', 'measure'), ('.', '.')]



============================ Sentence 154 =============================

For example, interestingness measures for association rules include support and confidence. 


>> Tokens are: 
 ['For', 'example', ',', 'interestingness', 'measures', 'association', 'rules', 'include', 'support', 'confidence', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'interestingness'), ('interestingness', 'measures'), ('measures', 'association'), ('association', 'rules'), ('rules', 'include'), ('include', 'support'), ('support', 'confidence'), ('confidence', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'interestingness'), (',', 'interestingness', 'measures'), ('interestingness', 'measures', 'association'), ('measures', 'association', 'rules'), ('association', 'rules', 'include'), ('rules', 'include', 'support'), ('include', 'support', 'confidence'), ('support', 'confidence', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('interestingness', 'NN'), ('measures', 'NNS'), ('association', 'NN'), ('rules', 'NNS'), ('include', 'VBP'), ('support', 'NN'), ('confidence', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  (NP interestingness/NN measures/NNS association/NN rules/NNS)
  include/VBP
  (NP support/NN confidence/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'interestingness measures association rules', 'support confidence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('interestingness', 'interesting'), ('measures', 'measur'), ('association', 'associ'), ('rules', 'rule'), ('include', 'includ'), ('support', 'support'), ('confidence', 'confid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('interestingness', 'interesting'), ('measures', 'measur'), ('association', 'associ'), ('rules', 'rule'), ('include', 'includ'), ('support', 'support'), ('confidence', 'confid'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('interestingness', 'interestingness'), ('measures', 'measure'), ('association', 'association'), ('rules', 'rule'), ('include', 'include'), ('support', 'support'), ('confidence', 'confidence'), ('.', '.')]



============================ Sentence 155 =============================

Rules whose support and confidence values are below user-specified thresholds are considered uninteresting. 


>> Tokens are: 
 ['Rules', 'whose', 'support', 'confidence', 'values', 'user-specified', 'thresholds', 'considered', 'uninteresting', '.']

>> Bigrams are: 
 [('Rules', 'whose'), ('whose', 'support'), ('support', 'confidence'), ('confidence', 'values'), ('values', 'user-specified'), ('user-specified', 'thresholds'), ('thresholds', 'considered'), ('considered', 'uninteresting'), ('uninteresting', '.')]

>> Trigrams are: 
 [('Rules', 'whose', 'support'), ('whose', 'support', 'confidence'), ('support', 'confidence', 'values'), ('confidence', 'values', 'user-specified'), ('values', 'user-specified', 'thresholds'), ('user-specified', 'thresholds', 'considered'), ('thresholds', 'considered', 'uninteresting'), ('considered', 'uninteresting', '.')]

>> POS Tags are: 
 [('Rules', 'NNS'), ('whose', 'WP$'), ('support', 'NN'), ('confidence', 'NN'), ('values', 'NNS'), ('user-specified', 'JJ'), ('thresholds', 'NNS'), ('considered', 'VBN'), ('uninteresting', 'JJ'), ('.', '.')]

 (S
  (NP Rules/NNS)
  whose/WP$
  (NP support/NN confidence/NN values/NNS)
  (NP user-specified/JJ thresholds/NNS)
  considered/VBN
  uninteresting/JJ
  ./.) 


>> Noun Phrases are: 
 ['Rules', 'support confidence values', 'user-specified thresholds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rules', 'rule'), ('whose', 'whose'), ('support', 'support'), ('confidence', 'confid'), ('values', 'valu'), ('user-specified', 'user-specifi'), ('thresholds', 'threshold'), ('considered', 'consid'), ('uninteresting', 'uninterest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rules', 'rule'), ('whose', 'whose'), ('support', 'support'), ('confidence', 'confid'), ('values', 'valu'), ('user-specified', 'user-specifi'), ('thresholds', 'threshold'), ('considered', 'consid'), ('uninteresting', 'uninterest'), ('.', '.')]

>> Lemmatization: 
 [('Rules', 'Rules'), ('whose', 'whose'), ('support', 'support'), ('confidence', 'confidence'), ('values', 'value'), ('user-specified', 'user-specified'), ('thresholds', 'threshold'), ('considered', 'considered'), ('uninteresting', 'uninteresting'), ('.', '.')]



============================ Sentence 156 =============================

The expected representation for visualizing the discovered patterns It refers to the discovered patterns are to be displayed, which may include rules, tables, charts, graphs, decision trees, and cubes. 


>> Tokens are: 
 ['The', 'expected', 'representation', 'visualizing', 'discovered', 'patterns', 'It', 'refers', 'discovered', 'patterns', 'displayed', ',', 'may', 'include', 'rules', ',', 'tables', ',', 'charts', ',', 'graphs', ',', 'decision', 'trees', ',', 'cubes', '.']

>> Bigrams are: 
 [('The', 'expected'), ('expected', 'representation'), ('representation', 'visualizing'), ('visualizing', 'discovered'), ('discovered', 'patterns'), ('patterns', 'It'), ('It', 'refers'), ('refers', 'discovered'), ('discovered', 'patterns'), ('patterns', 'displayed'), ('displayed', ','), (',', 'may'), ('may', 'include'), ('include', 'rules'), ('rules', ','), (',', 'tables'), ('tables', ','), (',', 'charts'), ('charts', ','), (',', 'graphs'), ('graphs', ','), (',', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'cubes'), ('cubes', '.')]

>> Trigrams are: 
 [('The', 'expected', 'representation'), ('expected', 'representation', 'visualizing'), ('representation', 'visualizing', 'discovered'), ('visualizing', 'discovered', 'patterns'), ('discovered', 'patterns', 'It'), ('patterns', 'It', 'refers'), ('It', 'refers', 'discovered'), ('refers', 'discovered', 'patterns'), ('discovered', 'patterns', 'displayed'), ('patterns', 'displayed', ','), ('displayed', ',', 'may'), (',', 'may', 'include'), ('may', 'include', 'rules'), ('include', 'rules', ','), ('rules', ',', 'tables'), (',', 'tables', ','), ('tables', ',', 'charts'), (',', 'charts', ','), ('charts', ',', 'graphs'), (',', 'graphs', ','), ('graphs', ',', 'decision'), (',', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'cubes'), (',', 'cubes', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('expected', 'JJ'), ('representation', 'NN'), ('visualizing', 'VBG'), ('discovered', 'VBN'), ('patterns', 'NNS'), ('It', 'PRP'), ('refers', 'VBZ'), ('discovered', 'VBN'), ('patterns', 'NNS'), ('displayed', 'VBD'), (',', ','), ('may', 'MD'), ('include', 'VB'), ('rules', 'NNS'), (',', ','), ('tables', 'NNS'), (',', ','), ('charts', 'NNS'), (',', ','), ('graphs', 'NN'), (',', ','), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('cubes', 'NNS'), ('.', '.')]

 (S
  (NP The/DT expected/JJ representation/NN)
  visualizing/VBG
  discovered/VBN
  (NP patterns/NNS)
  It/PRP
  refers/VBZ
  discovered/VBN
  (NP patterns/NNS)
  displayed/VBD
  ,/,
  may/MD
  include/VB
  (NP rules/NNS)
  ,/,
  (NP tables/NNS)
  ,/,
  (NP charts/NNS)
  ,/,
  (NP graphs/NN)
  ,/,
  (NP decision/NN trees/NNS)
  ,/,
  (NP cubes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The expected representation', 'patterns', 'patterns', 'rules', 'tables', 'charts', 'graphs', 'decision trees', 'cubes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('expected', 'expect'), ('representation', 'represent'), ('visualizing', 'visual'), ('discovered', 'discov'), ('patterns', 'pattern'), ('It', 'it'), ('refers', 'refer'), ('discovered', 'discov'), ('patterns', 'pattern'), ('displayed', 'display'), (',', ','), ('may', 'may'), ('include', 'includ'), ('rules', 'rule'), (',', ','), ('tables', 'tabl'), (',', ','), ('charts', 'chart'), (',', ','), ('graphs', 'graph'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('cubes', 'cube'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('expected', 'expect'), ('representation', 'represent'), ('visualizing', 'visual'), ('discovered', 'discov'), ('patterns', 'pattern'), ('It', 'it'), ('refers', 'refer'), ('discovered', 'discov'), ('patterns', 'pattern'), ('displayed', 'display'), (',', ','), ('may', 'may'), ('include', 'includ'), ('rules', 'rule'), (',', ','), ('tables', 'tabl'), (',', ','), ('charts', 'chart'), (',', ','), ('graphs', 'graph'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('cubes', 'cube'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('expected', 'expected'), ('representation', 'representation'), ('visualizing', 'visualizing'), ('discovered', 'discovered'), ('patterns', 'pattern'), ('It', 'It'), ('refers', 'refers'), ('discovered', 'discovered'), ('patterns', 'pattern'), ('displayed', 'displayed'), (',', ','), ('may', 'may'), ('include', 'include'), ('rules', 'rule'), (',', ','), ('tables', 'table'), (',', ','), ('charts', 'chart'), (',', ','), ('graphs', 'graph'), (',', ','), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('cubes', 'cube'), ('.', '.')]



============================ Sentence 157 =============================

A data mining query language can be designed to incorporate these primitives, allowing users to flexibly interact with data mining systems. 


>> Tokens are: 
 ['A', 'data', 'mining', 'query', 'language', 'designed', 'incorporate', 'primitives', ',', 'allowing', 'users', 'flexibly', 'interact', 'data', 'mining', 'systems', '.']

>> Bigrams are: 
 [('A', 'data'), ('data', 'mining'), ('mining', 'query'), ('query', 'language'), ('language', 'designed'), ('designed', 'incorporate'), ('incorporate', 'primitives'), ('primitives', ','), (',', 'allowing'), ('allowing', 'users'), ('users', 'flexibly'), ('flexibly', 'interact'), ('interact', 'data'), ('data', 'mining'), ('mining', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('A', 'data', 'mining'), ('data', 'mining', 'query'), ('mining', 'query', 'language'), ('query', 'language', 'designed'), ('language', 'designed', 'incorporate'), ('designed', 'incorporate', 'primitives'), ('incorporate', 'primitives', ','), ('primitives', ',', 'allowing'), (',', 'allowing', 'users'), ('allowing', 'users', 'flexibly'), ('users', 'flexibly', 'interact'), ('flexibly', 'interact', 'data'), ('interact', 'data', 'mining'), ('data', 'mining', 'systems'), ('mining', 'systems', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('data', 'NN'), ('mining', 'NN'), ('query', 'NN'), ('language', 'NN'), ('designed', 'VBN'), ('incorporate', 'JJ'), ('primitives', 'NNS'), (',', ','), ('allowing', 'VBG'), ('users', 'NNS'), ('flexibly', 'RB'), ('interact', 'VB'), ('data', 'NNS'), ('mining', 'VBG'), ('systems', 'NNS'), ('.', '.')]

 (S
  (NP A/DT data/NN mining/NN query/NN language/NN)
  designed/VBN
  (NP incorporate/JJ primitives/NNS)
  ,/,
  allowing/VBG
  (NP users/NNS)
  flexibly/RB
  interact/VB
  (NP data/NNS)
  mining/VBG
  (NP systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A data mining query language', 'incorporate primitives', 'users', 'data', 'systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), ('language', 'languag'), ('designed', 'design'), ('incorporate', 'incorpor'), ('primitives', 'primit'), (',', ','), ('allowing', 'allow'), ('users', 'user'), ('flexibly', 'flexibl'), ('interact', 'interact'), ('data', 'data'), ('mining', 'mine'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('data', 'data'), ('mining', 'mine'), ('query', 'queri'), ('language', 'languag'), ('designed', 'design'), ('incorporate', 'incorpor'), ('primitives', 'primit'), (',', ','), ('allowing', 'allow'), ('users', 'user'), ('flexibly', 'flexibl'), ('interact', 'interact'), ('data', 'data'), ('mining', 'mine'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('data', 'data'), ('mining', 'mining'), ('query', 'query'), ('language', 'language'), ('designed', 'designed'), ('incorporate', 'incorporate'), ('primitives', 'primitive'), (',', ','), ('allowing', 'allowing'), ('users', 'user'), ('flexibly', 'flexibly'), ('interact', 'interact'), ('data', 'data'), ('mining', 'mining'), ('systems', 'system'), ('.', '.')]



============================ Sentence 158 =============================

Unit: 4 – Data Preprocessing		Darshan Institute of Engineering & Technology  ‹#› 


>> Tokens are: 
 ['Unit', ':', '4', '–', 'Data', 'Preprocessing', 'Darshan', 'Institute', 'Engineering', '&', 'Technology', '‹', '#', '›']

>> Bigrams are: 
 [('Unit', ':'), (':', '4'), ('4', '–'), ('–', 'Data'), ('Data', 'Preprocessing'), ('Preprocessing', 'Darshan'), ('Darshan', 'Institute'), ('Institute', 'Engineering'), ('Engineering', '&'), ('&', 'Technology'), ('Technology', '‹'), ('‹', '#'), ('#', '›')]

>> Trigrams are: 
 [('Unit', ':', '4'), (':', '4', '–'), ('4', '–', 'Data'), ('–', 'Data', 'Preprocessing'), ('Data', 'Preprocessing', 'Darshan'), ('Preprocessing', 'Darshan', 'Institute'), ('Darshan', 'Institute', 'Engineering'), ('Institute', 'Engineering', '&'), ('Engineering', '&', 'Technology'), ('&', 'Technology', '‹'), ('Technology', '‹', '#'), ('‹', '#', '›')]

>> POS Tags are: 
 [('Unit', 'NN'), (':', ':'), ('4', 'CD'), ('–', 'NNP'), ('Data', 'NNP'), ('Preprocessing', 'NNP'), ('Darshan', 'NNP'), ('Institute', 'NNP'), ('Engineering', 'NNP'), ('&', 'CC'), ('Technology', 'NNP'), ('‹', 'NNP'), ('#', '#'), ('›', 'NN')]

 (S
  (NP Unit/NN)
  :/:
  4/CD
  (NP
    –/NNP
    Data/NNP
    Preprocessing/NNP
    Darshan/NNP
    Institute/NNP
    Engineering/NNP)
  &/CC
  (NP Technology/NNP ‹/NNP)
  #/#
  (NP ›/NN)) 


>> Noun Phrases are: 
 ['Unit', '– Data Preprocessing Darshan Institute Engineering', 'Technology ‹', '›']

>> Named Entities are: 
 [('GPE', 'Unit'), ('PERSON', 'Darshan Institute'), ('ORGANIZATION', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›')]

>> Stemming using Snowball Stemmer: 
 [('Unit', 'unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'data'), ('Preprocessing', 'preprocess'), ('Darshan', 'darshan'), ('Institute', 'institut'), ('Engineering', 'engin'), ('&', '&'), ('Technology', 'technolog'), ('‹', '‹'), ('#', '#'), ('›', '›')]

>> Lemmatization: 
 [('Unit', 'Unit'), (':', ':'), ('4', '4'), ('–', '–'), ('Data', 'Data'), ('Preprocessing', 'Preprocessing'), ('Darshan', 'Darshan'), ('Institute', 'Institute'), ('Engineering', 'Engineering'), ('&', '&'), ('Technology', 'Technology'), ('‹', '‹'), ('#', '#'), ('›', '›')]

