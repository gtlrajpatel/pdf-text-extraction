				 *** Text Processing using NLTK *** 


============================ Sentence 1 =============================

A Very Brief Introduction to Machine Learning With Applications to Communication Systems  Osvaldo Simeone, Fellow, IEEE  Abstract—Given the unprecedented availability of data and computing resources, there is widespread renewed interest in applying data-driven machine learning methods to problems for which the development of conventional engineering solutions is challenged by modelling or al- gorithmic deficiencies. 


>> Tokens are: 
 ['A', 'Very', 'Brief', 'Introduction', 'Machine', 'Learning', 'With', 'Applications', 'Communication', 'Systems', 'Osvaldo', 'Simeone', ',', 'Fellow', ',', 'IEEE', 'Abstract—Given', 'unprecedented', 'availability', 'data', 'computing', 'resources', ',', 'widespread', 'renewed', 'interest', 'applying', 'data-driven', 'machine', 'learning', 'methods', 'problems', 'development', 'conventional', 'engineering', 'solutions', 'challenged', 'modelling', 'al-', 'gorithmic', 'deficiencies', '.']

>> Bigrams are: 
 [('A', 'Very'), ('Very', 'Brief'), ('Brief', 'Introduction'), ('Introduction', 'Machine'), ('Machine', 'Learning'), ('Learning', 'With'), ('With', 'Applications'), ('Applications', 'Communication'), ('Communication', 'Systems'), ('Systems', 'Osvaldo'), ('Osvaldo', 'Simeone'), ('Simeone', ','), (',', 'Fellow'), ('Fellow', ','), (',', 'IEEE'), ('IEEE', 'Abstract—Given'), ('Abstract—Given', 'unprecedented'), ('unprecedented', 'availability'), ('availability', 'data'), ('data', 'computing'), ('computing', 'resources'), ('resources', ','), (',', 'widespread'), ('widespread', 'renewed'), ('renewed', 'interest'), ('interest', 'applying'), ('applying', 'data-driven'), ('data-driven', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'problems'), ('problems', 'development'), ('development', 'conventional'), ('conventional', 'engineering'), ('engineering', 'solutions'), ('solutions', 'challenged'), ('challenged', 'modelling'), ('modelling', 'al-'), ('al-', 'gorithmic'), ('gorithmic', 'deficiencies'), ('deficiencies', '.')]

>> Trigrams are: 
 [('A', 'Very', 'Brief'), ('Very', 'Brief', 'Introduction'), ('Brief', 'Introduction', 'Machine'), ('Introduction', 'Machine', 'Learning'), ('Machine', 'Learning', 'With'), ('Learning', 'With', 'Applications'), ('With', 'Applications', 'Communication'), ('Applications', 'Communication', 'Systems'), ('Communication', 'Systems', 'Osvaldo'), ('Systems', 'Osvaldo', 'Simeone'), ('Osvaldo', 'Simeone', ','), ('Simeone', ',', 'Fellow'), (',', 'Fellow', ','), ('Fellow', ',', 'IEEE'), (',', 'IEEE', 'Abstract—Given'), ('IEEE', 'Abstract—Given', 'unprecedented'), ('Abstract—Given', 'unprecedented', 'availability'), ('unprecedented', 'availability', 'data'), ('availability', 'data', 'computing'), ('data', 'computing', 'resources'), ('computing', 'resources', ','), ('resources', ',', 'widespread'), (',', 'widespread', 'renewed'), ('widespread', 'renewed', 'interest'), ('renewed', 'interest', 'applying'), ('interest', 'applying', 'data-driven'), ('applying', 'data-driven', 'machine'), ('data-driven', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'problems'), ('methods', 'problems', 'development'), ('problems', 'development', 'conventional'), ('development', 'conventional', 'engineering'), ('conventional', 'engineering', 'solutions'), ('engineering', 'solutions', 'challenged'), ('solutions', 'challenged', 'modelling'), ('challenged', 'modelling', 'al-'), ('modelling', 'al-', 'gorithmic'), ('al-', 'gorithmic', 'deficiencies'), ('gorithmic', 'deficiencies', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Very', 'NNP'), ('Brief', 'JJ'), ('Introduction', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('With', 'IN'), ('Applications', 'NNP'), ('Communication', 'NNP'), ('Systems', 'NNP'), ('Osvaldo', 'NNP'), ('Simeone', 'NNP'), (',', ','), ('Fellow', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Abstract—Given', 'NNP'), ('unprecedented', 'JJ'), ('availability', 'NN'), ('data', 'NNS'), ('computing', 'VBG'), ('resources', 'NNS'), (',', ','), ('widespread', 'JJ'), ('renewed', 'VBN'), ('interest', 'NN'), ('applying', 'VBG'), ('data-driven', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('problems', 'NNS'), ('development', 'NN'), ('conventional', 'JJ'), ('engineering', 'NN'), ('solutions', 'NNS'), ('challenged', 'VBD'), ('modelling', 'VBG'), ('al-', 'JJ'), ('gorithmic', 'JJ'), ('deficiencies', 'NNS'), ('.', '.')]

 (S
  (NP A/DT Very/NNP)
  (NP Brief/JJ Introduction/NNP Machine/NNP Learning/NNP)
  With/IN
  (NP
    Applications/NNP
    Communication/NNP
    Systems/NNP
    Osvaldo/NNP
    Simeone/NNP)
  ,/,
  (NP Fellow/NNP)
  ,/,
  (NP IEEE/NNP Abstract—Given/NNP)
  (NP unprecedented/JJ availability/NN data/NNS)
  computing/VBG
  (NP resources/NNS)
  ,/,
  widespread/JJ
  renewed/VBN
  (NP interest/NN)
  applying/VBG
  (NP data-driven/JJ machine/NN)
  learning/VBG
  (NP methods/NNS problems/NNS development/NN)
  (NP conventional/JJ engineering/NN solutions/NNS)
  challenged/VBD
  modelling/VBG
  (NP al-/JJ gorithmic/JJ deficiencies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A Very', 'Brief Introduction Machine Learning', 'Applications Communication Systems Osvaldo Simeone', 'Fellow', 'IEEE Abstract—Given', 'unprecedented availability data', 'resources', 'interest', 'data-driven machine', 'methods problems development', 'conventional engineering solutions', 'al- gorithmic deficiencies']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Applications Communication Systems Osvaldo Simeone'), ('PERSON', 'Fellow'), ('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Very', 'veri'), ('Brief', 'brief'), ('Introduction', 'introduct'), ('Machine', 'machin'), ('Learning', 'learn'), ('With', 'with'), ('Applications', 'applic'), ('Communication', 'commun'), ('Systems', 'system'), ('Osvaldo', 'osvaldo'), ('Simeone', 'simeon'), (',', ','), ('Fellow', 'fellow'), (',', ','), ('IEEE', 'ieee'), ('Abstract—Given', 'abstract—given'), ('unprecedented', 'unpreced'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), (',', ','), ('widespread', 'widespread'), ('renewed', 'renew'), ('interest', 'interest'), ('applying', 'appli'), ('data-driven', 'data-driven'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('problems', 'problem'), ('development', 'develop'), ('conventional', 'convent'), ('engineering', 'engin'), ('solutions', 'solut'), ('challenged', 'challeng'), ('modelling', 'model'), ('al-', 'al-'), ('gorithmic', 'gorithm'), ('deficiencies', 'defici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Very', 'veri'), ('Brief', 'brief'), ('Introduction', 'introduct'), ('Machine', 'machin'), ('Learning', 'learn'), ('With', 'with'), ('Applications', 'applic'), ('Communication', 'communic'), ('Systems', 'system'), ('Osvaldo', 'osvaldo'), ('Simeone', 'simeon'), (',', ','), ('Fellow', 'fellow'), (',', ','), ('IEEE', 'ieee'), ('Abstract—Given', 'abstract—given'), ('unprecedented', 'unpreced'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), (',', ','), ('widespread', 'widespread'), ('renewed', 'renew'), ('interest', 'interest'), ('applying', 'appli'), ('data-driven', 'data-driven'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('problems', 'problem'), ('development', 'develop'), ('conventional', 'convent'), ('engineering', 'engin'), ('solutions', 'solut'), ('challenged', 'challeng'), ('modelling', 'model'), ('al-', 'al-'), ('gorithmic', 'gorithm'), ('deficiencies', 'defici'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Very', 'Very'), ('Brief', 'Brief'), ('Introduction', 'Introduction'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('With', 'With'), ('Applications', 'Applications'), ('Communication', 'Communication'), ('Systems', 'Systems'), ('Osvaldo', 'Osvaldo'), ('Simeone', 'Simeone'), (',', ','), ('Fellow', 'Fellow'), (',', ','), ('IEEE', 'IEEE'), ('Abstract—Given', 'Abstract—Given'), ('unprecedented', 'unprecedented'), ('availability', 'availability'), ('data', 'data'), ('computing', 'computing'), ('resources', 'resource'), (',', ','), ('widespread', 'widespread'), ('renewed', 'renewed'), ('interest', 'interest'), ('applying', 'applying'), ('data-driven', 'data-driven'), ('machine', 'machine'), ('learning', 'learning'), ('methods', 'method'), ('problems', 'problem'), ('development', 'development'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('solutions', 'solution'), ('challenged', 'challenged'), ('modelling', 'modelling'), ('al-', 'al-'), ('gorithmic', 'gorithmic'), ('deficiencies', 'deficiency'), ('.', '.')]



============================ Sentence 2 =============================

This tutorial-style paper starts by addressing the questions of why and when such techniques can be useful. 


>> Tokens are: 
 ['This', 'tutorial-style', 'paper', 'starts', 'addressing', 'questions', 'techniques', 'useful', '.']

>> Bigrams are: 
 [('This', 'tutorial-style'), ('tutorial-style', 'paper'), ('paper', 'starts'), ('starts', 'addressing'), ('addressing', 'questions'), ('questions', 'techniques'), ('techniques', 'useful'), ('useful', '.')]

>> Trigrams are: 
 [('This', 'tutorial-style', 'paper'), ('tutorial-style', 'paper', 'starts'), ('paper', 'starts', 'addressing'), ('starts', 'addressing', 'questions'), ('addressing', 'questions', 'techniques'), ('questions', 'techniques', 'useful'), ('techniques', 'useful', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('tutorial-style', 'JJ'), ('paper', 'NN'), ('starts', 'VBZ'), ('addressing', 'VBG'), ('questions', 'NNS'), ('techniques', 'NNS'), ('useful', 'JJ'), ('.', '.')]

 (S
  (NP This/DT tutorial-style/JJ paper/NN)
  starts/VBZ
  addressing/VBG
  (NP questions/NNS techniques/NNS)
  useful/JJ
  ./.) 


>> Noun Phrases are: 
 ['This tutorial-style paper', 'questions techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('tutorial-style', 'tutorial-styl'), ('paper', 'paper'), ('starts', 'start'), ('addressing', 'address'), ('questions', 'question'), ('techniques', 'techniqu'), ('useful', 'use'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('tutorial-style', 'tutorial-styl'), ('paper', 'paper'), ('starts', 'start'), ('addressing', 'address'), ('questions', 'question'), ('techniques', 'techniqu'), ('useful', 'use'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('tutorial-style', 'tutorial-style'), ('paper', 'paper'), ('starts', 'start'), ('addressing', 'addressing'), ('questions', 'question'), ('techniques', 'technique'), ('useful', 'useful'), ('.', '.')]



============================ Sentence 3 =============================

It then provides a high-level introduction to the basics of supervised and unsupervised learning. 


>> Tokens are: 
 ['It', 'provides', 'high-level', 'introduction', 'basics', 'supervised', 'unsupervised', 'learning', '.']

>> Bigrams are: 
 [('It', 'provides'), ('provides', 'high-level'), ('high-level', 'introduction'), ('introduction', 'basics'), ('basics', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('It', 'provides', 'high-level'), ('provides', 'high-level', 'introduction'), ('high-level', 'introduction', 'basics'), ('introduction', 'basics', 'supervised'), ('basics', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('provides', 'VBZ'), ('high-level', 'JJ'), ('introduction', 'NN'), ('basics', 'NNS'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  It/PRP
  provides/VBZ
  (NP high-level/JJ introduction/NN basics/NNS)
  supervised/VBD
  (NP unsupervised/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['high-level introduction basics', 'unsupervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('high-level', 'high-level'), ('introduction', 'introduct'), ('basics', 'basic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('high-level', 'high-level'), ('introduction', 'introduct'), ('basics', 'basic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('provides', 'provides'), ('high-level', 'high-level'), ('introduction', 'introduction'), ('basics', 'basic'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 4 =============================

For both supervised and unsupervised learning, exemplifying applications to communication networks are discussed by distinguishing tasks carried out at the edge and at the cloud segments of the network at different layers of the protocol stack, with an emphasis on the physical layer. 


>> Tokens are: 
 ['For', 'supervised', 'unsupervised', 'learning', ',', 'exemplifying', 'applications', 'communication', 'networks', 'discussed', 'distinguishing', 'tasks', 'carried', 'edge', 'cloud', 'segments', 'network', 'different', 'layers', 'protocol', 'stack', ',', 'emphasis', 'physical', 'layer', '.']

>> Bigrams are: 
 [('For', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'exemplifying'), ('exemplifying', 'applications'), ('applications', 'communication'), ('communication', 'networks'), ('networks', 'discussed'), ('discussed', 'distinguishing'), ('distinguishing', 'tasks'), ('tasks', 'carried'), ('carried', 'edge'), ('edge', 'cloud'), ('cloud', 'segments'), ('segments', 'network'), ('network', 'different'), ('different', 'layers'), ('layers', 'protocol'), ('protocol', 'stack'), ('stack', ','), (',', 'emphasis'), ('emphasis', 'physical'), ('physical', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('For', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'exemplifying'), (',', 'exemplifying', 'applications'), ('exemplifying', 'applications', 'communication'), ('applications', 'communication', 'networks'), ('communication', 'networks', 'discussed'), ('networks', 'discussed', 'distinguishing'), ('discussed', 'distinguishing', 'tasks'), ('distinguishing', 'tasks', 'carried'), ('tasks', 'carried', 'edge'), ('carried', 'edge', 'cloud'), ('edge', 'cloud', 'segments'), ('cloud', 'segments', 'network'), ('segments', 'network', 'different'), ('network', 'different', 'layers'), ('different', 'layers', 'protocol'), ('layers', 'protocol', 'stack'), ('protocol', 'stack', ','), ('stack', ',', 'emphasis'), (',', 'emphasis', 'physical'), ('emphasis', 'physical', 'layer'), ('physical', 'layer', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('supervised', 'VBN'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('exemplifying', 'VBG'), ('applications', 'NNS'), ('communication', 'NN'), ('networks', 'NNS'), ('discussed', 'VBD'), ('distinguishing', 'VBG'), ('tasks', 'NNS'), ('carried', 'VBD'), ('edge', 'JJ'), ('cloud', 'NN'), ('segments', 'NNS'), ('network', 'NN'), ('different', 'JJ'), ('layers', 'NNS'), ('protocol', 'VBP'), ('stack', 'NN'), (',', ','), ('emphasis', 'NN'), ('physical', 'JJ'), ('layer', 'NN'), ('.', '.')]

 (S
  For/IN
  supervised/VBN
  (NP unsupervised/JJ learning/NN)
  ,/,
  exemplifying/VBG
  (NP applications/NNS communication/NN networks/NNS)
  discussed/VBD
  distinguishing/VBG
  (NP tasks/NNS)
  carried/VBD
  (NP edge/JJ cloud/NN segments/NNS network/NN)
  (NP different/JJ layers/NNS)
  protocol/VBP
  (NP stack/NN)
  ,/,
  (NP emphasis/NN)
  (NP physical/JJ layer/NN)
  ./.) 


>> Noun Phrases are: 
 ['unsupervised learning', 'applications communication networks', 'tasks', 'edge cloud segments network', 'different layers', 'stack', 'emphasis', 'physical layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('exemplifying', 'exemplifi'), ('applications', 'applic'), ('communication', 'commun'), ('networks', 'network'), ('discussed', 'discuss'), ('distinguishing', 'distinguish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('cloud', 'cloud'), ('segments', 'segment'), ('network', 'network'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('emphasis', 'emphasi'), ('physical', 'physic'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('exemplifying', 'exemplifi'), ('applications', 'applic'), ('communication', 'communic'), ('networks', 'network'), ('discussed', 'discuss'), ('distinguishing', 'distinguish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('cloud', 'cloud'), ('segments', 'segment'), ('network', 'network'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('emphasis', 'emphasi'), ('physical', 'physic'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('exemplifying', 'exemplifying'), ('applications', 'application'), ('communication', 'communication'), ('networks', 'network'), ('discussed', 'discussed'), ('distinguishing', 'distinguishing'), ('tasks', 'task'), ('carried', 'carried'), ('edge', 'edge'), ('cloud', 'cloud'), ('segments', 'segment'), ('network', 'network'), ('different', 'different'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('emphasis', 'emphasis'), ('physical', 'physical'), ('layer', 'layer'), ('.', '.')]



============================ Sentence 5 =============================

I. 


>> Tokens are: 
 ['I', '.']

>> Bigrams are: 
 [('I', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('I', 'PRP'), ('.', '.')]

 (S I/PRP ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), ('.', '.')]



============================ Sentence 6 =============================

INTRODUCTION  After the “AI winter” of the 80s and the 90s, interest in the application of data-driven Artificial Intelligence (AI) techniques has been steadily increasing in a number of engineering fields, including speech and image analysis [1] and communications [2]. 


>> Tokens are: 
 ['INTRODUCTION', 'After', '“', 'AI', 'winter', '”', '80s', '90s', ',', 'interest', 'application', 'data-driven', 'Artificial', 'Intelligence', '(', 'AI', ')', 'techniques', 'steadily', 'increasing', 'number', 'engineering', 'fields', ',', 'including', 'speech', 'image', 'analysis', '[', '1', ']', 'communications', '[', '2', ']', '.']

>> Bigrams are: 
 [('INTRODUCTION', 'After'), ('After', '“'), ('“', 'AI'), ('AI', 'winter'), ('winter', '”'), ('”', '80s'), ('80s', '90s'), ('90s', ','), (',', 'interest'), ('interest', 'application'), ('application', 'data-driven'), ('data-driven', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', '('), ('(', 'AI'), ('AI', ')'), (')', 'techniques'), ('techniques', 'steadily'), ('steadily', 'increasing'), ('increasing', 'number'), ('number', 'engineering'), ('engineering', 'fields'), ('fields', ','), (',', 'including'), ('including', 'speech'), ('speech', 'image'), ('image', 'analysis'), ('analysis', '['), ('[', '1'), ('1', ']'), (']', 'communications'), ('communications', '['), ('[', '2'), ('2', ']'), (']', '.')]

>> Trigrams are: 
 [('INTRODUCTION', 'After', '“'), ('After', '“', 'AI'), ('“', 'AI', 'winter'), ('AI', 'winter', '”'), ('winter', '”', '80s'), ('”', '80s', '90s'), ('80s', '90s', ','), ('90s', ',', 'interest'), (',', 'interest', 'application'), ('interest', 'application', 'data-driven'), ('application', 'data-driven', 'Artificial'), ('data-driven', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', '('), ('Intelligence', '(', 'AI'), ('(', 'AI', ')'), ('AI', ')', 'techniques'), (')', 'techniques', 'steadily'), ('techniques', 'steadily', 'increasing'), ('steadily', 'increasing', 'number'), ('increasing', 'number', 'engineering'), ('number', 'engineering', 'fields'), ('engineering', 'fields', ','), ('fields', ',', 'including'), (',', 'including', 'speech'), ('including', 'speech', 'image'), ('speech', 'image', 'analysis'), ('image', 'analysis', '['), ('analysis', '[', '1'), ('[', '1', ']'), ('1', ']', 'communications'), (']', 'communications', '['), ('communications', '[', '2'), ('[', '2', ']'), ('2', ']', '.')]

>> POS Tags are: 
 [('INTRODUCTION', 'NN'), ('After', 'IN'), ('“', 'NN'), ('AI', 'NNP'), ('winter', 'NN'), ('”', 'VBD'), ('80s', 'CD'), ('90s', 'CD'), (',', ','), ('interest', 'NN'), ('application', 'NN'), ('data-driven', 'RB'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('techniques', 'NNS'), ('steadily', 'RB'), ('increasing', 'VBG'), ('number', 'NN'), ('engineering', 'NN'), ('fields', 'NNS'), (',', ','), ('including', 'VBG'), ('speech', 'JJ'), ('image', 'NN'), ('analysis', 'NN'), ('[', 'VBD'), ('1', 'CD'), (']', 'JJ'), ('communications', 'NNS'), ('[', 'VBP'), ('2', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP INTRODUCTION/NN)
  After/IN
  (NP “/NN AI/NNP winter/NN)
  ”/VBD
  80s/CD
  90s/CD
  ,/,
  (NP interest/NN application/NN)
  data-driven/RB
  (NP Artificial/NNP Intelligence/NNP)
  (/(
  (NP AI/NNP)
  )/)
  (NP techniques/NNS)
  steadily/RB
  increasing/VBG
  (NP number/NN engineering/NN fields/NNS)
  ,/,
  including/VBG
  (NP speech/JJ image/NN analysis/NN)
  [/VBD
  1/CD
  (NP ]/JJ communications/NNS)
  [/VBP
  2/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['INTRODUCTION', '“ AI winter', 'interest application', 'Artificial Intelligence', 'AI', 'techniques', 'number engineering fields', 'speech image analysis', '] communications', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('INTRODUCTION', 'introduct'), ('After', 'after'), ('“', '“'), ('AI', 'ai'), ('winter', 'winter'), ('”', '”'), ('80s', '80'), ('90s', '90'), (',', ','), ('interest', 'interest'), ('application', 'applic'), ('data-driven', 'data-driven'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('techniques', 'techniqu'), ('steadily', 'steadili'), ('increasing', 'increas'), ('number', 'number'), ('engineering', 'engin'), ('fields', 'field'), (',', ','), ('including', 'includ'), ('speech', 'speech'), ('image', 'imag'), ('analysis', 'analysi'), ('[', '['), ('1', '1'), (']', ']'), ('communications', 'commun'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('INTRODUCTION', 'introduct'), ('After', 'after'), ('“', '“'), ('AI', 'ai'), ('winter', 'winter'), ('”', '”'), ('80s', '80s'), ('90s', '90s'), (',', ','), ('interest', 'interest'), ('application', 'applic'), ('data-driven', 'data-driven'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('techniques', 'techniqu'), ('steadily', 'steadili'), ('increasing', 'increas'), ('number', 'number'), ('engineering', 'engin'), ('fields', 'field'), (',', ','), ('including', 'includ'), ('speech', 'speech'), ('image', 'imag'), ('analysis', 'analysi'), ('[', '['), ('1', '1'), (']', ']'), ('communications', 'communic'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('INTRODUCTION', 'INTRODUCTION'), ('After', 'After'), ('“', '“'), ('AI', 'AI'), ('winter', 'winter'), ('”', '”'), ('80s', '80'), ('90s', '90'), (',', ','), ('interest', 'interest'), ('application', 'application'), ('data-driven', 'data-driven'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('(', '('), ('AI', 'AI'), (')', ')'), ('techniques', 'technique'), ('steadily', 'steadily'), ('increasing', 'increasing'), ('number', 'number'), ('engineering', 'engineering'), ('fields', 'field'), (',', ','), ('including', 'including'), ('speech', 'speech'), ('image', 'image'), ('analysis', 'analysis'), ('[', '['), ('1', '1'), (']', ']'), ('communications', 'communication'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]



============================ Sentence 7 =============================

Unlike the logic-based expert systems that were dominant in the earlier work on AI (see, e.g.-.-, [3]), the renewed confidence in data- driven methods is motivated by the successes of pattern recognition tools based on machine learning. 


>> Tokens are: 
 ['Unlike', 'logic-based', 'expert', 'systems', 'dominant', 'earlier', 'work', 'AI', '(', 'see', ',', 'e.g.-.-', ',', '[', '3', ']', ')', ',', 'renewed', 'confidence', 'data-', 'driven', 'methods', 'motivated', 'successes', 'pattern', 'recognition', 'tools', 'based', 'machine', 'learning', '.']

>> Bigrams are: 
 [('Unlike', 'logic-based'), ('logic-based', 'expert'), ('expert', 'systems'), ('systems', 'dominant'), ('dominant', 'earlier'), ('earlier', 'work'), ('work', 'AI'), ('AI', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '3'), ('3', ']'), (']', ')'), (')', ','), (',', 'renewed'), ('renewed', 'confidence'), ('confidence', 'data-'), ('data-', 'driven'), ('driven', 'methods'), ('methods', 'motivated'), ('motivated', 'successes'), ('successes', 'pattern'), ('pattern', 'recognition'), ('recognition', 'tools'), ('tools', 'based'), ('based', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Unlike', 'logic-based', 'expert'), ('logic-based', 'expert', 'systems'), ('expert', 'systems', 'dominant'), ('systems', 'dominant', 'earlier'), ('dominant', 'earlier', 'work'), ('earlier', 'work', 'AI'), ('work', 'AI', '('), ('AI', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '3'), ('[', '3', ']'), ('3', ']', ')'), (']', ')', ','), (')', ',', 'renewed'), (',', 'renewed', 'confidence'), ('renewed', 'confidence', 'data-'), ('confidence', 'data-', 'driven'), ('data-', 'driven', 'methods'), ('driven', 'methods', 'motivated'), ('methods', 'motivated', 'successes'), ('motivated', 'successes', 'pattern'), ('successes', 'pattern', 'recognition'), ('pattern', 'recognition', 'tools'), ('recognition', 'tools', 'based'), ('tools', 'based', 'machine'), ('based', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('Unlike', 'IN'), ('logic-based', 'JJ'), ('expert', 'JJ'), ('systems', 'NNS'), ('dominant', 'JJ'), ('earlier', 'JJR'), ('work', 'NN'), ('AI', 'NNP'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('3', 'CD'), (']', 'NN'), (')', ')'), (',', ','), ('renewed', 'VBN'), ('confidence', 'NN'), ('data-', 'JJ'), ('driven', 'JJ'), ('methods', 'NNS'), ('motivated', 'VBN'), ('successes', 'NNS'), ('pattern', 'JJ'), ('recognition', 'NN'), ('tools', 'NNS'), ('based', 'VBN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  Unlike/IN
  (NP logic-based/JJ expert/JJ systems/NNS)
  dominant/JJ
  earlier/JJR
  (NP work/NN AI/NNP)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  3/CD
  (NP ]/NN)
  )/)
  ,/,
  renewed/VBN
  (NP confidence/NN)
  (NP data-/JJ driven/JJ methods/NNS)
  motivated/VBN
  (NP successes/NNS)
  (NP pattern/JJ recognition/NN tools/NNS)
  based/VBN
  (NP machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['logic-based expert systems', 'work AI', ']', 'confidence', 'data- driven methods', 'successes', 'pattern recognition tools', 'machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlike', 'unlik'), ('logic-based', 'logic-bas'), ('expert', 'expert'), ('systems', 'system'), ('dominant', 'domin'), ('earlier', 'earlier'), ('work', 'work'), ('AI', 'ai'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), (',', ','), ('renewed', 'renew'), ('confidence', 'confid'), ('data-', 'data-'), ('driven', 'driven'), ('methods', 'method'), ('motivated', 'motiv'), ('successes', 'success'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('tools', 'tool'), ('based', 'base'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlike', 'unlik'), ('logic-based', 'logic-bas'), ('expert', 'expert'), ('systems', 'system'), ('dominant', 'domin'), ('earlier', 'earlier'), ('work', 'work'), ('AI', 'ai'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), (',', ','), ('renewed', 'renew'), ('confidence', 'confid'), ('data-', 'data-'), ('driven', 'driven'), ('methods', 'method'), ('motivated', 'motiv'), ('successes', 'success'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('tools', 'tool'), ('based', 'base'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Unlike', 'Unlike'), ('logic-based', 'logic-based'), ('expert', 'expert'), ('systems', 'system'), ('dominant', 'dominant'), ('earlier', 'earlier'), ('work', 'work'), ('AI', 'AI'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), (',', ','), ('renewed', 'renewed'), ('confidence', 'confidence'), ('data-', 'data-'), ('driven', 'driven'), ('methods', 'method'), ('motivated', 'motivated'), ('successes', 'success'), ('pattern', 'pattern'), ('recognition', 'recognition'), ('tools', 'tool'), ('based', 'based'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 8 =============================

These tools rely on decades-old algorithms, such as backpropagation [4], the Expectation Maximization (EM) algorithm [5], and Q-learning [6], with a number of modern algorithmic advances, including novel regularization techniques and adaptive learning rate schedules (see review in [7]). 


>> Tokens are: 
 ['These', 'tools', 'rely', 'decades-old', 'algorithms', ',', 'backpropagation', '[', '4', ']', ',', 'Expectation', 'Maximization', '(', 'EM', ')', 'algorithm', '[', '5', ']', ',', 'Q-learning', '[', '6', ']', ',', 'number', 'modern', 'algorithmic', 'advances', ',', 'including', 'novel', 'regularization', 'techniques', 'adaptive', 'learning', 'rate', 'schedules', '(', 'see', 'review', '[', '7', ']', ')', '.']

>> Bigrams are: 
 [('These', 'tools'), ('tools', 'rely'), ('rely', 'decades-old'), ('decades-old', 'algorithms'), ('algorithms', ','), (',', 'backpropagation'), ('backpropagation', '['), ('[', '4'), ('4', ']'), (']', ','), (',', 'Expectation'), ('Expectation', 'Maximization'), ('Maximization', '('), ('(', 'EM'), ('EM', ')'), (')', 'algorithm'), ('algorithm', '['), ('[', '5'), ('5', ']'), (']', ','), (',', 'Q-learning'), ('Q-learning', '['), ('[', '6'), ('6', ']'), (']', ','), (',', 'number'), ('number', 'modern'), ('modern', 'algorithmic'), ('algorithmic', 'advances'), ('advances', ','), (',', 'including'), ('including', 'novel'), ('novel', 'regularization'), ('regularization', 'techniques'), ('techniques', 'adaptive'), ('adaptive', 'learning'), ('learning', 'rate'), ('rate', 'schedules'), ('schedules', '('), ('(', 'see'), ('see', 'review'), ('review', '['), ('[', '7'), ('7', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('These', 'tools', 'rely'), ('tools', 'rely', 'decades-old'), ('rely', 'decades-old', 'algorithms'), ('decades-old', 'algorithms', ','), ('algorithms', ',', 'backpropagation'), (',', 'backpropagation', '['), ('backpropagation', '[', '4'), ('[', '4', ']'), ('4', ']', ','), (']', ',', 'Expectation'), (',', 'Expectation', 'Maximization'), ('Expectation', 'Maximization', '('), ('Maximization', '(', 'EM'), ('(', 'EM', ')'), ('EM', ')', 'algorithm'), (')', 'algorithm', '['), ('algorithm', '[', '5'), ('[', '5', ']'), ('5', ']', ','), (']', ',', 'Q-learning'), (',', 'Q-learning', '['), ('Q-learning', '[', '6'), ('[', '6', ']'), ('6', ']', ','), (']', ',', 'number'), (',', 'number', 'modern'), ('number', 'modern', 'algorithmic'), ('modern', 'algorithmic', 'advances'), ('algorithmic', 'advances', ','), ('advances', ',', 'including'), (',', 'including', 'novel'), ('including', 'novel', 'regularization'), ('novel', 'regularization', 'techniques'), ('regularization', 'techniques', 'adaptive'), ('techniques', 'adaptive', 'learning'), ('adaptive', 'learning', 'rate'), ('learning', 'rate', 'schedules'), ('rate', 'schedules', '('), ('schedules', '(', 'see'), ('(', 'see', 'review'), ('see', 'review', '['), ('review', '[', '7'), ('[', '7', ']'), ('7', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('tools', 'NNS'), ('rely', 'RB'), ('decades-old', 'JJ'), ('algorithms', 'NN'), (',', ','), ('backpropagation', 'NN'), ('[', 'VBD'), ('4', 'CD'), (']', 'NN'), (',', ','), ('Expectation', 'NNP'), ('Maximization', 'NNP'), ('(', '('), ('EM', 'NNP'), (')', ')'), ('algorithm', 'VBP'), ('[', '$'), ('5', 'CD'), (']', 'NNP'), (',', ','), ('Q-learning', 'NNP'), ('[', 'NNP'), ('6', 'CD'), (']', 'NNP'), (',', ','), ('number', 'NN'), ('modern', 'JJ'), ('algorithmic', 'JJ'), ('advances', 'NNS'), (',', ','), ('including', 'VBG'), ('novel', 'JJ'), ('regularization', 'NN'), ('techniques', 'NNS'), ('adaptive', 'VBP'), ('learning', 'VBG'), ('rate', 'NN'), ('schedules', 'NNS'), ('(', '('), ('see', 'VB'), ('review', 'NN'), ('[', '$'), ('7', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP These/DT tools/NNS)
  rely/RB
  (NP decades-old/JJ algorithms/NN)
  ,/,
  (NP backpropagation/NN)
  [/VBD
  4/CD
  (NP ]/NN)
  ,/,
  (NP Expectation/NNP Maximization/NNP)
  (/(
  (NP EM/NNP)
  )/)
  algorithm/VBP
  [/$
  5/CD
  (NP ]/NNP)
  ,/,
  (NP Q-learning/NNP [/NNP)
  6/CD
  (NP ]/NNP)
  ,/,
  (NP number/NN)
  (NP modern/JJ algorithmic/JJ advances/NNS)
  ,/,
  including/VBG
  (NP novel/JJ regularization/NN techniques/NNS)
  adaptive/VBP
  learning/VBG
  (NP rate/NN schedules/NNS)
  (/(
  see/VB
  (NP review/NN)
  [/$
  7/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['These tools', 'decades-old algorithms', 'backpropagation', ']', 'Expectation Maximization', 'EM', ']', 'Q-learning [', ']', 'number', 'modern algorithmic advances', 'novel regularization techniques', 'rate schedules', 'review', ']']

>> Named Entities are: 
 [('PERSON', 'Expectation Maximization')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('tools', 'tool'), ('rely', 'reli'), ('decades-old', 'decades-old'), ('algorithms', 'algorithm'), (',', ','), ('backpropagation', 'backpropag'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('Expectation', 'expect'), ('Maximization', 'maxim'), ('(', '('), ('EM', 'em'), (')', ')'), ('algorithm', 'algorithm'), ('[', '['), ('5', '5'), (']', ']'), (',', ','), ('Q-learning', 'q-learn'), ('[', '['), ('6', '6'), (']', ']'), (',', ','), ('number', 'number'), ('modern', 'modern'), ('algorithmic', 'algorithm'), ('advances', 'advanc'), (',', ','), ('including', 'includ'), ('novel', 'novel'), ('regularization', 'regular'), ('techniques', 'techniqu'), ('adaptive', 'adapt'), ('learning', 'learn'), ('rate', 'rate'), ('schedules', 'schedul'), ('(', '('), ('see', 'see'), ('review', 'review'), ('[', '['), ('7', '7'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('tools', 'tool'), ('rely', 'reli'), ('decades-old', 'decades-old'), ('algorithms', 'algorithm'), (',', ','), ('backpropagation', 'backpropag'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('Expectation', 'expect'), ('Maximization', 'maxim'), ('(', '('), ('EM', 'em'), (')', ')'), ('algorithm', 'algorithm'), ('[', '['), ('5', '5'), (']', ']'), (',', ','), ('Q-learning', 'q-learn'), ('[', '['), ('6', '6'), (']', ']'), (',', ','), ('number', 'number'), ('modern', 'modern'), ('algorithmic', 'algorithm'), ('advances', 'advanc'), (',', ','), ('including', 'includ'), ('novel', 'novel'), ('regularization', 'regular'), ('techniques', 'techniqu'), ('adaptive', 'adapt'), ('learning', 'learn'), ('rate', 'rate'), ('schedules', 'schedul'), ('(', '('), ('see', 'see'), ('review', 'review'), ('[', '['), ('7', '7'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('tools', 'tool'), ('rely', 'rely'), ('decades-old', 'decades-old'), ('algorithms', 'algorithm'), (',', ','), ('backpropagation', 'backpropagation'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('Expectation', 'Expectation'), ('Maximization', 'Maximization'), ('(', '('), ('EM', 'EM'), (')', ')'), ('algorithm', 'algorithm'), ('[', '['), ('5', '5'), (']', ']'), (',', ','), ('Q-learning', 'Q-learning'), ('[', '['), ('6', '6'), (']', ']'), (',', ','), ('number', 'number'), ('modern', 'modern'), ('algorithmic', 'algorithmic'), ('advances', 'advance'), (',', ','), ('including', 'including'), ('novel', 'novel'), ('regularization', 'regularization'), ('techniques', 'technique'), ('adaptive', 'adaptive'), ('learning', 'learning'), ('rate', 'rate'), ('schedules', 'schedule'), ('(', '('), ('see', 'see'), ('review', 'review'), ('[', '['), ('7', '7'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 9 =============================

Their success is built on the unprecedented availability of data and computing resources in many engineering domains. 


>> Tokens are: 
 ['Their', 'success', 'built', 'unprecedented', 'availability', 'data', 'computing', 'resources', 'many', 'engineering', 'domains', '.']

>> Bigrams are: 
 [('Their', 'success'), ('success', 'built'), ('built', 'unprecedented'), ('unprecedented', 'availability'), ('availability', 'data'), ('data', 'computing'), ('computing', 'resources'), ('resources', 'many'), ('many', 'engineering'), ('engineering', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('Their', 'success', 'built'), ('success', 'built', 'unprecedented'), ('built', 'unprecedented', 'availability'), ('unprecedented', 'availability', 'data'), ('availability', 'data', 'computing'), ('data', 'computing', 'resources'), ('computing', 'resources', 'many'), ('resources', 'many', 'engineering'), ('many', 'engineering', 'domains'), ('engineering', 'domains', '.')]

>> POS Tags are: 
 [('Their', 'PRP$'), ('success', 'NN'), ('built', 'VBN'), ('unprecedented', 'JJ'), ('availability', 'NN'), ('data', 'NNS'), ('computing', 'VBG'), ('resources', 'NNS'), ('many', 'JJ'), ('engineering', 'NN'), ('domains', 'NNS'), ('.', '.')]

 (S
  Their/PRP$
  (NP success/NN)
  built/VBN
  (NP unprecedented/JJ availability/NN data/NNS)
  computing/VBG
  (NP resources/NNS)
  (NP many/JJ engineering/NN domains/NNS)
  ./.) 


>> Noun Phrases are: 
 ['success', 'unprecedented availability data', 'resources', 'many engineering domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Their', 'their'), ('success', 'success'), ('built', 'built'), ('unprecedented', 'unpreced'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), ('many', 'mani'), ('engineering', 'engin'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Their', 'their'), ('success', 'success'), ('built', 'built'), ('unprecedented', 'unpreced'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), ('many', 'mani'), ('engineering', 'engin'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('Their', 'Their'), ('success', 'success'), ('built', 'built'), ('unprecedented', 'unprecedented'), ('availability', 'availability'), ('data', 'data'), ('computing', 'computing'), ('resources', 'resource'), ('many', 'many'), ('engineering', 'engineering'), ('domains', 'domain'), ('.', '.')]



============================ Sentence 10 =============================

While the new wave of promises and breakthroughs around machine learning arguably falls short, at least for now, of the requirements that drove early AI research [3], [8], learning algorithms have proven to be useful in a number of important applications – and more is certainly on the way. 


>> Tokens are: 
 ['While', 'new', 'wave', 'promises', 'breakthroughs', 'around', 'machine', 'learning', 'arguably', 'falls', 'short', ',', 'least', ',', 'requirements', 'drove', 'early', 'AI', 'research', '[', '3', ']', ',', '[', '8', ']', ',', 'learning', 'algorithms', 'proven', 'useful', 'number', 'important', 'applications', '–', 'certainly', 'way', '.']

>> Bigrams are: 
 [('While', 'new'), ('new', 'wave'), ('wave', 'promises'), ('promises', 'breakthroughs'), ('breakthroughs', 'around'), ('around', 'machine'), ('machine', 'learning'), ('learning', 'arguably'), ('arguably', 'falls'), ('falls', 'short'), ('short', ','), (',', 'least'), ('least', ','), (',', 'requirements'), ('requirements', 'drove'), ('drove', 'early'), ('early', 'AI'), ('AI', 'research'), ('research', '['), ('[', '3'), ('3', ']'), (']', ','), (',', '['), ('[', '8'), ('8', ']'), (']', ','), (',', 'learning'), ('learning', 'algorithms'), ('algorithms', 'proven'), ('proven', 'useful'), ('useful', 'number'), ('number', 'important'), ('important', 'applications'), ('applications', '–'), ('–', 'certainly'), ('certainly', 'way'), ('way', '.')]

>> Trigrams are: 
 [('While', 'new', 'wave'), ('new', 'wave', 'promises'), ('wave', 'promises', 'breakthroughs'), ('promises', 'breakthroughs', 'around'), ('breakthroughs', 'around', 'machine'), ('around', 'machine', 'learning'), ('machine', 'learning', 'arguably'), ('learning', 'arguably', 'falls'), ('arguably', 'falls', 'short'), ('falls', 'short', ','), ('short', ',', 'least'), (',', 'least', ','), ('least', ',', 'requirements'), (',', 'requirements', 'drove'), ('requirements', 'drove', 'early'), ('drove', 'early', 'AI'), ('early', 'AI', 'research'), ('AI', 'research', '['), ('research', '[', '3'), ('[', '3', ']'), ('3', ']', ','), (']', ',', '['), (',', '[', '8'), ('[', '8', ']'), ('8', ']', ','), (']', ',', 'learning'), (',', 'learning', 'algorithms'), ('learning', 'algorithms', 'proven'), ('algorithms', 'proven', 'useful'), ('proven', 'useful', 'number'), ('useful', 'number', 'important'), ('number', 'important', 'applications'), ('important', 'applications', '–'), ('applications', '–', 'certainly'), ('–', 'certainly', 'way'), ('certainly', 'way', '.')]

>> POS Tags are: 
 [('While', 'IN'), ('new', 'JJ'), ('wave', 'VBP'), ('promises', 'NNS'), ('breakthroughs', 'VBP'), ('around', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('arguably', 'RB'), ('falls', 'VBZ'), ('short', 'JJ'), (',', ','), ('least', 'JJS'), (',', ','), ('requirements', 'NNS'), ('drove', 'VBD'), ('early', 'JJ'), ('AI', 'NNP'), ('research', 'NN'), ('[', 'VBD'), ('3', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('8', 'CD'), (']', 'NN'), (',', ','), ('learning', 'VBG'), ('algorithms', 'JJ'), ('proven', 'RB'), ('useful', 'JJ'), ('number', 'NN'), ('important', 'JJ'), ('applications', 'NNS'), ('–', 'VBP'), ('certainly', 'RB'), ('way', 'NN'), ('.', '.')]

 (S
  While/IN
  new/JJ
  wave/VBP
  (NP promises/NNS)
  breakthroughs/VBP
  around/IN
  (NP machine/NN learning/NN)
  arguably/RB
  falls/VBZ
  short/JJ
  ,/,
  least/JJS
  ,/,
  (NP requirements/NNS)
  drove/VBD
  (NP early/JJ AI/NNP research/NN)
  [/VBD
  3/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  8/CD
  (NP ]/NN)
  ,/,
  learning/VBG
  algorithms/JJ
  proven/RB
  (NP useful/JJ number/NN)
  (NP important/JJ applications/NNS)
  –/VBP
  certainly/RB
  (NP way/NN)
  ./.) 


>> Noun Phrases are: 
 ['promises', 'machine learning', 'requirements', 'early AI research', ']', ']', 'useful number', 'important applications', 'way']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('new', 'new'), ('wave', 'wave'), ('promises', 'promis'), ('breakthroughs', 'breakthrough'), ('around', 'around'), ('machine', 'machin'), ('learning', 'learn'), ('arguably', 'arguabl'), ('falls', 'fall'), ('short', 'short'), (',', ','), ('least', 'least'), (',', ','), ('requirements', 'requir'), ('drove', 'drove'), ('early', 'earli'), ('AI', 'ai'), ('research', 'research'), ('[', '['), ('3', '3'), (']', ']'), (',', ','), ('[', '['), ('8', '8'), (']', ']'), (',', ','), ('learning', 'learn'), ('algorithms', 'algorithm'), ('proven', 'proven'), ('useful', 'use'), ('number', 'number'), ('important', 'import'), ('applications', 'applic'), ('–', '–'), ('certainly', 'certainli'), ('way', 'way'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('new', 'new'), ('wave', 'wave'), ('promises', 'promis'), ('breakthroughs', 'breakthrough'), ('around', 'around'), ('machine', 'machin'), ('learning', 'learn'), ('arguably', 'arguabl'), ('falls', 'fall'), ('short', 'short'), (',', ','), ('least', 'least'), (',', ','), ('requirements', 'requir'), ('drove', 'drove'), ('early', 'earli'), ('AI', 'ai'), ('research', 'research'), ('[', '['), ('3', '3'), (']', ']'), (',', ','), ('[', '['), ('8', '8'), (']', ']'), (',', ','), ('learning', 'learn'), ('algorithms', 'algorithm'), ('proven', 'proven'), ('useful', 'use'), ('number', 'number'), ('important', 'import'), ('applications', 'applic'), ('–', '–'), ('certainly', 'certain'), ('way', 'way'), ('.', '.')]

>> Lemmatization: 
 [('While', 'While'), ('new', 'new'), ('wave', 'wave'), ('promises', 'promise'), ('breakthroughs', 'breakthrough'), ('around', 'around'), ('machine', 'machine'), ('learning', 'learning'), ('arguably', 'arguably'), ('falls', 'fall'), ('short', 'short'), (',', ','), ('least', 'least'), (',', ','), ('requirements', 'requirement'), ('drove', 'drove'), ('early', 'early'), ('AI', 'AI'), ('research', 'research'), ('[', '['), ('3', '3'), (']', ']'), (',', ','), ('[', '['), ('8', '8'), (']', ']'), (',', ','), ('learning', 'learning'), ('algorithms', 'algorithm'), ('proven', 'proven'), ('useful', 'useful'), ('number', 'number'), ('important', 'important'), ('applications', 'application'), ('–', '–'), ('certainly', 'certainly'), ('way', 'way'), ('.', '.')]



============================ Sentence 11 =============================

King’s College London, United Kingdom (email: osvaldo.simeone@kcl.ac.uk). 


>> Tokens are: 
 ['King', '’', 'College', 'London', ',', 'United', 'Kingdom', '(', 'email', ':', 'osvaldo.simeone', '@', 'kcl.ac.uk', ')', '.']

>> Bigrams are: 
 [('King', '’'), ('’', 'College'), ('College', 'London'), ('London', ','), (',', 'United'), ('United', 'Kingdom'), ('Kingdom', '('), ('(', 'email'), ('email', ':'), (':', 'osvaldo.simeone'), ('osvaldo.simeone', '@'), ('@', 'kcl.ac.uk'), ('kcl.ac.uk', ')'), (')', '.')]

>> Trigrams are: 
 [('King', '’', 'College'), ('’', 'College', 'London'), ('College', 'London', ','), ('London', ',', 'United'), (',', 'United', 'Kingdom'), ('United', 'Kingdom', '('), ('Kingdom', '(', 'email'), ('(', 'email', ':'), ('email', ':', 'osvaldo.simeone'), (':', 'osvaldo.simeone', '@'), ('osvaldo.simeone', '@', 'kcl.ac.uk'), ('@', 'kcl.ac.uk', ')'), ('kcl.ac.uk', ')', '.')]

>> POS Tags are: 
 [('King', 'VBG'), ('’', 'NNP'), ('College', 'NNP'), ('London', 'NNP'), (',', ','), ('United', 'NNP'), ('Kingdom', 'NNP'), ('(', '('), ('email', 'NN'), (':', ':'), ('osvaldo.simeone', 'NN'), ('@', 'NNP'), ('kcl.ac.uk', 'NN'), (')', ')'), ('.', '.')]

 (S
  King/VBG
  (NP ’/NNP College/NNP London/NNP)
  ,/,
  (NP United/NNP Kingdom/NNP)
  (/(
  (NP email/NN)
  :/:
  (NP osvaldo.simeone/NN @/NNP kcl.ac.uk/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['’ College London', 'United Kingdom', 'email', 'osvaldo.simeone @ kcl.ac.uk']

>> Named Entities are: 
 [('GPE', 'London'), ('GPE', 'United Kingdom')] 

>> Stemming using Porter Stemmer: 
 [('King', 'king'), ('’', '’'), ('College', 'colleg'), ('London', 'london'), (',', ','), ('United', 'unit'), ('Kingdom', 'kingdom'), ('(', '('), ('email', 'email'), (':', ':'), ('osvaldo.simeone', 'osvaldo.simeon'), ('@', '@'), ('kcl.ac.uk', 'kcl.ac.uk'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('King', 'king'), ('’', '’'), ('College', 'colleg'), ('London', 'london'), (',', ','), ('United', 'unit'), ('Kingdom', 'kingdom'), ('(', '('), ('email', 'email'), (':', ':'), ('osvaldo.simeone', 'osvaldo.simeon'), ('@', '@'), ('kcl.ac.uk', 'kcl.ac.uk'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('King', 'King'), ('’', '’'), ('College', 'College'), ('London', 'London'), (',', ','), ('United', 'United'), ('Kingdom', 'Kingdom'), ('(', '('), ('email', 'email'), (':', ':'), ('osvaldo.simeone', 'osvaldo.simeone'), ('@', '@'), ('kcl.ac.uk', 'kcl.ac.uk'), (')', ')'), ('.', '.')]



============================ Sentence 12 =============================

This work has received funding from the European Research Council (ERC) under the European Union Horizon 2020 research and innovation program (grant agreement 725731). 


>> Tokens are: 
 ['This', 'work', 'received', 'funding', 'European', 'Research', 'Council', '(', 'ERC', ')', 'European', 'Union', 'Horizon', '2020', 'research', 'innovation', 'program', '(', 'grant', 'agreement', '725731', ')', '.']

>> Bigrams are: 
 [('This', 'work'), ('work', 'received'), ('received', 'funding'), ('funding', 'European'), ('European', 'Research'), ('Research', 'Council'), ('Council', '('), ('(', 'ERC'), ('ERC', ')'), (')', 'European'), ('European', 'Union'), ('Union', 'Horizon'), ('Horizon', '2020'), ('2020', 'research'), ('research', 'innovation'), ('innovation', 'program'), ('program', '('), ('(', 'grant'), ('grant', 'agreement'), ('agreement', '725731'), ('725731', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'work', 'received'), ('work', 'received', 'funding'), ('received', 'funding', 'European'), ('funding', 'European', 'Research'), ('European', 'Research', 'Council'), ('Research', 'Council', '('), ('Council', '(', 'ERC'), ('(', 'ERC', ')'), ('ERC', ')', 'European'), (')', 'European', 'Union'), ('European', 'Union', 'Horizon'), ('Union', 'Horizon', '2020'), ('Horizon', '2020', 'research'), ('2020', 'research', 'innovation'), ('research', 'innovation', 'program'), ('innovation', 'program', '('), ('program', '(', 'grant'), ('(', 'grant', 'agreement'), ('grant', 'agreement', '725731'), ('agreement', '725731', ')'), ('725731', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('work', 'NN'), ('received', 'VBD'), ('funding', 'JJ'), ('European', 'JJ'), ('Research', 'NNP'), ('Council', 'NNP'), ('(', '('), ('ERC', 'NNP'), (')', ')'), ('European', 'NNP'), ('Union', 'NNP'), ('Horizon', 'NNP'), ('2020', 'CD'), ('research', 'NN'), ('innovation', 'NN'), ('program', 'NN'), ('(', '('), ('grant', 'JJ'), ('agreement', 'NN'), ('725731', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT work/NN)
  received/VBD
  (NP funding/JJ European/JJ Research/NNP Council/NNP)
  (/(
  (NP ERC/NNP)
  )/)
  (NP European/NNP Union/NNP Horizon/NNP)
  2020/CD
  (NP research/NN innovation/NN program/NN)
  (/(
  (NP grant/JJ agreement/NN)
  725731/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This work', 'funding European Research Council', 'ERC', 'European Union Horizon', 'research innovation program', 'grant agreement']

>> Named Entities are: 
 [('ORGANIZATION', 'European Research Council'), ('ORGANIZATION', 'ERC'), ('GPE', 'European')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('work', 'work'), ('received', 'receiv'), ('funding', 'fund'), ('European', 'european'), ('Research', 'research'), ('Council', 'council'), ('(', '('), ('ERC', 'erc'), (')', ')'), ('European', 'european'), ('Union', 'union'), ('Horizon', 'horizon'), ('2020', '2020'), ('research', 'research'), ('innovation', 'innov'), ('program', 'program'), ('(', '('), ('grant', 'grant'), ('agreement', 'agreement'), ('725731', '725731'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('work', 'work'), ('received', 'receiv'), ('funding', 'fund'), ('European', 'european'), ('Research', 'research'), ('Council', 'council'), ('(', '('), ('ERC', 'erc'), (')', ')'), ('European', 'european'), ('Union', 'union'), ('Horizon', 'horizon'), ('2020', '2020'), ('research', 'research'), ('innovation', 'innov'), ('program', 'program'), ('(', '('), ('grant', 'grant'), ('agreement', 'agreement'), ('725731', '725731'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('work', 'work'), ('received', 'received'), ('funding', 'funding'), ('European', 'European'), ('Research', 'Research'), ('Council', 'Council'), ('(', '('), ('ERC', 'ERC'), (')', ')'), ('European', 'European'), ('Union', 'Union'), ('Horizon', 'Horizon'), ('2020', '2020'), ('research', 'research'), ('innovation', 'innovation'), ('program', 'program'), ('(', '('), ('grant', 'grant'), ('agreement', 'agreement'), ('725731', '725731'), (')', ')'), ('.', '.')]



============================ Sentence 13 =============================

This paper provides a very brief introduction to key concepts in machine learning and to the literature on machine learning for communication systems. 


>> Tokens are: 
 ['This', 'paper', 'provides', 'brief', 'introduction', 'key', 'concepts', 'machine', 'learning', 'literature', 'machine', 'learning', 'communication', 'systems', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'provides'), ('provides', 'brief'), ('brief', 'introduction'), ('introduction', 'key'), ('key', 'concepts'), ('concepts', 'machine'), ('machine', 'learning'), ('learning', 'literature'), ('literature', 'machine'), ('machine', 'learning'), ('learning', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('This', 'paper', 'provides'), ('paper', 'provides', 'brief'), ('provides', 'brief', 'introduction'), ('brief', 'introduction', 'key'), ('introduction', 'key', 'concepts'), ('key', 'concepts', 'machine'), ('concepts', 'machine', 'learning'), ('machine', 'learning', 'literature'), ('learning', 'literature', 'machine'), ('literature', 'machine', 'learning'), ('machine', 'learning', 'communication'), ('learning', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('provides', 'VBZ'), ('brief', 'JJ'), ('introduction', 'NN'), ('key', 'JJ'), ('concepts', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('literature', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  (NP This/DT paper/NN)
  provides/VBZ
  (NP brief/JJ introduction/NN)
  (NP key/JJ concepts/NNS machine/NN)
  learning/VBG
  (NP literature/JJ machine/NN)
  learning/VBG
  (NP communication/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This paper', 'brief introduction', 'key concepts machine', 'literature machine', 'communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('provides', 'provid'), ('brief', 'brief'), ('introduction', 'introduct'), ('key', 'key'), ('concepts', 'concept'), ('machine', 'machin'), ('learning', 'learn'), ('literature', 'literatur'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('provides', 'provid'), ('brief', 'brief'), ('introduction', 'introduct'), ('key', 'key'), ('concepts', 'concept'), ('machine', 'machin'), ('learning', 'learn'), ('literature', 'literatur'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('provides', 'provides'), ('brief', 'brief'), ('introduction', 'introduction'), ('key', 'key'), ('concepts', 'concept'), ('machine', 'machine'), ('learning', 'learning'), ('literature', 'literature'), ('machine', 'machine'), ('learning', 'learning'), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]



============================ Sentence 14 =============================

Unlike other review papers such as [9]–[11], the presentation aims at highlighting conditions under which the use of machine learning is justified in engineering problems, as well as specific classes of learning algorithms that are suitable for their solution. 


>> Tokens are: 
 ['Unlike', 'review', 'papers', '[', '9', ']', '–', '[', '11', ']', ',', 'presentation', 'aims', 'highlighting', 'conditions', 'use', 'machine', 'learning', 'justified', 'engineering', 'problems', ',', 'well', 'specific', 'classes', 'learning', 'algorithms', 'suitable', 'solution', '.']

>> Bigrams are: 
 [('Unlike', 'review'), ('review', 'papers'), ('papers', '['), ('[', '9'), ('9', ']'), (']', '–'), ('–', '['), ('[', '11'), ('11', ']'), (']', ','), (',', 'presentation'), ('presentation', 'aims'), ('aims', 'highlighting'), ('highlighting', 'conditions'), ('conditions', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'justified'), ('justified', 'engineering'), ('engineering', 'problems'), ('problems', ','), (',', 'well'), ('well', 'specific'), ('specific', 'classes'), ('classes', 'learning'), ('learning', 'algorithms'), ('algorithms', 'suitable'), ('suitable', 'solution'), ('solution', '.')]

>> Trigrams are: 
 [('Unlike', 'review', 'papers'), ('review', 'papers', '['), ('papers', '[', '9'), ('[', '9', ']'), ('9', ']', '–'), (']', '–', '['), ('–', '[', '11'), ('[', '11', ']'), ('11', ']', ','), (']', ',', 'presentation'), (',', 'presentation', 'aims'), ('presentation', 'aims', 'highlighting'), ('aims', 'highlighting', 'conditions'), ('highlighting', 'conditions', 'use'), ('conditions', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'justified'), ('learning', 'justified', 'engineering'), ('justified', 'engineering', 'problems'), ('engineering', 'problems', ','), ('problems', ',', 'well'), (',', 'well', 'specific'), ('well', 'specific', 'classes'), ('specific', 'classes', 'learning'), ('classes', 'learning', 'algorithms'), ('learning', 'algorithms', 'suitable'), ('algorithms', 'suitable', 'solution'), ('suitable', 'solution', '.')]

>> POS Tags are: 
 [('Unlike', 'IN'), ('review', 'NN'), ('papers', 'NNS'), ('[', 'VBP'), ('9', 'CD'), (']', 'JJ'), ('–', 'NNP'), ('[', 'NNP'), ('11', 'CD'), (']', 'NNP'), (',', ','), ('presentation', 'NN'), ('aims', 'NNS'), ('highlighting', 'VBG'), ('conditions', 'NNS'), ('use', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('justified', 'VBD'), ('engineering', 'NN'), ('problems', 'NNS'), (',', ','), ('well', 'RB'), ('specific', 'JJ'), ('classes', 'NNS'), ('learning', 'VBG'), ('algorithms', 'NN'), ('suitable', 'JJ'), ('solution', 'NN'), ('.', '.')]

 (S
  Unlike/IN
  (NP review/NN papers/NNS)
  [/VBP
  9/CD
  (NP ]/JJ –/NNP [/NNP)
  11/CD
  (NP ]/NNP)
  ,/,
  (NP presentation/NN aims/NNS)
  highlighting/VBG
  (NP conditions/NNS)
  use/VBP
  (NP machine/NN learning/NN)
  justified/VBD
  (NP engineering/NN problems/NNS)
  ,/,
  well/RB
  (NP specific/JJ classes/NNS)
  learning/VBG
  (NP algorithms/NN)
  (NP suitable/JJ solution/NN)
  ./.) 


>> Noun Phrases are: 
 ['review papers', '] – [', ']', 'presentation aims', 'conditions', 'machine learning', 'engineering problems', 'specific classes', 'algorithms', 'suitable solution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlike', 'unlik'), ('review', 'review'), ('papers', 'paper'), ('[', '['), ('9', '9'), (']', ']'), ('–', '–'), ('[', '['), ('11', '11'), (']', ']'), (',', ','), ('presentation', 'present'), ('aims', 'aim'), ('highlighting', 'highlight'), ('conditions', 'condit'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('justified', 'justifi'), ('engineering', 'engin'), ('problems', 'problem'), (',', ','), ('well', 'well'), ('specific', 'specif'), ('classes', 'class'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('suitable', 'suitabl'), ('solution', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlike', 'unlik'), ('review', 'review'), ('papers', 'paper'), ('[', '['), ('9', '9'), (']', ']'), ('–', '–'), ('[', '['), ('11', '11'), (']', ']'), (',', ','), ('presentation', 'present'), ('aims', 'aim'), ('highlighting', 'highlight'), ('conditions', 'condit'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('justified', 'justifi'), ('engineering', 'engin'), ('problems', 'problem'), (',', ','), ('well', 'well'), ('specific', 'specif'), ('classes', 'class'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('suitable', 'suitabl'), ('solution', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('Unlike', 'Unlike'), ('review', 'review'), ('papers', 'paper'), ('[', '['), ('9', '9'), (']', ']'), ('–', '–'), ('[', '['), ('11', '11'), (']', ']'), (',', ','), ('presentation', 'presentation'), ('aims', 'aim'), ('highlighting', 'highlighting'), ('conditions', 'condition'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('justified', 'justified'), ('engineering', 'engineering'), ('problems', 'problem'), (',', ','), ('well', 'well'), ('specific', 'specific'), ('classes', 'class'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('suitable', 'suitable'), ('solution', 'solution'), ('.', '.')]



============================ Sentence 15 =============================

The presentation is organized around the description of general technical concepts, for which an overview of applications to communication networks is subsequently provided. 


>> Tokens are: 
 ['The', 'presentation', 'organized', 'around', 'description', 'general', 'technical', 'concepts', ',', 'overview', 'applications', 'communication', 'networks', 'subsequently', 'provided', '.']

>> Bigrams are: 
 [('The', 'presentation'), ('presentation', 'organized'), ('organized', 'around'), ('around', 'description'), ('description', 'general'), ('general', 'technical'), ('technical', 'concepts'), ('concepts', ','), (',', 'overview'), ('overview', 'applications'), ('applications', 'communication'), ('communication', 'networks'), ('networks', 'subsequently'), ('subsequently', 'provided'), ('provided', '.')]

>> Trigrams are: 
 [('The', 'presentation', 'organized'), ('presentation', 'organized', 'around'), ('organized', 'around', 'description'), ('around', 'description', 'general'), ('description', 'general', 'technical'), ('general', 'technical', 'concepts'), ('technical', 'concepts', ','), ('concepts', ',', 'overview'), (',', 'overview', 'applications'), ('overview', 'applications', 'communication'), ('applications', 'communication', 'networks'), ('communication', 'networks', 'subsequently'), ('networks', 'subsequently', 'provided'), ('subsequently', 'provided', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('presentation', 'NN'), ('organized', 'VBN'), ('around', 'IN'), ('description', 'NN'), ('general', 'JJ'), ('technical', 'JJ'), ('concepts', 'NNS'), (',', ','), ('overview', 'NN'), ('applications', 'NNS'), ('communication', 'NN'), ('networks', 'NNS'), ('subsequently', 'RB'), ('provided', 'VBN'), ('.', '.')]

 (S
  (NP The/DT presentation/NN)
  organized/VBN
  around/IN
  (NP description/NN)
  (NP general/JJ technical/JJ concepts/NNS)
  ,/,
  (NP overview/NN applications/NNS communication/NN networks/NNS)
  subsequently/RB
  provided/VBN
  ./.) 


>> Noun Phrases are: 
 ['The presentation', 'description', 'general technical concepts', 'overview applications communication networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('presentation', 'present'), ('organized', 'organ'), ('around', 'around'), ('description', 'descript'), ('general', 'gener'), ('technical', 'technic'), ('concepts', 'concept'), (',', ','), ('overview', 'overview'), ('applications', 'applic'), ('communication', 'commun'), ('networks', 'network'), ('subsequently', 'subsequ'), ('provided', 'provid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('presentation', 'present'), ('organized', 'organ'), ('around', 'around'), ('description', 'descript'), ('general', 'general'), ('technical', 'technic'), ('concepts', 'concept'), (',', ','), ('overview', 'overview'), ('applications', 'applic'), ('communication', 'communic'), ('networks', 'network'), ('subsequently', 'subsequ'), ('provided', 'provid'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('presentation', 'presentation'), ('organized', 'organized'), ('around', 'around'), ('description', 'description'), ('general', 'general'), ('technical', 'technical'), ('concepts', 'concept'), (',', ','), ('overview', 'overview'), ('applications', 'application'), ('communication', 'communication'), ('networks', 'network'), ('subsequently', 'subsequently'), ('provided', 'provided'), ('.', '.')]



============================ Sentence 16 =============================

These applications are chosen to exemplify general design criteria and tools and not to offer a comprehensive review of the state of the art and of the historical progression of advances on the topic. 


>> Tokens are: 
 ['These', 'applications', 'chosen', 'exemplify', 'general', 'design', 'criteria', 'tools', 'offer', 'comprehensive', 'review', 'state', 'art', 'historical', 'progression', 'advances', 'topic', '.']

>> Bigrams are: 
 [('These', 'applications'), ('applications', 'chosen'), ('chosen', 'exemplify'), ('exemplify', 'general'), ('general', 'design'), ('design', 'criteria'), ('criteria', 'tools'), ('tools', 'offer'), ('offer', 'comprehensive'), ('comprehensive', 'review'), ('review', 'state'), ('state', 'art'), ('art', 'historical'), ('historical', 'progression'), ('progression', 'advances'), ('advances', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('These', 'applications', 'chosen'), ('applications', 'chosen', 'exemplify'), ('chosen', 'exemplify', 'general'), ('exemplify', 'general', 'design'), ('general', 'design', 'criteria'), ('design', 'criteria', 'tools'), ('criteria', 'tools', 'offer'), ('tools', 'offer', 'comprehensive'), ('offer', 'comprehensive', 'review'), ('comprehensive', 'review', 'state'), ('review', 'state', 'art'), ('state', 'art', 'historical'), ('art', 'historical', 'progression'), ('historical', 'progression', 'advances'), ('progression', 'advances', 'topic'), ('advances', 'topic', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('applications', 'NNS'), ('chosen', 'VBP'), ('exemplify', 'VB'), ('general', 'JJ'), ('design', 'NN'), ('criteria', 'NN'), ('tools', 'NNS'), ('offer', 'VBP'), ('comprehensive', 'JJ'), ('review', 'NN'), ('state', 'NN'), ('art', 'JJ'), ('historical', 'JJ'), ('progression', 'NN'), ('advances', 'NNS'), ('topic', 'NN'), ('.', '.')]

 (S
  (NP These/DT applications/NNS)
  chosen/VBP
  exemplify/VB
  (NP general/JJ design/NN criteria/NN tools/NNS)
  offer/VBP
  (NP comprehensive/JJ review/NN state/NN)
  (NP art/JJ historical/JJ progression/NN advances/NNS topic/NN)
  ./.) 


>> Noun Phrases are: 
 ['These applications', 'general design criteria tools', 'comprehensive review state', 'art historical progression advances topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('applications', 'applic'), ('chosen', 'chosen'), ('exemplify', 'exemplifi'), ('general', 'gener'), ('design', 'design'), ('criteria', 'criteria'), ('tools', 'tool'), ('offer', 'offer'), ('comprehensive', 'comprehens'), ('review', 'review'), ('state', 'state'), ('art', 'art'), ('historical', 'histor'), ('progression', 'progress'), ('advances', 'advanc'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('applications', 'applic'), ('chosen', 'chosen'), ('exemplify', 'exemplifi'), ('general', 'general'), ('design', 'design'), ('criteria', 'criteria'), ('tools', 'tool'), ('offer', 'offer'), ('comprehensive', 'comprehens'), ('review', 'review'), ('state', 'state'), ('art', 'art'), ('historical', 'histor'), ('progression', 'progress'), ('advances', 'advanc'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('applications', 'application'), ('chosen', 'chosen'), ('exemplify', 'exemplify'), ('general', 'general'), ('design', 'design'), ('criteria', 'criterion'), ('tools', 'tool'), ('offer', 'offer'), ('comprehensive', 'comprehensive'), ('review', 'review'), ('state', 'state'), ('art', 'art'), ('historical', 'historical'), ('progression', 'progression'), ('advances', 'advance'), ('topic', 'topic'), ('.', '.')]



============================ Sentence 17 =============================

We proceed in this section by addressing the question “What is machine learning?”, by providing a taxonomy of machine learning methods, and by finally considering the question “When to use machine learning?”. 


>> Tokens are: 
 ['We', 'proceed', 'section', 'addressing', 'question', '“', 'What', 'machine', 'learning', '?', '”', ',', 'providing', 'taxonomy', 'machine', 'learning', 'methods', ',', 'finally', 'considering', 'question', '“', 'When', 'use', 'machine', 'learning', '?', '”', '.']

>> Bigrams are: 
 [('We', 'proceed'), ('proceed', 'section'), ('section', 'addressing'), ('addressing', 'question'), ('question', '“'), ('“', 'What'), ('What', 'machine'), ('machine', 'learning'), ('learning', '?'), ('?', '”'), ('”', ','), (',', 'providing'), ('providing', 'taxonomy'), ('taxonomy', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', ','), (',', 'finally'), ('finally', 'considering'), ('considering', 'question'), ('question', '“'), ('“', 'When'), ('When', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', '?'), ('?', '”'), ('”', '.')]

>> Trigrams are: 
 [('We', 'proceed', 'section'), ('proceed', 'section', 'addressing'), ('section', 'addressing', 'question'), ('addressing', 'question', '“'), ('question', '“', 'What'), ('“', 'What', 'machine'), ('What', 'machine', 'learning'), ('machine', 'learning', '?'), ('learning', '?', '”'), ('?', '”', ','), ('”', ',', 'providing'), (',', 'providing', 'taxonomy'), ('providing', 'taxonomy', 'machine'), ('taxonomy', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', ','), ('methods', ',', 'finally'), (',', 'finally', 'considering'), ('finally', 'considering', 'question'), ('considering', 'question', '“'), ('question', '“', 'When'), ('“', 'When', 'use'), ('When', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', '?'), ('learning', '?', '”'), ('?', '”', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('proceed', 'VBP'), ('section', 'NN'), ('addressing', 'VBG'), ('question', 'NN'), ('“', 'VBD'), ('What', 'WP'), ('machine', 'NN'), ('learning', 'VBG'), ('?', '.'), ('”', 'NN'), (',', ','), ('providing', 'VBG'), ('taxonomy', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), (',', ','), ('finally', 'RB'), ('considering', 'VBG'), ('question', 'NN'), ('“', 'NN'), ('When', 'WRB'), ('use', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('?', '.'), ('”', 'NN'), ('.', '.')]

 (S
  We/PRP
  proceed/VBP
  (NP section/NN)
  addressing/VBG
  (NP question/NN)
  “/VBD
  What/WP
  (NP machine/NN)
  learning/VBG
  ?/.
  (NP ”/NN)
  ,/,
  providing/VBG
  (NP taxonomy/JJ machine/NN)
  learning/VBG
  (NP methods/NNS)
  ,/,
  finally/RB
  considering/VBG
  (NP question/NN “/NN)
  When/WRB
  (NP use/NN machine/NN learning/NN)
  ?/.
  (NP ”/NN)
  ./.) 


>> Noun Phrases are: 
 ['section', 'question', 'machine', '”', 'taxonomy machine', 'methods', 'question “', 'use machine learning', '”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('proceed', 'proceed'), ('section', 'section'), ('addressing', 'address'), ('question', 'question'), ('“', '“'), ('What', 'what'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?'), ('”', '”'), (',', ','), ('providing', 'provid'), ('taxonomy', 'taxonomi'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), (',', ','), ('finally', 'final'), ('considering', 'consid'), ('question', 'question'), ('“', '“'), ('When', 'when'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('proceed', 'proceed'), ('section', 'section'), ('addressing', 'address'), ('question', 'question'), ('“', '“'), ('What', 'what'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?'), ('”', '”'), (',', ','), ('providing', 'provid'), ('taxonomy', 'taxonomi'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), (',', ','), ('finally', 'final'), ('considering', 'consid'), ('question', 'question'), ('“', '“'), ('When', 'when'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('proceed', 'proceed'), ('section', 'section'), ('addressing', 'addressing'), ('question', 'question'), ('“', '“'), ('What', 'What'), ('machine', 'machine'), ('learning', 'learning'), ('?', '?'), ('”', '”'), (',', ','), ('providing', 'providing'), ('taxonomy', 'taxonomy'), ('machine', 'machine'), ('learning', 'learning'), ('methods', 'method'), (',', ','), ('finally', 'finally'), ('considering', 'considering'), ('question', 'question'), ('“', '“'), ('When', 'When'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('?', '?'), ('”', '”'), ('.', '.')]



============================ Sentence 18 =============================

A. 


>> Tokens are: 
 ['A', '.']

>> Bigrams are: 
 [('A', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('.', '.')]

 (S A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('.', '.')]



============================ Sentence 19 =============================

What is Machine Learning? 


>> Tokens are: 
 ['What', 'Machine', 'Learning', '?']

>> Bigrams are: 
 [('What', 'Machine'), ('Machine', 'Learning'), ('Learning', '?')]

>> Trigrams are: 
 [('What', 'Machine', 'Learning'), ('Machine', 'Learning', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('?', '.')]

 (S What/WP (NP Machine/NNP Learning/NNP) ?/.) 


>> Noun Phrases are: 
 ['Machine Learning']

>> Named Entities are: 
 [('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('?', '?')]



============================ Sentence 20 =============================

In order to fix the ideas, it is useful to introduce the machine learning methodology as an alternative to the conventional engineering approach for the design of an algorithmic solution. 


>> Tokens are: 
 ['In', 'order', 'fix', 'ideas', ',', 'useful', 'introduce', 'machine', 'learning', 'methodology', 'alternative', 'conventional', 'engineering', 'approach', 'design', 'algorithmic', 'solution', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'fix'), ('fix', 'ideas'), ('ideas', ','), (',', 'useful'), ('useful', 'introduce'), ('introduce', 'machine'), ('machine', 'learning'), ('learning', 'methodology'), ('methodology', 'alternative'), ('alternative', 'conventional'), ('conventional', 'engineering'), ('engineering', 'approach'), ('approach', 'design'), ('design', 'algorithmic'), ('algorithmic', 'solution'), ('solution', '.')]

>> Trigrams are: 
 [('In', 'order', 'fix'), ('order', 'fix', 'ideas'), ('fix', 'ideas', ','), ('ideas', ',', 'useful'), (',', 'useful', 'introduce'), ('useful', 'introduce', 'machine'), ('introduce', 'machine', 'learning'), ('machine', 'learning', 'methodology'), ('learning', 'methodology', 'alternative'), ('methodology', 'alternative', 'conventional'), ('alternative', 'conventional', 'engineering'), ('conventional', 'engineering', 'approach'), ('engineering', 'approach', 'design'), ('approach', 'design', 'algorithmic'), ('design', 'algorithmic', 'solution'), ('algorithmic', 'solution', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('fix', 'NN'), ('ideas', 'NNS'), (',', ','), ('useful', 'JJ'), ('introduce', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('methodology', 'NN'), ('alternative', 'JJ'), ('conventional', 'JJ'), ('engineering', 'NN'), ('approach', 'NN'), ('design', 'NN'), ('algorithmic', 'JJ'), ('solution', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP order/NN fix/NN ideas/NNS)
  ,/,
  (NP useful/JJ introduce/NN machine/NN)
  learning/VBG
  (NP methodology/NN)
  (NP
    alternative/JJ
    conventional/JJ
    engineering/NN
    approach/NN
    design/NN)
  (NP algorithmic/JJ solution/NN)
  ./.) 


>> Noun Phrases are: 
 ['order fix ideas', 'useful introduce machine', 'methodology', 'alternative conventional engineering approach design', 'algorithmic solution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('useful', 'use'), ('introduce', 'introduc'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('alternative', 'altern'), ('conventional', 'convent'), ('engineering', 'engin'), ('approach', 'approach'), ('design', 'design'), ('algorithmic', 'algorithm'), ('solution', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('useful', 'use'), ('introduce', 'introduc'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('alternative', 'altern'), ('conventional', 'convent'), ('engineering', 'engin'), ('approach', 'approach'), ('design', 'design'), ('algorithmic', 'algorithm'), ('solution', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('useful', 'useful'), ('introduce', 'introduce'), ('machine', 'machine'), ('learning', 'learning'), ('methodology', 'methodology'), ('alternative', 'alternative'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('approach', 'approach'), ('design', 'design'), ('algorithmic', 'algorithmic'), ('solution', 'solution'), ('.', '.')]



============================ Sentence 21 =============================

As illustrated in Fig. 


>> Tokens are: 
 ['As', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('As', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN (NP illustrated/JJ Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 22 =============================

1(a), the conventional engineering design flow starts with the ac- quisition of domain knowledge: The problem of interest is studied in detail, producing a mathematical model that capture the physics of the set-up under study. 


>> Tokens are: 
 ['1', '(', ')', ',', 'conventional', 'engineering', 'design', 'flow', 'starts', 'ac-', 'quisition', 'domain', 'knowledge', ':', 'The', 'problem', 'interest', 'studied', 'detail', ',', 'producing', 'mathematical', 'model', 'capture', 'physics', 'set-up', 'study', '.']

>> Bigrams are: 
 [('1', '('), ('(', ')'), (')', ','), (',', 'conventional'), ('conventional', 'engineering'), ('engineering', 'design'), ('design', 'flow'), ('flow', 'starts'), ('starts', 'ac-'), ('ac-', 'quisition'), ('quisition', 'domain'), ('domain', 'knowledge'), ('knowledge', ':'), (':', 'The'), ('The', 'problem'), ('problem', 'interest'), ('interest', 'studied'), ('studied', 'detail'), ('detail', ','), (',', 'producing'), ('producing', 'mathematical'), ('mathematical', 'model'), ('model', 'capture'), ('capture', 'physics'), ('physics', 'set-up'), ('set-up', 'study'), ('study', '.')]

>> Trigrams are: 
 [('1', '(', ')'), ('(', ')', ','), (')', ',', 'conventional'), (',', 'conventional', 'engineering'), ('conventional', 'engineering', 'design'), ('engineering', 'design', 'flow'), ('design', 'flow', 'starts'), ('flow', 'starts', 'ac-'), ('starts', 'ac-', 'quisition'), ('ac-', 'quisition', 'domain'), ('quisition', 'domain', 'knowledge'), ('domain', 'knowledge', ':'), ('knowledge', ':', 'The'), (':', 'The', 'problem'), ('The', 'problem', 'interest'), ('problem', 'interest', 'studied'), ('interest', 'studied', 'detail'), ('studied', 'detail', ','), ('detail', ',', 'producing'), (',', 'producing', 'mathematical'), ('producing', 'mathematical', 'model'), ('mathematical', 'model', 'capture'), ('model', 'capture', 'physics'), ('capture', 'physics', 'set-up'), ('physics', 'set-up', 'study'), ('set-up', 'study', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('(', '('), (')', ')'), (',', ','), ('conventional', 'JJ'), ('engineering', 'NN'), ('design', 'NN'), ('flow', 'NN'), ('starts', 'VBZ'), ('ac-', 'JJ'), ('quisition', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), (':', ':'), ('The', 'DT'), ('problem', 'NN'), ('interest', 'NN'), ('studied', 'VBD'), ('detail', 'NN'), (',', ','), ('producing', 'VBG'), ('mathematical', 'JJ'), ('model', 'NN'), ('capture', 'NN'), ('physics', 'NNS'), ('set-up', 'JJ'), ('study', 'NN'), ('.', '.')]

 (S
  1/CD
  (/(
  )/)
  ,/,
  (NP conventional/JJ engineering/NN design/NN flow/NN)
  starts/VBZ
  (NP ac-/JJ quisition/NN domain/NN knowledge/NN)
  :/:
  (NP The/DT problem/NN interest/NN)
  studied/VBD
  (NP detail/NN)
  ,/,
  producing/VBG
  (NP mathematical/JJ model/NN capture/NN physics/NNS)
  (NP set-up/JJ study/NN)
  ./.) 


>> Noun Phrases are: 
 ['conventional engineering design flow', 'ac- quisition domain knowledge', 'The problem interest', 'detail', 'mathematical model capture physics', 'set-up study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('(', '('), (')', ')'), (',', ','), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), ('starts', 'start'), ('ac-', 'ac-'), ('quisition', 'quisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), (':', ':'), ('The', 'the'), ('problem', 'problem'), ('interest', 'interest'), ('studied', 'studi'), ('detail', 'detail'), (',', ','), ('producing', 'produc'), ('mathematical', 'mathemat'), ('model', 'model'), ('capture', 'captur'), ('physics', 'physic'), ('set-up', 'set-up'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('(', '('), (')', ')'), (',', ','), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), ('starts', 'start'), ('ac-', 'ac-'), ('quisition', 'quisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), (':', ':'), ('The', 'the'), ('problem', 'problem'), ('interest', 'interest'), ('studied', 'studi'), ('detail', 'detail'), (',', ','), ('producing', 'produc'), ('mathematical', 'mathemat'), ('model', 'model'), ('capture', 'captur'), ('physics', 'physic'), ('set-up', 'set-up'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('(', '('), (')', ')'), (',', ','), ('conventional', 'conventional'), ('engineering', 'engineering'), ('design', 'design'), ('flow', 'flow'), ('starts', 'start'), ('ac-', 'ac-'), ('quisition', 'quisition'), ('domain', 'domain'), ('knowledge', 'knowledge'), (':', ':'), ('The', 'The'), ('problem', 'problem'), ('interest', 'interest'), ('studied', 'studied'), ('detail', 'detail'), (',', ','), ('producing', 'producing'), ('mathematical', 'mathematical'), ('model', 'model'), ('capture', 'capture'), ('physics', 'physic'), ('set-up', 'set-up'), ('study', 'study'), ('.', '.')]



============================ Sentence 23 =============================

Based on the model, an optimized algorithm is produced that offers performance guarantees under the assumption that the given physics-based model is an accurate representation of reality. 


>> Tokens are: 
 ['Based', 'model', ',', 'optimized', 'algorithm', 'produced', 'offers', 'performance', 'guarantees', 'assumption', 'given', 'physics-based', 'model', 'accurate', 'representation', 'reality', '.']

>> Bigrams are: 
 [('Based', 'model'), ('model', ','), (',', 'optimized'), ('optimized', 'algorithm'), ('algorithm', 'produced'), ('produced', 'offers'), ('offers', 'performance'), ('performance', 'guarantees'), ('guarantees', 'assumption'), ('assumption', 'given'), ('given', 'physics-based'), ('physics-based', 'model'), ('model', 'accurate'), ('accurate', 'representation'), ('representation', 'reality'), ('reality', '.')]

>> Trigrams are: 
 [('Based', 'model', ','), ('model', ',', 'optimized'), (',', 'optimized', 'algorithm'), ('optimized', 'algorithm', 'produced'), ('algorithm', 'produced', 'offers'), ('produced', 'offers', 'performance'), ('offers', 'performance', 'guarantees'), ('performance', 'guarantees', 'assumption'), ('guarantees', 'assumption', 'given'), ('assumption', 'given', 'physics-based'), ('given', 'physics-based', 'model'), ('physics-based', 'model', 'accurate'), ('model', 'accurate', 'representation'), ('accurate', 'representation', 'reality'), ('representation', 'reality', '.')]

>> POS Tags are: 
 [('Based', 'VBN'), ('model', 'NN'), (',', ','), ('optimized', 'VBN'), ('algorithm', 'NN'), ('produced', 'VBD'), ('offers', 'NNS'), ('performance', 'NN'), ('guarantees', 'NNS'), ('assumption', 'NN'), ('given', 'VBN'), ('physics-based', 'JJ'), ('model', 'NN'), ('accurate', 'NN'), ('representation', 'NN'), ('reality', 'NN'), ('.', '.')]

 (S
  Based/VBN
  (NP model/NN)
  ,/,
  optimized/VBN
  (NP algorithm/NN)
  produced/VBD
  (NP offers/NNS performance/NN guarantees/NNS assumption/NN)
  given/VBN
  (NP
    physics-based/JJ
    model/NN
    accurate/NN
    representation/NN
    reality/NN)
  ./.) 


>> Noun Phrases are: 
 ['model', 'algorithm', 'offers performance guarantees assumption', 'physics-based model accurate representation reality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('model', 'model'), (',', ','), ('optimized', 'optim'), ('algorithm', 'algorithm'), ('produced', 'produc'), ('offers', 'offer'), ('performance', 'perform'), ('guarantees', 'guarante'), ('assumption', 'assumpt'), ('given', 'given'), ('physics-based', 'physics-bas'), ('model', 'model'), ('accurate', 'accur'), ('representation', 'represent'), ('reality', 'realiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('model', 'model'), (',', ','), ('optimized', 'optim'), ('algorithm', 'algorithm'), ('produced', 'produc'), ('offers', 'offer'), ('performance', 'perform'), ('guarantees', 'guarante'), ('assumption', 'assumpt'), ('given', 'given'), ('physics-based', 'physics-bas'), ('model', 'model'), ('accurate', 'accur'), ('representation', 'represent'), ('reality', 'realiti'), ('.', '.')]

>> Lemmatization: 
 [('Based', 'Based'), ('model', 'model'), (',', ','), ('optimized', 'optimized'), ('algorithm', 'algorithm'), ('produced', 'produced'), ('offers', 'offer'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('assumption', 'assumption'), ('given', 'given'), ('physics-based', 'physics-based'), ('model', 'model'), ('accurate', 'accurate'), ('representation', 'representation'), ('reality', 'reality'), ('.', '.')]



============================ Sentence 24 =============================

As an example, designing a decoding algorithm for a wireless fading channel under the conventional engi- neering approach would require the development, or the selection, of a physical model for the channel connecting transmitter and receiver. 


>> Tokens are: 
 ['As', 'example', ',', 'designing', 'decoding', 'algorithm', 'wireless', 'fading', 'channel', 'conventional', 'engi-', 'neering', 'approach', 'would', 'require', 'development', ',', 'selection', ',', 'physical', 'model', 'channel', 'connecting', 'transmitter', 'receiver', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'designing'), ('designing', 'decoding'), ('decoding', 'algorithm'), ('algorithm', 'wireless'), ('wireless', 'fading'), ('fading', 'channel'), ('channel', 'conventional'), ('conventional', 'engi-'), ('engi-', 'neering'), ('neering', 'approach'), ('approach', 'would'), ('would', 'require'), ('require', 'development'), ('development', ','), (',', 'selection'), ('selection', ','), (',', 'physical'), ('physical', 'model'), ('model', 'channel'), ('channel', 'connecting'), ('connecting', 'transmitter'), ('transmitter', 'receiver'), ('receiver', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'designing'), (',', 'designing', 'decoding'), ('designing', 'decoding', 'algorithm'), ('decoding', 'algorithm', 'wireless'), ('algorithm', 'wireless', 'fading'), ('wireless', 'fading', 'channel'), ('fading', 'channel', 'conventional'), ('channel', 'conventional', 'engi-'), ('conventional', 'engi-', 'neering'), ('engi-', 'neering', 'approach'), ('neering', 'approach', 'would'), ('approach', 'would', 'require'), ('would', 'require', 'development'), ('require', 'development', ','), ('development', ',', 'selection'), (',', 'selection', ','), ('selection', ',', 'physical'), (',', 'physical', 'model'), ('physical', 'model', 'channel'), ('model', 'channel', 'connecting'), ('channel', 'connecting', 'transmitter'), ('connecting', 'transmitter', 'receiver'), ('transmitter', 'receiver', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('designing', 'VBG'), ('decoding', 'VBG'), ('algorithm', 'JJ'), ('wireless', 'NN'), ('fading', 'VBG'), ('channel', 'JJ'), ('conventional', 'JJ'), ('engi-', 'JJ'), ('neering', 'NN'), ('approach', 'NN'), ('would', 'MD'), ('require', 'VB'), ('development', 'NN'), (',', ','), ('selection', 'NN'), (',', ','), ('physical', 'JJ'), ('model', 'NN'), ('channel', 'NN'), ('connecting', 'VBG'), ('transmitter', 'NN'), ('receiver', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  designing/VBG
  decoding/VBG
  (NP algorithm/JJ wireless/NN)
  fading/VBG
  (NP channel/JJ conventional/JJ engi-/JJ neering/NN approach/NN)
  would/MD
  require/VB
  (NP development/NN)
  ,/,
  (NP selection/NN)
  ,/,
  (NP physical/JJ model/NN channel/NN)
  connecting/VBG
  (NP transmitter/NN receiver/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'algorithm wireless', 'channel conventional engi- neering approach', 'development', 'selection', 'physical model channel', 'transmitter receiver']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('designing', 'design'), ('decoding', 'decod'), ('algorithm', 'algorithm'), ('wireless', 'wireless'), ('fading', 'fade'), ('channel', 'channel'), ('conventional', 'convent'), ('engi-', 'engi-'), ('neering', 'neer'), ('approach', 'approach'), ('would', 'would'), ('require', 'requir'), ('development', 'develop'), (',', ','), ('selection', 'select'), (',', ','), ('physical', 'physic'), ('model', 'model'), ('channel', 'channel'), ('connecting', 'connect'), ('transmitter', 'transmitt'), ('receiver', 'receiv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('designing', 'design'), ('decoding', 'decod'), ('algorithm', 'algorithm'), ('wireless', 'wireless'), ('fading', 'fade'), ('channel', 'channel'), ('conventional', 'convent'), ('engi-', 'engi-'), ('neering', 'neer'), ('approach', 'approach'), ('would', 'would'), ('require', 'requir'), ('development', 'develop'), (',', ','), ('selection', 'select'), (',', ','), ('physical', 'physic'), ('model', 'model'), ('channel', 'channel'), ('connecting', 'connect'), ('transmitter', 'transmitt'), ('receiver', 'receiv'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('designing', 'designing'), ('decoding', 'decoding'), ('algorithm', 'algorithm'), ('wireless', 'wireless'), ('fading', 'fading'), ('channel', 'channel'), ('conventional', 'conventional'), ('engi-', 'engi-'), ('neering', 'neering'), ('approach', 'approach'), ('would', 'would'), ('require', 'require'), ('development', 'development'), (',', ','), ('selection', 'selection'), (',', ','), ('physical', 'physical'), ('model', 'model'), ('channel', 'channel'), ('connecting', 'connecting'), ('transmitter', 'transmitter'), ('receiver', 'receiver'), ('.', '.')]



============================ Sentence 25 =============================

The solution would be obtained by tackling an optimization problem, and it would yield optimality guarantees under the given channel model. 


>> Tokens are: 
 ['The', 'solution', 'would', 'obtained', 'tackling', 'optimization', 'problem', ',', 'would', 'yield', 'optimality', 'guarantees', 'given', 'channel', 'model', '.']

>> Bigrams are: 
 [('The', 'solution'), ('solution', 'would'), ('would', 'obtained'), ('obtained', 'tackling'), ('tackling', 'optimization'), ('optimization', 'problem'), ('problem', ','), (',', 'would'), ('would', 'yield'), ('yield', 'optimality'), ('optimality', 'guarantees'), ('guarantees', 'given'), ('given', 'channel'), ('channel', 'model'), ('model', '.')]

>> Trigrams are: 
 [('The', 'solution', 'would'), ('solution', 'would', 'obtained'), ('would', 'obtained', 'tackling'), ('obtained', 'tackling', 'optimization'), ('tackling', 'optimization', 'problem'), ('optimization', 'problem', ','), ('problem', ',', 'would'), (',', 'would', 'yield'), ('would', 'yield', 'optimality'), ('yield', 'optimality', 'guarantees'), ('optimality', 'guarantees', 'given'), ('guarantees', 'given', 'channel'), ('given', 'channel', 'model'), ('channel', 'model', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('solution', 'NN'), ('would', 'MD'), ('obtained', 'VB'), ('tackling', 'VBG'), ('optimization', 'NN'), ('problem', 'NN'), (',', ','), ('would', 'MD'), ('yield', 'VB'), ('optimality', 'NN'), ('guarantees', 'NNS'), ('given', 'VBN'), ('channel', 'NNS'), ('model', 'NN'), ('.', '.')]

 (S
  (NP The/DT solution/NN)
  would/MD
  obtained/VB
  tackling/VBG
  (NP optimization/NN problem/NN)
  ,/,
  would/MD
  yield/VB
  (NP optimality/NN guarantees/NNS)
  given/VBN
  (NP channel/NNS model/NN)
  ./.) 


>> Noun Phrases are: 
 ['The solution', 'optimization problem', 'optimality guarantees', 'channel model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('solution', 'solut'), ('would', 'would'), ('obtained', 'obtain'), ('tackling', 'tackl'), ('optimization', 'optim'), ('problem', 'problem'), (',', ','), ('would', 'would'), ('yield', 'yield'), ('optimality', 'optim'), ('guarantees', 'guarante'), ('given', 'given'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('solution', 'solut'), ('would', 'would'), ('obtained', 'obtain'), ('tackling', 'tackl'), ('optimization', 'optim'), ('problem', 'problem'), (',', ','), ('would', 'would'), ('yield', 'yield'), ('optimality', 'optim'), ('guarantees', 'guarante'), ('given', 'given'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('solution', 'solution'), ('would', 'would'), ('obtained', 'obtained'), ('tackling', 'tackling'), ('optimization', 'optimization'), ('problem', 'problem'), (',', ','), ('would', 'would'), ('yield', 'yield'), ('optimality', 'optimality'), ('guarantees', 'guarantee'), ('given', 'given'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]



============================ Sentence 26 =============================

Typical example of channel models include Gaussian and fading channels (see, e.g.-.-, [12]). 


>> Tokens are: 
 ['Typical', 'example', 'channel', 'models', 'include', 'Gaussian', 'fading', 'channels', '(', 'see', ',', 'e.g.-.-', ',', '[', '12', ']', ')', '.']

>> Bigrams are: 
 [('Typical', 'example'), ('example', 'channel'), ('channel', 'models'), ('models', 'include'), ('include', 'Gaussian'), ('Gaussian', 'fading'), ('fading', 'channels'), ('channels', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '12'), ('12', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('Typical', 'example', 'channel'), ('example', 'channel', 'models'), ('channel', 'models', 'include'), ('models', 'include', 'Gaussian'), ('include', 'Gaussian', 'fading'), ('Gaussian', 'fading', 'channels'), ('fading', 'channels', '('), ('channels', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '12'), ('[', '12', ']'), ('12', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('Typical', 'JJ'), ('example', 'NN'), ('channel', 'NN'), ('models', 'NNS'), ('include', 'VBP'), ('Gaussian', 'JJ'), ('fading', 'NN'), ('channels', 'NNS'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('12', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Typical/JJ example/NN channel/NN models/NNS)
  include/VBP
  (NP Gaussian/JJ fading/NN channels/NNS)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  12/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Typical example channel models', 'Gaussian fading channels', ']']

>> Named Entities are: 
 [('GPE', 'Typical'), ('GPE', 'Gaussian')] 

>> Stemming using Porter Stemmer: 
 [('Typical', 'typic'), ('example', 'exampl'), ('channel', 'channel'), ('models', 'model'), ('include', 'includ'), ('Gaussian', 'gaussian'), ('fading', 'fade'), ('channels', 'channel'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('12', '12'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Typical', 'typic'), ('example', 'exampl'), ('channel', 'channel'), ('models', 'model'), ('include', 'includ'), ('Gaussian', 'gaussian'), ('fading', 'fade'), ('channels', 'channel'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('12', '12'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Typical', 'Typical'), ('example', 'example'), ('channel', 'channel'), ('models', 'model'), ('include', 'include'), ('Gaussian', 'Gaussian'), ('fading', 'fading'), ('channels', 'channel'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('12', '12'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 27 =============================

1  ar X  iv :1  80 8. 


>> Tokens are: 
 ['1', 'ar', 'X', 'iv', ':1', '80', '8', '.']

>> Bigrams are: 
 [('1', 'ar'), ('ar', 'X'), ('X', 'iv'), ('iv', ':1'), (':1', '80'), ('80', '8'), ('8', '.')]

>> Trigrams are: 
 [('1', 'ar', 'X'), ('ar', 'X', 'iv'), ('X', 'iv', ':1'), ('iv', ':1', '80'), (':1', '80', '8'), ('80', '8', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('ar', 'JJ'), ('X', 'NNP'), ('iv', 'NN'), (':1', 'VBD'), ('80', 'CD'), ('8', 'CD'), ('.', '.')]

 (S 1/CD (NP ar/JJ X/NNP iv/NN) :1/VBD 80/CD 8/CD ./.) 


>> Noun Phrases are: 
 ['ar X iv']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('ar', 'ar'), ('X', 'x'), ('iv', 'iv'), (':1', ':1'), ('80', '80'), ('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('ar', 'ar'), ('X', 'x'), ('iv', 'iv'), (':1', ':1'), ('80', '80'), ('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('ar', 'ar'), ('X', 'X'), ('iv', 'iv'), (':1', ':1'), ('80', '80'), ('8', '8'), ('.', '.')]



============================ Sentence 28 =============================

02 34  2v 4    [ cs  .I T  ]   5   N ov   2 01  8    acquisition   of domain   knowledge  algorithm   development  physics-based   mathematical model  algorithm with   performance   guarantees  acquisition   of data  learning  training set  black-box  machine  hypothesis   class  (a)  (b)  Fig. 


>> Tokens are: 
 ['02', '34', '2v', '4', '[', 'cs', '.I', 'T', ']', '5', 'N', 'ov', '2', '01', '8', 'acquisition', 'domain', 'knowledge', 'algorithm', 'development', 'physics-based', 'mathematical', 'model', 'algorithm', 'performance', 'guarantees', 'acquisition', 'data', 'learning', 'training', 'set', 'black-box', 'machine', 'hypothesis', 'class', '(', ')', '(', 'b', ')', 'Fig', '.']

>> Bigrams are: 
 [('02', '34'), ('34', '2v'), ('2v', '4'), ('4', '['), ('[', 'cs'), ('cs', '.I'), ('.I', 'T'), ('T', ']'), (']', '5'), ('5', 'N'), ('N', 'ov'), ('ov', '2'), ('2', '01'), ('01', '8'), ('8', 'acquisition'), ('acquisition', 'domain'), ('domain', 'knowledge'), ('knowledge', 'algorithm'), ('algorithm', 'development'), ('development', 'physics-based'), ('physics-based', 'mathematical'), ('mathematical', 'model'), ('model', 'algorithm'), ('algorithm', 'performance'), ('performance', 'guarantees'), ('guarantees', 'acquisition'), ('acquisition', 'data'), ('data', 'learning'), ('learning', 'training'), ('training', 'set'), ('set', 'black-box'), ('black-box', 'machine'), ('machine', 'hypothesis'), ('hypothesis', 'class'), ('class', '('), ('(', ')'), (')', '('), ('(', 'b'), ('b', ')'), (')', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('02', '34', '2v'), ('34', '2v', '4'), ('2v', '4', '['), ('4', '[', 'cs'), ('[', 'cs', '.I'), ('cs', '.I', 'T'), ('.I', 'T', ']'), ('T', ']', '5'), (']', '5', 'N'), ('5', 'N', 'ov'), ('N', 'ov', '2'), ('ov', '2', '01'), ('2', '01', '8'), ('01', '8', 'acquisition'), ('8', 'acquisition', 'domain'), ('acquisition', 'domain', 'knowledge'), ('domain', 'knowledge', 'algorithm'), ('knowledge', 'algorithm', 'development'), ('algorithm', 'development', 'physics-based'), ('development', 'physics-based', 'mathematical'), ('physics-based', 'mathematical', 'model'), ('mathematical', 'model', 'algorithm'), ('model', 'algorithm', 'performance'), ('algorithm', 'performance', 'guarantees'), ('performance', 'guarantees', 'acquisition'), ('guarantees', 'acquisition', 'data'), ('acquisition', 'data', 'learning'), ('data', 'learning', 'training'), ('learning', 'training', 'set'), ('training', 'set', 'black-box'), ('set', 'black-box', 'machine'), ('black-box', 'machine', 'hypothesis'), ('machine', 'hypothesis', 'class'), ('hypothesis', 'class', '('), ('class', '(', ')'), ('(', ')', '('), (')', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'Fig'), (')', 'Fig', '.')]

>> POS Tags are: 
 [('02', 'CD'), ('34', 'CD'), ('2v', 'CD'), ('4', 'CD'), ('[', 'NN'), ('cs', 'NN'), ('.I', 'NNP'), ('T', 'NNP'), (']', 'VBD'), ('5', 'CD'), ('N', 'NNP'), ('ov', 'VBD'), ('2', 'CD'), ('01', 'CD'), ('8', 'CD'), ('acquisition', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('algorithm', 'NN'), ('development', 'NN'), ('physics-based', 'JJ'), ('mathematical', 'JJ'), ('model', 'NN'), ('algorithm', 'JJ'), ('performance', 'NN'), ('guarantees', 'NNS'), ('acquisition', 'NN'), ('data', 'NNS'), ('learning', 'VBG'), ('training', 'NN'), ('set', 'VBN'), ('black-box', 'JJ'), ('machine', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('(', '('), (')', ')'), ('(', '('), ('b', 'NN'), (')', ')'), ('Fig', 'NNP'), ('.', '.')]

 (S
  02/CD
  34/CD
  2v/CD
  4/CD
  (NP [/NN cs/NN .I/NNP T/NNP)
  ]/VBD
  5/CD
  (NP N/NNP)
  ov/VBD
  2/CD
  01/CD
  8/CD
  (NP
    acquisition/NN
    domain/NN
    knowledge/NN
    algorithm/NN
    development/NN)
  (NP physics-based/JJ mathematical/JJ model/NN)
  (NP
    algorithm/JJ
    performance/NN
    guarantees/NNS
    acquisition/NN
    data/NNS)
  learning/VBG
  (NP training/NN)
  set/VBN
  (NP black-box/JJ machine/NN hypothesis/NN class/NN)
  (/(
  )/)
  (/(
  (NP b/NN)
  )/)
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['[ cs .I T', 'N', 'acquisition domain knowledge algorithm development', 'physics-based mathematical model', 'algorithm performance guarantees acquisition data', 'training', 'black-box machine hypothesis class', 'b', 'Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('02', '02'), ('34', '34'), ('2v', '2v'), ('4', '4'), ('[', '['), ('cs', 'cs'), ('.I', '.i'), ('T', 't'), (']', ']'), ('5', '5'), ('N', 'n'), ('ov', 'ov'), ('2', '2'), ('01', '01'), ('8', '8'), ('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('algorithm', 'algorithm'), ('development', 'develop'), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('model', 'model'), ('algorithm', 'algorithm'), ('performance', 'perform'), ('guarantees', 'guarante'), ('acquisition', 'acquisit'), ('data', 'data'), ('learning', 'learn'), ('training', 'train'), ('set', 'set'), ('black-box', 'black-box'), ('machine', 'machin'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('02', '02'), ('34', '34'), ('2v', '2v'), ('4', '4'), ('[', '['), ('cs', 'cs'), ('.I', '.i'), ('T', 't'), (']', ']'), ('5', '5'), ('N', 'n'), ('ov', 'ov'), ('2', '2'), ('01', '01'), ('8', '8'), ('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('algorithm', 'algorithm'), ('development', 'develop'), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('model', 'model'), ('algorithm', 'algorithm'), ('performance', 'perform'), ('guarantees', 'guarante'), ('acquisition', 'acquisit'), ('data', 'data'), ('learning', 'learn'), ('training', 'train'), ('set', 'set'), ('black-box', 'black-box'), ('machine', 'machin'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('02', '02'), ('34', '34'), ('2v', '2v'), ('4', '4'), ('[', '['), ('cs', 'c'), ('.I', '.I'), ('T', 'T'), (']', ']'), ('5', '5'), ('N', 'N'), ('ov', 'ov'), ('2', '2'), ('01', '01'), ('8', '8'), ('acquisition', 'acquisition'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('algorithm', 'algorithm'), ('development', 'development'), ('physics-based', 'physics-based'), ('mathematical', 'mathematical'), ('model', 'model'), ('algorithm', 'algorithm'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('acquisition', 'acquisition'), ('data', 'data'), ('learning', 'learning'), ('training', 'training'), ('set', 'set'), ('black-box', 'black-box'), ('machine', 'machine'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 29 =============================

1. 


>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

 (S 1/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



============================ Sentence 30 =============================

(a) Conventional engineering design flow; and (b) baseline machine learning methodology. 


>> Tokens are: 
 ['(', ')', 'Conventional', 'engineering', 'design', 'flow', ';', '(', 'b', ')', 'baseline', 'machine', 'learning', 'methodology', '.']

>> Bigrams are: 
 [('(', ')'), (')', 'Conventional'), ('Conventional', 'engineering'), ('engineering', 'design'), ('design', 'flow'), ('flow', ';'), (';', '('), ('(', 'b'), ('b', ')'), (')', 'baseline'), ('baseline', 'machine'), ('machine', 'learning'), ('learning', 'methodology'), ('methodology', '.')]

>> Trigrams are: 
 [('(', ')', 'Conventional'), (')', 'Conventional', 'engineering'), ('Conventional', 'engineering', 'design'), ('engineering', 'design', 'flow'), ('design', 'flow', ';'), ('flow', ';', '('), (';', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'baseline'), (')', 'baseline', 'machine'), ('baseline', 'machine', 'learning'), ('machine', 'learning', 'methodology'), ('learning', 'methodology', '.')]

>> POS Tags are: 
 [('(', '('), (')', ')'), ('Conventional', 'NNP'), ('engineering', 'NN'), ('design', 'NN'), ('flow', 'NN'), (';', ':'), ('(', '('), ('b', 'NN'), (')', ')'), ('baseline', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('methodology', 'NN'), ('.', '.')]

 (S
  (/(
  )/)
  (NP Conventional/NNP engineering/NN design/NN flow/NN)
  ;/:
  (/(
  (NP b/NN)
  )/)
  (NP baseline/NN machine/NN)
  learning/VBG
  (NP methodology/NN)
  ./.) 


>> Noun Phrases are: 
 ['Conventional engineering design flow', 'b', 'baseline machine', 'methodology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), (')', ')'), ('Conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('baseline', 'baselin'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), (')', ')'), ('Conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('baseline', 'baselin'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), (')', ')'), ('Conventional', 'Conventional'), ('engineering', 'engineering'), ('design', 'design'), ('flow', 'flow'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('baseline', 'baseline'), ('machine', 'machine'), ('learning', 'learning'), ('methodology', 'methodology'), ('.', '.')]



============================ Sentence 31 =============================

In contrast, in its most basic form, the machine learning approach substitutes the step of acquiring do- main knowledge with the potentially easier task of collecting a sufficiently large number of examples of desired behaviour for the algorithm of interest. 


>> Tokens are: 
 ['In', 'contrast', ',', 'basic', 'form', ',', 'machine', 'learning', 'approach', 'substitutes', 'step', 'acquiring', 'do-', 'main', 'knowledge', 'potentially', 'easier', 'task', 'collecting', 'sufficiently', 'large', 'number', 'examples', 'desired', 'behaviour', 'algorithm', 'interest', '.']

>> Bigrams are: 
 [('In', 'contrast'), ('contrast', ','), (',', 'basic'), ('basic', 'form'), ('form', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'approach'), ('approach', 'substitutes'), ('substitutes', 'step'), ('step', 'acquiring'), ('acquiring', 'do-'), ('do-', 'main'), ('main', 'knowledge'), ('knowledge', 'potentially'), ('potentially', 'easier'), ('easier', 'task'), ('task', 'collecting'), ('collecting', 'sufficiently'), ('sufficiently', 'large'), ('large', 'number'), ('number', 'examples'), ('examples', 'desired'), ('desired', 'behaviour'), ('behaviour', 'algorithm'), ('algorithm', 'interest'), ('interest', '.')]

>> Trigrams are: 
 [('In', 'contrast', ','), ('contrast', ',', 'basic'), (',', 'basic', 'form'), ('basic', 'form', ','), ('form', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'approach'), ('learning', 'approach', 'substitutes'), ('approach', 'substitutes', 'step'), ('substitutes', 'step', 'acquiring'), ('step', 'acquiring', 'do-'), ('acquiring', 'do-', 'main'), ('do-', 'main', 'knowledge'), ('main', 'knowledge', 'potentially'), ('knowledge', 'potentially', 'easier'), ('potentially', 'easier', 'task'), ('easier', 'task', 'collecting'), ('task', 'collecting', 'sufficiently'), ('collecting', 'sufficiently', 'large'), ('sufficiently', 'large', 'number'), ('large', 'number', 'examples'), ('number', 'examples', 'desired'), ('examples', 'desired', 'behaviour'), ('desired', 'behaviour', 'algorithm'), ('behaviour', 'algorithm', 'interest'), ('algorithm', 'interest', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('contrast', 'NN'), (',', ','), ('basic', 'JJ'), ('form', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('approach', 'NN'), ('substitutes', 'NNS'), ('step', 'VBP'), ('acquiring', 'VBG'), ('do-', 'JJ'), ('main', 'JJ'), ('knowledge', 'NN'), ('potentially', 'RB'), ('easier', 'JJR'), ('task', 'NN'), ('collecting', 'VBG'), ('sufficiently', 'RB'), ('large', 'JJ'), ('number', 'NN'), ('examples', 'NNS'), ('desired', 'VBD'), ('behaviour', 'JJ'), ('algorithm', 'JJ'), ('interest', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP contrast/NN)
  ,/,
  (NP basic/JJ form/NN)
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP approach/NN substitutes/NNS)
  step/VBP
  acquiring/VBG
  (NP do-/JJ main/JJ knowledge/NN)
  potentially/RB
  easier/JJR
  (NP task/NN)
  collecting/VBG
  sufficiently/RB
  (NP large/JJ number/NN examples/NNS)
  desired/VBD
  (NP behaviour/JJ algorithm/JJ interest/NN)
  ./.) 


>> Noun Phrases are: 
 ['contrast', 'basic form', 'machine', 'approach substitutes', 'do- main knowledge', 'task', 'large number examples', 'behaviour algorithm interest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('basic', 'basic'), ('form', 'form'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('substitutes', 'substitut'), ('step', 'step'), ('acquiring', 'acquir'), ('do-', 'do-'), ('main', 'main'), ('knowledge', 'knowledg'), ('potentially', 'potenti'), ('easier', 'easier'), ('task', 'task'), ('collecting', 'collect'), ('sufficiently', 'suffici'), ('large', 'larg'), ('number', 'number'), ('examples', 'exampl'), ('desired', 'desir'), ('behaviour', 'behaviour'), ('algorithm', 'algorithm'), ('interest', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('basic', 'basic'), ('form', 'form'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('substitutes', 'substitut'), ('step', 'step'), ('acquiring', 'acquir'), ('do-', 'do-'), ('main', 'main'), ('knowledge', 'knowledg'), ('potentially', 'potenti'), ('easier', 'easier'), ('task', 'task'), ('collecting', 'collect'), ('sufficiently', 'suffici'), ('large', 'larg'), ('number', 'number'), ('examples', 'exampl'), ('desired', 'desir'), ('behaviour', 'behaviour'), ('algorithm', 'algorithm'), ('interest', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('contrast', 'contrast'), (',', ','), ('basic', 'basic'), ('form', 'form'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('approach', 'approach'), ('substitutes', 'substitute'), ('step', 'step'), ('acquiring', 'acquiring'), ('do-', 'do-'), ('main', 'main'), ('knowledge', 'knowledge'), ('potentially', 'potentially'), ('easier', 'easier'), ('task', 'task'), ('collecting', 'collecting'), ('sufficiently', 'sufficiently'), ('large', 'large'), ('number', 'number'), ('examples', 'example'), ('desired', 'desired'), ('behaviour', 'behaviour'), ('algorithm', 'algorithm'), ('interest', 'interest'), ('.', '.')]



============================ Sentence 32 =============================

These examples constitute the training set. 


>> Tokens are: 
 ['These', 'examples', 'constitute', 'training', 'set', '.']

>> Bigrams are: 
 [('These', 'examples'), ('examples', 'constitute'), ('constitute', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('These', 'examples', 'constitute'), ('examples', 'constitute', 'training'), ('constitute', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('examples', 'NNS'), ('constitute', 'VBP'), ('training', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  (NP These/DT examples/NNS)
  constitute/VBP
  (NP training/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['These examples', 'training set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('examples', 'exampl'), ('constitute', 'constitut'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('examples', 'exampl'), ('constitute', 'constitut'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('examples', 'example'), ('constitute', 'constitute'), ('training', 'training'), ('set', 'set'), ('.', '.')]



============================ Sentence 33 =============================

As seen in Fig. 


>> Tokens are: 
 ['As', 'seen', 'Fig', '.']

>> Bigrams are: 
 [('As', 'seen'), ('seen', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'seen', 'Fig'), ('seen', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('seen', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN seen/VBN (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('seen', 'seen'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('seen', 'seen'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('seen', 'seen'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 34 =============================

1(b), the examples in the training set are fed to a learning algorithm to produce a trained “machine” that carries out the desired task. 


>> Tokens are: 
 ['1', '(', 'b', ')', ',', 'examples', 'training', 'set', 'fed', 'learning', 'algorithm', 'produce', 'trained', '“', 'machine', '”', 'carries', 'desired', 'task', '.']

>> Bigrams are: 
 [('1', '('), ('(', 'b'), ('b', ')'), (')', ','), (',', 'examples'), ('examples', 'training'), ('training', 'set'), ('set', 'fed'), ('fed', 'learning'), ('learning', 'algorithm'), ('algorithm', 'produce'), ('produce', 'trained'), ('trained', '“'), ('“', 'machine'), ('machine', '”'), ('”', 'carries'), ('carries', 'desired'), ('desired', 'task'), ('task', '.')]

>> Trigrams are: 
 [('1', '(', 'b'), ('(', 'b', ')'), ('b', ')', ','), (')', ',', 'examples'), (',', 'examples', 'training'), ('examples', 'training', 'set'), ('training', 'set', 'fed'), ('set', 'fed', 'learning'), ('fed', 'learning', 'algorithm'), ('learning', 'algorithm', 'produce'), ('algorithm', 'produce', 'trained'), ('produce', 'trained', '“'), ('trained', '“', 'machine'), ('“', 'machine', '”'), ('machine', '”', 'carries'), ('”', 'carries', 'desired'), ('carries', 'desired', 'task'), ('desired', 'task', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('(', '('), ('b', 'NN'), (')', ')'), (',', ','), ('examples', 'VBZ'), ('training', 'VBG'), ('set', 'VBN'), ('fed', 'NNS'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('produce', 'NN'), ('trained', 'VBD'), ('“', 'NNP'), ('machine', 'NN'), ('”', 'NN'), ('carries', 'VBZ'), ('desired', 'VBN'), ('task', 'NN'), ('.', '.')]

 (S
  1/CD
  (/(
  (NP b/NN)
  )/)
  ,/,
  examples/VBZ
  training/VBG
  set/VBN
  (NP fed/NNS)
  learning/VBG
  (NP algorithm/JJ produce/NN)
  trained/VBD
  (NP “/NNP machine/NN ”/NN)
  carries/VBZ
  desired/VBN
  (NP task/NN)
  ./.) 


>> Noun Phrases are: 
 ['b', 'fed', 'algorithm produce', '“ machine ”', 'task']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('fed', 'fed'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('produce', 'produc'), ('trained', 'train'), ('“', '“'), ('machine', 'machin'), ('”', '”'), ('carries', 'carri'), ('desired', 'desir'), ('task', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('fed', 'fed'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('produce', 'produc'), ('trained', 'train'), ('“', '“'), ('machine', 'machin'), ('”', '”'), ('carries', 'carri'), ('desired', 'desir'), ('task', 'task'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('examples', 'example'), ('training', 'training'), ('set', 'set'), ('fed', 'fed'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('produce', 'produce'), ('trained', 'trained'), ('“', '“'), ('machine', 'machine'), ('”', '”'), ('carries', 'carry'), ('desired', 'desired'), ('task', 'task'), ('.', '.')]



============================ Sentence 35 =============================

Learning is made possible by the choice of a set of possible “machines”, also known as the hypothesis class, from which the learning algorithm makes a selection during training. 


>> Tokens are: 
 ['Learning', 'made', 'possible', 'choice', 'set', 'possible', '“', 'machines', '”', ',', 'also', 'known', 'hypothesis', 'class', ',', 'learning', 'algorithm', 'makes', 'selection', 'training', '.']

>> Bigrams are: 
 [('Learning', 'made'), ('made', 'possible'), ('possible', 'choice'), ('choice', 'set'), ('set', 'possible'), ('possible', '“'), ('“', 'machines'), ('machines', '”'), ('”', ','), (',', 'also'), ('also', 'known'), ('known', 'hypothesis'), ('hypothesis', 'class'), ('class', ','), (',', 'learning'), ('learning', 'algorithm'), ('algorithm', 'makes'), ('makes', 'selection'), ('selection', 'training'), ('training', '.')]

>> Trigrams are: 
 [('Learning', 'made', 'possible'), ('made', 'possible', 'choice'), ('possible', 'choice', 'set'), ('choice', 'set', 'possible'), ('set', 'possible', '“'), ('possible', '“', 'machines'), ('“', 'machines', '”'), ('machines', '”', ','), ('”', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'hypothesis'), ('known', 'hypothesis', 'class'), ('hypothesis', 'class', ','), ('class', ',', 'learning'), (',', 'learning', 'algorithm'), ('learning', 'algorithm', 'makes'), ('algorithm', 'makes', 'selection'), ('makes', 'selection', 'training'), ('selection', 'training', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('made', 'VBN'), ('possible', 'JJ'), ('choice', 'NN'), ('set', 'VBN'), ('possible', 'JJ'), ('“', 'JJ'), ('machines', 'NNS'), ('”', 'NN'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('hypothesis', 'NN'), ('class', 'NN'), (',', ','), ('learning', 'VBG'), ('algorithm', 'JJ'), ('makes', 'VBZ'), ('selection', 'NN'), ('training', 'NN'), ('.', '.')]

 (S
  Learning/VBG
  made/VBN
  (NP possible/JJ choice/NN)
  set/VBN
  (NP possible/JJ “/JJ machines/NNS ”/NN)
  ,/,
  also/RB
  known/VBN
  (NP hypothesis/NN class/NN)
  ,/,
  learning/VBG
  algorithm/JJ
  makes/VBZ
  (NP selection/NN training/NN)
  ./.) 


>> Noun Phrases are: 
 ['possible choice', 'possible “ machines ”', 'hypothesis class', 'selection training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('made', 'made'), ('possible', 'possibl'), ('choice', 'choic'), ('set', 'set'), ('possible', 'possibl'), ('“', '“'), ('machines', 'machin'), ('”', '”'), (',', ','), ('also', 'also'), ('known', 'known'), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('learning', 'learn'), ('algorithm', 'algorithm'), ('makes', 'make'), ('selection', 'select'), ('training', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('made', 'made'), ('possible', 'possibl'), ('choice', 'choic'), ('set', 'set'), ('possible', 'possibl'), ('“', '“'), ('machines', 'machin'), ('”', '”'), (',', ','), ('also', 'also'), ('known', 'known'), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('learning', 'learn'), ('algorithm', 'algorithm'), ('makes', 'make'), ('selection', 'select'), ('training', 'train'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('made', 'made'), ('possible', 'possible'), ('choice', 'choice'), ('set', 'set'), ('possible', 'possible'), ('“', '“'), ('machines', 'machine'), ('”', '”'), (',', ','), ('also', 'also'), ('known', 'known'), ('hypothesis', 'hypothesis'), ('class', 'class'), (',', ','), ('learning', 'learning'), ('algorithm', 'algorithm'), ('makes', 'make'), ('selection', 'selection'), ('training', 'training'), ('.', '.')]



============================ Sentence 36 =============================

An example of an hypothesis class is given by a neural network architecture with learnable synaptic weights. 


>> Tokens are: 
 ['An', 'example', 'hypothesis', 'class', 'given', 'neural', 'network', 'architecture', 'learnable', 'synaptic', 'weights', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', 'hypothesis'), ('hypothesis', 'class'), ('class', 'given'), ('given', 'neural'), ('neural', 'network'), ('network', 'architecture'), ('architecture', 'learnable'), ('learnable', 'synaptic'), ('synaptic', 'weights'), ('weights', '.')]

>> Trigrams are: 
 [('An', 'example', 'hypothesis'), ('example', 'hypothesis', 'class'), ('hypothesis', 'class', 'given'), ('class', 'given', 'neural'), ('given', 'neural', 'network'), ('neural', 'network', 'architecture'), ('network', 'architecture', 'learnable'), ('architecture', 'learnable', 'synaptic'), ('learnable', 'synaptic', 'weights'), ('synaptic', 'weights', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('given', 'VBN'), ('neural', 'JJ'), ('network', 'NN'), ('architecture', 'NN'), ('learnable', 'JJ'), ('synaptic', 'JJ'), ('weights', 'NNS'), ('.', '.')]

 (S
  (NP An/DT example/NN hypothesis/NN class/NN)
  given/VBN
  (NP neural/JJ network/NN architecture/NN)
  (NP learnable/JJ synaptic/JJ weights/NNS)
  ./.) 


>> Noun Phrases are: 
 ['An example hypothesis class', 'neural network architecture', 'learnable synaptic weights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('given', 'given'), ('neural', 'neural'), ('network', 'network'), ('architecture', 'architectur'), ('learnable', 'learnabl'), ('synaptic', 'synapt'), ('weights', 'weight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('given', 'given'), ('neural', 'neural'), ('network', 'network'), ('architecture', 'architectur'), ('learnable', 'learnabl'), ('synaptic', 'synapt'), ('weights', 'weight'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('given', 'given'), ('neural', 'neural'), ('network', 'network'), ('architecture', 'architecture'), ('learnable', 'learnable'), ('synaptic', 'synaptic'), ('weights', 'weight'), ('.', '.')]



============================ Sentence 37 =============================

Learning algorithms are generally based on the optimization of a performance criterion that measures how well the selected “machine” matches the available data. 


>> Tokens are: 
 ['Learning', 'algorithms', 'generally', 'based', 'optimization', 'performance', 'criterion', 'measures', 'well', 'selected', '“', 'machine', '”', 'matches', 'available', 'data', '.']

>> Bigrams are: 
 [('Learning', 'algorithms'), ('algorithms', 'generally'), ('generally', 'based'), ('based', 'optimization'), ('optimization', 'performance'), ('performance', 'criterion'), ('criterion', 'measures'), ('measures', 'well'), ('well', 'selected'), ('selected', '“'), ('“', 'machine'), ('machine', '”'), ('”', 'matches'), ('matches', 'available'), ('available', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Learning', 'algorithms', 'generally'), ('algorithms', 'generally', 'based'), ('generally', 'based', 'optimization'), ('based', 'optimization', 'performance'), ('optimization', 'performance', 'criterion'), ('performance', 'criterion', 'measures'), ('criterion', 'measures', 'well'), ('measures', 'well', 'selected'), ('well', 'selected', '“'), ('selected', '“', 'machine'), ('“', 'machine', '”'), ('machine', '”', 'matches'), ('”', 'matches', 'available'), ('matches', 'available', 'data'), ('available', 'data', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('algorithms', 'NNS'), ('generally', 'RB'), ('based', 'VBN'), ('optimization', 'NN'), ('performance', 'NN'), ('criterion', 'NN'), ('measures', 'NNS'), ('well', 'RB'), ('selected', 'VBN'), ('“', 'CD'), ('machine', 'NN'), ('”', 'NN'), ('matches', 'NNS'), ('available', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  Learning/VBG
  (NP algorithms/NNS)
  generally/RB
  based/VBN
  (NP optimization/NN performance/NN criterion/NN measures/NNS)
  well/RB
  selected/VBN
  “/CD
  (NP machine/NN ”/NN matches/NNS)
  (NP available/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['algorithms', 'optimization performance criterion measures', 'machine ” matches', 'available data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('algorithms', 'algorithm'), ('generally', 'gener'), ('based', 'base'), ('optimization', 'optim'), ('performance', 'perform'), ('criterion', 'criterion'), ('measures', 'measur'), ('well', 'well'), ('selected', 'select'), ('“', '“'), ('machine', 'machin'), ('”', '”'), ('matches', 'match'), ('available', 'avail'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('algorithms', 'algorithm'), ('generally', 'general'), ('based', 'base'), ('optimization', 'optim'), ('performance', 'perform'), ('criterion', 'criterion'), ('measures', 'measur'), ('well', 'well'), ('selected', 'select'), ('“', '“'), ('machine', 'machin'), ('”', '”'), ('matches', 'match'), ('available', 'avail'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('algorithms', 'algorithm'), ('generally', 'generally'), ('based', 'based'), ('optimization', 'optimization'), ('performance', 'performance'), ('criterion', 'criterion'), ('measures', 'measure'), ('well', 'well'), ('selected', 'selected'), ('“', '“'), ('machine', 'machine'), ('”', '”'), ('matches', 'match'), ('available', 'available'), ('data', 'data'), ('.', '.')]



============================ Sentence 38 =============================

For the problem of designing a channel decoder, a machine learning approach can hence operate even in the absence of a well-established channel model. 


>> Tokens are: 
 ['For', 'problem', 'designing', 'channel', 'decoder', ',', 'machine', 'learning', 'approach', 'hence', 'operate', 'even', 'absence', 'well-established', 'channel', 'model', '.']

>> Bigrams are: 
 [('For', 'problem'), ('problem', 'designing'), ('designing', 'channel'), ('channel', 'decoder'), ('decoder', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'approach'), ('approach', 'hence'), ('hence', 'operate'), ('operate', 'even'), ('even', 'absence'), ('absence', 'well-established'), ('well-established', 'channel'), ('channel', 'model'), ('model', '.')]

>> Trigrams are: 
 [('For', 'problem', 'designing'), ('problem', 'designing', 'channel'), ('designing', 'channel', 'decoder'), ('channel', 'decoder', ','), ('decoder', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'approach'), ('learning', 'approach', 'hence'), ('approach', 'hence', 'operate'), ('hence', 'operate', 'even'), ('operate', 'even', 'absence'), ('even', 'absence', 'well-established'), ('absence', 'well-established', 'channel'), ('well-established', 'channel', 'model'), ('channel', 'model', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('problem', 'NN'), ('designing', 'VBG'), ('channel', 'NNS'), ('decoder', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('approach', 'NN'), ('hence', 'NN'), ('operate', 'VB'), ('even', 'RB'), ('absence', 'VB'), ('well-established', 'JJ'), ('channel', 'NNS'), ('model', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP problem/NN)
  designing/VBG
  (NP channel/NNS decoder/NN)
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP approach/NN hence/NN)
  operate/VB
  even/RB
  absence/VB
  (NP well-established/JJ channel/NNS model/NN)
  ./.) 


>> Noun Phrases are: 
 ['problem', 'channel decoder', 'machine', 'approach hence', 'well-established channel model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('problem', 'problem'), ('designing', 'design'), ('channel', 'channel'), ('decoder', 'decod'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('hence', 'henc'), ('operate', 'oper'), ('even', 'even'), ('absence', 'absenc'), ('well-established', 'well-establish'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('problem', 'problem'), ('designing', 'design'), ('channel', 'channel'), ('decoder', 'decod'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('hence', 'henc'), ('operate', 'oper'), ('even', 'even'), ('absence', 'absenc'), ('well-established', 'well-establish'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('problem', 'problem'), ('designing', 'designing'), ('channel', 'channel'), ('decoder', 'decoder'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('approach', 'approach'), ('hence', 'hence'), ('operate', 'operate'), ('even', 'even'), ('absence', 'absence'), ('well-established', 'well-established'), ('channel', 'channel'), ('model', 'model'), ('.', '.')]



============================ Sentence 39 =============================

It is in fact enough to have a sufficiently large number of examples of received signals – the inputs to the decoding machine – and transmitted messages – the desired outputs of the decoding machine – to be used for the training of a given class of decoding functions [13]. 


>> Tokens are: 
 ['It', 'fact', 'enough', 'sufficiently', 'large', 'number', 'examples', 'received', 'signals', '–', 'inputs', 'decoding', 'machine', '–', 'transmitted', 'messages', '–', 'desired', 'outputs', 'decoding', 'machine', '–', 'used', 'training', 'given', 'class', 'decoding', 'functions', '[', '13', ']', '.']

>> Bigrams are: 
 [('It', 'fact'), ('fact', 'enough'), ('enough', 'sufficiently'), ('sufficiently', 'large'), ('large', 'number'), ('number', 'examples'), ('examples', 'received'), ('received', 'signals'), ('signals', '–'), ('–', 'inputs'), ('inputs', 'decoding'), ('decoding', 'machine'), ('machine', '–'), ('–', 'transmitted'), ('transmitted', 'messages'), ('messages', '–'), ('–', 'desired'), ('desired', 'outputs'), ('outputs', 'decoding'), ('decoding', 'machine'), ('machine', '–'), ('–', 'used'), ('used', 'training'), ('training', 'given'), ('given', 'class'), ('class', 'decoding'), ('decoding', 'functions'), ('functions', '['), ('[', '13'), ('13', ']'), (']', '.')]

>> Trigrams are: 
 [('It', 'fact', 'enough'), ('fact', 'enough', 'sufficiently'), ('enough', 'sufficiently', 'large'), ('sufficiently', 'large', 'number'), ('large', 'number', 'examples'), ('number', 'examples', 'received'), ('examples', 'received', 'signals'), ('received', 'signals', '–'), ('signals', '–', 'inputs'), ('–', 'inputs', 'decoding'), ('inputs', 'decoding', 'machine'), ('decoding', 'machine', '–'), ('machine', '–', 'transmitted'), ('–', 'transmitted', 'messages'), ('transmitted', 'messages', '–'), ('messages', '–', 'desired'), ('–', 'desired', 'outputs'), ('desired', 'outputs', 'decoding'), ('outputs', 'decoding', 'machine'), ('decoding', 'machine', '–'), ('machine', '–', 'used'), ('–', 'used', 'training'), ('used', 'training', 'given'), ('training', 'given', 'class'), ('given', 'class', 'decoding'), ('class', 'decoding', 'functions'), ('decoding', 'functions', '['), ('functions', '[', '13'), ('[', '13', ']'), ('13', ']', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('fact', 'NN'), ('enough', 'RB'), ('sufficiently', 'RB'), ('large', 'JJ'), ('number', 'NN'), ('examples', 'NNS'), ('received', 'VBN'), ('signals', 'NNS'), ('–', 'VBP'), ('inputs', 'NNS'), ('decoding', 'VBG'), ('machine', 'NN'), ('–', 'NN'), ('transmitted', 'VBD'), ('messages', 'NNS'), ('–', 'VBP'), ('desired', 'VBN'), ('outputs', 'NNS'), ('decoding', 'VBG'), ('machine', 'NN'), ('–', 'NN'), ('used', 'VBD'), ('training', 'VBG'), ('given', 'VBN'), ('class', 'NN'), ('decoding', 'VBG'), ('functions', 'NNS'), ('[', '$'), ('13', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  It/PRP
  (NP fact/NN)
  enough/RB
  sufficiently/RB
  (NP large/JJ number/NN examples/NNS)
  received/VBN
  (NP signals/NNS)
  –/VBP
  (NP inputs/NNS)
  decoding/VBG
  (NP machine/NN –/NN)
  transmitted/VBD
  (NP messages/NNS)
  –/VBP
  desired/VBN
  (NP outputs/NNS)
  decoding/VBG
  (NP machine/NN –/NN)
  used/VBD
  training/VBG
  given/VBN
  (NP class/NN)
  decoding/VBG
  (NP functions/NNS)
  [/$
  13/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'large number examples', 'signals', 'inputs', 'machine –', 'messages', 'outputs', 'machine –', 'class', 'functions', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('fact', 'fact'), ('enough', 'enough'), ('sufficiently', 'suffici'), ('large', 'larg'), ('number', 'number'), ('examples', 'exampl'), ('received', 'receiv'), ('signals', 'signal'), ('–', '–'), ('inputs', 'input'), ('decoding', 'decod'), ('machine', 'machin'), ('–', '–'), ('transmitted', 'transmit'), ('messages', 'messag'), ('–', '–'), ('desired', 'desir'), ('outputs', 'output'), ('decoding', 'decod'), ('machine', 'machin'), ('–', '–'), ('used', 'use'), ('training', 'train'), ('given', 'given'), ('class', 'class'), ('decoding', 'decod'), ('functions', 'function'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('fact', 'fact'), ('enough', 'enough'), ('sufficiently', 'suffici'), ('large', 'larg'), ('number', 'number'), ('examples', 'exampl'), ('received', 'receiv'), ('signals', 'signal'), ('–', '–'), ('inputs', 'input'), ('decoding', 'decod'), ('machine', 'machin'), ('–', '–'), ('transmitted', 'transmit'), ('messages', 'messag'), ('–', '–'), ('desired', 'desir'), ('outputs', 'output'), ('decoding', 'decod'), ('machine', 'machin'), ('–', '–'), ('used', 'use'), ('training', 'train'), ('given', 'given'), ('class', 'class'), ('decoding', 'decod'), ('functions', 'function'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('fact', 'fact'), ('enough', 'enough'), ('sufficiently', 'sufficiently'), ('large', 'large'), ('number', 'number'), ('examples', 'example'), ('received', 'received'), ('signals', 'signal'), ('–', '–'), ('inputs', 'input'), ('decoding', 'decoding'), ('machine', 'machine'), ('–', '–'), ('transmitted', 'transmitted'), ('messages', 'message'), ('–', '–'), ('desired', 'desired'), ('outputs', 'output'), ('decoding', 'decoding'), ('machine', 'machine'), ('–', '–'), ('used', 'used'), ('training', 'training'), ('given', 'given'), ('class', 'class'), ('decoding', 'decoding'), ('functions', 'function'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]



============================ Sentence 40 =============================

acquisition   of domain   knowledge  acquisition   of data  learning  training set   machine  hypothesis   class  Fig. 


>> Tokens are: 
 ['acquisition', 'domain', 'knowledge', 'acquisition', 'data', 'learning', 'training', 'set', 'machine', 'hypothesis', 'class', 'Fig', '.']

>> Bigrams are: 
 [('acquisition', 'domain'), ('domain', 'knowledge'), ('knowledge', 'acquisition'), ('acquisition', 'data'), ('data', 'learning'), ('learning', 'training'), ('training', 'set'), ('set', 'machine'), ('machine', 'hypothesis'), ('hypothesis', 'class'), ('class', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('acquisition', 'domain', 'knowledge'), ('domain', 'knowledge', 'acquisition'), ('knowledge', 'acquisition', 'data'), ('acquisition', 'data', 'learning'), ('data', 'learning', 'training'), ('learning', 'training', 'set'), ('training', 'set', 'machine'), ('set', 'machine', 'hypothesis'), ('machine', 'hypothesis', 'class'), ('hypothesis', 'class', 'Fig'), ('class', 'Fig', '.')]

>> POS Tags are: 
 [('acquisition', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('acquisition', 'NN'), ('data', 'NNS'), ('learning', 'VBG'), ('training', 'NN'), ('set', 'VBN'), ('machine', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP acquisition/NN domain/NN knowledge/NN acquisition/NN data/NNS)
  learning/VBG
  (NP training/NN)
  set/VBN
  (NP machine/NN hypothesis/NN class/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['acquisition domain knowledge acquisition data', 'training', 'machine hypothesis class Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('acquisition', 'acquisit'), ('data', 'data'), ('learning', 'learn'), ('training', 'train'), ('set', 'set'), ('machine', 'machin'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('acquisition', 'acquisit'), ('data', 'data'), ('learning', 'learn'), ('training', 'train'), ('set', 'set'), ('machine', 'machin'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('acquisition', 'acquisition'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('acquisition', 'acquisition'), ('data', 'data'), ('learning', 'learning'), ('training', 'training'), ('set', 'set'), ('machine', 'machine'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 41 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 42 =============================

Machine learning methodology that integrates domain knowl- edge during model selection. 


>> Tokens are: 
 ['Machine', 'learning', 'methodology', 'integrates', 'domain', 'knowl-', 'edge', 'model', 'selection', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'methodology'), ('methodology', 'integrates'), ('integrates', 'domain'), ('domain', 'knowl-'), ('knowl-', 'edge'), ('edge', 'model'), ('model', 'selection'), ('selection', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'methodology'), ('learning', 'methodology', 'integrates'), ('methodology', 'integrates', 'domain'), ('integrates', 'domain', 'knowl-'), ('domain', 'knowl-', 'edge'), ('knowl-', 'edge', 'model'), ('edge', 'model', 'selection'), ('model', 'selection', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('methodology', 'NN'), ('integrates', 'NNS'), ('domain', 'VBP'), ('knowl-', 'JJ'), ('edge', 'NN'), ('model', 'NN'), ('selection', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP methodology/NN integrates/NNS)
  domain/VBP
  (NP knowl-/JJ edge/NN model/NN selection/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'methodology integrates', 'knowl- edge model selection']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('integrates', 'integr'), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edg'), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('integrates', 'integr'), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edg'), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('methodology', 'methodology'), ('integrates', 'integrates'), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edge'), ('model', 'model'), ('selection', 'selection'), ('.', '.')]



============================ Sentence 43 =============================

Moving beyond the basic formulation described above, machine learning tools can integrate available domain knowledge in the learning process. 


>> Tokens are: 
 ['Moving', 'beyond', 'basic', 'formulation', 'described', ',', 'machine', 'learning', 'tools', 'integrate', 'available', 'domain', 'knowledge', 'learning', 'process', '.']

>> Bigrams are: 
 [('Moving', 'beyond'), ('beyond', 'basic'), ('basic', 'formulation'), ('formulation', 'described'), ('described', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', 'integrate'), ('integrate', 'available'), ('available', 'domain'), ('domain', 'knowledge'), ('knowledge', 'learning'), ('learning', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Moving', 'beyond', 'basic'), ('beyond', 'basic', 'formulation'), ('basic', 'formulation', 'described'), ('formulation', 'described', ','), ('described', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', 'integrate'), ('tools', 'integrate', 'available'), ('integrate', 'available', 'domain'), ('available', 'domain', 'knowledge'), ('domain', 'knowledge', 'learning'), ('knowledge', 'learning', 'process'), ('learning', 'process', '.')]

>> POS Tags are: 
 [('Moving', 'VBG'), ('beyond', 'IN'), ('basic', 'JJ'), ('formulation', 'NN'), ('described', 'VBD'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('integrate', 'VBP'), ('available', 'JJ'), ('domain', 'NN'), ('knowledge', 'NN'), ('learning', 'VBG'), ('process', 'NN'), ('.', '.')]

 (S
  Moving/VBG
  beyond/IN
  (NP basic/JJ formulation/NN)
  described/VBD
  ,/,
  (NP machine/NN learning/NN tools/NNS)
  integrate/VBP
  (NP available/JJ domain/NN knowledge/NN)
  learning/VBG
  (NP process/NN)
  ./.) 


>> Noun Phrases are: 
 ['basic formulation', 'machine learning tools', 'available domain knowledge', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moving', 'move'), ('beyond', 'beyond'), ('basic', 'basic'), ('formulation', 'formul'), ('described', 'describ'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('integrate', 'integr'), ('available', 'avail'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moving', 'move'), ('beyond', 'beyond'), ('basic', 'basic'), ('formulation', 'formul'), ('described', 'describ'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('integrate', 'integr'), ('available', 'avail'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Moving', 'Moving'), ('beyond', 'beyond'), ('basic', 'basic'), ('formulation', 'formulation'), ('described', 'described'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('integrate', 'integrate'), ('available', 'available'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('learning', 'learning'), ('process', 'process'), ('.', '.')]



============================ Sentence 44 =============================

This is indeed the key to the success of machine learning tools in a number of applications. 


>> Tokens are: 
 ['This', 'indeed', 'key', 'success', 'machine', 'learning', 'tools', 'number', 'applications', '.']

>> Bigrams are: 
 [('This', 'indeed'), ('indeed', 'key'), ('key', 'success'), ('success', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', 'number'), ('number', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('This', 'indeed', 'key'), ('indeed', 'key', 'success'), ('key', 'success', 'machine'), ('success', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', 'number'), ('tools', 'number', 'applications'), ('number', 'applications', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('indeed', 'RB'), ('key', 'JJ'), ('success', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('number', 'NN'), ('applications', 'NNS'), ('.', '.')]

 (S
  This/DT
  indeed/RB
  (NP
    key/JJ
    success/NN
    machine/NN
    learning/NN
    tools/NNS
    number/NN
    applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['key success machine learning tools number applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('indeed', 'inde'), ('key', 'key'), ('success', 'success'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('number', 'number'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('indeed', 'inde'), ('key', 'key'), ('success', 'success'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('number', 'number'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('indeed', 'indeed'), ('key', 'key'), ('success', 'success'), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('number', 'number'), ('applications', 'application'), ('.', '.')]



============================ Sentence 45 =============================

A notable example is image processing, whereby knowledge of the translational invariance of vi- sual features is reflected in the adoption of convolutional neural networks as the hypothesis class to be trained. 


>> Tokens are: 
 ['A', 'notable', 'example', 'image', 'processing', ',', 'whereby', 'knowledge', 'translational', 'invariance', 'vi-', 'sual', 'features', 'reflected', 'adoption', 'convolutional', 'neural', 'networks', 'hypothesis', 'class', 'trained', '.']

>> Bigrams are: 
 [('A', 'notable'), ('notable', 'example'), ('example', 'image'), ('image', 'processing'), ('processing', ','), (',', 'whereby'), ('whereby', 'knowledge'), ('knowledge', 'translational'), ('translational', 'invariance'), ('invariance', 'vi-'), ('vi-', 'sual'), ('sual', 'features'), ('features', 'reflected'), ('reflected', 'adoption'), ('adoption', 'convolutional'), ('convolutional', 'neural'), ('neural', 'networks'), ('networks', 'hypothesis'), ('hypothesis', 'class'), ('class', 'trained'), ('trained', '.')]

>> Trigrams are: 
 [('A', 'notable', 'example'), ('notable', 'example', 'image'), ('example', 'image', 'processing'), ('image', 'processing', ','), ('processing', ',', 'whereby'), (',', 'whereby', 'knowledge'), ('whereby', 'knowledge', 'translational'), ('knowledge', 'translational', 'invariance'), ('translational', 'invariance', 'vi-'), ('invariance', 'vi-', 'sual'), ('vi-', 'sual', 'features'), ('sual', 'features', 'reflected'), ('features', 'reflected', 'adoption'), ('reflected', 'adoption', 'convolutional'), ('adoption', 'convolutional', 'neural'), ('convolutional', 'neural', 'networks'), ('neural', 'networks', 'hypothesis'), ('networks', 'hypothesis', 'class'), ('hypothesis', 'class', 'trained'), ('class', 'trained', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('notable', 'JJ'), ('example', 'NN'), ('image', 'NN'), ('processing', 'NN'), (',', ','), ('whereby', 'WRB'), ('knowledge', 'VBP'), ('translational', 'JJ'), ('invariance', 'NN'), ('vi-', 'JJ'), ('sual', 'JJ'), ('features', 'NNS'), ('reflected', 'VBN'), ('adoption', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('hypothesis', 'NN'), ('class', 'NN'), ('trained', 'VBD'), ('.', '.')]

 (S
  (NP A/DT notable/JJ example/NN image/NN processing/NN)
  ,/,
  whereby/WRB
  knowledge/VBP
  (NP translational/JJ invariance/NN)
  (NP vi-/JJ sual/JJ features/NNS)
  reflected/VBN
  (NP
    adoption/JJ
    convolutional/JJ
    neural/JJ
    networks/NNS
    hypothesis/NN
    class/NN)
  trained/VBD
  ./.) 


>> Noun Phrases are: 
 ['A notable example image processing', 'translational invariance', 'vi- sual features', 'adoption convolutional neural networks hypothesis class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('notable', 'notabl'), ('example', 'exampl'), ('image', 'imag'), ('processing', 'process'), (',', ','), ('whereby', 'wherebi'), ('knowledge', 'knowledg'), ('translational', 'translat'), ('invariance', 'invari'), ('vi-', 'vi-'), ('sual', 'sual'), ('features', 'featur'), ('reflected', 'reflect'), ('adoption', 'adopt'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('trained', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('notable', 'notabl'), ('example', 'exampl'), ('image', 'imag'), ('processing', 'process'), (',', ','), ('whereby', 'wherebi'), ('knowledge', 'knowledg'), ('translational', 'translat'), ('invariance', 'invari'), ('vi-', 'vi-'), ('sual', 'sual'), ('features', 'featur'), ('reflected', 'reflect'), ('adoption', 'adopt'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('trained', 'train'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('notable', 'notable'), ('example', 'example'), ('image', 'image'), ('processing', 'processing'), (',', ','), ('whereby', 'whereby'), ('knowledge', 'knowledge'), ('translational', 'translational'), ('invariance', 'invariance'), ('vi-', 'vi-'), ('sual', 'sual'), ('features', 'feature'), ('reflected', 'reflected'), ('adoption', 'adoption'), ('convolutional', 'convolutional'), ('neural', 'neural'), ('networks', 'network'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('trained', 'trained'), ('.', '.')]



============================ Sentence 46 =============================

More generally, as illustrated in Fig. 


>> Tokens are: 
 ['More', 'generally', ',', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('More', 'generally'), ('generally', ','), (',', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('More', 'generally', ','), ('generally', ',', 'illustrated'), (',', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('generally', 'RB'), (',', ','), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S More/RBR generally/RB ,/, illustrated/VBD (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('generally', 'gener'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('generally', 'general'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('generally', 'generally'), (',', ','), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 47 =============================

2, domain knowl- edge can dictate the choice of a specific hypothesis class for use in the training process. 


>> Tokens are: 
 ['2', ',', 'domain', 'knowl-', 'edge', 'dictate', 'choice', 'specific', 'hypothesis', 'class', 'use', 'training', 'process', '.']

>> Bigrams are: 
 [('2', ','), (',', 'domain'), ('domain', 'knowl-'), ('knowl-', 'edge'), ('edge', 'dictate'), ('dictate', 'choice'), ('choice', 'specific'), ('specific', 'hypothesis'), ('hypothesis', 'class'), ('class', 'use'), ('use', 'training'), ('training', 'process'), ('process', '.')]

>> Trigrams are: 
 [('2', ',', 'domain'), (',', 'domain', 'knowl-'), ('domain', 'knowl-', 'edge'), ('knowl-', 'edge', 'dictate'), ('edge', 'dictate', 'choice'), ('dictate', 'choice', 'specific'), ('choice', 'specific', 'hypothesis'), ('specific', 'hypothesis', 'class'), ('hypothesis', 'class', 'use'), ('class', 'use', 'training'), ('use', 'training', 'process'), ('training', 'process', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('domain', 'VBP'), ('knowl-', 'JJ'), ('edge', 'NN'), ('dictate', 'NN'), ('choice', 'NN'), ('specific', 'JJ'), ('hypothesis', 'NN'), ('class', 'NN'), ('use', 'NN'), ('training', 'NN'), ('process', 'NN'), ('.', '.')]

 (S
  2/CD
  ,/,
  domain/VBP
  (NP knowl-/JJ edge/NN dictate/NN choice/NN)
  (NP
    specific/JJ
    hypothesis/NN
    class/NN
    use/NN
    training/NN
    process/NN)
  ./.) 


>> Noun Phrases are: 
 ['knowl- edge dictate choice', 'specific hypothesis class use training process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edg'), ('dictate', 'dictat'), ('choice', 'choic'), ('specific', 'specif'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('use', 'use'), ('training', 'train'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edg'), ('dictate', 'dictat'), ('choice', 'choic'), ('specific', 'specif'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('use', 'use'), ('training', 'train'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('domain', 'domain'), ('knowl-', 'knowl-'), ('edge', 'edge'), ('dictate', 'dictate'), ('choice', 'choice'), ('specific', 'specific'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('use', 'use'), ('training', 'training'), ('process', 'process'), ('.', '.')]



============================ Sentence 48 =============================

Examples of applications of this idea to communication systems, including to the problem of decoding, will be discussed later in the paper. 


>> Tokens are: 
 ['Examples', 'applications', 'idea', 'communication', 'systems', ',', 'including', 'problem', 'decoding', ',', 'discussed', 'later', 'paper', '.']

>> Bigrams are: 
 [('Examples', 'applications'), ('applications', 'idea'), ('idea', 'communication'), ('communication', 'systems'), ('systems', ','), (',', 'including'), ('including', 'problem'), ('problem', 'decoding'), ('decoding', ','), (',', 'discussed'), ('discussed', 'later'), ('later', 'paper'), ('paper', '.')]

>> Trigrams are: 
 [('Examples', 'applications', 'idea'), ('applications', 'idea', 'communication'), ('idea', 'communication', 'systems'), ('communication', 'systems', ','), ('systems', ',', 'including'), (',', 'including', 'problem'), ('including', 'problem', 'decoding'), ('problem', 'decoding', ','), ('decoding', ',', 'discussed'), (',', 'discussed', 'later'), ('discussed', 'later', 'paper'), ('later', 'paper', '.')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('applications', 'NNS'), ('idea', 'NN'), ('communication', 'NN'), ('systems', 'NNS'), (',', ','), ('including', 'VBG'), ('problem', 'NN'), ('decoding', 'NN'), (',', ','), ('discussed', 'VBN'), ('later', 'RB'), ('paper', 'NN'), ('.', '.')]

 (S
  (NP
    Examples/NNS
    applications/NNS
    idea/NN
    communication/NN
    systems/NNS)
  ,/,
  including/VBG
  (NP problem/NN decoding/NN)
  ,/,
  discussed/VBN
  later/RB
  (NP paper/NN)
  ./.) 


>> Noun Phrases are: 
 ['Examples applications idea communication systems', 'problem decoding', 'paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('applications', 'applic'), ('idea', 'idea'), ('communication', 'commun'), ('systems', 'system'), (',', ','), ('including', 'includ'), ('problem', 'problem'), ('decoding', 'decod'), (',', ','), ('discussed', 'discuss'), ('later', 'later'), ('paper', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('applications', 'applic'), ('idea', 'idea'), ('communication', 'communic'), ('systems', 'system'), (',', ','), ('including', 'includ'), ('problem', 'problem'), ('decoding', 'decod'), (',', ','), ('discussed', 'discuss'), ('later', 'later'), ('paper', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('applications', 'application'), ('idea', 'idea'), ('communication', 'communication'), ('systems', 'system'), (',', ','), ('including', 'including'), ('problem', 'problem'), ('decoding', 'decoding'), (',', ','), ('discussed', 'discussed'), ('later', 'later'), ('paper', 'paper'), ('.', '.')]



============================ Sentence 49 =============================

B. Taxonomy of Machine Learning Methods  There are three main classes of machine learning techniques, as discussed next. 


>> Tokens are: 
 ['B.', 'Taxonomy', 'Machine', 'Learning', 'Methods', 'There', 'three', 'main', 'classes', 'machine', 'learning', 'techniques', ',', 'discussed', 'next', '.']

>> Bigrams are: 
 [('B.', 'Taxonomy'), ('Taxonomy', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Methods'), ('Methods', 'There'), ('There', 'three'), ('three', 'main'), ('main', 'classes'), ('classes', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', 'discussed'), ('discussed', 'next'), ('next', '.')]

>> Trigrams are: 
 [('B.', 'Taxonomy', 'Machine'), ('Taxonomy', 'Machine', 'Learning'), ('Machine', 'Learning', 'Methods'), ('Learning', 'Methods', 'There'), ('Methods', 'There', 'three'), ('There', 'three', 'main'), ('three', 'main', 'classes'), ('main', 'classes', 'machine'), ('classes', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', 'discussed'), (',', 'discussed', 'next'), ('discussed', 'next', '.')]

>> POS Tags are: 
 [('B.', 'NNP'), ('Taxonomy', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Methods', 'NNP'), ('There', 'EX'), ('three', 'CD'), ('main', 'JJ'), ('classes', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('discussed', 'VBD'), ('next', 'JJ'), ('.', '.')]

 (S
  (NP B./NNP Taxonomy/NNP Machine/NNP Learning/NNP Methods/NNP)
  There/EX
  three/CD
  (NP main/JJ classes/NNS machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  discussed/VBD
  next/JJ
  ./.) 


>> Noun Phrases are: 
 ['B. Taxonomy Machine Learning Methods', 'main classes machine', 'techniques']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Methods')] 

>> Stemming using Porter Stemmer: 
 [('B.', 'b.'), ('Taxonomy', 'taxonomi'), ('Machine', 'machin'), ('Learning', 'learn'), ('Methods', 'method'), ('There', 'there'), ('three', 'three'), ('main', 'main'), ('classes', 'class'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('discussed', 'discuss'), ('next', 'next'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B.', 'b.'), ('Taxonomy', 'taxonomi'), ('Machine', 'machin'), ('Learning', 'learn'), ('Methods', 'method'), ('There', 'there'), ('three', 'three'), ('main', 'main'), ('classes', 'class'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('discussed', 'discuss'), ('next', 'next'), ('.', '.')]

>> Lemmatization: 
 [('B.', 'B.'), ('Taxonomy', 'Taxonomy'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Methods', 'Methods'), ('There', 'There'), ('three', 'three'), ('main', 'main'), ('classes', 'class'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('discussed', 'discussed'), ('next', 'next'), ('.', '.')]



============================ Sentence 50 =============================

• Supervised learning: In supervised learning, the  training set consists of pairs of input and desired output, and the goal is that of learning a mapping between input and output spaces. 


>> Tokens are: 
 ['•', 'Supervised', 'learning', ':', 'In', 'supervised', 'learning', ',', 'training', 'set', 'consists', 'pairs', 'input', 'desired', 'output', ',', 'goal', 'learning', 'mapping', 'input', 'output', 'spaces', '.']

>> Bigrams are: 
 [('•', 'Supervised'), ('Supervised', 'learning'), ('learning', ':'), (':', 'In'), ('In', 'supervised'), ('supervised', 'learning'), ('learning', ','), (',', 'training'), ('training', 'set'), ('set', 'consists'), ('consists', 'pairs'), ('pairs', 'input'), ('input', 'desired'), ('desired', 'output'), ('output', ','), (',', 'goal'), ('goal', 'learning'), ('learning', 'mapping'), ('mapping', 'input'), ('input', 'output'), ('output', 'spaces'), ('spaces', '.')]

>> Trigrams are: 
 [('•', 'Supervised', 'learning'), ('Supervised', 'learning', ':'), ('learning', ':', 'In'), (':', 'In', 'supervised'), ('In', 'supervised', 'learning'), ('supervised', 'learning', ','), ('learning', ',', 'training'), (',', 'training', 'set'), ('training', 'set', 'consists'), ('set', 'consists', 'pairs'), ('consists', 'pairs', 'input'), ('pairs', 'input', 'desired'), ('input', 'desired', 'output'), ('desired', 'output', ','), ('output', ',', 'goal'), (',', 'goal', 'learning'), ('goal', 'learning', 'mapping'), ('learning', 'mapping', 'input'), ('mapping', 'input', 'output'), ('input', 'output', 'spaces'), ('output', 'spaces', '.')]

>> POS Tags are: 
 [('•', 'NNS'), ('Supervised', 'VBD'), ('learning', 'NN'), (':', ':'), ('In', 'IN'), ('supervised', 'JJ'), ('learning', 'NN'), (',', ','), ('training', 'VBG'), ('set', 'NN'), ('consists', 'VBZ'), ('pairs', 'NNS'), ('input', 'NN'), ('desired', 'VBD'), ('output', 'NN'), (',', ','), ('goal', 'NN'), ('learning', 'VBG'), ('mapping', 'VBG'), ('input', 'NN'), ('output', 'NN'), ('spaces', 'NNS'), ('.', '.')]

 (S
  (NP •/NNS)
  Supervised/VBD
  (NP learning/NN)
  :/:
  In/IN
  (NP supervised/JJ learning/NN)
  ,/,
  training/VBG
  (NP set/NN)
  consists/VBZ
  (NP pairs/NNS input/NN)
  desired/VBD
  (NP output/NN)
  ,/,
  (NP goal/NN)
  learning/VBG
  mapping/VBG
  (NP input/NN output/NN spaces/NNS)
  ./.) 


>> Noun Phrases are: 
 ['•', 'learning', 'supervised learning', 'set', 'pairs input', 'output', 'goal', 'input output spaces']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Supervised', 'supervis'), ('learning', 'learn'), (':', ':'), ('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('training', 'train'), ('set', 'set'), ('consists', 'consist'), ('pairs', 'pair'), ('input', 'input'), ('desired', 'desir'), ('output', 'output'), (',', ','), ('goal', 'goal'), ('learning', 'learn'), ('mapping', 'map'), ('input', 'input'), ('output', 'output'), ('spaces', 'space'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Supervised', 'supervis'), ('learning', 'learn'), (':', ':'), ('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('training', 'train'), ('set', 'set'), ('consists', 'consist'), ('pairs', 'pair'), ('input', 'input'), ('desired', 'desir'), ('output', 'output'), (',', ','), ('goal', 'goal'), ('learning', 'learn'), ('mapping', 'map'), ('input', 'input'), ('output', 'output'), ('spaces', 'space'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Supervised', 'Supervised'), ('learning', 'learning'), (':', ':'), ('In', 'In'), ('supervised', 'supervised'), ('learning', 'learning'), (',', ','), ('training', 'training'), ('set', 'set'), ('consists', 'consists'), ('pairs', 'pair'), ('input', 'input'), ('desired', 'desired'), ('output', 'output'), (',', ','), ('goal', 'goal'), ('learning', 'learning'), ('mapping', 'mapping'), ('input', 'input'), ('output', 'output'), ('spaces', 'space'), ('.', '.')]



============================ Sentence 51 =============================

As an illustration, in Fig. 


>> Tokens are: 
 ['As', 'illustration', ',', 'Fig', '.']

>> Bigrams are: 
 [('As', 'illustration'), ('illustration', ','), (',', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'illustration', ','), ('illustration', ',', 'Fig'), (',', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('illustration', 'NN'), (',', ','), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN (NP illustration/NN) ,/, (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['illustration', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('illustration', 'illustr'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('illustration', 'illustr'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('illustration', 'illustration'), (',', ','), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 52 =============================

3(a), the inputs are points in the two- dimensional plane, the outputs are the labels as- signed to each input (circles or crosses), and the goal is to learn a binary classifier. 


>> Tokens are: 
 ['3', '(', ')', ',', 'inputs', 'points', 'two-', 'dimensional', 'plane', ',', 'outputs', 'labels', 'as-', 'signed', 'input', '(', 'circles', 'crosses', ')', ',', 'goal', 'learn', 'binary', 'classifier', '.']

>> Bigrams are: 
 [('3', '('), ('(', ')'), (')', ','), (',', 'inputs'), ('inputs', 'points'), ('points', 'two-'), ('two-', 'dimensional'), ('dimensional', 'plane'), ('plane', ','), (',', 'outputs'), ('outputs', 'labels'), ('labels', 'as-'), ('as-', 'signed'), ('signed', 'input'), ('input', '('), ('(', 'circles'), ('circles', 'crosses'), ('crosses', ')'), (')', ','), (',', 'goal'), ('goal', 'learn'), ('learn', 'binary'), ('binary', 'classifier'), ('classifier', '.')]

>> Trigrams are: 
 [('3', '(', ')'), ('(', ')', ','), (')', ',', 'inputs'), (',', 'inputs', 'points'), ('inputs', 'points', 'two-'), ('points', 'two-', 'dimensional'), ('two-', 'dimensional', 'plane'), ('dimensional', 'plane', ','), ('plane', ',', 'outputs'), (',', 'outputs', 'labels'), ('outputs', 'labels', 'as-'), ('labels', 'as-', 'signed'), ('as-', 'signed', 'input'), ('signed', 'input', '('), ('input', '(', 'circles'), ('(', 'circles', 'crosses'), ('circles', 'crosses', ')'), ('crosses', ')', ','), (')', ',', 'goal'), (',', 'goal', 'learn'), ('goal', 'learn', 'binary'), ('learn', 'binary', 'classifier'), ('binary', 'classifier', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('(', '('), (')', ')'), (',', ','), ('inputs', 'JJ'), ('points', 'NNS'), ('two-', 'JJ'), ('dimensional', 'JJ'), ('plane', 'NN'), (',', ','), ('outputs', 'JJ'), ('labels', 'NNS'), ('as-', 'RB'), ('signed', 'VBN'), ('input', 'NN'), ('(', '('), ('circles', 'NNS'), ('crosses', 'NNS'), (')', ')'), (',', ','), ('goal', 'NN'), ('learn', 'NN'), ('binary', 'JJ'), ('classifier', 'NN'), ('.', '.')]

 (S
  3/CD
  (/(
  )/)
  ,/,
  (NP inputs/JJ points/NNS)
  (NP two-/JJ dimensional/JJ plane/NN)
  ,/,
  (NP outputs/JJ labels/NNS)
  as-/RB
  signed/VBN
  (NP input/NN)
  (/(
  (NP circles/NNS crosses/NNS)
  )/)
  ,/,
  (NP goal/NN learn/NN)
  (NP binary/JJ classifier/NN)
  ./.) 


>> Noun Phrases are: 
 ['inputs points', 'two- dimensional plane', 'outputs labels', 'input', 'circles crosses', 'goal learn', 'binary classifier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('(', '('), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-', 'two-'), ('dimensional', 'dimension'), ('plane', 'plane'), (',', ','), ('outputs', 'output'), ('labels', 'label'), ('as-', 'as-'), ('signed', 'sign'), ('input', 'input'), ('(', '('), ('circles', 'circl'), ('crosses', 'cross'), (')', ')'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('binary', 'binari'), ('classifier', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('(', '('), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-', 'two-'), ('dimensional', 'dimension'), ('plane', 'plane'), (',', ','), ('outputs', 'output'), ('labels', 'label'), ('as-', 'as-'), ('signed', 'sign'), ('input', 'input'), ('(', '('), ('circles', 'circl'), ('crosses', 'cross'), (')', ')'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('binary', 'binari'), ('classifier', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('(', '('), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-', 'two-'), ('dimensional', 'dimensional'), ('plane', 'plane'), (',', ','), ('outputs', 'output'), ('labels', 'label'), ('as-', 'as-'), ('signed', 'signed'), ('input', 'input'), ('(', '('), ('circles', 'circle'), ('crosses', 'cross'), (')', ')'), (',', ','), ('goal', 'goal'), ('learn', 'learn'), ('binary', 'binary'), ('classifier', 'classifier'), ('.', '.')]



============================ Sentence 53 =============================

Applications include the channel decoder discussed above, as well as email spam classification on the basis of examples of spam/ non-spam emails. 


>> Tokens are: 
 ['Applications', 'include', 'channel', 'decoder', 'discussed', ',', 'well', 'email', 'spam', 'classification', 'basis', 'examples', 'spam/', 'non-spam', 'emails', '.']

>> Bigrams are: 
 [('Applications', 'include'), ('include', 'channel'), ('channel', 'decoder'), ('decoder', 'discussed'), ('discussed', ','), (',', 'well'), ('well', 'email'), ('email', 'spam'), ('spam', 'classification'), ('classification', 'basis'), ('basis', 'examples'), ('examples', 'spam/'), ('spam/', 'non-spam'), ('non-spam', 'emails'), ('emails', '.')]

>> Trigrams are: 
 [('Applications', 'include', 'channel'), ('include', 'channel', 'decoder'), ('channel', 'decoder', 'discussed'), ('decoder', 'discussed', ','), ('discussed', ',', 'well'), (',', 'well', 'email'), ('well', 'email', 'spam'), ('email', 'spam', 'classification'), ('spam', 'classification', 'basis'), ('classification', 'basis', 'examples'), ('basis', 'examples', 'spam/'), ('examples', 'spam/', 'non-spam'), ('spam/', 'non-spam', 'emails'), ('non-spam', 'emails', '.')]

>> POS Tags are: 
 [('Applications', 'NNS'), ('include', 'VBP'), ('channel', 'NNS'), ('decoder', 'NN'), ('discussed', 'VBN'), (',', ','), ('well', 'RB'), ('email', 'JJ'), ('spam', 'NN'), ('classification', 'NN'), ('basis', 'NN'), ('examples', 'VBZ'), ('spam/', 'RB'), ('non-spam', 'JJ'), ('emails', 'NNS'), ('.', '.')]

 (S
  (NP Applications/NNS)
  include/VBP
  (NP channel/NNS decoder/NN)
  discussed/VBN
  ,/,
  well/RB
  (NP email/JJ spam/NN classification/NN basis/NN)
  examples/VBZ
  spam//RB
  (NP non-spam/JJ emails/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Applications', 'channel decoder', 'email spam classification basis', 'non-spam emails']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applications', 'applic'), ('include', 'includ'), ('channel', 'channel'), ('decoder', 'decod'), ('discussed', 'discuss'), (',', ','), ('well', 'well'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('basis', 'basi'), ('examples', 'exampl'), ('spam/', 'spam/'), ('non-spam', 'non-spam'), ('emails', 'email'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applications', 'applic'), ('include', 'includ'), ('channel', 'channel'), ('decoder', 'decod'), ('discussed', 'discuss'), (',', ','), ('well', 'well'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('basis', 'basi'), ('examples', 'exampl'), ('spam/', 'spam/'), ('non-spam', 'non-spam'), ('emails', 'email'), ('.', '.')]

>> Lemmatization: 
 [('Applications', 'Applications'), ('include', 'include'), ('channel', 'channel'), ('decoder', 'decoder'), ('discussed', 'discussed'), (',', ','), ('well', 'well'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classification'), ('basis', 'basis'), ('examples', 'example'), ('spam/', 'spam/'), ('non-spam', 'non-spam'), ('emails', 'email'), ('.', '.')]



============================ Sentence 54 =============================

• Unsupervised learning: In unsupervised learning, the training set consists of unlabelled inputs, that is, of inputs without any assigned desired output. 


>> Tokens are: 
 ['•', 'Unsupervised', 'learning', ':', 'In', 'unsupervised', 'learning', ',', 'training', 'set', 'consists', 'unlabelled', 'inputs', ',', ',', 'inputs', 'without', 'assigned', 'desired', 'output', '.']

>> Bigrams are: 
 [('•', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', ':'), (':', 'In'), ('In', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'training'), ('training', 'set'), ('set', 'consists'), ('consists', 'unlabelled'), ('unlabelled', 'inputs'), ('inputs', ','), (',', ','), (',', 'inputs'), ('inputs', 'without'), ('without', 'assigned'), ('assigned', 'desired'), ('desired', 'output'), ('output', '.')]

>> Trigrams are: 
 [('•', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', ':'), ('learning', ':', 'In'), (':', 'In', 'unsupervised'), ('In', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'training'), (',', 'training', 'set'), ('training', 'set', 'consists'), ('set', 'consists', 'unlabelled'), ('consists', 'unlabelled', 'inputs'), ('unlabelled', 'inputs', ','), ('inputs', ',', ','), (',', ',', 'inputs'), (',', 'inputs', 'without'), ('inputs', 'without', 'assigned'), ('without', 'assigned', 'desired'), ('assigned', 'desired', 'output'), ('desired', 'output', '.')]

>> POS Tags are: 
 [('•', 'NNS'), ('Unsupervised', 'VBD'), ('learning', 'NN'), (':', ':'), ('In', 'IN'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('training', 'VBG'), ('set', 'NN'), ('consists', 'VBZ'), ('unlabelled', 'JJ'), ('inputs', 'NNS'), (',', ','), (',', ','), ('inputs', 'NNS'), ('without', 'IN'), ('assigned', 'VBN'), ('desired', 'VBN'), ('output', 'NN'), ('.', '.')]

 (S
  (NP •/NNS)
  Unsupervised/VBD
  (NP learning/NN)
  :/:
  In/IN
  (NP unsupervised/JJ learning/NN)
  ,/,
  training/VBG
  (NP set/NN)
  consists/VBZ
  (NP unlabelled/JJ inputs/NNS)
  ,/,
  ,/,
  (NP inputs/NNS)
  without/IN
  assigned/VBN
  desired/VBN
  (NP output/NN)
  ./.) 


>> Noun Phrases are: 
 ['•', 'learning', 'unsupervised learning', 'set', 'unlabelled inputs', 'inputs', 'output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), (':', ':'), ('In', 'in'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('training', 'train'), ('set', 'set'), ('consists', 'consist'), ('unlabelled', 'unlabel'), ('inputs', 'input'), (',', ','), (',', ','), ('inputs', 'input'), ('without', 'without'), ('assigned', 'assign'), ('desired', 'desir'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), (':', ':'), ('In', 'in'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('training', 'train'), ('set', 'set'), ('consists', 'consist'), ('unlabelled', 'unlabel'), ('inputs', 'input'), (',', ','), (',', ','), ('inputs', 'input'), ('without', 'without'), ('assigned', 'assign'), ('desired', 'desir'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), (':', ':'), ('In', 'In'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('training', 'training'), ('set', 'set'), ('consists', 'consists'), ('unlabelled', 'unlabelled'), ('inputs', 'input'), (',', ','), (',', ','), ('inputs', 'input'), ('without', 'without'), ('assigned', 'assigned'), ('desired', 'desired'), ('output', 'output'), ('.', '.')]



============================ Sentence 55 =============================

For instance, in Fig. 


>> Tokens are: 
 ['For', 'instance', ',', 'Fig', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'Fig'), (',', 'Fig', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('Fig', 'NNP'), ('.', '.')]

 (S For/IN (NP instance/NN) ,/, (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['instance', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 56 =============================

3(b), the inputs are again points in the two-dimensional plane, but no indication is provided by the data about the corresponding de- sired output. 


>> Tokens are: 
 ['3', '(', 'b', ')', ',', 'inputs', 'points', 'two-dimensional', 'plane', ',', 'indication', 'provided', 'data', 'corresponding', 'de-', 'sired', 'output', '.']

>> Bigrams are: 
 [('3', '('), ('(', 'b'), ('b', ')'), (')', ','), (',', 'inputs'), ('inputs', 'points'), ('points', 'two-dimensional'), ('two-dimensional', 'plane'), ('plane', ','), (',', 'indication'), ('indication', 'provided'), ('provided', 'data'), ('data', 'corresponding'), ('corresponding', 'de-'), ('de-', 'sired'), ('sired', 'output'), ('output', '.')]

>> Trigrams are: 
 [('3', '(', 'b'), ('(', 'b', ')'), ('b', ')', ','), (')', ',', 'inputs'), (',', 'inputs', 'points'), ('inputs', 'points', 'two-dimensional'), ('points', 'two-dimensional', 'plane'), ('two-dimensional', 'plane', ','), ('plane', ',', 'indication'), (',', 'indication', 'provided'), ('indication', 'provided', 'data'), ('provided', 'data', 'corresponding'), ('data', 'corresponding', 'de-'), ('corresponding', 'de-', 'sired'), ('de-', 'sired', 'output'), ('sired', 'output', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('(', '('), ('b', 'NN'), (')', ')'), (',', ','), ('inputs', 'JJ'), ('points', 'NNS'), ('two-dimensional', 'JJ'), ('plane', 'NN'), (',', ','), ('indication', 'NN'), ('provided', 'VBD'), ('data', 'NNS'), ('corresponding', 'VBG'), ('de-', 'NN'), ('sired', 'VBD'), ('output', 'NN'), ('.', '.')]

 (S
  3/CD
  (/(
  (NP b/NN)
  )/)
  ,/,
  (NP inputs/JJ points/NNS)
  (NP two-dimensional/JJ plane/NN)
  ,/,
  (NP indication/NN)
  provided/VBD
  (NP data/NNS)
  corresponding/VBG
  (NP de-/NN)
  sired/VBD
  (NP output/NN)
  ./.) 


>> Noun Phrases are: 
 ['b', 'inputs points', 'two-dimensional plane', 'indication', 'data', 'de-', 'output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-dimensional', 'two-dimension'), ('plane', 'plane'), (',', ','), ('indication', 'indic'), ('provided', 'provid'), ('data', 'data'), ('corresponding', 'correspond'), ('de-', 'de-'), ('sired', 'sire'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-dimensional', 'two-dimension'), ('plane', 'plane'), (',', ','), ('indication', 'indic'), ('provided', 'provid'), ('data', 'data'), ('corresponding', 'correspond'), ('de-', 'de-'), ('sired', 'sire'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('inputs', 'input'), ('points', 'point'), ('two-dimensional', 'two-dimensional'), ('plane', 'plane'), (',', ','), ('indication', 'indication'), ('provided', 'provided'), ('data', 'data'), ('corresponding', 'corresponding'), ('de-', 'de-'), ('sired', 'sired'), ('output', 'output'), ('.', '.')]



============================ Sentence 57 =============================

Unsupervised learning generally aims at discovering properties of the mechanism gen- erating the data. 


>> Tokens are: 
 ['Unsupervised', 'learning', 'generally', 'aims', 'discovering', 'properties', 'mechanism', 'gen-', 'erating', 'data', '.']

>> Bigrams are: 
 [('Unsupervised', 'learning'), ('learning', 'generally'), ('generally', 'aims'), ('aims', 'discovering'), ('discovering', 'properties'), ('properties', 'mechanism'), ('mechanism', 'gen-'), ('gen-', 'erating'), ('erating', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unsupervised', 'learning', 'generally'), ('learning', 'generally', 'aims'), ('generally', 'aims', 'discovering'), ('aims', 'discovering', 'properties'), ('discovering', 'properties', 'mechanism'), ('properties', 'mechanism', 'gen-'), ('mechanism', 'gen-', 'erating'), ('gen-', 'erating', 'data'), ('erating', 'data', '.')]

>> POS Tags are: 
 [('Unsupervised', 'VBN'), ('learning', 'VBG'), ('generally', 'RB'), ('aims', 'VBZ'), ('discovering', 'VBG'), ('properties', 'NNS'), ('mechanism', 'VBP'), ('gen-', 'JJ'), ('erating', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  Unsupervised/VBN
  learning/VBG
  generally/RB
  aims/VBZ
  discovering/VBG
  (NP properties/NNS)
  mechanism/VBP
  (NP gen-/JJ erating/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['properties', 'gen- erating data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('generally', 'gener'), ('aims', 'aim'), ('discovering', 'discov'), ('properties', 'properti'), ('mechanism', 'mechan'), ('gen-', 'gen-'), ('erating', 'erat'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('generally', 'general'), ('aims', 'aim'), ('discovering', 'discov'), ('properties', 'properti'), ('mechanism', 'mechan'), ('gen-', 'gen-'), ('erating', 'erat'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('generally', 'generally'), ('aims', 'aim'), ('discovering', 'discovering'), ('properties', 'property'), ('mechanism', 'mechanism'), ('gen-', 'gen-'), ('erating', 'erating'), ('data', 'data'), ('.', '.')]



============================ Sentence 58 =============================

In the example of Fig. 


>> Tokens are: 
 ['In', 'example', 'Fig', '.']

>> Bigrams are: 
 [('In', 'example'), ('example', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('In', 'example', 'Fig'), ('example', 'Fig', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('example', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S In/IN (NP example/NN Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['example Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('example', 'exampl'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('example', 'exampl'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('example', 'example'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 59 =============================

3(b), the goal of unsupervised learning is to cluster together  2    input points that are close to each other, hence assigning a label – the cluster index – to each input point (clusters are delimited by dashed lines). 


>> Tokens are: 
 ['3', '(', 'b', ')', ',', 'goal', 'unsupervised', 'learning', 'cluster', 'together', '2', 'input', 'points', 'close', ',', 'hence', 'assigning', 'label', '–', 'cluster', 'index', '–', 'input', 'point', '(', 'clusters', 'delimited', 'dashed', 'lines', ')', '.']

>> Bigrams are: 
 [('3', '('), ('(', 'b'), ('b', ')'), (')', ','), (',', 'goal'), ('goal', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'cluster'), ('cluster', 'together'), ('together', '2'), ('2', 'input'), ('input', 'points'), ('points', 'close'), ('close', ','), (',', 'hence'), ('hence', 'assigning'), ('assigning', 'label'), ('label', '–'), ('–', 'cluster'), ('cluster', 'index'), ('index', '–'), ('–', 'input'), ('input', 'point'), ('point', '('), ('(', 'clusters'), ('clusters', 'delimited'), ('delimited', 'dashed'), ('dashed', 'lines'), ('lines', ')'), (')', '.')]

>> Trigrams are: 
 [('3', '(', 'b'), ('(', 'b', ')'), ('b', ')', ','), (')', ',', 'goal'), (',', 'goal', 'unsupervised'), ('goal', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'cluster'), ('learning', 'cluster', 'together'), ('cluster', 'together', '2'), ('together', '2', 'input'), ('2', 'input', 'points'), ('input', 'points', 'close'), ('points', 'close', ','), ('close', ',', 'hence'), (',', 'hence', 'assigning'), ('hence', 'assigning', 'label'), ('assigning', 'label', '–'), ('label', '–', 'cluster'), ('–', 'cluster', 'index'), ('cluster', 'index', '–'), ('index', '–', 'input'), ('–', 'input', 'point'), ('input', 'point', '('), ('point', '(', 'clusters'), ('(', 'clusters', 'delimited'), ('clusters', 'delimited', 'dashed'), ('delimited', 'dashed', 'lines'), ('dashed', 'lines', ')'), ('lines', ')', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('(', '('), ('b', 'NN'), (')', ')'), (',', ','), ('goal', 'NN'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('cluster', 'NN'), ('together', 'RB'), ('2', 'CD'), ('input', 'NN'), ('points', 'NNS'), ('close', 'RB'), (',', ','), ('hence', 'NN'), ('assigning', 'VBG'), ('label', 'JJ'), ('–', 'NNP'), ('cluster', 'NN'), ('index', 'NN'), ('–', 'NNP'), ('input', 'NN'), ('point', 'NN'), ('(', '('), ('clusters', 'NNS'), ('delimited', 'VBN'), ('dashed', 'JJ'), ('lines', 'NNS'), (')', ')'), ('.', '.')]

 (S
  3/CD
  (/(
  (NP b/NN)
  )/)
  ,/,
  (NP goal/NN)
  unsupervised/VBD
  learning/VBG
  (NP cluster/NN)
  together/RB
  2/CD
  (NP input/NN points/NNS)
  close/RB
  ,/,
  (NP hence/NN)
  assigning/VBG
  (NP label/JJ –/NNP cluster/NN index/NN –/NNP input/NN point/NN)
  (/(
  (NP clusters/NNS)
  delimited/VBN
  (NP dashed/JJ lines/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['b', 'goal', 'cluster', 'input points', 'hence', 'label – cluster index – input point', 'clusters', 'dashed lines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('goal', 'goal'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('cluster', 'cluster'), ('together', 'togeth'), ('2', '2'), ('input', 'input'), ('points', 'point'), ('close', 'close'), (',', ','), ('hence', 'henc'), ('assigning', 'assign'), ('label', 'label'), ('–', '–'), ('cluster', 'cluster'), ('index', 'index'), ('–', '–'), ('input', 'input'), ('point', 'point'), ('(', '('), ('clusters', 'cluster'), ('delimited', 'delimit'), ('dashed', 'dash'), ('lines', 'line'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('goal', 'goal'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('cluster', 'cluster'), ('together', 'togeth'), ('2', '2'), ('input', 'input'), ('points', 'point'), ('close', 'close'), (',', ','), ('hence', 'henc'), ('assigning', 'assign'), ('label', 'label'), ('–', '–'), ('cluster', 'cluster'), ('index', 'index'), ('–', '–'), ('input', 'input'), ('point', 'point'), ('(', '('), ('clusters', 'cluster'), ('delimited', 'delimit'), ('dashed', 'dash'), ('lines', 'line'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('(', '('), ('b', 'b'), (')', ')'), (',', ','), ('goal', 'goal'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('cluster', 'cluster'), ('together', 'together'), ('2', '2'), ('input', 'input'), ('points', 'point'), ('close', 'close'), (',', ','), ('hence', 'hence'), ('assigning', 'assigning'), ('label', 'label'), ('–', '–'), ('cluster', 'cluster'), ('index', 'index'), ('–', '–'), ('input', 'input'), ('point', 'point'), ('(', '('), ('clusters', 'cluster'), ('delimited', 'delimited'), ('dashed', 'dashed'), ('lines', 'line'), (')', ')'), ('.', '.')]



============================ Sentence 60 =============================

Applications include clustering of documents with similar topics. 


>> Tokens are: 
 ['Applications', 'include', 'clustering', 'documents', 'similar', 'topics', '.']

>> Bigrams are: 
 [('Applications', 'include'), ('include', 'clustering'), ('clustering', 'documents'), ('documents', 'similar'), ('similar', 'topics'), ('topics', '.')]

>> Trigrams are: 
 [('Applications', 'include', 'clustering'), ('include', 'clustering', 'documents'), ('clustering', 'documents', 'similar'), ('documents', 'similar', 'topics'), ('similar', 'topics', '.')]

>> POS Tags are: 
 [('Applications', 'NNS'), ('include', 'VBP'), ('clustering', 'VBG'), ('documents', 'NNS'), ('similar', 'JJ'), ('topics', 'NNS'), ('.', '.')]

 (S
  (NP Applications/NNS)
  include/VBP
  clustering/VBG
  (NP documents/NNS)
  (NP similar/JJ topics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Applications', 'documents', 'similar topics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applications', 'applic'), ('include', 'includ'), ('clustering', 'cluster'), ('documents', 'document'), ('similar', 'similar'), ('topics', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applications', 'applic'), ('include', 'includ'), ('clustering', 'cluster'), ('documents', 'document'), ('similar', 'similar'), ('topics', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('Applications', 'Applications'), ('include', 'include'), ('clustering', 'clustering'), ('documents', 'document'), ('similar', 'similar'), ('topics', 'topic'), ('.', '.')]



============================ Sentence 61 =============================

It is emphasized that clustering is only one of the learning tasks that fall under the category of unsupervised learning (see Sec V). 


>> Tokens are: 
 ['It', 'emphasized', 'clustering', 'one', 'learning', 'tasks', 'fall', 'category', 'unsupervised', 'learning', '(', 'see', 'Sec', 'V', ')', '.']

>> Bigrams are: 
 [('It', 'emphasized'), ('emphasized', 'clustering'), ('clustering', 'one'), ('one', 'learning'), ('learning', 'tasks'), ('tasks', 'fall'), ('fall', 'category'), ('category', 'unsupervised'), ('unsupervised', 'learning'), ('learning', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'V'), ('V', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'emphasized', 'clustering'), ('emphasized', 'clustering', 'one'), ('clustering', 'one', 'learning'), ('one', 'learning', 'tasks'), ('learning', 'tasks', 'fall'), ('tasks', 'fall', 'category'), ('fall', 'category', 'unsupervised'), ('category', 'unsupervised', 'learning'), ('unsupervised', 'learning', '('), ('learning', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'V'), ('Sec', 'V', ')'), ('V', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('emphasized', 'VBD'), ('clustering', 'VBG'), ('one', 'CD'), ('learning', 'NN'), ('tasks', 'NNS'), ('fall', 'VBP'), ('category', 'NN'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('V', 'NNP'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  emphasized/VBD
  clustering/VBG
  one/CD
  (NP learning/NN tasks/NNS)
  fall/VBP
  (NP category/NN)
  (NP unsupervised/JJ learning/NN)
  (/(
  see/VB
  (NP Sec/NNP V/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['learning tasks', 'category', 'unsupervised learning', 'Sec V']

>> Named Entities are: 
 [('PERSON', 'Sec V')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('emphasized', 'emphas'), ('clustering', 'cluster'), ('one', 'one'), ('learning', 'learn'), ('tasks', 'task'), ('fall', 'fall'), ('category', 'categori'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V', 'v'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('emphasized', 'emphas'), ('clustering', 'cluster'), ('one', 'one'), ('learning', 'learn'), ('tasks', 'task'), ('fall', 'fall'), ('category', 'categori'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V', 'v'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('emphasized', 'emphasized'), ('clustering', 'clustering'), ('one', 'one'), ('learning', 'learning'), ('tasks', 'task'), ('fall', 'fall'), ('category', 'category'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('V', 'V'), (')', ')'), ('.', '.')]



============================ Sentence 62 =============================

• Reinforcement learning: Reinforcement learning lies, in a sense, between supervised and unsuper-to be encountered at runtime vised learning. 


>> Tokens are: 
 ['•', 'Reinforcement', 'learning', ':', 'Reinforcement', 'learning', 'lies', ',', 'sense', ',', 'supervised', 'unsuper-to', 'encountered', 'runtime', 'vised', 'learning', '.']

>> Bigrams are: 
 [('•', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', ':'), (':', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', 'lies'), ('lies', ','), (',', 'sense'), ('sense', ','), (',', 'supervised'), ('supervised', 'unsuper-to'), ('unsuper-to', 'encountered'), ('encountered', 'runtime'), ('runtime', 'vised'), ('vised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('•', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', ':'), ('learning', ':', 'Reinforcement'), (':', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', 'lies'), ('learning', 'lies', ','), ('lies', ',', 'sense'), (',', 'sense', ','), ('sense', ',', 'supervised'), (',', 'supervised', 'unsuper-to'), ('supervised', 'unsuper-to', 'encountered'), ('unsuper-to', 'encountered', 'runtime'), ('encountered', 'runtime', 'vised'), ('runtime', 'vised', 'learning'), ('vised', 'learning', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Reinforcement', 'NNP'), ('learning', 'NN'), (':', ':'), ('Reinforcement', 'NN'), ('learning', 'VBG'), ('lies', 'NNS'), (',', ','), ('sense', 'NN'), (',', ','), ('supervised', 'VBD'), ('unsuper-to', 'JJ'), ('encountered', 'JJ'), ('runtime', 'NN'), ('vised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP •/JJ Reinforcement/NNP learning/NN)
  :/:
  (NP Reinforcement/NN)
  learning/VBG
  (NP lies/NNS)
  ,/,
  (NP sense/NN)
  ,/,
  supervised/VBD
  (NP unsuper-to/JJ encountered/JJ runtime/NN)
  vised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['• Reinforcement learning', 'Reinforcement', 'lies', 'sense', 'unsuper-to encountered runtime', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), (':', ':'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), ('lies', 'lie'), (',', ','), ('sense', 'sens'), (',', ','), ('supervised', 'supervis'), ('unsuper-to', 'unsuper-to'), ('encountered', 'encount'), ('runtime', 'runtim'), ('vised', 'vise'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), (':', ':'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), ('lies', 'lie'), (',', ','), ('sense', 'sens'), (',', ','), ('supervised', 'supervis'), ('unsuper-to', 'unsuper-to'), ('encountered', 'encount'), ('runtime', 'runtim'), ('vised', 'vise'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Reinforcement', 'Reinforcement'), ('learning', 'learning'), (':', ':'), ('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('lies', 'lie'), (',', ','), ('sense', 'sense'), (',', ','), ('supervised', 'supervised'), ('unsuper-to', 'unsuper-to'), ('encountered', 'encountered'), ('runtime', 'runtime'), ('vised', 'vised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 63 =============================

Unlike unsupervised learning, some form of supervision exists, but this does not come in the form of the specification of a desired output for every input in the data. 


>> Tokens are: 
 ['Unlike', 'unsupervised', 'learning', ',', 'form', 'supervision', 'exists', ',', 'come', 'form', 'specification', 'desired', 'output', 'every', 'input', 'data', '.']

>> Bigrams are: 
 [('Unlike', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'form'), ('form', 'supervision'), ('supervision', 'exists'), ('exists', ','), (',', 'come'), ('come', 'form'), ('form', 'specification'), ('specification', 'desired'), ('desired', 'output'), ('output', 'every'), ('every', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unlike', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'form'), (',', 'form', 'supervision'), ('form', 'supervision', 'exists'), ('supervision', 'exists', ','), ('exists', ',', 'come'), (',', 'come', 'form'), ('come', 'form', 'specification'), ('form', 'specification', 'desired'), ('specification', 'desired', 'output'), ('desired', 'output', 'every'), ('output', 'every', 'input'), ('every', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('Unlike', 'IN'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('form', 'JJ'), ('supervision', 'NN'), ('exists', 'NNS'), (',', ','), ('come', 'VB'), ('form', 'NN'), ('specification', 'NN'), ('desired', 'VBD'), ('output', 'NN'), ('every', 'DT'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  Unlike/IN
  (NP unsupervised/JJ learning/NN)
  ,/,
  (NP form/JJ supervision/NN exists/NNS)
  ,/,
  come/VB
  (NP form/NN specification/NN)
  desired/VBD
  (NP output/NN)
  (NP every/DT input/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['unsupervised learning', 'form supervision exists', 'form specification', 'output', 'every input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlike', 'unlik'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('form', 'form'), ('supervision', 'supervis'), ('exists', 'exist'), (',', ','), ('come', 'come'), ('form', 'form'), ('specification', 'specif'), ('desired', 'desir'), ('output', 'output'), ('every', 'everi'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlike', 'unlik'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('form', 'form'), ('supervision', 'supervis'), ('exists', 'exist'), (',', ','), ('come', 'come'), ('form', 'form'), ('specification', 'specif'), ('desired', 'desir'), ('output', 'output'), ('every', 'everi'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unlike', 'Unlike'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('form', 'form'), ('supervision', 'supervision'), ('exists', 'exists'), (',', ','), ('come', 'come'), ('form', 'form'), ('specification', 'specification'), ('desired', 'desired'), ('output', 'output'), ('every', 'every'), ('input', 'input'), ('data', 'data'), ('.', '.')]



============================ Sentence 64 =============================

Instead, a reinforcement learning algorithm receives feedback from the envi- ronment only after selecting an output for a given input or observation. 


>> Tokens are: 
 ['Instead', ',', 'reinforcement', 'learning', 'algorithm', 'receives', 'feedback', 'envi-', 'ronment', 'selecting', 'output', 'given', 'input', 'observation', '.']

>> Bigrams are: 
 [('Instead', ','), (',', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'algorithm'), ('algorithm', 'receives'), ('receives', 'feedback'), ('feedback', 'envi-'), ('envi-', 'ronment'), ('ronment', 'selecting'), ('selecting', 'output'), ('output', 'given'), ('given', 'input'), ('input', 'observation'), ('observation', '.')]

>> Trigrams are: 
 [('Instead', ',', 'reinforcement'), (',', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'algorithm'), ('learning', 'algorithm', 'receives'), ('algorithm', 'receives', 'feedback'), ('receives', 'feedback', 'envi-'), ('feedback', 'envi-', 'ronment'), ('envi-', 'ronment', 'selecting'), ('ronment', 'selecting', 'output'), ('selecting', 'output', 'given'), ('output', 'given', 'input'), ('given', 'input', 'observation'), ('input', 'observation', '.')]

>> POS Tags are: 
 [('Instead', 'RB'), (',', ','), ('reinforcement', 'JJ'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('receives', 'NNS'), ('feedback', 'VBP'), ('envi-', 'JJ'), ('ronment', 'NN'), ('selecting', 'VBG'), ('output', 'NN'), ('given', 'VBN'), ('input', 'JJ'), ('observation', 'NN'), ('.', '.')]

 (S
  Instead/RB
  ,/,
  reinforcement/JJ
  learning/VBG
  (NP algorithm/JJ receives/NNS)
  feedback/VBP
  (NP envi-/JJ ronment/NN)
  selecting/VBG
  (NP output/NN)
  given/VBN
  (NP input/JJ observation/NN)
  ./.) 


>> Noun Phrases are: 
 ['algorithm receives', 'envi- ronment', 'output', 'input observation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instead', 'instead'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('receives', 'receiv'), ('feedback', 'feedback'), ('envi-', 'envi-'), ('ronment', 'ronment'), ('selecting', 'select'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('observation', 'observ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Instead', 'instead'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('receives', 'receiv'), ('feedback', 'feedback'), ('envi-', 'envi-'), ('ronment', 'ronment'), ('selecting', 'select'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('observation', 'observ'), ('.', '.')]

>> Lemmatization: 
 [('Instead', 'Instead'), (',', ','), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('receives', 'receives'), ('feedback', 'feedback'), ('envi-', 'envi-'), ('ronment', 'ronment'), ('selecting', 'selecting'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('observation', 'observation'), ('.', '.')]



============================ Sentence 65 =============================

The feedback indicates the degree to which the output, known as action in re- inforcement learning, fulfils the goals of the learner. 


>> Tokens are: 
 ['The', 'feedback', 'indicates', 'degree', 'output', ',', 'known', 'action', 're-', 'inforcement', 'learning', ',', 'fulfils', 'goals', 'learner', '.']

>> Bigrams are: 
 [('The', 'feedback'), ('feedback', 'indicates'), ('indicates', 'degree'), ('degree', 'output'), ('output', ','), (',', 'known'), ('known', 'action'), ('action', 're-'), ('re-', 'inforcement'), ('inforcement', 'learning'), ('learning', ','), (',', 'fulfils'), ('fulfils', 'goals'), ('goals', 'learner'), ('learner', '.')]

>> Trigrams are: 
 [('The', 'feedback', 'indicates'), ('feedback', 'indicates', 'degree'), ('indicates', 'degree', 'output'), ('degree', 'output', ','), ('output', ',', 'known'), (',', 'known', 'action'), ('known', 'action', 're-'), ('action', 're-', 'inforcement'), ('re-', 'inforcement', 'learning'), ('inforcement', 'learning', ','), ('learning', ',', 'fulfils'), (',', 'fulfils', 'goals'), ('fulfils', 'goals', 'learner'), ('goals', 'learner', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('feedback', 'NN'), ('indicates', 'VBZ'), ('degree', 'JJ'), ('output', 'NN'), (',', ','), ('known', 'VBN'), ('action', 'NN'), ('re-', 'JJ'), ('inforcement', 'NN'), ('learning', 'NN'), (',', ','), ('fulfils', 'JJ'), ('goals', 'NNS'), ('learner', 'NN'), ('.', '.')]

 (S
  (NP The/DT feedback/NN)
  indicates/VBZ
  (NP degree/JJ output/NN)
  ,/,
  known/VBN
  (NP action/NN)
  (NP re-/JJ inforcement/NN learning/NN)
  ,/,
  (NP fulfils/JJ goals/NNS learner/NN)
  ./.) 


>> Noun Phrases are: 
 ['The feedback', 'degree output', 'action', 're- inforcement learning', 'fulfils goals learner']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('feedback', 'feedback'), ('indicates', 'indic'), ('degree', 'degre'), ('output', 'output'), (',', ','), ('known', 'known'), ('action', 'action'), ('re-', 're-'), ('inforcement', 'inforc'), ('learning', 'learn'), (',', ','), ('fulfils', 'fulfil'), ('goals', 'goal'), ('learner', 'learner'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('feedback', 'feedback'), ('indicates', 'indic'), ('degree', 'degre'), ('output', 'output'), (',', ','), ('known', 'known'), ('action', 'action'), ('re-', 're-'), ('inforcement', 'inforc'), ('learning', 'learn'), (',', ','), ('fulfils', 'fulfil'), ('goals', 'goal'), ('learner', 'learner'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('feedback', 'feedback'), ('indicates', 'indicates'), ('degree', 'degree'), ('output', 'output'), (',', ','), ('known', 'known'), ('action', 'action'), ('re-', 're-'), ('inforcement', 'inforcement'), ('learning', 'learning'), (',', ','), ('fulfils', 'fulfils'), ('goals', 'goal'), ('learner', 'learner'), ('.', '.')]



============================ Sentence 66 =============================

Reinforcement learning applies to sequential deci- sion making problems in which the learner interacts with an environment by sequentially taking actions – the outputs – on the basis of its observations – its inputs – while receiving feedback regarding each selected action. 


>> Tokens are: 
 ['Reinforcement', 'learning', 'applies', 'sequential', 'deci-', 'sion', 'making', 'problems', 'learner', 'interacts', 'environment', 'sequentially', 'taking', 'actions', '–', 'outputs', '–', 'basis', 'observations', '–', 'inputs', '–', 'receiving', 'feedback', 'regarding', 'selected', 'action', '.']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', 'applies'), ('applies', 'sequential'), ('sequential', 'deci-'), ('deci-', 'sion'), ('sion', 'making'), ('making', 'problems'), ('problems', 'learner'), ('learner', 'interacts'), ('interacts', 'environment'), ('environment', 'sequentially'), ('sequentially', 'taking'), ('taking', 'actions'), ('actions', '–'), ('–', 'outputs'), ('outputs', '–'), ('–', 'basis'), ('basis', 'observations'), ('observations', '–'), ('–', 'inputs'), ('inputs', '–'), ('–', 'receiving'), ('receiving', 'feedback'), ('feedback', 'regarding'), ('regarding', 'selected'), ('selected', 'action'), ('action', '.')]

>> Trigrams are: 
 [('Reinforcement', 'learning', 'applies'), ('learning', 'applies', 'sequential'), ('applies', 'sequential', 'deci-'), ('sequential', 'deci-', 'sion'), ('deci-', 'sion', 'making'), ('sion', 'making', 'problems'), ('making', 'problems', 'learner'), ('problems', 'learner', 'interacts'), ('learner', 'interacts', 'environment'), ('interacts', 'environment', 'sequentially'), ('environment', 'sequentially', 'taking'), ('sequentially', 'taking', 'actions'), ('taking', 'actions', '–'), ('actions', '–', 'outputs'), ('–', 'outputs', '–'), ('outputs', '–', 'basis'), ('–', 'basis', 'observations'), ('basis', 'observations', '–'), ('observations', '–', 'inputs'), ('–', 'inputs', '–'), ('inputs', '–', 'receiving'), ('–', 'receiving', 'feedback'), ('receiving', 'feedback', 'regarding'), ('feedback', 'regarding', 'selected'), ('regarding', 'selected', 'action'), ('selected', 'action', '.')]

>> POS Tags are: 
 [('Reinforcement', 'NNP'), ('learning', 'VBG'), ('applies', 'NNS'), ('sequential', 'JJ'), ('deci-', 'JJ'), ('sion', 'NN'), ('making', 'VBG'), ('problems', 'NNS'), ('learner', 'JJ'), ('interacts', 'NNS'), ('environment', 'NN'), ('sequentially', 'RB'), ('taking', 'VBG'), ('actions', 'NNS'), ('–', 'VBP'), ('outputs', 'NNS'), ('–', 'JJ'), ('basis', 'NN'), ('observations', 'NNS'), ('–', 'VBP'), ('inputs', 'NNS'), ('–', 'VBP'), ('receiving', 'VBG'), ('feedback', 'NN'), ('regarding', 'VBG'), ('selected', 'VBN'), ('action', 'NN'), ('.', '.')]

 (S
  (NP Reinforcement/NNP)
  learning/VBG
  (NP applies/NNS)
  (NP sequential/JJ deci-/JJ sion/NN)
  making/VBG
  (NP problems/NNS)
  (NP learner/JJ interacts/NNS environment/NN)
  sequentially/RB
  taking/VBG
  (NP actions/NNS)
  –/VBP
  (NP outputs/NNS)
  (NP –/JJ basis/NN observations/NNS)
  –/VBP
  (NP inputs/NNS)
  –/VBP
  receiving/VBG
  (NP feedback/NN)
  regarding/VBG
  selected/VBN
  (NP action/NN)
  ./.) 


>> Noun Phrases are: 
 ['Reinforcement', 'applies', 'sequential deci- sion', 'problems', 'learner interacts environment', 'actions', 'outputs', '– basis observations', 'inputs', 'feedback', 'action']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('applies', 'appli'), ('sequential', 'sequenti'), ('deci-', 'deci-'), ('sion', 'sion'), ('making', 'make'), ('problems', 'problem'), ('learner', 'learner'), ('interacts', 'interact'), ('environment', 'environ'), ('sequentially', 'sequenti'), ('taking', 'take'), ('actions', 'action'), ('–', '–'), ('outputs', 'output'), ('–', '–'), ('basis', 'basi'), ('observations', 'observ'), ('–', '–'), ('inputs', 'input'), ('–', '–'), ('receiving', 'receiv'), ('feedback', 'feedback'), ('regarding', 'regard'), ('selected', 'select'), ('action', 'action'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('applies', 'appli'), ('sequential', 'sequenti'), ('deci-', 'deci-'), ('sion', 'sion'), ('making', 'make'), ('problems', 'problem'), ('learner', 'learner'), ('interacts', 'interact'), ('environment', 'environ'), ('sequentially', 'sequenti'), ('taking', 'take'), ('actions', 'action'), ('–', '–'), ('outputs', 'output'), ('–', '–'), ('basis', 'basi'), ('observations', 'observ'), ('–', '–'), ('inputs', 'input'), ('–', '–'), ('receiving', 'receiv'), ('feedback', 'feedback'), ('regarding', 'regard'), ('selected', 'select'), ('action', 'action'), ('.', '.')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('applies', 'applies'), ('sequential', 'sequential'), ('deci-', 'deci-'), ('sion', 'sion'), ('making', 'making'), ('problems', 'problem'), ('learner', 'learner'), ('interacts', 'interacts'), ('environment', 'environment'), ('sequentially', 'sequentially'), ('taking', 'taking'), ('actions', 'action'), ('–', '–'), ('outputs', 'output'), ('–', '–'), ('basis', 'basis'), ('observations', 'observation'), ('–', '–'), ('inputs', 'input'), ('–', '–'), ('receiving', 'receiving'), ('feedback', 'feedback'), ('regarding', 'regarding'), ('selected', 'selected'), ('action', 'action'), ('.', '.')]



============================ Sentence 67 =============================

Most current machine learning applications fall in the supervised learning category, and hence aim at learning an existing pattern between inputs and outputs. 


>> Tokens are: 
 ['Most', 'current', 'machine', 'learning', 'applications', 'fall', 'supervised', 'learning', 'category', ',', 'hence', 'aim', 'learning', 'existing', 'pattern', 'inputs', 'outputs', '.']

>> Bigrams are: 
 [('Most', 'current'), ('current', 'machine'), ('machine', 'learning'), ('learning', 'applications'), ('applications', 'fall'), ('fall', 'supervised'), ('supervised', 'learning'), ('learning', 'category'), ('category', ','), (',', 'hence'), ('hence', 'aim'), ('aim', 'learning'), ('learning', 'existing'), ('existing', 'pattern'), ('pattern', 'inputs'), ('inputs', 'outputs'), ('outputs', '.')]

>> Trigrams are: 
 [('Most', 'current', 'machine'), ('current', 'machine', 'learning'), ('machine', 'learning', 'applications'), ('learning', 'applications', 'fall'), ('applications', 'fall', 'supervised'), ('fall', 'supervised', 'learning'), ('supervised', 'learning', 'category'), ('learning', 'category', ','), ('category', ',', 'hence'), (',', 'hence', 'aim'), ('hence', 'aim', 'learning'), ('aim', 'learning', 'existing'), ('learning', 'existing', 'pattern'), ('existing', 'pattern', 'inputs'), ('pattern', 'inputs', 'outputs'), ('inputs', 'outputs', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('current', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('applications', 'NNS'), ('fall', 'VBP'), ('supervised', 'VBN'), ('learning', 'JJ'), ('category', 'NN'), (',', ','), ('hence', 'RB'), ('aim', 'NN'), ('learning', 'VBG'), ('existing', 'VBG'), ('pattern', 'NN'), ('inputs', 'NNS'), ('outputs', 'NNS'), ('.', '.')]

 (S
  Most/JJS
  (NP current/JJ machine/NN learning/NN applications/NNS)
  fall/VBP
  supervised/VBN
  (NP learning/JJ category/NN)
  ,/,
  hence/RB
  (NP aim/NN)
  learning/VBG
  existing/VBG
  (NP pattern/NN inputs/NNS outputs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['current machine learning applications', 'learning category', 'aim', 'pattern inputs outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('current', 'current'), ('machine', 'machin'), ('learning', 'learn'), ('applications', 'applic'), ('fall', 'fall'), ('supervised', 'supervis'), ('learning', 'learn'), ('category', 'categori'), (',', ','), ('hence', 'henc'), ('aim', 'aim'), ('learning', 'learn'), ('existing', 'exist'), ('pattern', 'pattern'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('current', 'current'), ('machine', 'machin'), ('learning', 'learn'), ('applications', 'applic'), ('fall', 'fall'), ('supervised', 'supervis'), ('learning', 'learn'), ('category', 'categori'), (',', ','), ('hence', 'henc'), ('aim', 'aim'), ('learning', 'learn'), ('existing', 'exist'), ('pattern', 'pattern'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('current', 'current'), ('machine', 'machine'), ('learning', 'learning'), ('applications', 'application'), ('fall', 'fall'), ('supervised', 'supervised'), ('learning', 'learning'), ('category', 'category'), (',', ','), ('hence', 'hence'), ('aim', 'aim'), ('learning', 'learning'), ('existing', 'existing'), ('pattern', 'pattern'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]



============================ Sentence 68 =============================

Supervised learning is relatively well-understood at a theoretical level [14], [15], and it benefits from well- established algorithmic tools. 


>> Tokens are: 
 ['Supervised', 'learning', 'relatively', 'well-understood', 'theoretical', 'level', '[', '14', ']', ',', '[', '15', ']', ',', 'benefits', 'well-', 'established', 'algorithmic', 'tools', '.']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'relatively'), ('relatively', 'well-understood'), ('well-understood', 'theoretical'), ('theoretical', 'level'), ('level', '['), ('[', '14'), ('14', ']'), (']', ','), (',', '['), ('[', '15'), ('15', ']'), (']', ','), (',', 'benefits'), ('benefits', 'well-'), ('well-', 'established'), ('established', 'algorithmic'), ('algorithmic', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Supervised', 'learning', 'relatively'), ('learning', 'relatively', 'well-understood'), ('relatively', 'well-understood', 'theoretical'), ('well-understood', 'theoretical', 'level'), ('theoretical', 'level', '['), ('level', '[', '14'), ('[', '14', ']'), ('14', ']', ','), (']', ',', '['), (',', '[', '15'), ('[', '15', ']'), ('15', ']', ','), (']', ',', 'benefits'), (',', 'benefits', 'well-'), ('benefits', 'well-', 'established'), ('well-', 'established', 'algorithmic'), ('established', 'algorithmic', 'tools'), ('algorithmic', 'tools', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'VBG'), ('relatively', 'RB'), ('well-understood', 'JJ'), ('theoretical', 'JJ'), ('level', 'NN'), ('[', 'VBD'), ('14', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('15', 'CD'), (']', 'NN'), (',', ','), ('benefits', 'NNS'), ('well-', 'VBP'), ('established', 'VBN'), ('algorithmic', 'JJ'), ('tools', 'NNS'), ('.', '.')]

 (S
  Supervised/VBN
  learning/VBG
  relatively/RB
  (NP well-understood/JJ theoretical/JJ level/NN)
  [/VBD
  14/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  15/CD
  (NP ]/NN)
  ,/,
  (NP benefits/NNS)
  well-/VBP
  established/VBN
  (NP algorithmic/JJ tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['well-understood theoretical level', ']', ']', 'benefits', 'algorithmic tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('relatively', 'rel'), ('well-understood', 'well-understood'), ('theoretical', 'theoret'), ('level', 'level'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('[', '['), ('15', '15'), (']', ']'), (',', ','), ('benefits', 'benefit'), ('well-', 'well-'), ('established', 'establish'), ('algorithmic', 'algorithm'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('relatively', 'relat'), ('well-understood', 'well-understood'), ('theoretical', 'theoret'), ('level', 'level'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('[', '['), ('15', '15'), (']', ']'), (',', ','), ('benefits', 'benefit'), ('well-', 'well-'), ('established', 'establish'), ('algorithmic', 'algorithm'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('relatively', 'relatively'), ('well-understood', 'well-understood'), ('theoretical', 'theoretical'), ('level', 'level'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('[', '['), ('15', '15'), (']', ']'), (',', ','), ('benefits', 'benefit'), ('well-', 'well-'), ('established', 'established'), ('algorithmic', 'algorithmic'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 69 =============================

Unsupervised learning has so far defied a unified theoretical treatment [16]. 


>> Tokens are: 
 ['Unsupervised', 'learning', 'far', 'defied', 'unified', 'theoretical', 'treatment', '[', '16', ']', '.']

>> Bigrams are: 
 [('Unsupervised', 'learning'), ('learning', 'far'), ('far', 'defied'), ('defied', 'unified'), ('unified', 'theoretical'), ('theoretical', 'treatment'), ('treatment', '['), ('[', '16'), ('16', ']'), (']', '.')]

>> Trigrams are: 
 [('Unsupervised', 'learning', 'far'), ('learning', 'far', 'defied'), ('far', 'defied', 'unified'), ('defied', 'unified', 'theoretical'), ('unified', 'theoretical', 'treatment'), ('theoretical', 'treatment', '['), ('treatment', '[', '16'), ('[', '16', ']'), ('16', ']', '.')]

>> POS Tags are: 
 [('Unsupervised', 'VBN'), ('learning', 'VBG'), ('far', 'RB'), ('defied', 'VBN'), ('unified', 'JJ'), ('theoretical', 'JJ'), ('treatment', 'NN'), ('[', 'VBD'), ('16', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Unsupervised/VBN
  learning/VBG
  far/RB
  defied/VBN
  (NP unified/JJ theoretical/JJ treatment/NN)
  [/VBD
  16/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['unified theoretical treatment', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('far', 'far'), ('defied', 'defi'), ('unified', 'unifi'), ('theoretical', 'theoret'), ('treatment', 'treatment'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('far', 'far'), ('defied', 'defi'), ('unified', 'unifi'), ('theoretical', 'theoret'), ('treatment', 'treatment'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('far', 'far'), ('defied', 'defied'), ('unified', 'unified'), ('theoretical', 'theoretical'), ('treatment', 'treatment'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]



============================ Sentence 70 =============================

Never- theless, it arguably poses a more fundamental practical problem in that it directly tackles the challenge of learn- ing by direct observation without any form of explicit feedback. 


>> Tokens are: 
 ['Never-', 'theless', ',', 'arguably', 'poses', 'fundamental', 'practical', 'problem', 'directly', 'tackles', 'challenge', 'learn-', 'ing', 'direct', 'observation', 'without', 'form', 'explicit', 'feedback', '.']

>> Bigrams are: 
 [('Never-', 'theless'), ('theless', ','), (',', 'arguably'), ('arguably', 'poses'), ('poses', 'fundamental'), ('fundamental', 'practical'), ('practical', 'problem'), ('problem', 'directly'), ('directly', 'tackles'), ('tackles', 'challenge'), ('challenge', 'learn-'), ('learn-', 'ing'), ('ing', 'direct'), ('direct', 'observation'), ('observation', 'without'), ('without', 'form'), ('form', 'explicit'), ('explicit', 'feedback'), ('feedback', '.')]

>> Trigrams are: 
 [('Never-', 'theless', ','), ('theless', ',', 'arguably'), (',', 'arguably', 'poses'), ('arguably', 'poses', 'fundamental'), ('poses', 'fundamental', 'practical'), ('fundamental', 'practical', 'problem'), ('practical', 'problem', 'directly'), ('problem', 'directly', 'tackles'), ('directly', 'tackles', 'challenge'), ('tackles', 'challenge', 'learn-'), ('challenge', 'learn-', 'ing'), ('learn-', 'ing', 'direct'), ('ing', 'direct', 'observation'), ('direct', 'observation', 'without'), ('observation', 'without', 'form'), ('without', 'form', 'explicit'), ('form', 'explicit', 'feedback'), ('explicit', 'feedback', '.')]

>> POS Tags are: 
 [('Never-', 'NNP'), ('theless', 'NN'), (',', ','), ('arguably', 'RB'), ('poses', 'VBZ'), ('fundamental', 'JJ'), ('practical', 'JJ'), ('problem', 'NN'), ('directly', 'RB'), ('tackles', 'VBZ'), ('challenge', 'VB'), ('learn-', 'JJ'), ('ing', 'VBG'), ('direct', 'JJ'), ('observation', 'NN'), ('without', 'IN'), ('form', 'NN'), ('explicit', 'NN'), ('feedback', 'NN'), ('.', '.')]

 (S
  (NP Never-/NNP theless/NN)
  ,/,
  arguably/RB
  poses/VBZ
  (NP fundamental/JJ practical/JJ problem/NN)
  directly/RB
  tackles/VBZ
  challenge/VB
  learn-/JJ
  ing/VBG
  (NP direct/JJ observation/NN)
  without/IN
  (NP form/NN explicit/NN feedback/NN)
  ./.) 


>> Noun Phrases are: 
 ['Never- theless', 'fundamental practical problem', 'direct observation', 'form explicit feedback']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Never-', 'never-'), ('theless', 'theless'), (',', ','), ('arguably', 'arguabl'), ('poses', 'pose'), ('fundamental', 'fundament'), ('practical', 'practic'), ('problem', 'problem'), ('directly', 'directli'), ('tackles', 'tackl'), ('challenge', 'challeng'), ('learn-', 'learn-'), ('ing', 'ing'), ('direct', 'direct'), ('observation', 'observ'), ('without', 'without'), ('form', 'form'), ('explicit', 'explicit'), ('feedback', 'feedback'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Never-', 'never-'), ('theless', 'theless'), (',', ','), ('arguably', 'arguabl'), ('poses', 'pose'), ('fundamental', 'fundament'), ('practical', 'practic'), ('problem', 'problem'), ('directly', 'direct'), ('tackles', 'tackl'), ('challenge', 'challeng'), ('learn-', 'learn-'), ('ing', 'ing'), ('direct', 'direct'), ('observation', 'observ'), ('without', 'without'), ('form', 'form'), ('explicit', 'explicit'), ('feedback', 'feedback'), ('.', '.')]

>> Lemmatization: 
 [('Never-', 'Never-'), ('theless', 'theless'), (',', ','), ('arguably', 'arguably'), ('poses', 'pose'), ('fundamental', 'fundamental'), ('practical', 'practical'), ('problem', 'problem'), ('directly', 'directly'), ('tackles', 'tackle'), ('challenge', 'challenge'), ('learn-', 'learn-'), ('ing', 'ing'), ('direct', 'direct'), ('observation', 'observation'), ('without', 'without'), ('form', 'form'), ('explicit', 'explicit'), ('feedback', 'feedback'), ('.', '.')]



============================ Sentence 71 =============================

Reinforcement learning has found extensive applications in problems that are characterized by clear feedback signals, such as win/lose outcomes in games, and that entail searches over large trees of possible action-observation histories [17], [18]. 


>> Tokens are: 
 ['Reinforcement', 'learning', 'found', 'extensive', 'applications', 'problems', 'characterized', 'clear', 'feedback', 'signals', ',', 'win/lose', 'outcomes', 'games', ',', 'entail', 'searches', 'large', 'trees', 'possible', 'action-observation', 'histories', '[', '17', ']', ',', '[', '18', ']', '.']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', 'found'), ('found', 'extensive'), ('extensive', 'applications'), ('applications', 'problems'), ('problems', 'characterized'), ('characterized', 'clear'), ('clear', 'feedback'), ('feedback', 'signals'), ('signals', ','), (',', 'win/lose'), ('win/lose', 'outcomes'), ('outcomes', 'games'), ('games', ','), (',', 'entail'), ('entail', 'searches'), ('searches', 'large'), ('large', 'trees'), ('trees', 'possible'), ('possible', 'action-observation'), ('action-observation', 'histories'), ('histories', '['), ('[', '17'), ('17', ']'), (']', ','), (',', '['), ('[', '18'), ('18', ']'), (']', '.')]

>> Trigrams are: 
 [('Reinforcement', 'learning', 'found'), ('learning', 'found', 'extensive'), ('found', 'extensive', 'applications'), ('extensive', 'applications', 'problems'), ('applications', 'problems', 'characterized'), ('problems', 'characterized', 'clear'), ('characterized', 'clear', 'feedback'), ('clear', 'feedback', 'signals'), ('feedback', 'signals', ','), ('signals', ',', 'win/lose'), (',', 'win/lose', 'outcomes'), ('win/lose', 'outcomes', 'games'), ('outcomes', 'games', ','), ('games', ',', 'entail'), (',', 'entail', 'searches'), ('entail', 'searches', 'large'), ('searches', 'large', 'trees'), ('large', 'trees', 'possible'), ('trees', 'possible', 'action-observation'), ('possible', 'action-observation', 'histories'), ('action-observation', 'histories', '['), ('histories', '[', '17'), ('[', '17', ']'), ('17', ']', ','), (']', ',', '['), (',', '[', '18'), ('[', '18', ']'), ('18', ']', '.')]

>> POS Tags are: 
 [('Reinforcement', 'NNP'), ('learning', 'VBG'), ('found', 'VBN'), ('extensive', 'JJ'), ('applications', 'NNS'), ('problems', 'NNS'), ('characterized', 'VBD'), ('clear', 'JJ'), ('feedback', 'NN'), ('signals', 'NNS'), (',', ','), ('win/lose', 'JJ'), ('outcomes', 'NNS'), ('games', 'NNS'), (',', ','), ('entail', 'NN'), ('searches', 'NNS'), ('large', 'JJ'), ('trees', 'NNS'), ('possible', 'JJ'), ('action-observation', 'JJ'), ('histories', 'NNS'), ('[', 'VBP'), ('17', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('18', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Reinforcement/NNP)
  learning/VBG
  found/VBN
  (NP extensive/JJ applications/NNS problems/NNS)
  characterized/VBD
  (NP clear/JJ feedback/NN signals/NNS)
  ,/,
  (NP win/lose/JJ outcomes/NNS games/NNS)
  ,/,
  (NP entail/NN searches/NNS)
  (NP large/JJ trees/NNS)
  (NP possible/JJ action-observation/JJ histories/NNS)
  [/VBP
  17/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  18/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Reinforcement', 'extensive applications problems', 'clear feedback signals', 'win/lose outcomes games', 'entail searches', 'large trees', 'possible action-observation histories', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('found', 'found'), ('extensive', 'extens'), ('applications', 'applic'), ('problems', 'problem'), ('characterized', 'character'), ('clear', 'clear'), ('feedback', 'feedback'), ('signals', 'signal'), (',', ','), ('win/lose', 'win/los'), ('outcomes', 'outcom'), ('games', 'game'), (',', ','), ('entail', 'entail'), ('searches', 'search'), ('large', 'larg'), ('trees', 'tree'), ('possible', 'possibl'), ('action-observation', 'action-observ'), ('histories', 'histori'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('[', '['), ('18', '18'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('found', 'found'), ('extensive', 'extens'), ('applications', 'applic'), ('problems', 'problem'), ('characterized', 'character'), ('clear', 'clear'), ('feedback', 'feedback'), ('signals', 'signal'), (',', ','), ('win/lose', 'win/los'), ('outcomes', 'outcom'), ('games', 'game'), (',', ','), ('entail', 'entail'), ('searches', 'search'), ('large', 'larg'), ('trees', 'tree'), ('possible', 'possibl'), ('action-observation', 'action-observ'), ('histories', 'histori'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('[', '['), ('18', '18'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('found', 'found'), ('extensive', 'extensive'), ('applications', 'application'), ('problems', 'problem'), ('characterized', 'characterized'), ('clear', 'clear'), ('feedback', 'feedback'), ('signals', 'signal'), (',', ','), ('win/lose', 'win/lose'), ('outcomes', 'outcome'), ('games', 'game'), (',', ','), ('entail', 'entail'), ('searches', 'search'), ('large', 'large'), ('trees', 'tree'), ('possible', 'possible'), ('action-observation', 'action-observation'), ('histories', 'history'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('[', '['), ('18', '18'), (']', ']'), ('.', '.')]



============================ Sentence 72 =============================

This paper only covers supervised and unsupervised learning. 


>> Tokens are: 
 ['This', 'paper', 'covers', 'supervised', 'unsupervised', 'learning', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'covers'), ('covers', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'paper', 'covers'), ('paper', 'covers', 'supervised'), ('covers', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('covers', 'VBZ'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP This/DT paper/NN)
  covers/VBZ
  supervised/VBD
  (NP unsupervised/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['This paper', 'unsupervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('covers', 'cover'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('covers', 'cover'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('covers', 'cover'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 73 =============================

Reinforcement learning requires a different analytical framework grounded in Markov Decision Pro- cesses and will not be discussed here (see [17]). 


>> Tokens are: 
 ['Reinforcement', 'learning', 'requires', 'different', 'analytical', 'framework', 'grounded', 'Markov', 'Decision', 'Pro-', 'cesses', 'discussed', '(', 'see', '[', '17', ']', ')', '.']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', 'requires'), ('requires', 'different'), ('different', 'analytical'), ('analytical', 'framework'), ('framework', 'grounded'), ('grounded', 'Markov'), ('Markov', 'Decision'), ('Decision', 'Pro-'), ('Pro-', 'cesses'), ('cesses', 'discussed'), ('discussed', '('), ('(', 'see'), ('see', '['), ('[', '17'), ('17', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('Reinforcement', 'learning', 'requires'), ('learning', 'requires', 'different'), ('requires', 'different', 'analytical'), ('different', 'analytical', 'framework'), ('analytical', 'framework', 'grounded'), ('framework', 'grounded', 'Markov'), ('grounded', 'Markov', 'Decision'), ('Markov', 'Decision', 'Pro-'), ('Decision', 'Pro-', 'cesses'), ('Pro-', 'cesses', 'discussed'), ('cesses', 'discussed', '('), ('discussed', '(', 'see'), ('(', 'see', '['), ('see', '[', '17'), ('[', '17', ']'), ('17', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('Reinforcement', 'NNP'), ('learning', 'VBG'), ('requires', 'VBZ'), ('different', 'JJ'), ('analytical', 'JJ'), ('framework', 'NN'), ('grounded', 'VBD'), ('Markov', 'NNP'), ('Decision', 'NNP'), ('Pro-', 'NNP'), ('cesses', 'NNS'), ('discussed', 'VBD'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('17', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Reinforcement/NNP)
  learning/VBG
  requires/VBZ
  (NP different/JJ analytical/JJ framework/NN)
  grounded/VBD
  (NP Markov/NNP Decision/NNP Pro-/NNP cesses/NNS)
  discussed/VBD
  (/(
  see/VB
  [/RB
  17/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Reinforcement', 'different analytical framework', 'Markov Decision Pro- cesses', ']']

>> Named Entities are: 
 [('PERSON', 'Markov Decision')] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('requires', 'requir'), ('different', 'differ'), ('analytical', 'analyt'), ('framework', 'framework'), ('grounded', 'ground'), ('Markov', 'markov'), ('Decision', 'decis'), ('Pro-', 'pro-'), ('cesses', 'cess'), ('discussed', 'discuss'), ('(', '('), ('see', 'see'), ('[', '['), ('17', '17'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('requires', 'requir'), ('different', 'differ'), ('analytical', 'analyt'), ('framework', 'framework'), ('grounded', 'ground'), ('Markov', 'markov'), ('Decision', 'decis'), ('Pro-', 'pro-'), ('cesses', 'cess'), ('discussed', 'discuss'), ('(', '('), ('see', 'see'), ('[', '['), ('17', '17'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('requires', 'requires'), ('different', 'different'), ('analytical', 'analytical'), ('framework', 'framework'), ('grounded', 'grounded'), ('Markov', 'Markov'), ('Decision', 'Decision'), ('Pro-', 'Pro-'), ('cesses', 'ce'), ('discussed', 'discussed'), ('(', '('), ('see', 'see'), ('[', '['), ('17', '17'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 74 =============================

For a broader discussion on the technical aspects of supervised and unsupervised learning, we point to [19] and refer- ences therein. 


>> Tokens are: 
 ['For', 'broader', 'discussion', 'technical', 'aspects', 'supervised', 'unsupervised', 'learning', ',', 'point', '[', '19', ']', 'refer-', 'ences', 'therein', '.']

>> Bigrams are: 
 [('For', 'broader'), ('broader', 'discussion'), ('discussion', 'technical'), ('technical', 'aspects'), ('aspects', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'point'), ('point', '['), ('[', '19'), ('19', ']'), (']', 'refer-'), ('refer-', 'ences'), ('ences', 'therein'), ('therein', '.')]

>> Trigrams are: 
 [('For', 'broader', 'discussion'), ('broader', 'discussion', 'technical'), ('discussion', 'technical', 'aspects'), ('technical', 'aspects', 'supervised'), ('aspects', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'point'), (',', 'point', '['), ('point', '[', '19'), ('[', '19', ']'), ('19', ']', 'refer-'), (']', 'refer-', 'ences'), ('refer-', 'ences', 'therein'), ('ences', 'therein', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('broader', 'JJR'), ('discussion', 'NN'), ('technical', 'JJ'), ('aspects', 'NNS'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('point', 'NN'), ('[', 'VBD'), ('19', 'CD'), (']', 'JJ'), ('refer-', 'JJ'), ('ences', 'NNS'), ('therein', 'RB'), ('.', '.')]

 (S
  For/IN
  broader/JJR
  (NP discussion/NN)
  (NP technical/JJ aspects/NNS)
  supervised/VBD
  (NP unsupervised/JJ learning/NN)
  ,/,
  (NP point/NN)
  [/VBD
  19/CD
  (NP ]/JJ refer-/JJ ences/NNS)
  therein/RB
  ./.) 


>> Noun Phrases are: 
 ['discussion', 'technical aspects', 'unsupervised learning', 'point', '] refer- ences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('broader', 'broader'), ('discussion', 'discuss'), ('technical', 'technic'), ('aspects', 'aspect'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('refer-', 'refer-'), ('ences', 'enc'), ('therein', 'therein'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('broader', 'broader'), ('discussion', 'discuss'), ('technical', 'technic'), ('aspects', 'aspect'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('refer-', 'refer-'), ('ences', 'enc'), ('therein', 'therein'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('broader', 'broader'), ('discussion', 'discussion'), ('technical', 'technical'), ('aspects', 'aspect'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('refer-', 'refer-'), ('ences', 'ences'), ('therein', 'therein'), ('.', '.')]



============================ Sentence 75 =============================

C. When to Use Machine Learning? 


>> Tokens are: 
 ['C.', 'When', 'Use', 'Machine', 'Learning', '?']

>> Bigrams are: 
 [('C.', 'When'), ('When', 'Use'), ('Use', 'Machine'), ('Machine', 'Learning'), ('Learning', '?')]

>> Trigrams are: 
 [('C.', 'When', 'Use'), ('When', 'Use', 'Machine'), ('Use', 'Machine', 'Learning'), ('Machine', 'Learning', '?')]

>> POS Tags are: 
 [('C.', 'NNP'), ('When', 'WRB'), ('Use', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('?', '.')]

 (S (NP C./NNP) When/WRB (NP Use/NNP Machine/NNP Learning/NNP) ?/.) 


>> Noun Phrases are: 
 ['C.', 'Use Machine Learning']

>> Named Entities are: 
 [('PERSON', 'Use Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('C.', 'c.'), ('When', 'when'), ('Use', 'use'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('C.', 'c.'), ('When', 'when'), ('Use', 'use'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('C.', 'C.'), ('When', 'When'), ('Use', 'Use'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('?', '?')]



============================ Sentence 76 =============================

Based on the discussion in Sec. 


>> Tokens are: 
 ['Based', 'discussion', 'Sec', '.']

>> Bigrams are: 
 [('Based', 'discussion'), ('discussion', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Based', 'discussion', 'Sec'), ('discussion', 'Sec', '.')]

>> POS Tags are: 
 [('Based', 'VBN'), ('discussion', 'NN'), ('Sec', 'NNP'), ('.', '.')]

 (S Based/VBN (NP discussion/NN Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['discussion Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Based', 'Based'), ('discussion', 'discussion'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 77 =============================

I-A, the use of a  machine learning approach in lieu of a more conventional engineering design should be justified on a case-by- case basis on the basis of its suitability and potential  advantages. 


>> Tokens are: 
 ['I-A', ',', 'use', 'machine', 'learning', 'approach', 'lieu', 'conventional', 'engineering', 'design', 'justified', 'case-by-', 'case', 'basis', 'basis', 'suitability', 'potential', 'advantages', '.']

>> Bigrams are: 
 [('I-A', ','), (',', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'approach'), ('approach', 'lieu'), ('lieu', 'conventional'), ('conventional', 'engineering'), ('engineering', 'design'), ('design', 'justified'), ('justified', 'case-by-'), ('case-by-', 'case'), ('case', 'basis'), ('basis', 'basis'), ('basis', 'suitability'), ('suitability', 'potential'), ('potential', 'advantages'), ('advantages', '.')]

>> Trigrams are: 
 [('I-A', ',', 'use'), (',', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'approach'), ('learning', 'approach', 'lieu'), ('approach', 'lieu', 'conventional'), ('lieu', 'conventional', 'engineering'), ('conventional', 'engineering', 'design'), ('engineering', 'design', 'justified'), ('design', 'justified', 'case-by-'), ('justified', 'case-by-', 'case'), ('case-by-', 'case', 'basis'), ('case', 'basis', 'basis'), ('basis', 'basis', 'suitability'), ('basis', 'suitability', 'potential'), ('suitability', 'potential', 'advantages'), ('potential', 'advantages', '.')]

>> POS Tags are: 
 [('I-A', 'NNP'), (',', ','), ('use', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('approach', 'NN'), ('lieu', 'JJ'), ('conventional', 'JJ'), ('engineering', 'NN'), ('design', 'NN'), ('justified', 'VBD'), ('case-by-', 'JJ'), ('case', 'NN'), ('basis', 'NN'), ('basis', 'NN'), ('suitability', 'NN'), ('potential', 'JJ'), ('advantages', 'NNS'), ('.', '.')]

 (S
  (NP I-A/NNP)
  ,/,
  (NP use/NN machine/NN)
  learning/VBG
  (NP approach/NN)
  (NP lieu/JJ conventional/JJ engineering/NN design/NN)
  justified/VBD
  (NP case-by-/JJ case/NN basis/NN basis/NN suitability/NN)
  (NP potential/JJ advantages/NNS)
  ./.) 


>> Noun Phrases are: 
 ['I-A', 'use machine', 'approach', 'lieu conventional engineering design', 'case-by- case basis basis suitability', 'potential advantages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I-A', 'i-a'), (',', ','), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('lieu', 'lieu'), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('justified', 'justifi'), ('case-by-', 'case-by-'), ('case', 'case'), ('basis', 'basi'), ('basis', 'basi'), ('suitability', 'suitabl'), ('potential', 'potenti'), ('advantages', 'advantag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I-A', 'i-a'), (',', ','), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('lieu', 'lieu'), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('justified', 'justifi'), ('case-by-', 'case-by-'), ('case', 'case'), ('basis', 'basi'), ('basis', 'basi'), ('suitability', 'suitabl'), ('potential', 'potenti'), ('advantages', 'advantag'), ('.', '.')]

>> Lemmatization: 
 [('I-A', 'I-A'), (',', ','), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('approach', 'approach'), ('lieu', 'lieu'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('design', 'design'), ('justified', 'justified'), ('case-by-', 'case-by-'), ('case', 'case'), ('basis', 'basis'), ('basis', 'basis'), ('suitability', 'suitability'), ('potential', 'potential'), ('advantages', 'advantage'), ('.', '.')]



============================ Sentence 78 =============================

The following criteria, inspired by [20], offer useful guidelines on the type of engineering tasks that can benefit from the use of machine learning tools. 


>> Tokens are: 
 ['The', 'following', 'criteria', ',', 'inspired', '[', '20', ']', ',', 'offer', 'useful', 'guidelines', 'type', 'engineering', 'tasks', 'benefit', 'use', 'machine', 'learning', 'tools', '.']

>> Bigrams are: 
 [('The', 'following'), ('following', 'criteria'), ('criteria', ','), (',', 'inspired'), ('inspired', '['), ('[', '20'), ('20', ']'), (']', ','), (',', 'offer'), ('offer', 'useful'), ('useful', 'guidelines'), ('guidelines', 'type'), ('type', 'engineering'), ('engineering', 'tasks'), ('tasks', 'benefit'), ('benefit', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('The', 'following', 'criteria'), ('following', 'criteria', ','), ('criteria', ',', 'inspired'), (',', 'inspired', '['), ('inspired', '[', '20'), ('[', '20', ']'), ('20', ']', ','), (']', ',', 'offer'), (',', 'offer', 'useful'), ('offer', 'useful', 'guidelines'), ('useful', 'guidelines', 'type'), ('guidelines', 'type', 'engineering'), ('type', 'engineering', 'tasks'), ('engineering', 'tasks', 'benefit'), ('tasks', 'benefit', 'use'), ('benefit', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('following', 'JJ'), ('criteria', 'NNS'), (',', ','), ('inspired', 'VBD'), ('[', 'JJ'), ('20', 'CD'), (']', 'NN'), (',', ','), ('offer', 'VBP'), ('useful', 'JJ'), ('guidelines', 'NNS'), ('type', 'IN'), ('engineering', 'NN'), ('tasks', 'NNS'), ('benefit', 'VBP'), ('use', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP The/DT following/JJ criteria/NNS)
  ,/,
  inspired/VBD
  [/JJ
  20/CD
  (NP ]/NN)
  ,/,
  offer/VBP
  (NP useful/JJ guidelines/NNS)
  type/IN
  (NP engineering/NN tasks/NNS)
  benefit/VBP
  (NP use/JJ machine/NN learning/NN tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The following criteria', ']', 'useful guidelines', 'engineering tasks', 'use machine learning tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('following', 'follow'), ('criteria', 'criteria'), (',', ','), ('inspired', 'inspir'), ('[', '['), ('20', '20'), (']', ']'), (',', ','), ('offer', 'offer'), ('useful', 'use'), ('guidelines', 'guidelin'), ('type', 'type'), ('engineering', 'engin'), ('tasks', 'task'), ('benefit', 'benefit'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('following', 'follow'), ('criteria', 'criteria'), (',', ','), ('inspired', 'inspir'), ('[', '['), ('20', '20'), (']', ']'), (',', ','), ('offer', 'offer'), ('useful', 'use'), ('guidelines', 'guidelin'), ('type', 'type'), ('engineering', 'engin'), ('tasks', 'task'), ('benefit', 'benefit'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('following', 'following'), ('criteria', 'criterion'), (',', ','), ('inspired', 'inspired'), ('[', '['), ('20', '20'), (']', ']'), (',', ','), ('offer', 'offer'), ('useful', 'useful'), ('guidelines', 'guideline'), ('type', 'type'), ('engineering', 'engineering'), ('tasks', 'task'), ('benefit', 'benefit'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 79 =============================

1. 


>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

 (S 1/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



============================ Sentence 80 =============================

The traditional engineering flow is not applicable or is undesirable due to a model deficit or to an algorithm deficit [21]. 


>> Tokens are: 
 ['The', 'traditional', 'engineering', 'flow', 'applicable', 'undesirable', 'due', 'model', 'deficit', 'algorithm', 'deficit', '[', '21', ']', '.']

>> Bigrams are: 
 [('The', 'traditional'), ('traditional', 'engineering'), ('engineering', 'flow'), ('flow', 'applicable'), ('applicable', 'undesirable'), ('undesirable', 'due'), ('due', 'model'), ('model', 'deficit'), ('deficit', 'algorithm'), ('algorithm', 'deficit'), ('deficit', '['), ('[', '21'), ('21', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'traditional', 'engineering'), ('traditional', 'engineering', 'flow'), ('engineering', 'flow', 'applicable'), ('flow', 'applicable', 'undesirable'), ('applicable', 'undesirable', 'due'), ('undesirable', 'due', 'model'), ('due', 'model', 'deficit'), ('model', 'deficit', 'algorithm'), ('deficit', 'algorithm', 'deficit'), ('algorithm', 'deficit', '['), ('deficit', '[', '21'), ('[', '21', ']'), ('21', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('traditional', 'JJ'), ('engineering', 'NN'), ('flow', 'NN'), ('applicable', 'JJ'), ('undesirable', 'JJ'), ('due', 'JJ'), ('model', 'NN'), ('deficit', 'NN'), ('algorithm', 'NN'), ('deficit', 'NN'), ('[', 'VBD'), ('21', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP The/DT traditional/JJ engineering/NN flow/NN)
  (NP
    applicable/JJ
    undesirable/JJ
    due/JJ
    model/NN
    deficit/NN
    algorithm/NN
    deficit/NN)
  [/VBD
  21/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['The traditional engineering flow', 'applicable undesirable due model deficit algorithm deficit', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('engineering', 'engin'), ('flow', 'flow'), ('applicable', 'applic'), ('undesirable', 'undesir'), ('due', 'due'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('engineering', 'engin'), ('flow', 'flow'), ('applicable', 'applic'), ('undesirable', 'undesir'), ('due', 'due'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('traditional', 'traditional'), ('engineering', 'engineering'), ('flow', 'flow'), ('applicable', 'applicable'), ('undesirable', 'undesirable'), ('due', 'due'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]



============================ Sentence 81 =============================

• With a model deficit, no physics-based mathematical models exist for the problem due to insufficient domain knowledge. 


>> Tokens are: 
 ['•', 'With', 'model', 'deficit', ',', 'physics-based', 'mathematical', 'models', 'exist', 'problem', 'due', 'insufficient', 'domain', 'knowledge', '.']

>> Bigrams are: 
 [('•', 'With'), ('With', 'model'), ('model', 'deficit'), ('deficit', ','), (',', 'physics-based'), ('physics-based', 'mathematical'), ('mathematical', 'models'), ('models', 'exist'), ('exist', 'problem'), ('problem', 'due'), ('due', 'insufficient'), ('insufficient', 'domain'), ('domain', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('•', 'With', 'model'), ('With', 'model', 'deficit'), ('model', 'deficit', ','), ('deficit', ',', 'physics-based'), (',', 'physics-based', 'mathematical'), ('physics-based', 'mathematical', 'models'), ('mathematical', 'models', 'exist'), ('models', 'exist', 'problem'), ('exist', 'problem', 'due'), ('problem', 'due', 'insufficient'), ('due', 'insufficient', 'domain'), ('insufficient', 'domain', 'knowledge'), ('domain', 'knowledge', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('With', 'IN'), ('model', 'NN'), ('deficit', 'NN'), (',', ','), ('physics-based', 'JJ'), ('mathematical', 'JJ'), ('models', 'NNS'), ('exist', 'VBP'), ('problem', 'NN'), ('due', 'JJ'), ('insufficient', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('.', '.')]

 (S
  (NP •/NN)
  With/IN
  (NP model/NN deficit/NN)
  ,/,
  (NP physics-based/JJ mathematical/JJ models/NNS)
  exist/VBP
  (NP problem/NN)
  (NP due/JJ insufficient/NN domain/NN knowledge/NN)
  ./.) 


>> Noun Phrases are: 
 ['•', 'model deficit', 'physics-based mathematical models', 'problem', 'due insufficient domain knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('With', 'with'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('models', 'model'), ('exist', 'exist'), ('problem', 'problem'), ('due', 'due'), ('insufficient', 'insuffici'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('With', 'with'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('models', 'model'), ('exist', 'exist'), ('problem', 'problem'), ('due', 'due'), ('insufficient', 'insuffici'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('With', 'With'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-based'), ('mathematical', 'mathematical'), ('models', 'model'), ('exist', 'exist'), ('problem', 'problem'), ('due', 'due'), ('insufficient', 'insufficient'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('.', '.')]



============================ Sentence 82 =============================

As a result, a conventional model-based design is inapplicable. 


>> Tokens are: 
 ['As', 'result', ',', 'conventional', 'model-based', 'design', 'inapplicable', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'conventional'), ('conventional', 'model-based'), ('model-based', 'design'), ('design', 'inapplicable'), ('inapplicable', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'conventional'), (',', 'conventional', 'model-based'), ('conventional', 'model-based', 'design'), ('model-based', 'design', 'inapplicable'), ('design', 'inapplicable', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('conventional', 'JJ'), ('model-based', 'JJ'), ('design', 'NN'), ('inapplicable', 'JJ'), ('.', '.')]

 (S
  As/IN
  (NP result/NN)
  ,/,
  (NP conventional/JJ model-based/JJ design/NN)
  inapplicable/JJ
  ./.) 


>> Noun Phrases are: 
 ['result', 'conventional model-based design']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('conventional', 'convent'), ('model-based', 'model-bas'), ('design', 'design'), ('inapplicable', 'inapplic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('conventional', 'convent'), ('model-based', 'model-bas'), ('design', 'design'), ('inapplicable', 'inapplic'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('conventional', 'conventional'), ('model-based', 'model-based'), ('design', 'design'), ('inapplicable', 'inapplicable'), ('.', '.')]



============================ Sentence 83 =============================

• With an algorithm deficit, a well-established math- ematical model is available, but existing algorithms optimized on the basis of such model are too com- plex to be implemented for the given application. 


>> Tokens are: 
 ['•', 'With', 'algorithm', 'deficit', ',', 'well-established', 'math-', 'ematical', 'model', 'available', ',', 'existing', 'algorithms', 'optimized', 'basis', 'model', 'com-', 'plex', 'implemented', 'given', 'application', '.']

>> Bigrams are: 
 [('•', 'With'), ('With', 'algorithm'), ('algorithm', 'deficit'), ('deficit', ','), (',', 'well-established'), ('well-established', 'math-'), ('math-', 'ematical'), ('ematical', 'model'), ('model', 'available'), ('available', ','), (',', 'existing'), ('existing', 'algorithms'), ('algorithms', 'optimized'), ('optimized', 'basis'), ('basis', 'model'), ('model', 'com-'), ('com-', 'plex'), ('plex', 'implemented'), ('implemented', 'given'), ('given', 'application'), ('application', '.')]

>> Trigrams are: 
 [('•', 'With', 'algorithm'), ('With', 'algorithm', 'deficit'), ('algorithm', 'deficit', ','), ('deficit', ',', 'well-established'), (',', 'well-established', 'math-'), ('well-established', 'math-', 'ematical'), ('math-', 'ematical', 'model'), ('ematical', 'model', 'available'), ('model', 'available', ','), ('available', ',', 'existing'), (',', 'existing', 'algorithms'), ('existing', 'algorithms', 'optimized'), ('algorithms', 'optimized', 'basis'), ('optimized', 'basis', 'model'), ('basis', 'model', 'com-'), ('model', 'com-', 'plex'), ('com-', 'plex', 'implemented'), ('plex', 'implemented', 'given'), ('implemented', 'given', 'application'), ('given', 'application', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('With', 'IN'), ('algorithm', 'JJ'), ('deficit', 'NN'), (',', ','), ('well-established', 'JJ'), ('math-', 'JJ'), ('ematical', 'JJ'), ('model', 'NN'), ('available', 'JJ'), (',', ','), ('existing', 'VBG'), ('algorithms', 'NNS'), ('optimized', 'VBN'), ('basis', 'NN'), ('model', 'NN'), ('com-', 'JJ'), ('plex', 'NN'), ('implemented', 'VBD'), ('given', 'VBN'), ('application', 'NN'), ('.', '.')]

 (S
  (NP •/NN)
  With/IN
  (NP algorithm/JJ deficit/NN)
  ,/,
  (NP well-established/JJ math-/JJ ematical/JJ model/NN)
  available/JJ
  ,/,
  existing/VBG
  (NP algorithms/NNS)
  optimized/VBN
  (NP basis/NN model/NN)
  (NP com-/JJ plex/NN)
  implemented/VBD
  given/VBN
  (NP application/NN)
  ./.) 


>> Noun Phrases are: 
 ['•', 'algorithm deficit', 'well-established math- ematical model', 'algorithms', 'basis model', 'com- plex', 'application']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('With', 'with'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('well-established', 'well-establish'), ('math-', 'math-'), ('ematical', 'emat'), ('model', 'model'), ('available', 'avail'), (',', ','), ('existing', 'exist'), ('algorithms', 'algorithm'), ('optimized', 'optim'), ('basis', 'basi'), ('model', 'model'), ('com-', 'com-'), ('plex', 'plex'), ('implemented', 'implement'), ('given', 'given'), ('application', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('With', 'with'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('well-established', 'well-establish'), ('math-', 'math-'), ('ematical', 'emat'), ('model', 'model'), ('available', 'avail'), (',', ','), ('existing', 'exist'), ('algorithms', 'algorithm'), ('optimized', 'optim'), ('basis', 'basi'), ('model', 'model'), ('com-', 'com-'), ('plex', 'plex'), ('implemented', 'implement'), ('given', 'given'), ('application', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('With', 'With'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('well-established', 'well-established'), ('math-', 'math-'), ('ematical', 'ematical'), ('model', 'model'), ('available', 'available'), (',', ','), ('existing', 'existing'), ('algorithms', 'algorithm'), ('optimized', 'optimized'), ('basis', 'basis'), ('model', 'model'), ('com-', 'com-'), ('plex', 'plex'), ('implemented', 'implemented'), ('given', 'given'), ('application', 'application'), ('.', '.')]



============================ Sentence 84 =============================

In this case, the use of hypothesis classes including efficient “machines”, such as neural network of lim- ited size or with tailored hardware implementations (see, e.g.-.-, [22], [23] and references therein), can yield lower-complexity solutions. 


>> Tokens are: 
 ['In', 'case', ',', 'use', 'hypothesis', 'classes', 'including', 'efficient', '“', 'machines', '”', ',', 'neural', 'network', 'lim-', 'ited', 'size', 'tailored', 'hardware', 'implementations', '(', 'see', ',', 'e.g.-.-', ',', '[', '22', ']', ',', '[', '23', ']', 'references', 'therein', ')', ',', 'yield', 'lower-complexity', 'solutions', '.']

>> Bigrams are: 
 [('In', 'case'), ('case', ','), (',', 'use'), ('use', 'hypothesis'), ('hypothesis', 'classes'), ('classes', 'including'), ('including', 'efficient'), ('efficient', '“'), ('“', 'machines'), ('machines', '”'), ('”', ','), (',', 'neural'), ('neural', 'network'), ('network', 'lim-'), ('lim-', 'ited'), ('ited', 'size'), ('size', 'tailored'), ('tailored', 'hardware'), ('hardware', 'implementations'), ('implementations', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '22'), ('22', ']'), (']', ','), (',', '['), ('[', '23'), ('23', ']'), (']', 'references'), ('references', 'therein'), ('therein', ')'), (')', ','), (',', 'yield'), ('yield', 'lower-complexity'), ('lower-complexity', 'solutions'), ('solutions', '.')]

>> Trigrams are: 
 [('In', 'case', ','), ('case', ',', 'use'), (',', 'use', 'hypothesis'), ('use', 'hypothesis', 'classes'), ('hypothesis', 'classes', 'including'), ('classes', 'including', 'efficient'), ('including', 'efficient', '“'), ('efficient', '“', 'machines'), ('“', 'machines', '”'), ('machines', '”', ','), ('”', ',', 'neural'), (',', 'neural', 'network'), ('neural', 'network', 'lim-'), ('network', 'lim-', 'ited'), ('lim-', 'ited', 'size'), ('ited', 'size', 'tailored'), ('size', 'tailored', 'hardware'), ('tailored', 'hardware', 'implementations'), ('hardware', 'implementations', '('), ('implementations', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '22'), ('[', '22', ']'), ('22', ']', ','), (']', ',', '['), (',', '[', '23'), ('[', '23', ']'), ('23', ']', 'references'), (']', 'references', 'therein'), ('references', 'therein', ')'), ('therein', ')', ','), (')', ',', 'yield'), (',', 'yield', 'lower-complexity'), ('yield', 'lower-complexity', 'solutions'), ('lower-complexity', 'solutions', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('case', 'NN'), (',', ','), ('use', 'VB'), ('hypothesis', 'NN'), ('classes', 'NNS'), ('including', 'VBG'), ('efficient', 'JJ'), ('“', 'JJ'), ('machines', 'NNS'), ('”', 'NNP'), (',', ','), ('neural', 'JJ'), ('network', 'NN'), ('lim-', 'JJ'), ('ited', 'JJ'), ('size', 'NN'), ('tailored', 'VBN'), ('hardware', 'NN'), ('implementations', 'NNS'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('22', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('23', 'CD'), (']', 'NN'), ('references', 'NNS'), ('therein', 'RB'), (')', ')'), (',', ','), ('yield', 'JJ'), ('lower-complexity', 'JJ'), ('solutions', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP case/NN)
  ,/,
  use/VB
  (NP hypothesis/NN classes/NNS)
  including/VBG
  (NP efficient/JJ “/JJ machines/NNS ”/NNP)
  ,/,
  (NP neural/JJ network/NN)
  (NP lim-/JJ ited/JJ size/NN)
  tailored/VBN
  (NP hardware/NN implementations/NNS)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  22/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  23/CD
  (NP ]/NN references/NNS)
  therein/RB
  )/)
  ,/,
  (NP yield/JJ lower-complexity/JJ solutions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['case', 'hypothesis classes', 'efficient “ machines ”', 'neural network', 'lim- ited size', 'hardware implementations', ']', '] references', 'yield lower-complexity solutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('case', 'case'), (',', ','), ('use', 'use'), ('hypothesis', 'hypothesi'), ('classes', 'class'), ('including', 'includ'), ('efficient', 'effici'), ('“', '“'), ('machines', 'machin'), ('”', '”'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('lim-', 'lim-'), ('ited', 'ite'), ('size', 'size'), ('tailored', 'tailor'), ('hardware', 'hardwar'), ('implementations', 'implement'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('[', '['), ('23', '23'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), (')', ')'), (',', ','), ('yield', 'yield'), ('lower-complexity', 'lower-complex'), ('solutions', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('case', 'case'), (',', ','), ('use', 'use'), ('hypothesis', 'hypothesi'), ('classes', 'class'), ('including', 'includ'), ('efficient', 'effici'), ('“', '“'), ('machines', 'machin'), ('”', '”'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('lim-', 'lim-'), ('ited', 'ite'), ('size', 'size'), ('tailored', 'tailor'), ('hardware', 'hardwar'), ('implementations', 'implement'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('[', '['), ('23', '23'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), (')', ')'), (',', ','), ('yield', 'yield'), ('lower-complexity', 'lower-complex'), ('solutions', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('case', 'case'), (',', ','), ('use', 'use'), ('hypothesis', 'hypothesis'), ('classes', 'class'), ('including', 'including'), ('efficient', 'efficient'), ('“', '“'), ('machines', 'machine'), ('”', '”'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('lim-', 'lim-'), ('ited', 'ited'), ('size', 'size'), ('tailored', 'tailored'), ('hardware', 'hardware'), ('implementations', 'implementation'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('[', '['), ('23', '23'), (']', ']'), ('references', 'reference'), ('therein', 'therein'), (')', ')'), (',', ','), ('yield', 'yield'), ('lower-complexity', 'lower-complexity'), ('solutions', 'solution'), ('.', '.')]



============================ Sentence 85 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 86 =============================

A sufficiently large training data sets exist or can be created. 


>> Tokens are: 
 ['A', 'sufficiently', 'large', 'training', 'data', 'sets', 'exist', 'created', '.']

>> Bigrams are: 
 [('A', 'sufficiently'), ('sufficiently', 'large'), ('large', 'training'), ('training', 'data'), ('data', 'sets'), ('sets', 'exist'), ('exist', 'created'), ('created', '.')]

>> Trigrams are: 
 [('A', 'sufficiently', 'large'), ('sufficiently', 'large', 'training'), ('large', 'training', 'data'), ('training', 'data', 'sets'), ('data', 'sets', 'exist'), ('sets', 'exist', 'created'), ('exist', 'created', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('sufficiently', 'RB'), ('large', 'JJ'), ('training', 'VBG'), ('data', 'NNS'), ('sets', 'NNS'), ('exist', 'VBP'), ('created', 'VBN'), ('.', '.')]

 (S
  A/DT
  sufficiently/RB
  large/JJ
  training/VBG
  (NP data/NNS sets/NNS)
  exist/VBP
  created/VBN
  ./.) 


>> Noun Phrases are: 
 ['data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('sufficiently', 'suffici'), ('large', 'larg'), ('training', 'train'), ('data', 'data'), ('sets', 'set'), ('exist', 'exist'), ('created', 'creat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('sufficiently', 'suffici'), ('large', 'larg'), ('training', 'train'), ('data', 'data'), ('sets', 'set'), ('exist', 'exist'), ('created', 'creat'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('sufficiently', 'sufficiently'), ('large', 'large'), ('training', 'training'), ('data', 'data'), ('sets', 'set'), ('exist', 'exist'), ('created', 'created'), ('.', '.')]



============================ Sentence 87 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 88 =============================

The task does not require the application of logic, common sense, or explicit reasoning based on back- ground knowledge. 


>> Tokens are: 
 ['The', 'task', 'require', 'application', 'logic', ',', 'common', 'sense', ',', 'explicit', 'reasoning', 'based', 'back-', 'ground', 'knowledge', '.']

>> Bigrams are: 
 [('The', 'task'), ('task', 'require'), ('require', 'application'), ('application', 'logic'), ('logic', ','), (',', 'common'), ('common', 'sense'), ('sense', ','), (',', 'explicit'), ('explicit', 'reasoning'), ('reasoning', 'based'), ('based', 'back-'), ('back-', 'ground'), ('ground', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('The', 'task', 'require'), ('task', 'require', 'application'), ('require', 'application', 'logic'), ('application', 'logic', ','), ('logic', ',', 'common'), (',', 'common', 'sense'), ('common', 'sense', ','), ('sense', ',', 'explicit'), (',', 'explicit', 'reasoning'), ('explicit', 'reasoning', 'based'), ('reasoning', 'based', 'back-'), ('based', 'back-', 'ground'), ('back-', 'ground', 'knowledge'), ('ground', 'knowledge', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('task', 'NN'), ('require', 'NN'), ('application', 'NN'), ('logic', 'NN'), (',', ','), ('common', 'JJ'), ('sense', 'NN'), (',', ','), ('explicit', 'VBP'), ('reasoning', 'VBG'), ('based', 'VBN'), ('back-', 'JJ'), ('ground', 'NN'), ('knowledge', 'NN'), ('.', '.')]

 (S
  (NP The/DT task/NN require/NN application/NN logic/NN)
  ,/,
  (NP common/JJ sense/NN)
  ,/,
  explicit/VBP
  reasoning/VBG
  based/VBN
  (NP back-/JJ ground/NN knowledge/NN)
  ./.) 


>> Noun Phrases are: 
 ['The task require application logic', 'common sense', 'back- ground knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('task', 'task'), ('require', 'requir'), ('application', 'applic'), ('logic', 'logic'), (',', ','), ('common', 'common'), ('sense', 'sens'), (',', ','), ('explicit', 'explicit'), ('reasoning', 'reason'), ('based', 'base'), ('back-', 'back-'), ('ground', 'ground'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('task', 'task'), ('require', 'requir'), ('application', 'applic'), ('logic', 'logic'), (',', ','), ('common', 'common'), ('sense', 'sens'), (',', ','), ('explicit', 'explicit'), ('reasoning', 'reason'), ('based', 'base'), ('back-', 'back-'), ('ground', 'ground'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('task', 'task'), ('require', 'require'), ('application', 'application'), ('logic', 'logic'), (',', ','), ('common', 'common'), ('sense', 'sense'), (',', ','), ('explicit', 'explicit'), ('reasoning', 'reasoning'), ('based', 'based'), ('back-', 'back-'), ('ground', 'ground'), ('knowledge', 'knowledge'), ('.', '.')]



============================ Sentence 89 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 90 =============================

The task does not require detailed explanations for how the decision was made. 


>> Tokens are: 
 ['The', 'task', 'require', 'detailed', 'explanations', 'decision', 'made', '.']

>> Bigrams are: 
 [('The', 'task'), ('task', 'require'), ('require', 'detailed'), ('detailed', 'explanations'), ('explanations', 'decision'), ('decision', 'made'), ('made', '.')]

>> Trigrams are: 
 [('The', 'task', 'require'), ('task', 'require', 'detailed'), ('require', 'detailed', 'explanations'), ('detailed', 'explanations', 'decision'), ('explanations', 'decision', 'made'), ('decision', 'made', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('task', 'NN'), ('require', 'NN'), ('detailed', 'JJ'), ('explanations', 'NNS'), ('decision', 'NN'), ('made', 'VBD'), ('.', '.')]

 (S
  (NP The/DT task/NN require/NN)
  (NP detailed/JJ explanations/NNS decision/NN)
  made/VBD
  ./.) 


>> Noun Phrases are: 
 ['The task require', 'detailed explanations decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('task', 'task'), ('require', 'requir'), ('detailed', 'detail'), ('explanations', 'explan'), ('decision', 'decis'), ('made', 'made'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('task', 'task'), ('require', 'requir'), ('detailed', 'detail'), ('explanations', 'explan'), ('decision', 'decis'), ('made', 'made'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('task', 'task'), ('require', 'require'), ('detailed', 'detailed'), ('explanations', 'explanation'), ('decision', 'decision'), ('made', 'made'), ('.', '.')]



============================ Sentence 91 =============================

The trained machine is by and large a black box that maps inputs to outputs. 


>> Tokens are: 
 ['The', 'trained', 'machine', 'large', 'black', 'box', 'maps', 'inputs', 'outputs', '.']

>> Bigrams are: 
 [('The', 'trained'), ('trained', 'machine'), ('machine', 'large'), ('large', 'black'), ('black', 'box'), ('box', 'maps'), ('maps', 'inputs'), ('inputs', 'outputs'), ('outputs', '.')]

>> Trigrams are: 
 [('The', 'trained', 'machine'), ('trained', 'machine', 'large'), ('machine', 'large', 'black'), ('large', 'black', 'box'), ('black', 'box', 'maps'), ('box', 'maps', 'inputs'), ('maps', 'inputs', 'outputs'), ('inputs', 'outputs', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('trained', 'JJ'), ('machine', 'NN'), ('large', 'JJ'), ('black', 'JJ'), ('box', 'NN'), ('maps', 'NNS'), ('inputs', 'VBZ'), ('outputs', 'NNS'), ('.', '.')]

 (S
  (NP The/DT trained/JJ machine/NN)
  (NP large/JJ black/JJ box/NN maps/NNS)
  inputs/VBZ
  (NP outputs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The trained machine', 'large black box maps', 'outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('trained', 'train'), ('machine', 'machin'), ('large', 'larg'), ('black', 'black'), ('box', 'box'), ('maps', 'map'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('trained', 'train'), ('machine', 'machin'), ('large', 'larg'), ('black', 'black'), ('box', 'box'), ('maps', 'map'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('trained', 'trained'), ('machine', 'machine'), ('large', 'large'), ('black', 'black'), ('box', 'box'), ('maps', 'map'), ('inputs', 'input'), ('outputs', 'output'), ('.', '.')]



============================ Sentence 92 =============================

As such, it does not provide direct means to ascertain why a given output has been produced in response to an input, although recent research has made some progress on this front [24]. 


>> Tokens are: 
 ['As', ',', 'provide', 'direct', 'means', 'ascertain', 'given', 'output', 'produced', 'response', 'input', ',', 'although', 'recent', 'research', 'made', 'progress', 'front', '[', '24', ']', '.']

>> Bigrams are: 
 [('As', ','), (',', 'provide'), ('provide', 'direct'), ('direct', 'means'), ('means', 'ascertain'), ('ascertain', 'given'), ('given', 'output'), ('output', 'produced'), ('produced', 'response'), ('response', 'input'), ('input', ','), (',', 'although'), ('although', 'recent'), ('recent', 'research'), ('research', 'made'), ('made', 'progress'), ('progress', 'front'), ('front', '['), ('[', '24'), ('24', ']'), (']', '.')]

>> Trigrams are: 
 [('As', ',', 'provide'), (',', 'provide', 'direct'), ('provide', 'direct', 'means'), ('direct', 'means', 'ascertain'), ('means', 'ascertain', 'given'), ('ascertain', 'given', 'output'), ('given', 'output', 'produced'), ('output', 'produced', 'response'), ('produced', 'response', 'input'), ('response', 'input', ','), ('input', ',', 'although'), (',', 'although', 'recent'), ('although', 'recent', 'research'), ('recent', 'research', 'made'), ('research', 'made', 'progress'), ('made', 'progress', 'front'), ('progress', 'front', '['), ('front', '[', '24'), ('[', '24', ']'), ('24', ']', '.')]

>> POS Tags are: 
 [('As', 'IN'), (',', ','), ('provide', 'IN'), ('direct', 'JJ'), ('means', 'VBZ'), ('ascertain', 'NN'), ('given', 'VBN'), ('output', 'NN'), ('produced', 'VBN'), ('response', 'NN'), ('input', 'NN'), (',', ','), ('although', 'IN'), ('recent', 'JJ'), ('research', 'NN'), ('made', 'VBD'), ('progress', 'NN'), ('front', 'NN'), ('[', 'VBD'), ('24', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  As/IN
  ,/,
  provide/IN
  direct/JJ
  means/VBZ
  (NP ascertain/NN)
  given/VBN
  (NP output/NN)
  produced/VBN
  (NP response/NN input/NN)
  ,/,
  although/IN
  (NP recent/JJ research/NN)
  made/VBD
  (NP progress/NN front/NN)
  [/VBD
  24/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['ascertain', 'output', 'response input', 'recent research', 'progress front', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), (',', ','), ('provide', 'provid'), ('direct', 'direct'), ('means', 'mean'), ('ascertain', 'ascertain'), ('given', 'given'), ('output', 'output'), ('produced', 'produc'), ('response', 'respons'), ('input', 'input'), (',', ','), ('although', 'although'), ('recent', 'recent'), ('research', 'research'), ('made', 'made'), ('progress', 'progress'), ('front', 'front'), ('[', '['), ('24', '24'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), (',', ','), ('provide', 'provid'), ('direct', 'direct'), ('means', 'mean'), ('ascertain', 'ascertain'), ('given', 'given'), ('output', 'output'), ('produced', 'produc'), ('response', 'respons'), ('input', 'input'), (',', ','), ('although', 'although'), ('recent', 'recent'), ('research', 'research'), ('made', 'made'), ('progress', 'progress'), ('front', 'front'), ('[', '['), ('24', '24'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), (',', ','), ('provide', 'provide'), ('direct', 'direct'), ('means', 'mean'), ('ascertain', 'ascertain'), ('given', 'given'), ('output', 'output'), ('produced', 'produced'), ('response', 'response'), ('input', 'input'), (',', ','), ('although', 'although'), ('recent', 'recent'), ('research', 'research'), ('made', 'made'), ('progress', 'progress'), ('front', 'front'), ('[', '['), ('24', '24'), (']', ']'), ('.', '.')]



============================ Sentence 93 =============================

This contrasts with engineered optimal solutions, which can be typically interpreted on the basis of physical performance criteria. 


>> Tokens are: 
 ['This', 'contrasts', 'engineered', 'optimal', 'solutions', ',', 'typically', 'interpreted', 'basis', 'physical', 'performance', 'criteria', '.']

>> Bigrams are: 
 [('This', 'contrasts'), ('contrasts', 'engineered'), ('engineered', 'optimal'), ('optimal', 'solutions'), ('solutions', ','), (',', 'typically'), ('typically', 'interpreted'), ('interpreted', 'basis'), ('basis', 'physical'), ('physical', 'performance'), ('performance', 'criteria'), ('criteria', '.')]

>> Trigrams are: 
 [('This', 'contrasts', 'engineered'), ('contrasts', 'engineered', 'optimal'), ('engineered', 'optimal', 'solutions'), ('optimal', 'solutions', ','), ('solutions', ',', 'typically'), (',', 'typically', 'interpreted'), ('typically', 'interpreted', 'basis'), ('interpreted', 'basis', 'physical'), ('basis', 'physical', 'performance'), ('physical', 'performance', 'criteria'), ('performance', 'criteria', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('contrasts', 'VBZ'), ('engineered', 'VBD'), ('optimal', 'JJ'), ('solutions', 'NNS'), (',', ','), ('typically', 'RB'), ('interpreted', 'JJ'), ('basis', 'NN'), ('physical', 'JJ'), ('performance', 'NN'), ('criteria', 'NNS'), ('.', '.')]

 (S
  This/DT
  contrasts/VBZ
  engineered/VBD
  (NP optimal/JJ solutions/NNS)
  ,/,
  typically/RB
  (NP interpreted/JJ basis/NN)
  (NP physical/JJ performance/NN criteria/NNS)
  ./.) 


>> Noun Phrases are: 
 ['optimal solutions', 'interpreted basis', 'physical performance criteria']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('contrasts', 'contrast'), ('engineered', 'engin'), ('optimal', 'optim'), ('solutions', 'solut'), (',', ','), ('typically', 'typic'), ('interpreted', 'interpret'), ('basis', 'basi'), ('physical', 'physic'), ('performance', 'perform'), ('criteria', 'criteria'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('contrasts', 'contrast'), ('engineered', 'engin'), ('optimal', 'optim'), ('solutions', 'solut'), (',', ','), ('typically', 'typic'), ('interpreted', 'interpret'), ('basis', 'basi'), ('physical', 'physic'), ('performance', 'perform'), ('criteria', 'criteria'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('contrasts', 'contrast'), ('engineered', 'engineered'), ('optimal', 'optimal'), ('solutions', 'solution'), (',', ','), ('typically', 'typically'), ('interpreted', 'interpreted'), ('basis', 'basis'), ('physical', 'physical'), ('performance', 'performance'), ('criteria', 'criterion'), ('.', '.')]



============================ Sentence 94 =============================

For instance, a maximum likelihood decoder chooses a given output because it minimizes the probability of error under the assumed model. 


>> Tokens are: 
 ['For', 'instance', ',', 'maximum', 'likelihood', 'decoder', 'chooses', 'given', 'output', 'minimizes', 'probability', 'error', 'assumed', 'model', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'maximum'), ('maximum', 'likelihood'), ('likelihood', 'decoder'), ('decoder', 'chooses'), ('chooses', 'given'), ('given', 'output'), ('output', 'minimizes'), ('minimizes', 'probability'), ('probability', 'error'), ('error', 'assumed'), ('assumed', 'model'), ('model', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'maximum'), (',', 'maximum', 'likelihood'), ('maximum', 'likelihood', 'decoder'), ('likelihood', 'decoder', 'chooses'), ('decoder', 'chooses', 'given'), ('chooses', 'given', 'output'), ('given', 'output', 'minimizes'), ('output', 'minimizes', 'probability'), ('minimizes', 'probability', 'error'), ('probability', 'error', 'assumed'), ('error', 'assumed', 'model'), ('assumed', 'model', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('maximum', 'JJ'), ('likelihood', 'NN'), ('decoder', 'NN'), ('chooses', 'VBZ'), ('given', 'VBN'), ('output', 'NN'), ('minimizes', 'NNS'), ('probability', 'NN'), ('error', 'NN'), ('assumed', 'VBD'), ('model', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN)
  ,/,
  (NP maximum/JJ likelihood/NN decoder/NN)
  chooses/VBZ
  given/VBN
  (NP output/NN minimizes/NNS probability/NN error/NN)
  assumed/VBD
  (NP model/NN)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'maximum likelihood decoder', 'output minimizes probability error', 'model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decod'), ('chooses', 'choos'), ('given', 'given'), ('output', 'output'), ('minimizes', 'minim'), ('probability', 'probabl'), ('error', 'error'), ('assumed', 'assum'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decod'), ('chooses', 'choos'), ('given', 'given'), ('output', 'output'), ('minimizes', 'minim'), ('probability', 'probabl'), ('error', 'error'), ('assumed', 'assum'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decoder'), ('chooses', 'chooses'), ('given', 'given'), ('output', 'output'), ('minimizes', 'minimizes'), ('probability', 'probability'), ('error', 'error'), ('assumed', 'assumed'), ('model', 'model'), ('.', '.')]



============================ Sentence 95 =============================

5. 


>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

 (S 5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



============================ Sentence 96 =============================

The phenomenon or function being learned is station- ary for a sufficiently long period of time. 


>> Tokens are: 
 ['The', 'phenomenon', 'function', 'learned', 'station-', 'ary', 'sufficiently', 'long', 'period', 'time', '.']

>> Bigrams are: 
 [('The', 'phenomenon'), ('phenomenon', 'function'), ('function', 'learned'), ('learned', 'station-'), ('station-', 'ary'), ('ary', 'sufficiently'), ('sufficiently', 'long'), ('long', 'period'), ('period', 'time'), ('time', '.')]

>> Trigrams are: 
 [('The', 'phenomenon', 'function'), ('phenomenon', 'function', 'learned'), ('function', 'learned', 'station-'), ('learned', 'station-', 'ary'), ('station-', 'ary', 'sufficiently'), ('ary', 'sufficiently', 'long'), ('sufficiently', 'long', 'period'), ('long', 'period', 'time'), ('period', 'time', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('phenomenon', 'NN'), ('function', 'NN'), ('learned', 'VBD'), ('station-', 'JJ'), ('ary', 'JJ'), ('sufficiently', 'RB'), ('long', 'RB'), ('period', 'NN'), ('time', 'NN'), ('.', '.')]

 (S
  (NP The/DT phenomenon/NN function/NN)
  learned/VBD
  station-/JJ
  ary/JJ
  sufficiently/RB
  long/RB
  (NP period/NN time/NN)
  ./.) 


>> Noun Phrases are: 
 ['The phenomenon function', 'period time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learn'), ('station-', 'station-'), ('ary', 'ari'), ('sufficiently', 'suffici'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learn'), ('station-', 'station-'), ('ary', 'ari'), ('sufficiently', 'suffici'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learned'), ('station-', 'station-'), ('ary', 'ary'), ('sufficiently', 'sufficiently'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('.', '.')]



============================ Sentence 97 =============================

This is in order to enable data collection and learning. 


>> Tokens are: 
 ['This', 'order', 'enable', 'data', 'collection', 'learning', '.']

>> Bigrams are: 
 [('This', 'order'), ('order', 'enable'), ('enable', 'data'), ('data', 'collection'), ('collection', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'order', 'enable'), ('order', 'enable', 'data'), ('enable', 'data', 'collection'), ('data', 'collection', 'learning'), ('collection', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('order', 'NN'), ('enable', 'JJ'), ('data', 'NNS'), ('collection', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP This/DT order/NN)
  (NP enable/JJ data/NNS collection/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['This order', 'enable data collection learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('order', 'order'), ('enable', 'enabl'), ('data', 'data'), ('collection', 'collect'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('order', 'order'), ('enable', 'enabl'), ('data', 'data'), ('collection', 'collect'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('order', 'order'), ('enable', 'enable'), ('data', 'data'), ('collection', 'collection'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 98 =============================

6. 


>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

 (S 6/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]



============================ Sentence 99 =============================

The task has either loose requirement constraints, or, in the case of an algorithm deficit, the required performance guarantees can be provided via numeri- cal simulations. 


>> Tokens are: 
 ['The', 'task', 'either', 'loose', 'requirement', 'constraints', ',', ',', 'case', 'algorithm', 'deficit', ',', 'required', 'performance', 'guarantees', 'provided', 'via', 'numeri-', 'cal', 'simulations', '.']

>> Bigrams are: 
 [('The', 'task'), ('task', 'either'), ('either', 'loose'), ('loose', 'requirement'), ('requirement', 'constraints'), ('constraints', ','), (',', ','), (',', 'case'), ('case', 'algorithm'), ('algorithm', 'deficit'), ('deficit', ','), (',', 'required'), ('required', 'performance'), ('performance', 'guarantees'), ('guarantees', 'provided'), ('provided', 'via'), ('via', 'numeri-'), ('numeri-', 'cal'), ('cal', 'simulations'), ('simulations', '.')]

>> Trigrams are: 
 [('The', 'task', 'either'), ('task', 'either', 'loose'), ('either', 'loose', 'requirement'), ('loose', 'requirement', 'constraints'), ('requirement', 'constraints', ','), ('constraints', ',', ','), (',', ',', 'case'), (',', 'case', 'algorithm'), ('case', 'algorithm', 'deficit'), ('algorithm', 'deficit', ','), ('deficit', ',', 'required'), (',', 'required', 'performance'), ('required', 'performance', 'guarantees'), ('performance', 'guarantees', 'provided'), ('guarantees', 'provided', 'via'), ('provided', 'via', 'numeri-'), ('via', 'numeri-', 'cal'), ('numeri-', 'cal', 'simulations'), ('cal', 'simulations', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('task', 'NN'), ('either', 'CC'), ('loose', 'JJ'), ('requirement', 'NN'), ('constraints', 'NNS'), (',', ','), (',', ','), ('case', 'NN'), ('algorithm', 'NN'), ('deficit', 'NN'), (',', ','), ('required', 'VBN'), ('performance', 'NN'), ('guarantees', 'NNS'), ('provided', 'VBD'), ('via', 'IN'), ('numeri-', 'JJ'), ('cal', 'JJ'), ('simulations', 'NNS'), ('.', '.')]

 (S
  (NP The/DT task/NN)
  either/CC
  (NP loose/JJ requirement/NN constraints/NNS)
  ,/,
  ,/,
  (NP case/NN algorithm/NN deficit/NN)
  ,/,
  required/VBN
  (NP performance/NN guarantees/NNS)
  provided/VBD
  via/IN
  (NP numeri-/JJ cal/JJ simulations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The task', 'loose requirement constraints', 'case algorithm deficit', 'performance guarantees', 'numeri- cal simulations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('task', 'task'), ('either', 'either'), ('loose', 'loos'), ('requirement', 'requir'), ('constraints', 'constraint'), (',', ','), (',', ','), ('case', 'case'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('guarantees', 'guarante'), ('provided', 'provid'), ('via', 'via'), ('numeri-', 'numeri-'), ('cal', 'cal'), ('simulations', 'simul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('task', 'task'), ('either', 'either'), ('loose', 'loos'), ('requirement', 'requir'), ('constraints', 'constraint'), (',', ','), (',', ','), ('case', 'case'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('guarantees', 'guarante'), ('provided', 'provid'), ('via', 'via'), ('numeri-', 'numeri-'), ('cal', 'cal'), ('simulations', 'simul'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('task', 'task'), ('either', 'either'), ('loose', 'loose'), ('requirement', 'requirement'), ('constraints', 'constraint'), (',', ','), (',', ','), ('case', 'case'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('required', 'required'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('provided', 'provided'), ('via', 'via'), ('numeri-', 'numeri-'), ('cal', 'cal'), ('simulations', 'simulation'), ('.', '.')]



============================ Sentence 100 =============================

With the conventional engineering ap- proach, theoretical performance guarantees can be ob- tained that are backed by a physics-based mathematical model. 


>> Tokens are: 
 ['With', 'conventional', 'engineering', 'ap-', 'proach', ',', 'theoretical', 'performance', 'guarantees', 'ob-', 'tained', 'backed', 'physics-based', 'mathematical', 'model', '.']

>> Bigrams are: 
 [('With', 'conventional'), ('conventional', 'engineering'), ('engineering', 'ap-'), ('ap-', 'proach'), ('proach', ','), (',', 'theoretical'), ('theoretical', 'performance'), ('performance', 'guarantees'), ('guarantees', 'ob-'), ('ob-', 'tained'), ('tained', 'backed'), ('backed', 'physics-based'), ('physics-based', 'mathematical'), ('mathematical', 'model'), ('model', '.')]

>> Trigrams are: 
 [('With', 'conventional', 'engineering'), ('conventional', 'engineering', 'ap-'), ('engineering', 'ap-', 'proach'), ('ap-', 'proach', ','), ('proach', ',', 'theoretical'), (',', 'theoretical', 'performance'), ('theoretical', 'performance', 'guarantees'), ('performance', 'guarantees', 'ob-'), ('guarantees', 'ob-', 'tained'), ('ob-', 'tained', 'backed'), ('tained', 'backed', 'physics-based'), ('backed', 'physics-based', 'mathematical'), ('physics-based', 'mathematical', 'model'), ('mathematical', 'model', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('conventional', 'JJ'), ('engineering', 'NN'), ('ap-', 'JJ'), ('proach', 'NN'), (',', ','), ('theoretical', 'JJ'), ('performance', 'NN'), ('guarantees', 'NNS'), ('ob-', 'RB'), ('tained', 'VBD'), ('backed', 'JJ'), ('physics-based', 'JJ'), ('mathematical', 'JJ'), ('model', 'NN'), ('.', '.')]

 (S
  With/IN
  (NP conventional/JJ engineering/NN)
  (NP ap-/JJ proach/NN)
  ,/,
  (NP theoretical/JJ performance/NN guarantees/NNS)
  ob-/RB
  tained/VBD
  (NP backed/JJ physics-based/JJ mathematical/JJ model/NN)
  ./.) 


>> Noun Phrases are: 
 ['conventional engineering', 'ap- proach', 'theoretical performance guarantees', 'backed physics-based mathematical model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('conventional', 'convent'), ('engineering', 'engin'), ('ap-', 'ap-'), ('proach', 'proach'), (',', ','), ('theoretical', 'theoret'), ('performance', 'perform'), ('guarantees', 'guarante'), ('ob-', 'ob-'), ('tained', 'tain'), ('backed', 'back'), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('conventional', 'convent'), ('engineering', 'engin'), ('ap-', 'ap-'), ('proach', 'proach'), (',', ','), ('theoretical', 'theoret'), ('performance', 'perform'), ('guarantees', 'guarante'), ('ob-', 'ob-'), ('tained', 'tain'), ('backed', 'back'), ('physics-based', 'physics-bas'), ('mathematical', 'mathemat'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('ap-', 'ap-'), ('proach', 'proach'), (',', ','), ('theoretical', 'theoretical'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('ob-', 'ob-'), ('tained', 'tained'), ('backed', 'backed'), ('physics-based', 'physics-based'), ('mathematical', 'mathematical'), ('model', 'model'), ('.', '.')]



============================ Sentence 101 =============================

These guarantees can be relied upon insofar as the model is trusted to be an accurate representation of reality. 


>> Tokens are: 
 ['These', 'guarantees', 'relied', 'upon', 'insofar', 'model', 'trusted', 'accurate', 'representation', 'reality', '.']

>> Bigrams are: 
 [('These', 'guarantees'), ('guarantees', 'relied'), ('relied', 'upon'), ('upon', 'insofar'), ('insofar', 'model'), ('model', 'trusted'), ('trusted', 'accurate'), ('accurate', 'representation'), ('representation', 'reality'), ('reality', '.')]

>> Trigrams are: 
 [('These', 'guarantees', 'relied'), ('guarantees', 'relied', 'upon'), ('relied', 'upon', 'insofar'), ('upon', 'insofar', 'model'), ('insofar', 'model', 'trusted'), ('model', 'trusted', 'accurate'), ('trusted', 'accurate', 'representation'), ('accurate', 'representation', 'reality'), ('representation', 'reality', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('guarantees', 'NNS'), ('relied', 'VBD'), ('upon', 'IN'), ('insofar', 'JJ'), ('model', 'NN'), ('trusted', 'VBD'), ('accurate', 'JJ'), ('representation', 'NN'), ('reality', 'NN'), ('.', '.')]

 (S
  (NP These/DT guarantees/NNS)
  relied/VBD
  upon/IN
  (NP insofar/JJ model/NN)
  trusted/VBD
  (NP accurate/JJ representation/NN reality/NN)
  ./.) 


>> Noun Phrases are: 
 ['These guarantees', 'insofar model', 'accurate representation reality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('guarantees', 'guarante'), ('relied', 'reli'), ('upon', 'upon'), ('insofar', 'insofar'), ('model', 'model'), ('trusted', 'trust'), ('accurate', 'accur'), ('representation', 'represent'), ('reality', 'realiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('guarantees', 'guarante'), ('relied', 'reli'), ('upon', 'upon'), ('insofar', 'insofar'), ('model', 'model'), ('trusted', 'trust'), ('accurate', 'accur'), ('representation', 'represent'), ('reality', 'realiti'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('guarantees', 'guarantee'), ('relied', 'relied'), ('upon', 'upon'), ('insofar', 'insofar'), ('model', 'model'), ('trusted', 'trusted'), ('accurate', 'accurate'), ('representation', 'representation'), ('reality', 'reality'), ('.', '.')]



============================ Sentence 102 =============================

If a machine learning approach is used to address an algorithm deficit and a physics-based model is available, then numerical results may be sufficient in order to compute satisfactory performance measures. 


>> Tokens are: 
 ['If', 'machine', 'learning', 'approach', 'used', 'address', 'algorithm', 'deficit', 'physics-based', 'model', 'available', ',', 'numerical', 'results', 'may', 'sufficient', 'order', 'compute', 'satisfactory', 'performance', 'measures', '.']

>> Bigrams are: 
 [('If', 'machine'), ('machine', 'learning'), ('learning', 'approach'), ('approach', 'used'), ('used', 'address'), ('address', 'algorithm'), ('algorithm', 'deficit'), ('deficit', 'physics-based'), ('physics-based', 'model'), ('model', 'available'), ('available', ','), (',', 'numerical'), ('numerical', 'results'), ('results', 'may'), ('may', 'sufficient'), ('sufficient', 'order'), ('order', 'compute'), ('compute', 'satisfactory'), ('satisfactory', 'performance'), ('performance', 'measures'), ('measures', '.')]

>> Trigrams are: 
 [('If', 'machine', 'learning'), ('machine', 'learning', 'approach'), ('learning', 'approach', 'used'), ('approach', 'used', 'address'), ('used', 'address', 'algorithm'), ('address', 'algorithm', 'deficit'), ('algorithm', 'deficit', 'physics-based'), ('deficit', 'physics-based', 'model'), ('physics-based', 'model', 'available'), ('model', 'available', ','), ('available', ',', 'numerical'), (',', 'numerical', 'results'), ('numerical', 'results', 'may'), ('results', 'may', 'sufficient'), ('may', 'sufficient', 'order'), ('sufficient', 'order', 'compute'), ('order', 'compute', 'satisfactory'), ('compute', 'satisfactory', 'performance'), ('satisfactory', 'performance', 'measures'), ('performance', 'measures', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('approach', 'NN'), ('used', 'VBD'), ('address', 'JJ'), ('algorithm', 'JJ'), ('deficit', 'NN'), ('physics-based', 'JJ'), ('model', 'NN'), ('available', 'JJ'), (',', ','), ('numerical', 'JJ'), ('results', 'NNS'), ('may', 'MD'), ('sufficient', 'VB'), ('order', 'NN'), ('compute', 'NN'), ('satisfactory', 'JJ'), ('performance', 'NN'), ('measures', 'NNS'), ('.', '.')]

 (S
  If/IN
  (NP machine/NN learning/NN approach/NN)
  used/VBD
  (NP address/JJ algorithm/JJ deficit/NN)
  (NP physics-based/JJ model/NN)
  available/JJ
  ,/,
  (NP numerical/JJ results/NNS)
  may/MD
  sufficient/VB
  (NP order/NN compute/NN)
  (NP satisfactory/JJ performance/NN measures/NNS)
  ./.) 


>> Noun Phrases are: 
 ['machine learning approach', 'address algorithm deficit', 'physics-based model', 'numerical results', 'order compute', 'satisfactory performance measures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('used', 'use'), ('address', 'address'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('physics-based', 'physics-bas'), ('model', 'model'), ('available', 'avail'), (',', ','), ('numerical', 'numer'), ('results', 'result'), ('may', 'may'), ('sufficient', 'suffici'), ('order', 'order'), ('compute', 'comput'), ('satisfactory', 'satisfactori'), ('performance', 'perform'), ('measures', 'measur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('machine', 'machin'), ('learning', 'learn'), ('approach', 'approach'), ('used', 'use'), ('address', 'address'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('physics-based', 'physics-bas'), ('model', 'model'), ('available', 'avail'), (',', ','), ('numerical', 'numer'), ('results', 'result'), ('may', 'may'), ('sufficient', 'suffici'), ('order', 'order'), ('compute', 'comput'), ('satisfactory', 'satisfactori'), ('performance', 'perform'), ('measures', 'measur'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('machine', 'machine'), ('learning', 'learning'), ('approach', 'approach'), ('used', 'used'), ('address', 'address'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('physics-based', 'physics-based'), ('model', 'model'), ('available', 'available'), (',', ','), ('numerical', 'numerical'), ('results', 'result'), ('may', 'may'), ('sufficient', 'sufficient'), ('order', 'order'), ('compute', 'compute'), ('satisfactory', 'satisfactory'), ('performance', 'performance'), ('measures', 'measure'), ('.', '.')]



============================ Sentence 103 =============================

In  3    4 5 6 7 8 9 0  1  2  3  4  5  4 5 6 7 8 0  1  2  3  4  5  (a)  (b)  Fig. 


>> Tokens are: 
 ['In', '3', '4', '5', '6', '7', '8', '9', '0', '1', '2', '3', '4', '5', '4', '5', '6', '7', '8', '0', '1', '2', '3', '4', '5', '(', ')', '(', 'b', ')', 'Fig', '.']

>> Bigrams are: 
 [('In', '3'), ('3', '4'), ('4', '5'), ('5', '6'), ('6', '7'), ('7', '8'), ('8', '9'), ('9', '0'), ('0', '1'), ('1', '2'), ('2', '3'), ('3', '4'), ('4', '5'), ('5', '4'), ('4', '5'), ('5', '6'), ('6', '7'), ('7', '8'), ('8', '0'), ('0', '1'), ('1', '2'), ('2', '3'), ('3', '4'), ('4', '5'), ('5', '('), ('(', ')'), (')', '('), ('(', 'b'), ('b', ')'), (')', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('In', '3', '4'), ('3', '4', '5'), ('4', '5', '6'), ('5', '6', '7'), ('6', '7', '8'), ('7', '8', '9'), ('8', '9', '0'), ('9', '0', '1'), ('0', '1', '2'), ('1', '2', '3'), ('2', '3', '4'), ('3', '4', '5'), ('4', '5', '4'), ('5', '4', '5'), ('4', '5', '6'), ('5', '6', '7'), ('6', '7', '8'), ('7', '8', '0'), ('8', '0', '1'), ('0', '1', '2'), ('1', '2', '3'), ('2', '3', '4'), ('3', '4', '5'), ('4', '5', '('), ('5', '(', ')'), ('(', ')', '('), (')', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'Fig'), (')', 'Fig', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('3', 'CD'), ('4', 'CD'), ('5', 'CD'), ('6', 'CD'), ('7', 'CD'), ('8', 'CD'), ('9', 'CD'), ('0', 'CD'), ('1', 'CD'), ('2', 'CD'), ('3', 'CD'), ('4', 'CD'), ('5', 'CD'), ('4', 'CD'), ('5', 'CD'), ('6', 'CD'), ('7', 'CD'), ('8', 'CD'), ('0', 'CD'), ('1', 'CD'), ('2', 'CD'), ('3', 'CD'), ('4', 'CD'), ('5', 'CD'), ('(', '('), (')', ')'), ('(', '('), ('b', 'NN'), (')', ')'), ('Fig', 'NNP'), ('.', '.')]

 (S
  In/IN
  3/CD
  4/CD
  5/CD
  6/CD
  7/CD
  8/CD
  9/CD
  0/CD
  1/CD
  2/CD
  3/CD
  4/CD
  5/CD
  4/CD
  5/CD
  6/CD
  7/CD
  8/CD
  0/CD
  1/CD
  2/CD
  3/CD
  4/CD
  5/CD
  (/(
  )/)
  (/(
  (NP b/NN)
  )/)
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['b', 'Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('(', '('), (')', ')'), ('(', '('), ('b', 'b'), (')', ')'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 104 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 105 =============================

Illustration of (a) supervised learning and (b) unsupervised learning. 


>> Tokens are: 
 ['Illustration', '(', ')', 'supervised', 'learning', '(', 'b', ')', 'unsupervised', 'learning', '.']

>> Bigrams are: 
 [('Illustration', '('), ('(', ')'), (')', 'supervised'), ('supervised', 'learning'), ('learning', '('), ('(', 'b'), ('b', ')'), (')', 'unsupervised'), ('unsupervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Illustration', '(', ')'), ('(', ')', 'supervised'), (')', 'supervised', 'learning'), ('supervised', 'learning', '('), ('learning', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'unsupervised'), (')', 'unsupervised', 'learning'), ('unsupervised', 'learning', '.')]

>> POS Tags are: 
 [('Illustration', 'NNP'), ('(', '('), (')', ')'), ('supervised', 'VBN'), ('learning', 'NN'), ('(', '('), ('b', 'NN'), (')', ')'), ('unsupervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Illustration/NNP)
  (/(
  )/)
  supervised/VBN
  (NP learning/NN)
  (/(
  (NP b/NN)
  )/)
  unsupervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Illustration', 'learning', 'b', 'learning']

>> Named Entities are: 
 [('GPE', 'Illustration')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('(', '('), (')', ')'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('b', 'b'), (')', ')'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('(', '('), (')', ')'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('b', 'b'), (')', ')'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('(', '('), (')', ')'), ('supervised', 'supervised'), ('learning', 'learning'), ('(', '('), ('b', 'b'), (')', ')'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 106 =============================

contrast, weaker guarantees can be offered by machine learning in the absence of a physics-based model. 


>> Tokens are: 
 ['contrast', ',', 'weaker', 'guarantees', 'offered', 'machine', 'learning', 'absence', 'physics-based', 'model', '.']

>> Bigrams are: 
 [('contrast', ','), (',', 'weaker'), ('weaker', 'guarantees'), ('guarantees', 'offered'), ('offered', 'machine'), ('machine', 'learning'), ('learning', 'absence'), ('absence', 'physics-based'), ('physics-based', 'model'), ('model', '.')]

>> Trigrams are: 
 [('contrast', ',', 'weaker'), (',', 'weaker', 'guarantees'), ('weaker', 'guarantees', 'offered'), ('guarantees', 'offered', 'machine'), ('offered', 'machine', 'learning'), ('machine', 'learning', 'absence'), ('learning', 'absence', 'physics-based'), ('absence', 'physics-based', 'model'), ('physics-based', 'model', '.')]

>> POS Tags are: 
 [('contrast', 'NN'), (',', ','), ('weaker', 'JJR'), ('guarantees', 'NNS'), ('offered', 'VBD'), ('machine', 'NN'), ('learning', 'VBG'), ('absence', 'JJ'), ('physics-based', 'JJ'), ('model', 'NN'), ('.', '.')]

 (S
  (NP contrast/NN)
  ,/,
  weaker/JJR
  (NP guarantees/NNS)
  offered/VBD
  (NP machine/NN)
  learning/VBG
  (NP absence/JJ physics-based/JJ model/NN)
  ./.) 


>> Noun Phrases are: 
 ['contrast', 'guarantees', 'machine', 'absence physics-based model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('contrast', 'contrast'), (',', ','), ('weaker', 'weaker'), ('guarantees', 'guarante'), ('offered', 'offer'), ('machine', 'machin'), ('learning', 'learn'), ('absence', 'absenc'), ('physics-based', 'physics-bas'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('contrast', 'contrast'), (',', ','), ('weaker', 'weaker'), ('guarantees', 'guarante'), ('offered', 'offer'), ('machine', 'machin'), ('learning', 'learn'), ('absence', 'absenc'), ('physics-based', 'physics-bas'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('contrast', 'contrast'), (',', ','), ('weaker', 'weaker'), ('guarantees', 'guarantee'), ('offered', 'offered'), ('machine', 'machine'), ('learning', 'learning'), ('absence', 'absence'), ('physics-based', 'physics-based'), ('model', 'model'), ('.', '.')]



============================ Sentence 107 =============================

In this case, one can provide performance bounds only under the assumptions that the hypothesis class is sufficiently general to include “machines” that can perform well on the problem and that the data is representative of the actual data distribution to be encountered at runtime (see, e.g.-.-, [19][Ch 5]). 


>> Tokens are: 
 ['In', 'case', ',', 'one', 'provide', 'performance', 'bounds', 'assumptions', 'hypothesis', 'class', 'sufficiently', 'general', 'include', '“', 'machines', '”', 'perform', 'well', 'problem', 'data', 'representative', 'actual', 'data', 'distribution', 'encountered', 'runtime', '(', 'see', ',', 'e.g.-.-', ',', '[', '19', ']', '[', 'Ch', '5', ']', ')', '.']

>> Bigrams are: 
 [('In', 'case'), ('case', ','), (',', 'one'), ('one', 'provide'), ('provide', 'performance'), ('performance', 'bounds'), ('bounds', 'assumptions'), ('assumptions', 'hypothesis'), ('hypothesis', 'class'), ('class', 'sufficiently'), ('sufficiently', 'general'), ('general', 'include'), ('include', '“'), ('“', 'machines'), ('machines', '”'), ('”', 'perform'), ('perform', 'well'), ('well', 'problem'), ('problem', 'data'), ('data', 'representative'), ('representative', 'actual'), ('actual', 'data'), ('data', 'distribution'), ('distribution', 'encountered'), ('encountered', 'runtime'), ('runtime', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '19'), ('19', ']'), (']', '['), ('[', 'Ch'), ('Ch', '5'), ('5', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'case', ','), ('case', ',', 'one'), (',', 'one', 'provide'), ('one', 'provide', 'performance'), ('provide', 'performance', 'bounds'), ('performance', 'bounds', 'assumptions'), ('bounds', 'assumptions', 'hypothesis'), ('assumptions', 'hypothesis', 'class'), ('hypothesis', 'class', 'sufficiently'), ('class', 'sufficiently', 'general'), ('sufficiently', 'general', 'include'), ('general', 'include', '“'), ('include', '“', 'machines'), ('“', 'machines', '”'), ('machines', '”', 'perform'), ('”', 'perform', 'well'), ('perform', 'well', 'problem'), ('well', 'problem', 'data'), ('problem', 'data', 'representative'), ('data', 'representative', 'actual'), ('representative', 'actual', 'data'), ('actual', 'data', 'distribution'), ('data', 'distribution', 'encountered'), ('distribution', 'encountered', 'runtime'), ('encountered', 'runtime', '('), ('runtime', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '19'), ('[', '19', ']'), ('19', ']', '['), (']', '[', 'Ch'), ('[', 'Ch', '5'), ('Ch', '5', ']'), ('5', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('case', 'NN'), (',', ','), ('one', 'CD'), ('provide', 'NN'), ('performance', 'NN'), ('bounds', 'VBZ'), ('assumptions', 'NNS'), ('hypothesis', 'NN'), ('class', 'NN'), ('sufficiently', 'RB'), ('general', 'JJ'), ('include', 'VBP'), ('“', 'JJ'), ('machines', 'NNS'), ('”', 'MD'), ('perform', 'VB'), ('well', 'RB'), ('problem', 'NN'), ('data', 'NNS'), ('representative', 'VBP'), ('actual', 'JJ'), ('data', 'NNS'), ('distribution', 'NN'), ('encountered', 'VBD'), ('runtime', 'NN'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('19', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Ch', 'NNP'), ('5', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP case/NN)
  ,/,
  one/CD
  (NP provide/NN performance/NN)
  bounds/VBZ
  (NP assumptions/NNS hypothesis/NN class/NN)
  sufficiently/RB
  general/JJ
  include/VBP
  (NP “/JJ machines/NNS)
  ”/MD
  perform/VB
  well/RB
  (NP problem/NN data/NNS)
  representative/VBP
  (NP actual/JJ data/NNS distribution/NN)
  encountered/VBD
  (NP runtime/NN)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  19/CD
  (NP ]/JJ [/NNP Ch/NNP)
  5/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['case', 'provide performance', 'assumptions hypothesis class', '“ machines', 'problem data', 'actual data distribution', 'runtime', '] [ Ch', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('case', 'case'), (',', ','), ('one', 'one'), ('provide', 'provid'), ('performance', 'perform'), ('bounds', 'bound'), ('assumptions', 'assumpt'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('sufficiently', 'suffici'), ('general', 'gener'), ('include', 'includ'), ('“', '“'), ('machines', 'machin'), ('”', '”'), ('perform', 'perform'), ('well', 'well'), ('problem', 'problem'), ('data', 'data'), ('representative', 'repres'), ('actual', 'actual'), ('data', 'data'), ('distribution', 'distribut'), ('encountered', 'encount'), ('runtime', 'runtim'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('[', '['), ('Ch', 'ch'), ('5', '5'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('case', 'case'), (',', ','), ('one', 'one'), ('provide', 'provid'), ('performance', 'perform'), ('bounds', 'bound'), ('assumptions', 'assumpt'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('sufficiently', 'suffici'), ('general', 'general'), ('include', 'includ'), ('“', '“'), ('machines', 'machin'), ('”', '”'), ('perform', 'perform'), ('well', 'well'), ('problem', 'problem'), ('data', 'data'), ('representative', 'repres'), ('actual', 'actual'), ('data', 'data'), ('distribution', 'distribut'), ('encountered', 'encount'), ('runtime', 'runtim'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('[', '['), ('Ch', 'ch'), ('5', '5'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('case', 'case'), (',', ','), ('one', 'one'), ('provide', 'provide'), ('performance', 'performance'), ('bounds', 'bound'), ('assumptions', 'assumption'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('sufficiently', 'sufficiently'), ('general', 'general'), ('include', 'include'), ('“', '“'), ('machines', 'machine'), ('”', '”'), ('perform', 'perform'), ('well', 'well'), ('problem', 'problem'), ('data', 'data'), ('representative', 'representative'), ('actual', 'actual'), ('data', 'data'), ('distribution', 'distribution'), ('encountered', 'encountered'), ('runtime', 'runtime'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('[', '['), ('Ch', 'Ch'), ('5', '5'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 108 =============================

The selection of a biased hypothesis class or the use of an unrepresentative data set may hence yield strongly suboptimal performance. 


>> Tokens are: 
 ['The', 'selection', 'biased', 'hypothesis', 'class', 'use', 'unrepresentative', 'data', 'set', 'may', 'hence', 'yield', 'strongly', 'suboptimal', 'performance', '.']

>> Bigrams are: 
 [('The', 'selection'), ('selection', 'biased'), ('biased', 'hypothesis'), ('hypothesis', 'class'), ('class', 'use'), ('use', 'unrepresentative'), ('unrepresentative', 'data'), ('data', 'set'), ('set', 'may'), ('may', 'hence'), ('hence', 'yield'), ('yield', 'strongly'), ('strongly', 'suboptimal'), ('suboptimal', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('The', 'selection', 'biased'), ('selection', 'biased', 'hypothesis'), ('biased', 'hypothesis', 'class'), ('hypothesis', 'class', 'use'), ('class', 'use', 'unrepresentative'), ('use', 'unrepresentative', 'data'), ('unrepresentative', 'data', 'set'), ('data', 'set', 'may'), ('set', 'may', 'hence'), ('may', 'hence', 'yield'), ('hence', 'yield', 'strongly'), ('yield', 'strongly', 'suboptimal'), ('strongly', 'suboptimal', 'performance'), ('suboptimal', 'performance', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('selection', 'NN'), ('biased', 'VBD'), ('hypothesis', 'NN'), ('class', 'NN'), ('use', 'NN'), ('unrepresentative', 'JJ'), ('data', 'NNS'), ('set', 'NN'), ('may', 'MD'), ('hence', 'VB'), ('yield', 'NN'), ('strongly', 'RB'), ('suboptimal', 'JJ'), ('performance', 'NN'), ('.', '.')]

 (S
  (NP The/DT selection/NN)
  biased/VBD
  (NP hypothesis/NN class/NN use/NN)
  (NP unrepresentative/JJ data/NNS set/NN)
  may/MD
  hence/VB
  (NP yield/NN)
  strongly/RB
  (NP suboptimal/JJ performance/NN)
  ./.) 


>> Noun Phrases are: 
 ['The selection', 'hypothesis class use', 'unrepresentative data set', 'yield', 'suboptimal performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('biased', 'bias'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('use', 'use'), ('unrepresentative', 'unrepres'), ('data', 'data'), ('set', 'set'), ('may', 'may'), ('hence', 'henc'), ('yield', 'yield'), ('strongly', 'strongli'), ('suboptimal', 'suboptim'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('biased', 'bias'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('use', 'use'), ('unrepresentative', 'unrepres'), ('data', 'data'), ('set', 'set'), ('may', 'may'), ('hence', 'henc'), ('yield', 'yield'), ('strongly', 'strong'), ('suboptimal', 'suboptim'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('selection', 'selection'), ('biased', 'biased'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('use', 'use'), ('unrepresentative', 'unrepresentative'), ('data', 'data'), ('set', 'set'), ('may', 'may'), ('hence', 'hence'), ('yield', 'yield'), ('strongly', 'strongly'), ('suboptimal', 'suboptimal'), ('performance', 'performance'), ('.', '.')]



============================ Sentence 109 =============================

We will return to these criteria when discussing ap- plications to communication systems. 


>> Tokens are: 
 ['We', 'return', 'criteria', 'discussing', 'ap-', 'plications', 'communication', 'systems', '.']

>> Bigrams are: 
 [('We', 'return'), ('return', 'criteria'), ('criteria', 'discussing'), ('discussing', 'ap-'), ('ap-', 'plications'), ('plications', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('We', 'return', 'criteria'), ('return', 'criteria', 'discussing'), ('criteria', 'discussing', 'ap-'), ('discussing', 'ap-', 'plications'), ('ap-', 'plications', 'communication'), ('plications', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('return', 'VBP'), ('criteria', 'NNS'), ('discussing', 'VBG'), ('ap-', 'JJ'), ('plications', 'NNS'), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  We/PRP
  return/VBP
  (NP criteria/NNS)
  discussing/VBG
  (NP ap-/JJ plications/NNS communication/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['criteria', 'ap- plications communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('return', 'return'), ('criteria', 'criteria'), ('discussing', 'discuss'), ('ap-', 'ap-'), ('plications', 'plicat'), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('return', 'return'), ('criteria', 'criteria'), ('discussing', 'discuss'), ('ap-', 'ap-'), ('plications', 'plicat'), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('return', 'return'), ('criteria', 'criterion'), ('discussing', 'discussing'), ('ap-', 'ap-'), ('plications', 'plication'), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]



============================ Sentence 110 =============================

II. 


>> Tokens are: 
 ['II', '.']

>> Bigrams are: 
 [('II', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('II', 'NNP'), ('.', '.')]

 (S (NP II/NNP) ./.) 


>> Noun Phrases are: 
 ['II']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Lemmatization: 
 [('II', 'II'), ('.', '.')]



============================ Sentence 111 =============================

MACHINE LEARNING FOR COMMUNICATION NETWORKS  In order to exemplify applications of supervised and unsupervised learning, we will offer annotated pointers to the literature on machine learning for communication systems. 


>> Tokens are: 
 ['MACHINE', 'LEARNING', 'FOR', 'COMMUNICATION', 'NETWORKS', 'In', 'order', 'exemplify', 'applications', 'supervised', 'unsupervised', 'learning', ',', 'offer', 'annotated', 'pointers', 'literature', 'machine', 'learning', 'communication', 'systems', '.']

>> Bigrams are: 
 [('MACHINE', 'LEARNING'), ('LEARNING', 'FOR'), ('FOR', 'COMMUNICATION'), ('COMMUNICATION', 'NETWORKS'), ('NETWORKS', 'In'), ('In', 'order'), ('order', 'exemplify'), ('exemplify', 'applications'), ('applications', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'offer'), ('offer', 'annotated'), ('annotated', 'pointers'), ('pointers', 'literature'), ('literature', 'machine'), ('machine', 'learning'), ('learning', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('MACHINE', 'LEARNING', 'FOR'), ('LEARNING', 'FOR', 'COMMUNICATION'), ('FOR', 'COMMUNICATION', 'NETWORKS'), ('COMMUNICATION', 'NETWORKS', 'In'), ('NETWORKS', 'In', 'order'), ('In', 'order', 'exemplify'), ('order', 'exemplify', 'applications'), ('exemplify', 'applications', 'supervised'), ('applications', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'offer'), (',', 'offer', 'annotated'), ('offer', 'annotated', 'pointers'), ('annotated', 'pointers', 'literature'), ('pointers', 'literature', 'machine'), ('literature', 'machine', 'learning'), ('machine', 'learning', 'communication'), ('learning', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('FOR', 'NNP'), ('COMMUNICATION', 'NNP'), ('NETWORKS', 'NNP'), ('In', 'IN'), ('order', 'NN'), ('exemplify', 'NN'), ('applications', 'NNS'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('offer', 'NN'), ('annotated', 'VBD'), ('pointers', 'NNS'), ('literature', 'VBP'), ('machine', 'NN'), ('learning', 'VBG'), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  (NP
    MACHINE/NNP
    LEARNING/NNP
    FOR/NNP
    COMMUNICATION/NNP
    NETWORKS/NNP)
  In/IN
  (NP order/NN exemplify/NN applications/NNS)
  supervised/VBD
  (NP unsupervised/JJ learning/NN)
  ,/,
  (NP offer/NN)
  annotated/VBD
  (NP pointers/NNS)
  literature/VBP
  (NP machine/NN)
  learning/VBG
  (NP communication/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['MACHINE LEARNING FOR COMMUNICATION NETWORKS', 'order exemplify applications', 'unsupervised learning', 'offer', 'pointers', 'machine', 'communication systems']

>> Named Entities are: 
 [('ORGANIZATION', 'MACHINE'), ('ORGANIZATION', 'LEARNING FOR'), ('ORGANIZATION', 'COMMUNICATION')] 

>> Stemming using Porter Stemmer: 
 [('MACHINE', 'machin'), ('LEARNING', 'learn'), ('FOR', 'for'), ('COMMUNICATION', 'commun'), ('NETWORKS', 'network'), ('In', 'in'), ('order', 'order'), ('exemplify', 'exemplifi'), ('applications', 'applic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('offer', 'offer'), ('annotated', 'annot'), ('pointers', 'pointer'), ('literature', 'literatur'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MACHINE', 'machin'), ('LEARNING', 'learn'), ('FOR', 'for'), ('COMMUNICATION', 'communic'), ('NETWORKS', 'network'), ('In', 'in'), ('order', 'order'), ('exemplify', 'exemplifi'), ('applications', 'applic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('offer', 'offer'), ('annotated', 'annot'), ('pointers', 'pointer'), ('literature', 'literatur'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('FOR', 'FOR'), ('COMMUNICATION', 'COMMUNICATION'), ('NETWORKS', 'NETWORKS'), ('In', 'In'), ('order', 'order'), ('exemplify', 'exemplify'), ('applications', 'application'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('offer', 'offer'), ('annotated', 'annotated'), ('pointers', 'pointer'), ('literature', 'literature'), ('machine', 'machine'), ('learning', 'learning'), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]



============================ Sentence 112 =============================

Rather than striving for a comprehensive, and historically minded, review, the applications and refer- ences have been selected with the goal of illustrating key aspects regarding the use of machine learning in engineering problems. 


>> Tokens are: 
 ['Rather', 'striving', 'comprehensive', ',', 'historically', 'minded', ',', 'review', ',', 'applications', 'refer-', 'ences', 'selected', 'goal', 'illustrating', 'key', 'aspects', 'regarding', 'use', 'machine', 'learning', 'engineering', 'problems', '.']

>> Bigrams are: 
 [('Rather', 'striving'), ('striving', 'comprehensive'), ('comprehensive', ','), (',', 'historically'), ('historically', 'minded'), ('minded', ','), (',', 'review'), ('review', ','), (',', 'applications'), ('applications', 'refer-'), ('refer-', 'ences'), ('ences', 'selected'), ('selected', 'goal'), ('goal', 'illustrating'), ('illustrating', 'key'), ('key', 'aspects'), ('aspects', 'regarding'), ('regarding', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'engineering'), ('engineering', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Rather', 'striving', 'comprehensive'), ('striving', 'comprehensive', ','), ('comprehensive', ',', 'historically'), (',', 'historically', 'minded'), ('historically', 'minded', ','), ('minded', ',', 'review'), (',', 'review', ','), ('review', ',', 'applications'), (',', 'applications', 'refer-'), ('applications', 'refer-', 'ences'), ('refer-', 'ences', 'selected'), ('ences', 'selected', 'goal'), ('selected', 'goal', 'illustrating'), ('goal', 'illustrating', 'key'), ('illustrating', 'key', 'aspects'), ('key', 'aspects', 'regarding'), ('aspects', 'regarding', 'use'), ('regarding', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'engineering'), ('learning', 'engineering', 'problems'), ('engineering', 'problems', '.')]

>> POS Tags are: 
 [('Rather', 'RB'), ('striving', 'VBG'), ('comprehensive', 'JJ'), (',', ','), ('historically', 'RB'), ('minded', 'VBN'), (',', ','), ('review', 'NN'), (',', ','), ('applications', 'NNS'), ('refer-', 'JJ'), ('ences', 'NNS'), ('selected', 'VBN'), ('goal', 'NN'), ('illustrating', 'VBG'), ('key', 'JJ'), ('aspects', 'NNS'), ('regarding', 'VBG'), ('use', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('engineering', 'NN'), ('problems', 'NNS'), ('.', '.')]

 (S
  Rather/RB
  striving/VBG
  comprehensive/JJ
  ,/,
  historically/RB
  minded/VBN
  ,/,
  (NP review/NN)
  ,/,
  (NP applications/NNS)
  (NP refer-/JJ ences/NNS)
  selected/VBN
  (NP goal/NN)
  illustrating/VBG
  (NP key/JJ aspects/NNS)
  regarding/VBG
  (NP use/NN machine/NN)
  learning/VBG
  (NP engineering/NN problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['review', 'applications', 'refer- ences', 'goal', 'key aspects', 'use machine', 'engineering problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rather', 'rather'), ('striving', 'strive'), ('comprehensive', 'comprehens'), (',', ','), ('historically', 'histor'), ('minded', 'mind'), (',', ','), ('review', 'review'), (',', ','), ('applications', 'applic'), ('refer-', 'refer-'), ('ences', 'enc'), ('selected', 'select'), ('goal', 'goal'), ('illustrating', 'illustr'), ('key', 'key'), ('aspects', 'aspect'), ('regarding', 'regard'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('engineering', 'engin'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rather', 'rather'), ('striving', 'strive'), ('comprehensive', 'comprehens'), (',', ','), ('historically', 'histor'), ('minded', 'mind'), (',', ','), ('review', 'review'), (',', ','), ('applications', 'applic'), ('refer-', 'refer-'), ('ences', 'enc'), ('selected', 'select'), ('goal', 'goal'), ('illustrating', 'illustr'), ('key', 'key'), ('aspects', 'aspect'), ('regarding', 'regard'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('engineering', 'engin'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Rather', 'Rather'), ('striving', 'striving'), ('comprehensive', 'comprehensive'), (',', ','), ('historically', 'historically'), ('minded', 'minded'), (',', ','), ('review', 'review'), (',', ','), ('applications', 'application'), ('refer-', 'refer-'), ('ences', 'ences'), ('selected', 'selected'), ('goal', 'goal'), ('illustrating', 'illustrating'), ('key', 'key'), ('aspects', 'aspect'), ('regarding', 'regarding'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('engineering', 'engineering'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 113 =============================

Core   Network  Edge   Cloud  Wireless   Edge  Access   Network  Core   Cloud  Cloud  Edge  Fig. 


>> Tokens are: 
 ['Core', 'Network', 'Edge', 'Cloud', 'Wireless', 'Edge', 'Access', 'Network', 'Core', 'Cloud', 'Cloud', 'Edge', 'Fig', '.']

>> Bigrams are: 
 [('Core', 'Network'), ('Network', 'Edge'), ('Edge', 'Cloud'), ('Cloud', 'Wireless'), ('Wireless', 'Edge'), ('Edge', 'Access'), ('Access', 'Network'), ('Network', 'Core'), ('Core', 'Cloud'), ('Cloud', 'Cloud'), ('Cloud', 'Edge'), ('Edge', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Core', 'Network', 'Edge'), ('Network', 'Edge', 'Cloud'), ('Edge', 'Cloud', 'Wireless'), ('Cloud', 'Wireless', 'Edge'), ('Wireless', 'Edge', 'Access'), ('Edge', 'Access', 'Network'), ('Access', 'Network', 'Core'), ('Network', 'Core', 'Cloud'), ('Core', 'Cloud', 'Cloud'), ('Cloud', 'Cloud', 'Edge'), ('Cloud', 'Edge', 'Fig'), ('Edge', 'Fig', '.')]

>> POS Tags are: 
 [('Core', 'NNP'), ('Network', 'NNP'), ('Edge', 'NNP'), ('Cloud', 'NNP'), ('Wireless', 'NNP'), ('Edge', 'NNP'), ('Access', 'NNP'), ('Network', 'NNP'), ('Core', 'NNP'), ('Cloud', 'NNP'), ('Cloud', 'NNP'), ('Edge', 'NNP'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP
    Core/NNP
    Network/NNP
    Edge/NNP
    Cloud/NNP
    Wireless/NNP
    Edge/NNP
    Access/NNP
    Network/NNP
    Core/NNP
    Cloud/NNP
    Cloud/NNP
    Edge/NNP
    Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Core Network Edge Cloud Wireless Edge Access Network Core Cloud Cloud Edge Fig']

>> Named Entities are: 
 [('GPE', 'Core'), ('PERSON', 'Network Edge Cloud Wireless Edge Access Network Core Cloud Cloud Edge Fig')] 

>> Stemming using Porter Stemmer: 
 [('Core', 'core'), ('Network', 'network'), ('Edge', 'edg'), ('Cloud', 'cloud'), ('Wireless', 'wireless'), ('Edge', 'edg'), ('Access', 'access'), ('Network', 'network'), ('Core', 'core'), ('Cloud', 'cloud'), ('Cloud', 'cloud'), ('Edge', 'edg'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Core', 'core'), ('Network', 'network'), ('Edge', 'edg'), ('Cloud', 'cloud'), ('Wireless', 'wireless'), ('Edge', 'edg'), ('Access', 'access'), ('Network', 'network'), ('Core', 'core'), ('Cloud', 'cloud'), ('Cloud', 'cloud'), ('Edge', 'edg'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Core', 'Core'), ('Network', 'Network'), ('Edge', 'Edge'), ('Cloud', 'Cloud'), ('Wireless', 'Wireless'), ('Edge', 'Edge'), ('Access', 'Access'), ('Network', 'Network'), ('Core', 'Core'), ('Cloud', 'Cloud'), ('Cloud', 'Cloud'), ('Edge', 'Edge'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 114 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 115 =============================

A generic cellular wireless network architecture that dis- tinguishes between edge segment, with base stations, access points, and associated computing resources, and cloud segment, consisting of core network and associated cloud computing platforms. 


>> Tokens are: 
 ['A', 'generic', 'cellular', 'wireless', 'network', 'architecture', 'dis-', 'tinguishes', 'edge', 'segment', ',', 'base', 'stations', ',', 'access', 'points', ',', 'associated', 'computing', 'resources', ',', 'cloud', 'segment', ',', 'consisting', 'core', 'network', 'associated', 'cloud', 'computing', 'platforms', '.']

>> Bigrams are: 
 [('A', 'generic'), ('generic', 'cellular'), ('cellular', 'wireless'), ('wireless', 'network'), ('network', 'architecture'), ('architecture', 'dis-'), ('dis-', 'tinguishes'), ('tinguishes', 'edge'), ('edge', 'segment'), ('segment', ','), (',', 'base'), ('base', 'stations'), ('stations', ','), (',', 'access'), ('access', 'points'), ('points', ','), (',', 'associated'), ('associated', 'computing'), ('computing', 'resources'), ('resources', ','), (',', 'cloud'), ('cloud', 'segment'), ('segment', ','), (',', 'consisting'), ('consisting', 'core'), ('core', 'network'), ('network', 'associated'), ('associated', 'cloud'), ('cloud', 'computing'), ('computing', 'platforms'), ('platforms', '.')]

>> Trigrams are: 
 [('A', 'generic', 'cellular'), ('generic', 'cellular', 'wireless'), ('cellular', 'wireless', 'network'), ('wireless', 'network', 'architecture'), ('network', 'architecture', 'dis-'), ('architecture', 'dis-', 'tinguishes'), ('dis-', 'tinguishes', 'edge'), ('tinguishes', 'edge', 'segment'), ('edge', 'segment', ','), ('segment', ',', 'base'), (',', 'base', 'stations'), ('base', 'stations', ','), ('stations', ',', 'access'), (',', 'access', 'points'), ('access', 'points', ','), ('points', ',', 'associated'), (',', 'associated', 'computing'), ('associated', 'computing', 'resources'), ('computing', 'resources', ','), ('resources', ',', 'cloud'), (',', 'cloud', 'segment'), ('cloud', 'segment', ','), ('segment', ',', 'consisting'), (',', 'consisting', 'core'), ('consisting', 'core', 'network'), ('core', 'network', 'associated'), ('network', 'associated', 'cloud'), ('associated', 'cloud', 'computing'), ('cloud', 'computing', 'platforms'), ('computing', 'platforms', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('generic', 'JJ'), ('cellular', 'JJ'), ('wireless', 'NN'), ('network', 'NN'), ('architecture', 'NN'), ('dis-', 'JJ'), ('tinguishes', 'NNS'), ('edge', 'VBP'), ('segment', 'NN'), (',', ','), ('base', 'NN'), ('stations', 'NNS'), (',', ','), ('access', 'NN'), ('points', 'NNS'), (',', ','), ('associated', 'VBN'), ('computing', 'NN'), ('resources', 'NNS'), (',', ','), ('cloud', 'NN'), ('segment', 'NN'), (',', ','), ('consisting', 'VBG'), ('core', 'NN'), ('network', 'NN'), ('associated', 'VBN'), ('cloud', 'NN'), ('computing', 'VBG'), ('platforms', 'NNS'), ('.', '.')]

 (S
  (NP
    A/DT
    generic/JJ
    cellular/JJ
    wireless/NN
    network/NN
    architecture/NN)
  (NP dis-/JJ tinguishes/NNS)
  edge/VBP
  (NP segment/NN)
  ,/,
  (NP base/NN stations/NNS)
  ,/,
  (NP access/NN points/NNS)
  ,/,
  associated/VBN
  (NP computing/NN resources/NNS)
  ,/,
  (NP cloud/NN segment/NN)
  ,/,
  consisting/VBG
  (NP core/NN network/NN)
  associated/VBN
  (NP cloud/NN)
  computing/VBG
  (NP platforms/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A generic cellular wireless network architecture', 'dis- tinguishes', 'segment', 'base stations', 'access points', 'computing resources', 'cloud segment', 'core network', 'cloud', 'platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('generic', 'gener'), ('cellular', 'cellular'), ('wireless', 'wireless'), ('network', 'network'), ('architecture', 'architectur'), ('dis-', 'dis-'), ('tinguishes', 'tinguish'), ('edge', 'edg'), ('segment', 'segment'), (',', ','), ('base', 'base'), ('stations', 'station'), (',', ','), ('access', 'access'), ('points', 'point'), (',', ','), ('associated', 'associ'), ('computing', 'comput'), ('resources', 'resourc'), (',', ','), ('cloud', 'cloud'), ('segment', 'segment'), (',', ','), ('consisting', 'consist'), ('core', 'core'), ('network', 'network'), ('associated', 'associ'), ('cloud', 'cloud'), ('computing', 'comput'), ('platforms', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('generic', 'generic'), ('cellular', 'cellular'), ('wireless', 'wireless'), ('network', 'network'), ('architecture', 'architectur'), ('dis-', 'dis-'), ('tinguishes', 'tinguish'), ('edge', 'edg'), ('segment', 'segment'), (',', ','), ('base', 'base'), ('stations', 'station'), (',', ','), ('access', 'access'), ('points', 'point'), (',', ','), ('associated', 'associ'), ('computing', 'comput'), ('resources', 'resourc'), (',', ','), ('cloud', 'cloud'), ('segment', 'segment'), (',', ','), ('consisting', 'consist'), ('core', 'core'), ('network', 'network'), ('associated', 'associ'), ('cloud', 'cloud'), ('computing', 'comput'), ('platforms', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('generic', 'generic'), ('cellular', 'cellular'), ('wireless', 'wireless'), ('network', 'network'), ('architecture', 'architecture'), ('dis-', 'dis-'), ('tinguishes', 'tinguishes'), ('edge', 'edge'), ('segment', 'segment'), (',', ','), ('base', 'base'), ('stations', 'station'), (',', ','), ('access', 'access'), ('points', 'point'), (',', ','), ('associated', 'associated'), ('computing', 'computing'), ('resources', 'resource'), (',', ','), ('cloud', 'cloud'), ('segment', 'segment'), (',', ','), ('consisting', 'consisting'), ('core', 'core'), ('network', 'network'), ('associated', 'associated'), ('cloud', 'cloud'), ('computing', 'computing'), ('platforms', 'platform'), ('.', '.')]



============================ Sentence 116 =============================

Throughout, we focus on tasks carried out at the network side, rather than at the users, and organize the applications along two axes. 


>> Tokens are: 
 ['Throughout', ',', 'focus', 'tasks', 'carried', 'network', 'side', ',', 'rather', 'users', ',', 'organize', 'applications', 'along', 'two', 'axes', '.']

>> Bigrams are: 
 [('Throughout', ','), (',', 'focus'), ('focus', 'tasks'), ('tasks', 'carried'), ('carried', 'network'), ('network', 'side'), ('side', ','), (',', 'rather'), ('rather', 'users'), ('users', ','), (',', 'organize'), ('organize', 'applications'), ('applications', 'along'), ('along', 'two'), ('two', 'axes'), ('axes', '.')]

>> Trigrams are: 
 [('Throughout', ',', 'focus'), (',', 'focus', 'tasks'), ('focus', 'tasks', 'carried'), ('tasks', 'carried', 'network'), ('carried', 'network', 'side'), ('network', 'side', ','), ('side', ',', 'rather'), (',', 'rather', 'users'), ('rather', 'users', ','), ('users', ',', 'organize'), (',', 'organize', 'applications'), ('organize', 'applications', 'along'), ('applications', 'along', 'two'), ('along', 'two', 'axes'), ('two', 'axes', '.')]

>> POS Tags are: 
 [('Throughout', 'NN'), (',', ','), ('focus', 'NN'), ('tasks', 'NNS'), ('carried', 'VBD'), ('network', 'NN'), ('side', 'NN'), (',', ','), ('rather', 'RB'), ('users', 'NNS'), (',', ','), ('organize', 'VB'), ('applications', 'NNS'), ('along', 'IN'), ('two', 'CD'), ('axes', 'NNS'), ('.', '.')]

 (S
  (NP Throughout/NN)
  ,/,
  (NP focus/NN tasks/NNS)
  carried/VBD
  (NP network/NN side/NN)
  ,/,
  rather/RB
  (NP users/NNS)
  ,/,
  organize/VB
  (NP applications/NNS)
  along/IN
  two/CD
  (NP axes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Throughout', 'focus tasks', 'network side', 'users', 'applications', 'axes']

>> Named Entities are: 
 [('GPE', 'Throughout')] 

>> Stemming using Porter Stemmer: 
 [('Throughout', 'throughout'), (',', ','), ('focus', 'focu'), ('tasks', 'task'), ('carried', 'carri'), ('network', 'network'), ('side', 'side'), (',', ','), ('rather', 'rather'), ('users', 'user'), (',', ','), ('organize', 'organ'), ('applications', 'applic'), ('along', 'along'), ('two', 'two'), ('axes', 'axe'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Throughout', 'throughout'), (',', ','), ('focus', 'focus'), ('tasks', 'task'), ('carried', 'carri'), ('network', 'network'), ('side', 'side'), (',', ','), ('rather', 'rather'), ('users', 'user'), (',', ','), ('organize', 'organ'), ('applications', 'applic'), ('along', 'along'), ('two', 'two'), ('axes', 'axe'), ('.', '.')]

>> Lemmatization: 
 [('Throughout', 'Throughout'), (',', ','), ('focus', 'focus'), ('tasks', 'task'), ('carried', 'carried'), ('network', 'network'), ('side', 'side'), (',', ','), ('rather', 'rather'), ('users', 'user'), (',', ','), ('organize', 'organize'), ('applications', 'application'), ('along', 'along'), ('two', 'two'), ('axes', 'ax'), ('.', '.')]



============================ Sentence 117 =============================

On one, with reference to Fig. 


>> Tokens are: 
 ['On', 'one', ',', 'reference', 'Fig', '.']

>> Bigrams are: 
 [('On', 'one'), ('one', ','), (',', 'reference'), ('reference', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('On', 'one', ','), ('one', ',', 'reference'), (',', 'reference', 'Fig'), ('reference', 'Fig', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('one', 'CD'), (',', ','), ('reference', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S On/IN one/CD ,/, (NP reference/NN Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['reference Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('one', 'one'), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('one', 'one'), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('one', 'one'), (',', ','), ('reference', 'reference'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 118 =============================

4, we distinguish tasks that are carried out at the edge of the network, that is, at the base stations or access points and at the associated computing platforms, from tasks that are instead responsibility of a centralized cloud processor connected to the core network (see, e.g.-.-, [25]). 


>> Tokens are: 
 ['4', ',', 'distinguish', 'tasks', 'carried', 'edge', 'network', ',', ',', 'base', 'stations', 'access', 'points', 'associated', 'computing', 'platforms', ',', 'tasks', 'instead', 'responsibility', 'centralized', 'cloud', 'processor', 'connected', 'core', 'network', '(', 'see', ',', 'e.g.-.-', ',', '[', '25', ']', ')', '.']

>> Bigrams are: 
 [('4', ','), (',', 'distinguish'), ('distinguish', 'tasks'), ('tasks', 'carried'), ('carried', 'edge'), ('edge', 'network'), ('network', ','), (',', ','), (',', 'base'), ('base', 'stations'), ('stations', 'access'), ('access', 'points'), ('points', 'associated'), ('associated', 'computing'), ('computing', 'platforms'), ('platforms', ','), (',', 'tasks'), ('tasks', 'instead'), ('instead', 'responsibility'), ('responsibility', 'centralized'), ('centralized', 'cloud'), ('cloud', 'processor'), ('processor', 'connected'), ('connected', 'core'), ('core', 'network'), ('network', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '25'), ('25', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('4', ',', 'distinguish'), (',', 'distinguish', 'tasks'), ('distinguish', 'tasks', 'carried'), ('tasks', 'carried', 'edge'), ('carried', 'edge', 'network'), ('edge', 'network', ','), ('network', ',', ','), (',', ',', 'base'), (',', 'base', 'stations'), ('base', 'stations', 'access'), ('stations', 'access', 'points'), ('access', 'points', 'associated'), ('points', 'associated', 'computing'), ('associated', 'computing', 'platforms'), ('computing', 'platforms', ','), ('platforms', ',', 'tasks'), (',', 'tasks', 'instead'), ('tasks', 'instead', 'responsibility'), ('instead', 'responsibility', 'centralized'), ('responsibility', 'centralized', 'cloud'), ('centralized', 'cloud', 'processor'), ('cloud', 'processor', 'connected'), ('processor', 'connected', 'core'), ('connected', 'core', 'network'), ('core', 'network', '('), ('network', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '25'), ('[', '25', ']'), ('25', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('distinguish', 'JJ'), ('tasks', 'NNS'), ('carried', 'VBD'), ('edge', 'NN'), ('network', 'NN'), (',', ','), (',', ','), ('base', 'NN'), ('stations', 'NNS'), ('access', 'NN'), ('points', 'NNS'), ('associated', 'VBD'), ('computing', 'VBG'), ('platforms', 'NNS'), (',', ','), ('tasks', 'NNS'), ('instead', 'RB'), ('responsibility', 'NN'), ('centralized', 'JJ'), ('cloud', 'NN'), ('processor', 'NN'), ('connected', 'VBN'), ('core', 'NN'), ('network', 'NN'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('25', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  4/CD
  ,/,
  (NP distinguish/JJ tasks/NNS)
  carried/VBD
  (NP edge/NN network/NN)
  ,/,
  ,/,
  (NP base/NN stations/NNS access/NN points/NNS)
  associated/VBD
  computing/VBG
  (NP platforms/NNS)
  ,/,
  (NP tasks/NNS)
  instead/RB
  (NP responsibility/NN)
  (NP centralized/JJ cloud/NN processor/NN)
  connected/VBN
  (NP core/NN network/NN)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  25/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['distinguish tasks', 'edge network', 'base stations access points', 'platforms', 'tasks', 'responsibility', 'centralized cloud processor', 'core network', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('distinguish', 'distinguish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('network', 'network'), (',', ','), (',', ','), ('base', 'base'), ('stations', 'station'), ('access', 'access'), ('points', 'point'), ('associated', 'associ'), ('computing', 'comput'), ('platforms', 'platform'), (',', ','), ('tasks', 'task'), ('instead', 'instead'), ('responsibility', 'respons'), ('centralized', 'central'), ('cloud', 'cloud'), ('processor', 'processor'), ('connected', 'connect'), ('core', 'core'), ('network', 'network'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('25', '25'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('distinguish', 'distinguish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('network', 'network'), (',', ','), (',', ','), ('base', 'base'), ('stations', 'station'), ('access', 'access'), ('points', 'point'), ('associated', 'associ'), ('computing', 'comput'), ('platforms', 'platform'), (',', ','), ('tasks', 'task'), ('instead', 'instead'), ('responsibility', 'respons'), ('centralized', 'central'), ('cloud', 'cloud'), ('processor', 'processor'), ('connected', 'connect'), ('core', 'core'), ('network', 'network'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('25', '25'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('distinguish', 'distinguish'), ('tasks', 'task'), ('carried', 'carried'), ('edge', 'edge'), ('network', 'network'), (',', ','), (',', ','), ('base', 'base'), ('stations', 'station'), ('access', 'access'), ('points', 'point'), ('associated', 'associated'), ('computing', 'computing'), ('platforms', 'platform'), (',', ','), ('tasks', 'task'), ('instead', 'instead'), ('responsibility', 'responsibility'), ('centralized', 'centralized'), ('cloud', 'cloud'), ('processor', 'processor'), ('connected', 'connected'), ('core', 'core'), ('network', 'network'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('25', '25'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 119 =============================

The edge operates on the basis of timely local information collected at different layers of the protocol stack, which may include all layers from the physical up to the application layer. 


>> Tokens are: 
 ['The', 'edge', 'operates', 'basis', 'timely', 'local', 'information', 'collected', 'different', 'layers', 'protocol', 'stack', ',', 'may', 'include', 'layers', 'physical', 'application', 'layer', '.']

>> Bigrams are: 
 [('The', 'edge'), ('edge', 'operates'), ('operates', 'basis'), ('basis', 'timely'), ('timely', 'local'), ('local', 'information'), ('information', 'collected'), ('collected', 'different'), ('different', 'layers'), ('layers', 'protocol'), ('protocol', 'stack'), ('stack', ','), (',', 'may'), ('may', 'include'), ('include', 'layers'), ('layers', 'physical'), ('physical', 'application'), ('application', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('The', 'edge', 'operates'), ('edge', 'operates', 'basis'), ('operates', 'basis', 'timely'), ('basis', 'timely', 'local'), ('timely', 'local', 'information'), ('local', 'information', 'collected'), ('information', 'collected', 'different'), ('collected', 'different', 'layers'), ('different', 'layers', 'protocol'), ('layers', 'protocol', 'stack'), ('protocol', 'stack', ','), ('stack', ',', 'may'), (',', 'may', 'include'), ('may', 'include', 'layers'), ('include', 'layers', 'physical'), ('layers', 'physical', 'application'), ('physical', 'application', 'layer'), ('application', 'layer', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('edge', 'NN'), ('operates', 'VBZ'), ('basis', 'NN'), ('timely', 'RB'), ('local', 'JJ'), ('information', 'NN'), ('collected', 'VBD'), ('different', 'JJ'), ('layers', 'NNS'), ('protocol', 'VBP'), ('stack', 'NN'), (',', ','), ('may', 'MD'), ('include', 'VB'), ('layers', 'NNS'), ('physical', 'JJ'), ('application', 'NN'), ('layer', 'NN'), ('.', '.')]

 (S
  (NP The/DT edge/NN)
  operates/VBZ
  (NP basis/NN)
  timely/RB
  (NP local/JJ information/NN)
  collected/VBD
  (NP different/JJ layers/NNS)
  protocol/VBP
  (NP stack/NN)
  ,/,
  may/MD
  include/VB
  (NP layers/NNS)
  (NP physical/JJ application/NN layer/NN)
  ./.) 


>> Noun Phrases are: 
 ['The edge', 'basis', 'local information', 'different layers', 'stack', 'layers', 'physical application layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('edge', 'edg'), ('operates', 'oper'), ('basis', 'basi'), ('timely', 'time'), ('local', 'local'), ('information', 'inform'), ('collected', 'collect'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('may', 'may'), ('include', 'includ'), ('layers', 'layer'), ('physical', 'physic'), ('application', 'applic'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('edge', 'edg'), ('operates', 'oper'), ('basis', 'basi'), ('timely', 'time'), ('local', 'local'), ('information', 'inform'), ('collected', 'collect'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('may', 'may'), ('include', 'includ'), ('layers', 'layer'), ('physical', 'physic'), ('application', 'applic'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('edge', 'edge'), ('operates', 'operates'), ('basis', 'basis'), ('timely', 'timely'), ('local', 'local'), ('information', 'information'), ('collected', 'collected'), ('different', 'different'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('may', 'may'), ('include', 'include'), ('layers', 'layer'), ('physical', 'physical'), ('application', 'application'), ('layer', 'layer'), ('.', '.')]



============================ Sentence 120 =============================

In contrast, the centralized cloud processes longer-term and global information collected from multiple nodes in the edge network, which typically encompasses only the higher layers of the protocol stack, namely networking and application layers. 


>> Tokens are: 
 ['In', 'contrast', ',', 'centralized', 'cloud', 'processes', 'longer-term', 'global', 'information', 'collected', 'multiple', 'nodes', 'edge', 'network', ',', 'typically', 'encompasses', 'higher', 'layers', 'protocol', 'stack', ',', 'namely', 'networking', 'application', 'layers', '.']

>> Bigrams are: 
 [('In', 'contrast'), ('contrast', ','), (',', 'centralized'), ('centralized', 'cloud'), ('cloud', 'processes'), ('processes', 'longer-term'), ('longer-term', 'global'), ('global', 'information'), ('information', 'collected'), ('collected', 'multiple'), ('multiple', 'nodes'), ('nodes', 'edge'), ('edge', 'network'), ('network', ','), (',', 'typically'), ('typically', 'encompasses'), ('encompasses', 'higher'), ('higher', 'layers'), ('layers', 'protocol'), ('protocol', 'stack'), ('stack', ','), (',', 'namely'), ('namely', 'networking'), ('networking', 'application'), ('application', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('In', 'contrast', ','), ('contrast', ',', 'centralized'), (',', 'centralized', 'cloud'), ('centralized', 'cloud', 'processes'), ('cloud', 'processes', 'longer-term'), ('processes', 'longer-term', 'global'), ('longer-term', 'global', 'information'), ('global', 'information', 'collected'), ('information', 'collected', 'multiple'), ('collected', 'multiple', 'nodes'), ('multiple', 'nodes', 'edge'), ('nodes', 'edge', 'network'), ('edge', 'network', ','), ('network', ',', 'typically'), (',', 'typically', 'encompasses'), ('typically', 'encompasses', 'higher'), ('encompasses', 'higher', 'layers'), ('higher', 'layers', 'protocol'), ('layers', 'protocol', 'stack'), ('protocol', 'stack', ','), ('stack', ',', 'namely'), (',', 'namely', 'networking'), ('namely', 'networking', 'application'), ('networking', 'application', 'layers'), ('application', 'layers', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('contrast', 'NN'), (',', ','), ('centralized', 'VBN'), ('cloud', 'NN'), ('processes', 'VBZ'), ('longer-term', 'JJ'), ('global', 'JJ'), ('information', 'NN'), ('collected', 'VBD'), ('multiple', 'JJ'), ('nodes', 'NNS'), ('edge', 'NN'), ('network', 'NN'), (',', ','), ('typically', 'RB'), ('encompasses', 'VBZ'), ('higher', 'JJR'), ('layers', 'NNS'), ('protocol', 'VBP'), ('stack', 'NN'), (',', ','), ('namely', 'RB'), ('networking', 'VBG'), ('application', 'NN'), ('layers', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP contrast/NN)
  ,/,
  centralized/VBN
  (NP cloud/NN)
  processes/VBZ
  (NP longer-term/JJ global/JJ information/NN)
  collected/VBD
  (NP multiple/JJ nodes/NNS edge/NN network/NN)
  ,/,
  typically/RB
  encompasses/VBZ
  higher/JJR
  (NP layers/NNS)
  protocol/VBP
  (NP stack/NN)
  ,/,
  namely/RB
  networking/VBG
  (NP application/NN layers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['contrast', 'cloud', 'longer-term global information', 'multiple nodes edge network', 'layers', 'stack', 'application layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('centralized', 'central'), ('cloud', 'cloud'), ('processes', 'process'), ('longer-term', 'longer-term'), ('global', 'global'), ('information', 'inform'), ('collected', 'collect'), ('multiple', 'multipl'), ('nodes', 'node'), ('edge', 'edg'), ('network', 'network'), (',', ','), ('typically', 'typic'), ('encompasses', 'encompass'), ('higher', 'higher'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('namely', 'name'), ('networking', 'network'), ('application', 'applic'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('centralized', 'central'), ('cloud', 'cloud'), ('processes', 'process'), ('longer-term', 'longer-term'), ('global', 'global'), ('information', 'inform'), ('collected', 'collect'), ('multiple', 'multipl'), ('nodes', 'node'), ('edge', 'edg'), ('network', 'network'), (',', ','), ('typically', 'typic'), ('encompasses', 'encompass'), ('higher', 'higher'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('namely', 'name'), ('networking', 'network'), ('application', 'applic'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('contrast', 'contrast'), (',', ','), ('centralized', 'centralized'), ('cloud', 'cloud'), ('processes', 'process'), ('longer-term', 'longer-term'), ('global', 'global'), ('information', 'information'), ('collected', 'collected'), ('multiple', 'multiple'), ('nodes', 'node'), ('edge', 'edge'), ('network', 'network'), (',', ','), ('typically', 'typically'), ('encompasses', 'encompasses'), ('higher', 'higher'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), (',', ','), ('namely', 'namely'), ('networking', 'networking'), ('application', 'application'), ('layers', 'layer'), ('.', '.')]



============================ Sentence 121 =============================

Examples of data that may be available at the cloud and at the edge can be found in Table I and Table II, respectively. 


>> Tokens are: 
 ['Examples', 'data', 'may', 'available', 'cloud', 'edge', 'found', 'Table', 'I', 'Table', 'II', ',', 'respectively', '.']

>> Bigrams are: 
 [('Examples', 'data'), ('data', 'may'), ('may', 'available'), ('available', 'cloud'), ('cloud', 'edge'), ('edge', 'found'), ('found', 'Table'), ('Table', 'I'), ('I', 'Table'), ('Table', 'II'), ('II', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('Examples', 'data', 'may'), ('data', 'may', 'available'), ('may', 'available', 'cloud'), ('available', 'cloud', 'edge'), ('cloud', 'edge', 'found'), ('edge', 'found', 'Table'), ('found', 'Table', 'I'), ('Table', 'I', 'Table'), ('I', 'Table', 'II'), ('Table', 'II', ','), ('II', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('data', 'NNS'), ('may', 'MD'), ('available', 'JJ'), ('cloud', 'NN'), ('edge', 'NN'), ('found', 'VBD'), ('Table', 'NNP'), ('I', 'PRP'), ('Table', 'NNP'), ('II', 'NNP'), (',', ','), ('respectively', 'RB'), ('.', '.')]

 (S
  (NP Examples/NNS data/NNS)
  may/MD
  (NP available/JJ cloud/NN edge/NN)
  found/VBD
  (NP Table/NNP)
  I/PRP
  (NP Table/NNP II/NNP)
  ,/,
  respectively/RB
  ./.) 


>> Noun Phrases are: 
 ['Examples data', 'available cloud edge', 'Table', 'Table II']

>> Named Entities are: 
 [('PERSON', 'Table II')] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('data', 'data'), ('may', 'may'), ('available', 'avail'), ('cloud', 'cloud'), ('edge', 'edg'), ('found', 'found'), ('Table', 'tabl'), ('I', 'i'), ('Table', 'tabl'), ('II', 'ii'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('data', 'data'), ('may', 'may'), ('available', 'avail'), ('cloud', 'cloud'), ('edge', 'edg'), ('found', 'found'), ('Table', 'tabl'), ('I', 'i'), ('Table', 'tabl'), ('II', 'ii'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('data', 'data'), ('may', 'may'), ('available', 'available'), ('cloud', 'cloud'), ('edge', 'edge'), ('found', 'found'), ('Table', 'Table'), ('I', 'I'), ('Table', 'Table'), ('II', 'II'), (',', ','), ('respectively', 'respectively'), ('.', '.')]



============================ Sentence 122 =============================

As a preliminary discussion, it is useful to ask which tasks of a communication network, if any, may benefit from machine learning through the lens of the criteria re- viewed in Sec. 


>> Tokens are: 
 ['As', 'preliminary', 'discussion', ',', 'useful', 'ask', 'tasks', 'communication', 'network', ',', ',', 'may', 'benefit', 'machine', 'learning', 'lens', 'criteria', 're-', 'viewed', 'Sec', '.']

>> Bigrams are: 
 [('As', 'preliminary'), ('preliminary', 'discussion'), ('discussion', ','), (',', 'useful'), ('useful', 'ask'), ('ask', 'tasks'), ('tasks', 'communication'), ('communication', 'network'), ('network', ','), (',', ','), (',', 'may'), ('may', 'benefit'), ('benefit', 'machine'), ('machine', 'learning'), ('learning', 'lens'), ('lens', 'criteria'), ('criteria', 're-'), ('re-', 'viewed'), ('viewed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('As', 'preliminary', 'discussion'), ('preliminary', 'discussion', ','), ('discussion', ',', 'useful'), (',', 'useful', 'ask'), ('useful', 'ask', 'tasks'), ('ask', 'tasks', 'communication'), ('tasks', 'communication', 'network'), ('communication', 'network', ','), ('network', ',', ','), (',', ',', 'may'), (',', 'may', 'benefit'), ('may', 'benefit', 'machine'), ('benefit', 'machine', 'learning'), ('machine', 'learning', 'lens'), ('learning', 'lens', 'criteria'), ('lens', 'criteria', 're-'), ('criteria', 're-', 'viewed'), ('re-', 'viewed', 'Sec'), ('viewed', 'Sec', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('preliminary', 'JJ'), ('discussion', 'NN'), (',', ','), ('useful', 'JJ'), ('ask', 'NN'), ('tasks', 'NNS'), ('communication', 'NN'), ('network', 'NN'), (',', ','), (',', ','), ('may', 'MD'), ('benefit', 'VB'), ('machine', 'NN'), ('learning', 'VBG'), ('lens', 'NNS'), ('criteria', 'NNS'), ('re-', 'JJ'), ('viewed', 'VBD'), ('Sec', 'NNP'), ('.', '.')]

 (S
  As/IN
  (NP preliminary/JJ discussion/NN)
  ,/,
  (NP useful/JJ ask/NN tasks/NNS communication/NN network/NN)
  ,/,
  ,/,
  may/MD
  benefit/VB
  (NP machine/NN)
  learning/VBG
  (NP lens/NNS criteria/NNS)
  re-/JJ
  viewed/VBD
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['preliminary discussion', 'useful ask tasks communication network', 'machine', 'lens criteria', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('preliminary', 'preliminari'), ('discussion', 'discuss'), (',', ','), ('useful', 'use'), ('ask', 'ask'), ('tasks', 'task'), ('communication', 'commun'), ('network', 'network'), (',', ','), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('machine', 'machin'), ('learning', 'learn'), ('lens', 'len'), ('criteria', 'criteria'), ('re-', 're-'), ('viewed', 'view'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('preliminary', 'preliminari'), ('discussion', 'discuss'), (',', ','), ('useful', 'use'), ('ask', 'ask'), ('tasks', 'task'), ('communication', 'communic'), ('network', 'network'), (',', ','), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('machine', 'machin'), ('learning', 'learn'), ('lens', 'len'), ('criteria', 'criteria'), ('re-', 're-'), ('viewed', 'view'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('preliminary', 'preliminary'), ('discussion', 'discussion'), (',', ','), ('useful', 'useful'), ('ask', 'ask'), ('tasks', 'task'), ('communication', 'communication'), ('network', 'network'), (',', ','), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('machine', 'machine'), ('learning', 'learning'), ('lens', 'lens'), ('criteria', 'criterion'), ('re-', 're-'), ('viewed', 'viewed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 123 =============================

I-C. First, as seen, there should be either a model deficit or an algorithm deficit that prevents the use of a conventional model-based engineering design. 


>> Tokens are: 
 ['I-C.', 'First', ',', 'seen', ',', 'either', 'model', 'deficit', 'algorithm', 'deficit', 'prevents', 'use', 'conventional', 'model-based', 'engineering', 'design', '.']

>> Bigrams are: 
 [('I-C.', 'First'), ('First', ','), (',', 'seen'), ('seen', ','), (',', 'either'), ('either', 'model'), ('model', 'deficit'), ('deficit', 'algorithm'), ('algorithm', 'deficit'), ('deficit', 'prevents'), ('prevents', 'use'), ('use', 'conventional'), ('conventional', 'model-based'), ('model-based', 'engineering'), ('engineering', 'design'), ('design', '.')]

>> Trigrams are: 
 [('I-C.', 'First', ','), ('First', ',', 'seen'), (',', 'seen', ','), ('seen', ',', 'either'), (',', 'either', 'model'), ('either', 'model', 'deficit'), ('model', 'deficit', 'algorithm'), ('deficit', 'algorithm', 'deficit'), ('algorithm', 'deficit', 'prevents'), ('deficit', 'prevents', 'use'), ('prevents', 'use', 'conventional'), ('use', 'conventional', 'model-based'), ('conventional', 'model-based', 'engineering'), ('model-based', 'engineering', 'design'), ('engineering', 'design', '.')]

>> POS Tags are: 
 [('I-C.', 'NNP'), ('First', 'NNP'), (',', ','), ('seen', 'VBN'), (',', ','), ('either', 'DT'), ('model', 'NN'), ('deficit', 'NN'), ('algorithm', 'NN'), ('deficit', 'NN'), ('prevents', 'NNS'), ('use', 'VBP'), ('conventional', 'JJ'), ('model-based', 'JJ'), ('engineering', 'NN'), ('design', 'NN'), ('.', '.')]

 (S
  (NP I-C./NNP First/NNP)
  ,/,
  seen/VBN
  ,/,
  (NP
    either/DT
    model/NN
    deficit/NN
    algorithm/NN
    deficit/NN
    prevents/NNS)
  use/VBP
  (NP conventional/JJ model-based/JJ engineering/NN design/NN)
  ./.) 


>> Noun Phrases are: 
 ['I-C. First', 'either model deficit algorithm deficit prevents', 'conventional model-based engineering design']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I-C.', 'i-c.'), ('First', 'first'), (',', ','), ('seen', 'seen'), (',', ','), ('either', 'either'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('prevents', 'prevent'), ('use', 'use'), ('conventional', 'convent'), ('model-based', 'model-bas'), ('engineering', 'engin'), ('design', 'design'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I-C.', 'i-c.'), ('First', 'first'), (',', ','), ('seen', 'seen'), (',', ','), ('either', 'either'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('prevents', 'prevent'), ('use', 'use'), ('conventional', 'convent'), ('model-based', 'model-bas'), ('engineering', 'engin'), ('design', 'design'), ('.', '.')]

>> Lemmatization: 
 [('I-C.', 'I-C.'), ('First', 'First'), (',', ','), ('seen', 'seen'), (',', ','), ('either', 'either'), ('model', 'model'), ('deficit', 'deficit'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('prevents', 'prevents'), ('use', 'use'), ('conventional', 'conventional'), ('model-based', 'model-based'), ('engineering', 'engineering'), ('design', 'design'), ('.', '.')]



============================ Sentence 124 =============================

As an example of model deficit, proactive resource allocation that is based on predictions of human behaviour, e.g.-.-, for caching popular contents, may not benefit from well- established and reliable models, making a data-driven approach desirable (see, e.g.-.-, [26], [27]). 


>> Tokens are: 
 ['As', 'example', 'model', 'deficit', ',', 'proactive', 'resource', 'allocation', 'based', 'predictions', 'human', 'behaviour', ',', 'e.g.-.-', ',', 'caching', 'popular', 'contents', ',', 'may', 'benefit', 'well-', 'established', 'reliable', 'models', ',', 'making', 'data-driven', 'approach', 'desirable', '(', 'see', ',', 'e.g.-.-', ',', '[', '26', ']', ',', '[', '27', ']', ')', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', 'model'), ('model', 'deficit'), ('deficit', ','), (',', 'proactive'), ('proactive', 'resource'), ('resource', 'allocation'), ('allocation', 'based'), ('based', 'predictions'), ('predictions', 'human'), ('human', 'behaviour'), ('behaviour', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'caching'), ('caching', 'popular'), ('popular', 'contents'), ('contents', ','), (',', 'may'), ('may', 'benefit'), ('benefit', 'well-'), ('well-', 'established'), ('established', 'reliable'), ('reliable', 'models'), ('models', ','), (',', 'making'), ('making', 'data-driven'), ('data-driven', 'approach'), ('approach', 'desirable'), ('desirable', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '26'), ('26', ']'), (']', ','), (',', '['), ('[', '27'), ('27', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('As', 'example', 'model'), ('example', 'model', 'deficit'), ('model', 'deficit', ','), ('deficit', ',', 'proactive'), (',', 'proactive', 'resource'), ('proactive', 'resource', 'allocation'), ('resource', 'allocation', 'based'), ('allocation', 'based', 'predictions'), ('based', 'predictions', 'human'), ('predictions', 'human', 'behaviour'), ('human', 'behaviour', ','), ('behaviour', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'caching'), (',', 'caching', 'popular'), ('caching', 'popular', 'contents'), ('popular', 'contents', ','), ('contents', ',', 'may'), (',', 'may', 'benefit'), ('may', 'benefit', 'well-'), ('benefit', 'well-', 'established'), ('well-', 'established', 'reliable'), ('established', 'reliable', 'models'), ('reliable', 'models', ','), ('models', ',', 'making'), (',', 'making', 'data-driven'), ('making', 'data-driven', 'approach'), ('data-driven', 'approach', 'desirable'), ('approach', 'desirable', '('), ('desirable', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '26'), ('[', '26', ']'), ('26', ']', ','), (']', ',', '['), (',', '[', '27'), ('[', '27', ']'), ('27', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), ('model', 'NN'), ('deficit', 'NN'), (',', ','), ('proactive', 'JJ'), ('resource', 'NN'), ('allocation', 'NN'), ('based', 'VBN'), ('predictions', 'NNS'), ('human', 'JJ'), ('behaviour', 'NN'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('caching', 'VBG'), ('popular', 'JJ'), ('contents', 'NNS'), (',', ','), ('may', 'MD'), ('benefit', 'VB'), ('well-', 'JJ'), ('established', 'VBN'), ('reliable', 'JJ'), ('models', 'NNS'), (',', ','), ('making', 'VBG'), ('data-driven', 'JJ'), ('approach', 'NN'), ('desirable', 'JJ'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('26', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('27', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  As/IN
  (NP example/NN model/NN deficit/NN)
  ,/,
  (NP proactive/JJ resource/NN allocation/NN)
  based/VBN
  (NP predictions/NNS)
  (NP human/JJ behaviour/NN)
  ,/,
  e.g.-.-/JJ
  ,/,
  caching/VBG
  (NP popular/JJ contents/NNS)
  ,/,
  may/MD
  benefit/VB
  well-/JJ
  established/VBN
  (NP reliable/JJ models/NNS)
  ,/,
  making/VBG
  (NP data-driven/JJ approach/NN)
  desirable/JJ
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  26/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  27/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['example model deficit', 'proactive resource allocation', 'predictions', 'human behaviour', 'popular contents', 'reliable models', 'data-driven approach', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('proactive', 'proactiv'), ('resource', 'resourc'), ('allocation', 'alloc'), ('based', 'base'), ('predictions', 'predict'), ('human', 'human'), ('behaviour', 'behaviour'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('caching', 'cach'), ('popular', 'popular'), ('contents', 'content'), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('well-', 'well-'), ('established', 'establish'), ('reliable', 'reliabl'), ('models', 'model'), (',', ','), ('making', 'make'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('desirable', 'desir'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('26', '26'), (']', ']'), (',', ','), ('[', '['), ('27', '27'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('proactive', 'proactiv'), ('resource', 'resourc'), ('allocation', 'alloc'), ('based', 'base'), ('predictions', 'predict'), ('human', 'human'), ('behaviour', 'behaviour'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('caching', 'cach'), ('popular', 'popular'), ('contents', 'content'), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('well-', 'well-'), ('established', 'establish'), ('reliable', 'reliabl'), ('models', 'model'), (',', ','), ('making', 'make'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('desirable', 'desir'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('26', '26'), (']', ']'), (',', ','), ('[', '['), ('27', '27'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('proactive', 'proactive'), ('resource', 'resource'), ('allocation', 'allocation'), ('based', 'based'), ('predictions', 'prediction'), ('human', 'human'), ('behaviour', 'behaviour'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('caching', 'caching'), ('popular', 'popular'), ('contents', 'content'), (',', ','), ('may', 'may'), ('benefit', 'benefit'), ('well-', 'well-'), ('established', 'established'), ('reliable', 'reliable'), ('models', 'model'), (',', ','), ('making', 'making'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('desirable', 'desirable'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('26', '26'), (']', ']'), (',', ','), ('[', '['), ('27', '27'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 125 =============================

For an instance of algorithm deficit, consider the problem of channel decoding for channels with known and accurate models based on which the maximum likelihood decoder entails an excessive complexity. 


>> Tokens are: 
 ['For', 'instance', 'algorithm', 'deficit', ',', 'consider', 'problem', 'channel', 'decoding', 'channels', 'known', 'accurate', 'models', 'based', 'maximum', 'likelihood', 'decoder', 'entails', 'excessive', 'complexity', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', 'algorithm'), ('algorithm', 'deficit'), ('deficit', ','), (',', 'consider'), ('consider', 'problem'), ('problem', 'channel'), ('channel', 'decoding'), ('decoding', 'channels'), ('channels', 'known'), ('known', 'accurate'), ('accurate', 'models'), ('models', 'based'), ('based', 'maximum'), ('maximum', 'likelihood'), ('likelihood', 'decoder'), ('decoder', 'entails'), ('entails', 'excessive'), ('excessive', 'complexity'), ('complexity', '.')]

>> Trigrams are: 
 [('For', 'instance', 'algorithm'), ('instance', 'algorithm', 'deficit'), ('algorithm', 'deficit', ','), ('deficit', ',', 'consider'), (',', 'consider', 'problem'), ('consider', 'problem', 'channel'), ('problem', 'channel', 'decoding'), ('channel', 'decoding', 'channels'), ('decoding', 'channels', 'known'), ('channels', 'known', 'accurate'), ('known', 'accurate', 'models'), ('accurate', 'models', 'based'), ('models', 'based', 'maximum'), ('based', 'maximum', 'likelihood'), ('maximum', 'likelihood', 'decoder'), ('likelihood', 'decoder', 'entails'), ('decoder', 'entails', 'excessive'), ('entails', 'excessive', 'complexity'), ('excessive', 'complexity', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), ('algorithm', 'NN'), ('deficit', 'NN'), (',', ','), ('consider', 'VB'), ('problem', 'NN'), ('channel', 'NN'), ('decoding', 'NN'), ('channels', 'NNS'), ('known', 'VBN'), ('accurate', 'JJ'), ('models', 'NNS'), ('based', 'VBN'), ('maximum', 'JJ'), ('likelihood', 'NN'), ('decoder', 'NN'), ('entails', 'VBZ'), ('excessive', 'JJ'), ('complexity', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN algorithm/NN deficit/NN)
  ,/,
  consider/VB
  (NP problem/NN channel/NN decoding/NN channels/NNS)
  known/VBN
  (NP accurate/JJ models/NNS)
  based/VBN
  (NP maximum/JJ likelihood/NN decoder/NN)
  entails/VBZ
  (NP excessive/JJ complexity/NN)
  ./.) 


>> Noun Phrases are: 
 ['instance algorithm deficit', 'problem channel decoding channels', 'accurate models', 'maximum likelihood decoder', 'excessive complexity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('consider', 'consid'), ('problem', 'problem'), ('channel', 'channel'), ('decoding', 'decod'), ('channels', 'channel'), ('known', 'known'), ('accurate', 'accur'), ('models', 'model'), ('based', 'base'), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decod'), ('entails', 'entail'), ('excessive', 'excess'), ('complexity', 'complex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('consider', 'consid'), ('problem', 'problem'), ('channel', 'channel'), ('decoding', 'decod'), ('channels', 'channel'), ('known', 'known'), ('accurate', 'accur'), ('models', 'model'), ('based', 'base'), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decod'), ('entails', 'entail'), ('excessive', 'excess'), ('complexity', 'complex'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('consider', 'consider'), ('problem', 'problem'), ('channel', 'channel'), ('decoding', 'decoding'), ('channels', 'channel'), ('known', 'known'), ('accurate', 'accurate'), ('models', 'model'), ('based', 'based'), ('maximum', 'maximum'), ('likelihood', 'likelihood'), ('decoder', 'decoder'), ('entails', 'entail'), ('excessive', 'excessive'), ('complexity', 'complexity'), ('.', '.')]



============================ Sentence 126 =============================

Assuming that the problem at hand is characterized by model or algorithm deficits, one should then consider the rest of the criteria discussed in Sec. 


>> Tokens are: 
 ['Assuming', 'problem', 'hand', 'characterized', 'model', 'algorithm', 'deficits', ',', 'one', 'consider', 'rest', 'criteria', 'discussed', 'Sec', '.']

>> Bigrams are: 
 [('Assuming', 'problem'), ('problem', 'hand'), ('hand', 'characterized'), ('characterized', 'model'), ('model', 'algorithm'), ('algorithm', 'deficits'), ('deficits', ','), (',', 'one'), ('one', 'consider'), ('consider', 'rest'), ('rest', 'criteria'), ('criteria', 'discussed'), ('discussed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Assuming', 'problem', 'hand'), ('problem', 'hand', 'characterized'), ('hand', 'characterized', 'model'), ('characterized', 'model', 'algorithm'), ('model', 'algorithm', 'deficits'), ('algorithm', 'deficits', ','), ('deficits', ',', 'one'), (',', 'one', 'consider'), ('one', 'consider', 'rest'), ('consider', 'rest', 'criteria'), ('rest', 'criteria', 'discussed'), ('criteria', 'discussed', 'Sec'), ('discussed', 'Sec', '.')]

>> POS Tags are: 
 [('Assuming', 'VBG'), ('problem', 'NN'), ('hand', 'NN'), ('characterized', 'VBD'), ('model', 'NN'), ('algorithm', 'NN'), ('deficits', 'NNS'), (',', ','), ('one', 'CD'), ('consider', 'NN'), ('rest', 'NN'), ('criteria', 'NNS'), ('discussed', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  Assuming/VBG
  (NP problem/NN hand/NN)
  characterized/VBD
  (NP model/NN algorithm/NN deficits/NNS)
  ,/,
  one/CD
  (NP consider/NN rest/NN criteria/NNS)
  discussed/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['problem hand', 'model algorithm deficits', 'consider rest criteria', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Assuming', 'assum'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'character'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficits', 'deficit'), (',', ','), ('one', 'one'), ('consider', 'consid'), ('rest', 'rest'), ('criteria', 'criteria'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Assuming', 'assum'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'character'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficits', 'deficit'), (',', ','), ('one', 'one'), ('consider', 'consid'), ('rest', 'rest'), ('criteria', 'criteria'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Assuming', 'Assuming'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'characterized'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficits', 'deficit'), (',', ','), ('one', 'one'), ('consider', 'consider'), ('rest', 'rest'), ('criteria', 'criterion'), ('discussed', 'discussed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 127 =============================

I-C. 


>> Tokens are: 
 ['I-C', '.']

>> Bigrams are: 
 [('I-C', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('I-C', 'NNP'), ('.', '.')]

 (S (NP I-C/NNP) ./.) 


>> Noun Phrases are: 
 ['I-C']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I-C', 'i-c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I-C', 'i-c'), ('.', '.')]

>> Lemmatization: 
 [('I-C', 'I-C'), ('.', '.')]



============================ Sentence 128 =============================

Most are  4    TABLE I EXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT OF A COMMUNICATION NETWORK  Layer Data Physical Baseband signals, channel state information  Medium Access Control/ Link Throughput, FER, random access load and latency Network Location, traffic loads across services, users’ device types, battery levels  Application Users’ preferences, content demands, computing loads, QoS metrics  TABLE II EXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT OF A COMMUNICATION NETWORK  Layer Data Network Mobility patterns, network-wide traffic statistics, outage rates  Application User’s behaviour patterns, subscription information, service usage statistics, TCP/IP traffic statistics  typically satisfied by communication problems. 


>> Tokens are: 
 ['Most', '4', 'TABLE', 'I', 'EXAMPLES', 'OF', 'DATA', 'AVAILABLE', 'AT', 'THE', 'EDGE', 'SEGMENT', 'OF', 'A', 'COMMUNICATION', 'NETWORK', 'Layer', 'Data', 'Physical', 'Baseband', 'signals', ',', 'channel', 'state', 'information', 'Medium', 'Access', 'Control/', 'Link', 'Throughput', ',', 'FER', ',', 'random', 'access', 'load', 'latency', 'Network', 'Location', ',', 'traffic', 'loads', 'across', 'services', ',', 'users', '’', 'device', 'types', ',', 'battery', 'levels', 'Application', 'Users', '’', 'preferences', ',', 'content', 'demands', ',', 'computing', 'loads', ',', 'QoS', 'metrics', 'TABLE', 'II', 'EXAMPLES', 'OF', 'DATA', 'AVAILABLE', 'AT', 'THE', 'CLOUD', 'SEGMENT', 'OF', 'A', 'COMMUNICATION', 'NETWORK', 'Layer', 'Data', 'Network', 'Mobility', 'patterns', ',', 'network-wide', 'traffic', 'statistics', ',', 'outage', 'rates', 'Application', 'User', '’', 'behaviour', 'patterns', ',', 'subscription', 'information', ',', 'service', 'usage', 'statistics', ',', 'TCP/IP', 'traffic', 'statistics', 'typically', 'satisfied', 'communication', 'problems', '.']

>> Bigrams are: 
 [('Most', '4'), ('4', 'TABLE'), ('TABLE', 'I'), ('I', 'EXAMPLES'), ('EXAMPLES', 'OF'), ('OF', 'DATA'), ('DATA', 'AVAILABLE'), ('AVAILABLE', 'AT'), ('AT', 'THE'), ('THE', 'EDGE'), ('EDGE', 'SEGMENT'), ('SEGMENT', 'OF'), ('OF', 'A'), ('A', 'COMMUNICATION'), ('COMMUNICATION', 'NETWORK'), ('NETWORK', 'Layer'), ('Layer', 'Data'), ('Data', 'Physical'), ('Physical', 'Baseband'), ('Baseband', 'signals'), ('signals', ','), (',', 'channel'), ('channel', 'state'), ('state', 'information'), ('information', 'Medium'), ('Medium', 'Access'), ('Access', 'Control/'), ('Control/', 'Link'), ('Link', 'Throughput'), ('Throughput', ','), (',', 'FER'), ('FER', ','), (',', 'random'), ('random', 'access'), ('access', 'load'), ('load', 'latency'), ('latency', 'Network'), ('Network', 'Location'), ('Location', ','), (',', 'traffic'), ('traffic', 'loads'), ('loads', 'across'), ('across', 'services'), ('services', ','), (',', 'users'), ('users', '’'), ('’', 'device'), ('device', 'types'), ('types', ','), (',', 'battery'), ('battery', 'levels'), ('levels', 'Application'), ('Application', 'Users'), ('Users', '’'), ('’', 'preferences'), ('preferences', ','), (',', 'content'), ('content', 'demands'), ('demands', ','), (',', 'computing'), ('computing', 'loads'), ('loads', ','), (',', 'QoS'), ('QoS', 'metrics'), ('metrics', 'TABLE'), ('TABLE', 'II'), ('II', 'EXAMPLES'), ('EXAMPLES', 'OF'), ('OF', 'DATA'), ('DATA', 'AVAILABLE'), ('AVAILABLE', 'AT'), ('AT', 'THE'), ('THE', 'CLOUD'), ('CLOUD', 'SEGMENT'), ('SEGMENT', 'OF'), ('OF', 'A'), ('A', 'COMMUNICATION'), ('COMMUNICATION', 'NETWORK'), ('NETWORK', 'Layer'), ('Layer', 'Data'), ('Data', 'Network'), ('Network', 'Mobility'), ('Mobility', 'patterns'), ('patterns', ','), (',', 'network-wide'), ('network-wide', 'traffic'), ('traffic', 'statistics'), ('statistics', ','), (',', 'outage'), ('outage', 'rates'), ('rates', 'Application'), ('Application', 'User'), ('User', '’'), ('’', 'behaviour'), ('behaviour', 'patterns'), ('patterns', ','), (',', 'subscription'), ('subscription', 'information'), ('information', ','), (',', 'service'), ('service', 'usage'), ('usage', 'statistics'), ('statistics', ','), (',', 'TCP/IP'), ('TCP/IP', 'traffic'), ('traffic', 'statistics'), ('statistics', 'typically'), ('typically', 'satisfied'), ('satisfied', 'communication'), ('communication', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Most', '4', 'TABLE'), ('4', 'TABLE', 'I'), ('TABLE', 'I', 'EXAMPLES'), ('I', 'EXAMPLES', 'OF'), ('EXAMPLES', 'OF', 'DATA'), ('OF', 'DATA', 'AVAILABLE'), ('DATA', 'AVAILABLE', 'AT'), ('AVAILABLE', 'AT', 'THE'), ('AT', 'THE', 'EDGE'), ('THE', 'EDGE', 'SEGMENT'), ('EDGE', 'SEGMENT', 'OF'), ('SEGMENT', 'OF', 'A'), ('OF', 'A', 'COMMUNICATION'), ('A', 'COMMUNICATION', 'NETWORK'), ('COMMUNICATION', 'NETWORK', 'Layer'), ('NETWORK', 'Layer', 'Data'), ('Layer', 'Data', 'Physical'), ('Data', 'Physical', 'Baseband'), ('Physical', 'Baseband', 'signals'), ('Baseband', 'signals', ','), ('signals', ',', 'channel'), (',', 'channel', 'state'), ('channel', 'state', 'information'), ('state', 'information', 'Medium'), ('information', 'Medium', 'Access'), ('Medium', 'Access', 'Control/'), ('Access', 'Control/', 'Link'), ('Control/', 'Link', 'Throughput'), ('Link', 'Throughput', ','), ('Throughput', ',', 'FER'), (',', 'FER', ','), ('FER', ',', 'random'), (',', 'random', 'access'), ('random', 'access', 'load'), ('access', 'load', 'latency'), ('load', 'latency', 'Network'), ('latency', 'Network', 'Location'), ('Network', 'Location', ','), ('Location', ',', 'traffic'), (',', 'traffic', 'loads'), ('traffic', 'loads', 'across'), ('loads', 'across', 'services'), ('across', 'services', ','), ('services', ',', 'users'), (',', 'users', '’'), ('users', '’', 'device'), ('’', 'device', 'types'), ('device', 'types', ','), ('types', ',', 'battery'), (',', 'battery', 'levels'), ('battery', 'levels', 'Application'), ('levels', 'Application', 'Users'), ('Application', 'Users', '’'), ('Users', '’', 'preferences'), ('’', 'preferences', ','), ('preferences', ',', 'content'), (',', 'content', 'demands'), ('content', 'demands', ','), ('demands', ',', 'computing'), (',', 'computing', 'loads'), ('computing', 'loads', ','), ('loads', ',', 'QoS'), (',', 'QoS', 'metrics'), ('QoS', 'metrics', 'TABLE'), ('metrics', 'TABLE', 'II'), ('TABLE', 'II', 'EXAMPLES'), ('II', 'EXAMPLES', 'OF'), ('EXAMPLES', 'OF', 'DATA'), ('OF', 'DATA', 'AVAILABLE'), ('DATA', 'AVAILABLE', 'AT'), ('AVAILABLE', 'AT', 'THE'), ('AT', 'THE', 'CLOUD'), ('THE', 'CLOUD', 'SEGMENT'), ('CLOUD', 'SEGMENT', 'OF'), ('SEGMENT', 'OF', 'A'), ('OF', 'A', 'COMMUNICATION'), ('A', 'COMMUNICATION', 'NETWORK'), ('COMMUNICATION', 'NETWORK', 'Layer'), ('NETWORK', 'Layer', 'Data'), ('Layer', 'Data', 'Network'), ('Data', 'Network', 'Mobility'), ('Network', 'Mobility', 'patterns'), ('Mobility', 'patterns', ','), ('patterns', ',', 'network-wide'), (',', 'network-wide', 'traffic'), ('network-wide', 'traffic', 'statistics'), ('traffic', 'statistics', ','), ('statistics', ',', 'outage'), (',', 'outage', 'rates'), ('outage', 'rates', 'Application'), ('rates', 'Application', 'User'), ('Application', 'User', '’'), ('User', '’', 'behaviour'), ('’', 'behaviour', 'patterns'), ('behaviour', 'patterns', ','), ('patterns', ',', 'subscription'), (',', 'subscription', 'information'), ('subscription', 'information', ','), ('information', ',', 'service'), (',', 'service', 'usage'), ('service', 'usage', 'statistics'), ('usage', 'statistics', ','), ('statistics', ',', 'TCP/IP'), (',', 'TCP/IP', 'traffic'), ('TCP/IP', 'traffic', 'statistics'), ('traffic', 'statistics', 'typically'), ('statistics', 'typically', 'satisfied'), ('typically', 'satisfied', 'communication'), ('satisfied', 'communication', 'problems'), ('communication', 'problems', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('4', 'CD'), ('TABLE', 'NN'), ('I', 'PRP'), ('EXAMPLES', 'NNP'), ('OF', 'NNP'), ('DATA', 'NNP'), ('AVAILABLE', 'NNP'), ('AT', 'NNP'), ('THE', 'NNP'), ('EDGE', 'NNP'), ('SEGMENT', 'NNP'), ('OF', 'IN'), ('A', 'NNP'), ('COMMUNICATION', 'NNP'), ('NETWORK', 'NNP'), ('Layer', 'NNP'), ('Data', 'NNP'), ('Physical', 'NNP'), ('Baseband', 'NNP'), ('signals', 'NNS'), (',', ','), ('channel', 'NN'), ('state', 'NN'), ('information', 'NN'), ('Medium', 'NNP'), ('Access', 'NNP'), ('Control/', 'NNP'), ('Link', 'NNP'), ('Throughput', 'NNP'), (',', ','), ('FER', 'NNP'), (',', ','), ('random', 'JJ'), ('access', 'NN'), ('load', 'NN'), ('latency', 'NN'), ('Network', 'NNP'), ('Location', 'NNP'), (',', ','), ('traffic', 'NN'), ('loads', 'NNS'), ('across', 'IN'), ('services', 'NNS'), (',', ','), ('users', 'NNS'), ('’', 'VBP'), ('device', 'NN'), ('types', 'NNS'), (',', ','), ('battery', 'NN'), ('levels', 'NNS'), ('Application', 'NNP'), ('Users', 'NNP'), ('’', 'NNP'), ('preferences', 'NNS'), (',', ','), ('content', 'NN'), ('demands', 'NNS'), (',', ','), ('computing', 'VBG'), ('loads', 'NNS'), (',', ','), ('QoS', 'NNP'), ('metrics', 'NNS'), ('TABLE', 'NNP'), ('II', 'NNP'), ('EXAMPLES', 'NNP'), ('OF', 'NNP'), ('DATA', 'NNP'), ('AVAILABLE', 'NNP'), ('AT', 'NNP'), ('THE', 'NNP'), ('CLOUD', 'NNP'), ('SEGMENT', 'NNP'), ('OF', 'IN'), ('A', 'NNP'), ('COMMUNICATION', 'NNP'), ('NETWORK', 'NNP'), ('Layer', 'NNP'), ('Data', 'NNP'), ('Network', 'NNP'), ('Mobility', 'NNP'), ('patterns', 'NNS'), (',', ','), ('network-wide', 'JJ'), ('traffic', 'NN'), ('statistics', 'NNS'), (',', ','), ('outage', 'NN'), ('rates', 'NNS'), ('Application', 'NNP'), ('User', 'NNP'), ('’', 'NNP'), ('behaviour', 'NN'), ('patterns', 'NNS'), (',', ','), ('subscription', 'NN'), ('information', 'NN'), (',', ','), ('service', 'NN'), ('usage', 'NN'), ('statistics', 'NNS'), (',', ','), ('TCP/IP', 'NNP'), ('traffic', 'NN'), ('statistics', 'NNS'), ('typically', 'RB'), ('satisfied', 'JJ'), ('communication', 'NN'), ('problems', 'NNS'), ('.', '.')]

 (S
  Most/JJS
  4/CD
  (NP TABLE/NN)
  I/PRP
  (NP
    EXAMPLES/NNP
    OF/NNP
    DATA/NNP
    AVAILABLE/NNP
    AT/NNP
    THE/NNP
    EDGE/NNP
    SEGMENT/NNP)
  OF/IN
  (NP
    A/NNP
    COMMUNICATION/NNP
    NETWORK/NNP
    Layer/NNP
    Data/NNP
    Physical/NNP
    Baseband/NNP
    signals/NNS)
  ,/,
  (NP
    channel/NN
    state/NN
    information/NN
    Medium/NNP
    Access/NNP
    Control//NNP
    Link/NNP
    Throughput/NNP)
  ,/,
  (NP FER/NNP)
  ,/,
  (NP
    random/JJ
    access/NN
    load/NN
    latency/NN
    Network/NNP
    Location/NNP)
  ,/,
  (NP traffic/NN loads/NNS)
  across/IN
  (NP services/NNS)
  ,/,
  (NP users/NNS)
  ’/VBP
  (NP device/NN types/NNS)
  ,/,
  (NP
    battery/NN
    levels/NNS
    Application/NNP
    Users/NNP
    ’/NNP
    preferences/NNS)
  ,/,
  (NP content/NN demands/NNS)
  ,/,
  computing/VBG
  (NP loads/NNS)
  ,/,
  (NP
    QoS/NNP
    metrics/NNS
    TABLE/NNP
    II/NNP
    EXAMPLES/NNP
    OF/NNP
    DATA/NNP
    AVAILABLE/NNP
    AT/NNP
    THE/NNP
    CLOUD/NNP
    SEGMENT/NNP)
  OF/IN
  (NP
    A/NNP
    COMMUNICATION/NNP
    NETWORK/NNP
    Layer/NNP
    Data/NNP
    Network/NNP
    Mobility/NNP
    patterns/NNS)
  ,/,
  (NP network-wide/JJ traffic/NN statistics/NNS)
  ,/,
  (NP
    outage/NN
    rates/NNS
    Application/NNP
    User/NNP
    ’/NNP
    behaviour/NN
    patterns/NNS)
  ,/,
  (NP subscription/NN information/NN)
  ,/,
  (NP service/NN usage/NN statistics/NNS)
  ,/,
  (NP TCP/IP/NNP traffic/NN statistics/NNS)
  typically/RB
  (NP satisfied/JJ communication/NN problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['TABLE', 'EXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT', 'A COMMUNICATION NETWORK Layer Data Physical Baseband signals', 'channel state information Medium Access Control/ Link Throughput', 'FER', 'random access load latency Network Location', 'traffic loads', 'services', 'users', 'device types', 'battery levels Application Users ’ preferences', 'content demands', 'loads', 'QoS metrics TABLE II EXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT', 'A COMMUNICATION NETWORK Layer Data Network Mobility patterns', 'network-wide traffic statistics', 'outage rates Application User ’ behaviour patterns', 'subscription information', 'service usage statistics', 'TCP/IP traffic statistics', 'satisfied communication problems']

>> Named Entities are: 
 [('ORGANIZATION', 'EXAMPLES OF'), ('ORGANIZATION', 'DATA'), ('ORGANIZATION', 'THE'), ('ORGANIZATION', 'EDGE'), ('ORGANIZATION', 'COMMUNICATION'), ('ORGANIZATION', 'NETWORK Layer Data Physical Baseband'), ('PERSON', 'Medium Access'), ('PERSON', 'Link Throughput'), ('ORGANIZATION', 'FER'), ('PERSON', 'Network Location'), ('ORGANIZATION', 'QoS'), ('ORGANIZATION', 'TABLE'), ('ORGANIZATION', 'THE'), ('ORGANIZATION', 'CLOUD'), ('ORGANIZATION', 'COMMUNICATION'), ('ORGANIZATION', 'NETWORK Layer Data Network')] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('4', '4'), ('TABLE', 'tabl'), ('I', 'i'), ('EXAMPLES', 'exampl'), ('OF', 'of'), ('DATA', 'data'), ('AVAILABLE', 'avail'), ('AT', 'at'), ('THE', 'the'), ('EDGE', 'edg'), ('SEGMENT', 'segment'), ('OF', 'of'), ('A', 'a'), ('COMMUNICATION', 'commun'), ('NETWORK', 'network'), ('Layer', 'layer'), ('Data', 'data'), ('Physical', 'physic'), ('Baseband', 'baseband'), ('signals', 'signal'), (',', ','), ('channel', 'channel'), ('state', 'state'), ('information', 'inform'), ('Medium', 'medium'), ('Access', 'access'), ('Control/', 'control/'), ('Link', 'link'), ('Throughput', 'throughput'), (',', ','), ('FER', 'fer'), (',', ','), ('random', 'random'), ('access', 'access'), ('load', 'load'), ('latency', 'latenc'), ('Network', 'network'), ('Location', 'locat'), (',', ','), ('traffic', 'traffic'), ('loads', 'load'), ('across', 'across'), ('services', 'servic'), (',', ','), ('users', 'user'), ('’', '’'), ('device', 'devic'), ('types', 'type'), (',', ','), ('battery', 'batteri'), ('levels', 'level'), ('Application', 'applic'), ('Users', 'user'), ('’', '’'), ('preferences', 'prefer'), (',', ','), ('content', 'content'), ('demands', 'demand'), (',', ','), ('computing', 'comput'), ('loads', 'load'), (',', ','), ('QoS', 'qo'), ('metrics', 'metric'), ('TABLE', 'tabl'), ('II', 'ii'), ('EXAMPLES', 'exampl'), ('OF', 'of'), ('DATA', 'data'), ('AVAILABLE', 'avail'), ('AT', 'at'), ('THE', 'the'), ('CLOUD', 'cloud'), ('SEGMENT', 'segment'), ('OF', 'of'), ('A', 'a'), ('COMMUNICATION', 'commun'), ('NETWORK', 'network'), ('Layer', 'layer'), ('Data', 'data'), ('Network', 'network'), ('Mobility', 'mobil'), ('patterns', 'pattern'), (',', ','), ('network-wide', 'network-wid'), ('traffic', 'traffic'), ('statistics', 'statist'), (',', ','), ('outage', 'outag'), ('rates', 'rate'), ('Application', 'applic'), ('User', 'user'), ('’', '’'), ('behaviour', 'behaviour'), ('patterns', 'pattern'), (',', ','), ('subscription', 'subscript'), ('information', 'inform'), (',', ','), ('service', 'servic'), ('usage', 'usag'), ('statistics', 'statist'), (',', ','), ('TCP/IP', 'tcp/ip'), ('traffic', 'traffic'), ('statistics', 'statist'), ('typically', 'typic'), ('satisfied', 'satisfi'), ('communication', 'commun'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('4', '4'), ('TABLE', 'tabl'), ('I', 'i'), ('EXAMPLES', 'exampl'), ('OF', 'of'), ('DATA', 'data'), ('AVAILABLE', 'avail'), ('AT', 'at'), ('THE', 'the'), ('EDGE', 'edg'), ('SEGMENT', 'segment'), ('OF', 'of'), ('A', 'a'), ('COMMUNICATION', 'communic'), ('NETWORK', 'network'), ('Layer', 'layer'), ('Data', 'data'), ('Physical', 'physic'), ('Baseband', 'baseband'), ('signals', 'signal'), (',', ','), ('channel', 'channel'), ('state', 'state'), ('information', 'inform'), ('Medium', 'medium'), ('Access', 'access'), ('Control/', 'control/'), ('Link', 'link'), ('Throughput', 'throughput'), (',', ','), ('FER', 'fer'), (',', ','), ('random', 'random'), ('access', 'access'), ('load', 'load'), ('latency', 'latenc'), ('Network', 'network'), ('Location', 'locat'), (',', ','), ('traffic', 'traffic'), ('loads', 'load'), ('across', 'across'), ('services', 'servic'), (',', ','), ('users', 'user'), ('’', '’'), ('device', 'devic'), ('types', 'type'), (',', ','), ('battery', 'batteri'), ('levels', 'level'), ('Application', 'applic'), ('Users', 'user'), ('’', '’'), ('preferences', 'prefer'), (',', ','), ('content', 'content'), ('demands', 'demand'), (',', ','), ('computing', 'comput'), ('loads', 'load'), (',', ','), ('QoS', 'qos'), ('metrics', 'metric'), ('TABLE', 'tabl'), ('II', 'ii'), ('EXAMPLES', 'exampl'), ('OF', 'of'), ('DATA', 'data'), ('AVAILABLE', 'avail'), ('AT', 'at'), ('THE', 'the'), ('CLOUD', 'cloud'), ('SEGMENT', 'segment'), ('OF', 'of'), ('A', 'a'), ('COMMUNICATION', 'communic'), ('NETWORK', 'network'), ('Layer', 'layer'), ('Data', 'data'), ('Network', 'network'), ('Mobility', 'mobil'), ('patterns', 'pattern'), (',', ','), ('network-wide', 'network-wid'), ('traffic', 'traffic'), ('statistics', 'statist'), (',', ','), ('outage', 'outag'), ('rates', 'rate'), ('Application', 'applic'), ('User', 'user'), ('’', '’'), ('behaviour', 'behaviour'), ('patterns', 'pattern'), (',', ','), ('subscription', 'subscript'), ('information', 'inform'), (',', ','), ('service', 'servic'), ('usage', 'usag'), ('statistics', 'statist'), (',', ','), ('TCP/IP', 'tcp/ip'), ('traffic', 'traffic'), ('statistics', 'statist'), ('typically', 'typic'), ('satisfied', 'satisfi'), ('communication', 'communic'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('4', '4'), ('TABLE', 'TABLE'), ('I', 'I'), ('EXAMPLES', 'EXAMPLES'), ('OF', 'OF'), ('DATA', 'DATA'), ('AVAILABLE', 'AVAILABLE'), ('AT', 'AT'), ('THE', 'THE'), ('EDGE', 'EDGE'), ('SEGMENT', 'SEGMENT'), ('OF', 'OF'), ('A', 'A'), ('COMMUNICATION', 'COMMUNICATION'), ('NETWORK', 'NETWORK'), ('Layer', 'Layer'), ('Data', 'Data'), ('Physical', 'Physical'), ('Baseband', 'Baseband'), ('signals', 'signal'), (',', ','), ('channel', 'channel'), ('state', 'state'), ('information', 'information'), ('Medium', 'Medium'), ('Access', 'Access'), ('Control/', 'Control/'), ('Link', 'Link'), ('Throughput', 'Throughput'), (',', ','), ('FER', 'FER'), (',', ','), ('random', 'random'), ('access', 'access'), ('load', 'load'), ('latency', 'latency'), ('Network', 'Network'), ('Location', 'Location'), (',', ','), ('traffic', 'traffic'), ('loads', 'load'), ('across', 'across'), ('services', 'service'), (',', ','), ('users', 'user'), ('’', '’'), ('device', 'device'), ('types', 'type'), (',', ','), ('battery', 'battery'), ('levels', 'level'), ('Application', 'Application'), ('Users', 'Users'), ('’', '’'), ('preferences', 'preference'), (',', ','), ('content', 'content'), ('demands', 'demand'), (',', ','), ('computing', 'computing'), ('loads', 'load'), (',', ','), ('QoS', 'QoS'), ('metrics', 'metric'), ('TABLE', 'TABLE'), ('II', 'II'), ('EXAMPLES', 'EXAMPLES'), ('OF', 'OF'), ('DATA', 'DATA'), ('AVAILABLE', 'AVAILABLE'), ('AT', 'AT'), ('THE', 'THE'), ('CLOUD', 'CLOUD'), ('SEGMENT', 'SEGMENT'), ('OF', 'OF'), ('A', 'A'), ('COMMUNICATION', 'COMMUNICATION'), ('NETWORK', 'NETWORK'), ('Layer', 'Layer'), ('Data', 'Data'), ('Network', 'Network'), ('Mobility', 'Mobility'), ('patterns', 'pattern'), (',', ','), ('network-wide', 'network-wide'), ('traffic', 'traffic'), ('statistics', 'statistic'), (',', ','), ('outage', 'outage'), ('rates', 'rate'), ('Application', 'Application'), ('User', 'User'), ('’', '’'), ('behaviour', 'behaviour'), ('patterns', 'pattern'), (',', ','), ('subscription', 'subscription'), ('information', 'information'), (',', ','), ('service', 'service'), ('usage', 'usage'), ('statistics', 'statistic'), (',', ','), ('TCP/IP', 'TCP/IP'), ('traffic', 'traffic'), ('statistics', 'statistic'), ('typically', 'typically'), ('satisfied', 'satisfied'), ('communication', 'communication'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 129 =============================

Indeed, for most tasks in communication networks, it is possible to collect or generate training data sets and there is no need to apply common sense or to provide detailed explanations for how a decision was made. 


>> Tokens are: 
 ['Indeed', ',', 'tasks', 'communication', 'networks', ',', 'possible', 'collect', 'generate', 'training', 'data', 'sets', 'need', 'apply', 'common', 'sense', 'provide', 'detailed', 'explanations', 'decision', 'made', '.']

>> Bigrams are: 
 [('Indeed', ','), (',', 'tasks'), ('tasks', 'communication'), ('communication', 'networks'), ('networks', ','), (',', 'possible'), ('possible', 'collect'), ('collect', 'generate'), ('generate', 'training'), ('training', 'data'), ('data', 'sets'), ('sets', 'need'), ('need', 'apply'), ('apply', 'common'), ('common', 'sense'), ('sense', 'provide'), ('provide', 'detailed'), ('detailed', 'explanations'), ('explanations', 'decision'), ('decision', 'made'), ('made', '.')]

>> Trigrams are: 
 [('Indeed', ',', 'tasks'), (',', 'tasks', 'communication'), ('tasks', 'communication', 'networks'), ('communication', 'networks', ','), ('networks', ',', 'possible'), (',', 'possible', 'collect'), ('possible', 'collect', 'generate'), ('collect', 'generate', 'training'), ('generate', 'training', 'data'), ('training', 'data', 'sets'), ('data', 'sets', 'need'), ('sets', 'need', 'apply'), ('need', 'apply', 'common'), ('apply', 'common', 'sense'), ('common', 'sense', 'provide'), ('sense', 'provide', 'detailed'), ('provide', 'detailed', 'explanations'), ('detailed', 'explanations', 'decision'), ('explanations', 'decision', 'made'), ('decision', 'made', '.')]

>> POS Tags are: 
 [('Indeed', 'RB'), (',', ','), ('tasks', 'NNS'), ('communication', 'NN'), ('networks', 'NNS'), (',', ','), ('possible', 'JJ'), ('collect', 'NN'), ('generate', 'NN'), ('training', 'NN'), ('data', 'NNS'), ('sets', 'NNS'), ('need', 'VBP'), ('apply', 'RB'), ('common', 'JJ'), ('sense', 'NN'), ('provide', 'NN'), ('detailed', 'VBD'), ('explanations', 'NNS'), ('decision', 'NN'), ('made', 'VBD'), ('.', '.')]

 (S
  Indeed/RB
  ,/,
  (NP tasks/NNS communication/NN networks/NNS)
  ,/,
  (NP
    possible/JJ
    collect/NN
    generate/NN
    training/NN
    data/NNS
    sets/NNS)
  need/VBP
  apply/RB
  (NP common/JJ sense/NN provide/NN)
  detailed/VBD
  (NP explanations/NNS decision/NN)
  made/VBD
  ./.) 


>> Noun Phrases are: 
 ['tasks communication networks', 'possible collect generate training data sets', 'common sense provide', 'explanations decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Indeed', 'inde'), (',', ','), ('tasks', 'task'), ('communication', 'commun'), ('networks', 'network'), (',', ','), ('possible', 'possibl'), ('collect', 'collect'), ('generate', 'gener'), ('training', 'train'), ('data', 'data'), ('sets', 'set'), ('need', 'need'), ('apply', 'appli'), ('common', 'common'), ('sense', 'sens'), ('provide', 'provid'), ('detailed', 'detail'), ('explanations', 'explan'), ('decision', 'decis'), ('made', 'made'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Indeed', 'inde'), (',', ','), ('tasks', 'task'), ('communication', 'communic'), ('networks', 'network'), (',', ','), ('possible', 'possibl'), ('collect', 'collect'), ('generate', 'generat'), ('training', 'train'), ('data', 'data'), ('sets', 'set'), ('need', 'need'), ('apply', 'appli'), ('common', 'common'), ('sense', 'sens'), ('provide', 'provid'), ('detailed', 'detail'), ('explanations', 'explan'), ('decision', 'decis'), ('made', 'made'), ('.', '.')]

>> Lemmatization: 
 [('Indeed', 'Indeed'), (',', ','), ('tasks', 'task'), ('communication', 'communication'), ('networks', 'network'), (',', ','), ('possible', 'possible'), ('collect', 'collect'), ('generate', 'generate'), ('training', 'training'), ('data', 'data'), ('sets', 'set'), ('need', 'need'), ('apply', 'apply'), ('common', 'common'), ('sense', 'sense'), ('provide', 'provide'), ('detailed', 'detailed'), ('explanations', 'explanation'), ('decision', 'decision'), ('made', 'made'), ('.', '.')]



============================ Sentence 130 =============================

The remaining two criteria need to be checked on a case-by-case basis. 


>> Tokens are: 
 ['The', 'remaining', 'two', 'criteria', 'need', 'checked', 'case-by-case', 'basis', '.']

>> Bigrams are: 
 [('The', 'remaining'), ('remaining', 'two'), ('two', 'criteria'), ('criteria', 'need'), ('need', 'checked'), ('checked', 'case-by-case'), ('case-by-case', 'basis'), ('basis', '.')]

>> Trigrams are: 
 [('The', 'remaining', 'two'), ('remaining', 'two', 'criteria'), ('two', 'criteria', 'need'), ('criteria', 'need', 'checked'), ('need', 'checked', 'case-by-case'), ('checked', 'case-by-case', 'basis'), ('case-by-case', 'basis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('remaining', 'VBG'), ('two', 'CD'), ('criteria', 'NNS'), ('need', 'VBP'), ('checked', 'VBN'), ('case-by-case', 'JJ'), ('basis', 'NN'), ('.', '.')]

 (S
  The/DT
  remaining/VBG
  two/CD
  (NP criteria/NNS)
  need/VBP
  checked/VBN
  (NP case-by-case/JJ basis/NN)
  ./.) 


>> Noun Phrases are: 
 ['criteria', 'case-by-case basis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('remaining', 'remain'), ('two', 'two'), ('criteria', 'criteria'), ('need', 'need'), ('checked', 'check'), ('case-by-case', 'case-by-cas'), ('basis', 'basi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('remaining', 'remain'), ('two', 'two'), ('criteria', 'criteria'), ('need', 'need'), ('checked', 'check'), ('case-by-case', 'case-by-cas'), ('basis', 'basi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('remaining', 'remaining'), ('two', 'two'), ('criteria', 'criterion'), ('need', 'need'), ('checked', 'checked'), ('case-by-case', 'case-by-case'), ('basis', 'basis'), ('.', '.')]



============================ Sentence 131 =============================

First, the phenomenon or function being learned should not change too rapidly over time. 


>> Tokens are: 
 ['First', ',', 'phenomenon', 'function', 'learned', 'change', 'rapidly', 'time', '.']

>> Bigrams are: 
 [('First', ','), (',', 'phenomenon'), ('phenomenon', 'function'), ('function', 'learned'), ('learned', 'change'), ('change', 'rapidly'), ('rapidly', 'time'), ('time', '.')]

>> Trigrams are: 
 [('First', ',', 'phenomenon'), (',', 'phenomenon', 'function'), ('phenomenon', 'function', 'learned'), ('function', 'learned', 'change'), ('learned', 'change', 'rapidly'), ('change', 'rapidly', 'time'), ('rapidly', 'time', '.')]

>> POS Tags are: 
 [('First', 'RB'), (',', ','), ('phenomenon', 'NN'), ('function', 'NN'), ('learned', 'VBD'), ('change', 'NN'), ('rapidly', 'RB'), ('time', 'NN'), ('.', '.')]

 (S
  First/RB
  ,/,
  (NP phenomenon/NN function/NN)
  learned/VBD
  (NP change/NN)
  rapidly/RB
  (NP time/NN)
  ./.) 


>> Noun Phrases are: 
 ['phenomenon function', 'change', 'time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('First', 'first'), (',', ','), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learn'), ('change', 'chang'), ('rapidly', 'rapidli'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('First', 'first'), (',', ','), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learn'), ('change', 'chang'), ('rapidly', 'rapid'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('First', 'First'), (',', ','), ('phenomenon', 'phenomenon'), ('function', 'function'), ('learned', 'learned'), ('change', 'change'), ('rapidly', 'rapidly'), ('time', 'time'), ('.', '.')]



============================ Sentence 132 =============================

For example, designing a channel decoder based on samples obtained from a limited number of realizations of a given propagation channel requires the channel is stationary over a sufficiently long period of time (see [28]). 


>> Tokens are: 
 ['For', 'example', ',', 'designing', 'channel', 'decoder', 'based', 'samples', 'obtained', 'limited', 'number', 'realizations', 'given', 'propagation', 'channel', 'requires', 'channel', 'stationary', 'sufficiently', 'long', 'period', 'time', '(', 'see', '[', '28', ']', ')', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'designing'), ('designing', 'channel'), ('channel', 'decoder'), ('decoder', 'based'), ('based', 'samples'), ('samples', 'obtained'), ('obtained', 'limited'), ('limited', 'number'), ('number', 'realizations'), ('realizations', 'given'), ('given', 'propagation'), ('propagation', 'channel'), ('channel', 'requires'), ('requires', 'channel'), ('channel', 'stationary'), ('stationary', 'sufficiently'), ('sufficiently', 'long'), ('long', 'period'), ('period', 'time'), ('time', '('), ('(', 'see'), ('see', '['), ('[', '28'), ('28', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'designing'), (',', 'designing', 'channel'), ('designing', 'channel', 'decoder'), ('channel', 'decoder', 'based'), ('decoder', 'based', 'samples'), ('based', 'samples', 'obtained'), ('samples', 'obtained', 'limited'), ('obtained', 'limited', 'number'), ('limited', 'number', 'realizations'), ('number', 'realizations', 'given'), ('realizations', 'given', 'propagation'), ('given', 'propagation', 'channel'), ('propagation', 'channel', 'requires'), ('channel', 'requires', 'channel'), ('requires', 'channel', 'stationary'), ('channel', 'stationary', 'sufficiently'), ('stationary', 'sufficiently', 'long'), ('sufficiently', 'long', 'period'), ('long', 'period', 'time'), ('period', 'time', '('), ('time', '(', 'see'), ('(', 'see', '['), ('see', '[', '28'), ('[', '28', ']'), ('28', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('designing', 'VBG'), ('channel', 'NNS'), ('decoder', 'NN'), ('based', 'VBN'), ('samples', 'NNS'), ('obtained', 'VBN'), ('limited', 'JJ'), ('number', 'NN'), ('realizations', 'NNS'), ('given', 'VBN'), ('propagation', 'NN'), ('channel', 'NN'), ('requires', 'VBZ'), ('channel', 'NNS'), ('stationary', 'JJ'), ('sufficiently', 'RB'), ('long', 'RB'), ('period', 'NN'), ('time', 'NN'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('28', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  designing/VBG
  (NP channel/NNS decoder/NN)
  based/VBN
  (NP samples/NNS)
  obtained/VBN
  (NP limited/JJ number/NN realizations/NNS)
  given/VBN
  (NP propagation/NN channel/NN)
  requires/VBZ
  (NP channel/NNS)
  stationary/JJ
  sufficiently/RB
  long/RB
  (NP period/NN time/NN)
  (/(
  see/VB
  [/RB
  28/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['example', 'channel decoder', 'samples', 'limited number realizations', 'propagation channel', 'channel', 'period time', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('designing', 'design'), ('channel', 'channel'), ('decoder', 'decod'), ('based', 'base'), ('samples', 'sampl'), ('obtained', 'obtain'), ('limited', 'limit'), ('number', 'number'), ('realizations', 'realiz'), ('given', 'given'), ('propagation', 'propag'), ('channel', 'channel'), ('requires', 'requir'), ('channel', 'channel'), ('stationary', 'stationari'), ('sufficiently', 'suffici'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('(', '('), ('see', 'see'), ('[', '['), ('28', '28'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('designing', 'design'), ('channel', 'channel'), ('decoder', 'decod'), ('based', 'base'), ('samples', 'sampl'), ('obtained', 'obtain'), ('limited', 'limit'), ('number', 'number'), ('realizations', 'realize'), ('given', 'given'), ('propagation', 'propag'), ('channel', 'channel'), ('requires', 'requir'), ('channel', 'channel'), ('stationary', 'stationari'), ('sufficiently', 'suffici'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('(', '('), ('see', 'see'), ('[', '['), ('28', '28'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('designing', 'designing'), ('channel', 'channel'), ('decoder', 'decoder'), ('based', 'based'), ('samples', 'sample'), ('obtained', 'obtained'), ('limited', 'limited'), ('number', 'number'), ('realizations', 'realization'), ('given', 'given'), ('propagation', 'propagation'), ('channel', 'channel'), ('requires', 'requires'), ('channel', 'channel'), ('stationary', 'stationary'), ('sufficiently', 'sufficiently'), ('long', 'long'), ('period', 'period'), ('time', 'time'), ('(', '('), ('see', 'see'), ('[', '['), ('28', '28'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 133 =============================

Second, in the case of a model deficit, the task should have some tolerance for error in the sense of not requir- ing provable performance guarantees. 


>> Tokens are: 
 ['Second', ',', 'case', 'model', 'deficit', ',', 'task', 'tolerance', 'error', 'sense', 'requir-', 'ing', 'provable', 'performance', 'guarantees', '.']

>> Bigrams are: 
 [('Second', ','), (',', 'case'), ('case', 'model'), ('model', 'deficit'), ('deficit', ','), (',', 'task'), ('task', 'tolerance'), ('tolerance', 'error'), ('error', 'sense'), ('sense', 'requir-'), ('requir-', 'ing'), ('ing', 'provable'), ('provable', 'performance'), ('performance', 'guarantees'), ('guarantees', '.')]

>> Trigrams are: 
 [('Second', ',', 'case'), (',', 'case', 'model'), ('case', 'model', 'deficit'), ('model', 'deficit', ','), ('deficit', ',', 'task'), (',', 'task', 'tolerance'), ('task', 'tolerance', 'error'), ('tolerance', 'error', 'sense'), ('error', 'sense', 'requir-'), ('sense', 'requir-', 'ing'), ('requir-', 'ing', 'provable'), ('ing', 'provable', 'performance'), ('provable', 'performance', 'guarantees'), ('performance', 'guarantees', '.')]

>> POS Tags are: 
 [('Second', 'NNP'), (',', ','), ('case', 'NN'), ('model', 'NN'), ('deficit', 'NN'), (',', ','), ('task', 'NN'), ('tolerance', 'NN'), ('error', 'NN'), ('sense', 'NN'), ('requir-', 'JJ'), ('ing', 'NN'), ('provable', 'JJ'), ('performance', 'NN'), ('guarantees', 'NNS'), ('.', '.')]

 (S
  (NP Second/NNP)
  ,/,
  (NP case/NN model/NN deficit/NN)
  ,/,
  (NP task/NN tolerance/NN error/NN sense/NN)
  (NP requir-/JJ ing/NN)
  (NP provable/JJ performance/NN guarantees/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Second', 'case model deficit', 'task tolerance error sense', 'requir- ing', 'provable performance guarantees']

>> Named Entities are: 
 [('GPE', 'Second')] 

>> Stemming using Porter Stemmer: 
 [('Second', 'second'), (',', ','), ('case', 'case'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('task', 'task'), ('tolerance', 'toler'), ('error', 'error'), ('sense', 'sens'), ('requir-', 'requir-'), ('ing', 'ing'), ('provable', 'provabl'), ('performance', 'perform'), ('guarantees', 'guarante'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Second', 'second'), (',', ','), ('case', 'case'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('task', 'task'), ('tolerance', 'toler'), ('error', 'error'), ('sense', 'sens'), ('requir-', 'requir-'), ('ing', 'ing'), ('provable', 'provabl'), ('performance', 'perform'), ('guarantees', 'guarante'), ('.', '.')]

>> Lemmatization: 
 [('Second', 'Second'), (',', ','), ('case', 'case'), ('model', 'model'), ('deficit', 'deficit'), (',', ','), ('task', 'task'), ('tolerance', 'tolerance'), ('error', 'error'), ('sense', 'sense'), ('requir-', 'requir-'), ('ing', 'ing'), ('provable', 'provable'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('.', '.')]



============================ Sentence 134 =============================

For instance, the performance of a decoder trained on a channel lacking a well-established channel model, such as a biological communication link, can only be relied upon insofar as one trusts the available data to be representative of the complete set of possible realizations of the problem under study. 


>> Tokens are: 
 ['For', 'instance', ',', 'performance', 'decoder', 'trained', 'channel', 'lacking', 'well-established', 'channel', 'model', ',', 'biological', 'communication', 'link', ',', 'relied', 'upon', 'insofar', 'one', 'trusts', 'available', 'data', 'representative', 'complete', 'set', 'possible', 'realizations', 'problem', 'study', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'performance'), ('performance', 'decoder'), ('decoder', 'trained'), ('trained', 'channel'), ('channel', 'lacking'), ('lacking', 'well-established'), ('well-established', 'channel'), ('channel', 'model'), ('model', ','), (',', 'biological'), ('biological', 'communication'), ('communication', 'link'), ('link', ','), (',', 'relied'), ('relied', 'upon'), ('upon', 'insofar'), ('insofar', 'one'), ('one', 'trusts'), ('trusts', 'available'), ('available', 'data'), ('data', 'representative'), ('representative', 'complete'), ('complete', 'set'), ('set', 'possible'), ('possible', 'realizations'), ('realizations', 'problem'), ('problem', 'study'), ('study', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'performance'), (',', 'performance', 'decoder'), ('performance', 'decoder', 'trained'), ('decoder', 'trained', 'channel'), ('trained', 'channel', 'lacking'), ('channel', 'lacking', 'well-established'), ('lacking', 'well-established', 'channel'), ('well-established', 'channel', 'model'), ('channel', 'model', ','), ('model', ',', 'biological'), (',', 'biological', 'communication'), ('biological', 'communication', 'link'), ('communication', 'link', ','), ('link', ',', 'relied'), (',', 'relied', 'upon'), ('relied', 'upon', 'insofar'), ('upon', 'insofar', 'one'), ('insofar', 'one', 'trusts'), ('one', 'trusts', 'available'), ('trusts', 'available', 'data'), ('available', 'data', 'representative'), ('data', 'representative', 'complete'), ('representative', 'complete', 'set'), ('complete', 'set', 'possible'), ('set', 'possible', 'realizations'), ('possible', 'realizations', 'problem'), ('realizations', 'problem', 'study'), ('problem', 'study', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('performance', 'NN'), ('decoder', 'NN'), ('trained', 'VBD'), ('channel', 'NNS'), ('lacking', 'VBG'), ('well-established', 'JJ'), ('channel', 'NN'), ('model', 'NN'), (',', ','), ('biological', 'JJ'), ('communication', 'NN'), ('link', 'NN'), (',', ','), ('relied', 'VBN'), ('upon', 'IN'), ('insofar', 'RB'), ('one', 'CD'), ('trusts', 'NNS'), ('available', 'JJ'), ('data', 'NNS'), ('representative', 'JJ'), ('complete', 'JJ'), ('set', 'VBN'), ('possible', 'JJ'), ('realizations', 'NNS'), ('problem', 'NN'), ('study', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN)
  ,/,
  (NP performance/NN decoder/NN)
  trained/VBD
  (NP channel/NNS)
  lacking/VBG
  (NP well-established/JJ channel/NN model/NN)
  ,/,
  (NP biological/JJ communication/NN link/NN)
  ,/,
  relied/VBN
  upon/IN
  insofar/RB
  one/CD
  (NP trusts/NNS)
  (NP available/JJ data/NNS)
  representative/JJ
  complete/JJ
  set/VBN
  (NP possible/JJ realizations/NNS problem/NN study/NN)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'performance decoder', 'channel', 'well-established channel model', 'biological communication link', 'trusts', 'available data', 'possible realizations problem study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('performance', 'perform'), ('decoder', 'decod'), ('trained', 'train'), ('channel', 'channel'), ('lacking', 'lack'), ('well-established', 'well-establish'), ('channel', 'channel'), ('model', 'model'), (',', ','), ('biological', 'biolog'), ('communication', 'commun'), ('link', 'link'), (',', ','), ('relied', 'reli'), ('upon', 'upon'), ('insofar', 'insofar'), ('one', 'one'), ('trusts', 'trust'), ('available', 'avail'), ('data', 'data'), ('representative', 'repres'), ('complete', 'complet'), ('set', 'set'), ('possible', 'possibl'), ('realizations', 'realiz'), ('problem', 'problem'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('performance', 'perform'), ('decoder', 'decod'), ('trained', 'train'), ('channel', 'channel'), ('lacking', 'lack'), ('well-established', 'well-establish'), ('channel', 'channel'), ('model', 'model'), (',', ','), ('biological', 'biolog'), ('communication', 'communic'), ('link', 'link'), (',', ','), ('relied', 'reli'), ('upon', 'upon'), ('insofar', 'insofar'), ('one', 'one'), ('trusts', 'trust'), ('available', 'avail'), ('data', 'data'), ('representative', 'repres'), ('complete', 'complet'), ('set', 'set'), ('possible', 'possibl'), ('realizations', 'realize'), ('problem', 'problem'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('performance', 'performance'), ('decoder', 'decoder'), ('trained', 'trained'), ('channel', 'channel'), ('lacking', 'lacking'), ('well-established', 'well-established'), ('channel', 'channel'), ('model', 'model'), (',', ','), ('biological', 'biological'), ('communication', 'communication'), ('link', 'link'), (',', ','), ('relied', 'relied'), ('upon', 'upon'), ('insofar', 'insofar'), ('one', 'one'), ('trusts', 'trust'), ('available', 'available'), ('data', 'data'), ('representative', 'representative'), ('complete', 'complete'), ('set', 'set'), ('possible', 'possible'), ('realizations', 'realization'), ('problem', 'problem'), ('study', 'study'), ('.', '.')]



============================ Sentence 135 =============================

Alternatively, under an algorithm deficit, a physics-based model, if available, can be possibly used to carry out computer simulations and obtain numerical performance guarantees. 


>> Tokens are: 
 ['Alternatively', ',', 'algorithm', 'deficit', ',', 'physics-based', 'model', ',', 'available', ',', 'possibly', 'used', 'carry', 'computer', 'simulations', 'obtain', 'numerical', 'performance', 'guarantees', '.']

>> Bigrams are: 
 [('Alternatively', ','), (',', 'algorithm'), ('algorithm', 'deficit'), ('deficit', ','), (',', 'physics-based'), ('physics-based', 'model'), ('model', ','), (',', 'available'), ('available', ','), (',', 'possibly'), ('possibly', 'used'), ('used', 'carry'), ('carry', 'computer'), ('computer', 'simulations'), ('simulations', 'obtain'), ('obtain', 'numerical'), ('numerical', 'performance'), ('performance', 'guarantees'), ('guarantees', '.')]

>> Trigrams are: 
 [('Alternatively', ',', 'algorithm'), (',', 'algorithm', 'deficit'), ('algorithm', 'deficit', ','), ('deficit', ',', 'physics-based'), (',', 'physics-based', 'model'), ('physics-based', 'model', ','), ('model', ',', 'available'), (',', 'available', ','), ('available', ',', 'possibly'), (',', 'possibly', 'used'), ('possibly', 'used', 'carry'), ('used', 'carry', 'computer'), ('carry', 'computer', 'simulations'), ('computer', 'simulations', 'obtain'), ('simulations', 'obtain', 'numerical'), ('obtain', 'numerical', 'performance'), ('numerical', 'performance', 'guarantees'), ('performance', 'guarantees', '.')]

>> POS Tags are: 
 [('Alternatively', 'RB'), (',', ','), ('algorithm', 'JJ'), ('deficit', 'NN'), (',', ','), ('physics-based', 'JJ'), ('model', 'NN'), (',', ','), ('available', 'JJ'), (',', ','), ('possibly', 'RB'), ('used', 'VBD'), ('carry', 'NN'), ('computer', 'NN'), ('simulations', 'NNS'), ('obtain', 'VB'), ('numerical', 'JJ'), ('performance', 'NN'), ('guarantees', 'NNS'), ('.', '.')]

 (S
  Alternatively/RB
  ,/,
  (NP algorithm/JJ deficit/NN)
  ,/,
  (NP physics-based/JJ model/NN)
  ,/,
  available/JJ
  ,/,
  possibly/RB
  used/VBD
  (NP carry/NN computer/NN simulations/NNS)
  obtain/VB
  (NP numerical/JJ performance/NN guarantees/NNS)
  ./.) 


>> Noun Phrases are: 
 ['algorithm deficit', 'physics-based model', 'carry computer simulations', 'numerical performance guarantees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Alternatively', 'altern'), (',', ','), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-bas'), ('model', 'model'), (',', ','), ('available', 'avail'), (',', ','), ('possibly', 'possibl'), ('used', 'use'), ('carry', 'carri'), ('computer', 'comput'), ('simulations', 'simul'), ('obtain', 'obtain'), ('numerical', 'numer'), ('performance', 'perform'), ('guarantees', 'guarante'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Alternatively', 'altern'), (',', ','), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-bas'), ('model', 'model'), (',', ','), ('available', 'avail'), (',', ','), ('possibly', 'possibl'), ('used', 'use'), ('carry', 'carri'), ('computer', 'comput'), ('simulations', 'simul'), ('obtain', 'obtain'), ('numerical', 'numer'), ('performance', 'perform'), ('guarantees', 'guarante'), ('.', '.')]

>> Lemmatization: 
 [('Alternatively', 'Alternatively'), (',', ','), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('physics-based', 'physics-based'), ('model', 'model'), (',', ','), ('available', 'available'), (',', ','), ('possibly', 'possibly'), ('used', 'used'), ('carry', 'carry'), ('computer', 'computer'), ('simulations', 'simulation'), ('obtain', 'obtain'), ('numerical', 'numerical'), ('performance', 'performance'), ('guarantees', 'guarantee'), ('.', '.')]



============================ Sentence 136 =============================

In Sec. 


>> Tokens are: 
 ['In', 'Sec', '.']

>> Bigrams are: 
 [('In', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('In', 'Sec', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Sec', 'NNP'), ('.', '.')]

 (S In/IN (NP Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['Sec']

>> Named Entities are: 
 [('GPE', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 137 =============================

IV and Sec. 


>> Tokens are: 
 ['IV', 'Sec', '.']

>> Bigrams are: 
 [('IV', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('IV', 'Sec', '.')]

>> POS Tags are: 
 [('IV', 'NNP'), ('Sec', 'NNP'), ('.', '.')]

 (S (NP IV/NNP Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['IV Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IV', 'iv'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IV', 'iv'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('IV', 'IV'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 138 =============================

VI, we will provide some pointers to specific applications to supervised and unsupervised learning, respectively. 


>> Tokens are: 
 ['VI', ',', 'provide', 'pointers', 'specific', 'applications', 'supervised', 'unsupervised', 'learning', ',', 'respectively', '.']

>> Bigrams are: 
 [('VI', ','), (',', 'provide'), ('provide', 'pointers'), ('pointers', 'specific'), ('specific', 'applications'), ('applications', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('VI', ',', 'provide'), (',', 'provide', 'pointers'), ('provide', 'pointers', 'specific'), ('pointers', 'specific', 'applications'), ('specific', 'applications', 'supervised'), ('applications', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('VI', 'NNP'), (',', ','), ('provide', 'NN'), ('pointers', 'NNS'), ('specific', 'JJ'), ('applications', 'NNS'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('respectively', 'RB'), ('.', '.')]

 (S
  (NP VI/NNP)
  ,/,
  (NP provide/NN pointers/NNS)
  (NP specific/JJ applications/NNS)
  supervised/VBD
  (NP unsupervised/JJ learning/NN)
  ,/,
  respectively/RB
  ./.) 


>> Noun Phrases are: 
 ['VI', 'provide pointers', 'specific applications', 'unsupervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('VI', 'vi'), (',', ','), ('provide', 'provid'), ('pointers', 'pointer'), ('specific', 'specif'), ('applications', 'applic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('VI', 'vi'), (',', ','), ('provide', 'provid'), ('pointers', 'pointer'), ('specific', 'specif'), ('applications', 'applic'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('VI', 'VI'), (',', ','), ('provide', 'provide'), ('pointers', 'pointer'), ('specific', 'specific'), ('applications', 'application'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('respectively', 'respectively'), ('.', '.')]



============================ Sentence 139 =============================

III. 


>> Tokens are: 
 ['III', '.']

>> Bigrams are: 
 [('III', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('III', 'NNP'), ('.', '.')]

 (S (NP III/NNP) ./.) 


>> Noun Phrases are: 
 ['III']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('III', 'iii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III', 'iii'), ('.', '.')]

>> Lemmatization: 
 [('III', 'III'), ('.', '.')]



============================ Sentence 140 =============================

SUPERVISED LEARNING  As introduced in Sec. 


>> Tokens are: 
 ['SUPERVISED', 'LEARNING', 'As', 'introduced', 'Sec', '.']

>> Bigrams are: 
 [('SUPERVISED', 'LEARNING'), ('LEARNING', 'As'), ('As', 'introduced'), ('introduced', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('SUPERVISED', 'LEARNING', 'As'), ('LEARNING', 'As', 'introduced'), ('As', 'introduced', 'Sec'), ('introduced', 'Sec', '.')]

>> POS Tags are: 
 [('SUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('As', 'IN'), ('introduced', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  (NP SUPERVISED/NNP LEARNING/NNP)
  As/IN
  introduced/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['SUPERVISED LEARNING', 'Sec']

>> Named Entities are: 
 [('ORGANIZATION', 'SUPERVISED')] 

>> Stemming using Porter Stemmer: 
 [('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('As', 'as'), ('introduced', 'introduc'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('As', 'as'), ('introduced', 'introduc'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('SUPERVISED', 'SUPERVISED'), ('LEARNING', 'LEARNING'), ('As', 'As'), ('introduced', 'introduced'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 141 =============================

I, supervised learning aims at discovering patterns that relate inputs to outputs on the basis of a training set of input-output examples. 


>> Tokens are: 
 ['I', ',', 'supervised', 'learning', 'aims', 'discovering', 'patterns', 'relate', 'inputs', 'outputs', 'basis', 'training', 'set', 'input-output', 'examples', '.']

>> Bigrams are: 
 [('I', ','), (',', 'supervised'), ('supervised', 'learning'), ('learning', 'aims'), ('aims', 'discovering'), ('discovering', 'patterns'), ('patterns', 'relate'), ('relate', 'inputs'), ('inputs', 'outputs'), ('outputs', 'basis'), ('basis', 'training'), ('training', 'set'), ('set', 'input-output'), ('input-output', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('I', ',', 'supervised'), (',', 'supervised', 'learning'), ('supervised', 'learning', 'aims'), ('learning', 'aims', 'discovering'), ('aims', 'discovering', 'patterns'), ('discovering', 'patterns', 'relate'), ('patterns', 'relate', 'inputs'), ('relate', 'inputs', 'outputs'), ('inputs', 'outputs', 'basis'), ('outputs', 'basis', 'training'), ('basis', 'training', 'set'), ('training', 'set', 'input-output'), ('set', 'input-output', 'examples'), ('input-output', 'examples', '.')]

>> POS Tags are: 
 [('I', 'PRP'), (',', ','), ('supervised', 'VBD'), ('learning', 'VBG'), ('aims', 'NNS'), ('discovering', 'VBG'), ('patterns', 'NNS'), ('relate', 'VBP'), ('inputs', 'NNS'), ('outputs', 'JJ'), ('basis', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('input-output', 'JJ'), ('examples', 'NNS'), ('.', '.')]

 (S
  I/PRP
  ,/,
  supervised/VBD
  learning/VBG
  (NP aims/NNS)
  discovering/VBG
  (NP patterns/NNS)
  relate/VBP
  (NP inputs/NNS)
  (NP outputs/JJ basis/NN training/NN)
  set/VBN
  (NP input-output/JJ examples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['aims', 'patterns', 'inputs', 'outputs basis training', 'input-output examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), (',', ','), ('supervised', 'supervis'), ('learning', 'learn'), ('aims', 'aim'), ('discovering', 'discov'), ('patterns', 'pattern'), ('relate', 'relat'), ('inputs', 'input'), ('outputs', 'output'), ('basis', 'basi'), ('training', 'train'), ('set', 'set'), ('input-output', 'input-output'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), (',', ','), ('supervised', 'supervis'), ('learning', 'learn'), ('aims', 'aim'), ('discovering', 'discov'), ('patterns', 'pattern'), ('relate', 'relat'), ('inputs', 'input'), ('outputs', 'output'), ('basis', 'basi'), ('training', 'train'), ('set', 'set'), ('input-output', 'input-output'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), (',', ','), ('supervised', 'supervised'), ('learning', 'learning'), ('aims', 'aim'), ('discovering', 'discovering'), ('patterns', 'pattern'), ('relate', 'relate'), ('inputs', 'input'), ('outputs', 'output'), ('basis', 'basis'), ('training', 'training'), ('set', 'set'), ('input-output', 'input-output'), ('examples', 'example'), ('.', '.')]



============================ Sentence 142 =============================

We can distinguish two classes of supervised learning problems depending on whether the outputs are continuous or dis- crete variables. 


>> Tokens are: 
 ['We', 'distinguish', 'two', 'classes', 'supervised', 'learning', 'problems', 'depending', 'whether', 'outputs', 'continuous', 'dis-', 'crete', 'variables', '.']

>> Bigrams are: 
 [('We', 'distinguish'), ('distinguish', 'two'), ('two', 'classes'), ('classes', 'supervised'), ('supervised', 'learning'), ('learning', 'problems'), ('problems', 'depending'), ('depending', 'whether'), ('whether', 'outputs'), ('outputs', 'continuous'), ('continuous', 'dis-'), ('dis-', 'crete'), ('crete', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('We', 'distinguish', 'two'), ('distinguish', 'two', 'classes'), ('two', 'classes', 'supervised'), ('classes', 'supervised', 'learning'), ('supervised', 'learning', 'problems'), ('learning', 'problems', 'depending'), ('problems', 'depending', 'whether'), ('depending', 'whether', 'outputs'), ('whether', 'outputs', 'continuous'), ('outputs', 'continuous', 'dis-'), ('continuous', 'dis-', 'crete'), ('dis-', 'crete', 'variables'), ('crete', 'variables', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('distinguish', 'VBP'), ('two', 'CD'), ('classes', 'NNS'), ('supervised', 'VBD'), ('learning', 'VBG'), ('problems', 'NNS'), ('depending', 'VBG'), ('whether', 'IN'), ('outputs', 'NNS'), ('continuous', 'JJ'), ('dis-', 'JJ'), ('crete', 'NN'), ('variables', 'NNS'), ('.', '.')]

 (S
  We/PRP
  distinguish/VBP
  two/CD
  (NP classes/NNS)
  supervised/VBD
  learning/VBG
  (NP problems/NNS)
  depending/VBG
  whether/IN
  (NP outputs/NNS)
  (NP continuous/JJ dis-/JJ crete/NN variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['classes', 'problems', 'outputs', 'continuous dis- crete variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('distinguish', 'distinguish'), ('two', 'two'), ('classes', 'class'), ('supervised', 'supervis'), ('learning', 'learn'), ('problems', 'problem'), ('depending', 'depend'), ('whether', 'whether'), ('outputs', 'output'), ('continuous', 'continu'), ('dis-', 'dis-'), ('crete', 'crete'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('distinguish', 'distinguish'), ('two', 'two'), ('classes', 'class'), ('supervised', 'supervis'), ('learning', 'learn'), ('problems', 'problem'), ('depending', 'depend'), ('whether', 'whether'), ('outputs', 'output'), ('continuous', 'continu'), ('dis-', 'dis-'), ('crete', 'crete'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('distinguish', 'distinguish'), ('two', 'two'), ('classes', 'class'), ('supervised', 'supervised'), ('learning', 'learning'), ('problems', 'problem'), ('depending', 'depending'), ('whether', 'whether'), ('outputs', 'output'), ('continuous', 'continuous'), ('dis-', 'dis-'), ('crete', 'crete'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 143 =============================

In the former case, we have a regression problem, while in the latter we have a classification  0 0.2 0.4 0.6 0.8 1 -1.5  -1  -0.5  0  0.5  1  1.5  ? 


>> Tokens are: 
 ['In', 'former', 'case', ',', 'regression', 'problem', ',', 'latter', 'classification', '0', '0.2', '0.4', '0.6', '0.8', '1', '-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5', '?']

>> Bigrams are: 
 [('In', 'former'), ('former', 'case'), ('case', ','), (',', 'regression'), ('regression', 'problem'), ('problem', ','), (',', 'latter'), ('latter', 'classification'), ('classification', '0'), ('0', '0.2'), ('0.2', '0.4'), ('0.4', '0.6'), ('0.6', '0.8'), ('0.8', '1'), ('1', '-1.5'), ('-1.5', '-1'), ('-1', '-0.5'), ('-0.5', '0'), ('0', '0.5'), ('0.5', '1'), ('1', '1.5'), ('1.5', '?')]

>> Trigrams are: 
 [('In', 'former', 'case'), ('former', 'case', ','), ('case', ',', 'regression'), (',', 'regression', 'problem'), ('regression', 'problem', ','), ('problem', ',', 'latter'), (',', 'latter', 'classification'), ('latter', 'classification', '0'), ('classification', '0', '0.2'), ('0', '0.2', '0.4'), ('0.2', '0.4', '0.6'), ('0.4', '0.6', '0.8'), ('0.6', '0.8', '1'), ('0.8', '1', '-1.5'), ('1', '-1.5', '-1'), ('-1.5', '-1', '-0.5'), ('-1', '-0.5', '0'), ('-0.5', '0', '0.5'), ('0', '0.5', '1'), ('0.5', '1', '1.5'), ('1', '1.5', '?')]

>> POS Tags are: 
 [('In', 'IN'), ('former', 'JJ'), ('case', 'NN'), (',', ','), ('regression', 'NN'), ('problem', 'NN'), (',', ','), ('latter', 'JJR'), ('classification', 'NN'), ('0', 'CD'), ('0.2', 'CD'), ('0.4', 'CD'), ('0.6', 'CD'), ('0.8', 'CD'), ('1', 'CD'), ('-1.5', 'NN'), ('-1', 'NNP'), ('-0.5', 'VBD'), ('0', 'CD'), ('0.5', 'CD'), ('1', 'CD'), ('1.5', 'CD'), ('?', '.')]

 (S
  In/IN
  (NP former/JJ case/NN)
  ,/,
  (NP regression/NN problem/NN)
  ,/,
  latter/JJR
  (NP classification/NN)
  0/CD
  0.2/CD
  0.4/CD
  0.6/CD
  0.8/CD
  1/CD
  (NP -1.5/NN -1/NNP)
  -0.5/VBD
  0/CD
  0.5/CD
  1/CD
  1.5/CD
  ?/.) 


>> Noun Phrases are: 
 ['former case', 'regression problem', 'classification', '-1.5 -1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('former', 'former'), ('case', 'case'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('latter', 'latter'), ('classification', 'classif'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-1.5', '-1.5'), ('-1', '-1'), ('-0.5', '-0.5'), ('0', '0'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('former', 'former'), ('case', 'case'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('latter', 'latter'), ('classification', 'classif'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-1.5', '-1.5'), ('-1', '-1'), ('-0.5', '-0.5'), ('0', '0'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('?', '?')]

>> Lemmatization: 
 [('In', 'In'), ('former', 'former'), ('case', 'case'), (',', ','), ('regression', 'regression'), ('problem', 'problem'), (',', ','), ('latter', 'latter'), ('classification', 'classification'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-1.5', '-1.5'), ('-1', '-1'), ('-0.5', '-0.5'), ('0', '0'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('?', '?')]



============================ Sentence 144 =============================

Fig. 


>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

 (S (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]



============================ Sentence 145 =============================

5. 


>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

 (S 5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



============================ Sentence 146 =============================

Illustration of the supervised learning problem of regression: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x? 


>> Tokens are: 
 ['Illustration', 'supervised', 'learning', 'problem', 'regression', ':', 'Given', 'input-output', 'training', 'examples', '(', 'xn', ',', 'tn', ')', ',', 'n', '=', '1', ',', '...', ',', 'N', ',', 'predict', 'output', 'unobserved', 'value', 'input', 'x', '?']

>> Bigrams are: 
 [('Illustration', 'supervised'), ('supervised', 'learning'), ('learning', 'problem'), ('problem', 'regression'), ('regression', ':'), (':', 'Given'), ('Given', 'input-output'), ('input-output', 'training'), ('training', 'examples'), ('examples', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', ','), (',', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', ','), (',', 'predict'), ('predict', 'output'), ('output', 'unobserved'), ('unobserved', 'value'), ('value', 'input'), ('input', 'x'), ('x', '?')]

>> Trigrams are: 
 [('Illustration', 'supervised', 'learning'), ('supervised', 'learning', 'problem'), ('learning', 'problem', 'regression'), ('problem', 'regression', ':'), ('regression', ':', 'Given'), (':', 'Given', 'input-output'), ('Given', 'input-output', 'training'), ('input-output', 'training', 'examples'), ('training', 'examples', '('), ('examples', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', ','), (')', ',', 'n'), (',', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', ','), ('N', ',', 'predict'), (',', 'predict', 'output'), ('predict', 'output', 'unobserved'), ('output', 'unobserved', 'value'), ('unobserved', 'value', 'input'), ('value', 'input', 'x'), ('input', 'x', '?')]

>> POS Tags are: 
 [('Illustration', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('problem', 'NN'), ('regression', 'NN'), (':', ':'), ('Given', 'VBN'), ('input-output', 'JJ'), ('training', 'NN'), ('examples', 'NNS'), ('(', '('), ('xn', 'NN'), (',', ','), ('tn', 'NN'), (')', ')'), (',', ','), ('n', 'JJ'), ('=', 'NN'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), (',', ','), ('predict', 'NN'), ('output', 'NN'), ('unobserved', 'VBD'), ('value', 'NN'), ('input', 'NN'), ('x', 'NNP'), ('?', '.')]

 (S
  (NP Illustration/NN)
  supervised/VBD
  learning/VBG
  (NP problem/NN regression/NN)
  :/:
  Given/VBN
  (NP input-output/JJ training/NN examples/NNS)
  (/(
  (NP xn/NN)
  ,/,
  (NP tn/NN)
  )/)
  ,/,
  (NP n/JJ =/NN)
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  ,/,
  (NP predict/NN output/NN)
  unobserved/VBD
  (NP value/NN input/NN x/NNP)
  ?/.) 


>> Noun Phrases are: 
 ['Illustration', 'problem regression', 'input-output training examples', 'xn', 'tn', 'n =', 'N', 'predict output', 'value input x']

>> Named Entities are: 
 [('GPE', 'Illustration'), ('GPE', 'N')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('regression', 'regress'), (':', ':'), ('Given', 'given'), ('input-output', 'input-output'), ('training', 'train'), ('examples', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserv'), ('value', 'valu'), ('input', 'input'), ('x', 'x'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('regression', 'regress'), (':', ':'), ('Given', 'given'), ('input-output', 'input-output'), ('training', 'train'), ('examples', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserv'), ('value', 'valu'), ('input', 'input'), ('x', 'x'), ('?', '?')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('supervised', 'supervised'), ('learning', 'learning'), ('problem', 'problem'), ('regression', 'regression'), (':', ':'), ('Given', 'Given'), ('input-output', 'input-output'), ('training', 'training'), ('examples', 'example'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserved'), ('value', 'value'), ('input', 'input'), ('x', 'x'), ('?', '?')]



============================ Sentence 147 =============================

problem. 


>> Tokens are: 
 ['problem', '.']

>> Bigrams are: 
 [('problem', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('problem', 'NN'), ('.', '.')]

 (S (NP problem/NN) ./.) 


>> Noun Phrases are: 
 ['problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('problem', 'problem'), ('.', '.')]



============================ Sentence 148 =============================

We discuss the respective goals of the two problems next. 


>> Tokens are: 
 ['We', 'discuss', 'respective', 'goals', 'two', 'problems', 'next', '.']

>> Bigrams are: 
 [('We', 'discuss'), ('discuss', 'respective'), ('respective', 'goals'), ('goals', 'two'), ('two', 'problems'), ('problems', 'next'), ('next', '.')]

>> Trigrams are: 
 [('We', 'discuss', 'respective'), ('discuss', 'respective', 'goals'), ('respective', 'goals', 'two'), ('goals', 'two', 'problems'), ('two', 'problems', 'next'), ('problems', 'next', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('discuss', 'VBP'), ('respective', 'JJ'), ('goals', 'NNS'), ('two', 'CD'), ('problems', 'NNS'), ('next', 'IN'), ('.', '.')]

 (S
  We/PRP
  discuss/VBP
  (NP respective/JJ goals/NNS)
  two/CD
  (NP problems/NNS)
  next/IN
  ./.) 


>> Noun Phrases are: 
 ['respective goals', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('discuss', 'discuss'), ('respective', 'respect'), ('goals', 'goal'), ('two', 'two'), ('problems', 'problem'), ('next', 'next'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('discuss', 'discuss'), ('respective', 'respect'), ('goals', 'goal'), ('two', 'two'), ('problems', 'problem'), ('next', 'next'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('discuss', 'discus'), ('respective', 'respective'), ('goals', 'goal'), ('two', 'two'), ('problems', 'problem'), ('next', 'next'), ('.', '.')]



============================ Sentence 149 =============================

This is followed by a formal definition of classification and regression, and by a discussion of the methodology and of the main steps involved in tackling the two classes of problems. 


>> Tokens are: 
 ['This', 'followed', 'formal', 'definition', 'classification', 'regression', ',', 'discussion', 'methodology', 'main', 'steps', 'involved', 'tackling', 'two', 'classes', 'problems', '.']

>> Bigrams are: 
 [('This', 'followed'), ('followed', 'formal'), ('formal', 'definition'), ('definition', 'classification'), ('classification', 'regression'), ('regression', ','), (',', 'discussion'), ('discussion', 'methodology'), ('methodology', 'main'), ('main', 'steps'), ('steps', 'involved'), ('involved', 'tackling'), ('tackling', 'two'), ('two', 'classes'), ('classes', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('This', 'followed', 'formal'), ('followed', 'formal', 'definition'), ('formal', 'definition', 'classification'), ('definition', 'classification', 'regression'), ('classification', 'regression', ','), ('regression', ',', 'discussion'), (',', 'discussion', 'methodology'), ('discussion', 'methodology', 'main'), ('methodology', 'main', 'steps'), ('main', 'steps', 'involved'), ('steps', 'involved', 'tackling'), ('involved', 'tackling', 'two'), ('tackling', 'two', 'classes'), ('two', 'classes', 'problems'), ('classes', 'problems', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('followed', 'VBD'), ('formal', 'JJ'), ('definition', 'NN'), ('classification', 'NN'), ('regression', 'NN'), (',', ','), ('discussion', 'NN'), ('methodology', 'NN'), ('main', 'JJ'), ('steps', 'NNS'), ('involved', 'VBN'), ('tackling', 'VBG'), ('two', 'CD'), ('classes', 'NNS'), ('problems', 'NNS'), ('.', '.')]

 (S
  This/DT
  followed/VBD
  (NP formal/JJ definition/NN classification/NN regression/NN)
  ,/,
  (NP discussion/NN methodology/NN)
  (NP main/JJ steps/NNS)
  involved/VBN
  tackling/VBG
  two/CD
  (NP classes/NNS problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['formal definition classification regression', 'discussion methodology', 'main steps', 'classes problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('followed', 'follow'), ('formal', 'formal'), ('definition', 'definit'), ('classification', 'classif'), ('regression', 'regress'), (',', ','), ('discussion', 'discuss'), ('methodology', 'methodolog'), ('main', 'main'), ('steps', 'step'), ('involved', 'involv'), ('tackling', 'tackl'), ('two', 'two'), ('classes', 'class'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('followed', 'follow'), ('formal', 'formal'), ('definition', 'definit'), ('classification', 'classif'), ('regression', 'regress'), (',', ','), ('discussion', 'discuss'), ('methodology', 'methodolog'), ('main', 'main'), ('steps', 'step'), ('involved', 'involv'), ('tackling', 'tackl'), ('two', 'two'), ('classes', 'class'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('followed', 'followed'), ('formal', 'formal'), ('definition', 'definition'), ('classification', 'classification'), ('regression', 'regression'), (',', ','), ('discussion', 'discussion'), ('methodology', 'methodology'), ('main', 'main'), ('steps', 'step'), ('involved', 'involved'), ('tackling', 'tackling'), ('two', 'two'), ('classes', 'class'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 150 =============================

A. 


>> Tokens are: 
 ['A', '.']

>> Bigrams are: 
 [('A', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('.', '.')]

 (S A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('.', '.')]



============================ Sentence 151 =============================

Goals  As illustrated in Fig. 


>> Tokens are: 
 ['Goals', 'As', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('Goals', 'As'), ('As', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Goals', 'As', 'illustrated'), ('As', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('Goals', 'NNS'), ('As', 'IN'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S (NP Goals/NNS) As/IN (NP illustrated/JJ Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Goals', 'illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Goals', 'goal'), ('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Goals', 'goal'), ('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Goals', 'Goals'), ('As', 'As'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 152 =============================

5, in a regression problem, we are given a training set D of N training points (xn, tn), with n = 1, ..., N , where the variables xn are the inputs, also known as covariates, domain points, or explanatory variables; while the variables tn are the outputs, also known as dependent variables, labels, or responses. 


>> Tokens are: 
 ['5', ',', 'regression', 'problem', ',', 'given', 'training', 'set', 'D', 'N', 'training', 'points', '(', 'xn', ',', 'tn', ')', ',', 'n', '=', '1', ',', '...', ',', 'N', ',', 'variables', 'xn', 'inputs', ',', 'also', 'known', 'covariates', ',', 'domain', 'points', ',', 'explanatory', 'variables', ';', 'variables', 'tn', 'outputs', ',', 'also', 'known', 'dependent', 'variables', ',', 'labels', ',', 'responses', '.']

>> Bigrams are: 
 [('5', ','), (',', 'regression'), ('regression', 'problem'), ('problem', ','), (',', 'given'), ('given', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'N'), ('N', 'training'), ('training', 'points'), ('points', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', ','), (',', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', ','), (',', 'variables'), ('variables', 'xn'), ('xn', 'inputs'), ('inputs', ','), (',', 'also'), ('also', 'known'), ('known', 'covariates'), ('covariates', ','), (',', 'domain'), ('domain', 'points'), ('points', ','), (',', 'explanatory'), ('explanatory', 'variables'), ('variables', ';'), (';', 'variables'), ('variables', 'tn'), ('tn', 'outputs'), ('outputs', ','), (',', 'also'), ('also', 'known'), ('known', 'dependent'), ('dependent', 'variables'), ('variables', ','), (',', 'labels'), ('labels', ','), (',', 'responses'), ('responses', '.')]

>> Trigrams are: 
 [('5', ',', 'regression'), (',', 'regression', 'problem'), ('regression', 'problem', ','), ('problem', ',', 'given'), (',', 'given', 'training'), ('given', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'N'), ('D', 'N', 'training'), ('N', 'training', 'points'), ('training', 'points', '('), ('points', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', ','), (')', ',', 'n'), (',', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', ','), ('N', ',', 'variables'), (',', 'variables', 'xn'), ('variables', 'xn', 'inputs'), ('xn', 'inputs', ','), ('inputs', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'covariates'), ('known', 'covariates', ','), ('covariates', ',', 'domain'), (',', 'domain', 'points'), ('domain', 'points', ','), ('points', ',', 'explanatory'), (',', 'explanatory', 'variables'), ('explanatory', 'variables', ';'), ('variables', ';', 'variables'), (';', 'variables', 'tn'), ('variables', 'tn', 'outputs'), ('tn', 'outputs', ','), ('outputs', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'dependent'), ('known', 'dependent', 'variables'), ('dependent', 'variables', ','), ('variables', ',', 'labels'), (',', 'labels', ','), ('labels', ',', 'responses'), (',', 'responses', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('regression', 'NN'), ('problem', 'NN'), (',', ','), ('given', 'VBN'), ('training', 'NN'), ('set', 'VBN'), ('D', 'NNP'), ('N', 'NNP'), ('training', 'NN'), ('points', 'NNS'), ('(', '('), ('xn', 'NN'), (',', ','), ('tn', 'NN'), (')', ')'), (',', ','), ('n', 'JJ'), ('=', 'NN'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), (',', ','), ('variables', 'VBZ'), ('xn', 'NNP'), ('inputs', 'NNS'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('covariates', 'NNS'), (',', ','), ('domain', 'NN'), ('points', 'NNS'), (',', ','), ('explanatory', 'JJ'), ('variables', 'NNS'), (';', ':'), ('variables', 'NNS'), ('tn', 'VBP'), ('outputs', 'NNS'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('dependent', 'JJ'), ('variables', 'NNS'), (',', ','), ('labels', 'NNS'), (',', ','), ('responses', 'NNS'), ('.', '.')]

 (S
  5/CD
  ,/,
  (NP regression/NN problem/NN)
  ,/,
  given/VBN
  (NP training/NN)
  set/VBN
  (NP D/NNP N/NNP training/NN points/NNS)
  (/(
  (NP xn/NN)
  ,/,
  (NP tn/NN)
  )/)
  ,/,
  (NP n/JJ =/NN)
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  ,/,
  variables/VBZ
  (NP xn/NNP inputs/NNS)
  ,/,
  also/RB
  known/VBN
  (NP covariates/NNS)
  ,/,
  (NP domain/NN points/NNS)
  ,/,
  (NP explanatory/JJ variables/NNS)
  ;/:
  (NP variables/NNS)
  tn/VBP
  (NP outputs/NNS)
  ,/,
  also/RB
  known/VBN
  (NP dependent/JJ variables/NNS)
  ,/,
  (NP labels/NNS)
  ,/,
  (NP responses/NNS)
  ./.) 


>> Noun Phrases are: 
 ['regression problem', 'training', 'D N training points', 'xn', 'tn', 'n =', 'N', 'xn inputs', 'covariates', 'domain points', 'explanatory variables', 'variables', 'outputs', 'dependent variables', 'labels', 'responses']

>> Named Entities are: 
 [('PERSON', 'D N'), ('GPE', 'N')] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('given', 'given'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('N', 'n'), ('training', 'train'), ('points', 'point'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('variables', 'variabl'), ('xn', 'xn'), ('inputs', 'input'), (',', ','), ('also', 'also'), ('known', 'known'), ('covariates', 'covari'), (',', ','), ('domain', 'domain'), ('points', 'point'), (',', ','), ('explanatory', 'explanatori'), ('variables', 'variabl'), (';', ';'), ('variables', 'variabl'), ('tn', 'tn'), ('outputs', 'output'), (',', ','), ('also', 'also'), ('known', 'known'), ('dependent', 'depend'), ('variables', 'variabl'), (',', ','), ('labels', 'label'), (',', ','), ('responses', 'respons'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('given', 'given'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('N', 'n'), ('training', 'train'), ('points', 'point'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('variables', 'variabl'), ('xn', 'xn'), ('inputs', 'input'), (',', ','), ('also', 'also'), ('known', 'known'), ('covariates', 'covari'), (',', ','), ('domain', 'domain'), ('points', 'point'), (',', ','), ('explanatory', 'explanatori'), ('variables', 'variabl'), (';', ';'), ('variables', 'variabl'), ('tn', 'tn'), ('outputs', 'output'), (',', ','), ('also', 'also'), ('known', 'known'), ('dependent', 'depend'), ('variables', 'variabl'), (',', ','), ('labels', 'label'), (',', ','), ('responses', 'respons'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('regression', 'regression'), ('problem', 'problem'), (',', ','), ('given', 'given'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('N', 'N'), ('training', 'training'), ('points', 'point'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), (',', ','), ('variables', 'variable'), ('xn', 'xn'), ('inputs', 'input'), (',', ','), ('also', 'also'), ('known', 'known'), ('covariates', 'covariates'), (',', ','), ('domain', 'domain'), ('points', 'point'), (',', ','), ('explanatory', 'explanatory'), ('variables', 'variable'), (';', ';'), ('variables', 'variable'), ('tn', 'tn'), ('outputs', 'output'), (',', ','), ('also', 'also'), ('known', 'known'), ('dependent', 'dependent'), ('variables', 'variable'), (',', ','), ('labels', 'label'), (',', ','), ('responses', 'response'), ('.', '.')]



============================ Sentence 153 =============================

In regression, the outputs are continuous variables. 


>> Tokens are: 
 ['In', 'regression', ',', 'outputs', 'continuous', 'variables', '.']

>> Bigrams are: 
 [('In', 'regression'), ('regression', ','), (',', 'outputs'), ('outputs', 'continuous'), ('continuous', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('In', 'regression', ','), ('regression', ',', 'outputs'), (',', 'outputs', 'continuous'), ('outputs', 'continuous', 'variables'), ('continuous', 'variables', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('regression', 'NN'), (',', ','), ('outputs', 'VBZ'), ('continuous', 'JJ'), ('variables', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP regression/NN)
  ,/,
  outputs/VBZ
  (NP continuous/JJ variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['regression', 'continuous variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('regression', 'regress'), (',', ','), ('outputs', 'output'), ('continuous', 'continu'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('regression', 'regress'), (',', ','), ('outputs', 'output'), ('continuous', 'continu'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('regression', 'regression'), (',', ','), ('outputs', 'output'), ('continuous', 'continuous'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 154 =============================

The problem is to predict the output t for a new, that is, as of yet unobserved, input x. 


>> Tokens are: 
 ['The', 'problem', 'predict', 'output', 'new', ',', ',', 'yet', 'unobserved', ',', 'input', 'x', '.']

>> Bigrams are: 
 [('The', 'problem'), ('problem', 'predict'), ('predict', 'output'), ('output', 'new'), ('new', ','), (',', ','), (',', 'yet'), ('yet', 'unobserved'), ('unobserved', ','), (',', 'input'), ('input', 'x'), ('x', '.')]

>> Trigrams are: 
 [('The', 'problem', 'predict'), ('problem', 'predict', 'output'), ('predict', 'output', 'new'), ('output', 'new', ','), ('new', ',', ','), (',', ',', 'yet'), (',', 'yet', 'unobserved'), ('yet', 'unobserved', ','), ('unobserved', ',', 'input'), (',', 'input', 'x'), ('input', 'x', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('problem', 'NN'), ('predict', 'NN'), ('output', 'NN'), ('new', 'JJ'), (',', ','), (',', ','), ('yet', 'RB'), ('unobserved', 'VBN'), (',', ','), ('input', 'VB'), ('x', 'NNP'), ('.', '.')]

 (S
  (NP The/DT problem/NN predict/NN output/NN)
  new/JJ
  ,/,
  ,/,
  yet/RB
  unobserved/VBN
  ,/,
  input/VB
  (NP x/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The problem predict output', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('predict', 'predict'), ('output', 'output'), ('new', 'new'), (',', ','), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserv'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('predict', 'predict'), ('output', 'output'), ('new', 'new'), (',', ','), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserv'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('problem', 'problem'), ('predict', 'predict'), ('output', 'output'), ('new', 'new'), (',', ','), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserved'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]



============================ Sentence 155 =============================

As illustrated in Fig. 


>> Tokens are: 
 ['As', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('As', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN (NP illustrated/JJ Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 156 =============================

6, classification is similarly defined with the only caveat that the outputs t are discrete  5    4 5 6 7 8 9 0.5  1  1.5  2  2.5  3  3.5  4  4.5  ? 


>> Tokens are: 
 ['6', ',', 'classification', 'similarly', 'defined', 'caveat', 'outputs', 'discrete', '5', '4', '5', '6', '7', '8', '9', '0.5', '1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '?']

>> Bigrams are: 
 [('6', ','), (',', 'classification'), ('classification', 'similarly'), ('similarly', 'defined'), ('defined', 'caveat'), ('caveat', 'outputs'), ('outputs', 'discrete'), ('discrete', '5'), ('5', '4'), ('4', '5'), ('5', '6'), ('6', '7'), ('7', '8'), ('8', '9'), ('9', '0.5'), ('0.5', '1'), ('1', '1.5'), ('1.5', '2'), ('2', '2.5'), ('2.5', '3'), ('3', '3.5'), ('3.5', '4'), ('4', '4.5'), ('4.5', '?')]

>> Trigrams are: 
 [('6', ',', 'classification'), (',', 'classification', 'similarly'), ('classification', 'similarly', 'defined'), ('similarly', 'defined', 'caveat'), ('defined', 'caveat', 'outputs'), ('caveat', 'outputs', 'discrete'), ('outputs', 'discrete', '5'), ('discrete', '5', '4'), ('5', '4', '5'), ('4', '5', '6'), ('5', '6', '7'), ('6', '7', '8'), ('7', '8', '9'), ('8', '9', '0.5'), ('9', '0.5', '1'), ('0.5', '1', '1.5'), ('1', '1.5', '2'), ('1.5', '2', '2.5'), ('2', '2.5', '3'), ('2.5', '3', '3.5'), ('3', '3.5', '4'), ('3.5', '4', '4.5'), ('4', '4.5', '?')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('classification', 'NN'), ('similarly', 'RB'), ('defined', 'VBD'), ('caveat', 'NN'), ('outputs', 'NNS'), ('discrete', 'VBP'), ('5', 'CD'), ('4', 'CD'), ('5', 'CD'), ('6', 'CD'), ('7', 'CD'), ('8', 'CD'), ('9', 'CD'), ('0.5', 'CD'), ('1', 'CD'), ('1.5', 'CD'), ('2', 'CD'), ('2.5', 'CD'), ('3', 'CD'), ('3.5', 'CD'), ('4', 'CD'), ('4.5', 'CD'), ('?', '.')]

 (S
  6/CD
  ,/,
  (NP classification/NN)
  similarly/RB
  defined/VBD
  (NP caveat/NN outputs/NNS)
  discrete/VBP
  5/CD
  4/CD
  5/CD
  6/CD
  7/CD
  8/CD
  9/CD
  0.5/CD
  1/CD
  1.5/CD
  2/CD
  2.5/CD
  3/CD
  3.5/CD
  4/CD
  4.5/CD
  ?/.) 


>> Noun Phrases are: 
 ['classification', 'caveat outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('classification', 'classif'), ('similarly', 'similarli'), ('defined', 'defin'), ('caveat', 'caveat'), ('outputs', 'output'), ('discrete', 'discret'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('2', '2'), ('2.5', '2.5'), ('3', '3'), ('3.5', '3.5'), ('4', '4'), ('4.5', '4.5'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('classification', 'classif'), ('similarly', 'similar'), ('defined', 'defin'), ('caveat', 'caveat'), ('outputs', 'output'), ('discrete', 'discret'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('2', '2'), ('2.5', '2.5'), ('3', '3'), ('3.5', '3.5'), ('4', '4'), ('4.5', '4.5'), ('?', '?')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('classification', 'classification'), ('similarly', 'similarly'), ('defined', 'defined'), ('caveat', 'caveat'), ('outputs', 'output'), ('discrete', 'discrete'), ('5', '5'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0.5', '0.5'), ('1', '1'), ('1.5', '1.5'), ('2', '2'), ('2.5', '2.5'), ('3', '3'), ('3.5', '3.5'), ('4', '4'), ('4.5', '4.5'), ('?', '?')]



============================ Sentence 157 =============================

Fig. 


>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

 (S (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]



============================ Sentence 158 =============================

6. 


>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

 (S 6/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]



============================ Sentence 159 =============================

Illustration of the supervised learning problem of classi- fication: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x? 


>> Tokens are: 
 ['Illustration', 'supervised', 'learning', 'problem', 'classi-', 'fication', ':', 'Given', 'input-output', 'training', 'examples', '(', 'xn', ',', 'tn', ')', ',', 'n', '=', '1', ',', '...', ',', 'N', ',', 'predict', 'output', 'unobserved', 'value', 'input', 'x', '?']

>> Bigrams are: 
 [('Illustration', 'supervised'), ('supervised', 'learning'), ('learning', 'problem'), ('problem', 'classi-'), ('classi-', 'fication'), ('fication', ':'), (':', 'Given'), ('Given', 'input-output'), ('input-output', 'training'), ('training', 'examples'), ('examples', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', ','), (',', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', ','), (',', 'predict'), ('predict', 'output'), ('output', 'unobserved'), ('unobserved', 'value'), ('value', 'input'), ('input', 'x'), ('x', '?')]

>> Trigrams are: 
 [('Illustration', 'supervised', 'learning'), ('supervised', 'learning', 'problem'), ('learning', 'problem', 'classi-'), ('problem', 'classi-', 'fication'), ('classi-', 'fication', ':'), ('fication', ':', 'Given'), (':', 'Given', 'input-output'), ('Given', 'input-output', 'training'), ('input-output', 'training', 'examples'), ('training', 'examples', '('), ('examples', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', ','), (')', ',', 'n'), (',', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', ','), ('N', ',', 'predict'), (',', 'predict', 'output'), ('predict', 'output', 'unobserved'), ('output', 'unobserved', 'value'), ('unobserved', 'value', 'input'), ('value', 'input', 'x'), ('input', 'x', '?')]

>> POS Tags are: 
 [('Illustration', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('problem', 'NN'), ('classi-', 'JJ'), ('fication', 'NN'), (':', ':'), ('Given', 'VBN'), ('input-output', 'JJ'), ('training', 'NN'), ('examples', 'NNS'), ('(', '('), ('xn', 'NN'), (',', ','), ('tn', 'NN'), (')', ')'), (',', ','), ('n', 'JJ'), ('=', 'NN'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), (',', ','), ('predict', 'NN'), ('output', 'NN'), ('unobserved', 'VBD'), ('value', 'NN'), ('input', 'NN'), ('x', 'NNP'), ('?', '.')]

 (S
  (NP Illustration/NN)
  supervised/VBD
  learning/VBG
  (NP problem/NN)
  (NP classi-/JJ fication/NN)
  :/:
  Given/VBN
  (NP input-output/JJ training/NN examples/NNS)
  (/(
  (NP xn/NN)
  ,/,
  (NP tn/NN)
  )/)
  ,/,
  (NP n/JJ =/NN)
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  ,/,
  (NP predict/NN output/NN)
  unobserved/VBD
  (NP value/NN input/NN x/NNP)
  ?/.) 


>> Noun Phrases are: 
 ['Illustration', 'problem', 'classi- fication', 'input-output training examples', 'xn', 'tn', 'n =', 'N', 'predict output', 'value input x']

>> Named Entities are: 
 [('GPE', 'Illustration'), ('GPE', 'N')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('classi-', 'classi-'), ('fication', 'ficat'), (':', ':'), ('Given', 'given'), ('input-output', 'input-output'), ('training', 'train'), ('examples', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserv'), ('value', 'valu'), ('input', 'input'), ('x', 'x'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('classi-', 'classi-'), ('fication', 'ficat'), (':', ':'), ('Given', 'given'), ('input-output', 'input-output'), ('training', 'train'), ('examples', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserv'), ('value', 'valu'), ('input', 'input'), ('x', 'x'), ('?', '?')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('supervised', 'supervised'), ('learning', 'learning'), ('problem', 'problem'), ('classi-', 'classi-'), ('fication', 'fication'), (':', ':'), ('Given', 'Given'), ('input-output', 'input-output'), ('training', 'training'), ('examples', 'example'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), (',', ','), ('predict', 'predict'), ('output', 'output'), ('unobserved', 'unobserved'), ('value', 'value'), ('input', 'input'), ('x', 'x'), ('?', '?')]



============================ Sentence 160 =============================

variables that take a finite number of possible values. 


>> Tokens are: 
 ['variables', 'take', 'finite', 'number', 'possible', 'values', '.']

>> Bigrams are: 
 [('variables', 'take'), ('take', 'finite'), ('finite', 'number'), ('number', 'possible'), ('possible', 'values'), ('values', '.')]

>> Trigrams are: 
 [('variables', 'take', 'finite'), ('take', 'finite', 'number'), ('finite', 'number', 'possible'), ('number', 'possible', 'values'), ('possible', 'values', '.')]

>> POS Tags are: 
 [('variables', 'NNS'), ('take', 'VBP'), ('finite', 'JJ'), ('number', 'NN'), ('possible', 'JJ'), ('values', 'NNS'), ('.', '.')]

 (S
  (NP variables/NNS)
  take/VBP
  (NP finite/JJ number/NN)
  (NP possible/JJ values/NNS)
  ./.) 


>> Noun Phrases are: 
 ['variables', 'finite number', 'possible values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variables', 'variabl'), ('take', 'take'), ('finite', 'finit'), ('number', 'number'), ('possible', 'possibl'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('variables', 'variabl'), ('take', 'take'), ('finite', 'finit'), ('number', 'number'), ('possible', 'possibl'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('variables', 'variable'), ('take', 'take'), ('finite', 'finite'), ('number', 'number'), ('possible', 'possible'), ('values', 'value'), ('.', '.')]



============================ Sentence 161 =============================

The value of the output t for a given input x indicates the class to which x belongs. 


>> Tokens are: 
 ['The', 'value', 'output', 'given', 'input', 'x', 'indicates', 'class', 'x', 'belongs', '.']

>> Bigrams are: 
 [('The', 'value'), ('value', 'output'), ('output', 'given'), ('given', 'input'), ('input', 'x'), ('x', 'indicates'), ('indicates', 'class'), ('class', 'x'), ('x', 'belongs'), ('belongs', '.')]

>> Trigrams are: 
 [('The', 'value', 'output'), ('value', 'output', 'given'), ('output', 'given', 'input'), ('given', 'input', 'x'), ('input', 'x', 'indicates'), ('x', 'indicates', 'class'), ('indicates', 'class', 'x'), ('class', 'x', 'belongs'), ('x', 'belongs', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('value', 'NN'), ('output', 'NN'), ('given', 'VBN'), ('input', 'JJ'), ('x', 'NNP'), ('indicates', 'VBZ'), ('class', 'NN'), ('x', 'JJ'), ('belongs', 'NNS'), ('.', '.')]

 (S
  (NP The/DT value/NN output/NN)
  given/VBN
  (NP input/JJ x/NNP)
  indicates/VBZ
  (NP class/NN)
  (NP x/JJ belongs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The value output', 'input x', 'class', 'x belongs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('value', 'valu'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('x', 'x'), ('indicates', 'indic'), ('class', 'class'), ('x', 'x'), ('belongs', 'belong'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('value', 'valu'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('x', 'x'), ('indicates', 'indic'), ('class', 'class'), ('x', 'x'), ('belongs', 'belong'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('value', 'value'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('x', 'x'), ('indicates', 'indicates'), ('class', 'class'), ('x', 'x'), ('belongs', 'belongs'), ('.', '.')]



============================ Sentence 162 =============================

For instance, the label t is a binary variable as in Fig. 


>> Tokens are: 
 ['For', 'instance', ',', 'label', 'binary', 'variable', 'Fig', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'label'), ('label', 'binary'), ('binary', 'variable'), ('variable', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'label'), (',', 'label', 'binary'), ('label', 'binary', 'variable'), ('binary', 'variable', 'Fig'), ('variable', 'Fig', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('label', 'JJ'), ('binary', 'NN'), ('variable', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN)
  ,/,
  (NP label/JJ binary/NN)
  (NP variable/JJ Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'label binary', 'variable Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('label', 'label'), ('binary', 'binari'), ('variable', 'variabl'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('label', 'label'), ('binary', 'binari'), ('variable', 'variabl'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('label', 'label'), ('binary', 'binary'), ('variable', 'variable'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 163 =============================

6 for a binary classification problem. 


>> Tokens are: 
 ['6', 'binary', 'classification', 'problem', '.']

>> Bigrams are: 
 [('6', 'binary'), ('binary', 'classification'), ('classification', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('6', 'binary', 'classification'), ('binary', 'classification', 'problem'), ('classification', 'problem', '.')]

>> POS Tags are: 
 [('6', 'CD'), ('binary', 'JJ'), ('classification', 'NN'), ('problem', 'NN'), ('.', '.')]

 (S 6/CD (NP binary/JJ classification/NN problem/NN) ./.) 


>> Noun Phrases are: 
 ['binary classification problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('binary', 'binary'), ('classification', 'classification'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 164 =============================

Based on the training set D, the goal is to predict the label, or the class, t for a new, as of yet unobserved, input x. 


>> Tokens are: 
 ['Based', 'training', 'set', 'D', ',', 'goal', 'predict', 'label', ',', 'class', ',', 'new', ',', 'yet', 'unobserved', ',', 'input', 'x', '.']

>> Bigrams are: 
 [('Based', 'training'), ('training', 'set'), ('set', 'D'), ('D', ','), (',', 'goal'), ('goal', 'predict'), ('predict', 'label'), ('label', ','), (',', 'class'), ('class', ','), (',', 'new'), ('new', ','), (',', 'yet'), ('yet', 'unobserved'), ('unobserved', ','), (',', 'input'), ('input', 'x'), ('x', '.')]

>> Trigrams are: 
 [('Based', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', ','), ('D', ',', 'goal'), (',', 'goal', 'predict'), ('goal', 'predict', 'label'), ('predict', 'label', ','), ('label', ',', 'class'), (',', 'class', ','), ('class', ',', 'new'), (',', 'new', ','), ('new', ',', 'yet'), (',', 'yet', 'unobserved'), ('yet', 'unobserved', ','), ('unobserved', ',', 'input'), (',', 'input', 'x'), ('input', 'x', '.')]

>> POS Tags are: 
 [('Based', 'JJ'), ('training', 'NN'), ('set', 'VBN'), ('D', 'NNP'), (',', ','), ('goal', 'NN'), ('predict', 'NN'), ('label', 'NN'), (',', ','), ('class', 'NN'), (',', ','), ('new', 'JJ'), (',', ','), ('yet', 'RB'), ('unobserved', 'VBN'), (',', ','), ('input', 'VB'), ('x', 'NNP'), ('.', '.')]

 (S
  (NP Based/JJ training/NN)
  set/VBN
  (NP D/NNP)
  ,/,
  (NP goal/NN predict/NN label/NN)
  ,/,
  (NP class/NN)
  ,/,
  new/JJ
  ,/,
  yet/RB
  unobserved/VBN
  ,/,
  input/VB
  (NP x/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Based training', 'D', 'goal predict label', 'class', 'x']

>> Named Entities are: 
 [('GPE', 'Based'), ('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('training', 'train'), ('set', 'set'), ('D', 'd'), (',', ','), ('goal', 'goal'), ('predict', 'predict'), ('label', 'label'), (',', ','), ('class', 'class'), (',', ','), ('new', 'new'), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserv'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('training', 'train'), ('set', 'set'), ('D', 'd'), (',', ','), ('goal', 'goal'), ('predict', 'predict'), ('label', 'label'), (',', ','), ('class', 'class'), (',', ','), ('new', 'new'), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserv'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Based', 'Based'), ('training', 'training'), ('set', 'set'), ('D', 'D'), (',', ','), ('goal', 'goal'), ('predict', 'predict'), ('label', 'label'), (',', ','), ('class', 'class'), (',', ','), ('new', 'new'), (',', ','), ('yet', 'yet'), ('unobserved', 'unobserved'), (',', ','), ('input', 'input'), ('x', 'x'), ('.', '.')]



============================ Sentence 165 =============================

To sum up, the goal of both regression and clas- sification is to derive from the training data set D a predictor t̂(x) that generalizes the input-output mapping in D to inputs x that are not present in D. As such, learning is markedly distinct from memorizing: while memorizing would require producing a value tn for some recorded input xn in the training set, learning is about generalization from the data set to the rest of the relevant input space. 


>> Tokens are: 
 ['To', 'sum', ',', 'goal', 'regression', 'clas-', 'sification', 'derive', 'training', 'data', 'set', 'D', 'predictor', 't̂', '(', 'x', ')', 'generalizes', 'input-output', 'mapping', 'D', 'inputs', 'x', 'present', 'D.', 'As', ',', 'learning', 'markedly', 'distinct', 'memorizing', ':', 'memorizing', 'would', 'require', 'producing', 'value', 'tn', 'recorded', 'input', 'xn', 'training', 'set', ',', 'learning', 'generalization', 'data', 'set', 'rest', 'relevant', 'input', 'space', '.']

>> Bigrams are: 
 [('To', 'sum'), ('sum', ','), (',', 'goal'), ('goal', 'regression'), ('regression', 'clas-'), ('clas-', 'sification'), ('sification', 'derive'), ('derive', 'training'), ('training', 'data'), ('data', 'set'), ('set', 'D'), ('D', 'predictor'), ('predictor', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', 'generalizes'), ('generalizes', 'input-output'), ('input-output', 'mapping'), ('mapping', 'D'), ('D', 'inputs'), ('inputs', 'x'), ('x', 'present'), ('present', 'D.'), ('D.', 'As'), ('As', ','), (',', 'learning'), ('learning', 'markedly'), ('markedly', 'distinct'), ('distinct', 'memorizing'), ('memorizing', ':'), (':', 'memorizing'), ('memorizing', 'would'), ('would', 'require'), ('require', 'producing'), ('producing', 'value'), ('value', 'tn'), ('tn', 'recorded'), ('recorded', 'input'), ('input', 'xn'), ('xn', 'training'), ('training', 'set'), ('set', ','), (',', 'learning'), ('learning', 'generalization'), ('generalization', 'data'), ('data', 'set'), ('set', 'rest'), ('rest', 'relevant'), ('relevant', 'input'), ('input', 'space'), ('space', '.')]

>> Trigrams are: 
 [('To', 'sum', ','), ('sum', ',', 'goal'), (',', 'goal', 'regression'), ('goal', 'regression', 'clas-'), ('regression', 'clas-', 'sification'), ('clas-', 'sification', 'derive'), ('sification', 'derive', 'training'), ('derive', 'training', 'data'), ('training', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', 'predictor'), ('D', 'predictor', 't̂'), ('predictor', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'generalizes'), (')', 'generalizes', 'input-output'), ('generalizes', 'input-output', 'mapping'), ('input-output', 'mapping', 'D'), ('mapping', 'D', 'inputs'), ('D', 'inputs', 'x'), ('inputs', 'x', 'present'), ('x', 'present', 'D.'), ('present', 'D.', 'As'), ('D.', 'As', ','), ('As', ',', 'learning'), (',', 'learning', 'markedly'), ('learning', 'markedly', 'distinct'), ('markedly', 'distinct', 'memorizing'), ('distinct', 'memorizing', ':'), ('memorizing', ':', 'memorizing'), (':', 'memorizing', 'would'), ('memorizing', 'would', 'require'), ('would', 'require', 'producing'), ('require', 'producing', 'value'), ('producing', 'value', 'tn'), ('value', 'tn', 'recorded'), ('tn', 'recorded', 'input'), ('recorded', 'input', 'xn'), ('input', 'xn', 'training'), ('xn', 'training', 'set'), ('training', 'set', ','), ('set', ',', 'learning'), (',', 'learning', 'generalization'), ('learning', 'generalization', 'data'), ('generalization', 'data', 'set'), ('data', 'set', 'rest'), ('set', 'rest', 'relevant'), ('rest', 'relevant', 'input'), ('relevant', 'input', 'space'), ('input', 'space', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('sum', 'VB'), (',', ','), ('goal', 'NN'), ('regression', 'NN'), ('clas-', 'JJ'), ('sification', 'NN'), ('derive', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), ('predictor', 'NN'), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('generalizes', 'VBZ'), ('input-output', 'JJ'), ('mapping', 'NN'), ('D', 'NNP'), ('inputs', 'VBZ'), ('x', 'JJ'), ('present', 'JJ'), ('D.', 'NNP'), ('As', 'NNP'), (',', ','), ('learning', 'VBG'), ('markedly', 'RB'), ('distinct', 'JJ'), ('memorizing', 'NN'), (':', ':'), ('memorizing', 'NN'), ('would', 'MD'), ('require', 'VB'), ('producing', 'VBG'), ('value', 'NN'), ('tn', 'NN'), ('recorded', 'VBD'), ('input', 'NN'), ('xn', 'RB'), ('training', 'NN'), ('set', 'NN'), (',', ','), ('learning', 'VBG'), ('generalization', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('rest', 'NN'), ('relevant', 'NN'), ('input', 'VBD'), ('space', 'NN'), ('.', '.')]

 (S
  To/TO
  sum/VB
  ,/,
  (NP goal/NN regression/NN)
  (NP clas-/JJ sification/NN)
  (NP derive/JJ training/NN data/NNS)
  set/VBD
  (NP D/NNP predictor/NN t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  generalizes/VBZ
  (NP input-output/JJ mapping/NN D/NNP)
  inputs/VBZ
  (NP x/JJ present/JJ D./NNP As/NNP)
  ,/,
  learning/VBG
  markedly/RB
  (NP distinct/JJ memorizing/NN)
  :/:
  (NP memorizing/NN)
  would/MD
  require/VB
  producing/VBG
  (NP value/NN tn/NN)
  recorded/VBD
  (NP input/NN)
  xn/RB
  (NP training/NN set/NN)
  ,/,
  learning/VBG
  (NP generalization/NN data/NNS)
  set/VBD
  (NP rest/NN relevant/NN)
  input/VBD
  (NP space/NN)
  ./.) 


>> Noun Phrases are: 
 ['goal regression', 'clas- sification', 'derive training data', 'D predictor t̂', 'x', 'input-output mapping D', 'x present D. As', 'distinct memorizing', 'memorizing', 'value tn', 'input', 'training set', 'generalization data', 'rest relevant', 'space']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('sum', 'sum'), (',', ','), ('goal', 'goal'), ('regression', 'regress'), ('clas-', 'clas-'), ('sification', 'sific'), ('derive', 'deriv'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('generalizes', 'gener'), ('input-output', 'input-output'), ('mapping', 'map'), ('D', 'd'), ('inputs', 'input'), ('x', 'x'), ('present', 'present'), ('D.', 'd.'), ('As', 'as'), (',', ','), ('learning', 'learn'), ('markedly', 'markedli'), ('distinct', 'distinct'), ('memorizing', 'memor'), (':', ':'), ('memorizing', 'memor'), ('would', 'would'), ('require', 'requir'), ('producing', 'produc'), ('value', 'valu'), ('tn', 'tn'), ('recorded', 'record'), ('input', 'input'), ('xn', 'xn'), ('training', 'train'), ('set', 'set'), (',', ','), ('learning', 'learn'), ('generalization', 'gener'), ('data', 'data'), ('set', 'set'), ('rest', 'rest'), ('relevant', 'relev'), ('input', 'input'), ('space', 'space'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('sum', 'sum'), (',', ','), ('goal', 'goal'), ('regression', 'regress'), ('clas-', 'clas-'), ('sification', 'sific'), ('derive', 'deriv'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('generalizes', 'general'), ('input-output', 'input-output'), ('mapping', 'map'), ('D', 'd'), ('inputs', 'input'), ('x', 'x'), ('present', 'present'), ('D.', 'd.'), ('As', 'as'), (',', ','), ('learning', 'learn'), ('markedly', 'mark'), ('distinct', 'distinct'), ('memorizing', 'memor'), (':', ':'), ('memorizing', 'memor'), ('would', 'would'), ('require', 'requir'), ('producing', 'produc'), ('value', 'valu'), ('tn', 'tn'), ('recorded', 'record'), ('input', 'input'), ('xn', 'xn'), ('training', 'train'), ('set', 'set'), (',', ','), ('learning', 'learn'), ('generalization', 'general'), ('data', 'data'), ('set', 'set'), ('rest', 'rest'), ('relevant', 'relev'), ('input', 'input'), ('space', 'space'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('sum', 'sum'), (',', ','), ('goal', 'goal'), ('regression', 'regression'), ('clas-', 'clas-'), ('sification', 'sification'), ('derive', 'derive'), ('training', 'training'), ('data', 'data'), ('set', 'set'), ('D', 'D'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('generalizes', 'generalizes'), ('input-output', 'input-output'), ('mapping', 'mapping'), ('D', 'D'), ('inputs', 'input'), ('x', 'x'), ('present', 'present'), ('D.', 'D.'), ('As', 'As'), (',', ','), ('learning', 'learning'), ('markedly', 'markedly'), ('distinct', 'distinct'), ('memorizing', 'memorizing'), (':', ':'), ('memorizing', 'memorizing'), ('would', 'would'), ('require', 'require'), ('producing', 'producing'), ('value', 'value'), ('tn', 'tn'), ('recorded', 'recorded'), ('input', 'input'), ('xn', 'xn'), ('training', 'training'), ('set', 'set'), (',', ','), ('learning', 'learning'), ('generalization', 'generalization'), ('data', 'data'), ('set', 'set'), ('rest', 'rest'), ('relevant', 'relevant'), ('input', 'input'), ('space', 'space'), ('.', '.')]



============================ Sentence 166 =============================

The problem of extrapolating a predictor from the training set is evidently impossible unless one is willing to make some assumption about the underlying input- output mapping. 


>> Tokens are: 
 ['The', 'problem', 'extrapolating', 'predictor', 'training', 'set', 'evidently', 'impossible', 'unless', 'one', 'willing', 'make', 'assumption', 'underlying', 'input-', 'output', 'mapping', '.']

>> Bigrams are: 
 [('The', 'problem'), ('problem', 'extrapolating'), ('extrapolating', 'predictor'), ('predictor', 'training'), ('training', 'set'), ('set', 'evidently'), ('evidently', 'impossible'), ('impossible', 'unless'), ('unless', 'one'), ('one', 'willing'), ('willing', 'make'), ('make', 'assumption'), ('assumption', 'underlying'), ('underlying', 'input-'), ('input-', 'output'), ('output', 'mapping'), ('mapping', '.')]

>> Trigrams are: 
 [('The', 'problem', 'extrapolating'), ('problem', 'extrapolating', 'predictor'), ('extrapolating', 'predictor', 'training'), ('predictor', 'training', 'set'), ('training', 'set', 'evidently'), ('set', 'evidently', 'impossible'), ('evidently', 'impossible', 'unless'), ('impossible', 'unless', 'one'), ('unless', 'one', 'willing'), ('one', 'willing', 'make'), ('willing', 'make', 'assumption'), ('make', 'assumption', 'underlying'), ('assumption', 'underlying', 'input-'), ('underlying', 'input-', 'output'), ('input-', 'output', 'mapping'), ('output', 'mapping', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('problem', 'NN'), ('extrapolating', 'VBG'), ('predictor', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('evidently', 'RB'), ('impossible', 'JJ'), ('unless', 'IN'), ('one', 'CD'), ('willing', 'JJ'), ('make', 'VB'), ('assumption', 'NN'), ('underlying', 'VBG'), ('input-', 'JJ'), ('output', 'NN'), ('mapping', 'NN'), ('.', '.')]

 (S
  (NP The/DT problem/NN)
  extrapolating/VBG
  (NP predictor/NN training/NN)
  set/VBN
  evidently/RB
  impossible/JJ
  unless/IN
  one/CD
  willing/JJ
  make/VB
  (NP assumption/NN)
  underlying/VBG
  (NP input-/JJ output/NN mapping/NN)
  ./.) 


>> Noun Phrases are: 
 ['The problem', 'predictor training', 'assumption', 'input- output mapping']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('extrapolating', 'extrapol'), ('predictor', 'predictor'), ('training', 'train'), ('set', 'set'), ('evidently', 'evid'), ('impossible', 'imposs'), ('unless', 'unless'), ('one', 'one'), ('willing', 'will'), ('make', 'make'), ('assumption', 'assumpt'), ('underlying', 'underli'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'map'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('extrapolating', 'extrapol'), ('predictor', 'predictor'), ('training', 'train'), ('set', 'set'), ('evidently', 'evid'), ('impossible', 'imposs'), ('unless', 'unless'), ('one', 'one'), ('willing', 'will'), ('make', 'make'), ('assumption', 'assumpt'), ('underlying', 'under'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'map'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('problem', 'problem'), ('extrapolating', 'extrapolating'), ('predictor', 'predictor'), ('training', 'training'), ('set', 'set'), ('evidently', 'evidently'), ('impossible', 'impossible'), ('unless', 'unless'), ('one', 'one'), ('willing', 'willing'), ('make', 'make'), ('assumption', 'assumption'), ('underlying', 'underlying'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'mapping'), ('.', '.')]



============================ Sentence 167 =============================

In fact, the output t may well equal any value for an unobserved x if nothing else is specified about the problem. 


>> Tokens are: 
 ['In', 'fact', ',', 'output', 'may', 'well', 'equal', 'value', 'unobserved', 'x', 'nothing', 'else', 'specified', 'problem', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'output'), ('output', 'may'), ('may', 'well'), ('well', 'equal'), ('equal', 'value'), ('value', 'unobserved'), ('unobserved', 'x'), ('x', 'nothing'), ('nothing', 'else'), ('else', 'specified'), ('specified', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'output'), (',', 'output', 'may'), ('output', 'may', 'well'), ('may', 'well', 'equal'), ('well', 'equal', 'value'), ('equal', 'value', 'unobserved'), ('value', 'unobserved', 'x'), ('unobserved', 'x', 'nothing'), ('x', 'nothing', 'else'), ('nothing', 'else', 'specified'), ('else', 'specified', 'problem'), ('specified', 'problem', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('output', 'NN'), ('may', 'MD'), ('well', 'RB'), ('equal', 'VB'), ('value', 'NN'), ('unobserved', 'JJ'), ('x', 'NNP'), ('nothing', 'NN'), ('else', 'RB'), ('specified', 'VBN'), ('problem', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP fact/NN)
  ,/,
  (NP output/NN)
  may/MD
  well/RB
  equal/VB
  (NP value/NN)
  (NP unobserved/JJ x/NNP nothing/NN)
  else/RB
  specified/VBN
  (NP problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'output', 'value', 'unobserved x nothing', 'problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('output', 'output'), ('may', 'may'), ('well', 'well'), ('equal', 'equal'), ('value', 'valu'), ('unobserved', 'unobserv'), ('x', 'x'), ('nothing', 'noth'), ('else', 'els'), ('specified', 'specifi'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('output', 'output'), ('may', 'may'), ('well', 'well'), ('equal', 'equal'), ('value', 'valu'), ('unobserved', 'unobserv'), ('x', 'x'), ('nothing', 'noth'), ('else', 'els'), ('specified', 'specifi'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('output', 'output'), ('may', 'may'), ('well', 'well'), ('equal', 'equal'), ('value', 'value'), ('unobserved', 'unobserved'), ('x', 'x'), ('nothing', 'nothing'), ('else', 'else'), ('specified', 'specified'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 168 =============================

This impossibility is formalized by the no free-lunch theorem: without making assumptions about the relationship between input and output, it is not possible to generalize the available observations outside the training set [14]. 


>> Tokens are: 
 ['This', 'impossibility', 'formalized', 'free-lunch', 'theorem', ':', 'without', 'making', 'assumptions', 'relationship', 'input', 'output', ',', 'possible', 'generalize', 'available', 'observations', 'outside', 'training', 'set', '[', '14', ']', '.']

>> Bigrams are: 
 [('This', 'impossibility'), ('impossibility', 'formalized'), ('formalized', 'free-lunch'), ('free-lunch', 'theorem'), ('theorem', ':'), (':', 'without'), ('without', 'making'), ('making', 'assumptions'), ('assumptions', 'relationship'), ('relationship', 'input'), ('input', 'output'), ('output', ','), (',', 'possible'), ('possible', 'generalize'), ('generalize', 'available'), ('available', 'observations'), ('observations', 'outside'), ('outside', 'training'), ('training', 'set'), ('set', '['), ('[', '14'), ('14', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'impossibility', 'formalized'), ('impossibility', 'formalized', 'free-lunch'), ('formalized', 'free-lunch', 'theorem'), ('free-lunch', 'theorem', ':'), ('theorem', ':', 'without'), (':', 'without', 'making'), ('without', 'making', 'assumptions'), ('making', 'assumptions', 'relationship'), ('assumptions', 'relationship', 'input'), ('relationship', 'input', 'output'), ('input', 'output', ','), ('output', ',', 'possible'), (',', 'possible', 'generalize'), ('possible', 'generalize', 'available'), ('generalize', 'available', 'observations'), ('available', 'observations', 'outside'), ('observations', 'outside', 'training'), ('outside', 'training', 'set'), ('training', 'set', '['), ('set', '[', '14'), ('[', '14', ']'), ('14', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('impossibility', 'NN'), ('formalized', 'VBD'), ('free-lunch', 'JJ'), ('theorem', 'NN'), (':', ':'), ('without', 'IN'), ('making', 'VBG'), ('assumptions', 'NNS'), ('relationship', 'NN'), ('input', 'NN'), ('output', 'NN'), (',', ','), ('possible', 'JJ'), ('generalize', 'NN'), ('available', 'JJ'), ('observations', 'NNS'), ('outside', 'IN'), ('training', 'NN'), ('set', 'VBN'), ('[', '$'), ('14', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT impossibility/NN)
  formalized/VBD
  (NP free-lunch/JJ theorem/NN)
  :/:
  without/IN
  making/VBG
  (NP assumptions/NNS relationship/NN input/NN output/NN)
  ,/,
  (NP possible/JJ generalize/NN)
  (NP available/JJ observations/NNS)
  outside/IN
  (NP training/NN)
  set/VBN
  [/$
  14/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This impossibility', 'free-lunch theorem', 'assumptions relationship input output', 'possible generalize', 'available observations', 'training', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('impossibility', 'imposs'), ('formalized', 'formal'), ('free-lunch', 'free-lunch'), ('theorem', 'theorem'), (':', ':'), ('without', 'without'), ('making', 'make'), ('assumptions', 'assumpt'), ('relationship', 'relationship'), ('input', 'input'), ('output', 'output'), (',', ','), ('possible', 'possibl'), ('generalize', 'gener'), ('available', 'avail'), ('observations', 'observ'), ('outside', 'outsid'), ('training', 'train'), ('set', 'set'), ('[', '['), ('14', '14'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('impossibility', 'imposs'), ('formalized', 'formal'), ('free-lunch', 'free-lunch'), ('theorem', 'theorem'), (':', ':'), ('without', 'without'), ('making', 'make'), ('assumptions', 'assumpt'), ('relationship', 'relationship'), ('input', 'input'), ('output', 'output'), (',', ','), ('possible', 'possibl'), ('generalize', 'general'), ('available', 'avail'), ('observations', 'observ'), ('outside', 'outsid'), ('training', 'train'), ('set', 'set'), ('[', '['), ('14', '14'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('impossibility', 'impossibility'), ('formalized', 'formalized'), ('free-lunch', 'free-lunch'), ('theorem', 'theorem'), (':', ':'), ('without', 'without'), ('making', 'making'), ('assumptions', 'assumption'), ('relationship', 'relationship'), ('input', 'input'), ('output', 'output'), (',', ','), ('possible', 'possible'), ('generalize', 'generalize'), ('available', 'available'), ('observations', 'observation'), ('outside', 'outside'), ('training', 'training'), ('set', 'set'), ('[', '['), ('14', '14'), (']', ']'), ('.', '.')]



============================ Sentence 169 =============================

The set of assumptions made in order to enable learning are known as inductive bias. 


>> Tokens are: 
 ['The', 'set', 'assumptions', 'made', 'order', 'enable', 'learning', 'known', 'inductive', 'bias', '.']

>> Bigrams are: 
 [('The', 'set'), ('set', 'assumptions'), ('assumptions', 'made'), ('made', 'order'), ('order', 'enable'), ('enable', 'learning'), ('learning', 'known'), ('known', 'inductive'), ('inductive', 'bias'), ('bias', '.')]

>> Trigrams are: 
 [('The', 'set', 'assumptions'), ('set', 'assumptions', 'made'), ('assumptions', 'made', 'order'), ('made', 'order', 'enable'), ('order', 'enable', 'learning'), ('enable', 'learning', 'known'), ('learning', 'known', 'inductive'), ('known', 'inductive', 'bias'), ('inductive', 'bias', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('set', 'NN'), ('assumptions', 'NNS'), ('made', 'VBD'), ('order', 'NN'), ('enable', 'JJ'), ('learning', 'VBG'), ('known', 'VBN'), ('inductive', 'JJ'), ('bias', 'NN'), ('.', '.')]

 (S
  (NP The/DT set/NN assumptions/NNS)
  made/VBD
  (NP order/NN)
  enable/JJ
  learning/VBG
  known/VBN
  (NP inductive/JJ bias/NN)
  ./.) 


>> Noun Phrases are: 
 ['The set assumptions', 'order', 'inductive bias']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('set', 'set'), ('assumptions', 'assumpt'), ('made', 'made'), ('order', 'order'), ('enable', 'enabl'), ('learning', 'learn'), ('known', 'known'), ('inductive', 'induct'), ('bias', 'bia'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('set', 'set'), ('assumptions', 'assumpt'), ('made', 'made'), ('order', 'order'), ('enable', 'enabl'), ('learning', 'learn'), ('known', 'known'), ('inductive', 'induct'), ('bias', 'bias'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('set', 'set'), ('assumptions', 'assumption'), ('made', 'made'), ('order', 'order'), ('enable', 'enable'), ('learning', 'learning'), ('known', 'known'), ('inductive', 'inductive'), ('bias', 'bias'), ('.', '.')]



============================ Sentence 170 =============================

As an example, for the regression problem in Fig. 


>> Tokens are: 
 ['As', 'example', ',', 'regression', 'problem', 'Fig', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'regression'), ('regression', 'problem'), ('problem', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'regression'), (',', 'regression', 'problem'), ('regression', 'problem', 'Fig'), ('problem', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('regression', 'NN'), ('problem', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  (NP regression/NN problem/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['example', 'regression problem Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('regression', 'regression'), ('problem', 'problem'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 171 =============================

5, a possible inductive bias is to postulate that the input- output mapping is a polynomial function of some order. 


>> Tokens are: 
 ['5', ',', 'possible', 'inductive', 'bias', 'postulate', 'input-', 'output', 'mapping', 'polynomial', 'function', 'order', '.']

>> Bigrams are: 
 [('5', ','), (',', 'possible'), ('possible', 'inductive'), ('inductive', 'bias'), ('bias', 'postulate'), ('postulate', 'input-'), ('input-', 'output'), ('output', 'mapping'), ('mapping', 'polynomial'), ('polynomial', 'function'), ('function', 'order'), ('order', '.')]

>> Trigrams are: 
 [('5', ',', 'possible'), (',', 'possible', 'inductive'), ('possible', 'inductive', 'bias'), ('inductive', 'bias', 'postulate'), ('bias', 'postulate', 'input-'), ('postulate', 'input-', 'output'), ('input-', 'output', 'mapping'), ('output', 'mapping', 'polynomial'), ('mapping', 'polynomial', 'function'), ('polynomial', 'function', 'order'), ('function', 'order', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('possible', 'JJ'), ('inductive', 'JJ'), ('bias', 'NN'), ('postulate', 'VB'), ('input-', 'JJ'), ('output', 'NN'), ('mapping', 'VBG'), ('polynomial', 'JJ'), ('function', 'NN'), ('order', 'NN'), ('.', '.')]

 (S
  5/CD
  ,/,
  (NP possible/JJ inductive/JJ bias/NN)
  postulate/VB
  (NP input-/JJ output/NN)
  mapping/VBG
  (NP polynomial/JJ function/NN order/NN)
  ./.) 


>> Noun Phrases are: 
 ['possible inductive bias', 'input- output', 'polynomial function order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('possible', 'possibl'), ('inductive', 'induct'), ('bias', 'bia'), ('postulate', 'postul'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'map'), ('polynomial', 'polynomi'), ('function', 'function'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('possible', 'possibl'), ('inductive', 'induct'), ('bias', 'bias'), ('postulate', 'postul'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'map'), ('polynomial', 'polynomi'), ('function', 'function'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('possible', 'possible'), ('inductive', 'inductive'), ('bias', 'bias'), ('postulate', 'postulate'), ('input-', 'input-'), ('output', 'output'), ('mapping', 'mapping'), ('polynomial', 'polynomial'), ('function', 'function'), ('order', 'order'), ('.', '.')]



============================ Sentence 172 =============================

B. 


>> Tokens are: 
 ['B', '.']

>> Bigrams are: 
 [('B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('.', '.')]

 (S (NP B/NNP) ./.) 


>> Noun Phrases are: 
 ['B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('B', 'B'), ('.', '.')]



============================ Sentence 173 =============================

Defining Supervised Learning  Having introduced the goal of supervised learning, we now provide a more formal definition of the problem. 


>> Tokens are: 
 ['Defining', 'Supervised', 'Learning', 'Having', 'introduced', 'goal', 'supervised', 'learning', ',', 'provide', 'formal', 'definition', 'problem', '.']

>> Bigrams are: 
 [('Defining', 'Supervised'), ('Supervised', 'Learning'), ('Learning', 'Having'), ('Having', 'introduced'), ('introduced', 'goal'), ('goal', 'supervised'), ('supervised', 'learning'), ('learning', ','), (',', 'provide'), ('provide', 'formal'), ('formal', 'definition'), ('definition', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('Defining', 'Supervised', 'Learning'), ('Supervised', 'Learning', 'Having'), ('Learning', 'Having', 'introduced'), ('Having', 'introduced', 'goal'), ('introduced', 'goal', 'supervised'), ('goal', 'supervised', 'learning'), ('supervised', 'learning', ','), ('learning', ',', 'provide'), (',', 'provide', 'formal'), ('provide', 'formal', 'definition'), ('formal', 'definition', 'problem'), ('definition', 'problem', '.')]

>> POS Tags are: 
 [('Defining', 'VBG'), ('Supervised', 'VBD'), ('Learning', 'VBG'), ('Having', 'NNP'), ('introduced', 'VBN'), ('goal', 'NN'), ('supervised', 'VBD'), ('learning', 'NN'), (',', ','), ('provide', 'VB'), ('formal', 'JJ'), ('definition', 'NN'), ('problem', 'NN'), ('.', '.')]

 (S
  Defining/VBG
  Supervised/VBD
  Learning/VBG
  (NP Having/NNP)
  introduced/VBN
  (NP goal/NN)
  supervised/VBD
  (NP learning/NN)
  ,/,
  provide/VB
  (NP formal/JJ definition/NN problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['Having', 'goal', 'learning', 'formal definition problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Defining', 'defin'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('Having', 'have'), ('introduced', 'introduc'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('provide', 'provid'), ('formal', 'formal'), ('definition', 'definit'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Defining', 'defin'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('Having', 'have'), ('introduced', 'introduc'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('provide', 'provid'), ('formal', 'formal'), ('definition', 'definit'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Defining', 'Defining'), ('Supervised', 'Supervised'), ('Learning', 'Learning'), ('Having', 'Having'), ('introduced', 'introduced'), ('goal', 'goal'), ('supervised', 'supervised'), ('learning', 'learning'), (',', ','), ('provide', 'provide'), ('formal', 'formal'), ('definition', 'definition'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 174 =============================

Throughout, we use Roman font to denote random variables and the corresponding letter in regular font for realizations. 


>> Tokens are: 
 ['Throughout', ',', 'use', 'Roman', 'font', 'denote', 'random', 'variables', 'corresponding', 'letter', 'regular', 'font', 'realizations', '.']

>> Bigrams are: 
 [('Throughout', ','), (',', 'use'), ('use', 'Roman'), ('Roman', 'font'), ('font', 'denote'), ('denote', 'random'), ('random', 'variables'), ('variables', 'corresponding'), ('corresponding', 'letter'), ('letter', 'regular'), ('regular', 'font'), ('font', 'realizations'), ('realizations', '.')]

>> Trigrams are: 
 [('Throughout', ',', 'use'), (',', 'use', 'Roman'), ('use', 'Roman', 'font'), ('Roman', 'font', 'denote'), ('font', 'denote', 'random'), ('denote', 'random', 'variables'), ('random', 'variables', 'corresponding'), ('variables', 'corresponding', 'letter'), ('corresponding', 'letter', 'regular'), ('letter', 'regular', 'font'), ('regular', 'font', 'realizations'), ('font', 'realizations', '.')]

>> POS Tags are: 
 [('Throughout', 'NN'), (',', ','), ('use', 'NN'), ('Roman', 'NNP'), ('font', 'VBZ'), ('denote', 'JJ'), ('random', 'NN'), ('variables', 'NNS'), ('corresponding', 'VBG'), ('letter', 'NN'), ('regular', 'JJ'), ('font', 'NN'), ('realizations', 'NNS'), ('.', '.')]

 (S
  (NP Throughout/NN)
  ,/,
  (NP use/NN Roman/NNP)
  font/VBZ
  (NP denote/JJ random/NN variables/NNS)
  corresponding/VBG
  (NP letter/NN)
  (NP regular/JJ font/NN realizations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Throughout', 'use Roman', 'denote random variables', 'letter', 'regular font realizations']

>> Named Entities are: 
 [('GPE', 'Throughout'), ('PERSON', 'Roman')] 

>> Stemming using Porter Stemmer: 
 [('Throughout', 'throughout'), (',', ','), ('use', 'use'), ('Roman', 'roman'), ('font', 'font'), ('denote', 'denot'), ('random', 'random'), ('variables', 'variabl'), ('corresponding', 'correspond'), ('letter', 'letter'), ('regular', 'regular'), ('font', 'font'), ('realizations', 'realiz'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Throughout', 'throughout'), (',', ','), ('use', 'use'), ('Roman', 'roman'), ('font', 'font'), ('denote', 'denot'), ('random', 'random'), ('variables', 'variabl'), ('corresponding', 'correspond'), ('letter', 'letter'), ('regular', 'regular'), ('font', 'font'), ('realizations', 'realize'), ('.', '.')]

>> Lemmatization: 
 [('Throughout', 'Throughout'), (',', ','), ('use', 'use'), ('Roman', 'Roman'), ('font', 'font'), ('denote', 'denote'), ('random', 'random'), ('variables', 'variable'), ('corresponding', 'corresponding'), ('letter', 'letter'), ('regular', 'regular'), ('font', 'font'), ('realizations', 'realization'), ('.', '.')]



============================ Sentence 175 =============================

As a starting point, we assume that the training set D is generated as  (xn, tn) ∼ i.i.d. 


>> Tokens are: 
 ['As', 'starting', 'point', ',', 'assume', 'training', 'set', 'D', 'generated', '(', 'xn', ',', 'tn', ')', '∼', 'i.i.d', '.']

>> Bigrams are: 
 [('As', 'starting'), ('starting', 'point'), ('point', ','), (',', 'assume'), ('assume', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'generated'), ('generated', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', '∼'), ('∼', 'i.i.d'), ('i.i.d', '.')]

>> Trigrams are: 
 [('As', 'starting', 'point'), ('starting', 'point', ','), ('point', ',', 'assume'), (',', 'assume', 'training'), ('assume', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'generated'), ('D', 'generated', '('), ('generated', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', '∼'), (')', '∼', 'i.i.d'), ('∼', 'i.i.d', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('starting', 'VBG'), ('point', 'NN'), (',', ','), ('assume', 'VBP'), ('training', 'VBG'), ('set', 'VBN'), ('D', 'NNP'), ('generated', 'VBD'), ('(', '('), ('xn', 'JJ'), (',', ','), ('tn', 'NN'), (')', ')'), ('∼', 'NN'), ('i.i.d', 'NN'), ('.', '.')]

 (S
  As/IN
  starting/VBG
  (NP point/NN)
  ,/,
  assume/VBP
  training/VBG
  set/VBN
  (NP D/NNP)
  generated/VBD
  (/(
  xn/JJ
  ,/,
  (NP tn/NN)
  )/)
  (NP ∼/NN i.i.d/NN)
  ./.) 


>> Noun Phrases are: 
 ['point', 'D', 'tn', '∼ i.i.d']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('starting', 'start'), ('point', 'point'), (',', ','), ('assume', 'assum'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('generated', 'gener'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('∼', '∼'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('starting', 'start'), ('point', 'point'), (',', ','), ('assume', 'assum'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('generated', 'generat'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('∼', '∼'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('starting', 'starting'), ('point', 'point'), (',', ','), ('assume', 'assume'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('generated', 'generated'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('∼', '∼'), ('i.i.d', 'i.i.d'), ('.', '.')]



============================ Sentence 176 =============================

p(x, t), n = 1, ..., N, (1)  that is, each training sample pair (xn, tn) is generated from the same true joint distribution p(x, t) and the sam- ple pairs are independent identically distributed (i.i.d.). 


>> Tokens are: 
 ['p', '(', 'x', ',', ')', ',', 'n', '=', '1', ',', '...', ',', 'N', ',', '(', '1', ')', ',', 'training', 'sample', 'pair', '(', 'xn', ',', 'tn', ')', 'generated', 'true', 'joint', 'distribution', 'p', '(', 'x', ',', ')', 'sam-', 'ple', 'pairs', 'independent', 'identically', 'distributed', '(', 'i.i.d', '.', ')', '.']

>> Bigrams are: 
 [('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', ','), (',', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', ','), (',', '('), ('(', '1'), ('1', ')'), (')', ','), (',', 'training'), ('training', 'sample'), ('sample', 'pair'), ('pair', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', 'generated'), ('generated', 'true'), ('true', 'joint'), ('joint', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'sam-'), ('sam-', 'ple'), ('ple', 'pairs'), ('pairs', 'independent'), ('independent', 'identically'), ('identically', 'distributed'), ('distributed', '('), ('(', 'i.i.d'), ('i.i.d', '.'), ('.', ')'), (')', '.')]

>> Trigrams are: 
 [('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', ','), (')', ',', 'n'), (',', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', ','), ('N', ',', '('), (',', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', 'training'), (',', 'training', 'sample'), ('training', 'sample', 'pair'), ('sample', 'pair', '('), ('pair', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', 'generated'), (')', 'generated', 'true'), ('generated', 'true', 'joint'), ('true', 'joint', 'distribution'), ('joint', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'sam-'), (')', 'sam-', 'ple'), ('sam-', 'ple', 'pairs'), ('ple', 'pairs', 'independent'), ('pairs', 'independent', 'identically'), ('independent', 'identically', 'distributed'), ('identically', 'distributed', '('), ('distributed', '(', 'i.i.d'), ('(', 'i.i.d', '.'), ('i.i.d', '.', ')'), ('.', ')', '.')]

>> POS Tags are: 
 [('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), (',', ','), ('n', 'JJ'), ('=', 'NN'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), (',', ','), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('training', 'VBG'), ('sample', 'JJ'), ('pair', 'NN'), ('(', '('), ('xn', 'UH'), (',', ','), ('tn', 'NN'), (')', ')'), ('generated', 'VBD'), ('true', 'JJ'), ('joint', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('sam-', 'JJ'), ('ple', 'JJ'), ('pairs', 'NNS'), ('independent', 'JJ'), ('identically', 'RB'), ('distributed', 'VBN'), ('(', '('), ('i.i.d', 'JJ'), ('.', '.'), (')', ')'), ('.', '.')]

 (S
  (NP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ,/,
  (NP n/JJ =/NN)
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  ,/,
  (/(
  1/CD
  )/)
  ,/,
  training/VBG
  (NP sample/JJ pair/NN)
  (/(
  xn/UH
  ,/,
  (NP tn/NN)
  )/)
  generated/VBD
  (NP true/JJ joint/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  (NP sam-/JJ ple/JJ pairs/NNS)
  independent/JJ
  identically/RB
  distributed/VBN
  (/(
  i.i.d/JJ
  ./.
  )/)
  ./.) 


>> Noun Phrases are: 
 ['p', 'x', 'n =', 'N', 'sample pair', 'tn', 'true joint distribution p', 'x', 'sam- ple pairs']

>> Named Entities are: 
 [('GPE', 'N')] 

>> Stemming using Porter Stemmer: 
 [('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('training', 'train'), ('sample', 'sampl'), ('pair', 'pair'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('generated', 'gener'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('sam-', 'sam-'), ('ple', 'ple'), ('pairs', 'pair'), ('independent', 'independ'), ('identically', 'ident'), ('distributed', 'distribut'), ('(', '('), ('i.i.d', 'i.i.d'), ('.', '.'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('training', 'train'), ('sample', 'sampl'), ('pair', 'pair'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('generated', 'generat'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('sam-', 'sam-'), ('ple', 'ple'), ('pairs', 'pair'), ('independent', 'independ'), ('identically', 'ident'), ('distributed', 'distribut'), ('(', '('), ('i.i.d', 'i.i.d'), ('.', '.'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), (',', ','), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('training', 'training'), ('sample', 'sample'), ('pair', 'pair'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('generated', 'generated'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('sam-', 'sam-'), ('ple', 'ple'), ('pairs', 'pair'), ('independent', 'independent'), ('identically', 'identically'), ('distributed', 'distributed'), ('(', '('), ('i.i.d', 'i.i.d'), ('.', '.'), (')', ')'), ('.', '.')]



============================ Sentence 177 =============================

As discussed, based on the training set D, we wish to obtain a predictor t̂(x) that performs well on any possible relevant input x. 


>> Tokens are: 
 ['As', 'discussed', ',', 'based', 'training', 'set', 'D', ',', 'wish', 'obtain', 'predictor', 't̂', '(', 'x', ')', 'performs', 'well', 'possible', 'relevant', 'input', 'x', '.']

>> Bigrams are: 
 [('As', 'discussed'), ('discussed', ','), (',', 'based'), ('based', 'training'), ('training', 'set'), ('set', 'D'), ('D', ','), (',', 'wish'), ('wish', 'obtain'), ('obtain', 'predictor'), ('predictor', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', 'performs'), ('performs', 'well'), ('well', 'possible'), ('possible', 'relevant'), ('relevant', 'input'), ('input', 'x'), ('x', '.')]

>> Trigrams are: 
 [('As', 'discussed', ','), ('discussed', ',', 'based'), (',', 'based', 'training'), ('based', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', ','), ('D', ',', 'wish'), (',', 'wish', 'obtain'), ('wish', 'obtain', 'predictor'), ('obtain', 'predictor', 't̂'), ('predictor', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'performs'), (')', 'performs', 'well'), ('performs', 'well', 'possible'), ('well', 'possible', 'relevant'), ('possible', 'relevant', 'input'), ('relevant', 'input', 'x'), ('input', 'x', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('discussed', 'VBN'), (',', ','), ('based', 'VBN'), ('training', 'NN'), ('set', 'VBN'), ('D', 'NNP'), (',', ','), ('wish', 'JJ'), ('obtain', 'VB'), ('predictor', 'NN'), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('performs', 'VBZ'), ('well', 'RB'), ('possible', 'JJ'), ('relevant', 'JJ'), ('input', 'NN'), ('x', 'NNP'), ('.', '.')]

 (S
  As/IN
  discussed/VBN
  ,/,
  based/VBN
  (NP training/NN)
  set/VBN
  (NP D/NNP)
  ,/,
  wish/JJ
  obtain/VB
  (NP predictor/NN t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  performs/VBZ
  well/RB
  (NP possible/JJ relevant/JJ input/NN x/NNP)
  ./.) 


>> Noun Phrases are: 
 ['training', 'D', 'predictor t̂', 'x', 'possible relevant input x']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('discussed', 'discuss'), (',', ','), ('based', 'base'), ('training', 'train'), ('set', 'set'), ('D', 'd'), (',', ','), ('wish', 'wish'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('performs', 'perform'), ('well', 'well'), ('possible', 'possibl'), ('relevant', 'relev'), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('discussed', 'discuss'), (',', ','), ('based', 'base'), ('training', 'train'), ('set', 'set'), ('D', 'd'), (',', ','), ('wish', 'wish'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('performs', 'perform'), ('well', 'well'), ('possible', 'possibl'), ('relevant', 'relev'), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('discussed', 'discussed'), (',', ','), ('based', 'based'), ('training', 'training'), ('set', 'set'), ('D', 'D'), (',', ','), ('wish', 'wish'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('performs', 'performs'), ('well', 'well'), ('possible', 'possible'), ('relevant', 'relevant'), ('input', 'input'), ('x', 'x'), ('.', '.')]



============================ Sentence 178 =============================

This requirement is formalized by imposing that the predictor is accurate for any test pair (x, t) ∼ p(x, t), which is generated independently of all the pairs in the training set D.  The quality of the prediction t̂(x) for a test pair (x, t) is measured by a given loss function `(t, t̂) as `(t, t̂(x)). 


>> Tokens are: 
 ['This', 'requirement', 'formalized', 'imposing', 'predictor', 'accurate', 'test', 'pair', '(', 'x', ',', ')', '∼', 'p', '(', 'x', ',', ')', ',', 'generated', 'independently', 'pairs', 'training', 'set', 'D.', 'The', 'quality', 'prediction', 't̂', '(', 'x', ')', 'test', 'pair', '(', 'x', ',', ')', 'measured', 'given', 'loss', 'function', '`', '(', ',', 't̂', ')', '`', '(', ',', 't̂', '(', 'x', ')', ')', '.']

>> Bigrams are: 
 [('This', 'requirement'), ('requirement', 'formalized'), ('formalized', 'imposing'), ('imposing', 'predictor'), ('predictor', 'accurate'), ('accurate', 'test'), ('test', 'pair'), ('pair', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '∼'), ('∼', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', ','), (',', 'generated'), ('generated', 'independently'), ('independently', 'pairs'), ('pairs', 'training'), ('training', 'set'), ('set', 'D.'), ('D.', 'The'), ('The', 'quality'), ('quality', 'prediction'), ('prediction', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', 'test'), ('test', 'pair'), ('pair', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'measured'), ('measured', 'given'), ('given', 'loss'), ('loss', 'function'), ('function', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', ')'), (')', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'requirement', 'formalized'), ('requirement', 'formalized', 'imposing'), ('formalized', 'imposing', 'predictor'), ('imposing', 'predictor', 'accurate'), ('predictor', 'accurate', 'test'), ('accurate', 'test', 'pair'), ('test', 'pair', '('), ('pair', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '∼'), (')', '∼', 'p'), ('∼', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', ','), (')', ',', 'generated'), (',', 'generated', 'independently'), ('generated', 'independently', 'pairs'), ('independently', 'pairs', 'training'), ('pairs', 'training', 'set'), ('training', 'set', 'D.'), ('set', 'D.', 'The'), ('D.', 'The', 'quality'), ('The', 'quality', 'prediction'), ('quality', 'prediction', 't̂'), ('prediction', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'test'), (')', 'test', 'pair'), ('test', 'pair', '('), ('pair', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'measured'), (')', 'measured', 'given'), ('measured', 'given', 'loss'), ('given', 'loss', 'function'), ('loss', 'function', '`'), ('function', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', ')'), ('t̂', ')', '`'), (')', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('requirement', 'NN'), ('formalized', 'VBD'), ('imposing', 'VBG'), ('predictor', 'NN'), ('accurate', 'JJ'), ('test', 'NN'), ('pair', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('∼', 'FW'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), (',', ','), ('generated', 'VBD'), ('independently', 'RB'), ('pairs', 'JJ'), ('training', 'NN'), ('set', 'VBN'), ('D.', 'NNP'), ('The', 'DT'), ('quality', 'NN'), ('prediction', 'NN'), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('test', 'NN'), ('pair', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('measured', 'VBD'), ('given', 'VBN'), ('loss', 'NN'), ('function', 'NN'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), (')', ')'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT requirement/NN)
  formalized/VBD
  imposing/VBG
  (NP predictor/NN)
  (NP accurate/JJ test/NN pair/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ∼/FW
  (NP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ,/,
  generated/VBD
  independently/RB
  (NP pairs/JJ training/NN)
  set/VBN
  (NP D./NNP)
  (NP The/DT quality/NN prediction/NN t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP test/NN pair/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  measured/VBD
  given/VBN
  (NP loss/NN function/NN)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  )/)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This requirement', 'predictor', 'accurate test pair', 'x', 'p', 'x', 'pairs training', 'D.', 'The quality prediction t̂', 'x', 'test pair', 'x', 'loss function', 't̂', 't̂', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('requirement', 'requir'), ('formalized', 'formal'), ('imposing', 'impos'), ('predictor', 'predictor'), ('accurate', 'accur'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('generated', 'gener'), ('independently', 'independ'), ('pairs', 'pair'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('The', 'the'), ('quality', 'qualiti'), ('prediction', 'predict'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('measured', 'measur'), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('requirement', 'requir'), ('formalized', 'formal'), ('imposing', 'impos'), ('predictor', 'predictor'), ('accurate', 'accur'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('generated', 'generat'), ('independently', 'independ'), ('pairs', 'pair'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('The', 'the'), ('quality', 'qualiti'), ('prediction', 'predict'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('measured', 'measur'), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('requirement', 'requirement'), ('formalized', 'formalized'), ('imposing', 'imposing'), ('predictor', 'predictor'), ('accurate', 'accurate'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), (',', ','), ('generated', 'generated'), ('independently', 'independently'), ('pairs', 'pair'), ('training', 'training'), ('set', 'set'), ('D.', 'D.'), ('The', 'The'), ('quality', 'quality'), ('prediction', 'prediction'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('measured', 'measured'), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('.', '.')]



============================ Sentence 179 =============================

Typical examples of loss functions include the quadratic loss `(t, t̂) = (t − t̂)2 for regression problems; and the error rate `(t, t̂) = 1(t 6= t̂), which equals 1 when the prediction is incorrect, i.e.-, t 6= t̂, and 0 otherwise, for classification problems. 


>> Tokens are: 
 ['Typical', 'examples', 'loss', 'functions', 'include', 'quadratic', 'loss', '`', '(', ',', 't̂', ')', '=', '(', '−', 't̂', ')', '2', 'regression', 'problems', ';', 'error', 'rate', '`', '(', ',', 't̂', ')', '=', '1', '(', '6=', 't̂', ')', ',', 'equals', '1', 'prediction', 'incorrect', ',', 'i.e.-', ',', '6=', 't̂', ',', '0', 'otherwise', ',', 'classification', 'problems', '.']

>> Bigrams are: 
 [('Typical', 'examples'), ('examples', 'loss'), ('loss', 'functions'), ('functions', 'include'), ('include', 'quadratic'), ('quadratic', 'loss'), ('loss', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', ')'), (')', '='), ('=', '('), ('(', '−'), ('−', 't̂'), ('t̂', ')'), (')', '2'), ('2', 'regression'), ('regression', 'problems'), ('problems', ';'), (';', 'error'), ('error', 'rate'), ('rate', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', ')'), (')', '='), ('=', '1'), ('1', '('), ('(', '6='), ('6=', 't̂'), ('t̂', ')'), (')', ','), (',', 'equals'), ('equals', '1'), ('1', 'prediction'), ('prediction', 'incorrect'), ('incorrect', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', '6='), ('6=', 't̂'), ('t̂', ','), (',', '0'), ('0', 'otherwise'), ('otherwise', ','), (',', 'classification'), ('classification', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Typical', 'examples', 'loss'), ('examples', 'loss', 'functions'), ('loss', 'functions', 'include'), ('functions', 'include', 'quadratic'), ('include', 'quadratic', 'loss'), ('quadratic', 'loss', '`'), ('loss', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', ')'), ('t̂', ')', '='), (')', '=', '('), ('=', '(', '−'), ('(', '−', 't̂'), ('−', 't̂', ')'), ('t̂', ')', '2'), (')', '2', 'regression'), ('2', 'regression', 'problems'), ('regression', 'problems', ';'), ('problems', ';', 'error'), (';', 'error', 'rate'), ('error', 'rate', '`'), ('rate', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', ')'), ('t̂', ')', '='), (')', '=', '1'), ('=', '1', '('), ('1', '(', '6='), ('(', '6=', 't̂'), ('6=', 't̂', ')'), ('t̂', ')', ','), (')', ',', 'equals'), (',', 'equals', '1'), ('equals', '1', 'prediction'), ('1', 'prediction', 'incorrect'), ('prediction', 'incorrect', ','), ('incorrect', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', '6='), (',', '6=', 't̂'), ('6=', 't̂', ','), ('t̂', ',', '0'), (',', '0', 'otherwise'), ('0', 'otherwise', ','), ('otherwise', ',', 'classification'), (',', 'classification', 'problems'), ('classification', 'problems', '.')]

>> POS Tags are: 
 [('Typical', 'JJ'), ('examples', 'NNS'), ('loss', 'NN'), ('functions', 'NNS'), ('include', 'VBP'), ('quadratic', 'JJ'), ('loss', 'NN'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('−', 'NNP'), ('t̂', 'NN'), (')', ')'), ('2', 'CD'), ('regression', 'NN'), ('problems', 'NNS'), (';', ':'), ('error', 'VB'), ('rate', 'NN'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), (')', ')'), ('=', 'VBZ'), ('1', 'CD'), ('(', '('), ('6=', 'CD'), ('t̂', 'NN'), (')', ')'), (',', ','), ('equals', 'VBZ'), ('1', 'CD'), ('prediction', 'NN'), ('incorrect', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('6=', 'CD'), ('t̂', 'NN'), (',', ','), ('0', 'CD'), ('otherwise', 'RB'), (',', ','), ('classification', 'NN'), ('problems', 'NNS'), ('.', '.')]

 (S
  (NP Typical/JJ examples/NNS loss/NN functions/NNS)
  include/VBP
  (NP quadratic/JJ loss/NN)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  )/)
  (NP =/NN)
  (/(
  (NP −/NNP t̂/NN)
  )/)
  2/CD
  (NP regression/NN problems/NNS)
  ;/:
  error/VB
  (NP rate/NN)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  )/)
  =/VBZ
  1/CD
  (/(
  6=/CD
  (NP t̂/NN)
  )/)
  ,/,
  equals/VBZ
  1/CD
  (NP prediction/NN incorrect/NN)
  ,/,
  i.e.-/JJ
  ,/,
  6=/CD
  (NP t̂/NN)
  ,/,
  0/CD
  otherwise/RB
  ,/,
  (NP classification/NN problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Typical examples loss functions', 'quadratic loss', 't̂', '=', '− t̂', 'regression problems', 'rate', 't̂', 't̂', 'prediction incorrect', 't̂', 'classification problems']

>> Named Entities are: 
 [('GPE', 'Typical')] 

>> Stemming using Porter Stemmer: 
 [('Typical', 'typic'), ('examples', 'exampl'), ('loss', 'loss'), ('functions', 'function'), ('include', 'includ'), ('quadratic', 'quadrat'), ('loss', 'loss'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('(', '('), ('−', '−'), ('t̂', 't̂'), (')', ')'), ('2', '2'), ('regression', 'regress'), ('problems', 'problem'), (';', ';'), ('error', 'error'), ('rate', 'rate'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('1', '1'), ('(', '('), ('6=', '6='), ('t̂', 't̂'), (')', ')'), (',', ','), ('equals', 'equal'), ('1', '1'), ('prediction', 'predict'), ('incorrect', 'incorrect'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('6=', '6='), ('t̂', 't̂'), (',', ','), ('0', '0'), ('otherwise', 'otherwis'), (',', ','), ('classification', 'classif'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Typical', 'typic'), ('examples', 'exampl'), ('loss', 'loss'), ('functions', 'function'), ('include', 'includ'), ('quadratic', 'quadrat'), ('loss', 'loss'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('(', '('), ('−', '−'), ('t̂', 't̂'), (')', ')'), ('2', '2'), ('regression', 'regress'), ('problems', 'problem'), (';', ';'), ('error', 'error'), ('rate', 'rate'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('1', '1'), ('(', '('), ('6=', '6='), ('t̂', 't̂'), (')', ')'), (',', ','), ('equals', 'equal'), ('1', '1'), ('prediction', 'predict'), ('incorrect', 'incorrect'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('6=', '6='), ('t̂', 't̂'), (',', ','), ('0', '0'), ('otherwise', 'otherwis'), (',', ','), ('classification', 'classif'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Typical', 'Typical'), ('examples', 'example'), ('loss', 'loss'), ('functions', 'function'), ('include', 'include'), ('quadratic', 'quadratic'), ('loss', 'loss'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('(', '('), ('−', '−'), ('t̂', 't̂'), (')', ')'), ('2', '2'), ('regression', 'regression'), ('problems', 'problem'), (';', ';'), ('error', 'error'), ('rate', 'rate'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('=', '='), ('1', '1'), ('(', '('), ('6=', '6='), ('t̂', 't̂'), (')', ')'), (',', ','), ('equals', 'equal'), ('1', '1'), ('prediction', 'prediction'), ('incorrect', 'incorrect'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('6=', '6='), ('t̂', 't̂'), (',', ','), ('0', '0'), ('otherwise', 'otherwise'), (',', ','), ('classification', 'classification'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 180 =============================

The formal goal of learning is that of minimizing the average loss on the test pair, which is referred to as the generalization loss. 


>> Tokens are: 
 ['The', 'formal', 'goal', 'learning', 'minimizing', 'average', 'loss', 'test', 'pair', ',', 'referred', 'generalization', 'loss', '.']

>> Bigrams are: 
 [('The', 'formal'), ('formal', 'goal'), ('goal', 'learning'), ('learning', 'minimizing'), ('minimizing', 'average'), ('average', 'loss'), ('loss', 'test'), ('test', 'pair'), ('pair', ','), (',', 'referred'), ('referred', 'generalization'), ('generalization', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('The', 'formal', 'goal'), ('formal', 'goal', 'learning'), ('goal', 'learning', 'minimizing'), ('learning', 'minimizing', 'average'), ('minimizing', 'average', 'loss'), ('average', 'loss', 'test'), ('loss', 'test', 'pair'), ('test', 'pair', ','), ('pair', ',', 'referred'), (',', 'referred', 'generalization'), ('referred', 'generalization', 'loss'), ('generalization', 'loss', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('formal', 'JJ'), ('goal', 'NN'), ('learning', 'VBG'), ('minimizing', 'JJ'), ('average', 'JJ'), ('loss', 'NN'), ('test', 'NN'), ('pair', 'NN'), (',', ','), ('referred', 'VBD'), ('generalization', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  (NP The/DT formal/JJ goal/NN)
  learning/VBG
  (NP minimizing/JJ average/JJ loss/NN test/NN pair/NN)
  ,/,
  referred/VBD
  (NP generalization/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['The formal goal', 'minimizing average loss test pair', 'generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('formal', 'formal'), ('goal', 'goal'), ('learning', 'learn'), ('minimizing', 'minim'), ('average', 'averag'), ('loss', 'loss'), ('test', 'test'), ('pair', 'pair'), (',', ','), ('referred', 'refer'), ('generalization', 'gener'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('formal', 'formal'), ('goal', 'goal'), ('learning', 'learn'), ('minimizing', 'minim'), ('average', 'averag'), ('loss', 'loss'), ('test', 'test'), ('pair', 'pair'), (',', ','), ('referred', 'refer'), ('generalization', 'general'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('formal', 'formal'), ('goal', 'goal'), ('learning', 'learning'), ('minimizing', 'minimizing'), ('average', 'average'), ('loss', 'loss'), ('test', 'test'), ('pair', 'pair'), (',', ','), ('referred', 'referred'), ('generalization', 'generalization'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 181 =============================

For a given predictor t̂, this is defined as  Lp(t̂) = E(x,t)∼p(x,t)[`(t, t̂(x))]. 


>> Tokens are: 
 ['For', 'given', 'predictor', 't̂', ',', 'defined', 'Lp', '(', 't̂', ')', '=', 'E', '(', 'x', ',', ')', '∼p', '(', 'x', ',', ')', '[', '`', '(', ',', 't̂', '(', 'x', ')', ')', ']', '.']

>> Bigrams are: 
 [('For', 'given'), ('given', 'predictor'), ('predictor', 't̂'), ('t̂', ','), (',', 'defined'), ('defined', 'Lp'), ('Lp', '('), ('(', 't̂'), ('t̂', ')'), (')', '='), ('=', 'E'), ('E', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '∼p'), ('∼p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '['), ('[', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'given', 'predictor'), ('given', 'predictor', 't̂'), ('predictor', 't̂', ','), ('t̂', ',', 'defined'), (',', 'defined', 'Lp'), ('defined', 'Lp', '('), ('Lp', '(', 't̂'), ('(', 't̂', ')'), ('t̂', ')', '='), (')', '=', 'E'), ('=', 'E', '('), ('E', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '∼p'), (')', '∼p', '('), ('∼p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '['), (')', '[', '`'), ('[', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', ']'), (')', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('given', 'VBN'), ('predictor', 'NN'), ('t̂', 'NN'), (',', ','), ('defined', 'VBN'), ('Lp', 'NNP'), ('(', '('), ('t̂', 'NN'), (')', ')'), ('=', 'NN'), ('E', 'NNP'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('∼p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('[', 'FW'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  given/VBN
  (NP predictor/NN t̂/NN)
  ,/,
  defined/VBN
  (NP Lp/NNP)
  (/(
  (NP t̂/NN)
  )/)
  (NP =/NN E/NNP)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  (NP ∼p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  [/FW
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  )/)
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['predictor t̂', 'Lp', 't̂', '= E', 'x', '∼p', 'x', 't̂', 'x', ']']

>> Named Entities are: 
 [('GPE', 'Lp')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('given', 'given'), ('predictor', 'predictor'), ('t̂', 't̂'), (',', ','), ('defined', 'defin'), ('Lp', 'lp'), ('(', '('), ('t̂', 't̂'), (')', ')'), ('=', '='), ('E', 'e'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼p', '∼p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('given', 'given'), ('predictor', 'predictor'), ('t̂', 't̂'), (',', ','), ('defined', 'defin'), ('Lp', 'lp'), ('(', '('), ('t̂', 't̂'), (')', ')'), ('=', '='), ('E', 'e'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼p', '∼p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('given', 'given'), ('predictor', 'predictor'), ('t̂', 't̂'), (',', ','), ('defined', 'defined'), ('Lp', 'Lp'), ('(', '('), ('t̂', 't̂'), (')', ')'), ('=', '='), ('E', 'E'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('∼p', '∼p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]



============================ Sentence 182 =============================

(2)  The generalization loss (2) is averaged over the distribu- tion of the test pair (x, t). 


>> Tokens are: 
 ['(', '2', ')', 'The', 'generalization', 'loss', '(', '2', ')', 'averaged', 'distribu-', 'tion', 'test', 'pair', '(', 'x', ',', ')', '.']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'The'), ('The', 'generalization'), ('generalization', 'loss'), ('loss', '('), ('(', '2'), ('2', ')'), (')', 'averaged'), ('averaged', 'distribu-'), ('distribu-', 'tion'), ('tion', 'test'), ('test', 'pair'), ('pair', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'The'), (')', 'The', 'generalization'), ('The', 'generalization', 'loss'), ('generalization', 'loss', '('), ('loss', '(', '2'), ('(', '2', ')'), ('2', ')', 'averaged'), (')', 'averaged', 'distribu-'), ('averaged', 'distribu-', 'tion'), ('distribu-', 'tion', 'test'), ('tion', 'test', 'pair'), ('test', 'pair', '('), ('pair', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('The', 'DT'), ('generalization', 'NN'), ('loss', 'NN'), ('(', '('), ('2', 'CD'), (')', ')'), ('averaged', 'VBD'), ('distribu-', 'JJ'), ('tion', 'NN'), ('test', 'NN'), ('pair', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('.', '.')]

 (S
  (/(
  2/CD
  )/)
  (NP The/DT generalization/NN loss/NN)
  (/(
  2/CD
  )/)
  averaged/VBD
  (NP distribu-/JJ tion/NN test/NN pair/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The generalization loss', 'distribu- tion test pair', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('The', 'the'), ('generalization', 'gener'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('averaged', 'averag'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('The', 'the'), ('generalization', 'general'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('averaged', 'averag'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('The', 'The'), ('generalization', 'generalization'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('averaged', 'averaged'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('test', 'test'), ('pair', 'pair'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]



============================ Sentence 183 =============================

Before moving on to the solution of the problem of minimizing the generalization loss, we mention that the formulation provided here is only one, albeit arguably the most popular, of a number of alternative formula- tions of supervised learning. 


>> Tokens are: 
 ['Before', 'moving', 'solution', 'problem', 'minimizing', 'generalization', 'loss', ',', 'mention', 'formulation', 'provided', 'one', ',', 'albeit', 'arguably', 'popular', ',', 'number', 'alternative', 'formula-', 'tions', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('Before', 'moving'), ('moving', 'solution'), ('solution', 'problem'), ('problem', 'minimizing'), ('minimizing', 'generalization'), ('generalization', 'loss'), ('loss', ','), (',', 'mention'), ('mention', 'formulation'), ('formulation', 'provided'), ('provided', 'one'), ('one', ','), (',', 'albeit'), ('albeit', 'arguably'), ('arguably', 'popular'), ('popular', ','), (',', 'number'), ('number', 'alternative'), ('alternative', 'formula-'), ('formula-', 'tions'), ('tions', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Before', 'moving', 'solution'), ('moving', 'solution', 'problem'), ('solution', 'problem', 'minimizing'), ('problem', 'minimizing', 'generalization'), ('minimizing', 'generalization', 'loss'), ('generalization', 'loss', ','), ('loss', ',', 'mention'), (',', 'mention', 'formulation'), ('mention', 'formulation', 'provided'), ('formulation', 'provided', 'one'), ('provided', 'one', ','), ('one', ',', 'albeit'), (',', 'albeit', 'arguably'), ('albeit', 'arguably', 'popular'), ('arguably', 'popular', ','), ('popular', ',', 'number'), (',', 'number', 'alternative'), ('number', 'alternative', 'formula-'), ('alternative', 'formula-', 'tions'), ('formula-', 'tions', 'supervised'), ('tions', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('Before', 'IN'), ('moving', 'VBG'), ('solution', 'NN'), ('problem', 'NN'), ('minimizing', 'VBG'), ('generalization', 'NN'), ('loss', 'NN'), (',', ','), ('mention', 'NN'), ('formulation', 'NN'), ('provided', 'VBD'), ('one', 'CD'), (',', ','), ('albeit', 'VBZ'), ('arguably', 'RB'), ('popular', 'JJ'), (',', ','), ('number', 'NN'), ('alternative', 'JJ'), ('formula-', 'JJ'), ('tions', 'NNS'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  Before/IN
  moving/VBG
  (NP solution/NN problem/NN)
  minimizing/VBG
  (NP generalization/NN loss/NN)
  ,/,
  (NP mention/NN formulation/NN)
  provided/VBD
  one/CD
  ,/,
  albeit/VBZ
  arguably/RB
  popular/JJ
  ,/,
  (NP number/NN)
  (NP alternative/JJ formula-/JJ tions/NNS)
  supervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['solution problem', 'generalization loss', 'mention formulation', 'number', 'alternative formula- tions', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Before', 'befor'), ('moving', 'move'), ('solution', 'solut'), ('problem', 'problem'), ('minimizing', 'minim'), ('generalization', 'gener'), ('loss', 'loss'), (',', ','), ('mention', 'mention'), ('formulation', 'formul'), ('provided', 'provid'), ('one', 'one'), (',', ','), ('albeit', 'albeit'), ('arguably', 'arguabl'), ('popular', 'popular'), (',', ','), ('number', 'number'), ('alternative', 'altern'), ('formula-', 'formula-'), ('tions', 'tion'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Before', 'befor'), ('moving', 'move'), ('solution', 'solut'), ('problem', 'problem'), ('minimizing', 'minim'), ('generalization', 'general'), ('loss', 'loss'), (',', ','), ('mention', 'mention'), ('formulation', 'formul'), ('provided', 'provid'), ('one', 'one'), (',', ','), ('albeit', 'albeit'), ('arguably', 'arguabl'), ('popular', 'popular'), (',', ','), ('number', 'number'), ('alternative', 'altern'), ('formula-', 'formula-'), ('tions', 'tion'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Before', 'Before'), ('moving', 'moving'), ('solution', 'solution'), ('problem', 'problem'), ('minimizing', 'minimizing'), ('generalization', 'generalization'), ('loss', 'loss'), (',', ','), ('mention', 'mention'), ('formulation', 'formulation'), ('provided', 'provided'), ('one', 'one'), (',', ','), ('albeit', 'albeit'), ('arguably', 'arguably'), ('popular', 'popular'), (',', ','), ('number', 'number'), ('alternative', 'alternative'), ('formula-', 'formula-'), ('tions', 'tions'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 184 =============================

The frequentist framework described above is in fact complemented by other view- points, including Bayesian and Minimum Description Length (MDL) (see [19] and references therein). 


>> Tokens are: 
 ['The', 'frequentist', 'framework', 'described', 'fact', 'complemented', 'view-', 'points', ',', 'including', 'Bayesian', 'Minimum', 'Description', 'Length', '(', 'MDL', ')', '(', 'see', '[', '19', ']', 'references', 'therein', ')', '.']

>> Bigrams are: 
 [('The', 'frequentist'), ('frequentist', 'framework'), ('framework', 'described'), ('described', 'fact'), ('fact', 'complemented'), ('complemented', 'view-'), ('view-', 'points'), ('points', ','), (',', 'including'), ('including', 'Bayesian'), ('Bayesian', 'Minimum'), ('Minimum', 'Description'), ('Description', 'Length'), ('Length', '('), ('(', 'MDL'), ('MDL', ')'), (')', '('), ('(', 'see'), ('see', '['), ('[', '19'), ('19', ']'), (']', 'references'), ('references', 'therein'), ('therein', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'frequentist', 'framework'), ('frequentist', 'framework', 'described'), ('framework', 'described', 'fact'), ('described', 'fact', 'complemented'), ('fact', 'complemented', 'view-'), ('complemented', 'view-', 'points'), ('view-', 'points', ','), ('points', ',', 'including'), (',', 'including', 'Bayesian'), ('including', 'Bayesian', 'Minimum'), ('Bayesian', 'Minimum', 'Description'), ('Minimum', 'Description', 'Length'), ('Description', 'Length', '('), ('Length', '(', 'MDL'), ('(', 'MDL', ')'), ('MDL', ')', '('), (')', '(', 'see'), ('(', 'see', '['), ('see', '[', '19'), ('[', '19', ']'), ('19', ']', 'references'), (']', 'references', 'therein'), ('references', 'therein', ')'), ('therein', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('frequentist', 'NN'), ('framework', 'NN'), ('described', 'VBD'), ('fact', 'NN'), ('complemented', 'VBN'), ('view-', 'JJ'), ('points', 'NNS'), (',', ','), ('including', 'VBG'), ('Bayesian', 'JJ'), ('Minimum', 'NNP'), ('Description', 'NNP'), ('Length', 'NNP'), ('(', '('), ('MDL', 'NNP'), (')', ')'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('19', 'CD'), (']', 'JJ'), ('references', 'NNS'), ('therein', 'RB'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT frequentist/NN framework/NN)
  described/VBD
  (NP fact/NN)
  complemented/VBN
  (NP view-/JJ points/NNS)
  ,/,
  including/VBG
  (NP Bayesian/JJ Minimum/NNP Description/NNP Length/NNP)
  (/(
  (NP MDL/NNP)
  )/)
  (/(
  see/VB
  [/RB
  19/CD
  (NP ]/JJ references/NNS)
  therein/RB
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The frequentist framework', 'fact', 'view- points', 'Bayesian Minimum Description Length', 'MDL', '] references']

>> Named Entities are: 
 [('PERSON', 'Bayesian Minimum'), ('ORGANIZATION', 'MDL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('frequentist', 'frequentist'), ('framework', 'framework'), ('described', 'describ'), ('fact', 'fact'), ('complemented', 'complement'), ('view-', 'view-'), ('points', 'point'), (',', ','), ('including', 'includ'), ('Bayesian', 'bayesian'), ('Minimum', 'minimum'), ('Description', 'descript'), ('Length', 'length'), ('(', '('), ('MDL', 'mdl'), (')', ')'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('frequentist', 'frequentist'), ('framework', 'framework'), ('described', 'describ'), ('fact', 'fact'), ('complemented', 'complement'), ('view-', 'view-'), ('points', 'point'), (',', ','), ('including', 'includ'), ('Bayesian', 'bayesian'), ('Minimum', 'minimum'), ('Description', 'descript'), ('Length', 'length'), ('(', '('), ('MDL', 'mdl'), (')', ')'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('frequentist', 'frequentist'), ('framework', 'framework'), ('described', 'described'), ('fact', 'fact'), ('complemented', 'complemented'), ('view-', 'view-'), ('points', 'point'), (',', ','), ('including', 'including'), ('Bayesian', 'Bayesian'), ('Minimum', 'Minimum'), ('Description', 'Description'), ('Length', 'Length'), ('(', '('), ('MDL', 'MDL'), (')', ')'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'reference'), ('therein', 'therein'), (')', ')'), ('.', '.')]



============================ Sentence 185 =============================

C. When The True Distribution p(x, t) is Known: Infer- ence  Consider first the case in which the true joint dis- tribution p(x, t) relating input and output is known. 


>> Tokens are: 
 ['C.', 'When', 'The', 'True', 'Distribution', 'p', '(', 'x', ',', ')', 'Known', ':', 'Infer-', 'ence', 'Consider', 'first', 'case', 'true', 'joint', 'dis-', 'tribution', 'p', '(', 'x', ',', ')', 'relating', 'input', 'output', 'known', '.']

>> Bigrams are: 
 [('C.', 'When'), ('When', 'The'), ('The', 'True'), ('True', 'Distribution'), ('Distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'Known'), ('Known', ':'), (':', 'Infer-'), ('Infer-', 'ence'), ('ence', 'Consider'), ('Consider', 'first'), ('first', 'case'), ('case', 'true'), ('true', 'joint'), ('joint', 'dis-'), ('dis-', 'tribution'), ('tribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'relating'), ('relating', 'input'), ('input', 'output'), ('output', 'known'), ('known', '.')]

>> Trigrams are: 
 [('C.', 'When', 'The'), ('When', 'The', 'True'), ('The', 'True', 'Distribution'), ('True', 'Distribution', 'p'), ('Distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'Known'), (')', 'Known', ':'), ('Known', ':', 'Infer-'), (':', 'Infer-', 'ence'), ('Infer-', 'ence', 'Consider'), ('ence', 'Consider', 'first'), ('Consider', 'first', 'case'), ('first', 'case', 'true'), ('case', 'true', 'joint'), ('true', 'joint', 'dis-'), ('joint', 'dis-', 'tribution'), ('dis-', 'tribution', 'p'), ('tribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'relating'), (')', 'relating', 'input'), ('relating', 'input', 'output'), ('input', 'output', 'known'), ('output', 'known', '.')]

>> POS Tags are: 
 [('C.', 'NNP'), ('When', 'WRB'), ('The', 'DT'), ('True', 'NNP'), ('Distribution', 'NNP'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('Known', 'VBN'), (':', ':'), ('Infer-', 'JJ'), ('ence', 'NN'), ('Consider', 'NNP'), ('first', 'JJ'), ('case', 'NN'), ('true', 'JJ'), ('joint', 'JJ'), ('dis-', 'JJ'), ('tribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('relating', 'VBG'), ('input', 'NN'), ('output', 'NN'), ('known', 'VBN'), ('.', '.')]

 (S
  (NP C./NNP)
  When/WRB
  (NP The/DT True/NNP Distribution/NNP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  Known/VBN
  :/:
  (NP Infer-/JJ ence/NN Consider/NNP)
  (NP first/JJ case/NN)
  (NP true/JJ joint/JJ dis-/JJ tribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  relating/VBG
  (NP input/NN output/NN)
  known/VBN
  ./.) 


>> Noun Phrases are: 
 ['C.', 'The True Distribution p', 'x', 'Infer- ence Consider', 'first case', 'true joint dis- tribution p', 'x', 'input output']

>> Named Entities are: 
 [('ORGANIZATION', 'True Distribution')] 

>> Stemming using Porter Stemmer: 
 [('C.', 'c.'), ('When', 'when'), ('The', 'the'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'known'), (':', ':'), ('Infer-', 'infer-'), ('ence', 'enc'), ('Consider', 'consid'), ('first', 'first'), ('case', 'case'), ('true', 'true'), ('joint', 'joint'), ('dis-', 'dis-'), ('tribution', 'tribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('relating', 'relat'), ('input', 'input'), ('output', 'output'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('C.', 'c.'), ('When', 'when'), ('The', 'the'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'known'), (':', ':'), ('Infer-', 'infer-'), ('ence', 'enc'), ('Consider', 'consid'), ('first', 'first'), ('case', 'case'), ('true', 'true'), ('joint', 'joint'), ('dis-', 'dis-'), ('tribution', 'tribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('relating', 'relat'), ('input', 'input'), ('output', 'output'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('C.', 'C.'), ('When', 'When'), ('The', 'The'), ('True', 'True'), ('Distribution', 'Distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'Known'), (':', ':'), ('Infer-', 'Infer-'), ('ence', 'ence'), ('Consider', 'Consider'), ('first', 'first'), ('case', 'case'), ('true', 'true'), ('joint', 'joint'), ('dis-', 'dis-'), ('tribution', 'tribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('relating', 'relating'), ('input', 'input'), ('output', 'output'), ('known', 'known'), ('.', '.')]



============================ Sentence 186 =============================

This scenario can be considered as an idealization of the situation resulting from the conventional engineering design flow when the available physics-based model is accurate (see Sec I). 


>> Tokens are: 
 ['This', 'scenario', 'considered', 'idealization', 'situation', 'resulting', 'conventional', 'engineering', 'design', 'flow', 'available', 'physics-based', 'model', 'accurate', '(', 'see', 'Sec', 'I', ')', '.']

>> Bigrams are: 
 [('This', 'scenario'), ('scenario', 'considered'), ('considered', 'idealization'), ('idealization', 'situation'), ('situation', 'resulting'), ('resulting', 'conventional'), ('conventional', 'engineering'), ('engineering', 'design'), ('design', 'flow'), ('flow', 'available'), ('available', 'physics-based'), ('physics-based', 'model'), ('model', 'accurate'), ('accurate', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'I'), ('I', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'scenario', 'considered'), ('scenario', 'considered', 'idealization'), ('considered', 'idealization', 'situation'), ('idealization', 'situation', 'resulting'), ('situation', 'resulting', 'conventional'), ('resulting', 'conventional', 'engineering'), ('conventional', 'engineering', 'design'), ('engineering', 'design', 'flow'), ('design', 'flow', 'available'), ('flow', 'available', 'physics-based'), ('available', 'physics-based', 'model'), ('physics-based', 'model', 'accurate'), ('model', 'accurate', '('), ('accurate', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'I'), ('Sec', 'I', ')'), ('I', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('scenario', 'NN'), ('considered', 'VBN'), ('idealization', 'NN'), ('situation', 'NN'), ('resulting', 'VBG'), ('conventional', 'JJ'), ('engineering', 'NN'), ('design', 'NN'), ('flow', 'NN'), ('available', 'JJ'), ('physics-based', 'JJ'), ('model', 'NN'), ('accurate', 'NN'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('I', 'PRP'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT scenario/NN)
  considered/VBN
  (NP idealization/NN situation/NN)
  resulting/VBG
  (NP conventional/JJ engineering/NN design/NN flow/NN)
  (NP available/JJ physics-based/JJ model/NN accurate/NN)
  (/(
  see/VB
  (NP Sec/NNP)
  I/PRP
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This scenario', 'idealization situation', 'conventional engineering design flow', 'available physics-based model accurate', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('scenario', 'scenario'), ('considered', 'consid'), ('idealization', 'ideal'), ('situation', 'situat'), ('resulting', 'result'), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), ('available', 'avail'), ('physics-based', 'physics-bas'), ('model', 'model'), ('accurate', 'accur'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('I', 'i'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('scenario', 'scenario'), ('considered', 'consid'), ('idealization', 'ideal'), ('situation', 'situat'), ('resulting', 'result'), ('conventional', 'convent'), ('engineering', 'engin'), ('design', 'design'), ('flow', 'flow'), ('available', 'avail'), ('physics-based', 'physics-bas'), ('model', 'model'), ('accurate', 'accur'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('I', 'i'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('scenario', 'scenario'), ('considered', 'considered'), ('idealization', 'idealization'), ('situation', 'situation'), ('resulting', 'resulting'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('design', 'design'), ('flow', 'flow'), ('available', 'available'), ('physics-based', 'physics-based'), ('model', 'model'), ('accurate', 'accurate'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('I', 'I'), (')', ')'), ('.', '.')]



============================ Sentence 187 =============================

Under this assumption, the data set  6    D is not necessary, since the mapping between input and output is fully described by the distribution p(x, t). 


>> Tokens are: 
 ['Under', 'assumption', ',', 'data', 'set', '6', 'D', 'necessary', ',', 'since', 'mapping', 'input', 'output', 'fully', 'described', 'distribution', 'p', '(', 'x', ',', ')', '.']

>> Bigrams are: 
 [('Under', 'assumption'), ('assumption', ','), (',', 'data'), ('data', 'set'), ('set', '6'), ('6', 'D'), ('D', 'necessary'), ('necessary', ','), (',', 'since'), ('since', 'mapping'), ('mapping', 'input'), ('input', 'output'), ('output', 'fully'), ('fully', 'described'), ('described', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '.')]

>> Trigrams are: 
 [('Under', 'assumption', ','), ('assumption', ',', 'data'), (',', 'data', 'set'), ('data', 'set', '6'), ('set', '6', 'D'), ('6', 'D', 'necessary'), ('D', 'necessary', ','), ('necessary', ',', 'since'), (',', 'since', 'mapping'), ('since', 'mapping', 'input'), ('mapping', 'input', 'output'), ('input', 'output', 'fully'), ('output', 'fully', 'described'), ('fully', 'described', 'distribution'), ('described', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '.')]

>> POS Tags are: 
 [('Under', 'IN'), ('assumption', 'NN'), (',', ','), ('data', 'NNS'), ('set', 'VBD'), ('6', 'CD'), ('D', 'NNP'), ('necessary', 'JJ'), (',', ','), ('since', 'IN'), ('mapping', 'VBG'), ('input', 'NN'), ('output', 'NN'), ('fully', 'RB'), ('described', 'VBN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('.', '.')]

 (S
  Under/IN
  (NP assumption/NN)
  ,/,
  (NP data/NNS)
  set/VBD
  6/CD
  (NP D/NNP)
  necessary/JJ
  ,/,
  since/IN
  mapping/VBG
  (NP input/NN output/NN)
  fully/RB
  described/VBN
  (NP distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ./.) 


>> Noun Phrases are: 
 ['assumption', 'data', 'D', 'input output', 'distribution p', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Under', 'under'), ('assumption', 'assumpt'), (',', ','), ('data', 'data'), ('set', 'set'), ('6', '6'), ('D', 'd'), ('necessary', 'necessari'), (',', ','), ('since', 'sinc'), ('mapping', 'map'), ('input', 'input'), ('output', 'output'), ('fully', 'fulli'), ('described', 'describ'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Under', 'under'), ('assumption', 'assumpt'), (',', ','), ('data', 'data'), ('set', 'set'), ('6', '6'), ('D', 'd'), ('necessary', 'necessari'), (',', ','), ('since', 'sinc'), ('mapping', 'map'), ('input', 'input'), ('output', 'output'), ('fully', 'fulli'), ('described', 'describ'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Under', 'Under'), ('assumption', 'assumption'), (',', ','), ('data', 'data'), ('set', 'set'), ('6', '6'), ('D', 'D'), ('necessary', 'necessary'), (',', ','), ('since', 'since'), ('mapping', 'mapping'), ('input', 'input'), ('output', 'output'), ('fully', 'fully'), ('described', 'described'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]



============================ Sentence 188 =============================

If the true distribution p(x, t) is known, the problem of minimizing the generalization loss reduces to a stan- dard inference problem, i.e.-, an estimation problem in a regression set-up, in which the outputs are continuous variables, or a detection problem in a classification set- up, in which the outputs are finite discrete variables. 


>> Tokens are: 
 ['If', 'true', 'distribution', 'p', '(', 'x', ',', ')', 'known', ',', 'problem', 'minimizing', 'generalization', 'loss', 'reduces', 'stan-', 'dard', 'inference', 'problem', ',', 'i.e.-', ',', 'estimation', 'problem', 'regression', 'set-up', ',', 'outputs', 'continuous', 'variables', ',', 'detection', 'problem', 'classification', 'set-', ',', 'outputs', 'finite', 'discrete', 'variables', '.']

>> Bigrams are: 
 [('If', 'true'), ('true', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'known'), ('known', ','), (',', 'problem'), ('problem', 'minimizing'), ('minimizing', 'generalization'), ('generalization', 'loss'), ('loss', 'reduces'), ('reduces', 'stan-'), ('stan-', 'dard'), ('dard', 'inference'), ('inference', 'problem'), ('problem', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'estimation'), ('estimation', 'problem'), ('problem', 'regression'), ('regression', 'set-up'), ('set-up', ','), (',', 'outputs'), ('outputs', 'continuous'), ('continuous', 'variables'), ('variables', ','), (',', 'detection'), ('detection', 'problem'), ('problem', 'classification'), ('classification', 'set-'), ('set-', ','), (',', 'outputs'), ('outputs', 'finite'), ('finite', 'discrete'), ('discrete', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('If', 'true', 'distribution'), ('true', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'known'), (')', 'known', ','), ('known', ',', 'problem'), (',', 'problem', 'minimizing'), ('problem', 'minimizing', 'generalization'), ('minimizing', 'generalization', 'loss'), ('generalization', 'loss', 'reduces'), ('loss', 'reduces', 'stan-'), ('reduces', 'stan-', 'dard'), ('stan-', 'dard', 'inference'), ('dard', 'inference', 'problem'), ('inference', 'problem', ','), ('problem', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'estimation'), (',', 'estimation', 'problem'), ('estimation', 'problem', 'regression'), ('problem', 'regression', 'set-up'), ('regression', 'set-up', ','), ('set-up', ',', 'outputs'), (',', 'outputs', 'continuous'), ('outputs', 'continuous', 'variables'), ('continuous', 'variables', ','), ('variables', ',', 'detection'), (',', 'detection', 'problem'), ('detection', 'problem', 'classification'), ('problem', 'classification', 'set-'), ('classification', 'set-', ','), ('set-', ',', 'outputs'), (',', 'outputs', 'finite'), ('outputs', 'finite', 'discrete'), ('finite', 'discrete', 'variables'), ('discrete', 'variables', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('true', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('known', 'VBN'), (',', ','), ('problem', 'NN'), ('minimizing', 'VBG'), ('generalization', 'NN'), ('loss', 'NN'), ('reduces', 'VBZ'), ('stan-', 'JJ'), ('dard', 'NN'), ('inference', 'NN'), ('problem', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('estimation', 'NN'), ('problem', 'NN'), ('regression', 'NN'), ('set-up', 'NN'), (',', ','), ('outputs', 'VBZ'), ('continuous', 'JJ'), ('variables', 'NNS'), (',', ','), ('detection', 'NN'), ('problem', 'NN'), ('classification', 'NN'), ('set-', 'NN'), (',', ','), ('outputs', 'VBZ'), ('finite', 'JJ'), ('discrete', 'JJ'), ('variables', 'NNS'), ('.', '.')]

 (S
  If/IN
  (NP true/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  known/VBN
  ,/,
  (NP problem/NN)
  minimizing/VBG
  (NP generalization/NN loss/NN)
  reduces/VBZ
  (NP stan-/JJ dard/NN inference/NN problem/NN)
  ,/,
  i.e.-/JJ
  ,/,
  (NP estimation/NN problem/NN regression/NN set-up/NN)
  ,/,
  outputs/VBZ
  (NP continuous/JJ variables/NNS)
  ,/,
  (NP detection/NN problem/NN classification/NN set-/NN)
  ,/,
  outputs/VBZ
  (NP finite/JJ discrete/JJ variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['true distribution p', 'x', 'problem', 'generalization loss', 'stan- dard inference problem', 'estimation problem regression set-up', 'continuous variables', 'detection problem classification set-', 'finite discrete variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('known', 'known'), (',', ','), ('problem', 'problem'), ('minimizing', 'minim'), ('generalization', 'gener'), ('loss', 'loss'), ('reduces', 'reduc'), ('stan-', 'stan-'), ('dard', 'dard'), ('inference', 'infer'), ('problem', 'problem'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('estimation', 'estim'), ('problem', 'problem'), ('regression', 'regress'), ('set-up', 'set-up'), (',', ','), ('outputs', 'output'), ('continuous', 'continu'), ('variables', 'variabl'), (',', ','), ('detection', 'detect'), ('problem', 'problem'), ('classification', 'classif'), ('set-', 'set-'), (',', ','), ('outputs', 'output'), ('finite', 'finit'), ('discrete', 'discret'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('known', 'known'), (',', ','), ('problem', 'problem'), ('minimizing', 'minim'), ('generalization', 'general'), ('loss', 'loss'), ('reduces', 'reduc'), ('stan-', 'stan-'), ('dard', 'dard'), ('inference', 'infer'), ('problem', 'problem'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('estimation', 'estim'), ('problem', 'problem'), ('regression', 'regress'), ('set-up', 'set-up'), (',', ','), ('outputs', 'output'), ('continuous', 'continu'), ('variables', 'variabl'), (',', ','), ('detection', 'detect'), ('problem', 'problem'), ('classification', 'classif'), ('set-', 'set-'), (',', ','), ('outputs', 'output'), ('finite', 'finit'), ('discrete', 'discret'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('true', 'true'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('known', 'known'), (',', ','), ('problem', 'problem'), ('minimizing', 'minimizing'), ('generalization', 'generalization'), ('loss', 'loss'), ('reduces', 'reduces'), ('stan-', 'stan-'), ('dard', 'dard'), ('inference', 'inference'), ('problem', 'problem'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('estimation', 'estimation'), ('problem', 'problem'), ('regression', 'regression'), ('set-up', 'set-up'), (',', ','), ('outputs', 'output'), ('continuous', 'continuous'), ('variables', 'variable'), (',', ','), ('detection', 'detection'), ('problem', 'problem'), ('classification', 'classification'), ('set-', 'set-'), (',', ','), ('outputs', 'output'), ('finite', 'finite'), ('discrete', 'discrete'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 189 =============================

In an inference problem, the optimal predictor t̂ can be directly computed from the posterior distribution  p(t|x) = p(x, t)  p(x) , (3)  where p(x) is the marginal distribution of the input x. 


>> Tokens are: 
 ['In', 'inference', 'problem', ',', 'optimal', 'predictor', 't̂', 'directly', 'computed', 'posterior', 'distribution', 'p', '(', 't|x', ')', '=', 'p', '(', 'x', ',', ')', 'p', '(', 'x', ')', ',', '(', '3', ')', 'p', '(', 'x', ')', 'marginal', 'distribution', 'input', 'x', '.']

>> Bigrams are: 
 [('In', 'inference'), ('inference', 'problem'), ('problem', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 't̂'), ('t̂', 'directly'), ('directly', 'computed'), ('computed', 'posterior'), ('posterior', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ')'), (')', '='), ('=', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', ','), (',', '('), ('(', '3'), ('3', ')'), (')', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'marginal'), ('marginal', 'distribution'), ('distribution', 'input'), ('input', 'x'), ('x', '.')]

>> Trigrams are: 
 [('In', 'inference', 'problem'), ('inference', 'problem', ','), ('problem', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 't̂'), ('predictor', 't̂', 'directly'), ('t̂', 'directly', 'computed'), ('directly', 'computed', 'posterior'), ('computed', 'posterior', 'distribution'), ('posterior', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', '='), (')', '=', 'p'), ('=', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'p'), (')', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', ','), (')', ',', '('), (',', '(', '3'), ('(', '3', ')'), ('3', ')', 'p'), (')', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'marginal'), (')', 'marginal', 'distribution'), ('marginal', 'distribution', 'input'), ('distribution', 'input', 'x'), ('input', 'x', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('inference', 'NN'), ('problem', 'NN'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('t̂', 'NN'), ('directly', 'RB'), ('computed', 'VBD'), ('posterior', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('=', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), (',', ','), ('(', '('), ('3', 'CD'), (')', ')'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('marginal', 'JJ'), ('distribution', 'NN'), ('input', 'NN'), ('x', 'NNP'), ('.', '.')]

 (S
  In/IN
  (NP inference/NN problem/NN)
  ,/,
  (NP optimal/JJ predictor/NN t̂/NN)
  directly/RB
  computed/VBD
  (NP posterior/JJ distribution/NN p/NN)
  (/(
  (NP t|x/NN)
  )/)
  (NP =/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  ,/,
  (/(
  3/CD
  )/)
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP marginal/JJ distribution/NN input/NN x/NNP)
  ./.) 


>> Noun Phrases are: 
 ['inference problem', 'optimal predictor t̂', 'posterior distribution p', 't|x', '= p', 'x', 'p', 'x', 'p', 'x', 'marginal distribution input x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('inference', 'infer'), ('problem', 'problem'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('t̂', 't̂'), ('directly', 'directli'), ('computed', 'comput'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('marginal', 'margin'), ('distribution', 'distribut'), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('inference', 'infer'), ('problem', 'problem'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('t̂', 't̂'), ('directly', 'direct'), ('computed', 'comput'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('marginal', 'margin'), ('distribution', 'distribut'), ('input', 'input'), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('inference', 'inference'), ('problem', 'problem'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('t̂', 't̂'), ('directly', 'directly'), ('computed', 'computed'), ('posterior', 'posterior'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('marginal', 'marginal'), ('distribution', 'distribution'), ('input', 'input'), ('x', 'x'), ('.', '.')]



============================ Sentence 190 =============================

The latter can be computed from the joint distribution p(x, t) by summing or integrating out all the values of t. In fact, given a loss function `(t, t̂), the optimal predictor for any input x is obtained as  t̂∗(x) = argmin t̂  Et∼p(t|x)[`(t, t̂)|x]. 


>> Tokens are: 
 ['The', 'latter', 'computed', 'joint', 'distribution', 'p', '(', 'x', ',', ')', 'summing', 'integrating', 'values', 't.', 'In', 'fact', ',', 'given', 'loss', 'function', '`', '(', ',', 't̂', ')', ',', 'optimal', 'predictor', 'input', 'x', 'obtained', 't̂∗', '(', 'x', ')', '=', 'argmin', 't̂', 'Et∼p', '(', 't|x', ')', '[', '`', '(', ',', 't̂', ')', '|x', ']', '.']

>> Bigrams are: 
 [('The', 'latter'), ('latter', 'computed'), ('computed', 'joint'), ('joint', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'summing'), ('summing', 'integrating'), ('integrating', 'values'), ('values', 't.'), ('t.', 'In'), ('In', 'fact'), ('fact', ','), (',', 'given'), ('given', 'loss'), ('loss', 'function'), ('function', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', ')'), (')', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'input'), ('input', 'x'), ('x', 'obtained'), ('obtained', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', 'argmin'), ('argmin', 't̂'), ('t̂', 'Et∼p'), ('Et∼p', '('), ('(', 't|x'), ('t|x', ')'), (')', '['), ('[', '`'), ('`', '('), ('(', ','), (',', 't̂'), ('t̂', ')'), (')', '|x'), ('|x', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'latter', 'computed'), ('latter', 'computed', 'joint'), ('computed', 'joint', 'distribution'), ('joint', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'summing'), (')', 'summing', 'integrating'), ('summing', 'integrating', 'values'), ('integrating', 'values', 't.'), ('values', 't.', 'In'), ('t.', 'In', 'fact'), ('In', 'fact', ','), ('fact', ',', 'given'), (',', 'given', 'loss'), ('given', 'loss', 'function'), ('loss', 'function', '`'), ('function', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', ')'), ('t̂', ')', ','), (')', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'input'), ('predictor', 'input', 'x'), ('input', 'x', 'obtained'), ('x', 'obtained', 't̂∗'), ('obtained', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', 'argmin'), ('=', 'argmin', 't̂'), ('argmin', 't̂', 'Et∼p'), ('t̂', 'Et∼p', '('), ('Et∼p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', '['), (')', '[', '`'), ('[', '`', '('), ('`', '(', ','), ('(', ',', 't̂'), (',', 't̂', ')'), ('t̂', ')', '|x'), (')', '|x', ']'), ('|x', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('latter', 'JJ'), ('computed', 'VBD'), ('joint', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('summing', 'VBG'), ('integrating', 'VBG'), ('values', 'NNS'), ('t.', 'VBP'), ('In', 'IN'), ('fact', 'NN'), (',', ','), ('given', 'VBN'), ('loss', 'NN'), ('function', 'NN'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), (')', ')'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('input', 'NN'), ('x', 'NNP'), ('obtained', 'VBD'), ('t̂∗', 'NNS'), ('(', '('), ('x', 'NN'), (')', ')'), ('=', 'VBZ'), ('argmin', 'JJ'), ('t̂', 'NN'), ('Et∼p', 'NNP'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('[', 'NN'), ('`', '``'), ('(', '('), (',', ','), ('t̂', 'NN'), (')', ')'), ('|x', 'NN'), (']', 'NN'), ('.', '.')]

 (S
  The/DT
  latter/JJ
  computed/VBD
  (NP joint/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  summing/VBG
  integrating/VBG
  (NP values/NNS)
  t./VBP
  In/IN
  (NP fact/NN)
  ,/,
  given/VBN
  (NP loss/NN function/NN)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  )/)
  ,/,
  (NP optimal/JJ predictor/NN input/NN x/NNP)
  obtained/VBD
  (NP t̂∗/NNS)
  (/(
  (NP x/NN)
  )/)
  =/VBZ
  (NP argmin/JJ t̂/NN Et∼p/NNP)
  (/(
  (NP t|x/NN)
  )/)
  (NP [/NN)
  `/``
  (/(
  ,/,
  (NP t̂/NN)
  )/)
  (NP |x/NN ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['joint distribution p', 'x', 'values', 'fact', 'loss function', 't̂', 'optimal predictor input x', 't̂∗', 'x', 'argmin t̂ Et∼p', 't|x', '[', 't̂', '|x ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('latter', 'latter'), ('computed', 'comput'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('summing', 'sum'), ('integrating', 'integr'), ('values', 'valu'), ('t.', 't.'), ('In', 'in'), ('fact', 'fact'), (',', ','), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('input', 'input'), ('x', 'x'), ('obtained', 'obtain'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmin', 'argmin'), ('t̂', 't̂'), ('Et∼p', 'et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('|x', '|x'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('latter', 'latter'), ('computed', 'comput'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('summing', 'sum'), ('integrating', 'integr'), ('values', 'valu'), ('t.', 't.'), ('In', 'in'), ('fact', 'fact'), (',', ','), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('input', 'input'), ('x', 'x'), ('obtained', 'obtain'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmin', 'argmin'), ('t̂', 't̂'), ('Et∼p', 'et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('|x', '|x'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('latter', 'latter'), ('computed', 'computed'), ('joint', 'joint'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('summing', 'summing'), ('integrating', 'integrating'), ('values', 'value'), ('t.', 't.'), ('In', 'In'), ('fact', 'fact'), (',', ','), ('given', 'given'), ('loss', 'loss'), ('function', 'function'), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('input', 'input'), ('x', 'x'), ('obtained', 'obtained'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmin', 'argmin'), ('t̂', 't̂'), ('Et∼p', 'Et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('`', '`'), ('(', '('), (',', ','), ('t̂', 't̂'), (')', ')'), ('|x', '|x'), (']', ']'), ('.', '.')]



============================ Sentence 191 =============================

(4)  In words, the optimal predictor t̂∗(x) is obtained by identifying the value (or values) of t that minimizes the average loss, where the average is taken with respect to the posterior distribution p(t|x) of the output given the input. 


>> Tokens are: 
 ['(', '4', ')', 'In', 'words', ',', 'optimal', 'predictor', 't̂∗', '(', 'x', ')', 'obtained', 'identifying', 'value', '(', 'values', ')', 'minimizes', 'average', 'loss', ',', 'average', 'taken', 'respect', 'posterior', 'distribution', 'p', '(', 't|x', ')', 'output', 'given', 'input', '.']

>> Bigrams are: 
 [('(', '4'), ('4', ')'), (')', 'In'), ('In', 'words'), ('words', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', 'obtained'), ('obtained', 'identifying'), ('identifying', 'value'), ('value', '('), ('(', 'values'), ('values', ')'), (')', 'minimizes'), ('minimizes', 'average'), ('average', 'loss'), ('loss', ','), (',', 'average'), ('average', 'taken'), ('taken', 'respect'), ('respect', 'posterior'), ('posterior', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ')'), (')', 'output'), ('output', 'given'), ('given', 'input'), ('input', '.')]

>> Trigrams are: 
 [('(', '4', ')'), ('4', ')', 'In'), (')', 'In', 'words'), ('In', 'words', ','), ('words', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 't̂∗'), ('predictor', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'obtained'), (')', 'obtained', 'identifying'), ('obtained', 'identifying', 'value'), ('identifying', 'value', '('), ('value', '(', 'values'), ('(', 'values', ')'), ('values', ')', 'minimizes'), (')', 'minimizes', 'average'), ('minimizes', 'average', 'loss'), ('average', 'loss', ','), ('loss', ',', 'average'), (',', 'average', 'taken'), ('average', 'taken', 'respect'), ('taken', 'respect', 'posterior'), ('respect', 'posterior', 'distribution'), ('posterior', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', 'output'), (')', 'output', 'given'), ('output', 'given', 'input'), ('given', 'input', '.')]

>> POS Tags are: 
 [('(', '('), ('4', 'CD'), (')', ')'), ('In', 'IN'), ('words', 'NNS'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('t̂∗', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('obtained', 'VBD'), ('identifying', 'VBG'), ('value', 'NN'), ('(', '('), ('values', 'NNS'), (')', ')'), ('minimizes', 'VBP'), ('average', 'JJ'), ('loss', 'NN'), (',', ','), ('average', 'JJ'), ('taken', 'VBN'), ('respect', 'NN'), ('posterior', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('output', 'NN'), ('given', 'VBN'), ('input', 'NN'), ('.', '.')]

 (S
  (/(
  4/CD
  )/)
  In/IN
  (NP words/NNS)
  ,/,
  (NP optimal/JJ predictor/NN t̂∗/NN)
  (/(
  (NP x/NNP)
  )/)
  obtained/VBD
  identifying/VBG
  (NP value/NN)
  (/(
  (NP values/NNS)
  )/)
  minimizes/VBP
  (NP average/JJ loss/NN)
  ,/,
  average/JJ
  taken/VBN
  (NP respect/NN)
  (NP posterior/JJ distribution/NN p/NN)
  (/(
  (NP t|x/NN)
  )/)
  (NP output/NN)
  given/VBN
  (NP input/NN)
  ./.) 


>> Noun Phrases are: 
 ['words', 'optimal predictor t̂∗', 'x', 'value', 'values', 'average loss', 'respect', 'posterior distribution p', 't|x', 'output', 'input']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('4', '4'), (')', ')'), ('In', 'in'), ('words', 'word'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('obtained', 'obtain'), ('identifying', 'identifi'), ('value', 'valu'), ('(', '('), ('values', 'valu'), (')', ')'), ('minimizes', 'minim'), ('average', 'averag'), ('loss', 'loss'), (',', ','), ('average', 'averag'), ('taken', 'taken'), ('respect', 'respect'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('4', '4'), (')', ')'), ('In', 'in'), ('words', 'word'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('obtained', 'obtain'), ('identifying', 'identifi'), ('value', 'valu'), ('(', '('), ('values', 'valu'), (')', ')'), ('minimizes', 'minim'), ('average', 'averag'), ('loss', 'loss'), (',', ','), ('average', 'averag'), ('taken', 'taken'), ('respect', 'respect'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('4', '4'), (')', ')'), ('In', 'In'), ('words', 'word'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('obtained', 'obtained'), ('identifying', 'identifying'), ('value', 'value'), ('(', '('), ('values', 'value'), (')', ')'), ('minimizes', 'minimizes'), ('average', 'average'), ('loss', 'loss'), (',', ','), ('average', 'average'), ('taken', 'taken'), ('respect', 'respect'), ('posterior', 'posterior'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('output', 'output'), ('given', 'given'), ('input', 'input'), ('.', '.')]



============================ Sentence 192 =============================

Given that the posterior p(t|x) yields the optimal predictor, it is also known as the true predictive distribution. 


>> Tokens are: 
 ['Given', 'posterior', 'p', '(', 't|x', ')', 'yields', 'optimal', 'predictor', ',', 'also', 'known', 'true', 'predictive', 'distribution', '.']

>> Bigrams are: 
 [('Given', 'posterior'), ('posterior', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ')'), (')', 'yields'), ('yields', 'optimal'), ('optimal', 'predictor'), ('predictor', ','), (',', 'also'), ('also', 'known'), ('known', 'true'), ('true', 'predictive'), ('predictive', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('Given', 'posterior', 'p'), ('posterior', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', 'yields'), (')', 'yields', 'optimal'), ('yields', 'optimal', 'predictor'), ('optimal', 'predictor', ','), ('predictor', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'true'), ('known', 'true', 'predictive'), ('true', 'predictive', 'distribution'), ('predictive', 'distribution', '.')]

>> POS Tags are: 
 [('Given', 'VBN'), ('posterior', 'JJ'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('yields', 'VBZ'), ('optimal', 'JJ'), ('predictor', 'NN'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('true', 'JJ'), ('predictive', 'JJ'), ('distribution', 'NN'), ('.', '.')]

 (S
  Given/VBN
  (NP posterior/JJ p/NN)
  (/(
  (NP t|x/NN)
  )/)
  yields/VBZ
  (NP optimal/JJ predictor/NN)
  ,/,
  also/RB
  known/VBN
  (NP true/JJ predictive/JJ distribution/NN)
  ./.) 


>> Noun Phrases are: 
 ['posterior p', 't|x', 'optimal predictor', 'true predictive distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Given', 'given'), ('posterior', 'posterior'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('yields', 'yield'), ('optimal', 'optim'), ('predictor', 'predictor'), (',', ','), ('also', 'also'), ('known', 'known'), ('true', 'true'), ('predictive', 'predict'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Given', 'given'), ('posterior', 'posterior'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('yields', 'yield'), ('optimal', 'optim'), ('predictor', 'predictor'), (',', ','), ('also', 'also'), ('known', 'known'), ('true', 'true'), ('predictive', 'predict'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('Given', 'Given'), ('posterior', 'posterior'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('yields', 'yield'), ('optimal', 'optimal'), ('predictor', 'predictor'), (',', ','), ('also', 'also'), ('known', 'known'), ('true', 'true'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('.', '.')]



============================ Sentence 193 =============================

The optimal predictor (4) can be explicitly evaluated for given loss functions. 


>> Tokens are: 
 ['The', 'optimal', 'predictor', '(', '4', ')', 'explicitly', 'evaluated', 'given', 'loss', 'functions', '.']

>> Bigrams are: 
 [('The', 'optimal'), ('optimal', 'predictor'), ('predictor', '('), ('(', '4'), ('4', ')'), (')', 'explicitly'), ('explicitly', 'evaluated'), ('evaluated', 'given'), ('given', 'loss'), ('loss', 'functions'), ('functions', '.')]

>> Trigrams are: 
 [('The', 'optimal', 'predictor'), ('optimal', 'predictor', '('), ('predictor', '(', '4'), ('(', '4', ')'), ('4', ')', 'explicitly'), (')', 'explicitly', 'evaluated'), ('explicitly', 'evaluated', 'given'), ('evaluated', 'given', 'loss'), ('given', 'loss', 'functions'), ('loss', 'functions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('optimal', 'JJ'), ('predictor', 'NN'), ('(', '('), ('4', 'CD'), (')', ')'), ('explicitly', 'RB'), ('evaluated', 'VBD'), ('given', 'VBN'), ('loss', 'NN'), ('functions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT optimal/JJ predictor/NN)
  (/(
  4/CD
  )/)
  explicitly/RB
  evaluated/VBD
  given/VBN
  (NP loss/NN functions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The optimal predictor', 'loss functions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('optimal', 'optim'), ('predictor', 'predictor'), ('(', '('), ('4', '4'), (')', ')'), ('explicitly', 'explicitli'), ('evaluated', 'evalu'), ('given', 'given'), ('loss', 'loss'), ('functions', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('optimal', 'optim'), ('predictor', 'predictor'), ('(', '('), ('4', '4'), (')', ')'), ('explicitly', 'explicit'), ('evaluated', 'evalu'), ('given', 'given'), ('loss', 'loss'), ('functions', 'function'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('optimal', 'optimal'), ('predictor', 'predictor'), ('(', '('), ('4', '4'), (')', ')'), ('explicitly', 'explicitly'), ('evaluated', 'evaluated'), ('given', 'given'), ('loss', 'loss'), ('functions', 'function'), ('.', '.')]



============================ Sentence 194 =============================

For instance, for the quadratic loss, which is typical for regression, the optimal predictor is given by the mean of the predictive distribution, or the posterior mean, i.e.-,  t̂∗(x) = Et∼p(t|x)[t|x], (5)  while, with the error rate loss, which is typical for classification, problems, the optimal predictor is given by the maximum of the predictive distribution, or the maximum a posteriori (MAP) estimate, i.e.-,  t̂∗(x) = argmax t p(t|x). 


>> Tokens are: 
 ['For', 'instance', ',', 'quadratic', 'loss', ',', 'typical', 'regression', ',', 'optimal', 'predictor', 'given', 'mean', 'predictive', 'distribution', ',', 'posterior', 'mean', ',', 'i.e.-', ',', 't̂∗', '(', 'x', ')', '=', 'Et∼p', '(', 't|x', ')', '[', 't|x', ']', ',', '(', '5', ')', ',', 'error', 'rate', 'loss', ',', 'typical', 'classification', ',', 'problems', ',', 'optimal', 'predictor', 'given', 'maximum', 'predictive', 'distribution', ',', 'maximum', 'posteriori', '(', 'MAP', ')', 'estimate', ',', 'i.e.-', ',', 't̂∗', '(', 'x', ')', '=', 'argmax', 'p', '(', 't|x', ')', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'quadratic'), ('quadratic', 'loss'), ('loss', ','), (',', 'typical'), ('typical', 'regression'), ('regression', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'given'), ('given', 'mean'), ('mean', 'predictive'), ('predictive', 'distribution'), ('distribution', ','), (',', 'posterior'), ('posterior', 'mean'), ('mean', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', 'Et∼p'), ('Et∼p', '('), ('(', 't|x'), ('t|x', ')'), (')', '['), ('[', 't|x'), ('t|x', ']'), (']', ','), (',', '('), ('(', '5'), ('5', ')'), (')', ','), (',', 'error'), ('error', 'rate'), ('rate', 'loss'), ('loss', ','), (',', 'typical'), ('typical', 'classification'), ('classification', ','), (',', 'problems'), ('problems', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'given'), ('given', 'maximum'), ('maximum', 'predictive'), ('predictive', 'distribution'), ('distribution', ','), (',', 'maximum'), ('maximum', 'posteriori'), ('posteriori', '('), ('(', 'MAP'), ('MAP', ')'), (')', 'estimate'), ('estimate', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', 'argmax'), ('argmax', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ')'), (')', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'quadratic'), (',', 'quadratic', 'loss'), ('quadratic', 'loss', ','), ('loss', ',', 'typical'), (',', 'typical', 'regression'), ('typical', 'regression', ','), ('regression', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'given'), ('predictor', 'given', 'mean'), ('given', 'mean', 'predictive'), ('mean', 'predictive', 'distribution'), ('predictive', 'distribution', ','), ('distribution', ',', 'posterior'), (',', 'posterior', 'mean'), ('posterior', 'mean', ','), ('mean', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 't̂∗'), (',', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', 'Et∼p'), ('=', 'Et∼p', '('), ('Et∼p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', '['), (')', '[', 't|x'), ('[', 't|x', ']'), ('t|x', ']', ','), (']', ',', '('), (',', '(', '5'), ('(', '5', ')'), ('5', ')', ','), (')', ',', 'error'), (',', 'error', 'rate'), ('error', 'rate', 'loss'), ('rate', 'loss', ','), ('loss', ',', 'typical'), (',', 'typical', 'classification'), ('typical', 'classification', ','), ('classification', ',', 'problems'), (',', 'problems', ','), ('problems', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'given'), ('predictor', 'given', 'maximum'), ('given', 'maximum', 'predictive'), ('maximum', 'predictive', 'distribution'), ('predictive', 'distribution', ','), ('distribution', ',', 'maximum'), (',', 'maximum', 'posteriori'), ('maximum', 'posteriori', '('), ('posteriori', '(', 'MAP'), ('(', 'MAP', ')'), ('MAP', ')', 'estimate'), (')', 'estimate', ','), ('estimate', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 't̂∗'), (',', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', 'argmax'), ('=', 'argmax', 'p'), ('argmax', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('quadratic', 'JJ'), ('loss', 'NN'), (',', ','), ('typical', 'JJ'), ('regression', 'NN'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('given', 'VBN'), ('mean', 'JJ'), ('predictive', 'JJ'), ('distribution', 'NN'), (',', ','), ('posterior', 'JJ'), ('mean', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('t̂∗', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBP'), ('Et∼p', 'NNP'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('[', 'VBZ'), ('t|x', 'JJ'), (']', 'NN'), (',', ','), ('(', '('), ('5', 'CD'), (')', ')'), (',', ','), ('error', 'JJ'), ('rate', 'NN'), ('loss', 'NN'), (',', ','), ('typical', 'JJ'), ('classification', 'NN'), (',', ','), ('problems', 'NNS'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('given', 'VBN'), ('maximum', 'JJ'), ('predictive', 'JJ'), ('distribution', 'NN'), (',', ','), ('maximum', 'JJ'), ('posteriori', 'NN'), ('(', '('), ('MAP', 'NNP'), (')', ')'), ('estimate', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('t̂∗', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBP'), ('argmax', 'JJ'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN)
  ,/,
  (NP quadratic/JJ loss/NN)
  ,/,
  (NP typical/JJ regression/NN)
  ,/,
  (NP optimal/JJ predictor/NN)
  given/VBN
  (NP mean/JJ predictive/JJ distribution/NN)
  ,/,
  (NP posterior/JJ mean/NN)
  ,/,
  i.e.-/JJ
  ,/,
  (NP t̂∗/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBP
  (NP Et∼p/NNP)
  (/(
  (NP t|x/NN)
  )/)
  [/VBZ
  (NP t|x/JJ ]/NN)
  ,/,
  (/(
  5/CD
  )/)
  ,/,
  (NP error/JJ rate/NN loss/NN)
  ,/,
  (NP typical/JJ classification/NN)
  ,/,
  (NP problems/NNS)
  ,/,
  (NP optimal/JJ predictor/NN)
  given/VBN
  (NP maximum/JJ predictive/JJ distribution/NN)
  ,/,
  (NP maximum/JJ posteriori/NN)
  (/(
  (NP MAP/NNP)
  )/)
  (NP estimate/NN)
  ,/,
  i.e.-/JJ
  ,/,
  (NP t̂∗/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBP
  (NP argmax/JJ p/NN)
  (/(
  (NP t|x/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'quadratic loss', 'typical regression', 'optimal predictor', 'mean predictive distribution', 'posterior mean', 't̂∗', 'x', 'Et∼p', 't|x', 't|x ]', 'error rate loss', 'typical classification', 'problems', 'optimal predictor', 'maximum predictive distribution', 'maximum posteriori', 'MAP', 'estimate', 't̂∗', 'x', 'argmax p', 't|x']

>> Named Entities are: 
 [('ORGANIZATION', 'MAP')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('typical', 'typic'), ('regression', 'regress'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('mean', 'mean'), ('predictive', 'predict'), ('distribution', 'distribut'), (',', ','), ('posterior', 'posterior'), ('mean', 'mean'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('Et∼p', 'et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('t|x', 't|x'), (']', ']'), (',', ','), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), (',', ','), ('typical', 'typic'), ('classification', 'classif'), (',', ','), ('problems', 'problem'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('maximum', 'maximum'), ('predictive', 'predict'), ('distribution', 'distribut'), (',', ','), ('maximum', 'maximum'), ('posteriori', 'posteriori'), ('(', '('), ('MAP', 'map'), (')', ')'), ('estimate', 'estim'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmax', 'argmax'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('typical', 'typic'), ('regression', 'regress'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('mean', 'mean'), ('predictive', 'predict'), ('distribution', 'distribut'), (',', ','), ('posterior', 'posterior'), ('mean', 'mean'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('Et∼p', 'et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('t|x', 't|x'), (']', ']'), (',', ','), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), (',', ','), ('typical', 'typic'), ('classification', 'classif'), (',', ','), ('problems', 'problem'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('maximum', 'maximum'), ('predictive', 'predict'), ('distribution', 'distribut'), (',', ','), ('maximum', 'maximum'), ('posteriori', 'posteriori'), ('(', '('), ('MAP', 'map'), (')', ')'), ('estimate', 'estim'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmax', 'argmax'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('quadratic', 'quadratic'), ('loss', 'loss'), (',', ','), ('typical', 'typical'), ('regression', 'regression'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('given', 'given'), ('mean', 'mean'), ('predictive', 'predictive'), ('distribution', 'distribution'), (',', ','), ('posterior', 'posterior'), ('mean', 'mean'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('Et∼p', 'Et∼p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('[', '['), ('t|x', 't|x'), (']', ']'), (',', ','), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), (',', ','), ('typical', 'typical'), ('classification', 'classification'), (',', ','), ('problems', 'problem'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('given', 'given'), ('maximum', 'maximum'), ('predictive', 'predictive'), ('distribution', 'distribution'), (',', ','), ('maximum', 'maximum'), ('posteriori', 'posteriori'), ('(', '('), ('MAP', 'MAP'), (')', ')'), ('estimate', 'estimate'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('argmax', 'argmax'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('.', '.')]



============================ Sentence 195 =============================

(6)  For a numerical example, consider binary inputs and outputs and the joint distribution p(x, t) such that p(0, 0) = 0.05, p(0, 1) = 0.45, p(1, 0) = 0.4 and p(1, 1) = 0.1. 


>> Tokens are: 
 ['(', '6', ')', 'For', 'numerical', 'example', ',', 'consider', 'binary', 'inputs', 'outputs', 'joint', 'distribution', 'p', '(', 'x', ',', ')', 'p', '(', '0', ',', '0', ')', '=', '0.05', ',', 'p', '(', '0', ',', '1', ')', '=', '0.45', ',', 'p', '(', '1', ',', '0', ')', '=', '0.4', 'p', '(', '1', ',', '1', ')', '=', '0.1', '.']

>> Bigrams are: 
 [('(', '6'), ('6', ')'), (')', 'For'), ('For', 'numerical'), ('numerical', 'example'), ('example', ','), (',', 'consider'), ('consider', 'binary'), ('binary', 'inputs'), ('inputs', 'outputs'), ('outputs', 'joint'), ('joint', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'p'), ('p', '('), ('(', '0'), ('0', ','), (',', '0'), ('0', ')'), (')', '='), ('=', '0.05'), ('0.05', ','), (',', 'p'), ('p', '('), ('(', '0'), ('0', ','), (',', '1'), ('1', ')'), (')', '='), ('=', '0.45'), ('0.45', ','), (',', 'p'), ('p', '('), ('(', '1'), ('1', ','), (',', '0'), ('0', ')'), (')', '='), ('=', '0.4'), ('0.4', 'p'), ('p', '('), ('(', '1'), ('1', ','), (',', '1'), ('1', ')'), (')', '='), ('=', '0.1'), ('0.1', '.')]

>> Trigrams are: 
 [('(', '6', ')'), ('6', ')', 'For'), (')', 'For', 'numerical'), ('For', 'numerical', 'example'), ('numerical', 'example', ','), ('example', ',', 'consider'), (',', 'consider', 'binary'), ('consider', 'binary', 'inputs'), ('binary', 'inputs', 'outputs'), ('inputs', 'outputs', 'joint'), ('outputs', 'joint', 'distribution'), ('joint', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'p'), (')', 'p', '('), ('p', '(', '0'), ('(', '0', ','), ('0', ',', '0'), (',', '0', ')'), ('0', ')', '='), (')', '=', '0.05'), ('=', '0.05', ','), ('0.05', ',', 'p'), (',', 'p', '('), ('p', '(', '0'), ('(', '0', ','), ('0', ',', '1'), (',', '1', ')'), ('1', ')', '='), (')', '=', '0.45'), ('=', '0.45', ','), ('0.45', ',', 'p'), (',', 'p', '('), ('p', '(', '1'), ('(', '1', ','), ('1', ',', '0'), (',', '0', ')'), ('0', ')', '='), (')', '=', '0.4'), ('=', '0.4', 'p'), ('0.4', 'p', '('), ('p', '(', '1'), ('(', '1', ','), ('1', ',', '1'), (',', '1', ')'), ('1', ')', '='), (')', '=', '0.1'), ('=', '0.1', '.')]

>> POS Tags are: 
 [('(', '('), ('6', 'CD'), (')', ')'), ('For', 'IN'), ('numerical', 'JJ'), ('example', 'NN'), (',', ','), ('consider', 'VB'), ('binary', 'JJ'), ('inputs', 'NNS'), ('outputs', 'NNS'), ('joint', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('p', 'NN'), ('(', '('), ('0', 'CD'), (',', ','), ('0', 'CD'), (')', ')'), ('=', 'NN'), ('0.05', 'CD'), (',', ','), ('p', 'NN'), ('(', '('), ('0', 'CD'), (',', ','), ('1', 'CD'), (')', ')'), ('=', 'NN'), ('0.45', 'CD'), (',', ','), ('p', 'NN'), ('(', '('), ('1', 'CD'), (',', ','), ('0', 'CD'), (')', ')'), ('=', 'VBD'), ('0.4', 'CD'), ('p', 'NN'), ('(', '('), ('1', 'CD'), (',', ','), ('1', 'CD'), (')', ')'), ('=', 'NN'), ('0.1', 'CD'), ('.', '.')]

 (S
  (/(
  6/CD
  )/)
  For/IN
  (NP numerical/JJ example/NN)
  ,/,
  consider/VB
  (NP binary/JJ inputs/NNS outputs/NNS)
  (NP joint/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  (NP p/NN)
  (/(
  0/CD
  ,/,
  0/CD
  )/)
  (NP =/NN)
  0.05/CD
  ,/,
  (NP p/NN)
  (/(
  0/CD
  ,/,
  1/CD
  )/)
  (NP =/NN)
  0.45/CD
  ,/,
  (NP p/NN)
  (/(
  1/CD
  ,/,
  0/CD
  )/)
  =/VBD
  0.4/CD
  (NP p/NN)
  (/(
  1/CD
  ,/,
  1/CD
  )/)
  (NP =/NN)
  0.1/CD
  ./.) 


>> Noun Phrases are: 
 ['numerical example', 'binary inputs outputs', 'joint distribution p', 'x', 'p', '=', 'p', '=', 'p', 'p', '=']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('6', '6'), (')', ')'), ('For', 'for'), ('numerical', 'numer'), ('example', 'exampl'), (',', ','), ('consider', 'consid'), ('binary', 'binari'), ('inputs', 'input'), ('outputs', 'output'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.05', '0.05'), (',', ','), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.45', '0.45'), (',', ','), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.4', '0.4'), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.1', '0.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('6', '6'), (')', ')'), ('For', 'for'), ('numerical', 'numer'), ('example', 'exampl'), (',', ','), ('consider', 'consid'), ('binary', 'binari'), ('inputs', 'input'), ('outputs', 'output'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.05', '0.05'), (',', ','), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.45', '0.45'), (',', ','), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.4', '0.4'), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.1', '0.1'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('6', '6'), (')', ')'), ('For', 'For'), ('numerical', 'numerical'), ('example', 'example'), (',', ','), ('consider', 'consider'), ('binary', 'binary'), ('inputs', 'input'), ('outputs', 'output'), ('joint', 'joint'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.05', '0.05'), (',', ','), ('p', 'p'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.45', '0.45'), (',', ','), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('0', '0'), (')', ')'), ('=', '='), ('0.4', '0.4'), ('p', 'p'), ('(', '('), ('1', '1'), (',', ','), ('1', '1'), (')', ')'), ('=', '='), ('0.1', '0.1'), ('.', '.')]



============================ Sentence 196 =============================

The predictive distribution for input x = 0 is then given as p(t = 1|x = 0) = 0.9, and hence we have the optimal predictor given by the average t̂∗(x = 0) = 0.9 × 1 + 0.1 × 0 = 0.9 for the quadratic loss, and by the MAP solution t̂∗(x = 0) = 1 for the error rate loss. 


>> Tokens are: 
 ['The', 'predictive', 'distribution', 'input', 'x', '=', '0', 'given', 'p', '(', '=', '1|x', '=', '0', ')', '=', '0.9', ',', 'hence', 'optimal', 'predictor', 'given', 'average', 't̂∗', '(', 'x', '=', '0', ')', '=', '0.9', '×', '1', '+', '0.1', '×', '0', '=', '0.9', 'quadratic', 'loss', ',', 'MAP', 'solution', 't̂∗', '(', 'x', '=', '0', ')', '=', '1', 'error', 'rate', 'loss', '.']

>> Bigrams are: 
 [('The', 'predictive'), ('predictive', 'distribution'), ('distribution', 'input'), ('input', 'x'), ('x', '='), ('=', '0'), ('0', 'given'), ('given', 'p'), ('p', '('), ('(', '='), ('=', '1|x'), ('1|x', '='), ('=', '0'), ('0', ')'), (')', '='), ('=', '0.9'), ('0.9', ','), (',', 'hence'), ('hence', 'optimal'), ('optimal', 'predictor'), ('predictor', 'given'), ('given', 'average'), ('average', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', '='), ('=', '0'), ('0', ')'), (')', '='), ('=', '0.9'), ('0.9', '×'), ('×', '1'), ('1', '+'), ('+', '0.1'), ('0.1', '×'), ('×', '0'), ('0', '='), ('=', '0.9'), ('0.9', 'quadratic'), ('quadratic', 'loss'), ('loss', ','), (',', 'MAP'), ('MAP', 'solution'), ('solution', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', '='), ('=', '0'), ('0', ')'), (')', '='), ('=', '1'), ('1', 'error'), ('error', 'rate'), ('rate', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('The', 'predictive', 'distribution'), ('predictive', 'distribution', 'input'), ('distribution', 'input', 'x'), ('input', 'x', '='), ('x', '=', '0'), ('=', '0', 'given'), ('0', 'given', 'p'), ('given', 'p', '('), ('p', '(', '='), ('(', '=', '1|x'), ('=', '1|x', '='), ('1|x', '=', '0'), ('=', '0', ')'), ('0', ')', '='), (')', '=', '0.9'), ('=', '0.9', ','), ('0.9', ',', 'hence'), (',', 'hence', 'optimal'), ('hence', 'optimal', 'predictor'), ('optimal', 'predictor', 'given'), ('predictor', 'given', 'average'), ('given', 'average', 't̂∗'), ('average', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', '='), ('x', '=', '0'), ('=', '0', ')'), ('0', ')', '='), (')', '=', '0.9'), ('=', '0.9', '×'), ('0.9', '×', '1'), ('×', '1', '+'), ('1', '+', '0.1'), ('+', '0.1', '×'), ('0.1', '×', '0'), ('×', '0', '='), ('0', '=', '0.9'), ('=', '0.9', 'quadratic'), ('0.9', 'quadratic', 'loss'), ('quadratic', 'loss', ','), ('loss', ',', 'MAP'), (',', 'MAP', 'solution'), ('MAP', 'solution', 't̂∗'), ('solution', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', '='), ('x', '=', '0'), ('=', '0', ')'), ('0', ')', '='), (')', '=', '1'), ('=', '1', 'error'), ('1', 'error', 'rate'), ('error', 'rate', 'loss'), ('rate', 'loss', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('predictive', 'JJ'), ('distribution', 'NN'), ('input', 'NN'), ('x', 'NNP'), ('=', 'VBZ'), ('0', 'CD'), ('given', 'VBN'), ('p', 'NN'), ('(', '('), ('=', 'JJ'), ('1|x', 'CD'), ('=', '$'), ('0', 'CD'), (')', ')'), ('=', 'NN'), ('0.9', 'CD'), (',', ','), ('hence', 'RB'), ('optimal', 'JJ'), ('predictor', 'NN'), ('given', 'VBN'), ('average', 'JJ'), ('t̂∗', 'NN'), ('(', '('), ('x', 'JJ'), ('=', 'NNP'), ('0', 'CD'), (')', ')'), ('=', 'VBD'), ('0.9', 'CD'), ('×', 'JJ'), ('1', 'CD'), ('+', 'JJ'), ('0.1', 'CD'), ('×', 'JJ'), ('0', 'CD'), ('=', 'JJ'), ('0.9', 'CD'), ('quadratic', 'JJ'), ('loss', 'NN'), (',', ','), ('MAP', 'NNP'), ('solution', 'NN'), ('t̂∗', 'NN'), ('(', '('), ('x', 'JJ'), ('=', 'NNP'), ('0', 'CD'), (')', ')'), ('=', 'VBD'), ('1', 'CD'), ('error', 'NN'), ('rate', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  (NP The/DT predictive/JJ distribution/NN input/NN x/NNP)
  =/VBZ
  0/CD
  given/VBN
  (NP p/NN)
  (/(
  =/JJ
  1|x/CD
  =/$
  0/CD
  )/)
  (NP =/NN)
  0.9/CD
  ,/,
  hence/RB
  (NP optimal/JJ predictor/NN)
  given/VBN
  (NP average/JJ t̂∗/NN)
  (/(
  (NP x/JJ =/NNP)
  0/CD
  )/)
  =/VBD
  0.9/CD
  ×/JJ
  1/CD
  +/JJ
  0.1/CD
  ×/JJ
  0/CD
  =/JJ
  0.9/CD
  (NP quadratic/JJ loss/NN)
  ,/,
  (NP MAP/NNP solution/NN t̂∗/NN)
  (/(
  (NP x/JJ =/NNP)
  0/CD
  )/)
  =/VBD
  1/CD
  (NP error/NN rate/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['The predictive distribution input x', 'p', '=', 'optimal predictor', 'average t̂∗', 'x =', 'quadratic loss', 'MAP solution t̂∗', 'x =', 'error rate loss']

>> Named Entities are: 
 [('ORGANIZATION', 'MAP')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('predictive', 'predict'), ('distribution', 'distribut'), ('input', 'input'), ('x', 'x'), ('=', '='), ('0', '0'), ('given', 'given'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), (',', ','), ('hence', 'henc'), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('average', 'averag'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), ('×', '×'), ('1', '1'), ('+', '+'), ('0.1', '0.1'), ('×', '×'), ('0', '0'), ('=', '='), ('0.9', '0.9'), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('MAP', 'map'), ('solution', 'solut'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('1', '1'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('predictive', 'predict'), ('distribution', 'distribut'), ('input', 'input'), ('x', 'x'), ('=', '='), ('0', '0'), ('given', 'given'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), (',', ','), ('hence', 'henc'), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('average', 'averag'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), ('×', '×'), ('1', '1'), ('+', '+'), ('0.1', '0.1'), ('×', '×'), ('0', '0'), ('=', '='), ('0.9', '0.9'), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('MAP', 'map'), ('solution', 'solut'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('1', '1'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('input', 'input'), ('x', 'x'), ('=', '='), ('0', '0'), ('given', 'given'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), (',', ','), ('hence', 'hence'), ('optimal', 'optimal'), ('predictor', 'predictor'), ('given', 'given'), ('average', 'average'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('0.9', '0.9'), ('×', '×'), ('1', '1'), ('+', '+'), ('0.1', '0.1'), ('×', '×'), ('0', '0'), ('=', '='), ('0.9', '0.9'), ('quadratic', 'quadratic'), ('loss', 'loss'), (',', ','), ('MAP', 'MAP'), ('solution', 'solution'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), ('=', '='), ('0', '0'), (')', ')'), ('=', '='), ('1', '1'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 197 =============================

D. When the True Distribution p(x, t) is Not Known: Machine Learning  Consider now the case of interest in which domain knowledge is not available and hence the true joint distribution is unknown. 


>> Tokens are: 
 ['D.', 'When', 'True', 'Distribution', 'p', '(', 'x', ',', ')', 'Not', 'Known', ':', 'Machine', 'Learning', 'Consider', 'case', 'interest', 'domain', 'knowledge', 'available', 'hence', 'true', 'joint', 'distribution', 'unknown', '.']

>> Bigrams are: 
 [('D.', 'When'), ('When', 'True'), ('True', 'Distribution'), ('Distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'Not'), ('Not', 'Known'), ('Known', ':'), (':', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Consider'), ('Consider', 'case'), ('case', 'interest'), ('interest', 'domain'), ('domain', 'knowledge'), ('knowledge', 'available'), ('available', 'hence'), ('hence', 'true'), ('true', 'joint'), ('joint', 'distribution'), ('distribution', 'unknown'), ('unknown', '.')]

>> Trigrams are: 
 [('D.', 'When', 'True'), ('When', 'True', 'Distribution'), ('True', 'Distribution', 'p'), ('Distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'Not'), (')', 'Not', 'Known'), ('Not', 'Known', ':'), ('Known', ':', 'Machine'), (':', 'Machine', 'Learning'), ('Machine', 'Learning', 'Consider'), ('Learning', 'Consider', 'case'), ('Consider', 'case', 'interest'), ('case', 'interest', 'domain'), ('interest', 'domain', 'knowledge'), ('domain', 'knowledge', 'available'), ('knowledge', 'available', 'hence'), ('available', 'hence', 'true'), ('hence', 'true', 'joint'), ('true', 'joint', 'distribution'), ('joint', 'distribution', 'unknown'), ('distribution', 'unknown', '.')]

>> POS Tags are: 
 [('D.', 'NNP'), ('When', 'WRB'), ('True', 'NNP'), ('Distribution', 'NNP'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('Not', 'RB'), ('Known', 'VBN'), (':', ':'), ('Machine', 'NN'), ('Learning', 'VBG'), ('Consider', 'NNP'), ('case', 'NN'), ('interest', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('available', 'JJ'), ('hence', 'NN'), ('true', 'JJ'), ('joint', 'JJ'), ('distribution', 'NN'), ('unknown', 'NN'), ('.', '.')]

 (S
  (NP D./NNP)
  When/WRB
  (NP True/NNP Distribution/NNP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  Not/RB
  Known/VBN
  :/:
  (NP Machine/NN)
  Learning/VBG
  (NP Consider/NNP case/NN interest/NN domain/NN knowledge/NN)
  (NP available/JJ hence/NN)
  (NP true/JJ joint/JJ distribution/NN unknown/NN)
  ./.) 


>> Noun Phrases are: 
 ['D.', 'True Distribution p', 'x', 'Machine', 'Consider case interest domain knowledge', 'available hence', 'true joint distribution unknown']

>> Named Entities are: 
 [('PERSON', 'True Distribution'), ('ORGANIZATION', 'Consider')] 

>> Stemming using Porter Stemmer: 
 [('D.', 'd.'), ('When', 'when'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'not'), ('Known', 'known'), (':', ':'), ('Machine', 'machin'), ('Learning', 'learn'), ('Consider', 'consid'), ('case', 'case'), ('interest', 'interest'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('available', 'avail'), ('hence', 'henc'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('unknown', 'unknown'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('D.', 'd.'), ('When', 'when'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'not'), ('Known', 'known'), (':', ':'), ('Machine', 'machin'), ('Learning', 'learn'), ('Consider', 'consid'), ('case', 'case'), ('interest', 'interest'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('available', 'avail'), ('hence', 'henc'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('unknown', 'unknown'), ('.', '.')]

>> Lemmatization: 
 [('D.', 'D.'), ('When', 'When'), ('True', 'True'), ('Distribution', 'Distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'Not'), ('Known', 'Known'), (':', ':'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Consider', 'Consider'), ('case', 'case'), ('interest', 'interest'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('available', 'available'), ('hence', 'hence'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribution'), ('unknown', 'unknown'), ('.', '.')]



============================ Sentence 198 =============================

In such a scenario, we have a learning problem and we need to use the examples in the training set D in order to obtain a meaningful predictor that approximately minimizes the generalization loss. 


>> Tokens are: 
 ['In', 'scenario', ',', 'learning', 'problem', 'need', 'use', 'examples', 'training', 'set', 'D', 'order', 'obtain', 'meaningful', 'predictor', 'approximately', 'minimizes', 'generalization', 'loss', '.']

>> Bigrams are: 
 [('In', 'scenario'), ('scenario', ','), (',', 'learning'), ('learning', 'problem'), ('problem', 'need'), ('need', 'use'), ('use', 'examples'), ('examples', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'order'), ('order', 'obtain'), ('obtain', 'meaningful'), ('meaningful', 'predictor'), ('predictor', 'approximately'), ('approximately', 'minimizes'), ('minimizes', 'generalization'), ('generalization', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('In', 'scenario', ','), ('scenario', ',', 'learning'), (',', 'learning', 'problem'), ('learning', 'problem', 'need'), ('problem', 'need', 'use'), ('need', 'use', 'examples'), ('use', 'examples', 'training'), ('examples', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'order'), ('D', 'order', 'obtain'), ('order', 'obtain', 'meaningful'), ('obtain', 'meaningful', 'predictor'), ('meaningful', 'predictor', 'approximately'), ('predictor', 'approximately', 'minimizes'), ('approximately', 'minimizes', 'generalization'), ('minimizes', 'generalization', 'loss'), ('generalization', 'loss', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('scenario', 'NN'), (',', ','), ('learning', 'VBG'), ('problem', 'NN'), ('need', 'NN'), ('use', 'NN'), ('examples', 'VBZ'), ('training', 'VBG'), ('set', 'VBN'), ('D', 'NNP'), ('order', 'NN'), ('obtain', 'VB'), ('meaningful', 'JJ'), ('predictor', 'NN'), ('approximately', 'RB'), ('minimizes', 'JJ'), ('generalization', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP scenario/NN)
  ,/,
  learning/VBG
  (NP problem/NN need/NN use/NN)
  examples/VBZ
  training/VBG
  set/VBN
  (NP D/NNP order/NN)
  obtain/VB
  (NP meaningful/JJ predictor/NN)
  approximately/RB
  (NP minimizes/JJ generalization/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['scenario', 'problem need use', 'D order', 'meaningful predictor', 'minimizes generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('scenario', 'scenario'), (',', ','), ('learning', 'learn'), ('problem', 'problem'), ('need', 'need'), ('use', 'use'), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('order', 'order'), ('obtain', 'obtain'), ('meaningful', 'meaning'), ('predictor', 'predictor'), ('approximately', 'approxim'), ('minimizes', 'minim'), ('generalization', 'gener'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('scenario', 'scenario'), (',', ','), ('learning', 'learn'), ('problem', 'problem'), ('need', 'need'), ('use', 'use'), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('order', 'order'), ('obtain', 'obtain'), ('meaningful', 'meaning'), ('predictor', 'predictor'), ('approximately', 'approxim'), ('minimizes', 'minim'), ('generalization', 'general'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('scenario', 'scenario'), (',', ','), ('learning', 'learning'), ('problem', 'problem'), ('need', 'need'), ('use', 'use'), ('examples', 'example'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('order', 'order'), ('obtain', 'obtain'), ('meaningful', 'meaningful'), ('predictor', 'predictor'), ('approximately', 'approximately'), ('minimizes', 'minimizes'), ('generalization', 'generalization'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 199 =============================

At a high level, the methodology applied by machine learning follows three main steps, which are described next. 


>> Tokens are: 
 ['At', 'high', 'level', ',', 'methodology', 'applied', 'machine', 'learning', 'follows', 'three', 'main', 'steps', ',', 'described', 'next', '.']

>> Bigrams are: 
 [('At', 'high'), ('high', 'level'), ('level', ','), (',', 'methodology'), ('methodology', 'applied'), ('applied', 'machine'), ('machine', 'learning'), ('learning', 'follows'), ('follows', 'three'), ('three', 'main'), ('main', 'steps'), ('steps', ','), (',', 'described'), ('described', 'next'), ('next', '.')]

>> Trigrams are: 
 [('At', 'high', 'level'), ('high', 'level', ','), ('level', ',', 'methodology'), (',', 'methodology', 'applied'), ('methodology', 'applied', 'machine'), ('applied', 'machine', 'learning'), ('machine', 'learning', 'follows'), ('learning', 'follows', 'three'), ('follows', 'three', 'main'), ('three', 'main', 'steps'), ('main', 'steps', ','), ('steps', ',', 'described'), (',', 'described', 'next'), ('described', 'next', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('high', 'JJ'), ('level', 'NN'), (',', ','), ('methodology', 'NN'), ('applied', 'VBD'), ('machine', 'NN'), ('learning', 'NN'), ('follows', 'VBZ'), ('three', 'CD'), ('main', 'JJ'), ('steps', 'NNS'), (',', ','), ('described', 'VBD'), ('next', 'JJ'), ('.', '.')]

 (S
  At/IN
  (NP high/JJ level/NN)
  ,/,
  (NP methodology/NN)
  applied/VBD
  (NP machine/NN learning/NN)
  follows/VBZ
  three/CD
  (NP main/JJ steps/NNS)
  ,/,
  described/VBD
  next/JJ
  ./.) 


>> Noun Phrases are: 
 ['high level', 'methodology', 'machine learning', 'main steps']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('high', 'high'), ('level', 'level'), (',', ','), ('methodology', 'methodolog'), ('applied', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('follows', 'follow'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), (',', ','), ('described', 'describ'), ('next', 'next'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('high', 'high'), ('level', 'level'), (',', ','), ('methodology', 'methodolog'), ('applied', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('follows', 'follow'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), (',', ','), ('described', 'describ'), ('next', 'next'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('high', 'high'), ('level', 'level'), (',', ','), ('methodology', 'methodology'), ('applied', 'applied'), ('machine', 'machine'), ('learning', 'learning'), ('follows', 'follows'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), (',', ','), ('described', 'described'), ('next', 'next'), ('.', '.')]



============================ Sentence 200 =============================

1. 


>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

 (S 1/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



============================ Sentence 201 =============================

Model selection (inductive bias): As a first step, one needs to commit to a specific class of hypotheses that the learning algorithm may choose from. 


>> Tokens are: 
 ['Model', 'selection', '(', 'inductive', 'bias', ')', ':', 'As', 'first', 'step', ',', 'one', 'needs', 'commit', 'specific', 'class', 'hypotheses', 'learning', 'algorithm', 'may', 'choose', '.']

>> Bigrams are: 
 [('Model', 'selection'), ('selection', '('), ('(', 'inductive'), ('inductive', 'bias'), ('bias', ')'), (')', ':'), (':', 'As'), ('As', 'first'), ('first', 'step'), ('step', ','), (',', 'one'), ('one', 'needs'), ('needs', 'commit'), ('commit', 'specific'), ('specific', 'class'), ('class', 'hypotheses'), ('hypotheses', 'learning'), ('learning', 'algorithm'), ('algorithm', 'may'), ('may', 'choose'), ('choose', '.')]

>> Trigrams are: 
 [('Model', 'selection', '('), ('selection', '(', 'inductive'), ('(', 'inductive', 'bias'), ('inductive', 'bias', ')'), ('bias', ')', ':'), (')', ':', 'As'), (':', 'As', 'first'), ('As', 'first', 'step'), ('first', 'step', ','), ('step', ',', 'one'), (',', 'one', 'needs'), ('one', 'needs', 'commit'), ('needs', 'commit', 'specific'), ('commit', 'specific', 'class'), ('specific', 'class', 'hypotheses'), ('class', 'hypotheses', 'learning'), ('hypotheses', 'learning', 'algorithm'), ('learning', 'algorithm', 'may'), ('algorithm', 'may', 'choose'), ('may', 'choose', '.')]

>> POS Tags are: 
 [('Model', 'NNP'), ('selection', 'NN'), ('(', '('), ('inductive', 'JJ'), ('bias', 'NN'), (')', ')'), (':', ':'), ('As', 'IN'), ('first', 'JJ'), ('step', 'NN'), (',', ','), ('one', 'CD'), ('needs', 'VBZ'), ('commit', 'NN'), ('specific', 'JJ'), ('class', 'NN'), ('hypotheses', 'NNS'), ('learning', 'VBG'), ('algorithm', 'NN'), ('may', 'MD'), ('choose', 'VB'), ('.', '.')]

 (S
  (NP Model/NNP selection/NN)
  (/(
  (NP inductive/JJ bias/NN)
  )/)
  :/:
  As/IN
  (NP first/JJ step/NN)
  ,/,
  one/CD
  needs/VBZ
  (NP commit/NN)
  (NP specific/JJ class/NN hypotheses/NNS)
  learning/VBG
  (NP algorithm/NN)
  may/MD
  choose/VB
  ./.) 


>> Noun Phrases are: 
 ['Model selection', 'inductive bias', 'first step', 'commit', 'specific class hypotheses', 'algorithm']

>> Named Entities are: 
 [('GPE', 'Model')] 

>> Stemming using Porter Stemmer: 
 [('Model', 'model'), ('selection', 'select'), ('(', '('), ('inductive', 'induct'), ('bias', 'bia'), (')', ')'), (':', ':'), ('As', 'as'), ('first', 'first'), ('step', 'step'), (',', ','), ('one', 'one'), ('needs', 'need'), ('commit', 'commit'), ('specific', 'specif'), ('class', 'class'), ('hypotheses', 'hypothes'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('may', 'may'), ('choose', 'choos'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Model', 'model'), ('selection', 'select'), ('(', '('), ('inductive', 'induct'), ('bias', 'bias'), (')', ')'), (':', ':'), ('As', 'as'), ('first', 'first'), ('step', 'step'), (',', ','), ('one', 'one'), ('needs', 'need'), ('commit', 'commit'), ('specific', 'specif'), ('class', 'class'), ('hypotheses', 'hypothes'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('may', 'may'), ('choose', 'choos'), ('.', '.')]

>> Lemmatization: 
 [('Model', 'Model'), ('selection', 'selection'), ('(', '('), ('inductive', 'inductive'), ('bias', 'bias'), (')', ')'), (':', ':'), ('As', 'As'), ('first', 'first'), ('step', 'step'), (',', ','), ('one', 'one'), ('needs', 'need'), ('commit', 'commit'), ('specific', 'specific'), ('class', 'class'), ('hypotheses', 'hypothesis'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('may', 'may'), ('choose', 'choose'), ('.', '.')]



============================ Sentence 202 =============================

The hypothesis class is also referred to as model. 


>> Tokens are: 
 ['The', 'hypothesis', 'class', 'also', 'referred', 'model', '.']

>> Bigrams are: 
 [('The', 'hypothesis'), ('hypothesis', 'class'), ('class', 'also'), ('also', 'referred'), ('referred', 'model'), ('model', '.')]

>> Trigrams are: 
 [('The', 'hypothesis', 'class'), ('hypothesis', 'class', 'also'), ('class', 'also', 'referred'), ('also', 'referred', 'model'), ('referred', 'model', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('hypothesis', 'NN'), ('class', 'NN'), ('also', 'RB'), ('referred', 'VBD'), ('model', 'NN'), ('.', '.')]

 (S
  (NP The/DT hypothesis/NN class/NN)
  also/RB
  referred/VBD
  (NP model/NN)
  ./.) 


>> Noun Phrases are: 
 ['The hypothesis class', 'model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('also', 'also'), ('referred', 'refer'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('also', 'also'), ('referred', 'refer'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('also', 'also'), ('referred', 'referred'), ('model', 'model'), ('.', '.')]



============================ Sentence 203 =============================

The selection of the hy- pothesis class characterizes the inductive bias mentioned above as a pre-requisite for learning. 


>> Tokens are: 
 ['The', 'selection', 'hy-', 'pothesis', 'class', 'characterizes', 'inductive', 'bias', 'mentioned', 'pre-requisite', 'learning', '.']

>> Bigrams are: 
 [('The', 'selection'), ('selection', 'hy-'), ('hy-', 'pothesis'), ('pothesis', 'class'), ('class', 'characterizes'), ('characterizes', 'inductive'), ('inductive', 'bias'), ('bias', 'mentioned'), ('mentioned', 'pre-requisite'), ('pre-requisite', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('The', 'selection', 'hy-'), ('selection', 'hy-', 'pothesis'), ('hy-', 'pothesis', 'class'), ('pothesis', 'class', 'characterizes'), ('class', 'characterizes', 'inductive'), ('characterizes', 'inductive', 'bias'), ('inductive', 'bias', 'mentioned'), ('bias', 'mentioned', 'pre-requisite'), ('mentioned', 'pre-requisite', 'learning'), ('pre-requisite', 'learning', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('selection', 'NN'), ('hy-', 'JJ'), ('pothesis', 'NN'), ('class', 'NN'), ('characterizes', 'VBZ'), ('inductive', 'JJ'), ('bias', 'NN'), ('mentioned', 'VBD'), ('pre-requisite', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP The/DT selection/NN)
  (NP hy-/JJ pothesis/NN class/NN)
  characterizes/VBZ
  (NP inductive/JJ bias/NN)
  mentioned/VBD
  (NP pre-requisite/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['The selection', 'hy- pothesis class', 'inductive bias', 'pre-requisite learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('hy-', 'hy-'), ('pothesis', 'pothesi'), ('class', 'class'), ('characterizes', 'character'), ('inductive', 'induct'), ('bias', 'bia'), ('mentioned', 'mention'), ('pre-requisite', 'pre-requisit'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('hy-', 'hy-'), ('pothesis', 'pothesi'), ('class', 'class'), ('characterizes', 'character'), ('inductive', 'induct'), ('bias', 'bias'), ('mentioned', 'mention'), ('pre-requisite', 'pre-requisit'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('selection', 'selection'), ('hy-', 'hy-'), ('pothesis', 'pothesis'), ('class', 'class'), ('characterizes', 'characterizes'), ('inductive', 'inductive'), ('bias', 'bias'), ('mentioned', 'mentioned'), ('pre-requisite', 'pre-requisite'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 204 =============================

In a probabilistic framework, the hypothesis class, or model, is defined by a family of probability distributions parameterized by a vector θ. 


>> Tokens are: 
 ['In', 'probabilistic', 'framework', ',', 'hypothesis', 'class', ',', 'model', ',', 'defined', 'family', 'probability', 'distributions', 'parameterized', 'vector', 'θ', '.']

>> Bigrams are: 
 [('In', 'probabilistic'), ('probabilistic', 'framework'), ('framework', ','), (',', 'hypothesis'), ('hypothesis', 'class'), ('class', ','), (',', 'model'), ('model', ','), (',', 'defined'), ('defined', 'family'), ('family', 'probability'), ('probability', 'distributions'), ('distributions', 'parameterized'), ('parameterized', 'vector'), ('vector', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('In', 'probabilistic', 'framework'), ('probabilistic', 'framework', ','), ('framework', ',', 'hypothesis'), (',', 'hypothesis', 'class'), ('hypothesis', 'class', ','), ('class', ',', 'model'), (',', 'model', ','), ('model', ',', 'defined'), (',', 'defined', 'family'), ('defined', 'family', 'probability'), ('family', 'probability', 'distributions'), ('probability', 'distributions', 'parameterized'), ('distributions', 'parameterized', 'vector'), ('parameterized', 'vector', 'θ'), ('vector', 'θ', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('probabilistic', 'JJ'), ('framework', 'NN'), (',', ','), ('hypothesis', 'NN'), ('class', 'NN'), (',', ','), ('model', 'NN'), (',', ','), ('defined', 'VBN'), ('family', 'NN'), ('probability', 'NN'), ('distributions', 'NNS'), ('parameterized', 'VBD'), ('vector', 'NN'), ('θ', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP probabilistic/JJ framework/NN)
  ,/,
  (NP hypothesis/NN class/NN)
  ,/,
  (NP model/NN)
  ,/,
  defined/VBN
  (NP family/NN probability/NN distributions/NNS)
  parameterized/VBD
  (NP vector/NN θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['probabilistic framework', 'hypothesis class', 'model', 'family probability distributions', 'vector θ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('probabilistic', 'probabilist'), ('framework', 'framework'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('model', 'model'), (',', ','), ('defined', 'defin'), ('family', 'famili'), ('probability', 'probabl'), ('distributions', 'distribut'), ('parameterized', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('probabilistic', 'probabilist'), ('framework', 'framework'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('model', 'model'), (',', ','), ('defined', 'defin'), ('family', 'famili'), ('probability', 'probabl'), ('distributions', 'distribut'), ('parameterized', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('probabilistic', 'probabilistic'), ('framework', 'framework'), (',', ','), ('hypothesis', 'hypothesis'), ('class', 'class'), (',', ','), ('model', 'model'), (',', ','), ('defined', 'defined'), ('family', 'family'), ('probability', 'probability'), ('distributions', 'distribution'), ('parameterized', 'parameterized'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 205 =============================

Specifically, there are two main ways of specifying a parametric family of distributions as a model for supervised learning: • Generative model: Generative models specify a  family of joint distributions p(x, t|θ); • Discriminative model: Discriminative models pa-  rameterize directly the predictive distribution as p(t|x, θ). 


>> Tokens are: 
 ['Specifically', ',', 'two', 'main', 'ways', 'specifying', 'parametric', 'family', 'distributions', 'model', 'supervised', 'learning', ':', '•', 'Generative', 'model', ':', 'Generative', 'models', 'specify', 'family', 'joint', 'distributions', 'p', '(', 'x', ',', 't|θ', ')', ';', '•', 'Discriminative', 'model', ':', 'Discriminative', 'models', 'pa-', 'rameterize', 'directly', 'predictive', 'distribution', 'p', '(', 't|x', ',', 'θ', ')', '.']

>> Bigrams are: 
 [('Specifically', ','), (',', 'two'), ('two', 'main'), ('main', 'ways'), ('ways', 'specifying'), ('specifying', 'parametric'), ('parametric', 'family'), ('family', 'distributions'), ('distributions', 'model'), ('model', 'supervised'), ('supervised', 'learning'), ('learning', ':'), (':', '•'), ('•', 'Generative'), ('Generative', 'model'), ('model', ':'), (':', 'Generative'), ('Generative', 'models'), ('models', 'specify'), ('specify', 'family'), ('family', 'joint'), ('joint', 'distributions'), ('distributions', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 't|θ'), ('t|θ', ')'), (')', ';'), (';', '•'), ('•', 'Discriminative'), ('Discriminative', 'model'), ('model', ':'), (':', 'Discriminative'), ('Discriminative', 'models'), ('models', 'pa-'), ('pa-', 'rameterize'), ('rameterize', 'directly'), ('directly', 'predictive'), ('predictive', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'θ'), ('θ', ')'), (')', '.')]

>> Trigrams are: 
 [('Specifically', ',', 'two'), (',', 'two', 'main'), ('two', 'main', 'ways'), ('main', 'ways', 'specifying'), ('ways', 'specifying', 'parametric'), ('specifying', 'parametric', 'family'), ('parametric', 'family', 'distributions'), ('family', 'distributions', 'model'), ('distributions', 'model', 'supervised'), ('model', 'supervised', 'learning'), ('supervised', 'learning', ':'), ('learning', ':', '•'), (':', '•', 'Generative'), ('•', 'Generative', 'model'), ('Generative', 'model', ':'), ('model', ':', 'Generative'), (':', 'Generative', 'models'), ('Generative', 'models', 'specify'), ('models', 'specify', 'family'), ('specify', 'family', 'joint'), ('family', 'joint', 'distributions'), ('joint', 'distributions', 'p'), ('distributions', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 't|θ'), (',', 't|θ', ')'), ('t|θ', ')', ';'), (')', ';', '•'), (';', '•', 'Discriminative'), ('•', 'Discriminative', 'model'), ('Discriminative', 'model', ':'), ('model', ':', 'Discriminative'), (':', 'Discriminative', 'models'), ('Discriminative', 'models', 'pa-'), ('models', 'pa-', 'rameterize'), ('pa-', 'rameterize', 'directly'), ('rameterize', 'directly', 'predictive'), ('directly', 'predictive', 'distribution'), ('predictive', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '.')]

>> POS Tags are: 
 [('Specifically', 'RB'), (',', ','), ('two', 'CD'), ('main', 'JJ'), ('ways', 'NNS'), ('specifying', 'VBG'), ('parametric', 'JJ'), ('family', 'NN'), ('distributions', 'NNS'), ('model', 'NN'), ('supervised', 'VBD'), ('learning', 'NN'), (':', ':'), ('•', 'JJ'), ('Generative', 'NNP'), ('model', 'NN'), (':', ':'), ('Generative', 'JJ'), ('models', 'NNS'), ('specify', 'VBP'), ('family', 'NN'), ('joint', 'NN'), ('distributions', 'NNS'), ('p', 'VBP'), ('(', '('), ('x', 'UH'), (',', ','), ('t|θ', 'JJ'), (')', ')'), (';', ':'), ('•', 'CC'), ('Discriminative', 'JJ'), ('model', 'NN'), (':', ':'), ('Discriminative', 'JJ'), ('models', 'NNS'), ('pa-', 'JJ'), ('rameterize', 'NNS'), ('directly', 'RB'), ('predictive', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('θ', 'NN'), (')', ')'), ('.', '.')]

 (S
  Specifically/RB
  ,/,
  two/CD
  (NP main/JJ ways/NNS)
  specifying/VBG
  (NP parametric/JJ family/NN distributions/NNS model/NN)
  supervised/VBD
  (NP learning/NN)
  :/:
  (NP •/JJ Generative/NNP model/NN)
  :/:
  (NP Generative/JJ models/NNS)
  specify/VBP
  (NP family/NN joint/NN distributions/NNS)
  p/VBP
  (/(
  x/UH
  ,/,
  t|θ/JJ
  )/)
  ;/:
  •/CC
  (NP Discriminative/JJ model/NN)
  :/:
  (NP Discriminative/JJ models/NNS)
  (NP pa-/JJ rameterize/NNS)
  directly/RB
  (NP predictive/JJ distribution/NN p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP θ/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['main ways', 'parametric family distributions model', 'learning', '• Generative model', 'Generative models', 'family joint distributions', 'Discriminative model', 'Discriminative models', 'pa- rameterize', 'predictive distribution p', 't|x', 'θ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Specifically', 'specif'), (',', ','), ('two', 'two'), ('main', 'main'), ('ways', 'way'), ('specifying', 'specifi'), ('parametric', 'parametr'), ('family', 'famili'), ('distributions', 'distribut'), ('model', 'model'), ('supervised', 'supervis'), ('learning', 'learn'), (':', ':'), ('•', '•'), ('Generative', 'gener'), ('model', 'model'), (':', ':'), ('Generative', 'gener'), ('models', 'model'), ('specify', 'specifi'), ('family', 'famili'), ('joint', 'joint'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), (';', ';'), ('•', '•'), ('Discriminative', 'discrimin'), ('model', 'model'), (':', ':'), ('Discriminative', 'discrimin'), ('models', 'model'), ('pa-', 'pa-'), ('rameterize', 'rameter'), ('directly', 'directli'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Specifically', 'specif'), (',', ','), ('two', 'two'), ('main', 'main'), ('ways', 'way'), ('specifying', 'specifi'), ('parametric', 'parametr'), ('family', 'famili'), ('distributions', 'distribut'), ('model', 'model'), ('supervised', 'supervis'), ('learning', 'learn'), (':', ':'), ('•', '•'), ('Generative', 'generat'), ('model', 'model'), (':', ':'), ('Generative', 'generat'), ('models', 'model'), ('specify', 'specifi'), ('family', 'famili'), ('joint', 'joint'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), (';', ';'), ('•', '•'), ('Discriminative', 'discrimin'), ('model', 'model'), (':', ':'), ('Discriminative', 'discrimin'), ('models', 'model'), ('pa-', 'pa-'), ('rameterize', 'rameter'), ('directly', 'direct'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Specifically', 'Specifically'), (',', ','), ('two', 'two'), ('main', 'main'), ('ways', 'way'), ('specifying', 'specifying'), ('parametric', 'parametric'), ('family', 'family'), ('distributions', 'distribution'), ('model', 'model'), ('supervised', 'supervised'), ('learning', 'learning'), (':', ':'), ('•', '•'), ('Generative', 'Generative'), ('model', 'model'), (':', ':'), ('Generative', 'Generative'), ('models', 'model'), ('specify', 'specify'), ('family', 'family'), ('joint', 'joint'), ('distributions', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), (';', ';'), ('•', '•'), ('Discriminative', 'Discriminative'), ('model', 'model'), (':', ':'), ('Discriminative', 'Discriminative'), ('models', 'model'), ('pa-', 'pa-'), ('rameterize', 'rameterize'), ('directly', 'directly'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]



============================ Sentence 206 =============================

Broadly speaking, discriminative models do not make any assumptions about the distribution of the inputs x and hence may be less prone to bias caused by a misspecification of the hypothesis class. 


>> Tokens are: 
 ['Broadly', 'speaking', ',', 'discriminative', 'models', 'make', 'assumptions', 'distribution', 'inputs', 'x', 'hence', 'may', 'less', 'prone', 'bias', 'caused', 'misspecification', 'hypothesis', 'class', '.']

>> Bigrams are: 
 [('Broadly', 'speaking'), ('speaking', ','), (',', 'discriminative'), ('discriminative', 'models'), ('models', 'make'), ('make', 'assumptions'), ('assumptions', 'distribution'), ('distribution', 'inputs'), ('inputs', 'x'), ('x', 'hence'), ('hence', 'may'), ('may', 'less'), ('less', 'prone'), ('prone', 'bias'), ('bias', 'caused'), ('caused', 'misspecification'), ('misspecification', 'hypothesis'), ('hypothesis', 'class'), ('class', '.')]

>> Trigrams are: 
 [('Broadly', 'speaking', ','), ('speaking', ',', 'discriminative'), (',', 'discriminative', 'models'), ('discriminative', 'models', 'make'), ('models', 'make', 'assumptions'), ('make', 'assumptions', 'distribution'), ('assumptions', 'distribution', 'inputs'), ('distribution', 'inputs', 'x'), ('inputs', 'x', 'hence'), ('x', 'hence', 'may'), ('hence', 'may', 'less'), ('may', 'less', 'prone'), ('less', 'prone', 'bias'), ('prone', 'bias', 'caused'), ('bias', 'caused', 'misspecification'), ('caused', 'misspecification', 'hypothesis'), ('misspecification', 'hypothesis', 'class'), ('hypothesis', 'class', '.')]

>> POS Tags are: 
 [('Broadly', 'RB'), ('speaking', 'NN'), (',', ','), ('discriminative', 'JJ'), ('models', 'NNS'), ('make', 'VBP'), ('assumptions', 'NNS'), ('distribution', 'NN'), ('inputs', 'NNS'), ('x', 'VBP'), ('hence', 'NN'), ('may', 'MD'), ('less', 'VB'), ('prone', 'NN'), ('bias', 'NN'), ('caused', 'VBD'), ('misspecification', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('.', '.')]

 (S
  Broadly/RB
  (NP speaking/NN)
  ,/,
  (NP discriminative/JJ models/NNS)
  make/VBP
  (NP assumptions/NNS distribution/NN inputs/NNS)
  x/VBP
  (NP hence/NN)
  may/MD
  less/VB
  (NP prone/NN bias/NN)
  caused/VBD
  (NP misspecification/NN hypothesis/NN class/NN)
  ./.) 


>> Noun Phrases are: 
 ['speaking', 'discriminative models', 'assumptions distribution inputs', 'hence', 'prone bias', 'misspecification hypothesis class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Broadly', 'broadli'), ('speaking', 'speak'), (',', ','), ('discriminative', 'discrimin'), ('models', 'model'), ('make', 'make'), ('assumptions', 'assumpt'), ('distribution', 'distribut'), ('inputs', 'input'), ('x', 'x'), ('hence', 'henc'), ('may', 'may'), ('less', 'less'), ('prone', 'prone'), ('bias', 'bia'), ('caused', 'caus'), ('misspecification', 'misspecif'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Broadly', 'broad'), ('speaking', 'speak'), (',', ','), ('discriminative', 'discrimin'), ('models', 'model'), ('make', 'make'), ('assumptions', 'assumpt'), ('distribution', 'distribut'), ('inputs', 'input'), ('x', 'x'), ('hence', 'henc'), ('may', 'may'), ('less', 'less'), ('prone', 'prone'), ('bias', 'bias'), ('caused', 'caus'), ('misspecification', 'misspecif'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('.', '.')]

>> Lemmatization: 
 [('Broadly', 'Broadly'), ('speaking', 'speaking'), (',', ','), ('discriminative', 'discriminative'), ('models', 'model'), ('make', 'make'), ('assumptions', 'assumption'), ('distribution', 'distribution'), ('inputs', 'input'), ('x', 'x'), ('hence', 'hence'), ('may', 'may'), ('less', 'le'), ('prone', 'prone'), ('bias', 'bias'), ('caused', 'caused'), ('misspecification', 'misspecification'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('.', '.')]



============================ Sentence 207 =============================

On the flip side, generative models may be able to capture more of the structure present in the data and consequently improve the performance of the predictor [29]. 


>> Tokens are: 
 ['On', 'flip', 'side', ',', 'generative', 'models', 'may', 'able', 'capture', 'structure', 'present', 'data', 'consequently', 'improve', 'performance', 'predictor', '[', '29', ']', '.']

>> Bigrams are: 
 [('On', 'flip'), ('flip', 'side'), ('side', ','), (',', 'generative'), ('generative', 'models'), ('models', 'may'), ('may', 'able'), ('able', 'capture'), ('capture', 'structure'), ('structure', 'present'), ('present', 'data'), ('data', 'consequently'), ('consequently', 'improve'), ('improve', 'performance'), ('performance', 'predictor'), ('predictor', '['), ('[', '29'), ('29', ']'), (']', '.')]

>> Trigrams are: 
 [('On', 'flip', 'side'), ('flip', 'side', ','), ('side', ',', 'generative'), (',', 'generative', 'models'), ('generative', 'models', 'may'), ('models', 'may', 'able'), ('may', 'able', 'capture'), ('able', 'capture', 'structure'), ('capture', 'structure', 'present'), ('structure', 'present', 'data'), ('present', 'data', 'consequently'), ('data', 'consequently', 'improve'), ('consequently', 'improve', 'performance'), ('improve', 'performance', 'predictor'), ('performance', 'predictor', '['), ('predictor', '[', '29'), ('[', '29', ']'), ('29', ']', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('flip', 'JJ'), ('side', 'NN'), (',', ','), ('generative', 'JJ'), ('models', 'NNS'), ('may', 'MD'), ('able', 'JJ'), ('capture', 'NN'), ('structure', 'NN'), ('present', 'JJ'), ('data', 'NNS'), ('consequently', 'RB'), ('improve', 'VB'), ('performance', 'NN'), ('predictor', 'NN'), ('[', 'VBD'), ('29', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  On/IN
  (NP flip/JJ side/NN)
  ,/,
  (NP generative/JJ models/NNS)
  may/MD
  (NP able/JJ capture/NN structure/NN)
  (NP present/JJ data/NNS)
  consequently/RB
  improve/VB
  (NP performance/NN predictor/NN)
  [/VBD
  29/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['flip side', 'generative models', 'able capture structure', 'present data', 'performance predictor', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('flip', 'flip'), ('side', 'side'), (',', ','), ('generative', 'gener'), ('models', 'model'), ('may', 'may'), ('able', 'abl'), ('capture', 'captur'), ('structure', 'structur'), ('present', 'present'), ('data', 'data'), ('consequently', 'consequ'), ('improve', 'improv'), ('performance', 'perform'), ('predictor', 'predictor'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('flip', 'flip'), ('side', 'side'), (',', ','), ('generative', 'generat'), ('models', 'model'), ('may', 'may'), ('able', 'abl'), ('capture', 'captur'), ('structure', 'structur'), ('present', 'present'), ('data', 'data'), ('consequently', 'consequ'), ('improve', 'improv'), ('performance', 'perform'), ('predictor', 'predictor'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('flip', 'flip'), ('side', 'side'), (',', ','), ('generative', 'generative'), ('models', 'model'), ('may', 'may'), ('able', 'able'), ('capture', 'capture'), ('structure', 'structure'), ('present', 'present'), ('data', 'data'), ('consequently', 'consequently'), ('improve', 'improve'), ('performance', 'performance'), ('predictor', 'predictor'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]



============================ Sentence 208 =============================

For both types of models, the hypothesis class is typically selected from a common set of probability distributions that lead to efficient learning algorithms in Step 2. 


>> Tokens are: 
 ['For', 'types', 'models', ',', 'hypothesis', 'class', 'typically', 'selected', 'common', 'set', 'probability', 'distributions', 'lead', 'efficient', 'learning', 'algorithms', 'Step', '2', '.']

>> Bigrams are: 
 [('For', 'types'), ('types', 'models'), ('models', ','), (',', 'hypothesis'), ('hypothesis', 'class'), ('class', 'typically'), ('typically', 'selected'), ('selected', 'common'), ('common', 'set'), ('set', 'probability'), ('probability', 'distributions'), ('distributions', 'lead'), ('lead', 'efficient'), ('efficient', 'learning'), ('learning', 'algorithms'), ('algorithms', 'Step'), ('Step', '2'), ('2', '.')]

>> Trigrams are: 
 [('For', 'types', 'models'), ('types', 'models', ','), ('models', ',', 'hypothesis'), (',', 'hypothesis', 'class'), ('hypothesis', 'class', 'typically'), ('class', 'typically', 'selected'), ('typically', 'selected', 'common'), ('selected', 'common', 'set'), ('common', 'set', 'probability'), ('set', 'probability', 'distributions'), ('probability', 'distributions', 'lead'), ('distributions', 'lead', 'efficient'), ('lead', 'efficient', 'learning'), ('efficient', 'learning', 'algorithms'), ('learning', 'algorithms', 'Step'), ('algorithms', 'Step', '2'), ('Step', '2', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('types', 'NNS'), ('models', 'NNS'), (',', ','), ('hypothesis', 'NN'), ('class', 'NN'), ('typically', 'RB'), ('selected', 'VBD'), ('common', 'JJ'), ('set', 'VBN'), ('probability', 'NN'), ('distributions', 'NNS'), ('lead', 'VBP'), ('efficient', 'JJ'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('Step', 'NNP'), ('2', 'CD'), ('.', '.')]

 (S
  For/IN
  (NP types/NNS models/NNS)
  ,/,
  (NP hypothesis/NN class/NN)
  typically/RB
  selected/VBD
  common/JJ
  set/VBN
  (NP probability/NN distributions/NNS)
  lead/VBP
  efficient/JJ
  learning/VBG
  (NP algorithms/JJ Step/NNP)
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['types models', 'hypothesis class', 'probability distributions', 'algorithms Step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('types', 'type'), ('models', 'model'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), ('typically', 'typic'), ('selected', 'select'), ('common', 'common'), ('set', 'set'), ('probability', 'probabl'), ('distributions', 'distribut'), ('lead', 'lead'), ('efficient', 'effici'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('Step', 'step'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('types', 'type'), ('models', 'model'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), ('typically', 'typic'), ('selected', 'select'), ('common', 'common'), ('set', 'set'), ('probability', 'probabl'), ('distributions', 'distribut'), ('lead', 'lead'), ('efficient', 'effici'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('Step', 'step'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('types', 'type'), ('models', 'model'), (',', ','), ('hypothesis', 'hypothesis'), ('class', 'class'), ('typically', 'typically'), ('selected', 'selected'), ('common', 'common'), ('set', 'set'), ('probability', 'probability'), ('distributions', 'distribution'), ('lead', 'lead'), ('efficient', 'efficient'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('Step', 'Step'), ('2', '2'), ('.', '.')]



============================ Sentence 209 =============================

Furthermore, any available basic domain knowledge can be in principle incorporated in the selection of the model (see also Sec VII). 


>> Tokens are: 
 ['Furthermore', ',', 'available', 'basic', 'domain', 'knowledge', 'principle', 'incorporated', 'selection', 'model', '(', 'see', 'also', 'Sec', 'VII', ')', '.']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'available'), ('available', 'basic'), ('basic', 'domain'), ('domain', 'knowledge'), ('knowledge', 'principle'), ('principle', 'incorporated'), ('incorporated', 'selection'), ('selection', 'model'), ('model', '('), ('(', 'see'), ('see', 'also'), ('also', 'Sec'), ('Sec', 'VII'), ('VII', ')'), (')', '.')]

>> Trigrams are: 
 [('Furthermore', ',', 'available'), (',', 'available', 'basic'), ('available', 'basic', 'domain'), ('basic', 'domain', 'knowledge'), ('domain', 'knowledge', 'principle'), ('knowledge', 'principle', 'incorporated'), ('principle', 'incorporated', 'selection'), ('incorporated', 'selection', 'model'), ('selection', 'model', '('), ('model', '(', 'see'), ('(', 'see', 'also'), ('see', 'also', 'Sec'), ('also', 'Sec', 'VII'), ('Sec', 'VII', ')'), ('VII', ')', '.')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('available', 'JJ'), ('basic', 'JJ'), ('domain', 'NN'), ('knowledge', 'NN'), ('principle', 'NN'), ('incorporated', 'VBN'), ('selection', 'NN'), ('model', 'NN'), ('(', '('), ('see', 'VB'), ('also', 'RB'), ('Sec', 'NNP'), ('VII', 'NNP'), (')', ')'), ('.', '.')]

 (S
  Furthermore/RB
  ,/,
  (NP available/JJ basic/JJ domain/NN knowledge/NN principle/NN)
  incorporated/VBN
  (NP selection/NN model/NN)
  (/(
  see/VB
  also/RB
  (NP Sec/NNP VII/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['available basic domain knowledge principle', 'selection model', 'Sec VII']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('available', 'avail'), ('basic', 'basic'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('principle', 'principl'), ('incorporated', 'incorpor'), ('selection', 'select'), ('model', 'model'), ('(', '('), ('see', 'see'), ('also', 'also'), ('Sec', 'sec'), ('VII', 'vii'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('available', 'avail'), ('basic', 'basic'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('principle', 'principl'), ('incorporated', 'incorpor'), ('selection', 'select'), ('model', 'model'), ('(', '('), ('see', 'see'), ('also', 'also'), ('Sec', 'sec'), ('VII', 'vii'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('available', 'available'), ('basic', 'basic'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('principle', 'principle'), ('incorporated', 'incorporated'), ('selection', 'selection'), ('model', 'model'), ('(', '('), ('see', 'see'), ('also', 'also'), ('Sec', 'Sec'), ('VII', 'VII'), (')', ')'), ('.', '.')]



============================ Sentence 210 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 211 =============================

Learning: Given data D, in the learning step, a learning criterion is optimized in order to obtain the parameter vector θ and identify a distribution p(x, t|θ) or p(t|x, θ), depending on whether a generative or dis- criminative model was selected at Step 1. 


>> Tokens are: 
 ['Learning', ':', 'Given', 'data', 'D', ',', 'learning', 'step', ',', 'learning', 'criterion', 'optimized', 'order', 'obtain', 'parameter', 'vector', 'θ', 'identify', 'distribution', 'p', '(', 'x', ',', 't|θ', ')', 'p', '(', 't|x', ',', 'θ', ')', ',', 'depending', 'whether', 'generative', 'dis-', 'criminative', 'model', 'selected', 'Step', '1', '.']

>> Bigrams are: 
 [('Learning', ':'), (':', 'Given'), ('Given', 'data'), ('data', 'D'), ('D', ','), (',', 'learning'), ('learning', 'step'), ('step', ','), (',', 'learning'), ('learning', 'criterion'), ('criterion', 'optimized'), ('optimized', 'order'), ('order', 'obtain'), ('obtain', 'parameter'), ('parameter', 'vector'), ('vector', 'θ'), ('θ', 'identify'), ('identify', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 't|θ'), ('t|θ', ')'), (')', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'θ'), ('θ', ')'), (')', ','), (',', 'depending'), ('depending', 'whether'), ('whether', 'generative'), ('generative', 'dis-'), ('dis-', 'criminative'), ('criminative', 'model'), ('model', 'selected'), ('selected', 'Step'), ('Step', '1'), ('1', '.')]

>> Trigrams are: 
 [('Learning', ':', 'Given'), (':', 'Given', 'data'), ('Given', 'data', 'D'), ('data', 'D', ','), ('D', ',', 'learning'), (',', 'learning', 'step'), ('learning', 'step', ','), ('step', ',', 'learning'), (',', 'learning', 'criterion'), ('learning', 'criterion', 'optimized'), ('criterion', 'optimized', 'order'), ('optimized', 'order', 'obtain'), ('order', 'obtain', 'parameter'), ('obtain', 'parameter', 'vector'), ('parameter', 'vector', 'θ'), ('vector', 'θ', 'identify'), ('θ', 'identify', 'distribution'), ('identify', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 't|θ'), (',', 't|θ', ')'), ('t|θ', ')', 'p'), (')', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ','), (')', ',', 'depending'), (',', 'depending', 'whether'), ('depending', 'whether', 'generative'), ('whether', 'generative', 'dis-'), ('generative', 'dis-', 'criminative'), ('dis-', 'criminative', 'model'), ('criminative', 'model', 'selected'), ('model', 'selected', 'Step'), ('selected', 'Step', '1'), ('Step', '1', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), (':', ':'), ('Given', 'VBN'), ('data', 'NNS'), ('D', 'NNP'), (',', ','), ('learning', 'VBG'), ('step', 'NN'), (',', ','), ('learning', 'VBG'), ('criterion', 'NN'), ('optimized', 'VBN'), ('order', 'NN'), ('obtain', 'VB'), ('parameter', 'NN'), ('vector', 'NN'), ('θ', 'NNP'), ('identify', 'VB'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'UH'), (',', ','), ('t|θ', 'JJ'), (')', ')'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), (',', ','), ('depending', 'VBG'), ('whether', 'IN'), ('generative', 'JJ'), ('dis-', 'JJ'), ('criminative', 'JJ'), ('model', 'NN'), ('selected', 'VBN'), ('Step', 'NNP'), ('1', 'CD'), ('.', '.')]

 (S
  Learning/VBG
  :/:
  Given/VBN
  (NP data/NNS D/NNP)
  ,/,
  learning/VBG
  (NP step/NN)
  ,/,
  learning/VBG
  (NP criterion/NN)
  optimized/VBN
  (NP order/NN)
  obtain/VB
  (NP parameter/NN vector/NN θ/NNP)
  identify/VB
  (NP distribution/NN p/NN)
  (/(
  x/UH
  ,/,
  t|θ/JJ
  )/)
  (NP p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP θ/NNP)
  )/)
  ,/,
  depending/VBG
  whether/IN
  (NP generative/JJ dis-/JJ criminative/JJ model/NN)
  selected/VBN
  (NP Step/NNP)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['data D', 'step', 'criterion', 'order', 'parameter vector θ', 'distribution p', 'p', 't|x', 'θ', 'generative dis- criminative model', 'Step']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), (':', ':'), ('Given', 'given'), ('data', 'data'), ('D', 'd'), (',', ','), ('learning', 'learn'), ('step', 'step'), (',', ','), ('learning', 'learn'), ('criterion', 'criterion'), ('optimized', 'optim'), ('order', 'order'), ('obtain', 'obtain'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('identify', 'identifi'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('depending', 'depend'), ('whether', 'whether'), ('generative', 'gener'), ('dis-', 'dis-'), ('criminative', 'crimin'), ('model', 'model'), ('selected', 'select'), ('Step', 'step'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), (':', ':'), ('Given', 'given'), ('data', 'data'), ('D', 'd'), (',', ','), ('learning', 'learn'), ('step', 'step'), (',', ','), ('learning', 'learn'), ('criterion', 'criterion'), ('optimized', 'optim'), ('order', 'order'), ('obtain', 'obtain'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('identify', 'identifi'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('depending', 'depend'), ('whether', 'whether'), ('generative', 'generat'), ('dis-', 'dis-'), ('criminative', 'crimin'), ('model', 'model'), ('selected', 'select'), ('Step', 'step'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), (':', ':'), ('Given', 'Given'), ('data', 'data'), ('D', 'D'), (',', ','), ('learning', 'learning'), ('step', 'step'), (',', ','), ('learning', 'learning'), ('criterion', 'criterion'), ('optimized', 'optimized'), ('order', 'order'), ('obtain', 'obtain'), ('parameter', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('identify', 'identify'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('depending', 'depending'), ('whether', 'whether'), ('generative', 'generative'), ('dis-', 'dis-'), ('criminative', 'criminative'), ('model', 'model'), ('selected', 'selected'), ('Step', 'Step'), ('1', '1'), ('.', '.')]



============================ Sentence 212 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 213 =============================

Inference: In the inference step, the learned model is used to obtain the predictor t̂(x) by using (4) with the learned model in lieu of the true distribution. 


>> Tokens are: 
 ['Inference', ':', 'In', 'inference', 'step', ',', 'learned', 'model', 'used', 'obtain', 'predictor', 't̂', '(', 'x', ')', 'using', '(', '4', ')', 'learned', 'model', 'lieu', 'true', 'distribution', '.']

>> Bigrams are: 
 [('Inference', ':'), (':', 'In'), ('In', 'inference'), ('inference', 'step'), ('step', ','), (',', 'learned'), ('learned', 'model'), ('model', 'used'), ('used', 'obtain'), ('obtain', 'predictor'), ('predictor', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', 'using'), ('using', '('), ('(', '4'), ('4', ')'), (')', 'learned'), ('learned', 'model'), ('model', 'lieu'), ('lieu', 'true'), ('true', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('Inference', ':', 'In'), (':', 'In', 'inference'), ('In', 'inference', 'step'), ('inference', 'step', ','), ('step', ',', 'learned'), (',', 'learned', 'model'), ('learned', 'model', 'used'), ('model', 'used', 'obtain'), ('used', 'obtain', 'predictor'), ('obtain', 'predictor', 't̂'), ('predictor', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'using'), (')', 'using', '('), ('using', '(', '4'), ('(', '4', ')'), ('4', ')', 'learned'), (')', 'learned', 'model'), ('learned', 'model', 'lieu'), ('model', 'lieu', 'true'), ('lieu', 'true', 'distribution'), ('true', 'distribution', '.')]

>> POS Tags are: 
 [('Inference', 'NN'), (':', ':'), ('In', 'IN'), ('inference', 'NN'), ('step', 'NN'), (',', ','), ('learned', 'VBD'), ('model', 'NN'), ('used', 'VBN'), ('obtain', 'VB'), ('predictor', 'JJ'), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('using', 'VBG'), ('(', '('), ('4', 'CD'), (')', ')'), ('learned', 'VBD'), ('model', 'JJ'), ('lieu', 'NN'), ('true', 'JJ'), ('distribution', 'NN'), ('.', '.')]

 (S
  (NP Inference/NN)
  :/:
  In/IN
  (NP inference/NN step/NN)
  ,/,
  learned/VBD
  (NP model/NN)
  used/VBN
  obtain/VB
  (NP predictor/JJ t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  using/VBG
  (/(
  4/CD
  )/)
  learned/VBD
  (NP model/JJ lieu/NN)
  (NP true/JJ distribution/NN)
  ./.) 


>> Noun Phrases are: 
 ['Inference', 'inference step', 'model', 'predictor t̂', 'x', 'model lieu', 'true distribution']

>> Named Entities are: 
 [('GPE', 'Inference')] 

>> Stemming using Porter Stemmer: 
 [('Inference', 'infer'), (':', ':'), ('In', 'in'), ('inference', 'infer'), ('step', 'step'), (',', ','), ('learned', 'learn'), ('model', 'model'), ('used', 'use'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('using', 'use'), ('(', '('), ('4', '4'), (')', ')'), ('learned', 'learn'), ('model', 'model'), ('lieu', 'lieu'), ('true', 'true'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inference', 'infer'), (':', ':'), ('In', 'in'), ('inference', 'infer'), ('step', 'step'), (',', ','), ('learned', 'learn'), ('model', 'model'), ('used', 'use'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('using', 'use'), ('(', '('), ('4', '4'), (')', ')'), ('learned', 'learn'), ('model', 'model'), ('lieu', 'lieu'), ('true', 'true'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('Inference', 'Inference'), (':', ':'), ('In', 'In'), ('inference', 'inference'), ('step', 'step'), (',', ','), ('learned', 'learned'), ('model', 'model'), ('used', 'used'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('using', 'using'), ('(', '('), ('4', '4'), (')', ')'), ('learned', 'learned'), ('model', 'model'), ('lieu', 'lieu'), ('true', 'true'), ('distribution', 'distribution'), ('.', '.')]



============================ Sentence 214 =============================

Note that generative models require the calculation of the predictive distribution p(t|x) via marginalization, while discriminative models provide directly the predictive  7    distribution. 


>> Tokens are: 
 ['Note', 'generative', 'models', 'require', 'calculation', 'predictive', 'distribution', 'p', '(', 't|x', ')', 'via', 'marginalization', ',', 'discriminative', 'models', 'provide', 'directly', 'predictive', '7', 'distribution', '.']

>> Bigrams are: 
 [('Note', 'generative'), ('generative', 'models'), ('models', 'require'), ('require', 'calculation'), ('calculation', 'predictive'), ('predictive', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ')'), (')', 'via'), ('via', 'marginalization'), ('marginalization', ','), (',', 'discriminative'), ('discriminative', 'models'), ('models', 'provide'), ('provide', 'directly'), ('directly', 'predictive'), ('predictive', '7'), ('7', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('Note', 'generative', 'models'), ('generative', 'models', 'require'), ('models', 'require', 'calculation'), ('require', 'calculation', 'predictive'), ('calculation', 'predictive', 'distribution'), ('predictive', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ')'), ('t|x', ')', 'via'), (')', 'via', 'marginalization'), ('via', 'marginalization', ','), ('marginalization', ',', 'discriminative'), (',', 'discriminative', 'models'), ('discriminative', 'models', 'provide'), ('models', 'provide', 'directly'), ('provide', 'directly', 'predictive'), ('directly', 'predictive', '7'), ('predictive', '7', 'distribution'), ('7', 'distribution', '.')]

>> POS Tags are: 
 [('Note', 'NNP'), ('generative', 'JJ'), ('models', 'NNS'), ('require', 'VBP'), ('calculation', 'NN'), ('predictive', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (')', ')'), ('via', 'IN'), ('marginalization', 'NN'), (',', ','), ('discriminative', 'JJ'), ('models', 'NNS'), ('provide', 'VBP'), ('directly', 'RB'), ('predictive', 'JJ'), ('7', 'CD'), ('distribution', 'NN'), ('.', '.')]

 (S
  (NP Note/NNP)
  (NP generative/JJ models/NNS)
  require/VBP
  (NP calculation/NN)
  (NP predictive/JJ distribution/NN p/NN)
  (/(
  (NP t|x/NN)
  )/)
  via/IN
  (NP marginalization/NN)
  ,/,
  (NP discriminative/JJ models/NNS)
  provide/VBP
  directly/RB
  predictive/JJ
  7/CD
  (NP distribution/NN)
  ./.) 


>> Noun Phrases are: 
 ['Note', 'generative models', 'calculation', 'predictive distribution p', 't|x', 'marginalization', 'discriminative models', 'distribution']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('generative', 'gener'), ('models', 'model'), ('require', 'requir'), ('calculation', 'calcul'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('via', 'via'), ('marginalization', 'margin'), (',', ','), ('discriminative', 'discrimin'), ('models', 'model'), ('provide', 'provid'), ('directly', 'directli'), ('predictive', 'predict'), ('7', '7'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('generative', 'generat'), ('models', 'model'), ('require', 'requir'), ('calculation', 'calcul'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('via', 'via'), ('marginalization', 'margin'), (',', ','), ('discriminative', 'discrimin'), ('models', 'model'), ('provide', 'provid'), ('directly', 'direct'), ('predictive', 'predict'), ('7', '7'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), ('generative', 'generative'), ('models', 'model'), ('require', 'require'), ('calculation', 'calculation'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (')', ')'), ('via', 'via'), ('marginalization', 'marginalization'), (',', ','), ('discriminative', 'discriminative'), ('models', 'model'), ('provide', 'provide'), ('directly', 'directly'), ('predictive', 'predictive'), ('7', '7'), ('distribution', 'distribution'), ('.', '.')]



============================ Sentence 215 =============================

As mentioned, the predictor should be eval- uated on test data that is different from the training set D. As we will discuss, the design cycle typically entails a loop between validation of the predictor at Step 3 and model selection at Step 1. 


>> Tokens are: 
 ['As', 'mentioned', ',', 'predictor', 'eval-', 'uated', 'test', 'data', 'different', 'training', 'set', 'D.', 'As', 'discuss', ',', 'design', 'cycle', 'typically', 'entails', 'loop', 'validation', 'predictor', 'Step', '3', 'model', 'selection', 'Step', '1', '.']

>> Bigrams are: 
 [('As', 'mentioned'), ('mentioned', ','), (',', 'predictor'), ('predictor', 'eval-'), ('eval-', 'uated'), ('uated', 'test'), ('test', 'data'), ('data', 'different'), ('different', 'training'), ('training', 'set'), ('set', 'D.'), ('D.', 'As'), ('As', 'discuss'), ('discuss', ','), (',', 'design'), ('design', 'cycle'), ('cycle', 'typically'), ('typically', 'entails'), ('entails', 'loop'), ('loop', 'validation'), ('validation', 'predictor'), ('predictor', 'Step'), ('Step', '3'), ('3', 'model'), ('model', 'selection'), ('selection', 'Step'), ('Step', '1'), ('1', '.')]

>> Trigrams are: 
 [('As', 'mentioned', ','), ('mentioned', ',', 'predictor'), (',', 'predictor', 'eval-'), ('predictor', 'eval-', 'uated'), ('eval-', 'uated', 'test'), ('uated', 'test', 'data'), ('test', 'data', 'different'), ('data', 'different', 'training'), ('different', 'training', 'set'), ('training', 'set', 'D.'), ('set', 'D.', 'As'), ('D.', 'As', 'discuss'), ('As', 'discuss', ','), ('discuss', ',', 'design'), (',', 'design', 'cycle'), ('design', 'cycle', 'typically'), ('cycle', 'typically', 'entails'), ('typically', 'entails', 'loop'), ('entails', 'loop', 'validation'), ('loop', 'validation', 'predictor'), ('validation', 'predictor', 'Step'), ('predictor', 'Step', '3'), ('Step', '3', 'model'), ('3', 'model', 'selection'), ('model', 'selection', 'Step'), ('selection', 'Step', '1'), ('Step', '1', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('mentioned', 'VBN'), (',', ','), ('predictor', 'JJ'), ('eval-', 'JJ'), ('uated', 'JJ'), ('test', 'NN'), ('data', 'NNS'), ('different', 'JJ'), ('training', 'NN'), ('set', 'VBN'), ('D.', 'NNP'), ('As', 'IN'), ('discuss', 'NN'), (',', ','), ('design', 'NN'), ('cycle', 'NN'), ('typically', 'RB'), ('entails', 'VBZ'), ('loop', 'JJ'), ('validation', 'NN'), ('predictor', 'NN'), ('Step', 'NNP'), ('3', 'CD'), ('model', 'NN'), ('selection', 'NN'), ('Step', 'NNP'), ('1', 'CD'), ('.', '.')]

 (S
  As/IN
  mentioned/VBN
  ,/,
  (NP predictor/JJ eval-/JJ uated/JJ test/NN data/NNS)
  (NP different/JJ training/NN)
  set/VBN
  (NP D./NNP)
  As/IN
  (NP discuss/NN)
  ,/,
  (NP design/NN cycle/NN)
  typically/RB
  entails/VBZ
  (NP loop/JJ validation/NN predictor/NN Step/NNP)
  3/CD
  (NP model/NN selection/NN Step/NNP)
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['predictor eval- uated test data', 'different training', 'D.', 'discuss', 'design cycle', 'loop validation predictor Step', 'model selection Step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), (',', ','), ('predictor', 'predictor'), ('eval-', 'eval-'), ('uated', 'uat'), ('test', 'test'), ('data', 'data'), ('different', 'differ'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('As', 'as'), ('discuss', 'discuss'), (',', ','), ('design', 'design'), ('cycle', 'cycl'), ('typically', 'typic'), ('entails', 'entail'), ('loop', 'loop'), ('validation', 'valid'), ('predictor', 'predictor'), ('Step', 'step'), ('3', '3'), ('model', 'model'), ('selection', 'select'), ('Step', 'step'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), (',', ','), ('predictor', 'predictor'), ('eval-', 'eval-'), ('uated', 'uat'), ('test', 'test'), ('data', 'data'), ('different', 'differ'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('As', 'as'), ('discuss', 'discuss'), (',', ','), ('design', 'design'), ('cycle', 'cycl'), ('typically', 'typic'), ('entails', 'entail'), ('loop', 'loop'), ('validation', 'valid'), ('predictor', 'predictor'), ('Step', 'step'), ('3', '3'), ('model', 'model'), ('selection', 'select'), ('Step', 'step'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('mentioned', 'mentioned'), (',', ','), ('predictor', 'predictor'), ('eval-', 'eval-'), ('uated', 'uated'), ('test', 'test'), ('data', 'data'), ('different', 'different'), ('training', 'training'), ('set', 'set'), ('D.', 'D.'), ('As', 'As'), ('discuss', 'discus'), (',', ','), ('design', 'design'), ('cycle', 'cycle'), ('typically', 'typically'), ('entails', 'entail'), ('loop', 'loop'), ('validation', 'validation'), ('predictor', 'predictor'), ('Step', 'Step'), ('3', '3'), ('model', 'model'), ('selection', 'selection'), ('Step', 'Step'), ('1', '1'), ('.', '.')]



============================ Sentence 216 =============================

The next examples illustrate the three steps introduced above for a binary classification problem. 


>> Tokens are: 
 ['The', 'next', 'examples', 'illustrate', 'three', 'steps', 'introduced', 'binary', 'classification', 'problem', '.']

>> Bigrams are: 
 [('The', 'next'), ('next', 'examples'), ('examples', 'illustrate'), ('illustrate', 'three'), ('three', 'steps'), ('steps', 'introduced'), ('introduced', 'binary'), ('binary', 'classification'), ('classification', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('The', 'next', 'examples'), ('next', 'examples', 'illustrate'), ('examples', 'illustrate', 'three'), ('illustrate', 'three', 'steps'), ('three', 'steps', 'introduced'), ('steps', 'introduced', 'binary'), ('introduced', 'binary', 'classification'), ('binary', 'classification', 'problem'), ('classification', 'problem', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('next', 'JJ'), ('examples', 'NNS'), ('illustrate', 'VBP'), ('three', 'CD'), ('steps', 'NNS'), ('introduced', 'VBD'), ('binary', 'JJ'), ('classification', 'NN'), ('problem', 'NN'), ('.', '.')]

 (S
  (NP The/DT next/JJ examples/NNS)
  illustrate/VBP
  three/CD
  (NP steps/NNS)
  introduced/VBD
  (NP binary/JJ classification/NN problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['The next examples', 'steps', 'binary classification problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('next', 'next'), ('examples', 'exampl'), ('illustrate', 'illustr'), ('three', 'three'), ('steps', 'step'), ('introduced', 'introduc'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('next', 'next'), ('examples', 'exampl'), ('illustrate', 'illustr'), ('three', 'three'), ('steps', 'step'), ('introduced', 'introduc'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('next', 'next'), ('examples', 'example'), ('illustrate', 'illustrate'), ('three', 'three'), ('steps', 'step'), ('introduced', 'introduced'), ('binary', 'binary'), ('classification', 'classification'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 217 =============================

Example 1: Consider a binary classification problem in which the input is a generic D-dimensional vector x = [x1, ..., xD]  T and the output is binary, i.e.-, t ∈ {0, 1}. 


>> Tokens are: 
 ['Example', '1', ':', 'Consider', 'binary', 'classification', 'problem', 'input', 'generic', 'D-dimensional', 'vector', 'x', '=', '[', 'x1', ',', '...', ',', 'xD', ']', 'T', 'output', 'binary', ',', 'i.e.-', ',', '∈', '{', '0', ',', '1', '}', '.']

>> Bigrams are: 
 [('Example', '1'), ('1', ':'), (':', 'Consider'), ('Consider', 'binary'), ('binary', 'classification'), ('classification', 'problem'), ('problem', 'input'), ('input', 'generic'), ('generic', 'D-dimensional'), ('D-dimensional', 'vector'), ('vector', 'x'), ('x', '='), ('=', '['), ('[', 'x1'), ('x1', ','), (',', '...'), ('...', ','), (',', 'xD'), ('xD', ']'), (']', 'T'), ('T', 'output'), ('output', 'binary'), ('binary', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', '∈'), ('∈', '{'), ('{', '0'), ('0', ','), (',', '1'), ('1', '}'), ('}', '.')]

>> Trigrams are: 
 [('Example', '1', ':'), ('1', ':', 'Consider'), (':', 'Consider', 'binary'), ('Consider', 'binary', 'classification'), ('binary', 'classification', 'problem'), ('classification', 'problem', 'input'), ('problem', 'input', 'generic'), ('input', 'generic', 'D-dimensional'), ('generic', 'D-dimensional', 'vector'), ('D-dimensional', 'vector', 'x'), ('vector', 'x', '='), ('x', '=', '['), ('=', '[', 'x1'), ('[', 'x1', ','), ('x1', ',', '...'), (',', '...', ','), ('...', ',', 'xD'), (',', 'xD', ']'), ('xD', ']', 'T'), (']', 'T', 'output'), ('T', 'output', 'binary'), ('output', 'binary', ','), ('binary', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', '∈'), (',', '∈', '{'), ('∈', '{', '0'), ('{', '0', ','), ('0', ',', '1'), (',', '1', '}'), ('1', '}', '.')]

>> POS Tags are: 
 [('Example', 'JJ'), ('1', 'CD'), (':', ':'), ('Consider', 'VB'), ('binary', 'JJ'), ('classification', 'NN'), ('problem', 'NN'), ('input', 'NN'), ('generic', 'JJ'), ('D-dimensional', 'JJ'), ('vector', 'NN'), ('x', 'NNP'), ('=', 'NNP'), ('[', 'NNP'), ('x1', 'NNP'), (',', ','), ('...', ':'), (',', ','), ('xD', 'FW'), (']', 'FW'), ('T', 'NNP'), ('output', 'NN'), ('binary', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('∈', 'NNP'), ('{', '('), ('0', 'CD'), (',', ','), ('1', 'CD'), ('}', ')'), ('.', '.')]

 (S
  Example/JJ
  1/CD
  :/:
  Consider/VB
  (NP binary/JJ classification/NN problem/NN input/NN)
  (NP generic/JJ D-dimensional/JJ vector/NN x/NNP =/NNP [/NNP x1/NNP)
  ,/,
  .../:
  ,/,
  xD/FW
  ]/FW
  (NP T/NNP output/NN binary/NN)
  ,/,
  i.e.-/JJ
  ,/,
  (NP ∈/NNP)
  {/(
  0/CD
  ,/,
  1/CD
  }/)
  ./.) 


>> Noun Phrases are: 
 ['binary classification problem input', 'generic D-dimensional vector x = [ x1', 'T output binary', '∈']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Example', 'exampl'), ('1', '1'), (':', ':'), ('Consider', 'consid'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('input', 'input'), ('generic', 'gener'), ('D-dimensional', 'd-dimension'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xd'), (']', ']'), ('T', 't'), ('output', 'output'), ('binary', 'binari'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('∈', '∈'), ('{', '{'), ('0', '0'), (',', ','), ('1', '1'), ('}', '}'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Example', 'exampl'), ('1', '1'), (':', ':'), ('Consider', 'consid'), ('binary', 'binari'), ('classification', 'classif'), ('problem', 'problem'), ('input', 'input'), ('generic', 'generic'), ('D-dimensional', 'd-dimension'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xd'), (']', ']'), ('T', 't'), ('output', 'output'), ('binary', 'binari'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('∈', '∈'), ('{', '{'), ('0', '0'), (',', ','), ('1', '1'), ('}', '}'), ('.', '.')]

>> Lemmatization: 
 [('Example', 'Example'), ('1', '1'), (':', ':'), ('Consider', 'Consider'), ('binary', 'binary'), ('classification', 'classification'), ('problem', 'problem'), ('input', 'input'), ('generic', 'generic'), ('D-dimensional', 'D-dimensional'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xD'), (']', ']'), ('T', 'T'), ('output', 'output'), ('binary', 'binary'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('∈', '∈'), ('{', '{'), ('0', '0'), (',', ','), ('1', '1'), ('}', '}'), ('.', '.')]



============================ Sentence 218 =============================

The superscript “T ” represents transposition. 


>> Tokens are: 
 ['The', 'superscript', '“', 'T', '”', 'represents', 'transposition', '.']

>> Bigrams are: 
 [('The', 'superscript'), ('superscript', '“'), ('“', 'T'), ('T', '”'), ('”', 'represents'), ('represents', 'transposition'), ('transposition', '.')]

>> Trigrams are: 
 [('The', 'superscript', '“'), ('superscript', '“', 'T'), ('“', 'T', '”'), ('T', '”', 'represents'), ('”', 'represents', 'transposition'), ('represents', 'transposition', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('superscript', 'NN'), ('“', 'NNP'), ('T', 'NNP'), ('”', 'NNP'), ('represents', 'VBZ'), ('transposition', 'NN'), ('.', '.')]

 (S
  (NP The/DT superscript/NN “/NNP T/NNP ”/NNP)
  represents/VBZ
  (NP transposition/NN)
  ./.) 


>> Noun Phrases are: 
 ['The superscript “ T ”', 'transposition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('superscript', 'superscript'), ('“', '“'), ('T', 't'), ('”', '”'), ('represents', 'repres'), ('transposition', 'transposit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('superscript', 'superscript'), ('“', '“'), ('T', 't'), ('”', '”'), ('represents', 'repres'), ('transposition', 'transposit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('superscript', 'superscript'), ('“', '“'), ('T', 'T'), ('”', '”'), ('represents', 'represents'), ('transposition', 'transposition'), ('.', '.')]



============================ Sentence 219 =============================

In Step 1, we select a model, that is, a parameterized family of distributions. 


>> Tokens are: 
 ['In', 'Step', '1', ',', 'select', 'model', ',', ',', 'parameterized', 'family', 'distributions', '.']

>> Bigrams are: 
 [('In', 'Step'), ('Step', '1'), ('1', ','), (',', 'select'), ('select', 'model'), ('model', ','), (',', ','), (',', 'parameterized'), ('parameterized', 'family'), ('family', 'distributions'), ('distributions', '.')]

>> Trigrams are: 
 [('In', 'Step', '1'), ('Step', '1', ','), ('1', ',', 'select'), (',', 'select', 'model'), ('select', 'model', ','), ('model', ',', ','), (',', ',', 'parameterized'), (',', 'parameterized', 'family'), ('parameterized', 'family', 'distributions'), ('family', 'distributions', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Step', 'NNP'), ('1', 'CD'), (',', ','), ('select', 'JJ'), ('model', 'NN'), (',', ','), (',', ','), ('parameterized', 'VBD'), ('family', 'NN'), ('distributions', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP Step/NNP)
  1/CD
  ,/,
  (NP select/JJ model/NN)
  ,/,
  ,/,
  parameterized/VBD
  (NP family/NN distributions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'select model', 'family distributions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('1', '1'), (',', ','), ('select', 'select'), ('model', 'model'), (',', ','), (',', ','), ('parameterized', 'parameter'), ('family', 'famili'), ('distributions', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('1', '1'), (',', ','), ('select', 'select'), ('model', 'model'), (',', ','), (',', ','), ('parameterized', 'parameter'), ('family', 'famili'), ('distributions', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Step', 'Step'), ('1', '1'), (',', ','), ('select', 'select'), ('model', 'model'), (',', ','), (',', ','), ('parameterized', 'parameterized'), ('family', 'family'), ('distributions', 'distribution'), ('.', '.')]



============================ Sentence 220 =============================

A common choice is given by logistic regression1, which is a discriminative model whereby the predictive distribution p(t|x, θ) is parameterized as illustrated in Fig. 


>> Tokens are: 
 ['A', 'common', 'choice', 'given', 'logistic', 'regression1', ',', 'discriminative', 'model', 'whereby', 'predictive', 'distribution', 'p', '(', 't|x', ',', 'θ', ')', 'parameterized', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('A', 'common'), ('common', 'choice'), ('choice', 'given'), ('given', 'logistic'), ('logistic', 'regression1'), ('regression1', ','), (',', 'discriminative'), ('discriminative', 'model'), ('model', 'whereby'), ('whereby', 'predictive'), ('predictive', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'θ'), ('θ', ')'), (')', 'parameterized'), ('parameterized', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('A', 'common', 'choice'), ('common', 'choice', 'given'), ('choice', 'given', 'logistic'), ('given', 'logistic', 'regression1'), ('logistic', 'regression1', ','), ('regression1', ',', 'discriminative'), (',', 'discriminative', 'model'), ('discriminative', 'model', 'whereby'), ('model', 'whereby', 'predictive'), ('whereby', 'predictive', 'distribution'), ('predictive', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'parameterized'), (')', 'parameterized', 'illustrated'), ('parameterized', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('common', 'JJ'), ('choice', 'NN'), ('given', 'VBN'), ('logistic', 'JJ'), ('regression1', 'NN'), (',', ','), ('discriminative', 'JJ'), ('model', 'NN'), ('whereby', 'WRB'), ('predictive', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('parameterized', 'VBD'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP A/DT common/JJ choice/NN)
  given/VBN
  (NP logistic/JJ regression1/NN)
  ,/,
  (NP discriminative/JJ model/NN)
  whereby/WRB
  (NP predictive/JJ distribution/NN p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP θ/NNP)
  )/)
  parameterized/VBD
  (NP illustrated/JJ Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['A common choice', 'logistic regression1', 'discriminative model', 'predictive distribution p', 't|x', 'θ', 'illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('common', 'common'), ('choice', 'choic'), ('given', 'given'), ('logistic', 'logist'), ('regression1', 'regression1'), (',', ','), ('discriminative', 'discrimin'), ('model', 'model'), ('whereby', 'wherebi'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('parameterized', 'parameter'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('common', 'common'), ('choice', 'choic'), ('given', 'given'), ('logistic', 'logist'), ('regression1', 'regression1'), (',', ','), ('discriminative', 'discrimin'), ('model', 'model'), ('whereby', 'wherebi'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('parameterized', 'parameter'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('common', 'common'), ('choice', 'choice'), ('given', 'given'), ('logistic', 'logistic'), ('regression1', 'regression1'), (',', ','), ('discriminative', 'discriminative'), ('model', 'model'), ('whereby', 'whereby'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('parameterized', 'parameterized'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 221 =============================

7. 


>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

 (S 7/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]



============================ Sentence 222 =============================

The model first computes D′ fixed features φ(x) = [φ1(x) · · ·φD′(x)]T of the input, where a feature is a function of the data. 


>> Tokens are: 
 ['The', 'model', 'first', 'computes', 'D′', 'fixed', 'features', 'φ', '(', 'x', ')', '=', '[', 'φ1', '(', 'x', ')', '·', '·', '·φD′', '(', 'x', ')', ']', 'T', 'input', ',', 'feature', 'function', 'data', '.']

>> Bigrams are: 
 [('The', 'model'), ('model', 'first'), ('first', 'computes'), ('computes', 'D′'), ('D′', 'fixed'), ('fixed', 'features'), ('features', 'φ'), ('φ', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', '['), ('[', 'φ1'), ('φ1', '('), ('(', 'x'), ('x', ')'), (')', '·'), ('·', '·'), ('·', '·φD′'), ('·φD′', '('), ('(', 'x'), ('x', ')'), (')', ']'), (']', 'T'), ('T', 'input'), ('input', ','), (',', 'feature'), ('feature', 'function'), ('function', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'model', 'first'), ('model', 'first', 'computes'), ('first', 'computes', 'D′'), ('computes', 'D′', 'fixed'), ('D′', 'fixed', 'features'), ('fixed', 'features', 'φ'), ('features', 'φ', '('), ('φ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', '['), ('=', '[', 'φ1'), ('[', 'φ1', '('), ('φ1', '(', 'x'), ('(', 'x', ')'), ('x', ')', '·'), (')', '·', '·'), ('·', '·', '·φD′'), ('·', '·φD′', '('), ('·φD′', '(', 'x'), ('(', 'x', ')'), ('x', ')', ']'), (')', ']', 'T'), (']', 'T', 'input'), ('T', 'input', ','), ('input', ',', 'feature'), (',', 'feature', 'function'), ('feature', 'function', 'data'), ('function', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('model', 'NN'), ('first', 'RB'), ('computes', 'VBZ'), ('D′', 'NNP'), ('fixed', 'JJ'), ('features', 'NNS'), ('φ', 'VBP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBP'), ('[', 'JJ'), ('φ1', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('·', 'VBP'), ('·', 'JJ'), ('·φD′', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (']', 'VBP'), ('T', 'NNP'), ('input', 'NN'), (',', ','), ('feature', 'NN'), ('function', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP The/DT model/NN)
  first/RB
  computes/VBZ
  (NP D′/NNP)
  (NP fixed/JJ features/NNS)
  φ/VBP
  (/(
  (NP x/NNP)
  )/)
  =/VBP
  (NP [/JJ φ1/NNP)
  (/(
  (NP x/NNP)
  )/)
  ·/VBP
  (NP ·/JJ ·φD′/NNP)
  (/(
  (NP x/NNP)
  )/)
  ]/VBP
  (NP T/NNP input/NN)
  ,/,
  (NP feature/NN function/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The model', 'D′', 'fixed features', 'x', '[ φ1', 'x', '· ·φD′', 'x', 'T input', 'feature function data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('model', 'model'), ('first', 'first'), ('computes', 'comput'), ('D′', 'd′'), ('fixed', 'fix'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('[', '['), ('φ1', 'φ1'), ('(', '('), ('x', 'x'), (')', ')'), ('·', '·'), ('·', '·'), ('·φD′', '·φd′'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('T', 't'), ('input', 'input'), (',', ','), ('feature', 'featur'), ('function', 'function'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('model', 'model'), ('first', 'first'), ('computes', 'comput'), ('D′', 'd′'), ('fixed', 'fix'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('[', '['), ('φ1', 'φ1'), ('(', '('), ('x', 'x'), (')', ')'), ('·', '·'), ('·', '·'), ('·φD′', '·φd′'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('T', 't'), ('input', 'input'), (',', ','), ('feature', 'featur'), ('function', 'function'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('model', 'model'), ('first', 'first'), ('computes', 'computes'), ('D′', 'D′'), ('fixed', 'fixed'), ('features', 'feature'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('[', '['), ('φ1', 'φ1'), ('(', '('), ('x', 'x'), (')', ')'), ('·', '·'), ('·', '·'), ('·φD′', '·φD′'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('T', 'T'), ('input', 'input'), (',', ','), ('feature', 'feature'), ('function', 'function'), ('data', 'data'), ('.', '.')]



============================ Sentence 223 =============================

Then, it computes the predictive probability as  p(t = 1|x,w) = σ(wTφ(x)), (7)  where w is the set of learnable weights – i.e.-, the pa- rameter θ defined above – and σ(a) = (1+exp(−a))−1 is the sigmoid function. 


>> Tokens are: 
 ['Then', ',', 'computes', 'predictive', 'probability', 'p', '(', '=', '1|x', ',', 'w', ')', '=', 'σ', '(', 'wTφ', '(', 'x', ')', ')', ',', '(', '7', ')', 'w', 'set', 'learnable', 'weights', '–', 'i.e.-', ',', 'pa-', 'rameter', 'θ', 'defined', '–', 'σ', '(', ')', '=', '(', '1+exp', '(', '−a', ')', ')', '−1', 'sigmoid', 'function', '.']

>> Bigrams are: 
 [('Then', ','), (',', 'computes'), ('computes', 'predictive'), ('predictive', 'probability'), ('probability', 'p'), ('p', '('), ('(', '='), ('=', '1|x'), ('1|x', ','), (',', 'w'), ('w', ')'), (')', '='), ('=', 'σ'), ('σ', '('), ('(', 'wTφ'), ('wTφ', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', ','), (',', '('), ('(', '7'), ('7', ')'), (')', 'w'), ('w', 'set'), ('set', 'learnable'), ('learnable', 'weights'), ('weights', '–'), ('–', 'i.e.-'), ('i.e.-', ','), (',', 'pa-'), ('pa-', 'rameter'), ('rameter', 'θ'), ('θ', 'defined'), ('defined', '–'), ('–', 'σ'), ('σ', '('), ('(', ')'), (')', '='), ('=', '('), ('(', '1+exp'), ('1+exp', '('), ('(', '−a'), ('−a', ')'), (')', ')'), (')', '−1'), ('−1', 'sigmoid'), ('sigmoid', 'function'), ('function', '.')]

>> Trigrams are: 
 [('Then', ',', 'computes'), (',', 'computes', 'predictive'), ('computes', 'predictive', 'probability'), ('predictive', 'probability', 'p'), ('probability', 'p', '('), ('p', '(', '='), ('(', '=', '1|x'), ('=', '1|x', ','), ('1|x', ',', 'w'), (',', 'w', ')'), ('w', ')', '='), (')', '=', 'σ'), ('=', 'σ', '('), ('σ', '(', 'wTφ'), ('(', 'wTφ', '('), ('wTφ', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', ','), (')', ',', '('), (',', '(', '7'), ('(', '7', ')'), ('7', ')', 'w'), (')', 'w', 'set'), ('w', 'set', 'learnable'), ('set', 'learnable', 'weights'), ('learnable', 'weights', '–'), ('weights', '–', 'i.e.-'), ('–', 'i.e.-', ','), ('i.e.-', ',', 'pa-'), (',', 'pa-', 'rameter'), ('pa-', 'rameter', 'θ'), ('rameter', 'θ', 'defined'), ('θ', 'defined', '–'), ('defined', '–', 'σ'), ('–', 'σ', '('), ('σ', '(', ')'), ('(', ')', '='), (')', '=', '('), ('=', '(', '1+exp'), ('(', '1+exp', '('), ('1+exp', '(', '−a'), ('(', '−a', ')'), ('−a', ')', ')'), (')', ')', '−1'), (')', '−1', 'sigmoid'), ('−1', 'sigmoid', 'function'), ('sigmoid', 'function', '.')]

>> POS Tags are: 
 [('Then', 'RB'), (',', ','), ('computes', 'NNS'), ('predictive', 'VBP'), ('probability', 'NN'), ('p', 'NN'), ('(', '('), ('=', 'JJ'), ('1|x', 'CD'), (',', ','), ('w', 'NN'), (')', ')'), ('=', 'NN'), ('σ', 'NNP'), ('(', '('), ('wTφ', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('7', 'CD'), (')', ')'), ('w', 'NN'), ('set', 'VBN'), ('learnable', 'JJ'), ('weights', 'NNS'), ('–', 'POS'), ('i.e.-', 'NN'), (',', ','), ('pa-', 'JJ'), ('rameter', 'NN'), ('θ', 'NN'), ('defined', 'VBD'), ('–', 'NNP'), ('σ', 'NNP'), ('(', '('), (')', ')'), ('=', 'NN'), ('(', '('), ('1+exp', 'CD'), ('(', '('), ('−a', 'NNP'), (')', ')'), (')', ')'), ('−1', 'VBP'), ('sigmoid', 'JJ'), ('function', 'NN'), ('.', '.')]

 (S
  Then/RB
  ,/,
  (NP computes/NNS)
  predictive/VBP
  (NP probability/NN p/NN)
  (/(
  =/JJ
  1|x/CD
  ,/,
  (NP w/NN)
  )/)
  (NP =/NN σ/NNP)
  (/(
  (NP wTφ/NN)
  (/(
  (NP x/NNP)
  )/)
  )/)
  ,/,
  (/(
  7/CD
  )/)
  (NP w/NN)
  set/VBN
  (NP learnable/JJ weights/NNS)
  –/POS
  (NP i.e.-/NN)
  ,/,
  (NP pa-/JJ rameter/NN θ/NN)
  defined/VBD
  (NP –/NNP σ/NNP)
  (/(
  )/)
  (NP =/NN)
  (/(
  1+exp/CD
  (/(
  (NP −a/NNP)
  )/)
  )/)
  −1/VBP
  (NP sigmoid/JJ function/NN)
  ./.) 


>> Noun Phrases are: 
 ['computes', 'probability p', 'w', '= σ', 'wTφ', 'x', 'w', 'learnable weights', 'i.e.-', 'pa- rameter θ', '– σ', '=', '−a', 'sigmoid function']

>> Named Entities are: 
 [('ORGANIZATION', 'wTφ')] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), (',', ','), ('computes', 'comput'), ('predictive', 'predict'), ('probability', 'probabl'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('=', '='), ('σ', 'σ'), ('(', '('), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('7', '7'), (')', ')'), ('w', 'w'), ('set', 'set'), ('learnable', 'learnabl'), ('weights', 'weight'), ('–', '–'), ('i.e.-', 'i.e.-'), (',', ','), ('pa-', 'pa-'), ('rameter', 'ramet'), ('θ', 'θ'), ('defined', 'defin'), ('–', '–'), ('σ', 'σ'), ('(', '('), (')', ')'), ('=', '='), ('(', '('), ('1+exp', '1+exp'), ('(', '('), ('−a', '−a'), (')', ')'), (')', ')'), ('−1', '−1'), ('sigmoid', 'sigmoid'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), (',', ','), ('computes', 'comput'), ('predictive', 'predict'), ('probability', 'probabl'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('=', '='), ('σ', 'σ'), ('(', '('), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('7', '7'), (')', ')'), ('w', 'w'), ('set', 'set'), ('learnable', 'learnabl'), ('weights', 'weight'), ('–', '–'), ('i.e.-', 'i.e.-'), (',', ','), ('pa-', 'pa-'), ('rameter', 'ramet'), ('θ', 'θ'), ('defined', 'defin'), ('–', '–'), ('σ', 'σ'), ('(', '('), (')', ')'), ('=', '='), ('(', '('), ('1+exp', '1+exp'), ('(', '('), ('−a', '−a'), (')', ')'), (')', ')'), ('−1', '−1'), ('sigmoid', 'sigmoid'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('Then', 'Then'), (',', ','), ('computes', 'computes'), ('predictive', 'predictive'), ('probability', 'probability'), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('=', '='), ('σ', 'σ'), ('(', '('), ('wTφ', 'wTφ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('7', '7'), (')', ')'), ('w', 'w'), ('set', 'set'), ('learnable', 'learnable'), ('weights', 'weight'), ('–', '–'), ('i.e.-', 'i.e.-'), (',', ','), ('pa-', 'pa-'), ('rameter', 'rameter'), ('θ', 'θ'), ('defined', 'defined'), ('–', '–'), ('σ', 'σ'), ('(', '('), (')', ')'), ('=', '='), ('(', '('), ('1+exp', '1+exp'), ('(', '('), ('−a', '−a'), (')', ')'), (')', ')'), ('−1', '−1'), ('sigmoid', 'sigmoid'), ('function', 'function'), ('.', '.')]



============================ Sentence 224 =============================

Under logistic regression, the probability that the label is t = 1 increases as the linear combination of features becomes more positive, and we have p(t = 1|x,w) > 0.5 for wTφ(x) > 0. 


>> Tokens are: 
 ['Under', 'logistic', 'regression', ',', 'probability', 'label', '=', '1', 'increases', 'linear', 'combination', 'features', 'becomes', 'positive', ',', 'p', '(', '=', '1|x', ',', 'w', ')', '>', '0.5', 'wTφ', '(', 'x', ')', '>', '0', '.']

>> Bigrams are: 
 [('Under', 'logistic'), ('logistic', 'regression'), ('regression', ','), (',', 'probability'), ('probability', 'label'), ('label', '='), ('=', '1'), ('1', 'increases'), ('increases', 'linear'), ('linear', 'combination'), ('combination', 'features'), ('features', 'becomes'), ('becomes', 'positive'), ('positive', ','), (',', 'p'), ('p', '('), ('(', '='), ('=', '1|x'), ('1|x', ','), (',', 'w'), ('w', ')'), (')', '>'), ('>', '0.5'), ('0.5', 'wTφ'), ('wTφ', '('), ('(', 'x'), ('x', ')'), (')', '>'), ('>', '0'), ('0', '.')]

>> Trigrams are: 
 [('Under', 'logistic', 'regression'), ('logistic', 'regression', ','), ('regression', ',', 'probability'), (',', 'probability', 'label'), ('probability', 'label', '='), ('label', '=', '1'), ('=', '1', 'increases'), ('1', 'increases', 'linear'), ('increases', 'linear', 'combination'), ('linear', 'combination', 'features'), ('combination', 'features', 'becomes'), ('features', 'becomes', 'positive'), ('becomes', 'positive', ','), ('positive', ',', 'p'), (',', 'p', '('), ('p', '(', '='), ('(', '=', '1|x'), ('=', '1|x', ','), ('1|x', ',', 'w'), (',', 'w', ')'), ('w', ')', '>'), (')', '>', '0.5'), ('>', '0.5', 'wTφ'), ('0.5', 'wTφ', '('), ('wTφ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '>'), (')', '>', '0'), ('>', '0', '.')]

>> POS Tags are: 
 [('Under', 'IN'), ('logistic', 'JJ'), ('regression', 'NN'), (',', ','), ('probability', 'NN'), ('label', 'NN'), ('=', 'VBZ'), ('1', 'CD'), ('increases', 'NNS'), ('linear', 'JJ'), ('combination', 'NN'), ('features', 'NNS'), ('becomes', 'VBZ'), ('positive', 'JJ'), (',', ','), ('p', 'NN'), ('(', '('), ('=', 'JJ'), ('1|x', 'CD'), (',', ','), ('w', 'NN'), (')', ')'), ('>', 'VBZ'), ('0.5', 'CD'), ('wTφ', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('>', 'VBD'), ('0', 'CD'), ('.', '.')]

 (S
  Under/IN
  (NP logistic/JJ regression/NN)
  ,/,
  (NP probability/NN label/NN)
  =/VBZ
  1/CD
  (NP increases/NNS)
  (NP linear/JJ combination/NN features/NNS)
  becomes/VBZ
  positive/JJ
  ,/,
  (NP p/NN)
  (/(
  =/JJ
  1|x/CD
  ,/,
  (NP w/NN)
  )/)
  >/VBZ
  0.5/CD
  (NP wTφ/NN)
  (/(
  (NP x/NNP)
  )/)
  >/VBD
  0/CD
  ./.) 


>> Noun Phrases are: 
 ['logistic regression', 'probability label', 'increases', 'linear combination features', 'p', 'w', 'wTφ', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Under', 'under'), ('logistic', 'logist'), ('regression', 'regress'), (',', ','), ('probability', 'probabl'), ('label', 'label'), ('=', '='), ('1', '1'), ('increases', 'increas'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('becomes', 'becom'), ('positive', 'posit'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Under', 'under'), ('logistic', 'logist'), ('regression', 'regress'), (',', ','), ('probability', 'probabl'), ('label', 'label'), ('=', '='), ('1', '1'), ('increases', 'increas'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('becomes', 'becom'), ('positive', 'posit'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('.', '.')]

>> Lemmatization: 
 [('Under', 'Under'), ('logistic', 'logistic'), ('regression', 'regression'), (',', ','), ('probability', 'probability'), ('label', 'label'), ('=', '='), ('1', '1'), ('increases', 'increase'), ('linear', 'linear'), ('combination', 'combination'), ('features', 'feature'), ('becomes', 'becomes'), ('positive', 'positive'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('1|x', '1|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wTφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('.', '.')]



============================ Sentence 225 =============================

Conversely, the probability that the label is t = 0 increases as the linear combination of features becomes more negative, with p(t = 0|x,w) > 0.5 for wTφ(x) < 0. 


>> Tokens are: 
 ['Conversely', ',', 'probability', 'label', '=', '0', 'increases', 'linear', 'combination', 'features', 'becomes', 'negative', ',', 'p', '(', '=', '0|x', ',', 'w', ')', '>', '0.5', 'wTφ', '(', 'x', ')', '<', '0', '.']

>> Bigrams are: 
 [('Conversely', ','), (',', 'probability'), ('probability', 'label'), ('label', '='), ('=', '0'), ('0', 'increases'), ('increases', 'linear'), ('linear', 'combination'), ('combination', 'features'), ('features', 'becomes'), ('becomes', 'negative'), ('negative', ','), (',', 'p'), ('p', '('), ('(', '='), ('=', '0|x'), ('0|x', ','), (',', 'w'), ('w', ')'), (')', '>'), ('>', '0.5'), ('0.5', 'wTφ'), ('wTφ', '('), ('(', 'x'), ('x', ')'), (')', '<'), ('<', '0'), ('0', '.')]

>> Trigrams are: 
 [('Conversely', ',', 'probability'), (',', 'probability', 'label'), ('probability', 'label', '='), ('label', '=', '0'), ('=', '0', 'increases'), ('0', 'increases', 'linear'), ('increases', 'linear', 'combination'), ('linear', 'combination', 'features'), ('combination', 'features', 'becomes'), ('features', 'becomes', 'negative'), ('becomes', 'negative', ','), ('negative', ',', 'p'), (',', 'p', '('), ('p', '(', '='), ('(', '=', '0|x'), ('=', '0|x', ','), ('0|x', ',', 'w'), (',', 'w', ')'), ('w', ')', '>'), (')', '>', '0.5'), ('>', '0.5', 'wTφ'), ('0.5', 'wTφ', '('), ('wTφ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '<'), (')', '<', '0'), ('<', '0', '.')]

>> POS Tags are: 
 [('Conversely', 'RB'), (',', ','), ('probability', 'NN'), ('label', 'NN'), ('=', 'VBZ'), ('0', 'CD'), ('increases', 'NNS'), ('linear', 'JJ'), ('combination', 'NN'), ('features', 'NNS'), ('becomes', 'VBZ'), ('negative', 'JJ'), (',', ','), ('p', 'NN'), ('(', '('), ('=', 'JJ'), ('0|x', 'CD'), (',', ','), ('w', 'NN'), (')', ')'), ('>', 'VBZ'), ('0.5', 'CD'), ('wTφ', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('<', 'VBD'), ('0', 'CD'), ('.', '.')]

 (S
  Conversely/RB
  ,/,
  (NP probability/NN label/NN)
  =/VBZ
  0/CD
  (NP increases/NNS)
  (NP linear/JJ combination/NN features/NNS)
  becomes/VBZ
  negative/JJ
  ,/,
  (NP p/NN)
  (/(
  =/JJ
  0|x/CD
  ,/,
  (NP w/NN)
  )/)
  >/VBZ
  0.5/CD
  (NP wTφ/NN)
  (/(
  (NP x/NNP)
  )/)
  </VBD
  0/CD
  ./.) 


>> Noun Phrases are: 
 ['probability label', 'increases', 'linear combination features', 'p', 'w', 'wTφ', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conversely', 'convers'), (',', ','), ('probability', 'probabl'), ('label', 'label'), ('=', '='), ('0', '0'), ('increases', 'increas'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('becomes', 'becom'), ('negative', 'neg'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('0|x', '0|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('<', '<'), ('0', '0'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conversely', 'convers'), (',', ','), ('probability', 'probabl'), ('label', 'label'), ('=', '='), ('0', '0'), ('increases', 'increas'), ('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('becomes', 'becom'), ('negative', 'negat'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('0|x', '0|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('<', '<'), ('0', '0'), ('.', '.')]

>> Lemmatization: 
 [('Conversely', 'Conversely'), (',', ','), ('probability', 'probability'), ('label', 'label'), ('=', '='), ('0', '0'), ('increases', 'increase'), ('linear', 'linear'), ('combination', 'combination'), ('features', 'feature'), ('becomes', 'becomes'), ('negative', 'negative'), (',', ','), ('p', 'p'), ('(', '('), ('=', '='), ('0|x', '0|x'), (',', ','), ('w', 'w'), (')', ')'), ('>', '>'), ('0.5', '0.5'), ('wTφ', 'wTφ'), ('(', '('), ('x', 'x'), (')', ')'), ('<', '<'), ('0', '0'), ('.', '.')]



============================ Sentence 226 =============================

As a specific instance of this problem, if we wish to classify emails between spam and non-spam ones, possible useful features may count the number of times that certain suspicious words appear in the text. 


>> Tokens are: 
 ['As', 'specific', 'instance', 'problem', ',', 'wish', 'classify', 'emails', 'spam', 'non-spam', 'ones', ',', 'possible', 'useful', 'features', 'may', 'count', 'number', 'times', 'certain', 'suspicious', 'words', 'appear', 'text', '.']

>> Bigrams are: 
 [('As', 'specific'), ('specific', 'instance'), ('instance', 'problem'), ('problem', ','), (',', 'wish'), ('wish', 'classify'), ('classify', 'emails'), ('emails', 'spam'), ('spam', 'non-spam'), ('non-spam', 'ones'), ('ones', ','), (',', 'possible'), ('possible', 'useful'), ('useful', 'features'), ('features', 'may'), ('may', 'count'), ('count', 'number'), ('number', 'times'), ('times', 'certain'), ('certain', 'suspicious'), ('suspicious', 'words'), ('words', 'appear'), ('appear', 'text'), ('text', '.')]

>> Trigrams are: 
 [('As', 'specific', 'instance'), ('specific', 'instance', 'problem'), ('instance', 'problem', ','), ('problem', ',', 'wish'), (',', 'wish', 'classify'), ('wish', 'classify', 'emails'), ('classify', 'emails', 'spam'), ('emails', 'spam', 'non-spam'), ('spam', 'non-spam', 'ones'), ('non-spam', 'ones', ','), ('ones', ',', 'possible'), (',', 'possible', 'useful'), ('possible', 'useful', 'features'), ('useful', 'features', 'may'), ('features', 'may', 'count'), ('may', 'count', 'number'), ('count', 'number', 'times'), ('number', 'times', 'certain'), ('times', 'certain', 'suspicious'), ('certain', 'suspicious', 'words'), ('suspicious', 'words', 'appear'), ('words', 'appear', 'text'), ('appear', 'text', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('specific', 'JJ'), ('instance', 'NN'), ('problem', 'NN'), (',', ','), ('wish', 'JJ'), ('classify', 'NN'), ('emails', 'NNS'), ('spam', 'VBD'), ('non-spam', 'JJ'), ('ones', 'NNS'), (',', ','), ('possible', 'JJ'), ('useful', 'JJ'), ('features', 'NNS'), ('may', 'MD'), ('count', 'VB'), ('number', 'NN'), ('times', 'NNS'), ('certain', 'JJ'), ('suspicious', 'JJ'), ('words', 'NNS'), ('appear', 'VBP'), ('text', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP specific/JJ instance/NN problem/NN)
  ,/,
  (NP wish/JJ classify/NN emails/NNS)
  spam/VBD
  (NP non-spam/JJ ones/NNS)
  ,/,
  (NP possible/JJ useful/JJ features/NNS)
  may/MD
  count/VB
  (NP number/NN times/NNS)
  (NP certain/JJ suspicious/JJ words/NNS)
  appear/VBP
  (NP text/NN)
  ./.) 


>> Noun Phrases are: 
 ['specific instance problem', 'wish classify emails', 'non-spam ones', 'possible useful features', 'number times', 'certain suspicious words', 'text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('specific', 'specif'), ('instance', 'instanc'), ('problem', 'problem'), (',', ','), ('wish', 'wish'), ('classify', 'classifi'), ('emails', 'email'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('ones', 'one'), (',', ','), ('possible', 'possibl'), ('useful', 'use'), ('features', 'featur'), ('may', 'may'), ('count', 'count'), ('number', 'number'), ('times', 'time'), ('certain', 'certain'), ('suspicious', 'suspici'), ('words', 'word'), ('appear', 'appear'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('specific', 'specif'), ('instance', 'instanc'), ('problem', 'problem'), (',', ','), ('wish', 'wish'), ('classify', 'classifi'), ('emails', 'email'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('ones', 'one'), (',', ','), ('possible', 'possibl'), ('useful', 'use'), ('features', 'featur'), ('may', 'may'), ('count', 'count'), ('number', 'number'), ('times', 'time'), ('certain', 'certain'), ('suspicious', 'suspici'), ('words', 'word'), ('appear', 'appear'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('specific', 'specific'), ('instance', 'instance'), ('problem', 'problem'), (',', ','), ('wish', 'wish'), ('classify', 'classify'), ('emails', 'email'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('ones', 'one'), (',', ','), ('possible', 'possible'), ('useful', 'useful'), ('features', 'feature'), ('may', 'may'), ('count', 'count'), ('number', 'number'), ('times', 'time'), ('certain', 'certain'), ('suspicious', 'suspicious'), ('words', 'word'), ('appear', 'appear'), ('text', 'text'), ('.', '.')]



============================ Sentence 227 =============================

Step 2 amounts to the identification of the weight vector w on the basis of the training set D with the ideal goal of minimizing the generalization loss (2). 


>> Tokens are: 
 ['Step', '2', 'amounts', 'identification', 'weight', 'vector', 'w', 'basis', 'training', 'set', 'D', 'ideal', 'goal', 'minimizing', 'generalization', 'loss', '(', '2', ')', '.']

>> Bigrams are: 
 [('Step', '2'), ('2', 'amounts'), ('amounts', 'identification'), ('identification', 'weight'), ('weight', 'vector'), ('vector', 'w'), ('w', 'basis'), ('basis', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'ideal'), ('ideal', 'goal'), ('goal', 'minimizing'), ('minimizing', 'generalization'), ('generalization', 'loss'), ('loss', '('), ('(', '2'), ('2', ')'), (')', '.')]

>> Trigrams are: 
 [('Step', '2', 'amounts'), ('2', 'amounts', 'identification'), ('amounts', 'identification', 'weight'), ('identification', 'weight', 'vector'), ('weight', 'vector', 'w'), ('vector', 'w', 'basis'), ('w', 'basis', 'training'), ('basis', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'ideal'), ('D', 'ideal', 'goal'), ('ideal', 'goal', 'minimizing'), ('goal', 'minimizing', 'generalization'), ('minimizing', 'generalization', 'loss'), ('generalization', 'loss', '('), ('loss', '(', '2'), ('(', '2', ')'), ('2', ')', '.')]

>> POS Tags are: 
 [('Step', 'NN'), ('2', 'CD'), ('amounts', 'NNS'), ('identification', 'NN'), ('weight', 'NN'), ('vector', 'NN'), ('w', 'JJ'), ('basis', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('D', 'NNP'), ('ideal', 'JJ'), ('goal', 'NN'), ('minimizing', 'VBG'), ('generalization', 'NN'), ('loss', 'NN'), ('(', '('), ('2', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Step/NN)
  2/CD
  (NP amounts/NNS identification/NN weight/NN vector/NN)
  (NP w/JJ basis/NN training/NN)
  set/VBN
  (NP D/NNP)
  (NP ideal/JJ goal/NN)
  minimizing/VBG
  (NP generalization/NN loss/NN)
  (/(
  2/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'amounts identification weight vector', 'w basis training', 'D', 'ideal goal', 'generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Step', 'step'), ('2', '2'), ('amounts', 'amount'), ('identification', 'identif'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('basis', 'basi'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('ideal', 'ideal'), ('goal', 'goal'), ('minimizing', 'minim'), ('generalization', 'gener'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Step', 'step'), ('2', '2'), ('amounts', 'amount'), ('identification', 'identif'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('basis', 'basi'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('ideal', 'ideal'), ('goal', 'goal'), ('minimizing', 'minim'), ('generalization', 'general'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Step', 'Step'), ('2', '2'), ('amounts', 'amount'), ('identification', 'identification'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('basis', 'basis'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('ideal', 'ideal'), ('goal', 'goal'), ('minimizing', 'minimizing'), ('generalization', 'generalization'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]



============================ Sentence 228 =============================

This step will be further discussed in the next subsection. 


>> Tokens are: 
 ['This', 'step', 'discussed', 'next', 'subsection', '.']

>> Bigrams are: 
 [('This', 'step'), ('step', 'discussed'), ('discussed', 'next'), ('next', 'subsection'), ('subsection', '.')]

>> Trigrams are: 
 [('This', 'step', 'discussed'), ('step', 'discussed', 'next'), ('discussed', 'next', 'subsection'), ('next', 'subsection', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('step', 'NN'), ('discussed', 'VBD'), ('next', 'JJ'), ('subsection', 'NN'), ('.', '.')]

 (S (NP This/DT step/NN) discussed/VBD (NP next/JJ subsection/NN) ./.) 


>> Noun Phrases are: 
 ['This step', 'next subsection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('step', 'step'), ('discussed', 'discuss'), ('next', 'next'), ('subsection', 'subsect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('step', 'step'), ('discussed', 'discuss'), ('next', 'next'), ('subsection', 'subsect'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('step', 'step'), ('discussed', 'discussed'), ('next', 'next'), ('subsection', 'subsection'), ('.', '.')]



============================ Sentence 229 =============================

Finally, in Step 3, the optimal predictor is obtained by assuming that the learned model p(t|x,w) is the true predictive distribution. 


>> Tokens are: 
 ['Finally', ',', 'Step', '3', ',', 'optimal', 'predictor', 'obtained', 'assuming', 'learned', 'model', 'p', '(', 't|x', ',', 'w', ')', 'true', 'predictive', 'distribution', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'Step'), ('Step', '3'), ('3', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'obtained'), ('obtained', 'assuming'), ('assuming', 'learned'), ('learned', 'model'), ('model', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'w'), ('w', ')'), (')', 'true'), ('true', 'predictive'), ('predictive', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('Finally', ',', 'Step'), (',', 'Step', '3'), ('Step', '3', ','), ('3', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'obtained'), ('predictor', 'obtained', 'assuming'), ('obtained', 'assuming', 'learned'), ('assuming', 'learned', 'model'), ('learned', 'model', 'p'), ('model', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'w'), (',', 'w', ')'), ('w', ')', 'true'), (')', 'true', 'predictive'), ('true', 'predictive', 'distribution'), ('predictive', 'distribution', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('Step', 'NNP'), ('3', 'CD'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('obtained', 'VBD'), ('assuming', 'VBG'), ('learned', 'VBN'), ('model', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('w', 'NN'), (')', ')'), ('true', 'JJ'), ('predictive', 'JJ'), ('distribution', 'NN'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP Step/NNP)
  3/CD
  ,/,
  (NP optimal/JJ predictor/NN)
  obtained/VBD
  assuming/VBG
  learned/VBN
  (NP model/NN p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP w/NN)
  )/)
  (NP true/JJ predictive/JJ distribution/NN)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'optimal predictor', 'model p', 't|x', 'w', 'true predictive distribution']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('Step', 'step'), ('3', '3'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('obtained', 'obtain'), ('assuming', 'assum'), ('learned', 'learn'), ('model', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('true', 'true'), ('predictive', 'predict'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('Step', 'step'), ('3', '3'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('obtained', 'obtain'), ('assuming', 'assum'), ('learned', 'learn'), ('model', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('true', 'true'), ('predictive', 'predict'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('Step', 'Step'), ('3', '3'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('obtained', 'obtained'), ('assuming', 'assuming'), ('learned', 'learned'), ('model', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('true', 'true'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('.', '.')]



============================ Sentence 230 =============================

Assuming an error rate loss function, following the discussion in Sec. 


>> Tokens are: 
 ['Assuming', 'error', 'rate', 'loss', 'function', ',', 'following', 'discussion', 'Sec', '.']

>> Bigrams are: 
 [('Assuming', 'error'), ('error', 'rate'), ('rate', 'loss'), ('loss', 'function'), ('function', ','), (',', 'following'), ('following', 'discussion'), ('discussion', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Assuming', 'error', 'rate'), ('error', 'rate', 'loss'), ('rate', 'loss', 'function'), ('loss', 'function', ','), ('function', ',', 'following'), (',', 'following', 'discussion'), ('following', 'discussion', 'Sec'), ('discussion', 'Sec', '.')]

>> POS Tags are: 
 [('Assuming', 'VBG'), ('error', 'NN'), ('rate', 'NN'), ('loss', 'NN'), ('function', 'NN'), (',', ','), ('following', 'VBG'), ('discussion', 'NN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  Assuming/VBG
  (NP error/NN rate/NN loss/NN function/NN)
  ,/,
  following/VBG
  (NP discussion/NN Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['error rate loss function', 'discussion Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Assuming', 'assum'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('function', 'function'), (',', ','), ('following', 'follow'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Assuming', 'assum'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('function', 'function'), (',', ','), ('following', 'follow'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Assuming', 'Assuming'), ('error', 'error'), ('rate', 'rate'), ('loss', 'loss'), ('function', 'function'), (',', ','), ('following', 'following'), ('discussion', 'discussion'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 231 =============================

III-C, the optimal predictor is given by the MAP choice t̂∗(x) = 1 if wTφ(x) > 0 and t̂∗(x) = 0 otherwise. 


>> Tokens are: 
 ['III-C', ',', 'optimal', 'predictor', 'given', 'MAP', 'choice', 't̂∗', '(', 'x', ')', '=', '1', 'wTφ', '(', 'x', ')', '>', '0', 't̂∗', '(', 'x', ')', '=', '0', 'otherwise', '.']

>> Bigrams are: 
 [('III-C', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'given'), ('given', 'MAP'), ('MAP', 'choice'), ('choice', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', '1'), ('1', 'wTφ'), ('wTφ', '('), ('(', 'x'), ('x', ')'), (')', '>'), ('>', '0'), ('0', 't̂∗'), ('t̂∗', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', '0'), ('0', 'otherwise'), ('otherwise', '.')]

>> Trigrams are: 
 [('III-C', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'given'), ('predictor', 'given', 'MAP'), ('given', 'MAP', 'choice'), ('MAP', 'choice', 't̂∗'), ('choice', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', '1'), ('=', '1', 'wTφ'), ('1', 'wTφ', '('), ('wTφ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '>'), (')', '>', '0'), ('>', '0', 't̂∗'), ('0', 't̂∗', '('), ('t̂∗', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', '0'), ('=', '0', 'otherwise'), ('0', 'otherwise', '.')]

>> POS Tags are: 
 [('III-C', 'NNP'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('given', 'VBN'), ('MAP', 'NNP'), ('choice', 'NN'), ('t̂∗', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBD'), ('1', 'CD'), ('wTφ', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('>', 'VBD'), ('0', 'CD'), ('t̂∗', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBD'), ('0', 'CD'), ('otherwise', 'RB'), ('.', '.')]

 (S
  (NP III-C/NNP)
  ,/,
  (NP optimal/JJ predictor/NN)
  given/VBN
  (NP MAP/NNP choice/NN t̂∗/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBD
  1/CD
  (NP wTφ/NN)
  (/(
  (NP x/NNP)
  )/)
  >/VBD
  0/CD
  (NP t̂∗/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBD
  0/CD
  otherwise/RB
  ./.) 


>> Noun Phrases are: 
 ['III-C', 'optimal predictor', 'MAP choice t̂∗', 'x', 'wTφ', 'x', 't̂∗', 'x']

>> Named Entities are: 
 [('ORGANIZATION', 'MAP')] 

>> Stemming using Porter Stemmer: 
 [('III-C', 'iii-c'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('MAP', 'map'), ('choice', 'choic'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('1', '1'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('0', '0'), ('otherwise', 'otherwis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III-C', 'iii-c'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('MAP', 'map'), ('choice', 'choic'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('1', '1'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('0', '0'), ('otherwise', 'otherwis'), ('.', '.')]

>> Lemmatization: 
 [('III-C', 'III-C'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('given', 'given'), ('MAP', 'MAP'), ('choice', 'choice'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('1', '1'), ('wTφ', 'wTφ'), ('(', '('), ('x', 'x'), (')', ')'), ('>', '>'), ('0', '0'), ('t̂∗', 't̂∗'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('0', '0'), ('otherwise', 'otherwise'), ('.', '.')]



============================ Sentence 232 =============================

It is noted that the linear combination wTφ(x) is also known as logit or log-likelihood ratio (LLR). 


>> Tokens are: 
 ['It', 'noted', 'linear', 'combination', 'wTφ', '(', 'x', ')', 'also', 'known', 'logit', 'log-likelihood', 'ratio', '(', 'LLR', ')', '.']

>> Bigrams are: 
 [('It', 'noted'), ('noted', 'linear'), ('linear', 'combination'), ('combination', 'wTφ'), ('wTφ', '('), ('(', 'x'), ('x', ')'), (')', 'also'), ('also', 'known'), ('known', 'logit'), ('logit', 'log-likelihood'), ('log-likelihood', 'ratio'), ('ratio', '('), ('(', 'LLR'), ('LLR', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'noted', 'linear'), ('noted', 'linear', 'combination'), ('linear', 'combination', 'wTφ'), ('combination', 'wTφ', '('), ('wTφ', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'also'), (')', 'also', 'known'), ('also', 'known', 'logit'), ('known', 'logit', 'log-likelihood'), ('logit', 'log-likelihood', 'ratio'), ('log-likelihood', 'ratio', '('), ('ratio', '(', 'LLR'), ('(', 'LLR', ')'), ('LLR', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('noted', 'VBD'), ('linear', 'JJ'), ('combination', 'NN'), ('wTφ', 'NN'), ('(', '('), ('x', 'NN'), (')', ')'), ('also', 'RB'), ('known', 'VBN'), ('logit', 'JJ'), ('log-likelihood', 'NN'), ('ratio', 'NN'), ('(', '('), ('LLR', 'NNP'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  noted/VBD
  (NP linear/JJ combination/NN wTφ/NN)
  (/(
  (NP x/NN)
  )/)
  also/RB
  known/VBN
  (NP logit/JJ log-likelihood/NN ratio/NN)
  (/(
  (NP LLR/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['linear combination wTφ', 'x', 'logit log-likelihood ratio', 'LLR']

>> Named Entities are: 
 [('ORGANIZATION', 'wTφ'), ('ORGANIZATION', 'LLR')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('noted', 'note'), ('linear', 'linear'), ('combination', 'combin'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('also', 'also'), ('known', 'known'), ('logit', 'logit'), ('log-likelihood', 'log-likelihood'), ('ratio', 'ratio'), ('(', '('), ('LLR', 'llr'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('noted', 'note'), ('linear', 'linear'), ('combination', 'combin'), ('wTφ', 'wtφ'), ('(', '('), ('x', 'x'), (')', ')'), ('also', 'also'), ('known', 'known'), ('logit', 'logit'), ('log-likelihood', 'log-likelihood'), ('ratio', 'ratio'), ('(', '('), ('LLR', 'llr'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('noted', 'noted'), ('linear', 'linear'), ('combination', 'combination'), ('wTφ', 'wTφ'), ('(', '('), ('x', 'x'), (')', ')'), ('also', 'also'), ('known', 'known'), ('logit', 'logit'), ('log-likelihood', 'log-likelihood'), ('ratio', 'ratio'), ('(', '('), ('LLR', 'LLR'), (')', ')'), ('.', '.')]



============================ Sentence 233 =============================

This rule can be seen to correspond to a linear classifier [19]. 


>> Tokens are: 
 ['This', 'rule', 'seen', 'correspond', 'linear', 'classifier', '[', '19', ']', '.']

>> Bigrams are: 
 [('This', 'rule'), ('rule', 'seen'), ('seen', 'correspond'), ('correspond', 'linear'), ('linear', 'classifier'), ('classifier', '['), ('[', '19'), ('19', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'rule', 'seen'), ('rule', 'seen', 'correspond'), ('seen', 'correspond', 'linear'), ('correspond', 'linear', 'classifier'), ('linear', 'classifier', '['), ('classifier', '[', '19'), ('[', '19', ']'), ('19', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('rule', 'NN'), ('seen', 'VBN'), ('correspond', 'NN'), ('linear', 'JJ'), ('classifier', 'NN'), ('[', '$'), ('19', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT rule/NN)
  seen/VBN
  (NP correspond/NN)
  (NP linear/JJ classifier/NN)
  [/$
  19/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This rule', 'correspond', 'linear classifier', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('rule', 'rule'), ('seen', 'seen'), ('correspond', 'correspond'), ('linear', 'linear'), ('classifier', 'classifi'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('rule', 'rule'), ('seen', 'seen'), ('correspond', 'correspond'), ('linear', 'linear'), ('classifier', 'classifi'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('rule', 'rule'), ('seen', 'seen'), ('correspond', 'correspond'), ('linear', 'linear'), ('classifier', 'classifier'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]



============================ Sentence 234 =============================

The performance  1The term ”regression” may be confusing, since the model applies to classification. 


>> Tokens are: 
 ['The', 'performance', '1The', 'term', '”', 'regression', '”', 'may', 'confusing', ',', 'since', 'model', 'applies', 'classification', '.']

>> Bigrams are: 
 [('The', 'performance'), ('performance', '1The'), ('1The', 'term'), ('term', '”'), ('”', 'regression'), ('regression', '”'), ('”', 'may'), ('may', 'confusing'), ('confusing', ','), (',', 'since'), ('since', 'model'), ('model', 'applies'), ('applies', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('The', 'performance', '1The'), ('performance', '1The', 'term'), ('1The', 'term', '”'), ('term', '”', 'regression'), ('”', 'regression', '”'), ('regression', '”', 'may'), ('”', 'may', 'confusing'), ('may', 'confusing', ','), ('confusing', ',', 'since'), (',', 'since', 'model'), ('since', 'model', 'applies'), ('model', 'applies', 'classification'), ('applies', 'classification', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('performance', 'NN'), ('1The', 'CD'), ('term', 'NN'), ('”', 'NNP'), ('regression', 'NN'), ('”', 'NN'), ('may', 'MD'), ('confusing', 'VB'), (',', ','), ('since', 'IN'), ('model', 'NN'), ('applies', 'NNS'), ('classification', 'NN'), ('.', '.')]

 (S
  (NP The/DT performance/NN)
  1The/CD
  (NP term/NN ”/NNP regression/NN ”/NN)
  may/MD
  confusing/VB
  ,/,
  since/IN
  (NP model/NN applies/NNS classification/NN)
  ./.) 


>> Noun Phrases are: 
 ['The performance', 'term ” regression ”', 'model applies classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('1The', '1the'), ('term', 'term'), ('”', '”'), ('regression', 'regress'), ('”', '”'), ('may', 'may'), ('confusing', 'confus'), (',', ','), ('since', 'sinc'), ('model', 'model'), ('applies', 'appli'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('1The', '1the'), ('term', 'term'), ('”', '”'), ('regression', 'regress'), ('”', '”'), ('may', 'may'), ('confusing', 'confus'), (',', ','), ('since', 'sinc'), ('model', 'model'), ('applies', 'appli'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('performance', 'performance'), ('1The', '1The'), ('term', 'term'), ('”', '”'), ('regression', 'regression'), ('”', '”'), ('may', 'may'), ('confusing', 'confusing'), (',', ','), ('since', 'since'), ('model', 'model'), ('applies', 'applies'), ('classification', 'classification'), ('.', '.')]



============================ Sentence 235 =============================

Fig. 


>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

 (S (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]



============================ Sentence 236 =============================

7. 


>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

 (S 7/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]



============================ Sentence 237 =============================

An illustration of the hypothesis class p(t|x,w) assumed by logistic regression using a neural network representation: functions φi, with i = 1, ..., D′, are fixed and compute features of the input vector x = [x1, ..., xD]. 


>> Tokens are: 
 ['An', 'illustration', 'hypothesis', 'class', 'p', '(', 't|x', ',', 'w', ')', 'assumed', 'logistic', 'regression', 'using', 'neural', 'network', 'representation', ':', 'functions', 'φi', ',', '=', '1', ',', '...', ',', 'D′', ',', 'fixed', 'compute', 'features', 'input', 'vector', 'x', '=', '[', 'x1', ',', '...', ',', 'xD', ']', '.']

>> Bigrams are: 
 [('An', 'illustration'), ('illustration', 'hypothesis'), ('hypothesis', 'class'), ('class', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'w'), ('w', ')'), (')', 'assumed'), ('assumed', 'logistic'), ('logistic', 'regression'), ('regression', 'using'), ('using', 'neural'), ('neural', 'network'), ('network', 'representation'), ('representation', ':'), (':', 'functions'), ('functions', 'φi'), ('φi', ','), (',', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'D′'), ('D′', ','), (',', 'fixed'), ('fixed', 'compute'), ('compute', 'features'), ('features', 'input'), ('input', 'vector'), ('vector', 'x'), ('x', '='), ('=', '['), ('[', 'x1'), ('x1', ','), (',', '...'), ('...', ','), (',', 'xD'), ('xD', ']'), (']', '.')]

>> Trigrams are: 
 [('An', 'illustration', 'hypothesis'), ('illustration', 'hypothesis', 'class'), ('hypothesis', 'class', 'p'), ('class', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'w'), (',', 'w', ')'), ('w', ')', 'assumed'), (')', 'assumed', 'logistic'), ('assumed', 'logistic', 'regression'), ('logistic', 'regression', 'using'), ('regression', 'using', 'neural'), ('using', 'neural', 'network'), ('neural', 'network', 'representation'), ('network', 'representation', ':'), ('representation', ':', 'functions'), (':', 'functions', 'φi'), ('functions', 'φi', ','), ('φi', ',', '='), (',', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'D′'), (',', 'D′', ','), ('D′', ',', 'fixed'), (',', 'fixed', 'compute'), ('fixed', 'compute', 'features'), ('compute', 'features', 'input'), ('features', 'input', 'vector'), ('input', 'vector', 'x'), ('vector', 'x', '='), ('x', '=', '['), ('=', '[', 'x1'), ('[', 'x1', ','), ('x1', ',', '...'), (',', '...', ','), ('...', ',', 'xD'), (',', 'xD', ']'), ('xD', ']', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('illustration', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('w', 'NN'), (')', ')'), ('assumed', 'VBD'), ('logistic', 'JJ'), ('regression', 'NN'), ('using', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('representation', 'NN'), (':', ':'), ('functions', 'NNS'), ('φi', 'VBP'), (',', ','), ('=', 'JJ'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('D′', 'NNP'), (',', ','), ('fixed', 'VBD'), ('compute', 'NN'), ('features', 'NNS'), ('input', 'VBP'), ('vector', 'NN'), ('x', 'NN'), ('=', 'NNP'), ('[', 'NNP'), ('x1', 'NNP'), (',', ','), ('...', ':'), (',', ','), ('xD', 'JJ'), (']', 'NN'), ('.', '.')]

 (S
  (NP An/DT illustration/NN hypothesis/NN class/NN p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP w/NN)
  )/)
  assumed/VBD
  (NP logistic/JJ regression/NN)
  using/VBG
  (NP neural/JJ network/NN representation/NN)
  :/:
  (NP functions/NNS)
  φi/VBP
  ,/,
  =/JJ
  1/CD
  ,/,
  .../:
  ,/,
  (NP D′/NNP)
  ,/,
  fixed/VBD
  (NP compute/NN features/NNS)
  input/VBP
  (NP vector/NN x/NN =/NNP [/NNP x1/NNP)
  ,/,
  .../:
  ,/,
  (NP xD/JJ ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['An illustration hypothesis class p', 't|x', 'w', 'logistic regression', 'neural network representation', 'functions', 'D′', 'compute features', 'vector x = [ x1', 'xD ]']

>> Named Entities are: 
 [('ORGANIZATION', 'xD')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('illustration', 'illustr'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assum'), ('logistic', 'logist'), ('regression', 'regress'), ('using', 'use'), ('neural', 'neural'), ('network', 'network'), ('representation', 'represent'), (':', ':'), ('functions', 'function'), ('φi', 'φi'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('D′', 'd′'), (',', ','), ('fixed', 'fix'), ('compute', 'comput'), ('features', 'featur'), ('input', 'input'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xd'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('illustration', 'illustr'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assum'), ('logistic', 'logist'), ('regression', 'regress'), ('using', 'use'), ('neural', 'neural'), ('network', 'network'), ('representation', 'represent'), (':', ':'), ('functions', 'function'), ('φi', 'φi'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('D′', 'd′'), (',', ','), ('fixed', 'fix'), ('compute', 'comput'), ('features', 'featur'), ('input', 'input'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xd'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('illustration', 'illustration'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assumed'), ('logistic', 'logistic'), ('regression', 'regression'), ('using', 'using'), ('neural', 'neural'), ('network', 'network'), ('representation', 'representation'), (':', ':'), ('functions', 'function'), ('φi', 'φi'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('D′', 'D′'), (',', ','), ('fixed', 'fixed'), ('compute', 'compute'), ('features', 'feature'), ('input', 'input'), ('vector', 'vector'), ('x', 'x'), ('=', '='), ('[', '['), ('x1', 'x1'), (',', ','), ('...', '...'), (',', ','), ('xD', 'xD'), (']', ']'), ('.', '.')]



============================ Sentence 238 =============================

The learnable parameter vector θ here corresponds to the weights w used to linearly combine the features in (7). 


>> Tokens are: 
 ['The', 'learnable', 'parameter', 'vector', 'θ', 'corresponds', 'weights', 'w', 'used', 'linearly', 'combine', 'features', '(', '7', ')', '.']

>> Bigrams are: 
 [('The', 'learnable'), ('learnable', 'parameter'), ('parameter', 'vector'), ('vector', 'θ'), ('θ', 'corresponds'), ('corresponds', 'weights'), ('weights', 'w'), ('w', 'used'), ('used', 'linearly'), ('linearly', 'combine'), ('combine', 'features'), ('features', '('), ('(', '7'), ('7', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'learnable', 'parameter'), ('learnable', 'parameter', 'vector'), ('parameter', 'vector', 'θ'), ('vector', 'θ', 'corresponds'), ('θ', 'corresponds', 'weights'), ('corresponds', 'weights', 'w'), ('weights', 'w', 'used'), ('w', 'used', 'linearly'), ('used', 'linearly', 'combine'), ('linearly', 'combine', 'features'), ('combine', 'features', '('), ('features', '(', '7'), ('(', '7', ')'), ('7', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learnable', 'JJ'), ('parameter', 'NN'), ('vector', 'NN'), ('θ', 'NNP'), ('corresponds', 'VBZ'), ('weights', 'NNS'), ('w', 'NN'), ('used', 'VBN'), ('linearly', 'RB'), ('combine', 'JJ'), ('features', 'NNS'), ('(', '('), ('7', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT learnable/JJ parameter/NN vector/NN θ/NNP)
  corresponds/VBZ
  (NP weights/NNS w/NN)
  used/VBN
  linearly/RB
  (NP combine/JJ features/NNS)
  (/(
  7/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The learnable parameter vector θ', 'weights w', 'combine features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'correspond'), ('weights', 'weight'), ('w', 'w'), ('used', 'use'), ('linearly', 'linearli'), ('combine', 'combin'), ('features', 'featur'), ('(', '('), ('7', '7'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'correspond'), ('weights', 'weight'), ('w', 'w'), ('used', 'use'), ('linearly', 'linear'), ('combine', 'combin'), ('features', 'featur'), ('(', '('), ('7', '7'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learnable', 'learnable'), ('parameter', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'corresponds'), ('weights', 'weight'), ('w', 'w'), ('used', 'used'), ('linearly', 'linearly'), ('combine', 'combine'), ('features', 'feature'), ('(', '('), ('7', '7'), (')', ')'), ('.', '.')]



============================ Sentence 239 =============================

of the predictor should be tested on new, test, input- output pairs, e.g.-.-, new emails in the spam classification example. 


>> Tokens are: 
 ['predictor', 'tested', 'new', ',', 'test', ',', 'input-', 'output', 'pairs', ',', 'e.g.-.-', ',', 'new', 'emails', 'spam', 'classification', 'example', '.']

>> Bigrams are: 
 [('predictor', 'tested'), ('tested', 'new'), ('new', ','), (',', 'test'), ('test', ','), (',', 'input-'), ('input-', 'output'), ('output', 'pairs'), ('pairs', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'new'), ('new', 'emails'), ('emails', 'spam'), ('spam', 'classification'), ('classification', 'example'), ('example', '.')]

>> Trigrams are: 
 [('predictor', 'tested', 'new'), ('tested', 'new', ','), ('new', ',', 'test'), (',', 'test', ','), ('test', ',', 'input-'), (',', 'input-', 'output'), ('input-', 'output', 'pairs'), ('output', 'pairs', ','), ('pairs', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'new'), (',', 'new', 'emails'), ('new', 'emails', 'spam'), ('emails', 'spam', 'classification'), ('spam', 'classification', 'example'), ('classification', 'example', '.')]

>> POS Tags are: 
 [('predictor', 'NN'), ('tested', 'VBD'), ('new', 'JJ'), (',', ','), ('test', 'NN'), (',', ','), ('input-', 'JJ'), ('output', 'NN'), ('pairs', 'NNS'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('new', 'JJ'), ('emails', 'NNS'), ('spam', 'JJ'), ('classification', 'NN'), ('example', 'NN'), ('.', '.')]

 (S
  (NP predictor/NN)
  tested/VBD
  new/JJ
  ,/,
  (NP test/NN)
  ,/,
  (NP input-/JJ output/NN pairs/NNS)
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP new/JJ emails/NNS)
  (NP spam/JJ classification/NN example/NN)
  ./.) 


>> Noun Phrases are: 
 ['predictor', 'test', 'input- output pairs', 'new emails', 'spam classification example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('predictor', 'predictor'), ('tested', 'test'), ('new', 'new'), (',', ','), ('test', 'test'), (',', ','), ('input-', 'input-'), ('output', 'output'), ('pairs', 'pair'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('new', 'new'), ('emails', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('example', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('predictor', 'predictor'), ('tested', 'test'), ('new', 'new'), (',', ','), ('test', 'test'), (',', ','), ('input-', 'input-'), ('output', 'output'), ('pairs', 'pair'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('new', 'new'), ('emails', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('example', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('predictor', 'predictor'), ('tested', 'tested'), ('new', 'new'), (',', ','), ('test', 'test'), (',', ','), ('input-', 'input-'), ('output', 'output'), ('pairs', 'pair'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('new', 'new'), ('emails', 'email'), ('spam', 'spam'), ('classification', 'classification'), ('example', 'example'), ('.', '.')]



============================ Sentence 240 =============================

�  Example 2: Logistic regression requires to specify a suitable vector of features φ(x). 


>> Tokens are: 
 ['�', 'Example', '2', ':', 'Logistic', 'regression', 'requires', 'specify', 'suitable', 'vector', 'features', 'φ', '(', 'x', ')', '.']

>> Bigrams are: 
 [('�', 'Example'), ('Example', '2'), ('2', ':'), (':', 'Logistic'), ('Logistic', 'regression'), ('regression', 'requires'), ('requires', 'specify'), ('specify', 'suitable'), ('suitable', 'vector'), ('vector', 'features'), ('features', 'φ'), ('φ', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('�', 'Example', '2'), ('Example', '2', ':'), ('2', ':', 'Logistic'), (':', 'Logistic', 'regression'), ('Logistic', 'regression', 'requires'), ('regression', 'requires', 'specify'), ('requires', 'specify', 'suitable'), ('specify', 'suitable', 'vector'), ('suitable', 'vector', 'features'), ('vector', 'features', 'φ'), ('features', 'φ', '('), ('φ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('�', 'JJ'), ('Example', 'NNP'), ('2', 'CD'), (':', ':'), ('Logistic', 'JJ'), ('regression', 'NN'), ('requires', 'VBZ'), ('specify', 'JJ'), ('suitable', 'JJ'), ('vector', 'NN'), ('features', 'NNS'), ('φ', 'VBP'), ('(', '('), ('x', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP �/JJ Example/NNP)
  2/CD
  :/:
  (NP Logistic/JJ regression/NN)
  requires/VBZ
  (NP specify/JJ suitable/JJ vector/NN features/NNS)
  φ/VBP
  (/(
  (NP x/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['� Example', 'Logistic regression', 'specify suitable vector features', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('�', '�'), ('Example', 'exampl'), ('2', '2'), (':', ':'), ('Logistic', 'logist'), ('regression', 'regress'), ('requires', 'requir'), ('specify', 'specifi'), ('suitable', 'suitabl'), ('vector', 'vector'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('�', '�'), ('Example', 'exampl'), ('2', '2'), (':', ':'), ('Logistic', 'logist'), ('regression', 'regress'), ('requires', 'requir'), ('specify', 'specifi'), ('suitable', 'suitabl'), ('vector', 'vector'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('�', '�'), ('Example', 'Example'), ('2', '2'), (':', ':'), ('Logistic', 'Logistic'), ('regression', 'regression'), ('requires', 'requires'), ('specify', 'specify'), ('suitable', 'suitable'), ('vector', 'vector'), ('features', 'feature'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 241 =============================

As seen in the email spam classification example, this entails the availability of some domain knowledge to be able to ascertain which functions of the input x may be more relevant for the classification task at hand. 


>> Tokens are: 
 ['As', 'seen', 'email', 'spam', 'classification', 'example', ',', 'entails', 'availability', 'domain', 'knowledge', 'able', 'ascertain', 'functions', 'input', 'x', 'may', 'relevant', 'classification', 'task', 'hand', '.']

>> Bigrams are: 
 [('As', 'seen'), ('seen', 'email'), ('email', 'spam'), ('spam', 'classification'), ('classification', 'example'), ('example', ','), (',', 'entails'), ('entails', 'availability'), ('availability', 'domain'), ('domain', 'knowledge'), ('knowledge', 'able'), ('able', 'ascertain'), ('ascertain', 'functions'), ('functions', 'input'), ('input', 'x'), ('x', 'may'), ('may', 'relevant'), ('relevant', 'classification'), ('classification', 'task'), ('task', 'hand'), ('hand', '.')]

>> Trigrams are: 
 [('As', 'seen', 'email'), ('seen', 'email', 'spam'), ('email', 'spam', 'classification'), ('spam', 'classification', 'example'), ('classification', 'example', ','), ('example', ',', 'entails'), (',', 'entails', 'availability'), ('entails', 'availability', 'domain'), ('availability', 'domain', 'knowledge'), ('domain', 'knowledge', 'able'), ('knowledge', 'able', 'ascertain'), ('able', 'ascertain', 'functions'), ('ascertain', 'functions', 'input'), ('functions', 'input', 'x'), ('input', 'x', 'may'), ('x', 'may', 'relevant'), ('may', 'relevant', 'classification'), ('relevant', 'classification', 'task'), ('classification', 'task', 'hand'), ('task', 'hand', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('seen', 'VBN'), ('email', 'NN'), ('spam', 'NN'), ('classification', 'NN'), ('example', 'NN'), (',', ','), ('entails', 'VBZ'), ('availability', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('able', 'JJ'), ('ascertain', 'NN'), ('functions', 'NNS'), ('input', 'VBP'), ('x', 'NNS'), ('may', 'MD'), ('relevant', 'VB'), ('classification', 'NN'), ('task', 'NN'), ('hand', 'NN'), ('.', '.')]

 (S
  As/IN
  seen/VBN
  (NP email/NN spam/NN classification/NN example/NN)
  ,/,
  entails/VBZ
  (NP availability/NN domain/NN knowledge/NN)
  (NP able/JJ ascertain/NN functions/NNS)
  input/VBP
  (NP x/NNS)
  may/MD
  relevant/VB
  (NP classification/NN task/NN hand/NN)
  ./.) 


>> Noun Phrases are: 
 ['email spam classification example', 'availability domain knowledge', 'able ascertain functions', 'x', 'classification task hand']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('seen', 'seen'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('example', 'exampl'), (',', ','), ('entails', 'entail'), ('availability', 'avail'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('able', 'abl'), ('ascertain', 'ascertain'), ('functions', 'function'), ('input', 'input'), ('x', 'x'), ('may', 'may'), ('relevant', 'relev'), ('classification', 'classif'), ('task', 'task'), ('hand', 'hand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('seen', 'seen'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classif'), ('example', 'exampl'), (',', ','), ('entails', 'entail'), ('availability', 'avail'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('able', 'abl'), ('ascertain', 'ascertain'), ('functions', 'function'), ('input', 'input'), ('x', 'x'), ('may', 'may'), ('relevant', 'relev'), ('classification', 'classif'), ('task', 'task'), ('hand', 'hand'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('seen', 'seen'), ('email', 'email'), ('spam', 'spam'), ('classification', 'classification'), ('example', 'example'), (',', ','), ('entails', 'entail'), ('availability', 'availability'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('able', 'able'), ('ascertain', 'ascertain'), ('functions', 'function'), ('input', 'input'), ('x', 'x'), ('may', 'may'), ('relevant', 'relevant'), ('classification', 'classification'), ('task', 'task'), ('hand', 'hand'), ('.', '.')]



============================ Sentence 242 =============================

As discussed in Sec. 


>> Tokens are: 
 ['As', 'discussed', 'Sec', '.']

>> Bigrams are: 
 [('As', 'discussed'), ('discussed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('As', 'discussed', 'Sec'), ('discussed', 'Sec', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('discussed', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S As/IN discussed/VBN (NP Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('discussed', 'discussed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 243 =============================

I, this knowledge may not be available due to, e.g.-.-, cost or time constraints. 


>> Tokens are: 
 ['I', ',', 'knowledge', 'may', 'available', 'due', ',', 'e.g.-.-', ',', 'cost', 'time', 'constraints', '.']

>> Bigrams are: 
 [('I', ','), (',', 'knowledge'), ('knowledge', 'may'), ('may', 'available'), ('available', 'due'), ('due', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'cost'), ('cost', 'time'), ('time', 'constraints'), ('constraints', '.')]

>> Trigrams are: 
 [('I', ',', 'knowledge'), (',', 'knowledge', 'may'), ('knowledge', 'may', 'available'), ('may', 'available', 'due'), ('available', 'due', ','), ('due', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'cost'), (',', 'cost', 'time'), ('cost', 'time', 'constraints'), ('time', 'constraints', '.')]

>> POS Tags are: 
 [('I', 'PRP'), (',', ','), ('knowledge', 'NN'), ('may', 'MD'), ('available', 'JJ'), ('due', 'JJ'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('cost', 'NN'), ('time', 'NN'), ('constraints', 'NNS'), ('.', '.')]

 (S
  I/PRP
  ,/,
  (NP knowledge/NN)
  may/MD
  available/JJ
  due/JJ
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP cost/NN time/NN constraints/NNS)
  ./.) 


>> Noun Phrases are: 
 ['knowledge', 'cost time constraints']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), (',', ','), ('knowledge', 'knowledg'), ('may', 'may'), ('available', 'avail'), ('due', 'due'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('cost', 'cost'), ('time', 'time'), ('constraints', 'constraint'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), (',', ','), ('knowledge', 'knowledg'), ('may', 'may'), ('available', 'avail'), ('due', 'due'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('cost', 'cost'), ('time', 'time'), ('constraints', 'constraint'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), (',', ','), ('knowledge', 'knowledge'), ('may', 'may'), ('available', 'available'), ('due', 'due'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('cost', 'cost'), ('time', 'time'), ('constraints', 'constraint'), ('.', '.')]



============================ Sentence 244 =============================

Multi-layer neural networks provide an alternative model choice at Step 1 that obviates the need for hand-crafted features. 


>> Tokens are: 
 ['Multi-layer', 'neural', 'networks', 'provide', 'alternative', 'model', 'choice', 'Step', '1', 'obviates', 'need', 'hand-crafted', 'features', '.']

>> Bigrams are: 
 [('Multi-layer', 'neural'), ('neural', 'networks'), ('networks', 'provide'), ('provide', 'alternative'), ('alternative', 'model'), ('model', 'choice'), ('choice', 'Step'), ('Step', '1'), ('1', 'obviates'), ('obviates', 'need'), ('need', 'hand-crafted'), ('hand-crafted', 'features'), ('features', '.')]

>> Trigrams are: 
 [('Multi-layer', 'neural', 'networks'), ('neural', 'networks', 'provide'), ('networks', 'provide', 'alternative'), ('provide', 'alternative', 'model'), ('alternative', 'model', 'choice'), ('model', 'choice', 'Step'), ('choice', 'Step', '1'), ('Step', '1', 'obviates'), ('1', 'obviates', 'need'), ('obviates', 'need', 'hand-crafted'), ('need', 'hand-crafted', 'features'), ('hand-crafted', 'features', '.')]

>> POS Tags are: 
 [('Multi-layer', 'NNP'), ('neural', 'JJ'), ('networks', 'NNS'), ('provide', 'VBP'), ('alternative', 'JJ'), ('model', 'NN'), ('choice', 'NN'), ('Step', 'NNP'), ('1', 'CD'), ('obviates', 'NNS'), ('need', 'VBP'), ('hand-crafted', 'JJ'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP Multi-layer/NNP)
  (NP neural/JJ networks/NNS)
  provide/VBP
  (NP alternative/JJ model/NN choice/NN Step/NNP)
  1/CD
  (NP obviates/NNS)
  need/VBP
  (NP hand-crafted/JJ features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Multi-layer', 'neural networks', 'alternative model choice Step', 'obviates', 'hand-crafted features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('provide', 'provid'), ('alternative', 'altern'), ('model', 'model'), ('choice', 'choic'), ('Step', 'step'), ('1', '1'), ('obviates', 'obviat'), ('need', 'need'), ('hand-crafted', 'hand-craft'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('provide', 'provid'), ('alternative', 'altern'), ('model', 'model'), ('choice', 'choic'), ('Step', 'step'), ('1', '1'), ('obviates', 'obviat'), ('need', 'need'), ('hand-crafted', 'hand-craft'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('Multi-layer', 'Multi-layer'), ('neural', 'neural'), ('networks', 'network'), ('provide', 'provide'), ('alternative', 'alternative'), ('model', 'model'), ('choice', 'choice'), ('Step', 'Step'), ('1', '1'), ('obviates', 'obviates'), ('need', 'need'), ('hand-crafted', 'hand-crafted'), ('features', 'feature'), ('.', '.')]



============================ Sentence 245 =============================

The model is illustrated in Fig. 


>> Tokens are: 
 ['The', 'model', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('The', 'model'), ('model', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'model', 'illustrated'), ('model', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('model', 'NN'), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S (NP The/DT model/NN) illustrated/VBD (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['The model', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('model', 'model'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('model', 'model'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('model', 'model'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 246 =============================

8. 


>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

 (S 8/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]



============================ Sentence 247 =============================

Unlike linear regression, in a multi-layer neural network, the feature vector φ(x) used by the last layer to compute the logit, or LLR, that determines the predictive probability (7) is not fixed a priori. 


>> Tokens are: 
 ['Unlike', 'linear', 'regression', ',', 'multi-layer', 'neural', 'network', ',', 'feature', 'vector', 'φ', '(', 'x', ')', 'used', 'last', 'layer', 'compute', 'logit', ',', 'LLR', ',', 'determines', 'predictive', 'probability', '(', '7', ')', 'fixed', 'priori', '.']

>> Bigrams are: 
 [('Unlike', 'linear'), ('linear', 'regression'), ('regression', ','), (',', 'multi-layer'), ('multi-layer', 'neural'), ('neural', 'network'), ('network', ','), (',', 'feature'), ('feature', 'vector'), ('vector', 'φ'), ('φ', '('), ('(', 'x'), ('x', ')'), (')', 'used'), ('used', 'last'), ('last', 'layer'), ('layer', 'compute'), ('compute', 'logit'), ('logit', ','), (',', 'LLR'), ('LLR', ','), (',', 'determines'), ('determines', 'predictive'), ('predictive', 'probability'), ('probability', '('), ('(', '7'), ('7', ')'), (')', 'fixed'), ('fixed', 'priori'), ('priori', '.')]

>> Trigrams are: 
 [('Unlike', 'linear', 'regression'), ('linear', 'regression', ','), ('regression', ',', 'multi-layer'), (',', 'multi-layer', 'neural'), ('multi-layer', 'neural', 'network'), ('neural', 'network', ','), ('network', ',', 'feature'), (',', 'feature', 'vector'), ('feature', 'vector', 'φ'), ('vector', 'φ', '('), ('φ', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'used'), (')', 'used', 'last'), ('used', 'last', 'layer'), ('last', 'layer', 'compute'), ('layer', 'compute', 'logit'), ('compute', 'logit', ','), ('logit', ',', 'LLR'), (',', 'LLR', ','), ('LLR', ',', 'determines'), (',', 'determines', 'predictive'), ('determines', 'predictive', 'probability'), ('predictive', 'probability', '('), ('probability', '(', '7'), ('(', '7', ')'), ('7', ')', 'fixed'), (')', 'fixed', 'priori'), ('fixed', 'priori', '.')]

>> POS Tags are: 
 [('Unlike', 'IN'), ('linear', 'JJ'), ('regression', 'NN'), (',', ','), ('multi-layer', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), (',', ','), ('feature', 'NN'), ('vector', 'NN'), ('φ', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('used', 'VBD'), ('last', 'JJ'), ('layer', 'JJ'), ('compute', 'NN'), ('logit', 'NN'), (',', ','), ('LLR', 'NNP'), (',', ','), ('determines', 'VBZ'), ('predictive', 'JJ'), ('probability', 'NN'), ('(', '('), ('7', 'CD'), (')', ')'), ('fixed', 'VBN'), ('priori', 'NN'), ('.', '.')]

 (S
  Unlike/IN
  (NP linear/JJ regression/NN)
  ,/,
  (NP multi-layer/JJ neural/JJ network/NN)
  ,/,
  (NP feature/NN vector/NN φ/NNP)
  (/(
  (NP x/NNP)
  )/)
  used/VBD
  (NP last/JJ layer/JJ compute/NN logit/NN)
  ,/,
  (NP LLR/NNP)
  ,/,
  determines/VBZ
  (NP predictive/JJ probability/NN)
  (/(
  7/CD
  )/)
  fixed/VBN
  (NP priori/NN)
  ./.) 


>> Noun Phrases are: 
 ['linear regression', 'multi-layer neural network', 'feature vector φ', 'x', 'last layer compute logit', 'LLR', 'predictive probability', 'priori']

>> Named Entities are: 
 [('ORGANIZATION', 'LLR')] 

>> Stemming using Porter Stemmer: 
 [('Unlike', 'unlik'), ('linear', 'linear'), ('regression', 'regress'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('network', 'network'), (',', ','), ('feature', 'featur'), ('vector', 'vector'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('used', 'use'), ('last', 'last'), ('layer', 'layer'), ('compute', 'comput'), ('logit', 'logit'), (',', ','), ('LLR', 'llr'), (',', ','), ('determines', 'determin'), ('predictive', 'predict'), ('probability', 'probabl'), ('(', '('), ('7', '7'), (')', ')'), ('fixed', 'fix'), ('priori', 'priori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlike', 'unlik'), ('linear', 'linear'), ('regression', 'regress'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('network', 'network'), (',', ','), ('feature', 'featur'), ('vector', 'vector'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('used', 'use'), ('last', 'last'), ('layer', 'layer'), ('compute', 'comput'), ('logit', 'logit'), (',', ','), ('LLR', 'llr'), (',', ','), ('determines', 'determin'), ('predictive', 'predict'), ('probability', 'probabl'), ('(', '('), ('7', '7'), (')', ')'), ('fixed', 'fix'), ('priori', 'priori'), ('.', '.')]

>> Lemmatization: 
 [('Unlike', 'Unlike'), ('linear', 'linear'), ('regression', 'regression'), (',', ','), ('multi-layer', 'multi-layer'), ('neural', 'neural'), ('network', 'network'), (',', ','), ('feature', 'feature'), ('vector', 'vector'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('used', 'used'), ('last', 'last'), ('layer', 'layer'), ('compute', 'compute'), ('logit', 'logit'), (',', ','), ('LLR', 'LLR'), (',', ','), ('determines', 'determines'), ('predictive', 'predictive'), ('probability', 'probability'), ('(', '('), ('7', '7'), (')', ')'), ('fixed', 'fixed'), ('priori', 'priori'), ('.', '.')]



============================ Sentence 248 =============================

Rather, the feature vector is computed by the previous layers. 


>> Tokens are: 
 ['Rather', ',', 'feature', 'vector', 'computed', 'previous', 'layers', '.']

>> Bigrams are: 
 [('Rather', ','), (',', 'feature'), ('feature', 'vector'), ('vector', 'computed'), ('computed', 'previous'), ('previous', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('Rather', ',', 'feature'), (',', 'feature', 'vector'), ('feature', 'vector', 'computed'), ('vector', 'computed', 'previous'), ('computed', 'previous', 'layers'), ('previous', 'layers', '.')]

>> POS Tags are: 
 [('Rather', 'RB'), (',', ','), ('feature', 'NN'), ('vector', 'NN'), ('computed', 'VBD'), ('previous', 'JJ'), ('layers', 'NNS'), ('.', '.')]

 (S
  Rather/RB
  ,/,
  (NP feature/NN vector/NN)
  computed/VBD
  (NP previous/JJ layers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['feature vector', 'previous layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rather', 'rather'), (',', ','), ('feature', 'featur'), ('vector', 'vector'), ('computed', 'comput'), ('previous', 'previou'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rather', 'rather'), (',', ','), ('feature', 'featur'), ('vector', 'vector'), ('computed', 'comput'), ('previous', 'previous'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('Rather', 'Rather'), (',', ','), ('feature', 'feature'), ('vector', 'vector'), ('computed', 'computed'), ('previous', 'previous'), ('layers', 'layer'), ('.', '.')]



============================ Sentence 249 =============================

To this end, each neuron, represented as a circle in Fig. 


>> Tokens are: 
 ['To', 'end', ',', 'neuron', ',', 'represented', 'circle', 'Fig', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'neuron'), ('neuron', ','), (',', 'represented'), ('represented', 'circle'), ('circle', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'neuron'), (',', 'neuron', ','), ('neuron', ',', 'represented'), (',', 'represented', 'circle'), ('represented', 'circle', 'Fig'), ('circle', 'Fig', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('neuron', 'FW'), (',', ','), ('represented', 'VBD'), ('circle', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  neuron/FW
  ,/,
  represented/VBD
  (NP circle/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['circle Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('neuron', 'neuron'), (',', ','), ('represented', 'repres'), ('circle', 'circl'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('neuron', 'neuron'), (',', ','), ('represented', 'repres'), ('circle', 'circl'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('neuron', 'neuron'), (',', ','), ('represented', 'represented'), ('circle', 'circle'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 250 =============================

8, computes a fixed non-linear function, e.g.-.-, sigmoid, of a linear combination of the values obtained from the previous layer. 


>> Tokens are: 
 ['8', ',', 'computes', 'fixed', 'non-linear', 'function', ',', 'e.g.-.-', ',', 'sigmoid', ',', 'linear', 'combination', 'values', 'obtained', 'previous', 'layer', '.']

>> Bigrams are: 
 [('8', ','), (',', 'computes'), ('computes', 'fixed'), ('fixed', 'non-linear'), ('non-linear', 'function'), ('function', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'sigmoid'), ('sigmoid', ','), (',', 'linear'), ('linear', 'combination'), ('combination', 'values'), ('values', 'obtained'), ('obtained', 'previous'), ('previous', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('8', ',', 'computes'), (',', 'computes', 'fixed'), ('computes', 'fixed', 'non-linear'), ('fixed', 'non-linear', 'function'), ('non-linear', 'function', ','), ('function', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'sigmoid'), (',', 'sigmoid', ','), ('sigmoid', ',', 'linear'), (',', 'linear', 'combination'), ('linear', 'combination', 'values'), ('combination', 'values', 'obtained'), ('values', 'obtained', 'previous'), ('obtained', 'previous', 'layer'), ('previous', 'layer', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('computes', 'NNS'), ('fixed', 'VBD'), ('non-linear', 'JJ'), ('function', 'NN'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('sigmoid', 'JJ'), (',', ','), ('linear', 'JJ'), ('combination', 'NN'), ('values', 'NNS'), ('obtained', 'VBD'), ('previous', 'JJ'), ('layer', 'NN'), ('.', '.')]

 (S
  8/CD
  ,/,
  (NP computes/NNS)
  fixed/VBD
  (NP non-linear/JJ function/NN)
  ,/,
  e.g.-.-/JJ
  ,/,
  sigmoid/JJ
  ,/,
  (NP linear/JJ combination/NN values/NNS)
  obtained/VBD
  (NP previous/JJ layer/NN)
  ./.) 


>> Noun Phrases are: 
 ['computes', 'non-linear function', 'linear combination values', 'previous layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('computes', 'comput'), ('fixed', 'fix'), ('non-linear', 'non-linear'), ('function', 'function'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('sigmoid', 'sigmoid'), (',', ','), ('linear', 'linear'), ('combination', 'combin'), ('values', 'valu'), ('obtained', 'obtain'), ('previous', 'previou'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('computes', 'comput'), ('fixed', 'fix'), ('non-linear', 'non-linear'), ('function', 'function'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('sigmoid', 'sigmoid'), (',', ','), ('linear', 'linear'), ('combination', 'combin'), ('values', 'valu'), ('obtained', 'obtain'), ('previous', 'previous'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('computes', 'computes'), ('fixed', 'fixed'), ('non-linear', 'non-linear'), ('function', 'function'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('sigmoid', 'sigmoid'), (',', ','), ('linear', 'linear'), ('combination', 'combination'), ('values', 'value'), ('obtained', 'obtained'), ('previous', 'previous'), ('layer', 'layer'), ('.', '.')]



============================ Sentence 251 =============================

The weights of these linear combinations are part of the learnable parameters θ, along with the weights of the last layer. 


>> Tokens are: 
 ['The', 'weights', 'linear', 'combinations', 'part', 'learnable', 'parameters', 'θ', ',', 'along', 'weights', 'last', 'layer', '.']

>> Bigrams are: 
 [('The', 'weights'), ('weights', 'linear'), ('linear', 'combinations'), ('combinations', 'part'), ('part', 'learnable'), ('learnable', 'parameters'), ('parameters', 'θ'), ('θ', ','), (',', 'along'), ('along', 'weights'), ('weights', 'last'), ('last', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('The', 'weights', 'linear'), ('weights', 'linear', 'combinations'), ('linear', 'combinations', 'part'), ('combinations', 'part', 'learnable'), ('part', 'learnable', 'parameters'), ('learnable', 'parameters', 'θ'), ('parameters', 'θ', ','), ('θ', ',', 'along'), (',', 'along', 'weights'), ('along', 'weights', 'last'), ('weights', 'last', 'layer'), ('last', 'layer', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('weights', 'NNS'), ('linear', 'VBP'), ('combinations', 'NNS'), ('part', 'NN'), ('learnable', 'JJ'), ('parameters', 'NNS'), ('θ', 'VBP'), (',', ','), ('along', 'IN'), ('weights', 'NNS'), ('last', 'JJ'), ('layer', 'NN'), ('.', '.')]

 (S
  (NP The/DT weights/NNS)
  linear/VBP
  (NP combinations/NNS part/NN)
  (NP learnable/JJ parameters/NNS)
  θ/VBP
  ,/,
  along/IN
  (NP weights/NNS)
  (NP last/JJ layer/NN)
  ./.) 


>> Noun Phrases are: 
 ['The weights', 'combinations part', 'learnable parameters', 'weights', 'last layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('weights', 'weight'), ('linear', 'linear'), ('combinations', 'combin'), ('part', 'part'), ('learnable', 'learnabl'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('along', 'along'), ('weights', 'weight'), ('last', 'last'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('weights', 'weight'), ('linear', 'linear'), ('combinations', 'combin'), ('part', 'part'), ('learnable', 'learnabl'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('along', 'along'), ('weights', 'weight'), ('last', 'last'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('weights', 'weight'), ('linear', 'linear'), ('combinations', 'combination'), ('part', 'part'), ('learnable', 'learnable'), ('parameters', 'parameter'), ('θ', 'θ'), (',', ','), ('along', 'along'), ('weights', 'weight'), ('last', 'last'), ('layer', 'layer'), ('.', '.')]



============================ Sentence 252 =============================

By allowing the weights at all layers of the model to be trained simultaneously, multi-layer neural networks enable the joint learning of the last-layer linear classifier and of the features φ(x) the classifier operates on. 


>> Tokens are: 
 ['By', 'allowing', 'weights', 'layers', 'model', 'trained', 'simultaneously', ',', 'multi-layer', 'neural', 'networks', 'enable', 'joint', 'learning', 'last-layer', 'linear', 'classifier', 'features', 'φ', '(', 'x', ')', 'classifier', 'operates', '.']

>> Bigrams are: 
 [('By', 'allowing'), ('allowing', 'weights'), ('weights', 'layers'), ('layers', 'model'), ('model', 'trained'), ('trained', 'simultaneously'), ('simultaneously', ','), (',', 'multi-layer'), ('multi-layer', 'neural'), ('neural', 'networks'), ('networks', 'enable'), ('enable', 'joint'), ('joint', 'learning'), ('learning', 'last-layer'), ('last-layer', 'linear'), ('linear', 'classifier'), ('classifier', 'features'), ('features', 'φ'), ('φ', '('), ('(', 'x'), ('x', ')'), (')', 'classifier'), ('classifier', 'operates'), ('operates', '.')]

>> Trigrams are: 
 [('By', 'allowing', 'weights'), ('allowing', 'weights', 'layers'), ('weights', 'layers', 'model'), ('layers', 'model', 'trained'), ('model', 'trained', 'simultaneously'), ('trained', 'simultaneously', ','), ('simultaneously', ',', 'multi-layer'), (',', 'multi-layer', 'neural'), ('multi-layer', 'neural', 'networks'), ('neural', 'networks', 'enable'), ('networks', 'enable', 'joint'), ('enable', 'joint', 'learning'), ('joint', 'learning', 'last-layer'), ('learning', 'last-layer', 'linear'), ('last-layer', 'linear', 'classifier'), ('linear', 'classifier', 'features'), ('classifier', 'features', 'φ'), ('features', 'φ', '('), ('φ', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'classifier'), (')', 'classifier', 'operates'), ('classifier', 'operates', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('allowing', 'VBG'), ('weights', 'NNS'), ('layers', 'NNS'), ('model', 'VBP'), ('trained', 'VBN'), ('simultaneously', 'RB'), (',', ','), ('multi-layer', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('enable', 'JJ'), ('joint', 'JJ'), ('learning', 'VBG'), ('last-layer', 'JJ'), ('linear', 'JJ'), ('classifier', 'NN'), ('features', 'NNS'), ('φ', 'VBP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('classifier', 'JJR'), ('operates', 'VBZ'), ('.', '.')]

 (S
  By/IN
  allowing/VBG
  (NP weights/NNS layers/NNS)
  model/VBP
  trained/VBN
  simultaneously/RB
  ,/,
  (NP multi-layer/JJ neural/JJ networks/NNS)
  enable/JJ
  joint/JJ
  learning/VBG
  (NP last-layer/JJ linear/JJ classifier/NN features/NNS)
  φ/VBP
  (/(
  (NP x/NNP)
  )/)
  classifier/JJR
  operates/VBZ
  ./.) 


>> Noun Phrases are: 
 ['weights layers', 'multi-layer neural networks', 'last-layer linear classifier features', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('allowing', 'allow'), ('weights', 'weight'), ('layers', 'layer'), ('model', 'model'), ('trained', 'train'), ('simultaneously', 'simultan'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('enable', 'enabl'), ('joint', 'joint'), ('learning', 'learn'), ('last-layer', 'last-lay'), ('linear', 'linear'), ('classifier', 'classifi'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('classifier', 'classifi'), ('operates', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('allowing', 'allow'), ('weights', 'weight'), ('layers', 'layer'), ('model', 'model'), ('trained', 'train'), ('simultaneously', 'simultan'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('enable', 'enabl'), ('joint', 'joint'), ('learning', 'learn'), ('last-layer', 'last-lay'), ('linear', 'linear'), ('classifier', 'classifi'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('classifier', 'classifi'), ('operates', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('allowing', 'allowing'), ('weights', 'weight'), ('layers', 'layer'), ('model', 'model'), ('trained', 'trained'), ('simultaneously', 'simultaneously'), (',', ','), ('multi-layer', 'multi-layer'), ('neural', 'neural'), ('networks', 'network'), ('enable', 'enable'), ('joint', 'joint'), ('learning', 'learning'), ('last-layer', 'last-layer'), ('linear', 'linear'), ('classifier', 'classifier'), ('features', 'feature'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('classifier', 'classifier'), ('operates', 'operates'), ('.', '.')]



============================ Sentence 253 =============================

As a notable example, deep neural networks are characterized by a large number of intermediate layers that tend to learn increasingly abstract features of the input [7]. 


>> Tokens are: 
 ['As', 'notable', 'example', ',', 'deep', 'neural', 'networks', 'characterized', 'large', 'number', 'intermediate', 'layers', 'tend', 'learn', 'increasingly', 'abstract', 'features', 'input', '[', '7', ']', '.']

>> Bigrams are: 
 [('As', 'notable'), ('notable', 'example'), ('example', ','), (',', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'characterized'), ('characterized', 'large'), ('large', 'number'), ('number', 'intermediate'), ('intermediate', 'layers'), ('layers', 'tend'), ('tend', 'learn'), ('learn', 'increasingly'), ('increasingly', 'abstract'), ('abstract', 'features'), ('features', 'input'), ('input', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('As', 'notable', 'example'), ('notable', 'example', ','), ('example', ',', 'deep'), (',', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'characterized'), ('networks', 'characterized', 'large'), ('characterized', 'large', 'number'), ('large', 'number', 'intermediate'), ('number', 'intermediate', 'layers'), ('intermediate', 'layers', 'tend'), ('layers', 'tend', 'learn'), ('tend', 'learn', 'increasingly'), ('learn', 'increasingly', 'abstract'), ('increasingly', 'abstract', 'features'), ('abstract', 'features', 'input'), ('features', 'input', '['), ('input', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('notable', 'JJ'), ('example', 'NN'), (',', ','), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('characterized', 'VBN'), ('large', 'JJ'), ('number', 'NN'), ('intermediate', 'JJ'), ('layers', 'NNS'), ('tend', 'VBP'), ('learn', 'JJ'), ('increasingly', 'RB'), ('abstract', 'JJ'), ('features', 'NNS'), ('input', 'VBP'), ('[', 'RB'), ('7', 'CD'), (']', 'NNS'), ('.', '.')]

 (S
  As/IN
  (NP notable/JJ example/NN)
  ,/,
  (NP deep/JJ neural/JJ networks/NNS)
  characterized/VBN
  (NP large/JJ number/NN)
  (NP intermediate/JJ layers/NNS)
  tend/VBP
  learn/JJ
  increasingly/RB
  (NP abstract/JJ features/NNS)
  input/VBP
  [/RB
  7/CD
  (NP ]/NNS)
  ./.) 


>> Noun Phrases are: 
 ['notable example', 'deep neural networks', 'large number', 'intermediate layers', 'abstract features', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('notable', 'notabl'), ('example', 'exampl'), (',', ','), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('characterized', 'character'), ('large', 'larg'), ('number', 'number'), ('intermediate', 'intermedi'), ('layers', 'layer'), ('tend', 'tend'), ('learn', 'learn'), ('increasingly', 'increasingli'), ('abstract', 'abstract'), ('features', 'featur'), ('input', 'input'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('notable', 'notabl'), ('example', 'exampl'), (',', ','), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('characterized', 'character'), ('large', 'larg'), ('number', 'number'), ('intermediate', 'intermedi'), ('layers', 'layer'), ('tend', 'tend'), ('learn', 'learn'), ('increasingly', 'increas'), ('abstract', 'abstract'), ('features', 'featur'), ('input', 'input'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('notable', 'notable'), ('example', 'example'), (',', ','), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('characterized', 'characterized'), ('large', 'large'), ('number', 'number'), ('intermediate', 'intermediate'), ('layers', 'layer'), ('tend', 'tend'), ('learn', 'learn'), ('increasingly', 'increasingly'), ('abstract', 'abstract'), ('features', 'feature'), ('input', 'input'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



============================ Sentence 254 =============================

�  In the rest of this section, we first provide some technical details about Step 2, i.e.-, learning, and then we return to Step 1, i.e.-, model selection. 


>> Tokens are: 
 ['�', 'In', 'rest', 'section', ',', 'first', 'provide', 'technical', 'details', 'Step', '2', ',', 'i.e.-', ',', 'learning', ',', 'return', 'Step', '1', ',', 'i.e.-', ',', 'model', 'selection', '.']

>> Bigrams are: 
 [('�', 'In'), ('In', 'rest'), ('rest', 'section'), ('section', ','), (',', 'first'), ('first', 'provide'), ('provide', 'technical'), ('technical', 'details'), ('details', 'Step'), ('Step', '2'), ('2', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'learning'), ('learning', ','), (',', 'return'), ('return', 'Step'), ('Step', '1'), ('1', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'model'), ('model', 'selection'), ('selection', '.')]

>> Trigrams are: 
 [('�', 'In', 'rest'), ('In', 'rest', 'section'), ('rest', 'section', ','), ('section', ',', 'first'), (',', 'first', 'provide'), ('first', 'provide', 'technical'), ('provide', 'technical', 'details'), ('technical', 'details', 'Step'), ('details', 'Step', '2'), ('Step', '2', ','), ('2', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'learning'), (',', 'learning', ','), ('learning', ',', 'return'), (',', 'return', 'Step'), ('return', 'Step', '1'), ('Step', '1', ','), ('1', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'model'), (',', 'model', 'selection'), ('model', 'selection', '.')]

>> POS Tags are: 
 [('�', 'NN'), ('In', 'IN'), ('rest', 'NN'), ('section', 'NN'), (',', ','), ('first', 'JJ'), ('provide', 'VBP'), ('technical', 'JJ'), ('details', 'NNS'), ('Step', 'NNP'), ('2', 'CD'), (',', ','), ('i.e.-', 'NN'), (',', ','), ('learning', 'NN'), (',', ','), ('return', 'VBP'), ('Step', 'NNP'), ('1', 'CD'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('model', 'JJ'), ('selection', 'NN'), ('.', '.')]

 (S
  (NP �/NN)
  In/IN
  (NP rest/NN section/NN)
  ,/,
  first/JJ
  provide/VBP
  (NP technical/JJ details/NNS Step/NNP)
  2/CD
  ,/,
  (NP i.e.-/NN)
  ,/,
  (NP learning/NN)
  ,/,
  return/VBP
  (NP Step/NNP)
  1/CD
  ,/,
  i.e.-/JJ
  ,/,
  (NP model/JJ selection/NN)
  ./.) 


>> Noun Phrases are: 
 ['�', 'rest section', 'technical details Step', 'i.e.-', 'learning', 'Step', 'model selection']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('�', '�'), ('In', 'in'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('first', 'first'), ('provide', 'provid'), ('technical', 'technic'), ('details', 'detail'), ('Step', 'step'), ('2', '2'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('learning', 'learn'), (',', ','), ('return', 'return'), ('Step', 'step'), ('1', '1'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('�', '�'), ('In', 'in'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('first', 'first'), ('provide', 'provid'), ('technical', 'technic'), ('details', 'detail'), ('Step', 'step'), ('2', '2'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('learning', 'learn'), (',', ','), ('return', 'return'), ('Step', 'step'), ('1', '1'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Lemmatization: 
 [('�', '�'), ('In', 'In'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('first', 'first'), ('provide', 'provide'), ('technical', 'technical'), ('details', 'detail'), ('Step', 'Step'), ('2', '2'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('learning', 'learning'), (',', ','), ('return', 'return'), ('Step', 'Step'), ('1', '1'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('model', 'model'), ('selection', 'selection'), ('.', '.')]



============================ Sentence 255 =============================

As it will be seen, this order is dictated by the fact that model selection requires some understanding of the learning process. 


>> Tokens are: 
 ['As', 'seen', ',', 'order', 'dictated', 'fact', 'model', 'selection', 'requires', 'understanding', 'learning', 'process', '.']

>> Bigrams are: 
 [('As', 'seen'), ('seen', ','), (',', 'order'), ('order', 'dictated'), ('dictated', 'fact'), ('fact', 'model'), ('model', 'selection'), ('selection', 'requires'), ('requires', 'understanding'), ('understanding', 'learning'), ('learning', 'process'), ('process', '.')]

>> Trigrams are: 
 [('As', 'seen', ','), ('seen', ',', 'order'), (',', 'order', 'dictated'), ('order', 'dictated', 'fact'), ('dictated', 'fact', 'model'), ('fact', 'model', 'selection'), ('model', 'selection', 'requires'), ('selection', 'requires', 'understanding'), ('requires', 'understanding', 'learning'), ('understanding', 'learning', 'process'), ('learning', 'process', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('seen', 'VBN'), (',', ','), ('order', 'NN'), ('dictated', 'VBD'), ('fact', 'NN'), ('model', 'NN'), ('selection', 'NN'), ('requires', 'VBZ'), ('understanding', 'VBG'), ('learning', 'VBG'), ('process', 'NN'), ('.', '.')]

 (S
  As/IN
  seen/VBN
  ,/,
  (NP order/NN)
  dictated/VBD
  (NP fact/NN model/NN selection/NN)
  requires/VBZ
  understanding/VBG
  learning/VBG
  (NP process/NN)
  ./.) 


>> Noun Phrases are: 
 ['order', 'fact model selection', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('seen', 'seen'), (',', ','), ('order', 'order'), ('dictated', 'dictat'), ('fact', 'fact'), ('model', 'model'), ('selection', 'select'), ('requires', 'requir'), ('understanding', 'understand'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('seen', 'seen'), (',', ','), ('order', 'order'), ('dictated', 'dictat'), ('fact', 'fact'), ('model', 'model'), ('selection', 'select'), ('requires', 'requir'), ('understanding', 'understand'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('seen', 'seen'), (',', ','), ('order', 'order'), ('dictated', 'dictated'), ('fact', 'fact'), ('model', 'model'), ('selection', 'selection'), ('requires', 'requires'), ('understanding', 'understanding'), ('learning', 'learning'), ('process', 'process'), ('.', '.')]



============================ Sentence 256 =============================

8    Fig. 


>> Tokens are: 
 ['8', 'Fig', '.']

>> Bigrams are: 
 [('8', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('8', 'Fig', '.')]

>> POS Tags are: 
 [('8', 'CD'), ('Fig', 'NNP'), ('.', '.')]

 (S 8/CD (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 257 =============================

8. 


>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

 (S 8/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]



============================ Sentence 258 =============================

An illustration of the hypothesis class p(t|x,w) assumed by multi-layer neural networks. 


>> Tokens are: 
 ['An', 'illustration', 'hypothesis', 'class', 'p', '(', 't|x', ',', 'w', ')', 'assumed', 'multi-layer', 'neural', 'networks', '.']

>> Bigrams are: 
 [('An', 'illustration'), ('illustration', 'hypothesis'), ('hypothesis', 'class'), ('class', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'w'), ('w', ')'), (')', 'assumed'), ('assumed', 'multi-layer'), ('multi-layer', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('An', 'illustration', 'hypothesis'), ('illustration', 'hypothesis', 'class'), ('hypothesis', 'class', 'p'), ('class', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'w'), (',', 'w', ')'), ('w', ')', 'assumed'), (')', 'assumed', 'multi-layer'), ('assumed', 'multi-layer', 'neural'), ('multi-layer', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('illustration', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('w', 'NN'), (')', ')'), ('assumed', 'VBD'), ('multi-layer', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP An/DT illustration/NN hypothesis/NN class/NN p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP w/NN)
  )/)
  assumed/VBD
  (NP multi-layer/JJ neural/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['An illustration hypothesis class p', 't|x', 'w', 'multi-layer neural networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('illustration', 'illustr'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assum'), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('illustration', 'illustr'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assum'), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('illustration', 'illustration'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('assumed', 'assumed'), ('multi-layer', 'multi-layer'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]



============================ Sentence 259 =============================

The learnable parameter vector θ here corresponds to the weights wL used at the last layer to linearly combine the features φ(x) and the weight matrices W 1, ...,WL−1  used at the preceding layers in order to compute the feature vector. 


>> Tokens are: 
 ['The', 'learnable', 'parameter', 'vector', 'θ', 'corresponds', 'weights', 'wL', 'used', 'last', 'layer', 'linearly', 'combine', 'features', 'φ', '(', 'x', ')', 'weight', 'matrices', 'W', '1', ',', '...', ',', 'WL−1', 'used', 'preceding', 'layers', 'order', 'compute', 'feature', 'vector', '.']

>> Bigrams are: 
 [('The', 'learnable'), ('learnable', 'parameter'), ('parameter', 'vector'), ('vector', 'θ'), ('θ', 'corresponds'), ('corresponds', 'weights'), ('weights', 'wL'), ('wL', 'used'), ('used', 'last'), ('last', 'layer'), ('layer', 'linearly'), ('linearly', 'combine'), ('combine', 'features'), ('features', 'φ'), ('φ', '('), ('(', 'x'), ('x', ')'), (')', 'weight'), ('weight', 'matrices'), ('matrices', 'W'), ('W', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'WL−1'), ('WL−1', 'used'), ('used', 'preceding'), ('preceding', 'layers'), ('layers', 'order'), ('order', 'compute'), ('compute', 'feature'), ('feature', 'vector'), ('vector', '.')]

>> Trigrams are: 
 [('The', 'learnable', 'parameter'), ('learnable', 'parameter', 'vector'), ('parameter', 'vector', 'θ'), ('vector', 'θ', 'corresponds'), ('θ', 'corresponds', 'weights'), ('corresponds', 'weights', 'wL'), ('weights', 'wL', 'used'), ('wL', 'used', 'last'), ('used', 'last', 'layer'), ('last', 'layer', 'linearly'), ('layer', 'linearly', 'combine'), ('linearly', 'combine', 'features'), ('combine', 'features', 'φ'), ('features', 'φ', '('), ('φ', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'weight'), (')', 'weight', 'matrices'), ('weight', 'matrices', 'W'), ('matrices', 'W', '1'), ('W', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'WL−1'), (',', 'WL−1', 'used'), ('WL−1', 'used', 'preceding'), ('used', 'preceding', 'layers'), ('preceding', 'layers', 'order'), ('layers', 'order', 'compute'), ('order', 'compute', 'feature'), ('compute', 'feature', 'vector'), ('feature', 'vector', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learnable', 'JJ'), ('parameter', 'NN'), ('vector', 'NN'), ('θ', 'NNP'), ('corresponds', 'VBZ'), ('weights', 'NNS'), ('wL', 'NN'), ('used', 'VBN'), ('last', 'JJ'), ('layer', 'JJ'), ('linearly', 'RB'), ('combine', 'NN'), ('features', 'NNS'), ('φ', 'VBP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('weight', 'VBD'), ('matrices', 'NNS'), ('W', 'NNP'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('WL−1', 'NNP'), ('used', 'VBD'), ('preceding', 'VBG'), ('layers', 'NNS'), ('order', 'NN'), ('compute', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('.', '.')]

 (S
  (NP The/DT learnable/JJ parameter/NN vector/NN θ/NNP)
  corresponds/VBZ
  (NP weights/NNS wL/NN)
  used/VBN
  last/JJ
  layer/JJ
  linearly/RB
  (NP combine/NN features/NNS)
  φ/VBP
  (/(
  (NP x/NNP)
  )/)
  weight/VBD
  (NP matrices/NNS W/NNP)
  1/CD
  ,/,
  .../:
  ,/,
  (NP WL−1/NNP)
  used/VBD
  preceding/VBG
  (NP layers/NNS order/NN compute/NN feature/NN vector/NN)
  ./.) 


>> Noun Phrases are: 
 ['The learnable parameter vector θ', 'weights wL', 'combine features', 'x', 'matrices W', 'WL−1', 'layers order compute feature vector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'correspond'), ('weights', 'weight'), ('wL', 'wl'), ('used', 'use'), ('last', 'last'), ('layer', 'layer'), ('linearly', 'linearli'), ('combine', 'combin'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('weight', 'weight'), ('matrices', 'matric'), ('W', 'w'), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('WL−1', 'wl−1'), ('used', 'use'), ('preceding', 'preced'), ('layers', 'layer'), ('order', 'order'), ('compute', 'comput'), ('feature', 'featur'), ('vector', 'vector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'correspond'), ('weights', 'weight'), ('wL', 'wl'), ('used', 'use'), ('last', 'last'), ('layer', 'layer'), ('linearly', 'linear'), ('combine', 'combin'), ('features', 'featur'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('weight', 'weight'), ('matrices', 'matric'), ('W', 'w'), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('WL−1', 'wl−1'), ('used', 'use'), ('preceding', 'preced'), ('layers', 'layer'), ('order', 'order'), ('compute', 'comput'), ('feature', 'featur'), ('vector', 'vector'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learnable', 'learnable'), ('parameter', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('corresponds', 'corresponds'), ('weights', 'weight'), ('wL', 'wL'), ('used', 'used'), ('last', 'last'), ('layer', 'layer'), ('linearly', 'linearly'), ('combine', 'combine'), ('features', 'feature'), ('φ', 'φ'), ('(', '('), ('x', 'x'), (')', ')'), ('weight', 'weight'), ('matrices', 'matrix'), ('W', 'W'), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('WL−1', 'WL−1'), ('used', 'used'), ('preceding', 'preceding'), ('layers', 'layer'), ('order', 'order'), ('compute', 'compute'), ('feature', 'feature'), ('vector', 'vector'), ('.', '.')]



============================ Sentence 260 =============================

E. Learning  Ideally, a learning rule should obtain a predictor that minimizes the generalization error (2). 


>> Tokens are: 
 ['E.', 'Learning', 'Ideally', ',', 'learning', 'rule', 'obtain', 'predictor', 'minimizes', 'generalization', 'error', '(', '2', ')', '.']

>> Bigrams are: 
 [('E.', 'Learning'), ('Learning', 'Ideally'), ('Ideally', ','), (',', 'learning'), ('learning', 'rule'), ('rule', 'obtain'), ('obtain', 'predictor'), ('predictor', 'minimizes'), ('minimizes', 'generalization'), ('generalization', 'error'), ('error', '('), ('(', '2'), ('2', ')'), (')', '.')]

>> Trigrams are: 
 [('E.', 'Learning', 'Ideally'), ('Learning', 'Ideally', ','), ('Ideally', ',', 'learning'), (',', 'learning', 'rule'), ('learning', 'rule', 'obtain'), ('rule', 'obtain', 'predictor'), ('obtain', 'predictor', 'minimizes'), ('predictor', 'minimizes', 'generalization'), ('minimizes', 'generalization', 'error'), ('generalization', 'error', '('), ('error', '(', '2'), ('(', '2', ')'), ('2', ')', '.')]

>> POS Tags are: 
 [('E.', 'NNP'), ('Learning', 'NNP'), ('Ideally', 'NNP'), (',', ','), ('learning', 'VBG'), ('rule', 'NN'), ('obtain', 'VB'), ('predictor', 'NN'), ('minimizes', 'JJ'), ('generalization', 'NN'), ('error', 'NN'), ('(', '('), ('2', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP E./NNP Learning/NNP Ideally/NNP)
  ,/,
  learning/VBG
  (NP rule/NN)
  obtain/VB
  (NP predictor/NN)
  (NP minimizes/JJ generalization/NN error/NN)
  (/(
  2/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['E. Learning Ideally', 'rule', 'predictor', 'minimizes generalization error']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E.', 'e.'), ('Learning', 'learn'), ('Ideally', 'ideal'), (',', ','), ('learning', 'learn'), ('rule', 'rule'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('minimizes', 'minim'), ('generalization', 'gener'), ('error', 'error'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('E.', 'e.'), ('Learning', 'learn'), ('Ideally', 'ideal'), (',', ','), ('learning', 'learn'), ('rule', 'rule'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('minimizes', 'minim'), ('generalization', 'general'), ('error', 'error'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('E.', 'E.'), ('Learning', 'Learning'), ('Ideally', 'Ideally'), (',', ','), ('learning', 'learning'), ('rule', 'rule'), ('obtain', 'obtain'), ('predictor', 'predictor'), ('minimizes', 'minimizes'), ('generalization', 'generalization'), ('error', 'error'), ('(', '('), ('2', '2'), (')', ')'), ('.', '.')]



============================ Sentence 261 =============================

However, as discussed in Sec. 


>> Tokens are: 
 ['However', ',', 'discussed', 'Sec', '.']

>> Bigrams are: 
 [('However', ','), (',', 'discussed'), ('discussed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('However', ',', 'discussed'), (',', 'discussed', 'Sec'), ('discussed', 'Sec', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('discussed', 'VBD'), ('Sec', 'NNP'), ('.', '.')]

 (S However/RB ,/, discussed/VBD (NP Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('discussed', 'discussed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 262 =============================

III-C, this task is out of reach without knowledge of the true joint distribution p(x, t). 


>> Tokens are: 
 ['III-C', ',', 'task', 'reach', 'without', 'knowledge', 'true', 'joint', 'distribution', 'p', '(', 'x', ',', ')', '.']

>> Bigrams are: 
 [('III-C', ','), (',', 'task'), ('task', 'reach'), ('reach', 'without'), ('without', 'knowledge'), ('knowledge', 'true'), ('true', 'joint'), ('joint', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', '.')]

>> Trigrams are: 
 [('III-C', ',', 'task'), (',', 'task', 'reach'), ('task', 'reach', 'without'), ('reach', 'without', 'knowledge'), ('without', 'knowledge', 'true'), ('knowledge', 'true', 'joint'), ('true', 'joint', 'distribution'), ('joint', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', '.')]

>> POS Tags are: 
 [('III-C', 'NNP'), (',', ','), ('task', 'NN'), ('reach', 'NN'), ('without', 'IN'), ('knowledge', 'NN'), ('true', 'JJ'), ('joint', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('.', '.')]

 (S
  (NP III-C/NNP)
  ,/,
  (NP task/NN reach/NN)
  without/IN
  (NP knowledge/NN)
  (NP true/JJ joint/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  ./.) 


>> Noun Phrases are: 
 ['III-C', 'task reach', 'knowledge', 'true joint distribution p', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('III-C', 'iii-c'), (',', ','), ('task', 'task'), ('reach', 'reach'), ('without', 'without'), ('knowledge', 'knowledg'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III-C', 'iii-c'), (',', ','), ('task', 'task'), ('reach', 'reach'), ('without', 'without'), ('knowledge', 'knowledg'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('III-C', 'III-C'), (',', ','), ('task', 'task'), ('reach', 'reach'), ('without', 'without'), ('knowledge', 'knowledge'), ('true', 'true'), ('joint', 'joint'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('.', '.')]



============================ Sentence 263 =============================

There- fore, alternative learning criteria need to be considered that rely on the training set D rather than on the true distribution. 


>> Tokens are: 
 ['There-', 'fore', ',', 'alternative', 'learning', 'criteria', 'need', 'considered', 'rely', 'training', 'set', 'D', 'rather', 'true', 'distribution', '.']

>> Bigrams are: 
 [('There-', 'fore'), ('fore', ','), (',', 'alternative'), ('alternative', 'learning'), ('learning', 'criteria'), ('criteria', 'need'), ('need', 'considered'), ('considered', 'rely'), ('rely', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'rather'), ('rather', 'true'), ('true', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('There-', 'fore', ','), ('fore', ',', 'alternative'), (',', 'alternative', 'learning'), ('alternative', 'learning', 'criteria'), ('learning', 'criteria', 'need'), ('criteria', 'need', 'considered'), ('need', 'considered', 'rely'), ('considered', 'rely', 'training'), ('rely', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'rather'), ('D', 'rather', 'true'), ('rather', 'true', 'distribution'), ('true', 'distribution', '.')]

>> POS Tags are: 
 [('There-', 'NNP'), ('fore', 'NN'), (',', ','), ('alternative', 'JJ'), ('learning', 'NN'), ('criteria', 'NNS'), ('need', 'VBP'), ('considered', 'VBN'), ('rely', 'RB'), ('training', 'VBG'), ('set', 'VBN'), ('D', 'NNP'), ('rather', 'RB'), ('true', 'JJ'), ('distribution', 'NN'), ('.', '.')]

 (S
  (NP There-/NNP fore/NN)
  ,/,
  (NP alternative/JJ learning/NN criteria/NNS)
  need/VBP
  considered/VBN
  rely/RB
  training/VBG
  set/VBN
  (NP D/NNP)
  rather/RB
  (NP true/JJ distribution/NN)
  ./.) 


>> Noun Phrases are: 
 ['There- fore', 'alternative learning criteria', 'D', 'true distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There-', 'there-'), ('fore', 'fore'), (',', ','), ('alternative', 'altern'), ('learning', 'learn'), ('criteria', 'criteria'), ('need', 'need'), ('considered', 'consid'), ('rely', 'reli'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('rather', 'rather'), ('true', 'true'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There-', 'there-'), ('fore', 'fore'), (',', ','), ('alternative', 'altern'), ('learning', 'learn'), ('criteria', 'criteria'), ('need', 'need'), ('considered', 'consid'), ('rely', 'reli'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('rather', 'rather'), ('true', 'true'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('There-', 'There-'), ('fore', 'fore'), (',', ','), ('alternative', 'alternative'), ('learning', 'learning'), ('criteria', 'criterion'), ('need', 'need'), ('considered', 'considered'), ('rely', 'rely'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('rather', 'rather'), ('true', 'true'), ('distribution', 'distribution'), ('.', '.')]



============================ Sentence 264 =============================

In the context of probabilistic models, the most basic learning criterion is Maximum Likelihood (ML). 


>> Tokens are: 
 ['In', 'context', 'probabilistic', 'models', ',', 'basic', 'learning', 'criterion', 'Maximum', 'Likelihood', '(', 'ML', ')', '.']

>> Bigrams are: 
 [('In', 'context'), ('context', 'probabilistic'), ('probabilistic', 'models'), ('models', ','), (',', 'basic'), ('basic', 'learning'), ('learning', 'criterion'), ('criterion', 'Maximum'), ('Maximum', 'Likelihood'), ('Likelihood', '('), ('(', 'ML'), ('ML', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'context', 'probabilistic'), ('context', 'probabilistic', 'models'), ('probabilistic', 'models', ','), ('models', ',', 'basic'), (',', 'basic', 'learning'), ('basic', 'learning', 'criterion'), ('learning', 'criterion', 'Maximum'), ('criterion', 'Maximum', 'Likelihood'), ('Maximum', 'Likelihood', '('), ('Likelihood', '(', 'ML'), ('(', 'ML', ')'), ('ML', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('context', 'JJ'), ('probabilistic', 'JJ'), ('models', 'NNS'), (',', ','), ('basic', 'JJ'), ('learning', 'VBG'), ('criterion', 'NN'), ('Maximum', 'NNP'), ('Likelihood', 'NNP'), ('(', '('), ('ML', 'NNP'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP context/JJ probabilistic/JJ models/NNS)
  ,/,
  basic/JJ
  learning/VBG
  (NP criterion/NN Maximum/NNP Likelihood/NNP)
  (/(
  (NP ML/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['context probabilistic models', 'criterion Maximum Likelihood', 'ML']

>> Named Entities are: 
 [('PERSON', 'Maximum Likelihood')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('context', 'context'), ('probabilistic', 'probabilist'), ('models', 'model'), (',', ','), ('basic', 'basic'), ('learning', 'learn'), ('criterion', 'criterion'), ('Maximum', 'maximum'), ('Likelihood', 'likelihood'), ('(', '('), ('ML', 'ml'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('context', 'context'), ('probabilistic', 'probabilist'), ('models', 'model'), (',', ','), ('basic', 'basic'), ('learning', 'learn'), ('criterion', 'criterion'), ('Maximum', 'maximum'), ('Likelihood', 'likelihood'), ('(', '('), ('ML', 'ml'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('context', 'context'), ('probabilistic', 'probabilistic'), ('models', 'model'), (',', ','), ('basic', 'basic'), ('learning', 'learning'), ('criterion', 'criterion'), ('Maximum', 'Maximum'), ('Likelihood', 'Likelihood'), ('(', '('), ('ML', 'ML'), (')', ')'), ('.', '.')]



============================ Sentence 265 =============================

ML selects a value of θ in the parameterized family of models p(x, t|θ) or p(t|x, θ) that is the most likely to have generated the observed training set D. Mathematically, ML solves the problem of maximizing the log-likelihood function  maximize ln p(D|θ) (8)  over θ, where p(D|θ) is the probability of the data set D for a given value of θ. 


>> Tokens are: 
 ['ML', 'selects', 'value', 'θ', 'parameterized', 'family', 'models', 'p', '(', 'x', ',', 't|θ', ')', 'p', '(', 't|x', ',', 'θ', ')', 'likely', 'generated', 'observed', 'training', 'set', 'D.', 'Mathematically', ',', 'ML', 'solves', 'problem', 'maximizing', 'log-likelihood', 'function', 'maximize', 'ln', 'p', '(', 'D|θ', ')', '(', '8', ')', 'θ', ',', 'p', '(', 'D|θ', ')', 'probability', 'data', 'set', 'D', 'given', 'value', 'θ', '.']

>> Bigrams are: 
 [('ML', 'selects'), ('selects', 'value'), ('value', 'θ'), ('θ', 'parameterized'), ('parameterized', 'family'), ('family', 'models'), ('models', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 't|θ'), ('t|θ', ')'), (')', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'θ'), ('θ', ')'), (')', 'likely'), ('likely', 'generated'), ('generated', 'observed'), ('observed', 'training'), ('training', 'set'), ('set', 'D.'), ('D.', 'Mathematically'), ('Mathematically', ','), (',', 'ML'), ('ML', 'solves'), ('solves', 'problem'), ('problem', 'maximizing'), ('maximizing', 'log-likelihood'), ('log-likelihood', 'function'), ('function', 'maximize'), ('maximize', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'D|θ'), ('D|θ', ')'), (')', '('), ('(', '8'), ('8', ')'), (')', 'θ'), ('θ', ','), (',', 'p'), ('p', '('), ('(', 'D|θ'), ('D|θ', ')'), (')', 'probability'), ('probability', 'data'), ('data', 'set'), ('set', 'D'), ('D', 'given'), ('given', 'value'), ('value', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('ML', 'selects', 'value'), ('selects', 'value', 'θ'), ('value', 'θ', 'parameterized'), ('θ', 'parameterized', 'family'), ('parameterized', 'family', 'models'), ('family', 'models', 'p'), ('models', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 't|θ'), (',', 't|θ', ')'), ('t|θ', ')', 'p'), (')', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'likely'), (')', 'likely', 'generated'), ('likely', 'generated', 'observed'), ('generated', 'observed', 'training'), ('observed', 'training', 'set'), ('training', 'set', 'D.'), ('set', 'D.', 'Mathematically'), ('D.', 'Mathematically', ','), ('Mathematically', ',', 'ML'), (',', 'ML', 'solves'), ('ML', 'solves', 'problem'), ('solves', 'problem', 'maximizing'), ('problem', 'maximizing', 'log-likelihood'), ('maximizing', 'log-likelihood', 'function'), ('log-likelihood', 'function', 'maximize'), ('function', 'maximize', 'ln'), ('maximize', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'D|θ'), ('(', 'D|θ', ')'), ('D|θ', ')', '('), (')', '(', '8'), ('(', '8', ')'), ('8', ')', 'θ'), (')', 'θ', ','), ('θ', ',', 'p'), (',', 'p', '('), ('p', '(', 'D|θ'), ('(', 'D|θ', ')'), ('D|θ', ')', 'probability'), (')', 'probability', 'data'), ('probability', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', 'given'), ('D', 'given', 'value'), ('given', 'value', 'θ'), ('value', 'θ', '.')]

>> POS Tags are: 
 [('ML', 'NNP'), ('selects', 'VBZ'), ('value', 'NN'), ('θ', 'NNP'), ('parameterized', 'VBD'), ('family', 'NN'), ('models', 'NNS'), ('p', 'VBP'), ('(', '('), ('x', 'UH'), (',', ','), ('t|θ', 'JJ'), (')', ')'), ('p', 'NN'), ('(', '('), ('t|x', 'NN'), (',', ','), ('θ', 'NN'), (')', ')'), ('likely', 'RB'), ('generated', 'VBD'), ('observed', 'JJ'), ('training', 'NN'), ('set', 'VBN'), ('D.', 'NNP'), ('Mathematically', 'NNP'), (',', ','), ('ML', 'NNP'), ('solves', 'VBZ'), ('problem', 'NN'), ('maximizing', 'VBG'), ('log-likelihood', 'JJ'), ('function', 'NN'), ('maximize', 'VB'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('D|θ', 'NNP'), (')', ')'), ('(', '('), ('8', 'CD'), (')', ')'), ('θ', 'NN'), (',', ','), ('p', 'NN'), ('(', '('), ('D|θ', 'NNP'), (')', ')'), ('probability', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), ('given', 'VBN'), ('value', 'NN'), ('θ', 'NN'), ('.', '.')]

 (S
  (NP ML/NNP)
  selects/VBZ
  (NP value/NN θ/NNP)
  parameterized/VBD
  (NP family/NN models/NNS)
  p/VBP
  (/(
  x/UH
  ,/,
  t|θ/JJ
  )/)
  (NP p/NN)
  (/(
  (NP t|x/NN)
  ,/,
  (NP θ/NN)
  )/)
  likely/RB
  generated/VBD
  (NP observed/JJ training/NN)
  set/VBN
  (NP D./NNP Mathematically/NNP)
  ,/,
  (NP ML/NNP)
  solves/VBZ
  (NP problem/NN)
  maximizing/VBG
  (NP log-likelihood/JJ function/NN)
  maximize/VB
  (NP ln/JJ p/NN)
  (/(
  (NP D|θ/NNP)
  )/)
  (/(
  8/CD
  )/)
  (NP θ/NN)
  ,/,
  (NP p/NN)
  (/(
  (NP D|θ/NNP)
  )/)
  (NP probability/NN data/NNS)
  set/VBD
  (NP D/NNP)
  given/VBN
  (NP value/NN θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['ML', 'value θ', 'family models', 'p', 't|x', 'θ', 'observed training', 'D. Mathematically', 'ML', 'problem', 'log-likelihood function', 'ln p', 'D|θ', 'θ', 'p', 'D|θ', 'probability data', 'D', 'value θ']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('ML', 'ml'), ('selects', 'select'), ('value', 'valu'), ('θ', 'θ'), ('parameterized', 'parameter'), ('family', 'famili'), ('models', 'model'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('likely', 'like'), ('generated', 'gener'), ('observed', 'observ'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('Mathematically', 'mathemat'), (',', ','), ('ML', 'ml'), ('solves', 'solv'), ('problem', 'problem'), ('maximizing', 'maxim'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('maximize', 'maxim'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('θ', 'θ'), (',', ','), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('probability', 'probabl'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('given', 'given'), ('value', 'valu'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ML', 'ml'), ('selects', 'select'), ('value', 'valu'), ('θ', 'θ'), ('parameterized', 'parameter'), ('family', 'famili'), ('models', 'model'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('likely', 'like'), ('generated', 'generat'), ('observed', 'observ'), ('training', 'train'), ('set', 'set'), ('D.', 'd.'), ('Mathematically', 'mathemat'), (',', ','), ('ML', 'ml'), ('solves', 'solv'), ('problem', 'problem'), ('maximizing', 'maxim'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('maximize', 'maxim'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('θ', 'θ'), (',', ','), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('probability', 'probabl'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('given', 'given'), ('value', 'valu'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('ML', 'ML'), ('selects', 'selects'), ('value', 'value'), ('θ', 'θ'), ('parameterized', 'parameterized'), ('family', 'family'), ('models', 'model'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('t|θ', 't|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('likely', 'likely'), ('generated', 'generated'), ('observed', 'observed'), ('training', 'training'), ('set', 'set'), ('D.', 'D.'), ('Mathematically', 'Mathematically'), (',', ','), ('ML', 'ML'), ('solves', 'solves'), ('problem', 'problem'), ('maximizing', 'maximizing'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('maximize', 'maximize'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'D|θ'), (')', ')'), ('(', '('), ('8', '8'), (')', ')'), ('θ', 'θ'), (',', ','), ('p', 'p'), ('(', '('), ('D|θ', 'D|θ'), (')', ')'), ('probability', 'probability'), ('data', 'data'), ('set', 'set'), ('D', 'D'), ('given', 'given'), ('value', 'value'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 266 =============================

Given the assumption of i.i.d. 


>> Tokens are: 
 ['Given', 'assumption', 'i.i.d', '.']

>> Bigrams are: 
 [('Given', 'assumption'), ('assumption', 'i.i.d'), ('i.i.d', '.')]

>> Trigrams are: 
 [('Given', 'assumption', 'i.i.d'), ('assumption', 'i.i.d', '.')]

>> POS Tags are: 
 [('Given', 'VBN'), ('assumption', 'NN'), ('i.i.d', 'NN'), ('.', '.')]

 (S Given/VBN (NP assumption/NN i.i.d/NN) ./.) 


>> Noun Phrases are: 
 ['assumption i.i.d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Given', 'given'), ('assumption', 'assumpt'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Given', 'given'), ('assumption', 'assumpt'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Lemmatization: 
 [('Given', 'Given'), ('assumption', 'assumption'), ('i.i.d', 'i.i.d'), ('.', '.')]



============================ Sentence 267 =============================

data points in D (see Sec III-B), the log-likelihood can be written as  ln p(D|θ) = N∑ n=1  ln p(tn|xn, θ), (9)  where we have used as an example the case of discrim- inative models. 


>> Tokens are: 
 ['data', 'points', 'D', '(', 'see', 'Sec', 'III-B', ')', ',', 'log-likelihood', 'written', 'ln', 'p', '(', 'D|θ', ')', '=', 'N∑', 'n=1', 'ln', 'p', '(', 'tn|xn', ',', 'θ', ')', ',', '(', '9', ')', 'used', 'example', 'case', 'discrim-', 'inative', 'models', '.']

>> Bigrams are: 
 [('data', 'points'), ('points', 'D'), ('D', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'III-B'), ('III-B', ')'), (')', ','), (',', 'log-likelihood'), ('log-likelihood', 'written'), ('written', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'D|θ'), ('D|θ', ')'), (')', '='), ('=', 'N∑'), ('N∑', 'n=1'), ('n=1', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'tn|xn'), ('tn|xn', ','), (',', 'θ'), ('θ', ')'), (')', ','), (',', '('), ('(', '9'), ('9', ')'), (')', 'used'), ('used', 'example'), ('example', 'case'), ('case', 'discrim-'), ('discrim-', 'inative'), ('inative', 'models'), ('models', '.')]

>> Trigrams are: 
 [('data', 'points', 'D'), ('points', 'D', '('), ('D', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'III-B'), ('Sec', 'III-B', ')'), ('III-B', ')', ','), (')', ',', 'log-likelihood'), (',', 'log-likelihood', 'written'), ('log-likelihood', 'written', 'ln'), ('written', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'D|θ'), ('(', 'D|θ', ')'), ('D|θ', ')', '='), (')', '=', 'N∑'), ('=', 'N∑', 'n=1'), ('N∑', 'n=1', 'ln'), ('n=1', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'tn|xn'), ('(', 'tn|xn', ','), ('tn|xn', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ','), (')', ',', '('), (',', '(', '9'), ('(', '9', ')'), ('9', ')', 'used'), (')', 'used', 'example'), ('used', 'example', 'case'), ('example', 'case', 'discrim-'), ('case', 'discrim-', 'inative'), ('discrim-', 'inative', 'models'), ('inative', 'models', '.')]

>> POS Tags are: 
 [('data', 'NN'), ('points', 'NNS'), ('D', 'NNP'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('III-B', 'NNP'), (')', ')'), (',', ','), ('log-likelihood', 'JJ'), ('written', 'VBN'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('D|θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('N∑', 'NNP'), ('n=1', 'FW'), ('ln', 'NN'), ('p', 'NN'), ('(', '('), ('tn|xn', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), (',', ','), ('(', '('), ('9', 'CD'), (')', ')'), ('used', 'VBN'), ('example', 'NN'), ('case', 'NN'), ('discrim-', 'JJ'), ('inative', 'JJ'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP data/NN points/NNS D/NNP)
  (/(
  see/VB
  (NP Sec/NNP III-B/NNP)
  )/)
  ,/,
  log-likelihood/JJ
  written/VBN
  (NP ln/JJ p/NN)
  (/(
  (NP D|θ/NNP)
  )/)
  =/VBP
  (NP N∑/NNP)
  n=1/FW
  (NP ln/NN p/NN)
  (/(
  (NP tn|xn/NN)
  ,/,
  (NP θ/NNP)
  )/)
  ,/,
  (/(
  9/CD
  )/)
  used/VBN
  (NP example/NN case/NN)
  (NP discrim-/JJ inative/JJ models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data points D', 'Sec III-B', 'ln p', 'D|θ', 'N∑', 'ln p', 'tn|xn', 'θ', 'example case', 'discrim- inative models']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('points', 'point'), ('D', 'd'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-B', 'iii-b'), (')', ')'), (',', ','), ('log-likelihood', 'log-likelihood'), ('written', 'written'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('=', '='), ('N∑', 'n∑'), ('n=1', 'n=1'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('(', '('), ('9', '9'), (')', ')'), ('used', 'use'), ('example', 'exampl'), ('case', 'case'), ('discrim-', 'discrim-'), ('inative', 'in'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('points', 'point'), ('D', 'd'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-B', 'iii-b'), (')', ')'), (',', ','), ('log-likelihood', 'log-likelihood'), ('written', 'written'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'd|θ'), (')', ')'), ('=', '='), ('N∑', 'n∑'), ('n=1', 'n=1'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('(', '('), ('9', '9'), (')', ')'), ('used', 'use'), ('example', 'exampl'), ('case', 'case'), ('discrim-', 'discrim-'), ('inative', 'inat'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('points', 'point'), ('D', 'D'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('III-B', 'III-B'), (')', ')'), (',', ','), ('log-likelihood', 'log-likelihood'), ('written', 'written'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('D|θ', 'D|θ'), (')', ')'), ('=', '='), ('N∑', 'N∑'), ('n=1', 'n=1'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('(', '('), ('9', '9'), (')', ')'), ('used', 'used'), ('example', 'example'), ('case', 'case'), ('discrim-', 'discrim-'), ('inative', 'inative'), ('models', 'model'), ('.', '.')]



============================ Sentence 268 =============================

Note that most learning criteria used in practice can be interpreted as ML problems, including the least squares criterion – ML for Gaussian models – and cross-entropy – ML for categorical models. 


>> Tokens are: 
 ['Note', 'learning', 'criteria', 'used', 'practice', 'interpreted', 'ML', 'problems', ',', 'including', 'least', 'squares', 'criterion', '–', 'ML', 'Gaussian', 'models', '–', 'cross-entropy', '–', 'ML', 'categorical', 'models', '.']

>> Bigrams are: 
 [('Note', 'learning'), ('learning', 'criteria'), ('criteria', 'used'), ('used', 'practice'), ('practice', 'interpreted'), ('interpreted', 'ML'), ('ML', 'problems'), ('problems', ','), (',', 'including'), ('including', 'least'), ('least', 'squares'), ('squares', 'criterion'), ('criterion', '–'), ('–', 'ML'), ('ML', 'Gaussian'), ('Gaussian', 'models'), ('models', '–'), ('–', 'cross-entropy'), ('cross-entropy', '–'), ('–', 'ML'), ('ML', 'categorical'), ('categorical', 'models'), ('models', '.')]

>> Trigrams are: 
 [('Note', 'learning', 'criteria'), ('learning', 'criteria', 'used'), ('criteria', 'used', 'practice'), ('used', 'practice', 'interpreted'), ('practice', 'interpreted', 'ML'), ('interpreted', 'ML', 'problems'), ('ML', 'problems', ','), ('problems', ',', 'including'), (',', 'including', 'least'), ('including', 'least', 'squares'), ('least', 'squares', 'criterion'), ('squares', 'criterion', '–'), ('criterion', '–', 'ML'), ('–', 'ML', 'Gaussian'), ('ML', 'Gaussian', 'models'), ('Gaussian', 'models', '–'), ('models', '–', 'cross-entropy'), ('–', 'cross-entropy', '–'), ('cross-entropy', '–', 'ML'), ('–', 'ML', 'categorical'), ('ML', 'categorical', 'models'), ('categorical', 'models', '.')]

>> POS Tags are: 
 [('Note', 'NN'), ('learning', 'VBG'), ('criteria', 'NNS'), ('used', 'VBN'), ('practice', 'NN'), ('interpreted', 'VBD'), ('ML', 'NNP'), ('problems', 'NNS'), (',', ','), ('including', 'VBG'), ('least', 'JJS'), ('squares', 'NNS'), ('criterion', 'VBP'), ('–', 'JJ'), ('ML', 'NNP'), ('Gaussian', 'NNP'), ('models', 'NNS'), ('–', 'VBP'), ('cross-entropy', 'JJ'), ('–', 'NNP'), ('ML', 'NNP'), ('categorical', 'JJ'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP Note/NN)
  learning/VBG
  (NP criteria/NNS)
  used/VBN
  (NP practice/NN)
  interpreted/VBD
  (NP ML/NNP problems/NNS)
  ,/,
  including/VBG
  least/JJS
  (NP squares/NNS)
  criterion/VBP
  (NP –/JJ ML/NNP Gaussian/NNP models/NNS)
  –/VBP
  (NP cross-entropy/JJ –/NNP ML/NNP)
  (NP categorical/JJ models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Note', 'criteria', 'practice', 'ML problems', 'squares', '– ML Gaussian models', 'cross-entropy – ML', 'categorical models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('learning', 'learn'), ('criteria', 'criteria'), ('used', 'use'), ('practice', 'practic'), ('interpreted', 'interpret'), ('ML', 'ml'), ('problems', 'problem'), (',', ','), ('including', 'includ'), ('least', 'least'), ('squares', 'squar'), ('criterion', 'criterion'), ('–', '–'), ('ML', 'ml'), ('Gaussian', 'gaussian'), ('models', 'model'), ('–', '–'), ('cross-entropy', 'cross-entropi'), ('–', '–'), ('ML', 'ml'), ('categorical', 'categor'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('learning', 'learn'), ('criteria', 'criteria'), ('used', 'use'), ('practice', 'practic'), ('interpreted', 'interpret'), ('ML', 'ml'), ('problems', 'problem'), (',', ','), ('including', 'includ'), ('least', 'least'), ('squares', 'squar'), ('criterion', 'criterion'), ('–', '–'), ('ML', 'ml'), ('Gaussian', 'gaussian'), ('models', 'model'), ('–', '–'), ('cross-entropy', 'cross-entropi'), ('–', '–'), ('ML', 'ml'), ('categorical', 'categor'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), ('learning', 'learning'), ('criteria', 'criterion'), ('used', 'used'), ('practice', 'practice'), ('interpreted', 'interpreted'), ('ML', 'ML'), ('problems', 'problem'), (',', ','), ('including', 'including'), ('least', 'least'), ('squares', 'square'), ('criterion', 'criterion'), ('–', '–'), ('ML', 'ML'), ('Gaussian', 'Gaussian'), ('models', 'model'), ('–', '–'), ('cross-entropy', 'cross-entropy'), ('–', '–'), ('ML', 'ML'), ('categorical', 'categorical'), ('models', 'model'), ('.', '.')]



============================ Sentence 269 =============================

The ML problem (8) rarely has analytical solutions and is typically addressed by Stochastic Gradient De- scent (SGD). 


>> Tokens are: 
 ['The', 'ML', 'problem', '(', '8', ')', 'rarely', 'analytical', 'solutions', 'typically', 'addressed', 'Stochastic', 'Gradient', 'De-', 'scent', '(', 'SGD', ')', '.']

>> Bigrams are: 
 [('The', 'ML'), ('ML', 'problem'), ('problem', '('), ('(', '8'), ('8', ')'), (')', 'rarely'), ('rarely', 'analytical'), ('analytical', 'solutions'), ('solutions', 'typically'), ('typically', 'addressed'), ('addressed', 'Stochastic'), ('Stochastic', 'Gradient'), ('Gradient', 'De-'), ('De-', 'scent'), ('scent', '('), ('(', 'SGD'), ('SGD', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'ML', 'problem'), ('ML', 'problem', '('), ('problem', '(', '8'), ('(', '8', ')'), ('8', ')', 'rarely'), (')', 'rarely', 'analytical'), ('rarely', 'analytical', 'solutions'), ('analytical', 'solutions', 'typically'), ('solutions', 'typically', 'addressed'), ('typically', 'addressed', 'Stochastic'), ('addressed', 'Stochastic', 'Gradient'), ('Stochastic', 'Gradient', 'De-'), ('Gradient', 'De-', 'scent'), ('De-', 'scent', '('), ('scent', '(', 'SGD'), ('(', 'SGD', ')'), ('SGD', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('ML', 'NNP'), ('problem', 'NN'), ('(', '('), ('8', 'CD'), (')', ')'), ('rarely', 'RB'), ('analytical', 'JJ'), ('solutions', 'NNS'), ('typically', 'RB'), ('addressed', 'VBD'), ('Stochastic', 'JJ'), ('Gradient', 'NNP'), ('De-', 'NNP'), ('scent', 'NN'), ('(', '('), ('SGD', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT ML/NNP problem/NN)
  (/(
  8/CD
  )/)
  rarely/RB
  (NP analytical/JJ solutions/NNS)
  typically/RB
  addressed/VBD
  (NP Stochastic/JJ Gradient/NNP De-/NNP scent/NN)
  (/(
  (NP SGD/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The ML problem', 'analytical solutions', 'Stochastic Gradient De- scent', 'SGD']

>> Named Entities are: 
 [('ORGANIZATION', 'ML'), ('ORGANIZATION', 'Stochastic Gradient'), ('ORGANIZATION', 'SGD')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ML', 'ml'), ('problem', 'problem'), ('(', '('), ('8', '8'), (')', ')'), ('rarely', 'rare'), ('analytical', 'analyt'), ('solutions', 'solut'), ('typically', 'typic'), ('addressed', 'address'), ('Stochastic', 'stochast'), ('Gradient', 'gradient'), ('De-', 'de-'), ('scent', 'scent'), ('(', '('), ('SGD', 'sgd'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ML', 'ml'), ('problem', 'problem'), ('(', '('), ('8', '8'), (')', ')'), ('rarely', 'rare'), ('analytical', 'analyt'), ('solutions', 'solut'), ('typically', 'typic'), ('addressed', 'address'), ('Stochastic', 'stochast'), ('Gradient', 'gradient'), ('De-', 'de-'), ('scent', 'scent'), ('(', '('), ('SGD', 'sgd'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('ML', 'ML'), ('problem', 'problem'), ('(', '('), ('8', '8'), (')', ')'), ('rarely', 'rarely'), ('analytical', 'analytical'), ('solutions', 'solution'), ('typically', 'typically'), ('addressed', 'addressed'), ('Stochastic', 'Stochastic'), ('Gradient', 'Gradient'), ('De-', 'De-'), ('scent', 'scent'), ('(', '('), ('SGD', 'SGD'), (')', ')'), ('.', '.')]



============================ Sentence 270 =============================

Accordingly, at each iteration, subsets of examples, also known as mini-batches, are selected from the training set, and the parameter vector is updated in the direction of gradient of the log-likelihood function as evaluated on these examples. 


>> Tokens are: 
 ['Accordingly', ',', 'iteration', ',', 'subsets', 'examples', ',', 'also', 'known', 'mini-batches', ',', 'selected', 'training', 'set', ',', 'parameter', 'vector', 'updated', 'direction', 'gradient', 'log-likelihood', 'function', 'evaluated', 'examples', '.']

>> Bigrams are: 
 [('Accordingly', ','), (',', 'iteration'), ('iteration', ','), (',', 'subsets'), ('subsets', 'examples'), ('examples', ','), (',', 'also'), ('also', 'known'), ('known', 'mini-batches'), ('mini-batches', ','), (',', 'selected'), ('selected', 'training'), ('training', 'set'), ('set', ','), (',', 'parameter'), ('parameter', 'vector'), ('vector', 'updated'), ('updated', 'direction'), ('direction', 'gradient'), ('gradient', 'log-likelihood'), ('log-likelihood', 'function'), ('function', 'evaluated'), ('evaluated', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('Accordingly', ',', 'iteration'), (',', 'iteration', ','), ('iteration', ',', 'subsets'), (',', 'subsets', 'examples'), ('subsets', 'examples', ','), ('examples', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'mini-batches'), ('known', 'mini-batches', ','), ('mini-batches', ',', 'selected'), (',', 'selected', 'training'), ('selected', 'training', 'set'), ('training', 'set', ','), ('set', ',', 'parameter'), (',', 'parameter', 'vector'), ('parameter', 'vector', 'updated'), ('vector', 'updated', 'direction'), ('updated', 'direction', 'gradient'), ('direction', 'gradient', 'log-likelihood'), ('gradient', 'log-likelihood', 'function'), ('log-likelihood', 'function', 'evaluated'), ('function', 'evaluated', 'examples'), ('evaluated', 'examples', '.')]

>> POS Tags are: 
 [('Accordingly', 'RB'), (',', ','), ('iteration', 'NN'), (',', ','), ('subsets', 'NNS'), ('examples', 'NNS'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('mini-batches', 'NNS'), (',', ','), ('selected', 'VBD'), ('training', 'NN'), ('set', 'NN'), (',', ','), ('parameter', 'NN'), ('vector', 'NN'), ('updated', 'JJ'), ('direction', 'NN'), ('gradient', 'NN'), ('log-likelihood', 'JJ'), ('function', 'NN'), ('evaluated', 'VBD'), ('examples', 'NNS'), ('.', '.')]

 (S
  Accordingly/RB
  ,/,
  (NP iteration/NN)
  ,/,
  (NP subsets/NNS examples/NNS)
  ,/,
  also/RB
  known/VBN
  (NP mini-batches/NNS)
  ,/,
  selected/VBD
  (NP training/NN set/NN)
  ,/,
  (NP parameter/NN vector/NN)
  (NP updated/JJ direction/NN gradient/NN)
  (NP log-likelihood/JJ function/NN)
  evaluated/VBD
  (NP examples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['iteration', 'subsets examples', 'mini-batches', 'training set', 'parameter vector', 'updated direction gradient', 'log-likelihood function', 'examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accordingly', 'accordingli'), (',', ','), ('iteration', 'iter'), (',', ','), ('subsets', 'subset'), ('examples', 'exampl'), (',', ','), ('also', 'also'), ('known', 'known'), ('mini-batches', 'mini-batch'), (',', ','), ('selected', 'select'), ('training', 'train'), ('set', 'set'), (',', ','), ('parameter', 'paramet'), ('vector', 'vector'), ('updated', 'updat'), ('direction', 'direct'), ('gradient', 'gradient'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('evaluated', 'evalu'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accordingly', 'accord'), (',', ','), ('iteration', 'iter'), (',', ','), ('subsets', 'subset'), ('examples', 'exampl'), (',', ','), ('also', 'also'), ('known', 'known'), ('mini-batches', 'mini-batch'), (',', ','), ('selected', 'select'), ('training', 'train'), ('set', 'set'), (',', ','), ('parameter', 'paramet'), ('vector', 'vector'), ('updated', 'updat'), ('direction', 'direct'), ('gradient', 'gradient'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('evaluated', 'evalu'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('Accordingly', 'Accordingly'), (',', ','), ('iteration', 'iteration'), (',', ','), ('subsets', 'subset'), ('examples', 'example'), (',', ','), ('also', 'also'), ('known', 'known'), ('mini-batches', 'mini-batches'), (',', ','), ('selected', 'selected'), ('training', 'training'), ('set', 'set'), (',', ','), ('parameter', 'parameter'), ('vector', 'vector'), ('updated', 'updated'), ('direction', 'direction'), ('gradient', 'gradient'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), ('evaluated', 'evaluated'), ('examples', 'example'), ('.', '.')]



============================ Sentence 271 =============================

The resulting learning rule can be written as  θnew ← θold + γ∇θ ln p(tn|xn, θ)|θ=θold , (10)  where we have defined as γ > 0 the learning rate, and, for simplicity of notation, we have considered a mini- batch given by a single example (xn, tn). 


>> Tokens are: 
 ['The', 'resulting', 'learning', 'rule', 'written', 'θnew', '←', 'θold', '+', 'γ∇θ', 'ln', 'p', '(', 'tn|xn', ',', 'θ', ')', '|θ=θold', ',', '(', '10', ')', 'defined', 'γ', '>', '0', 'learning', 'rate', ',', ',', 'simplicity', 'notation', ',', 'considered', 'mini-', 'batch', 'given', 'single', 'example', '(', 'xn', ',', 'tn', ')', '.']

>> Bigrams are: 
 [('The', 'resulting'), ('resulting', 'learning'), ('learning', 'rule'), ('rule', 'written'), ('written', 'θnew'), ('θnew', '←'), ('←', 'θold'), ('θold', '+'), ('+', 'γ∇θ'), ('γ∇θ', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'tn|xn'), ('tn|xn', ','), (',', 'θ'), ('θ', ')'), (')', '|θ=θold'), ('|θ=θold', ','), (',', '('), ('(', '10'), ('10', ')'), (')', 'defined'), ('defined', 'γ'), ('γ', '>'), ('>', '0'), ('0', 'learning'), ('learning', 'rate'), ('rate', ','), (',', ','), (',', 'simplicity'), ('simplicity', 'notation'), ('notation', ','), (',', 'considered'), ('considered', 'mini-'), ('mini-', 'batch'), ('batch', 'given'), ('given', 'single'), ('single', 'example'), ('example', '('), ('(', 'xn'), ('xn', ','), (',', 'tn'), ('tn', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'resulting', 'learning'), ('resulting', 'learning', 'rule'), ('learning', 'rule', 'written'), ('rule', 'written', 'θnew'), ('written', 'θnew', '←'), ('θnew', '←', 'θold'), ('←', 'θold', '+'), ('θold', '+', 'γ∇θ'), ('+', 'γ∇θ', 'ln'), ('γ∇θ', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'tn|xn'), ('(', 'tn|xn', ','), ('tn|xn', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '|θ=θold'), (')', '|θ=θold', ','), ('|θ=θold', ',', '('), (',', '(', '10'), ('(', '10', ')'), ('10', ')', 'defined'), (')', 'defined', 'γ'), ('defined', 'γ', '>'), ('γ', '>', '0'), ('>', '0', 'learning'), ('0', 'learning', 'rate'), ('learning', 'rate', ','), ('rate', ',', ','), (',', ',', 'simplicity'), (',', 'simplicity', 'notation'), ('simplicity', 'notation', ','), ('notation', ',', 'considered'), (',', 'considered', 'mini-'), ('considered', 'mini-', 'batch'), ('mini-', 'batch', 'given'), ('batch', 'given', 'single'), ('given', 'single', 'example'), ('single', 'example', '('), ('example', '(', 'xn'), ('(', 'xn', ','), ('xn', ',', 'tn'), (',', 'tn', ')'), ('tn', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('resulting', 'VBG'), ('learning', 'JJ'), ('rule', 'NN'), ('written', 'VBN'), ('θnew', 'NNP'), ('←', 'NNP'), ('θold', 'NNP'), ('+', 'NNP'), ('γ∇θ', 'NNP'), ('ln', 'NN'), ('p', 'NN'), ('(', '('), ('tn|xn', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('|θ=θold', 'NN'), (',', ','), ('(', '('), ('10', 'CD'), (')', ')'), ('defined', 'VBD'), ('γ', 'NNP'), ('>', 'NNP'), ('0', 'CD'), ('learning', 'VBG'), ('rate', 'NN'), (',', ','), (',', ','), ('simplicity', 'NN'), ('notation', 'NN'), (',', ','), ('considered', 'VBN'), ('mini-', 'JJ'), ('batch', 'NN'), ('given', 'VBN'), ('single', 'JJ'), ('example', 'NN'), ('(', '('), ('xn', 'UH'), (',', ','), ('tn', 'NN'), (')', ')'), ('.', '.')]

 (S
  The/DT
  resulting/VBG
  (NP learning/JJ rule/NN)
  written/VBN
  (NP θnew/NNP ←/NNP θold/NNP +/NNP γ∇θ/NNP ln/NN p/NN)
  (/(
  (NP tn|xn/NN)
  ,/,
  (NP θ/NNP)
  )/)
  (NP |θ=θold/NN)
  ,/,
  (/(
  10/CD
  )/)
  defined/VBD
  (NP γ/NNP >/NNP)
  0/CD
  learning/VBG
  (NP rate/NN)
  ,/,
  ,/,
  (NP simplicity/NN notation/NN)
  ,/,
  considered/VBN
  (NP mini-/JJ batch/NN)
  given/VBN
  (NP single/JJ example/NN)
  (/(
  xn/UH
  ,/,
  (NP tn/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['learning rule', 'θnew ← θold + γ∇θ ln p', 'tn|xn', 'θ', '|θ=θold', 'γ >', 'rate', 'simplicity notation', 'mini- batch', 'single example', 'tn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('learning', 'learn'), ('rule', 'rule'), ('written', 'written'), ('θnew', 'θnew'), ('←', '←'), ('θold', 'θold'), ('+', '+'), ('γ∇θ', 'γ∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('|θ=θold', '|θ=θold'), (',', ','), ('(', '('), ('10', '10'), (')', ')'), ('defined', 'defin'), ('γ', 'γ'), ('>', '>'), ('0', '0'), ('learning', 'learn'), ('rate', 'rate'), (',', ','), (',', ','), ('simplicity', 'simplic'), ('notation', 'notat'), (',', ','), ('considered', 'consid'), ('mini-', 'mini-'), ('batch', 'batch'), ('given', 'given'), ('single', 'singl'), ('example', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('learning', 'learn'), ('rule', 'rule'), ('written', 'written'), ('θnew', 'θnew'), ('←', '←'), ('θold', 'θold'), ('+', '+'), ('γ∇θ', 'γ∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('|θ=θold', '|θ=θold'), (',', ','), ('(', '('), ('10', '10'), (')', ')'), ('defined', 'defin'), ('γ', 'γ'), ('>', '>'), ('0', '0'), ('learning', 'learn'), ('rate', 'rate'), (',', ','), (',', ','), ('simplicity', 'simplic'), ('notation', 'notat'), (',', ','), ('considered', 'consid'), ('mini-', 'mini-'), ('batch', 'batch'), ('given', 'given'), ('single', 'singl'), ('example', 'exampl'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('resulting', 'resulting'), ('learning', 'learning'), ('rule', 'rule'), ('written', 'written'), ('θnew', 'θnew'), ('←', '←'), ('θold', 'θold'), ('+', '+'), ('γ∇θ', 'γ∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('|θ=θold', '|θ=θold'), (',', ','), ('(', '('), ('10', '10'), (')', ')'), ('defined', 'defined'), ('γ', 'γ'), ('>', '>'), ('0', '0'), ('learning', 'learning'), ('rate', 'rate'), (',', ','), (',', ','), ('simplicity', 'simplicity'), ('notation', 'notation'), (',', ','), ('considered', 'considered'), ('mini-', 'mini-'), ('batch', 'batch'), ('given', 'given'), ('single', 'single'), ('example', 'example'), ('(', '('), ('xn', 'xn'), (',', ','), ('tn', 'tn'), (')', ')'), ('.', '.')]



============================ Sentence 272 =============================

It is noted that, with multi-layer neural networks, the computation of the gradient ∇θ ln p(tn|xn, θ) yields the standard backpropagation algorithm [7], [19]. 


>> Tokens are: 
 ['It', 'noted', ',', 'multi-layer', 'neural', 'networks', ',', 'computation', 'gradient', '∇θ', 'ln', 'p', '(', 'tn|xn', ',', 'θ', ')', 'yields', 'standard', 'backpropagation', 'algorithm', '[', '7', ']', ',', '[', '19', ']', '.']

>> Bigrams are: 
 [('It', 'noted'), ('noted', ','), (',', 'multi-layer'), ('multi-layer', 'neural'), ('neural', 'networks'), ('networks', ','), (',', 'computation'), ('computation', 'gradient'), ('gradient', '∇θ'), ('∇θ', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'tn|xn'), ('tn|xn', ','), (',', 'θ'), ('θ', ')'), (')', 'yields'), ('yields', 'standard'), ('standard', 'backpropagation'), ('backpropagation', 'algorithm'), ('algorithm', '['), ('[', '7'), ('7', ']'), (']', ','), (',', '['), ('[', '19'), ('19', ']'), (']', '.')]

>> Trigrams are: 
 [('It', 'noted', ','), ('noted', ',', 'multi-layer'), (',', 'multi-layer', 'neural'), ('multi-layer', 'neural', 'networks'), ('neural', 'networks', ','), ('networks', ',', 'computation'), (',', 'computation', 'gradient'), ('computation', 'gradient', '∇θ'), ('gradient', '∇θ', 'ln'), ('∇θ', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'tn|xn'), ('(', 'tn|xn', ','), ('tn|xn', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'yields'), (')', 'yields', 'standard'), ('yields', 'standard', 'backpropagation'), ('standard', 'backpropagation', 'algorithm'), ('backpropagation', 'algorithm', '['), ('algorithm', '[', '7'), ('[', '7', ']'), ('7', ']', ','), (']', ',', '['), (',', '[', '19'), ('[', '19', ']'), ('19', ']', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('noted', 'VBD'), (',', ','), ('multi-layer', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), (',', ','), ('computation', 'NN'), ('gradient', 'NN'), ('∇θ', 'NNP'), ('ln', 'NN'), ('p', 'NN'), ('(', '('), ('tn|xn', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('yields', 'VBZ'), ('standard', 'JJ'), ('backpropagation', 'NN'), ('algorithm', 'NN'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('19', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  It/PRP
  noted/VBD
  ,/,
  (NP multi-layer/JJ neural/JJ networks/NNS)
  ,/,
  (NP computation/NN gradient/NN ∇θ/NNP ln/NN p/NN)
  (/(
  (NP tn|xn/NN)
  ,/,
  (NP θ/NNP)
  )/)
  yields/VBZ
  (NP standard/JJ backpropagation/NN algorithm/NN)
  [/VBD
  7/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  19/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['multi-layer neural networks', 'computation gradient ∇θ ln p', 'tn|xn', 'θ', 'standard backpropagation algorithm', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('noted', 'note'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('computation', 'comput'), ('gradient', 'gradient'), ('∇θ', '∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('yields', 'yield'), ('standard', 'standard'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('noted', 'note'), (',', ','), ('multi-layer', 'multi-lay'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('computation', 'comput'), ('gradient', 'gradient'), ('∇θ', '∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('yields', 'yield'), ('standard', 'standard'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('noted', 'noted'), (',', ','), ('multi-layer', 'multi-layer'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('computation', 'computation'), ('gradient', 'gradient'), ('∇θ', '∇θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('tn|xn', 'tn|xn'), (',', ','), ('θ', 'θ'), (')', ')'), ('yields', 'yield'), ('standard', 'standard'), ('backpropagation', 'backpropagation'), ('algorithm', 'algorithm'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]



============================ Sentence 273 =============================

The learning rate is an example of hyperparameters that define the learning algorithm. 


>> Tokens are: 
 ['The', 'learning', 'rate', 'example', 'hyperparameters', 'define', 'learning', 'algorithm', '.']

>> Bigrams are: 
 [('The', 'learning'), ('learning', 'rate'), ('rate', 'example'), ('example', 'hyperparameters'), ('hyperparameters', 'define'), ('define', 'learning'), ('learning', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('The', 'learning', 'rate'), ('learning', 'rate', 'example'), ('rate', 'example', 'hyperparameters'), ('example', 'hyperparameters', 'define'), ('hyperparameters', 'define', 'learning'), ('define', 'learning', 'algorithm'), ('learning', 'algorithm', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learning', 'NN'), ('rate', 'NN'), ('example', 'NN'), ('hyperparameters', 'NNS'), ('define', 'VBP'), ('learning', 'VBG'), ('algorithm', 'NN'), ('.', '.')]

 (S
  (NP The/DT learning/NN rate/NN example/NN hyperparameters/NNS)
  define/VBP
  learning/VBG
  (NP algorithm/NN)
  ./.) 


>> Noun Phrases are: 
 ['The learning rate example hyperparameters', 'algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learning', 'learn'), ('rate', 'rate'), ('example', 'exampl'), ('hyperparameters', 'hyperparamet'), ('define', 'defin'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learning', 'learn'), ('rate', 'rate'), ('example', 'exampl'), ('hyperparameters', 'hyperparamet'), ('define', 'defin'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learning', 'learning'), ('rate', 'rate'), ('example', 'example'), ('hyperparameters', 'hyperparameters'), ('define', 'define'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('.', '.')]



============================ Sentence 274 =============================

Many variations of SGD have been proposed that aim at improving convergence (see, e.g.-.-, [7], [19]). 


>> Tokens are: 
 ['Many', 'variations', 'SGD', 'proposed', 'aim', 'improving', 'convergence', '(', 'see', ',', 'e.g.-.-', ',', '[', '7', ']', ',', '[', '19', ']', ')', '.']

>> Bigrams are: 
 [('Many', 'variations'), ('variations', 'SGD'), ('SGD', 'proposed'), ('proposed', 'aim'), ('aim', 'improving'), ('improving', 'convergence'), ('convergence', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '7'), ('7', ']'), (']', ','), (',', '['), ('[', '19'), ('19', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('Many', 'variations', 'SGD'), ('variations', 'SGD', 'proposed'), ('SGD', 'proposed', 'aim'), ('proposed', 'aim', 'improving'), ('aim', 'improving', 'convergence'), ('improving', 'convergence', '('), ('convergence', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '7'), ('[', '7', ']'), ('7', ']', ','), (']', ',', '['), (',', '[', '19'), ('[', '19', ']'), ('19', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('variations', 'NNS'), ('SGD', 'VBP'), ('proposed', 'VBN'), ('aim', 'NN'), ('improving', 'VBG'), ('convergence', 'NN'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('7', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('19', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Many/JJ variations/NNS)
  SGD/VBP
  proposed/VBN
  (NP aim/NN)
  improving/VBG
  (NP convergence/NN)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  7/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  19/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Many variations', 'aim', 'convergence', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('variations', 'variat'), ('SGD', 'sgd'), ('proposed', 'propos'), ('aim', 'aim'), ('improving', 'improv'), ('convergence', 'converg'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('variations', 'variat'), ('SGD', 'sgd'), ('proposed', 'propos'), ('aim', 'aim'), ('improving', 'improv'), ('convergence', 'converg'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('variations', 'variation'), ('SGD', 'SGD'), ('proposed', 'proposed'), ('aim', 'aim'), ('improving', 'improving'), ('convergence', 'convergence'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 275 =============================

ML has evident drawbacks as an indirect means of minimizing the generalization error. 


>> Tokens are: 
 ['ML', 'evident', 'drawbacks', 'indirect', 'means', 'minimizing', 'generalization', 'error', '.']

>> Bigrams are: 
 [('ML', 'evident'), ('evident', 'drawbacks'), ('drawbacks', 'indirect'), ('indirect', 'means'), ('means', 'minimizing'), ('minimizing', 'generalization'), ('generalization', 'error'), ('error', '.')]

>> Trigrams are: 
 [('ML', 'evident', 'drawbacks'), ('evident', 'drawbacks', 'indirect'), ('drawbacks', 'indirect', 'means'), ('indirect', 'means', 'minimizing'), ('means', 'minimizing', 'generalization'), ('minimizing', 'generalization', 'error'), ('generalization', 'error', '.')]

>> POS Tags are: 
 [('ML', 'NNP'), ('evident', 'JJ'), ('drawbacks', 'NNS'), ('indirect', 'VBP'), ('means', 'VBZ'), ('minimizing', 'VBG'), ('generalization', 'NN'), ('error', 'NN'), ('.', '.')]

 (S
  (NP ML/NNP)
  (NP evident/JJ drawbacks/NNS)
  indirect/VBP
  means/VBZ
  minimizing/VBG
  (NP generalization/NN error/NN)
  ./.) 


>> Noun Phrases are: 
 ['ML', 'evident drawbacks', 'generalization error']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ML', 'ml'), ('evident', 'evid'), ('drawbacks', 'drawback'), ('indirect', 'indirect'), ('means', 'mean'), ('minimizing', 'minim'), ('generalization', 'gener'), ('error', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ML', 'ml'), ('evident', 'evid'), ('drawbacks', 'drawback'), ('indirect', 'indirect'), ('means', 'mean'), ('minimizing', 'minim'), ('generalization', 'general'), ('error', 'error'), ('.', '.')]

>> Lemmatization: 
 [('ML', 'ML'), ('evident', 'evident'), ('drawbacks', 'drawback'), ('indirect', 'indirect'), ('means', 'mean'), ('minimizing', 'minimizing'), ('generalization', 'generalization'), ('error', 'error'), ('.', '.')]



============================ Sentence 276 =============================

In fact, ML only considers the fit of the probabilistic model on the training set without any consideration for the performance on unobserved input-output pairs. 


>> Tokens are: 
 ['In', 'fact', ',', 'ML', 'considers', 'fit', 'probabilistic', 'model', 'training', 'set', 'without', 'consideration', 'performance', 'unobserved', 'input-output', 'pairs', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'ML'), ('ML', 'considers'), ('considers', 'fit'), ('fit', 'probabilistic'), ('probabilistic', 'model'), ('model', 'training'), ('training', 'set'), ('set', 'without'), ('without', 'consideration'), ('consideration', 'performance'), ('performance', 'unobserved'), ('unobserved', 'input-output'), ('input-output', 'pairs'), ('pairs', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'ML'), (',', 'ML', 'considers'), ('ML', 'considers', 'fit'), ('considers', 'fit', 'probabilistic'), ('fit', 'probabilistic', 'model'), ('probabilistic', 'model', 'training'), ('model', 'training', 'set'), ('training', 'set', 'without'), ('set', 'without', 'consideration'), ('without', 'consideration', 'performance'), ('consideration', 'performance', 'unobserved'), ('performance', 'unobserved', 'input-output'), ('unobserved', 'input-output', 'pairs'), ('input-output', 'pairs', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('ML', 'NNP'), ('considers', 'VBZ'), ('fit', 'JJ'), ('probabilistic', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('without', 'IN'), ('consideration', 'NN'), ('performance', 'NN'), ('unobserved', 'VBD'), ('input-output', 'JJ'), ('pairs', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP fact/NN)
  ,/,
  (NP ML/NNP)
  considers/VBZ
  (NP fit/JJ probabilistic/JJ model/NN training/NN)
  set/VBN
  without/IN
  (NP consideration/NN performance/NN)
  unobserved/VBD
  (NP input-output/JJ pairs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'ML', 'fit probabilistic model training', 'consideration performance', 'input-output pairs']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('ML', 'ml'), ('considers', 'consid'), ('fit', 'fit'), ('probabilistic', 'probabilist'), ('model', 'model'), ('training', 'train'), ('set', 'set'), ('without', 'without'), ('consideration', 'consider'), ('performance', 'perform'), ('unobserved', 'unobserv'), ('input-output', 'input-output'), ('pairs', 'pair'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('ML', 'ml'), ('considers', 'consid'), ('fit', 'fit'), ('probabilistic', 'probabilist'), ('model', 'model'), ('training', 'train'), ('set', 'set'), ('without', 'without'), ('consideration', 'consider'), ('performance', 'perform'), ('unobserved', 'unobserv'), ('input-output', 'input-output'), ('pairs', 'pair'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('ML', 'ML'), ('considers', 'considers'), ('fit', 'fit'), ('probabilistic', 'probabilistic'), ('model', 'model'), ('training', 'training'), ('set', 'set'), ('without', 'without'), ('consideration', 'consideration'), ('performance', 'performance'), ('unobserved', 'unobserved'), ('input-output', 'input-output'), ('pairs', 'pair'), ('.', '.')]



============================ Sentence 277 =============================

This weakness can be somewhat mitigated by regularization [7], [19] during learning and by a proper selection of the model via validation, as discussed in the next subsection. 


>> Tokens are: 
 ['This', 'weakness', 'somewhat', 'mitigated', 'regularization', '[', '7', ']', ',', '[', '19', ']', 'learning', 'proper', 'selection', 'model', 'via', 'validation', ',', 'discussed', 'next', 'subsection', '.']

>> Bigrams are: 
 [('This', 'weakness'), ('weakness', 'somewhat'), ('somewhat', 'mitigated'), ('mitigated', 'regularization'), ('regularization', '['), ('[', '7'), ('7', ']'), (']', ','), (',', '['), ('[', '19'), ('19', ']'), (']', 'learning'), ('learning', 'proper'), ('proper', 'selection'), ('selection', 'model'), ('model', 'via'), ('via', 'validation'), ('validation', ','), (',', 'discussed'), ('discussed', 'next'), ('next', 'subsection'), ('subsection', '.')]

>> Trigrams are: 
 [('This', 'weakness', 'somewhat'), ('weakness', 'somewhat', 'mitigated'), ('somewhat', 'mitigated', 'regularization'), ('mitigated', 'regularization', '['), ('regularization', '[', '7'), ('[', '7', ']'), ('7', ']', ','), (']', ',', '['), (',', '[', '19'), ('[', '19', ']'), ('19', ']', 'learning'), (']', 'learning', 'proper'), ('learning', 'proper', 'selection'), ('proper', 'selection', 'model'), ('selection', 'model', 'via'), ('model', 'via', 'validation'), ('via', 'validation', ','), ('validation', ',', 'discussed'), (',', 'discussed', 'next'), ('discussed', 'next', 'subsection'), ('next', 'subsection', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('weakness', 'NN'), ('somewhat', 'RB'), ('mitigated', 'VBD'), ('regularization', 'NN'), ('[', 'NN'), ('7', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('19', 'CD'), (']', 'NN'), ('learning', 'VBG'), ('proper', 'JJ'), ('selection', 'NN'), ('model', 'NN'), ('via', 'IN'), ('validation', 'NN'), (',', ','), ('discussed', 'VBD'), ('next', 'JJ'), ('subsection', 'NN'), ('.', '.')]

 (S
  (NP This/DT weakness/NN)
  somewhat/RB
  mitigated/VBD
  (NP regularization/NN [/NN)
  7/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  19/CD
  (NP ]/NN)
  learning/VBG
  (NP proper/JJ selection/NN model/NN)
  via/IN
  (NP validation/NN)
  ,/,
  discussed/VBD
  (NP next/JJ subsection/NN)
  ./.) 


>> Noun Phrases are: 
 ['This weakness', 'regularization [', ']', ']', 'proper selection model', 'validation', 'next subsection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('weakness', 'weak'), ('somewhat', 'somewhat'), ('mitigated', 'mitig'), ('regularization', 'regular'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('learning', 'learn'), ('proper', 'proper'), ('selection', 'select'), ('model', 'model'), ('via', 'via'), ('validation', 'valid'), (',', ','), ('discussed', 'discuss'), ('next', 'next'), ('subsection', 'subsect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('weakness', 'weak'), ('somewhat', 'somewhat'), ('mitigated', 'mitig'), ('regularization', 'regular'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('learning', 'learn'), ('proper', 'proper'), ('selection', 'select'), ('model', 'model'), ('via', 'via'), ('validation', 'valid'), (',', ','), ('discussed', 'discuss'), ('next', 'next'), ('subsection', 'subsect'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('weakness', 'weakness'), ('somewhat', 'somewhat'), ('mitigated', 'mitigated'), ('regularization', 'regularization'), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), ('learning', 'learning'), ('proper', 'proper'), ('selection', 'selection'), ('model', 'model'), ('via', 'via'), ('validation', 'validation'), (',', ','), ('discussed', 'discussed'), ('next', 'next'), ('subsection', 'subsection'), ('.', '.')]



============================ Sentence 278 =============================

Regu- larization adds a penalty term to the log-likelihood that depends on the model parameters θ. 


>> Tokens are: 
 ['Regu-', 'larization', 'adds', 'penalty', 'term', 'log-likelihood', 'depends', 'model', 'parameters', 'θ', '.']

>> Bigrams are: 
 [('Regu-', 'larization'), ('larization', 'adds'), ('adds', 'penalty'), ('penalty', 'term'), ('term', 'log-likelihood'), ('log-likelihood', 'depends'), ('depends', 'model'), ('model', 'parameters'), ('parameters', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('Regu-', 'larization', 'adds'), ('larization', 'adds', 'penalty'), ('adds', 'penalty', 'term'), ('penalty', 'term', 'log-likelihood'), ('term', 'log-likelihood', 'depends'), ('log-likelihood', 'depends', 'model'), ('depends', 'model', 'parameters'), ('model', 'parameters', 'θ'), ('parameters', 'θ', '.')]

>> POS Tags are: 
 [('Regu-', 'JJ'), ('larization', 'NN'), ('adds', 'VBZ'), ('penalty', 'JJ'), ('term', 'NN'), ('log-likelihood', 'JJ'), ('depends', 'VBZ'), ('model', 'NN'), ('parameters', 'NNS'), ('θ', 'VBP'), ('.', '.')]

 (S
  (NP Regu-/JJ larization/NN)
  adds/VBZ
  (NP penalty/JJ term/NN)
  log-likelihood/JJ
  depends/VBZ
  (NP model/NN parameters/NNS)
  θ/VBP
  ./.) 


>> Noun Phrases are: 
 ['Regu- larization', 'penalty term', 'model parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Regu-', 'regu-'), ('larization', 'lariz'), ('adds', 'add'), ('penalty', 'penalti'), ('term', 'term'), ('log-likelihood', 'log-likelihood'), ('depends', 'depend'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Regu-', 'regu-'), ('larization', 'larize'), ('adds', 'add'), ('penalty', 'penalti'), ('term', 'term'), ('log-likelihood', 'log-likelihood'), ('depends', 'depend'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('Regu-', 'Regu-'), ('larization', 'larization'), ('adds', 'add'), ('penalty', 'penalty'), ('term', 'term'), ('log-likelihood', 'log-likelihood'), ('depends', 'depends'), ('model', 'model'), ('parameters', 'parameter'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 279 =============================

The goal is to prevent the learned model parameters θ to assume values that are a priori too unlikely and that are hence possible symptoms of overfitting. 


>> Tokens are: 
 ['The', 'goal', 'prevent', 'learned', 'model', 'parameters', 'θ', 'assume', 'values', 'priori', 'unlikely', 'hence', 'possible', 'symptoms', 'overfitting', '.']

>> Bigrams are: 
 [('The', 'goal'), ('goal', 'prevent'), ('prevent', 'learned'), ('learned', 'model'), ('model', 'parameters'), ('parameters', 'θ'), ('θ', 'assume'), ('assume', 'values'), ('values', 'priori'), ('priori', 'unlikely'), ('unlikely', 'hence'), ('hence', 'possible'), ('possible', 'symptoms'), ('symptoms', 'overfitting'), ('overfitting', '.')]

>> Trigrams are: 
 [('The', 'goal', 'prevent'), ('goal', 'prevent', 'learned'), ('prevent', 'learned', 'model'), ('learned', 'model', 'parameters'), ('model', 'parameters', 'θ'), ('parameters', 'θ', 'assume'), ('θ', 'assume', 'values'), ('assume', 'values', 'priori'), ('values', 'priori', 'unlikely'), ('priori', 'unlikely', 'hence'), ('unlikely', 'hence', 'possible'), ('hence', 'possible', 'symptoms'), ('possible', 'symptoms', 'overfitting'), ('symptoms', 'overfitting', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('goal', 'NN'), ('prevent', 'NN'), ('learned', 'VBD'), ('model', 'NN'), ('parameters', 'NNS'), ('θ', 'VBP'), ('assume', 'JJ'), ('values', 'NNS'), ('priori', 'VBP'), ('unlikely', 'JJ'), ('hence', 'NN'), ('possible', 'JJ'), ('symptoms', 'NNS'), ('overfitting', 'VBG'), ('.', '.')]

 (S
  (NP The/DT goal/NN prevent/NN)
  learned/VBD
  (NP model/NN parameters/NNS)
  θ/VBP
  (NP assume/JJ values/NNS)
  priori/VBP
  (NP unlikely/JJ hence/NN)
  (NP possible/JJ symptoms/NNS)
  overfitting/VBG
  ./.) 


>> Noun Phrases are: 
 ['The goal prevent', 'model parameters', 'assume values', 'unlikely hence', 'possible symptoms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('prevent', 'prevent'), ('learned', 'learn'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), ('assume', 'assum'), ('values', 'valu'), ('priori', 'priori'), ('unlikely', 'unlik'), ('hence', 'henc'), ('possible', 'possibl'), ('symptoms', 'symptom'), ('overfitting', 'overfit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('prevent', 'prevent'), ('learned', 'learn'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), ('assume', 'assum'), ('values', 'valu'), ('priori', 'priori'), ('unlikely', 'unlik'), ('hence', 'henc'), ('possible', 'possibl'), ('symptoms', 'symptom'), ('overfitting', 'overfit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('goal', 'goal'), ('prevent', 'prevent'), ('learned', 'learned'), ('model', 'model'), ('parameters', 'parameter'), ('θ', 'θ'), ('assume', 'assume'), ('values', 'value'), ('priori', 'priori'), ('unlikely', 'unlikely'), ('hence', 'hence'), ('possible', 'possible'), ('symptoms', 'symptom'), ('overfitting', 'overfitting'), ('.', '.')]



============================ Sentence 280 =============================

As an example, for logistic regression, one can add a penalty that is proportional to the norm ||w||2 of the weight vector w in order to prevent the weights to assume excessively high values when fitting the data in the learning step. 


>> Tokens are: 
 ['As', 'example', ',', 'logistic', 'regression', ',', 'one', 'add', 'penalty', 'proportional', 'norm', '||w||2', 'weight', 'vector', 'w', 'order', 'prevent', 'weights', 'assume', 'excessively', 'high', 'values', 'fitting', 'data', 'learning', 'step', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'logistic'), ('logistic', 'regression'), ('regression', ','), (',', 'one'), ('one', 'add'), ('add', 'penalty'), ('penalty', 'proportional'), ('proportional', 'norm'), ('norm', '||w||2'), ('||w||2', 'weight'), ('weight', 'vector'), ('vector', 'w'), ('w', 'order'), ('order', 'prevent'), ('prevent', 'weights'), ('weights', 'assume'), ('assume', 'excessively'), ('excessively', 'high'), ('high', 'values'), ('values', 'fitting'), ('fitting', 'data'), ('data', 'learning'), ('learning', 'step'), ('step', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'logistic'), (',', 'logistic', 'regression'), ('logistic', 'regression', ','), ('regression', ',', 'one'), (',', 'one', 'add'), ('one', 'add', 'penalty'), ('add', 'penalty', 'proportional'), ('penalty', 'proportional', 'norm'), ('proportional', 'norm', '||w||2'), ('norm', '||w||2', 'weight'), ('||w||2', 'weight', 'vector'), ('weight', 'vector', 'w'), ('vector', 'w', 'order'), ('w', 'order', 'prevent'), ('order', 'prevent', 'weights'), ('prevent', 'weights', 'assume'), ('weights', 'assume', 'excessively'), ('assume', 'excessively', 'high'), ('excessively', 'high', 'values'), ('high', 'values', 'fitting'), ('values', 'fitting', 'data'), ('fitting', 'data', 'learning'), ('data', 'learning', 'step'), ('learning', 'step', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('logistic', 'JJ'), ('regression', 'NN'), (',', ','), ('one', 'CD'), ('add', 'NN'), ('penalty', 'NN'), ('proportional', 'JJ'), ('norm', 'NN'), ('||w||2', 'NN'), ('weight', 'VBD'), ('vector', 'NN'), ('w', 'NN'), ('order', 'NN'), ('prevent', 'NN'), ('weights', 'NNS'), ('assume', 'VBP'), ('excessively', 'RB'), ('high', 'JJ'), ('values', 'NNS'), ('fitting', 'VBG'), ('data', 'NNS'), ('learning', 'VBG'), ('step', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  (NP logistic/JJ regression/NN)
  ,/,
  one/CD
  (NP add/NN penalty/NN)
  (NP proportional/JJ norm/NN ||w||2/NN)
  weight/VBD
  (NP vector/NN w/NN order/NN prevent/NN weights/NNS)
  assume/VBP
  excessively/RB
  (NP high/JJ values/NNS)
  fitting/VBG
  (NP data/NNS)
  learning/VBG
  (NP step/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'logistic regression', 'add penalty', 'proportional norm ||w||2', 'vector w order prevent weights', 'high values', 'data', 'step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('logistic', 'logist'), ('regression', 'regress'), (',', ','), ('one', 'one'), ('add', 'add'), ('penalty', 'penalti'), ('proportional', 'proport'), ('norm', 'norm'), ('||w||2', '||w||2'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('order', 'order'), ('prevent', 'prevent'), ('weights', 'weight'), ('assume', 'assum'), ('excessively', 'excess'), ('high', 'high'), ('values', 'valu'), ('fitting', 'fit'), ('data', 'data'), ('learning', 'learn'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('logistic', 'logist'), ('regression', 'regress'), (',', ','), ('one', 'one'), ('add', 'add'), ('penalty', 'penalti'), ('proportional', 'proport'), ('norm', 'norm'), ('||w||2', '||w||2'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('order', 'order'), ('prevent', 'prevent'), ('weights', 'weight'), ('assume', 'assum'), ('excessively', 'excess'), ('high', 'high'), ('values', 'valu'), ('fitting', 'fit'), ('data', 'data'), ('learning', 'learn'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('logistic', 'logistic'), ('regression', 'regression'), (',', ','), ('one', 'one'), ('add', 'add'), ('penalty', 'penalty'), ('proportional', 'proportional'), ('norm', 'norm'), ('||w||2', '||w||2'), ('weight', 'weight'), ('vector', 'vector'), ('w', 'w'), ('order', 'order'), ('prevent', 'prevent'), ('weights', 'weight'), ('assume', 'assume'), ('excessively', 'excessively'), ('high', 'high'), ('values', 'value'), ('fitting', 'fitting'), ('data', 'data'), ('learning', 'learning'), ('step', 'step'), ('.', '.')]



============================ Sentence 281 =============================

F. Model Selection  We now discuss the first, key, step of model selection, which defines the inductive bias adopted in the learning process. 


>> Tokens are: 
 ['F.', 'Model', 'Selection', 'We', 'discuss', 'first', ',', 'key', ',', 'step', 'model', 'selection', ',', 'defines', 'inductive', 'bias', 'adopted', 'learning', 'process', '.']

>> Bigrams are: 
 [('F.', 'Model'), ('Model', 'Selection'), ('Selection', 'We'), ('We', 'discuss'), ('discuss', 'first'), ('first', ','), (',', 'key'), ('key', ','), (',', 'step'), ('step', 'model'), ('model', 'selection'), ('selection', ','), (',', 'defines'), ('defines', 'inductive'), ('inductive', 'bias'), ('bias', 'adopted'), ('adopted', 'learning'), ('learning', 'process'), ('process', '.')]

>> Trigrams are: 
 [('F.', 'Model', 'Selection'), ('Model', 'Selection', 'We'), ('Selection', 'We', 'discuss'), ('We', 'discuss', 'first'), ('discuss', 'first', ','), ('first', ',', 'key'), (',', 'key', ','), ('key', ',', 'step'), (',', 'step', 'model'), ('step', 'model', 'selection'), ('model', 'selection', ','), ('selection', ',', 'defines'), (',', 'defines', 'inductive'), ('defines', 'inductive', 'bias'), ('inductive', 'bias', 'adopted'), ('bias', 'adopted', 'learning'), ('adopted', 'learning', 'process'), ('learning', 'process', '.')]

>> POS Tags are: 
 [('F.', 'NNP'), ('Model', 'NNP'), ('Selection', 'NNP'), ('We', 'PRP'), ('discuss', 'VBP'), ('first', 'RB'), (',', ','), ('key', 'NN'), (',', ','), ('step', 'VB'), ('model', 'NN'), ('selection', 'NN'), (',', ','), ('defines', 'NNS'), ('inductive', 'VBP'), ('bias', 'NN'), ('adopted', 'VBN'), ('learning', 'JJ'), ('process', 'NN'), ('.', '.')]

 (S
  (NP F./NNP Model/NNP Selection/NNP)
  We/PRP
  discuss/VBP
  first/RB
  ,/,
  (NP key/NN)
  ,/,
  step/VB
  (NP model/NN selection/NN)
  ,/,
  (NP defines/NNS)
  inductive/VBP
  (NP bias/NN)
  adopted/VBN
  (NP learning/JJ process/NN)
  ./.) 


>> Noun Phrases are: 
 ['F. Model Selection', 'key', 'model selection', 'defines', 'bias', 'learning process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('F.', 'f.'), ('Model', 'model'), ('Selection', 'select'), ('We', 'we'), ('discuss', 'discuss'), ('first', 'first'), (',', ','), ('key', 'key'), (',', ','), ('step', 'step'), ('model', 'model'), ('selection', 'select'), (',', ','), ('defines', 'defin'), ('inductive', 'induct'), ('bias', 'bia'), ('adopted', 'adopt'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('F.', 'f.'), ('Model', 'model'), ('Selection', 'select'), ('We', 'we'), ('discuss', 'discuss'), ('first', 'first'), (',', ','), ('key', 'key'), (',', ','), ('step', 'step'), ('model', 'model'), ('selection', 'select'), (',', ','), ('defines', 'defin'), ('inductive', 'induct'), ('bias', 'bias'), ('adopted', 'adopt'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('F.', 'F.'), ('Model', 'Model'), ('Selection', 'Selection'), ('We', 'We'), ('discuss', 'discus'), ('first', 'first'), (',', ','), ('key', 'key'), (',', ','), ('step', 'step'), ('model', 'model'), ('selection', 'selection'), (',', ','), ('defines', 'defines'), ('inductive', 'inductive'), ('bias', 'bias'), ('adopted', 'adopted'), ('learning', 'learning'), ('process', 'process'), ('.', '.')]



============================ Sentence 282 =============================

In order to illustrate the main ideas, here we study a particular aspect of model selection, namely that of model order selection. 


>> Tokens are: 
 ['In', 'order', 'illustrate', 'main', 'ideas', ',', 'study', 'particular', 'aspect', 'model', 'selection', ',', 'namely', 'model', 'order', 'selection', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'illustrate'), ('illustrate', 'main'), ('main', 'ideas'), ('ideas', ','), (',', 'study'), ('study', 'particular'), ('particular', 'aspect'), ('aspect', 'model'), ('model', 'selection'), ('selection', ','), (',', 'namely'), ('namely', 'model'), ('model', 'order'), ('order', 'selection'), ('selection', '.')]

>> Trigrams are: 
 [('In', 'order', 'illustrate'), ('order', 'illustrate', 'main'), ('illustrate', 'main', 'ideas'), ('main', 'ideas', ','), ('ideas', ',', 'study'), (',', 'study', 'particular'), ('study', 'particular', 'aspect'), ('particular', 'aspect', 'model'), ('aspect', 'model', 'selection'), ('model', 'selection', ','), ('selection', ',', 'namely'), (',', 'namely', 'model'), ('namely', 'model', 'order'), ('model', 'order', 'selection'), ('order', 'selection', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('illustrate', 'NN'), ('main', 'JJ'), ('ideas', 'NNS'), (',', ','), ('study', 'NN'), ('particular', 'JJ'), ('aspect', 'NN'), ('model', 'NN'), ('selection', 'NN'), (',', ','), ('namely', 'RB'), ('model', 'JJ'), ('order', 'NN'), ('selection', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP order/NN illustrate/NN)
  (NP main/JJ ideas/NNS)
  ,/,
  (NP study/NN)
  (NP particular/JJ aspect/NN model/NN selection/NN)
  ,/,
  namely/RB
  (NP model/JJ order/NN selection/NN)
  ./.) 


>> Noun Phrases are: 
 ['order illustrate', 'main ideas', 'study', 'particular aspect model selection', 'model order selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('illustrate', 'illustr'), ('main', 'main'), ('ideas', 'idea'), (',', ','), ('study', 'studi'), ('particular', 'particular'), ('aspect', 'aspect'), ('model', 'model'), ('selection', 'select'), (',', ','), ('namely', 'name'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('illustrate', 'illustr'), ('main', 'main'), ('ideas', 'idea'), (',', ','), ('study', 'studi'), ('particular', 'particular'), ('aspect', 'aspect'), ('model', 'model'), ('selection', 'select'), (',', ','), ('namely', 'name'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('illustrate', 'illustrate'), ('main', 'main'), ('ideas', 'idea'), (',', ','), ('study', 'study'), ('particular', 'particular'), ('aspect', 'aspect'), ('model', 'model'), ('selection', 'selection'), (',', ','), ('namely', 'namely'), ('model', 'model'), ('order', 'order'), ('selection', 'selection'), ('.', '.')]



============================ Sentence 283 =============================

To this end, we consider a hierarchical set of models of increasing complexity and we address the problem of selecting (in Step 1) the order, or the complexity, of the specific model to be posited for learning (in Step 2). 


>> Tokens are: 
 ['To', 'end', ',', 'consider', 'hierarchical', 'set', 'models', 'increasing', 'complexity', 'address', 'problem', 'selecting', '(', 'Step', '1', ')', 'order', ',', 'complexity', ',', 'specific', 'model', 'posited', 'learning', '(', 'Step', '2', ')', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'consider'), ('consider', 'hierarchical'), ('hierarchical', 'set'), ('set', 'models'), ('models', 'increasing'), ('increasing', 'complexity'), ('complexity', 'address'), ('address', 'problem'), ('problem', 'selecting'), ('selecting', '('), ('(', 'Step'), ('Step', '1'), ('1', ')'), (')', 'order'), ('order', ','), (',', 'complexity'), ('complexity', ','), (',', 'specific'), ('specific', 'model'), ('model', 'posited'), ('posited', 'learning'), ('learning', '('), ('(', 'Step'), ('Step', '2'), ('2', ')'), (')', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'consider'), (',', 'consider', 'hierarchical'), ('consider', 'hierarchical', 'set'), ('hierarchical', 'set', 'models'), ('set', 'models', 'increasing'), ('models', 'increasing', 'complexity'), ('increasing', 'complexity', 'address'), ('complexity', 'address', 'problem'), ('address', 'problem', 'selecting'), ('problem', 'selecting', '('), ('selecting', '(', 'Step'), ('(', 'Step', '1'), ('Step', '1', ')'), ('1', ')', 'order'), (')', 'order', ','), ('order', ',', 'complexity'), (',', 'complexity', ','), ('complexity', ',', 'specific'), (',', 'specific', 'model'), ('specific', 'model', 'posited'), ('model', 'posited', 'learning'), ('posited', 'learning', '('), ('learning', '(', 'Step'), ('(', 'Step', '2'), ('Step', '2', ')'), ('2', ')', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('consider', 'VB'), ('hierarchical', 'JJ'), ('set', 'NN'), ('models', 'NNS'), ('increasing', 'VBG'), ('complexity', 'NN'), ('address', 'NN'), ('problem', 'NN'), ('selecting', 'NN'), ('(', '('), ('Step', 'NNP'), ('1', 'CD'), (')', ')'), ('order', 'NN'), (',', ','), ('complexity', 'NN'), (',', ','), ('specific', 'JJ'), ('model', 'NN'), ('posited', 'VBD'), ('learning', 'NN'), ('(', '('), ('Step', 'NNP'), ('2', 'CD'), (')', ')'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  consider/VB
  (NP hierarchical/JJ set/NN models/NNS)
  increasing/VBG
  (NP complexity/NN address/NN problem/NN selecting/NN)
  (/(
  (NP Step/NNP)
  1/CD
  )/)
  (NP order/NN)
  ,/,
  (NP complexity/NN)
  ,/,
  (NP specific/JJ model/NN)
  posited/VBD
  (NP learning/NN)
  (/(
  (NP Step/NNP)
  2/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['hierarchical set models', 'complexity address problem selecting', 'Step', 'order', 'complexity', 'specific model', 'learning', 'Step']

>> Named Entities are: 
 [('ORGANIZATION', 'Step'), ('ORGANIZATION', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('consider', 'consid'), ('hierarchical', 'hierarch'), ('set', 'set'), ('models', 'model'), ('increasing', 'increas'), ('complexity', 'complex'), ('address', 'address'), ('problem', 'problem'), ('selecting', 'select'), ('(', '('), ('Step', 'step'), ('1', '1'), (')', ')'), ('order', 'order'), (',', ','), ('complexity', 'complex'), (',', ','), ('specific', 'specif'), ('model', 'model'), ('posited', 'posit'), ('learning', 'learn'), ('(', '('), ('Step', 'step'), ('2', '2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('consider', 'consid'), ('hierarchical', 'hierarch'), ('set', 'set'), ('models', 'model'), ('increasing', 'increas'), ('complexity', 'complex'), ('address', 'address'), ('problem', 'problem'), ('selecting', 'select'), ('(', '('), ('Step', 'step'), ('1', '1'), (')', ')'), ('order', 'order'), (',', ','), ('complexity', 'complex'), (',', ','), ('specific', 'specif'), ('model', 'model'), ('posited', 'posit'), ('learning', 'learn'), ('(', '('), ('Step', 'step'), ('2', '2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('consider', 'consider'), ('hierarchical', 'hierarchical'), ('set', 'set'), ('models', 'model'), ('increasing', 'increasing'), ('complexity', 'complexity'), ('address', 'address'), ('problem', 'problem'), ('selecting', 'selecting'), ('(', '('), ('Step', 'Step'), ('1', '1'), (')', ')'), ('order', 'order'), (',', ','), ('complexity', 'complexity'), (',', ','), ('specific', 'specific'), ('model', 'model'), ('posited', 'posited'), ('learning', 'learning'), ('(', '('), ('Step', 'Step'), ('2', '2'), (')', ')'), ('.', '.')]



============================ Sentence 284 =============================

As an example of model order selection, one may fix a set of models including multi- layer networks of varying number of intermediate layers and focus on determining the number of layers. 


>> Tokens are: 
 ['As', 'example', 'model', 'order', 'selection', ',', 'one', 'may', 'fix', 'set', 'models', 'including', 'multi-', 'layer', 'networks', 'varying', 'number', 'intermediate', 'layers', 'focus', 'determining', 'number', 'layers', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', 'model'), ('model', 'order'), ('order', 'selection'), ('selection', ','), (',', 'one'), ('one', 'may'), ('may', 'fix'), ('fix', 'set'), ('set', 'models'), ('models', 'including'), ('including', 'multi-'), ('multi-', 'layer'), ('layer', 'networks'), ('networks', 'varying'), ('varying', 'number'), ('number', 'intermediate'), ('intermediate', 'layers'), ('layers', 'focus'), ('focus', 'determining'), ('determining', 'number'), ('number', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('As', 'example', 'model'), ('example', 'model', 'order'), ('model', 'order', 'selection'), ('order', 'selection', ','), ('selection', ',', 'one'), (',', 'one', 'may'), ('one', 'may', 'fix'), ('may', 'fix', 'set'), ('fix', 'set', 'models'), ('set', 'models', 'including'), ('models', 'including', 'multi-'), ('including', 'multi-', 'layer'), ('multi-', 'layer', 'networks'), ('layer', 'networks', 'varying'), ('networks', 'varying', 'number'), ('varying', 'number', 'intermediate'), ('number', 'intermediate', 'layers'), ('intermediate', 'layers', 'focus'), ('layers', 'focus', 'determining'), ('focus', 'determining', 'number'), ('determining', 'number', 'layers'), ('number', 'layers', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), ('model', 'NN'), ('order', 'NN'), ('selection', 'NN'), (',', ','), ('one', 'CD'), ('may', 'MD'), ('fix', 'VB'), ('set', 'NN'), ('models', 'NNS'), ('including', 'VBG'), ('multi-', 'JJ'), ('layer', 'NN'), ('networks', 'NNS'), ('varying', 'VBG'), ('number', 'NN'), ('intermediate', 'JJ'), ('layers', 'NNS'), ('focus', 'VBP'), ('determining', 'VBG'), ('number', 'NN'), ('layers', 'NNS'), ('.', '.')]

 (S
  As/IN
  (NP example/NN model/NN order/NN selection/NN)
  ,/,
  one/CD
  may/MD
  fix/VB
  (NP set/NN models/NNS)
  including/VBG
  (NP multi-/JJ layer/NN networks/NNS)
  varying/VBG
  (NP number/NN)
  (NP intermediate/JJ layers/NNS)
  focus/VBP
  determining/VBG
  (NP number/NN layers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['example model order selection', 'set models', 'multi- layer networks', 'number', 'intermediate layers', 'number layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), (',', ','), ('one', 'one'), ('may', 'may'), ('fix', 'fix'), ('set', 'set'), ('models', 'model'), ('including', 'includ'), ('multi-', 'multi-'), ('layer', 'layer'), ('networks', 'network'), ('varying', 'vari'), ('number', 'number'), ('intermediate', 'intermedi'), ('layers', 'layer'), ('focus', 'focu'), ('determining', 'determin'), ('number', 'number'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), (',', ','), ('one', 'one'), ('may', 'may'), ('fix', 'fix'), ('set', 'set'), ('models', 'model'), ('including', 'includ'), ('multi-', 'multi-'), ('layer', 'layer'), ('networks', 'network'), ('varying', 'vari'), ('number', 'number'), ('intermediate', 'intermedi'), ('layers', 'layer'), ('focus', 'focus'), ('determining', 'determin'), ('number', 'number'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), ('model', 'model'), ('order', 'order'), ('selection', 'selection'), (',', ','), ('one', 'one'), ('may', 'may'), ('fix', 'fix'), ('set', 'set'), ('models', 'model'), ('including', 'including'), ('multi-', 'multi-'), ('layer', 'layer'), ('networks', 'network'), ('varying', 'varying'), ('number', 'number'), ('intermediate', 'intermediate'), ('layers', 'layer'), ('focus', 'focus'), ('determining', 'determining'), ('number', 'number'), ('layers', 'layer'), ('.', '.')]



============================ Sentence 285 =============================

It is emphasized that the scope of model selection goes much beyond model order selection, including the possible incorporation of domain knowledge and the tuning of the hyperparameters of the learning algorithm. 


>> Tokens are: 
 ['It', 'emphasized', 'scope', 'model', 'selection', 'goes', 'much', 'beyond', 'model', 'order', 'selection', ',', 'including', 'possible', 'incorporation', 'domain', 'knowledge', 'tuning', 'hyperparameters', 'learning', 'algorithm', '.']

>> Bigrams are: 
 [('It', 'emphasized'), ('emphasized', 'scope'), ('scope', 'model'), ('model', 'selection'), ('selection', 'goes'), ('goes', 'much'), ('much', 'beyond'), ('beyond', 'model'), ('model', 'order'), ('order', 'selection'), ('selection', ','), (',', 'including'), ('including', 'possible'), ('possible', 'incorporation'), ('incorporation', 'domain'), ('domain', 'knowledge'), ('knowledge', 'tuning'), ('tuning', 'hyperparameters'), ('hyperparameters', 'learning'), ('learning', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('It', 'emphasized', 'scope'), ('emphasized', 'scope', 'model'), ('scope', 'model', 'selection'), ('model', 'selection', 'goes'), ('selection', 'goes', 'much'), ('goes', 'much', 'beyond'), ('much', 'beyond', 'model'), ('beyond', 'model', 'order'), ('model', 'order', 'selection'), ('order', 'selection', ','), ('selection', ',', 'including'), (',', 'including', 'possible'), ('including', 'possible', 'incorporation'), ('possible', 'incorporation', 'domain'), ('incorporation', 'domain', 'knowledge'), ('domain', 'knowledge', 'tuning'), ('knowledge', 'tuning', 'hyperparameters'), ('tuning', 'hyperparameters', 'learning'), ('hyperparameters', 'learning', 'algorithm'), ('learning', 'algorithm', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('emphasized', 'VBD'), ('scope', 'NN'), ('model', 'NN'), ('selection', 'NN'), ('goes', 'VBZ'), ('much', 'RB'), ('beyond', 'IN'), ('model', 'NN'), ('order', 'NN'), ('selection', 'NN'), (',', ','), ('including', 'VBG'), ('possible', 'JJ'), ('incorporation', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('tuning', 'VBG'), ('hyperparameters', 'NNS'), ('learning', 'VBG'), ('algorithm', 'NN'), ('.', '.')]

 (S
  It/PRP
  emphasized/VBD
  (NP scope/NN model/NN selection/NN)
  goes/VBZ
  much/RB
  beyond/IN
  (NP model/NN order/NN selection/NN)
  ,/,
  including/VBG
  (NP possible/JJ incorporation/NN domain/NN knowledge/NN)
  tuning/VBG
  (NP hyperparameters/NNS)
  learning/VBG
  (NP algorithm/NN)
  ./.) 


>> Noun Phrases are: 
 ['scope model selection', 'model order selection', 'possible incorporation domain knowledge', 'hyperparameters', 'algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('emphasized', 'emphas'), ('scope', 'scope'), ('model', 'model'), ('selection', 'select'), ('goes', 'goe'), ('much', 'much'), ('beyond', 'beyond'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), (',', ','), ('including', 'includ'), ('possible', 'possibl'), ('incorporation', 'incorpor'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('tuning', 'tune'), ('hyperparameters', 'hyperparamet'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('emphasized', 'emphas'), ('scope', 'scope'), ('model', 'model'), ('selection', 'select'), ('goes', 'goe'), ('much', 'much'), ('beyond', 'beyond'), ('model', 'model'), ('order', 'order'), ('selection', 'select'), (',', ','), ('including', 'includ'), ('possible', 'possibl'), ('incorporation', 'incorpor'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('tuning', 'tune'), ('hyperparameters', 'hyperparamet'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('emphasized', 'emphasized'), ('scope', 'scope'), ('model', 'model'), ('selection', 'selection'), ('goes', 'go'), ('much', 'much'), ('beyond', 'beyond'), ('model', 'model'), ('order', 'order'), ('selection', 'selection'), (',', ','), ('including', 'including'), ('possible', 'possible'), ('incorporation', 'incorporation'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('tuning', 'tuning'), ('hyperparameters', 'hyperparameters'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('.', '.')]



============================ Sentence 286 =============================

For concreteness, we focus on the regression problem illustrated in Fig. 


>> Tokens are: 
 ['For', 'concreteness', ',', 'focus', 'regression', 'problem', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('For', 'concreteness'), ('concreteness', ','), (',', 'focus'), ('focus', 'regression'), ('regression', 'problem'), ('problem', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('For', 'concreteness', ','), ('concreteness', ',', 'focus'), (',', 'focus', 'regression'), ('focus', 'regression', 'problem'), ('regression', 'problem', 'illustrated'), ('problem', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('concreteness', 'NN'), (',', ','), ('focus', 'VB'), ('regression', 'NN'), ('problem', 'NN'), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  For/IN
  (NP concreteness/NN)
  ,/,
  focus/VB
  (NP regression/NN problem/NN)
  illustrated/VBD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['concreteness', 'regression problem', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('concreteness', 'concret'), (',', ','), ('focus', 'focu'), ('regression', 'regress'), ('problem', 'problem'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('concreteness', 'concret'), (',', ','), ('focus', 'focus'), ('regression', 'regress'), ('problem', 'problem'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('concreteness', 'concreteness'), (',', ','), ('focus', 'focus'), ('regression', 'regression'), ('problem', 'problem'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 287 =============================

5 and assume a set of discriminative models p(t|x,w) under which the output t is distributed as  M∑ m=0  wmx m +N (0, 1). 


>> Tokens are: 
 ['5', 'assume', 'set', 'discriminative', 'models', 'p', '(', 't|x', ',', 'w', ')', 'output', 'distributed', 'M∑', 'm=0', 'wmx', '+N', '(', '0', ',', '1', ')', '.']

>> Bigrams are: 
 [('5', 'assume'), ('assume', 'set'), ('set', 'discriminative'), ('discriminative', 'models'), ('models', 'p'), ('p', '('), ('(', 't|x'), ('t|x', ','), (',', 'w'), ('w', ')'), (')', 'output'), ('output', 'distributed'), ('distributed', 'M∑'), ('M∑', 'm=0'), ('m=0', 'wmx'), ('wmx', '+N'), ('+N', '('), ('(', '0'), ('0', ','), (',', '1'), ('1', ')'), (')', '.')]

>> Trigrams are: 
 [('5', 'assume', 'set'), ('assume', 'set', 'discriminative'), ('set', 'discriminative', 'models'), ('discriminative', 'models', 'p'), ('models', 'p', '('), ('p', '(', 't|x'), ('(', 't|x', ','), ('t|x', ',', 'w'), (',', 'w', ')'), ('w', ')', 'output'), (')', 'output', 'distributed'), ('output', 'distributed', 'M∑'), ('distributed', 'M∑', 'm=0'), ('M∑', 'm=0', 'wmx'), ('m=0', 'wmx', '+N'), ('wmx', '+N', '('), ('+N', '(', '0'), ('(', '0', ','), ('0', ',', '1'), (',', '1', ')'), ('1', ')', '.')]

>> POS Tags are: 
 [('5', 'CD'), ('assume', 'JJ'), ('set', 'VBN'), ('discriminative', 'JJ'), ('models', 'NNS'), ('p', 'VBP'), ('(', '('), ('t|x', 'NN'), (',', ','), ('w', 'NN'), (')', ')'), ('output', 'NN'), ('distributed', 'VBN'), ('M∑', 'NNP'), ('m=0', 'FW'), ('wmx', 'NN'), ('+N', 'NNP'), ('(', '('), ('0', 'CD'), (',', ','), ('1', 'CD'), (')', ')'), ('.', '.')]

 (S
  5/CD
  assume/JJ
  set/VBN
  (NP discriminative/JJ models/NNS)
  p/VBP
  (/(
  (NP t|x/NN)
  ,/,
  (NP w/NN)
  )/)
  (NP output/NN)
  distributed/VBN
  (NP M∑/NNP)
  m=0/FW
  (NP wmx/NN +N/NNP)
  (/(
  0/CD
  ,/,
  1/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['discriminative models', 't|x', 'w', 'output', 'M∑', 'wmx +N']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('assume', 'assum'), ('set', 'set'), ('discriminative', 'discrimin'), ('models', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('output', 'output'), ('distributed', 'distribut'), ('M∑', 'm∑'), ('m=0', 'm=0'), ('wmx', 'wmx'), ('+N', '+n'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('assume', 'assum'), ('set', 'set'), ('discriminative', 'discrimin'), ('models', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('output', 'output'), ('distributed', 'distribut'), ('M∑', 'm∑'), ('m=0', 'm=0'), ('wmx', 'wmx'), ('+N', '+n'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('assume', 'assume'), ('set', 'set'), ('discriminative', 'discriminative'), ('models', 'model'), ('p', 'p'), ('(', '('), ('t|x', 't|x'), (',', ','), ('w', 'w'), (')', ')'), ('output', 'output'), ('distributed', 'distributed'), ('M∑', 'M∑'), ('m=0', 'm=0'), ('wmx', 'wmx'), ('+N', '+N'), ('(', '('), ('0', '0'), (',', ','), ('1', '1'), (')', ')'), ('.', '.')]



============================ Sentence 288 =============================

(11)  9    0 0.2 0.4 0.6 0.8 1 -3  -2  -1  0  1  2  3  = 9M  M= 1  M= 3  Fig. 


>> Tokens are: 
 ['(', '11', ')', '9', '0', '0.2', '0.4', '0.6', '0.8', '1', '-3', '-2', '-1', '0', '1', '2', '3', '=', '9M', 'M=', '1', 'M=', '3', 'Fig', '.']

>> Bigrams are: 
 [('(', '11'), ('11', ')'), (')', '9'), ('9', '0'), ('0', '0.2'), ('0.2', '0.4'), ('0.4', '0.6'), ('0.6', '0.8'), ('0.8', '1'), ('1', '-3'), ('-3', '-2'), ('-2', '-1'), ('-1', '0'), ('0', '1'), ('1', '2'), ('2', '3'), ('3', '='), ('=', '9M'), ('9M', 'M='), ('M=', '1'), ('1', 'M='), ('M=', '3'), ('3', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('(', '11', ')'), ('11', ')', '9'), (')', '9', '0'), ('9', '0', '0.2'), ('0', '0.2', '0.4'), ('0.2', '0.4', '0.6'), ('0.4', '0.6', '0.8'), ('0.6', '0.8', '1'), ('0.8', '1', '-3'), ('1', '-3', '-2'), ('-3', '-2', '-1'), ('-2', '-1', '0'), ('-1', '0', '1'), ('0', '1', '2'), ('1', '2', '3'), ('2', '3', '='), ('3', '=', '9M'), ('=', '9M', 'M='), ('9M', 'M=', '1'), ('M=', '1', 'M='), ('1', 'M=', '3'), ('M=', '3', 'Fig'), ('3', 'Fig', '.')]

>> POS Tags are: 
 [('(', '('), ('11', 'CD'), (')', ')'), ('9', 'CD'), ('0', 'CD'), ('0.2', 'CD'), ('0.4', 'CD'), ('0.6', 'CD'), ('0.8', 'CD'), ('1', 'CD'), ('-3', 'NN'), ('-2', 'NNP'), ('-1', 'VBD'), ('0', 'CD'), ('1', 'CD'), ('2', 'CD'), ('3', 'CD'), ('=', 'JJ'), ('9M', 'CD'), ('M=', 'NNP'), ('1', 'CD'), ('M=', 'NNP'), ('3', 'CD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (/(
  11/CD
  )/)
  9/CD
  0/CD
  0.2/CD
  0.4/CD
  0.6/CD
  0.8/CD
  1/CD
  (NP -3/NN -2/NNP)
  -1/VBD
  0/CD
  1/CD
  2/CD
  3/CD
  =/JJ
  9M/CD
  (NP M=/NNP)
  1/CD
  (NP M=/NNP)
  3/CD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['-3 -2', 'M=', 'M=', 'Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('11', '11'), (')', ')'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('=', '='), ('9M', '9m'), ('M=', 'm='), ('1', '1'), ('M=', 'm='), ('3', '3'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('11', '11'), (')', ')'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('=', '='), ('9M', '9m'), ('M=', 'm='), ('1', '1'), ('M=', 'm='), ('3', '3'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('11', '11'), (')', ')'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('=', '='), ('9M', '9M'), ('M=', 'M='), ('1', '1'), ('M=', 'M='), ('3', '3'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 289 =============================

9. 


>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

 (S 9/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]



============================ Sentence 290 =============================

Training set in Fig. 


>> Tokens are: 
 ['Training', 'set', 'Fig', '.']

>> Bigrams are: 
 [('Training', 'set'), ('set', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Training', 'set', 'Fig'), ('set', 'Fig', '.')]

>> POS Tags are: 
 [('Training', 'NN'), ('set', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S (NP Training/NN) set/VBN (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Training', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('set', 'set'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('set', 'set'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Training', 'Training'), ('set', 'set'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 291 =============================

5, along with a predictor trained by using the discriminative model (11) and ML for different values of the model order M . 


>> Tokens are: 
 ['5', ',', 'along', 'predictor', 'trained', 'using', 'discriminative', 'model', '(', '11', ')', 'ML', 'different', 'values', 'model', 'order', 'M', '.']

>> Bigrams are: 
 [('5', ','), (',', 'along'), ('along', 'predictor'), ('predictor', 'trained'), ('trained', 'using'), ('using', 'discriminative'), ('discriminative', 'model'), ('model', '('), ('(', '11'), ('11', ')'), (')', 'ML'), ('ML', 'different'), ('different', 'values'), ('values', 'model'), ('model', 'order'), ('order', 'M'), ('M', '.')]

>> Trigrams are: 
 [('5', ',', 'along'), (',', 'along', 'predictor'), ('along', 'predictor', 'trained'), ('predictor', 'trained', 'using'), ('trained', 'using', 'discriminative'), ('using', 'discriminative', 'model'), ('discriminative', 'model', '('), ('model', '(', '11'), ('(', '11', ')'), ('11', ')', 'ML'), (')', 'ML', 'different'), ('ML', 'different', 'values'), ('different', 'values', 'model'), ('values', 'model', 'order'), ('model', 'order', 'M'), ('order', 'M', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('along', 'IN'), ('predictor', 'NN'), ('trained', 'VBD'), ('using', 'VBG'), ('discriminative', 'JJ'), ('model', 'NN'), ('(', '('), ('11', 'CD'), (')', ')'), ('ML', 'NNP'), ('different', 'JJ'), ('values', 'NNS'), ('model', 'FW'), ('order', 'NN'), ('M', 'NNP'), ('.', '.')]

 (S
  5/CD
  ,/,
  along/IN
  (NP predictor/NN)
  trained/VBD
  using/VBG
  (NP discriminative/JJ model/NN)
  (/(
  11/CD
  )/)
  (NP ML/NNP)
  (NP different/JJ values/NNS)
  model/FW
  (NP order/NN M/NNP)
  ./.) 


>> Noun Phrases are: 
 ['predictor', 'discriminative model', 'ML', 'different values', 'order M']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('along', 'along'), ('predictor', 'predictor'), ('trained', 'train'), ('using', 'use'), ('discriminative', 'discrimin'), ('model', 'model'), ('(', '('), ('11', '11'), (')', ')'), ('ML', 'ml'), ('different', 'differ'), ('values', 'valu'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('along', 'along'), ('predictor', 'predictor'), ('trained', 'train'), ('using', 'use'), ('discriminative', 'discrimin'), ('model', 'model'), ('(', '('), ('11', '11'), (')', ')'), ('ML', 'ml'), ('different', 'differ'), ('values', 'valu'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('along', 'along'), ('predictor', 'predictor'), ('trained', 'trained'), ('using', 'using'), ('discriminative', 'discriminative'), ('model', 'model'), ('(', '('), ('11', '11'), (')', ')'), ('ML', 'ML'), ('different', 'different'), ('values', 'value'), ('model', 'model'), ('order', 'order'), ('M', 'M'), ('.', '.')]



============================ Sentence 292 =============================

In words, the output t is given by a polynomial function of order M of the input x plus zero-mean Gaussian noise of power equal to one. 


>> Tokens are: 
 ['In', 'words', ',', 'output', 'given', 'polynomial', 'function', 'order', 'M', 'input', 'x', 'plus', 'zero-mean', 'Gaussian', 'noise', 'power', 'equal', 'one', '.']

>> Bigrams are: 
 [('In', 'words'), ('words', ','), (',', 'output'), ('output', 'given'), ('given', 'polynomial'), ('polynomial', 'function'), ('function', 'order'), ('order', 'M'), ('M', 'input'), ('input', 'x'), ('x', 'plus'), ('plus', 'zero-mean'), ('zero-mean', 'Gaussian'), ('Gaussian', 'noise'), ('noise', 'power'), ('power', 'equal'), ('equal', 'one'), ('one', '.')]

>> Trigrams are: 
 [('In', 'words', ','), ('words', ',', 'output'), (',', 'output', 'given'), ('output', 'given', 'polynomial'), ('given', 'polynomial', 'function'), ('polynomial', 'function', 'order'), ('function', 'order', 'M'), ('order', 'M', 'input'), ('M', 'input', 'x'), ('input', 'x', 'plus'), ('x', 'plus', 'zero-mean'), ('plus', 'zero-mean', 'Gaussian'), ('zero-mean', 'Gaussian', 'noise'), ('Gaussian', 'noise', 'power'), ('noise', 'power', 'equal'), ('power', 'equal', 'one'), ('equal', 'one', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('words', 'NNS'), (',', ','), ('output', 'NN'), ('given', 'VBN'), ('polynomial', 'JJ'), ('function', 'NN'), ('order', 'NN'), ('M', 'NNP'), ('input', 'NN'), ('x', 'NNP'), ('plus', 'CC'), ('zero-mean', 'JJ'), ('Gaussian', 'NNP'), ('noise', 'NN'), ('power', 'NN'), ('equal', 'JJ'), ('one', 'CD'), ('.', '.')]

 (S
  In/IN
  (NP words/NNS)
  ,/,
  (NP output/NN)
  given/VBN
  (NP polynomial/JJ function/NN order/NN M/NNP input/NN x/NNP)
  plus/CC
  (NP zero-mean/JJ Gaussian/NNP noise/NN power/NN)
  equal/JJ
  one/CD
  ./.) 


>> Noun Phrases are: 
 ['words', 'output', 'polynomial function order M input x', 'zero-mean Gaussian noise power']

>> Named Entities are: 
 [('GPE', 'Gaussian')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('output', 'output'), ('given', 'given'), ('polynomial', 'polynomi'), ('function', 'function'), ('order', 'order'), ('M', 'm'), ('input', 'input'), ('x', 'x'), ('plus', 'plu'), ('zero-mean', 'zero-mean'), ('Gaussian', 'gaussian'), ('noise', 'nois'), ('power', 'power'), ('equal', 'equal'), ('one', 'one'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('output', 'output'), ('given', 'given'), ('polynomial', 'polynomi'), ('function', 'function'), ('order', 'order'), ('M', 'm'), ('input', 'input'), ('x', 'x'), ('plus', 'plus'), ('zero-mean', 'zero-mean'), ('Gaussian', 'gaussian'), ('noise', 'nois'), ('power', 'power'), ('equal', 'equal'), ('one', 'one'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('words', 'word'), (',', ','), ('output', 'output'), ('given', 'given'), ('polynomial', 'polynomial'), ('function', 'function'), ('order', 'order'), ('M', 'M'), ('input', 'input'), ('x', 'x'), ('plus', 'plus'), ('zero-mean', 'zero-mean'), ('Gaussian', 'Gaussian'), ('noise', 'noise'), ('power', 'power'), ('equal', 'equal'), ('one', 'one'), ('.', '.')]



============================ Sentence 293 =============================

The learnable parameter vector θ is given by the weights w = [w0, ..., wM−1]T . 


>> Tokens are: 
 ['The', 'learnable', 'parameter', 'vector', 'θ', 'given', 'weights', 'w', '=', '[', 'w0', ',', '...', ',', 'wM−1', ']', 'T', '.']

>> Bigrams are: 
 [('The', 'learnable'), ('learnable', 'parameter'), ('parameter', 'vector'), ('vector', 'θ'), ('θ', 'given'), ('given', 'weights'), ('weights', 'w'), ('w', '='), ('=', '['), ('[', 'w0'), ('w0', ','), (',', '...'), ('...', ','), (',', 'wM−1'), ('wM−1', ']'), (']', 'T'), ('T', '.')]

>> Trigrams are: 
 [('The', 'learnable', 'parameter'), ('learnable', 'parameter', 'vector'), ('parameter', 'vector', 'θ'), ('vector', 'θ', 'given'), ('θ', 'given', 'weights'), ('given', 'weights', 'w'), ('weights', 'w', '='), ('w', '=', '['), ('=', '[', 'w0'), ('[', 'w0', ','), ('w0', ',', '...'), (',', '...', ','), ('...', ',', 'wM−1'), (',', 'wM−1', ']'), ('wM−1', ']', 'T'), (']', 'T', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learnable', 'JJ'), ('parameter', 'NN'), ('vector', 'NN'), ('θ', 'NNP'), ('given', 'VBN'), ('weights', 'NNS'), ('w', 'VBP'), ('=', 'JJ'), ('[', 'NNP'), ('w0', 'NN'), (',', ','), ('...', ':'), (',', ','), ('wM−1', 'JJ'), (']', 'NNP'), ('T', 'NNP'), ('.', '.')]

 (S
  (NP The/DT learnable/JJ parameter/NN vector/NN θ/NNP)
  given/VBN
  (NP weights/NNS)
  w/VBP
  (NP =/JJ [/NNP w0/NN)
  ,/,
  .../:
  ,/,
  (NP wM−1/JJ ]/NNP T/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The learnable parameter vector θ', 'weights', '= [ w0', 'wM−1 ] T']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('given', 'given'), ('weights', 'weight'), ('w', 'w'), ('=', '='), ('[', '['), ('w0', 'w0'), (',', ','), ('...', '...'), (',', ','), ('wM−1', 'wm−1'), (']', ']'), ('T', 't'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learnable', 'learnabl'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('given', 'given'), ('weights', 'weight'), ('w', 'w'), ('=', '='), ('[', '['), ('w0', 'w0'), (',', ','), ('...', '...'), (',', ','), ('wM−1', 'wm−1'), (']', ']'), ('T', 't'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learnable', 'learnable'), ('parameter', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('given', 'given'), ('weights', 'weight'), ('w', 'w'), ('=', '='), ('[', '['), ('w0', 'w0'), (',', ','), ('...', '...'), (',', ','), ('wM−1', 'wM−1'), (']', ']'), ('T', 'T'), ('.', '.')]



============================ Sentence 294 =============================

Model selection, to be carried out in Step 1, amounts to the choice of the model order M . 


>> Tokens are: 
 ['Model', 'selection', ',', 'carried', 'Step', '1', ',', 'amounts', 'choice', 'model', 'order', 'M', '.']

>> Bigrams are: 
 [('Model', 'selection'), ('selection', ','), (',', 'carried'), ('carried', 'Step'), ('Step', '1'), ('1', ','), (',', 'amounts'), ('amounts', 'choice'), ('choice', 'model'), ('model', 'order'), ('order', 'M'), ('M', '.')]

>> Trigrams are: 
 [('Model', 'selection', ','), ('selection', ',', 'carried'), (',', 'carried', 'Step'), ('carried', 'Step', '1'), ('Step', '1', ','), ('1', ',', 'amounts'), (',', 'amounts', 'choice'), ('amounts', 'choice', 'model'), ('choice', 'model', 'order'), ('model', 'order', 'M'), ('order', 'M', '.')]

>> POS Tags are: 
 [('Model', 'NNP'), ('selection', 'NN'), (',', ','), ('carried', 'VBD'), ('Step', 'NNP'), ('1', 'CD'), (',', ','), ('amounts', 'NNS'), ('choice', 'NN'), ('model', 'NN'), ('order', 'NN'), ('M', 'NNP'), ('.', '.')]

 (S
  (NP Model/NNP selection/NN)
  ,/,
  carried/VBD
  (NP Step/NNP)
  1/CD
  ,/,
  (NP amounts/NNS choice/NN model/NN order/NN M/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Model selection', 'Step', 'amounts choice model order M']

>> Named Entities are: 
 [('GPE', 'Model'), ('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('Model', 'model'), ('selection', 'select'), (',', ','), ('carried', 'carri'), ('Step', 'step'), ('1', '1'), (',', ','), ('amounts', 'amount'), ('choice', 'choic'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Model', 'model'), ('selection', 'select'), (',', ','), ('carried', 'carri'), ('Step', 'step'), ('1', '1'), (',', ','), ('amounts', 'amount'), ('choice', 'choic'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('.', '.')]

>> Lemmatization: 
 [('Model', 'Model'), ('selection', 'selection'), (',', ','), ('carried', 'carried'), ('Step', 'Step'), ('1', '1'), (',', ','), ('amounts', 'amount'), ('choice', 'choice'), ('model', 'model'), ('order', 'order'), ('M', 'M'), ('.', '.')]



============================ Sentence 295 =============================

Having chosen M in Step 1, the weights w can be learned in Step 2 using ML, and then the optimal pre- dictor can be obtained for inference in Step 3. 


>> Tokens are: 
 ['Having', 'chosen', 'M', 'Step', '1', ',', 'weights', 'w', 'learned', 'Step', '2', 'using', 'ML', ',', 'optimal', 'pre-', 'dictor', 'obtained', 'inference', 'Step', '3', '.']

>> Bigrams are: 
 [('Having', 'chosen'), ('chosen', 'M'), ('M', 'Step'), ('Step', '1'), ('1', ','), (',', 'weights'), ('weights', 'w'), ('w', 'learned'), ('learned', 'Step'), ('Step', '2'), ('2', 'using'), ('using', 'ML'), ('ML', ','), (',', 'optimal'), ('optimal', 'pre-'), ('pre-', 'dictor'), ('dictor', 'obtained'), ('obtained', 'inference'), ('inference', 'Step'), ('Step', '3'), ('3', '.')]

>> Trigrams are: 
 [('Having', 'chosen', 'M'), ('chosen', 'M', 'Step'), ('M', 'Step', '1'), ('Step', '1', ','), ('1', ',', 'weights'), (',', 'weights', 'w'), ('weights', 'w', 'learned'), ('w', 'learned', 'Step'), ('learned', 'Step', '2'), ('Step', '2', 'using'), ('2', 'using', 'ML'), ('using', 'ML', ','), ('ML', ',', 'optimal'), (',', 'optimal', 'pre-'), ('optimal', 'pre-', 'dictor'), ('pre-', 'dictor', 'obtained'), ('dictor', 'obtained', 'inference'), ('obtained', 'inference', 'Step'), ('inference', 'Step', '3'), ('Step', '3', '.')]

>> POS Tags are: 
 [('Having', 'VBG'), ('chosen', 'VBN'), ('M', 'NNP'), ('Step', 'NNP'), ('1', 'CD'), (',', ','), ('weights', 'NNS'), ('w', 'VBP'), ('learned', 'JJ'), ('Step', 'NNP'), ('2', 'CD'), ('using', 'VBG'), ('ML', 'NNP'), (',', ','), ('optimal', 'JJ'), ('pre-', 'JJ'), ('dictor', 'NN'), ('obtained', 'VBD'), ('inference', 'JJ'), ('Step', 'NNP'), ('3', 'CD'), ('.', '.')]

 (S
  Having/VBG
  chosen/VBN
  (NP M/NNP Step/NNP)
  1/CD
  ,/,
  (NP weights/NNS)
  w/VBP
  (NP learned/JJ Step/NNP)
  2/CD
  using/VBG
  (NP ML/NNP)
  ,/,
  (NP optimal/JJ pre-/JJ dictor/NN)
  obtained/VBD
  (NP inference/JJ Step/NNP)
  3/CD
  ./.) 


>> Noun Phrases are: 
 ['M Step', 'weights', 'learned Step', 'ML', 'optimal pre- dictor', 'inference Step']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('Having', 'have'), ('chosen', 'chosen'), ('M', 'm'), ('Step', 'step'), ('1', '1'), (',', ','), ('weights', 'weight'), ('w', 'w'), ('learned', 'learn'), ('Step', 'step'), ('2', '2'), ('using', 'use'), ('ML', 'ml'), (',', ','), ('optimal', 'optim'), ('pre-', 'pre-'), ('dictor', 'dictor'), ('obtained', 'obtain'), ('inference', 'infer'), ('Step', 'step'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Having', 'have'), ('chosen', 'chosen'), ('M', 'm'), ('Step', 'step'), ('1', '1'), (',', ','), ('weights', 'weight'), ('w', 'w'), ('learned', 'learn'), ('Step', 'step'), ('2', '2'), ('using', 'use'), ('ML', 'ml'), (',', ','), ('optimal', 'optim'), ('pre-', 'pre-'), ('dictor', 'dictor'), ('obtained', 'obtain'), ('inference', 'infer'), ('Step', 'step'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Having', 'Having'), ('chosen', 'chosen'), ('M', 'M'), ('Step', 'Step'), ('1', '1'), (',', ','), ('weights', 'weight'), ('w', 'w'), ('learned', 'learned'), ('Step', 'Step'), ('2', '2'), ('using', 'using'), ('ML', 'ML'), (',', ','), ('optimal', 'optimal'), ('pre-', 'pre-'), ('dictor', 'dictor'), ('obtained', 'obtained'), ('inference', 'inference'), ('Step', 'Step'), ('3', '3'), ('.', '.')]



============================ Sentence 296 =============================

Assuming the quadratic loss, the optimal predictor is given by the posterior mean t̂(x) =  ∑M m=0wmx  m for the learned parameters w. This predictor is plotted in Fig. 


>> Tokens are: 
 ['Assuming', 'quadratic', 'loss', ',', 'optimal', 'predictor', 'given', 'posterior', 'mean', 't̂', '(', 'x', ')', '=', '∑M', 'm=0wmx', 'learned', 'parameters', 'w.', 'This', 'predictor', 'plotted', 'Fig', '.']

>> Bigrams are: 
 [('Assuming', 'quadratic'), ('quadratic', 'loss'), ('loss', ','), (',', 'optimal'), ('optimal', 'predictor'), ('predictor', 'given'), ('given', 'posterior'), ('posterior', 'mean'), ('mean', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', '∑M'), ('∑M', 'm=0wmx'), ('m=0wmx', 'learned'), ('learned', 'parameters'), ('parameters', 'w.'), ('w.', 'This'), ('This', 'predictor'), ('predictor', 'plotted'), ('plotted', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Assuming', 'quadratic', 'loss'), ('quadratic', 'loss', ','), ('loss', ',', 'optimal'), (',', 'optimal', 'predictor'), ('optimal', 'predictor', 'given'), ('predictor', 'given', 'posterior'), ('given', 'posterior', 'mean'), ('posterior', 'mean', 't̂'), ('mean', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', '∑M'), ('=', '∑M', 'm=0wmx'), ('∑M', 'm=0wmx', 'learned'), ('m=0wmx', 'learned', 'parameters'), ('learned', 'parameters', 'w.'), ('parameters', 'w.', 'This'), ('w.', 'This', 'predictor'), ('This', 'predictor', 'plotted'), ('predictor', 'plotted', 'Fig'), ('plotted', 'Fig', '.')]

>> POS Tags are: 
 [('Assuming', 'VBG'), ('quadratic', 'JJ'), ('loss', 'NN'), (',', ','), ('optimal', 'JJ'), ('predictor', 'NN'), ('given', 'VBN'), ('posterior', 'JJ'), ('mean', 'JJ'), ('t̂', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBP'), ('∑M', 'JJ'), ('m=0wmx', 'NN'), ('learned', 'VBD'), ('parameters', 'NNS'), ('w.', 'VBP'), ('This', 'DT'), ('predictor', 'NN'), ('plotted', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  Assuming/VBG
  (NP quadratic/JJ loss/NN)
  ,/,
  (NP optimal/JJ predictor/NN)
  given/VBN
  (NP posterior/JJ mean/JJ t̂/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBP
  (NP ∑M/JJ m=0wmx/NN)
  learned/VBD
  (NP parameters/NNS)
  w./VBP
  (NP This/DT predictor/NN)
  plotted/VBD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['quadratic loss', 'optimal predictor', 'posterior mean t̂', 'x', '∑M m=0wmx', 'parameters', 'This predictor', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Assuming', 'assum'), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('posterior', 'posterior'), ('mean', 'mean'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('∑M', '∑m'), ('m=0wmx', 'm=0wmx'), ('learned', 'learn'), ('parameters', 'paramet'), ('w.', 'w.'), ('This', 'thi'), ('predictor', 'predictor'), ('plotted', 'plot'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Assuming', 'assum'), ('quadratic', 'quadrat'), ('loss', 'loss'), (',', ','), ('optimal', 'optim'), ('predictor', 'predictor'), ('given', 'given'), ('posterior', 'posterior'), ('mean', 'mean'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('∑M', '∑m'), ('m=0wmx', 'm=0wmx'), ('learned', 'learn'), ('parameters', 'paramet'), ('w.', 'w.'), ('This', 'this'), ('predictor', 'predictor'), ('plotted', 'plot'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Assuming', 'Assuming'), ('quadratic', 'quadratic'), ('loss', 'loss'), (',', ','), ('optimal', 'optimal'), ('predictor', 'predictor'), ('given', 'given'), ('posterior', 'posterior'), ('mean', 'mean'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('∑M', '∑M'), ('m=0wmx', 'm=0wmx'), ('learned', 'learned'), ('parameters', 'parameter'), ('w.', 'w.'), ('This', 'This'), ('predictor', 'predictor'), ('plotted', 'plotted'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 297 =============================

9 for different values of M , along with the training set of Fig. 


>> Tokens are: 
 ['9', 'different', 'values', 'M', ',', 'along', 'training', 'set', 'Fig', '.']

>> Bigrams are: 
 [('9', 'different'), ('different', 'values'), ('values', 'M'), ('M', ','), (',', 'along'), ('along', 'training'), ('training', 'set'), ('set', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('9', 'different', 'values'), ('different', 'values', 'M'), ('values', 'M', ','), ('M', ',', 'along'), (',', 'along', 'training'), ('along', 'training', 'set'), ('training', 'set', 'Fig'), ('set', 'Fig', '.')]

>> POS Tags are: 
 [('9', 'CD'), ('different', 'JJ'), ('values', 'NNS'), ('M', 'NNP'), (',', ','), ('along', 'IN'), ('training', 'NN'), ('set', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  9/CD
  (NP different/JJ values/NNS M/NNP)
  ,/,
  along/IN
  (NP training/NN)
  set/VBN
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['different values M', 'training', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('different', 'differ'), ('values', 'valu'), ('M', 'm'), (',', ','), ('along', 'along'), ('training', 'train'), ('set', 'set'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('different', 'differ'), ('values', 'valu'), ('M', 'm'), (',', ','), ('along', 'along'), ('training', 'train'), ('set', 'set'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('different', 'different'), ('values', 'value'), ('M', 'M'), (',', ','), ('along', 'along'), ('training', 'training'), ('set', 'set'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 298 =============================

5. 


>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

 (S 5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



============================ Sentence 299 =============================

With M = 1, the predictor t̂(x) is seen to underfit the training data. 


>> Tokens are: 
 ['With', 'M', '=', '1', ',', 'predictor', 't̂', '(', 'x', ')', 'seen', 'underfit', 'training', 'data', '.']

>> Bigrams are: 
 [('With', 'M'), ('M', '='), ('=', '1'), ('1', ','), (',', 'predictor'), ('predictor', 't̂'), ('t̂', '('), ('(', 'x'), ('x', ')'), (')', 'seen'), ('seen', 'underfit'), ('underfit', 'training'), ('training', 'data'), ('data', '.')]

>> Trigrams are: 
 [('With', 'M', '='), ('M', '=', '1'), ('=', '1', ','), ('1', ',', 'predictor'), (',', 'predictor', 't̂'), ('predictor', 't̂', '('), ('t̂', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'seen'), (')', 'seen', 'underfit'), ('seen', 'underfit', 'training'), ('underfit', 'training', 'data'), ('training', 'data', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('M', 'NNP'), ('=', 'NNP'), ('1', 'CD'), (',', ','), ('predictor', 'NN'), ('t̂', 'NN'), ('(', '('), ('x', 'NN'), (')', ')'), ('seen', 'VBN'), ('underfit', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  With/IN
  (NP M/NNP =/NNP)
  1/CD
  ,/,
  (NP predictor/NN t̂/NN)
  (/(
  (NP x/NN)
  )/)
  seen/VBN
  (NP underfit/JJ training/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['M =', 'predictor t̂', 'x', 'underfit training data']

>> Named Entities are: 
 [('PERSON', 'M')] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('M', 'm'), ('=', '='), ('1', '1'), (',', ','), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('seen', 'seen'), ('underfit', 'underfit'), ('training', 'train'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('M', 'm'), ('=', '='), ('1', '1'), (',', ','), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('seen', 'seen'), ('underfit', 'underfit'), ('training', 'train'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('M', 'M'), ('=', '='), ('1', '1'), (',', ','), ('predictor', 'predictor'), ('t̂', 't̂'), ('(', '('), ('x', 'x'), (')', ')'), ('seen', 'seen'), ('underfit', 'underfit'), ('training', 'training'), ('data', 'data'), ('.', '.')]



============================ Sentence 300 =============================

This is in the sense that the model is not rich enough to capture the variations present in the training data, and, as a result, we obtain a large training loss  LD(w) = 1  N  N∑ n=1  (tn − t̂(xn))2. 


>> Tokens are: 
 ['This', 'sense', 'model', 'rich', 'enough', 'capture', 'variations', 'present', 'training', 'data', ',', ',', 'result', ',', 'obtain', 'large', 'training', 'loss', 'LD', '(', 'w', ')', '=', '1', 'N', 'N∑', 'n=1', '(', 'tn', '−', 't̂', '(', 'xn', ')', ')', '2', '.']

>> Bigrams are: 
 [('This', 'sense'), ('sense', 'model'), ('model', 'rich'), ('rich', 'enough'), ('enough', 'capture'), ('capture', 'variations'), ('variations', 'present'), ('present', 'training'), ('training', 'data'), ('data', ','), (',', ','), (',', 'result'), ('result', ','), (',', 'obtain'), ('obtain', 'large'), ('large', 'training'), ('training', 'loss'), ('loss', 'LD'), ('LD', '('), ('(', 'w'), ('w', ')'), (')', '='), ('=', '1'), ('1', 'N'), ('N', 'N∑'), ('N∑', 'n=1'), ('n=1', '('), ('(', 'tn'), ('tn', '−'), ('−', 't̂'), ('t̂', '('), ('(', 'xn'), ('xn', ')'), (')', ')'), (')', '2'), ('2', '.')]

>> Trigrams are: 
 [('This', 'sense', 'model'), ('sense', 'model', 'rich'), ('model', 'rich', 'enough'), ('rich', 'enough', 'capture'), ('enough', 'capture', 'variations'), ('capture', 'variations', 'present'), ('variations', 'present', 'training'), ('present', 'training', 'data'), ('training', 'data', ','), ('data', ',', ','), (',', ',', 'result'), (',', 'result', ','), ('result', ',', 'obtain'), (',', 'obtain', 'large'), ('obtain', 'large', 'training'), ('large', 'training', 'loss'), ('training', 'loss', 'LD'), ('loss', 'LD', '('), ('LD', '(', 'w'), ('(', 'w', ')'), ('w', ')', '='), (')', '=', '1'), ('=', '1', 'N'), ('1', 'N', 'N∑'), ('N', 'N∑', 'n=1'), ('N∑', 'n=1', '('), ('n=1', '(', 'tn'), ('(', 'tn', '−'), ('tn', '−', 't̂'), ('−', 't̂', '('), ('t̂', '(', 'xn'), ('(', 'xn', ')'), ('xn', ')', ')'), (')', ')', '2'), (')', '2', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('sense', 'NN'), ('model', 'NN'), ('rich', 'JJ'), ('enough', 'RB'), ('capture', 'NN'), ('variations', 'NNS'), ('present', 'JJ'), ('training', 'VBG'), ('data', 'NNS'), (',', ','), (',', ','), ('result', 'NN'), (',', ','), ('obtain', 'VB'), ('large', 'JJ'), ('training', 'NN'), ('loss', 'NN'), ('LD', 'NNP'), ('(', '('), ('w', 'NN'), (')', ')'), ('=', 'VBZ'), ('1', 'CD'), ('N', 'NNP'), ('N∑', 'NNP'), ('n=1', 'NN'), ('(', '('), ('tn', 'JJ'), ('−', 'NN'), ('t̂', 'NN'), ('(', '('), ('xn', 'NNP'), (')', ')'), (')', ')'), ('2', 'CD'), ('.', '.')]

 (S
  (NP This/DT sense/NN model/NN)
  rich/JJ
  enough/RB
  (NP capture/NN variations/NNS)
  present/JJ
  training/VBG
  (NP data/NNS)
  ,/,
  ,/,
  (NP result/NN)
  ,/,
  obtain/VB
  (NP large/JJ training/NN loss/NN LD/NNP)
  (/(
  (NP w/NN)
  )/)
  =/VBZ
  1/CD
  (NP N/NNP N∑/NNP n=1/NN)
  (/(
  (NP tn/JJ −/NN t̂/NN)
  (/(
  (NP xn/NNP)
  )/)
  )/)
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['This sense model', 'capture variations', 'data', 'result', 'large training loss LD', 'w', 'N N∑ n=1', 'tn − t̂', 'xn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('sense', 'sens'), ('model', 'model'), ('rich', 'rich'), ('enough', 'enough'), ('capture', 'captur'), ('variations', 'variat'), ('present', 'present'), ('training', 'train'), ('data', 'data'), (',', ','), (',', ','), ('result', 'result'), (',', ','), ('obtain', 'obtain'), ('large', 'larg'), ('training', 'train'), ('loss', 'loss'), ('LD', 'ld'), ('(', '('), ('w', 'w'), (')', ')'), ('=', '='), ('1', '1'), ('N', 'n'), ('N∑', 'n∑'), ('n=1', 'n=1'), ('(', '('), ('tn', 'tn'), ('−', '−'), ('t̂', 't̂'), ('(', '('), ('xn', 'xn'), (')', ')'), (')', ')'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('sense', 'sens'), ('model', 'model'), ('rich', 'rich'), ('enough', 'enough'), ('capture', 'captur'), ('variations', 'variat'), ('present', 'present'), ('training', 'train'), ('data', 'data'), (',', ','), (',', ','), ('result', 'result'), (',', ','), ('obtain', 'obtain'), ('large', 'larg'), ('training', 'train'), ('loss', 'loss'), ('LD', 'ld'), ('(', '('), ('w', 'w'), (')', ')'), ('=', '='), ('1', '1'), ('N', 'n'), ('N∑', 'n∑'), ('n=1', 'n=1'), ('(', '('), ('tn', 'tn'), ('−', '−'), ('t̂', 't̂'), ('(', '('), ('xn', 'xn'), (')', ')'), (')', ')'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('sense', 'sense'), ('model', 'model'), ('rich', 'rich'), ('enough', 'enough'), ('capture', 'capture'), ('variations', 'variation'), ('present', 'present'), ('training', 'training'), ('data', 'data'), (',', ','), (',', ','), ('result', 'result'), (',', ','), ('obtain', 'obtain'), ('large', 'large'), ('training', 'training'), ('loss', 'loss'), ('LD', 'LD'), ('(', '('), ('w', 'w'), (')', ')'), ('=', '='), ('1', '1'), ('N', 'N'), ('N∑', 'N∑'), ('n=1', 'n=1'), ('(', '('), ('tn', 'tn'), ('−', '−'), ('t̂', 't̂'), ('(', '('), ('xn', 'xn'), (')', ')'), (')', ')'), ('2', '2'), ('.', '.')]



============================ Sentence 301 =============================

(12)  The training loss measures the quality of the predictor defined by weights w on the points in the training set. 


>> Tokens are: 
 ['(', '12', ')', 'The', 'training', 'loss', 'measures', 'quality', 'predictor', 'defined', 'weights', 'w', 'points', 'training', 'set', '.']

>> Bigrams are: 
 [('(', '12'), ('12', ')'), (')', 'The'), ('The', 'training'), ('training', 'loss'), ('loss', 'measures'), ('measures', 'quality'), ('quality', 'predictor'), ('predictor', 'defined'), ('defined', 'weights'), ('weights', 'w'), ('w', 'points'), ('points', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('(', '12', ')'), ('12', ')', 'The'), (')', 'The', 'training'), ('The', 'training', 'loss'), ('training', 'loss', 'measures'), ('loss', 'measures', 'quality'), ('measures', 'quality', 'predictor'), ('quality', 'predictor', 'defined'), ('predictor', 'defined', 'weights'), ('defined', 'weights', 'w'), ('weights', 'w', 'points'), ('w', 'points', 'training'), ('points', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('(', '('), ('12', 'CD'), (')', ')'), ('The', 'DT'), ('training', 'NN'), ('loss', 'NN'), ('measures', 'VBZ'), ('quality', 'JJ'), ('predictor', 'NN'), ('defined', 'VBD'), ('weights', 'NNS'), ('w', 'JJ'), ('points', 'NNS'), ('training', 'VBG'), ('set', 'NN'), ('.', '.')]

 (S
  (/(
  12/CD
  )/)
  (NP The/DT training/NN loss/NN)
  measures/VBZ
  (NP quality/JJ predictor/NN)
  defined/VBD
  (NP weights/NNS)
  (NP w/JJ points/NNS)
  training/VBG
  (NP set/NN)
  ./.) 


>> Noun Phrases are: 
 ['The training loss', 'quality predictor', 'weights', 'w points', 'set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('12', '12'), (')', ')'), ('The', 'the'), ('training', 'train'), ('loss', 'loss'), ('measures', 'measur'), ('quality', 'qualiti'), ('predictor', 'predictor'), ('defined', 'defin'), ('weights', 'weight'), ('w', 'w'), ('points', 'point'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('12', '12'), (')', ')'), ('The', 'the'), ('training', 'train'), ('loss', 'loss'), ('measures', 'measur'), ('quality', 'qualiti'), ('predictor', 'predictor'), ('defined', 'defin'), ('weights', 'weight'), ('w', 'w'), ('points', 'point'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('12', '12'), (')', ')'), ('The', 'The'), ('training', 'training'), ('loss', 'loss'), ('measures', 'measure'), ('quality', 'quality'), ('predictor', 'predictor'), ('defined', 'defined'), ('weights', 'weight'), ('w', 'w'), ('points', 'point'), ('training', 'training'), ('set', 'set'), ('.', '.')]



============================ Sentence 302 =============================

In contrast, with M = 9, the predictor fits well the training data – so much so that it appears to overfit it. 


>> Tokens are: 
 ['In', 'contrast', ',', 'M', '=', '9', ',', 'predictor', 'fits', 'well', 'training', 'data', '–', 'much', 'appears', 'overfit', '.']

>> Bigrams are: 
 [('In', 'contrast'), ('contrast', ','), (',', 'M'), ('M', '='), ('=', '9'), ('9', ','), (',', 'predictor'), ('predictor', 'fits'), ('fits', 'well'), ('well', 'training'), ('training', 'data'), ('data', '–'), ('–', 'much'), ('much', 'appears'), ('appears', 'overfit'), ('overfit', '.')]

>> Trigrams are: 
 [('In', 'contrast', ','), ('contrast', ',', 'M'), (',', 'M', '='), ('M', '=', '9'), ('=', '9', ','), ('9', ',', 'predictor'), (',', 'predictor', 'fits'), ('predictor', 'fits', 'well'), ('fits', 'well', 'training'), ('well', 'training', 'data'), ('training', 'data', '–'), ('data', '–', 'much'), ('–', 'much', 'appears'), ('much', 'appears', 'overfit'), ('appears', 'overfit', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('contrast', 'NN'), (',', ','), ('M', 'NNP'), ('=', 'NNP'), ('9', 'CD'), (',', ','), ('predictor', 'NN'), ('fits', 'NNS'), ('well', 'RB'), ('training', 'VBG'), ('data', 'NNS'), ('–', 'RB'), ('much', 'JJ'), ('appears', 'VBZ'), ('overfit', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP contrast/NN)
  ,/,
  (NP M/NNP =/NNP)
  9/CD
  ,/,
  (NP predictor/NN fits/NNS)
  well/RB
  training/VBG
  (NP data/NNS)
  –/RB
  much/JJ
  appears/VBZ
  (NP overfit/NN)
  ./.) 


>> Noun Phrases are: 
 ['contrast', 'M =', 'predictor fits', 'data', 'overfit']

>> Named Entities are: 
 [('PERSON', 'M')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('M', 'm'), ('=', '='), ('9', '9'), (',', ','), ('predictor', 'predictor'), ('fits', 'fit'), ('well', 'well'), ('training', 'train'), ('data', 'data'), ('–', '–'), ('much', 'much'), ('appears', 'appear'), ('overfit', 'overfit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('M', 'm'), ('=', '='), ('9', '9'), (',', ','), ('predictor', 'predictor'), ('fits', 'fit'), ('well', 'well'), ('training', 'train'), ('data', 'data'), ('–', '–'), ('much', 'much'), ('appears', 'appear'), ('overfit', 'overfit'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('contrast', 'contrast'), (',', ','), ('M', 'M'), ('=', '='), ('9', '9'), (',', ','), ('predictor', 'predictor'), ('fits', 'fit'), ('well', 'well'), ('training', 'training'), ('data', 'data'), ('–', '–'), ('much', 'much'), ('appears', 'appears'), ('overfit', 'overfit'), ('.', '.')]



============================ Sentence 303 =============================

In other words, the model is too rich and, in order to account for the observations in the training set, it appears to yield inaccurate predictions outside it. 


>> Tokens are: 
 ['In', 'words', ',', 'model', 'rich', ',', 'order', 'account', 'observations', 'training', 'set', ',', 'appears', 'yield', 'inaccurate', 'predictions', 'outside', '.']

>> Bigrams are: 
 [('In', 'words'), ('words', ','), (',', 'model'), ('model', 'rich'), ('rich', ','), (',', 'order'), ('order', 'account'), ('account', 'observations'), ('observations', 'training'), ('training', 'set'), ('set', ','), (',', 'appears'), ('appears', 'yield'), ('yield', 'inaccurate'), ('inaccurate', 'predictions'), ('predictions', 'outside'), ('outside', '.')]

>> Trigrams are: 
 [('In', 'words', ','), ('words', ',', 'model'), (',', 'model', 'rich'), ('model', 'rich', ','), ('rich', ',', 'order'), (',', 'order', 'account'), ('order', 'account', 'observations'), ('account', 'observations', 'training'), ('observations', 'training', 'set'), ('training', 'set', ','), ('set', ',', 'appears'), (',', 'appears', 'yield'), ('appears', 'yield', 'inaccurate'), ('yield', 'inaccurate', 'predictions'), ('inaccurate', 'predictions', 'outside'), ('predictions', 'outside', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('words', 'NNS'), (',', ','), ('model', 'NN'), ('rich', 'JJ'), (',', ','), ('order', 'NN'), ('account', 'NN'), ('observations', 'NNS'), ('training', 'NN'), ('set', 'VBN'), (',', ','), ('appears', 'VBZ'), ('yield', 'JJ'), ('inaccurate', 'JJ'), ('predictions', 'NNS'), ('outside', 'IN'), ('.', '.')]

 (S
  In/IN
  (NP words/NNS)
  ,/,
  (NP model/NN)
  rich/JJ
  ,/,
  (NP order/NN account/NN observations/NNS training/NN)
  set/VBN
  ,/,
  appears/VBZ
  (NP yield/JJ inaccurate/JJ predictions/NNS)
  outside/IN
  ./.) 


>> Noun Phrases are: 
 ['words', 'model', 'order account observations training', 'yield inaccurate predictions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('model', 'model'), ('rich', 'rich'), (',', ','), ('order', 'order'), ('account', 'account'), ('observations', 'observ'), ('training', 'train'), ('set', 'set'), (',', ','), ('appears', 'appear'), ('yield', 'yield'), ('inaccurate', 'inaccur'), ('predictions', 'predict'), ('outside', 'outsid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('model', 'model'), ('rich', 'rich'), (',', ','), ('order', 'order'), ('account', 'account'), ('observations', 'observ'), ('training', 'train'), ('set', 'set'), (',', ','), ('appears', 'appear'), ('yield', 'yield'), ('inaccurate', 'inaccur'), ('predictions', 'predict'), ('outside', 'outsid'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('words', 'word'), (',', ','), ('model', 'model'), ('rich', 'rich'), (',', ','), ('order', 'order'), ('account', 'account'), ('observations', 'observation'), ('training', 'training'), ('set', 'set'), (',', ','), ('appears', 'appears'), ('yield', 'yield'), ('inaccurate', 'inaccurate'), ('predictions', 'prediction'), ('outside', 'outside'), ('.', '.')]



============================ Sentence 304 =============================

As a compromise between underfitting and overfitting, the selection M = 3 seems to be preferable. 


>> Tokens are: 
 ['As', 'compromise', 'underfitting', 'overfitting', ',', 'selection', 'M', '=', '3', 'seems', 'preferable', '.']

>> Bigrams are: 
 [('As', 'compromise'), ('compromise', 'underfitting'), ('underfitting', 'overfitting'), ('overfitting', ','), (',', 'selection'), ('selection', 'M'), ('M', '='), ('=', '3'), ('3', 'seems'), ('seems', 'preferable'), ('preferable', '.')]

>> Trigrams are: 
 [('As', 'compromise', 'underfitting'), ('compromise', 'underfitting', 'overfitting'), ('underfitting', 'overfitting', ','), ('overfitting', ',', 'selection'), (',', 'selection', 'M'), ('selection', 'M', '='), ('M', '=', '3'), ('=', '3', 'seems'), ('3', 'seems', 'preferable'), ('seems', 'preferable', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('compromise', 'NN'), ('underfitting', 'VBG'), ('overfitting', 'NN'), (',', ','), ('selection', 'NN'), ('M', 'NNP'), ('=', 'VBZ'), ('3', 'CD'), ('seems', 'VBZ'), ('preferable', 'JJ'), ('.', '.')]

 (S
  As/IN
  (NP compromise/NN)
  underfitting/VBG
  (NP overfitting/NN)
  ,/,
  (NP selection/NN M/NNP)
  =/VBZ
  3/CD
  seems/VBZ
  preferable/JJ
  ./.) 


>> Noun Phrases are: 
 ['compromise', 'overfitting', 'selection M']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('compromise', 'compromis'), ('underfitting', 'underfit'), ('overfitting', 'overfit'), (',', ','), ('selection', 'select'), ('M', 'm'), ('=', '='), ('3', '3'), ('seems', 'seem'), ('preferable', 'prefer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('compromise', 'compromis'), ('underfitting', 'underfit'), ('overfitting', 'overfit'), (',', ','), ('selection', 'select'), ('M', 'm'), ('=', '='), ('3', '3'), ('seems', 'seem'), ('preferable', 'prefer'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('compromise', 'compromise'), ('underfitting', 'underfitting'), ('overfitting', 'overfitting'), (',', ','), ('selection', 'selection'), ('M', 'M'), ('=', '='), ('3', '3'), ('seems', 'seems'), ('preferable', 'preferable'), ('.', '.')]



============================ Sentence 305 =============================

As implied by the discussion above, underfitting can be detected by observing solely the training data D via the evaluation of the training loss (12). 


>> Tokens are: 
 ['As', 'implied', 'discussion', ',', 'underfitting', 'detected', 'observing', 'solely', 'training', 'data', 'D', 'via', 'evaluation', 'training', 'loss', '(', '12', ')', '.']

>> Bigrams are: 
 [('As', 'implied'), ('implied', 'discussion'), ('discussion', ','), (',', 'underfitting'), ('underfitting', 'detected'), ('detected', 'observing'), ('observing', 'solely'), ('solely', 'training'), ('training', 'data'), ('data', 'D'), ('D', 'via'), ('via', 'evaluation'), ('evaluation', 'training'), ('training', 'loss'), ('loss', '('), ('(', '12'), ('12', ')'), (')', '.')]

>> Trigrams are: 
 [('As', 'implied', 'discussion'), ('implied', 'discussion', ','), ('discussion', ',', 'underfitting'), (',', 'underfitting', 'detected'), ('underfitting', 'detected', 'observing'), ('detected', 'observing', 'solely'), ('observing', 'solely', 'training'), ('solely', 'training', 'data'), ('training', 'data', 'D'), ('data', 'D', 'via'), ('D', 'via', 'evaluation'), ('via', 'evaluation', 'training'), ('evaluation', 'training', 'loss'), ('training', 'loss', '('), ('loss', '(', '12'), ('(', '12', ')'), ('12', ')', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('implied', 'JJ'), ('discussion', 'NN'), (',', ','), ('underfitting', 'VBG'), ('detected', 'VBN'), ('observing', 'VBG'), ('solely', 'RB'), ('training', 'VBG'), ('data', 'NNS'), ('D', 'NNP'), ('via', 'IN'), ('evaluation', 'NN'), ('training', 'NN'), ('loss', 'NN'), ('(', '('), ('12', 'CD'), (')', ')'), ('.', '.')]

 (S
  As/IN
  (NP implied/JJ discussion/NN)
  ,/,
  underfitting/VBG
  detected/VBN
  observing/VBG
  solely/RB
  training/VBG
  (NP data/NNS D/NNP)
  via/IN
  (NP evaluation/NN training/NN loss/NN)
  (/(
  12/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['implied discussion', 'data D', 'evaluation training loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('implied', 'impli'), ('discussion', 'discuss'), (',', ','), ('underfitting', 'underfit'), ('detected', 'detect'), ('observing', 'observ'), ('solely', 'sole'), ('training', 'train'), ('data', 'data'), ('D', 'd'), ('via', 'via'), ('evaluation', 'evalu'), ('training', 'train'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('implied', 'impli'), ('discussion', 'discuss'), (',', ','), ('underfitting', 'underfit'), ('detected', 'detect'), ('observing', 'observ'), ('solely', 'sole'), ('training', 'train'), ('data', 'data'), ('D', 'd'), ('via', 'via'), ('evaluation', 'evalu'), ('training', 'train'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('implied', 'implied'), ('discussion', 'discussion'), (',', ','), ('underfitting', 'underfitting'), ('detected', 'detected'), ('observing', 'observing'), ('solely', 'solely'), ('training', 'training'), ('data', 'data'), ('D', 'D'), ('via', 'via'), ('evaluation', 'evaluation'), ('training', 'training'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('.', '.')]



============================ Sentence 306 =============================

In contrast, over-  fitting cannot be ascertained on the basis of the training data as it refers to the performance of the predictor out- side D. It follows that model selection cannot be carried out by observing only the training set. 


>> Tokens are: 
 ['In', 'contrast', ',', 'over-', 'fitting', 'ascertained', 'basis', 'training', 'data', 'refers', 'performance', 'predictor', 'out-', 'side', 'D.', 'It', 'follows', 'model', 'selection', 'carried', 'observing', 'training', 'set', '.']

>> Bigrams are: 
 [('In', 'contrast'), ('contrast', ','), (',', 'over-'), ('over-', 'fitting'), ('fitting', 'ascertained'), ('ascertained', 'basis'), ('basis', 'training'), ('training', 'data'), ('data', 'refers'), ('refers', 'performance'), ('performance', 'predictor'), ('predictor', 'out-'), ('out-', 'side'), ('side', 'D.'), ('D.', 'It'), ('It', 'follows'), ('follows', 'model'), ('model', 'selection'), ('selection', 'carried'), ('carried', 'observing'), ('observing', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('In', 'contrast', ','), ('contrast', ',', 'over-'), (',', 'over-', 'fitting'), ('over-', 'fitting', 'ascertained'), ('fitting', 'ascertained', 'basis'), ('ascertained', 'basis', 'training'), ('basis', 'training', 'data'), ('training', 'data', 'refers'), ('data', 'refers', 'performance'), ('refers', 'performance', 'predictor'), ('performance', 'predictor', 'out-'), ('predictor', 'out-', 'side'), ('out-', 'side', 'D.'), ('side', 'D.', 'It'), ('D.', 'It', 'follows'), ('It', 'follows', 'model'), ('follows', 'model', 'selection'), ('model', 'selection', 'carried'), ('selection', 'carried', 'observing'), ('carried', 'observing', 'training'), ('observing', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('contrast', 'NN'), (',', ','), ('over-', 'JJ'), ('fitting', 'NN'), ('ascertained', 'VBN'), ('basis', 'NN'), ('training', 'NN'), ('data', 'NNS'), ('refers', 'NNS'), ('performance', 'NN'), ('predictor', 'NN'), ('out-', 'JJ'), ('side', 'NN'), ('D.', 'NNP'), ('It', 'PRP'), ('follows', 'VBZ'), ('model', 'NN'), ('selection', 'NN'), ('carried', 'VBD'), ('observing', 'VBG'), ('training', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP contrast/NN)
  ,/,
  (NP over-/JJ fitting/NN)
  ascertained/VBN
  (NP
    basis/NN
    training/NN
    data/NNS
    refers/NNS
    performance/NN
    predictor/NN)
  (NP out-/JJ side/NN D./NNP)
  It/PRP
  follows/VBZ
  (NP model/NN selection/NN)
  carried/VBD
  observing/VBG
  (NP training/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['contrast', 'over- fitting', 'basis training data refers performance predictor', 'out- side D.', 'model selection', 'training set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('over-', 'over-'), ('fitting', 'fit'), ('ascertained', 'ascertain'), ('basis', 'basi'), ('training', 'train'), ('data', 'data'), ('refers', 'refer'), ('performance', 'perform'), ('predictor', 'predictor'), ('out-', 'out-'), ('side', 'side'), ('D.', 'd.'), ('It', 'it'), ('follows', 'follow'), ('model', 'model'), ('selection', 'select'), ('carried', 'carri'), ('observing', 'observ'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('contrast', 'contrast'), (',', ','), ('over-', 'over-'), ('fitting', 'fit'), ('ascertained', 'ascertain'), ('basis', 'basi'), ('training', 'train'), ('data', 'data'), ('refers', 'refer'), ('performance', 'perform'), ('predictor', 'predictor'), ('out-', 'out-'), ('side', 'side'), ('D.', 'd.'), ('It', 'it'), ('follows', 'follow'), ('model', 'model'), ('selection', 'select'), ('carried', 'carri'), ('observing', 'observ'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('contrast', 'contrast'), (',', ','), ('over-', 'over-'), ('fitting', 'fitting'), ('ascertained', 'ascertained'), ('basis', 'basis'), ('training', 'training'), ('data', 'data'), ('refers', 'refers'), ('performance', 'performance'), ('predictor', 'predictor'), ('out-', 'out-'), ('side', 'side'), ('D.', 'D.'), ('It', 'It'), ('follows', 'follows'), ('model', 'model'), ('selection', 'selection'), ('carried', 'carried'), ('observing', 'observing'), ('training', 'training'), ('set', 'set'), ('.', '.')]



============================ Sentence 307 =============================

Rather, some information must be available about the generalization performance of the predictor. 


>> Tokens are: 
 ['Rather', ',', 'information', 'must', 'available', 'generalization', 'performance', 'predictor', '.']

>> Bigrams are: 
 [('Rather', ','), (',', 'information'), ('information', 'must'), ('must', 'available'), ('available', 'generalization'), ('generalization', 'performance'), ('performance', 'predictor'), ('predictor', '.')]

>> Trigrams are: 
 [('Rather', ',', 'information'), (',', 'information', 'must'), ('information', 'must', 'available'), ('must', 'available', 'generalization'), ('available', 'generalization', 'performance'), ('generalization', 'performance', 'predictor'), ('performance', 'predictor', '.')]

>> POS Tags are: 
 [('Rather', 'RB'), (',', ','), ('information', 'NN'), ('must', 'MD'), ('available', 'JJ'), ('generalization', 'NN'), ('performance', 'NN'), ('predictor', 'NN'), ('.', '.')]

 (S
  Rather/RB
  ,/,
  (NP information/NN)
  must/MD
  (NP available/JJ generalization/NN performance/NN predictor/NN)
  ./.) 


>> Noun Phrases are: 
 ['information', 'available generalization performance predictor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rather', 'rather'), (',', ','), ('information', 'inform'), ('must', 'must'), ('available', 'avail'), ('generalization', 'gener'), ('performance', 'perform'), ('predictor', 'predictor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rather', 'rather'), (',', ','), ('information', 'inform'), ('must', 'must'), ('available', 'avail'), ('generalization', 'general'), ('performance', 'perform'), ('predictor', 'predictor'), ('.', '.')]

>> Lemmatization: 
 [('Rather', 'Rather'), (',', ','), ('information', 'information'), ('must', 'must'), ('available', 'available'), ('generalization', 'generalization'), ('performance', 'performance'), ('predictor', 'predictor'), ('.', '.')]



============================ Sentence 308 =============================

This is typically obtained by means of validation. 


>> Tokens are: 
 ['This', 'typically', 'obtained', 'means', 'validation', '.']

>> Bigrams are: 
 [('This', 'typically'), ('typically', 'obtained'), ('obtained', 'means'), ('means', 'validation'), ('validation', '.')]

>> Trigrams are: 
 [('This', 'typically', 'obtained'), ('typically', 'obtained', 'means'), ('obtained', 'means', 'validation'), ('means', 'validation', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('typically', 'RB'), ('obtained', 'VBN'), ('means', 'VBZ'), ('validation', 'NN'), ('.', '.')]

 (S
  This/DT
  typically/RB
  obtained/VBN
  means/VBZ
  (NP validation/NN)
  ./.) 


>> Noun Phrases are: 
 ['validation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('typically', 'typic'), ('obtained', 'obtain'), ('means', 'mean'), ('validation', 'valid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('typically', 'typic'), ('obtained', 'obtain'), ('means', 'mean'), ('validation', 'valid'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('typically', 'typically'), ('obtained', 'obtained'), ('means', 'mean'), ('validation', 'validation'), ('.', '.')]



============================ Sentence 309 =============================

In its simplest instantiation, validation partitions the available data into two sets, a training set D and a validation set. 


>> Tokens are: 
 ['In', 'simplest', 'instantiation', ',', 'validation', 'partitions', 'available', 'data', 'two', 'sets', ',', 'training', 'set', 'D', 'validation', 'set', '.']

>> Bigrams are: 
 [('In', 'simplest'), ('simplest', 'instantiation'), ('instantiation', ','), (',', 'validation'), ('validation', 'partitions'), ('partitions', 'available'), ('available', 'data'), ('data', 'two'), ('two', 'sets'), ('sets', ','), (',', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'validation'), ('validation', 'set'), ('set', '.')]

>> Trigrams are: 
 [('In', 'simplest', 'instantiation'), ('simplest', 'instantiation', ','), ('instantiation', ',', 'validation'), (',', 'validation', 'partitions'), ('validation', 'partitions', 'available'), ('partitions', 'available', 'data'), ('available', 'data', 'two'), ('data', 'two', 'sets'), ('two', 'sets', ','), ('sets', ',', 'training'), (',', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'validation'), ('D', 'validation', 'set'), ('validation', 'set', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('simplest', 'JJS'), ('instantiation', 'NN'), (',', ','), ('validation', 'NN'), ('partitions', 'NNS'), ('available', 'JJ'), ('data', 'NNS'), ('two', 'CD'), ('sets', 'NNS'), (',', ','), ('training', 'VBG'), ('set', 'VBN'), ('D', 'NNP'), ('validation', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  In/IN
  simplest/JJS
  (NP instantiation/NN)
  ,/,
  (NP validation/NN partitions/NNS)
  (NP available/JJ data/NNS)
  two/CD
  (NP sets/NNS)
  ,/,
  training/VBG
  set/VBN
  (NP D/NNP validation/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['instantiation', 'validation partitions', 'available data', 'sets', 'D validation set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('simplest', 'simplest'), ('instantiation', 'instanti'), (',', ','), ('validation', 'valid'), ('partitions', 'partit'), ('available', 'avail'), ('data', 'data'), ('two', 'two'), ('sets', 'set'), (',', ','), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('validation', 'valid'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('simplest', 'simplest'), ('instantiation', 'instanti'), (',', ','), ('validation', 'valid'), ('partitions', 'partit'), ('available', 'avail'), ('data', 'data'), ('two', 'two'), ('sets', 'set'), (',', ','), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('validation', 'valid'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('simplest', 'simplest'), ('instantiation', 'instantiation'), (',', ','), ('validation', 'validation'), ('partitions', 'partition'), ('available', 'available'), ('data', 'data'), ('two', 'two'), ('sets', 'set'), (',', ','), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('validation', 'validation'), ('set', 'set'), ('.', '.')]



============================ Sentence 310 =============================

The training set is used for learning as discussed in Sec. 


>> Tokens are: 
 ['The', 'training', 'set', 'used', 'learning', 'discussed', 'Sec', '.']

>> Bigrams are: 
 [('The', 'training'), ('training', 'set'), ('set', 'used'), ('used', 'learning'), ('learning', 'discussed'), ('discussed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('The', 'training', 'set'), ('training', 'set', 'used'), ('set', 'used', 'learning'), ('used', 'learning', 'discussed'), ('learning', 'discussed', 'Sec'), ('discussed', 'Sec', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('training', 'NN'), ('set', 'NN'), ('used', 'VBN'), ('learning', 'NN'), ('discussed', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  (NP The/DT training/NN set/NN)
  used/VBN
  (NP learning/NN)
  discussed/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The training set', 'learning', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('training', 'train'), ('set', 'set'), ('used', 'use'), ('learning', 'learn'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('training', 'train'), ('set', 'set'), ('used', 'use'), ('learning', 'learn'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('training', 'training'), ('set', 'set'), ('used', 'used'), ('learning', 'learning'), ('discussed', 'discussed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 311 =============================

III-E, while the validation set is used to estimate the generalization loss. 


>> Tokens are: 
 ['III-E', ',', 'validation', 'set', 'used', 'estimate', 'generalization', 'loss', '.']

>> Bigrams are: 
 [('III-E', ','), (',', 'validation'), ('validation', 'set'), ('set', 'used'), ('used', 'estimate'), ('estimate', 'generalization'), ('generalization', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('III-E', ',', 'validation'), (',', 'validation', 'set'), ('validation', 'set', 'used'), ('set', 'used', 'estimate'), ('used', 'estimate', 'generalization'), ('estimate', 'generalization', 'loss'), ('generalization', 'loss', '.')]

>> POS Tags are: 
 [('III-E', 'NNP'), (',', ','), ('validation', 'NN'), ('set', 'NN'), ('used', 'VBN'), ('estimate', 'JJ'), ('generalization', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  (NP III-E/NNP)
  ,/,
  (NP validation/NN set/NN)
  used/VBN
  (NP estimate/JJ generalization/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['III-E', 'validation set', 'estimate generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('III-E', 'iii-'), (',', ','), ('validation', 'valid'), ('set', 'set'), ('used', 'use'), ('estimate', 'estim'), ('generalization', 'gener'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III-E', 'iii-'), (',', ','), ('validation', 'valid'), ('set', 'set'), ('used', 'use'), ('estimate', 'estim'), ('generalization', 'general'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('III-E', 'III-E'), (',', ','), ('validation', 'validation'), ('set', 'set'), ('used', 'used'), ('estimate', 'estimate'), ('generalization', 'generalization'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 312 =============================

This is done by computing the average in (12) only over the validation set. 


>> Tokens are: 
 ['This', 'done', 'computing', 'average', '(', '12', ')', 'validation', 'set', '.']

>> Bigrams are: 
 [('This', 'done'), ('done', 'computing'), ('computing', 'average'), ('average', '('), ('(', '12'), ('12', ')'), (')', 'validation'), ('validation', 'set'), ('set', '.')]

>> Trigrams are: 
 [('This', 'done', 'computing'), ('done', 'computing', 'average'), ('computing', 'average', '('), ('average', '(', '12'), ('(', '12', ')'), ('12', ')', 'validation'), (')', 'validation', 'set'), ('validation', 'set', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('done', 'VBN'), ('computing', 'NN'), ('average', 'NN'), ('(', '('), ('12', 'CD'), (')', ')'), ('validation', 'NN'), ('set', 'VBN'), ('.', '.')]

 (S
  This/DT
  done/VBN
  (NP computing/NN average/NN)
  (/(
  12/CD
  )/)
  (NP validation/NN)
  set/VBN
  ./.) 


>> Noun Phrases are: 
 ['computing average', 'validation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('done', 'done'), ('computing', 'comput'), ('average', 'averag'), ('(', '('), ('12', '12'), (')', ')'), ('validation', 'valid'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('done', 'done'), ('computing', 'comput'), ('average', 'averag'), ('(', '('), ('12', '12'), (')', ')'), ('validation', 'valid'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('done', 'done'), ('computing', 'computing'), ('average', 'average'), ('(', '('), ('12', '12'), (')', ')'), ('validation', 'validation'), ('set', 'set'), ('.', '.')]



============================ Sentence 313 =============================

More sophisticated forms of validation exist, including cross-validation [7]. 


>> Tokens are: 
 ['More', 'sophisticated', 'forms', 'validation', 'exist', ',', 'including', 'cross-validation', '[', '7', ']', '.']

>> Bigrams are: 
 [('More', 'sophisticated'), ('sophisticated', 'forms'), ('forms', 'validation'), ('validation', 'exist'), ('exist', ','), (',', 'including'), ('including', 'cross-validation'), ('cross-validation', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('More', 'sophisticated', 'forms'), ('sophisticated', 'forms', 'validation'), ('forms', 'validation', 'exist'), ('validation', 'exist', ','), ('exist', ',', 'including'), (',', 'including', 'cross-validation'), ('including', 'cross-validation', '['), ('cross-validation', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('sophisticated', 'JJ'), ('forms', 'NNS'), ('validation', 'NN'), ('exist', 'VBP'), (',', ','), ('including', 'VBG'), ('cross-validation', 'NN'), ('[', 'NN'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  More/RBR
  (NP sophisticated/JJ forms/NNS validation/NN)
  exist/VBP
  ,/,
  including/VBG
  (NP cross-validation/NN [/NN)
  7/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['sophisticated forms validation', 'cross-validation [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('sophisticated', 'sophist'), ('forms', 'form'), ('validation', 'valid'), ('exist', 'exist'), (',', ','), ('including', 'includ'), ('cross-validation', 'cross-valid'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('sophisticated', 'sophist'), ('forms', 'form'), ('validation', 'valid'), ('exist', 'exist'), (',', ','), ('including', 'includ'), ('cross-validation', 'cross-valid'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('sophisticated', 'sophisticated'), ('forms', 'form'), ('validation', 'validation'), ('exist', 'exist'), (',', ','), ('including', 'including'), ('cross-validation', 'cross-validation'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



============================ Sentence 314 =============================

Keeping some data aside for validation, one can obtain a plot as in Fig. 


>> Tokens are: 
 ['Keeping', 'data', 'aside', 'validation', ',', 'one', 'obtain', 'plot', 'Fig', '.']

>> Bigrams are: 
 [('Keeping', 'data'), ('data', 'aside'), ('aside', 'validation'), ('validation', ','), (',', 'one'), ('one', 'obtain'), ('obtain', 'plot'), ('plot', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Keeping', 'data', 'aside'), ('data', 'aside', 'validation'), ('aside', 'validation', ','), ('validation', ',', 'one'), (',', 'one', 'obtain'), ('one', 'obtain', 'plot'), ('obtain', 'plot', 'Fig'), ('plot', 'Fig', '.')]

>> POS Tags are: 
 [('Keeping', 'VBG'), ('data', 'NNS'), ('aside', 'RB'), ('validation', 'NN'), (',', ','), ('one', 'CD'), ('obtain', 'VB'), ('plot', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  Keeping/VBG
  (NP data/NNS)
  aside/RB
  (NP validation/NN)
  ,/,
  one/CD
  obtain/VB
  (NP plot/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['data', 'validation', 'plot Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Keeping', 'keep'), ('data', 'data'), ('aside', 'asid'), ('validation', 'valid'), (',', ','), ('one', 'one'), ('obtain', 'obtain'), ('plot', 'plot'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Keeping', 'keep'), ('data', 'data'), ('aside', 'asid'), ('validation', 'valid'), (',', ','), ('one', 'one'), ('obtain', 'obtain'), ('plot', 'plot'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Keeping', 'Keeping'), ('data', 'data'), ('aside', 'aside'), ('validation', 'validation'), (',', ','), ('one', 'one'), ('obtain', 'obtain'), ('plot', 'plot'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 315 =============================

10, where the training loss (12) is compared with the generalization loss (2) estimated via validation. 


>> Tokens are: 
 ['10', ',', 'training', 'loss', '(', '12', ')', 'compared', 'generalization', 'loss', '(', '2', ')', 'estimated', 'via', 'validation', '.']

>> Bigrams are: 
 [('10', ','), (',', 'training'), ('training', 'loss'), ('loss', '('), ('(', '12'), ('12', ')'), (')', 'compared'), ('compared', 'generalization'), ('generalization', 'loss'), ('loss', '('), ('(', '2'), ('2', ')'), (')', 'estimated'), ('estimated', 'via'), ('via', 'validation'), ('validation', '.')]

>> Trigrams are: 
 [('10', ',', 'training'), (',', 'training', 'loss'), ('training', 'loss', '('), ('loss', '(', '12'), ('(', '12', ')'), ('12', ')', 'compared'), (')', 'compared', 'generalization'), ('compared', 'generalization', 'loss'), ('generalization', 'loss', '('), ('loss', '(', '2'), ('(', '2', ')'), ('2', ')', 'estimated'), (')', 'estimated', 'via'), ('estimated', 'via', 'validation'), ('via', 'validation', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('training', 'VBG'), ('loss', 'NN'), ('(', '('), ('12', 'CD'), (')', ')'), ('compared', 'VBN'), ('generalization', 'NN'), ('loss', 'NN'), ('(', '('), ('2', 'CD'), (')', ')'), ('estimated', 'VBN'), ('via', 'IN'), ('validation', 'NN'), ('.', '.')]

 (S
  10/CD
  ,/,
  training/VBG
  (NP loss/NN)
  (/(
  12/CD
  )/)
  compared/VBN
  (NP generalization/NN loss/NN)
  (/(
  2/CD
  )/)
  estimated/VBN
  via/IN
  (NP validation/NN)
  ./.) 


>> Noun Phrases are: 
 ['loss', 'generalization loss', 'validation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('training', 'train'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('compared', 'compar'), ('generalization', 'gener'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('estimated', 'estim'), ('via', 'via'), ('validation', 'valid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('training', 'train'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('compared', 'compar'), ('generalization', 'general'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('estimated', 'estim'), ('via', 'via'), ('validation', 'valid'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('training', 'training'), ('loss', 'loss'), ('(', '('), ('12', '12'), (')', ')'), ('compared', 'compared'), ('generalization', 'generalization'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('estimated', 'estimated'), ('via', 'via'), ('validation', 'validation'), ('.', '.')]



============================ Sentence 316 =============================

The figure allows us to conclude that, when M is large enough, the generalization loss starts increasing, indicating overfitting. 


>> Tokens are: 
 ['The', 'figure', 'allows', 'us', 'conclude', ',', 'M', 'large', 'enough', ',', 'generalization', 'loss', 'starts', 'increasing', ',', 'indicating', 'overfitting', '.']

>> Bigrams are: 
 [('The', 'figure'), ('figure', 'allows'), ('allows', 'us'), ('us', 'conclude'), ('conclude', ','), (',', 'M'), ('M', 'large'), ('large', 'enough'), ('enough', ','), (',', 'generalization'), ('generalization', 'loss'), ('loss', 'starts'), ('starts', 'increasing'), ('increasing', ','), (',', 'indicating'), ('indicating', 'overfitting'), ('overfitting', '.')]

>> Trigrams are: 
 [('The', 'figure', 'allows'), ('figure', 'allows', 'us'), ('allows', 'us', 'conclude'), ('us', 'conclude', ','), ('conclude', ',', 'M'), (',', 'M', 'large'), ('M', 'large', 'enough'), ('large', 'enough', ','), ('enough', ',', 'generalization'), (',', 'generalization', 'loss'), ('generalization', 'loss', 'starts'), ('loss', 'starts', 'increasing'), ('starts', 'increasing', ','), ('increasing', ',', 'indicating'), (',', 'indicating', 'overfitting'), ('indicating', 'overfitting', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('figure', 'NN'), ('allows', 'VBZ'), ('us', 'PRP'), ('conclude', 'VBP'), (',', ','), ('M', 'NNP'), ('large', 'JJ'), ('enough', 'RB'), (',', ','), ('generalization', 'NN'), ('loss', 'NN'), ('starts', 'VBZ'), ('increasing', 'VBG'), (',', ','), ('indicating', 'VBG'), ('overfitting', 'NN'), ('.', '.')]

 (S
  (NP The/DT figure/NN)
  allows/VBZ
  us/PRP
  conclude/VBP
  ,/,
  (NP M/NNP)
  large/JJ
  enough/RB
  ,/,
  (NP generalization/NN loss/NN)
  starts/VBZ
  increasing/VBG
  ,/,
  indicating/VBG
  (NP overfitting/NN)
  ./.) 


>> Noun Phrases are: 
 ['The figure', 'M', 'generalization loss', 'overfitting']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('allows', 'allow'), ('us', 'us'), ('conclude', 'conclud'), (',', ','), ('M', 'm'), ('large', 'larg'), ('enough', 'enough'), (',', ','), ('generalization', 'gener'), ('loss', 'loss'), ('starts', 'start'), ('increasing', 'increas'), (',', ','), ('indicating', 'indic'), ('overfitting', 'overfit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('allows', 'allow'), ('us', 'us'), ('conclude', 'conclud'), (',', ','), ('M', 'm'), ('large', 'larg'), ('enough', 'enough'), (',', ','), ('generalization', 'general'), ('loss', 'loss'), ('starts', 'start'), ('increasing', 'increas'), (',', ','), ('indicating', 'indic'), ('overfitting', 'overfit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('figure', 'figure'), ('allows', 'allows'), ('us', 'u'), ('conclude', 'conclude'), (',', ','), ('M', 'M'), ('large', 'large'), ('enough', 'enough'), (',', ','), ('generalization', 'generalization'), ('loss', 'loss'), ('starts', 'start'), ('increasing', 'increasing'), (',', ','), ('indicating', 'indicating'), ('overfitting', 'overfitting'), ('.', '.')]



============================ Sentence 317 =============================

Note, in contrast, that underfitting is detectable by observing the training loss. 


>> Tokens are: 
 ['Note', ',', 'contrast', ',', 'underfitting', 'detectable', 'observing', 'training', 'loss', '.']

>> Bigrams are: 
 [('Note', ','), (',', 'contrast'), ('contrast', ','), (',', 'underfitting'), ('underfitting', 'detectable'), ('detectable', 'observing'), ('observing', 'training'), ('training', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('Note', ',', 'contrast'), (',', 'contrast', ','), ('contrast', ',', 'underfitting'), (',', 'underfitting', 'detectable'), ('underfitting', 'detectable', 'observing'), ('detectable', 'observing', 'training'), ('observing', 'training', 'loss'), ('training', 'loss', '.')]

>> POS Tags are: 
 [('Note', 'NN'), (',', ','), ('contrast', 'NN'), (',', ','), ('underfitting', 'VBG'), ('detectable', 'JJ'), ('observing', 'VBG'), ('training', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  (NP Note/NN)
  ,/,
  (NP contrast/NN)
  ,/,
  underfitting/VBG
  detectable/JJ
  observing/VBG
  (NP training/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['Note', 'contrast', 'training loss']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), (',', ','), ('contrast', 'contrast'), (',', ','), ('underfitting', 'underfit'), ('detectable', 'detect'), ('observing', 'observ'), ('training', 'train'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), (',', ','), ('contrast', 'contrast'), (',', ','), ('underfitting', 'underfit'), ('detectable', 'detect'), ('observing', 'observ'), ('training', 'train'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), (',', ','), ('contrast', 'contrast'), (',', ','), ('underfitting', 'underfitting'), ('detectable', 'detectable'), ('observing', 'observing'), ('training', 'training'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 318 =============================

A figure such as Fig. 


>> Tokens are: 
 ['A', 'figure', 'Fig', '.']

>> Bigrams are: 
 [('A', 'figure'), ('figure', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('A', 'figure', 'Fig'), ('figure', 'Fig', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('figure', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S (NP A/DT figure/NN Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['A figure Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('figure', 'figur'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('figure', 'figur'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('figure', 'figure'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 319 =============================

10 can be used to choose a value of M that approximately minimizes the generalization loss. 


>> Tokens are: 
 ['10', 'used', 'choose', 'value', 'M', 'approximately', 'minimizes', 'generalization', 'loss', '.']

>> Bigrams are: 
 [('10', 'used'), ('used', 'choose'), ('choose', 'value'), ('value', 'M'), ('M', 'approximately'), ('approximately', 'minimizes'), ('minimizes', 'generalization'), ('generalization', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('10', 'used', 'choose'), ('used', 'choose', 'value'), ('choose', 'value', 'M'), ('value', 'M', 'approximately'), ('M', 'approximately', 'minimizes'), ('approximately', 'minimizes', 'generalization'), ('minimizes', 'generalization', 'loss'), ('generalization', 'loss', '.')]

>> POS Tags are: 
 [('10', 'CD'), ('used', 'VBN'), ('choose', 'NN'), ('value', 'NN'), ('M', 'NNP'), ('approximately', 'RB'), ('minimizes', 'VBZ'), ('generalization', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  10/CD
  used/VBN
  (NP choose/NN value/NN M/NNP)
  approximately/RB
  minimizes/VBZ
  (NP generalization/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['choose value M', 'generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('used', 'use'), ('choose', 'choos'), ('value', 'valu'), ('M', 'm'), ('approximately', 'approxim'), ('minimizes', 'minim'), ('generalization', 'gener'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('used', 'use'), ('choose', 'choos'), ('value', 'valu'), ('M', 'm'), ('approximately', 'approxim'), ('minimizes', 'minim'), ('generalization', 'general'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('used', 'used'), ('choose', 'choose'), ('value', 'value'), ('M', 'M'), ('approximately', 'approximately'), ('minimizes', 'minimizes'), ('generalization', 'generalization'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 320 =============================

More generally, validation allows for model selection, as well as for the selection of the parameters used by learning the algorithm, such as the learning rate γ in (10). 


>> Tokens are: 
 ['More', 'generally', ',', 'validation', 'allows', 'model', 'selection', ',', 'well', 'selection', 'parameters', 'used', 'learning', 'algorithm', ',', 'learning', 'rate', 'γ', '(', '10', ')', '.']

>> Bigrams are: 
 [('More', 'generally'), ('generally', ','), (',', 'validation'), ('validation', 'allows'), ('allows', 'model'), ('model', 'selection'), ('selection', ','), (',', 'well'), ('well', 'selection'), ('selection', 'parameters'), ('parameters', 'used'), ('used', 'learning'), ('learning', 'algorithm'), ('algorithm', ','), (',', 'learning'), ('learning', 'rate'), ('rate', 'γ'), ('γ', '('), ('(', '10'), ('10', ')'), (')', '.')]

>> Trigrams are: 
 [('More', 'generally', ','), ('generally', ',', 'validation'), (',', 'validation', 'allows'), ('validation', 'allows', 'model'), ('allows', 'model', 'selection'), ('model', 'selection', ','), ('selection', ',', 'well'), (',', 'well', 'selection'), ('well', 'selection', 'parameters'), ('selection', 'parameters', 'used'), ('parameters', 'used', 'learning'), ('used', 'learning', 'algorithm'), ('learning', 'algorithm', ','), ('algorithm', ',', 'learning'), (',', 'learning', 'rate'), ('learning', 'rate', 'γ'), ('rate', 'γ', '('), ('γ', '(', '10'), ('(', '10', ')'), ('10', ')', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('generally', 'RB'), (',', ','), ('validation', 'NN'), ('allows', 'VBZ'), ('model', 'NN'), ('selection', 'NN'), (',', ','), ('well', 'UH'), ('selection', 'NN'), ('parameters', 'NNS'), ('used', 'VBD'), ('learning', 'VBG'), ('algorithm', 'NN'), (',', ','), ('learning', 'VBG'), ('rate', 'NN'), ('γ', 'NNP'), ('(', '('), ('10', 'CD'), (')', ')'), ('.', '.')]

 (S
  More/RBR
  generally/RB
  ,/,
  (NP validation/NN)
  allows/VBZ
  (NP model/NN selection/NN)
  ,/,
  well/UH
  (NP selection/NN parameters/NNS)
  used/VBD
  learning/VBG
  (NP algorithm/NN)
  ,/,
  learning/VBG
  (NP rate/NN γ/NNP)
  (/(
  10/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['validation', 'model selection', 'selection parameters', 'algorithm', 'rate γ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('generally', 'gener'), (',', ','), ('validation', 'valid'), ('allows', 'allow'), ('model', 'model'), ('selection', 'select'), (',', ','), ('well', 'well'), ('selection', 'select'), ('parameters', 'paramet'), ('used', 'use'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('learning', 'learn'), ('rate', 'rate'), ('γ', 'γ'), ('(', '('), ('10', '10'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('generally', 'general'), (',', ','), ('validation', 'valid'), ('allows', 'allow'), ('model', 'model'), ('selection', 'select'), (',', ','), ('well', 'well'), ('selection', 'select'), ('parameters', 'paramet'), ('used', 'use'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('learning', 'learn'), ('rate', 'rate'), ('γ', 'γ'), ('(', '('), ('10', '10'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('generally', 'generally'), (',', ','), ('validation', 'validation'), ('allows', 'allows'), ('model', 'model'), ('selection', 'selection'), (',', ','), ('well', 'well'), ('selection', 'selection'), ('parameters', 'parameter'), ('used', 'used'), ('learning', 'learning'), ('algorithm', 'algorithm'), (',', ','), ('learning', 'learning'), ('rate', 'rate'), ('γ', 'γ'), ('(', '('), ('10', '10'), (')', ')'), ('.', '.')]



============================ Sentence 321 =============================

To this end, one compares the generalization loss, estimated via validation, for a number of models and then chooses the one with the smallest estimated generalization loss. 


>> Tokens are: 
 ['To', 'end', ',', 'one', 'compares', 'generalization', 'loss', ',', 'estimated', 'via', 'validation', ',', 'number', 'models', 'chooses', 'one', 'smallest', 'estimated', 'generalization', 'loss', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'one'), ('one', 'compares'), ('compares', 'generalization'), ('generalization', 'loss'), ('loss', ','), (',', 'estimated'), ('estimated', 'via'), ('via', 'validation'), ('validation', ','), (',', 'number'), ('number', 'models'), ('models', 'chooses'), ('chooses', 'one'), ('one', 'smallest'), ('smallest', 'estimated'), ('estimated', 'generalization'), ('generalization', 'loss'), ('loss', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'one'), (',', 'one', 'compares'), ('one', 'compares', 'generalization'), ('compares', 'generalization', 'loss'), ('generalization', 'loss', ','), ('loss', ',', 'estimated'), (',', 'estimated', 'via'), ('estimated', 'via', 'validation'), ('via', 'validation', ','), ('validation', ',', 'number'), (',', 'number', 'models'), ('number', 'models', 'chooses'), ('models', 'chooses', 'one'), ('chooses', 'one', 'smallest'), ('one', 'smallest', 'estimated'), ('smallest', 'estimated', 'generalization'), ('estimated', 'generalization', 'loss'), ('generalization', 'loss', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('one', 'CD'), ('compares', 'VBZ'), ('generalization', 'NN'), ('loss', 'NN'), (',', ','), ('estimated', 'VBN'), ('via', 'IN'), ('validation', 'NN'), (',', ','), ('number', 'NN'), ('models', 'NNS'), ('chooses', 'VBZ'), ('one', 'CD'), ('smallest', 'NN'), ('estimated', 'VBN'), ('generalization', 'NN'), ('loss', 'NN'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  one/CD
  compares/VBZ
  (NP generalization/NN loss/NN)
  ,/,
  estimated/VBN
  via/IN
  (NP validation/NN)
  ,/,
  (NP number/NN models/NNS)
  chooses/VBZ
  one/CD
  (NP smallest/NN)
  estimated/VBN
  (NP generalization/NN loss/NN)
  ./.) 


>> Noun Phrases are: 
 ['generalization loss', 'validation', 'number models', 'smallest', 'generalization loss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('one', 'one'), ('compares', 'compar'), ('generalization', 'gener'), ('loss', 'loss'), (',', ','), ('estimated', 'estim'), ('via', 'via'), ('validation', 'valid'), (',', ','), ('number', 'number'), ('models', 'model'), ('chooses', 'choos'), ('one', 'one'), ('smallest', 'smallest'), ('estimated', 'estim'), ('generalization', 'gener'), ('loss', 'loss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('one', 'one'), ('compares', 'compar'), ('generalization', 'general'), ('loss', 'loss'), (',', ','), ('estimated', 'estim'), ('via', 'via'), ('validation', 'valid'), (',', ','), ('number', 'number'), ('models', 'model'), ('chooses', 'choos'), ('one', 'one'), ('smallest', 'smallest'), ('estimated', 'estim'), ('generalization', 'general'), ('loss', 'loss'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('one', 'one'), ('compares', 'compare'), ('generalization', 'generalization'), ('loss', 'loss'), (',', ','), ('estimated', 'estimated'), ('via', 'via'), ('validation', 'validation'), (',', ','), ('number', 'number'), ('models', 'model'), ('chooses', 'chooses'), ('one', 'one'), ('smallest', 'smallest'), ('estimated', 'estimated'), ('generalization', 'generalization'), ('loss', 'loss'), ('.', '.')]



============================ Sentence 322 =============================

Finally, it is important to remark that the performance of the model selected via validation should be estimated on the basis of a separate data set, typically called the test set. 


>> Tokens are: 
 ['Finally', ',', 'important', 'remark', 'performance', 'model', 'selected', 'via', 'validation', 'estimated', 'basis', 'separate', 'data', 'set', ',', 'typically', 'called', 'test', 'set', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'important'), ('important', 'remark'), ('remark', 'performance'), ('performance', 'model'), ('model', 'selected'), ('selected', 'via'), ('via', 'validation'), ('validation', 'estimated'), ('estimated', 'basis'), ('basis', 'separate'), ('separate', 'data'), ('data', 'set'), ('set', ','), (',', 'typically'), ('typically', 'called'), ('called', 'test'), ('test', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Finally', ',', 'important'), (',', 'important', 'remark'), ('important', 'remark', 'performance'), ('remark', 'performance', 'model'), ('performance', 'model', 'selected'), ('model', 'selected', 'via'), ('selected', 'via', 'validation'), ('via', 'validation', 'estimated'), ('validation', 'estimated', 'basis'), ('estimated', 'basis', 'separate'), ('basis', 'separate', 'data'), ('separate', 'data', 'set'), ('data', 'set', ','), ('set', ',', 'typically'), (',', 'typically', 'called'), ('typically', 'called', 'test'), ('called', 'test', 'set'), ('test', 'set', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('important', 'JJ'), ('remark', 'NN'), ('performance', 'NN'), ('model', 'NN'), ('selected', 'VBN'), ('via', 'IN'), ('validation', 'NN'), ('estimated', 'VBN'), ('basis', 'NN'), ('separate', 'JJ'), ('data', 'NNS'), ('set', 'NN'), (',', ','), ('typically', 'RB'), ('called', 'VBD'), ('test', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP important/JJ remark/NN performance/NN model/NN)
  selected/VBN
  via/IN
  (NP validation/NN)
  estimated/VBN
  (NP basis/NN)
  (NP separate/JJ data/NNS set/NN)
  ,/,
  typically/RB
  called/VBD
  (NP test/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['important remark performance model', 'validation', 'basis', 'separate data set', 'test set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('important', 'import'), ('remark', 'remark'), ('performance', 'perform'), ('model', 'model'), ('selected', 'select'), ('via', 'via'), ('validation', 'valid'), ('estimated', 'estim'), ('basis', 'basi'), ('separate', 'separ'), ('data', 'data'), ('set', 'set'), (',', ','), ('typically', 'typic'), ('called', 'call'), ('test', 'test'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('important', 'import'), ('remark', 'remark'), ('performance', 'perform'), ('model', 'model'), ('selected', 'select'), ('via', 'via'), ('validation', 'valid'), ('estimated', 'estim'), ('basis', 'basi'), ('separate', 'separ'), ('data', 'data'), ('set', 'set'), (',', ','), ('typically', 'typic'), ('called', 'call'), ('test', 'test'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('important', 'important'), ('remark', 'remark'), ('performance', 'performance'), ('model', 'model'), ('selected', 'selected'), ('via', 'via'), ('validation', 'validation'), ('estimated', 'estimated'), ('basis', 'basis'), ('separate', 'separate'), ('data', 'data'), ('set', 'set'), (',', ','), ('typically', 'typically'), ('called', 'called'), ('test', 'test'), ('set', 'set'), ('.', '.')]



============================ Sentence 323 =============================

This is because the generalization loss estimated using validation is a biased estimate of the true generalization loss (2) due to the process of model selection. 


>> Tokens are: 
 ['This', 'generalization', 'loss', 'estimated', 'using', 'validation', 'biased', 'estimate', 'true', 'generalization', 'loss', '(', '2', ')', 'due', 'process', 'model', 'selection', '.']

>> Bigrams are: 
 [('This', 'generalization'), ('generalization', 'loss'), ('loss', 'estimated'), ('estimated', 'using'), ('using', 'validation'), ('validation', 'biased'), ('biased', 'estimate'), ('estimate', 'true'), ('true', 'generalization'), ('generalization', 'loss'), ('loss', '('), ('(', '2'), ('2', ')'), (')', 'due'), ('due', 'process'), ('process', 'model'), ('model', 'selection'), ('selection', '.')]

>> Trigrams are: 
 [('This', 'generalization', 'loss'), ('generalization', 'loss', 'estimated'), ('loss', 'estimated', 'using'), ('estimated', 'using', 'validation'), ('using', 'validation', 'biased'), ('validation', 'biased', 'estimate'), ('biased', 'estimate', 'true'), ('estimate', 'true', 'generalization'), ('true', 'generalization', 'loss'), ('generalization', 'loss', '('), ('loss', '(', '2'), ('(', '2', ')'), ('2', ')', 'due'), (')', 'due', 'process'), ('due', 'process', 'model'), ('process', 'model', 'selection'), ('model', 'selection', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('generalization', 'NN'), ('loss', 'NN'), ('estimated', 'VBN'), ('using', 'VBG'), ('validation', 'NN'), ('biased', 'VBD'), ('estimate', 'NN'), ('true', 'JJ'), ('generalization', 'NN'), ('loss', 'NN'), ('(', '('), ('2', 'CD'), (')', ')'), ('due', 'JJ'), ('process', 'NN'), ('model', 'NN'), ('selection', 'NN'), ('.', '.')]

 (S
  (NP This/DT generalization/NN loss/NN)
  estimated/VBN
  using/VBG
  (NP validation/NN)
  biased/VBD
  (NP estimate/NN)
  (NP true/JJ generalization/NN loss/NN)
  (/(
  2/CD
  )/)
  (NP due/JJ process/NN model/NN selection/NN)
  ./.) 


>> Noun Phrases are: 
 ['This generalization loss', 'validation', 'estimate', 'true generalization loss', 'due process model selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('generalization', 'gener'), ('loss', 'loss'), ('estimated', 'estim'), ('using', 'use'), ('validation', 'valid'), ('biased', 'bias'), ('estimate', 'estim'), ('true', 'true'), ('generalization', 'gener'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('due', 'due'), ('process', 'process'), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('generalization', 'general'), ('loss', 'loss'), ('estimated', 'estim'), ('using', 'use'), ('validation', 'valid'), ('biased', 'bias'), ('estimate', 'estim'), ('true', 'true'), ('generalization', 'general'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('due', 'due'), ('process', 'process'), ('model', 'model'), ('selection', 'select'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('generalization', 'generalization'), ('loss', 'loss'), ('estimated', 'estimated'), ('using', 'using'), ('validation', 'validation'), ('biased', 'biased'), ('estimate', 'estimate'), ('true', 'true'), ('generalization', 'generalization'), ('loss', 'loss'), ('(', '('), ('2', '2'), (')', ')'), ('due', 'due'), ('process', 'process'), ('model', 'model'), ('selection', 'selection'), ('.', '.')]



============================ Sentence 324 =============================

In particular, the loss on the validation set will tend to be small, since the model was selected during validation with the aim of minimizing it. 


>> Tokens are: 
 ['In', 'particular', ',', 'loss', 'validation', 'set', 'tend', 'small', ',', 'since', 'model', 'selected', 'validation', 'aim', 'minimizing', '.']

>> Bigrams are: 
 [('In', 'particular'), ('particular', ','), (',', 'loss'), ('loss', 'validation'), ('validation', 'set'), ('set', 'tend'), ('tend', 'small'), ('small', ','), (',', 'since'), ('since', 'model'), ('model', 'selected'), ('selected', 'validation'), ('validation', 'aim'), ('aim', 'minimizing'), ('minimizing', '.')]

>> Trigrams are: 
 [('In', 'particular', ','), ('particular', ',', 'loss'), (',', 'loss', 'validation'), ('loss', 'validation', 'set'), ('validation', 'set', 'tend'), ('set', 'tend', 'small'), ('tend', 'small', ','), ('small', ',', 'since'), (',', 'since', 'model'), ('since', 'model', 'selected'), ('model', 'selected', 'validation'), ('selected', 'validation', 'aim'), ('validation', 'aim', 'minimizing'), ('aim', 'minimizing', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('particular', 'JJ'), (',', ','), ('loss', 'NN'), ('validation', 'NN'), ('set', 'VBN'), ('tend', 'VBP'), ('small', 'JJ'), (',', ','), ('since', 'IN'), ('model', 'NN'), ('selected', 'VBN'), ('validation', 'NN'), ('aim', 'NN'), ('minimizing', 'NN'), ('.', '.')]

 (S
  In/IN
  particular/JJ
  ,/,
  (NP loss/NN validation/NN)
  set/VBN
  tend/VBP
  small/JJ
  ,/,
  since/IN
  (NP model/NN)
  selected/VBN
  (NP validation/NN aim/NN minimizing/NN)
  ./.) 


>> Noun Phrases are: 
 ['loss validation', 'model', 'validation aim minimizing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('particular', 'particular'), (',', ','), ('loss', 'loss'), ('validation', 'valid'), ('set', 'set'), ('tend', 'tend'), ('small', 'small'), (',', ','), ('since', 'sinc'), ('model', 'model'), ('selected', 'select'), ('validation', 'valid'), ('aim', 'aim'), ('minimizing', 'minim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('particular', 'particular'), (',', ','), ('loss', 'loss'), ('validation', 'valid'), ('set', 'set'), ('tend', 'tend'), ('small', 'small'), (',', ','), ('since', 'sinc'), ('model', 'model'), ('selected', 'select'), ('validation', 'valid'), ('aim', 'aim'), ('minimizing', 'minim'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('particular', 'particular'), (',', ','), ('loss', 'loss'), ('validation', 'validation'), ('set', 'set'), ('tend', 'tend'), ('small', 'small'), (',', ','), ('since', 'since'), ('model', 'model'), ('selected', 'selected'), ('validation', 'validation'), ('aim', 'aim'), ('minimizing', 'minimizing'), ('.', '.')]



============================ Sentence 325 =============================

Importantly, the test set should never be used during the three steps that make up the machine learning methodology and should ideally only be used once to test the trained predictor. 


>> Tokens are: 
 ['Importantly', ',', 'test', 'set', 'never', 'used', 'three', 'steps', 'make', 'machine', 'learning', 'methodology', 'ideally', 'used', 'test', 'trained', 'predictor', '.']

>> Bigrams are: 
 [('Importantly', ','), (',', 'test'), ('test', 'set'), ('set', 'never'), ('never', 'used'), ('used', 'three'), ('three', 'steps'), ('steps', 'make'), ('make', 'machine'), ('machine', 'learning'), ('learning', 'methodology'), ('methodology', 'ideally'), ('ideally', 'used'), ('used', 'test'), ('test', 'trained'), ('trained', 'predictor'), ('predictor', '.')]

>> Trigrams are: 
 [('Importantly', ',', 'test'), (',', 'test', 'set'), ('test', 'set', 'never'), ('set', 'never', 'used'), ('never', 'used', 'three'), ('used', 'three', 'steps'), ('three', 'steps', 'make'), ('steps', 'make', 'machine'), ('make', 'machine', 'learning'), ('machine', 'learning', 'methodology'), ('learning', 'methodology', 'ideally'), ('methodology', 'ideally', 'used'), ('ideally', 'used', 'test'), ('used', 'test', 'trained'), ('test', 'trained', 'predictor'), ('trained', 'predictor', '.')]

>> POS Tags are: 
 [('Importantly', 'RB'), (',', ','), ('test', 'NN'), ('set', 'NN'), ('never', 'RB'), ('used', 'VBD'), ('three', 'CD'), ('steps', 'NNS'), ('make', 'VBP'), ('machine', 'NN'), ('learning', 'VBG'), ('methodology', 'NN'), ('ideally', 'RB'), ('used', 'JJ'), ('test', 'NN'), ('trained', 'VBD'), ('predictor', 'NN'), ('.', '.')]

 (S
  Importantly/RB
  ,/,
  (NP test/NN set/NN)
  never/RB
  used/VBD
  three/CD
  (NP steps/NNS)
  make/VBP
  (NP machine/NN)
  learning/VBG
  (NP methodology/NN)
  ideally/RB
  (NP used/JJ test/NN)
  trained/VBD
  (NP predictor/NN)
  ./.) 


>> Noun Phrases are: 
 ['test set', 'steps', 'machine', 'methodology', 'used test', 'predictor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Importantly', 'importantli'), (',', ','), ('test', 'test'), ('set', 'set'), ('never', 'never'), ('used', 'use'), ('three', 'three'), ('steps', 'step'), ('make', 'make'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('ideally', 'ideal'), ('used', 'use'), ('test', 'test'), ('trained', 'train'), ('predictor', 'predictor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Importantly', 'import'), (',', ','), ('test', 'test'), ('set', 'set'), ('never', 'never'), ('used', 'use'), ('three', 'three'), ('steps', 'step'), ('make', 'make'), ('machine', 'machin'), ('learning', 'learn'), ('methodology', 'methodolog'), ('ideally', 'ideal'), ('used', 'use'), ('test', 'test'), ('trained', 'train'), ('predictor', 'predictor'), ('.', '.')]

>> Lemmatization: 
 [('Importantly', 'Importantly'), (',', ','), ('test', 'test'), ('set', 'set'), ('never', 'never'), ('used', 'used'), ('three', 'three'), ('steps', 'step'), ('make', 'make'), ('machine', 'machine'), ('learning', 'learning'), ('methodology', 'methodology'), ('ideally', 'ideally'), ('used', 'used'), ('test', 'test'), ('trained', 'trained'), ('predictor', 'predictor'), ('.', '.')]



============================ Sentence 326 =============================

IV. 


>> Tokens are: 
 ['IV', '.']

>> Bigrams are: 
 [('IV', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IV', 'NNP'), ('.', '.')]

 (S (NP IV/NNP) ./.) 


>> Noun Phrases are: 
 ['IV']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Lemmatization: 
 [('IV', 'IV'), ('.', '.')]



============================ Sentence 327 =============================

APPLICATIONS OF SUPERVISED LEARNING TO COMMUNICATION SYSTEMS  In this section, we provide some pointers to existing applications of supervised learning to communication networks. 


>> Tokens are: 
 ['APPLICATIONS', 'OF', 'SUPERVISED', 'LEARNING', 'TO', 'COMMUNICATION', 'SYSTEMS', 'In', 'section', ',', 'provide', 'pointers', 'existing', 'applications', 'supervised', 'learning', 'communication', 'networks', '.']

>> Bigrams are: 
 [('APPLICATIONS', 'OF'), ('OF', 'SUPERVISED'), ('SUPERVISED', 'LEARNING'), ('LEARNING', 'TO'), ('TO', 'COMMUNICATION'), ('COMMUNICATION', 'SYSTEMS'), ('SYSTEMS', 'In'), ('In', 'section'), ('section', ','), (',', 'provide'), ('provide', 'pointers'), ('pointers', 'existing'), ('existing', 'applications'), ('applications', 'supervised'), ('supervised', 'learning'), ('learning', 'communication'), ('communication', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('APPLICATIONS', 'OF', 'SUPERVISED'), ('OF', 'SUPERVISED', 'LEARNING'), ('SUPERVISED', 'LEARNING', 'TO'), ('LEARNING', 'TO', 'COMMUNICATION'), ('TO', 'COMMUNICATION', 'SYSTEMS'), ('COMMUNICATION', 'SYSTEMS', 'In'), ('SYSTEMS', 'In', 'section'), ('In', 'section', ','), ('section', ',', 'provide'), (',', 'provide', 'pointers'), ('provide', 'pointers', 'existing'), ('pointers', 'existing', 'applications'), ('existing', 'applications', 'supervised'), ('applications', 'supervised', 'learning'), ('supervised', 'learning', 'communication'), ('learning', 'communication', 'networks'), ('communication', 'networks', '.')]

>> POS Tags are: 
 [('APPLICATIONS', 'NNP'), ('OF', 'NNP'), ('SUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('TO', 'NNP'), ('COMMUNICATION', 'NNP'), ('SYSTEMS', 'NNP'), ('In', 'IN'), ('section', 'NN'), (',', ','), ('provide', 'VBP'), ('pointers', 'NNS'), ('existing', 'VBG'), ('applications', 'NNS'), ('supervised', 'VBD'), ('learning', 'VBG'), ('communication', 'NN'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP
    APPLICATIONS/NNP
    OF/NNP
    SUPERVISED/NNP
    LEARNING/NNP
    TO/NNP
    COMMUNICATION/NNP
    SYSTEMS/NNP)
  In/IN
  (NP section/NN)
  ,/,
  provide/VBP
  (NP pointers/NNS)
  existing/VBG
  (NP applications/NNS)
  supervised/VBD
  learning/VBG
  (NP communication/NN networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['APPLICATIONS OF SUPERVISED LEARNING TO COMMUNICATION SYSTEMS', 'section', 'pointers', 'applications', 'communication networks']

>> Named Entities are: 
 [('ORGANIZATION', 'COMMUNICATION')] 

>> Stemming using Porter Stemmer: 
 [('APPLICATIONS', 'applic'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('TO', 'to'), ('COMMUNICATION', 'commun'), ('SYSTEMS', 'system'), ('In', 'in'), ('section', 'section'), (',', ','), ('provide', 'provid'), ('pointers', 'pointer'), ('existing', 'exist'), ('applications', 'applic'), ('supervised', 'supervis'), ('learning', 'learn'), ('communication', 'commun'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('APPLICATIONS', 'applic'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('TO', 'to'), ('COMMUNICATION', 'communic'), ('SYSTEMS', 'system'), ('In', 'in'), ('section', 'section'), (',', ','), ('provide', 'provid'), ('pointers', 'pointer'), ('existing', 'exist'), ('applications', 'applic'), ('supervised', 'supervis'), ('learning', 'learn'), ('communication', 'communic'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('APPLICATIONS', 'APPLICATIONS'), ('OF', 'OF'), ('SUPERVISED', 'SUPERVISED'), ('LEARNING', 'LEARNING'), ('TO', 'TO'), ('COMMUNICATION', 'COMMUNICATION'), ('SYSTEMS', 'SYSTEMS'), ('In', 'In'), ('section', 'section'), (',', ','), ('provide', 'provide'), ('pointers', 'pointer'), ('existing', 'existing'), ('applications', 'application'), ('supervised', 'supervised'), ('learning', 'learning'), ('communication', 'communication'), ('networks', 'network'), ('.', '.')]



============================ Sentence 328 =============================

The discussion is organized by following the approach described in Sec. 


>> Tokens are: 
 ['The', 'discussion', 'organized', 'following', 'approach', 'described', 'Sec', '.']

>> Bigrams are: 
 [('The', 'discussion'), ('discussion', 'organized'), ('organized', 'following'), ('following', 'approach'), ('approach', 'described'), ('described', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('The', 'discussion', 'organized'), ('discussion', 'organized', 'following'), ('organized', 'following', 'approach'), ('following', 'approach', 'described'), ('approach', 'described', 'Sec'), ('described', 'Sec', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('discussion', 'NN'), ('organized', 'VBD'), ('following', 'VBG'), ('approach', 'NN'), ('described', 'VBD'), ('Sec', 'NNP'), ('.', '.')]

 (S
  (NP The/DT discussion/NN)
  organized/VBD
  following/VBG
  (NP approach/NN)
  described/VBD
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The discussion', 'approach', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('discussion', 'discuss'), ('organized', 'organ'), ('following', 'follow'), ('approach', 'approach'), ('described', 'describ'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('discussion', 'discuss'), ('organized', 'organ'), ('following', 'follow'), ('approach', 'approach'), ('described', 'describ'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('discussion', 'discussion'), ('organized', 'organized'), ('following', 'following'), ('approach', 'approach'), ('described', 'described'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 329 =============================

II. 


>> Tokens are: 
 ['II', '.']

>> Bigrams are: 
 [('II', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('II', 'NNP'), ('.', '.')]

 (S (NP II/NNP) ./.) 


>> Noun Phrases are: 
 ['II']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), ('.', '.')]

>> Lemmatization: 
 [('II', 'II'), ('.', '.')]



============================ Sentence 330 =============================

Accordingly, we distin- guish between tasks carried out at edge and cloud (see  10    1 2 3 4 5 6 7 8 9 0  0.2  0.4  0.6  0.8  1  1.2  1.4  1.6 ro  ot  a  ve ra  ge  s  qu ar  ed  l  os s  training  generalization  (via validation)  overfittingunderfitting  Fig 10 Training loss and generalization loss, estimated via valida- tion, as a function of the model order M for the example in Fig 9  Fig 4), as well as at different layers of the protocol stack. 


>> Tokens are: 
 ['Accordingly', ',', 'distin-', 'guish', 'tasks', 'carried', 'edge', 'cloud', '(', 'see', '10', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '0.2', '0.4', '0.6', '0.8', '1', '1.2', '1.4', '1.6', 'ro', 'ot', 'ra', 'ge', 'qu', 'ar', 'ed', 'l', 'os', 'training', 'generalization', '(', 'via', 'validation', ')', 'overfittingunderfitting', 'Fig', '10', 'Training', 'loss', 'generalization', 'loss', ',', 'estimated', 'via', 'valida-', 'tion', ',', 'function', 'model', 'order', 'M', 'example', 'Fig', '9', 'Fig', '4', ')', ',', 'well', 'different', 'layers', 'protocol', 'stack', '.']

>> Bigrams are: 
 [('Accordingly', ','), (',', 'distin-'), ('distin-', 'guish'), ('guish', 'tasks'), ('tasks', 'carried'), ('carried', 'edge'), ('edge', 'cloud'), ('cloud', '('), ('(', 'see'), ('see', '10'), ('10', '1'), ('1', '2'), ('2', '3'), ('3', '4'), ('4', '5'), ('5', '6'), ('6', '7'), ('7', '8'), ('8', '9'), ('9', '0'), ('0', '0.2'), ('0.2', '0.4'), ('0.4', '0.6'), ('0.6', '0.8'), ('0.8', '1'), ('1', '1.2'), ('1.2', '1.4'), ('1.4', '1.6'), ('1.6', 'ro'), ('ro', 'ot'), ('ot', 'ra'), ('ra', 'ge'), ('ge', 'qu'), ('qu', 'ar'), ('ar', 'ed'), ('ed', 'l'), ('l', 'os'), ('os', 'training'), ('training', 'generalization'), ('generalization', '('), ('(', 'via'), ('via', 'validation'), ('validation', ')'), (')', 'overfittingunderfitting'), ('overfittingunderfitting', 'Fig'), ('Fig', '10'), ('10', 'Training'), ('Training', 'loss'), ('loss', 'generalization'), ('generalization', 'loss'), ('loss', ','), (',', 'estimated'), ('estimated', 'via'), ('via', 'valida-'), ('valida-', 'tion'), ('tion', ','), (',', 'function'), ('function', 'model'), ('model', 'order'), ('order', 'M'), ('M', 'example'), ('example', 'Fig'), ('Fig', '9'), ('9', 'Fig'), ('Fig', '4'), ('4', ')'), (')', ','), (',', 'well'), ('well', 'different'), ('different', 'layers'), ('layers', 'protocol'), ('protocol', 'stack'), ('stack', '.')]

>> Trigrams are: 
 [('Accordingly', ',', 'distin-'), (',', 'distin-', 'guish'), ('distin-', 'guish', 'tasks'), ('guish', 'tasks', 'carried'), ('tasks', 'carried', 'edge'), ('carried', 'edge', 'cloud'), ('edge', 'cloud', '('), ('cloud', '(', 'see'), ('(', 'see', '10'), ('see', '10', '1'), ('10', '1', '2'), ('1', '2', '3'), ('2', '3', '4'), ('3', '4', '5'), ('4', '5', '6'), ('5', '6', '7'), ('6', '7', '8'), ('7', '8', '9'), ('8', '9', '0'), ('9', '0', '0.2'), ('0', '0.2', '0.4'), ('0.2', '0.4', '0.6'), ('0.4', '0.6', '0.8'), ('0.6', '0.8', '1'), ('0.8', '1', '1.2'), ('1', '1.2', '1.4'), ('1.2', '1.4', '1.6'), ('1.4', '1.6', 'ro'), ('1.6', 'ro', 'ot'), ('ro', 'ot', 'ra'), ('ot', 'ra', 'ge'), ('ra', 'ge', 'qu'), ('ge', 'qu', 'ar'), ('qu', 'ar', 'ed'), ('ar', 'ed', 'l'), ('ed', 'l', 'os'), ('l', 'os', 'training'), ('os', 'training', 'generalization'), ('training', 'generalization', '('), ('generalization', '(', 'via'), ('(', 'via', 'validation'), ('via', 'validation', ')'), ('validation', ')', 'overfittingunderfitting'), (')', 'overfittingunderfitting', 'Fig'), ('overfittingunderfitting', 'Fig', '10'), ('Fig', '10', 'Training'), ('10', 'Training', 'loss'), ('Training', 'loss', 'generalization'), ('loss', 'generalization', 'loss'), ('generalization', 'loss', ','), ('loss', ',', 'estimated'), (',', 'estimated', 'via'), ('estimated', 'via', 'valida-'), ('via', 'valida-', 'tion'), ('valida-', 'tion', ','), ('tion', ',', 'function'), (',', 'function', 'model'), ('function', 'model', 'order'), ('model', 'order', 'M'), ('order', 'M', 'example'), ('M', 'example', 'Fig'), ('example', 'Fig', '9'), ('Fig', '9', 'Fig'), ('9', 'Fig', '4'), ('Fig', '4', ')'), ('4', ')', ','), (')', ',', 'well'), (',', 'well', 'different'), ('well', 'different', 'layers'), ('different', 'layers', 'protocol'), ('layers', 'protocol', 'stack'), ('protocol', 'stack', '.')]

>> POS Tags are: 
 [('Accordingly', 'RB'), (',', ','), ('distin-', 'JJ'), ('guish', 'JJ'), ('tasks', 'NNS'), ('carried', 'VBD'), ('edge', 'JJ'), ('cloud', 'NN'), ('(', '('), ('see', 'VB'), ('10', 'CD'), ('1', 'CD'), ('2', 'CD'), ('3', 'CD'), ('4', 'CD'), ('5', 'CD'), ('6', 'CD'), ('7', 'CD'), ('8', 'CD'), ('9', 'CD'), ('0', 'CD'), ('0.2', 'CD'), ('0.4', 'CD'), ('0.6', 'CD'), ('0.8', 'CD'), ('1', 'CD'), ('1.2', 'CD'), ('1.4', 'CD'), ('1.6', 'CD'), ('ro', 'NN'), ('ot', 'NN'), ('ra', 'NN'), ('ge', 'NN'), ('qu', 'NN'), ('ar', 'NN'), ('ed', 'NN'), ('l', 'NN'), ('os', 'IN'), ('training', 'VBG'), ('generalization', 'NN'), ('(', '('), ('via', 'IN'), ('validation', 'NN'), (')', ')'), ('overfittingunderfitting', 'VBG'), ('Fig', 'NNP'), ('10', 'CD'), ('Training', 'NNP'), ('loss', 'NN'), ('generalization', 'NN'), ('loss', 'NN'), (',', ','), ('estimated', 'VBN'), ('via', 'IN'), ('valida-', 'JJ'), ('tion', 'NN'), (',', ','), ('function', 'NN'), ('model', 'NN'), ('order', 'NN'), ('M', 'NNP'), ('example', 'NN'), ('Fig', 'NNP'), ('9', 'CD'), ('Fig', 'NNP'), ('4', 'CD'), (')', ')'), (',', ','), ('well', 'RB'), ('different', 'JJ'), ('layers', 'NNS'), ('protocol', 'VBP'), ('stack', 'NN'), ('.', '.')]

 (S
  Accordingly/RB
  ,/,
  (NP distin-/JJ guish/JJ tasks/NNS)
  carried/VBD
  (NP edge/JJ cloud/NN)
  (/(
  see/VB
  10/CD
  1/CD
  2/CD
  3/CD
  4/CD
  5/CD
  6/CD
  7/CD
  8/CD
  9/CD
  0/CD
  0.2/CD
  0.4/CD
  0.6/CD
  0.8/CD
  1/CD
  1.2/CD
  1.4/CD
  1.6/CD
  (NP ro/NN ot/NN ra/NN ge/NN qu/NN ar/NN ed/NN l/NN)
  os/IN
  training/VBG
  (NP generalization/NN)
  (/(
  via/IN
  (NP validation/NN)
  )/)
  overfittingunderfitting/VBG
  (NP Fig/NNP)
  10/CD
  (NP Training/NNP loss/NN generalization/NN loss/NN)
  ,/,
  estimated/VBN
  via/IN
  (NP valida-/JJ tion/NN)
  ,/,
  (NP function/NN model/NN order/NN M/NNP example/NN Fig/NNP)
  9/CD
  (NP Fig/NNP)
  4/CD
  )/)
  ,/,
  well/RB
  (NP different/JJ layers/NNS)
  protocol/VBP
  (NP stack/NN)
  ./.) 


>> Noun Phrases are: 
 ['distin- guish tasks', 'edge cloud', 'ro ot ra ge qu ar ed l', 'generalization', 'validation', 'Fig', 'Training loss generalization loss', 'valida- tion', 'function model order M example Fig', 'Fig', 'different layers', 'stack']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accordingly', 'accordingli'), (',', ','), ('distin-', 'distin-'), ('guish', 'guish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('cloud', 'cloud'), ('(', '('), ('see', 'see'), ('10', '10'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('1.2', '1.2'), ('1.4', '1.4'), ('1.6', '1.6'), ('ro', 'ro'), ('ot', 'ot'), ('ra', 'ra'), ('ge', 'ge'), ('qu', 'qu'), ('ar', 'ar'), ('ed', 'ed'), ('l', 'l'), ('os', 'os'), ('training', 'train'), ('generalization', 'gener'), ('(', '('), ('via', 'via'), ('validation', 'valid'), (')', ')'), ('overfittingunderfitting', 'overfittingunderfit'), ('Fig', 'fig'), ('10', '10'), ('Training', 'train'), ('loss', 'loss'), ('generalization', 'gener'), ('loss', 'loss'), (',', ','), ('estimated', 'estim'), ('via', 'via'), ('valida-', 'valida-'), ('tion', 'tion'), (',', ','), ('function', 'function'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('example', 'exampl'), ('Fig', 'fig'), ('9', '9'), ('Fig', 'fig'), ('4', '4'), (')', ')'), (',', ','), ('well', 'well'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accordingly', 'accord'), (',', ','), ('distin-', 'distin-'), ('guish', 'guish'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), ('cloud', 'cloud'), ('(', '('), ('see', 'see'), ('10', '10'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('1.2', '1.2'), ('1.4', '1.4'), ('1.6', '1.6'), ('ro', 'ro'), ('ot', 'ot'), ('ra', 'ra'), ('ge', 'ge'), ('qu', 'qu'), ('ar', 'ar'), ('ed', 'ed'), ('l', 'l'), ('os', 'os'), ('training', 'train'), ('generalization', 'general'), ('(', '('), ('via', 'via'), ('validation', 'valid'), (')', ')'), ('overfittingunderfitting', 'overfittingunderfit'), ('Fig', 'fig'), ('10', '10'), ('Training', 'train'), ('loss', 'loss'), ('generalization', 'general'), ('loss', 'loss'), (',', ','), ('estimated', 'estim'), ('via', 'via'), ('valida-', 'valida-'), ('tion', 'tion'), (',', ','), ('function', 'function'), ('model', 'model'), ('order', 'order'), ('M', 'm'), ('example', 'exampl'), ('Fig', 'fig'), ('9', '9'), ('Fig', 'fig'), ('4', '4'), (')', ')'), (',', ','), ('well', 'well'), ('different', 'differ'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), ('.', '.')]

>> Lemmatization: 
 [('Accordingly', 'Accordingly'), (',', ','), ('distin-', 'distin-'), ('guish', 'guish'), ('tasks', 'task'), ('carried', 'carried'), ('edge', 'edge'), ('cloud', 'cloud'), ('(', '('), ('see', 'see'), ('10', '10'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9'), ('0', '0'), ('0.2', '0.2'), ('0.4', '0.4'), ('0.6', '0.6'), ('0.8', '0.8'), ('1', '1'), ('1.2', '1.2'), ('1.4', '1.4'), ('1.6', '1.6'), ('ro', 'ro'), ('ot', 'ot'), ('ra', 'ra'), ('ge', 'ge'), ('qu', 'qu'), ('ar', 'ar'), ('ed', 'ed'), ('l', 'l'), ('os', 'o'), ('training', 'training'), ('generalization', 'generalization'), ('(', '('), ('via', 'via'), ('validation', 'validation'), (')', ')'), ('overfittingunderfitting', 'overfittingunderfitting'), ('Fig', 'Fig'), ('10', '10'), ('Training', 'Training'), ('loss', 'loss'), ('generalization', 'generalization'), ('loss', 'loss'), (',', ','), ('estimated', 'estimated'), ('via', 'via'), ('valida-', 'valida-'), ('tion', 'tion'), (',', ','), ('function', 'function'), ('model', 'model'), ('order', 'order'), ('M', 'M'), ('example', 'example'), ('Fig', 'Fig'), ('9', '9'), ('Fig', 'Fig'), ('4', '4'), (')', ')'), (',', ','), ('well', 'well'), ('different', 'different'), ('layers', 'layer'), ('protocol', 'protocol'), ('stack', 'stack'), ('.', '.')]



============================ Sentence 331 =============================

We refer to Table I and Table II for examples of data types that may be available at the edge and cloud segments. 


>> Tokens are: 
 ['We', 'refer', 'Table', 'I', 'Table', 'II', 'examples', 'data', 'types', 'may', 'available', 'edge', 'cloud', 'segments', '.']

>> Bigrams are: 
 [('We', 'refer'), ('refer', 'Table'), ('Table', 'I'), ('I', 'Table'), ('Table', 'II'), ('II', 'examples'), ('examples', 'data'), ('data', 'types'), ('types', 'may'), ('may', 'available'), ('available', 'edge'), ('edge', 'cloud'), ('cloud', 'segments'), ('segments', '.')]

>> Trigrams are: 
 [('We', 'refer', 'Table'), ('refer', 'Table', 'I'), ('Table', 'I', 'Table'), ('I', 'Table', 'II'), ('Table', 'II', 'examples'), ('II', 'examples', 'data'), ('examples', 'data', 'types'), ('data', 'types', 'may'), ('types', 'may', 'available'), ('may', 'available', 'edge'), ('available', 'edge', 'cloud'), ('edge', 'cloud', 'segments'), ('cloud', 'segments', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('refer', 'VBP'), ('Table', 'JJ'), ('I', 'PRP'), ('Table', 'VBP'), ('II', 'JJ'), ('examples', 'NNS'), ('data', 'NNS'), ('types', 'NNS'), ('may', 'MD'), ('available', 'JJ'), ('edge', 'NN'), ('cloud', 'NN'), ('segments', 'NNS'), ('.', '.')]

 (S
  We/PRP
  refer/VBP
  Table/JJ
  I/PRP
  Table/VBP
  (NP II/JJ examples/NNS data/NNS types/NNS)
  may/MD
  (NP available/JJ edge/NN cloud/NN segments/NNS)
  ./.) 


>> Noun Phrases are: 
 ['II examples data types', 'available edge cloud segments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('refer', 'refer'), ('Table', 'tabl'), ('I', 'i'), ('Table', 'tabl'), ('II', 'ii'), ('examples', 'exampl'), ('data', 'data'), ('types', 'type'), ('may', 'may'), ('available', 'avail'), ('edge', 'edg'), ('cloud', 'cloud'), ('segments', 'segment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('refer', 'refer'), ('Table', 'tabl'), ('I', 'i'), ('Table', 'tabl'), ('II', 'ii'), ('examples', 'exampl'), ('data', 'data'), ('types', 'type'), ('may', 'may'), ('available', 'avail'), ('edge', 'edg'), ('cloud', 'cloud'), ('segments', 'segment'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('refer', 'refer'), ('Table', 'Table'), ('I', 'I'), ('Table', 'Table'), ('II', 'II'), ('examples', 'example'), ('data', 'data'), ('types', 'type'), ('may', 'may'), ('available', 'available'), ('edge', 'edge'), ('cloud', 'cloud'), ('segments', 'segment'), ('.', '.')]



============================ Sentence 332 =============================

A. 


>> Tokens are: 
 ['A', '.']

>> Bigrams are: 
 [('A', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('.', '.')]

 (S A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('.', '.')]



============================ Sentence 333 =============================

At the Edge  Consider first tasks to be carried out at the edge, i.e.-, at the base stations or at the associated edge computing platform. 


>> Tokens are: 
 ['At', 'Edge', 'Consider', 'first', 'tasks', 'carried', 'edge', ',', 'i.e.-', ',', 'base', 'stations', 'associated', 'edge', 'computing', 'platform', '.']

>> Bigrams are: 
 [('At', 'Edge'), ('Edge', 'Consider'), ('Consider', 'first'), ('first', 'tasks'), ('tasks', 'carried'), ('carried', 'edge'), ('edge', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'base'), ('base', 'stations'), ('stations', 'associated'), ('associated', 'edge'), ('edge', 'computing'), ('computing', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('At', 'Edge', 'Consider'), ('Edge', 'Consider', 'first'), ('Consider', 'first', 'tasks'), ('first', 'tasks', 'carried'), ('tasks', 'carried', 'edge'), ('carried', 'edge', ','), ('edge', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'base'), (',', 'base', 'stations'), ('base', 'stations', 'associated'), ('stations', 'associated', 'edge'), ('associated', 'edge', 'computing'), ('edge', 'computing', 'platform'), ('computing', 'platform', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('Edge', 'NNP'), ('Consider', 'NNP'), ('first', 'JJ'), ('tasks', 'NNS'), ('carried', 'VBD'), ('edge', 'NN'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('base', 'JJ'), ('stations', 'NNS'), ('associated', 'VBN'), ('edge', 'NN'), ('computing', 'VBG'), ('platform', 'NN'), ('.', '.')]

 (S
  At/IN
  (NP Edge/NNP Consider/NNP)
  (NP first/JJ tasks/NNS)
  carried/VBD
  (NP edge/NN)
  ,/,
  i.e.-/JJ
  ,/,
  (NP base/JJ stations/NNS)
  associated/VBN
  (NP edge/NN)
  computing/VBG
  (NP platform/NN)
  ./.) 


>> Noun Phrases are: 
 ['Edge Consider', 'first tasks', 'edge', 'base stations', 'edge', 'platform']

>> Named Entities are: 
 [('ORGANIZATION', 'Edge')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('Edge', 'edg'), ('Consider', 'consid'), ('first', 'first'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('base', 'base'), ('stations', 'station'), ('associated', 'associ'), ('edge', 'edg'), ('computing', 'comput'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('Edge', 'edg'), ('Consider', 'consid'), ('first', 'first'), ('tasks', 'task'), ('carried', 'carri'), ('edge', 'edg'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('base', 'base'), ('stations', 'station'), ('associated', 'associ'), ('edge', 'edg'), ('computing', 'comput'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('Edge', 'Edge'), ('Consider', 'Consider'), ('first', 'first'), ('tasks', 'task'), ('carried', 'carried'), ('edge', 'edge'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('base', 'base'), ('stations', 'station'), ('associated', 'associated'), ('edge', 'edge'), ('computing', 'computing'), ('platform', 'platform'), ('.', '.')]



============================ Sentence 334 =============================

(1) Physical Layer: For the physical layer, we focus first on the receiver side and then on the transmitter. 


>> Tokens are: 
 ['(', '1', ')', 'Physical', 'Layer', ':', 'For', 'physical', 'layer', ',', 'focus', 'first', 'receiver', 'side', 'transmitter', '.']

>> Bigrams are: 
 [('(', '1'), ('1', ')'), (')', 'Physical'), ('Physical', 'Layer'), ('Layer', ':'), (':', 'For'), ('For', 'physical'), ('physical', 'layer'), ('layer', ','), (',', 'focus'), ('focus', 'first'), ('first', 'receiver'), ('receiver', 'side'), ('side', 'transmitter'), ('transmitter', '.')]

>> Trigrams are: 
 [('(', '1', ')'), ('1', ')', 'Physical'), (')', 'Physical', 'Layer'), ('Physical', 'Layer', ':'), ('Layer', ':', 'For'), (':', 'For', 'physical'), ('For', 'physical', 'layer'), ('physical', 'layer', ','), ('layer', ',', 'focus'), (',', 'focus', 'first'), ('focus', 'first', 'receiver'), ('first', 'receiver', 'side'), ('receiver', 'side', 'transmitter'), ('side', 'transmitter', '.')]

>> POS Tags are: 
 [('(', '('), ('1', 'CD'), (')', ')'), ('Physical', 'NNP'), ('Layer', 'NNP'), (':', ':'), ('For', 'IN'), ('physical', 'JJ'), ('layer', 'NN'), (',', ','), ('focus', 'NN'), ('first', 'RB'), ('receiver', 'JJ'), ('side', 'NN'), ('transmitter', 'NN'), ('.', '.')]

 (S
  (/(
  1/CD
  )/)
  (NP Physical/NNP Layer/NNP)
  :/:
  For/IN
  (NP physical/JJ layer/NN)
  ,/,
  (NP focus/NN)
  first/RB
  (NP receiver/JJ side/NN transmitter/NN)
  ./.) 


>> Noun Phrases are: 
 ['Physical Layer', 'physical layer', 'focus', 'receiver side transmitter']

>> Named Entities are: 
 [('PERSON', 'Physical Layer')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Physical', 'physic'), ('Layer', 'layer'), (':', ':'), ('For', 'for'), ('physical', 'physic'), ('layer', 'layer'), (',', ','), ('focus', 'focu'), ('first', 'first'), ('receiver', 'receiv'), ('side', 'side'), ('transmitter', 'transmitt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Physical', 'physic'), ('Layer', 'layer'), (':', ':'), ('For', 'for'), ('physical', 'physic'), ('layer', 'layer'), (',', ','), ('focus', 'focus'), ('first', 'first'), ('receiver', 'receiv'), ('side', 'side'), ('transmitter', 'transmitt'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1', '1'), (')', ')'), ('Physical', 'Physical'), ('Layer', 'Layer'), (':', ':'), ('For', 'For'), ('physical', 'physical'), ('layer', 'layer'), (',', ','), ('focus', 'focus'), ('first', 'first'), ('receiver', 'receiver'), ('side', 'side'), ('transmitter', 'transmitter'), ('.', '.')]



============================ Sentence 335 =============================

At the receiver, a central task that can potentially ben- efit from machine learning is channel detection and decoding. 


>> Tokens are: 
 ['At', 'receiver', ',', 'central', 'task', 'potentially', 'ben-', 'efit', 'machine', 'learning', 'channel', 'detection', 'decoding', '.']

>> Bigrams are: 
 [('At', 'receiver'), ('receiver', ','), (',', 'central'), ('central', 'task'), ('task', 'potentially'), ('potentially', 'ben-'), ('ben-', 'efit'), ('efit', 'machine'), ('machine', 'learning'), ('learning', 'channel'), ('channel', 'detection'), ('detection', 'decoding'), ('decoding', '.')]

>> Trigrams are: 
 [('At', 'receiver', ','), ('receiver', ',', 'central'), (',', 'central', 'task'), ('central', 'task', 'potentially'), ('task', 'potentially', 'ben-'), ('potentially', 'ben-', 'efit'), ('ben-', 'efit', 'machine'), ('efit', 'machine', 'learning'), ('machine', 'learning', 'channel'), ('learning', 'channel', 'detection'), ('channel', 'detection', 'decoding'), ('detection', 'decoding', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('receiver', 'NN'), (',', ','), ('central', 'JJ'), ('task', 'NN'), ('potentially', 'RB'), ('ben-', 'JJ'), ('efit', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('channel', 'NNS'), ('detection', 'NN'), ('decoding', 'NN'), ('.', '.')]

 (S
  At/IN
  (NP receiver/NN)
  ,/,
  (NP central/JJ task/NN)
  potentially/RB
  (NP ben-/JJ efit/NN machine/NN)
  learning/VBG
  (NP channel/NNS detection/NN decoding/NN)
  ./.) 


>> Noun Phrases are: 
 ['receiver', 'central task', 'ben- efit machine', 'channel detection decoding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('receiver', 'receiv'), (',', ','), ('central', 'central'), ('task', 'task'), ('potentially', 'potenti'), ('ben-', 'ben-'), ('efit', 'efit'), ('machine', 'machin'), ('learning', 'learn'), ('channel', 'channel'), ('detection', 'detect'), ('decoding', 'decod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('receiver', 'receiv'), (',', ','), ('central', 'central'), ('task', 'task'), ('potentially', 'potenti'), ('ben-', 'ben-'), ('efit', 'efit'), ('machine', 'machin'), ('learning', 'learn'), ('channel', 'channel'), ('detection', 'detect'), ('decoding', 'decod'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('receiver', 'receiver'), (',', ','), ('central', 'central'), ('task', 'task'), ('potentially', 'potentially'), ('ben-', 'ben-'), ('efit', 'efit'), ('machine', 'machine'), ('learning', 'learning'), ('channel', 'channel'), ('detection', 'detection'), ('decoding', 'decoding'), ('.', '.')]



============================ Sentence 336 =============================

This amounts to a multi-class classification problem, in which the input x is given by the received baseband signal and the output is the label of the correct transmitted message (e.g.-.-, the transmitted bits) [13], [30]. 


>> Tokens are: 
 ['This', 'amounts', 'multi-class', 'classification', 'problem', ',', 'input', 'x', 'given', 'received', 'baseband', 'signal', 'output', 'label', 'correct', 'transmitted', 'message', '(', 'e.g.-.-', ',', 'transmitted', 'bits', ')', '[', '13', ']', ',', '[', '30', ']', '.']

>> Bigrams are: 
 [('This', 'amounts'), ('amounts', 'multi-class'), ('multi-class', 'classification'), ('classification', 'problem'), ('problem', ','), (',', 'input'), ('input', 'x'), ('x', 'given'), ('given', 'received'), ('received', 'baseband'), ('baseband', 'signal'), ('signal', 'output'), ('output', 'label'), ('label', 'correct'), ('correct', 'transmitted'), ('transmitted', 'message'), ('message', '('), ('(', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'transmitted'), ('transmitted', 'bits'), ('bits', ')'), (')', '['), ('[', '13'), ('13', ']'), (']', ','), (',', '['), ('[', '30'), ('30', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'amounts', 'multi-class'), ('amounts', 'multi-class', 'classification'), ('multi-class', 'classification', 'problem'), ('classification', 'problem', ','), ('problem', ',', 'input'), (',', 'input', 'x'), ('input', 'x', 'given'), ('x', 'given', 'received'), ('given', 'received', 'baseband'), ('received', 'baseband', 'signal'), ('baseband', 'signal', 'output'), ('signal', 'output', 'label'), ('output', 'label', 'correct'), ('label', 'correct', 'transmitted'), ('correct', 'transmitted', 'message'), ('transmitted', 'message', '('), ('message', '(', 'e.g.-.-'), ('(', 'e.g.-.-', ','), ('e.g.-.-', ',', 'transmitted'), (',', 'transmitted', 'bits'), ('transmitted', 'bits', ')'), ('bits', ')', '['), (')', '[', '13'), ('[', '13', ']'), ('13', ']', ','), (']', ',', '['), (',', '[', '30'), ('[', '30', ']'), ('30', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('amounts', 'VBZ'), ('multi-class', 'JJ'), ('classification', 'NN'), ('problem', 'NN'), (',', ','), ('input', 'NN'), ('x', 'NNP'), ('given', 'VBN'), ('received', 'VBD'), ('baseband', 'JJ'), ('signal', 'JJ'), ('output', 'NN'), ('label', 'NN'), ('correct', 'NN'), ('transmitted', 'VBN'), ('message', 'NN'), ('(', '('), ('e.g.-.-', 'JJ'), (',', ','), ('transmitted', 'JJ'), ('bits', 'NNS'), (')', ')'), ('[', 'VBP'), ('13', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('30', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  This/DT
  amounts/VBZ
  (NP multi-class/JJ classification/NN problem/NN)
  ,/,
  (NP input/NN x/NNP)
  given/VBN
  received/VBD
  (NP baseband/JJ signal/JJ output/NN label/NN correct/NN)
  transmitted/VBN
  (NP message/NN)
  (/(
  e.g.-.-/JJ
  ,/,
  (NP transmitted/JJ bits/NNS)
  )/)
  [/VBP
  13/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  30/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['multi-class classification problem', 'input x', 'baseband signal output label correct', 'message', 'transmitted bits', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('amounts', 'amount'), ('multi-class', 'multi-class'), ('classification', 'classif'), ('problem', 'problem'), (',', ','), ('input', 'input'), ('x', 'x'), ('given', 'given'), ('received', 'receiv'), ('baseband', 'baseband'), ('signal', 'signal'), ('output', 'output'), ('label', 'label'), ('correct', 'correct'), ('transmitted', 'transmit'), ('message', 'messag'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transmitted', 'transmit'), ('bits', 'bit'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), (',', ','), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('amounts', 'amount'), ('multi-class', 'multi-class'), ('classification', 'classif'), ('problem', 'problem'), (',', ','), ('input', 'input'), ('x', 'x'), ('given', 'given'), ('received', 'receiv'), ('baseband', 'baseband'), ('signal', 'signal'), ('output', 'output'), ('label', 'label'), ('correct', 'correct'), ('transmitted', 'transmit'), ('message', 'messag'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transmitted', 'transmit'), ('bits', 'bit'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), (',', ','), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('amounts', 'amount'), ('multi-class', 'multi-class'), ('classification', 'classification'), ('problem', 'problem'), (',', ','), ('input', 'input'), ('x', 'x'), ('given', 'given'), ('received', 'received'), ('baseband', 'baseband'), ('signal', 'signal'), ('output', 'output'), ('label', 'label'), ('correct', 'correct'), ('transmitted', 'transmitted'), ('message', 'message'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transmitted', 'transmitted'), ('bits', 'bit'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), (',', ','), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]



============================ Sentence 337 =============================

When can machine learning help? 


>> Tokens are: 
 ['When', 'machine', 'learning', 'help', '?']

>> Bigrams are: 
 [('When', 'machine'), ('machine', 'learning'), ('learning', 'help'), ('help', '?')]

>> Trigrams are: 
 [('When', 'machine', 'learning'), ('machine', 'learning', 'help'), ('learning', 'help', '?')]

>> POS Tags are: 
 [('When', 'WRB'), ('machine', 'NN'), ('learning', 'VBG'), ('help', 'NN'), ('?', '.')]

 (S When/WRB (NP machine/NN) learning/VBG (NP help/NN) ?/.) 


>> Noun Phrases are: 
 ['machine', 'help']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('machine', 'machin'), ('learning', 'learn'), ('help', 'help'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('machine', 'machin'), ('learning', 'learn'), ('help', 'help'), ('?', '?')]

>> Lemmatization: 
 [('When', 'When'), ('machine', 'machine'), ('learning', 'learning'), ('help', 'help'), ('?', '?')]



============================ Sentence 338 =============================

Recalling the discussion in Sec. 


>> Tokens are: 
 ['Recalling', 'discussion', 'Sec', '.']

>> Bigrams are: 
 [('Recalling', 'discussion'), ('discussion', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Recalling', 'discussion', 'Sec'), ('discussion', 'Sec', '.')]

>> POS Tags are: 
 [('Recalling', 'VBG'), ('discussion', 'NN'), ('Sec', 'NNP'), ('.', '.')]

 (S Recalling/VBG (NP discussion/NN Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['discussion Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recalling', 'recal'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recalling', 'recal'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Recalling', 'Recalling'), ('discussion', 'discussion'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 339 =============================

II, we should first ask whether a modelling or algorithmic deficit exists. 


>> Tokens are: 
 ['II', ',', 'first', 'ask', 'whether', 'modelling', 'algorithmic', 'deficit', 'exists', '.']

>> Bigrams are: 
 [('II', ','), (',', 'first'), ('first', 'ask'), ('ask', 'whether'), ('whether', 'modelling'), ('modelling', 'algorithmic'), ('algorithmic', 'deficit'), ('deficit', 'exists'), ('exists', '.')]

>> Trigrams are: 
 [('II', ',', 'first'), (',', 'first', 'ask'), ('first', 'ask', 'whether'), ('ask', 'whether', 'modelling'), ('whether', 'modelling', 'algorithmic'), ('modelling', 'algorithmic', 'deficit'), ('algorithmic', 'deficit', 'exists'), ('deficit', 'exists', '.')]

>> POS Tags are: 
 [('II', 'NNP'), (',', ','), ('first', 'RB'), ('ask', 'VBZ'), ('whether', 'IN'), ('modelling', 'VBG'), ('algorithmic', 'JJ'), ('deficit', 'NN'), ('exists', 'NNS'), ('.', '.')]

 (S
  (NP II/NNP)
  ,/,
  first/RB
  ask/VBZ
  whether/IN
  modelling/VBG
  (NP algorithmic/JJ deficit/NN exists/NNS)
  ./.) 


>> Noun Phrases are: 
 ['II', 'algorithmic deficit exists']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), (',', ','), ('first', 'first'), ('ask', 'ask'), ('whether', 'whether'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), ('exists', 'exist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), (',', ','), ('first', 'first'), ('ask', 'ask'), ('whether', 'whether'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), ('exists', 'exist'), ('.', '.')]

>> Lemmatization: 
 [('II', 'II'), (',', ','), ('first', 'first'), ('ask', 'ask'), ('whether', 'whether'), ('modelling', 'modelling'), ('algorithmic', 'algorithmic'), ('deficit', 'deficit'), ('exists', 'exists'), ('.', '.')]



============================ Sentence 340 =============================

A model deficit may occur when operating over channels that do not have well-established mathematical models, such as for molecular communications [31]. 


>> Tokens are: 
 ['A', 'model', 'deficit', 'may', 'occur', 'operating', 'channels', 'well-established', 'mathematical', 'models', ',', 'molecular', 'communications', '[', '31', ']', '.']

>> Bigrams are: 
 [('A', 'model'), ('model', 'deficit'), ('deficit', 'may'), ('may', 'occur'), ('occur', 'operating'), ('operating', 'channels'), ('channels', 'well-established'), ('well-established', 'mathematical'), ('mathematical', 'models'), ('models', ','), (',', 'molecular'), ('molecular', 'communications'), ('communications', '['), ('[', '31'), ('31', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'model', 'deficit'), ('model', 'deficit', 'may'), ('deficit', 'may', 'occur'), ('may', 'occur', 'operating'), ('occur', 'operating', 'channels'), ('operating', 'channels', 'well-established'), ('channels', 'well-established', 'mathematical'), ('well-established', 'mathematical', 'models'), ('mathematical', 'models', ','), ('models', ',', 'molecular'), (',', 'molecular', 'communications'), ('molecular', 'communications', '['), ('communications', '[', '31'), ('[', '31', ']'), ('31', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('model', 'NN'), ('deficit', 'NN'), ('may', 'MD'), ('occur', 'VB'), ('operating', 'VBG'), ('channels', 'NNS'), ('well-established', 'JJ'), ('mathematical', 'JJ'), ('models', 'NNS'), (',', ','), ('molecular', 'JJ'), ('communications', 'NNS'), ('[', 'VBP'), ('31', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP A/DT model/NN deficit/NN)
  may/MD
  occur/VB
  operating/VBG
  (NP channels/NNS)
  (NP well-established/JJ mathematical/JJ models/NNS)
  ,/,
  (NP molecular/JJ communications/NNS)
  [/VBP
  31/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['A model deficit', 'channels', 'well-established mathematical models', 'molecular communications', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('model', 'model'), ('deficit', 'deficit'), ('may', 'may'), ('occur', 'occur'), ('operating', 'oper'), ('channels', 'channel'), ('well-established', 'well-establish'), ('mathematical', 'mathemat'), ('models', 'model'), (',', ','), ('molecular', 'molecular'), ('communications', 'commun'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('model', 'model'), ('deficit', 'deficit'), ('may', 'may'), ('occur', 'occur'), ('operating', 'oper'), ('channels', 'channel'), ('well-established', 'well-establish'), ('mathematical', 'mathemat'), ('models', 'model'), (',', ','), ('molecular', 'molecular'), ('communications', 'communic'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('model', 'model'), ('deficit', 'deficit'), ('may', 'may'), ('occur', 'occur'), ('operating', 'operating'), ('channels', 'channel'), ('well-established', 'well-established'), ('mathematical', 'mathematical'), ('models', 'model'), (',', ','), ('molecular', 'molecular'), ('communications', 'communication'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]



============================ Sentence 341 =============================

Algorithm deficit is more common, given that optimal decoders over a number of well-established channel models tend to be computationally complex. 


>> Tokens are: 
 ['Algorithm', 'deficit', 'common', ',', 'given', 'optimal', 'decoders', 'number', 'well-established', 'channel', 'models', 'tend', 'computationally', 'complex', '.']

>> Bigrams are: 
 [('Algorithm', 'deficit'), ('deficit', 'common'), ('common', ','), (',', 'given'), ('given', 'optimal'), ('optimal', 'decoders'), ('decoders', 'number'), ('number', 'well-established'), ('well-established', 'channel'), ('channel', 'models'), ('models', 'tend'), ('tend', 'computationally'), ('computationally', 'complex'), ('complex', '.')]

>> Trigrams are: 
 [('Algorithm', 'deficit', 'common'), ('deficit', 'common', ','), ('common', ',', 'given'), (',', 'given', 'optimal'), ('given', 'optimal', 'decoders'), ('optimal', 'decoders', 'number'), ('decoders', 'number', 'well-established'), ('number', 'well-established', 'channel'), ('well-established', 'channel', 'models'), ('channel', 'models', 'tend'), ('models', 'tend', 'computationally'), ('tend', 'computationally', 'complex'), ('computationally', 'complex', '.')]

>> POS Tags are: 
 [('Algorithm', 'NNP'), ('deficit', 'NN'), ('common', 'JJ'), (',', ','), ('given', 'VBN'), ('optimal', 'JJ'), ('decoders', 'NNS'), ('number', 'NN'), ('well-established', 'JJ'), ('channel', 'NN'), ('models', 'NNS'), ('tend', 'VBP'), ('computationally', 'RB'), ('complex', 'JJ'), ('.', '.')]

 (S
  (NP Algorithm/NNP deficit/NN)
  common/JJ
  ,/,
  given/VBN
  (NP optimal/JJ decoders/NNS number/NN)
  (NP well-established/JJ channel/NN models/NNS)
  tend/VBP
  computationally/RB
  complex/JJ
  ./.) 


>> Noun Phrases are: 
 ['Algorithm deficit', 'optimal decoders number', 'well-established channel models']

>> Named Entities are: 
 [('GPE', 'Algorithm')] 

>> Stemming using Porter Stemmer: 
 [('Algorithm', 'algorithm'), ('deficit', 'deficit'), ('common', 'common'), (',', ','), ('given', 'given'), ('optimal', 'optim'), ('decoders', 'decod'), ('number', 'number'), ('well-established', 'well-establish'), ('channel', 'channel'), ('models', 'model'), ('tend', 'tend'), ('computationally', 'comput'), ('complex', 'complex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Algorithm', 'algorithm'), ('deficit', 'deficit'), ('common', 'common'), (',', ','), ('given', 'given'), ('optimal', 'optim'), ('decoders', 'decod'), ('number', 'number'), ('well-established', 'well-establish'), ('channel', 'channel'), ('models', 'model'), ('tend', 'tend'), ('computationally', 'comput'), ('complex', 'complex'), ('.', '.')]

>> Lemmatization: 
 [('Algorithm', 'Algorithm'), ('deficit', 'deficit'), ('common', 'common'), (',', ','), ('given', 'given'), ('optimal', 'optimal'), ('decoders', 'decoder'), ('number', 'number'), ('well-established', 'well-established'), ('channel', 'channel'), ('models', 'model'), ('tend', 'tend'), ('computationally', 'computationally'), ('complex', 'complex'), ('.', '.')]



============================ Sentence 342 =============================

This is the case for channels with strong non-linearities, as recognized as early as the nineties in the context of satellite communication [2], [32] and more recently for optical communications [33]; or for modulation schemes such as continuous phase modulation [34] – another work from the nineties – or in multi–user networks [35]. 


>> Tokens are: 
 ['This', 'case', 'channels', 'strong', 'non-linearities', ',', 'recognized', 'early', 'nineties', 'context', 'satellite', 'communication', '[', '2', ']', ',', '[', '32', ']', 'recently', 'optical', 'communications', '[', '33', ']', ';', 'modulation', 'schemes', 'continuous', 'phase', 'modulation', '[', '34', ']', '–', 'another', 'work', 'nineties', '–', 'multi–user', 'networks', '[', '35', ']', '.']

>> Bigrams are: 
 [('This', 'case'), ('case', 'channels'), ('channels', 'strong'), ('strong', 'non-linearities'), ('non-linearities', ','), (',', 'recognized'), ('recognized', 'early'), ('early', 'nineties'), ('nineties', 'context'), ('context', 'satellite'), ('satellite', 'communication'), ('communication', '['), ('[', '2'), ('2', ']'), (']', ','), (',', '['), ('[', '32'), ('32', ']'), (']', 'recently'), ('recently', 'optical'), ('optical', 'communications'), ('communications', '['), ('[', '33'), ('33', ']'), (']', ';'), (';', 'modulation'), ('modulation', 'schemes'), ('schemes', 'continuous'), ('continuous', 'phase'), ('phase', 'modulation'), ('modulation', '['), ('[', '34'), ('34', ']'), (']', '–'), ('–', 'another'), ('another', 'work'), ('work', 'nineties'), ('nineties', '–'), ('–', 'multi–user'), ('multi–user', 'networks'), ('networks', '['), ('[', '35'), ('35', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'case', 'channels'), ('case', 'channels', 'strong'), ('channels', 'strong', 'non-linearities'), ('strong', 'non-linearities', ','), ('non-linearities', ',', 'recognized'), (',', 'recognized', 'early'), ('recognized', 'early', 'nineties'), ('early', 'nineties', 'context'), ('nineties', 'context', 'satellite'), ('context', 'satellite', 'communication'), ('satellite', 'communication', '['), ('communication', '[', '2'), ('[', '2', ']'), ('2', ']', ','), (']', ',', '['), (',', '[', '32'), ('[', '32', ']'), ('32', ']', 'recently'), (']', 'recently', 'optical'), ('recently', 'optical', 'communications'), ('optical', 'communications', '['), ('communications', '[', '33'), ('[', '33', ']'), ('33', ']', ';'), (']', ';', 'modulation'), (';', 'modulation', 'schemes'), ('modulation', 'schemes', 'continuous'), ('schemes', 'continuous', 'phase'), ('continuous', 'phase', 'modulation'), ('phase', 'modulation', '['), ('modulation', '[', '34'), ('[', '34', ']'), ('34', ']', '–'), (']', '–', 'another'), ('–', 'another', 'work'), ('another', 'work', 'nineties'), ('work', 'nineties', '–'), ('nineties', '–', 'multi–user'), ('–', 'multi–user', 'networks'), ('multi–user', 'networks', '['), ('networks', '[', '35'), ('[', '35', ']'), ('35', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('case', 'NN'), ('channels', 'VBZ'), ('strong', 'JJ'), ('non-linearities', 'NNS'), (',', ','), ('recognized', 'VBD'), ('early', 'JJ'), ('nineties', 'NNS'), ('context', 'VBP'), ('satellite', 'JJ'), ('communication', 'NN'), ('[', 'VBD'), ('2', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('32', 'CD'), (']', 'NN'), ('recently', 'RB'), ('optical', 'JJ'), ('communications', 'NNS'), ('[', 'VBP'), ('33', 'CD'), (']', 'NN'), (';', ':'), ('modulation', 'NN'), ('schemes', 'VBZ'), ('continuous', 'JJ'), ('phase', 'NN'), ('modulation', 'NN'), ('[', 'VBD'), ('34', 'CD'), (']', 'NNP'), ('–', 'NNP'), ('another', 'DT'), ('work', 'NN'), ('nineties', 'NNS'), ('–', 'VBP'), ('multi–user', 'JJR'), ('networks', 'NNS'), ('[', 'VBP'), ('35', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT case/NN)
  channels/VBZ
  (NP strong/JJ non-linearities/NNS)
  ,/,
  recognized/VBD
  (NP early/JJ nineties/NNS)
  context/VBP
  (NP satellite/JJ communication/NN)
  [/VBD
  2/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  32/CD
  (NP ]/NN)
  recently/RB
  (NP optical/JJ communications/NNS)
  [/VBP
  33/CD
  (NP ]/NN)
  ;/:
  (NP modulation/NN)
  schemes/VBZ
  (NP continuous/JJ phase/NN modulation/NN)
  [/VBD
  34/CD
  (NP ]/NNP –/NNP)
  (NP another/DT work/NN nineties/NNS)
  –/VBP
  multi–user/JJR
  (NP networks/NNS)
  [/VBP
  35/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This case', 'strong non-linearities', 'early nineties', 'satellite communication', ']', ']', 'optical communications', ']', 'modulation', 'continuous phase modulation', '] –', 'another work nineties', 'networks', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('case', 'case'), ('channels', 'channel'), ('strong', 'strong'), ('non-linearities', 'non-linear'), (',', ','), ('recognized', 'recogn'), ('early', 'earli'), ('nineties', 'nineti'), ('context', 'context'), ('satellite', 'satellit'), ('communication', 'commun'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('[', '['), ('32', '32'), (']', ']'), ('recently', 'recent'), ('optical', 'optic'), ('communications', 'commun'), ('[', '['), ('33', '33'), (']', ']'), (';', ';'), ('modulation', 'modul'), ('schemes', 'scheme'), ('continuous', 'continu'), ('phase', 'phase'), ('modulation', 'modul'), ('[', '['), ('34', '34'), (']', ']'), ('–', '–'), ('another', 'anoth'), ('work', 'work'), ('nineties', 'nineti'), ('–', '–'), ('multi–user', 'multi–us'), ('networks', 'network'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('case', 'case'), ('channels', 'channel'), ('strong', 'strong'), ('non-linearities', 'non-linear'), (',', ','), ('recognized', 'recogn'), ('early', 'earli'), ('nineties', 'nineti'), ('context', 'context'), ('satellite', 'satellit'), ('communication', 'communic'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('[', '['), ('32', '32'), (']', ']'), ('recently', 'recent'), ('optical', 'optic'), ('communications', 'communic'), ('[', '['), ('33', '33'), (']', ']'), (';', ';'), ('modulation', 'modul'), ('schemes', 'scheme'), ('continuous', 'continu'), ('phase', 'phase'), ('modulation', 'modul'), ('[', '['), ('34', '34'), (']', ']'), ('–', '–'), ('another', 'anoth'), ('work', 'work'), ('nineties', 'nineti'), ('–', '–'), ('multi–user', 'multi–us'), ('networks', 'network'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('case', 'case'), ('channels', 'channel'), ('strong', 'strong'), ('non-linearities', 'non-linearities'), (',', ','), ('recognized', 'recognized'), ('early', 'early'), ('nineties', 'ninety'), ('context', 'context'), ('satellite', 'satellite'), ('communication', 'communication'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('[', '['), ('32', '32'), (']', ']'), ('recently', 'recently'), ('optical', 'optical'), ('communications', 'communication'), ('[', '['), ('33', '33'), (']', ']'), (';', ';'), ('modulation', 'modulation'), ('schemes', 'scheme'), ('continuous', 'continuous'), ('phase', 'phase'), ('modulation', 'modulation'), ('[', '['), ('34', '34'), (']', ']'), ('–', '–'), ('another', 'another'), ('work', 'work'), ('nineties', 'ninety'), ('–', '–'), ('multi–user', 'multi–user'), ('networks', 'network'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]



============================ Sentence 343 =============================

Assuming that the problem at hand is characterized by a modelling or algorithmic deficit, then one should also  check the remaining criteria listed in Sec. 


>> Tokens are: 
 ['Assuming', 'problem', 'hand', 'characterized', 'modelling', 'algorithmic', 'deficit', ',', 'one', 'also', 'check', 'remaining', 'criteria', 'listed', 'Sec', '.']

>> Bigrams are: 
 [('Assuming', 'problem'), ('problem', 'hand'), ('hand', 'characterized'), ('characterized', 'modelling'), ('modelling', 'algorithmic'), ('algorithmic', 'deficit'), ('deficit', ','), (',', 'one'), ('one', 'also'), ('also', 'check'), ('check', 'remaining'), ('remaining', 'criteria'), ('criteria', 'listed'), ('listed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Assuming', 'problem', 'hand'), ('problem', 'hand', 'characterized'), ('hand', 'characterized', 'modelling'), ('characterized', 'modelling', 'algorithmic'), ('modelling', 'algorithmic', 'deficit'), ('algorithmic', 'deficit', ','), ('deficit', ',', 'one'), (',', 'one', 'also'), ('one', 'also', 'check'), ('also', 'check', 'remaining'), ('check', 'remaining', 'criteria'), ('remaining', 'criteria', 'listed'), ('criteria', 'listed', 'Sec'), ('listed', 'Sec', '.')]

>> POS Tags are: 
 [('Assuming', 'VBG'), ('problem', 'NN'), ('hand', 'NN'), ('characterized', 'VBD'), ('modelling', 'VBG'), ('algorithmic', 'JJ'), ('deficit', 'NN'), (',', ','), ('one', 'CD'), ('also', 'RB'), ('check', 'VB'), ('remaining', 'VBG'), ('criteria', 'NNS'), ('listed', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  Assuming/VBG
  (NP problem/NN hand/NN)
  characterized/VBD
  modelling/VBG
  (NP algorithmic/JJ deficit/NN)
  ,/,
  one/CD
  also/RB
  check/VB
  remaining/VBG
  (NP criteria/NNS)
  listed/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['problem hand', 'algorithmic deficit', 'criteria', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Assuming', 'assum'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'character'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('one', 'one'), ('also', 'also'), ('check', 'check'), ('remaining', 'remain'), ('criteria', 'criteria'), ('listed', 'list'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Assuming', 'assum'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'character'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), (',', ','), ('one', 'one'), ('also', 'also'), ('check', 'check'), ('remaining', 'remain'), ('criteria', 'criteria'), ('listed', 'list'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Assuming', 'Assuming'), ('problem', 'problem'), ('hand', 'hand'), ('characterized', 'characterized'), ('modelling', 'modelling'), ('algorithmic', 'algorithmic'), ('deficit', 'deficit'), (',', ','), ('one', 'one'), ('also', 'also'), ('check', 'check'), ('remaining', 'remaining'), ('criteria', 'criterion'), ('listed', 'listed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 344 =============================

II, particularly those regarding the rate of change of the phenomenon under study and the requirements in terms of perfor- mance guarantees. 


>> Tokens are: 
 ['II', ',', 'particularly', 'regarding', 'rate', 'change', 'phenomenon', 'study', 'requirements', 'terms', 'perfor-', 'mance', 'guarantees', '.']

>> Bigrams are: 
 [('II', ','), (',', 'particularly'), ('particularly', 'regarding'), ('regarding', 'rate'), ('rate', 'change'), ('change', 'phenomenon'), ('phenomenon', 'study'), ('study', 'requirements'), ('requirements', 'terms'), ('terms', 'perfor-'), ('perfor-', 'mance'), ('mance', 'guarantees'), ('guarantees', '.')]

>> Trigrams are: 
 [('II', ',', 'particularly'), (',', 'particularly', 'regarding'), ('particularly', 'regarding', 'rate'), ('regarding', 'rate', 'change'), ('rate', 'change', 'phenomenon'), ('change', 'phenomenon', 'study'), ('phenomenon', 'study', 'requirements'), ('study', 'requirements', 'terms'), ('requirements', 'terms', 'perfor-'), ('terms', 'perfor-', 'mance'), ('perfor-', 'mance', 'guarantees'), ('mance', 'guarantees', '.')]

>> POS Tags are: 
 [('II', 'NNP'), (',', ','), ('particularly', 'RB'), ('regarding', 'VBG'), ('rate', 'NN'), ('change', 'NN'), ('phenomenon', 'NN'), ('study', 'NN'), ('requirements', 'NNS'), ('terms', 'NNS'), ('perfor-', 'JJ'), ('mance', 'NN'), ('guarantees', 'NNS'), ('.', '.')]

 (S
  (NP II/NNP)
  ,/,
  particularly/RB
  regarding/VBG
  (NP
    rate/NN
    change/NN
    phenomenon/NN
    study/NN
    requirements/NNS
    terms/NNS)
  (NP perfor-/JJ mance/NN guarantees/NNS)
  ./.) 


>> Noun Phrases are: 
 ['II', 'rate change phenomenon study requirements terms', 'perfor- mance guarantees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), (',', ','), ('particularly', 'particularli'), ('regarding', 'regard'), ('rate', 'rate'), ('change', 'chang'), ('phenomenon', 'phenomenon'), ('study', 'studi'), ('requirements', 'requir'), ('terms', 'term'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('guarantees', 'guarante'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), (',', ','), ('particularly', 'particular'), ('regarding', 'regard'), ('rate', 'rate'), ('change', 'chang'), ('phenomenon', 'phenomenon'), ('study', 'studi'), ('requirements', 'requir'), ('terms', 'term'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('guarantees', 'guarante'), ('.', '.')]

>> Lemmatization: 
 [('II', 'II'), (',', ','), ('particularly', 'particularly'), ('regarding', 'regarding'), ('rate', 'rate'), ('change', 'change'), ('phenomenon', 'phenomenon'), ('study', 'study'), ('requirements', 'requirement'), ('terms', 'term'), ('perfor-', 'perfor-'), ('mance', 'mance'), ('guarantees', 'guarantee'), ('.', '.')]



============================ Sentence 345 =============================

For channel decoding, the presence of fast-varying channels may make the first criterion hard to be satisfied in practice (unless channel estimation is made part of the learning process); while stringent reliability requirements may preclude the use of machine learning in the presence of a model deficit. 


>> Tokens are: 
 ['For', 'channel', 'decoding', ',', 'presence', 'fast-varying', 'channels', 'may', 'make', 'first', 'criterion', 'hard', 'satisfied', 'practice', '(', 'unless', 'channel', 'estimation', 'made', 'part', 'learning', 'process', ')', ';', 'stringent', 'reliability', 'requirements', 'may', 'preclude', 'use', 'machine', 'learning', 'presence', 'model', 'deficit', '.']

>> Bigrams are: 
 [('For', 'channel'), ('channel', 'decoding'), ('decoding', ','), (',', 'presence'), ('presence', 'fast-varying'), ('fast-varying', 'channels'), ('channels', 'may'), ('may', 'make'), ('make', 'first'), ('first', 'criterion'), ('criterion', 'hard'), ('hard', 'satisfied'), ('satisfied', 'practice'), ('practice', '('), ('(', 'unless'), ('unless', 'channel'), ('channel', 'estimation'), ('estimation', 'made'), ('made', 'part'), ('part', 'learning'), ('learning', 'process'), ('process', ')'), (')', ';'), (';', 'stringent'), ('stringent', 'reliability'), ('reliability', 'requirements'), ('requirements', 'may'), ('may', 'preclude'), ('preclude', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'presence'), ('presence', 'model'), ('model', 'deficit'), ('deficit', '.')]

>> Trigrams are: 
 [('For', 'channel', 'decoding'), ('channel', 'decoding', ','), ('decoding', ',', 'presence'), (',', 'presence', 'fast-varying'), ('presence', 'fast-varying', 'channels'), ('fast-varying', 'channels', 'may'), ('channels', 'may', 'make'), ('may', 'make', 'first'), ('make', 'first', 'criterion'), ('first', 'criterion', 'hard'), ('criterion', 'hard', 'satisfied'), ('hard', 'satisfied', 'practice'), ('satisfied', 'practice', '('), ('practice', '(', 'unless'), ('(', 'unless', 'channel'), ('unless', 'channel', 'estimation'), ('channel', 'estimation', 'made'), ('estimation', 'made', 'part'), ('made', 'part', 'learning'), ('part', 'learning', 'process'), ('learning', 'process', ')'), ('process', ')', ';'), (')', ';', 'stringent'), (';', 'stringent', 'reliability'), ('stringent', 'reliability', 'requirements'), ('reliability', 'requirements', 'may'), ('requirements', 'may', 'preclude'), ('may', 'preclude', 'use'), ('preclude', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'presence'), ('learning', 'presence', 'model'), ('presence', 'model', 'deficit'), ('model', 'deficit', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('channel', 'NN'), ('decoding', 'NN'), (',', ','), ('presence', 'NN'), ('fast-varying', 'JJ'), ('channels', 'NNS'), ('may', 'MD'), ('make', 'VB'), ('first', 'JJ'), ('criterion', 'NN'), ('hard', 'RB'), ('satisfied', 'JJ'), ('practice', 'NN'), ('(', '('), ('unless', 'IN'), ('channel', 'NN'), ('estimation', 'NN'), ('made', 'VBD'), ('part', 'NN'), ('learning', 'VBG'), ('process', 'NN'), (')', ')'), (';', ':'), ('stringent', 'JJ'), ('reliability', 'NN'), ('requirements', 'NNS'), ('may', 'MD'), ('preclude', 'VB'), ('use', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('presence', 'NN'), ('model', 'NN'), ('deficit', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP channel/NN decoding/NN)
  ,/,
  (NP presence/NN)
  (NP fast-varying/JJ channels/NNS)
  may/MD
  make/VB
  (NP first/JJ criterion/NN)
  hard/RB
  (NP satisfied/JJ practice/NN)
  (/(
  unless/IN
  (NP channel/NN estimation/NN)
  made/VBD
  (NP part/NN)
  learning/VBG
  (NP process/NN)
  )/)
  ;/:
  (NP stringent/JJ reliability/NN requirements/NNS)
  may/MD
  preclude/VB
  (NP use/NN machine/NN)
  learning/VBG
  (NP presence/NN model/NN deficit/NN)
  ./.) 


>> Noun Phrases are: 
 ['channel decoding', 'presence', 'fast-varying channels', 'first criterion', 'satisfied practice', 'channel estimation', 'part', 'process', 'stringent reliability requirements', 'use machine', 'presence model deficit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('presence', 'presenc'), ('fast-varying', 'fast-vari'), ('channels', 'channel'), ('may', 'may'), ('make', 'make'), ('first', 'first'), ('criterion', 'criterion'), ('hard', 'hard'), ('satisfied', 'satisfi'), ('practice', 'practic'), ('(', '('), ('unless', 'unless'), ('channel', 'channel'), ('estimation', 'estim'), ('made', 'made'), ('part', 'part'), ('learning', 'learn'), ('process', 'process'), (')', ')'), (';', ';'), ('stringent', 'stringent'), ('reliability', 'reliabl'), ('requirements', 'requir'), ('may', 'may'), ('preclude', 'preclud'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('presence', 'presenc'), ('model', 'model'), ('deficit', 'deficit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('presence', 'presenc'), ('fast-varying', 'fast-vari'), ('channels', 'channel'), ('may', 'may'), ('make', 'make'), ('first', 'first'), ('criterion', 'criterion'), ('hard', 'hard'), ('satisfied', 'satisfi'), ('practice', 'practic'), ('(', '('), ('unless', 'unless'), ('channel', 'channel'), ('estimation', 'estim'), ('made', 'made'), ('part', 'part'), ('learning', 'learn'), ('process', 'process'), (')', ')'), (';', ';'), ('stringent', 'stringent'), ('reliability', 'reliabl'), ('requirements', 'requir'), ('may', 'may'), ('preclude', 'preclud'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('presence', 'presenc'), ('model', 'model'), ('deficit', 'deficit'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('channel', 'channel'), ('decoding', 'decoding'), (',', ','), ('presence', 'presence'), ('fast-varying', 'fast-varying'), ('channels', 'channel'), ('may', 'may'), ('make', 'make'), ('first', 'first'), ('criterion', 'criterion'), ('hard', 'hard'), ('satisfied', 'satisfied'), ('practice', 'practice'), ('(', '('), ('unless', 'unless'), ('channel', 'channel'), ('estimation', 'estimation'), ('made', 'made'), ('part', 'part'), ('learning', 'learning'), ('process', 'process'), (')', ')'), (';', ';'), ('stringent', 'stringent'), ('reliability', 'reliability'), ('requirements', 'requirement'), ('may', 'may'), ('preclude', 'preclude'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('presence', 'presence'), ('model', 'model'), ('deficit', 'deficit'), ('.', '.')]



============================ Sentence 346 =============================

As mentioned, a generally beneficial idea in the use of data-aided methods is that of incorporating domain knowledge in the definition of the hypothesis class. 


>> Tokens are: 
 ['As', 'mentioned', ',', 'generally', 'beneficial', 'idea', 'use', 'data-aided', 'methods', 'incorporating', 'domain', 'knowledge', 'definition', 'hypothesis', 'class', '.']

>> Bigrams are: 
 [('As', 'mentioned'), ('mentioned', ','), (',', 'generally'), ('generally', 'beneficial'), ('beneficial', 'idea'), ('idea', 'use'), ('use', 'data-aided'), ('data-aided', 'methods'), ('methods', 'incorporating'), ('incorporating', 'domain'), ('domain', 'knowledge'), ('knowledge', 'definition'), ('definition', 'hypothesis'), ('hypothesis', 'class'), ('class', '.')]

>> Trigrams are: 
 [('As', 'mentioned', ','), ('mentioned', ',', 'generally'), (',', 'generally', 'beneficial'), ('generally', 'beneficial', 'idea'), ('beneficial', 'idea', 'use'), ('idea', 'use', 'data-aided'), ('use', 'data-aided', 'methods'), ('data-aided', 'methods', 'incorporating'), ('methods', 'incorporating', 'domain'), ('incorporating', 'domain', 'knowledge'), ('domain', 'knowledge', 'definition'), ('knowledge', 'definition', 'hypothesis'), ('definition', 'hypothesis', 'class'), ('hypothesis', 'class', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('mentioned', 'VBN'), (',', ','), ('generally', 'RB'), ('beneficial', 'JJ'), ('idea', 'NN'), ('use', 'NN'), ('data-aided', 'JJ'), ('methods', 'NNS'), ('incorporating', 'VBG'), ('domain', 'NN'), ('knowledge', 'NN'), ('definition', 'NN'), ('hypothesis', 'NN'), ('class', 'NN'), ('.', '.')]

 (S
  As/IN
  mentioned/VBN
  ,/,
  generally/RB
  (NP beneficial/JJ idea/NN use/NN)
  (NP data-aided/JJ methods/NNS)
  incorporating/VBG
  (NP domain/NN knowledge/NN definition/NN hypothesis/NN class/NN)
  ./.) 


>> Noun Phrases are: 
 ['beneficial idea use', 'data-aided methods', 'domain knowledge definition hypothesis class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), (',', ','), ('generally', 'gener'), ('beneficial', 'benefici'), ('idea', 'idea'), ('use', 'use'), ('data-aided', 'data-aid'), ('methods', 'method'), ('incorporating', 'incorpor'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('definition', 'definit'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), (',', ','), ('generally', 'general'), ('beneficial', 'benefici'), ('idea', 'idea'), ('use', 'use'), ('data-aided', 'data-aid'), ('methods', 'method'), ('incorporating', 'incorpor'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('definition', 'definit'), ('hypothesis', 'hypothesi'), ('class', 'class'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('mentioned', 'mentioned'), (',', ','), ('generally', 'generally'), ('beneficial', 'beneficial'), ('idea', 'idea'), ('use', 'use'), ('data-aided', 'data-aided'), ('methods', 'method'), ('incorporating', 'incorporating'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('definition', 'definition'), ('hypothesis', 'hypothesis'), ('class', 'class'), ('.', '.')]



============================ Sentence 347 =============================

As notable examples related to channel decoding, in [36], [37], knowledge of the near-optimality of message pass- ing methods for the decoding of sparse graphical codes is used to set up a parameterized model that borrows the message passing structure and that is trained to decode more general codes. 


>> Tokens are: 
 ['As', 'notable', 'examples', 'related', 'channel', 'decoding', ',', '[', '36', ']', ',', '[', '37', ']', ',', 'knowledge', 'near-optimality', 'message', 'pass-', 'ing', 'methods', 'decoding', 'sparse', 'graphical', 'codes', 'used', 'set', 'parameterized', 'model', 'borrows', 'message', 'passing', 'structure', 'trained', 'decode', 'general', 'codes', '.']

>> Bigrams are: 
 [('As', 'notable'), ('notable', 'examples'), ('examples', 'related'), ('related', 'channel'), ('channel', 'decoding'), ('decoding', ','), (',', '['), ('[', '36'), ('36', ']'), (']', ','), (',', '['), ('[', '37'), ('37', ']'), (']', ','), (',', 'knowledge'), ('knowledge', 'near-optimality'), ('near-optimality', 'message'), ('message', 'pass-'), ('pass-', 'ing'), ('ing', 'methods'), ('methods', 'decoding'), ('decoding', 'sparse'), ('sparse', 'graphical'), ('graphical', 'codes'), ('codes', 'used'), ('used', 'set'), ('set', 'parameterized'), ('parameterized', 'model'), ('model', 'borrows'), ('borrows', 'message'), ('message', 'passing'), ('passing', 'structure'), ('structure', 'trained'), ('trained', 'decode'), ('decode', 'general'), ('general', 'codes'), ('codes', '.')]

>> Trigrams are: 
 [('As', 'notable', 'examples'), ('notable', 'examples', 'related'), ('examples', 'related', 'channel'), ('related', 'channel', 'decoding'), ('channel', 'decoding', ','), ('decoding', ',', '['), (',', '[', '36'), ('[', '36', ']'), ('36', ']', ','), (']', ',', '['), (',', '[', '37'), ('[', '37', ']'), ('37', ']', ','), (']', ',', 'knowledge'), (',', 'knowledge', 'near-optimality'), ('knowledge', 'near-optimality', 'message'), ('near-optimality', 'message', 'pass-'), ('message', 'pass-', 'ing'), ('pass-', 'ing', 'methods'), ('ing', 'methods', 'decoding'), ('methods', 'decoding', 'sparse'), ('decoding', 'sparse', 'graphical'), ('sparse', 'graphical', 'codes'), ('graphical', 'codes', 'used'), ('codes', 'used', 'set'), ('used', 'set', 'parameterized'), ('set', 'parameterized', 'model'), ('parameterized', 'model', 'borrows'), ('model', 'borrows', 'message'), ('borrows', 'message', 'passing'), ('message', 'passing', 'structure'), ('passing', 'structure', 'trained'), ('structure', 'trained', 'decode'), ('trained', 'decode', 'general'), ('decode', 'general', 'codes'), ('general', 'codes', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('notable', 'JJ'), ('examples', 'NNS'), ('related', 'VBN'), ('channel', 'NNS'), ('decoding', 'VBG'), (',', ','), ('[', '$'), ('36', 'CD'), (']', 'NNP'), (',', ','), ('[', 'VBD'), ('37', 'CD'), (']', 'NN'), (',', ','), ('knowledge', 'VB'), ('near-optimality', 'JJ'), ('message', 'NN'), ('pass-', 'JJ'), ('ing', 'NN'), ('methods', 'NNS'), ('decoding', 'VBG'), ('sparse', 'JJ'), ('graphical', 'JJ'), ('codes', 'NNS'), ('used', 'VBN'), ('set', 'VBN'), ('parameterized', 'JJ'), ('model', 'NN'), ('borrows', 'VBZ'), ('message', 'NN'), ('passing', 'NN'), ('structure', 'NN'), ('trained', 'VBD'), ('decode', 'JJ'), ('general', 'JJ'), ('codes', 'NNS'), ('.', '.')]

 (S
  As/IN
  (NP notable/JJ examples/NNS)
  related/VBN
  (NP channel/NNS)
  decoding/VBG
  ,/,
  [/$
  36/CD
  (NP ]/NNP)
  ,/,
  [/VBD
  37/CD
  (NP ]/NN)
  ,/,
  knowledge/VB
  (NP near-optimality/JJ message/NN)
  (NP pass-/JJ ing/NN methods/NNS)
  decoding/VBG
  (NP sparse/JJ graphical/JJ codes/NNS)
  used/VBN
  set/VBN
  (NP parameterized/JJ model/NN)
  borrows/VBZ
  (NP message/NN passing/NN structure/NN)
  trained/VBD
  (NP decode/JJ general/JJ codes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['notable examples', 'channel', ']', ']', 'near-optimality message', 'pass- ing methods', 'sparse graphical codes', 'parameterized model', 'message passing structure', 'decode general codes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('notable', 'notabl'), ('examples', 'exampl'), ('related', 'relat'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('knowledge', 'knowledg'), ('near-optimality', 'near-optim'), ('message', 'messag'), ('pass-', 'pass-'), ('ing', 'ing'), ('methods', 'method'), ('decoding', 'decod'), ('sparse', 'spars'), ('graphical', 'graphic'), ('codes', 'code'), ('used', 'use'), ('set', 'set'), ('parameterized', 'parameter'), ('model', 'model'), ('borrows', 'borrow'), ('message', 'messag'), ('passing', 'pass'), ('structure', 'structur'), ('trained', 'train'), ('decode', 'decod'), ('general', 'gener'), ('codes', 'code'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('notable', 'notabl'), ('examples', 'exampl'), ('related', 'relat'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('knowledge', 'knowledg'), ('near-optimality', 'near-optim'), ('message', 'messag'), ('pass-', 'pass-'), ('ing', 'ing'), ('methods', 'method'), ('decoding', 'decod'), ('sparse', 'spars'), ('graphical', 'graphic'), ('codes', 'code'), ('used', 'use'), ('set', 'set'), ('parameterized', 'parameter'), ('model', 'model'), ('borrows', 'borrow'), ('message', 'messag'), ('passing', 'pass'), ('structure', 'structur'), ('trained', 'train'), ('decode', 'decod'), ('general', 'general'), ('codes', 'code'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('notable', 'notable'), ('examples', 'example'), ('related', 'related'), ('channel', 'channel'), ('decoding', 'decoding'), (',', ','), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('knowledge', 'knowledge'), ('near-optimality', 'near-optimality'), ('message', 'message'), ('pass-', 'pass-'), ('ing', 'ing'), ('methods', 'method'), ('decoding', 'decoding'), ('sparse', 'sparse'), ('graphical', 'graphical'), ('codes', 'code'), ('used', 'used'), ('set', 'set'), ('parameterized', 'parameterized'), ('model', 'model'), ('borrows', 'borrows'), ('message', 'message'), ('passing', 'passing'), ('structure', 'structure'), ('trained', 'trained'), ('decode', 'decode'), ('general', 'general'), ('codes', 'code'), ('.', '.')]



============================ Sentence 348 =============================

A related approach is investigated in [38] for polar codes. 


>> Tokens are: 
 ['A', 'related', 'approach', 'investigated', '[', '38', ']', 'polar', 'codes', '.']

>> Bigrams are: 
 [('A', 'related'), ('related', 'approach'), ('approach', 'investigated'), ('investigated', '['), ('[', '38'), ('38', ']'), (']', 'polar'), ('polar', 'codes'), ('codes', '.')]

>> Trigrams are: 
 [('A', 'related', 'approach'), ('related', 'approach', 'investigated'), ('approach', 'investigated', '['), ('investigated', '[', '38'), ('[', '38', ']'), ('38', ']', 'polar'), (']', 'polar', 'codes'), ('polar', 'codes', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('related', 'JJ'), ('approach', 'NN'), ('investigated', 'VBD'), ('[', 'JJ'), ('38', 'CD'), (']', 'JJ'), ('polar', 'JJ'), ('codes', 'NNS'), ('.', '.')]

 (S
  (NP A/DT related/JJ approach/NN)
  investigated/VBD
  [/JJ
  38/CD
  (NP ]/JJ polar/JJ codes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A related approach', '] polar codes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('related', 'relat'), ('approach', 'approach'), ('investigated', 'investig'), ('[', '['), ('38', '38'), (']', ']'), ('polar', 'polar'), ('codes', 'code'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('related', 'relat'), ('approach', 'approach'), ('investigated', 'investig'), ('[', '['), ('38', '38'), (']', ']'), ('polar', 'polar'), ('codes', 'code'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('related', 'related'), ('approach', 'approach'), ('investigated', 'investigated'), ('[', '['), ('38', '38'), (']', ']'), ('polar', 'polar'), ('codes', 'code'), ('.', '.')]



============================ Sentence 349 =============================

Another useful idea is that of directly integrating algorithms designed using the standard engineering flow with trained machines. 


>> Tokens are: 
 ['Another', 'useful', 'idea', 'directly', 'integrating', 'algorithms', 'designed', 'using', 'standard', 'engineering', 'flow', 'trained', 'machines', '.']

>> Bigrams are: 
 [('Another', 'useful'), ('useful', 'idea'), ('idea', 'directly'), ('directly', 'integrating'), ('integrating', 'algorithms'), ('algorithms', 'designed'), ('designed', 'using'), ('using', 'standard'), ('standard', 'engineering'), ('engineering', 'flow'), ('flow', 'trained'), ('trained', 'machines'), ('machines', '.')]

>> Trigrams are: 
 [('Another', 'useful', 'idea'), ('useful', 'idea', 'directly'), ('idea', 'directly', 'integrating'), ('directly', 'integrating', 'algorithms'), ('integrating', 'algorithms', 'designed'), ('algorithms', 'designed', 'using'), ('designed', 'using', 'standard'), ('using', 'standard', 'engineering'), ('standard', 'engineering', 'flow'), ('engineering', 'flow', 'trained'), ('flow', 'trained', 'machines'), ('trained', 'machines', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('useful', 'JJ'), ('idea', 'NN'), ('directly', 'RB'), ('integrating', 'VBG'), ('algorithms', 'NN'), ('designed', 'VBN'), ('using', 'VBG'), ('standard', 'JJ'), ('engineering', 'NN'), ('flow', 'NN'), ('trained', 'VBD'), ('machines', 'NNS'), ('.', '.')]

 (S
  (NP Another/DT useful/JJ idea/NN)
  directly/RB
  integrating/VBG
  (NP algorithms/NN)
  designed/VBN
  using/VBG
  (NP standard/JJ engineering/NN flow/NN)
  trained/VBD
  (NP machines/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Another useful idea', 'algorithms', 'standard engineering flow', 'machines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('useful', 'use'), ('idea', 'idea'), ('directly', 'directli'), ('integrating', 'integr'), ('algorithms', 'algorithm'), ('designed', 'design'), ('using', 'use'), ('standard', 'standard'), ('engineering', 'engin'), ('flow', 'flow'), ('trained', 'train'), ('machines', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('useful', 'use'), ('idea', 'idea'), ('directly', 'direct'), ('integrating', 'integr'), ('algorithms', 'algorithm'), ('designed', 'design'), ('using', 'use'), ('standard', 'standard'), ('engineering', 'engin'), ('flow', 'flow'), ('trained', 'train'), ('machines', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('useful', 'useful'), ('idea', 'idea'), ('directly', 'directly'), ('integrating', 'integrating'), ('algorithms', 'algorithm'), ('designed', 'designed'), ('using', 'using'), ('standard', 'standard'), ('engineering', 'engineering'), ('flow', 'flow'), ('trained', 'trained'), ('machines', 'machine'), ('.', '.')]



============================ Sentence 350 =============================

Instances of this idea include [39] in which a conventional channel decoder is deployed in tandem with a channel equalizer at its input that is trained to compensate for hardware impairments. 


>> Tokens are: 
 ['Instances', 'idea', 'include', '[', '39', ']', 'conventional', 'channel', 'decoder', 'deployed', 'tandem', 'channel', 'equalizer', 'input', 'trained', 'compensate', 'hardware', 'impairments', '.']

>> Bigrams are: 
 [('Instances', 'idea'), ('idea', 'include'), ('include', '['), ('[', '39'), ('39', ']'), (']', 'conventional'), ('conventional', 'channel'), ('channel', 'decoder'), ('decoder', 'deployed'), ('deployed', 'tandem'), ('tandem', 'channel'), ('channel', 'equalizer'), ('equalizer', 'input'), ('input', 'trained'), ('trained', 'compensate'), ('compensate', 'hardware'), ('hardware', 'impairments'), ('impairments', '.')]

>> Trigrams are: 
 [('Instances', 'idea', 'include'), ('idea', 'include', '['), ('include', '[', '39'), ('[', '39', ']'), ('39', ']', 'conventional'), (']', 'conventional', 'channel'), ('conventional', 'channel', 'decoder'), ('channel', 'decoder', 'deployed'), ('decoder', 'deployed', 'tandem'), ('deployed', 'tandem', 'channel'), ('tandem', 'channel', 'equalizer'), ('channel', 'equalizer', 'input'), ('equalizer', 'input', 'trained'), ('input', 'trained', 'compensate'), ('trained', 'compensate', 'hardware'), ('compensate', 'hardware', 'impairments'), ('hardware', 'impairments', '.')]

>> POS Tags are: 
 [('Instances', 'NNS'), ('idea', 'NN'), ('include', 'VBP'), ('[', 'JJ'), ('39', 'CD'), (']', 'JJ'), ('conventional', 'JJ'), ('channel', 'NN'), ('decoder', 'NN'), ('deployed', 'VBD'), ('tandem', 'JJ'), ('channel', 'NNS'), ('equalizer', 'NN'), ('input', 'NN'), ('trained', 'VBD'), ('compensate', 'NN'), ('hardware', 'NN'), ('impairments', 'NNS'), ('.', '.')]

 (S
  (NP Instances/NNS idea/NN)
  include/VBP
  [/JJ
  39/CD
  (NP ]/JJ conventional/JJ channel/NN decoder/NN)
  deployed/VBD
  (NP tandem/JJ channel/NNS equalizer/NN input/NN)
  trained/VBD
  (NP compensate/NN hardware/NN impairments/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Instances idea', '] conventional channel decoder', 'tandem channel equalizer input', 'compensate hardware impairments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instances', 'instanc'), ('idea', 'idea'), ('include', 'includ'), ('[', '['), ('39', '39'), (']', ']'), ('conventional', 'convent'), ('channel', 'channel'), ('decoder', 'decod'), ('deployed', 'deploy'), ('tandem', 'tandem'), ('channel', 'channel'), ('equalizer', 'equal'), ('input', 'input'), ('trained', 'train'), ('compensate', 'compens'), ('hardware', 'hardwar'), ('impairments', 'impair'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Instances', 'instanc'), ('idea', 'idea'), ('include', 'includ'), ('[', '['), ('39', '39'), (']', ']'), ('conventional', 'convent'), ('channel', 'channel'), ('decoder', 'decod'), ('deployed', 'deploy'), ('tandem', 'tandem'), ('channel', 'channel'), ('equalizer', 'equal'), ('input', 'input'), ('trained', 'train'), ('compensate', 'compens'), ('hardware', 'hardwar'), ('impairments', 'impair'), ('.', '.')]

>> Lemmatization: 
 [('Instances', 'Instances'), ('idea', 'idea'), ('include', 'include'), ('[', '['), ('39', '39'), (']', ']'), ('conventional', 'conventional'), ('channel', 'channel'), ('decoder', 'decoder'), ('deployed', 'deployed'), ('tandem', 'tandem'), ('channel', 'channel'), ('equalizer', 'equalizer'), ('input', 'input'), ('trained', 'trained'), ('compensate', 'compensate'), ('hardware', 'hardware'), ('impairments', 'impairment'), ('.', '.')]



============================ Sentence 351 =============================

A related approach is proposed in [40], whereby a conventional decoder is implemented within a turbo-like iterative loop with a machine learning-based regressor that has the role of estimating the channel noise. 


>> Tokens are: 
 ['A', 'related', 'approach', 'proposed', '[', '40', ']', ',', 'whereby', 'conventional', 'decoder', 'implemented', 'within', 'turbo-like', 'iterative', 'loop', 'machine', 'learning-based', 'regressor', 'role', 'estimating', 'channel', 'noise', '.']

>> Bigrams are: 
 [('A', 'related'), ('related', 'approach'), ('approach', 'proposed'), ('proposed', '['), ('[', '40'), ('40', ']'), (']', ','), (',', 'whereby'), ('whereby', 'conventional'), ('conventional', 'decoder'), ('decoder', 'implemented'), ('implemented', 'within'), ('within', 'turbo-like'), ('turbo-like', 'iterative'), ('iterative', 'loop'), ('loop', 'machine'), ('machine', 'learning-based'), ('learning-based', 'regressor'), ('regressor', 'role'), ('role', 'estimating'), ('estimating', 'channel'), ('channel', 'noise'), ('noise', '.')]

>> Trigrams are: 
 [('A', 'related', 'approach'), ('related', 'approach', 'proposed'), ('approach', 'proposed', '['), ('proposed', '[', '40'), ('[', '40', ']'), ('40', ']', ','), (']', ',', 'whereby'), (',', 'whereby', 'conventional'), ('whereby', 'conventional', 'decoder'), ('conventional', 'decoder', 'implemented'), ('decoder', 'implemented', 'within'), ('implemented', 'within', 'turbo-like'), ('within', 'turbo-like', 'iterative'), ('turbo-like', 'iterative', 'loop'), ('iterative', 'loop', 'machine'), ('loop', 'machine', 'learning-based'), ('machine', 'learning-based', 'regressor'), ('learning-based', 'regressor', 'role'), ('regressor', 'role', 'estimating'), ('role', 'estimating', 'channel'), ('estimating', 'channel', 'noise'), ('channel', 'noise', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('related', 'JJ'), ('approach', 'NN'), ('proposed', 'VBD'), ('[', '$'), ('40', 'CD'), (']', 'NNP'), (',', ','), ('whereby', 'WRB'), ('conventional', 'JJ'), ('decoder', 'NN'), ('implemented', 'VBN'), ('within', 'IN'), ('turbo-like', 'JJ'), ('iterative', 'JJ'), ('loop', 'NN'), ('machine', 'NN'), ('learning-based', 'JJ'), ('regressor', 'NN'), ('role', 'NN'), ('estimating', 'VBG'), ('channel', 'NNS'), ('noise', 'NN'), ('.', '.')]

 (S
  (NP A/DT related/JJ approach/NN)
  proposed/VBD
  [/$
  40/CD
  (NP ]/NNP)
  ,/,
  whereby/WRB
  (NP conventional/JJ decoder/NN)
  implemented/VBN
  within/IN
  (NP turbo-like/JJ iterative/JJ loop/NN machine/NN)
  (NP learning-based/JJ regressor/NN role/NN)
  estimating/VBG
  (NP channel/NNS noise/NN)
  ./.) 


>> Noun Phrases are: 
 ['A related approach', ']', 'conventional decoder', 'turbo-like iterative loop machine', 'learning-based regressor role', 'channel noise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('related', 'relat'), ('approach', 'approach'), ('proposed', 'propos'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('whereby', 'wherebi'), ('conventional', 'convent'), ('decoder', 'decod'), ('implemented', 'implement'), ('within', 'within'), ('turbo-like', 'turbo-lik'), ('iterative', 'iter'), ('loop', 'loop'), ('machine', 'machin'), ('learning-based', 'learning-bas'), ('regressor', 'regressor'), ('role', 'role'), ('estimating', 'estim'), ('channel', 'channel'), ('noise', 'nois'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('related', 'relat'), ('approach', 'approach'), ('proposed', 'propos'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('whereby', 'wherebi'), ('conventional', 'convent'), ('decoder', 'decod'), ('implemented', 'implement'), ('within', 'within'), ('turbo-like', 'turbo-lik'), ('iterative', 'iter'), ('loop', 'loop'), ('machine', 'machin'), ('learning-based', 'learning-bas'), ('regressor', 'regressor'), ('role', 'role'), ('estimating', 'estim'), ('channel', 'channel'), ('noise', 'nois'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('related', 'related'), ('approach', 'approach'), ('proposed', 'proposed'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('whereby', 'whereby'), ('conventional', 'conventional'), ('decoder', 'decoder'), ('implemented', 'implemented'), ('within', 'within'), ('turbo-like', 'turbo-like'), ('iterative', 'iterative'), ('loop', 'loop'), ('machine', 'machine'), ('learning-based', 'learning-based'), ('regressor', 'regressor'), ('role', 'role'), ('estimating', 'estimating'), ('channel', 'channel'), ('noise', 'noise'), ('.', '.')]



============================ Sentence 352 =============================

Other tasks that can potentially benefit from machine learning at the receiver’s side include modulation clas- sification, which is a classification problem justified by the complexity of optimal solutions (algorithm deficit) [41]; localization, which is a regression problem, typ- ically motivated by the lack of tractable channels for complex propagation environments (model deficit) [42]; and channel state information-based authentication, a classification problem made difficult by the absence of well-established models relating channel features with devices’ identities (model deficit) [43]. 


>> Tokens are: 
 ['Other', 'tasks', 'potentially', 'benefit', 'machine', 'learning', 'receiver', '’', 'side', 'include', 'modulation', 'clas-', 'sification', ',', 'classification', 'problem', 'justified', 'complexity', 'optimal', 'solutions', '(', 'algorithm', 'deficit', ')', '[', '41', ']', ';', 'localization', ',', 'regression', 'problem', ',', 'typ-', 'ically', 'motivated', 'lack', 'tractable', 'channels', 'complex', 'propagation', 'environments', '(', 'model', 'deficit', ')', '[', '42', ']', ';', 'channel', 'state', 'information-based', 'authentication', ',', 'classification', 'problem', 'made', 'difficult', 'absence', 'well-established', 'models', 'relating', 'channel', 'features', 'devices', '’', 'identities', '(', 'model', 'deficit', ')', '[', '43', ']', '.']

>> Bigrams are: 
 [('Other', 'tasks'), ('tasks', 'potentially'), ('potentially', 'benefit'), ('benefit', 'machine'), ('machine', 'learning'), ('learning', 'receiver'), ('receiver', '’'), ('’', 'side'), ('side', 'include'), ('include', 'modulation'), ('modulation', 'clas-'), ('clas-', 'sification'), ('sification', ','), (',', 'classification'), ('classification', 'problem'), ('problem', 'justified'), ('justified', 'complexity'), ('complexity', 'optimal'), ('optimal', 'solutions'), ('solutions', '('), ('(', 'algorithm'), ('algorithm', 'deficit'), ('deficit', ')'), (')', '['), ('[', '41'), ('41', ']'), (']', ';'), (';', 'localization'), ('localization', ','), (',', 'regression'), ('regression', 'problem'), ('problem', ','), (',', 'typ-'), ('typ-', 'ically'), ('ically', 'motivated'), ('motivated', 'lack'), ('lack', 'tractable'), ('tractable', 'channels'), ('channels', 'complex'), ('complex', 'propagation'), ('propagation', 'environments'), ('environments', '('), ('(', 'model'), ('model', 'deficit'), ('deficit', ')'), (')', '['), ('[', '42'), ('42', ']'), (']', ';'), (';', 'channel'), ('channel', 'state'), ('state', 'information-based'), ('information-based', 'authentication'), ('authentication', ','), (',', 'classification'), ('classification', 'problem'), ('problem', 'made'), ('made', 'difficult'), ('difficult', 'absence'), ('absence', 'well-established'), ('well-established', 'models'), ('models', 'relating'), ('relating', 'channel'), ('channel', 'features'), ('features', 'devices'), ('devices', '’'), ('’', 'identities'), ('identities', '('), ('(', 'model'), ('model', 'deficit'), ('deficit', ')'), (')', '['), ('[', '43'), ('43', ']'), (']', '.')]

>> Trigrams are: 
 [('Other', 'tasks', 'potentially'), ('tasks', 'potentially', 'benefit'), ('potentially', 'benefit', 'machine'), ('benefit', 'machine', 'learning'), ('machine', 'learning', 'receiver'), ('learning', 'receiver', '’'), ('receiver', '’', 'side'), ('’', 'side', 'include'), ('side', 'include', 'modulation'), ('include', 'modulation', 'clas-'), ('modulation', 'clas-', 'sification'), ('clas-', 'sification', ','), ('sification', ',', 'classification'), (',', 'classification', 'problem'), ('classification', 'problem', 'justified'), ('problem', 'justified', 'complexity'), ('justified', 'complexity', 'optimal'), ('complexity', 'optimal', 'solutions'), ('optimal', 'solutions', '('), ('solutions', '(', 'algorithm'), ('(', 'algorithm', 'deficit'), ('algorithm', 'deficit', ')'), ('deficit', ')', '['), (')', '[', '41'), ('[', '41', ']'), ('41', ']', ';'), (']', ';', 'localization'), (';', 'localization', ','), ('localization', ',', 'regression'), (',', 'regression', 'problem'), ('regression', 'problem', ','), ('problem', ',', 'typ-'), (',', 'typ-', 'ically'), ('typ-', 'ically', 'motivated'), ('ically', 'motivated', 'lack'), ('motivated', 'lack', 'tractable'), ('lack', 'tractable', 'channels'), ('tractable', 'channels', 'complex'), ('channels', 'complex', 'propagation'), ('complex', 'propagation', 'environments'), ('propagation', 'environments', '('), ('environments', '(', 'model'), ('(', 'model', 'deficit'), ('model', 'deficit', ')'), ('deficit', ')', '['), (')', '[', '42'), ('[', '42', ']'), ('42', ']', ';'), (']', ';', 'channel'), (';', 'channel', 'state'), ('channel', 'state', 'information-based'), ('state', 'information-based', 'authentication'), ('information-based', 'authentication', ','), ('authentication', ',', 'classification'), (',', 'classification', 'problem'), ('classification', 'problem', 'made'), ('problem', 'made', 'difficult'), ('made', 'difficult', 'absence'), ('difficult', 'absence', 'well-established'), ('absence', 'well-established', 'models'), ('well-established', 'models', 'relating'), ('models', 'relating', 'channel'), ('relating', 'channel', 'features'), ('channel', 'features', 'devices'), ('features', 'devices', '’'), ('devices', '’', 'identities'), ('’', 'identities', '('), ('identities', '(', 'model'), ('(', 'model', 'deficit'), ('model', 'deficit', ')'), ('deficit', ')', '['), (')', '[', '43'), ('[', '43', ']'), ('43', ']', '.')]

>> POS Tags are: 
 [('Other', 'JJ'), ('tasks', 'NNS'), ('potentially', 'RB'), ('benefit', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('receiver', 'NN'), ('’', 'NNP'), ('side', 'NN'), ('include', 'VBP'), ('modulation', 'NN'), ('clas-', 'JJ'), ('sification', 'NN'), (',', ','), ('classification', 'NN'), ('problem', 'NN'), ('justified', 'VBD'), ('complexity', 'NN'), ('optimal', 'JJ'), ('solutions', 'NNS'), ('(', '('), ('algorithm', 'IN'), ('deficit', 'NN'), (')', ')'), ('[', 'VBZ'), ('41', 'CD'), (']', 'NN'), (';', ':'), ('localization', 'NN'), (',', ','), ('regression', 'NN'), ('problem', 'NN'), (',', ','), ('typ-', 'JJ'), ('ically', 'RB'), ('motivated', 'VBN'), ('lack', 'NN'), ('tractable', 'JJ'), ('channels', 'NNS'), ('complex', 'JJ'), ('propagation', 'NN'), ('environments', 'NNS'), ('(', '('), ('model', 'NN'), ('deficit', 'NN'), (')', ')'), ('[', 'VBZ'), ('42', 'CD'), (']', 'NN'), (';', ':'), ('channel', 'NNS'), ('state', 'NN'), ('information-based', 'JJ'), ('authentication', 'NN'), (',', ','), ('classification', 'NN'), ('problem', 'NN'), ('made', 'VBD'), ('difficult', 'JJ'), ('absence', 'JJ'), ('well-established', 'JJ'), ('models', 'NNS'), ('relating', 'VBG'), ('channel', 'NN'), ('features', 'NNS'), ('devices', 'NNS'), ('’', 'JJ'), ('identities', 'NNS'), ('(', '('), ('model', 'NN'), ('deficit', 'NN'), (')', ')'), ('[', 'VBZ'), ('43', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Other/JJ tasks/NNS)
  potentially/RB
  benefit/VBP
  (NP machine/NN learning/NN receiver/NN ’/NNP side/NN)
  include/VBP
  (NP modulation/NN)
  (NP clas-/JJ sification/NN)
  ,/,
  (NP classification/NN problem/NN)
  justified/VBD
  (NP complexity/NN)
  (NP optimal/JJ solutions/NNS)
  (/(
  algorithm/IN
  (NP deficit/NN)
  )/)
  [/VBZ
  41/CD
  (NP ]/NN)
  ;/:
  (NP localization/NN)
  ,/,
  (NP regression/NN problem/NN)
  ,/,
  typ-/JJ
  ically/RB
  motivated/VBN
  (NP lack/NN)
  (NP tractable/JJ channels/NNS)
  (NP complex/JJ propagation/NN environments/NNS)
  (/(
  (NP model/NN deficit/NN)
  )/)
  [/VBZ
  42/CD
  (NP ]/NN)
  ;/:
  (NP channel/NNS state/NN)
  (NP information-based/JJ authentication/NN)
  ,/,
  (NP classification/NN problem/NN)
  made/VBD
  (NP difficult/JJ absence/JJ well-established/JJ models/NNS)
  relating/VBG
  (NP channel/NN features/NNS devices/NNS)
  (NP ’/JJ identities/NNS)
  (/(
  (NP model/NN deficit/NN)
  )/)
  [/VBZ
  43/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Other tasks', 'machine learning receiver ’ side', 'modulation', 'clas- sification', 'classification problem', 'complexity', 'optimal solutions', 'deficit', ']', 'localization', 'regression problem', 'lack', 'tractable channels', 'complex propagation environments', 'model deficit', ']', 'channel state', 'information-based authentication', 'classification problem', 'difficult absence well-established models', 'channel features devices', '’ identities', 'model deficit', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('tasks', 'task'), ('potentially', 'potenti'), ('benefit', 'benefit'), ('machine', 'machin'), ('learning', 'learn'), ('receiver', 'receiv'), ('’', '’'), ('side', 'side'), ('include', 'includ'), ('modulation', 'modul'), ('clas-', 'clas-'), ('sification', 'sific'), (',', ','), ('classification', 'classif'), ('problem', 'problem'), ('justified', 'justifi'), ('complexity', 'complex'), ('optimal', 'optim'), ('solutions', 'solut'), ('(', '('), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), (';', ';'), ('localization', 'local'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('typ-', 'typ-'), ('ically', 'ical'), ('motivated', 'motiv'), ('lack', 'lack'), ('tractable', 'tractabl'), ('channels', 'channel'), ('complex', 'complex'), ('propagation', 'propag'), ('environments', 'environ'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), (';', ';'), ('channel', 'channel'), ('state', 'state'), ('information-based', 'information-bas'), ('authentication', 'authent'), (',', ','), ('classification', 'classif'), ('problem', 'problem'), ('made', 'made'), ('difficult', 'difficult'), ('absence', 'absenc'), ('well-established', 'well-establish'), ('models', 'model'), ('relating', 'relat'), ('channel', 'channel'), ('features', 'featur'), ('devices', 'devic'), ('’', '’'), ('identities', 'ident'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('tasks', 'task'), ('potentially', 'potenti'), ('benefit', 'benefit'), ('machine', 'machin'), ('learning', 'learn'), ('receiver', 'receiv'), ('’', '’'), ('side', 'side'), ('include', 'includ'), ('modulation', 'modul'), ('clas-', 'clas-'), ('sification', 'sific'), (',', ','), ('classification', 'classif'), ('problem', 'problem'), ('justified', 'justifi'), ('complexity', 'complex'), ('optimal', 'optim'), ('solutions', 'solut'), ('(', '('), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), (';', ';'), ('localization', 'local'), (',', ','), ('regression', 'regress'), ('problem', 'problem'), (',', ','), ('typ-', 'typ-'), ('ically', 'ical'), ('motivated', 'motiv'), ('lack', 'lack'), ('tractable', 'tractabl'), ('channels', 'channel'), ('complex', 'complex'), ('propagation', 'propag'), ('environments', 'environ'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), (';', ';'), ('channel', 'channel'), ('state', 'state'), ('information-based', 'information-bas'), ('authentication', 'authent'), (',', ','), ('classification', 'classif'), ('problem', 'problem'), ('made', 'made'), ('difficult', 'difficult'), ('absence', 'absenc'), ('well-established', 'well-establish'), ('models', 'model'), ('relating', 'relat'), ('channel', 'channel'), ('features', 'featur'), ('devices', 'devic'), ('’', '’'), ('identities', 'ident'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Other', 'Other'), ('tasks', 'task'), ('potentially', 'potentially'), ('benefit', 'benefit'), ('machine', 'machine'), ('learning', 'learning'), ('receiver', 'receiver'), ('’', '’'), ('side', 'side'), ('include', 'include'), ('modulation', 'modulation'), ('clas-', 'clas-'), ('sification', 'sification'), (',', ','), ('classification', 'classification'), ('problem', 'problem'), ('justified', 'justified'), ('complexity', 'complexity'), ('optimal', 'optimal'), ('solutions', 'solution'), ('(', '('), ('algorithm', 'algorithm'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), (';', ';'), ('localization', 'localization'), (',', ','), ('regression', 'regression'), ('problem', 'problem'), (',', ','), ('typ-', 'typ-'), ('ically', 'ically'), ('motivated', 'motivated'), ('lack', 'lack'), ('tractable', 'tractable'), ('channels', 'channel'), ('complex', 'complex'), ('propagation', 'propagation'), ('environments', 'environment'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), (';', ';'), ('channel', 'channel'), ('state', 'state'), ('information-based', 'information-based'), ('authentication', 'authentication'), (',', ','), ('classification', 'classification'), ('problem', 'problem'), ('made', 'made'), ('difficult', 'difficult'), ('absence', 'absence'), ('well-established', 'well-established'), ('models', 'model'), ('relating', 'relating'), ('channel', 'channel'), ('features', 'feature'), ('devices', 'device'), ('’', '’'), ('identities', 'identity'), ('(', '('), ('model', 'model'), ('deficit', 'deficit'), (')', ')'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]



============================ Sentence 353 =============================

Turning to the transmitter side, most emerging ap- plications tackle the algorithmic deficit related to the complexity of the non-convex programs that typically underlie power control and precoding optimization for the downlink. 


>> Tokens are: 
 ['Turning', 'transmitter', 'side', ',', 'emerging', 'ap-', 'plications', 'tackle', 'algorithmic', 'deficit', 'related', 'complexity', 'non-convex', 'programs', 'typically', 'underlie', 'power', 'control', 'precoding', 'optimization', 'downlink', '.']

>> Bigrams are: 
 [('Turning', 'transmitter'), ('transmitter', 'side'), ('side', ','), (',', 'emerging'), ('emerging', 'ap-'), ('ap-', 'plications'), ('plications', 'tackle'), ('tackle', 'algorithmic'), ('algorithmic', 'deficit'), ('deficit', 'related'), ('related', 'complexity'), ('complexity', 'non-convex'), ('non-convex', 'programs'), ('programs', 'typically'), ('typically', 'underlie'), ('underlie', 'power'), ('power', 'control'), ('control', 'precoding'), ('precoding', 'optimization'), ('optimization', 'downlink'), ('downlink', '.')]

>> Trigrams are: 
 [('Turning', 'transmitter', 'side'), ('transmitter', 'side', ','), ('side', ',', 'emerging'), (',', 'emerging', 'ap-'), ('emerging', 'ap-', 'plications'), ('ap-', 'plications', 'tackle'), ('plications', 'tackle', 'algorithmic'), ('tackle', 'algorithmic', 'deficit'), ('algorithmic', 'deficit', 'related'), ('deficit', 'related', 'complexity'), ('related', 'complexity', 'non-convex'), ('complexity', 'non-convex', 'programs'), ('non-convex', 'programs', 'typically'), ('programs', 'typically', 'underlie'), ('typically', 'underlie', 'power'), ('underlie', 'power', 'control'), ('power', 'control', 'precoding'), ('control', 'precoding', 'optimization'), ('precoding', 'optimization', 'downlink'), ('optimization', 'downlink', '.')]

>> POS Tags are: 
 [('Turning', 'VBG'), ('transmitter', 'JJ'), ('side', 'NN'), (',', ','), ('emerging', 'VBG'), ('ap-', 'JJ'), ('plications', 'NNS'), ('tackle', 'VBP'), ('algorithmic', 'JJ'), ('deficit', 'NN'), ('related', 'VBN'), ('complexity', 'NN'), ('non-convex', 'JJ'), ('programs', 'NNS'), ('typically', 'RB'), ('underlie', 'JJ'), ('power', 'NN'), ('control', 'NN'), ('precoding', 'VBG'), ('optimization', 'NN'), ('downlink', 'NN'), ('.', '.')]

 (S
  Turning/VBG
  (NP transmitter/JJ side/NN)
  ,/,
  emerging/VBG
  (NP ap-/JJ plications/NNS)
  tackle/VBP
  (NP algorithmic/JJ deficit/NN)
  related/VBN
  (NP complexity/NN)
  (NP non-convex/JJ programs/NNS)
  typically/RB
  (NP underlie/JJ power/NN control/NN)
  precoding/VBG
  (NP optimization/NN downlink/NN)
  ./.) 


>> Noun Phrases are: 
 ['transmitter side', 'ap- plications', 'algorithmic deficit', 'complexity', 'non-convex programs', 'underlie power control', 'optimization downlink']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Turning', 'turn'), ('transmitter', 'transmitt'), ('side', 'side'), (',', ','), ('emerging', 'emerg'), ('ap-', 'ap-'), ('plications', 'plicat'), ('tackle', 'tackl'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), ('related', 'relat'), ('complexity', 'complex'), ('non-convex', 'non-convex'), ('programs', 'program'), ('typically', 'typic'), ('underlie', 'underli'), ('power', 'power'), ('control', 'control'), ('precoding', 'precod'), ('optimization', 'optim'), ('downlink', 'downlink'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Turning', 'turn'), ('transmitter', 'transmitt'), ('side', 'side'), (',', ','), ('emerging', 'emerg'), ('ap-', 'ap-'), ('plications', 'plicat'), ('tackle', 'tackl'), ('algorithmic', 'algorithm'), ('deficit', 'deficit'), ('related', 'relat'), ('complexity', 'complex'), ('non-convex', 'non-convex'), ('programs', 'program'), ('typically', 'typic'), ('underlie', 'underli'), ('power', 'power'), ('control', 'control'), ('precoding', 'precod'), ('optimization', 'optim'), ('downlink', 'downlink'), ('.', '.')]

>> Lemmatization: 
 [('Turning', 'Turning'), ('transmitter', 'transmitter'), ('side', 'side'), (',', ','), ('emerging', 'emerging'), ('ap-', 'ap-'), ('plications', 'plication'), ('tackle', 'tackle'), ('algorithmic', 'algorithmic'), ('deficit', 'deficit'), ('related', 'related'), ('complexity', 'complexity'), ('non-convex', 'non-convex'), ('programs', 'program'), ('typically', 'typically'), ('underlie', 'underlie'), ('power', 'power'), ('control', 'control'), ('precoding', 'precoding'), ('optimization', 'optimization'), ('downlink', 'downlink'), ('.', '.')]



============================ Sentence 354 =============================

Notably, in [44], a training set is ob- tained by running a non-convex solver to produce an optimized output power vector for given input channels. 


>> Tokens are: 
 ['Notably', ',', '[', '44', ']', ',', 'training', 'set', 'ob-', 'tained', 'running', 'non-convex', 'solver', 'produce', 'optimized', 'output', 'power', 'vector', 'given', 'input', 'channels', '.']

>> Bigrams are: 
 [('Notably', ','), (',', '['), ('[', '44'), ('44', ']'), (']', ','), (',', 'training'), ('training', 'set'), ('set', 'ob-'), ('ob-', 'tained'), ('tained', 'running'), ('running', 'non-convex'), ('non-convex', 'solver'), ('solver', 'produce'), ('produce', 'optimized'), ('optimized', 'output'), ('output', 'power'), ('power', 'vector'), ('vector', 'given'), ('given', 'input'), ('input', 'channels'), ('channels', '.')]

>> Trigrams are: 
 [('Notably', ',', '['), (',', '[', '44'), ('[', '44', ']'), ('44', ']', ','), (']', ',', 'training'), (',', 'training', 'set'), ('training', 'set', 'ob-'), ('set', 'ob-', 'tained'), ('ob-', 'tained', 'running'), ('tained', 'running', 'non-convex'), ('running', 'non-convex', 'solver'), ('non-convex', 'solver', 'produce'), ('solver', 'produce', 'optimized'), ('produce', 'optimized', 'output'), ('optimized', 'output', 'power'), ('output', 'power', 'vector'), ('power', 'vector', 'given'), ('vector', 'given', 'input'), ('given', 'input', 'channels'), ('input', 'channels', '.')]

>> POS Tags are: 
 [('Notably', 'RB'), (',', ','), ('[', 'VBD'), ('44', 'CD'), (']', 'NN'), (',', ','), ('training', 'VBG'), ('set', 'VBN'), ('ob-', 'JJ'), ('tained', 'JJ'), ('running', 'VBG'), ('non-convex', 'JJ'), ('solver', 'NN'), ('produce', 'VBP'), ('optimized', 'VBN'), ('output', 'NN'), ('power', 'NN'), ('vector', 'NN'), ('given', 'VBN'), ('input', 'NN'), ('channels', 'NNS'), ('.', '.')]

 (S
  Notably/RB
  ,/,
  [/VBD
  44/CD
  (NP ]/NN)
  ,/,
  training/VBG
  set/VBN
  ob-/JJ
  tained/JJ
  running/VBG
  (NP non-convex/JJ solver/NN)
  produce/VBP
  optimized/VBN
  (NP output/NN power/NN vector/NN)
  given/VBN
  (NP input/NN channels/NNS)
  ./.) 


>> Noun Phrases are: 
 [']', 'non-convex solver', 'output power vector', 'input channels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Notably', 'notabl'), (',', ','), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('training', 'train'), ('set', 'set'), ('ob-', 'ob-'), ('tained', 'tain'), ('running', 'run'), ('non-convex', 'non-convex'), ('solver', 'solver'), ('produce', 'produc'), ('optimized', 'optim'), ('output', 'output'), ('power', 'power'), ('vector', 'vector'), ('given', 'given'), ('input', 'input'), ('channels', 'channel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Notably', 'notabl'), (',', ','), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('training', 'train'), ('set', 'set'), ('ob-', 'ob-'), ('tained', 'tain'), ('running', 'run'), ('non-convex', 'non-convex'), ('solver', 'solver'), ('produce', 'produc'), ('optimized', 'optim'), ('output', 'output'), ('power', 'power'), ('vector', 'vector'), ('given', 'given'), ('input', 'input'), ('channels', 'channel'), ('.', '.')]

>> Lemmatization: 
 [('Notably', 'Notably'), (',', ','), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('training', 'training'), ('set', 'set'), ('ob-', 'ob-'), ('tained', 'tained'), ('running', 'running'), ('non-convex', 'non-convex'), ('solver', 'solver'), ('produce', 'produce'), ('optimized', 'optimized'), ('output', 'output'), ('power', 'power'), ('vector', 'vector'), ('given', 'given'), ('input', 'input'), ('channels', 'channel'), ('.', '.')]



============================ Sentence 355 =============================

Note that the approach does not directly optimize the performance criterion of interest, such as the sum-rate. 


>> Tokens are: 
 ['Note', 'approach', 'directly', 'optimize', 'performance', 'criterion', 'interest', ',', 'sum-rate', '.']

>> Bigrams are: 
 [('Note', 'approach'), ('approach', 'directly'), ('directly', 'optimize'), ('optimize', 'performance'), ('performance', 'criterion'), ('criterion', 'interest'), ('interest', ','), (',', 'sum-rate'), ('sum-rate', '.')]

>> Trigrams are: 
 [('Note', 'approach', 'directly'), ('approach', 'directly', 'optimize'), ('directly', 'optimize', 'performance'), ('optimize', 'performance', 'criterion'), ('performance', 'criterion', 'interest'), ('criterion', 'interest', ','), ('interest', ',', 'sum-rate'), (',', 'sum-rate', '.')]

>> POS Tags are: 
 [('Note', 'NN'), ('approach', 'NN'), ('directly', 'RB'), ('optimize', 'JJ'), ('performance', 'NN'), ('criterion', 'NN'), ('interest', 'NN'), (',', ','), ('sum-rate', 'NN'), ('.', '.')]

 (S
  (NP Note/NN approach/NN)
  directly/RB
  (NP optimize/JJ performance/NN criterion/NN interest/NN)
  ,/,
  (NP sum-rate/NN)
  ./.) 


>> Noun Phrases are: 
 ['Note approach', 'optimize performance criterion interest', 'sum-rate']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('approach', 'approach'), ('directly', 'directli'), ('optimize', 'optim'), ('performance', 'perform'), ('criterion', 'criterion'), ('interest', 'interest'), (',', ','), ('sum-rate', 'sum-rat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('approach', 'approach'), ('directly', 'direct'), ('optimize', 'optim'), ('performance', 'perform'), ('criterion', 'criterion'), ('interest', 'interest'), (',', ','), ('sum-rate', 'sum-rat'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), ('approach', 'approach'), ('directly', 'directly'), ('optimize', 'optimize'), ('performance', 'performance'), ('criterion', 'criterion'), ('interest', 'interest'), (',', ','), ('sum-rate', 'sum-rate'), ('.', '.')]



============================ Sentence 356 =============================

Rather, it relies on the assumption that similar inputs – the channel coefficients – generally yield similar optimal solutions – the power allocation vector. 


>> Tokens are: 
 ['Rather', ',', 'relies', 'assumption', 'similar', 'inputs', '–', 'channel', 'coefficients', '–', 'generally', 'yield', 'similar', 'optimal', 'solutions', '–', 'power', 'allocation', 'vector', '.']

>> Bigrams are: 
 [('Rather', ','), (',', 'relies'), ('relies', 'assumption'), ('assumption', 'similar'), ('similar', 'inputs'), ('inputs', '–'), ('–', 'channel'), ('channel', 'coefficients'), ('coefficients', '–'), ('–', 'generally'), ('generally', 'yield'), ('yield', 'similar'), ('similar', 'optimal'), ('optimal', 'solutions'), ('solutions', '–'), ('–', 'power'), ('power', 'allocation'), ('allocation', 'vector'), ('vector', '.')]

>> Trigrams are: 
 [('Rather', ',', 'relies'), (',', 'relies', 'assumption'), ('relies', 'assumption', 'similar'), ('assumption', 'similar', 'inputs'), ('similar', 'inputs', '–'), ('inputs', '–', 'channel'), ('–', 'channel', 'coefficients'), ('channel', 'coefficients', '–'), ('coefficients', '–', 'generally'), ('–', 'generally', 'yield'), ('generally', 'yield', 'similar'), ('yield', 'similar', 'optimal'), ('similar', 'optimal', 'solutions'), ('optimal', 'solutions', '–'), ('solutions', '–', 'power'), ('–', 'power', 'allocation'), ('power', 'allocation', 'vector'), ('allocation', 'vector', '.')]

>> POS Tags are: 
 [('Rather', 'RB'), (',', ','), ('relies', 'NNS'), ('assumption', 'VBP'), ('similar', 'JJ'), ('inputs', 'NNS'), ('–', 'JJ'), ('channel', 'NN'), ('coefficients', 'NNS'), ('–', 'VBP'), ('generally', 'RB'), ('yield', 'VBP'), ('similar', 'JJ'), ('optimal', 'JJ'), ('solutions', 'NNS'), ('–', 'VBP'), ('power', 'NN'), ('allocation', 'NN'), ('vector', 'NN'), ('.', '.')]

 (S
  Rather/RB
  ,/,
  (NP relies/NNS)
  assumption/VBP
  (NP similar/JJ inputs/NNS)
  (NP –/JJ channel/NN coefficients/NNS)
  –/VBP
  generally/RB
  yield/VBP
  (NP similar/JJ optimal/JJ solutions/NNS)
  –/VBP
  (NP power/NN allocation/NN vector/NN)
  ./.) 


>> Noun Phrases are: 
 ['relies', 'similar inputs', '– channel coefficients', 'similar optimal solutions', 'power allocation vector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rather', 'rather'), (',', ','), ('relies', 'reli'), ('assumption', 'assumpt'), ('similar', 'similar'), ('inputs', 'input'), ('–', '–'), ('channel', 'channel'), ('coefficients', 'coeffici'), ('–', '–'), ('generally', 'gener'), ('yield', 'yield'), ('similar', 'similar'), ('optimal', 'optim'), ('solutions', 'solut'), ('–', '–'), ('power', 'power'), ('allocation', 'alloc'), ('vector', 'vector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rather', 'rather'), (',', ','), ('relies', 'reli'), ('assumption', 'assumpt'), ('similar', 'similar'), ('inputs', 'input'), ('–', '–'), ('channel', 'channel'), ('coefficients', 'coeffici'), ('–', '–'), ('generally', 'general'), ('yield', 'yield'), ('similar', 'similar'), ('optimal', 'optim'), ('solutions', 'solut'), ('–', '–'), ('power', 'power'), ('allocation', 'alloc'), ('vector', 'vector'), ('.', '.')]

>> Lemmatization: 
 [('Rather', 'Rather'), (',', ','), ('relies', 'relies'), ('assumption', 'assumption'), ('similar', 'similar'), ('inputs', 'input'), ('–', '–'), ('channel', 'channel'), ('coefficients', 'coefficient'), ('–', '–'), ('generally', 'generally'), ('yield', 'yield'), ('similar', 'similar'), ('optimal', 'optimal'), ('solutions', 'solution'), ('–', '–'), ('power', 'power'), ('allocation', 'allocation'), ('vector', 'vector'), ('.', '.')]



============================ Sentence 357 =============================

if the analytical  11    model available based on domain knowledge is only a coarse approximation of the physical model, the resulting training set can be used to augment the data in order to carry out a preliminary training of a machine learning model [45]2. 


>> Tokens are: 
 ['analytical', '11', 'model', 'available', 'based', 'domain', 'knowledge', 'coarse', 'approximation', 'physical', 'model', ',', 'resulting', 'training', 'set', 'used', 'augment', 'data', 'order', 'carry', 'preliminary', 'training', 'machine', 'learning', 'model', '[', '45', ']', '2', '.']

>> Bigrams are: 
 [('analytical', '11'), ('11', 'model'), ('model', 'available'), ('available', 'based'), ('based', 'domain'), ('domain', 'knowledge'), ('knowledge', 'coarse'), ('coarse', 'approximation'), ('approximation', 'physical'), ('physical', 'model'), ('model', ','), (',', 'resulting'), ('resulting', 'training'), ('training', 'set'), ('set', 'used'), ('used', 'augment'), ('augment', 'data'), ('data', 'order'), ('order', 'carry'), ('carry', 'preliminary'), ('preliminary', 'training'), ('training', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', '['), ('[', '45'), ('45', ']'), (']', '2'), ('2', '.')]

>> Trigrams are: 
 [('analytical', '11', 'model'), ('11', 'model', 'available'), ('model', 'available', 'based'), ('available', 'based', 'domain'), ('based', 'domain', 'knowledge'), ('domain', 'knowledge', 'coarse'), ('knowledge', 'coarse', 'approximation'), ('coarse', 'approximation', 'physical'), ('approximation', 'physical', 'model'), ('physical', 'model', ','), ('model', ',', 'resulting'), (',', 'resulting', 'training'), ('resulting', 'training', 'set'), ('training', 'set', 'used'), ('set', 'used', 'augment'), ('used', 'augment', 'data'), ('augment', 'data', 'order'), ('data', 'order', 'carry'), ('order', 'carry', 'preliminary'), ('carry', 'preliminary', 'training'), ('preliminary', 'training', 'machine'), ('training', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', '['), ('model', '[', '45'), ('[', '45', ']'), ('45', ']', '2'), (']', '2', '.')]

>> POS Tags are: 
 [('analytical', 'JJ'), ('11', 'CD'), ('model', 'NN'), ('available', 'JJ'), ('based', 'VBN'), ('domain', 'NN'), ('knowledge', 'NN'), ('coarse', 'JJ'), ('approximation', 'NN'), ('physical', 'JJ'), ('model', 'NN'), (',', ','), ('resulting', 'VBG'), ('training', 'NN'), ('set', 'NN'), ('used', 'VBN'), ('augment', 'NN'), ('data', 'NNS'), ('order', 'NN'), ('carry', 'VBP'), ('preliminary', 'JJ'), ('training', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('[', '$'), ('45', 'CD'), (']', 'JJ'), ('2', 'CD'), ('.', '.')]

 (S
  analytical/JJ
  11/CD
  (NP model/NN)
  available/JJ
  based/VBN
  (NP domain/NN knowledge/NN)
  (NP coarse/JJ approximation/NN)
  (NP physical/JJ model/NN)
  ,/,
  resulting/VBG
  (NP training/NN set/NN)
  used/VBN
  (NP augment/NN data/NNS order/NN)
  carry/VBP
  (NP preliminary/JJ training/NN machine/NN)
  learning/VBG
  (NP model/NN)
  [/$
  45/CD
  ]/JJ
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['model', 'domain knowledge', 'coarse approximation', 'physical model', 'training set', 'augment data order', 'preliminary training machine', 'model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analytical', 'analyt'), ('11', '11'), ('model', 'model'), ('available', 'avail'), ('based', 'base'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('coarse', 'coars'), ('approximation', 'approxim'), ('physical', 'physic'), ('model', 'model'), (',', ','), ('resulting', 'result'), ('training', 'train'), ('set', 'set'), ('used', 'use'), ('augment', 'augment'), ('data', 'data'), ('order', 'order'), ('carry', 'carri'), ('preliminary', 'preliminari'), ('training', 'train'), ('machine', 'machin'), ('learning', 'learn'), ('model', 'model'), ('[', '['), ('45', '45'), (']', ']'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analytical', 'analyt'), ('11', '11'), ('model', 'model'), ('available', 'avail'), ('based', 'base'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('coarse', 'coars'), ('approximation', 'approxim'), ('physical', 'physic'), ('model', 'model'), (',', ','), ('resulting', 'result'), ('training', 'train'), ('set', 'set'), ('used', 'use'), ('augment', 'augment'), ('data', 'data'), ('order', 'order'), ('carry', 'carri'), ('preliminary', 'preliminari'), ('training', 'train'), ('machine', 'machin'), ('learning', 'learn'), ('model', 'model'), ('[', '['), ('45', '45'), (']', ']'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('analytical', 'analytical'), ('11', '11'), ('model', 'model'), ('available', 'available'), ('based', 'based'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('coarse', 'coarse'), ('approximation', 'approximation'), ('physical', 'physical'), ('model', 'model'), (',', ','), ('resulting', 'resulting'), ('training', 'training'), ('set', 'set'), ('used', 'used'), ('augment', 'augment'), ('data', 'data'), ('order', 'order'), ('carry', 'carry'), ('preliminary', 'preliminary'), ('training', 'training'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('[', '['), ('45', '45'), (']', ']'), ('2', '2'), ('.', '.')]



============================ Sentence 358 =============================

For an application at a full-duplex transceiver, we refer to [47], which learns how to cancel self-interference in order to overcome the lack of well-established models for the transmitter-receiver chain of non-linearities. 


>> Tokens are: 
 ['For', 'application', 'full-duplex', 'transceiver', ',', 'refer', '[', '47', ']', ',', 'learns', 'cancel', 'self-interference', 'order', 'overcome', 'lack', 'well-established', 'models', 'transmitter-receiver', 'chain', 'non-linearities', '.']

>> Bigrams are: 
 [('For', 'application'), ('application', 'full-duplex'), ('full-duplex', 'transceiver'), ('transceiver', ','), (',', 'refer'), ('refer', '['), ('[', '47'), ('47', ']'), (']', ','), (',', 'learns'), ('learns', 'cancel'), ('cancel', 'self-interference'), ('self-interference', 'order'), ('order', 'overcome'), ('overcome', 'lack'), ('lack', 'well-established'), ('well-established', 'models'), ('models', 'transmitter-receiver'), ('transmitter-receiver', 'chain'), ('chain', 'non-linearities'), ('non-linearities', '.')]

>> Trigrams are: 
 [('For', 'application', 'full-duplex'), ('application', 'full-duplex', 'transceiver'), ('full-duplex', 'transceiver', ','), ('transceiver', ',', 'refer'), (',', 'refer', '['), ('refer', '[', '47'), ('[', '47', ']'), ('47', ']', ','), (']', ',', 'learns'), (',', 'learns', 'cancel'), ('learns', 'cancel', 'self-interference'), ('cancel', 'self-interference', 'order'), ('self-interference', 'order', 'overcome'), ('order', 'overcome', 'lack'), ('overcome', 'lack', 'well-established'), ('lack', 'well-established', 'models'), ('well-established', 'models', 'transmitter-receiver'), ('models', 'transmitter-receiver', 'chain'), ('transmitter-receiver', 'chain', 'non-linearities'), ('chain', 'non-linearities', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('application', 'NN'), ('full-duplex', 'JJ'), ('transceiver', 'NN'), (',', ','), ('refer', 'VBP'), ('[', 'JJ'), ('47', 'CD'), (']', 'NN'), (',', ','), ('learns', 'VBZ'), ('cancel', 'JJ'), ('self-interference', 'JJ'), ('order', 'NN'), ('overcome', 'JJ'), ('lack', 'NN'), ('well-established', 'JJ'), ('models', 'NNS'), ('transmitter-receiver', 'RB'), ('chain', 'NN'), ('non-linearities', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP application/NN)
  (NP full-duplex/JJ transceiver/NN)
  ,/,
  refer/VBP
  [/JJ
  47/CD
  (NP ]/NN)
  ,/,
  learns/VBZ
  (NP cancel/JJ self-interference/JJ order/NN)
  (NP overcome/JJ lack/NN)
  (NP well-established/JJ models/NNS)
  transmitter-receiver/RB
  (NP chain/NN non-linearities/NNS)
  ./.) 


>> Noun Phrases are: 
 ['application', 'full-duplex transceiver', ']', 'cancel self-interference order', 'overcome lack', 'well-established models', 'chain non-linearities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('application', 'applic'), ('full-duplex', 'full-duplex'), ('transceiver', 'transceiv'), (',', ','), ('refer', 'refer'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('learns', 'learn'), ('cancel', 'cancel'), ('self-interference', 'self-interfer'), ('order', 'order'), ('overcome', 'overcom'), ('lack', 'lack'), ('well-established', 'well-establish'), ('models', 'model'), ('transmitter-receiver', 'transmitter-receiv'), ('chain', 'chain'), ('non-linearities', 'non-linear'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('application', 'applic'), ('full-duplex', 'full-duplex'), ('transceiver', 'transceiv'), (',', ','), ('refer', 'refer'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('learns', 'learn'), ('cancel', 'cancel'), ('self-interference', 'self-interfer'), ('order', 'order'), ('overcome', 'overcom'), ('lack', 'lack'), ('well-established', 'well-establish'), ('models', 'model'), ('transmitter-receiver', 'transmitter-receiv'), ('chain', 'chain'), ('non-linearities', 'non-linear'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('application', 'application'), ('full-duplex', 'full-duplex'), ('transceiver', 'transceiver'), (',', ','), ('refer', 'refer'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('learns', 'learns'), ('cancel', 'cancel'), ('self-interference', 'self-interference'), ('order', 'order'), ('overcome', 'overcome'), ('lack', 'lack'), ('well-established', 'well-established'), ('models', 'model'), ('transmitter-receiver', 'transmitter-receiver'), ('chain', 'chain'), ('non-linearities', 'non-linearities'), ('.', '.')]



============================ Sentence 359 =============================

(2) Link and Medium Access Control Layers: At the medium access control layer, we highlight some ap- plications of machine learning that tackle the lack of mathematical models for complex access protocols and communication environments. 


>> Tokens are: 
 ['(', '2', ')', 'Link', 'Medium', 'Access', 'Control', 'Layers', ':', 'At', 'medium', 'access', 'control', 'layer', ',', 'highlight', 'ap-', 'plications', 'machine', 'learning', 'tackle', 'lack', 'mathematical', 'models', 'complex', 'access', 'protocols', 'communication', 'environments', '.']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'Link'), ('Link', 'Medium'), ('Medium', 'Access'), ('Access', 'Control'), ('Control', 'Layers'), ('Layers', ':'), (':', 'At'), ('At', 'medium'), ('medium', 'access'), ('access', 'control'), ('control', 'layer'), ('layer', ','), (',', 'highlight'), ('highlight', 'ap-'), ('ap-', 'plications'), ('plications', 'machine'), ('machine', 'learning'), ('learning', 'tackle'), ('tackle', 'lack'), ('lack', 'mathematical'), ('mathematical', 'models'), ('models', 'complex'), ('complex', 'access'), ('access', 'protocols'), ('protocols', 'communication'), ('communication', 'environments'), ('environments', '.')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'Link'), (')', 'Link', 'Medium'), ('Link', 'Medium', 'Access'), ('Medium', 'Access', 'Control'), ('Access', 'Control', 'Layers'), ('Control', 'Layers', ':'), ('Layers', ':', 'At'), (':', 'At', 'medium'), ('At', 'medium', 'access'), ('medium', 'access', 'control'), ('access', 'control', 'layer'), ('control', 'layer', ','), ('layer', ',', 'highlight'), (',', 'highlight', 'ap-'), ('highlight', 'ap-', 'plications'), ('ap-', 'plications', 'machine'), ('plications', 'machine', 'learning'), ('machine', 'learning', 'tackle'), ('learning', 'tackle', 'lack'), ('tackle', 'lack', 'mathematical'), ('lack', 'mathematical', 'models'), ('mathematical', 'models', 'complex'), ('models', 'complex', 'access'), ('complex', 'access', 'protocols'), ('access', 'protocols', 'communication'), ('protocols', 'communication', 'environments'), ('communication', 'environments', '.')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('Link', 'NNP'), ('Medium', 'NNP'), ('Access', 'NNP'), ('Control', 'NNP'), ('Layers', 'NNP'), (':', ':'), ('At', 'IN'), ('medium', 'NN'), ('access', 'NN'), ('control', 'NN'), ('layer', 'NN'), (',', ','), ('highlight', 'VBD'), ('ap-', 'JJ'), ('plications', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('tackle', 'JJ'), ('lack', 'NN'), ('mathematical', 'JJ'), ('models', 'NNS'), ('complex', 'JJ'), ('access', 'NN'), ('protocols', 'NNS'), ('communication', 'NN'), ('environments', 'NNS'), ('.', '.')]

 (S
  (/(
  2/CD
  )/)
  (NP Link/NNP Medium/NNP Access/NNP Control/NNP Layers/NNP)
  :/:
  At/IN
  (NP medium/NN access/NN control/NN layer/NN)
  ,/,
  highlight/VBD
  (NP ap-/JJ plications/NNS machine/NN)
  learning/VBG
  (NP tackle/JJ lack/NN)
  (NP mathematical/JJ models/NNS)
  (NP
    complex/JJ
    access/NN
    protocols/NNS
    communication/NN
    environments/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Link Medium Access Control Layers', 'medium access control layer', 'ap- plications machine', 'tackle lack', 'mathematical models', 'complex access protocols communication environments']

>> Named Entities are: 
 [('PERSON', 'Link Medium Access Control Layers')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Link', 'link'), ('Medium', 'medium'), ('Access', 'access'), ('Control', 'control'), ('Layers', 'layer'), (':', ':'), ('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('highlight', 'highlight'), ('ap-', 'ap-'), ('plications', 'plicat'), ('machine', 'machin'), ('learning', 'learn'), ('tackle', 'tackl'), ('lack', 'lack'), ('mathematical', 'mathemat'), ('models', 'model'), ('complex', 'complex'), ('access', 'access'), ('protocols', 'protocol'), ('communication', 'commun'), ('environments', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Link', 'link'), ('Medium', 'medium'), ('Access', 'access'), ('Control', 'control'), ('Layers', 'layer'), (':', ':'), ('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('highlight', 'highlight'), ('ap-', 'ap-'), ('plications', 'plicat'), ('machine', 'machin'), ('learning', 'learn'), ('tackle', 'tackl'), ('lack', 'lack'), ('mathematical', 'mathemat'), ('models', 'model'), ('complex', 'complex'), ('access', 'access'), ('protocols', 'protocol'), ('communication', 'communic'), ('environments', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('Link', 'Link'), ('Medium', 'Medium'), ('Access', 'Access'), ('Control', 'Control'), ('Layers', 'Layers'), (':', ':'), ('At', 'At'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('highlight', 'highlight'), ('ap-', 'ap-'), ('plications', 'plication'), ('machine', 'machine'), ('learning', 'learning'), ('tackle', 'tackle'), ('lack', 'lack'), ('mathematical', 'mathematical'), ('models', 'model'), ('complex', 'complex'), ('access', 'access'), ('protocols', 'protocol'), ('communication', 'communication'), ('environments', 'environment'), ('.', '.')]



============================ Sentence 360 =============================

In [48], a mechanism is proposed to predict whether a channel decoder will suc- ceed on the basis of the outputs of the first few iterations of the iterative decoding process. 


>> Tokens are: 
 ['In', '[', '48', ']', ',', 'mechanism', 'proposed', 'predict', 'whether', 'channel', 'decoder', 'suc-', 'ceed', 'basis', 'outputs', 'first', 'iterations', 'iterative', 'decoding', 'process', '.']

>> Bigrams are: 
 [('In', '['), ('[', '48'), ('48', ']'), (']', ','), (',', 'mechanism'), ('mechanism', 'proposed'), ('proposed', 'predict'), ('predict', 'whether'), ('whether', 'channel'), ('channel', 'decoder'), ('decoder', 'suc-'), ('suc-', 'ceed'), ('ceed', 'basis'), ('basis', 'outputs'), ('outputs', 'first'), ('first', 'iterations'), ('iterations', 'iterative'), ('iterative', 'decoding'), ('decoding', 'process'), ('process', '.')]

>> Trigrams are: 
 [('In', '[', '48'), ('[', '48', ']'), ('48', ']', ','), (']', ',', 'mechanism'), (',', 'mechanism', 'proposed'), ('mechanism', 'proposed', 'predict'), ('proposed', 'predict', 'whether'), ('predict', 'whether', 'channel'), ('whether', 'channel', 'decoder'), ('channel', 'decoder', 'suc-'), ('decoder', 'suc-', 'ceed'), ('suc-', 'ceed', 'basis'), ('ceed', 'basis', 'outputs'), ('basis', 'outputs', 'first'), ('outputs', 'first', 'iterations'), ('first', 'iterations', 'iterative'), ('iterations', 'iterative', 'decoding'), ('iterative', 'decoding', 'process'), ('decoding', 'process', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('48', 'CD'), (']', 'NNP'), (',', ','), ('mechanism', 'NN'), ('proposed', 'VBN'), ('predict', 'IN'), ('whether', 'IN'), ('channel', 'NN'), ('decoder', 'NN'), ('suc-', 'JJ'), ('ceed', 'JJ'), ('basis', 'NN'), ('outputs', 'NNS'), ('first', 'JJ'), ('iterations', 'NNS'), ('iterative', 'VBP'), ('decoding', 'VBG'), ('process', 'NN'), ('.', '.')]

 (S
  In/IN
  [/$
  48/CD
  (NP ]/NNP)
  ,/,
  (NP mechanism/NN)
  proposed/VBN
  predict/IN
  whether/IN
  (NP channel/NN decoder/NN)
  (NP suc-/JJ ceed/JJ basis/NN outputs/NNS)
  (NP first/JJ iterations/NNS)
  iterative/VBP
  decoding/VBG
  (NP process/NN)
  ./.) 


>> Noun Phrases are: 
 [']', 'mechanism', 'channel decoder', 'suc- ceed basis outputs', 'first iterations', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('mechanism', 'mechan'), ('proposed', 'propos'), ('predict', 'predict'), ('whether', 'whether'), ('channel', 'channel'), ('decoder', 'decod'), ('suc-', 'suc-'), ('ceed', 'ceed'), ('basis', 'basi'), ('outputs', 'output'), ('first', 'first'), ('iterations', 'iter'), ('iterative', 'iter'), ('decoding', 'decod'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('mechanism', 'mechan'), ('proposed', 'propos'), ('predict', 'predict'), ('whether', 'whether'), ('channel', 'channel'), ('decoder', 'decod'), ('suc-', 'suc-'), ('ceed', 'ceed'), ('basis', 'basi'), ('outputs', 'output'), ('first', 'first'), ('iterations', 'iter'), ('iterative', 'iter'), ('decoding', 'decod'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('mechanism', 'mechanism'), ('proposed', 'proposed'), ('predict', 'predict'), ('whether', 'whether'), ('channel', 'channel'), ('decoder', 'decoder'), ('suc-', 'suc-'), ('ceed', 'ceed'), ('basis', 'basis'), ('outputs', 'output'), ('first', 'first'), ('iterations', 'iteration'), ('iterative', 'iterative'), ('decoding', 'decoding'), ('process', 'process'), ('.', '.')]



============================ Sentence 361 =============================

This binary predictor is useful in order to request an early retransmission at the link layer using Automatic Retransmission Request (ARQ) or Hybrid ARQ (HARQ) in order to reduce latency. 


>> Tokens are: 
 ['This', 'binary', 'predictor', 'useful', 'order', 'request', 'early', 'retransmission', 'link', 'layer', 'using', 'Automatic', 'Retransmission', 'Request', '(', 'ARQ', ')', 'Hybrid', 'ARQ', '(', 'HARQ', ')', 'order', 'reduce', 'latency', '.']

>> Bigrams are: 
 [('This', 'binary'), ('binary', 'predictor'), ('predictor', 'useful'), ('useful', 'order'), ('order', 'request'), ('request', 'early'), ('early', 'retransmission'), ('retransmission', 'link'), ('link', 'layer'), ('layer', 'using'), ('using', 'Automatic'), ('Automatic', 'Retransmission'), ('Retransmission', 'Request'), ('Request', '('), ('(', 'ARQ'), ('ARQ', ')'), (')', 'Hybrid'), ('Hybrid', 'ARQ'), ('ARQ', '('), ('(', 'HARQ'), ('HARQ', ')'), (')', 'order'), ('order', 'reduce'), ('reduce', 'latency'), ('latency', '.')]

>> Trigrams are: 
 [('This', 'binary', 'predictor'), ('binary', 'predictor', 'useful'), ('predictor', 'useful', 'order'), ('useful', 'order', 'request'), ('order', 'request', 'early'), ('request', 'early', 'retransmission'), ('early', 'retransmission', 'link'), ('retransmission', 'link', 'layer'), ('link', 'layer', 'using'), ('layer', 'using', 'Automatic'), ('using', 'Automatic', 'Retransmission'), ('Automatic', 'Retransmission', 'Request'), ('Retransmission', 'Request', '('), ('Request', '(', 'ARQ'), ('(', 'ARQ', ')'), ('ARQ', ')', 'Hybrid'), (')', 'Hybrid', 'ARQ'), ('Hybrid', 'ARQ', '('), ('ARQ', '(', 'HARQ'), ('(', 'HARQ', ')'), ('HARQ', ')', 'order'), (')', 'order', 'reduce'), ('order', 'reduce', 'latency'), ('reduce', 'latency', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('binary', 'JJ'), ('predictor', 'NN'), ('useful', 'JJ'), ('order', 'NN'), ('request', 'NN'), ('early', 'JJ'), ('retransmission', 'NN'), ('link', 'NN'), ('layer', 'NN'), ('using', 'VBG'), ('Automatic', 'NNP'), ('Retransmission', 'NNP'), ('Request', 'NNP'), ('(', '('), ('ARQ', 'NNP'), (')', ')'), ('Hybrid', 'NNP'), ('ARQ', 'NNP'), ('(', '('), ('HARQ', 'NNP'), (')', ')'), ('order', 'NN'), ('reduce', 'VB'), ('latency', 'NN'), ('.', '.')]

 (S
  (NP This/DT binary/JJ predictor/NN)
  (NP useful/JJ order/NN request/NN)
  (NP early/JJ retransmission/NN link/NN layer/NN)
  using/VBG
  (NP Automatic/NNP Retransmission/NNP Request/NNP)
  (/(
  (NP ARQ/NNP)
  )/)
  (NP Hybrid/NNP ARQ/NNP)
  (/(
  (NP HARQ/NNP)
  )/)
  (NP order/NN)
  reduce/VB
  (NP latency/NN)
  ./.) 


>> Noun Phrases are: 
 ['This binary predictor', 'useful order request', 'early retransmission link layer', 'Automatic Retransmission Request', 'ARQ', 'Hybrid ARQ', 'HARQ', 'order', 'latency']

>> Named Entities are: 
 [('PERSON', 'Automatic Retransmission Request'), ('ORGANIZATION', 'ARQ'), ('PERSON', 'Hybrid ARQ'), ('ORGANIZATION', 'HARQ')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('binary', 'binari'), ('predictor', 'predictor'), ('useful', 'use'), ('order', 'order'), ('request', 'request'), ('early', 'earli'), ('retransmission', 'retransmiss'), ('link', 'link'), ('layer', 'layer'), ('using', 'use'), ('Automatic', 'automat'), ('Retransmission', 'retransmiss'), ('Request', 'request'), ('(', '('), ('ARQ', 'arq'), (')', ')'), ('Hybrid', 'hybrid'), ('ARQ', 'arq'), ('(', '('), ('HARQ', 'harq'), (')', ')'), ('order', 'order'), ('reduce', 'reduc'), ('latency', 'latenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('binary', 'binari'), ('predictor', 'predictor'), ('useful', 'use'), ('order', 'order'), ('request', 'request'), ('early', 'earli'), ('retransmission', 'retransmiss'), ('link', 'link'), ('layer', 'layer'), ('using', 'use'), ('Automatic', 'automat'), ('Retransmission', 'retransmiss'), ('Request', 'request'), ('(', '('), ('ARQ', 'arq'), (')', ')'), ('Hybrid', 'hybrid'), ('ARQ', 'arq'), ('(', '('), ('HARQ', 'harq'), (')', ')'), ('order', 'order'), ('reduce', 'reduc'), ('latency', 'latenc'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('binary', 'binary'), ('predictor', 'predictor'), ('useful', 'useful'), ('order', 'order'), ('request', 'request'), ('early', 'early'), ('retransmission', 'retransmission'), ('link', 'link'), ('layer', 'layer'), ('using', 'using'), ('Automatic', 'Automatic'), ('Retransmission', 'Retransmission'), ('Request', 'Request'), ('(', '('), ('ARQ', 'ARQ'), (')', ')'), ('Hybrid', 'Hybrid'), ('ARQ', 'ARQ'), ('(', '('), ('HARQ', 'HARQ'), (')', ')'), ('order', 'order'), ('reduce', 'reduce'), ('latency', 'latency'), ('.', '.')]



============================ Sentence 362 =============================

At the medium access control layer, data-aided methods can instead be used to predict the availability of spectrum in the presence of interfering incumbent devices with complex activation patterns for cognitive radio applications [49] (see also [50]). 


>> Tokens are: 
 ['At', 'medium', 'access', 'control', 'layer', ',', 'data-aided', 'methods', 'instead', 'used', 'predict', 'availability', 'spectrum', 'presence', 'interfering', 'incumbent', 'devices', 'complex', 'activation', 'patterns', 'cognitive', 'radio', 'applications', '[', '49', ']', '(', 'see', 'also', '[', '50', ']', ')', '.']

>> Bigrams are: 
 [('At', 'medium'), ('medium', 'access'), ('access', 'control'), ('control', 'layer'), ('layer', ','), (',', 'data-aided'), ('data-aided', 'methods'), ('methods', 'instead'), ('instead', 'used'), ('used', 'predict'), ('predict', 'availability'), ('availability', 'spectrum'), ('spectrum', 'presence'), ('presence', 'interfering'), ('interfering', 'incumbent'), ('incumbent', 'devices'), ('devices', 'complex'), ('complex', 'activation'), ('activation', 'patterns'), ('patterns', 'cognitive'), ('cognitive', 'radio'), ('radio', 'applications'), ('applications', '['), ('[', '49'), ('49', ']'), (']', '('), ('(', 'see'), ('see', 'also'), ('also', '['), ('[', '50'), ('50', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('At', 'medium', 'access'), ('medium', 'access', 'control'), ('access', 'control', 'layer'), ('control', 'layer', ','), ('layer', ',', 'data-aided'), (',', 'data-aided', 'methods'), ('data-aided', 'methods', 'instead'), ('methods', 'instead', 'used'), ('instead', 'used', 'predict'), ('used', 'predict', 'availability'), ('predict', 'availability', 'spectrum'), ('availability', 'spectrum', 'presence'), ('spectrum', 'presence', 'interfering'), ('presence', 'interfering', 'incumbent'), ('interfering', 'incumbent', 'devices'), ('incumbent', 'devices', 'complex'), ('devices', 'complex', 'activation'), ('complex', 'activation', 'patterns'), ('activation', 'patterns', 'cognitive'), ('patterns', 'cognitive', 'radio'), ('cognitive', 'radio', 'applications'), ('radio', 'applications', '['), ('applications', '[', '49'), ('[', '49', ']'), ('49', ']', '('), (']', '(', 'see'), ('(', 'see', 'also'), ('see', 'also', '['), ('also', '[', '50'), ('[', '50', ']'), ('50', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('medium', 'JJ'), ('access', 'NN'), ('control', 'NN'), ('layer', 'NN'), (',', ','), ('data-aided', 'JJ'), ('methods', 'NNS'), ('instead', 'RB'), ('used', 'VBD'), ('predict', 'JJ'), ('availability', 'NN'), ('spectrum', 'NN'), ('presence', 'NN'), ('interfering', 'VBG'), ('incumbent', 'JJ'), ('devices', 'NNS'), ('complex', 'JJ'), ('activation', 'NN'), ('patterns', 'NNS'), ('cognitive', 'JJ'), ('radio', 'NN'), ('applications', 'NNS'), ('[', 'VBP'), ('49', 'CD'), (']', 'NN'), ('(', '('), ('see', 'VB'), ('also', 'RB'), ('[', '$'), ('50', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  At/IN
  (NP medium/JJ access/NN control/NN layer/NN)
  ,/,
  (NP data-aided/JJ methods/NNS)
  instead/RB
  used/VBD
  (NP predict/JJ availability/NN spectrum/NN presence/NN)
  interfering/VBG
  (NP incumbent/JJ devices/NNS)
  (NP complex/JJ activation/NN patterns/NNS)
  (NP cognitive/JJ radio/NN applications/NNS)
  [/VBP
  49/CD
  (NP ]/NN)
  (/(
  see/VB
  also/RB
  [/$
  50/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['medium access control layer', 'data-aided methods', 'predict availability spectrum presence', 'incumbent devices', 'complex activation patterns', 'cognitive radio applications', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('data-aided', 'data-aid'), ('methods', 'method'), ('instead', 'instead'), ('used', 'use'), ('predict', 'predict'), ('availability', 'avail'), ('spectrum', 'spectrum'), ('presence', 'presenc'), ('interfering', 'interf'), ('incumbent', 'incumb'), ('devices', 'devic'), ('complex', 'complex'), ('activation', 'activ'), ('patterns', 'pattern'), ('cognitive', 'cognit'), ('radio', 'radio'), ('applications', 'applic'), ('[', '['), ('49', '49'), (']', ']'), ('(', '('), ('see', 'see'), ('also', 'also'), ('[', '['), ('50', '50'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('data-aided', 'data-aid'), ('methods', 'method'), ('instead', 'instead'), ('used', 'use'), ('predict', 'predict'), ('availability', 'avail'), ('spectrum', 'spectrum'), ('presence', 'presenc'), ('interfering', 'interf'), ('incumbent', 'incumb'), ('devices', 'devic'), ('complex', 'complex'), ('activation', 'activ'), ('patterns', 'pattern'), ('cognitive', 'cognit'), ('radio', 'radio'), ('applications', 'applic'), ('[', '['), ('49', '49'), (']', ']'), ('(', '('), ('see', 'see'), ('also', 'also'), ('[', '['), ('50', '50'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('medium', 'medium'), ('access', 'access'), ('control', 'control'), ('layer', 'layer'), (',', ','), ('data-aided', 'data-aided'), ('methods', 'method'), ('instead', 'instead'), ('used', 'used'), ('predict', 'predict'), ('availability', 'availability'), ('spectrum', 'spectrum'), ('presence', 'presence'), ('interfering', 'interfering'), ('incumbent', 'incumbent'), ('devices', 'device'), ('complex', 'complex'), ('activation', 'activation'), ('patterns', 'pattern'), ('cognitive', 'cognitive'), ('radio', 'radio'), ('applications', 'application'), ('[', '['), ('49', '49'), (']', ']'), ('(', '('), ('see', 'see'), ('also', 'also'), ('[', '['), ('50', '50'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 363 =============================

An approach that leverages depth images to detect the availability of mmwave channels is proposed in [51]. 


>> Tokens are: 
 ['An', 'approach', 'leverages', 'depth', 'images', 'detect', 'availability', 'mmwave', 'channels', 'proposed', '[', '51', ']', '.']

>> Bigrams are: 
 [('An', 'approach'), ('approach', 'leverages'), ('leverages', 'depth'), ('depth', 'images'), ('images', 'detect'), ('detect', 'availability'), ('availability', 'mmwave'), ('mmwave', 'channels'), ('channels', 'proposed'), ('proposed', '['), ('[', '51'), ('51', ']'), (']', '.')]

>> Trigrams are: 
 [('An', 'approach', 'leverages'), ('approach', 'leverages', 'depth'), ('leverages', 'depth', 'images'), ('depth', 'images', 'detect'), ('images', 'detect', 'availability'), ('detect', 'availability', 'mmwave'), ('availability', 'mmwave', 'channels'), ('mmwave', 'channels', 'proposed'), ('channels', 'proposed', '['), ('proposed', '[', '51'), ('[', '51', ']'), ('51', ']', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('approach', 'NN'), ('leverages', 'VBZ'), ('depth', 'JJ'), ('images', 'NNS'), ('detect', 'VBP'), ('availability', 'NN'), ('mmwave', 'VBP'), ('channels', 'NNS'), ('proposed', 'VBN'), ('[', 'RB'), ('51', 'CD'), (']', 'NNS'), ('.', '.')]

 (S
  (NP An/DT approach/NN)
  leverages/VBZ
  (NP depth/JJ images/NNS)
  detect/VBP
  (NP availability/NN)
  mmwave/VBP
  (NP channels/NNS)
  proposed/VBN
  [/RB
  51/CD
  (NP ]/NNS)
  ./.) 


>> Noun Phrases are: 
 ['An approach', 'depth images', 'availability', 'channels', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('approach', 'approach'), ('leverages', 'leverag'), ('depth', 'depth'), ('images', 'imag'), ('detect', 'detect'), ('availability', 'avail'), ('mmwave', 'mmwave'), ('channels', 'channel'), ('proposed', 'propos'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('approach', 'approach'), ('leverages', 'leverag'), ('depth', 'depth'), ('images', 'imag'), ('detect', 'detect'), ('availability', 'avail'), ('mmwave', 'mmwave'), ('channels', 'channel'), ('proposed', 'propos'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('approach', 'approach'), ('leverages', 'leverage'), ('depth', 'depth'), ('images', 'image'), ('detect', 'detect'), ('availability', 'availability'), ('mmwave', 'mmwave'), ('channels', 'channel'), ('proposed', 'proposed'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]



============================ Sentence 364 =============================

(3) Network and Application Layers: A task that is particularly well-suited for machine learning is the caching of popular contents for reduced latency and network congestion [52]. 


>> Tokens are: 
 ['(', '3', ')', 'Network', 'Application', 'Layers', ':', 'A', 'task', 'particularly', 'well-suited', 'machine', 'learning', 'caching', 'popular', 'contents', 'reduced', 'latency', 'network', 'congestion', '[', '52', ']', '.']

>> Bigrams are: 
 [('(', '3'), ('3', ')'), (')', 'Network'), ('Network', 'Application'), ('Application', 'Layers'), ('Layers', ':'), (':', 'A'), ('A', 'task'), ('task', 'particularly'), ('particularly', 'well-suited'), ('well-suited', 'machine'), ('machine', 'learning'), ('learning', 'caching'), ('caching', 'popular'), ('popular', 'contents'), ('contents', 'reduced'), ('reduced', 'latency'), ('latency', 'network'), ('network', 'congestion'), ('congestion', '['), ('[', '52'), ('52', ']'), (']', '.')]

>> Trigrams are: 
 [('(', '3', ')'), ('3', ')', 'Network'), (')', 'Network', 'Application'), ('Network', 'Application', 'Layers'), ('Application', 'Layers', ':'), ('Layers', ':', 'A'), (':', 'A', 'task'), ('A', 'task', 'particularly'), ('task', 'particularly', 'well-suited'), ('particularly', 'well-suited', 'machine'), ('well-suited', 'machine', 'learning'), ('machine', 'learning', 'caching'), ('learning', 'caching', 'popular'), ('caching', 'popular', 'contents'), ('popular', 'contents', 'reduced'), ('contents', 'reduced', 'latency'), ('reduced', 'latency', 'network'), ('latency', 'network', 'congestion'), ('network', 'congestion', '['), ('congestion', '[', '52'), ('[', '52', ']'), ('52', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('3', 'CD'), (')', ')'), ('Network', 'NNP'), ('Application', 'NNP'), ('Layers', 'NNP'), (':', ':'), ('A', 'DT'), ('task', 'NN'), ('particularly', 'RB'), ('well-suited', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('caching', 'VBG'), ('popular', 'JJ'), ('contents', 'NNS'), ('reduced', 'VBD'), ('latency', 'NN'), ('network', 'NN'), ('congestion', 'NN'), ('[', 'VBD'), ('52', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (/(
  3/CD
  )/)
  (NP Network/NNP Application/NNP Layers/NNP)
  :/:
  (NP A/DT task/NN)
  particularly/RB
  (NP well-suited/JJ machine/NN)
  learning/VBG
  caching/VBG
  (NP popular/JJ contents/NNS)
  reduced/VBD
  (NP latency/NN network/NN congestion/NN)
  [/VBD
  52/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Network Application Layers', 'A task', 'well-suited machine', 'popular contents', 'latency network congestion', ']']

>> Named Entities are: 
 [('PERSON', 'Network Application Layers')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('3', '3'), (')', ')'), ('Network', 'network'), ('Application', 'applic'), ('Layers', 'layer'), (':', ':'), ('A', 'a'), ('task', 'task'), ('particularly', 'particularli'), ('well-suited', 'well-suit'), ('machine', 'machin'), ('learning', 'learn'), ('caching', 'cach'), ('popular', 'popular'), ('contents', 'content'), ('reduced', 'reduc'), ('latency', 'latenc'), ('network', 'network'), ('congestion', 'congest'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('3', '3'), (')', ')'), ('Network', 'network'), ('Application', 'applic'), ('Layers', 'layer'), (':', ':'), ('A', 'a'), ('task', 'task'), ('particularly', 'particular'), ('well-suited', 'well-suit'), ('machine', 'machin'), ('learning', 'learn'), ('caching', 'cach'), ('popular', 'popular'), ('contents', 'content'), ('reduced', 'reduc'), ('latency', 'latenc'), ('network', 'network'), ('congestion', 'congest'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('3', '3'), (')', ')'), ('Network', 'Network'), ('Application', 'Application'), ('Layers', 'Layers'), (':', ':'), ('A', 'A'), ('task', 'task'), ('particularly', 'particularly'), ('well-suited', 'well-suited'), ('machine', 'machine'), ('learning', 'learning'), ('caching', 'caching'), ('popular', 'popular'), ('contents', 'content'), ('reduced', 'reduced'), ('latency', 'latency'), ('network', 'network'), ('congestion', 'congestion'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]



============================ Sentence 365 =============================

Caching may take place at the edge and, more traditionally, within the core network segment. 


>> Tokens are: 
 ['Caching', 'may', 'take', 'place', 'edge', ',', 'traditionally', ',', 'within', 'core', 'network', 'segment', '.']

>> Bigrams are: 
 [('Caching', 'may'), ('may', 'take'), ('take', 'place'), ('place', 'edge'), ('edge', ','), (',', 'traditionally'), ('traditionally', ','), (',', 'within'), ('within', 'core'), ('core', 'network'), ('network', 'segment'), ('segment', '.')]

>> Trigrams are: 
 [('Caching', 'may', 'take'), ('may', 'take', 'place'), ('take', 'place', 'edge'), ('place', 'edge', ','), ('edge', ',', 'traditionally'), (',', 'traditionally', ','), ('traditionally', ',', 'within'), (',', 'within', 'core'), ('within', 'core', 'network'), ('core', 'network', 'segment'), ('network', 'segment', '.')]

>> POS Tags are: 
 [('Caching', 'VBG'), ('may', 'MD'), ('take', 'VB'), ('place', 'NN'), ('edge', 'NN'), (',', ','), ('traditionally', 'RB'), (',', ','), ('within', 'IN'), ('core', 'NN'), ('network', 'NN'), ('segment', 'NN'), ('.', '.')]

 (S
  Caching/VBG
  may/MD
  take/VB
  (NP place/NN edge/NN)
  ,/,
  traditionally/RB
  ,/,
  within/IN
  (NP core/NN network/NN segment/NN)
  ./.) 


>> Noun Phrases are: 
 ['place edge', 'core network segment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Caching', 'cach'), ('may', 'may'), ('take', 'take'), ('place', 'place'), ('edge', 'edg'), (',', ','), ('traditionally', 'tradit'), (',', ','), ('within', 'within'), ('core', 'core'), ('network', 'network'), ('segment', 'segment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Caching', 'cach'), ('may', 'may'), ('take', 'take'), ('place', 'place'), ('edge', 'edg'), (',', ','), ('traditionally', 'tradit'), (',', ','), ('within', 'within'), ('core', 'core'), ('network', 'network'), ('segment', 'segment'), ('.', '.')]

>> Lemmatization: 
 [('Caching', 'Caching'), ('may', 'may'), ('take', 'take'), ('place', 'place'), ('edge', 'edge'), (',', ','), ('traditionally', 'traditionally'), (',', ','), ('within', 'within'), ('core', 'core'), ('network', 'network'), ('segment', 'segment'), ('.', '.')]



============================ Sentence 366 =============================

Caching at the edge has the advantage of catering directly to the preference of the local population of users, but it generally suffers from a reduced hit rate due to the smaller available storage capacity. 


>> Tokens are: 
 ['Caching', 'edge', 'advantage', 'catering', 'directly', 'preference', 'local', 'population', 'users', ',', 'generally', 'suffers', 'reduced', 'hit', 'rate', 'due', 'smaller', 'available', 'storage', 'capacity', '.']

>> Bigrams are: 
 [('Caching', 'edge'), ('edge', 'advantage'), ('advantage', 'catering'), ('catering', 'directly'), ('directly', 'preference'), ('preference', 'local'), ('local', 'population'), ('population', 'users'), ('users', ','), (',', 'generally'), ('generally', 'suffers'), ('suffers', 'reduced'), ('reduced', 'hit'), ('hit', 'rate'), ('rate', 'due'), ('due', 'smaller'), ('smaller', 'available'), ('available', 'storage'), ('storage', 'capacity'), ('capacity', '.')]

>> Trigrams are: 
 [('Caching', 'edge', 'advantage'), ('edge', 'advantage', 'catering'), ('advantage', 'catering', 'directly'), ('catering', 'directly', 'preference'), ('directly', 'preference', 'local'), ('preference', 'local', 'population'), ('local', 'population', 'users'), ('population', 'users', ','), ('users', ',', 'generally'), (',', 'generally', 'suffers'), ('generally', 'suffers', 'reduced'), ('suffers', 'reduced', 'hit'), ('reduced', 'hit', 'rate'), ('hit', 'rate', 'due'), ('rate', 'due', 'smaller'), ('due', 'smaller', 'available'), ('smaller', 'available', 'storage'), ('available', 'storage', 'capacity'), ('storage', 'capacity', '.')]

>> POS Tags are: 
 [('Caching', 'VBG'), ('edge', 'NN'), ('advantage', 'NN'), ('catering', 'VBG'), ('directly', 'RB'), ('preference', 'RB'), ('local', 'JJ'), ('population', 'NN'), ('users', 'NNS'), (',', ','), ('generally', 'RB'), ('suffers', 'NNS'), ('reduced', 'VBD'), ('hit', 'JJ'), ('rate', 'NN'), ('due', 'JJ'), ('smaller', 'JJR'), ('available', 'JJ'), ('storage', 'NN'), ('capacity', 'NN'), ('.', '.')]

 (S
  Caching/VBG
  (NP edge/NN advantage/NN)
  catering/VBG
  directly/RB
  preference/RB
  (NP local/JJ population/NN users/NNS)
  ,/,
  generally/RB
  (NP suffers/NNS)
  reduced/VBD
  (NP hit/JJ rate/NN)
  due/JJ
  smaller/JJR
  (NP available/JJ storage/NN capacity/NN)
  ./.) 


>> Noun Phrases are: 
 ['edge advantage', 'local population users', 'suffers', 'hit rate', 'available storage capacity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Caching', 'cach'), ('edge', 'edg'), ('advantage', 'advantag'), ('catering', 'cater'), ('directly', 'directli'), ('preference', 'prefer'), ('local', 'local'), ('population', 'popul'), ('users', 'user'), (',', ','), ('generally', 'gener'), ('suffers', 'suffer'), ('reduced', 'reduc'), ('hit', 'hit'), ('rate', 'rate'), ('due', 'due'), ('smaller', 'smaller'), ('available', 'avail'), ('storage', 'storag'), ('capacity', 'capac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Caching', 'cach'), ('edge', 'edg'), ('advantage', 'advantag'), ('catering', 'cater'), ('directly', 'direct'), ('preference', 'prefer'), ('local', 'local'), ('population', 'popul'), ('users', 'user'), (',', ','), ('generally', 'general'), ('suffers', 'suffer'), ('reduced', 'reduc'), ('hit', 'hit'), ('rate', 'rate'), ('due', 'due'), ('smaller', 'smaller'), ('available', 'avail'), ('storage', 'storag'), ('capacity', 'capac'), ('.', '.')]

>> Lemmatization: 
 [('Caching', 'Caching'), ('edge', 'edge'), ('advantage', 'advantage'), ('catering', 'catering'), ('directly', 'directly'), ('preference', 'preference'), ('local', 'local'), ('population', 'population'), ('users', 'user'), (',', ','), ('generally', 'generally'), ('suffers', 'suffers'), ('reduced', 'reduced'), ('hit', 'hit'), ('rate', 'rate'), ('due', 'due'), ('smaller', 'smaller'), ('available', 'available'), ('storage', 'storage'), ('capacity', 'capacity'), ('.', '.')]



============================ Sentence 367 =============================

Optimizing the selection of contents to be stored at the edge can be formulated as a classification problem that can benefit from a data-driven approach in order to adapt to the specific features of the local traffic [52]. 


>> Tokens are: 
 ['Optimizing', 'selection', 'contents', 'stored', 'edge', 'formulated', 'classification', 'problem', 'benefit', 'data-driven', 'approach', 'order', 'adapt', 'specific', 'features', 'local', 'traffic', '[', '52', ']', '.']

>> Bigrams are: 
 [('Optimizing', 'selection'), ('selection', 'contents'), ('contents', 'stored'), ('stored', 'edge'), ('edge', 'formulated'), ('formulated', 'classification'), ('classification', 'problem'), ('problem', 'benefit'), ('benefit', 'data-driven'), ('data-driven', 'approach'), ('approach', 'order'), ('order', 'adapt'), ('adapt', 'specific'), ('specific', 'features'), ('features', 'local'), ('local', 'traffic'), ('traffic', '['), ('[', '52'), ('52', ']'), (']', '.')]

>> Trigrams are: 
 [('Optimizing', 'selection', 'contents'), ('selection', 'contents', 'stored'), ('contents', 'stored', 'edge'), ('stored', 'edge', 'formulated'), ('edge', 'formulated', 'classification'), ('formulated', 'classification', 'problem'), ('classification', 'problem', 'benefit'), ('problem', 'benefit', 'data-driven'), ('benefit', 'data-driven', 'approach'), ('data-driven', 'approach', 'order'), ('approach', 'order', 'adapt'), ('order', 'adapt', 'specific'), ('adapt', 'specific', 'features'), ('specific', 'features', 'local'), ('features', 'local', 'traffic'), ('local', 'traffic', '['), ('traffic', '[', '52'), ('[', '52', ']'), ('52', ']', '.')]

>> POS Tags are: 
 [('Optimizing', 'VBG'), ('selection', 'NN'), ('contents', 'NNS'), ('stored', 'VBD'), ('edge', 'NN'), ('formulated', 'VBN'), ('classification', 'NN'), ('problem', 'NN'), ('benefit', 'NN'), ('data-driven', 'JJ'), ('approach', 'NN'), ('order', 'NN'), ('adapt', 'NN'), ('specific', 'JJ'), ('features', 'VBZ'), ('local', 'JJ'), ('traffic', 'NN'), ('[', 'VBZ'), ('52', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Optimizing/VBG
  (NP selection/NN contents/NNS)
  stored/VBD
  (NP edge/NN)
  formulated/VBN
  (NP classification/NN problem/NN benefit/NN)
  (NP data-driven/JJ approach/NN order/NN adapt/NN)
  specific/JJ
  features/VBZ
  (NP local/JJ traffic/NN)
  [/VBZ
  52/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['selection contents', 'edge', 'classification problem benefit', 'data-driven approach order adapt', 'local traffic', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Optimizing', 'optim'), ('selection', 'select'), ('contents', 'content'), ('stored', 'store'), ('edge', 'edg'), ('formulated', 'formul'), ('classification', 'classif'), ('problem', 'problem'), ('benefit', 'benefit'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('order', 'order'), ('adapt', 'adapt'), ('specific', 'specif'), ('features', 'featur'), ('local', 'local'), ('traffic', 'traffic'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Optimizing', 'optim'), ('selection', 'select'), ('contents', 'content'), ('stored', 'store'), ('edge', 'edg'), ('formulated', 'formul'), ('classification', 'classif'), ('problem', 'problem'), ('benefit', 'benefit'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('order', 'order'), ('adapt', 'adapt'), ('specific', 'specif'), ('features', 'featur'), ('local', 'local'), ('traffic', 'traffic'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Optimizing', 'Optimizing'), ('selection', 'selection'), ('contents', 'content'), ('stored', 'stored'), ('edge', 'edge'), ('formulated', 'formulated'), ('classification', 'classification'), ('problem', 'problem'), ('benefit', 'benefit'), ('data-driven', 'data-driven'), ('approach', 'approach'), ('order', 'order'), ('adapt', 'adapt'), ('specific', 'specific'), ('features', 'feature'), ('local', 'local'), ('traffic', 'traffic'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]



============================ Sentence 368 =============================

B. 


>> Tokens are: 
 ['B', '.']

>> Bigrams are: 
 [('B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('.', '.')]

 (S (NP B/NNP) ./.) 


>> Noun Phrases are: 
 ['B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('B', 'B'), ('.', '.')]



============================ Sentence 369 =============================

At the Cloud  We now turn to some relevant tasks to be carried out at the cloud at both network and application layers. 


>> Tokens are: 
 ['At', 'Cloud', 'We', 'turn', 'relevant', 'tasks', 'carried', 'cloud', 'network', 'application', 'layers', '.']

>> Bigrams are: 
 [('At', 'Cloud'), ('Cloud', 'We'), ('We', 'turn'), ('turn', 'relevant'), ('relevant', 'tasks'), ('tasks', 'carried'), ('carried', 'cloud'), ('cloud', 'network'), ('network', 'application'), ('application', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('At', 'Cloud', 'We'), ('Cloud', 'We', 'turn'), ('We', 'turn', 'relevant'), ('turn', 'relevant', 'tasks'), ('relevant', 'tasks', 'carried'), ('tasks', 'carried', 'cloud'), ('carried', 'cloud', 'network'), ('cloud', 'network', 'application'), ('network', 'application', 'layers'), ('application', 'layers', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('Cloud', 'NNP'), ('We', 'PRP'), ('turn', 'VBP'), ('relevant', 'JJ'), ('tasks', 'NNS'), ('carried', 'VBD'), ('cloud', 'JJ'), ('network', 'NN'), ('application', 'NN'), ('layers', 'NNS'), ('.', '.')]

 (S
  At/IN
  (NP Cloud/NNP)
  We/PRP
  turn/VBP
  (NP relevant/JJ tasks/NNS)
  carried/VBD
  (NP cloud/JJ network/NN application/NN layers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Cloud', 'relevant tasks', 'cloud network application layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('Cloud', 'cloud'), ('We', 'we'), ('turn', 'turn'), ('relevant', 'relev'), ('tasks', 'task'), ('carried', 'carri'), ('cloud', 'cloud'), ('network', 'network'), ('application', 'applic'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('Cloud', 'cloud'), ('We', 'we'), ('turn', 'turn'), ('relevant', 'relev'), ('tasks', 'task'), ('carried', 'carri'), ('cloud', 'cloud'), ('network', 'network'), ('application', 'applic'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('Cloud', 'Cloud'), ('We', 'We'), ('turn', 'turn'), ('relevant', 'relevant'), ('tasks', 'task'), ('carried', 'carried'), ('cloud', 'cloud'), ('network', 'network'), ('application', 'application'), ('layers', 'layer'), ('.', '.')]



============================ Sentence 370 =============================

(1) Network: The main task of the network layer is routing (see [53] for further discussion). 


>> Tokens are: 
 ['(', '1', ')', 'Network', ':', 'The', 'main', 'task', 'network', 'layer', 'routing', '(', 'see', '[', '53', ']', 'discussion', ')', '.']

>> Bigrams are: 
 [('(', '1'), ('1', ')'), (')', 'Network'), ('Network', ':'), (':', 'The'), ('The', 'main'), ('main', 'task'), ('task', 'network'), ('network', 'layer'), ('layer', 'routing'), ('routing', '('), ('(', 'see'), ('see', '['), ('[', '53'), ('53', ']'), (']', 'discussion'), ('discussion', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1', ')'), ('1', ')', 'Network'), (')', 'Network', ':'), ('Network', ':', 'The'), (':', 'The', 'main'), ('The', 'main', 'task'), ('main', 'task', 'network'), ('task', 'network', 'layer'), ('network', 'layer', 'routing'), ('layer', 'routing', '('), ('routing', '(', 'see'), ('(', 'see', '['), ('see', '[', '53'), ('[', '53', ']'), ('53', ']', 'discussion'), (']', 'discussion', ')'), ('discussion', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1', 'CD'), (')', ')'), ('Network', 'NN'), (':', ':'), ('The', 'DT'), ('main', 'JJ'), ('task', 'NN'), ('network', 'NN'), ('layer', 'NN'), ('routing', 'NN'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('53', 'CD'), (']', 'JJ'), ('discussion', 'NN'), (')', ')'), ('.', '.')]

 (S
  (/(
  1/CD
  )/)
  (NP Network/NN)
  :/:
  (NP The/DT main/JJ task/NN network/NN layer/NN routing/NN)
  (/(
  see/VB
  [/RB
  53/CD
  (NP ]/JJ discussion/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Network', 'The main task network layer routing', '] discussion']

>> Named Entities are: 
 [('PERSON', 'Network')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Network', 'network'), (':', ':'), ('The', 'the'), ('main', 'main'), ('task', 'task'), ('network', 'network'), ('layer', 'layer'), ('routing', 'rout'), ('(', '('), ('see', 'see'), ('[', '['), ('53', '53'), (']', ']'), ('discussion', 'discuss'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('Network', 'network'), (':', ':'), ('The', 'the'), ('main', 'main'), ('task', 'task'), ('network', 'network'), ('layer', 'layer'), ('routing', 'rout'), ('(', '('), ('see', 'see'), ('[', '['), ('53', '53'), (']', ']'), ('discussion', 'discuss'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1', '1'), (')', ')'), ('Network', 'Network'), (':', ':'), ('The', 'The'), ('main', 'main'), ('task', 'task'), ('network', 'network'), ('layer', 'layer'), ('routing', 'routing'), ('(', '('), ('see', 'see'), ('[', '['), ('53', '53'), (']', ']'), ('discussion', 'discussion'), (')', ')'), ('.', '.')]



============================ Sentence 371 =============================

Considering a software-defined networking implementation, routing re- quires the availability at a network controller of informa- tion regarding the quality of individual communication  2This can be thought of as an example of experience learning as part of small-sample learning techniques [46]. 


>> Tokens are: 
 ['Considering', 'software-defined', 'networking', 'implementation', ',', 'routing', 're-', 'quires', 'availability', 'network', 'controller', 'informa-', 'tion', 'regarding', 'quality', 'individual', 'communication', '2This', 'thought', 'example', 'experience', 'learning', 'part', 'small-sample', 'learning', 'techniques', '[', '46', ']', '.']

>> Bigrams are: 
 [('Considering', 'software-defined'), ('software-defined', 'networking'), ('networking', 'implementation'), ('implementation', ','), (',', 'routing'), ('routing', 're-'), ('re-', 'quires'), ('quires', 'availability'), ('availability', 'network'), ('network', 'controller'), ('controller', 'informa-'), ('informa-', 'tion'), ('tion', 'regarding'), ('regarding', 'quality'), ('quality', 'individual'), ('individual', 'communication'), ('communication', '2This'), ('2This', 'thought'), ('thought', 'example'), ('example', 'experience'), ('experience', 'learning'), ('learning', 'part'), ('part', 'small-sample'), ('small-sample', 'learning'), ('learning', 'techniques'), ('techniques', '['), ('[', '46'), ('46', ']'), (']', '.')]

>> Trigrams are: 
 [('Considering', 'software-defined', 'networking'), ('software-defined', 'networking', 'implementation'), ('networking', 'implementation', ','), ('implementation', ',', 'routing'), (',', 'routing', 're-'), ('routing', 're-', 'quires'), ('re-', 'quires', 'availability'), ('quires', 'availability', 'network'), ('availability', 'network', 'controller'), ('network', 'controller', 'informa-'), ('controller', 'informa-', 'tion'), ('informa-', 'tion', 'regarding'), ('tion', 'regarding', 'quality'), ('regarding', 'quality', 'individual'), ('quality', 'individual', 'communication'), ('individual', 'communication', '2This'), ('communication', '2This', 'thought'), ('2This', 'thought', 'example'), ('thought', 'example', 'experience'), ('example', 'experience', 'learning'), ('experience', 'learning', 'part'), ('learning', 'part', 'small-sample'), ('part', 'small-sample', 'learning'), ('small-sample', 'learning', 'techniques'), ('learning', 'techniques', '['), ('techniques', '[', '46'), ('[', '46', ']'), ('46', ']', '.')]

>> POS Tags are: 
 [('Considering', 'VBG'), ('software-defined', 'JJ'), ('networking', 'JJ'), ('implementation', 'NN'), (',', ','), ('routing', 'VBG'), ('re-', 'JJ'), ('quires', 'NNS'), ('availability', 'NN'), ('network', 'NN'), ('controller', 'NN'), ('informa-', 'JJ'), ('tion', 'NN'), ('regarding', 'VBG'), ('quality', 'NN'), ('individual', 'JJ'), ('communication', 'NN'), ('2This', 'CD'), ('thought', 'JJ'), ('example', 'NN'), ('experience', 'NN'), ('learning', 'VBG'), ('part', 'NN'), ('small-sample', 'JJ'), ('learning', 'NN'), ('techniques', 'NNS'), ('[', 'VBP'), ('46', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  Considering/VBG
  (NP software-defined/JJ networking/JJ implementation/NN)
  ,/,
  routing/VBG
  (NP re-/JJ quires/NNS availability/NN network/NN controller/NN)
  (NP informa-/JJ tion/NN)
  regarding/VBG
  (NP quality/NN)
  (NP individual/JJ communication/NN)
  2This/CD
  (NP thought/JJ example/NN experience/NN)
  learning/VBG
  (NP part/NN)
  (NP small-sample/JJ learning/NN techniques/NNS)
  [/VBP
  46/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['software-defined networking implementation', 're- quires availability network controller', 'informa- tion', 'quality', 'individual communication', 'thought example experience', 'part', 'small-sample learning techniques', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Considering', 'consid'), ('software-defined', 'software-defin'), ('networking', 'network'), ('implementation', 'implement'), (',', ','), ('routing', 'rout'), ('re-', 're-'), ('quires', 'quir'), ('availability', 'avail'), ('network', 'network'), ('controller', 'control'), ('informa-', 'informa-'), ('tion', 'tion'), ('regarding', 'regard'), ('quality', 'qualiti'), ('individual', 'individu'), ('communication', 'commun'), ('2This', '2thi'), ('thought', 'thought'), ('example', 'exampl'), ('experience', 'experi'), ('learning', 'learn'), ('part', 'part'), ('small-sample', 'small-sampl'), ('learning', 'learn'), ('techniques', 'techniqu'), ('[', '['), ('46', '46'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Considering', 'consid'), ('software-defined', 'software-defin'), ('networking', 'network'), ('implementation', 'implement'), (',', ','), ('routing', 'rout'), ('re-', 're-'), ('quires', 'quir'), ('availability', 'avail'), ('network', 'network'), ('controller', 'control'), ('informa-', 'informa-'), ('tion', 'tion'), ('regarding', 'regard'), ('quality', 'qualiti'), ('individual', 'individu'), ('communication', 'communic'), ('2This', '2this'), ('thought', 'thought'), ('example', 'exampl'), ('experience', 'experi'), ('learning', 'learn'), ('part', 'part'), ('small-sample', 'small-sampl'), ('learning', 'learn'), ('techniques', 'techniqu'), ('[', '['), ('46', '46'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Considering', 'Considering'), ('software-defined', 'software-defined'), ('networking', 'networking'), ('implementation', 'implementation'), (',', ','), ('routing', 'routing'), ('re-', 're-'), ('quires', 'quire'), ('availability', 'availability'), ('network', 'network'), ('controller', 'controller'), ('informa-', 'informa-'), ('tion', 'tion'), ('regarding', 'regarding'), ('quality', 'quality'), ('individual', 'individual'), ('communication', 'communication'), ('2This', '2This'), ('thought', 'thought'), ('example', 'example'), ('experience', 'experience'), ('learning', 'learning'), ('part', 'part'), ('small-sample', 'small-sample'), ('learning', 'learning'), ('techniques', 'technique'), ('[', '['), ('46', '46'), (']', ']'), ('.', '.')]



============================ Sentence 372 =============================

links in the core network, as well as regarding the status of the queues at the network routers. 


>> Tokens are: 
 ['links', 'core', 'network', ',', 'well', 'regarding', 'status', 'queues', 'network', 'routers', '.']

>> Bigrams are: 
 [('links', 'core'), ('core', 'network'), ('network', ','), (',', 'well'), ('well', 'regarding'), ('regarding', 'status'), ('status', 'queues'), ('queues', 'network'), ('network', 'routers'), ('routers', '.')]

>> Trigrams are: 
 [('links', 'core', 'network'), ('core', 'network', ','), ('network', ',', 'well'), (',', 'well', 'regarding'), ('well', 'regarding', 'status'), ('regarding', 'status', 'queues'), ('status', 'queues', 'network'), ('queues', 'network', 'routers'), ('network', 'routers', '.')]

>> POS Tags are: 
 [('links', 'NNS'), ('core', 'NN'), ('network', 'NN'), (',', ','), ('well', 'RB'), ('regarding', 'VBG'), ('status', 'NN'), ('queues', 'NNS'), ('network', 'NN'), ('routers', 'NNS'), ('.', '.')]

 (S
  (NP links/NNS core/NN network/NN)
  ,/,
  well/RB
  regarding/VBG
  (NP status/NN queues/NNS network/NN routers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['links core network', 'status queues network routers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('links', 'link'), ('core', 'core'), ('network', 'network'), (',', ','), ('well', 'well'), ('regarding', 'regard'), ('status', 'statu'), ('queues', 'queue'), ('network', 'network'), ('routers', 'router'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('links', 'link'), ('core', 'core'), ('network', 'network'), (',', ','), ('well', 'well'), ('regarding', 'regard'), ('status', 'status'), ('queues', 'queue'), ('network', 'network'), ('routers', 'router'), ('.', '.')]

>> Lemmatization: 
 [('links', 'link'), ('core', 'core'), ('network', 'network'), (',', ','), ('well', 'well'), ('regarding', 'regarding'), ('status', 'status'), ('queues', 'queue'), ('network', 'network'), ('routers', 'router'), ('.', '.')]



============================ Sentence 373 =============================

In the presence of wireless or optical communications, the quality of a link may not be available at the network controller, but it may be predicted using available historical data [33], [54] in the absence of agreed-upon dynamic availability models. 


>> Tokens are: 
 ['In', 'presence', 'wireless', 'optical', 'communications', ',', 'quality', 'link', 'may', 'available', 'network', 'controller', ',', 'may', 'predicted', 'using', 'available', 'historical', 'data', '[', '33', ']', ',', '[', '54', ']', 'absence', 'agreed-upon', 'dynamic', 'availability', 'models', '.']

>> Bigrams are: 
 [('In', 'presence'), ('presence', 'wireless'), ('wireless', 'optical'), ('optical', 'communications'), ('communications', ','), (',', 'quality'), ('quality', 'link'), ('link', 'may'), ('may', 'available'), ('available', 'network'), ('network', 'controller'), ('controller', ','), (',', 'may'), ('may', 'predicted'), ('predicted', 'using'), ('using', 'available'), ('available', 'historical'), ('historical', 'data'), ('data', '['), ('[', '33'), ('33', ']'), (']', ','), (',', '['), ('[', '54'), ('54', ']'), (']', 'absence'), ('absence', 'agreed-upon'), ('agreed-upon', 'dynamic'), ('dynamic', 'availability'), ('availability', 'models'), ('models', '.')]

>> Trigrams are: 
 [('In', 'presence', 'wireless'), ('presence', 'wireless', 'optical'), ('wireless', 'optical', 'communications'), ('optical', 'communications', ','), ('communications', ',', 'quality'), (',', 'quality', 'link'), ('quality', 'link', 'may'), ('link', 'may', 'available'), ('may', 'available', 'network'), ('available', 'network', 'controller'), ('network', 'controller', ','), ('controller', ',', 'may'), (',', 'may', 'predicted'), ('may', 'predicted', 'using'), ('predicted', 'using', 'available'), ('using', 'available', 'historical'), ('available', 'historical', 'data'), ('historical', 'data', '['), ('data', '[', '33'), ('[', '33', ']'), ('33', ']', ','), (']', ',', '['), (',', '[', '54'), ('[', '54', ']'), ('54', ']', 'absence'), (']', 'absence', 'agreed-upon'), ('absence', 'agreed-upon', 'dynamic'), ('agreed-upon', 'dynamic', 'availability'), ('dynamic', 'availability', 'models'), ('availability', 'models', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('presence', 'NN'), ('wireless', 'NN'), ('optical', 'JJ'), ('communications', 'NNS'), (',', ','), ('quality', 'NN'), ('link', 'NN'), ('may', 'MD'), ('available', 'JJ'), ('network', 'NN'), ('controller', 'NN'), (',', ','), ('may', 'MD'), ('predicted', 'VB'), ('using', 'VBG'), ('available', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('[', '$'), ('33', 'CD'), (']', 'NNP'), (',', ','), ('[', 'VBD'), ('54', 'CD'), (']', 'JJ'), ('absence', 'NN'), ('agreed-upon', 'JJ'), ('dynamic', 'JJ'), ('availability', 'NN'), ('models', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP presence/NN wireless/NN)
  (NP optical/JJ communications/NNS)
  ,/,
  (NP quality/NN link/NN)
  may/MD
  (NP available/JJ network/NN controller/NN)
  ,/,
  may/MD
  predicted/VB
  using/VBG
  (NP available/JJ historical/JJ data/NNS)
  [/$
  33/CD
  (NP ]/NNP)
  ,/,
  [/VBD
  54/CD
  (NP ]/JJ absence/NN)
  (NP agreed-upon/JJ dynamic/JJ availability/NN models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['presence wireless', 'optical communications', 'quality link', 'available network controller', 'available historical data', ']', '] absence', 'agreed-upon dynamic availability models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('presence', 'presenc'), ('wireless', 'wireless'), ('optical', 'optic'), ('communications', 'commun'), (',', ','), ('quality', 'qualiti'), ('link', 'link'), ('may', 'may'), ('available', 'avail'), ('network', 'network'), ('controller', 'control'), (',', ','), ('may', 'may'), ('predicted', 'predict'), ('using', 'use'), ('available', 'avail'), ('historical', 'histor'), ('data', 'data'), ('[', '['), ('33', '33'), (']', ']'), (',', ','), ('[', '['), ('54', '54'), (']', ']'), ('absence', 'absenc'), ('agreed-upon', 'agreed-upon'), ('dynamic', 'dynam'), ('availability', 'avail'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('presence', 'presenc'), ('wireless', 'wireless'), ('optical', 'optic'), ('communications', 'communic'), (',', ','), ('quality', 'qualiti'), ('link', 'link'), ('may', 'may'), ('available', 'avail'), ('network', 'network'), ('controller', 'control'), (',', ','), ('may', 'may'), ('predicted', 'predict'), ('using', 'use'), ('available', 'avail'), ('historical', 'histor'), ('data', 'data'), ('[', '['), ('33', '33'), (']', ']'), (',', ','), ('[', '['), ('54', '54'), (']', ']'), ('absence', 'absenc'), ('agreed-upon', 'agreed-upon'), ('dynamic', 'dynam'), ('availability', 'avail'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('presence', 'presence'), ('wireless', 'wireless'), ('optical', 'optical'), ('communications', 'communication'), (',', ','), ('quality', 'quality'), ('link', 'link'), ('may', 'may'), ('available', 'available'), ('network', 'network'), ('controller', 'controller'), (',', ','), ('may', 'may'), ('predicted', 'predicted'), ('using', 'using'), ('available', 'available'), ('historical', 'historical'), ('data', 'data'), ('[', '['), ('33', '33'), (']', ']'), (',', ','), ('[', '['), ('54', '54'), (']', ']'), ('absence', 'absence'), ('agreed-upon', 'agreed-upon'), ('dynamic', 'dynamic'), ('availability', 'availability'), ('models', 'model'), ('.', '.')]



============================ Sentence 374 =============================

In a similar manner, predicting congestion can be framed as a data-aided classification problem [55]. 


>> Tokens are: 
 ['In', 'similar', 'manner', ',', 'predicting', 'congestion', 'framed', 'data-aided', 'classification', 'problem', '[', '55', ']', '.']

>> Bigrams are: 
 [('In', 'similar'), ('similar', 'manner'), ('manner', ','), (',', 'predicting'), ('predicting', 'congestion'), ('congestion', 'framed'), ('framed', 'data-aided'), ('data-aided', 'classification'), ('classification', 'problem'), ('problem', '['), ('[', '55'), ('55', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'similar', 'manner'), ('similar', 'manner', ','), ('manner', ',', 'predicting'), (',', 'predicting', 'congestion'), ('predicting', 'congestion', 'framed'), ('congestion', 'framed', 'data-aided'), ('framed', 'data-aided', 'classification'), ('data-aided', 'classification', 'problem'), ('classification', 'problem', '['), ('problem', '[', '55'), ('[', '55', ']'), ('55', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('similar', 'JJ'), ('manner', 'NN'), (',', ','), ('predicting', 'VBG'), ('congestion', 'NN'), ('framed', 'VBD'), ('data-aided', 'JJ'), ('classification', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('55', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP similar/JJ manner/NN)
  ,/,
  predicting/VBG
  (NP congestion/NN)
  framed/VBD
  (NP data-aided/JJ classification/NN problem/NN)
  [/VBZ
  55/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['similar manner', 'congestion', 'data-aided classification problem', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('similar', 'similar'), ('manner', 'manner'), (',', ','), ('predicting', 'predict'), ('congestion', 'congest'), ('framed', 'frame'), ('data-aided', 'data-aid'), ('classification', 'classif'), ('problem', 'problem'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('similar', 'similar'), ('manner', 'manner'), (',', ','), ('predicting', 'predict'), ('congestion', 'congest'), ('framed', 'frame'), ('data-aided', 'data-aid'), ('classification', 'classif'), ('problem', 'problem'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('similar', 'similar'), ('manner', 'manner'), (',', ','), ('predicting', 'predicting'), ('congestion', 'congestion'), ('framed', 'framed'), ('data-aided', 'data-aided'), ('classification', 'classification'), ('problem', 'problem'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]



============================ Sentence 375 =============================

(2) Application: Finally, a relevant supervised learning task is that of traffic classification, whereby data streams are classified on the basis of some extracted features, such as packet sizes and inter-arrival times, in terms of their applications, e.g.-.-, Voice over IP. 


>> Tokens are: 
 ['(', '2', ')', 'Application', ':', 'Finally', ',', 'relevant', 'supervised', 'learning', 'task', 'traffic', 'classification', ',', 'whereby', 'data', 'streams', 'classified', 'basis', 'extracted', 'features', ',', 'packet', 'sizes', 'inter-arrival', 'times', ',', 'terms', 'applications', ',', 'e.g.-.-', ',', 'Voice', 'IP', '.']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'Application'), ('Application', ':'), (':', 'Finally'), ('Finally', ','), (',', 'relevant'), ('relevant', 'supervised'), ('supervised', 'learning'), ('learning', 'task'), ('task', 'traffic'), ('traffic', 'classification'), ('classification', ','), (',', 'whereby'), ('whereby', 'data'), ('data', 'streams'), ('streams', 'classified'), ('classified', 'basis'), ('basis', 'extracted'), ('extracted', 'features'), ('features', ','), (',', 'packet'), ('packet', 'sizes'), ('sizes', 'inter-arrival'), ('inter-arrival', 'times'), ('times', ','), (',', 'terms'), ('terms', 'applications'), ('applications', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'Voice'), ('Voice', 'IP'), ('IP', '.')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'Application'), (')', 'Application', ':'), ('Application', ':', 'Finally'), (':', 'Finally', ','), ('Finally', ',', 'relevant'), (',', 'relevant', 'supervised'), ('relevant', 'supervised', 'learning'), ('supervised', 'learning', 'task'), ('learning', 'task', 'traffic'), ('task', 'traffic', 'classification'), ('traffic', 'classification', ','), ('classification', ',', 'whereby'), (',', 'whereby', 'data'), ('whereby', 'data', 'streams'), ('data', 'streams', 'classified'), ('streams', 'classified', 'basis'), ('classified', 'basis', 'extracted'), ('basis', 'extracted', 'features'), ('extracted', 'features', ','), ('features', ',', 'packet'), (',', 'packet', 'sizes'), ('packet', 'sizes', 'inter-arrival'), ('sizes', 'inter-arrival', 'times'), ('inter-arrival', 'times', ','), ('times', ',', 'terms'), (',', 'terms', 'applications'), ('terms', 'applications', ','), ('applications', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'Voice'), (',', 'Voice', 'IP'), ('Voice', 'IP', '.')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('Application', 'NN'), (':', ':'), ('Finally', 'RB'), (',', ','), ('relevant', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('task', 'NN'), ('traffic', 'NN'), ('classification', 'NN'), (',', ','), ('whereby', 'WRB'), ('data', 'NNS'), ('streams', 'NNS'), ('classified', 'VBD'), ('basis', 'NN'), ('extracted', 'VBD'), ('features', 'NNS'), (',', ','), ('packet', 'NN'), ('sizes', 'VBD'), ('inter-arrival', 'JJ'), ('times', 'NNS'), (',', ','), ('terms', 'NNS'), ('applications', 'NNS'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('Voice', 'NNP'), ('IP', 'NNP'), ('.', '.')]

 (S
  (/(
  2/CD
  )/)
  (NP Application/NN)
  :/:
  Finally/RB
  ,/,
  (NP relevant/NN)
  supervised/VBD
  learning/VBG
  (NP task/NN traffic/NN classification/NN)
  ,/,
  whereby/WRB
  (NP data/NNS streams/NNS)
  classified/VBD
  (NP basis/NN)
  extracted/VBD
  (NP features/NNS)
  ,/,
  (NP packet/NN)
  sizes/VBD
  (NP inter-arrival/JJ times/NNS)
  ,/,
  (NP terms/NNS applications/NNS)
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP Voice/NNP IP/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Application', 'relevant', 'task traffic classification', 'data streams', 'basis', 'features', 'packet', 'inter-arrival times', 'terms applications', 'Voice IP']

>> Named Entities are: 
 [('PERSON', 'Voice IP')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'applic'), (':', ':'), ('Finally', 'final'), (',', ','), ('relevant', 'relev'), ('supervised', 'supervis'), ('learning', 'learn'), ('task', 'task'), ('traffic', 'traffic'), ('classification', 'classif'), (',', ','), ('whereby', 'wherebi'), ('data', 'data'), ('streams', 'stream'), ('classified', 'classifi'), ('basis', 'basi'), ('extracted', 'extract'), ('features', 'featur'), (',', ','), ('packet', 'packet'), ('sizes', 'size'), ('inter-arrival', 'inter-arriv'), ('times', 'time'), (',', ','), ('terms', 'term'), ('applications', 'applic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Voice', 'voic'), ('IP', 'ip'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'applic'), (':', ':'), ('Finally', 'final'), (',', ','), ('relevant', 'relev'), ('supervised', 'supervis'), ('learning', 'learn'), ('task', 'task'), ('traffic', 'traffic'), ('classification', 'classif'), (',', ','), ('whereby', 'wherebi'), ('data', 'data'), ('streams', 'stream'), ('classified', 'classifi'), ('basis', 'basi'), ('extracted', 'extract'), ('features', 'featur'), (',', ','), ('packet', 'packet'), ('sizes', 'size'), ('inter-arrival', 'inter-arriv'), ('times', 'time'), (',', ','), ('terms', 'term'), ('applications', 'applic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Voice', 'voic'), ('IP', 'ip'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'Application'), (':', ':'), ('Finally', 'Finally'), (',', ','), ('relevant', 'relevant'), ('supervised', 'supervised'), ('learning', 'learning'), ('task', 'task'), ('traffic', 'traffic'), ('classification', 'classification'), (',', ','), ('whereby', 'whereby'), ('data', 'data'), ('streams', 'stream'), ('classified', 'classified'), ('basis', 'basis'), ('extracted', 'extracted'), ('features', 'feature'), (',', ','), ('packet', 'packet'), ('sizes', 'size'), ('inter-arrival', 'inter-arrival'), ('times', 'time'), (',', ','), ('terms', 'term'), ('applications', 'application'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Voice', 'Voice'), ('IP', 'IP'), ('.', '.')]



============================ Sentence 376 =============================

[56]  V. UNSUPERVISED LEARNING  As introduced in Sec. 


>> Tokens are: 
 ['[', '56', ']', 'V.', 'UNSUPERVISED', 'LEARNING', 'As', 'introduced', 'Sec', '.']

>> Bigrams are: 
 [('[', '56'), ('56', ']'), (']', 'V.'), ('V.', 'UNSUPERVISED'), ('UNSUPERVISED', 'LEARNING'), ('LEARNING', 'As'), ('As', 'introduced'), ('introduced', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('[', '56', ']'), ('56', ']', 'V.'), (']', 'V.', 'UNSUPERVISED'), ('V.', 'UNSUPERVISED', 'LEARNING'), ('UNSUPERVISED', 'LEARNING', 'As'), ('LEARNING', 'As', 'introduced'), ('As', 'introduced', 'Sec'), ('introduced', 'Sec', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('56', 'CD'), (']', 'JJ'), ('V.', 'NNP'), ('UNSUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('As', 'IN'), ('introduced', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  [/RB
  56/CD
  (NP ]/JJ V./NNP UNSUPERVISED/NNP LEARNING/NNP)
  As/IN
  introduced/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] V. UNSUPERVISED LEARNING', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('V.', 'v.'), ('UNSUPERVISED', 'unsupervis'), ('LEARNING', 'learn'), ('As', 'as'), ('introduced', 'introduc'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('V.', 'v.'), ('UNSUPERVISED', 'unsupervis'), ('LEARNING', 'learn'), ('As', 'as'), ('introduced', 'introduc'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('56', '56'), (']', ']'), ('V.', 'V.'), ('UNSUPERVISED', 'UNSUPERVISED'), ('LEARNING', 'LEARNING'), ('As', 'As'), ('introduced', 'introduced'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 377 =============================

I, unlike supervised learning, unsupervised learning tasks operate over unlabelled data sets consisting solely of the inputs xn, with n = 1, ..., N , and the general goal is that of discovering properties of the data. 


>> Tokens are: 
 ['I', ',', 'unlike', 'supervised', 'learning', ',', 'unsupervised', 'learning', 'tasks', 'operate', 'unlabelled', 'data', 'sets', 'consisting', 'solely', 'inputs', 'xn', ',', 'n', '=', '1', ',', '...', ',', 'N', ',', 'general', 'goal', 'discovering', 'properties', 'data', '.']

>> Bigrams are: 
 [('I', ','), (',', 'unlike'), ('unlike', 'supervised'), ('supervised', 'learning'), ('learning', ','), (',', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'tasks'), ('tasks', 'operate'), ('operate', 'unlabelled'), ('unlabelled', 'data'), ('data', 'sets'), ('sets', 'consisting'), ('consisting', 'solely'), ('solely', 'inputs'), ('inputs', 'xn'), ('xn', ','), (',', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', ','), (',', 'general'), ('general', 'goal'), ('goal', 'discovering'), ('discovering', 'properties'), ('properties', 'data'), ('data', '.')]

>> Trigrams are: 
 [('I', ',', 'unlike'), (',', 'unlike', 'supervised'), ('unlike', 'supervised', 'learning'), ('supervised', 'learning', ','), ('learning', ',', 'unsupervised'), (',', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'tasks'), ('learning', 'tasks', 'operate'), ('tasks', 'operate', 'unlabelled'), ('operate', 'unlabelled', 'data'), ('unlabelled', 'data', 'sets'), ('data', 'sets', 'consisting'), ('sets', 'consisting', 'solely'), ('consisting', 'solely', 'inputs'), ('solely', 'inputs', 'xn'), ('inputs', 'xn', ','), ('xn', ',', 'n'), (',', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', ','), ('N', ',', 'general'), (',', 'general', 'goal'), ('general', 'goal', 'discovering'), ('goal', 'discovering', 'properties'), ('discovering', 'properties', 'data'), ('properties', 'data', '.')]

>> POS Tags are: 
 [('I', 'PRP'), (',', ','), ('unlike', 'IN'), ('supervised', 'VBN'), ('learning', 'NN'), (',', ','), ('unsupervised', 'JJ'), ('learning', 'NN'), ('tasks', 'NNS'), ('operate', 'VBP'), ('unlabelled', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('consisting', 'VBG'), ('solely', 'RB'), ('inputs', 'JJ'), ('xn', 'NNP'), (',', ','), ('n', 'JJ'), ('=', 'NN'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), (',', ','), ('general', 'JJ'), ('goal', 'NN'), ('discovering', 'VBG'), ('properties', 'NNS'), ('data', 'NNS'), ('.', '.')]

 (S
  I/PRP
  ,/,
  unlike/IN
  supervised/VBN
  (NP learning/NN)
  ,/,
  (NP unsupervised/JJ learning/NN tasks/NNS)
  operate/VBP
  (NP unlabelled/JJ data/NNS sets/NNS)
  consisting/VBG
  solely/RB
  (NP inputs/JJ xn/NNP)
  ,/,
  (NP n/JJ =/NN)
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  ,/,
  (NP general/JJ goal/NN)
  discovering/VBG
  (NP properties/NNS data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['learning', 'unsupervised learning tasks', 'unlabelled data sets', 'inputs xn', 'n =', 'N', 'general goal', 'properties data']

>> Named Entities are: 
 [('GPE', 'N')] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), (',', ','), ('unlike', 'unlik'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('tasks', 'task'), ('operate', 'oper'), ('unlabelled', 'unlabel'), ('data', 'data'), ('sets', 'set'), ('consisting', 'consist'), ('solely', 'sole'), ('inputs', 'input'), ('xn', 'xn'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('general', 'gener'), ('goal', 'goal'), ('discovering', 'discov'), ('properties', 'properti'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), (',', ','), ('unlike', 'unlik'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('tasks', 'task'), ('operate', 'oper'), ('unlabelled', 'unlabel'), ('data', 'data'), ('sets', 'set'), ('consisting', 'consist'), ('solely', 'sole'), ('inputs', 'input'), ('xn', 'xn'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), (',', ','), ('general', 'general'), ('goal', 'goal'), ('discovering', 'discov'), ('properties', 'properti'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('I', 'I'), (',', ','), ('unlike', 'unlike'), ('supervised', 'supervised'), ('learning', 'learning'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('tasks', 'task'), ('operate', 'operate'), ('unlabelled', 'unlabelled'), ('data', 'data'), ('sets', 'set'), ('consisting', 'consisting'), ('solely', 'solely'), ('inputs', 'input'), ('xn', 'xn'), (',', ','), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), (',', ','), ('general', 'general'), ('goal', 'goal'), ('discovering', 'discovering'), ('properties', 'property'), ('data', 'data'), ('.', '.')]



============================ Sentence 378 =============================

We start this section by reviewing some of the typical specific unsupervised learning tasks. 


>> Tokens are: 
 ['We', 'start', 'section', 'reviewing', 'typical', 'specific', 'unsupervised', 'learning', 'tasks', '.']

>> Bigrams are: 
 [('We', 'start'), ('start', 'section'), ('section', 'reviewing'), ('reviewing', 'typical'), ('typical', 'specific'), ('specific', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('We', 'start', 'section'), ('start', 'section', 'reviewing'), ('section', 'reviewing', 'typical'), ('reviewing', 'typical', 'specific'), ('typical', 'specific', 'unsupervised'), ('specific', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'tasks'), ('learning', 'tasks', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('start', 'VBP'), ('section', 'NN'), ('reviewing', 'VBG'), ('typical', 'JJ'), ('specific', 'NN'), ('unsupervised', 'VBD'), ('learning', 'JJ'), ('tasks', 'NNS'), ('.', '.')]

 (S
  We/PRP
  start/VBP
  (NP section/NN)
  reviewing/VBG
  (NP typical/JJ specific/NN)
  unsupervised/VBD
  (NP learning/JJ tasks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['section', 'typical specific', 'learning tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('start', 'start'), ('section', 'section'), ('reviewing', 'review'), ('typical', 'typic'), ('specific', 'specif'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('start', 'start'), ('section', 'section'), ('reviewing', 'review'), ('typical', 'typic'), ('specific', 'specif'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('start', 'start'), ('section', 'section'), ('reviewing', 'reviewing'), ('typical', 'typical'), ('specific', 'specific'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('tasks', 'task'), ('.', '.')]



============================ Sentence 379 =============================

We then cover methodology, models, and learning, includ- ing advanced methods such as Generative Adversarial Networks (GANs) [7]. 


>> Tokens are: 
 ['We', 'cover', 'methodology', ',', 'models', ',', 'learning', ',', 'includ-', 'ing', 'advanced', 'methods', 'Generative', 'Adversarial', 'Networks', '(', 'GANs', ')', '[', '7', ']', '.']

>> Bigrams are: 
 [('We', 'cover'), ('cover', 'methodology'), ('methodology', ','), (',', 'models'), ('models', ','), (',', 'learning'), ('learning', ','), (',', 'includ-'), ('includ-', 'ing'), ('ing', 'advanced'), ('advanced', 'methods'), ('methods', 'Generative'), ('Generative', 'Adversarial'), ('Adversarial', 'Networks'), ('Networks', '('), ('(', 'GANs'), ('GANs', ')'), (')', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('We', 'cover', 'methodology'), ('cover', 'methodology', ','), ('methodology', ',', 'models'), (',', 'models', ','), ('models', ',', 'learning'), (',', 'learning', ','), ('learning', ',', 'includ-'), (',', 'includ-', 'ing'), ('includ-', 'ing', 'advanced'), ('ing', 'advanced', 'methods'), ('advanced', 'methods', 'Generative'), ('methods', 'Generative', 'Adversarial'), ('Generative', 'Adversarial', 'Networks'), ('Adversarial', 'Networks', '('), ('Networks', '(', 'GANs'), ('(', 'GANs', ')'), ('GANs', ')', '['), (')', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('cover', 'VBP'), ('methodology', 'NN'), (',', ','), ('models', 'NNS'), (',', ','), ('learning', 'VBG'), (',', ','), ('includ-', 'JJ'), ('ing', 'NN'), ('advanced', 'VBD'), ('methods', 'NNS'), ('Generative', 'NNP'), ('Adversarial', 'NNP'), ('Networks', 'NNP'), ('(', '('), ('GANs', 'NNP'), (')', ')'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  We/PRP
  cover/VBP
  (NP methodology/NN)
  ,/,
  (NP models/NNS)
  ,/,
  learning/VBG
  ,/,
  (NP includ-/JJ ing/NN)
  advanced/VBD
  (NP methods/NNS Generative/NNP Adversarial/NNP Networks/NNP)
  (/(
  (NP GANs/NNP)
  )/)
  [/VBD
  7/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['methodology', 'models', 'includ- ing', 'methods Generative Adversarial Networks', 'GANs', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'GANs')] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('cover', 'cover'), ('methodology', 'methodolog'), (',', ','), ('models', 'model'), (',', ','), ('learning', 'learn'), (',', ','), ('includ-', 'includ-'), ('ing', 'ing'), ('advanced', 'advanc'), ('methods', 'method'), ('Generative', 'gener'), ('Adversarial', 'adversari'), ('Networks', 'network'), ('(', '('), ('GANs', 'gan'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('cover', 'cover'), ('methodology', 'methodolog'), (',', ','), ('models', 'model'), (',', ','), ('learning', 'learn'), (',', ','), ('includ-', 'includ-'), ('ing', 'ing'), ('advanced', 'advanc'), ('methods', 'method'), ('Generative', 'generat'), ('Adversarial', 'adversari'), ('Networks', 'network'), ('(', '('), ('GANs', 'gan'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('cover', 'cover'), ('methodology', 'methodology'), (',', ','), ('models', 'model'), (',', ','), ('learning', 'learning'), (',', ','), ('includ-', 'includ-'), ('ing', 'ing'), ('advanced', 'advanced'), ('methods', 'method'), ('Generative', 'Generative'), ('Adversarial', 'Adversarial'), ('Networks', 'Networks'), ('(', '('), ('GANs', 'GANs'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



============================ Sentence 380 =============================

A. 


>> Tokens are: 
 ['A', '.']

>> Bigrams are: 
 [('A', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('.', '.')]

 (S A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('.', '.')]



============================ Sentence 381 =============================

Goals and Definitions  In unsupervised learning, taking a frequentist formu- lation (see Sec III-A), we are given a training set D consisting of N i.i.d. 


>> Tokens are: 
 ['Goals', 'Definitions', 'In', 'unsupervised', 'learning', ',', 'taking', 'frequentist', 'formu-', 'lation', '(', 'see', 'Sec', 'III-A', ')', ',', 'given', 'training', 'set', 'D', 'consisting', 'N', 'i.i.d', '.']

>> Bigrams are: 
 [('Goals', 'Definitions'), ('Definitions', 'In'), ('In', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'taking'), ('taking', 'frequentist'), ('frequentist', 'formu-'), ('formu-', 'lation'), ('lation', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'III-A'), ('III-A', ')'), (')', ','), (',', 'given'), ('given', 'training'), ('training', 'set'), ('set', 'D'), ('D', 'consisting'), ('consisting', 'N'), ('N', 'i.i.d'), ('i.i.d', '.')]

>> Trigrams are: 
 [('Goals', 'Definitions', 'In'), ('Definitions', 'In', 'unsupervised'), ('In', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'taking'), (',', 'taking', 'frequentist'), ('taking', 'frequentist', 'formu-'), ('frequentist', 'formu-', 'lation'), ('formu-', 'lation', '('), ('lation', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'III-A'), ('Sec', 'III-A', ')'), ('III-A', ')', ','), (')', ',', 'given'), (',', 'given', 'training'), ('given', 'training', 'set'), ('training', 'set', 'D'), ('set', 'D', 'consisting'), ('D', 'consisting', 'N'), ('consisting', 'N', 'i.i.d'), ('N', 'i.i.d', '.')]

>> POS Tags are: 
 [('Goals', 'NNS'), ('Definitions', 'NNS'), ('In', 'IN'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('taking', 'VBG'), ('frequentist', 'JJ'), ('formu-', 'JJ'), ('lation', 'NN'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('III-A', 'NNP'), (')', ')'), (',', ','), ('given', 'VBN'), ('training', 'NN'), ('set', 'VBN'), ('D', 'NNP'), ('consisting', 'VBG'), ('N', 'NNP'), ('i.i.d', 'NN'), ('.', '.')]

 (S
  (NP Goals/NNS Definitions/NNS)
  In/IN
  (NP unsupervised/JJ learning/NN)
  ,/,
  taking/VBG
  (NP frequentist/JJ formu-/JJ lation/NN)
  (/(
  see/VB
  (NP Sec/NNP III-A/NNP)
  )/)
  ,/,
  given/VBN
  (NP training/NN)
  set/VBN
  (NP D/NNP)
  consisting/VBG
  (NP N/NNP i.i.d/NN)
  ./.) 


>> Noun Phrases are: 
 ['Goals Definitions', 'unsupervised learning', 'frequentist formu- lation', 'Sec III-A', 'training', 'D', 'N i.i.d']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('Goals', 'goal'), ('Definitions', 'definit'), ('In', 'in'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('taking', 'take'), ('frequentist', 'frequentist'), ('formu-', 'formu-'), ('lation', 'lation'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-A', 'iii-a'), (')', ')'), (',', ','), ('given', 'given'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('consisting', 'consist'), ('N', 'n'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Goals', 'goal'), ('Definitions', 'definit'), ('In', 'in'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('taking', 'take'), ('frequentist', 'frequentist'), ('formu-', 'formu-'), ('lation', 'lation'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-A', 'iii-a'), (')', ')'), (',', ','), ('given', 'given'), ('training', 'train'), ('set', 'set'), ('D', 'd'), ('consisting', 'consist'), ('N', 'n'), ('i.i.d', 'i.i.d'), ('.', '.')]

>> Lemmatization: 
 [('Goals', 'Goals'), ('Definitions', 'Definitions'), ('In', 'In'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('taking', 'taking'), ('frequentist', 'frequentist'), ('formu-', 'formu-'), ('lation', 'lation'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('III-A', 'III-A'), (')', ')'), (',', ','), ('given', 'given'), ('training', 'training'), ('set', 'set'), ('D', 'D'), ('consisting', 'consisting'), ('N', 'N'), ('i.i.d', 'i.i.d'), ('.', '.')]



============================ Sentence 382 =============================

samples xn ∼ p(x) with n = 1, ..., N generated from an unknown true distribution p(x). 


>> Tokens are: 
 ['samples', 'xn', '∼', 'p', '(', 'x', ')', 'n', '=', '1', ',', '...', ',', 'N', 'generated', 'unknown', 'true', 'distribution', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('samples', 'xn'), ('xn', '∼'), ('∼', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'n'), ('n', '='), ('=', '1'), ('1', ','), (',', '...'), ('...', ','), (',', 'N'), ('N', 'generated'), ('generated', 'unknown'), ('unknown', 'true'), ('true', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('samples', 'xn', '∼'), ('xn', '∼', 'p'), ('∼', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'n'), (')', 'n', '='), ('n', '=', '1'), ('=', '1', ','), ('1', ',', '...'), (',', '...', ','), ('...', ',', 'N'), (',', 'N', 'generated'), ('N', 'generated', 'unknown'), ('generated', 'unknown', 'true'), ('unknown', 'true', 'distribution'), ('true', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('samples', 'NNS'), ('xn', 'VBP'), ('∼', 'JJ'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('n', 'VBP'), ('=', '$'), ('1', 'CD'), (',', ','), ('...', ':'), (',', ','), ('N', 'NNP'), ('generated', 'VBD'), ('unknown', 'JJ'), ('true', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP samples/NNS)
  xn/VBP
  (NP ∼/JJ p/NN)
  (/(
  (NP x/NNP)
  )/)
  n/VBP
  =/$
  1/CD
  ,/,
  .../:
  ,/,
  (NP N/NNP)
  generated/VBD
  (NP unknown/JJ true/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['samples', '∼ p', 'x', 'N', 'unknown true distribution p', 'x']

>> Named Entities are: 
 [('PERSON', 'N')] 

>> Stemming using Porter Stemmer: 
 [('samples', 'sampl'), ('xn', 'xn'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), ('generated', 'gener'), ('unknown', 'unknown'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('samples', 'sampl'), ('xn', 'xn'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'n'), ('generated', 'generat'), ('unknown', 'unknown'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('samples', 'sample'), ('xn', 'xn'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('n', 'n'), ('=', '='), ('1', '1'), (',', ','), ('...', '...'), (',', ','), ('N', 'N'), ('generated', 'generated'), ('unknown', 'unknown'), ('true', 'true'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 383 =============================

The high-level goal is that of learning some useful properties of the distribution p(x). 


>> Tokens are: 
 ['The', 'high-level', 'goal', 'learning', 'useful', 'properties', 'distribution', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('The', 'high-level'), ('high-level', 'goal'), ('goal', 'learning'), ('learning', 'useful'), ('useful', 'properties'), ('properties', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'high-level', 'goal'), ('high-level', 'goal', 'learning'), ('goal', 'learning', 'useful'), ('learning', 'useful', 'properties'), ('useful', 'properties', 'distribution'), ('properties', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('high-level', 'JJ'), ('goal', 'NN'), ('learning', 'VBG'), ('useful', 'JJ'), ('properties', 'NNS'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT high-level/JJ goal/NN)
  learning/VBG
  (NP useful/JJ properties/NNS distribution/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The high-level goal', 'useful properties distribution p', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('high-level', 'high-level'), ('goal', 'goal'), ('learning', 'learn'), ('useful', 'use'), ('properties', 'properti'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('high-level', 'high-level'), ('goal', 'goal'), ('learning', 'learn'), ('useful', 'use'), ('properties', 'properti'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('high-level', 'high-level'), ('goal', 'goal'), ('learning', 'learning'), ('useful', 'useful'), ('properties', 'property'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 384 =============================

More specifically, we can identify the following tasks. 


>> Tokens are: 
 ['More', 'specifically', ',', 'identify', 'following', 'tasks', '.']

>> Bigrams are: 
 [('More', 'specifically'), ('specifically', ','), (',', 'identify'), ('identify', 'following'), ('following', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('More', 'specifically', ','), ('specifically', ',', 'identify'), (',', 'identify', 'following'), ('identify', 'following', 'tasks'), ('following', 'tasks', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('specifically', 'RB'), (',', ','), ('identify', 'VB'), ('following', 'VBG'), ('tasks', 'NNS'), ('.', '.')]

 (S
  More/RBR
  specifically/RB
  ,/,
  identify/VB
  following/VBG
  (NP tasks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('specifically', 'specif'), (',', ','), ('identify', 'identifi'), ('following', 'follow'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('specifically', 'specif'), (',', ','), ('identify', 'identifi'), ('following', 'follow'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('specifically', 'specifically'), (',', ','), ('identify', 'identify'), ('following', 'following'), ('tasks', 'task'), ('.', '.')]



============================ Sentence 385 =============================

• Density estimation: Density estimation aims at es-  timating directly the distribution p(x). 


>> Tokens are: 
 ['•', 'Density', 'estimation', ':', 'Density', 'estimation', 'aims', 'es-', 'timating', 'directly', 'distribution', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('•', 'Density'), ('Density', 'estimation'), ('estimation', ':'), (':', 'Density'), ('Density', 'estimation'), ('estimation', 'aims'), ('aims', 'es-'), ('es-', 'timating'), ('timating', 'directly'), ('directly', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'Density', 'estimation'), ('Density', 'estimation', ':'), ('estimation', ':', 'Density'), (':', 'Density', 'estimation'), ('Density', 'estimation', 'aims'), ('estimation', 'aims', 'es-'), ('aims', 'es-', 'timating'), ('es-', 'timating', 'directly'), ('timating', 'directly', 'distribution'), ('directly', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Density', 'NNP'), ('estimation', 'NN'), (':', ':'), ('Density', 'NNP'), ('estimation', 'NN'), ('aims', 'VBZ'), ('es-', 'JJ'), ('timating', 'VBG'), ('directly', 'RB'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP •/JJ Density/NNP estimation/NN)
  :/:
  (NP Density/NNP estimation/NN)
  aims/VBZ
  es-/JJ
  timating/VBG
  directly/RB
  (NP distribution/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['• Density estimation', 'Density estimation', 'distribution p', 'x']

>> Named Entities are: 
 [('ORGANIZATION', 'Density'), ('PERSON', 'Density')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Density', 'densiti'), ('estimation', 'estim'), (':', ':'), ('Density', 'densiti'), ('estimation', 'estim'), ('aims', 'aim'), ('es-', 'es-'), ('timating', 'timat'), ('directly', 'directli'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Density', 'densiti'), ('estimation', 'estim'), (':', ':'), ('Density', 'densiti'), ('estimation', 'estim'), ('aims', 'aim'), ('es-', 'es-'), ('timating', 'timat'), ('directly', 'direct'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Density', 'Density'), ('estimation', 'estimation'), (':', ':'), ('Density', 'Density'), ('estimation', 'estimation'), ('aims', 'aim'), ('es-', 'es-'), ('timating', 'timating'), ('directly', 'directly'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 386 =============================

This may be useful, for example, for use in plug-in estimators of information-theoretic quantities, for the design of compression algorithms, or to detect outliers;  • Clustering: Clustering aims at partitioning all points in the data set D in groups of similar objects, where the notion of similarity is domain-dependent;  • Dimensionality reduction, representation, and fea- ture extraction: These three related tasks represent each data point xn in a different space, typically of lower dimensionality, in order to highlight in- dependent explanatory factors and/or to ease visu- alization, interpretation, or the implementation of successive tasks, e.g.-.-, classification;  • Generation of new samples: Given the data set D, we wish to learn a machine that produces sam- ples that are approximately distributed according  12    to p(x). 


>> Tokens are: 
 ['This', 'may', 'useful', ',', 'example', ',', 'use', 'plug-in', 'estimators', 'information-theoretic', 'quantities', ',', 'design', 'compression', 'algorithms', ',', 'detect', 'outliers', ';', '•', 'Clustering', ':', 'Clustering', 'aims', 'partitioning', 'points', 'data', 'set', 'D', 'groups', 'similar', 'objects', ',', 'notion', 'similarity', 'domain-dependent', ';', '•', 'Dimensionality', 'reduction', ',', 'representation', ',', 'fea-', 'ture', 'extraction', ':', 'These', 'three', 'related', 'tasks', 'represent', 'data', 'point', 'xn', 'different', 'space', ',', 'typically', 'lower', 'dimensionality', ',', 'order', 'highlight', 'in-', 'dependent', 'explanatory', 'factors', 'and/or', 'ease', 'visu-', 'alization', ',', 'interpretation', ',', 'implementation', 'successive', 'tasks', ',', 'e.g.-.-', ',', 'classification', ';', '•', 'Generation', 'new', 'samples', ':', 'Given', 'data', 'set', 'D', ',', 'wish', 'learn', 'machine', 'produces', 'sam-', 'ples', 'approximately', 'distributed', 'according', '12', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('This', 'may'), ('may', 'useful'), ('useful', ','), (',', 'example'), ('example', ','), (',', 'use'), ('use', 'plug-in'), ('plug-in', 'estimators'), ('estimators', 'information-theoretic'), ('information-theoretic', 'quantities'), ('quantities', ','), (',', 'design'), ('design', 'compression'), ('compression', 'algorithms'), ('algorithms', ','), (',', 'detect'), ('detect', 'outliers'), ('outliers', ';'), (';', '•'), ('•', 'Clustering'), ('Clustering', ':'), (':', 'Clustering'), ('Clustering', 'aims'), ('aims', 'partitioning'), ('partitioning', 'points'), ('points', 'data'), ('data', 'set'), ('set', 'D'), ('D', 'groups'), ('groups', 'similar'), ('similar', 'objects'), ('objects', ','), (',', 'notion'), ('notion', 'similarity'), ('similarity', 'domain-dependent'), ('domain-dependent', ';'), (';', '•'), ('•', 'Dimensionality'), ('Dimensionality', 'reduction'), ('reduction', ','), (',', 'representation'), ('representation', ','), (',', 'fea-'), ('fea-', 'ture'), ('ture', 'extraction'), ('extraction', ':'), (':', 'These'), ('These', 'three'), ('three', 'related'), ('related', 'tasks'), ('tasks', 'represent'), ('represent', 'data'), ('data', 'point'), ('point', 'xn'), ('xn', 'different'), ('different', 'space'), ('space', ','), (',', 'typically'), ('typically', 'lower'), ('lower', 'dimensionality'), ('dimensionality', ','), (',', 'order'), ('order', 'highlight'), ('highlight', 'in-'), ('in-', 'dependent'), ('dependent', 'explanatory'), ('explanatory', 'factors'), ('factors', 'and/or'), ('and/or', 'ease'), ('ease', 'visu-'), ('visu-', 'alization'), ('alization', ','), (',', 'interpretation'), ('interpretation', ','), (',', 'implementation'), ('implementation', 'successive'), ('successive', 'tasks'), ('tasks', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'classification'), ('classification', ';'), (';', '•'), ('•', 'Generation'), ('Generation', 'new'), ('new', 'samples'), ('samples', ':'), (':', 'Given'), ('Given', 'data'), ('data', 'set'), ('set', 'D'), ('D', ','), (',', 'wish'), ('wish', 'learn'), ('learn', 'machine'), ('machine', 'produces'), ('produces', 'sam-'), ('sam-', 'ples'), ('ples', 'approximately'), ('approximately', 'distributed'), ('distributed', 'according'), ('according', '12'), ('12', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'may', 'useful'), ('may', 'useful', ','), ('useful', ',', 'example'), (',', 'example', ','), ('example', ',', 'use'), (',', 'use', 'plug-in'), ('use', 'plug-in', 'estimators'), ('plug-in', 'estimators', 'information-theoretic'), ('estimators', 'information-theoretic', 'quantities'), ('information-theoretic', 'quantities', ','), ('quantities', ',', 'design'), (',', 'design', 'compression'), ('design', 'compression', 'algorithms'), ('compression', 'algorithms', ','), ('algorithms', ',', 'detect'), (',', 'detect', 'outliers'), ('detect', 'outliers', ';'), ('outliers', ';', '•'), (';', '•', 'Clustering'), ('•', 'Clustering', ':'), ('Clustering', ':', 'Clustering'), (':', 'Clustering', 'aims'), ('Clustering', 'aims', 'partitioning'), ('aims', 'partitioning', 'points'), ('partitioning', 'points', 'data'), ('points', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', 'groups'), ('D', 'groups', 'similar'), ('groups', 'similar', 'objects'), ('similar', 'objects', ','), ('objects', ',', 'notion'), (',', 'notion', 'similarity'), ('notion', 'similarity', 'domain-dependent'), ('similarity', 'domain-dependent', ';'), ('domain-dependent', ';', '•'), (';', '•', 'Dimensionality'), ('•', 'Dimensionality', 'reduction'), ('Dimensionality', 'reduction', ','), ('reduction', ',', 'representation'), (',', 'representation', ','), ('representation', ',', 'fea-'), (',', 'fea-', 'ture'), ('fea-', 'ture', 'extraction'), ('ture', 'extraction', ':'), ('extraction', ':', 'These'), (':', 'These', 'three'), ('These', 'three', 'related'), ('three', 'related', 'tasks'), ('related', 'tasks', 'represent'), ('tasks', 'represent', 'data'), ('represent', 'data', 'point'), ('data', 'point', 'xn'), ('point', 'xn', 'different'), ('xn', 'different', 'space'), ('different', 'space', ','), ('space', ',', 'typically'), (',', 'typically', 'lower'), ('typically', 'lower', 'dimensionality'), ('lower', 'dimensionality', ','), ('dimensionality', ',', 'order'), (',', 'order', 'highlight'), ('order', 'highlight', 'in-'), ('highlight', 'in-', 'dependent'), ('in-', 'dependent', 'explanatory'), ('dependent', 'explanatory', 'factors'), ('explanatory', 'factors', 'and/or'), ('factors', 'and/or', 'ease'), ('and/or', 'ease', 'visu-'), ('ease', 'visu-', 'alization'), ('visu-', 'alization', ','), ('alization', ',', 'interpretation'), (',', 'interpretation', ','), ('interpretation', ',', 'implementation'), (',', 'implementation', 'successive'), ('implementation', 'successive', 'tasks'), ('successive', 'tasks', ','), ('tasks', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'classification'), (',', 'classification', ';'), ('classification', ';', '•'), (';', '•', 'Generation'), ('•', 'Generation', 'new'), ('Generation', 'new', 'samples'), ('new', 'samples', ':'), ('samples', ':', 'Given'), (':', 'Given', 'data'), ('Given', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', ','), ('D', ',', 'wish'), (',', 'wish', 'learn'), ('wish', 'learn', 'machine'), ('learn', 'machine', 'produces'), ('machine', 'produces', 'sam-'), ('produces', 'sam-', 'ples'), ('sam-', 'ples', 'approximately'), ('ples', 'approximately', 'distributed'), ('approximately', 'distributed', 'according'), ('distributed', 'according', '12'), ('according', '12', 'p'), ('12', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('may', 'MD'), ('useful', 'VB'), (',', ','), ('example', 'NN'), (',', ','), ('use', 'VB'), ('plug-in', 'JJ'), ('estimators', 'NNS'), ('information-theoretic', 'JJ'), ('quantities', 'NNS'), (',', ','), ('design', 'NN'), ('compression', 'NN'), ('algorithms', 'NN'), (',', ','), ('detect', 'JJ'), ('outliers', 'NNS'), (';', ':'), ('•', 'CC'), ('Clustering', 'NNP'), (':', ':'), ('Clustering', 'VBG'), ('aims', 'NNS'), ('partitioning', 'VBG'), ('points', 'NNS'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), ('groups', 'NNS'), ('similar', 'JJ'), ('objects', 'NNS'), (',', ','), ('notion', 'NN'), ('similarity', 'NN'), ('domain-dependent', 'NN'), (';', ':'), ('•', 'CC'), ('Dimensionality', 'NNP'), ('reduction', 'NN'), (',', ','), ('representation', 'NN'), (',', ','), ('fea-', 'JJ'), ('ture', 'NN'), ('extraction', 'NN'), (':', ':'), ('These', 'DT'), ('three', 'CD'), ('related', 'VBD'), ('tasks', 'NNS'), ('represent', 'JJ'), ('data', 'NNS'), ('point', 'NN'), ('xn', 'NNP'), ('different', 'JJ'), ('space', 'NN'), (',', ','), ('typically', 'RB'), ('lower', 'JJR'), ('dimensionality', 'NN'), (',', ','), ('order', 'NN'), ('highlight', 'VBD'), ('in-', 'JJ'), ('dependent', 'JJ'), ('explanatory', 'NN'), ('factors', 'NNS'), ('and/or', 'VBP'), ('ease', 'JJ'), ('visu-', 'JJ'), ('alization', 'NN'), (',', ','), ('interpretation', 'NN'), (',', ','), ('implementation', 'NN'), ('successive', 'JJ'), ('tasks', 'NNS'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('classification', 'NN'), (';', ':'), ('•', 'CC'), ('Generation', 'NNP'), ('new', 'JJ'), ('samples', 'NNS'), (':', ':'), ('Given', 'VBN'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), (',', ','), ('wish', 'JJ'), ('learn', 'FW'), ('machine', 'NN'), ('produces', 'VBZ'), ('sam-', 'JJ'), ('ples', 'NNS'), ('approximately', 'RB'), ('distributed', 'VBD'), ('according', 'VBG'), ('12', 'CD'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  This/DT
  may/MD
  useful/VB
  ,/,
  (NP example/NN)
  ,/,
  use/VB
  (NP plug-in/JJ estimators/NNS)
  (NP information-theoretic/JJ quantities/NNS)
  ,/,
  (NP design/NN compression/NN algorithms/NN)
  ,/,
  (NP detect/JJ outliers/NNS)
  ;/:
  •/CC
  (NP Clustering/NNP)
  :/:
  Clustering/VBG
  (NP aims/NNS)
  partitioning/VBG
  (NP points/NNS data/NNS)
  set/VBD
  (NP D/NNP groups/NNS)
  (NP similar/JJ objects/NNS)
  ,/,
  (NP notion/NN similarity/NN domain-dependent/NN)
  ;/:
  •/CC
  (NP Dimensionality/NNP reduction/NN)
  ,/,
  (NP representation/NN)
  ,/,
  (NP fea-/JJ ture/NN extraction/NN)
  :/:
  These/DT
  three/CD
  related/VBD
  (NP tasks/NNS)
  (NP represent/JJ data/NNS point/NN xn/NNP)
  (NP different/JJ space/NN)
  ,/,
  typically/RB
  lower/JJR
  (NP dimensionality/NN)
  ,/,
  (NP order/NN)
  highlight/VBD
  (NP in-/JJ dependent/JJ explanatory/NN factors/NNS)
  and/or/VBP
  (NP ease/JJ visu-/JJ alization/NN)
  ,/,
  (NP interpretation/NN)
  ,/,
  (NP implementation/NN)
  (NP successive/JJ tasks/NNS)
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP classification/NN)
  ;/:
  •/CC
  (NP Generation/NNP)
  (NP new/JJ samples/NNS)
  :/:
  Given/VBN
  (NP data/NNS)
  set/VBD
  (NP D/NNP)
  ,/,
  wish/JJ
  learn/FW
  (NP machine/NN)
  produces/VBZ
  (NP sam-/JJ ples/NNS)
  approximately/RB
  distributed/VBD
  according/VBG
  12/CD
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['example', 'plug-in estimators', 'information-theoretic quantities', 'design compression algorithms', 'detect outliers', 'Clustering', 'aims', 'points data', 'D groups', 'similar objects', 'notion similarity domain-dependent', 'Dimensionality reduction', 'representation', 'fea- ture extraction', 'tasks', 'represent data point xn', 'different space', 'dimensionality', 'order', 'in- dependent explanatory factors', 'ease visu- alization', 'interpretation', 'implementation', 'successive tasks', 'classification', 'Generation', 'new samples', 'data', 'D', 'machine', 'sam- ples', 'p', 'x']

>> Named Entities are: 
 [('ORGANIZATION', 'Dimensionality'), ('ORGANIZATION', 'Generation'), ('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('may', 'may'), ('useful', 'use'), (',', ','), ('example', 'exampl'), (',', ','), ('use', 'use'), ('plug-in', 'plug-in'), ('estimators', 'estim'), ('information-theoretic', 'information-theoret'), ('quantities', 'quantiti'), (',', ','), ('design', 'design'), ('compression', 'compress'), ('algorithms', 'algorithm'), (',', ','), ('detect', 'detect'), ('outliers', 'outlier'), (';', ';'), ('•', '•'), ('Clustering', 'cluster'), (':', ':'), ('Clustering', 'cluster'), ('aims', 'aim'), ('partitioning', 'partit'), ('points', 'point'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('groups', 'group'), ('similar', 'similar'), ('objects', 'object'), (',', ','), ('notion', 'notion'), ('similarity', 'similar'), ('domain-dependent', 'domain-depend'), (';', ';'), ('•', '•'), ('Dimensionality', 'dimension'), ('reduction', 'reduct'), (',', ','), ('representation', 'represent'), (',', ','), ('fea-', 'fea-'), ('ture', 'ture'), ('extraction', 'extract'), (':', ':'), ('These', 'these'), ('three', 'three'), ('related', 'relat'), ('tasks', 'task'), ('represent', 'repres'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('different', 'differ'), ('space', 'space'), (',', ','), ('typically', 'typic'), ('lower', 'lower'), ('dimensionality', 'dimension'), (',', ','), ('order', 'order'), ('highlight', 'highlight'), ('in-', 'in-'), ('dependent', 'depend'), ('explanatory', 'explanatori'), ('factors', 'factor'), ('and/or', 'and/or'), ('ease', 'eas'), ('visu-', 'visu-'), ('alization', 'aliz'), (',', ','), ('interpretation', 'interpret'), (',', ','), ('implementation', 'implement'), ('successive', 'success'), ('tasks', 'task'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('classification', 'classif'), (';', ';'), ('•', '•'), ('Generation', 'gener'), ('new', 'new'), ('samples', 'sampl'), (':', ':'), ('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('wish', 'wish'), ('learn', 'learn'), ('machine', 'machin'), ('produces', 'produc'), ('sam-', 'sam-'), ('ples', 'ple'), ('approximately', 'approxim'), ('distributed', 'distribut'), ('according', 'accord'), ('12', '12'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('may', 'may'), ('useful', 'use'), (',', ','), ('example', 'exampl'), (',', ','), ('use', 'use'), ('plug-in', 'plug-in'), ('estimators', 'estim'), ('information-theoretic', 'information-theoret'), ('quantities', 'quantiti'), (',', ','), ('design', 'design'), ('compression', 'compress'), ('algorithms', 'algorithm'), (',', ','), ('detect', 'detect'), ('outliers', 'outlier'), (';', ';'), ('•', '•'), ('Clustering', 'cluster'), (':', ':'), ('Clustering', 'cluster'), ('aims', 'aim'), ('partitioning', 'partit'), ('points', 'point'), ('data', 'data'), ('set', 'set'), ('D', 'd'), ('groups', 'group'), ('similar', 'similar'), ('objects', 'object'), (',', ','), ('notion', 'notion'), ('similarity', 'similar'), ('domain-dependent', 'domain-depend'), (';', ';'), ('•', '•'), ('Dimensionality', 'dimension'), ('reduction', 'reduct'), (',', ','), ('representation', 'represent'), (',', ','), ('fea-', 'fea-'), ('ture', 'ture'), ('extraction', 'extract'), (':', ':'), ('These', 'these'), ('three', 'three'), ('related', 'relat'), ('tasks', 'task'), ('represent', 'repres'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('different', 'differ'), ('space', 'space'), (',', ','), ('typically', 'typic'), ('lower', 'lower'), ('dimensionality', 'dimension'), (',', ','), ('order', 'order'), ('highlight', 'highlight'), ('in-', 'in-'), ('dependent', 'depend'), ('explanatory', 'explanatori'), ('factors', 'factor'), ('and/or', 'and/or'), ('ease', 'eas'), ('visu-', 'visu-'), ('alization', 'alize'), (',', ','), ('interpretation', 'interpret'), (',', ','), ('implementation', 'implement'), ('successive', 'success'), ('tasks', 'task'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('classification', 'classif'), (';', ';'), ('•', '•'), ('Generation', 'generat'), ('new', 'new'), ('samples', 'sampl'), (':', ':'), ('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('wish', 'wish'), ('learn', 'learn'), ('machine', 'machin'), ('produces', 'produc'), ('sam-', 'sam-'), ('ples', 'ples'), ('approximately', 'approxim'), ('distributed', 'distribut'), ('according', 'accord'), ('12', '12'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('may', 'may'), ('useful', 'useful'), (',', ','), ('example', 'example'), (',', ','), ('use', 'use'), ('plug-in', 'plug-in'), ('estimators', 'estimator'), ('information-theoretic', 'information-theoretic'), ('quantities', 'quantity'), (',', ','), ('design', 'design'), ('compression', 'compression'), ('algorithms', 'algorithm'), (',', ','), ('detect', 'detect'), ('outliers', 'outlier'), (';', ';'), ('•', '•'), ('Clustering', 'Clustering'), (':', ':'), ('Clustering', 'Clustering'), ('aims', 'aim'), ('partitioning', 'partitioning'), ('points', 'point'), ('data', 'data'), ('set', 'set'), ('D', 'D'), ('groups', 'group'), ('similar', 'similar'), ('objects', 'object'), (',', ','), ('notion', 'notion'), ('similarity', 'similarity'), ('domain-dependent', 'domain-dependent'), (';', ';'), ('•', '•'), ('Dimensionality', 'Dimensionality'), ('reduction', 'reduction'), (',', ','), ('representation', 'representation'), (',', ','), ('fea-', 'fea-'), ('ture', 'ture'), ('extraction', 'extraction'), (':', ':'), ('These', 'These'), ('three', 'three'), ('related', 'related'), ('tasks', 'task'), ('represent', 'represent'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('different', 'different'), ('space', 'space'), (',', ','), ('typically', 'typically'), ('lower', 'lower'), ('dimensionality', 'dimensionality'), (',', ','), ('order', 'order'), ('highlight', 'highlight'), ('in-', 'in-'), ('dependent', 'dependent'), ('explanatory', 'explanatory'), ('factors', 'factor'), ('and/or', 'and/or'), ('ease', 'ease'), ('visu-', 'visu-'), ('alization', 'alization'), (',', ','), ('interpretation', 'interpretation'), (',', ','), ('implementation', 'implementation'), ('successive', 'successive'), ('tasks', 'task'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('classification', 'classification'), (';', ';'), ('•', '•'), ('Generation', 'Generation'), ('new', 'new'), ('samples', 'sample'), (':', ':'), ('Given', 'Given'), ('data', 'data'), ('set', 'set'), ('D', 'D'), (',', ','), ('wish', 'wish'), ('learn', 'learn'), ('machine', 'machine'), ('produces', 'produce'), ('sam-', 'sam-'), ('ples', 'ples'), ('approximately', 'approximately'), ('distributed', 'distributed'), ('according', 'according'), ('12', '12'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 387 =============================

As an example, if the data set contains images of celebrities, the idea is to produce plausi- ble images of non-existent celebrities. 


>> Tokens are: 
 ['As', 'example', ',', 'data', 'set', 'contains', 'images', 'celebrities', ',', 'idea', 'produce', 'plausi-', 'ble', 'images', 'non-existent', 'celebrities', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'data'), ('data', 'set'), ('set', 'contains'), ('contains', 'images'), ('images', 'celebrities'), ('celebrities', ','), (',', 'idea'), ('idea', 'produce'), ('produce', 'plausi-'), ('plausi-', 'ble'), ('ble', 'images'), ('images', 'non-existent'), ('non-existent', 'celebrities'), ('celebrities', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'data'), (',', 'data', 'set'), ('data', 'set', 'contains'), ('set', 'contains', 'images'), ('contains', 'images', 'celebrities'), ('images', 'celebrities', ','), ('celebrities', ',', 'idea'), (',', 'idea', 'produce'), ('idea', 'produce', 'plausi-'), ('produce', 'plausi-', 'ble'), ('plausi-', 'ble', 'images'), ('ble', 'images', 'non-existent'), ('images', 'non-existent', 'celebrities'), ('non-existent', 'celebrities', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('data', 'NNS'), ('set', 'VBD'), ('contains', 'NNS'), ('images', 'JJ'), ('celebrities', 'NNS'), (',', ','), ('idea', 'NN'), ('produce', 'VBP'), ('plausi-', 'JJ'), ('ble', 'JJ'), ('images', 'NNS'), ('non-existent', 'JJ'), ('celebrities', 'NNS'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  (NP data/NNS)
  set/VBD
  (NP contains/NNS)
  (NP images/JJ celebrities/NNS)
  ,/,
  (NP idea/NN)
  produce/VBP
  (NP plausi-/JJ ble/JJ images/NNS)
  (NP non-existent/JJ celebrities/NNS)
  ./.) 


>> Noun Phrases are: 
 ['example', 'data', 'contains', 'images celebrities', 'idea', 'plausi- ble images', 'non-existent celebrities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('data', 'data'), ('set', 'set'), ('contains', 'contain'), ('images', 'imag'), ('celebrities', 'celebr'), (',', ','), ('idea', 'idea'), ('produce', 'produc'), ('plausi-', 'plausi-'), ('ble', 'ble'), ('images', 'imag'), ('non-existent', 'non-exist'), ('celebrities', 'celebr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('data', 'data'), ('set', 'set'), ('contains', 'contain'), ('images', 'imag'), ('celebrities', 'celebr'), (',', ','), ('idea', 'idea'), ('produce', 'produc'), ('plausi-', 'plausi-'), ('ble', 'ble'), ('images', 'imag'), ('non-existent', 'non-exist'), ('celebrities', 'celebr'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('data', 'data'), ('set', 'set'), ('contains', 'contains'), ('images', 'image'), ('celebrities', 'celebrity'), (',', ','), ('idea', 'idea'), ('produce', 'produce'), ('plausi-', 'plausi-'), ('ble', 'ble'), ('images', 'image'), ('non-existent', 'non-existent'), ('celebrities', 'celebrity'), ('.', '.')]



============================ Sentence 388 =============================

This can be useful, e.g.-.-, to produce artificial scenes for video parameterizes or films. 


>> Tokens are: 
 ['This', 'useful', ',', 'e.g.-.-', ',', 'produce', 'artificial', 'scenes', 'video', 'parameterizes', 'films', '.']

>> Bigrams are: 
 [('This', 'useful'), ('useful', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'produce'), ('produce', 'artificial'), ('artificial', 'scenes'), ('scenes', 'video'), ('video', 'parameterizes'), ('parameterizes', 'films'), ('films', '.')]

>> Trigrams are: 
 [('This', 'useful', ','), ('useful', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'produce'), (',', 'produce', 'artificial'), ('produce', 'artificial', 'scenes'), ('artificial', 'scenes', 'video'), ('scenes', 'video', 'parameterizes'), ('video', 'parameterizes', 'films'), ('parameterizes', 'films', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('useful', 'JJ'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('produce', 'VBP'), ('artificial', 'JJ'), ('scenes', 'NNS'), ('video', 'NN'), ('parameterizes', 'VBZ'), ('films', 'NNS'), ('.', '.')]

 (S
  This/DT
  useful/JJ
  ,/,
  e.g.-.-/JJ
  ,/,
  produce/VBP
  (NP artificial/JJ scenes/NNS video/NN)
  parameterizes/VBZ
  (NP films/NNS)
  ./.) 


>> Noun Phrases are: 
 ['artificial scenes video', 'films']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('useful', 'use'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('produce', 'produc'), ('artificial', 'artifici'), ('scenes', 'scene'), ('video', 'video'), ('parameterizes', 'parameter'), ('films', 'film'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('useful', 'use'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('produce', 'produc'), ('artificial', 'artifici'), ('scenes', 'scene'), ('video', 'video'), ('parameterizes', 'parameter'), ('films', 'film'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('useful', 'useful'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('produce', 'produce'), ('artificial', 'artificial'), ('scenes', 'scene'), ('video', 'video'), ('parameterizes', 'parameterizes'), ('films', 'film'), ('.', '.')]



============================ Sentence 389 =============================

As suggested by the variety of tasks listed above, unsupervised learning does not have a formal unified formulation as supervised learning. 


>> Tokens are: 
 ['As', 'suggested', 'variety', 'tasks', 'listed', ',', 'unsupervised', 'learning', 'formal', 'unified', 'formulation', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('As', 'suggested'), ('suggested', 'variety'), ('variety', 'tasks'), ('tasks', 'listed'), ('listed', ','), (',', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'formal'), ('formal', 'unified'), ('unified', 'formulation'), ('formulation', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('As', 'suggested', 'variety'), ('suggested', 'variety', 'tasks'), ('variety', 'tasks', 'listed'), ('tasks', 'listed', ','), ('listed', ',', 'unsupervised'), (',', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'formal'), ('learning', 'formal', 'unified'), ('formal', 'unified', 'formulation'), ('unified', 'formulation', 'supervised'), ('formulation', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('suggested', 'VBN'), ('variety', 'NN'), ('tasks', 'NNS'), ('listed', 'VBN'), (',', ','), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('formal', 'JJ'), ('unified', 'JJ'), ('formulation', 'NN'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  As/IN
  suggested/VBN
  (NP variety/NN tasks/NNS)
  listed/VBN
  ,/,
  unsupervised/JJ
  learning/VBG
  (NP formal/JJ unified/JJ formulation/NN)
  supervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['variety tasks', 'formal unified formulation', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('suggested', 'suggest'), ('variety', 'varieti'), ('tasks', 'task'), ('listed', 'list'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('formal', 'formal'), ('unified', 'unifi'), ('formulation', 'formul'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('suggested', 'suggest'), ('variety', 'varieti'), ('tasks', 'task'), ('listed', 'list'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('formal', 'formal'), ('unified', 'unifi'), ('formulation', 'formul'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('suggested', 'suggested'), ('variety', 'variety'), ('tasks', 'task'), ('listed', 'listed'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('formal', 'formal'), ('unified', 'unified'), ('formulation', 'formulation'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 390 =============================

Nevertheless, the general methodology follows three main steps in a manner similar to supervised learning (see Sec III-D). 


>> Tokens are: 
 ['Nevertheless', ',', 'general', 'methodology', 'follows', 'three', 'main', 'steps', 'manner', 'similar', 'supervised', 'learning', '(', 'see', 'Sec', 'III-D', ')', '.']

>> Bigrams are: 
 [('Nevertheless', ','), (',', 'general'), ('general', 'methodology'), ('methodology', 'follows'), ('follows', 'three'), ('three', 'main'), ('main', 'steps'), ('steps', 'manner'), ('manner', 'similar'), ('similar', 'supervised'), ('supervised', 'learning'), ('learning', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'III-D'), ('III-D', ')'), (')', '.')]

>> Trigrams are: 
 [('Nevertheless', ',', 'general'), (',', 'general', 'methodology'), ('general', 'methodology', 'follows'), ('methodology', 'follows', 'three'), ('follows', 'three', 'main'), ('three', 'main', 'steps'), ('main', 'steps', 'manner'), ('steps', 'manner', 'similar'), ('manner', 'similar', 'supervised'), ('similar', 'supervised', 'learning'), ('supervised', 'learning', '('), ('learning', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'III-D'), ('Sec', 'III-D', ')'), ('III-D', ')', '.')]

>> POS Tags are: 
 [('Nevertheless', 'RB'), (',', ','), ('general', 'JJ'), ('methodology', 'NN'), ('follows', 'VBZ'), ('three', 'CD'), ('main', 'JJ'), ('steps', 'NNS'), ('manner', 'RB'), ('similar', 'JJ'), ('supervised', 'VBD'), ('learning', 'NN'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('III-D', 'NNP'), (')', ')'), ('.', '.')]

 (S
  Nevertheless/RB
  ,/,
  (NP general/JJ methodology/NN)
  follows/VBZ
  three/CD
  (NP main/JJ steps/NNS)
  manner/RB
  similar/JJ
  supervised/VBD
  (NP learning/NN)
  (/(
  see/VB
  (NP Sec/NNP III-D/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['general methodology', 'main steps', 'learning', 'Sec III-D']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('general', 'gener'), ('methodology', 'methodolog'), ('follows', 'follow'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), ('manner', 'manner'), ('similar', 'similar'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-D', 'iii-d'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('general', 'general'), ('methodology', 'methodolog'), ('follows', 'follow'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), ('manner', 'manner'), ('similar', 'similar'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('III-D', 'iii-d'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nevertheless', 'Nevertheless'), (',', ','), ('general', 'general'), ('methodology', 'methodology'), ('follows', 'follows'), ('three', 'three'), ('main', 'main'), ('steps', 'step'), ('manner', 'manner'), ('similar', 'similar'), ('supervised', 'supervised'), ('learning', 'learning'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('III-D', 'III-D'), (')', ')'), ('.', '.')]



============================ Sentence 391 =============================

In Step 1 (model selection), a model, or a hypothesis class, is selected, defining the inductive bias of the learning process. 


>> Tokens are: 
 ['In', 'Step', '1', '(', 'model', 'selection', ')', ',', 'model', ',', 'hypothesis', 'class', ',', 'selected', ',', 'defining', 'inductive', 'bias', 'learning', 'process', '.']

>> Bigrams are: 
 [('In', 'Step'), ('Step', '1'), ('1', '('), ('(', 'model'), ('model', 'selection'), ('selection', ')'), (')', ','), (',', 'model'), ('model', ','), (',', 'hypothesis'), ('hypothesis', 'class'), ('class', ','), (',', 'selected'), ('selected', ','), (',', 'defining'), ('defining', 'inductive'), ('inductive', 'bias'), ('bias', 'learning'), ('learning', 'process'), ('process', '.')]

>> Trigrams are: 
 [('In', 'Step', '1'), ('Step', '1', '('), ('1', '(', 'model'), ('(', 'model', 'selection'), ('model', 'selection', ')'), ('selection', ')', ','), (')', ',', 'model'), (',', 'model', ','), ('model', ',', 'hypothesis'), (',', 'hypothesis', 'class'), ('hypothesis', 'class', ','), ('class', ',', 'selected'), (',', 'selected', ','), ('selected', ',', 'defining'), (',', 'defining', 'inductive'), ('defining', 'inductive', 'bias'), ('inductive', 'bias', 'learning'), ('bias', 'learning', 'process'), ('learning', 'process', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Step', 'NNP'), ('1', 'CD'), ('(', '('), ('model', 'NN'), ('selection', 'NN'), (')', ')'), (',', ','), ('model', 'NN'), (',', ','), ('hypothesis', 'NN'), ('class', 'NN'), (',', ','), ('selected', 'VBN'), (',', ','), ('defining', 'VBG'), ('inductive', 'JJ'), ('bias', 'NN'), ('learning', 'VBG'), ('process', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP Step/NNP)
  1/CD
  (/(
  (NP model/NN selection/NN)
  )/)
  ,/,
  (NP model/NN)
  ,/,
  (NP hypothesis/NN class/NN)
  ,/,
  selected/VBN
  ,/,
  defining/VBG
  (NP inductive/JJ bias/NN)
  learning/VBG
  (NP process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'model selection', 'model', 'hypothesis class', 'inductive bias', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'select'), (')', ')'), (',', ','), ('model', 'model'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('selected', 'select'), (',', ','), ('defining', 'defin'), ('inductive', 'induct'), ('bias', 'bia'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'select'), (')', ')'), (',', ','), ('model', 'model'), (',', ','), ('hypothesis', 'hypothesi'), ('class', 'class'), (',', ','), ('selected', 'select'), (',', ','), ('defining', 'defin'), ('inductive', 'induct'), ('bias', 'bias'), ('learning', 'learn'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Step', 'Step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'selection'), (')', ')'), (',', ','), ('model', 'model'), (',', ','), ('hypothesis', 'hypothesis'), ('class', 'class'), (',', ','), ('selected', 'selected'), (',', ','), ('defining', 'defining'), ('inductive', 'inductive'), ('bias', 'bias'), ('learning', 'learning'), ('process', 'process'), ('.', '.')]



============================ Sentence 392 =============================

This is done by positing a family of probability distributions p(x|θ) parameterized by a vector θ. 


>> Tokens are: 
 ['This', 'done', 'positing', 'family', 'probability', 'distributions', 'p', '(', 'x|θ', ')', 'parameterized', 'vector', 'θ', '.']

>> Bigrams are: 
 [('This', 'done'), ('done', 'positing'), ('positing', 'family'), ('family', 'probability'), ('probability', 'distributions'), ('distributions', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', 'parameterized'), ('parameterized', 'vector'), ('vector', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('This', 'done', 'positing'), ('done', 'positing', 'family'), ('positing', 'family', 'probability'), ('family', 'probability', 'distributions'), ('probability', 'distributions', 'p'), ('distributions', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', 'parameterized'), (')', 'parameterized', 'vector'), ('parameterized', 'vector', 'θ'), ('vector', 'θ', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('done', 'VBN'), ('positing', 'VBG'), ('family', 'NN'), ('probability', 'NN'), ('distributions', 'NNS'), ('p', 'VBP'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('parameterized', 'VBD'), ('vector', 'NN'), ('θ', 'NN'), ('.', '.')]

 (S
  This/DT
  done/VBN
  positing/VBG
  (NP family/NN probability/NN distributions/NNS)
  p/VBP
  (/(
  (NP x|θ/NNP)
  )/)
  parameterized/VBD
  (NP vector/NN θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['family probability distributions', 'x|θ', 'vector θ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('done', 'done'), ('positing', 'posit'), ('family', 'famili'), ('probability', 'probabl'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('parameterized', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('done', 'done'), ('positing', 'posit'), ('family', 'famili'), ('probability', 'probabl'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('parameterized', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('done', 'done'), ('positing', 'positing'), ('family', 'family'), ('probability', 'probability'), ('distributions', 'distribution'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('parameterized', 'parameterized'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 393 =============================

In Step 2 (learning), the data D is used to optimize a learning criterion with the aim of choosing a value for the parameter vector θ. 


>> Tokens are: 
 ['In', 'Step', '2', '(', 'learning', ')', ',', 'data', 'D', 'used', 'optimize', 'learning', 'criterion', 'aim', 'choosing', 'value', 'parameter', 'vector', 'θ', '.']

>> Bigrams are: 
 [('In', 'Step'), ('Step', '2'), ('2', '('), ('(', 'learning'), ('learning', ')'), (')', ','), (',', 'data'), ('data', 'D'), ('D', 'used'), ('used', 'optimize'), ('optimize', 'learning'), ('learning', 'criterion'), ('criterion', 'aim'), ('aim', 'choosing'), ('choosing', 'value'), ('value', 'parameter'), ('parameter', 'vector'), ('vector', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('In', 'Step', '2'), ('Step', '2', '('), ('2', '(', 'learning'), ('(', 'learning', ')'), ('learning', ')', ','), (')', ',', 'data'), (',', 'data', 'D'), ('data', 'D', 'used'), ('D', 'used', 'optimize'), ('used', 'optimize', 'learning'), ('optimize', 'learning', 'criterion'), ('learning', 'criterion', 'aim'), ('criterion', 'aim', 'choosing'), ('aim', 'choosing', 'value'), ('choosing', 'value', 'parameter'), ('value', 'parameter', 'vector'), ('parameter', 'vector', 'θ'), ('vector', 'θ', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Step', 'NNP'), ('2', 'CD'), ('(', '('), ('learning', 'VBG'), (')', ')'), (',', ','), ('data', 'NNS'), ('D', 'NNP'), ('used', 'VBD'), ('optimize', 'RP'), ('learning', 'JJ'), ('criterion', 'NN'), ('aim', 'NN'), ('choosing', 'VBG'), ('value', 'NN'), ('parameter', 'NN'), ('vector', 'NN'), ('θ', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP Step/NNP)
  2/CD
  (/(
  learning/VBG
  )/)
  ,/,
  (NP data/NNS D/NNP)
  used/VBD
  optimize/RP
  (NP learning/JJ criterion/NN aim/NN)
  choosing/VBG
  (NP value/NN parameter/NN vector/NN θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'data D', 'learning criterion aim', 'value parameter vector θ']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('2', '2'), ('(', '('), ('learning', 'learn'), (')', ')'), (',', ','), ('data', 'data'), ('D', 'd'), ('used', 'use'), ('optimize', 'optim'), ('learning', 'learn'), ('criterion', 'criterion'), ('aim', 'aim'), ('choosing', 'choos'), ('value', 'valu'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Step', 'step'), ('2', '2'), ('(', '('), ('learning', 'learn'), (')', ')'), (',', ','), ('data', 'data'), ('D', 'd'), ('used', 'use'), ('optimize', 'optim'), ('learning', 'learn'), ('criterion', 'criterion'), ('aim', 'aim'), ('choosing', 'choos'), ('value', 'valu'), ('parameter', 'paramet'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Step', 'Step'), ('2', '2'), ('(', '('), ('learning', 'learning'), (')', ')'), (',', ','), ('data', 'data'), ('D', 'D'), ('used', 'used'), ('optimize', 'optimize'), ('learning', 'learning'), ('criterion', 'criterion'), ('aim', 'aim'), ('choosing', 'choosing'), ('value', 'value'), ('parameter', 'parameter'), ('vector', 'vector'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 394 =============================

Finally, in Step 3, the trained model is leveraged in order to carry out the task of interest, e.g.-.-, clustering or sample generation. 


>> Tokens are: 
 ['Finally', ',', 'Step', '3', ',', 'trained', 'model', 'leveraged', 'order', 'carry', 'task', 'interest', ',', 'e.g.-.-', ',', 'clustering', 'sample', 'generation', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'Step'), ('Step', '3'), ('3', ','), (',', 'trained'), ('trained', 'model'), ('model', 'leveraged'), ('leveraged', 'order'), ('order', 'carry'), ('carry', 'task'), ('task', 'interest'), ('interest', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'clustering'), ('clustering', 'sample'), ('sample', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('Finally', ',', 'Step'), (',', 'Step', '3'), ('Step', '3', ','), ('3', ',', 'trained'), (',', 'trained', 'model'), ('trained', 'model', 'leveraged'), ('model', 'leveraged', 'order'), ('leveraged', 'order', 'carry'), ('order', 'carry', 'task'), ('carry', 'task', 'interest'), ('task', 'interest', ','), ('interest', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'clustering'), (',', 'clustering', 'sample'), ('clustering', 'sample', 'generation'), ('sample', 'generation', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('Step', 'NNP'), ('3', 'CD'), (',', ','), ('trained', 'VBD'), ('model', 'NN'), ('leveraged', 'JJ'), ('order', 'NN'), ('carry', 'NN'), ('task', 'NN'), ('interest', 'NN'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('clustering', 'VBG'), ('sample', 'JJ'), ('generation', 'NN'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP Step/NNP)
  3/CD
  ,/,
  trained/VBD
  (NP model/NN)
  (NP leveraged/JJ order/NN carry/NN task/NN interest/NN)
  ,/,
  e.g.-.-/JJ
  ,/,
  clustering/VBG
  (NP sample/JJ generation/NN)
  ./.) 


>> Noun Phrases are: 
 ['Step', 'model', 'leveraged order carry task interest', 'sample generation']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('Step', 'step'), ('3', '3'), (',', ','), ('trained', 'train'), ('model', 'model'), ('leveraged', 'leverag'), ('order', 'order'), ('carry', 'carri'), ('task', 'task'), ('interest', 'interest'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('clustering', 'cluster'), ('sample', 'sampl'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('Step', 'step'), ('3', '3'), (',', ','), ('trained', 'train'), ('model', 'model'), ('leveraged', 'leverag'), ('order', 'order'), ('carry', 'carri'), ('task', 'task'), ('interest', 'interest'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('clustering', 'cluster'), ('sample', 'sampl'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('Step', 'Step'), ('3', '3'), (',', ','), ('trained', 'trained'), ('model', 'model'), ('leveraged', 'leveraged'), ('order', 'order'), ('carry', 'carry'), ('task', 'task'), ('interest', 'interest'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('clustering', 'clustering'), ('sample', 'sample'), ('generation', 'generation'), ('.', '.')]



============================ Sentence 395 =============================

In the following, we discuss Step 1 (model selection) and Step 2 (learning). 


>> Tokens are: 
 ['In', 'following', ',', 'discuss', 'Step', '1', '(', 'model', 'selection', ')', 'Step', '2', '(', 'learning', ')', '.']

>> Bigrams are: 
 [('In', 'following'), ('following', ','), (',', 'discuss'), ('discuss', 'Step'), ('Step', '1'), ('1', '('), ('(', 'model'), ('model', 'selection'), ('selection', ')'), (')', 'Step'), ('Step', '2'), ('2', '('), ('(', 'learning'), ('learning', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'following', ','), ('following', ',', 'discuss'), (',', 'discuss', 'Step'), ('discuss', 'Step', '1'), ('Step', '1', '('), ('1', '(', 'model'), ('(', 'model', 'selection'), ('model', 'selection', ')'), ('selection', ')', 'Step'), (')', 'Step', '2'), ('Step', '2', '('), ('2', '(', 'learning'), ('(', 'learning', ')'), ('learning', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('following', 'VBG'), (',', ','), ('discuss', 'JJ'), ('Step', 'NNP'), ('1', 'CD'), ('(', '('), ('model', 'NN'), ('selection', 'NN'), (')', ')'), ('Step', 'NN'), ('2', 'CD'), ('(', '('), ('learning', 'VBG'), (')', ')'), ('.', '.')]

 (S
  In/IN
  following/VBG
  ,/,
  (NP discuss/JJ Step/NNP)
  1/CD
  (/(
  (NP model/NN selection/NN)
  )/)
  (NP Step/NN)
  2/CD
  (/(
  learning/VBG
  )/)
  ./.) 


>> Noun Phrases are: 
 ['discuss Step', 'model selection', 'Step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('following', 'follow'), (',', ','), ('discuss', 'discuss'), ('Step', 'step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'select'), (')', ')'), ('Step', 'step'), ('2', '2'), ('(', '('), ('learning', 'learn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('following', 'follow'), (',', ','), ('discuss', 'discuss'), ('Step', 'step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'select'), (')', ')'), ('Step', 'step'), ('2', '2'), ('(', '('), ('learning', 'learn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('following', 'following'), (',', ','), ('discuss', 'discus'), ('Step', 'Step'), ('1', '1'), ('(', '('), ('model', 'model'), ('selection', 'selection'), (')', ')'), ('Step', 'Step'), ('2', '2'), ('(', '('), ('learning', 'learning'), (')', ')'), ('.', '.')]



============================ Sentence 396 =============================

For the formulation of specific tasks to be carried out at Step 3, we refer to, e.g.-.-, [7], [19], [57]. 


>> Tokens are: 
 ['For', 'formulation', 'specific', 'tasks', 'carried', 'Step', '3', ',', 'refer', ',', 'e.g.-.-', ',', '[', '7', ']', ',', '[', '19', ']', ',', '[', '57', ']', '.']

>> Bigrams are: 
 [('For', 'formulation'), ('formulation', 'specific'), ('specific', 'tasks'), ('tasks', 'carried'), ('carried', 'Step'), ('Step', '3'), ('3', ','), (',', 'refer'), ('refer', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '7'), ('7', ']'), (']', ','), (',', '['), ('[', '19'), ('19', ']'), (']', ','), (',', '['), ('[', '57'), ('57', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'formulation', 'specific'), ('formulation', 'specific', 'tasks'), ('specific', 'tasks', 'carried'), ('tasks', 'carried', 'Step'), ('carried', 'Step', '3'), ('Step', '3', ','), ('3', ',', 'refer'), (',', 'refer', ','), ('refer', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '7'), ('[', '7', ']'), ('7', ']', ','), (']', ',', '['), (',', '[', '19'), ('[', '19', ']'), ('19', ']', ','), (']', ',', '['), (',', '[', '57'), ('[', '57', ']'), ('57', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('formulation', 'NN'), ('specific', 'JJ'), ('tasks', 'NNS'), ('carried', 'VBD'), ('Step', 'NNP'), ('3', 'CD'), (',', ','), ('refer', 'NN'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('7', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('19', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('57', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP formulation/NN)
  (NP specific/JJ tasks/NNS)
  carried/VBD
  (NP Step/NNP)
  3/CD
  ,/,
  (NP refer/NN)
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  7/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  19/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  57/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['formulation', 'specific tasks', 'Step', 'refer', ']', ']', ']']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('formulation', 'formul'), ('specific', 'specif'), ('tasks', 'task'), ('carried', 'carri'), ('Step', 'step'), ('3', '3'), (',', ','), ('refer', 'refer'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('formulation', 'formul'), ('specific', 'specif'), ('tasks', 'task'), ('carried', 'carri'), ('Step', 'step'), ('3', '3'), (',', ','), ('refer', 'refer'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('formulation', 'formulation'), ('specific', 'specific'), ('tasks', 'task'), ('carried', 'carried'), ('Step', 'Step'), ('3', '3'), (',', ','), ('refer', 'refer'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('7', '7'), (']', ']'), (',', ','), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]



============================ Sentence 397 =============================

B. 


>> Tokens are: 
 ['B', '.']

>> Bigrams are: 
 [('B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('.', '.')]

 (S (NP B/NNP) ./.) 


>> Noun Phrases are: 
 ['B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('B', 'B'), ('.', '.')]



============================ Sentence 398 =============================

Models  Unsupervised learning models, selected at Step 1 of the machine learning process, typically involve a hidden or latent (vector of) variables zn for each data point xn. 


>> Tokens are: 
 ['Models', 'Unsupervised', 'learning', 'models', ',', 'selected', 'Step', '1', 'machine', 'learning', 'process', ',', 'typically', 'involve', 'hidden', 'latent', '(', 'vector', ')', 'variables', 'zn', 'data', 'point', 'xn', '.']

>> Bigrams are: 
 [('Models', 'Unsupervised'), ('Unsupervised', 'learning'), ('learning', 'models'), ('models', ','), (',', 'selected'), ('selected', 'Step'), ('Step', '1'), ('1', 'machine'), ('machine', 'learning'), ('learning', 'process'), ('process', ','), (',', 'typically'), ('typically', 'involve'), ('involve', 'hidden'), ('hidden', 'latent'), ('latent', '('), ('(', 'vector'), ('vector', ')'), (')', 'variables'), ('variables', 'zn'), ('zn', 'data'), ('data', 'point'), ('point', 'xn'), ('xn', '.')]

>> Trigrams are: 
 [('Models', 'Unsupervised', 'learning'), ('Unsupervised', 'learning', 'models'), ('learning', 'models', ','), ('models', ',', 'selected'), (',', 'selected', 'Step'), ('selected', 'Step', '1'), ('Step', '1', 'machine'), ('1', 'machine', 'learning'), ('machine', 'learning', 'process'), ('learning', 'process', ','), ('process', ',', 'typically'), (',', 'typically', 'involve'), ('typically', 'involve', 'hidden'), ('involve', 'hidden', 'latent'), ('hidden', 'latent', '('), ('latent', '(', 'vector'), ('(', 'vector', ')'), ('vector', ')', 'variables'), (')', 'variables', 'zn'), ('variables', 'zn', 'data'), ('zn', 'data', 'point'), ('data', 'point', 'xn'), ('point', 'xn', '.')]

>> POS Tags are: 
 [('Models', 'NNS'), ('Unsupervised', 'VBD'), ('learning', 'VBG'), ('models', 'NNS'), (',', ','), ('selected', 'VBN'), ('Step', 'NN'), ('1', 'CD'), ('machine', 'NN'), ('learning', 'NN'), ('process', 'NN'), (',', ','), ('typically', 'RB'), ('involve', 'VB'), ('hidden', 'JJ'), ('latent', 'NN'), ('(', '('), ('vector', 'NN'), (')', ')'), ('variables', 'VBZ'), ('zn', 'JJ'), ('data', 'NNS'), ('point', 'NN'), ('xn', 'NN'), ('.', '.')]

 (S
  (NP Models/NNS)
  Unsupervised/VBD
  learning/VBG
  (NP models/NNS)
  ,/,
  selected/VBN
  (NP Step/NN)
  1/CD
  (NP machine/NN learning/NN process/NN)
  ,/,
  typically/RB
  involve/VB
  (NP hidden/JJ latent/NN)
  (/(
  (NP vector/NN)
  )/)
  variables/VBZ
  (NP zn/JJ data/NNS point/NN xn/NN)
  ./.) 


>> Noun Phrases are: 
 ['Models', 'models', 'Step', 'machine learning process', 'hidden latent', 'vector', 'zn data point xn']

>> Named Entities are: 
 [('PERSON', 'Models')] 

>> Stemming using Porter Stemmer: 
 [('Models', 'model'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('models', 'model'), (',', ','), ('selected', 'select'), ('Step', 'step'), ('1', '1'), ('machine', 'machin'), ('learning', 'learn'), ('process', 'process'), (',', ','), ('typically', 'typic'), ('involve', 'involv'), ('hidden', 'hidden'), ('latent', 'latent'), ('(', '('), ('vector', 'vector'), (')', ')'), ('variables', 'variabl'), ('zn', 'zn'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Models', 'model'), ('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('models', 'model'), (',', ','), ('selected', 'select'), ('Step', 'step'), ('1', '1'), ('machine', 'machin'), ('learning', 'learn'), ('process', 'process'), (',', ','), ('typically', 'typic'), ('involve', 'involv'), ('hidden', 'hidden'), ('latent', 'latent'), ('(', '('), ('vector', 'vector'), (')', ')'), ('variables', 'variabl'), ('zn', 'zn'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('.', '.')]

>> Lemmatization: 
 [('Models', 'Models'), ('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('models', 'model'), (',', ','), ('selected', 'selected'), ('Step', 'Step'), ('1', '1'), ('machine', 'machine'), ('learning', 'learning'), ('process', 'process'), (',', ','), ('typically', 'typically'), ('involve', 'involve'), ('hidden', 'hidden'), ('latent', 'latent'), ('(', '('), ('vector', 'vector'), (')', ')'), ('variables', 'variable'), ('zn', 'zn'), ('data', 'data'), ('point', 'point'), ('xn', 'xn'), ('.', '.')]



============================ Sentence 399 =============================

For example, in a clustering problem, the latent variable zn represents the cluster index of xn. 


>> Tokens are: 
 ['For', 'example', ',', 'clustering', 'problem', ',', 'latent', 'variable', 'zn', 'represents', 'cluster', 'index', 'xn', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'clustering'), ('clustering', 'problem'), ('problem', ','), (',', 'latent'), ('latent', 'variable'), ('variable', 'zn'), ('zn', 'represents'), ('represents', 'cluster'), ('cluster', 'index'), ('index', 'xn'), ('xn', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'clustering'), (',', 'clustering', 'problem'), ('clustering', 'problem', ','), ('problem', ',', 'latent'), (',', 'latent', 'variable'), ('latent', 'variable', 'zn'), ('variable', 'zn', 'represents'), ('zn', 'represents', 'cluster'), ('represents', 'cluster', 'index'), ('cluster', 'index', 'xn'), ('index', 'xn', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('clustering', 'VBG'), ('problem', 'NN'), (',', ','), ('latent', 'NN'), ('variable', 'JJ'), ('zn', 'NN'), ('represents', 'VBZ'), ('cluster', 'JJ'), ('index', 'NN'), ('xn', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  clustering/VBG
  (NP problem/NN)
  ,/,
  (NP latent/NN)
  (NP variable/JJ zn/NN)
  represents/VBZ
  (NP cluster/JJ index/NN xn/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'problem', 'latent', 'variable zn', 'cluster index xn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('clustering', 'cluster'), ('problem', 'problem'), (',', ','), ('latent', 'latent'), ('variable', 'variabl'), ('zn', 'zn'), ('represents', 'repres'), ('cluster', 'cluster'), ('index', 'index'), ('xn', 'xn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('clustering', 'cluster'), ('problem', 'problem'), (',', ','), ('latent', 'latent'), ('variable', 'variabl'), ('zn', 'zn'), ('represents', 'repres'), ('cluster', 'cluster'), ('index', 'index'), ('xn', 'xn'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('clustering', 'clustering'), ('problem', 'problem'), (',', ','), ('latent', 'latent'), ('variable', 'variable'), ('zn', 'zn'), ('represents', 'represents'), ('cluster', 'cluster'), ('index', 'index'), ('xn', 'xn'), ('.', '.')]



============================ Sentence 400 =============================

Latent variables are hidden or unobserved in the sense that they do not appear for any of the data points xn in D.3 The relationship between latent variables zn and observable variables xn can be modelled in different ways, giving rise to a number of different types of models for unsupervised learning. 


>> Tokens are: 
 ['Latent', 'variables', 'hidden', 'unobserved', 'sense', 'appear', 'data', 'points', 'xn', 'D.3', 'The', 'relationship', 'latent', 'variables', 'zn', 'observable', 'variables', 'xn', 'modelled', 'different', 'ways', ',', 'giving', 'rise', 'number', 'different', 'types', 'models', 'unsupervised', 'learning', '.']

>> Bigrams are: 
 [('Latent', 'variables'), ('variables', 'hidden'), ('hidden', 'unobserved'), ('unobserved', 'sense'), ('sense', 'appear'), ('appear', 'data'), ('data', 'points'), ('points', 'xn'), ('xn', 'D.3'), ('D.3', 'The'), ('The', 'relationship'), ('relationship', 'latent'), ('latent', 'variables'), ('variables', 'zn'), ('zn', 'observable'), ('observable', 'variables'), ('variables', 'xn'), ('xn', 'modelled'), ('modelled', 'different'), ('different', 'ways'), ('ways', ','), (',', 'giving'), ('giving', 'rise'), ('rise', 'number'), ('number', 'different'), ('different', 'types'), ('types', 'models'), ('models', 'unsupervised'), ('unsupervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Latent', 'variables', 'hidden'), ('variables', 'hidden', 'unobserved'), ('hidden', 'unobserved', 'sense'), ('unobserved', 'sense', 'appear'), ('sense', 'appear', 'data'), ('appear', 'data', 'points'), ('data', 'points', 'xn'), ('points', 'xn', 'D.3'), ('xn', 'D.3', 'The'), ('D.3', 'The', 'relationship'), ('The', 'relationship', 'latent'), ('relationship', 'latent', 'variables'), ('latent', 'variables', 'zn'), ('variables', 'zn', 'observable'), ('zn', 'observable', 'variables'), ('observable', 'variables', 'xn'), ('variables', 'xn', 'modelled'), ('xn', 'modelled', 'different'), ('modelled', 'different', 'ways'), ('different', 'ways', ','), ('ways', ',', 'giving'), (',', 'giving', 'rise'), ('giving', 'rise', 'number'), ('rise', 'number', 'different'), ('number', 'different', 'types'), ('different', 'types', 'models'), ('types', 'models', 'unsupervised'), ('models', 'unsupervised', 'learning'), ('unsupervised', 'learning', '.')]

>> POS Tags are: 
 [('Latent', 'JJ'), ('variables', 'NNS'), ('hidden', 'VBP'), ('unobserved', 'JJ'), ('sense', 'NN'), ('appear', 'VBP'), ('data', 'NN'), ('points', 'NNS'), ('xn', 'JJ'), ('D.3', 'NNP'), ('The', 'DT'), ('relationship', 'NN'), ('latent', 'JJ'), ('variables', 'NNS'), ('zn', 'VBP'), ('observable', 'JJ'), ('variables', 'NNS'), ('xn', 'VBP'), ('modelled', 'VBN'), ('different', 'JJ'), ('ways', 'NNS'), (',', ','), ('giving', 'VBG'), ('rise', 'NN'), ('number', 'NN'), ('different', 'JJ'), ('types', 'NNS'), ('models', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Latent/JJ variables/NNS)
  hidden/VBP
  (NP unobserved/JJ sense/NN)
  appear/VBP
  (NP data/NN points/NNS)
  (NP xn/JJ D.3/NNP)
  (NP The/DT relationship/NN)
  (NP latent/JJ variables/NNS)
  zn/VBP
  (NP observable/JJ variables/NNS)
  xn/VBP
  modelled/VBN
  (NP different/JJ ways/NNS)
  ,/,
  giving/VBG
  (NP rise/NN number/NN)
  (NP different/JJ types/NNS models/NNS)
  unsupervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Latent variables', 'unobserved sense', 'data points', 'xn D.3', 'The relationship', 'latent variables', 'observable variables', 'different ways', 'rise number', 'different types models', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Latent', 'latent'), ('variables', 'variabl'), ('hidden', 'hidden'), ('unobserved', 'unobserv'), ('sense', 'sens'), ('appear', 'appear'), ('data', 'data'), ('points', 'point'), ('xn', 'xn'), ('D.3', 'd.3'), ('The', 'the'), ('relationship', 'relationship'), ('latent', 'latent'), ('variables', 'variabl'), ('zn', 'zn'), ('observable', 'observ'), ('variables', 'variabl'), ('xn', 'xn'), ('modelled', 'model'), ('different', 'differ'), ('ways', 'way'), (',', ','), ('giving', 'give'), ('rise', 'rise'), ('number', 'number'), ('different', 'differ'), ('types', 'type'), ('models', 'model'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Latent', 'latent'), ('variables', 'variabl'), ('hidden', 'hidden'), ('unobserved', 'unobserv'), ('sense', 'sens'), ('appear', 'appear'), ('data', 'data'), ('points', 'point'), ('xn', 'xn'), ('D.3', 'd.3'), ('The', 'the'), ('relationship', 'relationship'), ('latent', 'latent'), ('variables', 'variabl'), ('zn', 'zn'), ('observable', 'observ'), ('variables', 'variabl'), ('xn', 'xn'), ('modelled', 'model'), ('different', 'differ'), ('ways', 'way'), (',', ','), ('giving', 'give'), ('rise', 'rise'), ('number', 'number'), ('different', 'differ'), ('types', 'type'), ('models', 'model'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Latent', 'Latent'), ('variables', 'variable'), ('hidden', 'hidden'), ('unobserved', 'unobserved'), ('sense', 'sense'), ('appear', 'appear'), ('data', 'data'), ('points', 'point'), ('xn', 'xn'), ('D.3', 'D.3'), ('The', 'The'), ('relationship', 'relationship'), ('latent', 'latent'), ('variables', 'variable'), ('zn', 'zn'), ('observable', 'observable'), ('variables', 'variable'), ('xn', 'xn'), ('modelled', 'modelled'), ('different', 'different'), ('ways', 'way'), (',', ','), ('giving', 'giving'), ('rise', 'rise'), ('number', 'number'), ('different', 'different'), ('types', 'type'), ('models', 'model'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 401 =============================

These are illustrated in Fig. 


>> Tokens are: 
 ['These', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('These', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('These', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S These/DT illustrated/VBD (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 402 =============================

11 and discussed next. 


>> Tokens are: 
 ['11', 'discussed', 'next', '.']

>> Bigrams are: 
 [('11', 'discussed'), ('discussed', 'next'), ('next', '.')]

>> Trigrams are: 
 [('11', 'discussed', 'next'), ('discussed', 'next', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('discussed', 'JJ'), ('next', 'JJ'), ('.', '.')]

 (S 11/CD discussed/JJ next/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('discussed', 'discuss'), ('next', 'next'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('discussed', 'discuss'), ('next', 'next'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('discussed', 'discussed'), ('next', 'next'), ('.', '.')]



============================ Sentence 403 =============================

By way of a short round-up of types of models, with reference to Fig. 


>> Tokens are: 
 ['By', 'way', 'short', 'round-up', 'types', 'models', ',', 'reference', 'Fig', '.']

>> Bigrams are: 
 [('By', 'way'), ('way', 'short'), ('short', 'round-up'), ('round-up', 'types'), ('types', 'models'), ('models', ','), (',', 'reference'), ('reference', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('By', 'way', 'short'), ('way', 'short', 'round-up'), ('short', 'round-up', 'types'), ('round-up', 'types', 'models'), ('types', 'models', ','), ('models', ',', 'reference'), (',', 'reference', 'Fig'), ('reference', 'Fig', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('way', 'NN'), ('short', 'JJ'), ('round-up', 'NN'), ('types', 'NNS'), ('models', 'NNS'), (',', ','), ('reference', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  By/IN
  (NP way/NN)
  (NP short/JJ round-up/NN types/NNS models/NNS)
  ,/,
  (NP reference/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['way', 'short round-up types models', 'reference Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('way', 'way'), ('short', 'short'), ('round-up', 'round-up'), ('types', 'type'), ('models', 'model'), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('way', 'way'), ('short', 'short'), ('round-up', 'round-up'), ('types', 'type'), ('models', 'model'), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('way', 'way'), ('short', 'short'), ('round-up', 'round-up'), ('types', 'type'), ('models', 'model'), (',', ','), ('reference', 'reference'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 404 =============================

11, directed generative models, illustrated by Fig. 


>> Tokens are: 
 ['11', ',', 'directed', 'generative', 'models', ',', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('11', ','), (',', 'directed'), ('directed', 'generative'), ('generative', 'models'), ('models', ','), (',', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('11', ',', 'directed'), (',', 'directed', 'generative'), ('directed', 'generative', 'models'), ('generative', 'models', ','), ('models', ',', 'illustrated'), (',', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('11', 'CD'), (',', ','), ('directed', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), (',', ','), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  11/CD
  ,/,
  directed/VBD
  (NP generative/JJ models/NNS)
  ,/,
  illustrated/VBD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['generative models', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), (',', ','), ('directed', 'direct'), ('generative', 'gener'), ('models', 'model'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), (',', ','), ('directed', 'direct'), ('generative', 'generat'), ('models', 'model'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), (',', ','), ('directed', 'directed'), ('generative', 'generative'), ('models', 'model'), (',', ','), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 405 =============================

11(a), posit that there exist hidden causes z yielding the observation x. Undirected genera- tive models, represented in Fig. 


>> Tokens are: 
 ['11', '(', ')', ',', 'posit', 'exist', 'hidden', 'causes', 'z', 'yielding', 'observation', 'x.', 'Undirected', 'genera-', 'tive', 'models', ',', 'represented', 'Fig', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', ','), (',', 'posit'), ('posit', 'exist'), ('exist', 'hidden'), ('hidden', 'causes'), ('causes', 'z'), ('z', 'yielding'), ('yielding', 'observation'), ('observation', 'x.'), ('x.', 'Undirected'), ('Undirected', 'genera-'), ('genera-', 'tive'), ('tive', 'models'), ('models', ','), (',', 'represented'), ('represented', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', ','), (')', ',', 'posit'), (',', 'posit', 'exist'), ('posit', 'exist', 'hidden'), ('exist', 'hidden', 'causes'), ('hidden', 'causes', 'z'), ('causes', 'z', 'yielding'), ('z', 'yielding', 'observation'), ('yielding', 'observation', 'x.'), ('observation', 'x.', 'Undirected'), ('x.', 'Undirected', 'genera-'), ('Undirected', 'genera-', 'tive'), ('genera-', 'tive', 'models'), ('tive', 'models', ','), ('models', ',', 'represented'), (',', 'represented', 'Fig'), ('represented', 'Fig', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), (',', ','), ('posit', 'VBP'), ('exist', 'VBP'), ('hidden', 'JJ'), ('causes', 'NNS'), ('z', 'VBP'), ('yielding', 'VBG'), ('observation', 'NN'), ('x.', 'RB'), ('Undirected', 'VBD'), ('genera-', 'JJ'), ('tive', 'JJ'), ('models', 'NNS'), (',', ','), ('represented', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  11/CD
  (/(
  )/)
  ,/,
  posit/VBP
  exist/VBP
  (NP hidden/JJ causes/NNS)
  z/VBP
  yielding/VBG
  (NP observation/NN)
  x./RB
  Undirected/VBD
  (NP genera-/JJ tive/JJ models/NNS)
  ,/,
  represented/VBN
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['hidden causes', 'observation', 'genera- tive models', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('posit', 'posit'), ('exist', 'exist'), ('hidden', 'hidden'), ('causes', 'caus'), ('z', 'z'), ('yielding', 'yield'), ('observation', 'observ'), ('x.', 'x.'), ('Undirected', 'undirect'), ('genera-', 'genera-'), ('tive', 'tive'), ('models', 'model'), (',', ','), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('posit', 'posit'), ('exist', 'exist'), ('hidden', 'hidden'), ('causes', 'caus'), ('z', 'z'), ('yielding', 'yield'), ('observation', 'observ'), ('x.', 'x.'), ('Undirected', 'undirect'), ('genera-', 'genera-'), ('tive', 'tive'), ('models', 'model'), (',', ','), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('posit', 'posit'), ('exist', 'exist'), ('hidden', 'hidden'), ('causes', 'cause'), ('z', 'z'), ('yielding', 'yielding'), ('observation', 'observation'), ('x.', 'x.'), ('Undirected', 'Undirected'), ('genera-', 'genera-'), ('tive', 'tive'), ('models', 'model'), (',', ','), ('represented', 'represented'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 406 =============================

11(b) model the mutual correlation between x and z. Discriminative models, illustrated by Fig. 


>> Tokens are: 
 ['11', '(', 'b', ')', 'model', 'mutual', 'correlation', 'x', 'z.', 'Discriminative', 'models', ',', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('11', '('), ('(', 'b'), ('b', ')'), (')', 'model'), ('model', 'mutual'), ('mutual', 'correlation'), ('correlation', 'x'), ('x', 'z.'), ('z.', 'Discriminative'), ('Discriminative', 'models'), ('models', ','), (',', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('11', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'model'), (')', 'model', 'mutual'), ('model', 'mutual', 'correlation'), ('mutual', 'correlation', 'x'), ('correlation', 'x', 'z.'), ('x', 'z.', 'Discriminative'), ('z.', 'Discriminative', 'models'), ('Discriminative', 'models', ','), ('models', ',', 'illustrated'), (',', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), ('b', 'NN'), (')', ')'), ('model', 'NN'), ('mutual', 'JJ'), ('correlation', 'NN'), ('x', 'NNP'), ('z.', 'NNP'), ('Discriminative', 'NNP'), ('models', 'NNS'), (',', ','), ('illustrated', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  11/CD
  (/(
  (NP b/NN)
  )/)
  (NP model/NN)
  (NP
    mutual/JJ
    correlation/NN
    x/NNP
    z./NNP
    Discriminative/NNP
    models/NNS)
  ,/,
  illustrated/VBD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['b', 'model', 'mutual correlation x z. Discriminative models', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), ('b', 'b'), (')', ')'), ('model', 'model'), ('mutual', 'mutual'), ('correlation', 'correl'), ('x', 'x'), ('z.', 'z.'), ('Discriminative', 'discrimin'), ('models', 'model'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), ('b', 'b'), (')', ')'), ('model', 'model'), ('mutual', 'mutual'), ('correlation', 'correl'), ('x', 'x'), ('z.', 'z.'), ('Discriminative', 'discrimin'), ('models', 'model'), (',', ','), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), ('b', 'b'), (')', ')'), ('model', 'model'), ('mutual', 'mutual'), ('correlation', 'correlation'), ('x', 'x'), ('z.', 'z.'), ('Discriminative', 'Discriminative'), ('models', 'model'), (',', ','), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 407 =============================

11(c) model the extraction of the latent representation z from x. 


>> Tokens are: 
 ['11', '(', 'c', ')', 'model', 'extraction', 'latent', 'representation', 'z', 'x', '.']

>> Bigrams are: 
 [('11', '('), ('(', 'c'), ('c', ')'), (')', 'model'), ('model', 'extraction'), ('extraction', 'latent'), ('latent', 'representation'), ('representation', 'z'), ('z', 'x'), ('x', '.')]

>> Trigrams are: 
 [('11', '(', 'c'), ('(', 'c', ')'), ('c', ')', 'model'), (')', 'model', 'extraction'), ('model', 'extraction', 'latent'), ('extraction', 'latent', 'representation'), ('latent', 'representation', 'z'), ('representation', 'z', 'x'), ('z', 'x', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), ('c', 'NN'), (')', ')'), ('model', 'NN'), ('extraction', 'NN'), ('latent', 'JJ'), ('representation', 'NN'), ('z', 'NN'), ('x', 'NN'), ('.', '.')]

 (S
  11/CD
  (/(
  (NP c/NN)
  )/)
  (NP model/NN extraction/NN)
  (NP latent/JJ representation/NN z/NN x/NN)
  ./.) 


>> Noun Phrases are: 
 ['c', 'model extraction', 'latent representation z x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), ('c', 'c'), (')', ')'), ('model', 'model'), ('extraction', 'extract'), ('latent', 'latent'), ('representation', 'represent'), ('z', 'z'), ('x', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), ('c', 'c'), (')', ')'), ('model', 'model'), ('extraction', 'extract'), ('latent', 'latent'), ('representation', 'represent'), ('z', 'z'), ('x', 'x'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), ('c', 'c'), (')', ')'), ('model', 'model'), ('extraction', 'extraction'), ('latent', 'latent'), ('representation', 'representation'), ('z', 'z'), ('x', 'x'), ('.', '.')]



============================ Sentence 408 =============================

Finally, autoencoders, represented in Fig. 


>> Tokens are: 
 ['Finally', ',', 'autoencoders', ',', 'represented', 'Fig', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'autoencoders'), ('autoencoders', ','), (',', 'represented'), ('represented', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Finally', ',', 'autoencoders'), (',', 'autoencoders', ','), ('autoencoders', ',', 'represented'), (',', 'represented', 'Fig'), ('represented', 'Fig', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('autoencoders', 'NNS'), (',', ','), ('represented', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP autoencoders/NNS)
  ,/,
  represented/VBN
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['autoencoders', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('autoencoders', 'autoencod'), (',', ','), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('autoencoders', 'autoencod'), (',', ','), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('autoencoders', 'autoencoders'), (',', ','), ('represented', 'represented'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 409 =============================

11(d) assume that x is encoded into a latent representation z in such as way that x can then be approximately recovered from z. 


>> Tokens are: 
 ['11', '(', ')', 'assume', 'x', 'encoded', 'latent', 'representation', 'z', 'way', 'x', 'approximately', 'recovered', 'z', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', 'assume'), ('assume', 'x'), ('x', 'encoded'), ('encoded', 'latent'), ('latent', 'representation'), ('representation', 'z'), ('z', 'way'), ('way', 'x'), ('x', 'approximately'), ('approximately', 'recovered'), ('recovered', 'z'), ('z', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', 'assume'), (')', 'assume', 'x'), ('assume', 'x', 'encoded'), ('x', 'encoded', 'latent'), ('encoded', 'latent', 'representation'), ('latent', 'representation', 'z'), ('representation', 'z', 'way'), ('z', 'way', 'x'), ('way', 'x', 'approximately'), ('x', 'approximately', 'recovered'), ('approximately', 'recovered', 'z'), ('recovered', 'z', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), ('assume', 'VBP'), ('x', '$'), ('encoded', 'JJ'), ('latent', 'NN'), ('representation', 'NN'), ('z', 'NNP'), ('way', 'NN'), ('x', 'NNP'), ('approximately', 'RB'), ('recovered', 'VBD'), ('z', 'NN'), ('.', '.')]

 (S
  11/CD
  (/(
  )/)
  assume/VBP
  x/$
  (NP encoded/JJ latent/NN representation/NN z/NNP way/NN x/NNP)
  approximately/RB
  recovered/VBD
  (NP z/NN)
  ./.) 


>> Noun Phrases are: 
 ['encoded latent representation z way x', 'z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), ('assume', 'assum'), ('x', 'x'), ('encoded', 'encod'), ('latent', 'latent'), ('representation', 'represent'), ('z', 'z'), ('way', 'way'), ('x', 'x'), ('approximately', 'approxim'), ('recovered', 'recov'), ('z', 'z'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), ('assume', 'assum'), ('x', 'x'), ('encoded', 'encod'), ('latent', 'latent'), ('representation', 'represent'), ('z', 'z'), ('way', 'way'), ('x', 'x'), ('approximately', 'approxim'), ('recovered', 'recov'), ('z', 'z'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), ('assume', 'assume'), ('x', 'x'), ('encoded', 'encoded'), ('latent', 'latent'), ('representation', 'representation'), ('z', 'z'), ('way', 'way'), ('x', 'x'), ('approximately', 'approximately'), ('recovered', 'recovered'), ('z', 'z'), ('.', '.')]



============================ Sentence 410 =============================

In the following, we provide some additional details about directed generative  3Problems in which some of the inputs in D are labelled by a value zn are filed under the rubric of semi-supervised learning [29]. 


>> Tokens are: 
 ['In', 'following', ',', 'provide', 'additional', 'details', 'directed', 'generative', '3Problems', 'inputs', 'D', 'labelled', 'value', 'zn', 'filed', 'rubric', 'semi-supervised', 'learning', '[', '29', ']', '.']

>> Bigrams are: 
 [('In', 'following'), ('following', ','), (',', 'provide'), ('provide', 'additional'), ('additional', 'details'), ('details', 'directed'), ('directed', 'generative'), ('generative', '3Problems'), ('3Problems', 'inputs'), ('inputs', 'D'), ('D', 'labelled'), ('labelled', 'value'), ('value', 'zn'), ('zn', 'filed'), ('filed', 'rubric'), ('rubric', 'semi-supervised'), ('semi-supervised', 'learning'), ('learning', '['), ('[', '29'), ('29', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'following', ','), ('following', ',', 'provide'), (',', 'provide', 'additional'), ('provide', 'additional', 'details'), ('additional', 'details', 'directed'), ('details', 'directed', 'generative'), ('directed', 'generative', '3Problems'), ('generative', '3Problems', 'inputs'), ('3Problems', 'inputs', 'D'), ('inputs', 'D', 'labelled'), ('D', 'labelled', 'value'), ('labelled', 'value', 'zn'), ('value', 'zn', 'filed'), ('zn', 'filed', 'rubric'), ('filed', 'rubric', 'semi-supervised'), ('rubric', 'semi-supervised', 'learning'), ('semi-supervised', 'learning', '['), ('learning', '[', '29'), ('[', '29', ']'), ('29', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('following', 'VBG'), (',', ','), ('provide', 'VBP'), ('additional', 'JJ'), ('details', 'NNS'), ('directed', 'VBD'), ('generative', 'JJ'), ('3Problems', 'CD'), ('inputs', 'NNS'), ('D', 'NNP'), ('labelled', 'VBD'), ('value', 'NN'), ('zn', 'NN'), ('filed', 'VBN'), ('rubric', 'JJ'), ('semi-supervised', 'JJ'), ('learning', 'NN'), ('[', '$'), ('29', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  In/IN
  following/VBG
  ,/,
  provide/VBP
  (NP additional/JJ details/NNS)
  directed/VBD
  generative/JJ
  3Problems/CD
  (NP inputs/NNS D/NNP)
  labelled/VBD
  (NP value/NN zn/NN)
  filed/VBN
  (NP rubric/JJ semi-supervised/JJ learning/NN)
  [/$
  29/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['additional details', 'inputs D', 'value zn', 'rubric semi-supervised learning', ']']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('following', 'follow'), (',', ','), ('provide', 'provid'), ('additional', 'addit'), ('details', 'detail'), ('directed', 'direct'), ('generative', 'gener'), ('3Problems', '3problem'), ('inputs', 'input'), ('D', 'd'), ('labelled', 'label'), ('value', 'valu'), ('zn', 'zn'), ('filed', 'file'), ('rubric', 'rubric'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('following', 'follow'), (',', ','), ('provide', 'provid'), ('additional', 'addit'), ('details', 'detail'), ('directed', 'direct'), ('generative', 'generat'), ('3Problems', '3problem'), ('inputs', 'input'), ('D', 'd'), ('labelled', 'label'), ('value', 'valu'), ('zn', 'zn'), ('filed', 'file'), ('rubric', 'rubric'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('following', 'following'), (',', ','), ('provide', 'provide'), ('additional', 'additional'), ('details', 'detail'), ('directed', 'directed'), ('generative', 'generative'), ('3Problems', '3Problems'), ('inputs', 'input'), ('D', 'D'), ('labelled', 'labelled'), ('value', 'value'), ('zn', 'zn'), ('filed', 'filed'), ('rubric', 'rubric'), ('semi-supervised', 'semi-supervised'), ('learning', 'learning'), ('[', '['), ('29', '29'), (']', ']'), ('.', '.')]



============================ Sentence 411 =============================

Fig. 


>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

 (S (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]



============================ Sentence 412 =============================

11. 


>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

 (S 11/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]



============================ Sentence 413 =============================

Illustration of typical unsupervised learning models: (a) directed generative models; (b) undirected generative models; (c) discriminative models; and (d) autoencoders. 


>> Tokens are: 
 ['Illustration', 'typical', 'unsupervised', 'learning', 'models', ':', '(', ')', 'directed', 'generative', 'models', ';', '(', 'b', ')', 'undirected', 'generative', 'models', ';', '(', 'c', ')', 'discriminative', 'models', ';', '(', ')', 'autoencoders', '.']

>> Bigrams are: 
 [('Illustration', 'typical'), ('typical', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'models'), ('models', ':'), (':', '('), ('(', ')'), (')', 'directed'), ('directed', 'generative'), ('generative', 'models'), ('models', ';'), (';', '('), ('(', 'b'), ('b', ')'), (')', 'undirected'), ('undirected', 'generative'), ('generative', 'models'), ('models', ';'), (';', '('), ('(', 'c'), ('c', ')'), (')', 'discriminative'), ('discriminative', 'models'), ('models', ';'), (';', '('), ('(', ')'), (')', 'autoencoders'), ('autoencoders', '.')]

>> Trigrams are: 
 [('Illustration', 'typical', 'unsupervised'), ('typical', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'models'), ('learning', 'models', ':'), ('models', ':', '('), (':', '(', ')'), ('(', ')', 'directed'), (')', 'directed', 'generative'), ('directed', 'generative', 'models'), ('generative', 'models', ';'), ('models', ';', '('), (';', '(', 'b'), ('(', 'b', ')'), ('b', ')', 'undirected'), (')', 'undirected', 'generative'), ('undirected', 'generative', 'models'), ('generative', 'models', ';'), ('models', ';', '('), (';', '(', 'c'), ('(', 'c', ')'), ('c', ')', 'discriminative'), (')', 'discriminative', 'models'), ('discriminative', 'models', ';'), ('models', ';', '('), (';', '(', ')'), ('(', ')', 'autoencoders'), (')', 'autoencoders', '.')]

>> POS Tags are: 
 [('Illustration', 'NNP'), ('typical', 'JJ'), ('unsupervised', 'VBD'), ('learning', 'JJ'), ('models', 'NNS'), (':', ':'), ('(', '('), (')', ')'), ('directed', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), (';', ':'), ('(', '('), ('b', 'NN'), (')', ')'), ('undirected', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), (';', ':'), ('(', '('), ('c', 'NN'), (')', ')'), ('discriminative', 'JJ'), ('models', 'NNS'), (';', ':'), ('(', '('), (')', ')'), ('autoencoders', 'NNS'), ('.', '.')]

 (S
  (NP Illustration/NNP)
  typical/JJ
  unsupervised/VBD
  (NP learning/JJ models/NNS)
  :/:
  (/(
  )/)
  directed/VBD
  (NP generative/JJ models/NNS)
  ;/:
  (/(
  (NP b/NN)
  )/)
  undirected/VBD
  (NP generative/JJ models/NNS)
  ;/:
  (/(
  (NP c/NN)
  )/)
  (NP discriminative/JJ models/NNS)
  ;/:
  (/(
  )/)
  (NP autoencoders/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Illustration', 'learning models', 'generative models', 'b', 'generative models', 'c', 'discriminative models', 'autoencoders']

>> Named Entities are: 
 [('GPE', 'Illustration')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('typical', 'typic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('models', 'model'), (':', ':'), ('(', '('), (')', ')'), ('directed', 'direct'), ('generative', 'gener'), ('models', 'model'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('undirected', 'undirect'), ('generative', 'gener'), ('models', 'model'), (';', ';'), ('(', '('), ('c', 'c'), (')', ')'), ('discriminative', 'discrimin'), ('models', 'model'), (';', ';'), ('(', '('), (')', ')'), ('autoencoders', 'autoencod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('typical', 'typic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('models', 'model'), (':', ':'), ('(', '('), (')', ')'), ('directed', 'direct'), ('generative', 'generat'), ('models', 'model'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('undirected', 'undirect'), ('generative', 'generat'), ('models', 'model'), (';', ';'), ('(', '('), ('c', 'c'), (')', ')'), ('discriminative', 'discrimin'), ('models', 'model'), (';', ';'), ('(', '('), (')', ')'), ('autoencoders', 'autoencod'), ('.', '.')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('typical', 'typical'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('models', 'model'), (':', ':'), ('(', '('), (')', ')'), ('directed', 'directed'), ('generative', 'generative'), ('models', 'model'), (';', ';'), ('(', '('), ('b', 'b'), (')', ')'), ('undirected', 'undirected'), ('generative', 'generative'), ('models', 'model'), (';', ';'), ('(', '('), ('c', 'c'), (')', ')'), ('discriminative', 'discriminative'), ('models', 'model'), (';', ';'), ('(', '('), (')', ')'), ('autoencoders', 'autoencoders'), ('.', '.')]



============================ Sentence 414 =============================

models and autoencoders, and we point to [19] and references therein for a discussion about the remaining models. 


>> Tokens are: 
 ['models', 'autoencoders', ',', 'point', '[', '19', ']', 'references', 'therein', 'discussion', 'remaining', 'models', '.']

>> Bigrams are: 
 [('models', 'autoencoders'), ('autoencoders', ','), (',', 'point'), ('point', '['), ('[', '19'), ('19', ']'), (']', 'references'), ('references', 'therein'), ('therein', 'discussion'), ('discussion', 'remaining'), ('remaining', 'models'), ('models', '.')]

>> Trigrams are: 
 [('models', 'autoencoders', ','), ('autoencoders', ',', 'point'), (',', 'point', '['), ('point', '[', '19'), ('[', '19', ']'), ('19', ']', 'references'), (']', 'references', 'therein'), ('references', 'therein', 'discussion'), ('therein', 'discussion', 'remaining'), ('discussion', 'remaining', 'models'), ('remaining', 'models', '.')]

>> POS Tags are: 
 [('models', 'NNS'), ('autoencoders', 'NNS'), (',', ','), ('point', 'NN'), ('[', 'VBD'), ('19', 'CD'), (']', 'JJ'), ('references', 'NNS'), ('therein', 'JJ'), ('discussion', 'NN'), ('remaining', 'VBG'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP models/NNS autoencoders/NNS)
  ,/,
  (NP point/NN)
  [/VBD
  19/CD
  (NP ]/JJ references/NNS)
  (NP therein/JJ discussion/NN)
  remaining/VBG
  (NP models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['models autoencoders', 'point', '] references', 'therein discussion', 'models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('models', 'model'), ('autoencoders', 'autoencod'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), ('discussion', 'discuss'), ('remaining', 'remain'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('models', 'model'), ('autoencoders', 'autoencod'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), ('discussion', 'discuss'), ('remaining', 'remain'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('models', 'model'), ('autoencoders', 'autoencoders'), (',', ','), ('point', 'point'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'reference'), ('therein', 'therein'), ('discussion', 'discussion'), ('remaining', 'remaining'), ('models', 'model'), ('.', '.')]



============================ Sentence 415 =============================

As illustrated in Fig. 


>> Tokens are: 
 ['As', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('As', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN (NP illustrated/JJ Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 416 =============================

11(a), directed generative models assume that each data point x is caused4 by a hidden variable z. 


>> Tokens are: 
 ['11', '(', ')', ',', 'directed', 'generative', 'models', 'assume', 'data', 'point', 'x', 'caused4', 'hidden', 'variable', 'z', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', ','), (',', 'directed'), ('directed', 'generative'), ('generative', 'models'), ('models', 'assume'), ('assume', 'data'), ('data', 'point'), ('point', 'x'), ('x', 'caused4'), ('caused4', 'hidden'), ('hidden', 'variable'), ('variable', 'z'), ('z', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', ','), (')', ',', 'directed'), (',', 'directed', 'generative'), ('directed', 'generative', 'models'), ('generative', 'models', 'assume'), ('models', 'assume', 'data'), ('assume', 'data', 'point'), ('data', 'point', 'x'), ('point', 'x', 'caused4'), ('x', 'caused4', 'hidden'), ('caused4', 'hidden', 'variable'), ('hidden', 'variable', 'z'), ('variable', 'z', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), (',', ','), ('directed', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), ('assume', 'VBP'), ('data', 'NNS'), ('point', 'NN'), ('x', 'NNP'), ('caused4', 'NN'), ('hidden', 'NN'), ('variable', 'JJ'), ('z', 'NN'), ('.', '.')]

 (S
  11/CD
  (/(
  )/)
  ,/,
  directed/VBD
  (NP generative/JJ models/NNS)
  assume/VBP
  (NP data/NNS point/NN x/NNP caused4/NN hidden/NN)
  (NP variable/JJ z/NN)
  ./.) 


>> Noun Phrases are: 
 ['generative models', 'data point x caused4 hidden', 'variable z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('directed', 'direct'), ('generative', 'gener'), ('models', 'model'), ('assume', 'assum'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('caused4', 'caused4'), ('hidden', 'hidden'), ('variable', 'variabl'), ('z', 'z'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('directed', 'direct'), ('generative', 'generat'), ('models', 'model'), ('assume', 'assum'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('caused4', 'caused4'), ('hidden', 'hidden'), ('variable', 'variabl'), ('z', 'z'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('directed', 'directed'), ('generative', 'generative'), ('models', 'model'), ('assume', 'assume'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('caused4', 'caused4'), ('hidden', 'hidden'), ('variable', 'variable'), ('z', 'z'), ('.', '.')]



============================ Sentence 417 =============================

This is in the sense that the joint distribution p(x, z|θ) is parameterized as p(x, z|θ) = p(z|θ)p(x|z, θ), where p(z|θ) is the distribution of the hidden cause and p(x|z, θ) is the conditional distribution of the data x given the cause z. 


>> Tokens are: 
 ['This', 'sense', 'joint', 'distribution', 'p', '(', 'x', ',', 'z|θ', ')', 'parameterized', 'p', '(', 'x', ',', 'z|θ', ')', '=', 'p', '(', 'z|θ', ')', 'p', '(', 'x|z', ',', 'θ', ')', ',', 'p', '(', 'z|θ', ')', 'distribution', 'hidden', 'cause', 'p', '(', 'x|z', ',', 'θ', ')', 'conditional', 'distribution', 'data', 'x', 'given', 'cause', 'z', '.']

>> Bigrams are: 
 [('This', 'sense'), ('sense', 'joint'), ('joint', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 'z|θ'), ('z|θ', ')'), (')', 'parameterized'), ('parameterized', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 'z|θ'), ('z|θ', ')'), (')', '='), ('=', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ','), (',', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', 'distribution'), ('distribution', 'hidden'), ('hidden', 'cause'), ('cause', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', 'conditional'), ('conditional', 'distribution'), ('distribution', 'data'), ('data', 'x'), ('x', 'given'), ('given', 'cause'), ('cause', 'z'), ('z', '.')]

>> Trigrams are: 
 [('This', 'sense', 'joint'), ('sense', 'joint', 'distribution'), ('joint', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 'z|θ'), (',', 'z|θ', ')'), ('z|θ', ')', 'parameterized'), (')', 'parameterized', 'p'), ('parameterized', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 'z|θ'), (',', 'z|θ', ')'), ('z|θ', ')', '='), (')', '=', 'p'), ('=', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', 'p'), (')', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ','), (')', ',', 'p'), (',', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', 'distribution'), (')', 'distribution', 'hidden'), ('distribution', 'hidden', 'cause'), ('hidden', 'cause', 'p'), ('cause', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'conditional'), (')', 'conditional', 'distribution'), ('conditional', 'distribution', 'data'), ('distribution', 'data', 'x'), ('data', 'x', 'given'), ('x', 'given', 'cause'), ('given', 'cause', 'z'), ('cause', 'z', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('sense', 'NN'), ('joint', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'UH'), (',', ','), ('z|θ', 'NN'), (')', ')'), ('parameterized', 'VBD'), ('p', 'NN'), ('(', '('), ('x', 'UH'), (',', ','), ('z|θ', 'NN'), (')', ')'), ('=', 'NN'), ('p', 'NN'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (',', ','), ('p', 'FW'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('distribution', 'NN'), ('hidden', 'VBN'), ('cause', 'NN'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), ('conditional', 'JJ'), ('distribution', 'NN'), ('data', 'NNS'), ('x', 'VBD'), ('given', 'VBN'), ('cause', 'NN'), ('z', 'NN'), ('.', '.')]

 (S
  (NP This/DT sense/NN)
  (NP joint/JJ distribution/NN p/NN)
  (/(
  x/UH
  ,/,
  (NP z|θ/NN)
  )/)
  parameterized/VBD
  (NP p/NN)
  (/(
  x/UH
  ,/,
  (NP z|θ/NN)
  )/)
  (NP =/NN p/NN)
  (/(
  (NP z|θ/NN)
  )/)
  (NP p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  ,/,
  p/FW
  (/(
  (NP z|θ/NN)
  )/)
  (NP distribution/NN)
  hidden/VBN
  (NP cause/NN p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  (NP conditional/JJ distribution/NN data/NNS)
  x/VBD
  given/VBN
  (NP cause/NN z/NN)
  ./.) 


>> Noun Phrases are: 
 ['This sense', 'joint distribution p', 'z|θ', 'p', 'z|θ', '= p', 'z|θ', 'p', 'θ', 'z|θ', 'distribution', 'cause p', 'θ', 'conditional distribution data', 'cause z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('sense', 'sens'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('parameterized', 'parameter'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('cause', 'caus'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('conditional', 'condit'), ('distribution', 'distribut'), ('data', 'data'), ('x', 'x'), ('given', 'given'), ('cause', 'caus'), ('z', 'z'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('sense', 'sens'), ('joint', 'joint'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('parameterized', 'parameter'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('cause', 'caus'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('conditional', 'condit'), ('distribution', 'distribut'), ('data', 'data'), ('x', 'x'), ('given', 'given'), ('cause', 'caus'), ('z', 'z'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('sense', 'sense'), ('joint', 'joint'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('parameterized', 'parameterized'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('distribution', 'distribution'), ('hidden', 'hidden'), ('cause', 'cause'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('conditional', 'conditional'), ('distribution', 'distribution'), ('data', 'data'), ('x', 'x'), ('given', 'given'), ('cause', 'cause'), ('z', 'z'), ('.', '.')]



============================ Sentence 418 =============================

As a result, under a directed generative model, the distribution of an observation x = x can be written as  p(x|θ) = ∑ z  p(z|θ)p(x|z, θ) = Ez∼p(z|θ)[ln p(x|z, θ)],  (13) where the sum in the second term should be replaced by an integration for continuous hidden variables, and the last equality expresses the marginalization over z as an expectation. 


>> Tokens are: 
 ['As', 'result', ',', 'directed', 'generative', 'model', ',', 'distribution', 'observation', 'x', '=', 'x', 'written', 'p', '(', 'x|θ', ')', '=', '∑', 'z', 'p', '(', 'z|θ', ')', 'p', '(', 'x|z', ',', 'θ', ')', '=', 'Ez∼p', '(', 'z|θ', ')', '[', 'ln', 'p', '(', 'x|z', ',', 'θ', ')', ']', ',', '(', '13', ')', 'sum', 'second', 'term', 'replaced', 'integration', 'continuous', 'hidden', 'variables', ',', 'last', 'equality', 'expresses', 'marginalization', 'z', 'expectation', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'directed'), ('directed', 'generative'), ('generative', 'model'), ('model', ','), (',', 'distribution'), ('distribution', 'observation'), ('observation', 'x'), ('x', '='), ('=', 'x'), ('x', 'written'), ('written', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', '='), ('=', '∑'), ('∑', 'z'), ('z', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', '='), ('=', 'Ez∼p'), ('Ez∼p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', '['), ('[', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ']'), (']', ','), (',', '('), ('(', '13'), ('13', ')'), (')', 'sum'), ('sum', 'second'), ('second', 'term'), ('term', 'replaced'), ('replaced', 'integration'), ('integration', 'continuous'), ('continuous', 'hidden'), ('hidden', 'variables'), ('variables', ','), (',', 'last'), ('last', 'equality'), ('equality', 'expresses'), ('expresses', 'marginalization'), ('marginalization', 'z'), ('z', 'expectation'), ('expectation', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'directed'), (',', 'directed', 'generative'), ('directed', 'generative', 'model'), ('generative', 'model', ','), ('model', ',', 'distribution'), (',', 'distribution', 'observation'), ('distribution', 'observation', 'x'), ('observation', 'x', '='), ('x', '=', 'x'), ('=', 'x', 'written'), ('x', 'written', 'p'), ('written', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', '='), (')', '=', '∑'), ('=', '∑', 'z'), ('∑', 'z', 'p'), ('z', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', 'p'), (')', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '='), (')', '=', 'Ez∼p'), ('=', 'Ez∼p', '('), ('Ez∼p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', '['), (')', '[', 'ln'), ('[', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ']'), (')', ']', ','), (']', ',', '('), (',', '(', '13'), ('(', '13', ')'), ('13', ')', 'sum'), (')', 'sum', 'second'), ('sum', 'second', 'term'), ('second', 'term', 'replaced'), ('term', 'replaced', 'integration'), ('replaced', 'integration', 'continuous'), ('integration', 'continuous', 'hidden'), ('continuous', 'hidden', 'variables'), ('hidden', 'variables', ','), ('variables', ',', 'last'), (',', 'last', 'equality'), ('last', 'equality', 'expresses'), ('equality', 'expresses', 'marginalization'), ('expresses', 'marginalization', 'z'), ('marginalization', 'z', 'expectation'), ('z', 'expectation', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('directed', 'VBD'), ('generative', 'JJ'), ('model', 'NN'), (',', ','), ('distribution', 'NN'), ('observation', 'NN'), ('x', 'NNP'), ('=', 'NNP'), ('x', 'NNP'), ('written', 'VBN'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('∑', 'JJ'), ('z', 'NN'), ('p', 'NN'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('Ez∼p', 'NNP'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('[', 'VBZ'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (']', 'NN'), (',', ','), ('(', '('), ('13', 'CD'), (')', ')'), ('sum', 'NN'), ('second', 'JJ'), ('term', 'NN'), ('replaced', 'VBD'), ('integration', 'NN'), ('continuous', 'JJ'), ('hidden', 'NN'), ('variables', 'NNS'), (',', ','), ('last', 'JJ'), ('equality', 'NN'), ('expresses', 'VBZ'), ('marginalization', 'NN'), ('z', 'NN'), ('expectation', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP result/NN)
  ,/,
  directed/VBD
  (NP generative/JJ model/NN)
  ,/,
  (NP distribution/NN observation/NN x/NNP =/NNP x/NNP)
  written/VBN
  (NP p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  =/VBP
  (NP ∑/JJ z/NN p/NN)
  (/(
  (NP z|θ/NN)
  )/)
  (NP p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  =/VBP
  (NP Ez∼p/NNP)
  (/(
  (NP z|θ/NN)
  )/)
  [/VBZ
  (NP ln/JJ p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  (NP ]/NN)
  ,/,
  (/(
  13/CD
  )/)
  (NP sum/NN)
  (NP second/JJ term/NN)
  replaced/VBD
  (NP integration/NN)
  (NP continuous/JJ hidden/NN variables/NNS)
  ,/,
  (NP last/JJ equality/NN)
  expresses/VBZ
  (NP marginalization/NN z/NN expectation/NN)
  ./.) 


>> Noun Phrases are: 
 ['result', 'generative model', 'distribution observation x = x', 'p', 'x|θ', '∑ z p', 'z|θ', 'p', 'θ', 'Ez∼p', 'z|θ', 'ln p', 'θ', ']', 'sum', 'second term', 'integration', 'continuous hidden variables', 'last equality', 'marginalization z expectation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('directed', 'direct'), ('generative', 'gener'), ('model', 'model'), (',', ','), ('distribution', 'distribut'), ('observation', 'observ'), ('x', 'x'), ('=', '='), ('x', 'x'), ('written', 'written'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('∑', '∑'), ('z', 'z'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼p', 'ez∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('13', '13'), (')', ')'), ('sum', 'sum'), ('second', 'second'), ('term', 'term'), ('replaced', 'replac'), ('integration', 'integr'), ('continuous', 'continu'), ('hidden', 'hidden'), ('variables', 'variabl'), (',', ','), ('last', 'last'), ('equality', 'equal'), ('expresses', 'express'), ('marginalization', 'margin'), ('z', 'z'), ('expectation', 'expect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('directed', 'direct'), ('generative', 'generat'), ('model', 'model'), (',', ','), ('distribution', 'distribut'), ('observation', 'observ'), ('x', 'x'), ('=', '='), ('x', 'x'), ('written', 'written'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('∑', '∑'), ('z', 'z'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼p', 'ez∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('13', '13'), (')', ')'), ('sum', 'sum'), ('second', 'second'), ('term', 'term'), ('replaced', 'replac'), ('integration', 'integr'), ('continuous', 'continu'), ('hidden', 'hidden'), ('variables', 'variabl'), (',', ','), ('last', 'last'), ('equality', 'equal'), ('expresses', 'express'), ('marginalization', 'margin'), ('z', 'z'), ('expectation', 'expect'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('directed', 'directed'), ('generative', 'generative'), ('model', 'model'), (',', ','), ('distribution', 'distribution'), ('observation', 'observation'), ('x', 'x'), ('=', '='), ('x', 'x'), ('written', 'written'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('∑', '∑'), ('z', 'z'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼p', 'Ez∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('13', '13'), (')', ')'), ('sum', 'sum'), ('second', 'second'), ('term', 'term'), ('replaced', 'replaced'), ('integration', 'integration'), ('continuous', 'continuous'), ('hidden', 'hidden'), ('variables', 'variable'), (',', ','), ('last', 'last'), ('equality', 'equality'), ('expresses', 'express'), ('marginalization', 'marginalization'), ('z', 'z'), ('expectation', 'expectation'), ('.', '.')]



============================ Sentence 419 =============================

As an example, for the problem of document clus- tering, variable x represents a document in the training set and z is interpreted as a latent topic that “causes” the generation of the document. 


>> Tokens are: 
 ['As', 'example', ',', 'problem', 'document', 'clus-', 'tering', ',', 'variable', 'x', 'represents', 'document', 'training', 'set', 'z', 'interpreted', 'latent', 'topic', '“', 'causes', '”', 'generation', 'document', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'problem'), ('problem', 'document'), ('document', 'clus-'), ('clus-', 'tering'), ('tering', ','), (',', 'variable'), ('variable', 'x'), ('x', 'represents'), ('represents', 'document'), ('document', 'training'), ('training', 'set'), ('set', 'z'), ('z', 'interpreted'), ('interpreted', 'latent'), ('latent', 'topic'), ('topic', '“'), ('“', 'causes'), ('causes', '”'), ('”', 'generation'), ('generation', 'document'), ('document', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'problem'), (',', 'problem', 'document'), ('problem', 'document', 'clus-'), ('document', 'clus-', 'tering'), ('clus-', 'tering', ','), ('tering', ',', 'variable'), (',', 'variable', 'x'), ('variable', 'x', 'represents'), ('x', 'represents', 'document'), ('represents', 'document', 'training'), ('document', 'training', 'set'), ('training', 'set', 'z'), ('set', 'z', 'interpreted'), ('z', 'interpreted', 'latent'), ('interpreted', 'latent', 'topic'), ('latent', 'topic', '“'), ('topic', '“', 'causes'), ('“', 'causes', '”'), ('causes', '”', 'generation'), ('”', 'generation', 'document'), ('generation', 'document', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('problem', 'NN'), ('document', 'NN'), ('clus-', 'NN'), ('tering', 'NN'), (',', ','), ('variable', 'JJ'), ('x', 'NN'), ('represents', 'VBZ'), ('document', 'JJ'), ('training', 'NN'), ('set', 'VBN'), ('z', 'NN'), ('interpreted', 'JJ'), ('latent', 'NN'), ('topic', 'NN'), ('“', 'NNP'), ('causes', 'VBZ'), ('”', 'JJ'), ('generation', 'NN'), ('document', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  (NP problem/NN document/NN clus-/NN tering/NN)
  ,/,
  (NP variable/JJ x/NN)
  represents/VBZ
  (NP document/JJ training/NN)
  set/VBN
  (NP z/NN)
  (NP interpreted/JJ latent/NN topic/NN “/NNP)
  causes/VBZ
  (NP ”/JJ generation/NN document/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'problem document clus- tering', 'variable x', 'document training', 'z', 'interpreted latent topic “', '” generation document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('problem', 'problem'), ('document', 'document'), ('clus-', 'clus-'), ('tering', 'tere'), (',', ','), ('variable', 'variabl'), ('x', 'x'), ('represents', 'repres'), ('document', 'document'), ('training', 'train'), ('set', 'set'), ('z', 'z'), ('interpreted', 'interpret'), ('latent', 'latent'), ('topic', 'topic'), ('“', '“'), ('causes', 'caus'), ('”', '”'), ('generation', 'gener'), ('document', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('problem', 'problem'), ('document', 'document'), ('clus-', 'clus-'), ('tering', 'tere'), (',', ','), ('variable', 'variabl'), ('x', 'x'), ('represents', 'repres'), ('document', 'document'), ('training', 'train'), ('set', 'set'), ('z', 'z'), ('interpreted', 'interpret'), ('latent', 'latent'), ('topic', 'topic'), ('“', '“'), ('causes', 'caus'), ('”', '”'), ('generation', 'generat'), ('document', 'document'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('problem', 'problem'), ('document', 'document'), ('clus-', 'clus-'), ('tering', 'tering'), (',', ','), ('variable', 'variable'), ('x', 'x'), ('represents', 'represents'), ('document', 'document'), ('training', 'training'), ('set', 'set'), ('z', 'z'), ('interpreted', 'interpreted'), ('latent', 'latent'), ('topic', 'topic'), ('“', '“'), ('causes', 'cause'), ('”', '”'), ('generation', 'generation'), ('document', 'document'), ('.', '.')]



============================ Sentence 420 =============================

Model selection requires the specification of a parameterized distribution p(z|θ) over the topics, e.g.-.-, a categorical distribution with parameters equals to the probability of each possible value, and the distribution p(x|z, θ) of the document given a topic. 


>> Tokens are: 
 ['Model', 'selection', 'requires', 'specification', 'parameterized', 'distribution', 'p', '(', 'z|θ', ')', 'topics', ',', 'e.g.-.-', ',', 'categorical', 'distribution', 'parameters', 'equals', 'probability', 'possible', 'value', ',', 'distribution', 'p', '(', 'x|z', ',', 'θ', ')', 'document', 'given', 'topic', '.']

>> Bigrams are: 
 [('Model', 'selection'), ('selection', 'requires'), ('requires', 'specification'), ('specification', 'parameterized'), ('parameterized', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', 'topics'), ('topics', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'categorical'), ('categorical', 'distribution'), ('distribution', 'parameters'), ('parameters', 'equals'), ('equals', 'probability'), ('probability', 'possible'), ('possible', 'value'), ('value', ','), (',', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', 'document'), ('document', 'given'), ('given', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('Model', 'selection', 'requires'), ('selection', 'requires', 'specification'), ('requires', 'specification', 'parameterized'), ('specification', 'parameterized', 'distribution'), ('parameterized', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', 'topics'), (')', 'topics', ','), ('topics', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'categorical'), (',', 'categorical', 'distribution'), ('categorical', 'distribution', 'parameters'), ('distribution', 'parameters', 'equals'), ('parameters', 'equals', 'probability'), ('equals', 'probability', 'possible'), ('probability', 'possible', 'value'), ('possible', 'value', ','), ('value', ',', 'distribution'), (',', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'document'), (')', 'document', 'given'), ('document', 'given', 'topic'), ('given', 'topic', '.')]

>> POS Tags are: 
 [('Model', 'NNP'), ('selection', 'NN'), ('requires', 'VBZ'), ('specification', 'JJ'), ('parameterized', 'VBN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('topics', 'NNS'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('categorical', 'JJ'), ('distribution', 'NN'), ('parameters', 'NNS'), ('equals', 'VBP'), ('probability', 'NN'), ('possible', 'JJ'), ('value', 'NN'), (',', ','), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), ('document', 'NN'), ('given', 'VBN'), ('topic', 'NN'), ('.', '.')]

 (S
  (NP Model/NNP selection/NN)
  requires/VBZ
  specification/JJ
  parameterized/VBN
  (NP distribution/NN p/NN)
  (/(
  (NP z|θ/NN)
  )/)
  (NP topics/NNS)
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP categorical/JJ distribution/NN parameters/NNS)
  equals/VBP
  (NP probability/NN)
  (NP possible/JJ value/NN)
  ,/,
  (NP distribution/NN p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  (NP document/NN)
  given/VBN
  (NP topic/NN)
  ./.) 


>> Noun Phrases are: 
 ['Model selection', 'distribution p', 'z|θ', 'topics', 'categorical distribution parameters', 'probability', 'possible value', 'distribution p', 'θ', 'document', 'topic']

>> Named Entities are: 
 [('GPE', 'Model')] 

>> Stemming using Porter Stemmer: 
 [('Model', 'model'), ('selection', 'select'), ('requires', 'requir'), ('specification', 'specif'), ('parameterized', 'parameter'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('topics', 'topic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('categorical', 'categor'), ('distribution', 'distribut'), ('parameters', 'paramet'), ('equals', 'equal'), ('probability', 'probabl'), ('possible', 'possibl'), ('value', 'valu'), (',', ','), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('document', 'document'), ('given', 'given'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Model', 'model'), ('selection', 'select'), ('requires', 'requir'), ('specification', 'specif'), ('parameterized', 'parameter'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('topics', 'topic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('categorical', 'categor'), ('distribution', 'distribut'), ('parameters', 'paramet'), ('equals', 'equal'), ('probability', 'probabl'), ('possible', 'possibl'), ('value', 'valu'), (',', ','), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('document', 'document'), ('given', 'given'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('Model', 'Model'), ('selection', 'selection'), ('requires', 'requires'), ('specification', 'specification'), ('parameterized', 'parameterized'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('topics', 'topic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('categorical', 'categorical'), ('distribution', 'distribution'), ('parameters', 'parameter'), ('equals', 'equal'), ('probability', 'probability'), ('possible', 'possible'), ('value', 'value'), (',', ','), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('document', 'document'), ('given', 'given'), ('topic', 'topic'), ('.', '.')]



============================ Sentence 421 =============================

Basic representatives of directed generative models include mixture of Gaussians and likelihood-free models [19], [58]. 


>> Tokens are: 
 ['Basic', 'representatives', 'directed', 'generative', 'models', 'include', 'mixture', 'Gaussians', 'likelihood-free', 'models', '[', '19', ']', ',', '[', '58', ']', '.']

>> Bigrams are: 
 [('Basic', 'representatives'), ('representatives', 'directed'), ('directed', 'generative'), ('generative', 'models'), ('models', 'include'), ('include', 'mixture'), ('mixture', 'Gaussians'), ('Gaussians', 'likelihood-free'), ('likelihood-free', 'models'), ('models', '['), ('[', '19'), ('19', ']'), (']', ','), (',', '['), ('[', '58'), ('58', ']'), (']', '.')]

>> Trigrams are: 
 [('Basic', 'representatives', 'directed'), ('representatives', 'directed', 'generative'), ('directed', 'generative', 'models'), ('generative', 'models', 'include'), ('models', 'include', 'mixture'), ('include', 'mixture', 'Gaussians'), ('mixture', 'Gaussians', 'likelihood-free'), ('Gaussians', 'likelihood-free', 'models'), ('likelihood-free', 'models', '['), ('models', '[', '19'), ('[', '19', ']'), ('19', ']', ','), (']', ',', '['), (',', '[', '58'), ('[', '58', ']'), ('58', ']', '.')]

>> POS Tags are: 
 [('Basic', 'JJ'), ('representatives', 'NNS'), ('directed', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), ('include', 'VBP'), ('mixture', 'JJ'), ('Gaussians', 'NNPS'), ('likelihood-free', 'JJ'), ('models', 'NNS'), ('[', 'VBP'), ('19', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('58', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Basic/JJ representatives/NNS)
  directed/VBD
  (NP generative/JJ models/NNS)
  include/VBP
  mixture/JJ
  Gaussians/NNPS
  (NP likelihood-free/JJ models/NNS)
  [/VBP
  19/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  58/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Basic representatives', 'generative models', 'likelihood-free models', ']', ']']

>> Named Entities are: 
 [('GPE', 'Basic')] 

>> Stemming using Porter Stemmer: 
 [('Basic', 'basic'), ('representatives', 'repres'), ('directed', 'direct'), ('generative', 'gener'), ('models', 'model'), ('include', 'includ'), ('mixture', 'mixtur'), ('Gaussians', 'gaussian'), ('likelihood-free', 'likelihood-fre'), ('models', 'model'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Basic', 'basic'), ('representatives', 'repres'), ('directed', 'direct'), ('generative', 'generat'), ('models', 'model'), ('include', 'includ'), ('mixture', 'mixtur'), ('Gaussians', 'gaussian'), ('likelihood-free', 'likelihood-fre'), ('models', 'model'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Basic', 'Basic'), ('representatives', 'representative'), ('directed', 'directed'), ('generative', 'generative'), ('models', 'model'), ('include', 'include'), ('mixture', 'mixture'), ('Gaussians', 'Gaussians'), ('likelihood-free', 'likelihood-free'), ('models', 'model'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]



============================ Sentence 422 =============================

4The use of the term “cause” is meant to be taken in an intuitive, rather than formal, way. 


>> Tokens are: 
 ['4The', 'use', 'term', '“', 'cause', '”', 'meant', 'taken', 'intuitive', ',', 'rather', 'formal', ',', 'way', '.']

>> Bigrams are: 
 [('4The', 'use'), ('use', 'term'), ('term', '“'), ('“', 'cause'), ('cause', '”'), ('”', 'meant'), ('meant', 'taken'), ('taken', 'intuitive'), ('intuitive', ','), (',', 'rather'), ('rather', 'formal'), ('formal', ','), (',', 'way'), ('way', '.')]

>> Trigrams are: 
 [('4The', 'use', 'term'), ('use', 'term', '“'), ('term', '“', 'cause'), ('“', 'cause', '”'), ('cause', '”', 'meant'), ('”', 'meant', 'taken'), ('meant', 'taken', 'intuitive'), ('taken', 'intuitive', ','), ('intuitive', ',', 'rather'), (',', 'rather', 'formal'), ('rather', 'formal', ','), ('formal', ',', 'way'), (',', 'way', '.')]

>> POS Tags are: 
 [('4The', 'CD'), ('use', 'JJ'), ('term', 'NN'), ('“', 'NNP'), ('cause', 'NN'), ('”', 'NN'), ('meant', 'VBD'), ('taken', 'VBN'), ('intuitive', 'JJ'), (',', ','), ('rather', 'RB'), ('formal', 'JJ'), (',', ','), ('way', 'NN'), ('.', '.')]

 (S
  4The/CD
  (NP use/JJ term/NN “/NNP cause/NN ”/NN)
  meant/VBD
  taken/VBN
  intuitive/JJ
  ,/,
  rather/RB
  formal/JJ
  ,/,
  (NP way/NN)
  ./.) 


>> Noun Phrases are: 
 ['use term “ cause ”', 'way']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4The', '4the'), ('use', 'use'), ('term', 'term'), ('“', '“'), ('cause', 'caus'), ('”', '”'), ('meant', 'meant'), ('taken', 'taken'), ('intuitive', 'intuit'), (',', ','), ('rather', 'rather'), ('formal', 'formal'), (',', ','), ('way', 'way'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4The', '4the'), ('use', 'use'), ('term', 'term'), ('“', '“'), ('cause', 'caus'), ('”', '”'), ('meant', 'meant'), ('taken', 'taken'), ('intuitive', 'intuit'), (',', ','), ('rather', 'rather'), ('formal', 'formal'), (',', ','), ('way', 'way'), ('.', '.')]

>> Lemmatization: 
 [('4The', '4The'), ('use', 'use'), ('term', 'term'), ('“', '“'), ('cause', 'cause'), ('”', '”'), ('meant', 'meant'), ('taken', 'taken'), ('intuitive', 'intuitive'), (',', ','), ('rather', 'rather'), ('formal', 'formal'), (',', ','), ('way', 'way'), ('.', '.')]



============================ Sentence 423 =============================

For a discussion on the study of causality, we refer to [8]. 


>> Tokens are: 
 ['For', 'discussion', 'study', 'causality', ',', 'refer', '[', '8', ']', '.']

>> Bigrams are: 
 [('For', 'discussion'), ('discussion', 'study'), ('study', 'causality'), ('causality', ','), (',', 'refer'), ('refer', '['), ('[', '8'), ('8', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'discussion', 'study'), ('discussion', 'study', 'causality'), ('study', 'causality', ','), ('causality', ',', 'refer'), (',', 'refer', '['), ('refer', '[', '8'), ('[', '8', ']'), ('8', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('discussion', 'NN'), ('study', 'NN'), ('causality', 'NN'), (',', ','), ('refer', 'VBP'), ('[', 'JJ'), ('8', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP discussion/NN study/NN causality/NN)
  ,/,
  refer/VBP
  [/JJ
  8/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['discussion study causality', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('discussion', 'discuss'), ('study', 'studi'), ('causality', 'causal'), (',', ','), ('refer', 'refer'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('discussion', 'discuss'), ('study', 'studi'), ('causality', 'causal'), (',', ','), ('refer', 'refer'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('discussion', 'discussion'), ('study', 'study'), ('causality', 'causality'), (',', ','), ('refer', 'refer'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]



============================ Sentence 424 =============================

13    As represented in Fig. 


>> Tokens are: 
 ['13', 'As', 'represented', 'Fig', '.']

>> Bigrams are: 
 [('13', 'As'), ('As', 'represented'), ('represented', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('13', 'As', 'represented'), ('As', 'represented', 'Fig'), ('represented', 'Fig', '.')]

>> POS Tags are: 
 [('13', 'CD'), ('As', 'IN'), ('represented', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S 13/CD As/IN represented/VBN (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('As', 'as'), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('As', 'as'), ('represented', 'repres'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('As', 'As'), ('represented', 'represented'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 425 =============================

11(d), autoencoders model encoding from data x to hidden variables z, as well as de- coding from hidden variables back to data. 


>> Tokens are: 
 ['11', '(', ')', ',', 'autoencoders', 'model', 'encoding', 'data', 'x', 'hidden', 'variables', 'z', ',', 'well', 'de-', 'coding', 'hidden', 'variables', 'back', 'data', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', ','), (',', 'autoencoders'), ('autoencoders', 'model'), ('model', 'encoding'), ('encoding', 'data'), ('data', 'x'), ('x', 'hidden'), ('hidden', 'variables'), ('variables', 'z'), ('z', ','), (',', 'well'), ('well', 'de-'), ('de-', 'coding'), ('coding', 'hidden'), ('hidden', 'variables'), ('variables', 'back'), ('back', 'data'), ('data', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', ','), (')', ',', 'autoencoders'), (',', 'autoencoders', 'model'), ('autoencoders', 'model', 'encoding'), ('model', 'encoding', 'data'), ('encoding', 'data', 'x'), ('data', 'x', 'hidden'), ('x', 'hidden', 'variables'), ('hidden', 'variables', 'z'), ('variables', 'z', ','), ('z', ',', 'well'), (',', 'well', 'de-'), ('well', 'de-', 'coding'), ('de-', 'coding', 'hidden'), ('coding', 'hidden', 'variables'), ('hidden', 'variables', 'back'), ('variables', 'back', 'data'), ('back', 'data', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), (',', ','), ('autoencoders', 'NNS'), ('model', 'VBP'), ('encoding', 'VBG'), ('data', 'NNS'), ('x', 'NNP'), ('hidden', 'NN'), ('variables', 'NNS'), ('z', 'NN'), (',', ','), ('well', 'RB'), ('de-', 'JJ'), ('coding', 'VBG'), ('hidden', 'JJ'), ('variables', 'NNS'), ('back', 'RB'), ('data', 'NNS'), ('.', '.')]

 (S
  11/CD
  (/(
  )/)
  ,/,
  (NP autoencoders/NNS)
  model/VBP
  encoding/VBG
  (NP data/NNS x/NNP hidden/NN variables/NNS z/NN)
  ,/,
  well/RB
  de-/JJ
  coding/VBG
  (NP hidden/JJ variables/NNS)
  back/RB
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['autoencoders', 'data x hidden variables z', 'hidden variables', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('autoencoders', 'autoencod'), ('model', 'model'), ('encoding', 'encod'), ('data', 'data'), ('x', 'x'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), (',', ','), ('well', 'well'), ('de-', 'de-'), ('coding', 'code'), ('hidden', 'hidden'), ('variables', 'variabl'), ('back', 'back'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('autoencoders', 'autoencod'), ('model', 'model'), ('encoding', 'encod'), ('data', 'data'), ('x', 'x'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), (',', ','), ('well', 'well'), ('de-', 'de-'), ('coding', 'code'), ('hidden', 'hidden'), ('variables', 'variabl'), ('back', 'back'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('autoencoders', 'autoencoders'), ('model', 'model'), ('encoding', 'encoding'), ('data', 'data'), ('x', 'x'), ('hidden', 'hidden'), ('variables', 'variable'), ('z', 'z'), (',', ','), ('well', 'well'), ('de-', 'de-'), ('coding', 'coding'), ('hidden', 'hidden'), ('variables', 'variable'), ('back', 'back'), ('data', 'data'), ('.', '.')]



============================ Sentence 426 =============================

Accordingly, model selection for autoencoders requires the specifica- tion of a parameterized family of encoders p(z|x, θ) and decoders p(x|z, θ). 


>> Tokens are: 
 ['Accordingly', ',', 'model', 'selection', 'autoencoders', 'requires', 'specifica-', 'tion', 'parameterized', 'family', 'encoders', 'p', '(', 'z|x', ',', 'θ', ')', 'decoders', 'p', '(', 'x|z', ',', 'θ', ')', '.']

>> Bigrams are: 
 [('Accordingly', ','), (',', 'model'), ('model', 'selection'), ('selection', 'autoencoders'), ('autoencoders', 'requires'), ('requires', 'specifica-'), ('specifica-', 'tion'), ('tion', 'parameterized'), ('parameterized', 'family'), ('family', 'encoders'), ('encoders', 'p'), ('p', '('), ('(', 'z|x'), ('z|x', ','), (',', 'θ'), ('θ', ')'), (')', 'decoders'), ('decoders', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', '.')]

>> Trigrams are: 
 [('Accordingly', ',', 'model'), (',', 'model', 'selection'), ('model', 'selection', 'autoencoders'), ('selection', 'autoencoders', 'requires'), ('autoencoders', 'requires', 'specifica-'), ('requires', 'specifica-', 'tion'), ('specifica-', 'tion', 'parameterized'), ('tion', 'parameterized', 'family'), ('parameterized', 'family', 'encoders'), ('family', 'encoders', 'p'), ('encoders', 'p', '('), ('p', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'decoders'), (')', 'decoders', 'p'), ('decoders', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '.')]

>> POS Tags are: 
 [('Accordingly', 'RB'), (',', ','), ('model', 'NN'), ('selection', 'NN'), ('autoencoders', 'NNS'), ('requires', 'VBZ'), ('specifica-', 'JJ'), ('tion', 'NN'), ('parameterized', 'VBN'), ('family', 'NN'), ('encoders', 'NNS'), ('p', 'VBP'), ('(', '('), ('z|x', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('decoders', 'NNS'), ('p', 'VBP'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), ('.', '.')]

 (S
  Accordingly/RB
  ,/,
  (NP model/NN selection/NN autoencoders/NNS)
  requires/VBZ
  (NP specifica-/JJ tion/NN)
  parameterized/VBN
  (NP family/NN encoders/NNS)
  p/VBP
  (/(
  (NP z|x/NN)
  ,/,
  (NP θ/NNP)
  )/)
  (NP decoders/NNS)
  p/VBP
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['model selection autoencoders', 'specifica- tion', 'family encoders', 'z|x', 'θ', 'decoders', 'θ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accordingly', 'accordingli'), (',', ','), ('model', 'model'), ('selection', 'select'), ('autoencoders', 'autoencod'), ('requires', 'requir'), ('specifica-', 'specifica-'), ('tion', 'tion'), ('parameterized', 'parameter'), ('family', 'famili'), ('encoders', 'encod'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('decoders', 'decod'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accordingly', 'accord'), (',', ','), ('model', 'model'), ('selection', 'select'), ('autoencoders', 'autoencod'), ('requires', 'requir'), ('specifica-', 'specifica-'), ('tion', 'tion'), ('parameterized', 'parameter'), ('family', 'famili'), ('encoders', 'encod'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('decoders', 'decod'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Accordingly', 'Accordingly'), (',', ','), ('model', 'model'), ('selection', 'selection'), ('autoencoders', 'autoencoders'), ('requires', 'requires'), ('specifica-', 'specifica-'), ('tion', 'tion'), ('parameterized', 'parameterized'), ('family', 'family'), ('encoders', 'encoders'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), ('decoders', 'decoder'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]



============================ Sentence 427 =============================

As an example, autoencoders can be used to learn how to compress an input signal x into a representation z in a smaller space so as to ensure that x can be recovered from z within an admissible level of distortion. 


>> Tokens are: 
 ['As', 'example', ',', 'autoencoders', 'used', 'learn', 'compress', 'input', 'signal', 'x', 'representation', 'z', 'smaller', 'space', 'ensure', 'x', 'recovered', 'z', 'within', 'admissible', 'level', 'distortion', '.']

>> Bigrams are: 
 [('As', 'example'), ('example', ','), (',', 'autoencoders'), ('autoencoders', 'used'), ('used', 'learn'), ('learn', 'compress'), ('compress', 'input'), ('input', 'signal'), ('signal', 'x'), ('x', 'representation'), ('representation', 'z'), ('z', 'smaller'), ('smaller', 'space'), ('space', 'ensure'), ('ensure', 'x'), ('x', 'recovered'), ('recovered', 'z'), ('z', 'within'), ('within', 'admissible'), ('admissible', 'level'), ('level', 'distortion'), ('distortion', '.')]

>> Trigrams are: 
 [('As', 'example', ','), ('example', ',', 'autoencoders'), (',', 'autoencoders', 'used'), ('autoencoders', 'used', 'learn'), ('used', 'learn', 'compress'), ('learn', 'compress', 'input'), ('compress', 'input', 'signal'), ('input', 'signal', 'x'), ('signal', 'x', 'representation'), ('x', 'representation', 'z'), ('representation', 'z', 'smaller'), ('z', 'smaller', 'space'), ('smaller', 'space', 'ensure'), ('space', 'ensure', 'x'), ('ensure', 'x', 'recovered'), ('x', 'recovered', 'z'), ('recovered', 'z', 'within'), ('z', 'within', 'admissible'), ('within', 'admissible', 'level'), ('admissible', 'level', 'distortion'), ('level', 'distortion', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('example', 'NN'), (',', ','), ('autoencoders', 'NNS'), ('used', 'VBD'), ('learn', 'JJ'), ('compress', 'NN'), ('input', 'VBD'), ('signal', 'JJ'), ('x', 'NNP'), ('representation', 'NN'), ('z', 'NNP'), ('smaller', 'JJR'), ('space', 'NN'), ('ensure', 'VB'), ('x', 'NN'), ('recovered', 'VBN'), ('z', 'CD'), ('within', 'IN'), ('admissible', 'JJ'), ('level', 'NN'), ('distortion', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP example/NN)
  ,/,
  (NP autoencoders/NNS)
  used/VBD
  (NP learn/JJ compress/NN)
  input/VBD
  (NP signal/JJ x/NNP representation/NN z/NNP)
  smaller/JJR
  (NP space/NN)
  ensure/VB
  (NP x/NN)
  recovered/VBN
  z/CD
  within/IN
  (NP admissible/JJ level/NN distortion/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'autoencoders', 'learn compress', 'signal x representation z', 'space', 'x', 'admissible level distortion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('autoencoders', 'autoencod'), ('used', 'use'), ('learn', 'learn'), ('compress', 'compress'), ('input', 'input'), ('signal', 'signal'), ('x', 'x'), ('representation', 'represent'), ('z', 'z'), ('smaller', 'smaller'), ('space', 'space'), ('ensure', 'ensur'), ('x', 'x'), ('recovered', 'recov'), ('z', 'z'), ('within', 'within'), ('admissible', 'admiss'), ('level', 'level'), ('distortion', 'distort'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('example', 'exampl'), (',', ','), ('autoencoders', 'autoencod'), ('used', 'use'), ('learn', 'learn'), ('compress', 'compress'), ('input', 'input'), ('signal', 'signal'), ('x', 'x'), ('representation', 'represent'), ('z', 'z'), ('smaller', 'smaller'), ('space', 'space'), ('ensure', 'ensur'), ('x', 'x'), ('recovered', 'recov'), ('z', 'z'), ('within', 'within'), ('admissible', 'admiss'), ('level', 'level'), ('distortion', 'distort'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('example', 'example'), (',', ','), ('autoencoders', 'autoencoders'), ('used', 'used'), ('learn', 'learn'), ('compress', 'compress'), ('input', 'input'), ('signal', 'signal'), ('x', 'x'), ('representation', 'representation'), ('z', 'z'), ('smaller', 'smaller'), ('space', 'space'), ('ensure', 'ensure'), ('x', 'x'), ('recovered', 'recovered'), ('z', 'z'), ('within', 'within'), ('admissible', 'admissible'), ('level', 'level'), ('distortion', 'distortion'), ('.', '.')]



============================ Sentence 428 =============================

Representatives of autoencoders, which cor- respond to specific choices for the encoder and decoder families of distributions, include Principal Component Analysis (PCA), dictionary learning, and neural network- based autoencoders [19], [57], [58]. 


>> Tokens are: 
 ['Representatives', 'autoencoders', ',', 'cor-', 'respond', 'specific', 'choices', 'encoder', 'decoder', 'families', 'distributions', ',', 'include', 'Principal', 'Component', 'Analysis', '(', 'PCA', ')', ',', 'dictionary', 'learning', ',', 'neural', 'network-', 'based', 'autoencoders', '[', '19', ']', ',', '[', '57', ']', ',', '[', '58', ']', '.']

>> Bigrams are: 
 [('Representatives', 'autoencoders'), ('autoencoders', ','), (',', 'cor-'), ('cor-', 'respond'), ('respond', 'specific'), ('specific', 'choices'), ('choices', 'encoder'), ('encoder', 'decoder'), ('decoder', 'families'), ('families', 'distributions'), ('distributions', ','), (',', 'include'), ('include', 'Principal'), ('Principal', 'Component'), ('Component', 'Analysis'), ('Analysis', '('), ('(', 'PCA'), ('PCA', ')'), (')', ','), (',', 'dictionary'), ('dictionary', 'learning'), ('learning', ','), (',', 'neural'), ('neural', 'network-'), ('network-', 'based'), ('based', 'autoencoders'), ('autoencoders', '['), ('[', '19'), ('19', ']'), (']', ','), (',', '['), ('[', '57'), ('57', ']'), (']', ','), (',', '['), ('[', '58'), ('58', ']'), (']', '.')]

>> Trigrams are: 
 [('Representatives', 'autoencoders', ','), ('autoencoders', ',', 'cor-'), (',', 'cor-', 'respond'), ('cor-', 'respond', 'specific'), ('respond', 'specific', 'choices'), ('specific', 'choices', 'encoder'), ('choices', 'encoder', 'decoder'), ('encoder', 'decoder', 'families'), ('decoder', 'families', 'distributions'), ('families', 'distributions', ','), ('distributions', ',', 'include'), (',', 'include', 'Principal'), ('include', 'Principal', 'Component'), ('Principal', 'Component', 'Analysis'), ('Component', 'Analysis', '('), ('Analysis', '(', 'PCA'), ('(', 'PCA', ')'), ('PCA', ')', ','), (')', ',', 'dictionary'), (',', 'dictionary', 'learning'), ('dictionary', 'learning', ','), ('learning', ',', 'neural'), (',', 'neural', 'network-'), ('neural', 'network-', 'based'), ('network-', 'based', 'autoencoders'), ('based', 'autoencoders', '['), ('autoencoders', '[', '19'), ('[', '19', ']'), ('19', ']', ','), (']', ',', '['), (',', '[', '57'), ('[', '57', ']'), ('57', ']', ','), (']', ',', '['), (',', '[', '58'), ('[', '58', ']'), ('58', ']', '.')]

>> POS Tags are: 
 [('Representatives', 'NNS'), ('autoencoders', 'NNS'), (',', ','), ('cor-', 'JJ'), ('respond', 'NN'), ('specific', 'JJ'), ('choices', 'NNS'), ('encoder', 'VBP'), ('decoder', 'NN'), ('families', 'NNS'), ('distributions', 'NNS'), (',', ','), ('include', 'VBP'), ('Principal', 'NNP'), ('Component', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('PCA', 'NNP'), (')', ')'), (',', ','), ('dictionary', 'JJ'), ('learning', 'NN'), (',', ','), ('neural', 'JJ'), ('network-', 'NNS'), ('based', 'VBN'), ('autoencoders', 'NNS'), ('[', 'VBP'), ('19', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('57', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('58', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Representatives/NNS autoencoders/NNS)
  ,/,
  (NP cor-/JJ respond/NN)
  (NP specific/JJ choices/NNS)
  encoder/VBP
  (NP decoder/NN families/NNS distributions/NNS)
  ,/,
  include/VBP
  (NP Principal/NNP Component/NNP Analysis/NNP)
  (/(
  (NP PCA/NNP)
  )/)
  ,/,
  (NP dictionary/JJ learning/NN)
  ,/,
  (NP neural/JJ network-/NNS)
  based/VBN
  (NP autoencoders/NNS)
  [/VBP
  19/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  57/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  58/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Representatives autoencoders', 'cor- respond', 'specific choices', 'decoder families distributions', 'Principal Component Analysis', 'PCA', 'dictionary learning', 'neural network-', 'autoencoders', ']', ']', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Principal'), ('ORGANIZATION', 'PCA')] 

>> Stemming using Porter Stemmer: 
 [('Representatives', 'repres'), ('autoencoders', 'autoencod'), (',', ','), ('cor-', 'cor-'), ('respond', 'respond'), ('specific', 'specif'), ('choices', 'choic'), ('encoder', 'encod'), ('decoder', 'decod'), ('families', 'famili'), ('distributions', 'distribut'), (',', ','), ('include', 'includ'), ('Principal', 'princip'), ('Component', 'compon'), ('Analysis', 'analysi'), ('(', '('), ('PCA', 'pca'), (')', ')'), (',', ','), ('dictionary', 'dictionari'), ('learning', 'learn'), (',', ','), ('neural', 'neural'), ('network-', 'network-'), ('based', 'base'), ('autoencoders', 'autoencod'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Representatives', 'repres'), ('autoencoders', 'autoencod'), (',', ','), ('cor-', 'cor-'), ('respond', 'respond'), ('specific', 'specif'), ('choices', 'choic'), ('encoder', 'encod'), ('decoder', 'decod'), ('families', 'famili'), ('distributions', 'distribut'), (',', ','), ('include', 'includ'), ('Principal', 'princip'), ('Component', 'compon'), ('Analysis', 'analysi'), ('(', '('), ('PCA', 'pca'), (')', ')'), (',', ','), ('dictionary', 'dictionari'), ('learning', 'learn'), (',', ','), ('neural', 'neural'), ('network-', 'network-'), ('based', 'base'), ('autoencoders', 'autoencod'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Representatives', 'Representatives'), ('autoencoders', 'autoencoders'), (',', ','), ('cor-', 'cor-'), ('respond', 'respond'), ('specific', 'specific'), ('choices', 'choice'), ('encoder', 'encoder'), ('decoder', 'decoder'), ('families', 'family'), ('distributions', 'distribution'), (',', ','), ('include', 'include'), ('Principal', 'Principal'), ('Component', 'Component'), ('Analysis', 'Analysis'), ('(', '('), ('PCA', 'PCA'), (')', ')'), (',', ','), ('dictionary', 'dictionary'), ('learning', 'learning'), (',', ','), ('neural', 'neural'), ('network-', 'network-'), ('based', 'based'), ('autoencoders', 'autoencoders'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]



============================ Sentence 429 =============================

C. Learning  We now discuss learning, to be carried out as Step 2. 


>> Tokens are: 
 ['C.', 'Learning', 'We', 'discuss', 'learning', ',', 'carried', 'Step', '2', '.']

>> Bigrams are: 
 [('C.', 'Learning'), ('Learning', 'We'), ('We', 'discuss'), ('discuss', 'learning'), ('learning', ','), (',', 'carried'), ('carried', 'Step'), ('Step', '2'), ('2', '.')]

>> Trigrams are: 
 [('C.', 'Learning', 'We'), ('Learning', 'We', 'discuss'), ('We', 'discuss', 'learning'), ('discuss', 'learning', ','), ('learning', ',', 'carried'), (',', 'carried', 'Step'), ('carried', 'Step', '2'), ('Step', '2', '.')]

>> POS Tags are: 
 [('C.', 'NNP'), ('Learning', 'NNP'), ('We', 'PRP'), ('discuss', 'VBP'), ('learning', 'VBG'), (',', ','), ('carried', 'VBD'), ('Step', 'NNP'), ('2', 'CD'), ('.', '.')]

 (S
  (NP C./NNP Learning/NNP)
  We/PRP
  discuss/VBP
  learning/VBG
  ,/,
  carried/VBD
  (NP Step/NNP)
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['C. Learning', 'Step']

>> Named Entities are: 
 [('PERSON', 'Step')] 

>> Stemming using Porter Stemmer: 
 [('C.', 'c.'), ('Learning', 'learn'), ('We', 'we'), ('discuss', 'discuss'), ('learning', 'learn'), (',', ','), ('carried', 'carri'), ('Step', 'step'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('C.', 'c.'), ('Learning', 'learn'), ('We', 'we'), ('discuss', 'discuss'), ('learning', 'learn'), (',', ','), ('carried', 'carri'), ('Step', 'step'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('C.', 'C.'), ('Learning', 'Learning'), ('We', 'We'), ('discuss', 'discus'), ('learning', 'learning'), (',', ','), ('carried', 'carried'), ('Step', 'Step'), ('2', '2'), ('.', '.')]



============================ Sentence 430 =============================

For brevity, we focus on directed generative models and refer to [19] and references therein for a treatment of learning for the other models in Fig. 


>> Tokens are: 
 ['For', 'brevity', ',', 'focus', 'directed', 'generative', 'models', 'refer', '[', '19', ']', 'references', 'therein', 'treatment', 'learning', 'models', 'Fig', '.']

>> Bigrams are: 
 [('For', 'brevity'), ('brevity', ','), (',', 'focus'), ('focus', 'directed'), ('directed', 'generative'), ('generative', 'models'), ('models', 'refer'), ('refer', '['), ('[', '19'), ('19', ']'), (']', 'references'), ('references', 'therein'), ('therein', 'treatment'), ('treatment', 'learning'), ('learning', 'models'), ('models', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('For', 'brevity', ','), ('brevity', ',', 'focus'), (',', 'focus', 'directed'), ('focus', 'directed', 'generative'), ('directed', 'generative', 'models'), ('generative', 'models', 'refer'), ('models', 'refer', '['), ('refer', '[', '19'), ('[', '19', ']'), ('19', ']', 'references'), (']', 'references', 'therein'), ('references', 'therein', 'treatment'), ('therein', 'treatment', 'learning'), ('treatment', 'learning', 'models'), ('learning', 'models', 'Fig'), ('models', 'Fig', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('brevity', 'NN'), (',', ','), ('focus', 'NN'), ('directed', 'VBD'), ('generative', 'JJ'), ('models', 'NNS'), ('refer', 'VBP'), ('[', 'JJ'), ('19', 'CD'), (']', 'JJ'), ('references', 'NNS'), ('therein', 'VBP'), ('treatment', 'NN'), ('learning', 'NN'), ('models', 'NNS'), ('Fig', 'NNP'), ('.', '.')]

 (S
  For/IN
  (NP brevity/NN)
  ,/,
  (NP focus/NN)
  directed/VBD
  (NP generative/JJ models/NNS)
  refer/VBP
  [/JJ
  19/CD
  (NP ]/JJ references/NNS)
  therein/VBP
  (NP treatment/NN learning/NN models/NNS Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['brevity', 'focus', 'generative models', '] references', 'treatment learning models Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('brevity', 'breviti'), (',', ','), ('focus', 'focu'), ('directed', 'direct'), ('generative', 'gener'), ('models', 'model'), ('refer', 'refer'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), ('treatment', 'treatment'), ('learning', 'learn'), ('models', 'model'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('brevity', 'breviti'), (',', ','), ('focus', 'focus'), ('directed', 'direct'), ('generative', 'generat'), ('models', 'model'), ('refer', 'refer'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'refer'), ('therein', 'therein'), ('treatment', 'treatment'), ('learning', 'learn'), ('models', 'model'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('brevity', 'brevity'), (',', ','), ('focus', 'focus'), ('directed', 'directed'), ('generative', 'generative'), ('models', 'model'), ('refer', 'refer'), ('[', '['), ('19', '19'), (']', ']'), ('references', 'reference'), ('therein', 'therein'), ('treatment', 'treatment'), ('learning', 'learning'), ('models', 'model'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 431 =============================

11. 


>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

 (S 11/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]



============================ Sentence 432 =============================

In this regard, we note that the problem of training autoencoders is akin to supervised learning in the sense that autoencoders specify the desired output for each input in the training set. 


>> Tokens are: 
 ['In', 'regard', ',', 'note', 'problem', 'training', 'autoencoders', 'akin', 'supervised', 'learning', 'sense', 'autoencoders', 'specify', 'desired', 'output', 'input', 'training', 'set', '.']

>> Bigrams are: 
 [('In', 'regard'), ('regard', ','), (',', 'note'), ('note', 'problem'), ('problem', 'training'), ('training', 'autoencoders'), ('autoencoders', 'akin'), ('akin', 'supervised'), ('supervised', 'learning'), ('learning', 'sense'), ('sense', 'autoencoders'), ('autoencoders', 'specify'), ('specify', 'desired'), ('desired', 'output'), ('output', 'input'), ('input', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('In', 'regard', ','), ('regard', ',', 'note'), (',', 'note', 'problem'), ('note', 'problem', 'training'), ('problem', 'training', 'autoencoders'), ('training', 'autoencoders', 'akin'), ('autoencoders', 'akin', 'supervised'), ('akin', 'supervised', 'learning'), ('supervised', 'learning', 'sense'), ('learning', 'sense', 'autoencoders'), ('sense', 'autoencoders', 'specify'), ('autoencoders', 'specify', 'desired'), ('specify', 'desired', 'output'), ('desired', 'output', 'input'), ('output', 'input', 'training'), ('input', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('regard', 'NN'), (',', ','), ('note', 'NN'), ('problem', 'NN'), ('training', 'NN'), ('autoencoders', 'NNS'), ('akin', 'VBP'), ('supervised', 'VBN'), ('learning', 'JJ'), ('sense', 'NN'), ('autoencoders', 'NNS'), ('specify', 'VBP'), ('desired', 'VBN'), ('output', 'NN'), ('input', 'NN'), ('training', 'NN'), ('set', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP regard/NN)
  ,/,
  (NP note/NN problem/NN training/NN autoencoders/NNS)
  akin/VBP
  supervised/VBN
  (NP learning/JJ sense/NN autoencoders/NNS)
  specify/VBP
  desired/VBN
  (NP output/NN input/NN training/NN set/NN)
  ./.) 


>> Noun Phrases are: 
 ['regard', 'note problem training autoencoders', 'learning sense autoencoders', 'output input training set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('regard', 'regard'), (',', ','), ('note', 'note'), ('problem', 'problem'), ('training', 'train'), ('autoencoders', 'autoencod'), ('akin', 'akin'), ('supervised', 'supervis'), ('learning', 'learn'), ('sense', 'sens'), ('autoencoders', 'autoencod'), ('specify', 'specifi'), ('desired', 'desir'), ('output', 'output'), ('input', 'input'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('regard', 'regard'), (',', ','), ('note', 'note'), ('problem', 'problem'), ('training', 'train'), ('autoencoders', 'autoencod'), ('akin', 'akin'), ('supervised', 'supervis'), ('learning', 'learn'), ('sense', 'sens'), ('autoencoders', 'autoencod'), ('specify', 'specifi'), ('desired', 'desir'), ('output', 'output'), ('input', 'input'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('regard', 'regard'), (',', ','), ('note', 'note'), ('problem', 'problem'), ('training', 'training'), ('autoencoders', 'autoencoders'), ('akin', 'akin'), ('supervised', 'supervised'), ('learning', 'learning'), ('sense', 'sense'), ('autoencoders', 'autoencoders'), ('specify', 'specify'), ('desired', 'desired'), ('output', 'output'), ('input', 'input'), ('training', 'training'), ('set', 'set'), ('.', '.')]



============================ Sentence 433 =============================

As for supervised learning, the most basic learning criterion for probabilistic models is ML. 


>> Tokens are: 
 ['As', 'supervised', 'learning', ',', 'basic', 'learning', 'criterion', 'probabilistic', 'models', 'ML', '.']

>> Bigrams are: 
 [('As', 'supervised'), ('supervised', 'learning'), ('learning', ','), (',', 'basic'), ('basic', 'learning'), ('learning', 'criterion'), ('criterion', 'probabilistic'), ('probabilistic', 'models'), ('models', 'ML'), ('ML', '.')]

>> Trigrams are: 
 [('As', 'supervised', 'learning'), ('supervised', 'learning', ','), ('learning', ',', 'basic'), (',', 'basic', 'learning'), ('basic', 'learning', 'criterion'), ('learning', 'criterion', 'probabilistic'), ('criterion', 'probabilistic', 'models'), ('probabilistic', 'models', 'ML'), ('models', 'ML', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('supervised', 'VBN'), ('learning', 'NN'), (',', ','), ('basic', 'JJ'), ('learning', 'VBG'), ('criterion', 'NN'), ('probabilistic', 'JJ'), ('models', 'NNS'), ('ML', 'NNP'), ('.', '.')]

 (S
  As/IN
  supervised/VBN
  (NP learning/NN)
  ,/,
  basic/JJ
  learning/VBG
  (NP criterion/NN)
  (NP probabilistic/JJ models/NNS ML/NNP)
  ./.) 


>> Noun Phrases are: 
 ['learning', 'criterion', 'probabilistic models ML']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('basic', 'basic'), ('learning', 'learn'), ('criterion', 'criterion'), ('probabilistic', 'probabilist'), ('models', 'model'), ('ML', 'ml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('basic', 'basic'), ('learning', 'learn'), ('criterion', 'criterion'), ('probabilistic', 'probabilist'), ('models', 'model'), ('ML', 'ml'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('supervised', 'supervised'), ('learning', 'learning'), (',', ','), ('basic', 'basic'), ('learning', 'learning'), ('criterion', 'criterion'), ('probabilistic', 'probabilistic'), ('models', 'model'), ('ML', 'ML'), ('.', '.')]



============================ Sentence 434 =============================

Following the discussion in Sec. 


>> Tokens are: 
 ['Following', 'discussion', 'Sec', '.']

>> Bigrams are: 
 [('Following', 'discussion'), ('discussion', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Following', 'discussion', 'Sec'), ('discussion', 'Sec', '.')]

>> POS Tags are: 
 [('Following', 'VBG'), ('discussion', 'NN'), ('Sec', 'NNP'), ('.', '.')]

 (S Following/VBG (NP discussion/NN Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['discussion Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Following', 'follow'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Following', 'follow'), ('discussion', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Following', 'Following'), ('discussion', 'discussion'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 435 =============================

III-E, ML tackles the problem of maximizing the log-likelihood of the data, i.e.-,  maximize θ  ln p(x|θ) = lnEz∼p(z|θ)[ln p(x|z, θ)]. 


>> Tokens are: 
 ['III-E', ',', 'ML', 'tackles', 'problem', 'maximizing', 'log-likelihood', 'data', ',', 'i.e.-', ',', 'maximize', 'θ', 'ln', 'p', '(', 'x|θ', ')', '=', 'lnEz∼p', '(', 'z|θ', ')', '[', 'ln', 'p', '(', 'x|z', ',', 'θ', ')', ']', '.']

>> Bigrams are: 
 [('III-E', ','), (',', 'ML'), ('ML', 'tackles'), ('tackles', 'problem'), ('problem', 'maximizing'), ('maximizing', 'log-likelihood'), ('log-likelihood', 'data'), ('data', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'maximize'), ('maximize', 'θ'), ('θ', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', '='), ('=', 'lnEz∼p'), ('lnEz∼p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', '['), ('[', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ']'), (']', '.')]

>> Trigrams are: 
 [('III-E', ',', 'ML'), (',', 'ML', 'tackles'), ('ML', 'tackles', 'problem'), ('tackles', 'problem', 'maximizing'), ('problem', 'maximizing', 'log-likelihood'), ('maximizing', 'log-likelihood', 'data'), ('log-likelihood', 'data', ','), ('data', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'maximize'), (',', 'maximize', 'θ'), ('maximize', 'θ', 'ln'), ('θ', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', '='), (')', '=', 'lnEz∼p'), ('=', 'lnEz∼p', '('), ('lnEz∼p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', '['), (')', '[', 'ln'), ('[', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ']'), (')', ']', '.')]

>> POS Tags are: 
 [('III-E', 'NNP'), (',', ','), ('ML', 'NNP'), ('tackles', 'VBZ'), ('problem', 'NN'), ('maximizing', 'VBG'), ('log-likelihood', 'JJ'), ('data', 'NNS'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('maximize', 'VB'), ('θ', 'NNP'), ('ln', 'NN'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('lnEz∼p', 'NN'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('[', 'VBZ'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (']', 'NN'), ('.', '.')]

 (S
  (NP III-E/NNP)
  ,/,
  (NP ML/NNP)
  tackles/VBZ
  (NP problem/NN)
  maximizing/VBG
  (NP log-likelihood/JJ data/NNS)
  ,/,
  i.e.-/JJ
  ,/,
  maximize/VB
  (NP θ/NNP ln/NN p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  =/VBP
  (NP lnEz∼p/NN)
  (/(
  (NP z|θ/NN)
  )/)
  [/VBZ
  (NP ln/JJ p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['III-E', 'ML', 'problem', 'log-likelihood data', 'θ ln p', 'x|θ', 'lnEz∼p', 'z|θ', 'ln p', 'θ', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('III-E', 'iii-'), (',', ','), ('ML', 'ml'), ('tackles', 'tackl'), ('problem', 'problem'), ('maximizing', 'maxim'), ('log-likelihood', 'log-likelihood'), ('data', 'data'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('maximize', 'maxim'), ('θ', 'θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('lnEz∼p', 'lnez∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('III-E', 'iii-'), (',', ','), ('ML', 'ml'), ('tackles', 'tackl'), ('problem', 'problem'), ('maximizing', 'maxim'), ('log-likelihood', 'log-likelihood'), ('data', 'data'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('maximize', 'maxim'), ('θ', 'θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('lnEz∼p', 'lnez∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('III-E', 'III-E'), (',', ','), ('ML', 'ML'), ('tackles', 'tackle'), ('problem', 'problem'), ('maximizing', 'maximizing'), ('log-likelihood', 'log-likelihood'), ('data', 'data'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('maximize', 'maximize'), ('θ', 'θ'), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('=', '='), ('lnEz∼p', 'lnEz∼p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('.', '.')]



============================ Sentence 436 =============================

(14)  Note that problem (14) considers only one data point x in the data set for the purpose of simplifying the notation, but in practice the log-likelihood needs to be summed over the N examples in D.  Unlike the corresponding problem for supervised learning (8), the likelihood in (14) requires an average over the hidden variables. 


>> Tokens are: 
 ['(', '14', ')', 'Note', 'problem', '(', '14', ')', 'considers', 'one', 'data', 'point', 'x', 'data', 'set', 'purpose', 'simplifying', 'notation', ',', 'practice', 'log-likelihood', 'needs', 'summed', 'N', 'examples', 'D.', 'Unlike', 'corresponding', 'problem', 'supervised', 'learning', '(', '8', ')', ',', 'likelihood', '(', '14', ')', 'requires', 'average', 'hidden', 'variables', '.']

>> Bigrams are: 
 [('(', '14'), ('14', ')'), (')', 'Note'), ('Note', 'problem'), ('problem', '('), ('(', '14'), ('14', ')'), (')', 'considers'), ('considers', 'one'), ('one', 'data'), ('data', 'point'), ('point', 'x'), ('x', 'data'), ('data', 'set'), ('set', 'purpose'), ('purpose', 'simplifying'), ('simplifying', 'notation'), ('notation', ','), (',', 'practice'), ('practice', 'log-likelihood'), ('log-likelihood', 'needs'), ('needs', 'summed'), ('summed', 'N'), ('N', 'examples'), ('examples', 'D.'), ('D.', 'Unlike'), ('Unlike', 'corresponding'), ('corresponding', 'problem'), ('problem', 'supervised'), ('supervised', 'learning'), ('learning', '('), ('(', '8'), ('8', ')'), (')', ','), (',', 'likelihood'), ('likelihood', '('), ('(', '14'), ('14', ')'), (')', 'requires'), ('requires', 'average'), ('average', 'hidden'), ('hidden', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('(', '14', ')'), ('14', ')', 'Note'), (')', 'Note', 'problem'), ('Note', 'problem', '('), ('problem', '(', '14'), ('(', '14', ')'), ('14', ')', 'considers'), (')', 'considers', 'one'), ('considers', 'one', 'data'), ('one', 'data', 'point'), ('data', 'point', 'x'), ('point', 'x', 'data'), ('x', 'data', 'set'), ('data', 'set', 'purpose'), ('set', 'purpose', 'simplifying'), ('purpose', 'simplifying', 'notation'), ('simplifying', 'notation', ','), ('notation', ',', 'practice'), (',', 'practice', 'log-likelihood'), ('practice', 'log-likelihood', 'needs'), ('log-likelihood', 'needs', 'summed'), ('needs', 'summed', 'N'), ('summed', 'N', 'examples'), ('N', 'examples', 'D.'), ('examples', 'D.', 'Unlike'), ('D.', 'Unlike', 'corresponding'), ('Unlike', 'corresponding', 'problem'), ('corresponding', 'problem', 'supervised'), ('problem', 'supervised', 'learning'), ('supervised', 'learning', '('), ('learning', '(', '8'), ('(', '8', ')'), ('8', ')', ','), (')', ',', 'likelihood'), (',', 'likelihood', '('), ('likelihood', '(', '14'), ('(', '14', ')'), ('14', ')', 'requires'), (')', 'requires', 'average'), ('requires', 'average', 'hidden'), ('average', 'hidden', 'variables'), ('hidden', 'variables', '.')]

>> POS Tags are: 
 [('(', '('), ('14', 'CD'), (')', ')'), ('Note', 'NN'), ('problem', 'NN'), ('(', '('), ('14', 'CD'), (')', ')'), ('considers', 'NNS'), ('one', 'CD'), ('data', 'NNS'), ('point', 'NN'), ('x', 'NNP'), ('data', 'NN'), ('set', 'NN'), ('purpose', 'NN'), ('simplifying', 'VBG'), ('notation', 'NN'), (',', ','), ('practice', 'NN'), ('log-likelihood', 'NN'), ('needs', 'NNS'), ('summed', 'VBD'), ('N', 'NNP'), ('examples', 'NNS'), ('D.', 'NNP'), ('Unlike', 'IN'), ('corresponding', 'VBG'), ('problem', 'NN'), ('supervised', 'VBD'), ('learning', 'NN'), ('(', '('), ('8', 'CD'), (')', ')'), (',', ','), ('likelihood', 'NN'), ('(', '('), ('14', 'CD'), (')', ')'), ('requires', 'VBZ'), ('average', 'JJ'), ('hidden', 'JJ'), ('variables', 'NNS'), ('.', '.')]

 (S
  (/(
  14/CD
  )/)
  (NP Note/NN problem/NN)
  (/(
  14/CD
  )/)
  (NP considers/NNS)
  one/CD
  (NP data/NNS point/NN x/NNP data/NN set/NN purpose/NN)
  simplifying/VBG
  (NP notation/NN)
  ,/,
  (NP practice/NN log-likelihood/NN needs/NNS)
  summed/VBD
  (NP N/NNP examples/NNS D./NNP)
  Unlike/IN
  corresponding/VBG
  (NP problem/NN)
  supervised/VBD
  (NP learning/NN)
  (/(
  8/CD
  )/)
  ,/,
  (NP likelihood/NN)
  (/(
  14/CD
  )/)
  requires/VBZ
  (NP average/JJ hidden/JJ variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Note problem', 'considers', 'data point x data set purpose', 'notation', 'practice log-likelihood needs', 'N examples D.', 'problem', 'learning', 'likelihood', 'average hidden variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('14', '14'), (')', ')'), ('Note', 'note'), ('problem', 'problem'), ('(', '('), ('14', '14'), (')', ')'), ('considers', 'consid'), ('one', 'one'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('data', 'data'), ('set', 'set'), ('purpose', 'purpos'), ('simplifying', 'simplifi'), ('notation', 'notat'), (',', ','), ('practice', 'practic'), ('log-likelihood', 'log-likelihood'), ('needs', 'need'), ('summed', 'sum'), ('N', 'n'), ('examples', 'exampl'), ('D.', 'd.'), ('Unlike', 'unlik'), ('corresponding', 'correspond'), ('problem', 'problem'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('8', '8'), (')', ')'), (',', ','), ('likelihood', 'likelihood'), ('(', '('), ('14', '14'), (')', ')'), ('requires', 'requir'), ('average', 'averag'), ('hidden', 'hidden'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('14', '14'), (')', ')'), ('Note', 'note'), ('problem', 'problem'), ('(', '('), ('14', '14'), (')', ')'), ('considers', 'consid'), ('one', 'one'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('data', 'data'), ('set', 'set'), ('purpose', 'purpos'), ('simplifying', 'simplifi'), ('notation', 'notat'), (',', ','), ('practice', 'practic'), ('log-likelihood', 'log-likelihood'), ('needs', 'need'), ('summed', 'sum'), ('N', 'n'), ('examples', 'exampl'), ('D.', 'd.'), ('Unlike', 'unlik'), ('corresponding', 'correspond'), ('problem', 'problem'), ('supervised', 'supervis'), ('learning', 'learn'), ('(', '('), ('8', '8'), (')', ')'), (',', ','), ('likelihood', 'likelihood'), ('(', '('), ('14', '14'), (')', ')'), ('requires', 'requir'), ('average', 'averag'), ('hidden', 'hidden'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('14', '14'), (')', ')'), ('Note', 'Note'), ('problem', 'problem'), ('(', '('), ('14', '14'), (')', ')'), ('considers', 'considers'), ('one', 'one'), ('data', 'data'), ('point', 'point'), ('x', 'x'), ('data', 'data'), ('set', 'set'), ('purpose', 'purpose'), ('simplifying', 'simplifying'), ('notation', 'notation'), (',', ','), ('practice', 'practice'), ('log-likelihood', 'log-likelihood'), ('needs', 'need'), ('summed', 'summed'), ('N', 'N'), ('examples', 'example'), ('D.', 'D.'), ('Unlike', 'Unlike'), ('corresponding', 'corresponding'), ('problem', 'problem'), ('supervised', 'supervised'), ('learning', 'learning'), ('(', '('), ('8', '8'), (')', ')'), (',', ','), ('likelihood', 'likelihood'), ('(', '('), ('14', '14'), (')', ')'), ('requires', 'requires'), ('average', 'average'), ('hidden', 'hidden'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 437 =============================

This is because the value of the hidden variables z is not known, and hence the probability of the observation x needs to account for all possible values of z weighted by their probabilities p(z|θ). 


>> Tokens are: 
 ['This', 'value', 'hidden', 'variables', 'z', 'known', ',', 'hence', 'probability', 'observation', 'x', 'needs', 'account', 'possible', 'values', 'z', 'weighted', 'probabilities', 'p', '(', 'z|θ', ')', '.']

>> Bigrams are: 
 [('This', 'value'), ('value', 'hidden'), ('hidden', 'variables'), ('variables', 'z'), ('z', 'known'), ('known', ','), (',', 'hence'), ('hence', 'probability'), ('probability', 'observation'), ('observation', 'x'), ('x', 'needs'), ('needs', 'account'), ('account', 'possible'), ('possible', 'values'), ('values', 'z'), ('z', 'weighted'), ('weighted', 'probabilities'), ('probabilities', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'value', 'hidden'), ('value', 'hidden', 'variables'), ('hidden', 'variables', 'z'), ('variables', 'z', 'known'), ('z', 'known', ','), ('known', ',', 'hence'), (',', 'hence', 'probability'), ('hence', 'probability', 'observation'), ('probability', 'observation', 'x'), ('observation', 'x', 'needs'), ('x', 'needs', 'account'), ('needs', 'account', 'possible'), ('account', 'possible', 'values'), ('possible', 'values', 'z'), ('values', 'z', 'weighted'), ('z', 'weighted', 'probabilities'), ('weighted', 'probabilities', 'p'), ('probabilities', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('value', 'NN'), ('hidden', 'VBZ'), ('variables', 'NNS'), ('z', 'CD'), ('known', 'VBN'), (',', ','), ('hence', 'NN'), ('probability', 'NN'), ('observation', 'NN'), ('x', 'NNP'), ('needs', 'VBZ'), ('account', 'NN'), ('possible', 'JJ'), ('values', 'NNS'), ('z', 'VBP'), ('weighted', 'JJ'), ('probabilities', 'NNS'), ('p', 'VBP'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT value/NN)
  hidden/VBZ
  (NP variables/NNS)
  z/CD
  known/VBN
  ,/,
  (NP hence/NN probability/NN observation/NN x/NNP)
  needs/VBZ
  (NP account/NN)
  (NP possible/JJ values/NNS)
  z/VBP
  (NP weighted/JJ probabilities/NNS)
  p/VBP
  (/(
  (NP z|θ/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This value', 'variables', 'hence probability observation x', 'account', 'possible values', 'weighted probabilities', 'z|θ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('value', 'valu'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), ('known', 'known'), (',', ','), ('hence', 'henc'), ('probability', 'probabl'), ('observation', 'observ'), ('x', 'x'), ('needs', 'need'), ('account', 'account'), ('possible', 'possibl'), ('values', 'valu'), ('z', 'z'), ('weighted', 'weight'), ('probabilities', 'probabl'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('value', 'valu'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), ('known', 'known'), (',', ','), ('hence', 'henc'), ('probability', 'probabl'), ('observation', 'observ'), ('x', 'x'), ('needs', 'need'), ('account', 'account'), ('possible', 'possibl'), ('values', 'valu'), ('z', 'z'), ('weighted', 'weight'), ('probabilities', 'probabl'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('value', 'value'), ('hidden', 'hidden'), ('variables', 'variable'), ('z', 'z'), ('known', 'known'), (',', ','), ('hence', 'hence'), ('probability', 'probability'), ('observation', 'observation'), ('x', 'x'), ('needs', 'need'), ('account', 'account'), ('possible', 'possible'), ('values', 'value'), ('z', 'z'), ('weighted', 'weighted'), ('probabilities', 'probability'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('.', '.')]



============================ Sentence 438 =============================

This creates a number of technical challenges. 


>> Tokens are: 
 ['This', 'creates', 'number', 'technical', 'challenges', '.']

>> Bigrams are: 
 [('This', 'creates'), ('creates', 'number'), ('number', 'technical'), ('technical', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('This', 'creates', 'number'), ('creates', 'number', 'technical'), ('number', 'technical', 'challenges'), ('technical', 'challenges', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('creates', 'VBZ'), ('number', 'NN'), ('technical', 'JJ'), ('challenges', 'NNS'), ('.', '.')]

 (S
  This/DT
  creates/VBZ
  (NP number/NN)
  (NP technical/JJ challenges/NNS)
  ./.) 


>> Noun Phrases are: 
 ['number', 'technical challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('creates', 'creat'), ('number', 'number'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('creates', 'creat'), ('number', 'number'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('creates', 'creates'), ('number', 'number'), ('technical', 'technical'), ('challenges', 'challenge'), ('.', '.')]



============================ Sentence 439 =============================

First, the objective in (14) is generally more complex to optimize, since the average over z destroys the typical structure of the model p(x|z, θ), whose logarithm is often selected as a tractable function (see, e.g.-.-, logistic re- gression). 


>> Tokens are: 
 ['First', ',', 'objective', '(', '14', ')', 'generally', 'complex', 'optimize', ',', 'since', 'average', 'z', 'destroys', 'typical', 'structure', 'model', 'p', '(', 'x|z', ',', 'θ', ')', ',', 'whose', 'logarithm', 'often', 'selected', 'tractable', 'function', '(', 'see', ',', 'e.g.-.-', ',', 'logistic', 're-', 'gression', ')', '.']

>> Bigrams are: 
 [('First', ','), (',', 'objective'), ('objective', '('), ('(', '14'), ('14', ')'), (')', 'generally'), ('generally', 'complex'), ('complex', 'optimize'), ('optimize', ','), (',', 'since'), ('since', 'average'), ('average', 'z'), ('z', 'destroys'), ('destroys', 'typical'), ('typical', 'structure'), ('structure', 'model'), ('model', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ','), (',', 'whose'), ('whose', 'logarithm'), ('logarithm', 'often'), ('often', 'selected'), ('selected', 'tractable'), ('tractable', 'function'), ('function', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'logistic'), ('logistic', 're-'), ('re-', 'gression'), ('gression', ')'), (')', '.')]

>> Trigrams are: 
 [('First', ',', 'objective'), (',', 'objective', '('), ('objective', '(', '14'), ('(', '14', ')'), ('14', ')', 'generally'), (')', 'generally', 'complex'), ('generally', 'complex', 'optimize'), ('complex', 'optimize', ','), ('optimize', ',', 'since'), (',', 'since', 'average'), ('since', 'average', 'z'), ('average', 'z', 'destroys'), ('z', 'destroys', 'typical'), ('destroys', 'typical', 'structure'), ('typical', 'structure', 'model'), ('structure', 'model', 'p'), ('model', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ','), (')', ',', 'whose'), (',', 'whose', 'logarithm'), ('whose', 'logarithm', 'often'), ('logarithm', 'often', 'selected'), ('often', 'selected', 'tractable'), ('selected', 'tractable', 'function'), ('tractable', 'function', '('), ('function', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'logistic'), (',', 'logistic', 're-'), ('logistic', 're-', 'gression'), ('re-', 'gression', ')'), ('gression', ')', '.')]

>> POS Tags are: 
 [('First', 'RB'), (',', ','), ('objective', 'JJ'), ('(', '('), ('14', 'CD'), (')', ')'), ('generally', 'RB'), ('complex', 'JJ'), ('optimize', 'NN'), (',', ','), ('since', 'IN'), ('average', 'JJ'), ('z', 'NN'), ('destroys', 'VBZ'), ('typical', 'JJ'), ('structure', 'NN'), ('model', 'NN'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (',', ','), ('whose', 'WP$'), ('logarithm', 'NN'), ('often', 'RB'), ('selected', 'VBN'), ('tractable', 'JJ'), ('function', 'NN'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('logistic', 'JJ'), ('re-', 'JJ'), ('gression', 'NN'), (')', ')'), ('.', '.')]

 (S
  First/RB
  ,/,
  objective/JJ
  (/(
  14/CD
  )/)
  generally/RB
  (NP complex/JJ optimize/NN)
  ,/,
  since/IN
  (NP average/JJ z/NN)
  destroys/VBZ
  (NP typical/JJ structure/NN model/NN p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  ,/,
  whose/WP$
  (NP logarithm/NN)
  often/RB
  selected/VBN
  (NP tractable/JJ function/NN)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP logistic/JJ re-/JJ gression/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['complex optimize', 'average z', 'typical structure model p', 'θ', 'logarithm', 'tractable function', 'logistic re- gression']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('First', 'first'), (',', ','), ('objective', 'object'), ('(', '('), ('14', '14'), (')', ')'), ('generally', 'gener'), ('complex', 'complex'), ('optimize', 'optim'), (',', ','), ('since', 'sinc'), ('average', 'averag'), ('z', 'z'), ('destroys', 'destroy'), ('typical', 'typic'), ('structure', 'structur'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('whose', 'whose'), ('logarithm', 'logarithm'), ('often', 'often'), ('selected', 'select'), ('tractable', 'tractabl'), ('function', 'function'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('logistic', 'logist'), ('re-', 're-'), ('gression', 'gression'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('First', 'first'), (',', ','), ('objective', 'object'), ('(', '('), ('14', '14'), (')', ')'), ('generally', 'general'), ('complex', 'complex'), ('optimize', 'optim'), (',', ','), ('since', 'sinc'), ('average', 'averag'), ('z', 'z'), ('destroys', 'destroy'), ('typical', 'typic'), ('structure', 'structur'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('whose', 'whose'), ('logarithm', 'logarithm'), ('often', 'often'), ('selected', 'select'), ('tractable', 'tractabl'), ('function', 'function'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('logistic', 'logist'), ('re-', 're-'), ('gression', 'gression'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('First', 'First'), (',', ','), ('objective', 'objective'), ('(', '('), ('14', '14'), (')', ')'), ('generally', 'generally'), ('complex', 'complex'), ('optimize', 'optimize'), (',', ','), ('since', 'since'), ('average', 'average'), ('z', 'z'), ('destroys', 'destroys'), ('typical', 'typical'), ('structure', 'structure'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), ('whose', 'whose'), ('logarithm', 'logarithm'), ('often', 'often'), ('selected', 'selected'), ('tractable', 'tractable'), ('function', 'function'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('logistic', 'logistic'), ('re-', 're-'), ('gression', 'gression'), (')', ')'), ('.', '.')]



============================ Sentence 440 =============================

Second, the average in (14) cannot be directly approximated using Monte Carlo methods if the goal is to optimize over the model parameters θ, given that the distribution p(z|θ) generally depends on θ itself. 


>> Tokens are: 
 ['Second', ',', 'average', '(', '14', ')', 'directly', 'approximated', 'using', 'Monte', 'Carlo', 'methods', 'goal', 'optimize', 'model', 'parameters', 'θ', ',', 'given', 'distribution', 'p', '(', 'z|θ', ')', 'generally', 'depends', 'θ', '.']

>> Bigrams are: 
 [('Second', ','), (',', 'average'), ('average', '('), ('(', '14'), ('14', ')'), (')', 'directly'), ('directly', 'approximated'), ('approximated', 'using'), ('using', 'Monte'), ('Monte', 'Carlo'), ('Carlo', 'methods'), ('methods', 'goal'), ('goal', 'optimize'), ('optimize', 'model'), ('model', 'parameters'), ('parameters', 'θ'), ('θ', ','), (',', 'given'), ('given', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', 'generally'), ('generally', 'depends'), ('depends', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('Second', ',', 'average'), (',', 'average', '('), ('average', '(', '14'), ('(', '14', ')'), ('14', ')', 'directly'), (')', 'directly', 'approximated'), ('directly', 'approximated', 'using'), ('approximated', 'using', 'Monte'), ('using', 'Monte', 'Carlo'), ('Monte', 'Carlo', 'methods'), ('Carlo', 'methods', 'goal'), ('methods', 'goal', 'optimize'), ('goal', 'optimize', 'model'), ('optimize', 'model', 'parameters'), ('model', 'parameters', 'θ'), ('parameters', 'θ', ','), ('θ', ',', 'given'), (',', 'given', 'distribution'), ('given', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', 'generally'), (')', 'generally', 'depends'), ('generally', 'depends', 'θ'), ('depends', 'θ', '.')]

>> POS Tags are: 
 [('Second', 'JJ'), (',', ','), ('average', 'JJ'), ('(', '('), ('14', 'CD'), (')', ')'), ('directly', 'RB'), ('approximated', 'VBN'), ('using', 'VBG'), ('Monte', 'NNP'), ('Carlo', 'NNP'), ('methods', 'NNS'), ('goal', 'NN'), ('optimize', 'VBP'), ('model', 'NN'), ('parameters', 'NNS'), ('θ', 'VBP'), (',', ','), ('given', 'VBN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('z|θ', 'NN'), (')', ')'), ('generally', 'RB'), ('depends', 'VBZ'), ('θ', 'NN'), ('.', '.')]

 (S
  Second/JJ
  ,/,
  average/JJ
  (/(
  14/CD
  )/)
  directly/RB
  approximated/VBN
  using/VBG
  (NP Monte/NNP Carlo/NNP methods/NNS goal/NN)
  optimize/VBP
  (NP model/NN parameters/NNS)
  θ/VBP
  ,/,
  given/VBN
  (NP distribution/NN p/NN)
  (/(
  (NP z|θ/NN)
  )/)
  generally/RB
  depends/VBZ
  (NP θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['Monte Carlo methods goal', 'model parameters', 'distribution p', 'z|θ', 'θ']

>> Named Entities are: 
 [('GPE', 'Second'), ('PERSON', 'Monte Carlo')] 

>> Stemming using Porter Stemmer: 
 [('Second', 'second'), (',', ','), ('average', 'averag'), ('(', '('), ('14', '14'), (')', ')'), ('directly', 'directli'), ('approximated', 'approxim'), ('using', 'use'), ('Monte', 'mont'), ('Carlo', 'carlo'), ('methods', 'method'), ('goal', 'goal'), ('optimize', 'optim'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('given', 'given'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('generally', 'gener'), ('depends', 'depend'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Second', 'second'), (',', ','), ('average', 'averag'), ('(', '('), ('14', '14'), (')', ')'), ('directly', 'direct'), ('approximated', 'approxim'), ('using', 'use'), ('Monte', 'mont'), ('Carlo', 'carlo'), ('methods', 'method'), ('goal', 'goal'), ('optimize', 'optim'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('given', 'given'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('generally', 'general'), ('depends', 'depend'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('Second', 'Second'), (',', ','), ('average', 'average'), ('(', '('), ('14', '14'), (')', ')'), ('directly', 'directly'), ('approximated', 'approximated'), ('using', 'using'), ('Monte', 'Monte'), ('Carlo', 'Carlo'), ('methods', 'method'), ('goal', 'goal'), ('optimize', 'optimize'), ('model', 'model'), ('parameters', 'parameter'), ('θ', 'θ'), (',', ','), ('given', 'given'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), ('generally', 'generally'), ('depends', 'depends'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 441 =============================

To tackle these issues, a standard approach is based on the introduction of a variational distribution q(z)  over the hidden variables and on the optimization of a tractable lower bound on the log-likelihood known as the Evidence Lower BOund (ELBO). 


>> Tokens are: 
 ['To', 'tackle', 'issues', ',', 'standard', 'approach', 'based', 'introduction', 'variational', 'distribution', 'q', '(', 'z', ')', 'hidden', 'variables', 'optimization', 'tractable', 'lower', 'bound', 'log-likelihood', 'known', 'Evidence', 'Lower', 'BOund', '(', 'ELBO', ')', '.']

>> Bigrams are: 
 [('To', 'tackle'), ('tackle', 'issues'), ('issues', ','), (',', 'standard'), ('standard', 'approach'), ('approach', 'based'), ('based', 'introduction'), ('introduction', 'variational'), ('variational', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', 'hidden'), ('hidden', 'variables'), ('variables', 'optimization'), ('optimization', 'tractable'), ('tractable', 'lower'), ('lower', 'bound'), ('bound', 'log-likelihood'), ('log-likelihood', 'known'), ('known', 'Evidence'), ('Evidence', 'Lower'), ('Lower', 'BOund'), ('BOund', '('), ('(', 'ELBO'), ('ELBO', ')'), (')', '.')]

>> Trigrams are: 
 [('To', 'tackle', 'issues'), ('tackle', 'issues', ','), ('issues', ',', 'standard'), (',', 'standard', 'approach'), ('standard', 'approach', 'based'), ('approach', 'based', 'introduction'), ('based', 'introduction', 'variational'), ('introduction', 'variational', 'distribution'), ('variational', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', 'hidden'), (')', 'hidden', 'variables'), ('hidden', 'variables', 'optimization'), ('variables', 'optimization', 'tractable'), ('optimization', 'tractable', 'lower'), ('tractable', 'lower', 'bound'), ('lower', 'bound', 'log-likelihood'), ('bound', 'log-likelihood', 'known'), ('log-likelihood', 'known', 'Evidence'), ('known', 'Evidence', 'Lower'), ('Evidence', 'Lower', 'BOund'), ('Lower', 'BOund', '('), ('BOund', '(', 'ELBO'), ('(', 'ELBO', ')'), ('ELBO', ')', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('tackle', 'VB'), ('issues', 'NNS'), (',', ','), ('standard', 'JJ'), ('approach', 'NN'), ('based', 'VBN'), ('introduction', 'NN'), ('variational', 'JJ'), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('hidden', 'NN'), ('variables', 'NNS'), ('optimization', 'VBP'), ('tractable', 'JJ'), ('lower', 'JJR'), ('bound', 'IN'), ('log-likelihood', 'JJ'), ('known', 'VBN'), ('Evidence', 'NNP'), ('Lower', 'NNP'), ('BOund', 'NNP'), ('(', '('), ('ELBO', 'NNP'), (')', ')'), ('.', '.')]

 (S
  To/TO
  tackle/VB
  (NP issues/NNS)
  ,/,
  (NP standard/JJ approach/NN)
  based/VBN
  (NP introduction/NN)
  (NP variational/JJ distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  (NP hidden/NN variables/NNS)
  optimization/VBP
  tractable/JJ
  lower/JJR
  bound/IN
  log-likelihood/JJ
  known/VBN
  (NP Evidence/NNP Lower/NNP BOund/NNP)
  (/(
  (NP ELBO/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['issues', 'standard approach', 'introduction', 'variational distribution q', 'z', 'hidden variables', 'Evidence Lower BOund', 'ELBO']

>> Named Entities are: 
 [('PERSON', 'Evidence Lower'), ('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('tackle', 'tackl'), ('issues', 'issu'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('based', 'base'), ('introduction', 'introduct'), ('variational', 'variat'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('hidden', 'hidden'), ('variables', 'variabl'), ('optimization', 'optim'), ('tractable', 'tractabl'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('known', 'known'), ('Evidence', 'evid'), ('Lower', 'lower'), ('BOund', 'bound'), ('(', '('), ('ELBO', 'elbo'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('tackle', 'tackl'), ('issues', 'issu'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('based', 'base'), ('introduction', 'introduct'), ('variational', 'variat'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('hidden', 'hidden'), ('variables', 'variabl'), ('optimization', 'optim'), ('tractable', 'tractabl'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('known', 'known'), ('Evidence', 'evid'), ('Lower', 'lower'), ('BOund', 'bound'), ('(', '('), ('ELBO', 'elbo'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('tackle', 'tackle'), ('issues', 'issue'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('based', 'based'), ('introduction', 'introduction'), ('variational', 'variational'), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('hidden', 'hidden'), ('variables', 'variable'), ('optimization', 'optimization'), ('tractable', 'tractable'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('known', 'known'), ('Evidence', 'Evidence'), ('Lower', 'Lower'), ('BOund', 'BOund'), ('(', '('), ('ELBO', 'ELBO'), (')', ')'), ('.', '.')]



============================ Sentence 442 =============================

To elaborate, for any fixed value x and any distribution q(z) on the latent variables z (possibly dependent on x), the ELBO L(q, θ) is defined as  L(q, θ) = Ez∼q(z)[ln p(x|z, θ)]−KL(q(z)||p(z|θ)), (15)  where KL(q||p) = Ez∼q(z)[ln(q(z)/p(z))] is the Kullback-Leibler (KL) divergence. 


>> Tokens are: 
 ['To', 'elaborate', ',', 'fixed', 'value', 'x', 'distribution', 'q', '(', 'z', ')', 'latent', 'variables', 'z', '(', 'possibly', 'dependent', 'x', ')', ',', 'ELBO', 'L', '(', 'q', ',', 'θ', ')', 'defined', 'L', '(', 'q', ',', 'θ', ')', '=', 'Ez∼q', '(', 'z', ')', '[', 'ln', 'p', '(', 'x|z', ',', 'θ', ')', ']', '−KL', '(', 'q', '(', 'z', ')', '||p', '(', 'z|θ', ')', ')', ',', '(', '15', ')', 'KL', '(', 'q||p', ')', '=', 'Ez∼q', '(', 'z', ')', '[', 'ln', '(', 'q', '(', 'z', ')', '/p', '(', 'z', ')', ')', ']', 'Kullback-Leibler', '(', 'KL', ')', 'divergence', '.']

>> Bigrams are: 
 [('To', 'elaborate'), ('elaborate', ','), (',', 'fixed'), ('fixed', 'value'), ('value', 'x'), ('x', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', 'latent'), ('latent', 'variables'), ('variables', 'z'), ('z', '('), ('(', 'possibly'), ('possibly', 'dependent'), ('dependent', 'x'), ('x', ')'), (')', ','), (',', 'ELBO'), ('ELBO', 'L'), ('L', '('), ('(', 'q'), ('q', ','), (',', 'θ'), ('θ', ')'), (')', 'defined'), ('defined', 'L'), ('L', '('), ('(', 'q'), ('q', ','), (',', 'θ'), ('θ', ')'), (')', '='), ('=', 'Ez∼q'), ('Ez∼q', '('), ('(', 'z'), ('z', ')'), (')', '['), ('[', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ']'), (']', '−KL'), ('−KL', '('), ('(', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', '||p'), ('||p', '('), ('(', 'z|θ'), ('z|θ', ')'), (')', ')'), (')', ','), (',', '('), ('(', '15'), ('15', ')'), (')', 'KL'), ('KL', '('), ('(', 'q||p'), ('q||p', ')'), (')', '='), ('=', 'Ez∼q'), ('Ez∼q', '('), ('(', 'z'), ('z', ')'), (')', '['), ('[', 'ln'), ('ln', '('), ('(', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', '/p'), ('/p', '('), ('(', 'z'), ('z', ')'), (')', ')'), (')', ']'), (']', 'Kullback-Leibler'), ('Kullback-Leibler', '('), ('(', 'KL'), ('KL', ')'), (')', 'divergence'), ('divergence', '.')]

>> Trigrams are: 
 [('To', 'elaborate', ','), ('elaborate', ',', 'fixed'), (',', 'fixed', 'value'), ('fixed', 'value', 'x'), ('value', 'x', 'distribution'), ('x', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', 'latent'), (')', 'latent', 'variables'), ('latent', 'variables', 'z'), ('variables', 'z', '('), ('z', '(', 'possibly'), ('(', 'possibly', 'dependent'), ('possibly', 'dependent', 'x'), ('dependent', 'x', ')'), ('x', ')', ','), (')', ',', 'ELBO'), (',', 'ELBO', 'L'), ('ELBO', 'L', '('), ('L', '(', 'q'), ('(', 'q', ','), ('q', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'defined'), (')', 'defined', 'L'), ('defined', 'L', '('), ('L', '(', 'q'), ('(', 'q', ','), ('q', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '='), (')', '=', 'Ez∼q'), ('=', 'Ez∼q', '('), ('Ez∼q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '['), (')', '[', 'ln'), ('[', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ']'), (')', ']', '−KL'), (']', '−KL', '('), ('−KL', '(', 'q'), ('(', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '||p'), (')', '||p', '('), ('||p', '(', 'z|θ'), ('(', 'z|θ', ')'), ('z|θ', ')', ')'), (')', ')', ','), (')', ',', '('), (',', '(', '15'), ('(', '15', ')'), ('15', ')', 'KL'), (')', 'KL', '('), ('KL', '(', 'q||p'), ('(', 'q||p', ')'), ('q||p', ')', '='), (')', '=', 'Ez∼q'), ('=', 'Ez∼q', '('), ('Ez∼q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '['), (')', '[', 'ln'), ('[', 'ln', '('), ('ln', '(', 'q'), ('(', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '/p'), (')', '/p', '('), ('/p', '(', 'z'), ('(', 'z', ')'), ('z', ')', ')'), (')', ')', ']'), (')', ']', 'Kullback-Leibler'), (']', 'Kullback-Leibler', '('), ('Kullback-Leibler', '(', 'KL'), ('(', 'KL', ')'), ('KL', ')', 'divergence'), (')', 'divergence', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('elaborate', 'VB'), (',', ','), ('fixed', 'VBN'), ('value', 'NN'), ('x', 'NNP'), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('latent', 'NN'), ('variables', 'NNS'), ('z', 'VBP'), ('(', '('), ('possibly', 'RB'), ('dependent', 'VB'), ('x', 'NN'), (')', ')'), (',', ','), ('ELBO', 'NNP'), ('L', 'NNP'), ('(', '('), ('q', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('defined', 'VBD'), ('L', 'NNP'), ('(', '('), ('q', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('Ez∼q', 'NNP'), ('(', '('), ('z', 'NN'), (')', ')'), ('[', 'VBZ'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (']', 'VBP'), ('−KL', 'NNP'), ('(', '('), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('||p', 'NN'), ('(', '('), ('z|θ', 'NNP'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('15', 'CD'), (')', ')'), ('KL', 'NNP'), ('(', '('), ('q||p', 'NN'), (')', ')'), ('=', 'NN'), ('Ez∼q', 'NNP'), ('(', '('), ('z', 'NN'), (')', ')'), ('[', 'NN'), ('ln', 'NN'), ('(', '('), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('/p', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), (')', ')'), (']', '$'), ('Kullback-Leibler', 'NNP'), ('(', '('), ('KL', 'NNP'), (')', ')'), ('divergence', 'NN'), ('.', '.')]

 (S
  To/TO
  elaborate/VB
  ,/,
  fixed/VBN
  (NP value/NN x/NNP distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  (NP latent/NN variables/NNS)
  z/VBP
  (/(
  possibly/RB
  dependent/VB
  (NP x/NN)
  )/)
  ,/,
  (NP ELBO/NNP L/NNP)
  (/(
  (NP q/NN)
  ,/,
  (NP θ/NNP)
  )/)
  defined/VBD
  (NP L/NNP)
  (/(
  (NP q/NN)
  ,/,
  (NP θ/NNP)
  )/)
  =/VBP
  (NP Ez∼q/NNP)
  (/(
  (NP z/NN)
  )/)
  [/VBZ
  (NP ln/JJ p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  ]/VBP
  (NP −KL/NNP)
  (/(
  (NP q/NN)
  (/(
  (NP z/NN)
  )/)
  (NP ||p/NN)
  (/(
  (NP z|θ/NNP)
  )/)
  )/)
  ,/,
  (/(
  15/CD
  )/)
  (NP KL/NNP)
  (/(
  (NP q||p/NN)
  )/)
  (NP =/NN Ez∼q/NNP)
  (/(
  (NP z/NN)
  )/)
  (NP [/NN ln/NN)
  (/(
  (NP q/NN)
  (/(
  (NP z/NN)
  )/)
  (NP /p/NN)
  (/(
  (NP z/NN)
  )/)
  )/)
  ]/$
  (NP Kullback-Leibler/NNP)
  (/(
  (NP KL/NNP)
  )/)
  (NP divergence/NN)
  ./.) 


>> Noun Phrases are: 
 ['value x distribution q', 'z', 'latent variables', 'x', 'ELBO L', 'q', 'θ', 'L', 'q', 'θ', 'Ez∼q', 'z', 'ln p', 'θ', '−KL', 'q', 'z', '||p', 'z|θ', 'KL', 'q||p', '= Ez∼q', 'z', '[ ln', 'q', 'z', '/p', 'z', 'Kullback-Leibler', 'KL', 'divergence']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('elaborate', 'elabor'), (',', ','), ('fixed', 'fix'), ('value', 'valu'), ('x', 'x'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), ('(', '('), ('possibly', 'possibl'), ('dependent', 'depend'), ('x', 'x'), (')', ')'), (',', ','), ('ELBO', 'elbo'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('defined', 'defin'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼q', 'ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('−KL', '−kl'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('||p', '||p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('15', '15'), (')', ')'), ('KL', 'kl'), ('(', '('), ('q||p', 'q||p'), (')', ')'), ('=', '='), ('Ez∼q', 'ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('/p', '/p'), ('(', '('), ('z', 'z'), (')', ')'), (')', ')'), (']', ']'), ('Kullback-Leibler', 'kullback-leibl'), ('(', '('), ('KL', 'kl'), (')', ')'), ('divergence', 'diverg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('elaborate', 'elabor'), (',', ','), ('fixed', 'fix'), ('value', 'valu'), ('x', 'x'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), ('(', '('), ('possibly', 'possibl'), ('dependent', 'depend'), ('x', 'x'), (')', ')'), (',', ','), ('ELBO', 'elbo'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('defined', 'defin'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼q', 'ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('−KL', '−kl'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('||p', '||p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('15', '15'), (')', ')'), ('KL', 'kl'), ('(', '('), ('q||p', 'q||p'), (')', ')'), ('=', '='), ('Ez∼q', 'ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('/p', '/p'), ('(', '('), ('z', 'z'), (')', ')'), (')', ')'), (']', ']'), ('Kullback-Leibler', 'kullback-leibl'), ('(', '('), ('KL', 'kl'), (')', ')'), ('divergence', 'diverg'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('elaborate', 'elaborate'), (',', ','), ('fixed', 'fixed'), ('value', 'value'), ('x', 'x'), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('latent', 'latent'), ('variables', 'variable'), ('z', 'z'), ('(', '('), ('possibly', 'possibly'), ('dependent', 'dependent'), ('x', 'x'), (')', ')'), (',', ','), ('ELBO', 'ELBO'), ('L', 'L'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('defined', 'defined'), ('L', 'L'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼q', 'Ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (']', ']'), ('−KL', '−KL'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('||p', '||p'), ('(', '('), ('z|θ', 'z|θ'), (')', ')'), (')', ')'), (',', ','), ('(', '('), ('15', '15'), (')', ')'), ('KL', 'KL'), ('(', '('), ('q||p', 'q||p'), (')', ')'), ('=', '='), ('Ez∼q', 'Ez∼q'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('(', '('), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('/p', '/p'), ('(', '('), ('z', 'z'), (')', ')'), (')', ')'), (']', ']'), ('Kullback-Leibler', 'Kullback-Leibler'), ('(', '('), ('KL', 'KL'), (')', ')'), ('divergence', 'divergence'), ('.', '.')]



============================ Sentence 443 =============================

The latter is a mea- sure of the distance between the two distributions, as we will further discuss in Sec. 


>> Tokens are: 
 ['The', 'latter', 'mea-', 'sure', 'distance', 'two', 'distributions', ',', 'discuss', 'Sec', '.']

>> Bigrams are: 
 [('The', 'latter'), ('latter', 'mea-'), ('mea-', 'sure'), ('sure', 'distance'), ('distance', 'two'), ('two', 'distributions'), ('distributions', ','), (',', 'discuss'), ('discuss', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('The', 'latter', 'mea-'), ('latter', 'mea-', 'sure'), ('mea-', 'sure', 'distance'), ('sure', 'distance', 'two'), ('distance', 'two', 'distributions'), ('two', 'distributions', ','), ('distributions', ',', 'discuss'), (',', 'discuss', 'Sec'), ('discuss', 'Sec', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('latter', 'JJ'), ('mea-', 'JJ'), ('sure', 'JJ'), ('distance', 'NN'), ('two', 'CD'), ('distributions', 'NNS'), (',', ','), ('discuss', 'NN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  (NP The/DT latter/JJ mea-/JJ sure/JJ distance/NN)
  two/CD
  (NP distributions/NNS)
  ,/,
  (NP discuss/NN Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The latter mea- sure distance', 'distributions', 'discuss Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('latter', 'latter'), ('mea-', 'mea-'), ('sure', 'sure'), ('distance', 'distanc'), ('two', 'two'), ('distributions', 'distribut'), (',', ','), ('discuss', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('latter', 'latter'), ('mea-', 'mea-'), ('sure', 'sure'), ('distance', 'distanc'), ('two', 'two'), ('distributions', 'distribut'), (',', ','), ('discuss', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('latter', 'latter'), ('mea-', 'mea-'), ('sure', 'sure'), ('distance', 'distance'), ('two', 'two'), ('distributions', 'distribution'), (',', ','), ('discuss', 'discus'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 444 =============================

V-D (see [59], [60]). 


>> Tokens are: 
 ['V-D', '(', 'see', '[', '59', ']', ',', '[', '60', ']', ')', '.']

>> Bigrams are: 
 [('V-D', '('), ('(', 'see'), ('see', '['), ('[', '59'), ('59', ']'), (']', ','), (',', '['), ('[', '60'), ('60', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('V-D', '(', 'see'), ('(', 'see', '['), ('see', '[', '59'), ('[', '59', ']'), ('59', ']', ','), (']', ',', '['), (',', '[', '60'), ('[', '60', ']'), ('60', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('V-D', 'NNP'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('59', 'CD'), (']', 'NNS'), (',', ','), ('[', 'VBP'), ('60', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP V-D/NNP)
  (/(
  see/VB
  [/RB
  59/CD
  (NP ]/NNS)
  ,/,
  [/VBP
  60/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['V-D', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('V-D', 'v-d'), ('(', '('), ('see', 'see'), ('[', '['), ('59', '59'), (']', ']'), (',', ','), ('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('V-D', 'v-d'), ('(', '('), ('see', 'see'), ('[', '['), ('59', '59'), (']', ']'), (',', ','), ('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('V-D', 'V-D'), ('(', '('), ('see', 'see'), ('[', '['), ('59', '59'), (']', ']'), (',', ','), ('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 445 =============================

The analytical advantages of the ELBO L(q, θ) over the original log-likelihood are that: (i) it entails an expectation of the logarithm of the model p(x|z, θ), which, as mentioned, is typically a tractable function; and (ii) the average is over a fixed distribution q(z), which does not depend on the model parameter θ. 


>> Tokens are: 
 ['The', 'analytical', 'advantages', 'ELBO', 'L', '(', 'q', ',', 'θ', ')', 'original', 'log-likelihood', ':', '(', ')', 'entails', 'expectation', 'logarithm', 'model', 'p', '(', 'x|z', ',', 'θ', ')', ',', ',', 'mentioned', ',', 'typically', 'tractable', 'function', ';', '(', 'ii', ')', 'average', 'fixed', 'distribution', 'q', '(', 'z', ')', ',', 'depend', 'model', 'parameter', 'θ', '.']

>> Bigrams are: 
 [('The', 'analytical'), ('analytical', 'advantages'), ('advantages', 'ELBO'), ('ELBO', 'L'), ('L', '('), ('(', 'q'), ('q', ','), (',', 'θ'), ('θ', ')'), (')', 'original'), ('original', 'log-likelihood'), ('log-likelihood', ':'), (':', '('), ('(', ')'), (')', 'entails'), ('entails', 'expectation'), ('expectation', 'logarithm'), ('logarithm', 'model'), ('model', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ','), (',', 'θ'), ('θ', ')'), (')', ','), (',', ','), (',', 'mentioned'), ('mentioned', ','), (',', 'typically'), ('typically', 'tractable'), ('tractable', 'function'), ('function', ';'), (';', '('), ('(', 'ii'), ('ii', ')'), (')', 'average'), ('average', 'fixed'), ('fixed', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', ','), (',', 'depend'), ('depend', 'model'), ('model', 'parameter'), ('parameter', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('The', 'analytical', 'advantages'), ('analytical', 'advantages', 'ELBO'), ('advantages', 'ELBO', 'L'), ('ELBO', 'L', '('), ('L', '(', 'q'), ('(', 'q', ','), ('q', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', 'original'), (')', 'original', 'log-likelihood'), ('original', 'log-likelihood', ':'), ('log-likelihood', ':', '('), (':', '(', ')'), ('(', ')', 'entails'), (')', 'entails', 'expectation'), ('entails', 'expectation', 'logarithm'), ('expectation', 'logarithm', 'model'), ('logarithm', 'model', 'p'), ('model', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ','), ('x|z', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ','), (')', ',', ','), (',', ',', 'mentioned'), (',', 'mentioned', ','), ('mentioned', ',', 'typically'), (',', 'typically', 'tractable'), ('typically', 'tractable', 'function'), ('tractable', 'function', ';'), ('function', ';', '('), (';', '(', 'ii'), ('(', 'ii', ')'), ('ii', ')', 'average'), (')', 'average', 'fixed'), ('average', 'fixed', 'distribution'), ('fixed', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', ','), (')', ',', 'depend'), (',', 'depend', 'model'), ('depend', 'model', 'parameter'), ('model', 'parameter', 'θ'), ('parameter', 'θ', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('analytical', 'JJ'), ('advantages', 'NNS'), ('ELBO', 'NNP'), ('L', 'NNP'), ('(', '('), ('q', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), ('original', 'JJ'), ('log-likelihood', 'NN'), (':', ':'), ('(', '('), (')', ')'), ('entails', 'VBZ'), ('expectation', 'NN'), ('logarithm', 'NN'), ('model', 'NN'), ('p', 'NN'), ('(', '('), ('x|z', 'UH'), (',', ','), ('θ', 'NNP'), (')', ')'), (',', ','), (',', ','), ('mentioned', 'VBD'), (',', ','), ('typically', 'RB'), ('tractable', 'JJ'), ('function', 'NN'), (';', ':'), ('(', '('), ('ii', 'NN'), (')', ')'), ('average', 'NN'), ('fixed', 'VBN'), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), (',', ','), ('depend', 'VBP'), ('model', 'NN'), ('parameter', 'NN'), ('θ', 'NNP'), ('.', '.')]

 (S
  (NP The/DT analytical/JJ advantages/NNS ELBO/NNP L/NNP)
  (/(
  (NP q/NN)
  ,/,
  (NP θ/NNP)
  )/)
  (NP original/JJ log-likelihood/NN)
  :/:
  (/(
  )/)
  entails/VBZ
  (NP expectation/NN logarithm/NN model/NN p/NN)
  (/(
  x|z/UH
  ,/,
  (NP θ/NNP)
  )/)
  ,/,
  ,/,
  mentioned/VBD
  ,/,
  typically/RB
  (NP tractable/JJ function/NN)
  ;/:
  (/(
  (NP ii/NN)
  )/)
  (NP average/NN)
  fixed/VBN
  (NP distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  ,/,
  depend/VBP
  (NP model/NN parameter/NN θ/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The analytical advantages ELBO L', 'q', 'θ', 'original log-likelihood', 'expectation logarithm model p', 'θ', 'tractable function', 'ii', 'average', 'distribution q', 'z', 'model parameter θ']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('analytical', 'analyt'), ('advantages', 'advantag'), ('ELBO', 'elbo'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('original', 'origin'), ('log-likelihood', 'log-likelihood'), (':', ':'), ('(', '('), (')', ')'), ('entails', 'entail'), ('expectation', 'expect'), ('logarithm', 'logarithm'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), (',', ','), ('mentioned', 'mention'), (',', ','), ('typically', 'typic'), ('tractable', 'tractabl'), ('function', 'function'), (';', ';'), ('(', '('), ('ii', 'ii'), (')', ')'), ('average', 'averag'), ('fixed', 'fix'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('depend', 'depend'), ('model', 'model'), ('parameter', 'paramet'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('analytical', 'analyt'), ('advantages', 'advantag'), ('ELBO', 'elbo'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('original', 'origin'), ('log-likelihood', 'log-likelihood'), (':', ':'), ('(', '('), (')', ')'), ('entails', 'entail'), ('expectation', 'expect'), ('logarithm', 'logarithm'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), (',', ','), ('mentioned', 'mention'), (',', ','), ('typically', 'typic'), ('tractable', 'tractabl'), ('function', 'function'), (';', ';'), ('(', '('), ('ii', 'ii'), (')', ')'), ('average', 'averag'), ('fixed', 'fix'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('depend', 'depend'), ('model', 'model'), ('parameter', 'paramet'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('analytical', 'analytical'), ('advantages', 'advantage'), ('ELBO', 'ELBO'), ('L', 'L'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('original', 'original'), ('log-likelihood', 'log-likelihood'), (':', ':'), ('(', '('), (')', ')'), ('entails', 'entail'), ('expectation', 'expectation'), ('logarithm', 'logarithm'), ('model', 'model'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (',', ','), ('θ', 'θ'), (')', ')'), (',', ','), (',', ','), ('mentioned', 'mentioned'), (',', ','), ('typically', 'typically'), ('tractable', 'tractable'), ('function', 'function'), (';', ';'), ('(', '('), ('ii', 'ii'), (')', ')'), ('average', 'average'), ('fixed', 'fixed'), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('depend', 'depend'), ('model', 'model'), ('parameter', 'parameter'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 446 =============================

Using Jensen’s inequality, it can be seen that the ELBO (15) is a global lower bound on the log-likelihood function, that is,  ln p(x|θ) ≥ L(q, θ). 


>> Tokens are: 
 ['Using', 'Jensen', '’', 'inequality', ',', 'seen', 'ELBO', '(', '15', ')', 'global', 'lower', 'bound', 'log-likelihood', 'function', ',', ',', 'ln', 'p', '(', 'x|θ', ')', '≥', 'L', '(', 'q', ',', 'θ', ')', '.']

>> Bigrams are: 
 [('Using', 'Jensen'), ('Jensen', '’'), ('’', 'inequality'), ('inequality', ','), (',', 'seen'), ('seen', 'ELBO'), ('ELBO', '('), ('(', '15'), ('15', ')'), (')', 'global'), ('global', 'lower'), ('lower', 'bound'), ('bound', 'log-likelihood'), ('log-likelihood', 'function'), ('function', ','), (',', ','), (',', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', '≥'), ('≥', 'L'), ('L', '('), ('(', 'q'), ('q', ','), (',', 'θ'), ('θ', ')'), (')', '.')]

>> Trigrams are: 
 [('Using', 'Jensen', '’'), ('Jensen', '’', 'inequality'), ('’', 'inequality', ','), ('inequality', ',', 'seen'), (',', 'seen', 'ELBO'), ('seen', 'ELBO', '('), ('ELBO', '(', '15'), ('(', '15', ')'), ('15', ')', 'global'), (')', 'global', 'lower'), ('global', 'lower', 'bound'), ('lower', 'bound', 'log-likelihood'), ('bound', 'log-likelihood', 'function'), ('log-likelihood', 'function', ','), ('function', ',', ','), (',', ',', 'ln'), (',', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', '≥'), (')', '≥', 'L'), ('≥', 'L', '('), ('L', '(', 'q'), ('(', 'q', ','), ('q', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '.')]

>> POS Tags are: 
 [('Using', 'VBG'), ('Jensen', 'NNP'), ('’', 'NNP'), ('inequality', 'NN'), (',', ','), ('seen', 'VBN'), ('ELBO', 'NNP'), ('(', '('), ('15', 'CD'), (')', ')'), ('global', 'JJ'), ('lower', 'JJR'), ('bound', 'IN'), ('log-likelihood', 'JJ'), ('function', 'NN'), (',', ','), (',', ','), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('≥', 'VBP'), ('L', 'NNP'), ('(', '('), ('q', 'NN'), (',', ','), ('θ', 'NN'), (')', ')'), ('.', '.')]

 (S
  Using/VBG
  (NP Jensen/NNP ’/NNP inequality/NN)
  ,/,
  seen/VBN
  (NP ELBO/NNP)
  (/(
  15/CD
  )/)
  global/JJ
  lower/JJR
  bound/IN
  (NP log-likelihood/JJ function/NN)
  ,/,
  ,/,
  (NP ln/JJ p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  ≥/VBP
  (NP L/NNP)
  (/(
  (NP q/NN)
  ,/,
  (NP θ/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Jensen ’ inequality', 'ELBO', 'log-likelihood function', 'ln p', 'x|θ', 'L', 'q', 'θ']

>> Named Entities are: 
 [('PERSON', 'Jensen'), ('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('Jensen', 'jensen'), ('’', '’'), ('inequality', 'inequ'), (',', ','), ('seen', 'seen'), ('ELBO', 'elbo'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), (',', ','), (',', ','), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('≥', '≥'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('Jensen', 'jensen'), ('’', '’'), ('inequality', 'inequ'), (',', ','), ('seen', 'seen'), ('ELBO', 'elbo'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), (',', ','), (',', ','), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('≥', '≥'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Using', 'Using'), ('Jensen', 'Jensen'), ('’', '’'), ('inequality', 'inequality'), (',', ','), ('seen', 'seen'), ('ELBO', 'ELBO'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('function', 'function'), (',', ','), (',', ','), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('≥', '≥'), ('L', 'L'), ('(', '('), ('q', 'q'), (',', ','), ('θ', 'θ'), (')', ')'), ('.', '.')]



============================ Sentence 447 =============================

(16)  An illustration of the lower bounding property of the ELBO can be found in Fig. 


>> Tokens are: 
 ['(', '16', ')', 'An', 'illustration', 'lower', 'bounding', 'property', 'ELBO', 'found', 'Fig', '.']

>> Bigrams are: 
 [('(', '16'), ('16', ')'), (')', 'An'), ('An', 'illustration'), ('illustration', 'lower'), ('lower', 'bounding'), ('bounding', 'property'), ('property', 'ELBO'), ('ELBO', 'found'), ('found', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('(', '16', ')'), ('16', ')', 'An'), (')', 'An', 'illustration'), ('An', 'illustration', 'lower'), ('illustration', 'lower', 'bounding'), ('lower', 'bounding', 'property'), ('bounding', 'property', 'ELBO'), ('property', 'ELBO', 'found'), ('ELBO', 'found', 'Fig'), ('found', 'Fig', '.')]

>> POS Tags are: 
 [('(', '('), ('16', 'CD'), (')', ')'), ('An', 'DT'), ('illustration', 'NN'), ('lower', 'RBR'), ('bounding', 'VBG'), ('property', 'NN'), ('ELBO', 'NNP'), ('found', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (/(
  16/CD
  )/)
  (NP An/DT illustration/NN)
  lower/RBR
  bounding/VBG
  (NP property/NN ELBO/NNP)
  found/VBD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['An illustration', 'property ELBO', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO'), ('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('16', '16'), (')', ')'), ('An', 'an'), ('illustration', 'illustr'), ('lower', 'lower'), ('bounding', 'bound'), ('property', 'properti'), ('ELBO', 'elbo'), ('found', 'found'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('16', '16'), (')', ')'), ('An', 'an'), ('illustration', 'illustr'), ('lower', 'lower'), ('bounding', 'bound'), ('property', 'properti'), ('ELBO', 'elbo'), ('found', 'found'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('16', '16'), (')', ')'), ('An', 'An'), ('illustration', 'illustration'), ('lower', 'lower'), ('bounding', 'bounding'), ('property', 'property'), ('ELBO', 'ELBO'), ('found', 'found'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 448 =============================

12. 


>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

 (S 12/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]



============================ Sentence 449 =============================

An important feature of this inequality is that the ELBO “touches” the log- likelihood function at values θ0, if any, for which the distribution q(z) satisfies the equality  q(z) = p(z|x, θ0). 


>> Tokens are: 
 ['An', 'important', 'feature', 'inequality', 'ELBO', '“', 'touches', '”', 'log-', 'likelihood', 'function', 'values', 'θ0', ',', ',', 'distribution', 'q', '(', 'z', ')', 'satisfies', 'equality', 'q', '(', 'z', ')', '=', 'p', '(', 'z|x', ',', 'θ0', ')', '.']

>> Bigrams are: 
 [('An', 'important'), ('important', 'feature'), ('feature', 'inequality'), ('inequality', 'ELBO'), ('ELBO', '“'), ('“', 'touches'), ('touches', '”'), ('”', 'log-'), ('log-', 'likelihood'), ('likelihood', 'function'), ('function', 'values'), ('values', 'θ0'), ('θ0', ','), (',', ','), (',', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', 'satisfies'), ('satisfies', 'equality'), ('equality', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', 'p'), ('p', '('), ('(', 'z|x'), ('z|x', ','), (',', 'θ0'), ('θ0', ')'), (')', '.')]

>> Trigrams are: 
 [('An', 'important', 'feature'), ('important', 'feature', 'inequality'), ('feature', 'inequality', 'ELBO'), ('inequality', 'ELBO', '“'), ('ELBO', '“', 'touches'), ('“', 'touches', '”'), ('touches', '”', 'log-'), ('”', 'log-', 'likelihood'), ('log-', 'likelihood', 'function'), ('likelihood', 'function', 'values'), ('function', 'values', 'θ0'), ('values', 'θ0', ','), ('θ0', ',', ','), (',', ',', 'distribution'), (',', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', 'satisfies'), (')', 'satisfies', 'equality'), ('satisfies', 'equality', 'q'), ('equality', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', 'p'), ('=', 'p', '('), ('p', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'θ0'), (',', 'θ0', ')'), ('θ0', ')', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('important', 'JJ'), ('feature', 'NN'), ('inequality', 'NN'), ('ELBO', 'NNP'), ('“', 'NNP'), ('touches', 'NNS'), ('”', 'VBD'), ('log-', 'JJ'), ('likelihood', 'NN'), ('function', 'NN'), ('values', 'NNS'), ('θ0', 'NNP'), (',', ','), (',', ','), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('satisfies', 'VBZ'), ('equality', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'NN'), ('p', 'NN'), ('(', '('), ('z|x', 'NN'), (',', ','), ('θ0', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP
    An/DT
    important/JJ
    feature/NN
    inequality/NN
    ELBO/NNP
    “/NNP
    touches/NNS)
  ”/VBD
  (NP log-/JJ likelihood/NN function/NN values/NNS θ0/NNP)
  ,/,
  ,/,
  (NP distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  satisfies/VBZ
  (NP equality/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  (NP =/NN p/NN)
  (/(
  (NP z|x/NN)
  ,/,
  (NP θ0/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['An important feature inequality ELBO “ touches', 'log- likelihood function values θ0', 'distribution q', 'z', 'equality q', 'z', '= p', 'z|x', 'θ0']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('important', 'import'), ('feature', 'featur'), ('inequality', 'inequ'), ('ELBO', 'elbo'), ('“', '“'), ('touches', 'touch'), ('”', '”'), ('log-', 'log-'), ('likelihood', 'likelihood'), ('function', 'function'), ('values', 'valu'), ('θ0', 'θ0'), (',', ','), (',', ','), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('satisfies', 'satisfi'), ('equality', 'equal'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ0', 'θ0'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('important', 'import'), ('feature', 'featur'), ('inequality', 'inequ'), ('ELBO', 'elbo'), ('“', '“'), ('touches', 'touch'), ('”', '”'), ('log-', 'log-'), ('likelihood', 'likelihood'), ('function', 'function'), ('values', 'valu'), ('θ0', 'θ0'), (',', ','), (',', ','), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('satisfies', 'satisfi'), ('equality', 'equal'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ0', 'θ0'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('important', 'important'), ('feature', 'feature'), ('inequality', 'inequality'), ('ELBO', 'ELBO'), ('“', '“'), ('touches', 'touch'), ('”', '”'), ('log-', 'log-'), ('likelihood', 'likelihood'), ('function', 'function'), ('values', 'value'), ('θ0', 'θ0'), (',', ','), (',', ','), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('satisfies', 'satisfies'), ('equality', 'equality'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ0', 'θ0'), (')', ')'), ('.', '.')]



============================ Sentence 450 =============================

(17)  In words, the ELBO is tight if the variational distribution is selected to equal the posterior distribution of the hidden variables given the observation x under the model parameter θ0. 


>> Tokens are: 
 ['(', '17', ')', 'In', 'words', ',', 'ELBO', 'tight', 'variational', 'distribution', 'selected', 'equal', 'posterior', 'distribution', 'hidden', 'variables', 'given', 'observation', 'x', 'model', 'parameter', 'θ0', '.']

>> Bigrams are: 
 [('(', '17'), ('17', ')'), (')', 'In'), ('In', 'words'), ('words', ','), (',', 'ELBO'), ('ELBO', 'tight'), ('tight', 'variational'), ('variational', 'distribution'), ('distribution', 'selected'), ('selected', 'equal'), ('equal', 'posterior'), ('posterior', 'distribution'), ('distribution', 'hidden'), ('hidden', 'variables'), ('variables', 'given'), ('given', 'observation'), ('observation', 'x'), ('x', 'model'), ('model', 'parameter'), ('parameter', 'θ0'), ('θ0', '.')]

>> Trigrams are: 
 [('(', '17', ')'), ('17', ')', 'In'), (')', 'In', 'words'), ('In', 'words', ','), ('words', ',', 'ELBO'), (',', 'ELBO', 'tight'), ('ELBO', 'tight', 'variational'), ('tight', 'variational', 'distribution'), ('variational', 'distribution', 'selected'), ('distribution', 'selected', 'equal'), ('selected', 'equal', 'posterior'), ('equal', 'posterior', 'distribution'), ('posterior', 'distribution', 'hidden'), ('distribution', 'hidden', 'variables'), ('hidden', 'variables', 'given'), ('variables', 'given', 'observation'), ('given', 'observation', 'x'), ('observation', 'x', 'model'), ('x', 'model', 'parameter'), ('model', 'parameter', 'θ0'), ('parameter', 'θ0', '.')]

>> POS Tags are: 
 [('(', '('), ('17', 'CD'), (')', ')'), ('In', 'IN'), ('words', 'NNS'), (',', ','), ('ELBO', 'NNP'), ('tight', 'VBD'), ('variational', 'JJ'), ('distribution', 'NN'), ('selected', 'VBN'), ('equal', 'JJ'), ('posterior', 'JJ'), ('distribution', 'NN'), ('hidden', 'NN'), ('variables', 'NNS'), ('given', 'VBN'), ('observation', 'NN'), ('x', 'NNP'), ('model', 'NN'), ('parameter', 'NN'), ('θ0', 'NNP'), ('.', '.')]

 (S
  (/(
  17/CD
  )/)
  In/IN
  (NP words/NNS)
  ,/,
  (NP ELBO/NNP)
  tight/VBD
  (NP variational/JJ distribution/NN)
  selected/VBN
  (NP equal/JJ posterior/JJ distribution/NN hidden/NN variables/NNS)
  given/VBN
  (NP observation/NN x/NNP model/NN parameter/NN θ0/NNP)
  ./.) 


>> Noun Phrases are: 
 ['words', 'ELBO', 'variational distribution', 'equal posterior distribution hidden variables', 'observation x model parameter θ0']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('17', '17'), (')', ')'), ('In', 'in'), ('words', 'word'), (',', ','), ('ELBO', 'elbo'), ('tight', 'tight'), ('variational', 'variat'), ('distribution', 'distribut'), ('selected', 'select'), ('equal', 'equal'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('variables', 'variabl'), ('given', 'given'), ('observation', 'observ'), ('x', 'x'), ('model', 'model'), ('parameter', 'paramet'), ('θ0', 'θ0'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('17', '17'), (')', ')'), ('In', 'in'), ('words', 'word'), (',', ','), ('ELBO', 'elbo'), ('tight', 'tight'), ('variational', 'variat'), ('distribution', 'distribut'), ('selected', 'select'), ('equal', 'equal'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('variables', 'variabl'), ('given', 'given'), ('observation', 'observ'), ('x', 'x'), ('model', 'model'), ('parameter', 'paramet'), ('θ0', 'θ0'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('17', '17'), (')', ')'), ('In', 'In'), ('words', 'word'), (',', ','), ('ELBO', 'ELBO'), ('tight', 'tight'), ('variational', 'variational'), ('distribution', 'distribution'), ('selected', 'selected'), ('equal', 'equal'), ('posterior', 'posterior'), ('distribution', 'distribution'), ('hidden', 'hidden'), ('variables', 'variable'), ('given', 'given'), ('observation', 'observation'), ('x', 'x'), ('model', 'model'), ('parameter', 'parameter'), ('θ0', 'θ0'), ('.', '.')]



============================ Sentence 451 =============================

Stated less formally, in order to ensure that the ELBO is tight at a value θ0, one needs to solve the problem of inferring the distribution of the hidden variables z given the observation x under the model identified by the value θ0. 


>> Tokens are: 
 ['Stated', 'less', 'formally', ',', 'order', 'ensure', 'ELBO', 'tight', 'value', 'θ0', ',', 'one', 'needs', 'solve', 'problem', 'inferring', 'distribution', 'hidden', 'variables', 'z', 'given', 'observation', 'x', 'model', 'identified', 'value', 'θ0', '.']

>> Bigrams are: 
 [('Stated', 'less'), ('less', 'formally'), ('formally', ','), (',', 'order'), ('order', 'ensure'), ('ensure', 'ELBO'), ('ELBO', 'tight'), ('tight', 'value'), ('value', 'θ0'), ('θ0', ','), (',', 'one'), ('one', 'needs'), ('needs', 'solve'), ('solve', 'problem'), ('problem', 'inferring'), ('inferring', 'distribution'), ('distribution', 'hidden'), ('hidden', 'variables'), ('variables', 'z'), ('z', 'given'), ('given', 'observation'), ('observation', 'x'), ('x', 'model'), ('model', 'identified'), ('identified', 'value'), ('value', 'θ0'), ('θ0', '.')]

>> Trigrams are: 
 [('Stated', 'less', 'formally'), ('less', 'formally', ','), ('formally', ',', 'order'), (',', 'order', 'ensure'), ('order', 'ensure', 'ELBO'), ('ensure', 'ELBO', 'tight'), ('ELBO', 'tight', 'value'), ('tight', 'value', 'θ0'), ('value', 'θ0', ','), ('θ0', ',', 'one'), (',', 'one', 'needs'), ('one', 'needs', 'solve'), ('needs', 'solve', 'problem'), ('solve', 'problem', 'inferring'), ('problem', 'inferring', 'distribution'), ('inferring', 'distribution', 'hidden'), ('distribution', 'hidden', 'variables'), ('hidden', 'variables', 'z'), ('variables', 'z', 'given'), ('z', 'given', 'observation'), ('given', 'observation', 'x'), ('observation', 'x', 'model'), ('x', 'model', 'identified'), ('model', 'identified', 'value'), ('identified', 'value', 'θ0'), ('value', 'θ0', '.')]

>> POS Tags are: 
 [('Stated', 'VBN'), ('less', 'RBR'), ('formally', 'RB'), (',', ','), ('order', 'NN'), ('ensure', 'VB'), ('ELBO', 'NNP'), ('tight', 'JJ'), ('value', 'NN'), ('θ0', 'NNP'), (',', ','), ('one', 'CD'), ('needs', 'VBZ'), ('solve', 'NN'), ('problem', 'NN'), ('inferring', 'VBG'), ('distribution', 'NN'), ('hidden', 'NN'), ('variables', 'NNS'), ('z', 'CD'), ('given', 'VBN'), ('observation', 'NN'), ('x', 'NNP'), ('model', 'NN'), ('identified', 'VBD'), ('value', 'NN'), ('θ0', 'NN'), ('.', '.')]

 (S
  Stated/VBN
  less/RBR
  formally/RB
  ,/,
  (NP order/NN)
  ensure/VB
  (NP ELBO/NNP)
  (NP tight/JJ value/NN θ0/NNP)
  ,/,
  one/CD
  needs/VBZ
  (NP solve/NN problem/NN)
  inferring/VBG
  (NP distribution/NN hidden/NN variables/NNS)
  z/CD
  given/VBN
  (NP observation/NN x/NNP model/NN)
  identified/VBD
  (NP value/NN θ0/NN)
  ./.) 


>> Noun Phrases are: 
 ['order', 'ELBO', 'tight value θ0', 'solve problem', 'distribution hidden variables', 'observation x model', 'value θ0']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('Stated', 'state'), ('less', 'less'), ('formally', 'formal'), (',', ','), ('order', 'order'), ('ensure', 'ensur'), ('ELBO', 'elbo'), ('tight', 'tight'), ('value', 'valu'), ('θ0', 'θ0'), (',', ','), ('one', 'one'), ('needs', 'need'), ('solve', 'solv'), ('problem', 'problem'), ('inferring', 'infer'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), ('given', 'given'), ('observation', 'observ'), ('x', 'x'), ('model', 'model'), ('identified', 'identifi'), ('value', 'valu'), ('θ0', 'θ0'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stated', 'state'), ('less', 'less'), ('formally', 'formal'), (',', ','), ('order', 'order'), ('ensure', 'ensur'), ('ELBO', 'elbo'), ('tight', 'tight'), ('value', 'valu'), ('θ0', 'θ0'), (',', ','), ('one', 'one'), ('needs', 'need'), ('solve', 'solv'), ('problem', 'problem'), ('inferring', 'infer'), ('distribution', 'distribut'), ('hidden', 'hidden'), ('variables', 'variabl'), ('z', 'z'), ('given', 'given'), ('observation', 'observ'), ('x', 'x'), ('model', 'model'), ('identified', 'identifi'), ('value', 'valu'), ('θ0', 'θ0'), ('.', '.')]

>> Lemmatization: 
 [('Stated', 'Stated'), ('less', 'le'), ('formally', 'formally'), (',', ','), ('order', 'order'), ('ensure', 'ensure'), ('ELBO', 'ELBO'), ('tight', 'tight'), ('value', 'value'), ('θ0', 'θ0'), (',', ','), ('one', 'one'), ('needs', 'need'), ('solve', 'solve'), ('problem', 'problem'), ('inferring', 'inferring'), ('distribution', 'distribution'), ('hidden', 'hidden'), ('variables', 'variable'), ('z', 'z'), ('given', 'given'), ('observation', 'observation'), ('x', 'x'), ('model', 'model'), ('identified', 'identified'), ('value', 'value'), ('θ0', 'θ0'), ('.', '.')]



============================ Sentence 452 =============================

The property (16) leads to the natural idea of the Expectation-Maximization (EM) algorithm as a means to tackle the ML problem. 


>> Tokens are: 
 ['The', 'property', '(', '16', ')', 'leads', 'natural', 'idea', 'Expectation-Maximization', '(', 'EM', ')', 'algorithm', 'means', 'tackle', 'ML', 'problem', '.']

>> Bigrams are: 
 [('The', 'property'), ('property', '('), ('(', '16'), ('16', ')'), (')', 'leads'), ('leads', 'natural'), ('natural', 'idea'), ('idea', 'Expectation-Maximization'), ('Expectation-Maximization', '('), ('(', 'EM'), ('EM', ')'), (')', 'algorithm'), ('algorithm', 'means'), ('means', 'tackle'), ('tackle', 'ML'), ('ML', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('The', 'property', '('), ('property', '(', '16'), ('(', '16', ')'), ('16', ')', 'leads'), (')', 'leads', 'natural'), ('leads', 'natural', 'idea'), ('natural', 'idea', 'Expectation-Maximization'), ('idea', 'Expectation-Maximization', '('), ('Expectation-Maximization', '(', 'EM'), ('(', 'EM', ')'), ('EM', ')', 'algorithm'), (')', 'algorithm', 'means'), ('algorithm', 'means', 'tackle'), ('means', 'tackle', 'ML'), ('tackle', 'ML', 'problem'), ('ML', 'problem', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('property', 'NN'), ('(', '('), ('16', 'CD'), (')', ')'), ('leads', 'VBZ'), ('natural', 'JJ'), ('idea', 'NN'), ('Expectation-Maximization', 'NNP'), ('(', '('), ('EM', 'NNP'), (')', ')'), ('algorithm', 'NN'), ('means', 'VBZ'), ('tackle', 'JJ'), ('ML', 'NNP'), ('problem', 'NN'), ('.', '.')]

 (S
  (NP The/DT property/NN)
  (/(
  16/CD
  )/)
  leads/VBZ
  (NP natural/JJ idea/NN Expectation-Maximization/NNP)
  (/(
  (NP EM/NNP)
  )/)
  (NP algorithm/NN)
  means/VBZ
  (NP tackle/JJ ML/NNP problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['The property', 'natural idea Expectation-Maximization', 'EM', 'algorithm', 'tackle ML problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('property', 'properti'), ('(', '('), ('16', '16'), (')', ')'), ('leads', 'lead'), ('natural', 'natur'), ('idea', 'idea'), ('Expectation-Maximization', 'expectation-maxim'), ('(', '('), ('EM', 'em'), (')', ')'), ('algorithm', 'algorithm'), ('means', 'mean'), ('tackle', 'tackl'), ('ML', 'ml'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('property', 'properti'), ('(', '('), ('16', '16'), (')', ')'), ('leads', 'lead'), ('natural', 'natur'), ('idea', 'idea'), ('Expectation-Maximization', 'expectation-maxim'), ('(', '('), ('EM', 'em'), (')', ')'), ('algorithm', 'algorithm'), ('means', 'mean'), ('tackle', 'tackl'), ('ML', 'ml'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('property', 'property'), ('(', '('), ('16', '16'), (')', ')'), ('leads', 'lead'), ('natural', 'natural'), ('idea', 'idea'), ('Expectation-Maximization', 'Expectation-Maximization'), ('(', '('), ('EM', 'EM'), (')', ')'), ('algorithm', 'algorithm'), ('means', 'mean'), ('tackle', 'tackle'), ('ML', 'ML'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 453 =============================

As illustrated in Fig. 


>> Tokens are: 
 ['As', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('As', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('illustrated', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S As/IN (NP illustrated/JJ Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['illustrated Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 454 =============================

13, EM maximizes the ELBO iteratively, where the ELBO at each iteration is computed to be tight at the current iterate for θ. 


>> Tokens are: 
 ['13', ',', 'EM', 'maximizes', 'ELBO', 'iteratively', ',', 'ELBO', 'iteration', 'computed', 'tight', 'current', 'iterate', 'θ', '.']

>> Bigrams are: 
 [('13', ','), (',', 'EM'), ('EM', 'maximizes'), ('maximizes', 'ELBO'), ('ELBO', 'iteratively'), ('iteratively', ','), (',', 'ELBO'), ('ELBO', 'iteration'), ('iteration', 'computed'), ('computed', 'tight'), ('tight', 'current'), ('current', 'iterate'), ('iterate', 'θ'), ('θ', '.')]

>> Trigrams are: 
 [('13', ',', 'EM'), (',', 'EM', 'maximizes'), ('EM', 'maximizes', 'ELBO'), ('maximizes', 'ELBO', 'iteratively'), ('ELBO', 'iteratively', ','), ('iteratively', ',', 'ELBO'), (',', 'ELBO', 'iteration'), ('ELBO', 'iteration', 'computed'), ('iteration', 'computed', 'tight'), ('computed', 'tight', 'current'), ('tight', 'current', 'iterate'), ('current', 'iterate', 'θ'), ('iterate', 'θ', '.')]

>> POS Tags are: 
 [('13', 'CD'), (',', ','), ('EM', 'NNP'), ('maximizes', 'VBZ'), ('ELBO', 'NNP'), ('iteratively', 'RB'), (',', ','), ('ELBO', 'NNP'), ('iteration', 'NN'), ('computed', 'VBD'), ('tight', 'JJ'), ('current', 'JJ'), ('iterate', 'NN'), ('θ', 'NN'), ('.', '.')]

 (S
  13/CD
  ,/,
  (NP EM/NNP)
  maximizes/VBZ
  (NP ELBO/NNP)
  iteratively/RB
  ,/,
  (NP ELBO/NNP iteration/NN)
  computed/VBD
  (NP tight/JJ current/JJ iterate/NN θ/NN)
  ./.) 


>> Noun Phrases are: 
 ['EM', 'ELBO', 'ELBO iteration', 'tight current iterate θ']

>> Named Entities are: 
 [('ORGANIZATION', 'EM'), ('ORGANIZATION', 'ELBO'), ('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (',', ','), ('EM', 'em'), ('maximizes', 'maxim'), ('ELBO', 'elbo'), ('iteratively', 'iter'), (',', ','), ('ELBO', 'elbo'), ('iteration', 'iter'), ('computed', 'comput'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iter'), ('θ', 'θ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (',', ','), ('EM', 'em'), ('maximizes', 'maxim'), ('ELBO', 'elbo'), ('iteratively', 'iter'), (',', ','), ('ELBO', 'elbo'), ('iteration', 'iter'), ('computed', 'comput'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iter'), ('θ', 'θ'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), (',', ','), ('EM', 'EM'), ('maximizes', 'maximizes'), ('ELBO', 'ELBO'), ('iteratively', 'iteratively'), (',', ','), ('ELBO', 'ELBO'), ('iteration', 'iteration'), ('computed', 'computed'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iterate'), ('θ', 'θ'), ('.', '.')]



============================ Sentence 455 =============================

More formally, the EM algorithm can be summarized as follows5. 


>> Tokens are: 
 ['More', 'formally', ',', 'EM', 'algorithm', 'summarized', 'follows5', '.']

>> Bigrams are: 
 [('More', 'formally'), ('formally', ','), (',', 'EM'), ('EM', 'algorithm'), ('algorithm', 'summarized'), ('summarized', 'follows5'), ('follows5', '.')]

>> Trigrams are: 
 [('More', 'formally', ','), ('formally', ',', 'EM'), (',', 'EM', 'algorithm'), ('EM', 'algorithm', 'summarized'), ('algorithm', 'summarized', 'follows5'), ('summarized', 'follows5', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('formally', 'RB'), (',', ','), ('EM', 'NNP'), ('algorithm', 'VBZ'), ('summarized', 'VBN'), ('follows5', 'NN'), ('.', '.')]

 (S
  More/RBR
  formally/RB
  ,/,
  (NP EM/NNP)
  algorithm/VBZ
  summarized/VBN
  (NP follows5/NN)
  ./.) 


>> Noun Phrases are: 
 ['EM', 'follows5']

>> Named Entities are: 
 [('ORGANIZATION', 'EM')] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('formally', 'formal'), (',', ','), ('EM', 'em'), ('algorithm', 'algorithm'), ('summarized', 'summar'), ('follows5', 'follows5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('formally', 'formal'), (',', ','), ('EM', 'em'), ('algorithm', 'algorithm'), ('summarized', 'summar'), ('follows5', 'follows5'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('formally', 'formally'), (',', ','), ('EM', 'EM'), ('algorithm', 'algorithm'), ('summarized', 'summarized'), ('follows5', 'follows5'), ('.', '.')]



============================ Sentence 456 =============================

The model vector is initialized to some value θold and then for each iteration the following two steps are performed. 


>> Tokens are: 
 ['The', 'model', 'vector', 'initialized', 'value', 'θold', 'iteration', 'following', 'two', 'steps', 'performed', '.']

>> Bigrams are: 
 [('The', 'model'), ('model', 'vector'), ('vector', 'initialized'), ('initialized', 'value'), ('value', 'θold'), ('θold', 'iteration'), ('iteration', 'following'), ('following', 'two'), ('two', 'steps'), ('steps', 'performed'), ('performed', '.')]

>> Trigrams are: 
 [('The', 'model', 'vector'), ('model', 'vector', 'initialized'), ('vector', 'initialized', 'value'), ('initialized', 'value', 'θold'), ('value', 'θold', 'iteration'), ('θold', 'iteration', 'following'), ('iteration', 'following', 'two'), ('following', 'two', 'steps'), ('two', 'steps', 'performed'), ('steps', 'performed', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('model', 'NN'), ('vector', 'NN'), ('initialized', 'JJ'), ('value', 'NN'), ('θold', 'VBN'), ('iteration', 'NN'), ('following', 'VBG'), ('two', 'CD'), ('steps', 'NNS'), ('performed', 'VBN'), ('.', '.')]

 (S
  (NP The/DT model/NN vector/NN)
  (NP initialized/JJ value/NN)
  θold/VBN
  (NP iteration/NN)
  following/VBG
  two/CD
  (NP steps/NNS)
  performed/VBN
  ./.) 


>> Noun Phrases are: 
 ['The model vector', 'initialized value', 'iteration', 'steps']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('model', 'model'), ('vector', 'vector'), ('initialized', 'initi'), ('value', 'valu'), ('θold', 'θold'), ('iteration', 'iter'), ('following', 'follow'), ('two', 'two'), ('steps', 'step'), ('performed', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('model', 'model'), ('vector', 'vector'), ('initialized', 'initi'), ('value', 'valu'), ('θold', 'θold'), ('iteration', 'iter'), ('following', 'follow'), ('two', 'two'), ('steps', 'step'), ('performed', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('model', 'model'), ('vector', 'vector'), ('initialized', 'initialized'), ('value', 'value'), ('θold', 'θold'), ('iteration', 'iteration'), ('following', 'following'), ('two', 'two'), ('steps', 'step'), ('performed', 'performed'), ('.', '.')]



============================ Sentence 457 =============================

5EM is an instance of the more general Majorization-Minimization algorithm [61]. 


>> Tokens are: 
 ['5EM', 'instance', 'general', 'Majorization-Minimization', 'algorithm', '[', '61', ']', '.']

>> Bigrams are: 
 [('5EM', 'instance'), ('instance', 'general'), ('general', 'Majorization-Minimization'), ('Majorization-Minimization', 'algorithm'), ('algorithm', '['), ('[', '61'), ('61', ']'), (']', '.')]

>> Trigrams are: 
 [('5EM', 'instance', 'general'), ('instance', 'general', 'Majorization-Minimization'), ('general', 'Majorization-Minimization', 'algorithm'), ('Majorization-Minimization', 'algorithm', '['), ('algorithm', '[', '61'), ('[', '61', ']'), ('61', ']', '.')]

>> POS Tags are: 
 [('5EM', 'CD'), ('instance', 'NN'), ('general', 'JJ'), ('Majorization-Minimization', 'NNP'), ('algorithm', 'NN'), ('[', 'VBD'), ('61', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  5EM/CD
  (NP instance/NN)
  (NP general/JJ Majorization-Minimization/NNP algorithm/NN)
  [/VBD
  61/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'general Majorization-Minimization algorithm', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5EM', '5em'), ('instance', 'instanc'), ('general', 'gener'), ('Majorization-Minimization', 'majorization-minim'), ('algorithm', 'algorithm'), ('[', '['), ('61', '61'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5EM', '5em'), ('instance', 'instanc'), ('general', 'general'), ('Majorization-Minimization', 'majorization-minim'), ('algorithm', 'algorithm'), ('[', '['), ('61', '61'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('5EM', '5EM'), ('instance', 'instance'), ('general', 'general'), ('Majorization-Minimization', 'Majorization-Minimization'), ('algorithm', 'algorithm'), ('[', '['), ('61', '61'), (']', ']'), ('.', '.')]



============================ Sentence 458 =============================

14    -4 -3 -2 -1 0 1 2 3 4 -5  -4.5  -4  -3.5  -3  -2.5  -2  -1.5 L  o g  -l ik  e lih  o o  d  ELBO ( 0 =  3)  ELBO ( 0  =  2)  LL  Fig. 


>> Tokens are: 
 ['14', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '-5', '-4.5', '-4', '-3.5', '-3', '-2.5', '-2', '-1.5', 'L', 'g', '-l', 'ik', 'e', 'lih', 'ELBO', '(', '0', '=', '3', ')', 'ELBO', '(', '0', '=', '2', ')', 'LL', 'Fig', '.']

>> Bigrams are: 
 [('14', '-4'), ('-4', '-3'), ('-3', '-2'), ('-2', '-1'), ('-1', '0'), ('0', '1'), ('1', '2'), ('2', '3'), ('3', '4'), ('4', '-5'), ('-5', '-4.5'), ('-4.5', '-4'), ('-4', '-3.5'), ('-3.5', '-3'), ('-3', '-2.5'), ('-2.5', '-2'), ('-2', '-1.5'), ('-1.5', 'L'), ('L', 'g'), ('g', '-l'), ('-l', 'ik'), ('ik', 'e'), ('e', 'lih'), ('lih', 'ELBO'), ('ELBO', '('), ('(', '0'), ('0', '='), ('=', '3'), ('3', ')'), (')', 'ELBO'), ('ELBO', '('), ('(', '0'), ('0', '='), ('=', '2'), ('2', ')'), (')', 'LL'), ('LL', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('14', '-4', '-3'), ('-4', '-3', '-2'), ('-3', '-2', '-1'), ('-2', '-1', '0'), ('-1', '0', '1'), ('0', '1', '2'), ('1', '2', '3'), ('2', '3', '4'), ('3', '4', '-5'), ('4', '-5', '-4.5'), ('-5', '-4.5', '-4'), ('-4.5', '-4', '-3.5'), ('-4', '-3.5', '-3'), ('-3.5', '-3', '-2.5'), ('-3', '-2.5', '-2'), ('-2.5', '-2', '-1.5'), ('-2', '-1.5', 'L'), ('-1.5', 'L', 'g'), ('L', 'g', '-l'), ('g', '-l', 'ik'), ('-l', 'ik', 'e'), ('ik', 'e', 'lih'), ('e', 'lih', 'ELBO'), ('lih', 'ELBO', '('), ('ELBO', '(', '0'), ('(', '0', '='), ('0', '=', '3'), ('=', '3', ')'), ('3', ')', 'ELBO'), (')', 'ELBO', '('), ('ELBO', '(', '0'), ('(', '0', '='), ('0', '=', '2'), ('=', '2', ')'), ('2', ')', 'LL'), (')', 'LL', 'Fig'), ('LL', 'Fig', '.')]

>> POS Tags are: 
 [('14', 'CD'), ('-4', 'JJ'), ('-3', 'NNP'), ('-2', 'NNP'), ('-1', 'VBD'), ('0', 'CD'), ('1', 'CD'), ('2', 'CD'), ('3', 'CD'), ('4', 'CD'), ('-5', 'NN'), ('-4.5', 'NNP'), ('-4', 'NNP'), ('-3.5', 'NNP'), ('-3', 'NNP'), ('-2.5', 'NNP'), ('-2', 'NNP'), ('-1.5', 'NNP'), ('L', 'NNP'), ('g', 'NN'), ('-l', 'NNP'), ('ik', 'NN'), ('e', 'NN'), ('lih', 'NN'), ('ELBO', 'NNP'), ('(', '('), ('0', 'CD'), ('=', 'RB'), ('3', 'CD'), (')', ')'), ('ELBO', 'NNP'), ('(', '('), ('0', 'CD'), ('=', 'RB'), ('2', 'CD'), (')', ')'), ('LL', 'NNP'), ('Fig', 'NNP'), ('.', '.')]

 (S
  14/CD
  (NP -4/JJ -3/NNP -2/NNP)
  -1/VBD
  0/CD
  1/CD
  2/CD
  3/CD
  4/CD
  (NP
    -5/NN
    -4.5/NNP
    -4/NNP
    -3.5/NNP
    -3/NNP
    -2.5/NNP
    -2/NNP
    -1.5/NNP
    L/NNP
    g/NN
    -l/NNP
    ik/NN
    e/NN
    lih/NN
    ELBO/NNP)
  (/(
  0/CD
  =/RB
  3/CD
  )/)
  (NP ELBO/NNP)
  (/(
  0/CD
  =/RB
  2/CD
  )/)
  (NP LL/NNP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['-4 -3 -2', '-5 -4.5 -4 -3.5 -3 -2.5 -2 -1.5 L g -l ik e lih ELBO', 'ELBO', 'LL Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO'), ('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('-4', '-4'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('-5', '-5'), ('-4.5', '-4.5'), ('-4', '-4'), ('-3.5', '-3.5'), ('-3', '-3'), ('-2.5', '-2.5'), ('-2', '-2'), ('-1.5', '-1.5'), ('L', 'l'), ('g', 'g'), ('-l', '-l'), ('ik', 'ik'), ('e', 'e'), ('lih', 'lih'), ('ELBO', 'elbo'), ('(', '('), ('0', '0'), ('=', '='), ('3', '3'), (')', ')'), ('ELBO', 'elbo'), ('(', '('), ('0', '0'), ('=', '='), ('2', '2'), (')', ')'), ('LL', 'll'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('-4', '-4'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('-5', '-5'), ('-4.5', '-4.5'), ('-4', '-4'), ('-3.5', '-3.5'), ('-3', '-3'), ('-2.5', '-2.5'), ('-2', '-2'), ('-1.5', '-1.5'), ('L', 'l'), ('g', 'g'), ('-l', '-l'), ('ik', 'ik'), ('e', 'e'), ('lih', 'lih'), ('ELBO', 'elbo'), ('(', '('), ('0', '0'), ('=', '='), ('3', '3'), (')', ')'), ('ELBO', 'elbo'), ('(', '('), ('0', '0'), ('=', '='), ('2', '2'), (')', ')'), ('LL', 'll'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('-4', '-4'), ('-3', '-3'), ('-2', '-2'), ('-1', '-1'), ('0', '0'), ('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('-5', '-5'), ('-4.5', '-4.5'), ('-4', '-4'), ('-3.5', '-3.5'), ('-3', '-3'), ('-2.5', '-2.5'), ('-2', '-2'), ('-1.5', '-1.5'), ('L', 'L'), ('g', 'g'), ('-l', '-l'), ('ik', 'ik'), ('e', 'e'), ('lih', 'lih'), ('ELBO', 'ELBO'), ('(', '('), ('0', '0'), ('=', '='), ('3', '3'), (')', ')'), ('ELBO', 'ELBO'), ('(', '('), ('0', '0'), ('=', '='), ('2', '2'), (')', ')'), ('LL', 'LL'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 459 =============================

12. 


>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

 (S 12/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]



============================ Sentence 460 =============================

The ELBO (15) is a global lower bound on the log-likelihood that is tight at values of the model parameters θ0 for which equality (17) holds. 


>> Tokens are: 
 ['The', 'ELBO', '(', '15', ')', 'global', 'lower', 'bound', 'log-likelihood', 'tight', 'values', 'model', 'parameters', 'θ0', 'equality', '(', '17', ')', 'holds', '.']

>> Bigrams are: 
 [('The', 'ELBO'), ('ELBO', '('), ('(', '15'), ('15', ')'), (')', 'global'), ('global', 'lower'), ('lower', 'bound'), ('bound', 'log-likelihood'), ('log-likelihood', 'tight'), ('tight', 'values'), ('values', 'model'), ('model', 'parameters'), ('parameters', 'θ0'), ('θ0', 'equality'), ('equality', '('), ('(', '17'), ('17', ')'), (')', 'holds'), ('holds', '.')]

>> Trigrams are: 
 [('The', 'ELBO', '('), ('ELBO', '(', '15'), ('(', '15', ')'), ('15', ')', 'global'), (')', 'global', 'lower'), ('global', 'lower', 'bound'), ('lower', 'bound', 'log-likelihood'), ('bound', 'log-likelihood', 'tight'), ('log-likelihood', 'tight', 'values'), ('tight', 'values', 'model'), ('values', 'model', 'parameters'), ('model', 'parameters', 'θ0'), ('parameters', 'θ0', 'equality'), ('θ0', 'equality', '('), ('equality', '(', '17'), ('(', '17', ')'), ('17', ')', 'holds'), (')', 'holds', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('ELBO', 'NNP'), ('(', '('), ('15', 'CD'), (')', ')'), ('global', 'JJ'), ('lower', 'JJR'), ('bound', 'IN'), ('log-likelihood', 'JJ'), ('tight', 'JJ'), ('values', 'NNS'), ('model', 'VBP'), ('parameters', 'NNS'), ('θ0', 'VBP'), ('equality', 'NN'), ('(', '('), ('17', 'CD'), (')', ')'), ('holds', 'VBZ'), ('.', '.')]

 (S
  (NP The/DT ELBO/NNP)
  (/(
  15/CD
  )/)
  global/JJ
  lower/JJR
  bound/IN
  (NP log-likelihood/JJ tight/JJ values/NNS)
  model/VBP
  (NP parameters/NNS)
  θ0/VBP
  (NP equality/NN)
  (/(
  17/CD
  )/)
  holds/VBZ
  ./.) 


>> Noun Phrases are: 
 ['The ELBO', 'log-likelihood tight values', 'parameters', 'equality']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ELBO', 'elbo'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('values', 'valu'), ('model', 'model'), ('parameters', 'paramet'), ('θ0', 'θ0'), ('equality', 'equal'), ('(', '('), ('17', '17'), (')', ')'), ('holds', 'hold'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ELBO', 'elbo'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('values', 'valu'), ('model', 'model'), ('parameters', 'paramet'), ('θ0', 'θ0'), ('equality', 'equal'), ('(', '('), ('17', '17'), (')', ')'), ('holds', 'hold'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('ELBO', 'ELBO'), ('(', '('), ('15', '15'), (')', ')'), ('global', 'global'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('values', 'value'), ('model', 'model'), ('parameters', 'parameter'), ('θ0', 'θ0'), ('equality', 'equality'), ('(', '('), ('17', '17'), (')', ')'), ('holds', 'hold'), ('.', '.')]



============================ Sentence 461 =============================

• Expectation, or E, step: For fixed parameter vector θold, solve the problem  maximize q  L(q, θold). 


>> Tokens are: 
 ['•', 'Expectation', ',', 'E', ',', 'step', ':', 'For', 'fixed', 'parameter', 'vector', 'θold', ',', 'solve', 'problem', 'maximize', 'q', 'L', '(', 'q', ',', 'θold', ')', '.']

>> Bigrams are: 
 [('•', 'Expectation'), ('Expectation', ','), (',', 'E'), ('E', ','), (',', 'step'), ('step', ':'), (':', 'For'), ('For', 'fixed'), ('fixed', 'parameter'), ('parameter', 'vector'), ('vector', 'θold'), ('θold', ','), (',', 'solve'), ('solve', 'problem'), ('problem', 'maximize'), ('maximize', 'q'), ('q', 'L'), ('L', '('), ('(', 'q'), ('q', ','), (',', 'θold'), ('θold', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'Expectation', ','), ('Expectation', ',', 'E'), (',', 'E', ','), ('E', ',', 'step'), (',', 'step', ':'), ('step', ':', 'For'), (':', 'For', 'fixed'), ('For', 'fixed', 'parameter'), ('fixed', 'parameter', 'vector'), ('parameter', 'vector', 'θold'), ('vector', 'θold', ','), ('θold', ',', 'solve'), (',', 'solve', 'problem'), ('solve', 'problem', 'maximize'), ('problem', 'maximize', 'q'), ('maximize', 'q', 'L'), ('q', 'L', '('), ('L', '(', 'q'), ('(', 'q', ','), ('q', ',', 'θold'), (',', 'θold', ')'), ('θold', ')', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Expectation', 'NNP'), (',', ','), ('E', 'NNP'), (',', ','), ('step', 'NN'), (':', ':'), ('For', 'IN'), ('fixed', 'VBN'), ('parameter', 'NN'), ('vector', 'NN'), ('θold', 'NNP'), (',', ','), ('solve', 'NN'), ('problem', 'NN'), ('maximize', 'VB'), ('q', 'JJ'), ('L', 'NNP'), ('(', '('), ('q', 'NN'), (',', ','), ('θold', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP •/JJ Expectation/NNP)
  ,/,
  (NP E/NNP)
  ,/,
  (NP step/NN)
  :/:
  For/IN
  fixed/VBN
  (NP parameter/NN vector/NN θold/NNP)
  ,/,
  (NP solve/NN problem/NN)
  maximize/VB
  (NP q/JJ L/NNP)
  (/(
  (NP q/NN)
  ,/,
  (NP θold/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['• Expectation', 'E', 'step', 'parameter vector θold', 'solve problem', 'q L', 'q', 'θold']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Expectation', 'expect'), (',', ','), ('E', 'e'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'for'), ('fixed', 'fix'), ('parameter', 'paramet'), ('vector', 'vector'), ('θold', 'θold'), (',', ','), ('solve', 'solv'), ('problem', 'problem'), ('maximize', 'maxim'), ('q', 'q'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Expectation', 'expect'), (',', ','), ('E', 'e'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'for'), ('fixed', 'fix'), ('parameter', 'paramet'), ('vector', 'vector'), ('θold', 'θold'), (',', ','), ('solve', 'solv'), ('problem', 'problem'), ('maximize', 'maxim'), ('q', 'q'), ('L', 'l'), ('(', '('), ('q', 'q'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Expectation', 'Expectation'), (',', ','), ('E', 'E'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'For'), ('fixed', 'fixed'), ('parameter', 'parameter'), ('vector', 'vector'), ('θold', 'θold'), (',', ','), ('solve', 'solve'), ('problem', 'problem'), ('maximize', 'maximize'), ('q', 'q'), ('L', 'L'), ('(', '('), ('q', 'q'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]



============================ Sentence 462 =============================

(18)  The solution of this problem is given by qnew(z) = p(z|x, θold). 


>> Tokens are: 
 ['(', '18', ')', 'The', 'solution', 'problem', 'given', 'qnew', '(', 'z', ')', '=', 'p', '(', 'z|x', ',', 'θold', ')', '.']

>> Bigrams are: 
 [('(', '18'), ('18', ')'), (')', 'The'), ('The', 'solution'), ('solution', 'problem'), ('problem', 'given'), ('given', 'qnew'), ('qnew', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', 'p'), ('p', '('), ('(', 'z|x'), ('z|x', ','), (',', 'θold'), ('θold', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '18', ')'), ('18', ')', 'The'), (')', 'The', 'solution'), ('The', 'solution', 'problem'), ('solution', 'problem', 'given'), ('problem', 'given', 'qnew'), ('given', 'qnew', '('), ('qnew', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', 'p'), ('=', 'p', '('), ('p', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'θold'), (',', 'θold', ')'), ('θold', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('18', 'CD'), (')', ')'), ('The', 'DT'), ('solution', 'NN'), ('problem', 'NN'), ('given', 'VBN'), ('qnew', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'NN'), ('p', 'NN'), ('(', '('), ('z|x', 'NN'), (',', ','), ('θold', 'NN'), (')', ')'), ('.', '.')]

 (S
  (/(
  18/CD
  )/)
  (NP The/DT solution/NN problem/NN)
  given/VBN
  (NP qnew/NN)
  (/(
  (NP z/NN)
  )/)
  (NP =/NN p/NN)
  (/(
  (NP z|x/NN)
  ,/,
  (NP θold/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The solution problem', 'qnew', 'z', '= p', 'z|x', 'θold']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('18', '18'), (')', ')'), ('The', 'the'), ('solution', 'solut'), ('problem', 'problem'), ('given', 'given'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('18', '18'), (')', ')'), ('The', 'the'), ('solution', 'solut'), ('problem', 'problem'), ('given', 'given'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('18', '18'), (')', ')'), ('The', 'The'), ('solution', 'solution'), ('problem', 'problem'), ('given', 'given'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), ('.', '.')]



============================ Sentence 463 =============================

In fact, as discussed, the tightest (i.e.-, largest) value of the ELBO is obtained by choosing the variational distribution q(z) as the posterior of the latent variables under the current model θold. 


>> Tokens are: 
 ['In', 'fact', ',', 'discussed', ',', 'tightest', '(', 'i.e.-', ',', 'largest', ')', 'value', 'ELBO', 'obtained', 'choosing', 'variational', 'distribution', 'q', '(', 'z', ')', 'posterior', 'latent', 'variables', 'current', 'model', 'θold', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'discussed'), ('discussed', ','), (',', 'tightest'), ('tightest', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'largest'), ('largest', ')'), (')', 'value'), ('value', 'ELBO'), ('ELBO', 'obtained'), ('obtained', 'choosing'), ('choosing', 'variational'), ('variational', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', 'posterior'), ('posterior', 'latent'), ('latent', 'variables'), ('variables', 'current'), ('current', 'model'), ('model', 'θold'), ('θold', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'discussed'), (',', 'discussed', ','), ('discussed', ',', 'tightest'), (',', 'tightest', '('), ('tightest', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'largest'), (',', 'largest', ')'), ('largest', ')', 'value'), (')', 'value', 'ELBO'), ('value', 'ELBO', 'obtained'), ('ELBO', 'obtained', 'choosing'), ('obtained', 'choosing', 'variational'), ('choosing', 'variational', 'distribution'), ('variational', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', 'posterior'), (')', 'posterior', 'latent'), ('posterior', 'latent', 'variables'), ('latent', 'variables', 'current'), ('variables', 'current', 'model'), ('current', 'model', 'θold'), ('model', 'θold', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('discussed', 'VBN'), (',', ','), ('tightest', 'JJS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('largest', 'JJS'), (')', ')'), ('value', 'NN'), ('ELBO', 'NNP'), ('obtained', 'VBD'), ('choosing', 'VBG'), ('variational', 'JJ'), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('posterior', 'FW'), ('latent', 'JJ'), ('variables', 'NNS'), ('current', 'JJ'), ('model', 'NN'), ('θold', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP fact/NN)
  ,/,
  discussed/VBN
  ,/,
  tightest/JJS
  (/(
  i.e.-/JJ
  ,/,
  largest/JJS
  )/)
  (NP value/NN ELBO/NNP)
  obtained/VBD
  choosing/VBG
  (NP variational/JJ distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  posterior/FW
  (NP latent/JJ variables/NNS)
  (NP current/JJ model/NN θold/NN)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'value ELBO', 'variational distribution q', 'z', 'latent variables', 'current model θold']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('discussed', 'discuss'), (',', ','), ('tightest', 'tightest'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('largest', 'largest'), (')', ')'), ('value', 'valu'), ('ELBO', 'elbo'), ('obtained', 'obtain'), ('choosing', 'choos'), ('variational', 'variat'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variabl'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('discussed', 'discuss'), (',', ','), ('tightest', 'tightest'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('largest', 'largest'), (')', ')'), ('value', 'valu'), ('ELBO', 'elbo'), ('obtained', 'obtain'), ('choosing', 'choos'), ('variational', 'variat'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variabl'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('discussed', 'discussed'), (',', ','), ('tightest', 'tightest'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('largest', 'largest'), (')', ')'), ('value', 'value'), ('ELBO', 'ELBO'), ('obtained', 'obtained'), ('choosing', 'choosing'), ('variational', 'variational'), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variable'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('.', '.')]



============================ Sentence 464 =============================

This step can be interpreted as estimating the latent variables z, via the predictive distribution p(z|x, θold), assuming that the current model θold is correct. 


>> Tokens are: 
 ['This', 'step', 'interpreted', 'estimating', 'latent', 'variables', 'z', ',', 'via', 'predictive', 'distribution', 'p', '(', 'z|x', ',', 'θold', ')', ',', 'assuming', 'current', 'model', 'θold', 'correct', '.']

>> Bigrams are: 
 [('This', 'step'), ('step', 'interpreted'), ('interpreted', 'estimating'), ('estimating', 'latent'), ('latent', 'variables'), ('variables', 'z'), ('z', ','), (',', 'via'), ('via', 'predictive'), ('predictive', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'z|x'), ('z|x', ','), (',', 'θold'), ('θold', ')'), (')', ','), (',', 'assuming'), ('assuming', 'current'), ('current', 'model'), ('model', 'θold'), ('θold', 'correct'), ('correct', '.')]

>> Trigrams are: 
 [('This', 'step', 'interpreted'), ('step', 'interpreted', 'estimating'), ('interpreted', 'estimating', 'latent'), ('estimating', 'latent', 'variables'), ('latent', 'variables', 'z'), ('variables', 'z', ','), ('z', ',', 'via'), (',', 'via', 'predictive'), ('via', 'predictive', 'distribution'), ('predictive', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'θold'), (',', 'θold', ')'), ('θold', ')', ','), (')', ',', 'assuming'), (',', 'assuming', 'current'), ('assuming', 'current', 'model'), ('current', 'model', 'θold'), ('model', 'θold', 'correct'), ('θold', 'correct', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('step', 'NN'), ('interpreted', 'VBD'), ('estimating', 'VBG'), ('latent', 'NN'), ('variables', 'NNS'), ('z', 'VBP'), (',', ','), ('via', 'IN'), ('predictive', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('z|x', 'NN'), (',', ','), ('θold', 'NN'), (')', ')'), (',', ','), ('assuming', 'VBG'), ('current', 'JJ'), ('model', 'NN'), ('θold', 'NN'), ('correct', 'NN'), ('.', '.')]

 (S
  (NP This/DT step/NN)
  interpreted/VBD
  estimating/VBG
  (NP latent/NN variables/NNS)
  z/VBP
  ,/,
  via/IN
  (NP predictive/JJ distribution/NN p/NN)
  (/(
  (NP z|x/NN)
  ,/,
  (NP θold/NN)
  )/)
  ,/,
  assuming/VBG
  (NP current/JJ model/NN θold/NN correct/NN)
  ./.) 


>> Noun Phrases are: 
 ['This step', 'latent variables', 'predictive distribution p', 'z|x', 'θold', 'current model θold correct']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('step', 'step'), ('interpreted', 'interpret'), ('estimating', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), (',', ','), ('via', 'via'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), (',', ','), ('assuming', 'assum'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('correct', 'correct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('step', 'step'), ('interpreted', 'interpret'), ('estimating', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), (',', ','), ('via', 'via'), ('predictive', 'predict'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), (',', ','), ('assuming', 'assum'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('correct', 'correct'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('step', 'step'), ('interpreted', 'interpreted'), ('estimating', 'estimating'), ('latent', 'latent'), ('variables', 'variable'), ('z', 'z'), (',', ','), ('via', 'via'), ('predictive', 'predictive'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θold', 'θold'), (')', ')'), (',', ','), ('assuming', 'assuming'), ('current', 'current'), ('model', 'model'), ('θold', 'θold'), ('correct', 'correct'), ('.', '.')]



============================ Sentence 465 =============================

• Maximization, or M, step: For fixed variational distribution qnew(z), solve the problem  maximize θ  L(qnew, θ) = Ez∼qnew(z) [ln p(x, z|θ)] . 


>> Tokens are: 
 ['•', 'Maximization', ',', 'M', ',', 'step', ':', 'For', 'fixed', 'variational', 'distribution', 'qnew', '(', 'z', ')', ',', 'solve', 'problem', 'maximize', 'θ', 'L', '(', 'qnew', ',', 'θ', ')', '=', 'Ez∼qnew', '(', 'z', ')', '[', 'ln', 'p', '(', 'x', ',', 'z|θ', ')', ']', '.']

>> Bigrams are: 
 [('•', 'Maximization'), ('Maximization', ','), (',', 'M'), ('M', ','), (',', 'step'), ('step', ':'), (':', 'For'), ('For', 'fixed'), ('fixed', 'variational'), ('variational', 'distribution'), ('distribution', 'qnew'), ('qnew', '('), ('(', 'z'), ('z', ')'), (')', ','), (',', 'solve'), ('solve', 'problem'), ('problem', 'maximize'), ('maximize', 'θ'), ('θ', 'L'), ('L', '('), ('(', 'qnew'), ('qnew', ','), (',', 'θ'), ('θ', ')'), (')', '='), ('=', 'Ez∼qnew'), ('Ez∼qnew', '('), ('(', 'z'), ('z', ')'), (')', '['), ('[', 'ln'), ('ln', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', 'z|θ'), ('z|θ', ')'), (')', ']'), (']', '.')]

>> Trigrams are: 
 [('•', 'Maximization', ','), ('Maximization', ',', 'M'), (',', 'M', ','), ('M', ',', 'step'), (',', 'step', ':'), ('step', ':', 'For'), (':', 'For', 'fixed'), ('For', 'fixed', 'variational'), ('fixed', 'variational', 'distribution'), ('variational', 'distribution', 'qnew'), ('distribution', 'qnew', '('), ('qnew', '(', 'z'), ('(', 'z', ')'), ('z', ')', ','), (')', ',', 'solve'), (',', 'solve', 'problem'), ('solve', 'problem', 'maximize'), ('problem', 'maximize', 'θ'), ('maximize', 'θ', 'L'), ('θ', 'L', '('), ('L', '(', 'qnew'), ('(', 'qnew', ','), ('qnew', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', '='), (')', '=', 'Ez∼qnew'), ('=', 'Ez∼qnew', '('), ('Ez∼qnew', '(', 'z'), ('(', 'z', ')'), ('z', ')', '['), (')', '[', 'ln'), ('[', 'ln', 'p'), ('ln', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', 'z|θ'), (',', 'z|θ', ')'), ('z|θ', ')', ']'), (')', ']', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Maximization', 'NNP'), (',', ','), ('M', 'NNP'), (',', ','), ('step', 'NN'), (':', ':'), ('For', 'IN'), ('fixed', 'VBN'), ('variational', 'JJ'), ('distribution', 'NN'), ('qnew', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), (',', ','), ('solve', 'VBP'), ('problem', 'NN'), ('maximize', 'NN'), ('θ', 'NNP'), ('L', 'NNP'), ('(', '('), ('qnew', 'RB'), (',', ','), ('θ', 'NNP'), (')', ')'), ('=', 'VBP'), ('Ez∼qnew', 'NNP'), ('(', '('), ('z', 'NN'), (')', ')'), ('[', 'VBZ'), ('ln', 'JJ'), ('p', 'NN'), ('(', '('), ('x', 'UH'), (',', ','), ('z|θ', 'NN'), (')', ')'), (']', 'NN'), ('.', '.')]

 (S
  (NP •/JJ Maximization/NNP)
  ,/,
  (NP M/NNP)
  ,/,
  (NP step/NN)
  :/:
  For/IN
  fixed/VBN
  (NP variational/JJ distribution/NN qnew/NN)
  (/(
  (NP z/NN)
  )/)
  ,/,
  solve/VBP
  (NP problem/NN maximize/NN θ/NNP L/NNP)
  (/(
  qnew/RB
  ,/,
  (NP θ/NNP)
  )/)
  =/VBP
  (NP Ez∼qnew/NNP)
  (/(
  (NP z/NN)
  )/)
  [/VBZ
  (NP ln/JJ p/NN)
  (/(
  x/UH
  ,/,
  (NP z|θ/NN)
  )/)
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['• Maximization', 'M', 'step', 'variational distribution qnew', 'z', 'problem maximize θ L', 'θ', 'Ez∼qnew', 'z', 'ln p', 'z|θ', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Maximization', 'maxim'), (',', ','), ('M', 'm'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'for'), ('fixed', 'fix'), ('variational', 'variat'), ('distribution', 'distribut'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('solve', 'solv'), ('problem', 'problem'), ('maximize', 'maxim'), ('θ', 'θ'), ('L', 'l'), ('(', '('), ('qnew', 'qnew'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼qnew', 'ez∼qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Maximization', 'maxim'), (',', ','), ('M', 'm'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'for'), ('fixed', 'fix'), ('variational', 'variat'), ('distribution', 'distribut'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('solve', 'solv'), ('problem', 'problem'), ('maximize', 'maxim'), ('θ', 'θ'), ('L', 'l'), ('(', '('), ('qnew', 'qnew'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼qnew', 'ez∼qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Maximization', 'Maximization'), (',', ','), ('M', 'M'), (',', ','), ('step', 'step'), (':', ':'), ('For', 'For'), ('fixed', 'fixed'), ('variational', 'variational'), ('distribution', 'distribution'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), (',', ','), ('solve', 'solve'), ('problem', 'problem'), ('maximize', 'maximize'), ('θ', 'θ'), ('L', 'L'), ('(', '('), ('qnew', 'qnew'), (',', ','), ('θ', 'θ'), (')', ')'), ('=', '='), ('Ez∼qnew', 'Ez∼qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('[', '['), ('ln', 'ln'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), ('z|θ', 'z|θ'), (')', ')'), (']', ']'), ('.', '.')]



============================ Sentence 466 =============================

(19)  This optimization is akin to that carried out in the corresponding supervised learning problem with known latent variables z with the difference that these are randomly selected from the fixed varia- tional distribution qnew(z) obtained in the E step. 


>> Tokens are: 
 ['(', '19', ')', 'This', 'optimization', 'akin', 'carried', 'corresponding', 'supervised', 'learning', 'problem', 'known', 'latent', 'variables', 'z', 'difference', 'randomly', 'selected', 'fixed', 'varia-', 'tional', 'distribution', 'qnew', '(', 'z', ')', 'obtained', 'E', 'step', '.']

>> Bigrams are: 
 [('(', '19'), ('19', ')'), (')', 'This'), ('This', 'optimization'), ('optimization', 'akin'), ('akin', 'carried'), ('carried', 'corresponding'), ('corresponding', 'supervised'), ('supervised', 'learning'), ('learning', 'problem'), ('problem', 'known'), ('known', 'latent'), ('latent', 'variables'), ('variables', 'z'), ('z', 'difference'), ('difference', 'randomly'), ('randomly', 'selected'), ('selected', 'fixed'), ('fixed', 'varia-'), ('varia-', 'tional'), ('tional', 'distribution'), ('distribution', 'qnew'), ('qnew', '('), ('(', 'z'), ('z', ')'), (')', 'obtained'), ('obtained', 'E'), ('E', 'step'), ('step', '.')]

>> Trigrams are: 
 [('(', '19', ')'), ('19', ')', 'This'), (')', 'This', 'optimization'), ('This', 'optimization', 'akin'), ('optimization', 'akin', 'carried'), ('akin', 'carried', 'corresponding'), ('carried', 'corresponding', 'supervised'), ('corresponding', 'supervised', 'learning'), ('supervised', 'learning', 'problem'), ('learning', 'problem', 'known'), ('problem', 'known', 'latent'), ('known', 'latent', 'variables'), ('latent', 'variables', 'z'), ('variables', 'z', 'difference'), ('z', 'difference', 'randomly'), ('difference', 'randomly', 'selected'), ('randomly', 'selected', 'fixed'), ('selected', 'fixed', 'varia-'), ('fixed', 'varia-', 'tional'), ('varia-', 'tional', 'distribution'), ('tional', 'distribution', 'qnew'), ('distribution', 'qnew', '('), ('qnew', '(', 'z'), ('(', 'z', ')'), ('z', ')', 'obtained'), (')', 'obtained', 'E'), ('obtained', 'E', 'step'), ('E', 'step', '.')]

>> POS Tags are: 
 [('(', '('), ('19', 'CD'), (')', ')'), ('This', 'DT'), ('optimization', 'NN'), ('akin', 'FW'), ('carried', 'VBD'), ('corresponding', 'VBG'), ('supervised', 'VBN'), ('learning', 'NN'), ('problem', 'NN'), ('known', 'VBN'), ('latent', 'JJ'), ('variables', 'NNS'), ('z', 'VBP'), ('difference', 'NN'), ('randomly', 'RB'), ('selected', 'VBN'), ('fixed', 'VBN'), ('varia-', 'JJ'), ('tional', 'JJ'), ('distribution', 'NN'), ('qnew', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('obtained', 'VBD'), ('E', 'NNP'), ('step', 'NN'), ('.', '.')]

 (S
  (/(
  19/CD
  )/)
  (NP This/DT optimization/NN)
  akin/FW
  carried/VBD
  corresponding/VBG
  supervised/VBN
  (NP learning/NN problem/NN)
  known/VBN
  (NP latent/JJ variables/NNS)
  z/VBP
  (NP difference/NN)
  randomly/RB
  selected/VBN
  fixed/VBN
  (NP varia-/JJ tional/JJ distribution/NN qnew/NN)
  (/(
  (NP z/NN)
  )/)
  obtained/VBD
  (NP E/NNP step/NN)
  ./.) 


>> Noun Phrases are: 
 ['This optimization', 'learning problem', 'latent variables', 'difference', 'varia- tional distribution qnew', 'z', 'E step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('19', '19'), (')', ')'), ('This', 'thi'), ('optimization', 'optim'), ('akin', 'akin'), ('carried', 'carri'), ('corresponding', 'correspond'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('known', 'known'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), ('difference', 'differ'), ('randomly', 'randomli'), ('selected', 'select'), ('fixed', 'fix'), ('varia-', 'varia-'), ('tional', 'tional'), ('distribution', 'distribut'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('obtained', 'obtain'), ('E', 'e'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('19', '19'), (')', ')'), ('This', 'this'), ('optimization', 'optim'), ('akin', 'akin'), ('carried', 'carri'), ('corresponding', 'correspond'), ('supervised', 'supervis'), ('learning', 'learn'), ('problem', 'problem'), ('known', 'known'), ('latent', 'latent'), ('variables', 'variabl'), ('z', 'z'), ('difference', 'differ'), ('randomly', 'random'), ('selected', 'select'), ('fixed', 'fix'), ('varia-', 'varia-'), ('tional', 'tional'), ('distribution', 'distribut'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('obtained', 'obtain'), ('E', 'e'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('19', '19'), (')', ')'), ('This', 'This'), ('optimization', 'optimization'), ('akin', 'akin'), ('carried', 'carried'), ('corresponding', 'corresponding'), ('supervised', 'supervised'), ('learning', 'learning'), ('problem', 'problem'), ('known', 'known'), ('latent', 'latent'), ('variables', 'variable'), ('z', 'z'), ('difference', 'difference'), ('randomly', 'randomly'), ('selected', 'selected'), ('fixed', 'fixed'), ('varia-', 'varia-'), ('tional', 'tional'), ('distribution', 'distribution'), ('qnew', 'qnew'), ('(', '('), ('z', 'z'), (')', ')'), ('obtained', 'obtained'), ('E', 'E'), ('step', 'step'), ('.', '.')]



============================ Sentence 467 =============================

Given that the EM algorithm maximizes at each step a lower bound on the log-likelihood that is tight at the current iterate θold, EM guarantees decreasing objective values along the iterations, which ensures convergence to a local optimum of the original problem. 


>> Tokens are: 
 ['Given', 'EM', 'algorithm', 'maximizes', 'step', 'lower', 'bound', 'log-likelihood', 'tight', 'current', 'iterate', 'θold', ',', 'EM', 'guarantees', 'decreasing', 'objective', 'values', 'along', 'iterations', ',', 'ensures', 'convergence', 'local', 'optimum', 'original', 'problem', '.']

>> Bigrams are: 
 [('Given', 'EM'), ('EM', 'algorithm'), ('algorithm', 'maximizes'), ('maximizes', 'step'), ('step', 'lower'), ('lower', 'bound'), ('bound', 'log-likelihood'), ('log-likelihood', 'tight'), ('tight', 'current'), ('current', 'iterate'), ('iterate', 'θold'), ('θold', ','), (',', 'EM'), ('EM', 'guarantees'), ('guarantees', 'decreasing'), ('decreasing', 'objective'), ('objective', 'values'), ('values', 'along'), ('along', 'iterations'), ('iterations', ','), (',', 'ensures'), ('ensures', 'convergence'), ('convergence', 'local'), ('local', 'optimum'), ('optimum', 'original'), ('original', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('Given', 'EM', 'algorithm'), ('EM', 'algorithm', 'maximizes'), ('algorithm', 'maximizes', 'step'), ('maximizes', 'step', 'lower'), ('step', 'lower', 'bound'), ('lower', 'bound', 'log-likelihood'), ('bound', 'log-likelihood', 'tight'), ('log-likelihood', 'tight', 'current'), ('tight', 'current', 'iterate'), ('current', 'iterate', 'θold'), ('iterate', 'θold', ','), ('θold', ',', 'EM'), (',', 'EM', 'guarantees'), ('EM', 'guarantees', 'decreasing'), ('guarantees', 'decreasing', 'objective'), ('decreasing', 'objective', 'values'), ('objective', 'values', 'along'), ('values', 'along', 'iterations'), ('along', 'iterations', ','), ('iterations', ',', 'ensures'), (',', 'ensures', 'convergence'), ('ensures', 'convergence', 'local'), ('convergence', 'local', 'optimum'), ('local', 'optimum', 'original'), ('optimum', 'original', 'problem'), ('original', 'problem', '.')]

>> POS Tags are: 
 [('Given', 'VBN'), ('EM', 'NNP'), ('algorithm', 'NN'), ('maximizes', 'NNS'), ('step', 'VB'), ('lower', 'JJR'), ('bound', 'IN'), ('log-likelihood', 'JJ'), ('tight', 'JJ'), ('current', 'JJ'), ('iterate', 'NN'), ('θold', 'NN'), (',', ','), ('EM', 'NNP'), ('guarantees', 'VBZ'), ('decreasing', 'VBG'), ('objective', 'JJ'), ('values', 'NNS'), ('along', 'IN'), ('iterations', 'NNS'), (',', ','), ('ensures', 'VBZ'), ('convergence', 'NN'), ('local', 'JJ'), ('optimum', 'JJ'), ('original', 'JJ'), ('problem', 'NN'), ('.', '.')]

 (S
  Given/VBN
  (NP EM/NNP algorithm/NN maximizes/NNS)
  step/VB
  lower/JJR
  bound/IN
  (NP log-likelihood/JJ tight/JJ current/JJ iterate/NN θold/NN)
  ,/,
  (NP EM/NNP)
  guarantees/VBZ
  decreasing/VBG
  (NP objective/JJ values/NNS)
  along/IN
  (NP iterations/NNS)
  ,/,
  ensures/VBZ
  (NP convergence/NN)
  (NP local/JJ optimum/JJ original/JJ problem/NN)
  ./.) 


>> Noun Phrases are: 
 ['EM algorithm maximizes', 'log-likelihood tight current iterate θold', 'EM', 'objective values', 'iterations', 'convergence', 'local optimum original problem']

>> Named Entities are: 
 [('ORGANIZATION', 'EM')] 

>> Stemming using Porter Stemmer: 
 [('Given', 'given'), ('EM', 'em'), ('algorithm', 'algorithm'), ('maximizes', 'maxim'), ('step', 'step'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iter'), ('θold', 'θold'), (',', ','), ('EM', 'em'), ('guarantees', 'guarante'), ('decreasing', 'decreas'), ('objective', 'object'), ('values', 'valu'), ('along', 'along'), ('iterations', 'iter'), (',', ','), ('ensures', 'ensur'), ('convergence', 'converg'), ('local', 'local'), ('optimum', 'optimum'), ('original', 'origin'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Given', 'given'), ('EM', 'em'), ('algorithm', 'algorithm'), ('maximizes', 'maxim'), ('step', 'step'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iter'), ('θold', 'θold'), (',', ','), ('EM', 'em'), ('guarantees', 'guarante'), ('decreasing', 'decreas'), ('objective', 'object'), ('values', 'valu'), ('along', 'along'), ('iterations', 'iter'), (',', ','), ('ensures', 'ensur'), ('convergence', 'converg'), ('local', 'local'), ('optimum', 'optimum'), ('original', 'origin'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Given', 'Given'), ('EM', 'EM'), ('algorithm', 'algorithm'), ('maximizes', 'maximizes'), ('step', 'step'), ('lower', 'lower'), ('bound', 'bound'), ('log-likelihood', 'log-likelihood'), ('tight', 'tight'), ('current', 'current'), ('iterate', 'iterate'), ('θold', 'θold'), (',', ','), ('EM', 'EM'), ('guarantees', 'guarantee'), ('decreasing', 'decreasing'), ('objective', 'objective'), ('values', 'value'), ('along', 'along'), ('iterations', 'iteration'), (',', ','), ('ensures', 'ensures'), ('convergence', 'convergence'), ('local', 'local'), ('optimum', 'optimum'), ('original', 'original'), ('problem', 'problem'), ('.', '.')]



============================ Sentence 468 =============================

We refer to [57], [58] for detailed examples. 


>> Tokens are: 
 ['We', 'refer', '[', '57', ']', ',', '[', '58', ']', 'detailed', 'examples', '.']

>> Bigrams are: 
 [('We', 'refer'), ('refer', '['), ('[', '57'), ('57', ']'), (']', ','), (',', '['), ('[', '58'), ('58', ']'), (']', 'detailed'), ('detailed', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('We', 'refer', '['), ('refer', '[', '57'), ('[', '57', ']'), ('57', ']', ','), (']', ',', '['), (',', '[', '58'), ('[', '58', ']'), ('58', ']', 'detailed'), (']', 'detailed', 'examples'), ('detailed', 'examples', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('refer', 'VBP'), ('[', 'JJ'), ('57', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('58', 'CD'), (']', 'NN'), ('detailed', 'JJ'), ('examples', 'NNS'), ('.', '.')]

 (S
  We/PRP
  refer/VBP
  [/JJ
  57/CD
  (NP ]/NN)
  ,/,
  [/VBZ
  58/CD
  (NP ]/NN)
  (NP detailed/JJ examples/NNS)
  ./.) 


>> Noun Phrases are: 
 [']', ']', 'detailed examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('refer', 'refer'), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('detailed', 'detail'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('refer', 'refer'), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('detailed', 'detail'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('refer', 'refer'), ('[', '['), ('57', '57'), (']', ']'), (',', ','), ('[', '['), ('58', '58'), (']', ']'), ('detailed', 'detailed'), ('examples', 'example'), ('.', '.')]



============================ Sentence 469 =============================

The EM algorithm is generally impractical for large- scale problems due to the complexity of computing the posterior of the latent variables in the E step and of averaging over such distribution in the M step. 


>> Tokens are: 
 ['The', 'EM', 'algorithm', 'generally', 'impractical', 'large-', 'scale', 'problems', 'due', 'complexity', 'computing', 'posterior', 'latent', 'variables', 'E', 'step', 'averaging', 'distribution', 'M', 'step', '.']

>> Bigrams are: 
 [('The', 'EM'), ('EM', 'algorithm'), ('algorithm', 'generally'), ('generally', 'impractical'), ('impractical', 'large-'), ('large-', 'scale'), ('scale', 'problems'), ('problems', 'due'), ('due', 'complexity'), ('complexity', 'computing'), ('computing', 'posterior'), ('posterior', 'latent'), ('latent', 'variables'), ('variables', 'E'), ('E', 'step'), ('step', 'averaging'), ('averaging', 'distribution'), ('distribution', 'M'), ('M', 'step'), ('step', '.')]

>> Trigrams are: 
 [('The', 'EM', 'algorithm'), ('EM', 'algorithm', 'generally'), ('algorithm', 'generally', 'impractical'), ('generally', 'impractical', 'large-'), ('impractical', 'large-', 'scale'), ('large-', 'scale', 'problems'), ('scale', 'problems', 'due'), ('problems', 'due', 'complexity'), ('due', 'complexity', 'computing'), ('complexity', 'computing', 'posterior'), ('computing', 'posterior', 'latent'), ('posterior', 'latent', 'variables'), ('latent', 'variables', 'E'), ('variables', 'E', 'step'), ('E', 'step', 'averaging'), ('step', 'averaging', 'distribution'), ('averaging', 'distribution', 'M'), ('distribution', 'M', 'step'), ('M', 'step', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('EM', 'NNP'), ('algorithm', 'NN'), ('generally', 'RB'), ('impractical', 'JJ'), ('large-', 'JJ'), ('scale', 'NN'), ('problems', 'NNS'), ('due', 'JJ'), ('complexity', 'NN'), ('computing', 'VBG'), ('posterior', 'JJ'), ('latent', 'NN'), ('variables', 'NNS'), ('E', 'NNP'), ('step', 'NN'), ('averaging', 'VBG'), ('distribution', 'NN'), ('M', 'NNP'), ('step', 'NN'), ('.', '.')]

 (S
  (NP The/DT EM/NNP algorithm/NN)
  generally/RB
  (NP impractical/JJ large-/JJ scale/NN problems/NNS)
  (NP due/JJ complexity/NN)
  computing/VBG
  (NP posterior/JJ latent/NN variables/NNS E/NNP step/NN)
  averaging/VBG
  (NP distribution/NN M/NNP step/NN)
  ./.) 


>> Noun Phrases are: 
 ['The EM algorithm', 'impractical large- scale problems', 'due complexity', 'posterior latent variables E step', 'distribution M step']

>> Named Entities are: 
 [('ORGANIZATION', 'EM')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('EM', 'em'), ('algorithm', 'algorithm'), ('generally', 'gener'), ('impractical', 'impract'), ('large-', 'large-'), ('scale', 'scale'), ('problems', 'problem'), ('due', 'due'), ('complexity', 'complex'), ('computing', 'comput'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variabl'), ('E', 'e'), ('step', 'step'), ('averaging', 'averag'), ('distribution', 'distribut'), ('M', 'm'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('EM', 'em'), ('algorithm', 'algorithm'), ('generally', 'general'), ('impractical', 'impract'), ('large-', 'large-'), ('scale', 'scale'), ('problems', 'problem'), ('due', 'due'), ('complexity', 'complex'), ('computing', 'comput'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variabl'), ('E', 'e'), ('step', 'step'), ('averaging', 'averag'), ('distribution', 'distribut'), ('M', 'm'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('EM', 'EM'), ('algorithm', 'algorithm'), ('generally', 'generally'), ('impractical', 'impractical'), ('large-', 'large-'), ('scale', 'scale'), ('problems', 'problem'), ('due', 'due'), ('complexity', 'complexity'), ('computing', 'computing'), ('posterior', 'posterior'), ('latent', 'latent'), ('variables', 'variable'), ('E', 'E'), ('step', 'step'), ('averaging', 'averaging'), ('distribution', 'distribution'), ('M', 'M'), ('step', 'step'), ('.', '.')]



============================ Sentence 470 =============================

Many state-of-the-art solutions to the problem of unsupervised  ...  LL  newold  Fig. 


>> Tokens are: 
 ['Many', 'state-of-the-art', 'solutions', 'problem', 'unsupervised', '...', 'LL', 'newold', 'Fig', '.']

>> Bigrams are: 
 [('Many', 'state-of-the-art'), ('state-of-the-art', 'solutions'), ('solutions', 'problem'), ('problem', 'unsupervised'), ('unsupervised', '...'), ('...', 'LL'), ('LL', 'newold'), ('newold', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Many', 'state-of-the-art', 'solutions'), ('state-of-the-art', 'solutions', 'problem'), ('solutions', 'problem', 'unsupervised'), ('problem', 'unsupervised', '...'), ('unsupervised', '...', 'LL'), ('...', 'LL', 'newold'), ('LL', 'newold', 'Fig'), ('newold', 'Fig', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('state-of-the-art', 'JJ'), ('solutions', 'NNS'), ('problem', 'NN'), ('unsupervised', 'VBD'), ('...', ':'), ('LL', 'NNP'), ('newold', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP Many/JJ state-of-the-art/JJ solutions/NNS problem/NN)
  unsupervised/VBD
  .../:
  (NP LL/NNP)
  (NP newold/JJ Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Many state-of-the-art solutions problem', 'LL', 'newold Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('state-of-the-art', 'state-of-the-art'), ('solutions', 'solut'), ('problem', 'problem'), ('unsupervised', 'unsupervis'), ('...', '...'), ('LL', 'll'), ('newold', 'newold'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('state-of-the-art', 'state-of-the-art'), ('solutions', 'solut'), ('problem', 'problem'), ('unsupervised', 'unsupervis'), ('...', '...'), ('LL', 'll'), ('newold', 'newold'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('state-of-the-art', 'state-of-the-art'), ('solutions', 'solution'), ('problem', 'problem'), ('unsupervised', 'unsupervised'), ('...', '...'), ('LL', 'LL'), ('newold', 'newold'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 471 =============================

13. 


>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

 (S 13/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]



============================ Sentence 472 =============================

Illustration of the EM algorithm: At each iteration, a tight ELBO is evaluated in the E step by solving the problem of estimating the latent variables (via the posterior distribution p(z|x, θ)), and then the ELBO is maximized in the M step by solving a problem akin to supervised learning with the estimated latent variables. 


>> Tokens are: 
 ['Illustration', 'EM', 'algorithm', ':', 'At', 'iteration', ',', 'tight', 'ELBO', 'evaluated', 'E', 'step', 'solving', 'problem', 'estimating', 'latent', 'variables', '(', 'via', 'posterior', 'distribution', 'p', '(', 'z|x', ',', 'θ', ')', ')', ',', 'ELBO', 'maximized', 'M', 'step', 'solving', 'problem', 'akin', 'supervised', 'learning', 'estimated', 'latent', 'variables', '.']

>> Bigrams are: 
 [('Illustration', 'EM'), ('EM', 'algorithm'), ('algorithm', ':'), (':', 'At'), ('At', 'iteration'), ('iteration', ','), (',', 'tight'), ('tight', 'ELBO'), ('ELBO', 'evaluated'), ('evaluated', 'E'), ('E', 'step'), ('step', 'solving'), ('solving', 'problem'), ('problem', 'estimating'), ('estimating', 'latent'), ('latent', 'variables'), ('variables', '('), ('(', 'via'), ('via', 'posterior'), ('posterior', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'z|x'), ('z|x', ','), (',', 'θ'), ('θ', ')'), (')', ')'), (')', ','), (',', 'ELBO'), ('ELBO', 'maximized'), ('maximized', 'M'), ('M', 'step'), ('step', 'solving'), ('solving', 'problem'), ('problem', 'akin'), ('akin', 'supervised'), ('supervised', 'learning'), ('learning', 'estimated'), ('estimated', 'latent'), ('latent', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('Illustration', 'EM', 'algorithm'), ('EM', 'algorithm', ':'), ('algorithm', ':', 'At'), (':', 'At', 'iteration'), ('At', 'iteration', ','), ('iteration', ',', 'tight'), (',', 'tight', 'ELBO'), ('tight', 'ELBO', 'evaluated'), ('ELBO', 'evaluated', 'E'), ('evaluated', 'E', 'step'), ('E', 'step', 'solving'), ('step', 'solving', 'problem'), ('solving', 'problem', 'estimating'), ('problem', 'estimating', 'latent'), ('estimating', 'latent', 'variables'), ('latent', 'variables', '('), ('variables', '(', 'via'), ('(', 'via', 'posterior'), ('via', 'posterior', 'distribution'), ('posterior', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'θ'), (',', 'θ', ')'), ('θ', ')', ')'), (')', ')', ','), (')', ',', 'ELBO'), (',', 'ELBO', 'maximized'), ('ELBO', 'maximized', 'M'), ('maximized', 'M', 'step'), ('M', 'step', 'solving'), ('step', 'solving', 'problem'), ('solving', 'problem', 'akin'), ('problem', 'akin', 'supervised'), ('akin', 'supervised', 'learning'), ('supervised', 'learning', 'estimated'), ('learning', 'estimated', 'latent'), ('estimated', 'latent', 'variables'), ('latent', 'variables', '.')]

>> POS Tags are: 
 [('Illustration', 'NNP'), ('EM', 'NNP'), ('algorithm', 'NN'), (':', ':'), ('At', 'IN'), ('iteration', 'NN'), (',', ','), ('tight', 'JJ'), ('ELBO', 'NNP'), ('evaluated', 'VBD'), ('E', 'NNP'), ('step', 'NN'), ('solving', 'VBG'), ('problem', 'NN'), ('estimating', 'VBG'), ('latent', 'JJ'), ('variables', 'NNS'), ('(', '('), ('via', 'IN'), ('posterior', 'NN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('z|x', 'NN'), (',', ','), ('θ', 'NNP'), (')', ')'), (')', ')'), (',', ','), ('ELBO', 'NNP'), ('maximized', 'VBD'), ('M', 'NNP'), ('step', 'NN'), ('solving', 'VBG'), ('problem', 'NN'), ('akin', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('estimated', 'VBN'), ('latent', 'JJ'), ('variables', 'NNS'), ('.', '.')]

 (S
  (NP Illustration/NNP EM/NNP algorithm/NN)
  :/:
  At/IN
  (NP iteration/NN)
  ,/,
  (NP tight/JJ ELBO/NNP)
  evaluated/VBD
  (NP E/NNP step/NN)
  solving/VBG
  (NP problem/NN)
  estimating/VBG
  (NP latent/JJ variables/NNS)
  (/(
  via/IN
  (NP posterior/NN distribution/NN p/NN)
  (/(
  (NP z|x/NN)
  ,/,
  (NP θ/NNP)
  )/)
  )/)
  ,/,
  (NP ELBO/NNP)
  maximized/VBD
  (NP M/NNP step/NN)
  solving/VBG
  (NP problem/NN akin/NN)
  supervised/VBD
  learning/VBG
  estimated/VBN
  (NP latent/JJ variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Illustration EM algorithm', 'iteration', 'tight ELBO', 'E step', 'problem', 'latent variables', 'posterior distribution p', 'z|x', 'θ', 'ELBO', 'M step', 'problem akin', 'latent variables']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO'), ('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('EM', 'em'), ('algorithm', 'algorithm'), (':', ':'), ('At', 'at'), ('iteration', 'iter'), (',', ','), ('tight', 'tight'), ('ELBO', 'elbo'), ('evaluated', 'evalu'), ('E', 'e'), ('step', 'step'), ('solving', 'solv'), ('problem', 'problem'), ('estimating', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('(', '('), ('via', 'via'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), (')', ')'), (',', ','), ('ELBO', 'elbo'), ('maximized', 'maxim'), ('M', 'm'), ('step', 'step'), ('solving', 'solv'), ('problem', 'problem'), ('akin', 'akin'), ('supervised', 'supervis'), ('learning', 'learn'), ('estimated', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('EM', 'em'), ('algorithm', 'algorithm'), (':', ':'), ('At', 'at'), ('iteration', 'iter'), (',', ','), ('tight', 'tight'), ('ELBO', 'elbo'), ('evaluated', 'evalu'), ('E', 'e'), ('step', 'step'), ('solving', 'solv'), ('problem', 'problem'), ('estimating', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('(', '('), ('via', 'via'), ('posterior', 'posterior'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), (')', ')'), (',', ','), ('ELBO', 'elbo'), ('maximized', 'maxim'), ('M', 'm'), ('step', 'step'), ('solving', 'solv'), ('problem', 'problem'), ('akin', 'akin'), ('supervised', 'supervis'), ('learning', 'learn'), ('estimated', 'estim'), ('latent', 'latent'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('EM', 'EM'), ('algorithm', 'algorithm'), (':', ':'), ('At', 'At'), ('iteration', 'iteration'), (',', ','), ('tight', 'tight'), ('ELBO', 'ELBO'), ('evaluated', 'evaluated'), ('E', 'E'), ('step', 'step'), ('solving', 'solving'), ('problem', 'problem'), ('estimating', 'estimating'), ('latent', 'latent'), ('variables', 'variable'), ('(', '('), ('via', 'via'), ('posterior', 'posterior'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('θ', 'θ'), (')', ')'), (')', ')'), (',', ','), ('ELBO', 'ELBO'), ('maximized', 'maximized'), ('M', 'M'), ('step', 'step'), ('solving', 'solving'), ('problem', 'problem'), ('akin', 'akin'), ('supervised', 'supervised'), ('learning', 'learning'), ('estimated', 'estimated'), ('latent', 'latent'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 473 =============================

learning with probabilistic models entail some approxi- mation of the EM algorithm. 


>> Tokens are: 
 ['learning', 'probabilistic', 'models', 'entail', 'approxi-', 'mation', 'EM', 'algorithm', '.']

>> Bigrams are: 
 [('learning', 'probabilistic'), ('probabilistic', 'models'), ('models', 'entail'), ('entail', 'approxi-'), ('approxi-', 'mation'), ('mation', 'EM'), ('EM', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('learning', 'probabilistic', 'models'), ('probabilistic', 'models', 'entail'), ('models', 'entail', 'approxi-'), ('entail', 'approxi-', 'mation'), ('approxi-', 'mation', 'EM'), ('mation', 'EM', 'algorithm'), ('EM', 'algorithm', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('probabilistic', 'JJ'), ('models', 'NNS'), ('entail', 'VBP'), ('approxi-', 'JJ'), ('mation', 'NN'), ('EM', 'NNP'), ('algorithm', 'NN'), ('.', '.')]

 (S
  learning/VBG
  (NP probabilistic/JJ models/NNS)
  entail/VBP
  (NP approxi-/JJ mation/NN EM/NNP algorithm/NN)
  ./.) 


>> Noun Phrases are: 
 ['probabilistic models', 'approxi- mation EM algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('probabilistic', 'probabilist'), ('models', 'model'), ('entail', 'entail'), ('approxi-', 'approxi-'), ('mation', 'mation'), ('EM', 'em'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('probabilistic', 'probabilist'), ('models', 'model'), ('entail', 'entail'), ('approxi-', 'approxi-'), ('mation', 'mation'), ('EM', 'em'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('probabilistic', 'probabilistic'), ('models', 'model'), ('entail', 'entail'), ('approxi-', 'approxi-'), ('mation', 'mation'), ('EM', 'EM'), ('algorithm', 'algorithm'), ('.', '.')]



============================ Sentence 474 =============================

Notably, the E step can be approximated by parametrizing the variational distribu- tion with some function q(z|ϕ), or q(z|x, ϕ) to include the dependence on x, and by maximizing ELBO over the variational parameters ϕ. 


>> Tokens are: 
 ['Notably', ',', 'E', 'step', 'approximated', 'parametrizing', 'variational', 'distribu-', 'tion', 'function', 'q', '(', 'z|ϕ', ')', ',', 'q', '(', 'z|x', ',', 'ϕ', ')', 'include', 'dependence', 'x', ',', 'maximizing', 'ELBO', 'variational', 'parameters', 'ϕ', '.']

>> Bigrams are: 
 [('Notably', ','), (',', 'E'), ('E', 'step'), ('step', 'approximated'), ('approximated', 'parametrizing'), ('parametrizing', 'variational'), ('variational', 'distribu-'), ('distribu-', 'tion'), ('tion', 'function'), ('function', 'q'), ('q', '('), ('(', 'z|ϕ'), ('z|ϕ', ')'), (')', ','), (',', 'q'), ('q', '('), ('(', 'z|x'), ('z|x', ','), (',', 'ϕ'), ('ϕ', ')'), (')', 'include'), ('include', 'dependence'), ('dependence', 'x'), ('x', ','), (',', 'maximizing'), ('maximizing', 'ELBO'), ('ELBO', 'variational'), ('variational', 'parameters'), ('parameters', 'ϕ'), ('ϕ', '.')]

>> Trigrams are: 
 [('Notably', ',', 'E'), (',', 'E', 'step'), ('E', 'step', 'approximated'), ('step', 'approximated', 'parametrizing'), ('approximated', 'parametrizing', 'variational'), ('parametrizing', 'variational', 'distribu-'), ('variational', 'distribu-', 'tion'), ('distribu-', 'tion', 'function'), ('tion', 'function', 'q'), ('function', 'q', '('), ('q', '(', 'z|ϕ'), ('(', 'z|ϕ', ')'), ('z|ϕ', ')', ','), (')', ',', 'q'), (',', 'q', '('), ('q', '(', 'z|x'), ('(', 'z|x', ','), ('z|x', ',', 'ϕ'), (',', 'ϕ', ')'), ('ϕ', ')', 'include'), (')', 'include', 'dependence'), ('include', 'dependence', 'x'), ('dependence', 'x', ','), ('x', ',', 'maximizing'), (',', 'maximizing', 'ELBO'), ('maximizing', 'ELBO', 'variational'), ('ELBO', 'variational', 'parameters'), ('variational', 'parameters', 'ϕ'), ('parameters', 'ϕ', '.')]

>> POS Tags are: 
 [('Notably', 'RB'), (',', ','), ('E', 'NNP'), ('step', 'NN'), ('approximated', 'VBD'), ('parametrizing', 'VBG'), ('variational', 'JJ'), ('distribu-', 'JJ'), ('tion', 'NN'), ('function', 'NN'), ('q', 'NN'), ('(', '('), ('z|ϕ', 'NN'), (')', ')'), (',', ','), ('q', 'FW'), ('(', '('), ('z|x', 'NN'), (',', ','), ('ϕ', 'NNP'), (')', ')'), ('include', 'VBP'), ('dependence', 'NN'), ('x', 'NN'), (',', ','), ('maximizing', 'VBG'), ('ELBO', 'NNP'), ('variational', 'JJ'), ('parameters', 'NNS'), ('ϕ', 'VBP'), ('.', '.')]

 (S
  Notably/RB
  ,/,
  (NP E/NNP step/NN)
  approximated/VBD
  parametrizing/VBG
  (NP variational/JJ distribu-/JJ tion/NN function/NN q/NN)
  (/(
  (NP z|ϕ/NN)
  )/)
  ,/,
  q/FW
  (/(
  (NP z|x/NN)
  ,/,
  (NP ϕ/NNP)
  )/)
  include/VBP
  (NP dependence/NN x/NN)
  ,/,
  maximizing/VBG
  (NP ELBO/NNP)
  (NP variational/JJ parameters/NNS)
  ϕ/VBP
  ./.) 


>> Noun Phrases are: 
 ['E step', 'variational distribu- tion function q', 'z|ϕ', 'z|x', 'ϕ', 'dependence x', 'ELBO', 'variational parameters']

>> Named Entities are: 
 [('ORGANIZATION', 'ELBO')] 

>> Stemming using Porter Stemmer: 
 [('Notably', 'notabl'), (',', ','), ('E', 'e'), ('step', 'step'), ('approximated', 'approxim'), ('parametrizing', 'parametr'), ('variational', 'variat'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('function', 'function'), ('q', 'q'), ('(', '('), ('z|ϕ', 'z|ϕ'), (')', ')'), (',', ','), ('q', 'q'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('ϕ', 'ϕ'), (')', ')'), ('include', 'includ'), ('dependence', 'depend'), ('x', 'x'), (',', ','), ('maximizing', 'maxim'), ('ELBO', 'elbo'), ('variational', 'variat'), ('parameters', 'paramet'), ('ϕ', 'ϕ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Notably', 'notabl'), (',', ','), ('E', 'e'), ('step', 'step'), ('approximated', 'approxim'), ('parametrizing', 'parametr'), ('variational', 'variat'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('function', 'function'), ('q', 'q'), ('(', '('), ('z|ϕ', 'z|ϕ'), (')', ')'), (',', ','), ('q', 'q'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('ϕ', 'ϕ'), (')', ')'), ('include', 'includ'), ('dependence', 'depend'), ('x', 'x'), (',', ','), ('maximizing', 'maxim'), ('ELBO', 'elbo'), ('variational', 'variat'), ('parameters', 'paramet'), ('ϕ', 'ϕ'), ('.', '.')]

>> Lemmatization: 
 [('Notably', 'Notably'), (',', ','), ('E', 'E'), ('step', 'step'), ('approximated', 'approximated'), ('parametrizing', 'parametrizing'), ('variational', 'variational'), ('distribu-', 'distribu-'), ('tion', 'tion'), ('function', 'function'), ('q', 'q'), ('(', '('), ('z|ϕ', 'z|ϕ'), (')', ')'), (',', ','), ('q', 'q'), ('(', '('), ('z|x', 'z|x'), (',', ','), ('ϕ', 'ϕ'), (')', ')'), ('include', 'include'), ('dependence', 'dependence'), ('x', 'x'), (',', ','), ('maximizing', 'maximizing'), ('ELBO', 'ELBO'), ('variational', 'variational'), ('parameters', 'parameter'), ('ϕ', 'ϕ'), ('.', '.')]



============================ Sentence 475 =============================

This approach underlies the popular variational autoencoder technique [7]. 


>> Tokens are: 
 ['This', 'approach', 'underlies', 'popular', 'variational', 'autoencoder', 'technique', '[', '7', ']', '.']

>> Bigrams are: 
 [('This', 'approach'), ('approach', 'underlies'), ('underlies', 'popular'), ('popular', 'variational'), ('variational', 'autoencoder'), ('autoencoder', 'technique'), ('technique', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'approach', 'underlies'), ('approach', 'underlies', 'popular'), ('underlies', 'popular', 'variational'), ('popular', 'variational', 'autoencoder'), ('variational', 'autoencoder', 'technique'), ('autoencoder', 'technique', '['), ('technique', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('approach', 'NN'), ('underlies', 'VBZ'), ('popular', 'JJ'), ('variational', 'JJ'), ('autoencoder', 'NN'), ('technique', 'NN'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT approach/NN)
  underlies/VBZ
  (NP popular/JJ variational/JJ autoencoder/NN technique/NN)
  [/VBD
  7/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This approach', 'popular variational autoencoder technique', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('approach', 'approach'), ('underlies', 'underli'), ('popular', 'popular'), ('variational', 'variat'), ('autoencoder', 'autoencod'), ('technique', 'techniqu'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('approach', 'approach'), ('underlies', 'under'), ('popular', 'popular'), ('variational', 'variat'), ('autoencoder', 'autoencod'), ('technique', 'techniqu'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('approach', 'approach'), ('underlies', 'underlies'), ('popular', 'popular'), ('variational', 'variational'), ('autoencoder', 'autoencoder'), ('technique', 'technique'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



============================ Sentence 476 =============================

In the M step, instead, one can approximate the expectation in (19) using Monte Carlo stochastic approximation based on randomly sampled values of z from the current distribution q(z). 


>> Tokens are: 
 ['In', 'M', 'step', ',', 'instead', ',', 'one', 'approximate', 'expectation', '(', '19', ')', 'using', 'Monte', 'Carlo', 'stochastic', 'approximation', 'based', 'randomly', 'sampled', 'values', 'z', 'current', 'distribution', 'q', '(', 'z', ')', '.']

>> Bigrams are: 
 [('In', 'M'), ('M', 'step'), ('step', ','), (',', 'instead'), ('instead', ','), (',', 'one'), ('one', 'approximate'), ('approximate', 'expectation'), ('expectation', '('), ('(', '19'), ('19', ')'), (')', 'using'), ('using', 'Monte'), ('Monte', 'Carlo'), ('Carlo', 'stochastic'), ('stochastic', 'approximation'), ('approximation', 'based'), ('based', 'randomly'), ('randomly', 'sampled'), ('sampled', 'values'), ('values', 'z'), ('z', 'current'), ('current', 'distribution'), ('distribution', 'q'), ('q', '('), ('(', 'z'), ('z', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'M', 'step'), ('M', 'step', ','), ('step', ',', 'instead'), (',', 'instead', ','), ('instead', ',', 'one'), (',', 'one', 'approximate'), ('one', 'approximate', 'expectation'), ('approximate', 'expectation', '('), ('expectation', '(', '19'), ('(', '19', ')'), ('19', ')', 'using'), (')', 'using', 'Monte'), ('using', 'Monte', 'Carlo'), ('Monte', 'Carlo', 'stochastic'), ('Carlo', 'stochastic', 'approximation'), ('stochastic', 'approximation', 'based'), ('approximation', 'based', 'randomly'), ('based', 'randomly', 'sampled'), ('randomly', 'sampled', 'values'), ('sampled', 'values', 'z'), ('values', 'z', 'current'), ('z', 'current', 'distribution'), ('current', 'distribution', 'q'), ('distribution', 'q', '('), ('q', '(', 'z'), ('(', 'z', ')'), ('z', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('M', 'NNP'), ('step', 'NN'), (',', ','), ('instead', 'RB'), (',', ','), ('one', 'CD'), ('approximate', 'NN'), ('expectation', 'NN'), ('(', '('), ('19', 'CD'), (')', ')'), ('using', 'VBG'), ('Monte', 'NNP'), ('Carlo', 'NNP'), ('stochastic', 'JJ'), ('approximation', 'NN'), ('based', 'VBN'), ('randomly', 'RB'), ('sampled', 'VBN'), ('values', 'NNS'), ('z', 'VBP'), ('current', 'JJ'), ('distribution', 'NN'), ('q', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP M/NNP step/NN)
  ,/,
  instead/RB
  ,/,
  one/CD
  (NP approximate/NN expectation/NN)
  (/(
  19/CD
  )/)
  using/VBG
  (NP Monte/NNP Carlo/NNP)
  (NP stochastic/JJ approximation/NN)
  based/VBN
  randomly/RB
  sampled/VBN
  (NP values/NNS)
  z/VBP
  (NP current/JJ distribution/NN q/NN)
  (/(
  (NP z/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['M step', 'approximate expectation', 'Monte Carlo', 'stochastic approximation', 'values', 'current distribution q', 'z']

>> Named Entities are: 
 [('GPE', 'M'), ('PERSON', 'Monte Carlo')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('M', 'm'), ('step', 'step'), (',', ','), ('instead', 'instead'), (',', ','), ('one', 'one'), ('approximate', 'approxim'), ('expectation', 'expect'), ('(', '('), ('19', '19'), (')', ')'), ('using', 'use'), ('Monte', 'mont'), ('Carlo', 'carlo'), ('stochastic', 'stochast'), ('approximation', 'approxim'), ('based', 'base'), ('randomly', 'randomli'), ('sampled', 'sampl'), ('values', 'valu'), ('z', 'z'), ('current', 'current'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('M', 'm'), ('step', 'step'), (',', ','), ('instead', 'instead'), (',', ','), ('one', 'one'), ('approximate', 'approxim'), ('expectation', 'expect'), ('(', '('), ('19', '19'), (')', ')'), ('using', 'use'), ('Monte', 'mont'), ('Carlo', 'carlo'), ('stochastic', 'stochast'), ('approximation', 'approxim'), ('based', 'base'), ('randomly', 'random'), ('sampled', 'sampl'), ('values', 'valu'), ('z', 'z'), ('current', 'current'), ('distribution', 'distribut'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('M', 'M'), ('step', 'step'), (',', ','), ('instead', 'instead'), (',', ','), ('one', 'one'), ('approximate', 'approximate'), ('expectation', 'expectation'), ('(', '('), ('19', '19'), (')', ')'), ('using', 'using'), ('Monte', 'Monte'), ('Carlo', 'Carlo'), ('stochastic', 'stochastic'), ('approximation', 'approximation'), ('based', 'based'), ('randomly', 'randomly'), ('sampled', 'sampled'), ('values', 'value'), ('z', 'z'), ('current', 'current'), ('distribution', 'distribution'), ('q', 'q'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]



============================ Sentence 477 =============================

Finally, gradient descent can be used to carry out the mentioned optimizations for both E and M steps (see, e.g.-.-, [62]). 


>> Tokens are: 
 ['Finally', ',', 'gradient', 'descent', 'used', 'carry', 'mentioned', 'optimizations', 'E', 'M', 'steps', '(', 'see', ',', 'e.g.-.-', ',', '[', '62', ']', ')', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'gradient'), ('gradient', 'descent'), ('descent', 'used'), ('used', 'carry'), ('carry', 'mentioned'), ('mentioned', 'optimizations'), ('optimizations', 'E'), ('E', 'M'), ('M', 'steps'), ('steps', '('), ('(', 'see'), ('see', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', '['), ('[', '62'), ('62', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('Finally', ',', 'gradient'), (',', 'gradient', 'descent'), ('gradient', 'descent', 'used'), ('descent', 'used', 'carry'), ('used', 'carry', 'mentioned'), ('carry', 'mentioned', 'optimizations'), ('mentioned', 'optimizations', 'E'), ('optimizations', 'E', 'M'), ('E', 'M', 'steps'), ('M', 'steps', '('), ('steps', '(', 'see'), ('(', 'see', ','), ('see', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', '['), (',', '[', '62'), ('[', '62', ']'), ('62', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('gradient', 'JJ'), ('descent', 'NN'), ('used', 'VBN'), ('carry', 'NN'), ('mentioned', 'VBD'), ('optimizations', 'NNS'), ('E', 'NNP'), ('M', 'NNP'), ('steps', 'NNS'), ('(', '('), ('see', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('[', 'JJ'), ('62', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP gradient/JJ descent/NN)
  used/VBN
  (NP carry/NN)
  mentioned/VBD
  (NP optimizations/NNS E/NNP M/NNP steps/NNS)
  (/(
  see/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  [/JJ
  62/CD
  (NP ]/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['gradient descent', 'carry', 'optimizations E M steps', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('gradient', 'gradient'), ('descent', 'descent'), ('used', 'use'), ('carry', 'carri'), ('mentioned', 'mention'), ('optimizations', 'optim'), ('E', 'e'), ('M', 'm'), ('steps', 'step'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('62', '62'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('gradient', 'gradient'), ('descent', 'descent'), ('used', 'use'), ('carry', 'carri'), ('mentioned', 'mention'), ('optimizations', 'optim'), ('E', 'e'), ('M', 'm'), ('steps', 'step'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('62', '62'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('gradient', 'gradient'), ('descent', 'descent'), ('used', 'used'), ('carry', 'carry'), ('mentioned', 'mentioned'), ('optimizations', 'optimization'), ('E', 'E'), ('M', 'M'), ('steps', 'step'), ('(', '('), ('see', 'see'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('[', '['), ('62', '62'), (']', ']'), (')', ')'), ('.', '.')]



============================ Sentence 478 =============================

D. Advanced Learning Methods  As discussed in the previous section, ML is generally prone to overfitting for supervised learning. 


>> Tokens are: 
 ['D.', 'Advanced', 'Learning', 'Methods', 'As', 'discussed', 'previous', 'section', ',', 'ML', 'generally', 'prone', 'overfitting', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('D.', 'Advanced'), ('Advanced', 'Learning'), ('Learning', 'Methods'), ('Methods', 'As'), ('As', 'discussed'), ('discussed', 'previous'), ('previous', 'section'), ('section', ','), (',', 'ML'), ('ML', 'generally'), ('generally', 'prone'), ('prone', 'overfitting'), ('overfitting', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('D.', 'Advanced', 'Learning'), ('Advanced', 'Learning', 'Methods'), ('Learning', 'Methods', 'As'), ('Methods', 'As', 'discussed'), ('As', 'discussed', 'previous'), ('discussed', 'previous', 'section'), ('previous', 'section', ','), ('section', ',', 'ML'), (',', 'ML', 'generally'), ('ML', 'generally', 'prone'), ('generally', 'prone', 'overfitting'), ('prone', 'overfitting', 'supervised'), ('overfitting', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('D.', 'NNP'), ('Advanced', 'NNP'), ('Learning', 'NNP'), ('Methods', 'NNP'), ('As', 'IN'), ('discussed', 'VBN'), ('previous', 'JJ'), ('section', 'NN'), (',', ','), ('ML', 'NNP'), ('generally', 'RB'), ('prone', 'VBP'), ('overfitting', 'VBG'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP D./NNP Advanced/NNP Learning/NNP Methods/NNP)
  As/IN
  discussed/VBN
  (NP previous/JJ section/NN)
  ,/,
  (NP ML/NNP)
  generally/RB
  prone/VBP
  overfitting/VBG
  supervised/VBD
  (NP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['D. Advanced Learning Methods', 'previous section', 'ML', 'learning']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('D.', 'd.'), ('Advanced', 'advanc'), ('Learning', 'learn'), ('Methods', 'method'), ('As', 'as'), ('discussed', 'discuss'), ('previous', 'previou'), ('section', 'section'), (',', ','), ('ML', 'ml'), ('generally', 'gener'), ('prone', 'prone'), ('overfitting', 'overfit'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('D.', 'd.'), ('Advanced', 'advanc'), ('Learning', 'learn'), ('Methods', 'method'), ('As', 'as'), ('discussed', 'discuss'), ('previous', 'previous'), ('section', 'section'), (',', ','), ('ML', 'ml'), ('generally', 'general'), ('prone', 'prone'), ('overfitting', 'overfit'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('D.', 'D.'), ('Advanced', 'Advanced'), ('Learning', 'Learning'), ('Methods', 'Methods'), ('As', 'As'), ('discussed', 'discussed'), ('previous', 'previous'), ('section', 'section'), (',', ','), ('ML', 'ML'), ('generally', 'generally'), ('prone', 'prone'), ('overfitting', 'overfitting'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 479 =============================

For unsu- pervised learning, the performance of ML depends on the task of interest. 


>> Tokens are: 
 ['For', 'unsu-', 'pervised', 'learning', ',', 'performance', 'ML', 'depends', 'task', 'interest', '.']

>> Bigrams are: 
 [('For', 'unsu-'), ('unsu-', 'pervised'), ('pervised', 'learning'), ('learning', ','), (',', 'performance'), ('performance', 'ML'), ('ML', 'depends'), ('depends', 'task'), ('task', 'interest'), ('interest', '.')]

>> Trigrams are: 
 [('For', 'unsu-', 'pervised'), ('unsu-', 'pervised', 'learning'), ('pervised', 'learning', ','), ('learning', ',', 'performance'), (',', 'performance', 'ML'), ('performance', 'ML', 'depends'), ('ML', 'depends', 'task'), ('depends', 'task', 'interest'), ('task', 'interest', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('unsu-', 'JJ'), ('pervised', 'JJ'), ('learning', 'NN'), (',', ','), ('performance', 'NN'), ('ML', 'NNP'), ('depends', 'VBZ'), ('task', 'JJ'), ('interest', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP unsu-/JJ pervised/JJ learning/NN)
  ,/,
  (NP performance/NN ML/NNP)
  depends/VBZ
  (NP task/JJ interest/NN)
  ./.) 


>> Noun Phrases are: 
 ['unsu- pervised learning', 'performance ML', 'task interest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('unsu-', 'unsu-'), ('pervised', 'pervis'), ('learning', 'learn'), (',', ','), ('performance', 'perform'), ('ML', 'ml'), ('depends', 'depend'), ('task', 'task'), ('interest', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('unsu-', 'unsu-'), ('pervised', 'pervis'), ('learning', 'learn'), (',', ','), ('performance', 'perform'), ('ML', 'ml'), ('depends', 'depend'), ('task', 'task'), ('interest', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('unsu-', 'unsu-'), ('pervised', 'pervised'), ('learning', 'learning'), (',', ','), ('performance', 'performance'), ('ML', 'ML'), ('depends', 'depends'), ('task', 'task'), ('interest', 'interest'), ('.', '.')]



============================ Sentence 480 =============================

For example, consider the tasks of density estimation or of generation of new samples (see Sec V-A). 


>> Tokens are: 
 ['For', 'example', ',', 'consider', 'tasks', 'density', 'estimation', 'generation', 'new', 'samples', '(', 'see', 'Sec', 'V-A', ')', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'consider'), ('consider', 'tasks'), ('tasks', 'density'), ('density', 'estimation'), ('estimation', 'generation'), ('generation', 'new'), ('new', 'samples'), ('samples', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'V-A'), ('V-A', ')'), (')', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'consider'), (',', 'consider', 'tasks'), ('consider', 'tasks', 'density'), ('tasks', 'density', 'estimation'), ('density', 'estimation', 'generation'), ('estimation', 'generation', 'new'), ('generation', 'new', 'samples'), ('new', 'samples', '('), ('samples', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'V-A'), ('Sec', 'V-A', ')'), ('V-A', ')', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('consider', 'VB'), ('tasks', 'NNS'), ('density', 'NN'), ('estimation', 'NN'), ('generation', 'NN'), ('new', 'JJ'), ('samples', 'NNS'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('V-A', 'NNP'), (')', ')'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  consider/VB
  (NP tasks/NNS density/NN estimation/NN generation/NN)
  (NP new/JJ samples/NNS)
  (/(
  see/VB
  (NP Sec/NNP V-A/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['example', 'tasks density estimation generation', 'new samples', 'Sec V-A']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('consider', 'consid'), ('tasks', 'task'), ('density', 'densiti'), ('estimation', 'estim'), ('generation', 'gener'), ('new', 'new'), ('samples', 'sampl'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V-A', 'v-a'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('consider', 'consid'), ('tasks', 'task'), ('density', 'densiti'), ('estimation', 'estim'), ('generation', 'generat'), ('new', 'new'), ('samples', 'sampl'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V-A', 'v-a'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('consider', 'consider'), ('tasks', 'task'), ('density', 'density'), ('estimation', 'estimation'), ('generation', 'generation'), ('new', 'new'), ('samples', 'sample'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('V-A', 'V-A'), (')', ')'), ('.', '.')]



============================ Sentence 481 =============================

In order to illustrate some of the typical issues encountered when applying the ML criterion, in Fig. 


>> Tokens are: 
 ['In', 'order', 'illustrate', 'typical', 'issues', 'encountered', 'applying', 'ML', 'criterion', ',', 'Fig', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'illustrate'), ('illustrate', 'typical'), ('typical', 'issues'), ('issues', 'encountered'), ('encountered', 'applying'), ('applying', 'ML'), ('ML', 'criterion'), ('criterion', ','), (',', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('In', 'order', 'illustrate'), ('order', 'illustrate', 'typical'), ('illustrate', 'typical', 'issues'), ('typical', 'issues', 'encountered'), ('issues', 'encountered', 'applying'), ('encountered', 'applying', 'ML'), ('applying', 'ML', 'criterion'), ('ML', 'criterion', ','), ('criterion', ',', 'Fig'), (',', 'Fig', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('illustrate', 'NN'), ('typical', 'JJ'), ('issues', 'NNS'), ('encountered', 'VBD'), ('applying', 'VBG'), ('ML', 'NNP'), ('criterion', 'NN'), (',', ','), ('Fig', 'NNP'), ('.', '.')]

 (S
  In/IN
  (NP order/NN illustrate/NN)
  (NP typical/JJ issues/NNS)
  encountered/VBD
  applying/VBG
  (NP ML/NNP criterion/NN)
  ,/,
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['order illustrate', 'typical issues', 'ML criterion', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('illustrate', 'illustr'), ('typical', 'typic'), ('issues', 'issu'), ('encountered', 'encount'), ('applying', 'appli'), ('ML', 'ml'), ('criterion', 'criterion'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('illustrate', 'illustr'), ('typical', 'typic'), ('issues', 'issu'), ('encountered', 'encount'), ('applying', 'appli'), ('ML', 'ml'), ('criterion', 'criterion'), (',', ','), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('illustrate', 'illustrate'), ('typical', 'typical'), ('issues', 'issue'), ('encountered', 'encountered'), ('applying', 'applying'), ('ML', 'ML'), ('criterion', 'criterion'), (',', ','), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 482 =============================

14 we report a numerical result for a problem in which the true data distribution p(x) is multi-modal and the model distribution p(x|θ) is assumed to be a mixture of Gaussians, i.e.-, a directed generative model. 


>> Tokens are: 
 ['14', 'report', 'numerical', 'result', 'problem', 'true', 'data', 'distribution', 'p', '(', 'x', ')', 'multi-modal', 'model', 'distribution', 'p', '(', 'x|θ', ')', 'assumed', 'mixture', 'Gaussians', ',', 'i.e.-', ',', 'directed', 'generative', 'model', '.']

>> Bigrams are: 
 [('14', 'report'), ('report', 'numerical'), ('numerical', 'result'), ('result', 'problem'), ('problem', 'true'), ('true', 'data'), ('data', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'multi-modal'), ('multi-modal', 'model'), ('model', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', 'assumed'), ('assumed', 'mixture'), ('mixture', 'Gaussians'), ('Gaussians', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'directed'), ('directed', 'generative'), ('generative', 'model'), ('model', '.')]

>> Trigrams are: 
 [('14', 'report', 'numerical'), ('report', 'numerical', 'result'), ('numerical', 'result', 'problem'), ('result', 'problem', 'true'), ('problem', 'true', 'data'), ('true', 'data', 'distribution'), ('data', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'multi-modal'), (')', 'multi-modal', 'model'), ('multi-modal', 'model', 'distribution'), ('model', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', 'assumed'), (')', 'assumed', 'mixture'), ('assumed', 'mixture', 'Gaussians'), ('mixture', 'Gaussians', ','), ('Gaussians', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'directed'), (',', 'directed', 'generative'), ('directed', 'generative', 'model'), ('generative', 'model', '.')]

>> POS Tags are: 
 [('14', 'CD'), ('report', 'NN'), ('numerical', 'JJ'), ('result', 'NN'), ('problem', 'NN'), ('true', 'JJ'), ('data', 'NNS'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'JJ'), (')', ')'), ('multi-modal', 'JJ'), ('model', 'NN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('assumed', 'VBD'), ('mixture', 'NN'), ('Gaussians', 'NNPS'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('directed', 'VBD'), ('generative', 'JJ'), ('model', 'NN'), ('.', '.')]

 (S
  14/CD
  (NP report/NN)
  (NP numerical/JJ result/NN problem/NN)
  (NP true/JJ data/NNS distribution/NN p/NN)
  (/(
  x/JJ
  )/)
  (NP multi-modal/JJ model/NN distribution/NN p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  assumed/VBD
  (NP mixture/NN)
  Gaussians/NNPS
  ,/,
  i.e.-/JJ
  ,/,
  directed/VBD
  (NP generative/JJ model/NN)
  ./.) 


>> Noun Phrases are: 
 ['report', 'numerical result problem', 'true data distribution p', 'multi-modal model distribution p', 'x|θ', 'mixture', 'generative model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('report', 'report'), ('numerical', 'numer'), ('result', 'result'), ('problem', 'problem'), ('true', 'true'), ('data', 'data'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('multi-modal', 'multi-mod'), ('model', 'model'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('assumed', 'assum'), ('mixture', 'mixtur'), ('Gaussians', 'gaussian'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('directed', 'direct'), ('generative', 'gener'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('report', 'report'), ('numerical', 'numer'), ('result', 'result'), ('problem', 'problem'), ('true', 'true'), ('data', 'data'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('multi-modal', 'multi-mod'), ('model', 'model'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('assumed', 'assum'), ('mixture', 'mixtur'), ('Gaussians', 'gaussian'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('directed', 'direct'), ('generative', 'generat'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('report', 'report'), ('numerical', 'numerical'), ('result', 'result'), ('problem', 'problem'), ('true', 'true'), ('data', 'data'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('multi-modal', 'multi-modal'), ('model', 'model'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('assumed', 'assumed'), ('mixture', 'mixture'), ('Gaussians', 'Gaussians'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('directed', 'directed'), ('generative', 'generative'), ('model', 'model'), ('.', '.')]



============================ Sentence 483 =============================

The ML problem is tackled by using EM based on samples generated from the true distribution (see [19] for details). 


>> Tokens are: 
 ['The', 'ML', 'problem', 'tackled', 'using', 'EM', 'based', 'samples', 'generated', 'true', 'distribution', '(', 'see', '[', '19', ']', 'details', ')', '.']

>> Bigrams are: 
 [('The', 'ML'), ('ML', 'problem'), ('problem', 'tackled'), ('tackled', 'using'), ('using', 'EM'), ('EM', 'based'), ('based', 'samples'), ('samples', 'generated'), ('generated', 'true'), ('true', 'distribution'), ('distribution', '('), ('(', 'see'), ('see', '['), ('[', '19'), ('19', ']'), (']', 'details'), ('details', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'ML', 'problem'), ('ML', 'problem', 'tackled'), ('problem', 'tackled', 'using'), ('tackled', 'using', 'EM'), ('using', 'EM', 'based'), ('EM', 'based', 'samples'), ('based', 'samples', 'generated'), ('samples', 'generated', 'true'), ('generated', 'true', 'distribution'), ('true', 'distribution', '('), ('distribution', '(', 'see'), ('(', 'see', '['), ('see', '[', '19'), ('[', '19', ']'), ('19', ']', 'details'), (']', 'details', ')'), ('details', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('ML', 'NNP'), ('problem', 'NN'), ('tackled', 'VBD'), ('using', 'VBG'), ('EM', 'NNP'), ('based', 'VBN'), ('samples', 'NNS'), ('generated', 'VBD'), ('true', 'JJ'), ('distribution', 'NN'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('19', 'CD'), (']', 'NNP'), ('details', 'NNS'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT ML/NNP problem/NN)
  tackled/VBD
  using/VBG
  (NP EM/NNP)
  based/VBN
  (NP samples/NNS)
  generated/VBD
  (NP true/JJ distribution/NN)
  (/(
  see/VB
  [/RB
  19/CD
  (NP ]/NNP details/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The ML problem', 'EM', 'samples', 'true distribution', '] details']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ML', 'ml'), ('problem', 'problem'), ('tackled', 'tackl'), ('using', 'use'), ('EM', 'em'), ('based', 'base'), ('samples', 'sampl'), ('generated', 'gener'), ('true', 'true'), ('distribution', 'distribut'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ML', 'ml'), ('problem', 'problem'), ('tackled', 'tackl'), ('using', 'use'), ('EM', 'em'), ('based', 'base'), ('samples', 'sampl'), ('generated', 'generat'), ('true', 'true'), ('distribution', 'distribut'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('ML', 'ML'), ('problem', 'problem'), ('tackled', 'tackled'), ('using', 'using'), ('EM', 'EM'), ('based', 'based'), ('samples', 'sample'), ('generated', 'generated'), ('true', 'true'), ('distribution', 'distribution'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]



============================ Sentence 484 =============================

The learned distribution is seen to be a rather“blurry” estimate that misses the modes of p(x) in an attempt of being inclusive of the full support of p(x). 


>> Tokens are: 
 ['The', 'learned', 'distribution', 'seen', 'rather', '“', 'blurry', '”', 'estimate', 'misses', 'modes', 'p', '(', 'x', ')', 'attempt', 'inclusive', 'full', 'support', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('The', 'learned'), ('learned', 'distribution'), ('distribution', 'seen'), ('seen', 'rather'), ('rather', '“'), ('“', 'blurry'), ('blurry', '”'), ('”', 'estimate'), ('estimate', 'misses'), ('misses', 'modes'), ('modes', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'attempt'), ('attempt', 'inclusive'), ('inclusive', 'full'), ('full', 'support'), ('support', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'learned', 'distribution'), ('learned', 'distribution', 'seen'), ('distribution', 'seen', 'rather'), ('seen', 'rather', '“'), ('rather', '“', 'blurry'), ('“', 'blurry', '”'), ('blurry', '”', 'estimate'), ('”', 'estimate', 'misses'), ('estimate', 'misses', 'modes'), ('misses', 'modes', 'p'), ('modes', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'attempt'), (')', 'attempt', 'inclusive'), ('attempt', 'inclusive', 'full'), ('inclusive', 'full', 'support'), ('full', 'support', 'p'), ('support', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('learned', 'JJ'), ('distribution', 'NN'), ('seen', 'VBN'), ('rather', 'RB'), ('“', 'JJ'), ('blurry', 'NN'), ('”', 'JJ'), ('estimate', 'NN'), ('misses', 'NNS'), ('modes', 'NNS'), ('p', 'VBP'), ('(', '('), ('x', 'NN'), (')', ')'), ('attempt', 'NN'), ('inclusive', 'JJ'), ('full', 'JJ'), ('support', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT learned/JJ distribution/NN)
  seen/VBN
  rather/RB
  (NP “/JJ blurry/NN)
  (NP ”/JJ estimate/NN misses/NNS modes/NNS)
  p/VBP
  (/(
  (NP x/NN)
  )/)
  (NP attempt/NN)
  (NP inclusive/JJ full/JJ support/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The learned distribution', '“ blurry', '” estimate misses modes', 'x', 'attempt', 'inclusive full support p', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learned', 'learn'), ('distribution', 'distribut'), ('seen', 'seen'), ('rather', 'rather'), ('“', '“'), ('blurry', 'blurri'), ('”', '”'), ('estimate', 'estim'), ('misses', 'miss'), ('modes', 'mode'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('attempt', 'attempt'), ('inclusive', 'inclus'), ('full', 'full'), ('support', 'support'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learned', 'learn'), ('distribution', 'distribut'), ('seen', 'seen'), ('rather', 'rather'), ('“', '“'), ('blurry', 'blurri'), ('”', '”'), ('estimate', 'estim'), ('misses', 'miss'), ('modes', 'mode'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('attempt', 'attempt'), ('inclusive', 'inclus'), ('full', 'full'), ('support', 'support'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('learned', 'learned'), ('distribution', 'distribution'), ('seen', 'seen'), ('rather', 'rather'), ('“', '“'), ('blurry', 'blurry'), ('”', '”'), ('estimate', 'estimate'), ('misses', 'miss'), ('modes', 'mode'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('attempt', 'attempt'), ('inclusive', 'inclusive'), ('full', 'full'), ('support', 'support'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 485 =============================

Being a poor estimate of the true distribution, the learned model  15    -5 0 5 0  0.05  0.1  0.15  0.2  0.25  0.3  0.35  Fig. 


>> Tokens are: 
 ['Being', 'poor', 'estimate', 'true', 'distribution', ',', 'learned', 'model', '15', '-5', '0', '5', '0', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', 'Fig', '.']

>> Bigrams are: 
 [('Being', 'poor'), ('poor', 'estimate'), ('estimate', 'true'), ('true', 'distribution'), ('distribution', ','), (',', 'learned'), ('learned', 'model'), ('model', '15'), ('15', '-5'), ('-5', '0'), ('0', '5'), ('5', '0'), ('0', '0.05'), ('0.05', '0.1'), ('0.1', '0.15'), ('0.15', '0.2'), ('0.2', '0.25'), ('0.25', '0.3'), ('0.3', '0.35'), ('0.35', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Being', 'poor', 'estimate'), ('poor', 'estimate', 'true'), ('estimate', 'true', 'distribution'), ('true', 'distribution', ','), ('distribution', ',', 'learned'), (',', 'learned', 'model'), ('learned', 'model', '15'), ('model', '15', '-5'), ('15', '-5', '0'), ('-5', '0', '5'), ('0', '5', '0'), ('5', '0', '0.05'), ('0', '0.05', '0.1'), ('0.05', '0.1', '0.15'), ('0.1', '0.15', '0.2'), ('0.15', '0.2', '0.25'), ('0.2', '0.25', '0.3'), ('0.25', '0.3', '0.35'), ('0.3', '0.35', 'Fig'), ('0.35', 'Fig', '.')]

>> POS Tags are: 
 [('Being', 'VBG'), ('poor', 'JJ'), ('estimate', 'NN'), ('true', 'JJ'), ('distribution', 'NN'), (',', ','), ('learned', 'VBD'), ('model', 'NN'), ('15', 'CD'), ('-5', 'JJ'), ('0', 'CD'), ('5', 'CD'), ('0', 'CD'), ('0.05', 'CD'), ('0.1', 'CD'), ('0.15', 'CD'), ('0.2', 'CD'), ('0.25', 'CD'), ('0.3', 'CD'), ('0.35', 'CD'), ('Fig', 'NNP'), ('.', '.')]

 (S
  Being/VBG
  (NP poor/JJ estimate/NN)
  (NP true/JJ distribution/NN)
  ,/,
  learned/VBD
  (NP model/NN)
  15/CD
  -5/JJ
  0/CD
  5/CD
  0/CD
  0.05/CD
  0.1/CD
  0.15/CD
  0.2/CD
  0.25/CD
  0.3/CD
  0.35/CD
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['poor estimate', 'true distribution', 'model', 'Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Being', 'be'), ('poor', 'poor'), ('estimate', 'estim'), ('true', 'true'), ('distribution', 'distribut'), (',', ','), ('learned', 'learn'), ('model', 'model'), ('15', '15'), ('-5', '-5'), ('0', '0'), ('5', '5'), ('0', '0'), ('0.05', '0.05'), ('0.1', '0.1'), ('0.15', '0.15'), ('0.2', '0.2'), ('0.25', '0.25'), ('0.3', '0.3'), ('0.35', '0.35'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Being', 'be'), ('poor', 'poor'), ('estimate', 'estim'), ('true', 'true'), ('distribution', 'distribut'), (',', ','), ('learned', 'learn'), ('model', 'model'), ('15', '15'), ('-5', '-5'), ('0', '0'), ('5', '5'), ('0', '0'), ('0.05', '0.05'), ('0.1', '0.1'), ('0.15', '0.15'), ('0.2', '0.2'), ('0.25', '0.25'), ('0.3', '0.3'), ('0.35', '0.35'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Being', 'Being'), ('poor', 'poor'), ('estimate', 'estimate'), ('true', 'true'), ('distribution', 'distribution'), (',', ','), ('learned', 'learned'), ('model', 'model'), ('15', '15'), ('-5', '-5'), ('0', '0'), ('5', '5'), ('0', '0'), ('0.05', '0.05'), ('0.1', '0.1'), ('0.15', '0.15'), ('0.2', '0.2'), ('0.25', '0.25'), ('0.3', '0.3'), ('0.35', '0.35'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 486 =============================

14. 


>> Tokens are: 
 ['14', '.']

>> Bigrams are: 
 [('14', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD'), ('.', '.')]

 (S 14/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('.', '.')]



============================ Sentence 487 =============================

Illustration of the limitations of ML unsupervised learning, here obtained via the EM algorithm: The ML solution tends to be blurry, missing the modes of the true distribution p(x). 


>> Tokens are: 
 ['Illustration', 'limitations', 'ML', 'unsupervised', 'learning', ',', 'obtained', 'via', 'EM', 'algorithm', ':', 'The', 'ML', 'solution', 'tends', 'blurry', ',', 'missing', 'modes', 'true', 'distribution', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('Illustration', 'limitations'), ('limitations', 'ML'), ('ML', 'unsupervised'), ('unsupervised', 'learning'), ('learning', ','), (',', 'obtained'), ('obtained', 'via'), ('via', 'EM'), ('EM', 'algorithm'), ('algorithm', ':'), (':', 'The'), ('The', 'ML'), ('ML', 'solution'), ('solution', 'tends'), ('tends', 'blurry'), ('blurry', ','), (',', 'missing'), ('missing', 'modes'), ('modes', 'true'), ('true', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('Illustration', 'limitations', 'ML'), ('limitations', 'ML', 'unsupervised'), ('ML', 'unsupervised', 'learning'), ('unsupervised', 'learning', ','), ('learning', ',', 'obtained'), (',', 'obtained', 'via'), ('obtained', 'via', 'EM'), ('via', 'EM', 'algorithm'), ('EM', 'algorithm', ':'), ('algorithm', ':', 'The'), (':', 'The', 'ML'), ('The', 'ML', 'solution'), ('ML', 'solution', 'tends'), ('solution', 'tends', 'blurry'), ('tends', 'blurry', ','), ('blurry', ',', 'missing'), (',', 'missing', 'modes'), ('missing', 'modes', 'true'), ('modes', 'true', 'distribution'), ('true', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('Illustration', 'NN'), ('limitations', 'NNS'), ('ML', 'NNP'), ('unsupervised', 'VBD'), ('learning', 'NN'), (',', ','), ('obtained', 'VBN'), ('via', 'IN'), ('EM', 'NNP'), ('algorithm', 'NN'), (':', ':'), ('The', 'DT'), ('ML', 'NNP'), ('solution', 'NN'), ('tends', 'VBZ'), ('blurry', 'NN'), (',', ','), ('missing', 'VBG'), ('modes', 'NNS'), ('true', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Illustration/NN limitations/NNS ML/NNP)
  unsupervised/VBD
  (NP learning/NN)
  ,/,
  obtained/VBN
  via/IN
  (NP EM/NNP algorithm/NN)
  :/:
  (NP The/DT ML/NNP solution/NN)
  tends/VBZ
  (NP blurry/NN)
  ,/,
  missing/VBG
  (NP modes/NNS)
  (NP true/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Illustration limitations ML', 'learning', 'EM algorithm', 'The ML solution', 'blurry', 'modes', 'true distribution p', 'x']

>> Named Entities are: 
 [('GPE', 'Illustration'), ('ORGANIZATION', 'EM'), ('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('Illustration', 'illustr'), ('limitations', 'limit'), ('ML', 'ml'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('obtained', 'obtain'), ('via', 'via'), ('EM', 'em'), ('algorithm', 'algorithm'), (':', ':'), ('The', 'the'), ('ML', 'ml'), ('solution', 'solut'), ('tends', 'tend'), ('blurry', 'blurri'), (',', ','), ('missing', 'miss'), ('modes', 'mode'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Illustration', 'illustr'), ('limitations', 'limit'), ('ML', 'ml'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), (',', ','), ('obtained', 'obtain'), ('via', 'via'), ('EM', 'em'), ('algorithm', 'algorithm'), (':', ':'), ('The', 'the'), ('ML', 'ml'), ('solution', 'solut'), ('tends', 'tend'), ('blurry', 'blurri'), (',', ','), ('missing', 'miss'), ('modes', 'mode'), ('true', 'true'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Illustration', 'Illustration'), ('limitations', 'limitation'), ('ML', 'ML'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('obtained', 'obtained'), ('via', 'via'), ('EM', 'EM'), ('algorithm', 'algorithm'), (':', ':'), ('The', 'The'), ('ML', 'ML'), ('solution', 'solution'), ('tends', 'tends'), ('blurry', 'blurry'), (',', ','), ('missing', 'missing'), ('modes', 'mode'), ('true', 'true'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 488 =============================

can clearly also be problematic for sample generation in the sense that samples generated from the model would tend to be quite different from the data samples. 


>> Tokens are: 
 ['clearly', 'also', 'problematic', 'sample', 'generation', 'sense', 'samples', 'generated', 'model', 'would', 'tend', 'quite', 'different', 'data', 'samples', '.']

>> Bigrams are: 
 [('clearly', 'also'), ('also', 'problematic'), ('problematic', 'sample'), ('sample', 'generation'), ('generation', 'sense'), ('sense', 'samples'), ('samples', 'generated'), ('generated', 'model'), ('model', 'would'), ('would', 'tend'), ('tend', 'quite'), ('quite', 'different'), ('different', 'data'), ('data', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('clearly', 'also', 'problematic'), ('also', 'problematic', 'sample'), ('problematic', 'sample', 'generation'), ('sample', 'generation', 'sense'), ('generation', 'sense', 'samples'), ('sense', 'samples', 'generated'), ('samples', 'generated', 'model'), ('generated', 'model', 'would'), ('model', 'would', 'tend'), ('would', 'tend', 'quite'), ('tend', 'quite', 'different'), ('quite', 'different', 'data'), ('different', 'data', 'samples'), ('data', 'samples', '.')]

>> POS Tags are: 
 [('clearly', 'RB'), ('also', 'RB'), ('problematic', 'JJ'), ('sample', 'NN'), ('generation', 'NN'), ('sense', 'NN'), ('samples', 'NNS'), ('generated', 'VBD'), ('model', 'NN'), ('would', 'MD'), ('tend', 'VB'), ('quite', 'RB'), ('different', 'JJ'), ('data', 'NNS'), ('samples', 'NNS'), ('.', '.')]

 (S
  clearly/RB
  also/RB
  (NP problematic/JJ sample/NN generation/NN sense/NN samples/NNS)
  generated/VBD
  (NP model/NN)
  would/MD
  tend/VB
  quite/RB
  (NP different/JJ data/NNS samples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['problematic sample generation sense samples', 'model', 'different data samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('clearly', 'clearli'), ('also', 'also'), ('problematic', 'problemat'), ('sample', 'sampl'), ('generation', 'gener'), ('sense', 'sens'), ('samples', 'sampl'), ('generated', 'gener'), ('model', 'model'), ('would', 'would'), ('tend', 'tend'), ('quite', 'quit'), ('different', 'differ'), ('data', 'data'), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('clearly', 'clear'), ('also', 'also'), ('problematic', 'problemat'), ('sample', 'sampl'), ('generation', 'generat'), ('sense', 'sens'), ('samples', 'sampl'), ('generated', 'generat'), ('model', 'model'), ('would', 'would'), ('tend', 'tend'), ('quite', 'quit'), ('different', 'differ'), ('data', 'data'), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('clearly', 'clearly'), ('also', 'also'), ('problematic', 'problematic'), ('sample', 'sample'), ('generation', 'generation'), ('sense', 'sense'), ('samples', 'sample'), ('generated', 'generated'), ('model', 'model'), ('would', 'would'), ('tend', 'tend'), ('quite', 'quite'), ('different', 'different'), ('data', 'data'), ('samples', 'sample'), ('.', '.')]



============================ Sentence 489 =============================

In the rest of this section, we briefly review advanced learning methods that address this limitation of ML. 


>> Tokens are: 
 ['In', 'rest', 'section', ',', 'briefly', 'review', 'advanced', 'learning', 'methods', 'address', 'limitation', 'ML', '.']

>> Bigrams are: 
 [('In', 'rest'), ('rest', 'section'), ('section', ','), (',', 'briefly'), ('briefly', 'review'), ('review', 'advanced'), ('advanced', 'learning'), ('learning', 'methods'), ('methods', 'address'), ('address', 'limitation'), ('limitation', 'ML'), ('ML', '.')]

>> Trigrams are: 
 [('In', 'rest', 'section'), ('rest', 'section', ','), ('section', ',', 'briefly'), (',', 'briefly', 'review'), ('briefly', 'review', 'advanced'), ('review', 'advanced', 'learning'), ('advanced', 'learning', 'methods'), ('learning', 'methods', 'address'), ('methods', 'address', 'limitation'), ('address', 'limitation', 'ML'), ('limitation', 'ML', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('rest', 'NN'), ('section', 'NN'), (',', ','), ('briefly', 'NN'), ('review', 'NN'), ('advanced', 'VBD'), ('learning', 'JJ'), ('methods', 'NNS'), ('address', 'JJ'), ('limitation', 'NN'), ('ML', 'NNP'), ('.', '.')]

 (S
  In/IN
  (NP rest/NN section/NN)
  ,/,
  (NP briefly/NN review/NN)
  advanced/VBD
  (NP learning/JJ methods/NNS)
  (NP address/JJ limitation/NN ML/NNP)
  ./.) 


>> Noun Phrases are: 
 ['rest section', 'briefly review', 'learning methods', 'address limitation ML']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('briefly', 'briefli'), ('review', 'review'), ('advanced', 'advanc'), ('learning', 'learn'), ('methods', 'method'), ('address', 'address'), ('limitation', 'limit'), ('ML', 'ml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('briefly', 'briefli'), ('review', 'review'), ('advanced', 'advanc'), ('learning', 'learn'), ('methods', 'method'), ('address', 'address'), ('limitation', 'limit'), ('ML', 'ml'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('rest', 'rest'), ('section', 'section'), (',', ','), ('briefly', 'briefly'), ('review', 'review'), ('advanced', 'advanced'), ('learning', 'learning'), ('methods', 'method'), ('address', 'address'), ('limitation', 'limitation'), ('ML', 'ML'), ('.', '.')]



============================ Sentence 490 =============================

In order to move beyond ML, we first observe that ML can be proven to minimize the KL divergence  KL(pD(x)||p(x|θ)) = Ez∼pD(x) [ ln pD(x)  p(x|θ)  ] (20)  between the empirical distribution, or histogram, of the data  pD(x) = N [x]  N , (21)  where N [x] counts the number of occurrences of value x in the data, and the parameterized model distribution p(x|θ). 


>> Tokens are: 
 ['In', 'order', 'move', 'beyond', 'ML', ',', 'first', 'observe', 'ML', 'proven', 'minimize', 'KL', 'divergence', 'KL', '(', 'pD', '(', 'x', ')', '||p', '(', 'x|θ', ')', ')', '=', 'Ez∼pD', '(', 'x', ')', '[', 'ln', 'pD', '(', 'x', ')', 'p', '(', 'x|θ', ')', ']', '(', '20', ')', 'empirical', 'distribution', ',', 'histogram', ',', 'data', 'pD', '(', 'x', ')', '=', 'N', '[', 'x', ']', 'N', ',', '(', '21', ')', 'N', '[', 'x', ']', 'counts', 'number', 'occurrences', 'value', 'x', 'data', ',', 'parameterized', 'model', 'distribution', 'p', '(', 'x|θ', ')', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'move'), ('move', 'beyond'), ('beyond', 'ML'), ('ML', ','), (',', 'first'), ('first', 'observe'), ('observe', 'ML'), ('ML', 'proven'), ('proven', 'minimize'), ('minimize', 'KL'), ('KL', 'divergence'), ('divergence', 'KL'), ('KL', '('), ('(', 'pD'), ('pD', '('), ('(', 'x'), ('x', ')'), (')', '||p'), ('||p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', ')'), (')', '='), ('=', 'Ez∼pD'), ('Ez∼pD', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'ln'), ('ln', 'pD'), ('pD', '('), ('(', 'x'), ('x', ')'), (')', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', ']'), (']', '('), ('(', '20'), ('20', ')'), (')', 'empirical'), ('empirical', 'distribution'), ('distribution', ','), (',', 'histogram'), ('histogram', ','), (',', 'data'), ('data', 'pD'), ('pD', '('), ('(', 'x'), ('x', ')'), (')', '='), ('=', 'N'), ('N', '['), ('[', 'x'), ('x', ']'), (']', 'N'), ('N', ','), (',', '('), ('(', '21'), ('21', ')'), (')', 'N'), ('N', '['), ('[', 'x'), ('x', ']'), (']', 'counts'), ('counts', 'number'), ('number', 'occurrences'), ('occurrences', 'value'), ('value', 'x'), ('x', 'data'), ('data', ','), (',', 'parameterized'), ('parameterized', 'model'), ('model', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'order', 'move'), ('order', 'move', 'beyond'), ('move', 'beyond', 'ML'), ('beyond', 'ML', ','), ('ML', ',', 'first'), (',', 'first', 'observe'), ('first', 'observe', 'ML'), ('observe', 'ML', 'proven'), ('ML', 'proven', 'minimize'), ('proven', 'minimize', 'KL'), ('minimize', 'KL', 'divergence'), ('KL', 'divergence', 'KL'), ('divergence', 'KL', '('), ('KL', '(', 'pD'), ('(', 'pD', '('), ('pD', '(', 'x'), ('(', 'x', ')'), ('x', ')', '||p'), (')', '||p', '('), ('||p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', ')'), (')', ')', '='), (')', '=', 'Ez∼pD'), ('=', 'Ez∼pD', '('), ('Ez∼pD', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'ln'), ('[', 'ln', 'pD'), ('ln', 'pD', '('), ('pD', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'p'), (')', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', ']'), (')', ']', '('), (']', '(', '20'), ('(', '20', ')'), ('20', ')', 'empirical'), (')', 'empirical', 'distribution'), ('empirical', 'distribution', ','), ('distribution', ',', 'histogram'), (',', 'histogram', ','), ('histogram', ',', 'data'), (',', 'data', 'pD'), ('data', 'pD', '('), ('pD', '(', 'x'), ('(', 'x', ')'), ('x', ')', '='), (')', '=', 'N'), ('=', 'N', '['), ('N', '[', 'x'), ('[', 'x', ']'), ('x', ']', 'N'), (']', 'N', ','), ('N', ',', '('), (',', '(', '21'), ('(', '21', ')'), ('21', ')', 'N'), (')', 'N', '['), ('N', '[', 'x'), ('[', 'x', ']'), ('x', ']', 'counts'), (']', 'counts', 'number'), ('counts', 'number', 'occurrences'), ('number', 'occurrences', 'value'), ('occurrences', 'value', 'x'), ('value', 'x', 'data'), ('x', 'data', ','), ('data', ',', 'parameterized'), (',', 'parameterized', 'model'), ('parameterized', 'model', 'distribution'), ('model', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('move', 'NN'), ('beyond', 'IN'), ('ML', 'NNP'), (',', ','), ('first', 'RB'), ('observe', 'VBP'), ('ML', 'NNP'), ('proven', 'RB'), ('minimize', 'VB'), ('KL', 'NNP'), ('divergence', 'NN'), ('KL', 'NNP'), ('(', '('), ('pD', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('||p', 'NNP'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), (')', ')'), ('=', 'FW'), ('Ez∼pD', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('ln', 'JJ'), ('pD', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), (']', 'NNP'), ('(', '('), ('20', 'CD'), (')', ')'), ('empirical', 'JJ'), ('distribution', 'NN'), (',', ','), ('histogram', 'NN'), (',', ','), ('data', 'NNS'), ('pD', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('=', 'VBP'), ('N', 'NNP'), ('[', 'NNP'), ('x', 'NNP'), (']', 'NNP'), ('N', 'NNP'), (',', ','), ('(', '('), ('21', 'CD'), (')', ')'), ('N', 'NNP'), ('[', 'NNP'), ('x', 'NNP'), (']', 'NNP'), ('counts', 'VBZ'), ('number', 'NN'), ('occurrences', 'NNS'), ('value', 'NN'), ('x', 'NNP'), ('data', 'NNS'), (',', ','), ('parameterized', 'VBN'), ('model', 'NN'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP order/NN move/NN)
  beyond/IN
  (NP ML/NNP)
  ,/,
  first/RB
  observe/VBP
  (NP ML/NNP)
  proven/RB
  minimize/VB
  (NP KL/NNP divergence/NN KL/NNP)
  (/(
  (NP pD/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP ||p/NNP)
  (/(
  (NP x|θ/NNP)
  )/)
  )/)
  =/FW
  (NP Ez∼pD/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP ln/JJ pD/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  (NP ]/NNP)
  (/(
  20/CD
  )/)
  (NP empirical/JJ distribution/NN)
  ,/,
  (NP histogram/NN)
  ,/,
  (NP data/NNS pD/NN)
  (/(
  (NP x/NNP)
  )/)
  =/VBP
  (NP N/NNP [/NNP x/NNP ]/NNP N/NNP)
  ,/,
  (/(
  21/CD
  )/)
  (NP N/NNP [/NNP x/NNP ]/NNP)
  counts/VBZ
  (NP number/NN occurrences/NNS value/NN x/NNP data/NNS)
  ,/,
  parameterized/VBN
  (NP model/NN distribution/NN p/NN)
  (/(
  (NP x|θ/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['order move', 'ML', 'ML', 'KL divergence KL', 'pD', 'x', '||p', 'x|θ', 'Ez∼pD', 'x', 'ln pD', 'x', 'p', 'x|θ', ']', 'empirical distribution', 'histogram', 'data pD', 'x', 'N [ x ] N', 'N [ x ]', 'number occurrences value x data', 'model distribution p', 'x|θ']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ml'), (',', ','), ('first', 'first'), ('observe', 'observ'), ('ML', 'ml'), ('proven', 'proven'), ('minimize', 'minim'), ('KL', 'kl'), ('divergence', 'diverg'), ('KL', 'kl'), ('(', '('), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('||p', '||p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (')', ')'), ('=', '='), ('Ez∼pD', 'ez∼pd'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('ln', 'ln'), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (']', ']'), ('(', '('), ('20', '20'), (')', ')'), ('empirical', 'empir'), ('distribution', 'distribut'), (',', ','), ('histogram', 'histogram'), (',', ','), ('data', 'data'), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('N', 'n'), ('[', '['), ('x', 'x'), (']', ']'), ('N', 'n'), (',', ','), ('(', '('), ('21', '21'), (')', ')'), ('N', 'n'), ('[', '['), ('x', 'x'), (']', ']'), ('counts', 'count'), ('number', 'number'), ('occurrences', 'occurr'), ('value', 'valu'), ('x', 'x'), ('data', 'data'), (',', ','), ('parameterized', 'parameter'), ('model', 'model'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ml'), (',', ','), ('first', 'first'), ('observe', 'observ'), ('ML', 'ml'), ('proven', 'proven'), ('minimize', 'minim'), ('KL', 'kl'), ('divergence', 'diverg'), ('KL', 'kl'), ('(', '('), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('||p', '||p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (')', ')'), ('=', '='), ('Ez∼pD', 'ez∼pd'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('ln', 'ln'), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (']', ']'), ('(', '('), ('20', '20'), (')', ')'), ('empirical', 'empir'), ('distribution', 'distribut'), (',', ','), ('histogram', 'histogram'), (',', ','), ('data', 'data'), ('pD', 'pd'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('N', 'n'), ('[', '['), ('x', 'x'), (']', ']'), ('N', 'n'), (',', ','), ('(', '('), ('21', '21'), (')', ')'), ('N', 'n'), ('[', '['), ('x', 'x'), (']', ']'), ('counts', 'count'), ('number', 'number'), ('occurrences', 'occurr'), ('value', 'valu'), ('x', 'x'), ('data', 'data'), (',', ','), ('parameterized', 'parameter'), ('model', 'model'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ML'), (',', ','), ('first', 'first'), ('observe', 'observe'), ('ML', 'ML'), ('proven', 'proven'), ('minimize', 'minimize'), ('KL', 'KL'), ('divergence', 'divergence'), ('KL', 'KL'), ('(', '('), ('pD', 'pD'), ('(', '('), ('x', 'x'), (')', ')'), ('||p', '||p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (')', ')'), ('=', '='), ('Ez∼pD', 'Ez∼pD'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('ln', 'ln'), ('pD', 'pD'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), (']', ']'), ('(', '('), ('20', '20'), (')', ')'), ('empirical', 'empirical'), ('distribution', 'distribution'), (',', ','), ('histogram', 'histogram'), (',', ','), ('data', 'data'), ('pD', 'pD'), ('(', '('), ('x', 'x'), (')', ')'), ('=', '='), ('N', 'N'), ('[', '['), ('x', 'x'), (']', ']'), ('N', 'N'), (',', ','), ('(', '('), ('21', '21'), (')', ')'), ('N', 'N'), ('[', '['), ('x', 'x'), (']', ']'), ('counts', 'count'), ('number', 'number'), ('occurrences', 'occurrence'), ('value', 'value'), ('x', 'x'), ('data', 'data'), (',', ','), ('parameterized', 'parameterized'), ('model', 'model'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('.', '.')]



============================ Sentence 491 =============================

In other words, ML fits the model to the his- togram of the data by using the KL divergence as a measure of fitness. 


>> Tokens are: 
 ['In', 'words', ',', 'ML', 'fits', 'model', 'his-', 'togram', 'data', 'using', 'KL', 'divergence', 'measure', 'fitness', '.']

>> Bigrams are: 
 [('In', 'words'), ('words', ','), (',', 'ML'), ('ML', 'fits'), ('fits', 'model'), ('model', 'his-'), ('his-', 'togram'), ('togram', 'data'), ('data', 'using'), ('using', 'KL'), ('KL', 'divergence'), ('divergence', 'measure'), ('measure', 'fitness'), ('fitness', '.')]

>> Trigrams are: 
 [('In', 'words', ','), ('words', ',', 'ML'), (',', 'ML', 'fits'), ('ML', 'fits', 'model'), ('fits', 'model', 'his-'), ('model', 'his-', 'togram'), ('his-', 'togram', 'data'), ('togram', 'data', 'using'), ('data', 'using', 'KL'), ('using', 'KL', 'divergence'), ('KL', 'divergence', 'measure'), ('divergence', 'measure', 'fitness'), ('measure', 'fitness', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('words', 'NNS'), (',', ','), ('ML', 'NNP'), ('fits', 'VBZ'), ('model', 'FW'), ('his-', 'JJ'), ('togram', 'NN'), ('data', 'NNS'), ('using', 'VBG'), ('KL', 'NNP'), ('divergence', 'NN'), ('measure', 'NN'), ('fitness', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP words/NNS)
  ,/,
  (NP ML/NNP)
  fits/VBZ
  model/FW
  (NP his-/JJ togram/NN data/NNS)
  using/VBG
  (NP KL/NNP divergence/NN measure/NN fitness/NN)
  ./.) 


>> Noun Phrases are: 
 ['words', 'ML', 'his- togram data', 'KL divergence measure fitness']

>> Named Entities are: 
 [('ORGANIZATION', 'ML'), ('ORGANIZATION', 'KL')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('ML', 'ml'), ('fits', 'fit'), ('model', 'model'), ('his-', 'his-'), ('togram', 'togram'), ('data', 'data'), ('using', 'use'), ('KL', 'kl'), ('divergence', 'diverg'), ('measure', 'measur'), ('fitness', 'fit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('ML', 'ml'), ('fits', 'fit'), ('model', 'model'), ('his-', 'his-'), ('togram', 'togram'), ('data', 'data'), ('using', 'use'), ('KL', 'kl'), ('divergence', 'diverg'), ('measure', 'measur'), ('fitness', 'fit'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('words', 'word'), (',', ','), ('ML', 'ML'), ('fits', 'fit'), ('model', 'model'), ('his-', 'his-'), ('togram', 'togram'), ('data', 'data'), ('using', 'using'), ('KL', 'KL'), ('divergence', 'divergence'), ('measure', 'measure'), ('fitness', 'fitness'), ('.', '.')]



============================ Sentence 492 =============================

Indeed, as mentioned in Sec. 


>> Tokens are: 
 ['Indeed', ',', 'mentioned', 'Sec', '.']

>> Bigrams are: 
 [('Indeed', ','), (',', 'mentioned'), ('mentioned', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Indeed', ',', 'mentioned'), (',', 'mentioned', 'Sec'), ('mentioned', 'Sec', '.')]

>> POS Tags are: 
 [('Indeed', 'RB'), (',', ','), ('mentioned', 'VBD'), ('Sec', 'NNP'), ('.', '.')]

 (S Indeed/RB ,/, mentioned/VBD (NP Sec/NNP) ./.) 


>> Noun Phrases are: 
 ['Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Indeed', 'inde'), (',', ','), ('mentioned', 'mention'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Indeed', 'inde'), (',', ','), ('mentioned', 'mention'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Indeed', 'Indeed'), (',', ','), ('mentioned', 'mentioned'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 493 =============================

V-C, the KL divergence is a quantitative measure of “difference” between two distributions. 


>> Tokens are: 
 ['V-C', ',', 'KL', 'divergence', 'quantitative', 'measure', '“', 'difference', '”', 'two', 'distributions', '.']

>> Bigrams are: 
 [('V-C', ','), (',', 'KL'), ('KL', 'divergence'), ('divergence', 'quantitative'), ('quantitative', 'measure'), ('measure', '“'), ('“', 'difference'), ('difference', '”'), ('”', 'two'), ('two', 'distributions'), ('distributions', '.')]

>> Trigrams are: 
 [('V-C', ',', 'KL'), (',', 'KL', 'divergence'), ('KL', 'divergence', 'quantitative'), ('divergence', 'quantitative', 'measure'), ('quantitative', 'measure', '“'), ('measure', '“', 'difference'), ('“', 'difference', '”'), ('difference', '”', 'two'), ('”', 'two', 'distributions'), ('two', 'distributions', '.')]

>> POS Tags are: 
 [('V-C', 'NNP'), (',', ','), ('KL', 'NNP'), ('divergence', 'NN'), ('quantitative', 'JJ'), ('measure', 'NN'), ('“', 'NNP'), ('difference', 'NN'), ('”', 'CD'), ('two', 'CD'), ('distributions', 'NNS'), ('.', '.')]

 (S
  (NP V-C/NNP)
  ,/,
  (NP KL/NNP divergence/NN)
  (NP quantitative/JJ measure/NN “/NNP difference/NN)
  ”/CD
  two/CD
  (NP distributions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['V-C', 'KL divergence', 'quantitative measure “ difference', 'distributions']

>> Named Entities are: 
 [('ORGANIZATION', 'KL')] 

>> Stemming using Porter Stemmer: 
 [('V-C', 'v-c'), (',', ','), ('KL', 'kl'), ('divergence', 'diverg'), ('quantitative', 'quantit'), ('measure', 'measur'), ('“', '“'), ('difference', 'differ'), ('”', '”'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('V-C', 'v-c'), (',', ','), ('KL', 'kl'), ('divergence', 'diverg'), ('quantitative', 'quantit'), ('measure', 'measur'), ('“', '“'), ('difference', 'differ'), ('”', '”'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('V-C', 'V-C'), (',', ','), ('KL', 'KL'), ('divergence', 'divergence'), ('quantitative', 'quantitative'), ('measure', 'measure'), ('“', '“'), ('difference', 'difference'), ('”', '”'), ('two', 'two'), ('distributions', 'distribution'), ('.', '.')]



============================ Sentence 494 =============================

More precisely, as per (20), the KL divergence KL(p||q) quantifies the difference between two distributions p(x) and q(x) by evaluating the average of the LLR ln(p(x)/q(x)) with respect to p(x). 


>> Tokens are: 
 ['More', 'precisely', ',', 'per', '(', '20', ')', ',', 'KL', 'divergence', 'KL', '(', 'p||q', ')', 'quantifies', 'difference', 'two', 'distributions', 'p', '(', 'x', ')', 'q', '(', 'x', ')', 'evaluating', 'average', 'LLR', 'ln', '(', 'p', '(', 'x', ')', '/q', '(', 'x', ')', ')', 'respect', 'p', '(', 'x', ')', '.']

>> Bigrams are: 
 [('More', 'precisely'), ('precisely', ','), (',', 'per'), ('per', '('), ('(', '20'), ('20', ')'), (')', ','), (',', 'KL'), ('KL', 'divergence'), ('divergence', 'KL'), ('KL', '('), ('(', 'p||q'), ('p||q', ')'), (')', 'quantifies'), ('quantifies', 'difference'), ('difference', 'two'), ('two', 'distributions'), ('distributions', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', 'evaluating'), ('evaluating', 'average'), ('average', 'LLR'), ('LLR', 'ln'), ('ln', '('), ('(', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '/q'), ('/q', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', 'respect'), ('respect', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('More', 'precisely', ','), ('precisely', ',', 'per'), (',', 'per', '('), ('per', '(', '20'), ('(', '20', ')'), ('20', ')', ','), (')', ',', 'KL'), (',', 'KL', 'divergence'), ('KL', 'divergence', 'KL'), ('divergence', 'KL', '('), ('KL', '(', 'p||q'), ('(', 'p||q', ')'), ('p||q', ')', 'quantifies'), (')', 'quantifies', 'difference'), ('quantifies', 'difference', 'two'), ('difference', 'two', 'distributions'), ('two', 'distributions', 'p'), ('distributions', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'q'), (')', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'evaluating'), (')', 'evaluating', 'average'), ('evaluating', 'average', 'LLR'), ('average', 'LLR', 'ln'), ('LLR', 'ln', '('), ('ln', '(', 'p'), ('(', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '/q'), (')', '/q', '('), ('/q', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', 'respect'), (')', 'respect', 'p'), ('respect', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('precisely', 'RB'), (',', ','), ('per', 'IN'), ('(', '('), ('20', 'CD'), (')', ')'), (',', ','), ('KL', 'NNP'), ('divergence', 'NN'), ('KL', 'NNP'), ('(', '('), ('p||q', 'NN'), (')', ')'), ('quantifies', 'VBZ'), ('difference', 'NN'), ('two', 'CD'), ('distributions', 'NNS'), ('p', 'VBP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('q', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('evaluating', 'VBG'), ('average', 'JJ'), ('LLR', 'NNP'), ('ln', 'NN'), ('(', '('), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('/q', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), ('respect', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  More/RBR
  precisely/RB
  ,/,
  per/IN
  (/(
  20/CD
  )/)
  ,/,
  (NP KL/NNP divergence/NN KL/NNP)
  (/(
  (NP p||q/NN)
  )/)
  quantifies/VBZ
  (NP difference/NN)
  two/CD
  (NP distributions/NNS)
  p/VBP
  (/(
  (NP x/NNP)
  )/)
  (NP q/NN)
  (/(
  (NP x/NNP)
  )/)
  evaluating/VBG
  (NP average/JJ LLR/NNP ln/NN)
  (/(
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP /q/NNP)
  (/(
  (NP x/NNP)
  )/)
  )/)
  (NP respect/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['KL divergence KL', 'p||q', 'difference', 'distributions', 'x', 'q', 'x', 'average LLR ln', 'p', 'x', '/q', 'x', 'respect p', 'x']

>> Named Entities are: 
 [('ORGANIZATION', 'KL'), ('ORGANIZATION', 'LLR')] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('per', 'per'), ('(', '('), ('20', '20'), (')', ')'), (',', ','), ('KL', 'kl'), ('divergence', 'diverg'), ('KL', 'kl'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('quantifies', 'quantifi'), ('difference', 'differ'), ('two', 'two'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('evaluating', 'evalu'), ('average', 'averag'), ('LLR', 'llr'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('respect', 'respect'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('per', 'per'), ('(', '('), ('20', '20'), (')', ')'), (',', ','), ('KL', 'kl'), ('divergence', 'diverg'), ('KL', 'kl'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('quantifies', 'quantifi'), ('difference', 'differ'), ('two', 'two'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('evaluating', 'evalu'), ('average', 'averag'), ('LLR', 'llr'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('respect', 'respect'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('precisely', 'precisely'), (',', ','), ('per', 'per'), ('(', '('), ('20', '20'), (')', ')'), (',', ','), ('KL', 'KL'), ('divergence', 'divergence'), ('KL', 'KL'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('quantifies', 'quantifies'), ('difference', 'difference'), ('two', 'two'), ('distributions', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('evaluating', 'evaluating'), ('average', 'average'), ('LLR', 'LLR'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('respect', 'respect'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 495 =============================

Consider now the problem illustrated in Fig. 


>> Tokens are: 
 ['Consider', 'problem', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('Consider', 'problem'), ('problem', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Consider', 'problem', 'illustrated'), ('problem', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('Consider', 'VB'), ('problem', 'NN'), ('illustrated', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S Consider/VB (NP problem/NN) illustrated/VBN (NP Fig/NNP) ./.) 


>> Noun Phrases are: 
 ['problem', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Consider', 'consid'), ('problem', 'problem'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Consider', 'consid'), ('problem', 'problem'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Consider', 'Consider'), ('problem', 'problem'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 496 =============================

15, in which a discriminator wishes to distinguish between two hypotheses, namely the hypothesis that the data x is a sample from distribution p(x) and the hypothesis that it is instead generated from q(x). 


>> Tokens are: 
 ['15', ',', 'discriminator', 'wishes', 'distinguish', 'two', 'hypotheses', ',', 'namely', 'hypothesis', 'data', 'x', 'sample', 'distribution', 'p', '(', 'x', ')', 'hypothesis', 'instead', 'generated', 'q', '(', 'x', ')', '.']

>> Bigrams are: 
 [('15', ','), (',', 'discriminator'), ('discriminator', 'wishes'), ('wishes', 'distinguish'), ('distinguish', 'two'), ('two', 'hypotheses'), ('hypotheses', ','), (',', 'namely'), ('namely', 'hypothesis'), ('hypothesis', 'data'), ('data', 'x'), ('x', 'sample'), ('sample', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'hypothesis'), ('hypothesis', 'instead'), ('instead', 'generated'), ('generated', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('15', ',', 'discriminator'), (',', 'discriminator', 'wishes'), ('discriminator', 'wishes', 'distinguish'), ('wishes', 'distinguish', 'two'), ('distinguish', 'two', 'hypotheses'), ('two', 'hypotheses', ','), ('hypotheses', ',', 'namely'), (',', 'namely', 'hypothesis'), ('namely', 'hypothesis', 'data'), ('hypothesis', 'data', 'x'), ('data', 'x', 'sample'), ('x', 'sample', 'distribution'), ('sample', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'hypothesis'), (')', 'hypothesis', 'instead'), ('hypothesis', 'instead', 'generated'), ('instead', 'generated', 'q'), ('generated', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('15', 'CD'), (',', ','), ('discriminator', 'NN'), ('wishes', 'NNS'), ('distinguish', 'JJ'), ('two', 'CD'), ('hypotheses', 'NNS'), (',', ','), ('namely', 'RB'), ('hypothesis', 'NN'), ('data', 'NNS'), ('x', 'VBP'), ('sample', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('hypothesis', 'NN'), ('instead', 'RB'), ('generated', 'VBD'), ('q', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  15/CD
  ,/,
  (NP discriminator/NN wishes/NNS)
  distinguish/JJ
  two/CD
  (NP hypotheses/NNS)
  ,/,
  namely/RB
  (NP hypothesis/NN data/NNS)
  x/VBP
  (NP sample/JJ distribution/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP hypothesis/NN)
  instead/RB
  generated/VBD
  (NP q/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['discriminator wishes', 'hypotheses', 'hypothesis data', 'sample distribution p', 'x', 'hypothesis', 'q', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), (',', ','), ('discriminator', 'discrimin'), ('wishes', 'wish'), ('distinguish', 'distinguish'), ('two', 'two'), ('hypotheses', 'hypothes'), (',', ','), ('namely', 'name'), ('hypothesis', 'hypothesi'), ('data', 'data'), ('x', 'x'), ('sample', 'sampl'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('hypothesis', 'hypothesi'), ('instead', 'instead'), ('generated', 'gener'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), (',', ','), ('discriminator', 'discrimin'), ('wishes', 'wish'), ('distinguish', 'distinguish'), ('two', 'two'), ('hypotheses', 'hypothes'), (',', ','), ('namely', 'name'), ('hypothesis', 'hypothesi'), ('data', 'data'), ('x', 'x'), ('sample', 'sampl'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('hypothesis', 'hypothesi'), ('instead', 'instead'), ('generated', 'generat'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), (',', ','), ('discriminator', 'discriminator'), ('wishes', 'wish'), ('distinguish', 'distinguish'), ('two', 'two'), ('hypotheses', 'hypothesis'), (',', ','), ('namely', 'namely'), ('hypothesis', 'hypothesis'), ('data', 'data'), ('x', 'x'), ('sample', 'sample'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('hypothesis', 'hypothesis'), ('instead', 'instead'), ('generated', 'generated'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 497 =============================

To fix the ideas, one can focus as an example on the case where p(x) and q(x) are two Gaussian distributions with different means. 


>> Tokens are: 
 ['To', 'fix', 'ideas', ',', 'one', 'focus', 'example', 'case', 'p', '(', 'x', ')', 'q', '(', 'x', ')', 'two', 'Gaussian', 'distributions', 'different', 'means', '.']

>> Bigrams are: 
 [('To', 'fix'), ('fix', 'ideas'), ('ideas', ','), (',', 'one'), ('one', 'focus'), ('focus', 'example'), ('example', 'case'), ('case', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', 'two'), ('two', 'Gaussian'), ('Gaussian', 'distributions'), ('distributions', 'different'), ('different', 'means'), ('means', '.')]

>> Trigrams are: 
 [('To', 'fix', 'ideas'), ('fix', 'ideas', ','), ('ideas', ',', 'one'), (',', 'one', 'focus'), ('one', 'focus', 'example'), ('focus', 'example', 'case'), ('example', 'case', 'p'), ('case', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'q'), (')', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'two'), (')', 'two', 'Gaussian'), ('two', 'Gaussian', 'distributions'), ('Gaussian', 'distributions', 'different'), ('distributions', 'different', 'means'), ('different', 'means', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('fix', 'VB'), ('ideas', 'NNS'), (',', ','), ('one', 'CD'), ('focus', 'NN'), ('example', 'NN'), ('case', 'NN'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('q', 'NN'), ('(', '('), ('x', 'JJ'), (')', ')'), ('two', 'CD'), ('Gaussian', 'JJ'), ('distributions', 'NNS'), ('different', 'JJ'), ('means', 'NNS'), ('.', '.')]

 (S
  To/TO
  fix/VB
  (NP ideas/NNS)
  ,/,
  one/CD
  (NP focus/NN example/NN case/NN p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP q/NN)
  (/(
  x/JJ
  )/)
  two/CD
  (NP Gaussian/JJ distributions/NNS)
  (NP different/JJ means/NNS)
  ./.) 


>> Noun Phrases are: 
 ['ideas', 'focus example case p', 'x', 'q', 'Gaussian distributions', 'different means']

>> Named Entities are: 
 [('GPE', 'Gaussian')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('one', 'one'), ('focus', 'focu'), ('example', 'exampl'), ('case', 'case'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('two', 'two'), ('Gaussian', 'gaussian'), ('distributions', 'distribut'), ('different', 'differ'), ('means', 'mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('one', 'one'), ('focus', 'focus'), ('example', 'exampl'), ('case', 'case'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('two', 'two'), ('Gaussian', 'gaussian'), ('distributions', 'distribut'), ('different', 'differ'), ('means', 'mean'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('fix', 'fix'), ('ideas', 'idea'), (',', ','), ('one', 'one'), ('focus', 'focus'), ('example', 'example'), ('case', 'case'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('two', 'two'), ('Gaussian', 'Gaussian'), ('distributions', 'distribution'), ('different', 'different'), ('means', 'mean'), ('.', '.')]



============================ Sentence 498 =============================

To this end, the discriminator computes a statistic, that is, a function, T (x) of the data x, and then decides for the former hypothesis if T (x) is sufficiently large and for  𝑇(𝑥)  𝑥~𝑝(𝑥)  𝑥~𝑞(𝑥)  𝑝 𝑥 if 𝑇 𝑥 large  discriminator  𝑞 𝑥 if 𝑇 𝑥 small  Fig. 


>> Tokens are: 
 ['To', 'end', ',', 'discriminator', 'computes', 'statistic', ',', ',', 'function', ',', 'T', '(', 'x', ')', 'data', 'x', ',', 'decides', 'former', 'hypothesis', 'T', '(', 'x', ')', 'sufficiently', 'large', '𝑇', '(', '𝑥', ')', '𝑥~𝑝', '(', '𝑥', ')', '𝑥~𝑞', '(', '𝑥', ')', '𝑝', '𝑥', '𝑇', '𝑥', 'large', 'discriminator', '𝑞', '𝑥', '𝑇', '𝑥', 'small', 'Fig', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'discriminator'), ('discriminator', 'computes'), ('computes', 'statistic'), ('statistic', ','), (',', ','), (',', 'function'), ('function', ','), (',', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'data'), ('data', 'x'), ('x', ','), (',', 'decides'), ('decides', 'former'), ('former', 'hypothesis'), ('hypothesis', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'sufficiently'), ('sufficiently', 'large'), ('large', '𝑇'), ('𝑇', '('), ('(', '𝑥'), ('𝑥', ')'), (')', '𝑥~𝑝'), ('𝑥~𝑝', '('), ('(', '𝑥'), ('𝑥', ')'), (')', '𝑥~𝑞'), ('𝑥~𝑞', '('), ('(', '𝑥'), ('𝑥', ')'), (')', '𝑝'), ('𝑝', '𝑥'), ('𝑥', '𝑇'), ('𝑇', '𝑥'), ('𝑥', 'large'), ('large', 'discriminator'), ('discriminator', '𝑞'), ('𝑞', '𝑥'), ('𝑥', '𝑇'), ('𝑇', '𝑥'), ('𝑥', 'small'), ('small', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'discriminator'), (',', 'discriminator', 'computes'), ('discriminator', 'computes', 'statistic'), ('computes', 'statistic', ','), ('statistic', ',', ','), (',', ',', 'function'), (',', 'function', ','), ('function', ',', 'T'), (',', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'data'), (')', 'data', 'x'), ('data', 'x', ','), ('x', ',', 'decides'), (',', 'decides', 'former'), ('decides', 'former', 'hypothesis'), ('former', 'hypothesis', 'T'), ('hypothesis', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'sufficiently'), (')', 'sufficiently', 'large'), ('sufficiently', 'large', '𝑇'), ('large', '𝑇', '('), ('𝑇', '(', '𝑥'), ('(', '𝑥', ')'), ('𝑥', ')', '𝑥~𝑝'), (')', '𝑥~𝑝', '('), ('𝑥~𝑝', '(', '𝑥'), ('(', '𝑥', ')'), ('𝑥', ')', '𝑥~𝑞'), (')', '𝑥~𝑞', '('), ('𝑥~𝑞', '(', '𝑥'), ('(', '𝑥', ')'), ('𝑥', ')', '𝑝'), (')', '𝑝', '𝑥'), ('𝑝', '𝑥', '𝑇'), ('𝑥', '𝑇', '𝑥'), ('𝑇', '𝑥', 'large'), ('𝑥', 'large', 'discriminator'), ('large', 'discriminator', '𝑞'), ('discriminator', '𝑞', '𝑥'), ('𝑞', '𝑥', '𝑇'), ('𝑥', '𝑇', '𝑥'), ('𝑇', '𝑥', 'small'), ('𝑥', 'small', 'Fig'), ('small', 'Fig', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('discriminator', 'NN'), ('computes', 'NNS'), ('statistic', 'JJ'), (',', ','), (',', ','), ('function', 'NN'), (',', ','), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('data', 'NNS'), ('x', 'NN'), (',', ','), ('decides', 'VBZ'), ('former', 'JJ'), ('hypothesis', 'NN'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('sufficiently', 'RB'), ('large', 'JJ'), ('𝑇', 'NNP'), ('(', '('), ('𝑥', 'NNP'), (')', ')'), ('𝑥~𝑝', 'NN'), ('(', '('), ('𝑥', 'NNP'), (')', ')'), ('𝑥~𝑞', 'NN'), ('(', '('), ('𝑥', 'NNP'), (')', ')'), ('𝑝', 'VBP'), ('𝑥', 'JJ'), ('𝑇', 'NNP'), ('𝑥', 'NNP'), ('large', 'JJ'), ('discriminator', 'NN'), ('𝑞', 'NNP'), ('𝑥', 'NNP'), ('𝑇', 'NNP'), ('𝑥', 'NNP'), ('small', 'JJ'), ('Fig', 'NNP'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  (NP discriminator/NN computes/NNS)
  statistic/JJ
  ,/,
  ,/,
  (NP function/NN)
  ,/,
  (NP T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP data/NNS x/NN)
  ,/,
  decides/VBZ
  (NP former/JJ hypothesis/NN T/NNP)
  (/(
  (NP x/NNP)
  )/)
  sufficiently/RB
  (NP large/JJ 𝑇/NNP)
  (/(
  (NP 𝑥/NNP)
  )/)
  (NP 𝑥~𝑝/NN)
  (/(
  (NP 𝑥/NNP)
  )/)
  (NP 𝑥~𝑞/NN)
  (/(
  (NP 𝑥/NNP)
  )/)
  𝑝/VBP
  (NP 𝑥/JJ 𝑇/NNP 𝑥/NNP)
  (NP large/JJ discriminator/NN 𝑞/NNP 𝑥/NNP 𝑇/NNP 𝑥/NNP)
  (NP small/JJ Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['discriminator computes', 'function', 'T', 'x', 'data x', 'former hypothesis T', 'x', 'large 𝑇', '𝑥', '𝑥~𝑝', '𝑥', '𝑥~𝑞', '𝑥', '𝑥 𝑇 𝑥', 'large discriminator 𝑞 𝑥 𝑇 𝑥', 'small Fig']

>> Named Entities are: 
 [('GPE', 'T')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('discriminator', 'discrimin'), ('computes', 'comput'), ('statistic', 'statist'), (',', ','), (',', ','), ('function', 'function'), (',', ','), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('data', 'data'), ('x', 'x'), (',', ','), ('decides', 'decid'), ('former', 'former'), ('hypothesis', 'hypothesi'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('sufficiently', 'suffici'), ('large', 'larg'), ('𝑇', '𝑇'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑝', '𝑥~𝑝'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑞', '𝑥~𝑞'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑝', '𝑝'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('large', 'larg'), ('discriminator', 'discrimin'), ('𝑞', '𝑞'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('small', 'small'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('discriminator', 'discrimin'), ('computes', 'comput'), ('statistic', 'statist'), (',', ','), (',', ','), ('function', 'function'), (',', ','), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('data', 'data'), ('x', 'x'), (',', ','), ('decides', 'decid'), ('former', 'former'), ('hypothesis', 'hypothesi'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('sufficiently', 'suffici'), ('large', 'larg'), ('𝑇', '𝑇'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑝', '𝑥~𝑝'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑞', '𝑥~𝑞'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑝', '𝑝'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('large', 'larg'), ('discriminator', 'discrimin'), ('𝑞', '𝑞'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('small', 'small'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('discriminator', 'discriminator'), ('computes', 'computes'), ('statistic', 'statistic'), (',', ','), (',', ','), ('function', 'function'), (',', ','), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('data', 'data'), ('x', 'x'), (',', ','), ('decides', 'decides'), ('former', 'former'), ('hypothesis', 'hypothesis'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('sufficiently', 'sufficiently'), ('large', 'large'), ('𝑇', '𝑇'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑝', '𝑥~𝑝'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑥~𝑞', '𝑥~𝑞'), ('(', '('), ('𝑥', '𝑥'), (')', ')'), ('𝑝', '𝑝'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('large', 'large'), ('discriminator', 'discriminator'), ('𝑞', '𝑞'), ('𝑥', '𝑥'), ('𝑇', '𝑇'), ('𝑥', '𝑥'), ('small', 'small'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 499 =============================

15. 


>> Tokens are: 
 ['15', '.']

>> Bigrams are: 
 [('15', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('15', 'CD'), ('.', '.')]

 (S 15/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), ('.', '.')]



============================ Sentence 500 =============================

Discriminator between the hypotheses x ∼ p(x) and x ∼ q(x) based on the statistic T (x). 


>> Tokens are: 
 ['Discriminator', 'hypotheses', 'x', '∼', 'p', '(', 'x', ')', 'x', '∼', 'q', '(', 'x', ')', 'based', 'statistic', 'T', '(', 'x', ')', '.']

>> Bigrams are: 
 [('Discriminator', 'hypotheses'), ('hypotheses', 'x'), ('x', '∼'), ('∼', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'x'), ('x', '∼'), ('∼', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', 'based'), ('based', 'statistic'), ('statistic', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('Discriminator', 'hypotheses', 'x'), ('hypotheses', 'x', '∼'), ('x', '∼', 'p'), ('∼', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'x'), (')', 'x', '∼'), ('x', '∼', 'q'), ('∼', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'based'), (')', 'based', 'statistic'), ('based', 'statistic', 'T'), ('statistic', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('Discriminator', 'NN'), ('hypotheses', 'VBZ'), ('x', 'NNP'), ('∼', 'NNP'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('x', 'VBP'), ('∼', 'JJ'), ('q', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('based', 'VBN'), ('statistic', 'JJ'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Discriminator/NN)
  hypotheses/VBZ
  (NP x/NNP ∼/NNP p/NN)
  (/(
  (NP x/NNP)
  )/)
  x/VBP
  (NP ∼/JJ q/NN)
  (/(
  (NP x/NNP)
  )/)
  based/VBN
  (NP statistic/JJ T/NNP)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Discriminator', 'x ∼ p', 'x', '∼ q', 'x', 'statistic T', 'x']

>> Named Entities are: 
 [('GPE', 'Discriminator')] 

>> Stemming using Porter Stemmer: 
 [('Discriminator', 'discrimin'), ('hypotheses', 'hypothes'), ('x', 'x'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('x', 'x'), ('∼', '∼'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('based', 'base'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Discriminator', 'discrimin'), ('hypotheses', 'hypothes'), ('x', 'x'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('x', 'x'), ('∼', '∼'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('based', 'base'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Discriminator', 'Discriminator'), ('hypotheses', 'hypothesis'), ('x', 'x'), ('∼', '∼'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('x', 'x'), ('∼', '∼'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('based', 'based'), ('statistic', 'statistic'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 501 =============================

The performance of the optimal discriminator function T (x) under different design criteria yields a measure of the difference between the two distributions. 


>> Tokens are: 
 ['The', 'performance', 'optimal', 'discriminator', 'function', 'T', '(', 'x', ')', 'different', 'design', 'criteria', 'yields', 'measure', 'difference', 'two', 'distributions', '.']

>> Bigrams are: 
 [('The', 'performance'), ('performance', 'optimal'), ('optimal', 'discriminator'), ('discriminator', 'function'), ('function', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'different'), ('different', 'design'), ('design', 'criteria'), ('criteria', 'yields'), ('yields', 'measure'), ('measure', 'difference'), ('difference', 'two'), ('two', 'distributions'), ('distributions', '.')]

>> Trigrams are: 
 [('The', 'performance', 'optimal'), ('performance', 'optimal', 'discriminator'), ('optimal', 'discriminator', 'function'), ('discriminator', 'function', 'T'), ('function', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'different'), (')', 'different', 'design'), ('different', 'design', 'criteria'), ('design', 'criteria', 'yields'), ('criteria', 'yields', 'measure'), ('yields', 'measure', 'difference'), ('measure', 'difference', 'two'), ('difference', 'two', 'distributions'), ('two', 'distributions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('performance', 'NN'), ('optimal', 'JJ'), ('discriminator', 'NN'), ('function', 'NN'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('different', 'JJ'), ('design', 'NN'), ('criteria', 'NN'), ('yields', 'NNS'), ('measure', 'NN'), ('difference', 'NN'), ('two', 'CD'), ('distributions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT performance/NN)
  (NP optimal/JJ discriminator/NN function/NN T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP
    different/JJ
    design/NN
    criteria/NN
    yields/NNS
    measure/NN
    difference/NN)
  two/CD
  (NP distributions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The performance', 'optimal discriminator function T', 'x', 'different design criteria yields measure difference', 'distributions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('optimal', 'optim'), ('discriminator', 'discrimin'), ('function', 'function'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('different', 'differ'), ('design', 'design'), ('criteria', 'criteria'), ('yields', 'yield'), ('measure', 'measur'), ('difference', 'differ'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('optimal', 'optim'), ('discriminator', 'discrimin'), ('function', 'function'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('different', 'differ'), ('design', 'design'), ('criteria', 'criteria'), ('yields', 'yield'), ('measure', 'measur'), ('difference', 'differ'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('performance', 'performance'), ('optimal', 'optimal'), ('discriminator', 'discriminator'), ('function', 'function'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('different', 'different'), ('design', 'design'), ('criteria', 'criterion'), ('yields', 'yield'), ('measure', 'measure'), ('difference', 'difference'), ('two', 'two'), ('distributions', 'distribution'), ('.', '.')]



============================ Sentence 502 =============================

the latter hypothesis otherwise. 


>> Tokens are: 
 ['latter', 'hypothesis', 'otherwise', '.']

>> Bigrams are: 
 [('latter', 'hypothesis'), ('hypothesis', 'otherwise'), ('otherwise', '.')]

>> Trigrams are: 
 [('latter', 'hypothesis', 'otherwise'), ('hypothesis', 'otherwise', '.')]

>> POS Tags are: 
 [('latter', 'JJ'), ('hypothesis', 'NN'), ('otherwise', 'RB'), ('.', '.')]

 (S (NP latter/JJ hypothesis/NN) otherwise/RB ./.) 


>> Noun Phrases are: 
 ['latter hypothesis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('latter', 'latter'), ('hypothesis', 'hypothesi'), ('otherwise', 'otherwis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('latter', 'latter'), ('hypothesis', 'hypothesi'), ('otherwise', 'otherwis'), ('.', '.')]

>> Lemmatization: 
 [('latter', 'latter'), ('hypothesis', 'hypothesis'), ('otherwise', 'otherwise'), ('.', '.')]



============================ Sentence 503 =============================

Intuitively, one should expect that, the more distinct the two distributions p(x) and q(x) are, the easier it is to design a discriminator that is able to choose the correct hypothesis with high probability. 


>> Tokens are: 
 ['Intuitively', ',', 'one', 'expect', ',', 'distinct', 'two', 'distributions', 'p', '(', 'x', ')', 'q', '(', 'x', ')', ',', 'easier', 'design', 'discriminator', 'able', 'choose', 'correct', 'hypothesis', 'high', 'probability', '.']

>> Bigrams are: 
 [('Intuitively', ','), (',', 'one'), ('one', 'expect'), ('expect', ','), (',', 'distinct'), ('distinct', 'two'), ('two', 'distributions'), ('distributions', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', ','), (',', 'easier'), ('easier', 'design'), ('design', 'discriminator'), ('discriminator', 'able'), ('able', 'choose'), ('choose', 'correct'), ('correct', 'hypothesis'), ('hypothesis', 'high'), ('high', 'probability'), ('probability', '.')]

>> Trigrams are: 
 [('Intuitively', ',', 'one'), (',', 'one', 'expect'), ('one', 'expect', ','), ('expect', ',', 'distinct'), (',', 'distinct', 'two'), ('distinct', 'two', 'distributions'), ('two', 'distributions', 'p'), ('distributions', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'q'), (')', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', ','), (')', ',', 'easier'), (',', 'easier', 'design'), ('easier', 'design', 'discriminator'), ('design', 'discriminator', 'able'), ('discriminator', 'able', 'choose'), ('able', 'choose', 'correct'), ('choose', 'correct', 'hypothesis'), ('correct', 'hypothesis', 'high'), ('hypothesis', 'high', 'probability'), ('high', 'probability', '.')]

>> POS Tags are: 
 [('Intuitively', 'RB'), (',', ','), ('one', 'CD'), ('expect', 'NN'), (',', ','), ('distinct', 'JJ'), ('two', 'CD'), ('distributions', 'NNS'), ('p', 'VBP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('q', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), (',', ','), ('easier', 'JJR'), ('design', 'NN'), ('discriminator', 'NN'), ('able', 'JJ'), ('choose', 'JJ'), ('correct', 'JJ'), ('hypothesis', 'NN'), ('high', 'JJ'), ('probability', 'NN'), ('.', '.')]

 (S
  Intuitively/RB
  ,/,
  one/CD
  (NP expect/NN)
  ,/,
  distinct/JJ
  two/CD
  (NP distributions/NNS)
  p/VBP
  (/(
  (NP x/NNP)
  )/)
  (NP q/NN)
  (/(
  (NP x/NNP)
  )/)
  ,/,
  easier/JJR
  (NP design/NN discriminator/NN)
  (NP able/JJ choose/JJ correct/JJ hypothesis/NN)
  (NP high/JJ probability/NN)
  ./.) 


>> Noun Phrases are: 
 ['expect', 'distributions', 'x', 'q', 'x', 'design discriminator', 'able choose correct hypothesis', 'high probability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intuitively', 'intuit'), (',', ','), ('one', 'one'), ('expect', 'expect'), (',', ','), ('distinct', 'distinct'), ('two', 'two'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('easier', 'easier'), ('design', 'design'), ('discriminator', 'discrimin'), ('able', 'abl'), ('choose', 'choos'), ('correct', 'correct'), ('hypothesis', 'hypothesi'), ('high', 'high'), ('probability', 'probabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intuitively', 'intuit'), (',', ','), ('one', 'one'), ('expect', 'expect'), (',', ','), ('distinct', 'distinct'), ('two', 'two'), ('distributions', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('easier', 'easier'), ('design', 'design'), ('discriminator', 'discrimin'), ('able', 'abl'), ('choose', 'choos'), ('correct', 'correct'), ('hypothesis', 'hypothesi'), ('high', 'high'), ('probability', 'probabl'), ('.', '.')]

>> Lemmatization: 
 [('Intuitively', 'Intuitively'), (',', ','), ('one', 'one'), ('expect', 'expect'), (',', ','), ('distinct', 'distinct'), ('two', 'two'), ('distributions', 'distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), (',', ','), ('easier', 'easier'), ('design', 'design'), ('discriminator', 'discriminator'), ('able', 'able'), ('choose', 'choose'), ('correct', 'correct'), ('hypothesis', 'hypothesis'), ('high', 'high'), ('probability', 'probability'), ('.', '.')]



============================ Sentence 504 =============================

The connection between the hypothesis testing prob- lem in Fig. 


>> Tokens are: 
 ['The', 'connection', 'hypothesis', 'testing', 'prob-', 'lem', 'Fig', '.']

>> Bigrams are: 
 [('The', 'connection'), ('connection', 'hypothesis'), ('hypothesis', 'testing'), ('testing', 'prob-'), ('prob-', 'lem'), ('lem', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'connection', 'hypothesis'), ('connection', 'hypothesis', 'testing'), ('hypothesis', 'testing', 'prob-'), ('testing', 'prob-', 'lem'), ('prob-', 'lem', 'Fig'), ('lem', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('connection', 'NN'), ('hypothesis', 'NN'), ('testing', 'VBG'), ('prob-', 'JJ'), ('lem', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP The/DT connection/NN hypothesis/NN)
  testing/VBG
  (NP prob-/JJ lem/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['The connection hypothesis', 'prob- lem Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('connection', 'connect'), ('hypothesis', 'hypothesi'), ('testing', 'test'), ('prob-', 'prob-'), ('lem', 'lem'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('connection', 'connect'), ('hypothesis', 'hypothesi'), ('testing', 'test'), ('prob-', 'prob-'), ('lem', 'lem'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('connection', 'connection'), ('hypothesis', 'hypothesis'), ('testing', 'testing'), ('prob-', 'prob-'), ('lem', 'lem'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 505 =============================

15 and the KL divergence becomes evident if one recalls that the LLR ln(p(x)/q(x)) is known to be the best statistic T (x) in the Neyman-Pearson sense [63]. 


>> Tokens are: 
 ['15', 'KL', 'divergence', 'becomes', 'evident', 'one', 'recalls', 'LLR', 'ln', '(', 'p', '(', 'x', ')', '/q', '(', 'x', ')', ')', 'known', 'best', 'statistic', 'T', '(', 'x', ')', 'Neyman-Pearson', 'sense', '[', '63', ']', '.']

>> Bigrams are: 
 [('15', 'KL'), ('KL', 'divergence'), ('divergence', 'becomes'), ('becomes', 'evident'), ('evident', 'one'), ('one', 'recalls'), ('recalls', 'LLR'), ('LLR', 'ln'), ('ln', '('), ('(', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', '/q'), ('/q', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', 'known'), ('known', 'best'), ('best', 'statistic'), ('statistic', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'Neyman-Pearson'), ('Neyman-Pearson', 'sense'), ('sense', '['), ('[', '63'), ('63', ']'), (']', '.')]

>> Trigrams are: 
 [('15', 'KL', 'divergence'), ('KL', 'divergence', 'becomes'), ('divergence', 'becomes', 'evident'), ('becomes', 'evident', 'one'), ('evident', 'one', 'recalls'), ('one', 'recalls', 'LLR'), ('recalls', 'LLR', 'ln'), ('LLR', 'ln', '('), ('ln', '(', 'p'), ('(', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '/q'), (')', '/q', '('), ('/q', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', 'known'), (')', 'known', 'best'), ('known', 'best', 'statistic'), ('best', 'statistic', 'T'), ('statistic', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'Neyman-Pearson'), (')', 'Neyman-Pearson', 'sense'), ('Neyman-Pearson', 'sense', '['), ('sense', '[', '63'), ('[', '63', ']'), ('63', ']', '.')]

>> POS Tags are: 
 [('15', 'CD'), ('KL', 'NNP'), ('divergence', 'NN'), ('becomes', 'VBZ'), ('evident', 'JJ'), ('one', 'CD'), ('recalls', 'VBZ'), ('LLR', 'NNP'), ('ln', 'NN'), ('(', '('), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('/q', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), ('known', 'VBN'), ('best', 'JJS'), ('statistic', 'JJ'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('Neyman-Pearson', 'NNP'), ('sense', 'NN'), ('[', 'VBZ'), ('63', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  15/CD
  (NP KL/NNP divergence/NN)
  becomes/VBZ
  evident/JJ
  one/CD
  recalls/VBZ
  (NP LLR/NNP ln/NN)
  (/(
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP /q/NNP)
  (/(
  (NP x/NNP)
  )/)
  )/)
  known/VBN
  best/JJS
  (NP statistic/JJ T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP Neyman-Pearson/NNP sense/NN)
  [/VBZ
  63/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['KL divergence', 'LLR ln', 'p', 'x', '/q', 'x', 'statistic T', 'x', 'Neyman-Pearson sense', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'LLR')] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), ('KL', 'kl'), ('divergence', 'diverg'), ('becomes', 'becom'), ('evident', 'evid'), ('one', 'one'), ('recalls', 'recal'), ('LLR', 'llr'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('known', 'known'), ('best', 'best'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('Neyman-Pearson', 'neyman-pearson'), ('sense', 'sens'), ('[', '['), ('63', '63'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), ('KL', 'kl'), ('divergence', 'diverg'), ('becomes', 'becom'), ('evident', 'evid'), ('one', 'one'), ('recalls', 'recal'), ('LLR', 'llr'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('known', 'known'), ('best', 'best'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('Neyman-Pearson', 'neyman-pearson'), ('sense', 'sens'), ('[', '['), ('63', '63'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), ('KL', 'KL'), ('divergence', 'divergence'), ('becomes', 'becomes'), ('evident', 'evident'), ('one', 'one'), ('recalls', 'recall'), ('LLR', 'LLR'), ('ln', 'ln'), ('(', '('), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('/q', '/q'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), ('known', 'known'), ('best', 'best'), ('statistic', 'statistic'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('Neyman-Pearson', 'Neyman-Pearson'), ('sense', 'sense'), ('[', '['), ('63', '63'), (']', ']'), ('.', '.')]



============================ Sentence 506 =============================

The KL divergence is hence associated to a particular way of evaluating the performance of the discriminator between the two distributions. 


>> Tokens are: 
 ['The', 'KL', 'divergence', 'hence', 'associated', 'particular', 'way', 'evaluating', 'performance', 'discriminator', 'two', 'distributions', '.']

>> Bigrams are: 
 [('The', 'KL'), ('KL', 'divergence'), ('divergence', 'hence'), ('hence', 'associated'), ('associated', 'particular'), ('particular', 'way'), ('way', 'evaluating'), ('evaluating', 'performance'), ('performance', 'discriminator'), ('discriminator', 'two'), ('two', 'distributions'), ('distributions', '.')]

>> Trigrams are: 
 [('The', 'KL', 'divergence'), ('KL', 'divergence', 'hence'), ('divergence', 'hence', 'associated'), ('hence', 'associated', 'particular'), ('associated', 'particular', 'way'), ('particular', 'way', 'evaluating'), ('way', 'evaluating', 'performance'), ('evaluating', 'performance', 'discriminator'), ('performance', 'discriminator', 'two'), ('discriminator', 'two', 'distributions'), ('two', 'distributions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('KL', 'NNP'), ('divergence', 'NN'), ('hence', 'NN'), ('associated', 'VBN'), ('particular', 'JJ'), ('way', 'NN'), ('evaluating', 'VBG'), ('performance', 'NN'), ('discriminator', 'NN'), ('two', 'CD'), ('distributions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT KL/NNP divergence/NN hence/NN)
  associated/VBN
  (NP particular/JJ way/NN)
  evaluating/VBG
  (NP performance/NN discriminator/NN)
  two/CD
  (NP distributions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The KL divergence hence', 'particular way', 'performance discriminator', 'distributions']

>> Named Entities are: 
 [('ORGANIZATION', 'KL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('KL', 'kl'), ('divergence', 'diverg'), ('hence', 'henc'), ('associated', 'associ'), ('particular', 'particular'), ('way', 'way'), ('evaluating', 'evalu'), ('performance', 'perform'), ('discriminator', 'discrimin'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('KL', 'kl'), ('divergence', 'diverg'), ('hence', 'henc'), ('associated', 'associ'), ('particular', 'particular'), ('way', 'way'), ('evaluating', 'evalu'), ('performance', 'perform'), ('discriminator', 'discrimin'), ('two', 'two'), ('distributions', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('KL', 'KL'), ('divergence', 'divergence'), ('hence', 'hence'), ('associated', 'associated'), ('particular', 'particular'), ('way', 'way'), ('evaluating', 'evaluating'), ('performance', 'performance'), ('discriminator', 'discriminator'), ('two', 'two'), ('distributions', 'distribution'), ('.', '.')]



============================ Sentence 507 =============================

Considering a broader formulation of the problem of designing the discriminator in Fig. 


>> Tokens are: 
 ['Considering', 'broader', 'formulation', 'problem', 'designing', 'discriminator', 'Fig', '.']

>> Bigrams are: 
 [('Considering', 'broader'), ('broader', 'formulation'), ('formulation', 'problem'), ('problem', 'designing'), ('designing', 'discriminator'), ('discriminator', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Considering', 'broader', 'formulation'), ('broader', 'formulation', 'problem'), ('formulation', 'problem', 'designing'), ('problem', 'designing', 'discriminator'), ('designing', 'discriminator', 'Fig'), ('discriminator', 'Fig', '.')]

>> POS Tags are: 
 [('Considering', 'VBG'), ('broader', 'JJR'), ('formulation', 'NN'), ('problem', 'NN'), ('designing', 'VBG'), ('discriminator', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  Considering/VBG
  broader/JJR
  (NP formulation/NN problem/NN)
  designing/VBG
  (NP discriminator/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['formulation problem', 'discriminator Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Considering', 'consid'), ('broader', 'broader'), ('formulation', 'formul'), ('problem', 'problem'), ('designing', 'design'), ('discriminator', 'discrimin'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Considering', 'consid'), ('broader', 'broader'), ('formulation', 'formul'), ('problem', 'problem'), ('designing', 'design'), ('discriminator', 'discrimin'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Considering', 'Considering'), ('broader', 'broader'), ('formulation', 'formulation'), ('problem', 'problem'), ('designing', 'designing'), ('discriminator', 'discriminator'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 508 =============================

15, one can generalize the notion of KL divergence to the class of f -divergences. 


>> Tokens are: 
 ['15', ',', 'one', 'generalize', 'notion', 'KL', 'divergence', 'class', 'f', '-divergences', '.']

>> Bigrams are: 
 [('15', ','), (',', 'one'), ('one', 'generalize'), ('generalize', 'notion'), ('notion', 'KL'), ('KL', 'divergence'), ('divergence', 'class'), ('class', 'f'), ('f', '-divergences'), ('-divergences', '.')]

>> Trigrams are: 
 [('15', ',', 'one'), (',', 'one', 'generalize'), ('one', 'generalize', 'notion'), ('generalize', 'notion', 'KL'), ('notion', 'KL', 'divergence'), ('KL', 'divergence', 'class'), ('divergence', 'class', 'f'), ('class', 'f', '-divergences'), ('f', '-divergences', '.')]

>> POS Tags are: 
 [('15', 'CD'), (',', ','), ('one', 'CD'), ('generalize', 'NN'), ('notion', 'NN'), ('KL', 'NNP'), ('divergence', 'NN'), ('class', 'NN'), ('f', 'NN'), ('-divergences', 'NNS'), ('.', '.')]

 (S
  15/CD
  ,/,
  one/CD
  (NP
    generalize/NN
    notion/NN
    KL/NNP
    divergence/NN
    class/NN
    f/NN
    -divergences/NNS)
  ./.) 


>> Noun Phrases are: 
 ['generalize notion KL divergence class f -divergences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), (',', ','), ('one', 'one'), ('generalize', 'gener'), ('notion', 'notion'), ('KL', 'kl'), ('divergence', 'diverg'), ('class', 'class'), ('f', 'f'), ('-divergences', '-diverg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), (',', ','), ('one', 'one'), ('generalize', 'general'), ('notion', 'notion'), ('KL', 'kl'), ('divergence', 'diverg'), ('class', 'class'), ('f', 'f'), ('-divergences', '-diverg'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), (',', ','), ('one', 'one'), ('generalize', 'generalize'), ('notion', 'notion'), ('KL', 'KL'), ('divergence', 'divergence'), ('class', 'class'), ('f', 'f'), ('-divergences', '-divergences'), ('.', '.')]



============================ Sentence 509 =============================

These are defined as  Df (p||q) = max T (x)  Ex∼p(x)[T (x)]− Ex∼q(x)[g(T (x))], (22)  for some concave increasing function g(·). 


>> Tokens are: 
 ['These', 'defined', 'Df', '(', 'p||q', ')', '=', 'max', 'T', '(', 'x', ')', 'Ex∼p', '(', 'x', ')', '[', 'T', '(', 'x', ')', ']', '−', 'Ex∼q', '(', 'x', ')', '[', 'g', '(', 'T', '(', 'x', ')', ')', ']', ',', '(', '22', ')', 'concave', 'increasing', 'function', 'g', '(', '·', ')', '.']

>> Bigrams are: 
 [('These', 'defined'), ('defined', 'Df'), ('Df', '('), ('(', 'p||q'), ('p||q', ')'), (')', '='), ('=', 'max'), ('max', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'Ex∼p'), ('Ex∼p', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', ']'), (']', '−'), ('−', 'Ex∼q'), ('Ex∼q', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'g'), ('g', '('), ('(', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', ']'), (']', ','), (',', '('), ('(', '22'), ('22', ')'), (')', 'concave'), ('concave', 'increasing'), ('increasing', 'function'), ('function', 'g'), ('g', '('), ('(', '·'), ('·', ')'), (')', '.')]

>> Trigrams are: 
 [('These', 'defined', 'Df'), ('defined', 'Df', '('), ('Df', '(', 'p||q'), ('(', 'p||q', ')'), ('p||q', ')', '='), (')', '=', 'max'), ('=', 'max', 'T'), ('max', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'Ex∼p'), (')', 'Ex∼p', '('), ('Ex∼p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'T'), ('[', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', ']'), (')', ']', '−'), (']', '−', 'Ex∼q'), ('−', 'Ex∼q', '('), ('Ex∼q', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'g'), ('[', 'g', '('), ('g', '(', 'T'), ('(', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', ']'), (')', ']', ','), (']', ',', '('), (',', '(', '22'), ('(', '22', ')'), ('22', ')', 'concave'), (')', 'concave', 'increasing'), ('concave', 'increasing', 'function'), ('increasing', 'function', 'g'), ('function', 'g', '('), ('g', '(', '·'), ('(', '·', ')'), ('·', ')', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('defined', 'VBN'), ('Df', 'NNP'), ('(', '('), ('p||q', 'NN'), (')', ')'), ('=', 'VBZ'), ('max', 'JJ'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('Ex∼p', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (']', 'VBP'), ('−', 'JJ'), ('Ex∼q', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('g', 'NN'), ('(', '('), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), (']', 'NN'), (',', ','), ('(', '('), ('22', 'CD'), (')', ')'), ('concave', 'VBP'), ('increasing', 'VBG'), ('function', 'NN'), ('g', 'NN'), ('(', '('), ('·', 'NNP'), (')', ')'), ('.', '.')]

 (S
  These/DT
  defined/VBN
  (NP Df/NNP)
  (/(
  (NP p||q/NN)
  )/)
  =/VBZ
  (NP max/JJ T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP Ex∼p/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP T/NNP)
  (/(
  (NP x/NNP)
  )/)
  ]/VBP
  (NP −/JJ Ex∼q/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP g/NN)
  (/(
  (NP T/NNP)
  (/(
  (NP x/NNP)
  )/)
  )/)
  (NP ]/NN)
  ,/,
  (/(
  22/CD
  )/)
  concave/VBP
  increasing/VBG
  (NP function/NN g/NN)
  (/(
  (NP ·/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Df', 'p||q', 'max T', 'x', 'Ex∼p', 'x', 'T', 'x', '− Ex∼q', 'x', 'g', 'T', 'x', ']', 'function g', '·']

>> Named Entities are: 
 [('GPE', 'Df')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('defined', 'defin'), ('Df', 'df'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('=', '='), ('max', 'max'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('Ex∼p', 'ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('22', '22'), (')', ')'), ('concave', 'concav'), ('increasing', 'increas'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('defined', 'defin'), ('Df', 'df'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('=', '='), ('max', 'max'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('Ex∼p', 'ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('22', '22'), (')', ')'), ('concave', 'concav'), ('increasing', 'increas'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('defined', 'defined'), ('Df', 'Df'), ('(', '('), ('p||q', 'p||q'), (')', ')'), ('=', '='), ('max', 'max'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('Ex∼p', 'Ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'Ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('(', '('), ('22', '22'), (')', ')'), ('concave', 'concave'), ('increasing', 'increasing'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]



============================ Sentence 510 =============================

The expres- sion above can be interpreted as measuring the perfor- mance of the best discriminator T (x) when the design criterion is given by the right-hand side of (22), i.e.-, Ex∼p(x)[T (x)] − Ex∼q(x)[g(T (x))], for a given function g(·). 


>> Tokens are: 
 ['The', 'expres-', 'sion', 'interpreted', 'measuring', 'perfor-', 'mance', 'best', 'discriminator', 'T', '(', 'x', ')', 'design', 'criterion', 'given', 'right-hand', 'side', '(', '22', ')', ',', 'i.e.-', ',', 'Ex∼p', '(', 'x', ')', '[', 'T', '(', 'x', ')', ']', '−', 'Ex∼q', '(', 'x', ')', '[', 'g', '(', 'T', '(', 'x', ')', ')', ']', ',', 'given', 'function', 'g', '(', '·', ')', '.']

>> Bigrams are: 
 [('The', 'expres-'), ('expres-', 'sion'), ('sion', 'interpreted'), ('interpreted', 'measuring'), ('measuring', 'perfor-'), ('perfor-', 'mance'), ('mance', 'best'), ('best', 'discriminator'), ('discriminator', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'design'), ('design', 'criterion'), ('criterion', 'given'), ('given', 'right-hand'), ('right-hand', 'side'), ('side', '('), ('(', '22'), ('22', ')'), (')', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'Ex∼p'), ('Ex∼p', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', ']'), (']', '−'), ('−', 'Ex∼q'), ('Ex∼q', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'g'), ('g', '('), ('(', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', ']'), (']', ','), (',', 'given'), ('given', 'function'), ('function', 'g'), ('g', '('), ('(', '·'), ('·', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'expres-', 'sion'), ('expres-', 'sion', 'interpreted'), ('sion', 'interpreted', 'measuring'), ('interpreted', 'measuring', 'perfor-'), ('measuring', 'perfor-', 'mance'), ('perfor-', 'mance', 'best'), ('mance', 'best', 'discriminator'), ('best', 'discriminator', 'T'), ('discriminator', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'design'), (')', 'design', 'criterion'), ('design', 'criterion', 'given'), ('criterion', 'given', 'right-hand'), ('given', 'right-hand', 'side'), ('right-hand', 'side', '('), ('side', '(', '22'), ('(', '22', ')'), ('22', ')', ','), (')', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'Ex∼p'), (',', 'Ex∼p', '('), ('Ex∼p', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'T'), ('[', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', ']'), (')', ']', '−'), (']', '−', 'Ex∼q'), ('−', 'Ex∼q', '('), ('Ex∼q', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'g'), ('[', 'g', '('), ('g', '(', 'T'), ('(', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', ']'), (')', ']', ','), (']', ',', 'given'), (',', 'given', 'function'), ('given', 'function', 'g'), ('function', 'g', '('), ('g', '(', '·'), ('(', '·', ')'), ('·', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('expres-', 'JJ'), ('sion', 'NN'), ('interpreted', 'VBD'), ('measuring', 'VBG'), ('perfor-', 'JJ'), ('mance', 'NN'), ('best', 'JJS'), ('discriminator', 'NN'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('design', 'NN'), ('criterion', 'NN'), ('given', 'VBN'), ('right-hand', 'JJ'), ('side', 'NN'), ('(', '('), ('22', 'CD'), (')', ')'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('Ex∼p', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (']', 'VBP'), ('−', 'JJ'), ('Ex∼q', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('g', 'NN'), ('(', '('), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), (']', 'NN'), (',', ','), ('given', 'VBN'), ('function', 'NN'), ('g', 'NN'), ('(', '('), ('·', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT expres-/JJ sion/NN)
  interpreted/VBD
  measuring/VBG
  (NP perfor-/JJ mance/NN)
  best/JJS
  (NP discriminator/NN T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP design/NN criterion/NN)
  given/VBN
  (NP right-hand/JJ side/NN)
  (/(
  22/CD
  )/)
  ,/,
  i.e.-/JJ
  ,/,
  (NP Ex∼p/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP T/NNP)
  (/(
  (NP x/NNP)
  )/)
  ]/VBP
  (NP −/JJ Ex∼q/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP g/NN)
  (/(
  (NP T/NNP)
  (/(
  (NP x/NNP)
  )/)
  )/)
  (NP ]/NN)
  ,/,
  given/VBN
  (NP function/NN g/NN)
  (/(
  (NP ·/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The expres- sion', 'perfor- mance', 'discriminator T', 'x', 'design criterion', 'right-hand side', 'Ex∼p', 'x', 'T', 'x', '− Ex∼q', 'x', 'g', 'T', 'x', ']', 'function g', '·']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('expres-', 'expres-'), ('sion', 'sion'), ('interpreted', 'interpret'), ('measuring', 'measur'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('best', 'best'), ('discriminator', 'discrimin'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('design', 'design'), ('criterion', 'criterion'), ('given', 'given'), ('right-hand', 'right-hand'), ('side', 'side'), ('(', '('), ('22', '22'), (')', ')'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('Ex∼p', 'ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('given', 'given'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('expres-', 'expres-'), ('sion', 'sion'), ('interpreted', 'interpret'), ('measuring', 'measur'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('best', 'best'), ('discriminator', 'discrimin'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('design', 'design'), ('criterion', 'criterion'), ('given', 'given'), ('right-hand', 'right-hand'), ('side', 'side'), ('(', '('), ('22', '22'), (')', ')'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('Ex∼p', 'ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('given', 'given'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('expres-', 'expres-'), ('sion', 'sion'), ('interpreted', 'interpreted'), ('measuring', 'measuring'), ('perfor-', 'perfor-'), ('mance', 'mance'), ('best', 'best'), ('discriminator', 'discriminator'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('design', 'design'), ('criterion', 'criterion'), ('given', 'given'), ('right-hand', 'right-hand'), ('side', 'side'), ('(', '('), ('22', '22'), (')', ')'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('Ex∼p', 'Ex∼p'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼q', 'Ex∼q'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), (',', ','), ('given', 'given'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('.', '.')]



============================ Sentence 511 =============================

Note that this criterion is indeed larger for a discriminator that is able to output a large value of the statistic T (x) under p(x) and a small value under q(x). 


>> Tokens are: 
 ['Note', 'criterion', 'indeed', 'larger', 'discriminator', 'able', 'output', 'large', 'value', 'statistic', 'T', '(', 'x', ')', 'p', '(', 'x', ')', 'small', 'value', 'q', '(', 'x', ')', '.']

>> Bigrams are: 
 [('Note', 'criterion'), ('criterion', 'indeed'), ('indeed', 'larger'), ('larger', 'discriminator'), ('discriminator', 'able'), ('able', 'output'), ('output', 'large'), ('large', 'value'), ('value', 'statistic'), ('statistic', 'T'), ('T', '('), ('(', 'x'), ('x', ')'), (')', 'p'), ('p', '('), ('(', 'x'), ('x', ')'), (')', 'small'), ('small', 'value'), ('value', 'q'), ('q', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('Note', 'criterion', 'indeed'), ('criterion', 'indeed', 'larger'), ('indeed', 'larger', 'discriminator'), ('larger', 'discriminator', 'able'), ('discriminator', 'able', 'output'), ('able', 'output', 'large'), ('output', 'large', 'value'), ('large', 'value', 'statistic'), ('value', 'statistic', 'T'), ('statistic', 'T', '('), ('T', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'p'), (')', 'p', '('), ('p', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'small'), (')', 'small', 'value'), ('small', 'value', 'q'), ('value', 'q', '('), ('q', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('Note', 'NNP'), ('criterion', 'NN'), ('indeed', 'RB'), ('larger', 'JJR'), ('discriminator', 'NN'), ('able', 'JJ'), ('output', 'NN'), ('large', 'JJ'), ('value', 'NN'), ('statistic', 'JJ'), ('T', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('small', 'JJ'), ('value', 'NN'), ('q', 'NN'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Note/NNP criterion/NN)
  indeed/RB
  larger/JJR
  (NP discriminator/NN)
  (NP able/JJ output/NN)
  (NP large/JJ value/NN)
  (NP statistic/JJ T/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP p/NN)
  (/(
  (NP x/NNP)
  )/)
  (NP small/JJ value/NN q/NN)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Note criterion', 'discriminator', 'able output', 'large value', 'statistic T', 'x', 'p', 'x', 'small value q', 'x']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('criterion', 'criterion'), ('indeed', 'inde'), ('larger', 'larger'), ('discriminator', 'discrimin'), ('able', 'abl'), ('output', 'output'), ('large', 'larg'), ('value', 'valu'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('small', 'small'), ('value', 'valu'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('criterion', 'criterion'), ('indeed', 'inde'), ('larger', 'larger'), ('discriminator', 'discrimin'), ('able', 'abl'), ('output', 'output'), ('large', 'larg'), ('value', 'valu'), ('statistic', 'statist'), ('T', 't'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('small', 'small'), ('value', 'valu'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), ('criterion', 'criterion'), ('indeed', 'indeed'), ('larger', 'larger'), ('discriminator', 'discriminator'), ('able', 'able'), ('output', 'output'), ('large', 'large'), ('value', 'value'), ('statistic', 'statistic'), ('T', 'T'), ('(', '('), ('x', 'x'), (')', ')'), ('p', 'p'), ('(', '('), ('x', 'x'), (')', ')'), ('small', 'small'), ('value', 'value'), ('q', 'q'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 512 =============================

The KL divergence corresponds to a specific choice of such function (see [19] for details). 


>> Tokens are: 
 ['The', 'KL', 'divergence', 'corresponds', 'specific', 'choice', 'function', '(', 'see', '[', '19', ']', 'details', ')', '.']

>> Bigrams are: 
 [('The', 'KL'), ('KL', 'divergence'), ('divergence', 'corresponds'), ('corresponds', 'specific'), ('specific', 'choice'), ('choice', 'function'), ('function', '('), ('(', 'see'), ('see', '['), ('[', '19'), ('19', ']'), (']', 'details'), ('details', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'KL', 'divergence'), ('KL', 'divergence', 'corresponds'), ('divergence', 'corresponds', 'specific'), ('corresponds', 'specific', 'choice'), ('specific', 'choice', 'function'), ('choice', 'function', '('), ('function', '(', 'see'), ('(', 'see', '['), ('see', '[', '19'), ('[', '19', ']'), ('19', ']', 'details'), (']', 'details', ')'), ('details', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('KL', 'NNP'), ('divergence', 'NN'), ('corresponds', 'NNS'), ('specific', 'JJ'), ('choice', 'NN'), ('function', 'NN'), ('(', '('), ('see', 'VB'), ('[', 'RB'), ('19', 'CD'), (']', 'NNP'), ('details', 'NNS'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT KL/NNP divergence/NN corresponds/NNS)
  (NP specific/JJ choice/NN function/NN)
  (/(
  see/VB
  [/RB
  19/CD
  (NP ]/NNP details/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The KL divergence corresponds', 'specific choice function', '] details']

>> Named Entities are: 
 [('ORGANIZATION', 'KL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('KL', 'kl'), ('divergence', 'diverg'), ('corresponds', 'correspond'), ('specific', 'specif'), ('choice', 'choic'), ('function', 'function'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('KL', 'kl'), ('divergence', 'diverg'), ('corresponds', 'correspond'), ('specific', 'specif'), ('choice', 'choic'), ('function', 'function'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('KL', 'KL'), ('divergence', 'divergence'), ('corresponds', 'corresponds'), ('specific', 'specific'), ('choice', 'choice'), ('function', 'function'), ('(', '('), ('see', 'see'), ('[', '['), ('19', '19'), (']', ']'), ('details', 'detail'), (')', ')'), ('.', '.')]



============================ Sentence 513 =============================

In order to move beyond ML, one can then consider fitting the model distribution to the data histogram by using a divergence measure that is tailored to the data and that captures the features of the empirical distribution that are most relevant for a given application. 


>> Tokens are: 
 ['In', 'order', 'move', 'beyond', 'ML', ',', 'one', 'consider', 'fitting', 'model', 'distribution', 'data', 'histogram', 'using', 'divergence', 'measure', 'tailored', 'data', 'captures', 'features', 'empirical', 'distribution', 'relevant', 'given', 'application', '.']

>> Bigrams are: 
 [('In', 'order'), ('order', 'move'), ('move', 'beyond'), ('beyond', 'ML'), ('ML', ','), (',', 'one'), ('one', 'consider'), ('consider', 'fitting'), ('fitting', 'model'), ('model', 'distribution'), ('distribution', 'data'), ('data', 'histogram'), ('histogram', 'using'), ('using', 'divergence'), ('divergence', 'measure'), ('measure', 'tailored'), ('tailored', 'data'), ('data', 'captures'), ('captures', 'features'), ('features', 'empirical'), ('empirical', 'distribution'), ('distribution', 'relevant'), ('relevant', 'given'), ('given', 'application'), ('application', '.')]

>> Trigrams are: 
 [('In', 'order', 'move'), ('order', 'move', 'beyond'), ('move', 'beyond', 'ML'), ('beyond', 'ML', ','), ('ML', ',', 'one'), (',', 'one', 'consider'), ('one', 'consider', 'fitting'), ('consider', 'fitting', 'model'), ('fitting', 'model', 'distribution'), ('model', 'distribution', 'data'), ('distribution', 'data', 'histogram'), ('data', 'histogram', 'using'), ('histogram', 'using', 'divergence'), ('using', 'divergence', 'measure'), ('divergence', 'measure', 'tailored'), ('measure', 'tailored', 'data'), ('tailored', 'data', 'captures'), ('data', 'captures', 'features'), ('captures', 'features', 'empirical'), ('features', 'empirical', 'distribution'), ('empirical', 'distribution', 'relevant'), ('distribution', 'relevant', 'given'), ('relevant', 'given', 'application'), ('given', 'application', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('move', 'NN'), ('beyond', 'IN'), ('ML', 'NNP'), (',', ','), ('one', 'CD'), ('consider', 'NN'), ('fitting', 'VBG'), ('model', 'NN'), ('distribution', 'NN'), ('data', 'NNS'), ('histogram', 'NN'), ('using', 'VBG'), ('divergence', 'NN'), ('measure', 'NN'), ('tailored', 'VBN'), ('data', 'NN'), ('captures', 'NNS'), ('features', 'VBZ'), ('empirical', 'JJ'), ('distribution', 'NN'), ('relevant', 'VB'), ('given', 'VBN'), ('application', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP order/NN move/NN)
  beyond/IN
  (NP ML/NNP)
  ,/,
  one/CD
  (NP consider/NN)
  fitting/VBG
  (NP model/NN distribution/NN data/NNS histogram/NN)
  using/VBG
  (NP divergence/NN measure/NN)
  tailored/VBN
  (NP data/NN captures/NNS)
  features/VBZ
  (NP empirical/JJ distribution/NN)
  relevant/VB
  given/VBN
  (NP application/NN)
  ./.) 


>> Noun Phrases are: 
 ['order move', 'ML', 'consider', 'model distribution data histogram', 'divergence measure', 'data captures', 'empirical distribution', 'application']

>> Named Entities are: 
 [('ORGANIZATION', 'ML')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ml'), (',', ','), ('one', 'one'), ('consider', 'consid'), ('fitting', 'fit'), ('model', 'model'), ('distribution', 'distribut'), ('data', 'data'), ('histogram', 'histogram'), ('using', 'use'), ('divergence', 'diverg'), ('measure', 'measur'), ('tailored', 'tailor'), ('data', 'data'), ('captures', 'captur'), ('features', 'featur'), ('empirical', 'empir'), ('distribution', 'distribut'), ('relevant', 'relev'), ('given', 'given'), ('application', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ml'), (',', ','), ('one', 'one'), ('consider', 'consid'), ('fitting', 'fit'), ('model', 'model'), ('distribution', 'distribut'), ('data', 'data'), ('histogram', 'histogram'), ('using', 'use'), ('divergence', 'diverg'), ('measure', 'measur'), ('tailored', 'tailor'), ('data', 'data'), ('captures', 'captur'), ('features', 'featur'), ('empirical', 'empir'), ('distribution', 'distribut'), ('relevant', 'relev'), ('given', 'given'), ('application', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('move', 'move'), ('beyond', 'beyond'), ('ML', 'ML'), (',', ','), ('one', 'one'), ('consider', 'consider'), ('fitting', 'fitting'), ('model', 'model'), ('distribution', 'distribution'), ('data', 'data'), ('histogram', 'histogram'), ('using', 'using'), ('divergence', 'divergence'), ('measure', 'measure'), ('tailored', 'tailored'), ('data', 'data'), ('captures', 'capture'), ('features', 'feature'), ('empirical', 'empirical'), ('distribution', 'distribution'), ('relevant', 'relevant'), ('given', 'given'), ('application', 'application'), ('.', '.')]



============================ Sentence 514 =============================

Such a divergence measure can be obtained by choosing a suitable function g(·) in (22) and by optimizing (22) over a parameterized (differentiable) discriminator function Tϕ(x). 


>> Tokens are: 
 ['Such', 'divergence', 'measure', 'obtained', 'choosing', 'suitable', 'function', 'g', '(', '·', ')', '(', '22', ')', 'optimizing', '(', '22', ')', 'parameterized', '(', 'differentiable', ')', 'discriminator', 'function', 'Tϕ', '(', 'x', ')', '.']

>> Bigrams are: 
 [('Such', 'divergence'), ('divergence', 'measure'), ('measure', 'obtained'), ('obtained', 'choosing'), ('choosing', 'suitable'), ('suitable', 'function'), ('function', 'g'), ('g', '('), ('(', '·'), ('·', ')'), (')', '('), ('(', '22'), ('22', ')'), (')', 'optimizing'), ('optimizing', '('), ('(', '22'), ('22', ')'), (')', 'parameterized'), ('parameterized', '('), ('(', 'differentiable'), ('differentiable', ')'), (')', 'discriminator'), ('discriminator', 'function'), ('function', 'Tϕ'), ('Tϕ', '('), ('(', 'x'), ('x', ')'), (')', '.')]

>> Trigrams are: 
 [('Such', 'divergence', 'measure'), ('divergence', 'measure', 'obtained'), ('measure', 'obtained', 'choosing'), ('obtained', 'choosing', 'suitable'), ('choosing', 'suitable', 'function'), ('suitable', 'function', 'g'), ('function', 'g', '('), ('g', '(', '·'), ('(', '·', ')'), ('·', ')', '('), (')', '(', '22'), ('(', '22', ')'), ('22', ')', 'optimizing'), (')', 'optimizing', '('), ('optimizing', '(', '22'), ('(', '22', ')'), ('22', ')', 'parameterized'), (')', 'parameterized', '('), ('parameterized', '(', 'differentiable'), ('(', 'differentiable', ')'), ('differentiable', ')', 'discriminator'), (')', 'discriminator', 'function'), ('discriminator', 'function', 'Tϕ'), ('function', 'Tϕ', '('), ('Tϕ', '(', 'x'), ('(', 'x', ')'), ('x', ')', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('divergence', 'NN'), ('measure', 'NN'), ('obtained', 'VBN'), ('choosing', 'VBG'), ('suitable', 'JJ'), ('function', 'NN'), ('g', 'NN'), ('(', '('), ('·', 'NN'), (')', ')'), ('(', '('), ('22', 'CD'), (')', ')'), ('optimizing', 'NN'), ('(', '('), ('22', 'CD'), (')', ')'), ('parameterized', 'VBN'), ('(', '('), ('differentiable', 'JJ'), (')', ')'), ('discriminator', 'NN'), ('function', 'NN'), ('Tϕ', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Such/JJ divergence/NN measure/NN)
  obtained/VBN
  choosing/VBG
  (NP suitable/JJ function/NN g/NN)
  (/(
  (NP ·/NN)
  )/)
  (/(
  22/CD
  )/)
  (NP optimizing/NN)
  (/(
  22/CD
  )/)
  parameterized/VBN
  (/(
  differentiable/JJ
  )/)
  (NP discriminator/NN function/NN Tϕ/NNP)
  (/(
  (NP x/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Such divergence measure', 'suitable function g', '·', 'optimizing', 'discriminator function Tϕ', 'x']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('divergence', 'diverg'), ('measure', 'measur'), ('obtained', 'obtain'), ('choosing', 'choos'), ('suitable', 'suitabl'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('(', '('), ('22', '22'), (')', ')'), ('optimizing', 'optim'), ('(', '('), ('22', '22'), (')', ')'), ('parameterized', 'parameter'), ('(', '('), ('differentiable', 'differenti'), (')', ')'), ('discriminator', 'discrimin'), ('function', 'function'), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('divergence', 'diverg'), ('measure', 'measur'), ('obtained', 'obtain'), ('choosing', 'choos'), ('suitable', 'suitabl'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('(', '('), ('22', '22'), (')', ')'), ('optimizing', 'optim'), ('(', '('), ('22', '22'), (')', ')'), ('parameterized', 'parameter'), ('(', '('), ('differentiable', 'differenti'), (')', ')'), ('discriminator', 'discrimin'), ('function', 'function'), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('divergence', 'divergence'), ('measure', 'measure'), ('obtained', 'obtained'), ('choosing', 'choosing'), ('suitable', 'suitable'), ('function', 'function'), ('g', 'g'), ('(', '('), ('·', '·'), (')', ')'), ('(', '('), ('22', '22'), (')', ')'), ('optimizing', 'optimizing'), ('(', '('), ('22', '22'), (')', ')'), ('parameterized', 'parameterized'), ('(', '('), ('differentiable', 'differentiable'), (')', ')'), ('discriminator', 'discriminator'), ('function', 'function'), ('Tϕ', 'Tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('.', '.')]



============================ Sentence 515 =============================

Integrating the evaluation of the divergence with the problem of learning the model parameters yields the  16    min-max problem  min θ  max ϕ  Ex∼pD(x)[Tϕ(x)]− Ex∼p(x|θ)[g(Tϕ(x))]. 


>> Tokens are: 
 ['Integrating', 'evaluation', 'divergence', 'problem', 'learning', 'model', 'parameters', 'yields', '16', 'min-max', 'problem', 'min', 'θ', 'max', 'ϕ', 'Ex∼pD', '(', 'x', ')', '[', 'Tϕ', '(', 'x', ')', ']', '−', 'Ex∼p', '(', 'x|θ', ')', '[', 'g', '(', 'Tϕ', '(', 'x', ')', ')', ']', '.']

>> Bigrams are: 
 [('Integrating', 'evaluation'), ('evaluation', 'divergence'), ('divergence', 'problem'), ('problem', 'learning'), ('learning', 'model'), ('model', 'parameters'), ('parameters', 'yields'), ('yields', '16'), ('16', 'min-max'), ('min-max', 'problem'), ('problem', 'min'), ('min', 'θ'), ('θ', 'max'), ('max', 'ϕ'), ('ϕ', 'Ex∼pD'), ('Ex∼pD', '('), ('(', 'x'), ('x', ')'), (')', '['), ('[', 'Tϕ'), ('Tϕ', '('), ('(', 'x'), ('x', ')'), (')', ']'), (']', '−'), ('−', 'Ex∼p'), ('Ex∼p', '('), ('(', 'x|θ'), ('x|θ', ')'), (')', '['), ('[', 'g'), ('g', '('), ('(', 'Tϕ'), ('Tϕ', '('), ('(', 'x'), ('x', ')'), (')', ')'), (')', ']'), (']', '.')]

>> Trigrams are: 
 [('Integrating', 'evaluation', 'divergence'), ('evaluation', 'divergence', 'problem'), ('divergence', 'problem', 'learning'), ('problem', 'learning', 'model'), ('learning', 'model', 'parameters'), ('model', 'parameters', 'yields'), ('parameters', 'yields', '16'), ('yields', '16', 'min-max'), ('16', 'min-max', 'problem'), ('min-max', 'problem', 'min'), ('problem', 'min', 'θ'), ('min', 'θ', 'max'), ('θ', 'max', 'ϕ'), ('max', 'ϕ', 'Ex∼pD'), ('ϕ', 'Ex∼pD', '('), ('Ex∼pD', '(', 'x'), ('(', 'x', ')'), ('x', ')', '['), (')', '[', 'Tϕ'), ('[', 'Tϕ', '('), ('Tϕ', '(', 'x'), ('(', 'x', ')'), ('x', ')', ']'), (')', ']', '−'), (']', '−', 'Ex∼p'), ('−', 'Ex∼p', '('), ('Ex∼p', '(', 'x|θ'), ('(', 'x|θ', ')'), ('x|θ', ')', '['), (')', '[', 'g'), ('[', 'g', '('), ('g', '(', 'Tϕ'), ('(', 'Tϕ', '('), ('Tϕ', '(', 'x'), ('(', 'x', ')'), ('x', ')', ')'), (')', ')', ']'), (')', ']', '.')]

>> POS Tags are: 
 [('Integrating', 'VBG'), ('evaluation', 'NN'), ('divergence', 'NN'), ('problem', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('parameters', 'NNS'), ('yields', 'NNS'), ('16', 'CD'), ('min-max', 'JJ'), ('problem', 'NN'), ('min', 'NN'), ('θ', 'NNP'), ('max', 'NN'), ('ϕ', 'NNP'), ('Ex∼pD', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('[', 'VBP'), ('Tϕ', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (']', 'VBP'), ('−', 'JJ'), ('Ex∼p', 'NNP'), ('(', '('), ('x|θ', 'NNP'), (')', ')'), ('[', 'VBP'), ('g', 'NN'), ('(', '('), ('Tϕ', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), (')', ')'), (']', 'NN'), ('.', '.')]

 (S
  Integrating/VBG
  (NP evaluation/NN divergence/NN problem/NN)
  learning/VBG
  (NP model/NN parameters/NNS yields/NNS)
  16/CD
  (NP min-max/JJ problem/NN min/NN θ/NNP max/NN ϕ/NNP Ex∼pD/NNP)
  (/(
  (NP x/NNP)
  )/)
  [/VBP
  (NP Tϕ/NNP)
  (/(
  (NP x/NNP)
  )/)
  ]/VBP
  (NP −/JJ Ex∼p/NNP)
  (/(
  (NP x|θ/NNP)
  )/)
  [/VBP
  (NP g/NN)
  (/(
  (NP Tϕ/NNP)
  (/(
  (NP x/NNP)
  )/)
  )/)
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['evaluation divergence problem', 'model parameters yields', 'min-max problem min θ max ϕ Ex∼pD', 'x', 'Tϕ', 'x', '− Ex∼p', 'x|θ', 'g', 'Tϕ', 'x', ']']

>> Named Entities are: 
 [('GPE', 'Tϕ')] 

>> Stemming using Porter Stemmer: 
 [('Integrating', 'integr'), ('evaluation', 'evalu'), ('divergence', 'diverg'), ('problem', 'problem'), ('learning', 'learn'), ('model', 'model'), ('parameters', 'paramet'), ('yields', 'yield'), ('16', '16'), ('min-max', 'min-max'), ('problem', 'problem'), ('min', 'min'), ('θ', 'θ'), ('max', 'max'), ('ϕ', 'ϕ'), ('Ex∼pD', 'ex∼pd'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼p', 'ex∼p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Integrating', 'integr'), ('evaluation', 'evalu'), ('divergence', 'diverg'), ('problem', 'problem'), ('learning', 'learn'), ('model', 'model'), ('parameters', 'paramet'), ('yields', 'yield'), ('16', '16'), ('min-max', 'min-max'), ('problem', 'problem'), ('min', 'min'), ('θ', 'θ'), ('max', 'max'), ('ϕ', 'ϕ'), ('Ex∼pD', 'ex∼pd'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼p', 'ex∼p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Integrating', 'Integrating'), ('evaluation', 'evaluation'), ('divergence', 'divergence'), ('problem', 'problem'), ('learning', 'learning'), ('model', 'model'), ('parameters', 'parameter'), ('yields', 'yield'), ('16', '16'), ('min-max', 'min-max'), ('problem', 'problem'), ('min', 'min'), ('θ', 'θ'), ('max', 'max'), ('ϕ', 'ϕ'), ('Ex∼pD', 'Ex∼pD'), ('(', '('), ('x', 'x'), (')', ')'), ('[', '['), ('Tϕ', 'Tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (']', ']'), ('−', '−'), ('Ex∼p', 'Ex∼p'), ('(', '('), ('x|θ', 'x|θ'), (')', ')'), ('[', '['), ('g', 'g'), ('(', '('), ('Tϕ', 'Tϕ'), ('(', '('), ('x', 'x'), (')', ')'), (')', ')'), (']', ']'), ('.', '.')]



============================ Sentence 516 =============================

(23)  This can be famously interpreted as a game between the learner, which optimizes the model parameters θ, and the discriminator, which tries to find the best function Tϕ(x) to distinguish between data and generated samples. 


>> Tokens are: 
 ['(', '23', ')', 'This', 'famously', 'interpreted', 'game', 'learner', ',', 'optimizes', 'model', 'parameters', 'θ', ',', 'discriminator', ',', 'tries', 'find', 'best', 'function', 'Tϕ', '(', 'x', ')', 'distinguish', 'data', 'generated', 'samples', '.']

>> Bigrams are: 
 [('(', '23'), ('23', ')'), (')', 'This'), ('This', 'famously'), ('famously', 'interpreted'), ('interpreted', 'game'), ('game', 'learner'), ('learner', ','), (',', 'optimizes'), ('optimizes', 'model'), ('model', 'parameters'), ('parameters', 'θ'), ('θ', ','), (',', 'discriminator'), ('discriminator', ','), (',', 'tries'), ('tries', 'find'), ('find', 'best'), ('best', 'function'), ('function', 'Tϕ'), ('Tϕ', '('), ('(', 'x'), ('x', ')'), (')', 'distinguish'), ('distinguish', 'data'), ('data', 'generated'), ('generated', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('(', '23', ')'), ('23', ')', 'This'), (')', 'This', 'famously'), ('This', 'famously', 'interpreted'), ('famously', 'interpreted', 'game'), ('interpreted', 'game', 'learner'), ('game', 'learner', ','), ('learner', ',', 'optimizes'), (',', 'optimizes', 'model'), ('optimizes', 'model', 'parameters'), ('model', 'parameters', 'θ'), ('parameters', 'θ', ','), ('θ', ',', 'discriminator'), (',', 'discriminator', ','), ('discriminator', ',', 'tries'), (',', 'tries', 'find'), ('tries', 'find', 'best'), ('find', 'best', 'function'), ('best', 'function', 'Tϕ'), ('function', 'Tϕ', '('), ('Tϕ', '(', 'x'), ('(', 'x', ')'), ('x', ')', 'distinguish'), (')', 'distinguish', 'data'), ('distinguish', 'data', 'generated'), ('data', 'generated', 'samples'), ('generated', 'samples', '.')]

>> POS Tags are: 
 [('(', '('), ('23', 'CD'), (')', ')'), ('This', 'DT'), ('famously', 'RB'), ('interpreted', 'JJ'), ('game', 'NN'), ('learner', 'NN'), (',', ','), ('optimizes', 'VBZ'), ('model', 'NN'), ('parameters', 'NNS'), ('θ', 'VBP'), (',', ','), ('discriminator', 'NN'), (',', ','), ('tries', 'VBZ'), ('find', 'VBP'), ('best', 'JJS'), ('function', 'NN'), ('Tϕ', 'NNP'), ('(', '('), ('x', 'NNP'), (')', ')'), ('distinguish', 'JJ'), ('data', 'NNS'), ('generated', 'VBD'), ('samples', 'NNS'), ('.', '.')]

 (S
  (/(
  23/CD
  )/)
  This/DT
  famously/RB
  (NP interpreted/JJ game/NN learner/NN)
  ,/,
  optimizes/VBZ
  (NP model/NN parameters/NNS)
  θ/VBP
  ,/,
  (NP discriminator/NN)
  ,/,
  tries/VBZ
  find/VBP
  best/JJS
  (NP function/NN Tϕ/NNP)
  (/(
  (NP x/NNP)
  )/)
  (NP distinguish/JJ data/NNS)
  generated/VBD
  (NP samples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['interpreted game learner', 'model parameters', 'discriminator', 'function Tϕ', 'x', 'distinguish data', 'samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('23', '23'), (')', ')'), ('This', 'thi'), ('famously', 'famous'), ('interpreted', 'interpret'), ('game', 'game'), ('learner', 'learner'), (',', ','), ('optimizes', 'optim'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('discriminator', 'discrimin'), (',', ','), ('tries', 'tri'), ('find', 'find'), ('best', 'best'), ('function', 'function'), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('distinguish', 'distinguish'), ('data', 'data'), ('generated', 'gener'), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('23', '23'), (')', ')'), ('This', 'this'), ('famously', 'famous'), ('interpreted', 'interpret'), ('game', 'game'), ('learner', 'learner'), (',', ','), ('optimizes', 'optim'), ('model', 'model'), ('parameters', 'paramet'), ('θ', 'θ'), (',', ','), ('discriminator', 'discrimin'), (',', ','), ('tries', 'tri'), ('find', 'find'), ('best', 'best'), ('function', 'function'), ('Tϕ', 'tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('distinguish', 'distinguish'), ('data', 'data'), ('generated', 'generat'), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('23', '23'), (')', ')'), ('This', 'This'), ('famously', 'famously'), ('interpreted', 'interpreted'), ('game', 'game'), ('learner', 'learner'), (',', ','), ('optimizes', 'optimizes'), ('model', 'model'), ('parameters', 'parameter'), ('θ', 'θ'), (',', ','), ('discriminator', 'discriminator'), (',', ','), ('tries', 'try'), ('find', 'find'), ('best', 'best'), ('function', 'function'), ('Tϕ', 'Tϕ'), ('(', '('), ('x', 'x'), (')', ')'), ('distinguish', 'distinguish'), ('data', 'data'), ('generated', 'generated'), ('samples', 'sample'), ('.', '.')]



============================ Sentence 517 =============================

The resulting method, known as GAN, has recently led to impressive improvements of ML for sample generation [64]. 


>> Tokens are: 
 ['The', 'resulting', 'method', ',', 'known', 'GAN', ',', 'recently', 'led', 'impressive', 'improvements', 'ML', 'sample', 'generation', '[', '64', ']', '.']

>> Bigrams are: 
 [('The', 'resulting'), ('resulting', 'method'), ('method', ','), (',', 'known'), ('known', 'GAN'), ('GAN', ','), (',', 'recently'), ('recently', 'led'), ('led', 'impressive'), ('impressive', 'improvements'), ('improvements', 'ML'), ('ML', 'sample'), ('sample', 'generation'), ('generation', '['), ('[', '64'), ('64', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'resulting', 'method'), ('resulting', 'method', ','), ('method', ',', 'known'), (',', 'known', 'GAN'), ('known', 'GAN', ','), ('GAN', ',', 'recently'), (',', 'recently', 'led'), ('recently', 'led', 'impressive'), ('led', 'impressive', 'improvements'), ('impressive', 'improvements', 'ML'), ('improvements', 'ML', 'sample'), ('ML', 'sample', 'generation'), ('sample', 'generation', '['), ('generation', '[', '64'), ('[', '64', ']'), ('64', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('resulting', 'VBG'), ('method', 'NN'), (',', ','), ('known', 'VBN'), ('GAN', 'NNP'), (',', ','), ('recently', 'RB'), ('led', 'VBD'), ('impressive', 'JJ'), ('improvements', 'NNS'), ('ML', 'NNP'), ('sample', 'NN'), ('generation', 'NN'), ('[', 'VBD'), ('64', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  The/DT
  resulting/VBG
  (NP method/NN)
  ,/,
  known/VBN
  (NP GAN/NNP)
  ,/,
  recently/RB
  led/VBD
  (NP impressive/JJ improvements/NNS ML/NNP sample/NN generation/NN)
  [/VBD
  64/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['method', 'GAN', 'impressive improvements ML sample generation', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'GAN')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('method', 'method'), (',', ','), ('known', 'known'), ('GAN', 'gan'), (',', ','), ('recently', 'recent'), ('led', 'led'), ('impressive', 'impress'), ('improvements', 'improv'), ('ML', 'ml'), ('sample', 'sampl'), ('generation', 'gener'), ('[', '['), ('64', '64'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('method', 'method'), (',', ','), ('known', 'known'), ('GAN', 'gan'), (',', ','), ('recently', 'recent'), ('led', 'led'), ('impressive', 'impress'), ('improvements', 'improv'), ('ML', 'ml'), ('sample', 'sampl'), ('generation', 'generat'), ('[', '['), ('64', '64'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('resulting', 'resulting'), ('method', 'method'), (',', ','), ('known', 'known'), ('GAN', 'GAN'), (',', ','), ('recently', 'recently'), ('led', 'led'), ('impressive', 'impressive'), ('improvements', 'improvement'), ('ML', 'ML'), ('sample', 'sample'), ('generation', 'generation'), ('[', '['), ('64', '64'), (']', ']'), ('.', '.')]



============================ Sentence 518 =============================

VI. 


>> Tokens are: 
 ['VI', '.']

>> Bigrams are: 
 [('VI', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('VI', 'NNP'), ('.', '.')]

 (S (NP VI/NNP) ./.) 


>> Noun Phrases are: 
 ['VI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('VI', 'vi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('VI', 'vi'), ('.', '.')]

>> Lemmatization: 
 [('VI', 'VI'), ('.', '.')]



============================ Sentence 519 =============================

APPLICATIONS OF UNSUPERVISED LEARNING TO COMMUNICATION SYSTEMS  In this section, we highlight some applications of unsupervised learning to communication networks. 


>> Tokens are: 
 ['APPLICATIONS', 'OF', 'UNSUPERVISED', 'LEARNING', 'TO', 'COMMUNICATION', 'SYSTEMS', 'In', 'section', ',', 'highlight', 'applications', 'unsupervised', 'learning', 'communication', 'networks', '.']

>> Bigrams are: 
 [('APPLICATIONS', 'OF'), ('OF', 'UNSUPERVISED'), ('UNSUPERVISED', 'LEARNING'), ('LEARNING', 'TO'), ('TO', 'COMMUNICATION'), ('COMMUNICATION', 'SYSTEMS'), ('SYSTEMS', 'In'), ('In', 'section'), ('section', ','), (',', 'highlight'), ('highlight', 'applications'), ('applications', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'communication'), ('communication', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('APPLICATIONS', 'OF', 'UNSUPERVISED'), ('OF', 'UNSUPERVISED', 'LEARNING'), ('UNSUPERVISED', 'LEARNING', 'TO'), ('LEARNING', 'TO', 'COMMUNICATION'), ('TO', 'COMMUNICATION', 'SYSTEMS'), ('COMMUNICATION', 'SYSTEMS', 'In'), ('SYSTEMS', 'In', 'section'), ('In', 'section', ','), ('section', ',', 'highlight'), (',', 'highlight', 'applications'), ('highlight', 'applications', 'unsupervised'), ('applications', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'communication'), ('learning', 'communication', 'networks'), ('communication', 'networks', '.')]

>> POS Tags are: 
 [('APPLICATIONS', 'NNP'), ('OF', 'NNP'), ('UNSUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('TO', 'NNP'), ('COMMUNICATION', 'NNP'), ('SYSTEMS', 'NNP'), ('In', 'IN'), ('section', 'NN'), (',', ','), ('highlight', 'NN'), ('applications', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('communication', 'NN'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP
    APPLICATIONS/NNP
    OF/NNP
    UNSUPERVISED/NNP
    LEARNING/NNP
    TO/NNP
    COMMUNICATION/NNP
    SYSTEMS/NNP)
  In/IN
  (NP section/NN)
  ,/,
  (NP highlight/NN applications/NNS)
  unsupervised/VBD
  learning/VBG
  (NP communication/NN networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['APPLICATIONS OF UNSUPERVISED LEARNING TO COMMUNICATION SYSTEMS', 'section', 'highlight applications', 'communication networks']

>> Named Entities are: 
 [('ORGANIZATION', 'COMMUNICATION')] 

>> Stemming using Porter Stemmer: 
 [('APPLICATIONS', 'applic'), ('OF', 'of'), ('UNSUPERVISED', 'unsupervis'), ('LEARNING', 'learn'), ('TO', 'to'), ('COMMUNICATION', 'commun'), ('SYSTEMS', 'system'), ('In', 'in'), ('section', 'section'), (',', ','), ('highlight', 'highlight'), ('applications', 'applic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('communication', 'commun'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('APPLICATIONS', 'applic'), ('OF', 'of'), ('UNSUPERVISED', 'unsupervis'), ('LEARNING', 'learn'), ('TO', 'to'), ('COMMUNICATION', 'communic'), ('SYSTEMS', 'system'), ('In', 'in'), ('section', 'section'), (',', ','), ('highlight', 'highlight'), ('applications', 'applic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('communication', 'communic'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('APPLICATIONS', 'APPLICATIONS'), ('OF', 'OF'), ('UNSUPERVISED', 'UNSUPERVISED'), ('LEARNING', 'LEARNING'), ('TO', 'TO'), ('COMMUNICATION', 'COMMUNICATION'), ('SYSTEMS', 'SYSTEMS'), ('In', 'In'), ('section', 'section'), (',', ','), ('highlight', 'highlight'), ('applications', 'application'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('communication', 'communication'), ('networks', 'network'), ('.', '.')]



============================ Sentence 520 =============================

A. 


>> Tokens are: 
 ['A', '.']

>> Bigrams are: 
 [('A', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('.', '.')]

 (S A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('.', '.')]



============================ Sentence 521 =============================

At the Edge  (1) Physical Layer: Let us first consider some appli- cations of autoencoders at the physical layer as imple- mented by the network edge nodes. 


>> Tokens are: 
 ['At', 'Edge', '(', '1', ')', 'Physical', 'Layer', ':', 'Let', 'us', 'first', 'consider', 'appli-', 'cations', 'autoencoders', 'physical', 'layer', 'imple-', 'mented', 'network', 'edge', 'nodes', '.']

>> Bigrams are: 
 [('At', 'Edge'), ('Edge', '('), ('(', '1'), ('1', ')'), (')', 'Physical'), ('Physical', 'Layer'), ('Layer', ':'), (':', 'Let'), ('Let', 'us'), ('us', 'first'), ('first', 'consider'), ('consider', 'appli-'), ('appli-', 'cations'), ('cations', 'autoencoders'), ('autoencoders', 'physical'), ('physical', 'layer'), ('layer', 'imple-'), ('imple-', 'mented'), ('mented', 'network'), ('network', 'edge'), ('edge', 'nodes'), ('nodes', '.')]

>> Trigrams are: 
 [('At', 'Edge', '('), ('Edge', '(', '1'), ('(', '1', ')'), ('1', ')', 'Physical'), (')', 'Physical', 'Layer'), ('Physical', 'Layer', ':'), ('Layer', ':', 'Let'), (':', 'Let', 'us'), ('Let', 'us', 'first'), ('us', 'first', 'consider'), ('first', 'consider', 'appli-'), ('consider', 'appli-', 'cations'), ('appli-', 'cations', 'autoencoders'), ('cations', 'autoencoders', 'physical'), ('autoencoders', 'physical', 'layer'), ('physical', 'layer', 'imple-'), ('layer', 'imple-', 'mented'), ('imple-', 'mented', 'network'), ('mented', 'network', 'edge'), ('network', 'edge', 'nodes'), ('edge', 'nodes', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('Edge', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')'), ('Physical', 'NNP'), ('Layer', 'NNP'), (':', ':'), ('Let', 'VB'), ('us', 'PRP'), ('first', 'JJ'), ('consider', 'VB'), ('appli-', 'JJ'), ('cations', 'NNS'), ('autoencoders', 'NNS'), ('physical', 'JJ'), ('layer', 'NN'), ('imple-', 'NN'), ('mented', 'VBD'), ('network', 'NN'), ('edge', 'NN'), ('nodes', 'NNS'), ('.', '.')]

 (S
  At/IN
  (NP Edge/NNP)
  (/(
  1/CD
  )/)
  (NP Physical/NNP Layer/NNP)
  :/:
  Let/VB
  us/PRP
  first/JJ
  consider/VB
  (NP appli-/JJ cations/NNS autoencoders/NNS)
  (NP physical/JJ layer/NN imple-/NN)
  mented/VBD
  (NP network/NN edge/NN nodes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Edge', 'Physical Layer', 'appli- cations autoencoders', 'physical layer imple-', 'network edge nodes']

>> Named Entities are: 
 [('GPE', 'Edge'), ('PERSON', 'Physical Layer')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('Edge', 'edg'), ('(', '('), ('1', '1'), (')', ')'), ('Physical', 'physic'), ('Layer', 'layer'), (':', ':'), ('Let', 'let'), ('us', 'us'), ('first', 'first'), ('consider', 'consid'), ('appli-', 'appli-'), ('cations', 'cation'), ('autoencoders', 'autoencod'), ('physical', 'physic'), ('layer', 'layer'), ('imple-', 'imple-'), ('mented', 'ment'), ('network', 'network'), ('edge', 'edg'), ('nodes', 'node'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('Edge', 'edg'), ('(', '('), ('1', '1'), (')', ')'), ('Physical', 'physic'), ('Layer', 'layer'), (':', ':'), ('Let', 'let'), ('us', 'us'), ('first', 'first'), ('consider', 'consid'), ('appli-', 'appli-'), ('cations', 'cation'), ('autoencoders', 'autoencod'), ('physical', 'physic'), ('layer', 'layer'), ('imple-', 'imple-'), ('mented', 'ment'), ('network', 'network'), ('edge', 'edg'), ('nodes', 'node'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('Edge', 'Edge'), ('(', '('), ('1', '1'), (')', ')'), ('Physical', 'Physical'), ('Layer', 'Layer'), (':', ':'), ('Let', 'Let'), ('us', 'u'), ('first', 'first'), ('consider', 'consider'), ('appli-', 'appli-'), ('cations', 'cation'), ('autoencoders', 'autoencoders'), ('physical', 'physical'), ('layer', 'layer'), ('imple-', 'imple-'), ('mented', 'mented'), ('network', 'network'), ('edge', 'edge'), ('nodes', 'node'), ('.', '.')]



============================ Sentence 522 =============================

A fundamental idea is to treat the chain of encoder, channel, and decoder in a communication link as an autoencoder, where, with reference to Fig. 


>> Tokens are: 
 ['A', 'fundamental', 'idea', 'treat', 'chain', 'encoder', ',', 'channel', ',', 'decoder', 'communication', 'link', 'autoencoder', ',', ',', 'reference', 'Fig', '.']

>> Bigrams are: 
 [('A', 'fundamental'), ('fundamental', 'idea'), ('idea', 'treat'), ('treat', 'chain'), ('chain', 'encoder'), ('encoder', ','), (',', 'channel'), ('channel', ','), (',', 'decoder'), ('decoder', 'communication'), ('communication', 'link'), ('link', 'autoencoder'), ('autoencoder', ','), (',', ','), (',', 'reference'), ('reference', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('A', 'fundamental', 'idea'), ('fundamental', 'idea', 'treat'), ('idea', 'treat', 'chain'), ('treat', 'chain', 'encoder'), ('chain', 'encoder', ','), ('encoder', ',', 'channel'), (',', 'channel', ','), ('channel', ',', 'decoder'), (',', 'decoder', 'communication'), ('decoder', 'communication', 'link'), ('communication', 'link', 'autoencoder'), ('link', 'autoencoder', ','), ('autoencoder', ',', ','), (',', ',', 'reference'), (',', 'reference', 'Fig'), ('reference', 'Fig', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('fundamental', 'JJ'), ('idea', 'NN'), ('treat', 'NN'), ('chain', 'NN'), ('encoder', 'NN'), (',', ','), ('channel', 'NN'), (',', ','), ('decoder', 'NN'), ('communication', 'NN'), ('link', 'NN'), ('autoencoder', 'NN'), (',', ','), (',', ','), ('reference', 'NN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  (NP A/DT fundamental/JJ idea/NN treat/NN chain/NN encoder/NN)
  ,/,
  (NP channel/NN)
  ,/,
  (NP decoder/NN communication/NN link/NN autoencoder/NN)
  ,/,
  ,/,
  (NP reference/NN Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['A fundamental idea treat chain encoder', 'channel', 'decoder communication link autoencoder', 'reference Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('fundamental', 'fundament'), ('idea', 'idea'), ('treat', 'treat'), ('chain', 'chain'), ('encoder', 'encod'), (',', ','), ('channel', 'channel'), (',', ','), ('decoder', 'decod'), ('communication', 'commun'), ('link', 'link'), ('autoencoder', 'autoencod'), (',', ','), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('fundamental', 'fundament'), ('idea', 'idea'), ('treat', 'treat'), ('chain', 'chain'), ('encoder', 'encod'), (',', ','), ('channel', 'channel'), (',', ','), ('decoder', 'decod'), ('communication', 'communic'), ('link', 'link'), ('autoencoder', 'autoencod'), (',', ','), (',', ','), ('reference', 'refer'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('fundamental', 'fundamental'), ('idea', 'idea'), ('treat', 'treat'), ('chain', 'chain'), ('encoder', 'encoder'), (',', ','), ('channel', 'channel'), (',', ','), ('decoder', 'decoder'), ('communication', 'communication'), ('link', 'link'), ('autoencoder', 'autoencoder'), (',', ','), (',', ','), ('reference', 'reference'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 523 =============================

11(d), the input message is x, the transmitted codewords and received signals represent the intermediate representation z, and the output of the decoder should match the input [30]. 


>> Tokens are: 
 ['11', '(', ')', ',', 'input', 'message', 'x', ',', 'transmitted', 'codewords', 'received', 'signals', 'represent', 'intermediate', 'representation', 'z', ',', 'output', 'decoder', 'match', 'input', '[', '30', ']', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', ','), (',', 'input'), ('input', 'message'), ('message', 'x'), ('x', ','), (',', 'transmitted'), ('transmitted', 'codewords'), ('codewords', 'received'), ('received', 'signals'), ('signals', 'represent'), ('represent', 'intermediate'), ('intermediate', 'representation'), ('representation', 'z'), ('z', ','), (',', 'output'), ('output', 'decoder'), ('decoder', 'match'), ('match', 'input'), ('input', '['), ('[', '30'), ('30', ']'), (']', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', ','), (')', ',', 'input'), (',', 'input', 'message'), ('input', 'message', 'x'), ('message', 'x', ','), ('x', ',', 'transmitted'), (',', 'transmitted', 'codewords'), ('transmitted', 'codewords', 'received'), ('codewords', 'received', 'signals'), ('received', 'signals', 'represent'), ('signals', 'represent', 'intermediate'), ('represent', 'intermediate', 'representation'), ('intermediate', 'representation', 'z'), ('representation', 'z', ','), ('z', ',', 'output'), (',', 'output', 'decoder'), ('output', 'decoder', 'match'), ('decoder', 'match', 'input'), ('match', 'input', '['), ('input', '[', '30'), ('[', '30', ']'), ('30', ']', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), (',', ','), ('input', 'JJ'), ('message', 'NN'), ('x', 'NN'), (',', ','), ('transmitted', 'JJ'), ('codewords', 'NNS'), ('received', 'VBN'), ('signals', 'NNS'), ('represent', 'VBP'), ('intermediate', 'JJ'), ('representation', 'NN'), ('z', 'NN'), (',', ','), ('output', 'NN'), ('decoder', 'NN'), ('match', 'NN'), ('input', 'NN'), ('[', 'VBD'), ('30', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  11/CD
  (/(
  )/)
  ,/,
  (NP input/JJ message/NN x/NN)
  ,/,
  (NP transmitted/JJ codewords/NNS)
  received/VBN
  (NP signals/NNS)
  represent/VBP
  (NP intermediate/JJ representation/NN z/NN)
  ,/,
  (NP output/NN decoder/NN match/NN input/NN)
  [/VBD
  30/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['input message x', 'transmitted codewords', 'signals', 'intermediate representation z', 'output decoder match input', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('input', 'input'), ('message', 'messag'), ('x', 'x'), (',', ','), ('transmitted', 'transmit'), ('codewords', 'codeword'), ('received', 'receiv'), ('signals', 'signal'), ('represent', 'repres'), ('intermediate', 'intermedi'), ('representation', 'represent'), ('z', 'z'), (',', ','), ('output', 'output'), ('decoder', 'decod'), ('match', 'match'), ('input', 'input'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('input', 'input'), ('message', 'messag'), ('x', 'x'), (',', ','), ('transmitted', 'transmit'), ('codewords', 'codeword'), ('received', 'receiv'), ('signals', 'signal'), ('represent', 'repres'), ('intermediate', 'intermedi'), ('representation', 'represent'), ('z', 'z'), (',', ','), ('output', 'output'), ('decoder', 'decod'), ('match', 'match'), ('input', 'input'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), (',', ','), ('input', 'input'), ('message', 'message'), ('x', 'x'), (',', ','), ('transmitted', 'transmitted'), ('codewords', 'codewords'), ('received', 'received'), ('signals', 'signal'), ('represent', 'represent'), ('intermediate', 'intermediate'), ('representation', 'representation'), ('z', 'z'), (',', ','), ('output', 'output'), ('decoder', 'decoder'), ('match', 'match'), ('input', 'input'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]



============================ Sentence 524 =============================

Note that, for this particular autoencoder, the mapping p(x|z) can only be partially learned, as it includes not only the encoder but also the communication channel, while the conditional distribution p(x|z) defining the decoder can be learned. 


>> Tokens are: 
 ['Note', ',', 'particular', 'autoencoder', ',', 'mapping', 'p', '(', 'x|z', ')', 'partially', 'learned', ',', 'includes', 'encoder', 'also', 'communication', 'channel', ',', 'conditional', 'distribution', 'p', '(', 'x|z', ')', 'defining', 'decoder', 'learned', '.']

>> Bigrams are: 
 [('Note', ','), (',', 'particular'), ('particular', 'autoencoder'), ('autoencoder', ','), (',', 'mapping'), ('mapping', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ')'), (')', 'partially'), ('partially', 'learned'), ('learned', ','), (',', 'includes'), ('includes', 'encoder'), ('encoder', 'also'), ('also', 'communication'), ('communication', 'channel'), ('channel', ','), (',', 'conditional'), ('conditional', 'distribution'), ('distribution', 'p'), ('p', '('), ('(', 'x|z'), ('x|z', ')'), (')', 'defining'), ('defining', 'decoder'), ('decoder', 'learned'), ('learned', '.')]

>> Trigrams are: 
 [('Note', ',', 'particular'), (',', 'particular', 'autoencoder'), ('particular', 'autoencoder', ','), ('autoencoder', ',', 'mapping'), (',', 'mapping', 'p'), ('mapping', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ')'), ('x|z', ')', 'partially'), (')', 'partially', 'learned'), ('partially', 'learned', ','), ('learned', ',', 'includes'), (',', 'includes', 'encoder'), ('includes', 'encoder', 'also'), ('encoder', 'also', 'communication'), ('also', 'communication', 'channel'), ('communication', 'channel', ','), ('channel', ',', 'conditional'), (',', 'conditional', 'distribution'), ('conditional', 'distribution', 'p'), ('distribution', 'p', '('), ('p', '(', 'x|z'), ('(', 'x|z', ')'), ('x|z', ')', 'defining'), (')', 'defining', 'decoder'), ('defining', 'decoder', 'learned'), ('decoder', 'learned', '.')]

>> POS Tags are: 
 [('Note', 'NN'), (',', ','), ('particular', 'JJ'), ('autoencoder', 'NN'), (',', ','), ('mapping', 'VBG'), ('p', 'NN'), ('(', '('), ('x|z', 'NNP'), (')', ')'), ('partially', 'RB'), ('learned', 'VBN'), (',', ','), ('includes', 'VBZ'), ('encoder', 'NN'), ('also', 'RB'), ('communication', 'NN'), ('channel', 'NNS'), (',', ','), ('conditional', 'JJ'), ('distribution', 'NN'), ('p', 'NN'), ('(', '('), ('x|z', 'NNP'), (')', ')'), ('defining', 'VBG'), ('decoder', 'NN'), ('learned', 'VBN'), ('.', '.')]

 (S
  (NP Note/NN)
  ,/,
  (NP particular/JJ autoencoder/NN)
  ,/,
  mapping/VBG
  (NP p/NN)
  (/(
  (NP x|z/NNP)
  )/)
  partially/RB
  learned/VBN
  ,/,
  includes/VBZ
  (NP encoder/NN)
  also/RB
  (NP communication/NN channel/NNS)
  ,/,
  (NP conditional/JJ distribution/NN p/NN)
  (/(
  (NP x|z/NNP)
  )/)
  defining/VBG
  (NP decoder/NN)
  learned/VBN
  ./.) 


>> Noun Phrases are: 
 ['Note', 'particular autoencoder', 'p', 'x|z', 'encoder', 'communication channel', 'conditional distribution p', 'x|z', 'decoder']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), (',', ','), ('particular', 'particular'), ('autoencoder', 'autoencod'), (',', ','), ('mapping', 'map'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('partially', 'partial'), ('learned', 'learn'), (',', ','), ('includes', 'includ'), ('encoder', 'encod'), ('also', 'also'), ('communication', 'commun'), ('channel', 'channel'), (',', ','), ('conditional', 'condit'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('defining', 'defin'), ('decoder', 'decod'), ('learned', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), (',', ','), ('particular', 'particular'), ('autoencoder', 'autoencod'), (',', ','), ('mapping', 'map'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('partially', 'partial'), ('learned', 'learn'), (',', ','), ('includes', 'includ'), ('encoder', 'encod'), ('also', 'also'), ('communication', 'communic'), ('channel', 'channel'), (',', ','), ('conditional', 'condit'), ('distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('defining', 'defin'), ('decoder', 'decod'), ('learned', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), (',', ','), ('particular', 'particular'), ('autoencoder', 'autoencoder'), (',', ','), ('mapping', 'mapping'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('partially', 'partially'), ('learned', 'learned'), (',', ','), ('includes', 'includes'), ('encoder', 'encoder'), ('also', 'also'), ('communication', 'communication'), ('channel', 'channel'), (',', ','), ('conditional', 'conditional'), ('distribution', 'distribution'), ('p', 'p'), ('(', '('), ('x|z', 'x|z'), (')', ')'), ('defining', 'defining'), ('decoder', 'decoder'), ('learned', 'learned'), ('.', '.')]



============================ Sentence 525 =============================

We should now ask when this viewpoint can be beneficial in light of the criteria reviewed in Sec. 


>> Tokens are: 
 ['We', 'ask', 'viewpoint', 'beneficial', 'light', 'criteria', 'reviewed', 'Sec', '.']

>> Bigrams are: 
 [('We', 'ask'), ('ask', 'viewpoint'), ('viewpoint', 'beneficial'), ('beneficial', 'light'), ('light', 'criteria'), ('criteria', 'reviewed'), ('reviewed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('We', 'ask', 'viewpoint'), ('ask', 'viewpoint', 'beneficial'), ('viewpoint', 'beneficial', 'light'), ('beneficial', 'light', 'criteria'), ('light', 'criteria', 'reviewed'), ('criteria', 'reviewed', 'Sec'), ('reviewed', 'Sec', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('ask', 'VBP'), ('viewpoint', 'JJ'), ('beneficial', 'JJ'), ('light', 'NN'), ('criteria', 'NNS'), ('reviewed', 'VBD'), ('Sec', 'NNP'), ('.', '.')]

 (S
  We/PRP
  ask/VBP
  (NP viewpoint/JJ beneficial/JJ light/NN criteria/NNS)
  reviewed/VBD
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['viewpoint beneficial light criteria', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('ask', 'ask'), ('viewpoint', 'viewpoint'), ('beneficial', 'benefici'), ('light', 'light'), ('criteria', 'criteria'), ('reviewed', 'review'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('ask', 'ask'), ('viewpoint', 'viewpoint'), ('beneficial', 'benefici'), ('light', 'light'), ('criteria', 'criteria'), ('reviewed', 'review'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('ask', 'ask'), ('viewpoint', 'viewpoint'), ('beneficial', 'beneficial'), ('light', 'light'), ('criteria', 'criterion'), ('reviewed', 'reviewed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 526 =============================

I-C.  To address this question, one should check whether a model or algorithm deficit exists to justify the use of machine learning tools. 


>> Tokens are: 
 ['I-C.', 'To', 'address', 'question', ',', 'one', 'check', 'whether', 'model', 'algorithm', 'deficit', 'exists', 'justify', 'use', 'machine', 'learning', 'tools', '.']

>> Bigrams are: 
 [('I-C.', 'To'), ('To', 'address'), ('address', 'question'), ('question', ','), (',', 'one'), ('one', 'check'), ('check', 'whether'), ('whether', 'model'), ('model', 'algorithm'), ('algorithm', 'deficit'), ('deficit', 'exists'), ('exists', 'justify'), ('justify', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('I-C.', 'To', 'address'), ('To', 'address', 'question'), ('address', 'question', ','), ('question', ',', 'one'), (',', 'one', 'check'), ('one', 'check', 'whether'), ('check', 'whether', 'model'), ('whether', 'model', 'algorithm'), ('model', 'algorithm', 'deficit'), ('algorithm', 'deficit', 'exists'), ('deficit', 'exists', 'justify'), ('exists', 'justify', 'use'), ('justify', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', '.')]

>> POS Tags are: 
 [('I-C.', 'JJ'), ('To', 'TO'), ('address', 'VB'), ('question', 'NN'), (',', ','), ('one', 'CD'), ('check', 'NN'), ('whether', 'IN'), ('model', 'NN'), ('algorithm', 'NN'), ('deficit', 'NN'), ('exists', 'VBZ'), ('justify', 'NN'), ('use', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('.', '.')]

 (S
  I-C./JJ
  To/TO
  address/VB
  (NP question/NN)
  ,/,
  one/CD
  (NP check/NN)
  whether/IN
  (NP model/NN algorithm/NN deficit/NN)
  exists/VBZ
  (NP justify/NN use/NN machine/NN learning/NN tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['question', 'check', 'model algorithm deficit', 'justify use machine learning tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I-C.', 'i-c.'), ('To', 'to'), ('address', 'address'), ('question', 'question'), (',', ','), ('one', 'one'), ('check', 'check'), ('whether', 'whether'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('exists', 'exist'), ('justify', 'justifi'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('I-C.', 'i-c.'), ('To', 'to'), ('address', 'address'), ('question', 'question'), (',', ','), ('one', 'one'), ('check', 'check'), ('whether', 'whether'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('exists', 'exist'), ('justify', 'justifi'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('I-C.', 'I-C.'), ('To', 'To'), ('address', 'address'), ('question', 'question'), (',', ','), ('one', 'one'), ('check', 'check'), ('whether', 'whether'), ('model', 'model'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('exists', 'exists'), ('justify', 'justify'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 527 =============================

Training an autoencoder requires the availability of a model for the channel, and hence a model deficit would make this approach inapplicable unless further mechanisms are put in place (see below). 


>> Tokens are: 
 ['Training', 'autoencoder', 'requires', 'availability', 'model', 'channel', ',', 'hence', 'model', 'deficit', 'would', 'make', 'approach', 'inapplicable', 'unless', 'mechanisms', 'put', 'place', '(', 'see', ')', '.']

>> Bigrams are: 
 [('Training', 'autoencoder'), ('autoencoder', 'requires'), ('requires', 'availability'), ('availability', 'model'), ('model', 'channel'), ('channel', ','), (',', 'hence'), ('hence', 'model'), ('model', 'deficit'), ('deficit', 'would'), ('would', 'make'), ('make', 'approach'), ('approach', 'inapplicable'), ('inapplicable', 'unless'), ('unless', 'mechanisms'), ('mechanisms', 'put'), ('put', 'place'), ('place', '('), ('(', 'see'), ('see', ')'), (')', '.')]

>> Trigrams are: 
 [('Training', 'autoencoder', 'requires'), ('autoencoder', 'requires', 'availability'), ('requires', 'availability', 'model'), ('availability', 'model', 'channel'), ('model', 'channel', ','), ('channel', ',', 'hence'), (',', 'hence', 'model'), ('hence', 'model', 'deficit'), ('model', 'deficit', 'would'), ('deficit', 'would', 'make'), ('would', 'make', 'approach'), ('make', 'approach', 'inapplicable'), ('approach', 'inapplicable', 'unless'), ('inapplicable', 'unless', 'mechanisms'), ('unless', 'mechanisms', 'put'), ('mechanisms', 'put', 'place'), ('put', 'place', '('), ('place', '(', 'see'), ('(', 'see', ')'), ('see', ')', '.')]

>> POS Tags are: 
 [('Training', 'VBG'), ('autoencoder', 'NN'), ('requires', 'VBZ'), ('availability', 'JJ'), ('model', 'NN'), ('channel', 'NN'), (',', ','), ('hence', 'RB'), ('model', 'NN'), ('deficit', 'NN'), ('would', 'MD'), ('make', 'VB'), ('approach', 'NN'), ('inapplicable', 'JJ'), ('unless', 'IN'), ('mechanisms', 'NNS'), ('put', 'VBN'), ('place', 'NN'), ('(', '('), ('see', 'VB'), (')', ')'), ('.', '.')]

 (S
  Training/VBG
  (NP autoencoder/NN)
  requires/VBZ
  (NP availability/JJ model/NN channel/NN)
  ,/,
  hence/RB
  (NP model/NN deficit/NN)
  would/MD
  make/VB
  (NP approach/NN)
  inapplicable/JJ
  unless/IN
  (NP mechanisms/NNS)
  put/VBN
  (NP place/NN)
  (/(
  see/VB
  )/)
  ./.) 


>> Noun Phrases are: 
 ['autoencoder', 'availability model channel', 'model deficit', 'approach', 'mechanisms', 'place']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('autoencoder', 'autoencod'), ('requires', 'requir'), ('availability', 'avail'), ('model', 'model'), ('channel', 'channel'), (',', ','), ('hence', 'henc'), ('model', 'model'), ('deficit', 'deficit'), ('would', 'would'), ('make', 'make'), ('approach', 'approach'), ('inapplicable', 'inapplic'), ('unless', 'unless'), ('mechanisms', 'mechan'), ('put', 'put'), ('place', 'place'), ('(', '('), ('see', 'see'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('autoencoder', 'autoencod'), ('requires', 'requir'), ('availability', 'avail'), ('model', 'model'), ('channel', 'channel'), (',', ','), ('hence', 'henc'), ('model', 'model'), ('deficit', 'deficit'), ('would', 'would'), ('make', 'make'), ('approach', 'approach'), ('inapplicable', 'inapplic'), ('unless', 'unless'), ('mechanisms', 'mechan'), ('put', 'put'), ('place', 'place'), ('(', '('), ('see', 'see'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Training', 'Training'), ('autoencoder', 'autoencoder'), ('requires', 'requires'), ('availability', 'availability'), ('model', 'model'), ('channel', 'channel'), (',', ','), ('hence', 'hence'), ('model', 'model'), ('deficit', 'deficit'), ('would', 'would'), ('make', 'make'), ('approach', 'approach'), ('inapplicable', 'inapplicable'), ('unless', 'unless'), ('mechanisms', 'mechanism'), ('put', 'put'), ('place', 'place'), ('(', '('), ('see', 'see'), (')', ')'), ('.', '.')]



============================ Sentence 528 =============================

Examples of algorithm deficit include channels with complex non-linear dynamical models, such as optical links [65]; Gaussian channels with feedback, for which optimal practical encoding schemes are not known [66]; multiple access channels with sparse transmission codes [67]; and joint source-channel coding [68]. 


>> Tokens are: 
 ['Examples', 'algorithm', 'deficit', 'include', 'channels', 'complex', 'non-linear', 'dynamical', 'models', ',', 'optical', 'links', '[', '65', ']', ';', 'Gaussian', 'channels', 'feedback', ',', 'optimal', 'practical', 'encoding', 'schemes', 'known', '[', '66', ']', ';', 'multiple', 'access', 'channels', 'sparse', 'transmission', 'codes', '[', '67', ']', ';', 'joint', 'source-channel', 'coding', '[', '68', ']', '.']

>> Bigrams are: 
 [('Examples', 'algorithm'), ('algorithm', 'deficit'), ('deficit', 'include'), ('include', 'channels'), ('channels', 'complex'), ('complex', 'non-linear'), ('non-linear', 'dynamical'), ('dynamical', 'models'), ('models', ','), (',', 'optical'), ('optical', 'links'), ('links', '['), ('[', '65'), ('65', ']'), (']', ';'), (';', 'Gaussian'), ('Gaussian', 'channels'), ('channels', 'feedback'), ('feedback', ','), (',', 'optimal'), ('optimal', 'practical'), ('practical', 'encoding'), ('encoding', 'schemes'), ('schemes', 'known'), ('known', '['), ('[', '66'), ('66', ']'), (']', ';'), (';', 'multiple'), ('multiple', 'access'), ('access', 'channels'), ('channels', 'sparse'), ('sparse', 'transmission'), ('transmission', 'codes'), ('codes', '['), ('[', '67'), ('67', ']'), (']', ';'), (';', 'joint'), ('joint', 'source-channel'), ('source-channel', 'coding'), ('coding', '['), ('[', '68'), ('68', ']'), (']', '.')]

>> Trigrams are: 
 [('Examples', 'algorithm', 'deficit'), ('algorithm', 'deficit', 'include'), ('deficit', 'include', 'channels'), ('include', 'channels', 'complex'), ('channels', 'complex', 'non-linear'), ('complex', 'non-linear', 'dynamical'), ('non-linear', 'dynamical', 'models'), ('dynamical', 'models', ','), ('models', ',', 'optical'), (',', 'optical', 'links'), ('optical', 'links', '['), ('links', '[', '65'), ('[', '65', ']'), ('65', ']', ';'), (']', ';', 'Gaussian'), (';', 'Gaussian', 'channels'), ('Gaussian', 'channels', 'feedback'), ('channels', 'feedback', ','), ('feedback', ',', 'optimal'), (',', 'optimal', 'practical'), ('optimal', 'practical', 'encoding'), ('practical', 'encoding', 'schemes'), ('encoding', 'schemes', 'known'), ('schemes', 'known', '['), ('known', '[', '66'), ('[', '66', ']'), ('66', ']', ';'), (']', ';', 'multiple'), (';', 'multiple', 'access'), ('multiple', 'access', 'channels'), ('access', 'channels', 'sparse'), ('channels', 'sparse', 'transmission'), ('sparse', 'transmission', 'codes'), ('transmission', 'codes', '['), ('codes', '[', '67'), ('[', '67', ']'), ('67', ']', ';'), (']', ';', 'joint'), (';', 'joint', 'source-channel'), ('joint', 'source-channel', 'coding'), ('source-channel', 'coding', '['), ('coding', '[', '68'), ('[', '68', ']'), ('68', ']', '.')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('algorithm', 'VBP'), ('deficit', 'NN'), ('include', 'VBP'), ('channels', 'NNS'), ('complex', 'JJ'), ('non-linear', 'JJ'), ('dynamical', 'JJ'), ('models', 'NNS'), (',', ','), ('optical', 'JJ'), ('links', 'NNS'), ('[', 'VBP'), ('65', 'CD'), (']', 'NN'), (';', ':'), ('Gaussian', 'JJ'), ('channels', 'NNS'), ('feedback', 'NN'), (',', ','), ('optimal', 'JJ'), ('practical', 'JJ'), ('encoding', 'VBG'), ('schemes', 'NNS'), ('known', 'VBN'), ('[', 'RB'), ('66', 'CD'), (']', 'NNS'), (';', ':'), ('multiple', 'JJ'), ('access', 'NN'), ('channels', 'NNS'), ('sparse', 'VBP'), ('transmission', 'NN'), ('codes', 'NNS'), ('[', 'VBP'), ('67', 'CD'), (']', 'NNS'), (';', ':'), ('joint', 'JJ'), ('source-channel', 'NNS'), ('coding', 'VBG'), ('[', 'JJ'), ('68', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Examples/NNS)
  algorithm/VBP
  (NP deficit/NN)
  include/VBP
  (NP channels/NNS)
  (NP complex/JJ non-linear/JJ dynamical/JJ models/NNS)
  ,/,
  (NP optical/JJ links/NNS)
  [/VBP
  65/CD
  (NP ]/NN)
  ;/:
  (NP Gaussian/JJ channels/NNS feedback/NN)
  ,/,
  optimal/JJ
  practical/JJ
  encoding/VBG
  (NP schemes/NNS)
  known/VBN
  [/RB
  66/CD
  (NP ]/NNS)
  ;/:
  (NP multiple/JJ access/NN channels/NNS)
  sparse/VBP
  (NP transmission/NN codes/NNS)
  [/VBP
  67/CD
  (NP ]/NNS)
  ;/:
  (NP joint/JJ source-channel/NNS)
  coding/VBG
  [/JJ
  68/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Examples', 'deficit', 'channels', 'complex non-linear dynamical models', 'optical links', ']', 'Gaussian channels feedback', 'schemes', ']', 'multiple access channels', 'transmission codes', ']', 'joint source-channel', ']']

>> Named Entities are: 
 [('GPE', 'Gaussian')] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('include', 'includ'), ('channels', 'channel'), ('complex', 'complex'), ('non-linear', 'non-linear'), ('dynamical', 'dynam'), ('models', 'model'), (',', ','), ('optical', 'optic'), ('links', 'link'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Gaussian', 'gaussian'), ('channels', 'channel'), ('feedback', 'feedback'), (',', ','), ('optimal', 'optim'), ('practical', 'practic'), ('encoding', 'encod'), ('schemes', 'scheme'), ('known', 'known'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('multiple', 'multipl'), ('access', 'access'), ('channels', 'channel'), ('sparse', 'spars'), ('transmission', 'transmiss'), ('codes', 'code'), ('[', '['), ('67', '67'), (']', ']'), (';', ';'), ('joint', 'joint'), ('source-channel', 'source-channel'), ('coding', 'code'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('include', 'includ'), ('channels', 'channel'), ('complex', 'complex'), ('non-linear', 'non-linear'), ('dynamical', 'dynam'), ('models', 'model'), (',', ','), ('optical', 'optic'), ('links', 'link'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Gaussian', 'gaussian'), ('channels', 'channel'), ('feedback', 'feedback'), (',', ','), ('optimal', 'optim'), ('practical', 'practic'), ('encoding', 'encod'), ('schemes', 'scheme'), ('known', 'known'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('multiple', 'multipl'), ('access', 'access'), ('channels', 'channel'), ('sparse', 'spars'), ('transmission', 'transmiss'), ('codes', 'code'), ('[', '['), ('67', '67'), (']', ']'), (';', ';'), ('joint', 'joint'), ('source-channel', 'source-channel'), ('coding', 'code'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('include', 'include'), ('channels', 'channel'), ('complex', 'complex'), ('non-linear', 'non-linear'), ('dynamical', 'dynamical'), ('models', 'model'), (',', ','), ('optical', 'optical'), ('links', 'link'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Gaussian', 'Gaussian'), ('channels', 'channel'), ('feedback', 'feedback'), (',', ','), ('optimal', 'optimal'), ('practical', 'practical'), ('encoding', 'encoding'), ('schemes', 'scheme'), ('known', 'known'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('multiple', 'multiple'), ('access', 'access'), ('channels', 'channel'), ('sparse', 'sparse'), ('transmission', 'transmission'), ('codes', 'code'), ('[', '['), ('67', '67'), (']', ']'), (';', ';'), ('joint', 'joint'), ('source-channel', 'source-channel'), ('coding', 'coding'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]



============================ Sentence 529 =============================

Other applications at the physical layer leverage the use of autoencoders as compressors (see Sec V-B) or denoisers. 


>> Tokens are: 
 ['Other', 'applications', 'physical', 'layer', 'leverage', 'use', 'autoencoders', 'compressors', '(', 'see', 'Sec', 'V-B', ')', 'denoisers', '.']

>> Bigrams are: 
 [('Other', 'applications'), ('applications', 'physical'), ('physical', 'layer'), ('layer', 'leverage'), ('leverage', 'use'), ('use', 'autoencoders'), ('autoencoders', 'compressors'), ('compressors', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'V-B'), ('V-B', ')'), (')', 'denoisers'), ('denoisers', '.')]

>> Trigrams are: 
 [('Other', 'applications', 'physical'), ('applications', 'physical', 'layer'), ('physical', 'layer', 'leverage'), ('layer', 'leverage', 'use'), ('leverage', 'use', 'autoencoders'), ('use', 'autoencoders', 'compressors'), ('autoencoders', 'compressors', '('), ('compressors', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'V-B'), ('Sec', 'V-B', ')'), ('V-B', ')', 'denoisers'), (')', 'denoisers', '.')]

>> POS Tags are: 
 [('Other', 'JJ'), ('applications', 'NNS'), ('physical', 'JJ'), ('layer', 'NN'), ('leverage', 'NN'), ('use', 'NN'), ('autoencoders', 'NNS'), ('compressors', 'NNS'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('V-B', 'NNP'), (')', ')'), ('denoisers', 'NNS'), ('.', '.')]

 (S
  (NP Other/JJ applications/NNS)
  (NP
    physical/JJ
    layer/NN
    leverage/NN
    use/NN
    autoencoders/NNS
    compressors/NNS)
  (/(
  see/VB
  (NP Sec/NNP V-B/NNP)
  )/)
  (NP denoisers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Other applications', 'physical layer leverage use autoencoders compressors', 'Sec V-B', 'denoisers']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('applications', 'applic'), ('physical', 'physic'), ('layer', 'layer'), ('leverage', 'leverag'), ('use', 'use'), ('autoencoders', 'autoencod'), ('compressors', 'compressor'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V-B', 'v-b'), (')', ')'), ('denoisers', 'denois'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('applications', 'applic'), ('physical', 'physic'), ('layer', 'layer'), ('leverage', 'leverag'), ('use', 'use'), ('autoencoders', 'autoencod'), ('compressors', 'compressor'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('V-B', 'v-b'), (')', ')'), ('denoisers', 'denois'), ('.', '.')]

>> Lemmatization: 
 [('Other', 'Other'), ('applications', 'application'), ('physical', 'physical'), ('layer', 'layer'), ('leverage', 'leverage'), ('use', 'use'), ('autoencoders', 'autoencoders'), ('compressors', 'compressor'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('V-B', 'V-B'), (')', ')'), ('denoisers', 'denoisers'), ('.', '.')]



============================ Sentence 530 =============================

For channels with a complex structure with unavailable channel models or with unknown optimal compression algorithms, autoencoders can be used to compress channel state information for the purpose of feedback on frequency-division duplex links [69]. 


>> Tokens are: 
 ['For', 'channels', 'complex', 'structure', 'unavailable', 'channel', 'models', 'unknown', 'optimal', 'compression', 'algorithms', ',', 'autoencoders', 'used', 'compress', 'channel', 'state', 'information', 'purpose', 'feedback', 'frequency-division', 'duplex', 'links', '[', '69', ']', '.']

>> Bigrams are: 
 [('For', 'channels'), ('channels', 'complex'), ('complex', 'structure'), ('structure', 'unavailable'), ('unavailable', 'channel'), ('channel', 'models'), ('models', 'unknown'), ('unknown', 'optimal'), ('optimal', 'compression'), ('compression', 'algorithms'), ('algorithms', ','), (',', 'autoencoders'), ('autoencoders', 'used'), ('used', 'compress'), ('compress', 'channel'), ('channel', 'state'), ('state', 'information'), ('information', 'purpose'), ('purpose', 'feedback'), ('feedback', 'frequency-division'), ('frequency-division', 'duplex'), ('duplex', 'links'), ('links', '['), ('[', '69'), ('69', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'channels', 'complex'), ('channels', 'complex', 'structure'), ('complex', 'structure', 'unavailable'), ('structure', 'unavailable', 'channel'), ('unavailable', 'channel', 'models'), ('channel', 'models', 'unknown'), ('models', 'unknown', 'optimal'), ('unknown', 'optimal', 'compression'), ('optimal', 'compression', 'algorithms'), ('compression', 'algorithms', ','), ('algorithms', ',', 'autoencoders'), (',', 'autoencoders', 'used'), ('autoencoders', 'used', 'compress'), ('used', 'compress', 'channel'), ('compress', 'channel', 'state'), ('channel', 'state', 'information'), ('state', 'information', 'purpose'), ('information', 'purpose', 'feedback'), ('purpose', 'feedback', 'frequency-division'), ('feedback', 'frequency-division', 'duplex'), ('frequency-division', 'duplex', 'links'), ('duplex', 'links', '['), ('links', '[', '69'), ('[', '69', ']'), ('69', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('channels', 'NNS'), ('complex', 'JJ'), ('structure', 'NN'), ('unavailable', 'JJ'), ('channel', 'NN'), ('models', 'NNS'), ('unknown', 'IN'), ('optimal', 'JJ'), ('compression', 'NN'), ('algorithms', 'NN'), (',', ','), ('autoencoders', 'NNS'), ('used', 'VBD'), ('compress', 'JJ'), ('channel', 'NN'), ('state', 'NN'), ('information', 'NN'), ('purpose', 'JJ'), ('feedback', 'NN'), ('frequency-division', 'NN'), ('duplex', 'JJ'), ('links', 'NNS'), ('[', 'VBP'), ('69', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP channels/NNS)
  (NP complex/JJ structure/NN)
  (NP unavailable/JJ channel/NN models/NNS)
  unknown/IN
  (NP optimal/JJ compression/NN algorithms/NN)
  ,/,
  (NP autoencoders/NNS)
  used/VBD
  (NP compress/JJ channel/NN state/NN information/NN)
  (NP purpose/JJ feedback/NN frequency-division/NN)
  (NP duplex/JJ links/NNS)
  [/VBP
  69/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['channels', 'complex structure', 'unavailable channel models', 'optimal compression algorithms', 'autoencoders', 'compress channel state information', 'purpose feedback frequency-division', 'duplex links', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('channels', 'channel'), ('complex', 'complex'), ('structure', 'structur'), ('unavailable', 'unavail'), ('channel', 'channel'), ('models', 'model'), ('unknown', 'unknown'), ('optimal', 'optim'), ('compression', 'compress'), ('algorithms', 'algorithm'), (',', ','), ('autoencoders', 'autoencod'), ('used', 'use'), ('compress', 'compress'), ('channel', 'channel'), ('state', 'state'), ('information', 'inform'), ('purpose', 'purpos'), ('feedback', 'feedback'), ('frequency-division', 'frequency-divis'), ('duplex', 'duplex'), ('links', 'link'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('channels', 'channel'), ('complex', 'complex'), ('structure', 'structur'), ('unavailable', 'unavail'), ('channel', 'channel'), ('models', 'model'), ('unknown', 'unknown'), ('optimal', 'optim'), ('compression', 'compress'), ('algorithms', 'algorithm'), (',', ','), ('autoencoders', 'autoencod'), ('used', 'use'), ('compress', 'compress'), ('channel', 'channel'), ('state', 'state'), ('information', 'inform'), ('purpose', 'purpos'), ('feedback', 'feedback'), ('frequency-division', 'frequency-divis'), ('duplex', 'duplex'), ('links', 'link'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('channels', 'channel'), ('complex', 'complex'), ('structure', 'structure'), ('unavailable', 'unavailable'), ('channel', 'channel'), ('models', 'model'), ('unknown', 'unknown'), ('optimal', 'optimal'), ('compression', 'compression'), ('algorithms', 'algorithm'), (',', ','), ('autoencoders', 'autoencoders'), ('used', 'used'), ('compress', 'compress'), ('channel', 'channel'), ('state', 'state'), ('information', 'information'), ('purpose', 'purpose'), ('feedback', 'feedback'), ('frequency-division', 'frequency-division'), ('duplex', 'duplex'), ('links', 'link'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]



============================ Sentence 531 =============================

Autoencoders can also be used for their capacity to denoise the input signal by means of filtering through the lower dimensional representation z. 


>> Tokens are: 
 ['Autoencoders', 'also', 'used', 'capacity', 'denoise', 'input', 'signal', 'means', 'filtering', 'lower', 'dimensional', 'representation', 'z', '.']

>> Bigrams are: 
 [('Autoencoders', 'also'), ('also', 'used'), ('used', 'capacity'), ('capacity', 'denoise'), ('denoise', 'input'), ('input', 'signal'), ('signal', 'means'), ('means', 'filtering'), ('filtering', 'lower'), ('lower', 'dimensional'), ('dimensional', 'representation'), ('representation', 'z'), ('z', '.')]

>> Trigrams are: 
 [('Autoencoders', 'also', 'used'), ('also', 'used', 'capacity'), ('used', 'capacity', 'denoise'), ('capacity', 'denoise', 'input'), ('denoise', 'input', 'signal'), ('input', 'signal', 'means'), ('signal', 'means', 'filtering'), ('means', 'filtering', 'lower'), ('filtering', 'lower', 'dimensional'), ('lower', 'dimensional', 'representation'), ('dimensional', 'representation', 'z'), ('representation', 'z', '.')]

>> POS Tags are: 
 [('Autoencoders', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('capacity', 'NN'), ('denoise', 'NN'), ('input', 'VBD'), ('signal', 'JJ'), ('means', 'NNS'), ('filtering', 'VBG'), ('lower', 'JJR'), ('dimensional', 'JJ'), ('representation', 'NN'), ('z', 'NN'), ('.', '.')]

 (S
  (NP Autoencoders/NNS)
  also/RB
  used/VBD
  (NP capacity/NN denoise/NN)
  input/VBD
  (NP signal/JJ means/NNS)
  filtering/VBG
  lower/JJR
  (NP dimensional/JJ representation/NN z/NN)
  ./.) 


>> Noun Phrases are: 
 ['Autoencoders', 'capacity denoise', 'signal means', 'dimensional representation z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Autoencoders', 'autoencod'), ('also', 'also'), ('used', 'use'), ('capacity', 'capac'), ('denoise', 'denois'), ('input', 'input'), ('signal', 'signal'), ('means', 'mean'), ('filtering', 'filter'), ('lower', 'lower'), ('dimensional', 'dimension'), ('representation', 'represent'), ('z', 'z'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Autoencoders', 'autoencod'), ('also', 'also'), ('used', 'use'), ('capacity', 'capac'), ('denoise', 'denois'), ('input', 'input'), ('signal', 'signal'), ('means', 'mean'), ('filtering', 'filter'), ('lower', 'lower'), ('dimensional', 'dimension'), ('representation', 'represent'), ('z', 'z'), ('.', '.')]

>> Lemmatization: 
 [('Autoencoders', 'Autoencoders'), ('also', 'also'), ('used', 'used'), ('capacity', 'capacity'), ('denoise', 'denoise'), ('input', 'input'), ('signal', 'signal'), ('means', 'mean'), ('filtering', 'filtering'), ('lower', 'lower'), ('dimensional', 'dimensional'), ('representation', 'representation'), ('z', 'z'), ('.', '.')]



============================ Sentence 532 =============================

This is done in [70] for the task of localization on the basis of the received baseband signal. 


>> Tokens are: 
 ['This', 'done', '[', '70', ']', 'task', 'localization', 'basis', 'received', 'baseband', 'signal', '.']

>> Bigrams are: 
 [('This', 'done'), ('done', '['), ('[', '70'), ('70', ']'), (']', 'task'), ('task', 'localization'), ('localization', 'basis'), ('basis', 'received'), ('received', 'baseband'), ('baseband', 'signal'), ('signal', '.')]

>> Trigrams are: 
 [('This', 'done', '['), ('done', '[', '70'), ('[', '70', ']'), ('70', ']', 'task'), (']', 'task', 'localization'), ('task', 'localization', 'basis'), ('localization', 'basis', 'received'), ('basis', 'received', 'baseband'), ('received', 'baseband', 'signal'), ('baseband', 'signal', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('done', 'VBN'), ('[', 'NN'), ('70', 'CD'), (']', 'NN'), ('task', 'NN'), ('localization', 'NN'), ('basis', 'NN'), ('received', 'VBD'), ('baseband', 'JJ'), ('signal', 'NN'), ('.', '.')]

 (S
  This/DT
  done/VBN
  (NP [/NN)
  70/CD
  (NP ]/NN task/NN localization/NN basis/NN)
  received/VBD
  (NP baseband/JJ signal/NN)
  ./.) 


>> Noun Phrases are: 
 ['[', '] task localization basis', 'baseband signal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('done', 'done'), ('[', '['), ('70', '70'), (']', ']'), ('task', 'task'), ('localization', 'local'), ('basis', 'basi'), ('received', 'receiv'), ('baseband', 'baseband'), ('signal', 'signal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('done', 'done'), ('[', '['), ('70', '70'), (']', ']'), ('task', 'task'), ('localization', 'local'), ('basis', 'basi'), ('received', 'receiv'), ('baseband', 'baseband'), ('signal', 'signal'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('done', 'done'), ('[', '['), ('70', '70'), (']', ']'), ('task', 'task'), ('localization', 'localization'), ('basis', 'basis'), ('received', 'received'), ('baseband', 'baseband'), ('signal', 'signal'), ('.', '.')]



============================ Sentence 533 =============================

To this end, an autoencoder is learned for every reference position in space with the objective of denoising signals received from the given location. 


>> Tokens are: 
 ['To', 'end', ',', 'autoencoder', 'learned', 'every', 'reference', 'position', 'space', 'objective', 'denoising', 'signals', 'received', 'given', 'location', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'autoencoder'), ('autoencoder', 'learned'), ('learned', 'every'), ('every', 'reference'), ('reference', 'position'), ('position', 'space'), ('space', 'objective'), ('objective', 'denoising'), ('denoising', 'signals'), ('signals', 'received'), ('received', 'given'), ('given', 'location'), ('location', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'autoencoder'), (',', 'autoencoder', 'learned'), ('autoencoder', 'learned', 'every'), ('learned', 'every', 'reference'), ('every', 'reference', 'position'), ('reference', 'position', 'space'), ('position', 'space', 'objective'), ('space', 'objective', 'denoising'), ('objective', 'denoising', 'signals'), ('denoising', 'signals', 'received'), ('signals', 'received', 'given'), ('received', 'given', 'location'), ('given', 'location', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('autoencoder', 'NN'), ('learned', 'VBD'), ('every', 'DT'), ('reference', 'NN'), ('position', 'NN'), ('space', 'NN'), ('objective', 'JJ'), ('denoising', 'NN'), ('signals', 'NNS'), ('received', 'VBD'), ('given', 'VBN'), ('location', 'NN'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  (NP autoencoder/NN)
  learned/VBD
  (NP every/DT reference/NN position/NN space/NN)
  (NP objective/JJ denoising/NN signals/NNS)
  received/VBD
  given/VBN
  (NP location/NN)
  ./.) 


>> Noun Phrases are: 
 ['autoencoder', 'every reference position space', 'objective denoising signals', 'location']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('autoencoder', 'autoencod'), ('learned', 'learn'), ('every', 'everi'), ('reference', 'refer'), ('position', 'posit'), ('space', 'space'), ('objective', 'object'), ('denoising', 'denois'), ('signals', 'signal'), ('received', 'receiv'), ('given', 'given'), ('location', 'locat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('autoencoder', 'autoencod'), ('learned', 'learn'), ('every', 'everi'), ('reference', 'refer'), ('position', 'posit'), ('space', 'space'), ('objective', 'object'), ('denoising', 'denois'), ('signals', 'signal'), ('received', 'receiv'), ('given', 'given'), ('location', 'locat'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('autoencoder', 'autoencoder'), ('learned', 'learned'), ('every', 'every'), ('reference', 'reference'), ('position', 'position'), ('space', 'space'), ('objective', 'objective'), ('denoising', 'denoising'), ('signals', 'signal'), ('received', 'received'), ('given', 'given'), ('location', 'location'), ('.', '.')]



============================ Sentence 534 =============================

At test time, the location that corresponds to the autoencoder with the smallest reconstruction error is taken as an estimate of the unknown transmitting device. 


>> Tokens are: 
 ['At', 'test', 'time', ',', 'location', 'corresponds', 'autoencoder', 'smallest', 'reconstruction', 'error', 'taken', 'estimate', 'unknown', 'transmitting', 'device', '.']

>> Bigrams are: 
 [('At', 'test'), ('test', 'time'), ('time', ','), (',', 'location'), ('location', 'corresponds'), ('corresponds', 'autoencoder'), ('autoencoder', 'smallest'), ('smallest', 'reconstruction'), ('reconstruction', 'error'), ('error', 'taken'), ('taken', 'estimate'), ('estimate', 'unknown'), ('unknown', 'transmitting'), ('transmitting', 'device'), ('device', '.')]

>> Trigrams are: 
 [('At', 'test', 'time'), ('test', 'time', ','), ('time', ',', 'location'), (',', 'location', 'corresponds'), ('location', 'corresponds', 'autoencoder'), ('corresponds', 'autoencoder', 'smallest'), ('autoencoder', 'smallest', 'reconstruction'), ('smallest', 'reconstruction', 'error'), ('reconstruction', 'error', 'taken'), ('error', 'taken', 'estimate'), ('taken', 'estimate', 'unknown'), ('estimate', 'unknown', 'transmitting'), ('unknown', 'transmitting', 'device'), ('transmitting', 'device', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('test', 'NN'), ('time', 'NN'), (',', ','), ('location', 'NN'), ('corresponds', 'NNS'), ('autoencoder', 'VBP'), ('smallest', 'JJS'), ('reconstruction', 'NN'), ('error', 'NN'), ('taken', 'VBN'), ('estimate', 'NN'), ('unknown', 'JJ'), ('transmitting', 'VBG'), ('device', 'NN'), ('.', '.')]

 (S
  At/IN
  (NP test/NN time/NN)
  ,/,
  (NP location/NN corresponds/NNS)
  autoencoder/VBP
  smallest/JJS
  (NP reconstruction/NN error/NN)
  taken/VBN
  (NP estimate/NN)
  unknown/JJ
  transmitting/VBG
  (NP device/NN)
  ./.) 


>> Noun Phrases are: 
 ['test time', 'location corresponds', 'reconstruction error', 'estimate', 'device']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('test', 'test'), ('time', 'time'), (',', ','), ('location', 'locat'), ('corresponds', 'correspond'), ('autoencoder', 'autoencod'), ('smallest', 'smallest'), ('reconstruction', 'reconstruct'), ('error', 'error'), ('taken', 'taken'), ('estimate', 'estim'), ('unknown', 'unknown'), ('transmitting', 'transmit'), ('device', 'devic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('test', 'test'), ('time', 'time'), (',', ','), ('location', 'locat'), ('corresponds', 'correspond'), ('autoencoder', 'autoencod'), ('smallest', 'smallest'), ('reconstruction', 'reconstruct'), ('error', 'error'), ('taken', 'taken'), ('estimate', 'estim'), ('unknown', 'unknown'), ('transmitting', 'transmit'), ('device', 'devic'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('test', 'test'), ('time', 'time'), (',', ','), ('location', 'location'), ('corresponds', 'corresponds'), ('autoencoder', 'autoencoder'), ('smallest', 'smallest'), ('reconstruction', 'reconstruction'), ('error', 'error'), ('taken', 'taken'), ('estimate', 'estimate'), ('unknown', 'unknown'), ('transmitting', 'transmitting'), ('device', 'device'), ('.', '.')]



============================ Sentence 535 =============================

We now review some applications of the generative models illustrated in Fig. 


>> Tokens are: 
 ['We', 'review', 'applications', 'generative', 'models', 'illustrated', 'Fig', '.']

>> Bigrams are: 
 [('We', 'review'), ('review', 'applications'), ('applications', 'generative'), ('generative', 'models'), ('models', 'illustrated'), ('illustrated', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('We', 'review', 'applications'), ('review', 'applications', 'generative'), ('applications', 'generative', 'models'), ('generative', 'models', 'illustrated'), ('models', 'illustrated', 'Fig'), ('illustrated', 'Fig', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('review', 'VBP'), ('applications', 'NNS'), ('generative', 'JJ'), ('models', 'NNS'), ('illustrated', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

 (S
  We/PRP
  review/VBP
  (NP applications/NNS)
  (NP generative/JJ models/NNS)
  illustrated/VBN
  (NP Fig/NNP)
  ./.) 


>> Noun Phrases are: 
 ['applications', 'generative models', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('review', 'review'), ('applications', 'applic'), ('generative', 'gener'), ('models', 'model'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('review', 'review'), ('applications', 'applic'), ('generative', 'generat'), ('models', 'model'), ('illustrated', 'illustr'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('review', 'review'), ('applications', 'application'), ('generative', 'generative'), ('models', 'model'), ('illustrated', 'illustrated'), ('Fig', 'Fig'), ('.', '.')]



============================ Sentence 536 =============================

11(a). 


>> Tokens are: 
 ['11', '(', ')', '.']

>> Bigrams are: 
 [('11', '('), ('(', ')'), (')', '.')]

>> Trigrams are: 
 [('11', '(', ')'), ('(', ')', '.')]

>> POS Tags are: 
 [('11', 'CD'), ('(', '('), (')', ')'), ('.', '.')]

 (S 11/CD (/( )/) ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('(', '('), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('(', '('), (')', ')'), ('.', '.')]



============================ Sentence 537 =============================

A natural idea is that of using generative models to learn how to generate samples from a given channel [71], [72]. 


>> Tokens are: 
 ['A', 'natural', 'idea', 'using', 'generative', 'models', 'learn', 'generate', 'samples', 'given', 'channel', '[', '71', ']', ',', '[', '72', ']', '.']

>> Bigrams are: 
 [('A', 'natural'), ('natural', 'idea'), ('idea', 'using'), ('using', 'generative'), ('generative', 'models'), ('models', 'learn'), ('learn', 'generate'), ('generate', 'samples'), ('samples', 'given'), ('given', 'channel'), ('channel', '['), ('[', '71'), ('71', ']'), (']', ','), (',', '['), ('[', '72'), ('72', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'natural', 'idea'), ('natural', 'idea', 'using'), ('idea', 'using', 'generative'), ('using', 'generative', 'models'), ('generative', 'models', 'learn'), ('models', 'learn', 'generate'), ('learn', 'generate', 'samples'), ('generate', 'samples', 'given'), ('samples', 'given', 'channel'), ('given', 'channel', '['), ('channel', '[', '71'), ('[', '71', ']'), ('71', ']', ','), (']', ',', '['), (',', '[', '72'), ('[', '72', ']'), ('72', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('natural', 'JJ'), ('idea', 'NN'), ('using', 'VBG'), ('generative', 'JJ'), ('models', 'NNS'), ('learn', 'VBP'), ('generate', 'JJ'), ('samples', 'NNS'), ('given', 'VBN'), ('channel', 'NNS'), ('[', '$'), ('71', 'CD'), (']', 'NNP'), (',', ','), ('[', 'VBD'), ('72', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP A/DT natural/JJ idea/NN)
  using/VBG
  (NP generative/JJ models/NNS)
  learn/VBP
  (NP generate/JJ samples/NNS)
  given/VBN
  (NP channel/NNS)
  [/$
  71/CD
  (NP ]/NNP)
  ,/,
  [/VBD
  72/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['A natural idea', 'generative models', 'generate samples', 'channel', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('natural', 'natur'), ('idea', 'idea'), ('using', 'use'), ('generative', 'gener'), ('models', 'model'), ('learn', 'learn'), ('generate', 'gener'), ('samples', 'sampl'), ('given', 'given'), ('channel', 'channel'), ('[', '['), ('71', '71'), (']', ']'), (',', ','), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('natural', 'natur'), ('idea', 'idea'), ('using', 'use'), ('generative', 'generat'), ('models', 'model'), ('learn', 'learn'), ('generate', 'generat'), ('samples', 'sampl'), ('given', 'given'), ('channel', 'channel'), ('[', '['), ('71', '71'), (']', ']'), (',', ','), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('natural', 'natural'), ('idea', 'idea'), ('using', 'using'), ('generative', 'generative'), ('models', 'model'), ('learn', 'learn'), ('generate', 'generate'), ('samples', 'sample'), ('given', 'given'), ('channel', 'channel'), ('[', '['), ('71', '71'), (']', ']'), (',', ','), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]



============================ Sentence 538 =============================

This approach is sound for scenarios that lack tractable channel models. 


>> Tokens are: 
 ['This', 'approach', 'sound', 'scenarios', 'lack', 'tractable', 'channel', 'models', '.']

>> Bigrams are: 
 [('This', 'approach'), ('approach', 'sound'), ('sound', 'scenarios'), ('scenarios', 'lack'), ('lack', 'tractable'), ('tractable', 'channel'), ('channel', 'models'), ('models', '.')]

>> Trigrams are: 
 [('This', 'approach', 'sound'), ('approach', 'sound', 'scenarios'), ('sound', 'scenarios', 'lack'), ('scenarios', 'lack', 'tractable'), ('lack', 'tractable', 'channel'), ('tractable', 'channel', 'models'), ('channel', 'models', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('approach', 'NN'), ('sound', 'VBD'), ('scenarios', 'NNS'), ('lack', 'VBP'), ('tractable', 'JJ'), ('channel', 'NN'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP This/DT approach/NN)
  sound/VBD
  (NP scenarios/NNS)
  lack/VBP
  (NP tractable/JJ channel/NN models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This approach', 'scenarios', 'tractable channel models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('approach', 'approach'), ('sound', 'sound'), ('scenarios', 'scenario'), ('lack', 'lack'), ('tractable', 'tractabl'), ('channel', 'channel'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('approach', 'approach'), ('sound', 'sound'), ('scenarios', 'scenario'), ('lack', 'lack'), ('tractable', 'tractabl'), ('channel', 'channel'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('approach', 'approach'), ('sound', 'sound'), ('scenarios', 'scenario'), ('lack', 'lack'), ('tractable', 'tractable'), ('channel', 'channel'), ('models', 'model'), ('.', '.')]



============================ Sentence 539 =============================

As a pertinent example, generative models can be used to mimic and identify non-linear channels for satellite com- munications [2]. 


>> Tokens are: 
 ['As', 'pertinent', 'example', ',', 'generative', 'models', 'used', 'mimic', 'identify', 'non-linear', 'channels', 'satellite', 'com-', 'munications', '[', '2', ']', '.']

>> Bigrams are: 
 [('As', 'pertinent'), ('pertinent', 'example'), ('example', ','), (',', 'generative'), ('generative', 'models'), ('models', 'used'), ('used', 'mimic'), ('mimic', 'identify'), ('identify', 'non-linear'), ('non-linear', 'channels'), ('channels', 'satellite'), ('satellite', 'com-'), ('com-', 'munications'), ('munications', '['), ('[', '2'), ('2', ']'), (']', '.')]

>> Trigrams are: 
 [('As', 'pertinent', 'example'), ('pertinent', 'example', ','), ('example', ',', 'generative'), (',', 'generative', 'models'), ('generative', 'models', 'used'), ('models', 'used', 'mimic'), ('used', 'mimic', 'identify'), ('mimic', 'identify', 'non-linear'), ('identify', 'non-linear', 'channels'), ('non-linear', 'channels', 'satellite'), ('channels', 'satellite', 'com-'), ('satellite', 'com-', 'munications'), ('com-', 'munications', '['), ('munications', '[', '2'), ('[', '2', ']'), ('2', ']', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('pertinent', 'JJ'), ('example', 'NN'), (',', ','), ('generative', 'JJ'), ('models', 'NNS'), ('used', 'VBN'), ('mimic', 'JJ'), ('identify', 'JJ'), ('non-linear', 'JJ'), ('channels', 'NNS'), ('satellite', 'VBP'), ('com-', 'JJ'), ('munications', 'NNS'), ('[', 'VBP'), ('2', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP pertinent/JJ example/NN)
  ,/,
  (NP generative/JJ models/NNS)
  used/VBN
  (NP mimic/JJ identify/JJ non-linear/JJ channels/NNS)
  satellite/VBP
  (NP com-/JJ munications/NNS)
  [/VBP
  2/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['pertinent example', 'generative models', 'mimic identify non-linear channels', 'com- munications', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('pertinent', 'pertin'), ('example', 'exampl'), (',', ','), ('generative', 'gener'), ('models', 'model'), ('used', 'use'), ('mimic', 'mimic'), ('identify', 'identifi'), ('non-linear', 'non-linear'), ('channels', 'channel'), ('satellite', 'satellit'), ('com-', 'com-'), ('munications', 'munic'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('pertinent', 'pertin'), ('example', 'exampl'), (',', ','), ('generative', 'generat'), ('models', 'model'), ('used', 'use'), ('mimic', 'mimic'), ('identify', 'identifi'), ('non-linear', 'non-linear'), ('channels', 'channel'), ('satellite', 'satellit'), ('com-', 'com-'), ('munications', 'munic'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('pertinent', 'pertinent'), ('example', 'example'), (',', ','), ('generative', 'generative'), ('models', 'model'), ('used', 'used'), ('mimic', 'mimic'), ('identify', 'identify'), ('non-linear', 'non-linear'), ('channels', 'channel'), ('satellite', 'satellite'), ('com-', 'com-'), ('munications', 'munications'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]



============================ Sentence 540 =============================

The early works on the subject carried out in the nineties are also notable for the integration of the domain knowledge into the definition of machine learning models (see Sec IV). 


>> Tokens are: 
 ['The', 'early', 'works', 'subject', 'carried', 'nineties', 'also', 'notable', 'integration', 'domain', 'knowledge', 'definition', 'machine', 'learning', 'models', '(', 'see', 'Sec', 'IV', ')', '.']

>> Bigrams are: 
 [('The', 'early'), ('early', 'works'), ('works', 'subject'), ('subject', 'carried'), ('carried', 'nineties'), ('nineties', 'also'), ('also', 'notable'), ('notable', 'integration'), ('integration', 'domain'), ('domain', 'knowledge'), ('knowledge', 'definition'), ('definition', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'IV'), ('IV', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'early', 'works'), ('early', 'works', 'subject'), ('works', 'subject', 'carried'), ('subject', 'carried', 'nineties'), ('carried', 'nineties', 'also'), ('nineties', 'also', 'notable'), ('also', 'notable', 'integration'), ('notable', 'integration', 'domain'), ('integration', 'domain', 'knowledge'), ('domain', 'knowledge', 'definition'), ('knowledge', 'definition', 'machine'), ('definition', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', '('), ('models', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'IV'), ('Sec', 'IV', ')'), ('IV', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('early', 'JJ'), ('works', 'NNS'), ('subject', 'JJ'), ('carried', 'VBD'), ('nineties', 'NNS'), ('also', 'RB'), ('notable', 'JJ'), ('integration', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), ('definition', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('models', 'NNS'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('IV', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT early/JJ works/NNS)
  subject/JJ
  carried/VBD
  (NP nineties/NNS)
  also/RB
  (NP
    notable/JJ
    integration/NN
    domain/NN
    knowledge/NN
    definition/NN
    machine/NN
    learning/NN
    models/NNS)
  (/(
  see/VB
  (NP Sec/NNP IV/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The early works', 'nineties', 'notable integration domain knowledge definition machine learning models', 'Sec IV']

>> Named Entities are: 
 [('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('early', 'earli'), ('works', 'work'), ('subject', 'subject'), ('carried', 'carri'), ('nineties', 'nineti'), ('also', 'also'), ('notable', 'notabl'), ('integration', 'integr'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('definition', 'definit'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('IV', 'iv'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('early', 'earli'), ('works', 'work'), ('subject', 'subject'), ('carried', 'carri'), ('nineties', 'nineti'), ('also', 'also'), ('notable', 'notabl'), ('integration', 'integr'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('definition', 'definit'), ('machine', 'machin'), ('learning', 'learn'), ('models', 'model'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('IV', 'iv'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('early', 'early'), ('works', 'work'), ('subject', 'subject'), ('carried', 'carried'), ('nineties', 'ninety'), ('also', 'also'), ('notable', 'notable'), ('integration', 'integration'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('definition', 'definition'), ('machine', 'machine'), ('learning', 'learning'), ('models', 'model'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('IV', 'IV'), (')', ')'), ('.', '.')]



============================ Sentence 541 =============================

In fact, mindful of the strong linear components of the channels, these works posit a learnable model that includes linear filters and non-linearities [2]. 


>> Tokens are: 
 ['In', 'fact', ',', 'mindful', 'strong', 'linear', 'components', 'channels', ',', 'works', 'posit', 'learnable', 'model', 'includes', 'linear', 'filters', 'non-linearities', '[', '2', ']', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'mindful'), ('mindful', 'strong'), ('strong', 'linear'), ('linear', 'components'), ('components', 'channels'), ('channels', ','), (',', 'works'), ('works', 'posit'), ('posit', 'learnable'), ('learnable', 'model'), ('model', 'includes'), ('includes', 'linear'), ('linear', 'filters'), ('filters', 'non-linearities'), ('non-linearities', '['), ('[', '2'), ('2', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'mindful'), (',', 'mindful', 'strong'), ('mindful', 'strong', 'linear'), ('strong', 'linear', 'components'), ('linear', 'components', 'channels'), ('components', 'channels', ','), ('channels', ',', 'works'), (',', 'works', 'posit'), ('works', 'posit', 'learnable'), ('posit', 'learnable', 'model'), ('learnable', 'model', 'includes'), ('model', 'includes', 'linear'), ('includes', 'linear', 'filters'), ('linear', 'filters', 'non-linearities'), ('filters', 'non-linearities', '['), ('non-linearities', '[', '2'), ('[', '2', ']'), ('2', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('mindful', 'JJ'), ('strong', 'JJ'), ('linear', 'JJ'), ('components', 'NNS'), ('channels', 'NNS'), (',', ','), ('works', 'VBZ'), ('posit', 'NN'), ('learnable', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('linear', 'JJ'), ('filters', 'NNS'), ('non-linearities', 'NNS'), ('[', 'VBP'), ('2', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP fact/NN)
  ,/,
  (NP mindful/JJ strong/JJ linear/JJ components/NNS channels/NNS)
  ,/,
  works/VBZ
  (NP posit/NN)
  (NP learnable/JJ model/NN)
  includes/VBZ
  (NP linear/JJ filters/NNS non-linearities/NNS)
  [/VBP
  2/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'mindful strong linear components channels', 'posit', 'learnable model', 'linear filters non-linearities', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('mindful', 'mind'), ('strong', 'strong'), ('linear', 'linear'), ('components', 'compon'), ('channels', 'channel'), (',', ','), ('works', 'work'), ('posit', 'posit'), ('learnable', 'learnabl'), ('model', 'model'), ('includes', 'includ'), ('linear', 'linear'), ('filters', 'filter'), ('non-linearities', 'non-linear'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('mindful', 'mind'), ('strong', 'strong'), ('linear', 'linear'), ('components', 'compon'), ('channels', 'channel'), (',', ','), ('works', 'work'), ('posit', 'posit'), ('learnable', 'learnabl'), ('model', 'model'), ('includes', 'includ'), ('linear', 'linear'), ('filters', 'filter'), ('non-linearities', 'non-linear'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('mindful', 'mindful'), ('strong', 'strong'), ('linear', 'linear'), ('components', 'component'), ('channels', 'channel'), (',', ','), ('works', 'work'), ('posit', 'posit'), ('learnable', 'learnable'), ('model', 'model'), ('includes', 'includes'), ('linear', 'linear'), ('filters', 'filter'), ('non-linearities', 'non-linearities'), ('[', '['), ('2', '2'), (']', ']'), ('.', '.')]



============================ Sentence 542 =============================

Another approach that can be considered as unsu- pervised was proposed in [73] in order to solve the challenging problem of power control for interference channels. 


>> Tokens are: 
 ['Another', 'approach', 'considered', 'unsu-', 'pervised', 'proposed', '[', '73', ']', 'order', 'solve', 'challenging', 'problem', 'power', 'control', 'interference', 'channels', '.']

>> Bigrams are: 
 [('Another', 'approach'), ('approach', 'considered'), ('considered', 'unsu-'), ('unsu-', 'pervised'), ('pervised', 'proposed'), ('proposed', '['), ('[', '73'), ('73', ']'), (']', 'order'), ('order', 'solve'), ('solve', 'challenging'), ('challenging', 'problem'), ('problem', 'power'), ('power', 'control'), ('control', 'interference'), ('interference', 'channels'), ('channels', '.')]

>> Trigrams are: 
 [('Another', 'approach', 'considered'), ('approach', 'considered', 'unsu-'), ('considered', 'unsu-', 'pervised'), ('unsu-', 'pervised', 'proposed'), ('pervised', 'proposed', '['), ('proposed', '[', '73'), ('[', '73', ']'), ('73', ']', 'order'), (']', 'order', 'solve'), ('order', 'solve', 'challenging'), ('solve', 'challenging', 'problem'), ('challenging', 'problem', 'power'), ('problem', 'power', 'control'), ('power', 'control', 'interference'), ('control', 'interference', 'channels'), ('interference', 'channels', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('approach', 'NN'), ('considered', 'VBN'), ('unsu-', 'JJ'), ('pervised', 'NNS'), ('proposed', 'VBN'), ('[', 'RB'), ('73', 'CD'), (']', 'JJ'), ('order', 'NN'), ('solve', 'NN'), ('challenging', 'VBG'), ('problem', 'NN'), ('power', 'NN'), ('control', 'NN'), ('interference', 'NN'), ('channels', 'NNS'), ('.', '.')]

 (S
  (NP Another/DT approach/NN)
  considered/VBN
  (NP unsu-/JJ pervised/NNS)
  proposed/VBN
  [/RB
  73/CD
  (NP ]/JJ order/NN solve/NN)
  challenging/VBG
  (NP problem/NN power/NN control/NN interference/NN channels/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Another approach', 'unsu- pervised', '] order solve', 'problem power control interference channels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('approach', 'approach'), ('considered', 'consid'), ('unsu-', 'unsu-'), ('pervised', 'pervis'), ('proposed', 'propos'), ('[', '['), ('73', '73'), (']', ']'), ('order', 'order'), ('solve', 'solv'), ('challenging', 'challeng'), ('problem', 'problem'), ('power', 'power'), ('control', 'control'), ('interference', 'interfer'), ('channels', 'channel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('approach', 'approach'), ('considered', 'consid'), ('unsu-', 'unsu-'), ('pervised', 'pervis'), ('proposed', 'propos'), ('[', '['), ('73', '73'), (']', ']'), ('order', 'order'), ('solve', 'solv'), ('challenging', 'challeng'), ('problem', 'problem'), ('power', 'power'), ('control', 'control'), ('interference', 'interfer'), ('channels', 'channel'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('approach', 'approach'), ('considered', 'considered'), ('unsu-', 'unsu-'), ('pervised', 'pervised'), ('proposed', 'proposed'), ('[', '['), ('73', '73'), (']', ']'), ('order', 'order'), ('solve', 'solve'), ('challenging', 'challenging'), ('problem', 'problem'), ('power', 'power'), ('control', 'control'), ('interference', 'interference'), ('channels', 'channel'), ('.', '.')]



============================ Sentence 543 =============================

The approach tackles the resulting algorithm deficit by means of a direct optimization of the sum-rate with the aim of obtaining the power allocation vector (as fractions of the maximal available powers) at the output of a neural network. 


>> Tokens are: 
 ['The', 'approach', 'tackles', 'resulting', 'algorithm', 'deficit', 'means', 'direct', 'optimization', 'sum-rate', 'aim', 'obtaining', 'power', 'allocation', 'vector', '(', 'fractions', 'maximal', 'available', 'powers', ')', 'output', 'neural', 'network', '.']

>> Bigrams are: 
 [('The', 'approach'), ('approach', 'tackles'), ('tackles', 'resulting'), ('resulting', 'algorithm'), ('algorithm', 'deficit'), ('deficit', 'means'), ('means', 'direct'), ('direct', 'optimization'), ('optimization', 'sum-rate'), ('sum-rate', 'aim'), ('aim', 'obtaining'), ('obtaining', 'power'), ('power', 'allocation'), ('allocation', 'vector'), ('vector', '('), ('(', 'fractions'), ('fractions', 'maximal'), ('maximal', 'available'), ('available', 'powers'), ('powers', ')'), (')', 'output'), ('output', 'neural'), ('neural', 'network'), ('network', '.')]

>> Trigrams are: 
 [('The', 'approach', 'tackles'), ('approach', 'tackles', 'resulting'), ('tackles', 'resulting', 'algorithm'), ('resulting', 'algorithm', 'deficit'), ('algorithm', 'deficit', 'means'), ('deficit', 'means', 'direct'), ('means', 'direct', 'optimization'), ('direct', 'optimization', 'sum-rate'), ('optimization', 'sum-rate', 'aim'), ('sum-rate', 'aim', 'obtaining'), ('aim', 'obtaining', 'power'), ('obtaining', 'power', 'allocation'), ('power', 'allocation', 'vector'), ('allocation', 'vector', '('), ('vector', '(', 'fractions'), ('(', 'fractions', 'maximal'), ('fractions', 'maximal', 'available'), ('maximal', 'available', 'powers'), ('available', 'powers', ')'), ('powers', ')', 'output'), (')', 'output', 'neural'), ('output', 'neural', 'network'), ('neural', 'network', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('approach', 'NN'), ('tackles', 'VBZ'), ('resulting', 'VBG'), ('algorithm', 'JJ'), ('deficit', 'NN'), ('means', 'VBZ'), ('direct', 'JJ'), ('optimization', 'NN'), ('sum-rate', 'JJ'), ('aim', 'NN'), ('obtaining', 'VBG'), ('power', 'NN'), ('allocation', 'NN'), ('vector', 'NN'), ('(', '('), ('fractions', 'NNS'), ('maximal', 'VBP'), ('available', 'JJ'), ('powers', 'NNS'), (')', ')'), ('output', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('.', '.')]

 (S
  (NP The/DT approach/NN)
  tackles/VBZ
  resulting/VBG
  (NP algorithm/JJ deficit/NN)
  means/VBZ
  (NP direct/JJ optimization/NN)
  (NP sum-rate/JJ aim/NN)
  obtaining/VBG
  (NP power/NN allocation/NN vector/NN)
  (/(
  (NP fractions/NNS)
  maximal/VBP
  (NP available/JJ powers/NNS)
  )/)
  (NP output/NN)
  (NP neural/JJ network/NN)
  ./.) 


>> Noun Phrases are: 
 ['The approach', 'algorithm deficit', 'direct optimization', 'sum-rate aim', 'power allocation vector', 'fractions', 'available powers', 'output', 'neural network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('approach', 'approach'), ('tackles', 'tackl'), ('resulting', 'result'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('means', 'mean'), ('direct', 'direct'), ('optimization', 'optim'), ('sum-rate', 'sum-rat'), ('aim', 'aim'), ('obtaining', 'obtain'), ('power', 'power'), ('allocation', 'alloc'), ('vector', 'vector'), ('(', '('), ('fractions', 'fraction'), ('maximal', 'maxim'), ('available', 'avail'), ('powers', 'power'), (')', ')'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('approach', 'approach'), ('tackles', 'tackl'), ('resulting', 'result'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('means', 'mean'), ('direct', 'direct'), ('optimization', 'optim'), ('sum-rate', 'sum-rat'), ('aim', 'aim'), ('obtaining', 'obtain'), ('power', 'power'), ('allocation', 'alloc'), ('vector', 'vector'), ('(', '('), ('fractions', 'fraction'), ('maximal', 'maxim'), ('available', 'avail'), ('powers', 'power'), (')', ')'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('approach', 'approach'), ('tackles', 'tackle'), ('resulting', 'resulting'), ('algorithm', 'algorithm'), ('deficit', 'deficit'), ('means', 'mean'), ('direct', 'direct'), ('optimization', 'optimization'), ('sum-rate', 'sum-rate'), ('aim', 'aim'), ('obtaining', 'obtaining'), ('power', 'power'), ('allocation', 'allocation'), ('vector', 'vector'), ('(', '('), ('fractions', 'fraction'), ('maximal', 'maximal'), ('available', 'available'), ('powers', 'power'), (')', ')'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]



============================ Sentence 544 =============================

Related supervised learning methods were discussed in Sec. 


>> Tokens are: 
 ['Related', 'supervised', 'learning', 'methods', 'discussed', 'Sec', '.']

>> Bigrams are: 
 [('Related', 'supervised'), ('supervised', 'learning'), ('learning', 'methods'), ('methods', 'discussed'), ('discussed', 'Sec'), ('Sec', '.')]

>> Trigrams are: 
 [('Related', 'supervised', 'learning'), ('supervised', 'learning', 'methods'), ('learning', 'methods', 'discussed'), ('methods', 'discussed', 'Sec'), ('discussed', 'Sec', '.')]

>> POS Tags are: 
 [('Related', 'VBN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('methods', 'NNS'), ('discussed', 'VBN'), ('Sec', 'NNP'), ('.', '.')]

 (S
  Related/VBN
  supervised/VBD
  learning/VBG
  (NP methods/NNS)
  discussed/VBN
  (NP Sec/NNP)
  ./.) 


>> Noun Phrases are: 
 ['methods', 'Sec']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Related', 'relat'), ('supervised', 'supervis'), ('learning', 'learn'), ('methods', 'method'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Related', 'relat'), ('supervised', 'supervis'), ('learning', 'learn'), ('methods', 'method'), ('discussed', 'discuss'), ('Sec', 'sec'), ('.', '.')]

>> Lemmatization: 
 [('Related', 'Related'), ('supervised', 'supervised'), ('learning', 'learning'), ('methods', 'method'), ('discussed', 'discussed'), ('Sec', 'Sec'), ('.', '.')]



============================ Sentence 545 =============================

IV. 


>> Tokens are: 
 ['IV', '.']

>> Bigrams are: 
 [('IV', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IV', 'NNP'), ('.', '.')]

 (S (NP IV/NNP) ./.) 


>> Noun Phrases are: 
 ['IV']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IV', 'iv'), ('.', '.')]

>> Lemmatization: 
 [('IV', 'IV'), ('.', '.')]



============================ Sentence 546 =============================

A similar approach – also based on the idea of directly maximizing the criterion of interest so as to obtain an approximate solution at the output of a neural network – was considered in [74] for minimum mean squared error channel estimation with non-Gaussian channels, e.g.-.-, multi-path channels. 


>> Tokens are: 
 ['A', 'similar', 'approach', '–', 'also', 'based', 'idea', 'directly', 'maximizing', 'criterion', 'interest', 'obtain', 'approximate', 'solution', 'output', 'neural', 'network', '–', 'considered', '[', '74', ']', 'minimum', 'mean', 'squared', 'error', 'channel', 'estimation', 'non-Gaussian', 'channels', ',', 'e.g.-.-', ',', 'multi-path', 'channels', '.']

>> Bigrams are: 
 [('A', 'similar'), ('similar', 'approach'), ('approach', '–'), ('–', 'also'), ('also', 'based'), ('based', 'idea'), ('idea', 'directly'), ('directly', 'maximizing'), ('maximizing', 'criterion'), ('criterion', 'interest'), ('interest', 'obtain'), ('obtain', 'approximate'), ('approximate', 'solution'), ('solution', 'output'), ('output', 'neural'), ('neural', 'network'), ('network', '–'), ('–', 'considered'), ('considered', '['), ('[', '74'), ('74', ']'), (']', 'minimum'), ('minimum', 'mean'), ('mean', 'squared'), ('squared', 'error'), ('error', 'channel'), ('channel', 'estimation'), ('estimation', 'non-Gaussian'), ('non-Gaussian', 'channels'), ('channels', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'multi-path'), ('multi-path', 'channels'), ('channels', '.')]

>> Trigrams are: 
 [('A', 'similar', 'approach'), ('similar', 'approach', '–'), ('approach', '–', 'also'), ('–', 'also', 'based'), ('also', 'based', 'idea'), ('based', 'idea', 'directly'), ('idea', 'directly', 'maximizing'), ('directly', 'maximizing', 'criterion'), ('maximizing', 'criterion', 'interest'), ('criterion', 'interest', 'obtain'), ('interest', 'obtain', 'approximate'), ('obtain', 'approximate', 'solution'), ('approximate', 'solution', 'output'), ('solution', 'output', 'neural'), ('output', 'neural', 'network'), ('neural', 'network', '–'), ('network', '–', 'considered'), ('–', 'considered', '['), ('considered', '[', '74'), ('[', '74', ']'), ('74', ']', 'minimum'), (']', 'minimum', 'mean'), ('minimum', 'mean', 'squared'), ('mean', 'squared', 'error'), ('squared', 'error', 'channel'), ('error', 'channel', 'estimation'), ('channel', 'estimation', 'non-Gaussian'), ('estimation', 'non-Gaussian', 'channels'), ('non-Gaussian', 'channels', ','), ('channels', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'multi-path'), (',', 'multi-path', 'channels'), ('multi-path', 'channels', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('similar', 'JJ'), ('approach', 'NN'), ('–', 'NN'), ('also', 'RB'), ('based', 'VBN'), ('idea', 'NN'), ('directly', 'RB'), ('maximizing', 'VBG'), ('criterion', 'NN'), ('interest', 'NN'), ('obtain', 'VB'), ('approximate', 'JJ'), ('solution', 'NN'), ('output', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('–', 'NN'), ('considered', 'VBN'), ('[', '$'), ('74', 'CD'), (']', 'NNP'), ('minimum', 'JJ'), ('mean', 'NN'), ('squared', 'VBD'), ('error', 'JJ'), ('channel', 'NN'), ('estimation', 'NN'), ('non-Gaussian', 'JJ'), ('channels', 'NNS'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('multi-path', 'JJ'), ('channels', 'NNS'), ('.', '.')]

 (S
  (NP A/DT similar/JJ approach/NN –/NN)
  also/RB
  based/VBN
  (NP idea/NN)
  directly/RB
  maximizing/VBG
  (NP criterion/NN interest/NN)
  obtain/VB
  (NP approximate/JJ solution/NN output/NN)
  (NP neural/JJ network/NN –/NN)
  considered/VBN
  [/$
  74/CD
  (NP ]/NNP)
  (NP minimum/JJ mean/NN)
  squared/VBD
  (NP error/JJ channel/NN estimation/NN)
  (NP non-Gaussian/JJ channels/NNS)
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP multi-path/JJ channels/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A similar approach –', 'idea', 'criterion interest', 'approximate solution output', 'neural network –', ']', 'minimum mean', 'error channel estimation', 'non-Gaussian channels', 'multi-path channels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('similar', 'similar'), ('approach', 'approach'), ('–', '–'), ('also', 'also'), ('based', 'base'), ('idea', 'idea'), ('directly', 'directli'), ('maximizing', 'maxim'), ('criterion', 'criterion'), ('interest', 'interest'), ('obtain', 'obtain'), ('approximate', 'approxim'), ('solution', 'solut'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('–', '–'), ('considered', 'consid'), ('[', '['), ('74', '74'), (']', ']'), ('minimum', 'minimum'), ('mean', 'mean'), ('squared', 'squar'), ('error', 'error'), ('channel', 'channel'), ('estimation', 'estim'), ('non-Gaussian', 'non-gaussian'), ('channels', 'channel'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('multi-path', 'multi-path'), ('channels', 'channel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('similar', 'similar'), ('approach', 'approach'), ('–', '–'), ('also', 'also'), ('based', 'base'), ('idea', 'idea'), ('directly', 'direct'), ('maximizing', 'maxim'), ('criterion', 'criterion'), ('interest', 'interest'), ('obtain', 'obtain'), ('approximate', 'approxim'), ('solution', 'solut'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('–', '–'), ('considered', 'consid'), ('[', '['), ('74', '74'), (']', ']'), ('minimum', 'minimum'), ('mean', 'mean'), ('squared', 'squar'), ('error', 'error'), ('channel', 'channel'), ('estimation', 'estim'), ('non-Gaussian', 'non-gaussian'), ('channels', 'channel'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('multi-path', 'multi-path'), ('channels', 'channel'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('similar', 'similar'), ('approach', 'approach'), ('–', '–'), ('also', 'also'), ('based', 'based'), ('idea', 'idea'), ('directly', 'directly'), ('maximizing', 'maximizing'), ('criterion', 'criterion'), ('interest', 'interest'), ('obtain', 'obtain'), ('approximate', 'approximate'), ('solution', 'solution'), ('output', 'output'), ('neural', 'neural'), ('network', 'network'), ('–', '–'), ('considered', 'considered'), ('[', '['), ('74', '74'), (']', ']'), ('minimum', 'minimum'), ('mean', 'mean'), ('squared', 'squared'), ('error', 'error'), ('channel', 'channel'), ('estimation', 'estimation'), ('non-Gaussian', 'non-Gaussian'), ('channels', 'channel'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('multi-path', 'multi-path'), ('channels', 'channel'), ('.', '.')]



============================ Sentence 547 =============================

(2) Medium Access Layer: At the medium access layer, generative models have been advocated in [75] as a way to generate new examples so as to augment a data set used to train a classifier for spectrum sensing (see Sec IV). 


>> Tokens are: 
 ['(', '2', ')', 'Medium', 'Access', 'Layer', ':', 'At', 'medium', 'access', 'layer', ',', 'generative', 'models', 'advocated', '[', '75', ']', 'way', 'generate', 'new', 'examples', 'augment', 'data', 'set', 'used', 'train', 'classifier', 'spectrum', 'sensing', '(', 'see', 'Sec', 'IV', ')', '.']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'Medium'), ('Medium', 'Access'), ('Access', 'Layer'), ('Layer', ':'), (':', 'At'), ('At', 'medium'), ('medium', 'access'), ('access', 'layer'), ('layer', ','), (',', 'generative'), ('generative', 'models'), ('models', 'advocated'), ('advocated', '['), ('[', '75'), ('75', ']'), (']', 'way'), ('way', 'generate'), ('generate', 'new'), ('new', 'examples'), ('examples', 'augment'), ('augment', 'data'), ('data', 'set'), ('set', 'used'), ('used', 'train'), ('train', 'classifier'), ('classifier', 'spectrum'), ('spectrum', 'sensing'), ('sensing', '('), ('(', 'see'), ('see', 'Sec'), ('Sec', 'IV'), ('IV', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'Medium'), (')', 'Medium', 'Access'), ('Medium', 'Access', 'Layer'), ('Access', 'Layer', ':'), ('Layer', ':', 'At'), (':', 'At', 'medium'), ('At', 'medium', 'access'), ('medium', 'access', 'layer'), ('access', 'layer', ','), ('layer', ',', 'generative'), (',', 'generative', 'models'), ('generative', 'models', 'advocated'), ('models', 'advocated', '['), ('advocated', '[', '75'), ('[', '75', ']'), ('75', ']', 'way'), (']', 'way', 'generate'), ('way', 'generate', 'new'), ('generate', 'new', 'examples'), ('new', 'examples', 'augment'), ('examples', 'augment', 'data'), ('augment', 'data', 'set'), ('data', 'set', 'used'), ('set', 'used', 'train'), ('used', 'train', 'classifier'), ('train', 'classifier', 'spectrum'), ('classifier', 'spectrum', 'sensing'), ('spectrum', 'sensing', '('), ('sensing', '(', 'see'), ('(', 'see', 'Sec'), ('see', 'Sec', 'IV'), ('Sec', 'IV', ')'), ('IV', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('Medium', 'NNP'), ('Access', 'NNP'), ('Layer', 'NNP'), (':', ':'), ('At', 'IN'), ('medium', 'NN'), ('access', 'NN'), ('layer', 'NN'), (',', ','), ('generative', 'JJ'), ('models', 'NNS'), ('advocated', 'VBN'), ('[', 'JJ'), ('75', 'CD'), (']', 'JJ'), ('way', 'NN'), ('generate', 'VBP'), ('new', 'JJ'), ('examples', 'NNS'), ('augment', 'JJ'), ('data', 'NNS'), ('set', 'NN'), ('used', 'VBN'), ('train', 'NN'), ('classifier', 'NN'), ('spectrum', 'NN'), ('sensing', 'NN'), ('(', '('), ('see', 'VB'), ('Sec', 'NNP'), ('IV', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (/(
  2/CD
  )/)
  (NP Medium/NNP Access/NNP Layer/NNP)
  :/:
  At/IN
  (NP medium/NN access/NN layer/NN)
  ,/,
  (NP generative/JJ models/NNS)
  advocated/VBN
  [/JJ
  75/CD
  (NP ]/JJ way/NN)
  generate/VBP
  (NP new/JJ examples/NNS)
  (NP augment/JJ data/NNS set/NN)
  used/VBN
  (NP train/NN classifier/NN spectrum/NN sensing/NN)
  (/(
  see/VB
  (NP Sec/NNP IV/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Medium Access Layer', 'medium access layer', 'generative models', '] way', 'new examples', 'augment data set', 'train classifier spectrum sensing', 'Sec IV']

>> Named Entities are: 
 [('PERSON', 'Medium Access Layer'), ('ORGANIZATION', 'Sec')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Medium', 'medium'), ('Access', 'access'), ('Layer', 'layer'), (':', ':'), ('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('layer', 'layer'), (',', ','), ('generative', 'gener'), ('models', 'model'), ('advocated', 'advoc'), ('[', '['), ('75', '75'), (']', ']'), ('way', 'way'), ('generate', 'gener'), ('new', 'new'), ('examples', 'exampl'), ('augment', 'augment'), ('data', 'data'), ('set', 'set'), ('used', 'use'), ('train', 'train'), ('classifier', 'classifi'), ('spectrum', 'spectrum'), ('sensing', 'sens'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('IV', 'iv'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Medium', 'medium'), ('Access', 'access'), ('Layer', 'layer'), (':', ':'), ('At', 'at'), ('medium', 'medium'), ('access', 'access'), ('layer', 'layer'), (',', ','), ('generative', 'generat'), ('models', 'model'), ('advocated', 'advoc'), ('[', '['), ('75', '75'), (']', ']'), ('way', 'way'), ('generate', 'generat'), ('new', 'new'), ('examples', 'exampl'), ('augment', 'augment'), ('data', 'data'), ('set', 'set'), ('used', 'use'), ('train', 'train'), ('classifier', 'classifi'), ('spectrum', 'spectrum'), ('sensing', 'sens'), ('(', '('), ('see', 'see'), ('Sec', 'sec'), ('IV', 'iv'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('Medium', 'Medium'), ('Access', 'Access'), ('Layer', 'Layer'), (':', ':'), ('At', 'At'), ('medium', 'medium'), ('access', 'access'), ('layer', 'layer'), (',', ','), ('generative', 'generative'), ('models', 'model'), ('advocated', 'advocated'), ('[', '['), ('75', '75'), (']', ']'), ('way', 'way'), ('generate', 'generate'), ('new', 'new'), ('examples', 'example'), ('augment', 'augment'), ('data', 'data'), ('set', 'set'), ('used', 'used'), ('train', 'train'), ('classifier', 'classifier'), ('spectrum', 'spectrum'), ('sensing', 'sensing'), ('(', '('), ('see', 'see'), ('Sec', 'Sec'), ('IV', 'IV'), (')', ')'), ('.', '.')]



============================ Sentence 548 =============================

An unsupervised learning task that has found many applications in communications is clustering. 


>> Tokens are: 
 ['An', 'unsupervised', 'learning', 'task', 'found', 'many', 'applications', 'communications', 'clustering', '.']

>> Bigrams are: 
 [('An', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'task'), ('task', 'found'), ('found', 'many'), ('many', 'applications'), ('applications', 'communications'), ('communications', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('An', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'task'), ('learning', 'task', 'found'), ('task', 'found', 'many'), ('found', 'many', 'applications'), ('many', 'applications', 'communications'), ('applications', 'communications', 'clustering'), ('communications', 'clustering', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('task', 'NN'), ('found', 'VBD'), ('many', 'JJ'), ('applications', 'NNS'), ('communications', 'NNS'), ('clustering', 'VBG'), ('.', '.')]

 (S
  (NP An/DT unsupervised/JJ learning/NN task/NN)
  found/VBD
  (NP many/JJ applications/NNS communications/NNS)
  clustering/VBG
  ./.) 


>> Noun Phrases are: 
 ['An unsupervised learning task', 'many applications communications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('task', 'task'), ('found', 'found'), ('many', 'mani'), ('applications', 'applic'), ('communications', 'commun'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('task', 'task'), ('found', 'found'), ('many', 'mani'), ('applications', 'applic'), ('communications', 'communic'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('task', 'task'), ('found', 'found'), ('many', 'many'), ('applications', 'application'), ('communications', 'communication'), ('clustering', 'clustering'), ('.', '.')]



============================ Sentence 549 =============================

For example, in [76], clustering is used to support radio resource allocation in a heterogeneous network. 


>> Tokens are: 
 ['For', 'example', ',', '[', '76', ']', ',', 'clustering', 'used', 'support', 'radio', 'resource', 'allocation', 'heterogeneous', 'network', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', '['), ('[', '76'), ('76', ']'), (']', ','), (',', 'clustering'), ('clustering', 'used'), ('used', 'support'), ('support', 'radio'), ('radio', 'resource'), ('resource', 'allocation'), ('allocation', 'heterogeneous'), ('heterogeneous', 'network'), ('network', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', '['), (',', '[', '76'), ('[', '76', ']'), ('76', ']', ','), (']', ',', 'clustering'), (',', 'clustering', 'used'), ('clustering', 'used', 'support'), ('used', 'support', 'radio'), ('support', 'radio', 'resource'), ('radio', 'resource', 'allocation'), ('resource', 'allocation', 'heterogeneous'), ('allocation', 'heterogeneous', 'network'), ('heterogeneous', 'network', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('[', 'VBZ'), ('76', 'CD'), (']', 'NN'), (',', ','), ('clustering', 'VBG'), ('used', 'VBN'), ('support', 'NN'), ('radio', 'NN'), ('resource', 'NN'), ('allocation', 'NN'), ('heterogeneous', 'JJ'), ('network', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  [/VBZ
  76/CD
  (NP ]/NN)
  ,/,
  clustering/VBG
  used/VBN
  (NP support/NN radio/NN resource/NN allocation/NN)
  (NP heterogeneous/JJ network/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', ']', 'support radio resource allocation', 'heterogeneous network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('clustering', 'cluster'), ('used', 'use'), ('support', 'support'), ('radio', 'radio'), ('resource', 'resourc'), ('allocation', 'alloc'), ('heterogeneous', 'heterogen'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('clustering', 'cluster'), ('used', 'use'), ('support', 'support'), ('radio', 'radio'), ('resource', 'resourc'), ('allocation', 'alloc'), ('heterogeneous', 'heterogen'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('clustering', 'clustering'), ('used', 'used'), ('support', 'support'), ('radio', 'radio'), ('resource', 'resource'), ('allocation', 'allocation'), ('heterogeneous', 'heterogeneous'), ('network', 'network'), ('.', '.')]



============================ Sentence 550 =============================

B. 


>> Tokens are: 
 ['B', '.']

>> Bigrams are: 
 [('B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('.', '.')]

 (S (NP B/NNP) ./.) 


>> Noun Phrases are: 
 ['B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('B', 'B'), ('.', '.')]



============================ Sentence 551 =============================

At the Cloud  (1) Network Layer: Another typical application of clustering is to enable hierarchical clustering for routing in self-organizing multi-hop networks. 


>> Tokens are: 
 ['At', 'Cloud', '(', '1', ')', 'Network', 'Layer', ':', 'Another', 'typical', 'application', 'clustering', 'enable', 'hierarchical', 'clustering', 'routing', 'self-organizing', 'multi-hop', 'networks', '.']

>> Bigrams are: 
 [('At', 'Cloud'), ('Cloud', '('), ('(', '1'), ('1', ')'), (')', 'Network'), ('Network', 'Layer'), ('Layer', ':'), (':', 'Another'), ('Another', 'typical'), ('typical', 'application'), ('application', 'clustering'), ('clustering', 'enable'), ('enable', 'hierarchical'), ('hierarchical', 'clustering'), ('clustering', 'routing'), ('routing', 'self-organizing'), ('self-organizing', 'multi-hop'), ('multi-hop', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('At', 'Cloud', '('), ('Cloud', '(', '1'), ('(', '1', ')'), ('1', ')', 'Network'), (')', 'Network', 'Layer'), ('Network', 'Layer', ':'), ('Layer', ':', 'Another'), (':', 'Another', 'typical'), ('Another', 'typical', 'application'), ('typical', 'application', 'clustering'), ('application', 'clustering', 'enable'), ('clustering', 'enable', 'hierarchical'), ('enable', 'hierarchical', 'clustering'), ('hierarchical', 'clustering', 'routing'), ('clustering', 'routing', 'self-organizing'), ('routing', 'self-organizing', 'multi-hop'), ('self-organizing', 'multi-hop', 'networks'), ('multi-hop', 'networks', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('Cloud', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')'), ('Network', 'NNP'), ('Layer', 'NNP'), (':', ':'), ('Another', 'DT'), ('typical', 'JJ'), ('application', 'NN'), ('clustering', 'VBG'), ('enable', 'JJ'), ('hierarchical', 'JJ'), ('clustering', 'VBG'), ('routing', 'VBG'), ('self-organizing', 'JJ'), ('multi-hop', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  At/IN
  (NP Cloud/NNP)
  (/(
  1/CD
  )/)
  (NP Network/NNP Layer/NNP)
  :/:
  (NP Another/DT typical/JJ application/NN)
  clustering/VBG
  enable/JJ
  hierarchical/JJ
  clustering/VBG
  routing/VBG
  (NP self-organizing/JJ multi-hop/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Cloud', 'Network Layer', 'Another typical application', 'self-organizing multi-hop networks']

>> Named Entities are: 
 [('GPE', 'Cloud'), ('PERSON', 'Network Layer')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('Cloud', 'cloud'), ('(', '('), ('1', '1'), (')', ')'), ('Network', 'network'), ('Layer', 'layer'), (':', ':'), ('Another', 'anoth'), ('typical', 'typic'), ('application', 'applic'), ('clustering', 'cluster'), ('enable', 'enabl'), ('hierarchical', 'hierarch'), ('clustering', 'cluster'), ('routing', 'rout'), ('self-organizing', 'self-organ'), ('multi-hop', 'multi-hop'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('Cloud', 'cloud'), ('(', '('), ('1', '1'), (')', ')'), ('Network', 'network'), ('Layer', 'layer'), (':', ':'), ('Another', 'anoth'), ('typical', 'typic'), ('application', 'applic'), ('clustering', 'cluster'), ('enable', 'enabl'), ('hierarchical', 'hierarch'), ('clustering', 'cluster'), ('routing', 'rout'), ('self-organizing', 'self-organ'), ('multi-hop', 'multi-hop'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('Cloud', 'Cloud'), ('(', '('), ('1', '1'), (')', ')'), ('Network', 'Network'), ('Layer', 'Layer'), (':', ':'), ('Another', 'Another'), ('typical', 'typical'), ('application', 'application'), ('clustering', 'clustering'), ('enable', 'enable'), ('hierarchical', 'hierarchical'), ('clustering', 'clustering'), ('routing', 'routing'), ('self-organizing', 'self-organizing'), ('multi-hop', 'multi-hop'), ('networks', 'network'), ('.', '.')]



============================ Sentence 552 =============================

Thanks to cluster- ing, routing can be carried out more efficiently by routing  17    first at the level of clusters, and then locally within each cluster [77]. 


>> Tokens are: 
 ['Thanks', 'cluster-', 'ing', ',', 'routing', 'carried', 'efficiently', 'routing', '17', 'first', 'level', 'clusters', ',', 'locally', 'within', 'cluster', '[', '77', ']', '.']

>> Bigrams are: 
 [('Thanks', 'cluster-'), ('cluster-', 'ing'), ('ing', ','), (',', 'routing'), ('routing', 'carried'), ('carried', 'efficiently'), ('efficiently', 'routing'), ('routing', '17'), ('17', 'first'), ('first', 'level'), ('level', 'clusters'), ('clusters', ','), (',', 'locally'), ('locally', 'within'), ('within', 'cluster'), ('cluster', '['), ('[', '77'), ('77', ']'), (']', '.')]

>> Trigrams are: 
 [('Thanks', 'cluster-', 'ing'), ('cluster-', 'ing', ','), ('ing', ',', 'routing'), (',', 'routing', 'carried'), ('routing', 'carried', 'efficiently'), ('carried', 'efficiently', 'routing'), ('efficiently', 'routing', '17'), ('routing', '17', 'first'), ('17', 'first', 'level'), ('first', 'level', 'clusters'), ('level', 'clusters', ','), ('clusters', ',', 'locally'), (',', 'locally', 'within'), ('locally', 'within', 'cluster'), ('within', 'cluster', '['), ('cluster', '[', '77'), ('[', '77', ']'), ('77', ']', '.')]

>> POS Tags are: 
 [('Thanks', 'NNS'), ('cluster-', 'JJ'), ('ing', 'NN'), (',', ','), ('routing', 'VBG'), ('carried', 'VBN'), ('efficiently', 'RB'), ('routing', 'VBG'), ('17', 'CD'), ('first', 'JJ'), ('level', 'NN'), ('clusters', 'NNS'), (',', ','), ('locally', 'RB'), ('within', 'IN'), ('cluster', 'NN'), ('[', 'VBP'), ('77', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Thanks/NNS)
  (NP cluster-/JJ ing/NN)
  ,/,
  routing/VBG
  carried/VBN
  efficiently/RB
  routing/VBG
  17/CD
  (NP first/JJ level/NN clusters/NNS)
  ,/,
  locally/RB
  within/IN
  (NP cluster/NN)
  [/VBP
  77/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Thanks', 'cluster- ing', 'first level clusters', 'cluster', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thanks', 'thank'), ('cluster-', 'cluster-'), ('ing', 'ing'), (',', ','), ('routing', 'rout'), ('carried', 'carri'), ('efficiently', 'effici'), ('routing', 'rout'), ('17', '17'), ('first', 'first'), ('level', 'level'), ('clusters', 'cluster'), (',', ','), ('locally', 'local'), ('within', 'within'), ('cluster', 'cluster'), ('[', '['), ('77', '77'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thanks', 'thank'), ('cluster-', 'cluster-'), ('ing', 'ing'), (',', ','), ('routing', 'rout'), ('carried', 'carri'), ('efficiently', 'effici'), ('routing', 'rout'), ('17', '17'), ('first', 'first'), ('level', 'level'), ('clusters', 'cluster'), (',', ','), ('locally', 'local'), ('within', 'within'), ('cluster', 'cluster'), ('[', '['), ('77', '77'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Thanks', 'Thanks'), ('cluster-', 'cluster-'), ('ing', 'ing'), (',', ','), ('routing', 'routing'), ('carried', 'carried'), ('efficiently', 'efficiently'), ('routing', 'routing'), ('17', '17'), ('first', 'first'), ('level', 'level'), ('clusters', 'cluster'), (',', ','), ('locally', 'locally'), ('within', 'within'), ('cluster', 'cluster'), ('[', '['), ('77', '77'), (']', ']'), ('.', '.')]



============================ Sentence 553 =============================

For an application of the unsupervised learning task of density estimation, consider the problem of detecting anomalies in networks. 


>> Tokens are: 
 ['For', 'application', 'unsupervised', 'learning', 'task', 'density', 'estimation', ',', 'consider', 'problem', 'detecting', 'anomalies', 'networks', '.']

>> Bigrams are: 
 [('For', 'application'), ('application', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'task'), ('task', 'density'), ('density', 'estimation'), ('estimation', ','), (',', 'consider'), ('consider', 'problem'), ('problem', 'detecting'), ('detecting', 'anomalies'), ('anomalies', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('For', 'application', 'unsupervised'), ('application', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'task'), ('learning', 'task', 'density'), ('task', 'density', 'estimation'), ('density', 'estimation', ','), ('estimation', ',', 'consider'), (',', 'consider', 'problem'), ('consider', 'problem', 'detecting'), ('problem', 'detecting', 'anomalies'), ('detecting', 'anomalies', 'networks'), ('anomalies', 'networks', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('application', 'NN'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('task', 'NN'), ('density', 'NN'), ('estimation', 'NN'), (',', ','), ('consider', 'VB'), ('problem', 'NN'), ('detecting', 'VBG'), ('anomalies', 'NNS'), ('networks', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP application/NN)
  (NP unsupervised/JJ learning/NN task/NN density/NN estimation/NN)
  ,/,
  consider/VB
  (NP problem/NN)
  detecting/VBG
  (NP anomalies/NNS networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['application', 'unsupervised learning task density estimation', 'problem', 'anomalies networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('application', 'applic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('task', 'task'), ('density', 'densiti'), ('estimation', 'estim'), (',', ','), ('consider', 'consid'), ('problem', 'problem'), ('detecting', 'detect'), ('anomalies', 'anomali'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('application', 'applic'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('task', 'task'), ('density', 'densiti'), ('estimation', 'estim'), (',', ','), ('consider', 'consid'), ('problem', 'problem'), ('detecting', 'detect'), ('anomalies', 'anomali'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('application', 'application'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('task', 'task'), ('density', 'density'), ('estimation', 'estimation'), (',', ','), ('consider', 'consider'), ('problem', 'problem'), ('detecting', 'detecting'), ('anomalies', 'anomaly'), ('networks', 'network'), ('.', '.')]



============================ Sentence 554 =============================

For instance, by learning the typical distribution of the features of a working link, one can identify malfunctioning ones. 


>> Tokens are: 
 ['For', 'instance', ',', 'learning', 'typical', 'distribution', 'features', 'working', 'link', ',', 'one', 'identify', 'malfunctioning', 'ones', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'learning'), ('learning', 'typical'), ('typical', 'distribution'), ('distribution', 'features'), ('features', 'working'), ('working', 'link'), ('link', ','), (',', 'one'), ('one', 'identify'), ('identify', 'malfunctioning'), ('malfunctioning', 'ones'), ('ones', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'learning'), (',', 'learning', 'typical'), ('learning', 'typical', 'distribution'), ('typical', 'distribution', 'features'), ('distribution', 'features', 'working'), ('features', 'working', 'link'), ('working', 'link', ','), ('link', ',', 'one'), (',', 'one', 'identify'), ('one', 'identify', 'malfunctioning'), ('identify', 'malfunctioning', 'ones'), ('malfunctioning', 'ones', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('learning', 'VBG'), ('typical', 'JJ'), ('distribution', 'NN'), ('features', 'NNS'), ('working', 'VBG'), ('link', 'NN'), (',', ','), ('one', 'CD'), ('identify', 'NN'), ('malfunctioning', 'VBG'), ('ones', 'NNS'), ('.', '.')]

 (S
  For/IN
  (NP instance/NN)
  ,/,
  learning/VBG
  (NP typical/JJ distribution/NN features/NNS)
  working/VBG
  (NP link/NN)
  ,/,
  one/CD
  (NP identify/NN)
  malfunctioning/VBG
  (NP ones/NNS)
  ./.) 


>> Noun Phrases are: 
 ['instance', 'typical distribution features', 'link', 'identify', 'ones']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('learning', 'learn'), ('typical', 'typic'), ('distribution', 'distribut'), ('features', 'featur'), ('working', 'work'), ('link', 'link'), (',', ','), ('one', 'one'), ('identify', 'identifi'), ('malfunctioning', 'malfunct'), ('ones', 'one'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('learning', 'learn'), ('typical', 'typic'), ('distribution', 'distribut'), ('features', 'featur'), ('working', 'work'), ('link', 'link'), (',', ','), ('one', 'one'), ('identify', 'identifi'), ('malfunctioning', 'malfunct'), ('ones', 'one'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('learning', 'learning'), ('typical', 'typical'), ('distribution', 'distribution'), ('features', 'feature'), ('working', 'working'), ('link', 'link'), (',', ','), ('one', 'one'), ('identify', 'identify'), ('malfunctioning', 'malfunctioning'), ('ones', 'one'), ('.', '.')]



============================ Sentence 555 =============================

This approach may be applied, e.g.-.-, to optical networks [54]. 


>> Tokens are: 
 ['This', 'approach', 'may', 'applied', ',', 'e.g.-.-', ',', 'optical', 'networks', '[', '54', ']', '.']

>> Bigrams are: 
 [('This', 'approach'), ('approach', 'may'), ('may', 'applied'), ('applied', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'optical'), ('optical', 'networks'), ('networks', '['), ('[', '54'), ('54', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'approach', 'may'), ('approach', 'may', 'applied'), ('may', 'applied', ','), ('applied', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'optical'), (',', 'optical', 'networks'), ('optical', 'networks', '['), ('networks', '[', '54'), ('[', '54', ']'), ('54', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('approach', 'NN'), ('may', 'MD'), ('applied', 'VB'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('optical', 'JJ'), ('networks', 'NNS'), ('[', 'VBP'), ('54', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP This/DT approach/NN)
  may/MD
  applied/VB
  ,/,
  e.g.-.-/JJ
  ,/,
  (NP optical/JJ networks/NNS)
  [/VBP
  54/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['This approach', 'optical networks', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('approach', 'approach'), ('may', 'may'), ('applied', 'appli'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('optical', 'optic'), ('networks', 'network'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('approach', 'approach'), ('may', 'may'), ('applied', 'appli'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('optical', 'optic'), ('networks', 'network'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('approach', 'approach'), ('may', 'may'), ('applied', 'applied'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('optical', 'optical'), ('networks', 'network'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]



============================ Sentence 556 =============================

(2) Application Layer: Finally, we point to two in- stances of unsupervised learning at the application layer that are usually carried out at data centers in the cloud. 


>> Tokens are: 
 ['(', '2', ')', 'Application', 'Layer', ':', 'Finally', ',', 'point', 'two', 'in-', 'stances', 'unsupervised', 'learning', 'application', 'layer', 'usually', 'carried', 'data', 'centers', 'cloud', '.']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'Application'), ('Application', 'Layer'), ('Layer', ':'), (':', 'Finally'), ('Finally', ','), (',', 'point'), ('point', 'two'), ('two', 'in-'), ('in-', 'stances'), ('stances', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'application'), ('application', 'layer'), ('layer', 'usually'), ('usually', 'carried'), ('carried', 'data'), ('data', 'centers'), ('centers', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'Application'), (')', 'Application', 'Layer'), ('Application', 'Layer', ':'), ('Layer', ':', 'Finally'), (':', 'Finally', ','), ('Finally', ',', 'point'), (',', 'point', 'two'), ('point', 'two', 'in-'), ('two', 'in-', 'stances'), ('in-', 'stances', 'unsupervised'), ('stances', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'application'), ('learning', 'application', 'layer'), ('application', 'layer', 'usually'), ('layer', 'usually', 'carried'), ('usually', 'carried', 'data'), ('carried', 'data', 'centers'), ('data', 'centers', 'cloud'), ('centers', 'cloud', '.')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('Application', 'NNP'), ('Layer', 'NNP'), (':', ':'), ('Finally', 'RB'), (',', ','), ('point', 'NN'), ('two', 'CD'), ('in-', 'JJ'), ('stances', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('application', 'NN'), ('layer', 'NN'), ('usually', 'RB'), ('carried', 'VBN'), ('data', 'NN'), ('centers', 'NNS'), ('cloud', 'VBP'), ('.', '.')]

 (S
  (/(
  2/CD
  )/)
  (NP Application/NNP Layer/NNP)
  :/:
  Finally/RB
  ,/,
  (NP point/NN)
  two/CD
  (NP in-/JJ stances/NNS)
  unsupervised/VBD
  learning/VBG
  (NP application/NN layer/NN)
  usually/RB
  carried/VBN
  (NP data/NN centers/NNS)
  cloud/VBP
  ./.) 


>> Noun Phrases are: 
 ['Application Layer', 'point', 'in- stances', 'application layer', 'data centers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'applic'), ('Layer', 'layer'), (':', ':'), ('Finally', 'final'), (',', ','), ('point', 'point'), ('two', 'two'), ('in-', 'in-'), ('stances', 'stanc'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('application', 'applic'), ('layer', 'layer'), ('usually', 'usual'), ('carried', 'carri'), ('data', 'data'), ('centers', 'center'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'applic'), ('Layer', 'layer'), (':', ':'), ('Finally', 'final'), (',', ','), ('point', 'point'), ('two', 'two'), ('in-', 'in-'), ('stances', 'stanc'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('application', 'applic'), ('layer', 'layer'), ('usually', 'usual'), ('carried', 'carri'), ('data', 'data'), ('centers', 'center'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('Application', 'Application'), ('Layer', 'Layer'), (':', ':'), ('Finally', 'Finally'), (',', ','), ('point', 'point'), ('two', 'two'), ('in-', 'in-'), ('stances', 'stance'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('application', 'application'), ('layer', 'layer'), ('usually', 'usually'), ('carried', 'carried'), ('data', 'data'), ('centers', 'center'), ('cloud', 'cloud'), ('.', '.')]



============================ Sentence 557 =============================

These tasks follow a conceptually different approach as they are based on discovering structure in graphs. 


>> Tokens are: 
 ['These', 'tasks', 'follow', 'conceptually', 'different', 'approach', 'based', 'discovering', 'structure', 'graphs', '.']

>> Bigrams are: 
 [('These', 'tasks'), ('tasks', 'follow'), ('follow', 'conceptually'), ('conceptually', 'different'), ('different', 'approach'), ('approach', 'based'), ('based', 'discovering'), ('discovering', 'structure'), ('structure', 'graphs'), ('graphs', '.')]

>> Trigrams are: 
 [('These', 'tasks', 'follow'), ('tasks', 'follow', 'conceptually'), ('follow', 'conceptually', 'different'), ('conceptually', 'different', 'approach'), ('different', 'approach', 'based'), ('approach', 'based', 'discovering'), ('based', 'discovering', 'structure'), ('discovering', 'structure', 'graphs'), ('structure', 'graphs', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('tasks', 'NNS'), ('follow', 'VBP'), ('conceptually', 'RB'), ('different', 'JJ'), ('approach', 'NN'), ('based', 'VBN'), ('discovering', 'JJ'), ('structure', 'NN'), ('graphs', 'NN'), ('.', '.')]

 (S
  (NP These/DT tasks/NNS)
  follow/VBP
  conceptually/RB
  (NP different/JJ approach/NN)
  based/VBN
  (NP discovering/JJ structure/NN graphs/NN)
  ./.) 


>> Noun Phrases are: 
 ['These tasks', 'different approach', 'discovering structure graphs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('tasks', 'task'), ('follow', 'follow'), ('conceptually', 'conceptu'), ('different', 'differ'), ('approach', 'approach'), ('based', 'base'), ('discovering', 'discov'), ('structure', 'structur'), ('graphs', 'graph'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('tasks', 'task'), ('follow', 'follow'), ('conceptually', 'conceptu'), ('different', 'differ'), ('approach', 'approach'), ('based', 'base'), ('discovering', 'discov'), ('structure', 'structur'), ('graphs', 'graph'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('tasks', 'task'), ('follow', 'follow'), ('conceptually', 'conceptually'), ('different', 'different'), ('approach', 'approach'), ('based', 'based'), ('discovering', 'discovering'), ('structure', 'structure'), ('graphs', 'graph'), ('.', '.')]



============================ Sentence 558 =============================

The first problem is community detection in social networks. 


>> Tokens are: 
 ['The', 'first', 'problem', 'community', 'detection', 'social', 'networks', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'problem'), ('problem', 'community'), ('community', 'detection'), ('detection', 'social'), ('social', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('The', 'first', 'problem'), ('first', 'problem', 'community'), ('problem', 'community', 'detection'), ('community', 'detection', 'social'), ('detection', 'social', 'networks'), ('social', 'networks', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('problem', 'NN'), ('community', 'NN'), ('detection', 'NN'), ('social', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP The/DT first/JJ problem/NN community/NN detection/NN)
  (NP social/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The first problem community detection', 'social networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('problem', 'problem'), ('community', 'commun'), ('detection', 'detect'), ('social', 'social'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('problem', 'problem'), ('community', 'communiti'), ('detection', 'detect'), ('social', 'social'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('problem', 'problem'), ('community', 'community'), ('detection', 'detection'), ('social', 'social'), ('networks', 'network'), ('.', '.')]



============================ Sentence 559 =============================

This amounts to a clustering problem whereby one wishes to isolate communities of nodes in a social graph on the basis of the observation of a realization of the underlying true graph of relationships [78]. 


>> Tokens are: 
 ['This', 'amounts', 'clustering', 'problem', 'whereby', 'one', 'wishes', 'isolate', 'communities', 'nodes', 'social', 'graph', 'basis', 'observation', 'realization', 'underlying', 'true', 'graph', 'relationships', '[', '78', ']', '.']

>> Bigrams are: 
 [('This', 'amounts'), ('amounts', 'clustering'), ('clustering', 'problem'), ('problem', 'whereby'), ('whereby', 'one'), ('one', 'wishes'), ('wishes', 'isolate'), ('isolate', 'communities'), ('communities', 'nodes'), ('nodes', 'social'), ('social', 'graph'), ('graph', 'basis'), ('basis', 'observation'), ('observation', 'realization'), ('realization', 'underlying'), ('underlying', 'true'), ('true', 'graph'), ('graph', 'relationships'), ('relationships', '['), ('[', '78'), ('78', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'amounts', 'clustering'), ('amounts', 'clustering', 'problem'), ('clustering', 'problem', 'whereby'), ('problem', 'whereby', 'one'), ('whereby', 'one', 'wishes'), ('one', 'wishes', 'isolate'), ('wishes', 'isolate', 'communities'), ('isolate', 'communities', 'nodes'), ('communities', 'nodes', 'social'), ('nodes', 'social', 'graph'), ('social', 'graph', 'basis'), ('graph', 'basis', 'observation'), ('basis', 'observation', 'realization'), ('observation', 'realization', 'underlying'), ('realization', 'underlying', 'true'), ('underlying', 'true', 'graph'), ('true', 'graph', 'relationships'), ('graph', 'relationships', '['), ('relationships', '[', '78'), ('[', '78', ']'), ('78', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('amounts', 'VBZ'), ('clustering', 'VBG'), ('problem', 'NN'), ('whereby', 'WRB'), ('one', 'CD'), ('wishes', 'VBZ'), ('isolate', 'JJ'), ('communities', 'NNS'), ('nodes', 'IN'), ('social', 'JJ'), ('graph', 'JJ'), ('basis', 'NN'), ('observation', 'NN'), ('realization', 'NN'), ('underlying', 'VBG'), ('true', 'JJ'), ('graph', 'JJ'), ('relationships', 'NNS'), ('[', 'VBP'), ('78', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  This/DT
  amounts/VBZ
  clustering/VBG
  (NP problem/NN)
  whereby/WRB
  one/CD
  wishes/VBZ
  (NP isolate/JJ communities/NNS)
  nodes/IN
  (NP social/JJ graph/JJ basis/NN observation/NN realization/NN)
  underlying/VBG
  (NP true/JJ graph/JJ relationships/NNS)
  [/VBP
  78/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['problem', 'isolate communities', 'social graph basis observation realization', 'true graph relationships', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('amounts', 'amount'), ('clustering', 'cluster'), ('problem', 'problem'), ('whereby', 'wherebi'), ('one', 'one'), ('wishes', 'wish'), ('isolate', 'isol'), ('communities', 'commun'), ('nodes', 'node'), ('social', 'social'), ('graph', 'graph'), ('basis', 'basi'), ('observation', 'observ'), ('realization', 'realiz'), ('underlying', 'underli'), ('true', 'true'), ('graph', 'graph'), ('relationships', 'relationship'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('amounts', 'amount'), ('clustering', 'cluster'), ('problem', 'problem'), ('whereby', 'wherebi'), ('one', 'one'), ('wishes', 'wish'), ('isolate', 'isol'), ('communities', 'communiti'), ('nodes', 'node'), ('social', 'social'), ('graph', 'graph'), ('basis', 'basi'), ('observation', 'observ'), ('realization', 'realize'), ('underlying', 'under'), ('true', 'true'), ('graph', 'graph'), ('relationships', 'relationship'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('amounts', 'amount'), ('clustering', 'clustering'), ('problem', 'problem'), ('whereby', 'whereby'), ('one', 'one'), ('wishes', 'wish'), ('isolate', 'isolate'), ('communities', 'community'), ('nodes', 'node'), ('social', 'social'), ('graph', 'graph'), ('basis', 'basis'), ('observation', 'observation'), ('realization', 'realization'), ('underlying', 'underlying'), ('true', 'true'), ('graph', 'graph'), ('relationships', 'relationship'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]



============================ Sentence 560 =============================

Another application is the ranking of webpages based on the graph of hyperlinks carried out by PageRank [19], [79]. 


>> Tokens are: 
 ['Another', 'application', 'ranking', 'webpages', 'based', 'graph', 'hyperlinks', 'carried', 'PageRank', '[', '19', ']', ',', '[', '79', ']', '.']

>> Bigrams are: 
 [('Another', 'application'), ('application', 'ranking'), ('ranking', 'webpages'), ('webpages', 'based'), ('based', 'graph'), ('graph', 'hyperlinks'), ('hyperlinks', 'carried'), ('carried', 'PageRank'), ('PageRank', '['), ('[', '19'), ('19', ']'), (']', ','), (',', '['), ('[', '79'), ('79', ']'), (']', '.')]

>> Trigrams are: 
 [('Another', 'application', 'ranking'), ('application', 'ranking', 'webpages'), ('ranking', 'webpages', 'based'), ('webpages', 'based', 'graph'), ('based', 'graph', 'hyperlinks'), ('graph', 'hyperlinks', 'carried'), ('hyperlinks', 'carried', 'PageRank'), ('carried', 'PageRank', '['), ('PageRank', '[', '19'), ('[', '19', ']'), ('19', ']', ','), (']', ',', '['), (',', '[', '79'), ('[', '79', ']'), ('79', ']', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('application', 'NN'), ('ranking', 'VBG'), ('webpages', 'NNS'), ('based', 'VBN'), ('graph', 'JJ'), ('hyperlinks', 'NNS'), ('carried', 'VBD'), ('PageRank', 'NNP'), ('[', 'NNP'), ('19', 'CD'), (']', 'NNP'), (',', ','), ('[', 'VBD'), ('79', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP Another/DT application/NN)
  ranking/VBG
  (NP webpages/NNS)
  based/VBN
  (NP graph/JJ hyperlinks/NNS)
  carried/VBD
  (NP PageRank/NNP [/NNP)
  19/CD
  (NP ]/NNP)
  ,/,
  [/VBD
  79/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['Another application', 'webpages', 'graph hyperlinks', 'PageRank [', ']', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'PageRank')] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('application', 'applic'), ('ranking', 'rank'), ('webpages', 'webpag'), ('based', 'base'), ('graph', 'graph'), ('hyperlinks', 'hyperlink'), ('carried', 'carri'), ('PageRank', 'pagerank'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('79', '79'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('application', 'applic'), ('ranking', 'rank'), ('webpages', 'webpag'), ('based', 'base'), ('graph', 'graph'), ('hyperlinks', 'hyperlink'), ('carried', 'carri'), ('PageRank', 'pagerank'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('79', '79'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('application', 'application'), ('ranking', 'ranking'), ('webpages', 'webpage'), ('based', 'based'), ('graph', 'graph'), ('hyperlinks', 'hyperlink'), ('carried', 'carried'), ('PageRank', 'PageRank'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('[', '['), ('79', '79'), (']', ']'), ('.', '.')]



============================ Sentence 561 =============================

VII. 


>> Tokens are: 
 ['VII', '.']

>> Bigrams are: 
 [('VII', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('VII', 'NNP'), ('.', '.')]

 (S (NP VII/NNP) ./.) 


>> Noun Phrases are: 
 ['VII']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('VII', 'vii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('VII', 'vii'), ('.', '.')]

>> Lemmatization: 
 [('VII', 'VII'), ('.', '.')]



============================ Sentence 562 =============================

CONCLUDING REMARKS  In the presence of modelling or algorithmic deficien- cies in the conventional engineering flow based on the acquisition of domain knowledge, data-driven machine learning tools can speed up the design cycle, reduce the complexity and cost of implementation, and improve over the performance of known algorithms. 


>> Tokens are: 
 ['CONCLUDING', 'REMARKS', 'In', 'presence', 'modelling', 'algorithmic', 'deficien-', 'cies', 'conventional', 'engineering', 'flow', 'based', 'acquisition', 'domain', 'knowledge', ',', 'data-driven', 'machine', 'learning', 'tools', 'speed', 'design', 'cycle', ',', 'reduce', 'complexity', 'cost', 'implementation', ',', 'improve', 'performance', 'known', 'algorithms', '.']

>> Bigrams are: 
 [('CONCLUDING', 'REMARKS'), ('REMARKS', 'In'), ('In', 'presence'), ('presence', 'modelling'), ('modelling', 'algorithmic'), ('algorithmic', 'deficien-'), ('deficien-', 'cies'), ('cies', 'conventional'), ('conventional', 'engineering'), ('engineering', 'flow'), ('flow', 'based'), ('based', 'acquisition'), ('acquisition', 'domain'), ('domain', 'knowledge'), ('knowledge', ','), (',', 'data-driven'), ('data-driven', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', 'speed'), ('speed', 'design'), ('design', 'cycle'), ('cycle', ','), (',', 'reduce'), ('reduce', 'complexity'), ('complexity', 'cost'), ('cost', 'implementation'), ('implementation', ','), (',', 'improve'), ('improve', 'performance'), ('performance', 'known'), ('known', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('CONCLUDING', 'REMARKS', 'In'), ('REMARKS', 'In', 'presence'), ('In', 'presence', 'modelling'), ('presence', 'modelling', 'algorithmic'), ('modelling', 'algorithmic', 'deficien-'), ('algorithmic', 'deficien-', 'cies'), ('deficien-', 'cies', 'conventional'), ('cies', 'conventional', 'engineering'), ('conventional', 'engineering', 'flow'), ('engineering', 'flow', 'based'), ('flow', 'based', 'acquisition'), ('based', 'acquisition', 'domain'), ('acquisition', 'domain', 'knowledge'), ('domain', 'knowledge', ','), ('knowledge', ',', 'data-driven'), (',', 'data-driven', 'machine'), ('data-driven', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', 'speed'), ('tools', 'speed', 'design'), ('speed', 'design', 'cycle'), ('design', 'cycle', ','), ('cycle', ',', 'reduce'), (',', 'reduce', 'complexity'), ('reduce', 'complexity', 'cost'), ('complexity', 'cost', 'implementation'), ('cost', 'implementation', ','), ('implementation', ',', 'improve'), (',', 'improve', 'performance'), ('improve', 'performance', 'known'), ('performance', 'known', 'algorithms'), ('known', 'algorithms', '.')]

>> POS Tags are: 
 [('CONCLUDING', 'NN'), ('REMARKS', 'NNP'), ('In', 'IN'), ('presence', 'NN'), ('modelling', 'VBG'), ('algorithmic', 'JJ'), ('deficien-', 'JJ'), ('cies', 'NNS'), ('conventional', 'JJ'), ('engineering', 'NN'), ('flow', 'NN'), ('based', 'VBN'), ('acquisition', 'NN'), ('domain', 'NN'), ('knowledge', 'NN'), (',', ','), ('data-driven', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('speed', 'VBP'), ('design', 'NN'), ('cycle', 'NN'), (',', ','), ('reduce', 'VB'), ('complexity', 'NN'), ('cost', 'NN'), ('implementation', 'NN'), (',', ','), ('improve', 'VB'), ('performance', 'NN'), ('known', 'VBN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  (NP CONCLUDING/NN REMARKS/NNP)
  In/IN
  (NP presence/NN)
  modelling/VBG
  (NP algorithmic/JJ deficien-/JJ cies/NNS)
  (NP conventional/JJ engineering/NN flow/NN)
  based/VBN
  (NP acquisition/NN domain/NN knowledge/NN)
  ,/,
  (NP data-driven/JJ machine/NN learning/NN tools/NNS)
  speed/VBP
  (NP design/NN cycle/NN)
  ,/,
  reduce/VB
  (NP complexity/NN cost/NN implementation/NN)
  ,/,
  improve/VB
  (NP performance/NN)
  known/VBN
  (NP algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['CONCLUDING REMARKS', 'presence', 'algorithmic deficien- cies', 'conventional engineering flow', 'acquisition domain knowledge', 'data-driven machine learning tools', 'design cycle', 'complexity cost implementation', 'performance', 'algorithms']

>> Named Entities are: 
 [('ORGANIZATION', 'CONCLUDING'), ('ORGANIZATION', 'REMARKS')] 

>> Stemming using Porter Stemmer: 
 [('CONCLUDING', 'conclud'), ('REMARKS', 'remark'), ('In', 'in'), ('presence', 'presenc'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficien-', 'deficien-'), ('cies', 'cie'), ('conventional', 'convent'), ('engineering', 'engin'), ('flow', 'flow'), ('based', 'base'), ('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), (',', ','), ('data-driven', 'data-driven'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('speed', 'speed'), ('design', 'design'), ('cycle', 'cycl'), (',', ','), ('reduce', 'reduc'), ('complexity', 'complex'), ('cost', 'cost'), ('implementation', 'implement'), (',', ','), ('improve', 'improv'), ('performance', 'perform'), ('known', 'known'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CONCLUDING', 'conclud'), ('REMARKS', 'remark'), ('In', 'in'), ('presence', 'presenc'), ('modelling', 'model'), ('algorithmic', 'algorithm'), ('deficien-', 'deficien-'), ('cies', 'cie'), ('conventional', 'convent'), ('engineering', 'engin'), ('flow', 'flow'), ('based', 'base'), ('acquisition', 'acquisit'), ('domain', 'domain'), ('knowledge', 'knowledg'), (',', ','), ('data-driven', 'data-driven'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('speed', 'speed'), ('design', 'design'), ('cycle', 'cycl'), (',', ','), ('reduce', 'reduc'), ('complexity', 'complex'), ('cost', 'cost'), ('implementation', 'implement'), (',', ','), ('improve', 'improv'), ('performance', 'perform'), ('known', 'known'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('CONCLUDING', 'CONCLUDING'), ('REMARKS', 'REMARKS'), ('In', 'In'), ('presence', 'presence'), ('modelling', 'modelling'), ('algorithmic', 'algorithmic'), ('deficien-', 'deficien-'), ('cies', 'cies'), ('conventional', 'conventional'), ('engineering', 'engineering'), ('flow', 'flow'), ('based', 'based'), ('acquisition', 'acquisition'), ('domain', 'domain'), ('knowledge', 'knowledge'), (',', ','), ('data-driven', 'data-driven'), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('speed', 'speed'), ('design', 'design'), ('cycle', 'cycle'), (',', ','), ('reduce', 'reduce'), ('complexity', 'complexity'), ('cost', 'cost'), ('implementation', 'implementation'), (',', ','), ('improve', 'improve'), ('performance', 'performance'), ('known', 'known'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 563 =============================

To this end, machine learning can leverage the availability of data and computing resources in many engineering domains, including modern communication systems. 


>> Tokens are: 
 ['To', 'end', ',', 'machine', 'learning', 'leverage', 'availability', 'data', 'computing', 'resources', 'many', 'engineering', 'domains', ',', 'including', 'modern', 'communication', 'systems', '.']

>> Bigrams are: 
 [('To', 'end'), ('end', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'leverage'), ('leverage', 'availability'), ('availability', 'data'), ('data', 'computing'), ('computing', 'resources'), ('resources', 'many'), ('many', 'engineering'), ('engineering', 'domains'), ('domains', ','), (',', 'including'), ('including', 'modern'), ('modern', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('To', 'end', ','), ('end', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'leverage'), ('learning', 'leverage', 'availability'), ('leverage', 'availability', 'data'), ('availability', 'data', 'computing'), ('data', 'computing', 'resources'), ('computing', 'resources', 'many'), ('resources', 'many', 'engineering'), ('many', 'engineering', 'domains'), ('engineering', 'domains', ','), ('domains', ',', 'including'), (',', 'including', 'modern'), ('including', 'modern', 'communication'), ('modern', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('end', 'VB'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('leverage', 'NN'), ('availability', 'NN'), ('data', 'NNS'), ('computing', 'VBG'), ('resources', 'NNS'), ('many', 'JJ'), ('engineering', 'NN'), ('domains', 'NNS'), (',', ','), ('including', 'VBG'), ('modern', 'JJ'), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  To/TO
  end/VB
  ,/,
  (NP machine/NN learning/NN leverage/NN availability/NN data/NNS)
  computing/VBG
  (NP resources/NNS)
  (NP many/JJ engineering/NN domains/NNS)
  ,/,
  including/VBG
  (NP modern/JJ communication/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['machine learning leverage availability data', 'resources', 'many engineering domains', 'modern communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('leverage', 'leverag'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), ('many', 'mani'), ('engineering', 'engin'), ('domains', 'domain'), (',', ','), ('including', 'includ'), ('modern', 'modern'), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('end', 'end'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('leverage', 'leverag'), ('availability', 'avail'), ('data', 'data'), ('computing', 'comput'), ('resources', 'resourc'), ('many', 'mani'), ('engineering', 'engin'), ('domains', 'domain'), (',', ','), ('including', 'includ'), ('modern', 'modern'), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('end', 'end'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('leverage', 'leverage'), ('availability', 'availability'), ('data', 'data'), ('computing', 'computing'), ('resources', 'resource'), ('many', 'many'), ('engineering', 'engineering'), ('domains', 'domain'), (',', ','), ('including', 'including'), ('modern', 'modern'), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]



============================ Sentence 564 =============================

Supervised, unsupervised, and reinforcement learning paradigms lend themselves to different tasks depending on the availabil- ity of examples of desired behaviour or of feedback. 


>> Tokens are: 
 ['Supervised', ',', 'unsupervised', ',', 'reinforcement', 'learning', 'paradigms', 'lend', 'different', 'tasks', 'depending', 'availabil-', 'ity', 'examples', 'desired', 'behaviour', 'feedback', '.']

>> Bigrams are: 
 [('Supervised', ','), (',', 'unsupervised'), ('unsupervised', ','), (',', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'paradigms'), ('paradigms', 'lend'), ('lend', 'different'), ('different', 'tasks'), ('tasks', 'depending'), ('depending', 'availabil-'), ('availabil-', 'ity'), ('ity', 'examples'), ('examples', 'desired'), ('desired', 'behaviour'), ('behaviour', 'feedback'), ('feedback', '.')]

>> Trigrams are: 
 [('Supervised', ',', 'unsupervised'), (',', 'unsupervised', ','), ('unsupervised', ',', 'reinforcement'), (',', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'paradigms'), ('learning', 'paradigms', 'lend'), ('paradigms', 'lend', 'different'), ('lend', 'different', 'tasks'), ('different', 'tasks', 'depending'), ('tasks', 'depending', 'availabil-'), ('depending', 'availabil-', 'ity'), ('availabil-', 'ity', 'examples'), ('ity', 'examples', 'desired'), ('examples', 'desired', 'behaviour'), ('desired', 'behaviour', 'feedback'), ('behaviour', 'feedback', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), (',', ','), ('unsupervised', 'JJ'), (',', ','), ('reinforcement', 'JJ'), ('learning', 'VBG'), ('paradigms', 'JJ'), ('lend', 'VBP'), ('different', 'JJ'), ('tasks', 'NNS'), ('depending', 'VBG'), ('availabil-', 'JJ'), ('ity', 'NN'), ('examples', 'NNS'), ('desired', 'VBD'), ('behaviour', 'JJ'), ('feedback', 'NN'), ('.', '.')]

 (S
  Supervised/VBN
  ,/,
  unsupervised/JJ
  ,/,
  reinforcement/JJ
  learning/VBG
  paradigms/JJ
  lend/VBP
  (NP different/JJ tasks/NNS)
  depending/VBG
  (NP availabil-/JJ ity/NN examples/NNS)
  desired/VBD
  (NP behaviour/JJ feedback/NN)
  ./.) 


>> Noun Phrases are: 
 ['different tasks', 'availabil- ity examples', 'behaviour feedback']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), (',', ','), ('unsupervised', 'unsupervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('lend', 'lend'), ('different', 'differ'), ('tasks', 'task'), ('depending', 'depend'), ('availabil-', 'availabil-'), ('ity', 'iti'), ('examples', 'exampl'), ('desired', 'desir'), ('behaviour', 'behaviour'), ('feedback', 'feedback'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), (',', ','), ('unsupervised', 'unsupervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('lend', 'lend'), ('different', 'differ'), ('tasks', 'task'), ('depending', 'depend'), ('availabil-', 'availabil-'), ('ity', 'iti'), ('examples', 'exampl'), ('desired', 'desir'), ('behaviour', 'behaviour'), ('feedback', 'feedback'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), (',', ','), ('unsupervised', 'unsupervised'), (',', ','), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('paradigms', 'paradigm'), ('lend', 'lend'), ('different', 'different'), ('tasks', 'task'), ('depending', 'depending'), ('availabil-', 'availabil-'), ('ity', 'ity'), ('examples', 'example'), ('desired', 'desired'), ('behaviour', 'behaviour'), ('feedback', 'feedback'), ('.', '.')]



============================ Sentence 565 =============================

The applicability of learning methods hinges on specific features of the problem under study, including its time variability and its tolerance to errors. 


>> Tokens are: 
 ['The', 'applicability', 'learning', 'methods', 'hinges', 'specific', 'features', 'problem', 'study', ',', 'including', 'time', 'variability', 'tolerance', 'errors', '.']

>> Bigrams are: 
 [('The', 'applicability'), ('applicability', 'learning'), ('learning', 'methods'), ('methods', 'hinges'), ('hinges', 'specific'), ('specific', 'features'), ('features', 'problem'), ('problem', 'study'), ('study', ','), (',', 'including'), ('including', 'time'), ('time', 'variability'), ('variability', 'tolerance'), ('tolerance', 'errors'), ('errors', '.')]

>> Trigrams are: 
 [('The', 'applicability', 'learning'), ('applicability', 'learning', 'methods'), ('learning', 'methods', 'hinges'), ('methods', 'hinges', 'specific'), ('hinges', 'specific', 'features'), ('specific', 'features', 'problem'), ('features', 'problem', 'study'), ('problem', 'study', ','), ('study', ',', 'including'), (',', 'including', 'time'), ('including', 'time', 'variability'), ('time', 'variability', 'tolerance'), ('variability', 'tolerance', 'errors'), ('tolerance', 'errors', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('applicability', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('hinges', 'NNS'), ('specific', 'JJ'), ('features', 'NNS'), ('problem', 'NN'), ('study', 'NN'), (',', ','), ('including', 'VBG'), ('time', 'NN'), ('variability', 'NN'), ('tolerance', 'NN'), ('errors', 'NNS'), ('.', '.')]

 (S
  (NP The/DT applicability/NN)
  learning/VBG
  (NP methods/NNS hinges/NNS)
  (NP specific/JJ features/NNS problem/NN study/NN)
  ,/,
  including/VBG
  (NP time/NN variability/NN tolerance/NN errors/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The applicability', 'methods hinges', 'specific features problem study', 'time variability tolerance errors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('applicability', 'applic'), ('learning', 'learn'), ('methods', 'method'), ('hinges', 'hing'), ('specific', 'specif'), ('features', 'featur'), ('problem', 'problem'), ('study', 'studi'), (',', ','), ('including', 'includ'), ('time', 'time'), ('variability', 'variabl'), ('tolerance', 'toler'), ('errors', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('applicability', 'applic'), ('learning', 'learn'), ('methods', 'method'), ('hinges', 'hing'), ('specific', 'specif'), ('features', 'featur'), ('problem', 'problem'), ('study', 'studi'), (',', ','), ('including', 'includ'), ('time', 'time'), ('variability', 'variabl'), ('tolerance', 'toler'), ('errors', 'error'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('applicability', 'applicability'), ('learning', 'learning'), ('methods', 'method'), ('hinges', 'hinge'), ('specific', 'specific'), ('features', 'feature'), ('problem', 'problem'), ('study', 'study'), (',', ','), ('including', 'including'), ('time', 'time'), ('variability', 'variability'), ('tolerance', 'tolerance'), ('errors', 'error'), ('.', '.')]



============================ Sentence 566 =============================

As such, a data- driven approach should not be considered as a universal solution, but rather as a useful tool whose suitability should be assessed on a case-by-case basis. 


>> Tokens are: 
 ['As', ',', 'data-', 'driven', 'approach', 'considered', 'universal', 'solution', ',', 'rather', 'useful', 'tool', 'whose', 'suitability', 'assessed', 'case-by-case', 'basis', '.']

>> Bigrams are: 
 [('As', ','), (',', 'data-'), ('data-', 'driven'), ('driven', 'approach'), ('approach', 'considered'), ('considered', 'universal'), ('universal', 'solution'), ('solution', ','), (',', 'rather'), ('rather', 'useful'), ('useful', 'tool'), ('tool', 'whose'), ('whose', 'suitability'), ('suitability', 'assessed'), ('assessed', 'case-by-case'), ('case-by-case', 'basis'), ('basis', '.')]

>> Trigrams are: 
 [('As', ',', 'data-'), (',', 'data-', 'driven'), ('data-', 'driven', 'approach'), ('driven', 'approach', 'considered'), ('approach', 'considered', 'universal'), ('considered', 'universal', 'solution'), ('universal', 'solution', ','), ('solution', ',', 'rather'), (',', 'rather', 'useful'), ('rather', 'useful', 'tool'), ('useful', 'tool', 'whose'), ('tool', 'whose', 'suitability'), ('whose', 'suitability', 'assessed'), ('suitability', 'assessed', 'case-by-case'), ('assessed', 'case-by-case', 'basis'), ('case-by-case', 'basis', '.')]

>> POS Tags are: 
 [('As', 'IN'), (',', ','), ('data-', 'JJ'), ('driven', 'NN'), ('approach', 'NN'), ('considered', 'VBD'), ('universal', 'JJ'), ('solution', 'NN'), (',', ','), ('rather', 'RB'), ('useful', 'JJ'), ('tool', 'NN'), ('whose', 'WP$'), ('suitability', 'NN'), ('assessed', 'VBD'), ('case-by-case', 'JJ'), ('basis', 'NN'), ('.', '.')]

 (S
  As/IN
  ,/,
  (NP data-/JJ driven/NN approach/NN)
  considered/VBD
  (NP universal/JJ solution/NN)
  ,/,
  rather/RB
  (NP useful/JJ tool/NN)
  whose/WP$
  (NP suitability/NN)
  assessed/VBD
  (NP case-by-case/JJ basis/NN)
  ./.) 


>> Noun Phrases are: 
 ['data- driven approach', 'universal solution', 'useful tool', 'suitability', 'case-by-case basis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), (',', ','), ('data-', 'data-'), ('driven', 'driven'), ('approach', 'approach'), ('considered', 'consid'), ('universal', 'univers'), ('solution', 'solut'), (',', ','), ('rather', 'rather'), ('useful', 'use'), ('tool', 'tool'), ('whose', 'whose'), ('suitability', 'suitabl'), ('assessed', 'assess'), ('case-by-case', 'case-by-cas'), ('basis', 'basi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), (',', ','), ('data-', 'data-'), ('driven', 'driven'), ('approach', 'approach'), ('considered', 'consid'), ('universal', 'univers'), ('solution', 'solut'), (',', ','), ('rather', 'rather'), ('useful', 'use'), ('tool', 'tool'), ('whose', 'whose'), ('suitability', 'suitabl'), ('assessed', 'assess'), ('case-by-case', 'case-by-cas'), ('basis', 'basi'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), (',', ','), ('data-', 'data-'), ('driven', 'driven'), ('approach', 'approach'), ('considered', 'considered'), ('universal', 'universal'), ('solution', 'solution'), (',', ','), ('rather', 'rather'), ('useful', 'useful'), ('tool', 'tool'), ('whose', 'whose'), ('suitability', 'suitability'), ('assessed', 'assessed'), ('case-by-case', 'case-by-case'), ('basis', 'basis'), ('.', '.')]



============================ Sentence 567 =============================

Further- more, machine learning tools allow for the integration of traditional model-based engineering techniques and of existing domain knowledge in order to leverage the complementarity and synergy of the two solutions (see Fig 2). 


>> Tokens are: 
 ['Further-', ',', 'machine', 'learning', 'tools', 'allow', 'integration', 'traditional', 'model-based', 'engineering', 'techniques', 'existing', 'domain', 'knowledge', 'order', 'leverage', 'complementarity', 'synergy', 'two', 'solutions', '(', 'see', 'Fig', '2', ')', '.']

>> Bigrams are: 
 [('Further-', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', 'allow'), ('allow', 'integration'), ('integration', 'traditional'), ('traditional', 'model-based'), ('model-based', 'engineering'), ('engineering', 'techniques'), ('techniques', 'existing'), ('existing', 'domain'), ('domain', 'knowledge'), ('knowledge', 'order'), ('order', 'leverage'), ('leverage', 'complementarity'), ('complementarity', 'synergy'), ('synergy', 'two'), ('two', 'solutions'), ('solutions', '('), ('(', 'see'), ('see', 'Fig'), ('Fig', '2'), ('2', ')'), (')', '.')]

>> Trigrams are: 
 [('Further-', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', 'allow'), ('tools', 'allow', 'integration'), ('allow', 'integration', 'traditional'), ('integration', 'traditional', 'model-based'), ('traditional', 'model-based', 'engineering'), ('model-based', 'engineering', 'techniques'), ('engineering', 'techniques', 'existing'), ('techniques', 'existing', 'domain'), ('existing', 'domain', 'knowledge'), ('domain', 'knowledge', 'order'), ('knowledge', 'order', 'leverage'), ('order', 'leverage', 'complementarity'), ('leverage', 'complementarity', 'synergy'), ('complementarity', 'synergy', 'two'), ('synergy', 'two', 'solutions'), ('two', 'solutions', '('), ('solutions', '(', 'see'), ('(', 'see', 'Fig'), ('see', 'Fig', '2'), ('Fig', '2', ')'), ('2', ')', '.')]

>> POS Tags are: 
 [('Further-', 'NNP'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('allow', 'VBP'), ('integration', 'NN'), ('traditional', 'JJ'), ('model-based', 'JJ'), ('engineering', 'NN'), ('techniques', 'NNS'), ('existing', 'VBG'), ('domain', 'NN'), ('knowledge', 'NN'), ('order', 'NN'), ('leverage', 'NN'), ('complementarity', 'NN'), ('synergy', 'VBP'), ('two', 'CD'), ('solutions', 'NNS'), ('(', '('), ('see', 'VB'), ('Fig', 'NNP'), ('2', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Further-/NNP)
  ,/,
  (NP machine/NN learning/NN tools/NNS)
  allow/VBP
  (NP integration/NN)
  (NP traditional/JJ model-based/JJ engineering/NN techniques/NNS)
  existing/VBG
  (NP domain/NN knowledge/NN order/NN leverage/NN complementarity/NN)
  synergy/VBP
  two/CD
  (NP solutions/NNS)
  (/(
  see/VB
  (NP Fig/NNP)
  2/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Further-', 'machine learning tools', 'integration', 'traditional model-based engineering techniques', 'domain knowledge order leverage complementarity', 'solutions', 'Fig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Further-', 'further-'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('allow', 'allow'), ('integration', 'integr'), ('traditional', 'tradit'), ('model-based', 'model-bas'), ('engineering', 'engin'), ('techniques', 'techniqu'), ('existing', 'exist'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('order', 'order'), ('leverage', 'leverag'), ('complementarity', 'complementar'), ('synergy', 'synergi'), ('two', 'two'), ('solutions', 'solut'), ('(', '('), ('see', 'see'), ('Fig', 'fig'), ('2', '2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Further-', 'further-'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('allow', 'allow'), ('integration', 'integr'), ('traditional', 'tradit'), ('model-based', 'model-bas'), ('engineering', 'engin'), ('techniques', 'techniqu'), ('existing', 'exist'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('order', 'order'), ('leverage', 'leverag'), ('complementarity', 'complementar'), ('synergy', 'synergi'), ('two', 'two'), ('solutions', 'solut'), ('(', '('), ('see', 'see'), ('Fig', 'fig'), ('2', '2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Further-', 'Further-'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('allow', 'allow'), ('integration', 'integration'), ('traditional', 'traditional'), ('model-based', 'model-based'), ('engineering', 'engineering'), ('techniques', 'technique'), ('existing', 'existing'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('order', 'order'), ('leverage', 'leverage'), ('complementarity', 'complementarity'), ('synergy', 'synergy'), ('two', 'two'), ('solutions', 'solution'), ('(', '('), ('see', 'see'), ('Fig', 'Fig'), ('2', '2'), (')', ')'), ('.', '.')]



============================ Sentence 568 =============================

As a final note, while this paper has focused on appli- cations of machine learning to communication systems, communication is conversely a key element of distributed machine learning platforms. 


>> Tokens are: 
 ['As', 'final', 'note', ',', 'paper', 'focused', 'appli-', 'cations', 'machine', 'learning', 'communication', 'systems', ',', 'communication', 'conversely', 'key', 'element', 'distributed', 'machine', 'learning', 'platforms', '.']

>> Bigrams are: 
 [('As', 'final'), ('final', 'note'), ('note', ','), (',', 'paper'), ('paper', 'focused'), ('focused', 'appli-'), ('appli-', 'cations'), ('cations', 'machine'), ('machine', 'learning'), ('learning', 'communication'), ('communication', 'systems'), ('systems', ','), (',', 'communication'), ('communication', 'conversely'), ('conversely', 'key'), ('key', 'element'), ('element', 'distributed'), ('distributed', 'machine'), ('machine', 'learning'), ('learning', 'platforms'), ('platforms', '.')]

>> Trigrams are: 
 [('As', 'final', 'note'), ('final', 'note', ','), ('note', ',', 'paper'), (',', 'paper', 'focused'), ('paper', 'focused', 'appli-'), ('focused', 'appli-', 'cations'), ('appli-', 'cations', 'machine'), ('cations', 'machine', 'learning'), ('machine', 'learning', 'communication'), ('learning', 'communication', 'systems'), ('communication', 'systems', ','), ('systems', ',', 'communication'), (',', 'communication', 'conversely'), ('communication', 'conversely', 'key'), ('conversely', 'key', 'element'), ('key', 'element', 'distributed'), ('element', 'distributed', 'machine'), ('distributed', 'machine', 'learning'), ('machine', 'learning', 'platforms'), ('learning', 'platforms', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('final', 'JJ'), ('note', 'NN'), (',', ','), ('paper', 'NN'), ('focused', 'VBD'), ('appli-', 'JJ'), ('cations', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('communication', 'NN'), ('systems', 'NNS'), (',', ','), ('communication', 'NN'), ('conversely', 'RB'), ('key', 'JJ'), ('element', 'NN'), ('distributed', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('platforms', 'NNS'), ('.', '.')]

 (S
  As/IN
  (NP final/JJ note/NN)
  ,/,
  (NP paper/NN)
  focused/VBD
  (NP appli-/JJ cations/NNS machine/NN)
  learning/VBG
  (NP communication/NN systems/NNS)
  ,/,
  (NP communication/NN)
  conversely/RB
  (NP key/JJ element/NN)
  distributed/VBN
  (NP machine/NN)
  learning/VBG
  (NP platforms/NNS)
  ./.) 


>> Noun Phrases are: 
 ['final note', 'paper', 'appli- cations machine', 'communication systems', 'communication', 'key element', 'machine', 'platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('final', 'final'), ('note', 'note'), (',', ','), ('paper', 'paper'), ('focused', 'focus'), ('appli-', 'appli-'), ('cations', 'cation'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'commun'), ('systems', 'system'), (',', ','), ('communication', 'commun'), ('conversely', 'convers'), ('key', 'key'), ('element', 'element'), ('distributed', 'distribut'), ('machine', 'machin'), ('learning', 'learn'), ('platforms', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('final', 'final'), ('note', 'note'), (',', ','), ('paper', 'paper'), ('focused', 'focus'), ('appli-', 'appli-'), ('cations', 'cation'), ('machine', 'machin'), ('learning', 'learn'), ('communication', 'communic'), ('systems', 'system'), (',', ','), ('communication', 'communic'), ('conversely', 'convers'), ('key', 'key'), ('element', 'element'), ('distributed', 'distribut'), ('machine', 'machin'), ('learning', 'learn'), ('platforms', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('final', 'final'), ('note', 'note'), (',', ','), ('paper', 'paper'), ('focused', 'focused'), ('appli-', 'appli-'), ('cations', 'cation'), ('machine', 'machine'), ('learning', 'learning'), ('communication', 'communication'), ('systems', 'system'), (',', ','), ('communication', 'communication'), ('conversely', 'conversely'), ('key', 'key'), ('element', 'element'), ('distributed', 'distributed'), ('machine', 'machine'), ('learning', 'learning'), ('platforms', 'platform'), ('.', '.')]



============================ Sentence 569 =============================

In these systems, learning tasks are carried out at distributed machines that need to coordinate via communication, e.g.-.-, by transferring the results of intermediate computations. 


>> Tokens are: 
 ['In', 'systems', ',', 'learning', 'tasks', 'carried', 'distributed', 'machines', 'need', 'coordinate', 'via', 'communication', ',', 'e.g.-.-', ',', 'transferring', 'results', 'intermediate', 'computations', '.']

>> Bigrams are: 
 [('In', 'systems'), ('systems', ','), (',', 'learning'), ('learning', 'tasks'), ('tasks', 'carried'), ('carried', 'distributed'), ('distributed', 'machines'), ('machines', 'need'), ('need', 'coordinate'), ('coordinate', 'via'), ('via', 'communication'), ('communication', ','), (',', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'transferring'), ('transferring', 'results'), ('results', 'intermediate'), ('intermediate', 'computations'), ('computations', '.')]

>> Trigrams are: 
 [('In', 'systems', ','), ('systems', ',', 'learning'), (',', 'learning', 'tasks'), ('learning', 'tasks', 'carried'), ('tasks', 'carried', 'distributed'), ('carried', 'distributed', 'machines'), ('distributed', 'machines', 'need'), ('machines', 'need', 'coordinate'), ('need', 'coordinate', 'via'), ('coordinate', 'via', 'communication'), ('via', 'communication', ','), ('communication', ',', 'e.g.-.-'), (',', 'e.g.-.-', ','), ('e.g.-.-', ',', 'transferring'), (',', 'transferring', 'results'), ('transferring', 'results', 'intermediate'), ('results', 'intermediate', 'computations'), ('intermediate', 'computations', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('systems', 'NNS'), (',', ','), ('learning', 'VBG'), ('tasks', 'NNS'), ('carried', 'VBD'), ('distributed', 'JJ'), ('machines', 'NNS'), ('need', 'VBP'), ('coordinate', 'JJ'), ('via', 'IN'), ('communication', 'NN'), (',', ','), ('e.g.-.-', 'JJ'), (',', ','), ('transferring', 'VBG'), ('results', 'NNS'), ('intermediate', 'JJ'), ('computations', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP systems/NNS)
  ,/,
  learning/VBG
  (NP tasks/NNS)
  carried/VBD
  (NP distributed/JJ machines/NNS)
  need/VBP
  coordinate/JJ
  via/IN
  (NP communication/NN)
  ,/,
  e.g.-.-/JJ
  ,/,
  transferring/VBG
  (NP results/NNS)
  (NP intermediate/JJ computations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['systems', 'tasks', 'distributed machines', 'communication', 'results', 'intermediate computations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('systems', 'system'), (',', ','), ('learning', 'learn'), ('tasks', 'task'), ('carried', 'carri'), ('distributed', 'distribut'), ('machines', 'machin'), ('need', 'need'), ('coordinate', 'coordin'), ('via', 'via'), ('communication', 'commun'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transferring', 'transfer'), ('results', 'result'), ('intermediate', 'intermedi'), ('computations', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('systems', 'system'), (',', ','), ('learning', 'learn'), ('tasks', 'task'), ('carried', 'carri'), ('distributed', 'distribut'), ('machines', 'machin'), ('need', 'need'), ('coordinate', 'coordin'), ('via', 'via'), ('communication', 'communic'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transferring', 'transfer'), ('results', 'result'), ('intermediate', 'intermedi'), ('computations', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('systems', 'system'), (',', ','), ('learning', 'learning'), ('tasks', 'task'), ('carried', 'carried'), ('distributed', 'distributed'), ('machines', 'machine'), ('need', 'need'), ('coordinate', 'coordinate'), ('via', 'via'), ('communication', 'communication'), (',', ','), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('transferring', 'transferring'), ('results', 'result'), ('intermediate', 'intermediate'), ('computations', 'computation'), ('.', '.')]



============================ Sentence 570 =============================

A recent line  of work investigates the resulting interplay between computation and communication [80]. 


>> Tokens are: 
 ['A', 'recent', 'line', 'work', 'investigates', 'resulting', 'interplay', 'computation', 'communication', '[', '80', ']', '.']

>> Bigrams are: 
 [('A', 'recent'), ('recent', 'line'), ('line', 'work'), ('work', 'investigates'), ('investigates', 'resulting'), ('resulting', 'interplay'), ('interplay', 'computation'), ('computation', 'communication'), ('communication', '['), ('[', '80'), ('80', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'recent', 'line'), ('recent', 'line', 'work'), ('line', 'work', 'investigates'), ('work', 'investigates', 'resulting'), ('investigates', 'resulting', 'interplay'), ('resulting', 'interplay', 'computation'), ('interplay', 'computation', 'communication'), ('computation', 'communication', '['), ('communication', '[', '80'), ('[', '80', ']'), ('80', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('recent', 'JJ'), ('line', 'NN'), ('work', 'NN'), ('investigates', 'NNS'), ('resulting', 'VBG'), ('interplay', 'JJ'), ('computation', 'NN'), ('communication', 'NN'), ('[', 'VBD'), ('80', 'CD'), (']', 'NN'), ('.', '.')]

 (S
  (NP A/DT recent/JJ line/NN work/NN investigates/NNS)
  resulting/VBG
  (NP interplay/JJ computation/NN communication/NN)
  [/VBD
  80/CD
  (NP ]/NN)
  ./.) 


>> Noun Phrases are: 
 ['A recent line work investigates', 'interplay computation communication', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('line', 'line'), ('work', 'work'), ('investigates', 'investig'), ('resulting', 'result'), ('interplay', 'interplay'), ('computation', 'comput'), ('communication', 'commun'), ('[', '['), ('80', '80'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('line', 'line'), ('work', 'work'), ('investigates', 'investig'), ('resulting', 'result'), ('interplay', 'interplay'), ('computation', 'comput'), ('communication', 'communic'), ('[', '['), ('80', '80'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('recent', 'recent'), ('line', 'line'), ('work', 'work'), ('investigates', 'investigates'), ('resulting', 'resulting'), ('interplay', 'interplay'), ('computation', 'computation'), ('communication', 'communication'), ('[', '['), ('80', '80'), (']', ']'), ('.', '.')]



============================ Sentence 571 =============================

REFERENCES [1] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,  N. Jaitly, A. 


>> Tokens are: 
 ['REFERENCES', '[', '1', ']', 'G.', 'Hinton', ',', 'L.', 'Deng', ',', 'D.', 'Yu', ',', 'G.', 'E.', 'Dahl', ',', 'A.-r.', 'Mohamed', ',', 'N.', 'Jaitly', ',', 'A', '.']

>> Bigrams are: 
 [('REFERENCES', '['), ('[', '1'), ('1', ']'), (']', 'G.'), ('G.', 'Hinton'), ('Hinton', ','), (',', 'L.'), ('L.', 'Deng'), ('Deng', ','), (',', 'D.'), ('D.', 'Yu'), ('Yu', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'Dahl'), ('Dahl', ','), (',', 'A.-r.'), ('A.-r.', 'Mohamed'), ('Mohamed', ','), (',', 'N.'), ('N.', 'Jaitly'), ('Jaitly', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('REFERENCES', '[', '1'), ('[', '1', ']'), ('1', ']', 'G.'), (']', 'G.', 'Hinton'), ('G.', 'Hinton', ','), ('Hinton', ',', 'L.'), (',', 'L.', 'Deng'), ('L.', 'Deng', ','), ('Deng', ',', 'D.'), (',', 'D.', 'Yu'), ('D.', 'Yu', ','), ('Yu', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'Dahl'), ('E.', 'Dahl', ','), ('Dahl', ',', 'A.-r.'), (',', 'A.-r.', 'Mohamed'), ('A.-r.', 'Mohamed', ','), ('Mohamed', ',', 'N.'), (',', 'N.', 'Jaitly'), ('N.', 'Jaitly', ','), ('Jaitly', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('REFERENCES', 'NNP'), ('[', 'VBD'), ('1', 'CD'), (']', 'NNP'), ('G.', 'NNP'), ('Hinton', 'NNP'), (',', ','), ('L.', 'NNP'), ('Deng', 'NNP'), (',', ','), ('D.', 'NNP'), ('Yu', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('Dahl', 'NNP'), (',', ','), ('A.-r.', 'NNP'), ('Mohamed', 'NNP'), (',', ','), ('N.', 'NNP'), ('Jaitly', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

 (S
  (NP REFERENCES/NNP)
  [/VBD
  1/CD
  (NP ]/NNP G./NNP Hinton/NNP)
  ,/,
  (NP L./NNP Deng/NNP)
  ,/,
  (NP D./NNP Yu/NNP)
  ,/,
  (NP G./NNP E./NNP Dahl/NNP)
  ,/,
  (NP A.-r./NNP Mohamed/NNP)
  ,/,
  (NP N./NNP Jaitly/NNP)
  ,/,
  (NP A/NNP)
  ./.) 


>> Noun Phrases are: 
 ['REFERENCES', '] G. Hinton', 'L. Deng', 'D. Yu', 'G. E. Dahl', 'A.-r. Mohamed', 'N. Jaitly', 'A']

>> Named Entities are: 
 [('ORGANIZATION', 'REFERENCES'), ('PERSON', 'Hinton'), ('PERSON', 'Deng'), ('PERSON', 'Mohamed')] 

>> Stemming using Porter Stemmer: 
 [('REFERENCES', 'refer'), ('[', '['), ('1', '1'), (']', ']'), ('G.', 'g.'), ('Hinton', 'hinton'), (',', ','), ('L.', 'l.'), ('Deng', 'deng'), (',', ','), ('D.', 'd.'), ('Yu', 'yu'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Dahl', 'dahl'), (',', ','), ('A.-r.', 'a.-r.'), ('Mohamed', 'moham'), (',', ','), ('N.', 'n.'), ('Jaitly', 'jaitli'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('REFERENCES', 'refer'), ('[', '['), ('1', '1'), (']', ']'), ('G.', 'g.'), ('Hinton', 'hinton'), (',', ','), ('L.', 'l.'), ('Deng', 'deng'), (',', ','), ('D.', 'd.'), ('Yu', 'yu'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Dahl', 'dahl'), (',', ','), ('A.-r.', 'a.-r.'), ('Mohamed', 'moham'), (',', ','), ('N.', 'n.'), ('Jaitly', 'jait'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('REFERENCES', 'REFERENCES'), ('[', '['), ('1', '1'), (']', ']'), ('G.', 'G.'), ('Hinton', 'Hinton'), (',', ','), ('L.', 'L.'), ('Deng', 'Deng'), (',', ','), ('D.', 'D.'), ('Yu', 'Yu'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('Dahl', 'Dahl'), (',', ','), ('A.-r.', 'A.-r.'), ('Mohamed', 'Mohamed'), (',', ','), ('N.', 'N.'), ('Jaitly', 'Jaitly'), (',', ','), ('A', 'A'), ('.', '.')]



============================ Sentence 572 =============================

Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al., “Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups,” IEEE Signal processing magazine, vol. 


>> Tokens are: 
 ['Senior', ',', 'V.', 'Vanhoucke', ',', 'P.', 'Nguyen', ',', 'T.', 'N.', 'Sainath', 'et', 'al.', ',', '“', 'Deep', 'neural', 'networks', 'acoustic', 'modeling', 'speech', 'recognition', ':', 'The', 'shared', 'views', 'four', 'research', 'groups', ',', '”', 'IEEE', 'Signal', 'processing', 'magazine', ',', 'vol', '.']

>> Bigrams are: 
 [('Senior', ','), (',', 'V.'), ('V.', 'Vanhoucke'), ('Vanhoucke', ','), (',', 'P.'), ('P.', 'Nguyen'), ('Nguyen', ','), (',', 'T.'), ('T.', 'N.'), ('N.', 'Sainath'), ('Sainath', 'et'), ('et', 'al.'), ('al.', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'neural'), ('neural', 'networks'), ('networks', 'acoustic'), ('acoustic', 'modeling'), ('modeling', 'speech'), ('speech', 'recognition'), ('recognition', ':'), (':', 'The'), ('The', 'shared'), ('shared', 'views'), ('views', 'four'), ('four', 'research'), ('research', 'groups'), ('groups', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Signal'), ('Signal', 'processing'), ('processing', 'magazine'), ('magazine', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Senior', ',', 'V.'), (',', 'V.', 'Vanhoucke'), ('V.', 'Vanhoucke', ','), ('Vanhoucke', ',', 'P.'), (',', 'P.', 'Nguyen'), ('P.', 'Nguyen', ','), ('Nguyen', ',', 'T.'), (',', 'T.', 'N.'), ('T.', 'N.', 'Sainath'), ('N.', 'Sainath', 'et'), ('Sainath', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'neural'), ('Deep', 'neural', 'networks'), ('neural', 'networks', 'acoustic'), ('networks', 'acoustic', 'modeling'), ('acoustic', 'modeling', 'speech'), ('modeling', 'speech', 'recognition'), ('speech', 'recognition', ':'), ('recognition', ':', 'The'), (':', 'The', 'shared'), ('The', 'shared', 'views'), ('shared', 'views', 'four'), ('views', 'four', 'research'), ('four', 'research', 'groups'), ('research', 'groups', ','), ('groups', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Signal'), ('IEEE', 'Signal', 'processing'), ('Signal', 'processing', 'magazine'), ('processing', 'magazine', ','), ('magazine', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('Senior', 'NNP'), (',', ','), ('V.', 'NNP'), ('Vanhoucke', 'NNP'), (',', ','), ('P.', 'NNP'), ('Nguyen', 'NNP'), (',', ','), ('T.', 'NNP'), ('N.', 'NNP'), ('Sainath', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('“', 'JJ'), ('Deep', 'NNP'), ('neural', 'JJ'), ('networks', 'NNS'), ('acoustic', 'JJ'), ('modeling', 'VBG'), ('speech', 'JJ'), ('recognition', 'NN'), (':', ':'), ('The', 'DT'), ('shared', 'VBN'), ('views', 'NNS'), ('four', 'CD'), ('research', 'NN'), ('groups', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Signal', 'NNP'), ('processing', 'NN'), ('magazine', 'NN'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP Senior/NNP)
  ,/,
  (NP V./NNP Vanhoucke/NNP)
  ,/,
  (NP P./NNP Nguyen/NNP)
  ,/,
  (NP T./NNP N./NNP Sainath/NNP)
  et/FW
  (NP al./NN)
  ,/,
  (NP “/JJ Deep/NNP)
  (NP neural/JJ networks/NNS)
  acoustic/JJ
  modeling/VBG
  (NP speech/JJ recognition/NN)
  :/:
  The/DT
  shared/VBN
  (NP views/NNS)
  four/CD
  (NP research/NN groups/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Signal/NNP processing/NN magazine/NN)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['Senior', 'V. Vanhoucke', 'P. Nguyen', 'T. N. Sainath', 'al.', '“ Deep', 'neural networks', 'speech recognition', 'views', 'research groups', '” IEEE Signal processing magazine', 'vol']

>> Named Entities are: 
 [('GPE', 'Senior')] 

>> Stemming using Porter Stemmer: 
 [('Senior', 'senior'), (',', ','), ('V.', 'v.'), ('Vanhoucke', 'vanhouck'), (',', ','), ('P.', 'p.'), ('Nguyen', 'nguyen'), (',', ','), ('T.', 't.'), ('N.', 'n.'), ('Sainath', 'sainath'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoust'), ('modeling', 'model'), ('speech', 'speech'), ('recognition', 'recognit'), (':', ':'), ('The', 'the'), ('shared', 'share'), ('views', 'view'), ('four', 'four'), ('research', 'research'), ('groups', 'group'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('processing', 'process'), ('magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Senior', 'senior'), (',', ','), ('V.', 'v.'), ('Vanhoucke', 'vanhouck'), (',', ','), ('P.', 'p.'), ('Nguyen', 'nguyen'), (',', ','), ('T.', 't.'), ('N.', 'n.'), ('Sainath', 'sainath'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoust'), ('modeling', 'model'), ('speech', 'speech'), ('recognition', 'recognit'), (':', ':'), ('The', 'the'), ('shared', 'share'), ('views', 'view'), ('four', 'four'), ('research', 'research'), ('groups', 'group'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('processing', 'process'), ('magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Senior', 'Senior'), (',', ','), ('V.', 'V.'), ('Vanhoucke', 'Vanhoucke'), (',', ','), ('P.', 'P.'), ('Nguyen', 'Nguyen'), (',', ','), ('T.', 'T.'), ('N.', 'N.'), ('Sainath', 'Sainath'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoustic'), ('modeling', 'modeling'), ('speech', 'speech'), ('recognition', 'recognition'), (':', ':'), ('The', 'The'), ('shared', 'shared'), ('views', 'view'), ('four', 'four'), ('research', 'research'), ('groups', 'group'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Signal', 'Signal'), ('processing', 'processing'), ('magazine', 'magazine'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 573 =============================

29, no. 


>> Tokens are: 
 ['29', ',', '.']

>> Bigrams are: 
 [('29', ','), (',', '.')]

>> Trigrams are: 
 [('29', ',', '.')]

>> POS Tags are: 
 [('29', 'CD'), (',', ','), ('.', '.')]

 (S 29/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('29', '29'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('29', '29'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('29', '29'), (',', ','), ('.', '.')]



============================ Sentence 574 =============================

6, pp. 


>> Tokens are: 
 ['6', ',', 'pp', '.']

>> Bigrams are: 
 [('6', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('6', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 6/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 575 =============================

82–97, 2012. 


>> Tokens are: 
 ['82–97', ',', '2012', '.']

>> Bigrams are: 
 [('82–97', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('82–97', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('82–97', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S 82–97/CD ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('82–97', '82–97'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('82–97', '82–97'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('82–97', '82–97'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 576 =============================

[2] M. Ibnkahla, “Applications of neural networks to digital communications–a survey,” Signal processing, vol. 


>> Tokens are: 
 ['[', '2', ']', 'M.', 'Ibnkahla', ',', '“', 'Applications', 'neural', 'networks', 'digital', 'communications–a', 'survey', ',', '”', 'Signal', 'processing', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '2'), ('2', ']'), (']', 'M.'), ('M.', 'Ibnkahla'), ('Ibnkahla', ','), (',', '“'), ('“', 'Applications'), ('Applications', 'neural'), ('neural', 'networks'), ('networks', 'digital'), ('digital', 'communications–a'), ('communications–a', 'survey'), ('survey', ','), (',', '”'), ('”', 'Signal'), ('Signal', 'processing'), ('processing', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '2', ']'), ('2', ']', 'M.'), (']', 'M.', 'Ibnkahla'), ('M.', 'Ibnkahla', ','), ('Ibnkahla', ',', '“'), (',', '“', 'Applications'), ('“', 'Applications', 'neural'), ('Applications', 'neural', 'networks'), ('neural', 'networks', 'digital'), ('networks', 'digital', 'communications–a'), ('digital', 'communications–a', 'survey'), ('communications–a', 'survey', ','), ('survey', ',', '”'), (',', '”', 'Signal'), ('”', 'Signal', 'processing'), ('Signal', 'processing', ','), ('processing', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('2', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Ibnkahla', 'NNP'), (',', ','), ('“', 'NNP'), ('Applications', 'NNP'), ('neural', 'JJ'), ('networks', 'NNS'), ('digital', 'JJ'), ('communications–a', 'NN'), ('survey', 'NN'), (',', ','), ('”', 'NNP'), ('Signal', 'NNP'), ('processing', 'NN'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  2/CD
  (NP ]/NNP M./NNP Ibnkahla/NNP)
  ,/,
  (NP “/NNP Applications/NNP)
  (NP neural/JJ networks/NNS)
  (NP digital/JJ communications–a/NN survey/NN)
  ,/,
  (NP ”/NNP Signal/NNP processing/NN)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. Ibnkahla', '“ Applications', 'neural networks', 'digital communications–a survey', '” Signal processing', 'vol']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('M.', 'm.'), ('Ibnkahla', 'ibnkahla'), (',', ','), ('“', '“'), ('Applications', 'applic'), ('neural', 'neural'), ('networks', 'network'), ('digital', 'digit'), ('communications–a', 'communications–a'), ('survey', 'survey'), (',', ','), ('”', '”'), ('Signal', 'signal'), ('processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('M.', 'm.'), ('Ibnkahla', 'ibnkahla'), (',', ','), ('“', '“'), ('Applications', 'applic'), ('neural', 'neural'), ('networks', 'network'), ('digital', 'digit'), ('communications–a', 'communications–a'), ('survey', 'survey'), (',', ','), ('”', '”'), ('Signal', 'signal'), ('processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('2', '2'), (']', ']'), ('M.', 'M.'), ('Ibnkahla', 'Ibnkahla'), (',', ','), ('“', '“'), ('Applications', 'Applications'), ('neural', 'neural'), ('networks', 'network'), ('digital', 'digital'), ('communications–a', 'communications–a'), ('survey', 'survey'), (',', ','), ('”', '”'), ('Signal', 'Signal'), ('processing', 'processing'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 577 =============================

80, no. 


>> Tokens are: 
 ['80', ',', '.']

>> Bigrams are: 
 [('80', ','), (',', '.')]

>> Trigrams are: 
 [('80', ',', '.')]

>> POS Tags are: 
 [('80', 'CD'), (',', ','), ('.', '.')]

 (S 80/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('80', '80'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('80', '80'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('80', '80'), (',', ','), ('.', '.')]



============================ Sentence 578 =============================

7, pp. 


>> Tokens are: 
 ['7', ',', 'pp', '.']

>> Bigrams are: 
 [('7', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('7', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 7/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 579 =============================

1185–1215, 2000. 


>> Tokens are: 
 ['1185–1215', ',', '2000', '.']

>> Bigrams are: 
 [('1185–1215', ','), (',', '2000'), ('2000', '.')]

>> Trigrams are: 
 [('1185–1215', ',', '2000'), (',', '2000', '.')]

>> POS Tags are: 
 [('1185–1215', 'CD'), (',', ','), ('2000', 'CD'), ('.', '.')]

 (S 1185–1215/CD ,/, 2000/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1185–1215', '1185–1215'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1185–1215', '1185–1215'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Lemmatization: 
 [('1185–1215', '1185–1215'), (',', ','), ('2000', '2000'), ('.', '.')]



============================ Sentence 580 =============================

[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest for Real AI: Reflections on Natural and Artificial Intelligence. 


>> Tokens are: 
 ['[', '3', ']', 'H.', 'J.', 'Levesque', ',', 'Common', 'Sense', ',', 'Turing', 'Test', ',', 'Quest', 'Real', 'AI', ':', 'Reflections', 'Natural', 'Artificial', 'Intelligence', '.']

>> Bigrams are: 
 [('[', '3'), ('3', ']'), (']', 'H.'), ('H.', 'J.'), ('J.', 'Levesque'), ('Levesque', ','), (',', 'Common'), ('Common', 'Sense'), ('Sense', ','), (',', 'Turing'), ('Turing', 'Test'), ('Test', ','), (',', 'Quest'), ('Quest', 'Real'), ('Real', 'AI'), ('AI', ':'), (':', 'Reflections'), ('Reflections', 'Natural'), ('Natural', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', '.')]

>> Trigrams are: 
 [('[', '3', ']'), ('3', ']', 'H.'), (']', 'H.', 'J.'), ('H.', 'J.', 'Levesque'), ('J.', 'Levesque', ','), ('Levesque', ',', 'Common'), (',', 'Common', 'Sense'), ('Common', 'Sense', ','), ('Sense', ',', 'Turing'), (',', 'Turing', 'Test'), ('Turing', 'Test', ','), ('Test', ',', 'Quest'), (',', 'Quest', 'Real'), ('Quest', 'Real', 'AI'), ('Real', 'AI', ':'), ('AI', ':', 'Reflections'), (':', 'Reflections', 'Natural'), ('Reflections', 'Natural', 'Artificial'), ('Natural', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('3', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('J.', 'NNP'), ('Levesque', 'NNP'), (',', ','), ('Common', 'NNP'), ('Sense', 'NNP'), (',', ','), ('Turing', 'NNP'), ('Test', 'NNP'), (',', ','), ('Quest', 'NNP'), ('Real', 'NNP'), ('AI', 'NNP'), (':', ':'), ('Reflections', 'NNP'), ('Natural', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('.', '.')]

 (S
  [/RB
  3/CD
  (NP ]/JJ H./NNP J./NNP Levesque/NNP)
  ,/,
  (NP Common/NNP Sense/NNP)
  ,/,
  (NP Turing/NNP Test/NNP)
  ,/,
  (NP Quest/NNP Real/NNP AI/NNP)
  :/:
  (NP Reflections/NNP Natural/NNP Artificial/NNP Intelligence/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] H. J. Levesque', 'Common Sense', 'Turing Test', 'Quest Real AI', 'Reflections Natural Artificial Intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'Common Sense'), ('GPE', 'Turing Test'), ('PERSON', 'Quest Real')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('H.', 'h.'), ('J.', 'j.'), ('Levesque', 'levesqu'), (',', ','), ('Common', 'common'), ('Sense', 'sens'), (',', ','), ('Turing', 'ture'), ('Test', 'test'), (',', ','), ('Quest', 'quest'), ('Real', 'real'), ('AI', 'ai'), (':', ':'), ('Reflections', 'reflect'), ('Natural', 'natur'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('H.', 'h.'), ('J.', 'j.'), ('Levesque', 'levesqu'), (',', ','), ('Common', 'common'), ('Sense', 'sens'), (',', ','), ('Turing', 'ture'), ('Test', 'test'), (',', ','), ('Quest', 'quest'), ('Real', 'real'), ('AI', 'ai'), (':', ':'), ('Reflections', 'reflect'), ('Natural', 'natur'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('3', '3'), (']', ']'), ('H.', 'H.'), ('J.', 'J.'), ('Levesque', 'Levesque'), (',', ','), ('Common', 'Common'), ('Sense', 'Sense'), (',', ','), ('Turing', 'Turing'), ('Test', 'Test'), (',', ','), ('Quest', 'Quest'), ('Real', 'Real'), ('AI', 'AI'), (':', ':'), ('Reflections', 'Reflections'), ('Natural', 'Natural'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('.', '.')]



============================ Sentence 581 =============================

MIT Press, 2017. 


>> Tokens are: 
 ['MIT', 'Press', ',', '2017', '.']

>> Bigrams are: 
 [('MIT', 'Press'), ('Press', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('MIT', 'Press', ','), ('Press', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S (NP MIT/NNP Press/NNP) ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 ['MIT Press']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 582 =============================

[4] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning internal representations by error propagation,” California Univ San Diego La Jolla Inst for Cognitive Science, Tech. 


>> Tokens are: 
 ['[', '4', ']', 'D.', 'E.', 'Rumelhart', ',', 'G.', 'E.', 'Hinton', ',', 'R.', 'J.', 'Williams', ',', '“', 'Learning', 'internal', 'representations', 'error', 'propagation', ',', '”', 'California', 'Univ', 'San', 'Diego', 'La', 'Jolla', 'Inst', 'Cognitive', 'Science', ',', 'Tech', '.']

>> Bigrams are: 
 [('[', '4'), ('4', ']'), (']', 'D.'), ('D.', 'E.'), ('E.', 'Rumelhart'), ('Rumelhart', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'Hinton'), ('Hinton', ','), (',', 'R.'), ('R.', 'J.'), ('J.', 'Williams'), ('Williams', ','), (',', '“'), ('“', 'Learning'), ('Learning', 'internal'), ('internal', 'representations'), ('representations', 'error'), ('error', 'propagation'), ('propagation', ','), (',', '”'), ('”', 'California'), ('California', 'Univ'), ('Univ', 'San'), ('San', 'Diego'), ('Diego', 'La'), ('La', 'Jolla'), ('Jolla', 'Inst'), ('Inst', 'Cognitive'), ('Cognitive', 'Science'), ('Science', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('[', '4', ']'), ('4', ']', 'D.'), (']', 'D.', 'E.'), ('D.', 'E.', 'Rumelhart'), ('E.', 'Rumelhart', ','), ('Rumelhart', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'Hinton'), ('E.', 'Hinton', ','), ('Hinton', ',', 'R.'), (',', 'R.', 'J.'), ('R.', 'J.', 'Williams'), ('J.', 'Williams', ','), ('Williams', ',', '“'), (',', '“', 'Learning'), ('“', 'Learning', 'internal'), ('Learning', 'internal', 'representations'), ('internal', 'representations', 'error'), ('representations', 'error', 'propagation'), ('error', 'propagation', ','), ('propagation', ',', '”'), (',', '”', 'California'), ('”', 'California', 'Univ'), ('California', 'Univ', 'San'), ('Univ', 'San', 'Diego'), ('San', 'Diego', 'La'), ('Diego', 'La', 'Jolla'), ('La', 'Jolla', 'Inst'), ('Jolla', 'Inst', 'Cognitive'), ('Inst', 'Cognitive', 'Science'), ('Cognitive', 'Science', ','), ('Science', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('4', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('E.', 'NNP'), ('Rumelhart', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('Hinton', 'NNP'), (',', ','), ('R.', 'NNP'), ('J.', 'NNP'), ('Williams', 'NNP'), (',', ','), ('“', 'NNP'), ('Learning', 'NNP'), ('internal', 'JJ'), ('representations', 'NNS'), ('error', 'VBP'), ('propagation', 'NN'), (',', ','), ('”', 'NNP'), ('California', 'NNP'), ('Univ', 'NNP'), ('San', 'NNP'), ('Diego', 'NNP'), ('La', 'NNP'), ('Jolla', 'NNP'), ('Inst', 'NNP'), ('Cognitive', 'NNP'), ('Science', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

 (S
  [/RB
  4/CD
  (NP ]/JJ D./NNP E./NNP Rumelhart/NNP)
  ,/,
  (NP G./NNP E./NNP Hinton/NNP)
  ,/,
  (NP R./NNP J./NNP Williams/NNP)
  ,/,
  (NP “/NNP Learning/NNP)
  (NP internal/JJ representations/NNS)
  error/VBP
  (NP propagation/NN)
  ,/,
  (NP
    ”/NNP
    California/NNP
    Univ/NNP
    San/NNP
    Diego/NNP
    La/NNP
    Jolla/NNP
    Inst/NNP
    Cognitive/NNP
    Science/NNP)
  ,/,
  (NP Tech/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] D. E. Rumelhart', 'G. E. Hinton', 'R. J. Williams', '“ Learning', 'internal representations', 'propagation', '” California Univ San Diego La Jolla Inst Cognitive Science', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Hinton'), ('PERSON', 'Williams'), ('PERSON', 'Univ San Diego La Jolla Inst Cognitive Science'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('D.', 'd.'), ('E.', 'e.'), ('Rumelhart', 'rumelhart'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('R.', 'r.'), ('J.', 'j.'), ('Williams', 'william'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('internal', 'intern'), ('representations', 'represent'), ('error', 'error'), ('propagation', 'propag'), (',', ','), ('”', '”'), ('California', 'california'), ('Univ', 'univ'), ('San', 'san'), ('Diego', 'diego'), ('La', 'la'), ('Jolla', 'jolla'), ('Inst', 'inst'), ('Cognitive', 'cognit'), ('Science', 'scienc'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('D.', 'd.'), ('E.', 'e.'), ('Rumelhart', 'rumelhart'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('R.', 'r.'), ('J.', 'j.'), ('Williams', 'william'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('internal', 'intern'), ('representations', 'represent'), ('error', 'error'), ('propagation', 'propag'), (',', ','), ('”', '”'), ('California', 'california'), ('Univ', 'univ'), ('San', 'san'), ('Diego', 'diego'), ('La', 'la'), ('Jolla', 'jolla'), ('Inst', 'inst'), ('Cognitive', 'cognit'), ('Science', 'scienc'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('4', '4'), (']', ']'), ('D.', 'D.'), ('E.', 'E.'), ('Rumelhart', 'Rumelhart'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('Hinton', 'Hinton'), (',', ','), ('R.', 'R.'), ('J.', 'J.'), ('Williams', 'Williams'), (',', ','), ('“', '“'), ('Learning', 'Learning'), ('internal', 'internal'), ('representations', 'representation'), ('error', 'error'), ('propagation', 'propagation'), (',', ','), ('”', '”'), ('California', 'California'), ('Univ', 'Univ'), ('San', 'San'), ('Diego', 'Diego'), ('La', 'La'), ('Jolla', 'Jolla'), ('Inst', 'Inst'), ('Cognitive', 'Cognitive'), ('Science', 'Science'), (',', ','), ('Tech', 'Tech'), ('.', '.')]



============================ Sentence 583 =============================

Rep., 1985. 


>> Tokens are: 
 ['Rep.', ',', '1985', '.']

>> Bigrams are: 
 [('Rep.', ','), (',', '1985'), ('1985', '.')]

>> Trigrams are: 
 [('Rep.', ',', '1985'), (',', '1985', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), (',', ','), ('1985', 'CD'), ('.', '.')]

 (S (NP Rep./NNP) ,/, 1985/CD ./.) 


>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('1985', '1985'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('1985', '1985'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), (',', ','), ('1985', '1985'), ('.', '.')]



============================ Sentence 584 =============================

[5] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum likelihood from incomplete data via the em algorithm,” Journal of the royal statistical society. 


>> Tokens are: 
 ['[', '5', ']', 'A.', 'P.', 'Dempster', ',', 'N.', 'M.', 'Laird', ',', 'D.', 'B.', 'Rubin', ',', '“', 'Maximum', 'likelihood', 'incomplete', 'data', 'via', 'em', 'algorithm', ',', '”', 'Journal', 'royal', 'statistical', 'society', '.']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'A.'), ('A.', 'P.'), ('P.', 'Dempster'), ('Dempster', ','), (',', 'N.'), ('N.', 'M.'), ('M.', 'Laird'), ('Laird', ','), (',', 'D.'), ('D.', 'B.'), ('B.', 'Rubin'), ('Rubin', ','), (',', '“'), ('“', 'Maximum'), ('Maximum', 'likelihood'), ('likelihood', 'incomplete'), ('incomplete', 'data'), ('data', 'via'), ('via', 'em'), ('em', 'algorithm'), ('algorithm', ','), (',', '”'), ('”', 'Journal'), ('Journal', 'royal'), ('royal', 'statistical'), ('statistical', 'society'), ('society', '.')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'A.'), (']', 'A.', 'P.'), ('A.', 'P.', 'Dempster'), ('P.', 'Dempster', ','), ('Dempster', ',', 'N.'), (',', 'N.', 'M.'), ('N.', 'M.', 'Laird'), ('M.', 'Laird', ','), ('Laird', ',', 'D.'), (',', 'D.', 'B.'), ('D.', 'B.', 'Rubin'), ('B.', 'Rubin', ','), ('Rubin', ',', '“'), (',', '“', 'Maximum'), ('“', 'Maximum', 'likelihood'), ('Maximum', 'likelihood', 'incomplete'), ('likelihood', 'incomplete', 'data'), ('incomplete', 'data', 'via'), ('data', 'via', 'em'), ('via', 'em', 'algorithm'), ('em', 'algorithm', ','), ('algorithm', ',', '”'), (',', '”', 'Journal'), ('”', 'Journal', 'royal'), ('Journal', 'royal', 'statistical'), ('royal', 'statistical', 'society'), ('statistical', 'society', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('P.', 'NNP'), ('Dempster', 'NNP'), (',', ','), ('N.', 'NNP'), ('M.', 'NNP'), ('Laird', 'NNP'), (',', ','), ('D.', 'NNP'), ('B.', 'NNP'), ('Rubin', 'NNP'), (',', ','), ('“', 'NNP'), ('Maximum', 'NNP'), ('likelihood', 'VBD'), ('incomplete', 'JJ'), ('data', 'NNS'), ('via', 'IN'), ('em', 'NN'), ('algorithm', 'NN'), (',', ','), ('”', 'NNP'), ('Journal', 'NNP'), ('royal', 'VB'), ('statistical', 'JJ'), ('society', 'NN'), ('.', '.')]

 (S
  [/RB
  5/CD
  (NP ]/JJ A./NNP P./NNP Dempster/NNP)
  ,/,
  (NP N./NNP M./NNP Laird/NNP)
  ,/,
  (NP D./NNP B./NNP Rubin/NNP)
  ,/,
  (NP “/NNP Maximum/NNP)
  likelihood/VBD
  (NP incomplete/JJ data/NNS)
  via/IN
  (NP em/NN algorithm/NN)
  ,/,
  (NP ”/NNP Journal/NNP)
  royal/VB
  (NP statistical/JJ society/NN)
  ./.) 


>> Noun Phrases are: 
 ['] A. P. Dempster', 'N. M. Laird', 'D. B. Rubin', '“ Maximum', 'incomplete data', 'em algorithm', '” Journal', 'statistical society']

>> Named Entities are: 
 [('PERSON', 'Maximum')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('A.', 'a.'), ('P.', 'p.'), ('Dempster', 'dempster'), (',', ','), ('N.', 'n.'), ('M.', 'm.'), ('Laird', 'laird'), (',', ','), ('D.', 'd.'), ('B.', 'b.'), ('Rubin', 'rubin'), (',', ','), ('“', '“'), ('Maximum', 'maximum'), ('likelihood', 'likelihood'), ('incomplete', 'incomplet'), ('data', 'data'), ('via', 'via'), ('em', 'em'), ('algorithm', 'algorithm'), (',', ','), ('”', '”'), ('Journal', 'journal'), ('royal', 'royal'), ('statistical', 'statist'), ('society', 'societi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('A.', 'a.'), ('P.', 'p.'), ('Dempster', 'dempster'), (',', ','), ('N.', 'n.'), ('M.', 'm.'), ('Laird', 'laird'), (',', ','), ('D.', 'd.'), ('B.', 'b.'), ('Rubin', 'rubin'), (',', ','), ('“', '“'), ('Maximum', 'maximum'), ('likelihood', 'likelihood'), ('incomplete', 'incomplet'), ('data', 'data'), ('via', 'via'), ('em', 'em'), ('algorithm', 'algorithm'), (',', ','), ('”', '”'), ('Journal', 'journal'), ('royal', 'royal'), ('statistical', 'statist'), ('society', 'societi'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('A.', 'A.'), ('P.', 'P.'), ('Dempster', 'Dempster'), (',', ','), ('N.', 'N.'), ('M.', 'M.'), ('Laird', 'Laird'), (',', ','), ('D.', 'D.'), ('B.', 'B.'), ('Rubin', 'Rubin'), (',', ','), ('“', '“'), ('Maximum', 'Maximum'), ('likelihood', 'likelihood'), ('incomplete', 'incomplete'), ('data', 'data'), ('via', 'via'), ('em', 'em'), ('algorithm', 'algorithm'), (',', ','), ('”', '”'), ('Journal', 'Journal'), ('royal', 'royal'), ('statistical', 'statistical'), ('society', 'society'), ('.', '.')]



============================ Sentence 585 =============================

Series B (methodological), pp. 


>> Tokens are: 
 ['Series', 'B', '(', 'methodological', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Series', 'B'), ('B', '('), ('(', 'methodological'), ('methodological', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Series', 'B', '('), ('B', '(', 'methodological'), ('(', 'methodological', ')'), ('methodological', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Series', 'NN'), ('B', 'NNP'), ('(', '('), ('methodological', 'JJ'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Series/NN B/NNP) (/( methodological/JJ )/) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Series B', 'pp']

>> Named Entities are: 
 [('GPE', 'Series'), ('PERSON', 'B')] 

>> Stemming using Porter Stemmer: 
 [('Series', 'seri'), ('B', 'b'), ('(', '('), ('methodological', 'methodolog'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Series', 'seri'), ('B', 'b'), ('(', '('), ('methodological', 'methodolog'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Series', 'Series'), ('B', 'B'), ('(', '('), ('methodological', 'methodological'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 586 =============================

1–38, 1977. 


>> Tokens are: 
 ['1–38', ',', '1977', '.']

>> Bigrams are: 
 [('1–38', ','), (',', '1977'), ('1977', '.')]

>> Trigrams are: 
 [('1–38', ',', '1977'), (',', '1977', '.')]

>> POS Tags are: 
 [('1–38', 'CD'), (',', ','), ('1977', 'CD'), ('.', '.')]

 (S 1–38/CD ,/, 1977/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–38', '1–38'), (',', ','), ('1977', '1977'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–38', '1–38'), (',', ','), ('1977', '1977'), ('.', '.')]

>> Lemmatization: 
 [('1–38', '1–38'), (',', ','), ('1977', '1977'), ('.', '.')]



============================ Sentence 587 =============================

[6] C. Watkins, “Learning form delayed rewards,” Ph. 


>> Tokens are: 
 ['[', '6', ']', 'C.', 'Watkins', ',', '“', 'Learning', 'form', 'delayed', 'rewards', ',', '”', 'Ph', '.']

>> Bigrams are: 
 [('[', '6'), ('6', ']'), (']', 'C.'), ('C.', 'Watkins'), ('Watkins', ','), (',', '“'), ('“', 'Learning'), ('Learning', 'form'), ('form', 'delayed'), ('delayed', 'rewards'), ('rewards', ','), (',', '”'), ('”', 'Ph'), ('Ph', '.')]

>> Trigrams are: 
 [('[', '6', ']'), ('6', ']', 'C.'), (']', 'C.', 'Watkins'), ('C.', 'Watkins', ','), ('Watkins', ',', '“'), (',', '“', 'Learning'), ('“', 'Learning', 'form'), ('Learning', 'form', 'delayed'), ('form', 'delayed', 'rewards'), ('delayed', 'rewards', ','), ('rewards', ',', '”'), (',', '”', 'Ph'), ('”', 'Ph', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('6', 'CD'), (']', 'JJ'), ('C.', 'NNP'), ('Watkins', 'NNP'), (',', ','), ('“', 'NNP'), ('Learning', 'NNP'), ('form', 'NN'), ('delayed', 'NN'), ('rewards', 'NNS'), (',', ','), ('”', 'NNP'), ('Ph', 'NNP'), ('.', '.')]

 (S
  [/RB
  6/CD
  (NP ]/JJ C./NNP Watkins/NNP)
  ,/,
  (NP “/NNP Learning/NNP form/NN delayed/NN rewards/NNS)
  ,/,
  (NP ”/NNP Ph/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] C. Watkins', '“ Learning form delayed rewards', '” Ph']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('C.', 'c.'), ('Watkins', 'watkin'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('form', 'form'), ('delayed', 'delay'), ('rewards', 'reward'), (',', ','), ('”', '”'), ('Ph', 'ph'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('C.', 'c.'), ('Watkins', 'watkin'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('form', 'form'), ('delayed', 'delay'), ('rewards', 'reward'), (',', ','), ('”', '”'), ('Ph', 'ph'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('6', '6'), (']', ']'), ('C.', 'C.'), ('Watkins', 'Watkins'), (',', ','), ('“', '“'), ('Learning', 'Learning'), ('form', 'form'), ('delayed', 'delayed'), ('rewards', 'reward'), (',', ','), ('”', '”'), ('Ph', 'Ph'), ('.', '.')]



============================ Sentence 588 =============================

D. thesis, King’s College, University of Cambridge, 1989. 


>> Tokens are: 
 ['D.', 'thesis', ',', 'King', '’', 'College', ',', 'University', 'Cambridge', ',', '1989', '.']

>> Bigrams are: 
 [('D.', 'thesis'), ('thesis', ','), (',', 'King'), ('King', '’'), ('’', 'College'), ('College', ','), (',', 'University'), ('University', 'Cambridge'), ('Cambridge', ','), (',', '1989'), ('1989', '.')]

>> Trigrams are: 
 [('D.', 'thesis', ','), ('thesis', ',', 'King'), (',', 'King', '’'), ('King', '’', 'College'), ('’', 'College', ','), ('College', ',', 'University'), (',', 'University', 'Cambridge'), ('University', 'Cambridge', ','), ('Cambridge', ',', '1989'), (',', '1989', '.')]

>> POS Tags are: 
 [('D.', 'NNP'), ('thesis', 'NN'), (',', ','), ('King', 'NNP'), ('’', 'NNP'), ('College', 'NNP'), (',', ','), ('University', 'NNP'), ('Cambridge', 'NNP'), (',', ','), ('1989', 'CD'), ('.', '.')]

 (S
  (NP D./NNP thesis/NN)
  ,/,
  (NP King/NNP ’/NNP College/NNP)
  ,/,
  (NP University/NNP Cambridge/NNP)
  ,/,
  1989/CD
  ./.) 


>> Noun Phrases are: 
 ['D. thesis', 'King ’ College', 'University Cambridge']

>> Named Entities are: 
 [('ORGANIZATION', 'University Cambridge')] 

>> Stemming using Porter Stemmer: 
 [('D.', 'd.'), ('thesis', 'thesi'), (',', ','), ('King', 'king'), ('’', '’'), ('College', 'colleg'), (',', ','), ('University', 'univers'), ('Cambridge', 'cambridg'), (',', ','), ('1989', '1989'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('D.', 'd.'), ('thesis', 'thesi'), (',', ','), ('King', 'king'), ('’', '’'), ('College', 'colleg'), (',', ','), ('University', 'univers'), ('Cambridge', 'cambridg'), (',', ','), ('1989', '1989'), ('.', '.')]

>> Lemmatization: 
 [('D.', 'D.'), ('thesis', 'thesis'), (',', ','), ('King', 'King'), ('’', '’'), ('College', 'College'), (',', ','), ('University', 'University'), ('Cambridge', 'Cambridge'), (',', ','), ('1989', '1989'), ('.', '.')]



============================ Sentence 589 =============================

[7] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning. 


>> Tokens are: 
 ['[', '7', ']', 'I.', 'Goodfellow', ',', 'Y.', 'Bengio', ',', 'A.', 'Courville', ',', 'Y.', 'Bengio', ',', 'Deep', 'learning', '.']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', 'I.'), ('I.', 'Goodfellow'), ('Goodfellow', ','), (',', 'Y.'), ('Y.', 'Bengio'), ('Bengio', ','), (',', 'A.'), ('A.', 'Courville'), ('Courville', ','), (',', 'Y.'), ('Y.', 'Bengio'), ('Bengio', ','), (',', 'Deep'), ('Deep', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', 'I.'), (']', 'I.', 'Goodfellow'), ('I.', 'Goodfellow', ','), ('Goodfellow', ',', 'Y.'), (',', 'Y.', 'Bengio'), ('Y.', 'Bengio', ','), ('Bengio', ',', 'A.'), (',', 'A.', 'Courville'), ('A.', 'Courville', ','), ('Courville', ',', 'Y.'), (',', 'Y.', 'Bengio'), ('Y.', 'Bengio', ','), ('Bengio', ',', 'Deep'), (',', 'Deep', 'learning'), ('Deep', 'learning', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('I.', 'NNP'), ('Goodfellow', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('A.', 'NNP'), ('Courville', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('Deep', 'NNP'), ('learning', 'NN'), ('.', '.')]

 (S
  [/RB
  7/CD
  (NP ]/JJ I./NNP Goodfellow/NNP)
  ,/,
  (NP Y./NNP Bengio/NNP)
  ,/,
  (NP A./NNP Courville/NNP)
  ,/,
  (NP Y./NNP Bengio/NNP)
  ,/,
  (NP Deep/NNP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['] I. Goodfellow', 'Y. Bengio', 'A. Courville', 'Y. Bengio', 'Deep learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('I.', 'i.'), ('Goodfellow', 'goodfellow'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('A.', 'a.'), ('Courville', 'courvil'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('Deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('I.', 'i.'), ('Goodfellow', 'goodfellow'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('A.', 'a.'), ('Courville', 'courvill'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('Deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), ('I.', 'I.'), ('Goodfellow', 'Goodfellow'), (',', ','), ('Y.', 'Y.'), ('Bengio', 'Bengio'), (',', ','), ('A.', 'A.'), ('Courville', 'Courville'), (',', ','), ('Y.', 'Y.'), ('Bengio', 'Bengio'), (',', ','), ('Deep', 'Deep'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 590 =============================

MIT press Cambridge, 2016, vol. 


>> Tokens are: 
 ['MIT', 'press', 'Cambridge', ',', '2016', ',', 'vol', '.']

>> Bigrams are: 
 [('MIT', 'press'), ('press', 'Cambridge'), ('Cambridge', ','), (',', '2016'), ('2016', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('MIT', 'press', 'Cambridge'), ('press', 'Cambridge', ','), ('Cambridge', ',', '2016'), (',', '2016', ','), ('2016', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('press', 'NN'), ('Cambridge', 'NNP'), (',', ','), ('2016', 'CD'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP MIT/NNP press/NN Cambridge/NNP)
  ,/,
  2016/CD
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['MIT press Cambridge', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT'), ('PERSON', 'Cambridge')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), ('Cambridge', 'cambridg'), (',', ','), ('2016', '2016'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), ('Cambridge', 'cambridg'), (',', ','), ('2016', '2016'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('press', 'press'), ('Cambridge', 'Cambridge'), (',', ','), ('2016', '2016'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 591 =============================

1. 


>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

 (S 1/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]



============================ Sentence 592 =============================

[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science of Cause and Effect. 


>> Tokens are: 
 ['[', '8', ']', 'J.', 'Pearl', 'D.', 'Mackenzie', ',', 'The', 'Book', 'Why', ':', 'The', 'New', 'Science', 'Cause', 'Effect', '.']

>> Bigrams are: 
 [('[', '8'), ('8', ']'), (']', 'J.'), ('J.', 'Pearl'), ('Pearl', 'D.'), ('D.', 'Mackenzie'), ('Mackenzie', ','), (',', 'The'), ('The', 'Book'), ('Book', 'Why'), ('Why', ':'), (':', 'The'), ('The', 'New'), ('New', 'Science'), ('Science', 'Cause'), ('Cause', 'Effect'), ('Effect', '.')]

>> Trigrams are: 
 [('[', '8', ']'), ('8', ']', 'J.'), (']', 'J.', 'Pearl'), ('J.', 'Pearl', 'D.'), ('Pearl', 'D.', 'Mackenzie'), ('D.', 'Mackenzie', ','), ('Mackenzie', ',', 'The'), (',', 'The', 'Book'), ('The', 'Book', 'Why'), ('Book', 'Why', ':'), ('Why', ':', 'The'), (':', 'The', 'New'), ('The', 'New', 'Science'), ('New', 'Science', 'Cause'), ('Science', 'Cause', 'Effect'), ('Cause', 'Effect', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('8', 'CD'), (']', 'NNP'), ('J.', 'NNP'), ('Pearl', 'NNP'), ('D.', 'NNP'), ('Mackenzie', 'NNP'), (',', ','), ('The', 'DT'), ('Book', 'NNP'), ('Why', 'WRB'), (':', ':'), ('The', 'DT'), ('New', 'NNP'), ('Science', 'NNP'), ('Cause', 'NNP'), ('Effect', 'NNP'), ('.', '.')]

 (S
  [/RB
  8/CD
  (NP ]/NNP J./NNP Pearl/NNP D./NNP Mackenzie/NNP)
  ,/,
  (NP The/DT Book/NNP)
  Why/WRB
  :/:
  (NP The/DT New/NNP Science/NNP Cause/NNP Effect/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] J. Pearl D. Mackenzie', 'The Book', 'The New Science Cause Effect']

>> Named Entities are: 
 [('ORGANIZATION', 'Book'), ('ORGANIZATION', 'New Science Cause Effect')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('J.', 'j.'), ('Pearl', 'pearl'), ('D.', 'd.'), ('Mackenzie', 'mackenzi'), (',', ','), ('The', 'the'), ('Book', 'book'), ('Why', 'whi'), (':', ':'), ('The', 'the'), ('New', 'new'), ('Science', 'scienc'), ('Cause', 'caus'), ('Effect', 'effect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('J.', 'j.'), ('Pearl', 'pearl'), ('D.', 'd.'), ('Mackenzie', 'mackenzi'), (',', ','), ('The', 'the'), ('Book', 'book'), ('Why', 'whi'), (':', ':'), ('The', 'the'), ('New', 'new'), ('Science', 'scienc'), ('Cause', 'caus'), ('Effect', 'effect'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('8', '8'), (']', ']'), ('J.', 'J.'), ('Pearl', 'Pearl'), ('D.', 'D.'), ('Mackenzie', 'Mackenzie'), (',', ','), ('The', 'The'), ('Book', 'Book'), ('Why', 'Why'), (':', ':'), ('The', 'The'), ('New', 'New'), ('Science', 'Science'), ('Cause', 'Cause'), ('Effect', 'Effect'), ('.', '.')]



============================ Sentence 593 =============================

Basic Books, 2018. 


>> Tokens are: 
 ['Basic', 'Books', ',', '2018', '.']

>> Bigrams are: 
 [('Basic', 'Books'), ('Books', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Basic', 'Books', ','), ('Books', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Basic', 'NNP'), ('Books', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S (NP Basic/NNP Books/NNP) ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 ['Basic Books']

>> Named Entities are: 
 [('PERSON', 'Basic'), ('GPE', 'Books')] 

>> Stemming using Porter Stemmer: 
 [('Basic', 'basic'), ('Books', 'book'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Basic', 'basic'), ('Books', 'book'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Basic', 'Basic'), ('Books', 'Books'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 594 =============================

[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine learning in wireless sensor networks: Algorithms, strategies, and applications,” IEEE Communications Surveys & Tutorials, vol. 


>> Tokens are: 
 ['[', '9', ']', 'M.', 'A.', 'Alsheikh', ',', 'S.', 'Lin', ',', 'D.', 'Niyato', ',', 'H.-P.', 'Tan', ',', '“', 'Machine', 'learning', 'wireless', 'sensor', 'networks', ':', 'Algorithms', ',', 'strategies', ',', 'applications', ',', '”', 'IEEE', 'Communications', 'Surveys', '&', 'Tutorials', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '9'), ('9', ']'), (']', 'M.'), ('M.', 'A.'), ('A.', 'Alsheikh'), ('Alsheikh', ','), (',', 'S.'), ('S.', 'Lin'), ('Lin', ','), (',', 'D.'), ('D.', 'Niyato'), ('Niyato', ','), (',', 'H.-P.'), ('H.-P.', 'Tan'), ('Tan', ','), (',', '“'), ('“', 'Machine'), ('Machine', 'learning'), ('learning', 'wireless'), ('wireless', 'sensor'), ('sensor', 'networks'), ('networks', ':'), (':', 'Algorithms'), ('Algorithms', ','), (',', 'strategies'), ('strategies', ','), (',', 'applications'), ('applications', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Surveys'), ('Surveys', '&'), ('&', 'Tutorials'), ('Tutorials', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '9', ']'), ('9', ']', 'M.'), (']', 'M.', 'A.'), ('M.', 'A.', 'Alsheikh'), ('A.', 'Alsheikh', ','), ('Alsheikh', ',', 'S.'), (',', 'S.', 'Lin'), ('S.', 'Lin', ','), ('Lin', ',', 'D.'), (',', 'D.', 'Niyato'), ('D.', 'Niyato', ','), ('Niyato', ',', 'H.-P.'), (',', 'H.-P.', 'Tan'), ('H.-P.', 'Tan', ','), ('Tan', ',', '“'), (',', '“', 'Machine'), ('“', 'Machine', 'learning'), ('Machine', 'learning', 'wireless'), ('learning', 'wireless', 'sensor'), ('wireless', 'sensor', 'networks'), ('sensor', 'networks', ':'), ('networks', ':', 'Algorithms'), (':', 'Algorithms', ','), ('Algorithms', ',', 'strategies'), (',', 'strategies', ','), ('strategies', ',', 'applications'), (',', 'applications', ','), ('applications', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Surveys'), ('Communications', 'Surveys', '&'), ('Surveys', '&', 'Tutorials'), ('&', 'Tutorials', ','), ('Tutorials', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('9', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('A.', 'NNP'), ('Alsheikh', 'NNP'), (',', ','), ('S.', 'NNP'), ('Lin', 'NNP'), (',', ','), ('D.', 'NNP'), ('Niyato', 'NNP'), (',', ','), ('H.-P.', 'NNP'), ('Tan', 'NNP'), (',', ','), ('“', 'NNP'), ('Machine', 'NNP'), ('learning', 'VBG'), ('wireless', 'NN'), ('sensor', 'NN'), ('networks', 'NNS'), (':', ':'), ('Algorithms', 'NNP'), (',', ','), ('strategies', 'NNS'), (',', ','), ('applications', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Surveys', 'NNP'), ('&', 'CC'), ('Tutorials', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  9/CD
  (NP ]/NNP M./NNP A./NNP Alsheikh/NNP)
  ,/,
  (NP S./NNP Lin/NNP)
  ,/,
  (NP D./NNP Niyato/NNP)
  ,/,
  (NP H.-P./NNP Tan/NNP)
  ,/,
  (NP “/NNP Machine/NNP)
  learning/VBG
  (NP wireless/NN sensor/NN networks/NNS)
  :/:
  (NP Algorithms/NNP)
  ,/,
  (NP strategies/NNS)
  ,/,
  (NP applications/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Communications/NNP Surveys/NNP)
  &/CC
  (NP Tutorials/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. A. Alsheikh', 'S. Lin', 'D. Niyato', 'H.-P. Tan', '“ Machine', 'wireless sensor networks', 'Algorithms', 'strategies', 'applications', '” IEEE Communications Surveys', 'Tutorials', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Communications Surveys'), ('PERSON', 'Tutorials')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('M.', 'm.'), ('A.', 'a.'), ('Alsheikh', 'alsheikh'), (',', ','), ('S.', 's.'), ('Lin', 'lin'), (',', ','), ('D.', 'd.'), ('Niyato', 'niyato'), (',', ','), ('H.-P.', 'h.-p.'), ('Tan', 'tan'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (':', ':'), ('Algorithms', 'algorithm'), (',', ','), ('strategies', 'strategi'), (',', ','), ('applications', 'applic'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Surveys', 'survey'), ('&', '&'), ('Tutorials', 'tutori'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('M.', 'm.'), ('A.', 'a.'), ('Alsheikh', 'alsheikh'), (',', ','), ('S.', 's.'), ('Lin', 'lin'), (',', ','), ('D.', 'd.'), ('Niyato', 'niyato'), (',', ','), ('H.-P.', 'h.-p.'), ('Tan', 'tan'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (':', ':'), ('Algorithms', 'algorithm'), (',', ','), ('strategies', 'strategi'), (',', ','), ('applications', 'applic'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Surveys', 'survey'), ('&', '&'), ('Tutorials', 'tutori'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('9', '9'), (']', ']'), ('M.', 'M.'), ('A.', 'A.'), ('Alsheikh', 'Alsheikh'), (',', ','), ('S.', 'S.'), ('Lin', 'Lin'), (',', ','), ('D.', 'D.'), ('Niyato', 'Niyato'), (',', ','), ('H.-P.', 'H.-P.'), ('Tan', 'Tan'), (',', ','), ('“', '“'), ('Machine', 'Machine'), ('learning', 'learning'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (':', ':'), ('Algorithms', 'Algorithms'), (',', ','), ('strategies', 'strategy'), (',', ','), ('applications', 'application'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Surveys', 'Surveys'), ('&', '&'), ('Tutorials', 'Tutorials'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 595 =============================

16, no. 


>> Tokens are: 
 ['16', ',', '.']

>> Bigrams are: 
 [('16', ','), (',', '.')]

>> Trigrams are: 
 [('16', ',', '.')]

>> POS Tags are: 
 [('16', 'CD'), (',', ','), ('.', '.')]

 (S 16/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), (',', ','), ('.', '.')]



============================ Sentence 596 =============================

4, pp. 


>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 4/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 597 =============================

1996–2018, 2014. 


>> Tokens are: 
 ['1996–2018', ',', '2014', '.']

>> Bigrams are: 
 [('1996–2018', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('1996–2018', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('1996–2018', 'CD'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S 1996–2018/CD ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996–2018', '1996–2018'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996–2018', '1996–2018'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('1996–2018', '1996–2018'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 598 =============================

[10] C. Jiang, H. Zhang, Y. Ren, Z. Han, K.-C. Chen, and L. Hanzo, “Machine learning paradigms for next-generation wireless net- works,” IEEE Wireless Communications, vol. 


>> Tokens are: 
 ['[', '10', ']', 'C.', 'Jiang', ',', 'H.', 'Zhang', ',', 'Y.', 'Ren', ',', 'Z.', 'Han', ',', 'K.-C.', 'Chen', ',', 'L.', 'Hanzo', ',', '“', 'Machine', 'learning', 'paradigms', 'next-generation', 'wireless', 'net-', 'works', ',', '”', 'IEEE', 'Wireless', 'Communications', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '10'), ('10', ']'), (']', 'C.'), ('C.', 'Jiang'), ('Jiang', ','), (',', 'H.'), ('H.', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', 'Ren'), ('Ren', ','), (',', 'Z.'), ('Z.', 'Han'), ('Han', ','), (',', 'K.-C.'), ('K.-C.', 'Chen'), ('Chen', ','), (',', 'L.'), ('L.', 'Hanzo'), ('Hanzo', ','), (',', '“'), ('“', 'Machine'), ('Machine', 'learning'), ('learning', 'paradigms'), ('paradigms', 'next-generation'), ('next-generation', 'wireless'), ('wireless', 'net-'), ('net-', 'works'), ('works', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Wireless'), ('Wireless', 'Communications'), ('Communications', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '10', ']'), ('10', ']', 'C.'), (']', 'C.', 'Jiang'), ('C.', 'Jiang', ','), ('Jiang', ',', 'H.'), (',', 'H.', 'Zhang'), ('H.', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', 'Ren'), ('Y.', 'Ren', ','), ('Ren', ',', 'Z.'), (',', 'Z.', 'Han'), ('Z.', 'Han', ','), ('Han', ',', 'K.-C.'), (',', 'K.-C.', 'Chen'), ('K.-C.', 'Chen', ','), ('Chen', ',', 'L.'), (',', 'L.', 'Hanzo'), ('L.', 'Hanzo', ','), ('Hanzo', ',', '“'), (',', '“', 'Machine'), ('“', 'Machine', 'learning'), ('Machine', 'learning', 'paradigms'), ('learning', 'paradigms', 'next-generation'), ('paradigms', 'next-generation', 'wireless'), ('next-generation', 'wireless', 'net-'), ('wireless', 'net-', 'works'), ('net-', 'works', ','), ('works', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Wireless'), ('IEEE', 'Wireless', 'Communications'), ('Wireless', 'Communications', ','), ('Communications', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('C.', 'NNP'), ('Jiang', 'NNP'), (',', ','), ('H.', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Ren', 'NNP'), (',', ','), ('Z.', 'NNP'), ('Han', 'NNP'), (',', ','), ('K.-C.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('L.', 'NNP'), ('Hanzo', 'NNP'), (',', ','), ('“', 'NNP'), ('Machine', 'NNP'), ('learning', 'VBG'), ('paradigms', 'JJ'), ('next-generation', 'JJ'), ('wireless', 'NN'), ('net-', 'JJ'), ('works', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  10/CD
  (NP ]/JJ C./NNP Jiang/NNP)
  ,/,
  (NP H./NNP Zhang/NNP)
  ,/,
  (NP Y./NNP Ren/NNP)
  ,/,
  (NP Z./NNP Han/NNP)
  ,/,
  (NP K.-C./NNP Chen/NNP)
  ,/,
  (NP L./NNP Hanzo/NNP)
  ,/,
  (NP “/NNP Machine/NNP)
  learning/VBG
  (NP paradigms/JJ next-generation/JJ wireless/NN)
  (NP net-/JJ works/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Wireless/NNP Communications/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] C. Jiang', 'H. Zhang', 'Y. Ren', 'Z. Han', 'K.-C. Chen', 'L. Hanzo', '“ Machine', 'paradigms next-generation wireless', 'net- works', '” IEEE Wireless Communications', 'vol']

>> Named Entities are: 
 [('PERSON', 'Jiang'), ('PERSON', 'Zhang'), ('ORGANIZATION', 'Wireless Communications')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('C.', 'c.'), ('Jiang', 'jiang'), (',', ','), ('H.', 'h.'), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Ren', 'ren'), (',', ','), ('Z.', 'z.'), ('Han', 'han'), (',', ','), ('K.-C.', 'k.-c.'), ('Chen', 'chen'), (',', ','), ('L.', 'l.'), ('Hanzo', 'hanzo'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'commun'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('C.', 'c.'), ('Jiang', 'jiang'), (',', ','), ('H.', 'h.'), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Ren', 'ren'), (',', ','), ('Z.', 'z.'), ('Han', 'han'), (',', ','), ('K.-C.', 'k.-c.'), ('Chen', 'chen'), (',', ','), ('L.', 'l.'), ('Hanzo', 'hanzo'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'communic'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('10', '10'), (']', ']'), ('C.', 'C.'), ('Jiang', 'Jiang'), (',', ','), ('H.', 'H.'), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), ('Ren', 'Ren'), (',', ','), ('Z.', 'Z.'), ('Han', 'Han'), (',', ','), ('K.-C.', 'K.-C.'), ('Chen', 'Chen'), (',', ','), ('L.', 'L.'), ('Hanzo', 'Hanzo'), (',', ','), ('“', '“'), ('Machine', 'Machine'), ('learning', 'learning'), ('paradigms', 'paradigm'), ('next-generation', 'next-generation'), ('wireless', 'wireless'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 599 =============================

24, no. 


>> Tokens are: 
 ['24', ',', '.']

>> Bigrams are: 
 [('24', ','), (',', '.')]

>> Trigrams are: 
 [('24', ',', '.')]

>> POS Tags are: 
 [('24', 'CD'), (',', ','), ('.', '.')]

 (S 24/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('24', '24'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('24', '24'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('24', '24'), (',', ','), ('.', '.')]



============================ Sentence 600 =============================

2, pp. 


>> Tokens are: 
 ['2', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 2/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 601 =============================

98– 105, 2017. 


>> Tokens are: 
 ['98–', '105', ',', '2017', '.']

>> Bigrams are: 
 [('98–', '105'), ('105', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('98–', '105', ','), ('105', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('98–', 'CD'), ('105', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 98–/CD 105/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98–', '98–'), ('105', '105'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98–', '98–'), ('105', '105'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('98–', '98–'), ('105', '105'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 602 =============================

[11] Z. Qin, H. Ye, G. Y. Li, and B.-H. F. Juang, “Deep Learning in Physical Layer Communications,” ArXiv e-prints, Jul. 


>> Tokens are: 
 ['[', '11', ']', 'Z.', 'Qin', ',', 'H.', 'Ye', ',', 'G.', 'Y.', 'Li', ',', 'B.-H.', 'F.', 'Juang', ',', '“', 'Deep', 'Learning', 'Physical', 'Layer', 'Communications', ',', '”', 'ArXiv', 'e-prints', ',', 'Jul', '.']

>> Bigrams are: 
 [('[', '11'), ('11', ']'), (']', 'Z.'), ('Z.', 'Qin'), ('Qin', ','), (',', 'H.'), ('H.', 'Ye'), ('Ye', ','), (',', 'G.'), ('G.', 'Y.'), ('Y.', 'Li'), ('Li', ','), (',', 'B.-H.'), ('B.-H.', 'F.'), ('F.', 'Juang'), ('Juang', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Physical'), ('Physical', 'Layer'), ('Layer', 'Communications'), ('Communications', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jul'), ('Jul', '.')]

>> Trigrams are: 
 [('[', '11', ']'), ('11', ']', 'Z.'), (']', 'Z.', 'Qin'), ('Z.', 'Qin', ','), ('Qin', ',', 'H.'), (',', 'H.', 'Ye'), ('H.', 'Ye', ','), ('Ye', ',', 'G.'), (',', 'G.', 'Y.'), ('G.', 'Y.', 'Li'), ('Y.', 'Li', ','), ('Li', ',', 'B.-H.'), (',', 'B.-H.', 'F.'), ('B.-H.', 'F.', 'Juang'), ('F.', 'Juang', ','), ('Juang', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'Learning'), ('Deep', 'Learning', 'Physical'), ('Learning', 'Physical', 'Layer'), ('Physical', 'Layer', 'Communications'), ('Layer', 'Communications', ','), ('Communications', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jul'), (',', 'Jul', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('Z.', 'NNP'), ('Qin', 'NNP'), (',', ','), ('H.', 'NNP'), ('Ye', 'NNP'), (',', ','), ('G.', 'NNP'), ('Y.', 'NNP'), ('Li', 'NNP'), (',', ','), ('B.-H.', 'NNP'), ('F.', 'NNP'), ('Juang', 'NNP'), (',', ','), ('“', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Physical', 'NNP'), ('Layer', 'NNP'), ('Communications', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jul', 'NNP'), ('.', '.')]

 (S
  [/RB
  11/CD
  (NP ]/JJ Z./NNP Qin/NNP)
  ,/,
  (NP H./NNP Ye/NNP)
  ,/,
  (NP G./NNP Y./NNP Li/NNP)
  ,/,
  (NP B.-H./NNP F./NNP Juang/NNP)
  ,/,
  (NP
    “/NNP
    Deep/NNP
    Learning/NNP
    Physical/NNP
    Layer/NNP
    Communications/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jul/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Z. Qin', 'H. Ye', 'G. Y. Li', 'B.-H. F. Juang', '“ Deep Learning Physical Layer Communications', '” ArXiv e-prints', 'Jul']

>> Named Entities are: 
 [('PERSON', 'Juang'), ('PERSON', 'Jul')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Z.', 'z.'), ('Qin', 'qin'), (',', ','), ('H.', 'h.'), ('Ye', 'ye'), (',', ','), ('G.', 'g.'), ('Y.', 'y.'), ('Li', 'li'), (',', ','), ('B.-H.', 'b.-h.'), ('F.', 'f.'), ('Juang', 'juang'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Learning', 'learn'), ('Physical', 'physic'), ('Layer', 'layer'), ('Communications', 'commun'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Z.', 'z.'), ('Qin', 'qin'), (',', ','), ('H.', 'h.'), ('Ye', 'ye'), (',', ','), ('G.', 'g.'), ('Y.', 'y.'), ('Li', 'li'), (',', ','), ('B.-H.', 'b.-h.'), ('F.', 'f.'), ('Juang', 'juang'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Learning', 'learn'), ('Physical', 'physic'), ('Layer', 'layer'), ('Communications', 'communic'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('11', '11'), (']', ']'), ('Z.', 'Z.'), ('Qin', 'Qin'), (',', ','), ('H.', 'H.'), ('Ye', 'Ye'), (',', ','), ('G.', 'G.'), ('Y.', 'Y.'), ('Li', 'Li'), (',', ','), ('B.-H.', 'B.-H.'), ('F.', 'F.'), ('Juang', 'Juang'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Physical', 'Physical'), ('Layer', 'Layer'), ('Communications', 'Communications'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jul', 'Jul'), ('.', '.')]



============================ Sentence 603 =============================

2018. 


>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

 (S 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]



============================ Sentence 604 =============================

[12] S. Lin and D. J. Costello, Error control coding. 


>> Tokens are: 
 ['[', '12', ']', 'S.', 'Lin', 'D.', 'J.', 'Costello', ',', 'Error', 'control', 'coding', '.']

>> Bigrams are: 
 [('[', '12'), ('12', ']'), (']', 'S.'), ('S.', 'Lin'), ('Lin', 'D.'), ('D.', 'J.'), ('J.', 'Costello'), ('Costello', ','), (',', 'Error'), ('Error', 'control'), ('control', 'coding'), ('coding', '.')]

>> Trigrams are: 
 [('[', '12', ']'), ('12', ']', 'S.'), (']', 'S.', 'Lin'), ('S.', 'Lin', 'D.'), ('Lin', 'D.', 'J.'), ('D.', 'J.', 'Costello'), ('J.', 'Costello', ','), ('Costello', ',', 'Error'), (',', 'Error', 'control'), ('Error', 'control', 'coding'), ('control', 'coding', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('12', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('Lin', 'NNP'), ('D.', 'NNP'), ('J.', 'NNP'), ('Costello', 'NNP'), (',', ','), ('Error', 'NNP'), ('control', 'NN'), ('coding', 'NN'), ('.', '.')]

 (S
  [/RB
  12/CD
  (NP ]/NNP S./NNP Lin/NNP D./NNP J./NNP Costello/NNP)
  ,/,
  (NP Error/NNP control/NN coding/NN)
  ./.) 


>> Noun Phrases are: 
 ['] S. Lin D. J. Costello', 'Error control coding']

>> Named Entities are: 
 [('PERSON', 'Lin D. J. Costello'), ('GPE', 'Error')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('S.', 's.'), ('Lin', 'lin'), ('D.', 'd.'), ('J.', 'j.'), ('Costello', 'costello'), (',', ','), ('Error', 'error'), ('control', 'control'), ('coding', 'code'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('S.', 's.'), ('Lin', 'lin'), ('D.', 'd.'), ('J.', 'j.'), ('Costello', 'costello'), (',', ','), ('Error', 'error'), ('control', 'control'), ('coding', 'code'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('12', '12'), (']', ']'), ('S.', 'S.'), ('Lin', 'Lin'), ('D.', 'D.'), ('J.', 'J.'), ('Costello', 'Costello'), (',', ','), ('Error', 'Error'), ('control', 'control'), ('coding', 'coding'), ('.', '.')]



============================ Sentence 605 =============================

Pearson Education India, 2001. 


>> Tokens are: 
 ['Pearson', 'Education', 'India', ',', '2001', '.']

>> Bigrams are: 
 [('Pearson', 'Education'), ('Education', 'India'), ('India', ','), (',', '2001'), ('2001', '.')]

>> Trigrams are: 
 [('Pearson', 'Education', 'India'), ('Education', 'India', ','), ('India', ',', '2001'), (',', '2001', '.')]

>> POS Tags are: 
 [('Pearson', 'NNP'), ('Education', 'NNP'), ('India', 'NNP'), (',', ','), ('2001', 'CD'), ('.', '.')]

 (S (NP Pearson/NNP Education/NNP India/NNP) ,/, 2001/CD ./.) 


>> Noun Phrases are: 
 ['Pearson Education India']

>> Named Entities are: 
 [('PERSON', 'Pearson'), ('PERSON', 'Education India')] 

>> Stemming using Porter Stemmer: 
 [('Pearson', 'pearson'), ('Education', 'educ'), ('India', 'india'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pearson', 'pearson'), ('Education', 'educ'), ('India', 'india'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Lemmatization: 
 [('Pearson', 'Pearson'), ('Education', 'Education'), ('India', 'India'), (',', ','), ('2001', '2001'), ('.', '.')]



============================ Sentence 606 =============================

[13] T. Gruber, S. Cammerer, J. Hoydis, and S. ten Brink, “On deep learning-based channel decoding,” in CISS 2017, 2017, pp. 


>> Tokens are: 
 ['[', '13', ']', 'T.', 'Gruber', ',', 'S.', 'Cammerer', ',', 'J.', 'Hoydis', ',', 'S.', 'ten', 'Brink', ',', '“', 'On', 'deep', 'learning-based', 'channel', 'decoding', ',', '”', 'CISS', '2017', ',', '2017', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', 'T.'), ('T.', 'Gruber'), ('Gruber', ','), (',', 'S.'), ('S.', 'Cammerer'), ('Cammerer', ','), (',', 'J.'), ('J.', 'Hoydis'), ('Hoydis', ','), (',', 'S.'), ('S.', 'ten'), ('ten', 'Brink'), ('Brink', ','), (',', '“'), ('“', 'On'), ('On', 'deep'), ('deep', 'learning-based'), ('learning-based', 'channel'), ('channel', 'decoding'), ('decoding', ','), (',', '”'), ('”', 'CISS'), ('CISS', '2017'), ('2017', ','), (',', '2017'), ('2017', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', 'T.'), (']', 'T.', 'Gruber'), ('T.', 'Gruber', ','), ('Gruber', ',', 'S.'), (',', 'S.', 'Cammerer'), ('S.', 'Cammerer', ','), ('Cammerer', ',', 'J.'), (',', 'J.', 'Hoydis'), ('J.', 'Hoydis', ','), ('Hoydis', ',', 'S.'), (',', 'S.', 'ten'), ('S.', 'ten', 'Brink'), ('ten', 'Brink', ','), ('Brink', ',', '“'), (',', '“', 'On'), ('“', 'On', 'deep'), ('On', 'deep', 'learning-based'), ('deep', 'learning-based', 'channel'), ('learning-based', 'channel', 'decoding'), ('channel', 'decoding', ','), ('decoding', ',', '”'), (',', '”', 'CISS'), ('”', 'CISS', '2017'), ('CISS', '2017', ','), ('2017', ',', '2017'), (',', '2017', ','), ('2017', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('Gruber', 'NNP'), (',', ','), ('S.', 'NNP'), ('Cammerer', 'NNP'), (',', ','), ('J.', 'NNP'), ('Hoydis', 'NNP'), (',', ','), ('S.', 'NNP'), ('ten', 'VBZ'), ('Brink', 'NNP'), (',', ','), ('“', 'NNP'), ('On', 'IN'), ('deep', 'JJ'), ('learning-based', 'JJ'), ('channel', 'NN'), ('decoding', 'NN'), (',', ','), ('”', 'NNP'), ('CISS', 'NNP'), ('2017', 'CD'), (',', ','), ('2017', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  13/CD
  (NP ]/JJ T./NNP Gruber/NNP)
  ,/,
  (NP S./NNP Cammerer/NNP)
  ,/,
  (NP J./NNP Hoydis/NNP)
  ,/,
  (NP S./NNP)
  ten/VBZ
  (NP Brink/NNP)
  ,/,
  (NP “/NNP)
  On/IN
  (NP deep/JJ learning-based/JJ channel/NN decoding/NN)
  ,/,
  (NP ”/NNP CISS/NNP)
  2017/CD
  ,/,
  2017/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] T. Gruber', 'S. Cammerer', 'J. Hoydis', 'S.', 'Brink', '“', 'deep learning-based channel decoding', '” CISS', 'pp']

>> Named Entities are: 
 [('PERSON', 'J. Hoydis'), ('GPE', 'Brink')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('T.', 't.'), ('Gruber', 'gruber'), (',', ','), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('ten', 'ten'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('On', 'on'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('CISS', 'ciss'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('T.', 't.'), ('Gruber', 'gruber'), (',', ','), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('ten', 'ten'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('On', 'on'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('CISS', 'ciss'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('T.', 'T.'), ('Gruber', 'Gruber'), (',', ','), ('S.', 'S.'), ('Cammerer', 'Cammerer'), (',', ','), ('J.', 'J.'), ('Hoydis', 'Hoydis'), (',', ','), ('S.', 'S.'), ('ten', 'ten'), ('Brink', 'Brink'), (',', ','), ('“', '“'), ('On', 'On'), ('deep', 'deep'), ('learning-based', 'learning-based'), ('channel', 'channel'), ('decoding', 'decoding'), (',', ','), ('”', '”'), ('CISS', 'CISS'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 607 =============================

1–6. 


>> Tokens are: 
 ['1–6', '.']

>> Bigrams are: 
 [('1–6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–6', 'CD'), ('.', '.')]

 (S 1–6/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Lemmatization: 
 [('1–6', '1–6'), ('.', '.')]



============================ Sentence 608 =============================

[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine learning: From theory to algorithms. 


>> Tokens are: 
 ['[', '14', ']', 'S.', 'Shalev-Shwartz', 'S.', 'Ben-David', ',', 'Understanding', 'machine', 'learning', ':', 'From', 'theory', 'algorithms', '.']

>> Bigrams are: 
 [('[', '14'), ('14', ']'), (']', 'S.'), ('S.', 'Shalev-Shwartz'), ('Shalev-Shwartz', 'S.'), ('S.', 'Ben-David'), ('Ben-David', ','), (',', 'Understanding'), ('Understanding', 'machine'), ('machine', 'learning'), ('learning', ':'), (':', 'From'), ('From', 'theory'), ('theory', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('[', '14', ']'), ('14', ']', 'S.'), (']', 'S.', 'Shalev-Shwartz'), ('S.', 'Shalev-Shwartz', 'S.'), ('Shalev-Shwartz', 'S.', 'Ben-David'), ('S.', 'Ben-David', ','), ('Ben-David', ',', 'Understanding'), (',', 'Understanding', 'machine'), ('Understanding', 'machine', 'learning'), ('machine', 'learning', ':'), ('learning', ':', 'From'), (':', 'From', 'theory'), ('From', 'theory', 'algorithms'), ('theory', 'algorithms', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('14', 'CD'), (']', 'JJ'), ('S.', 'NNP'), ('Shalev-Shwartz', 'NNP'), ('S.', 'NNP'), ('Ben-David', 'NNP'), (',', ','), ('Understanding', 'NNP'), ('machine', 'NN'), ('learning', 'NN'), (':', ':'), ('From', 'IN'), ('theory', 'NN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  [/RB
  14/CD
  (NP ]/JJ S./NNP Shalev-Shwartz/NNP S./NNP Ben-David/NNP)
  ,/,
  (NP Understanding/NNP machine/NN learning/NN)
  :/:
  From/IN
  (NP theory/NN algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['] S. Shalev-Shwartz S. Ben-David', 'Understanding machine learning', 'theory algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('S.', 's.'), ('Shalev-Shwartz', 'shalev-shwartz'), ('S.', 's.'), ('Ben-David', 'ben-david'), (',', ','), ('Understanding', 'understand'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('From', 'from'), ('theory', 'theori'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('S.', 's.'), ('Shalev-Shwartz', 'shalev-shwartz'), ('S.', 's.'), ('Ben-David', 'ben-david'), (',', ','), ('Understanding', 'understand'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('From', 'from'), ('theory', 'theori'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('14', '14'), (']', ']'), ('S.', 'S.'), ('Shalev-Shwartz', 'Shalev-Shwartz'), ('S.', 'S.'), ('Ben-David', 'Ben-David'), (',', ','), ('Understanding', 'Understanding'), ('machine', 'machine'), ('learning', 'learning'), (':', ':'), ('From', 'From'), ('theory', 'theory'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 609 =============================

Cambridge university press, 2014. 


>> Tokens are: 
 ['Cambridge', 'university', 'press', ',', '2014', '.']

>> Bigrams are: 
 [('Cambridge', 'university'), ('university', 'press'), ('press', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Cambridge', 'university', 'press'), ('university', 'press', ','), ('press', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Cambridge', 'NNP'), ('university', 'NN'), ('press', 'NN'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Cambridge/NNP university/NN press/NN) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Cambridge university press']

>> Named Entities are: 
 [('GPE', 'Cambridge')] 

>> Stemming using Porter Stemmer: 
 [('Cambridge', 'cambridg'), ('university', 'univers'), ('press', 'press'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cambridge', 'cambridg'), ('university', 'univers'), ('press', 'press'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Cambridge', 'Cambridge'), ('university', 'university'), ('press', 'press'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 610 =============================

[15] D. Arpit, S. Jastrzȩbski, N. Ballas, D. Krueger, E. Bengio, M. S. Kanwal, T. Maharaj, A. Fischer, A. Courville, Y. Bengio, and S. Lacoste-Julien, “A Closer Look at Memorization in Deep Networks,” ArXiv e-prints, Jun. 


>> Tokens are: 
 ['[', '15', ']', 'D.', 'Arpit', ',', 'S.', 'Jastrzȩbski', ',', 'N.', 'Ballas', ',', 'D.', 'Krueger', ',', 'E.', 'Bengio', ',', 'M.', 'S.', 'Kanwal', ',', 'T.', 'Maharaj', ',', 'A.', 'Fischer', ',', 'A.', 'Courville', ',', 'Y.', 'Bengio', ',', 'S.', 'Lacoste-Julien', ',', '“', 'A', 'Closer', 'Look', 'Memorization', 'Deep', 'Networks', ',', '”', 'ArXiv', 'e-prints', ',', 'Jun', '.']

>> Bigrams are: 
 [('[', '15'), ('15', ']'), (']', 'D.'), ('D.', 'Arpit'), ('Arpit', ','), (',', 'S.'), ('S.', 'Jastrzȩbski'), ('Jastrzȩbski', ','), (',', 'N.'), ('N.', 'Ballas'), ('Ballas', ','), (',', 'D.'), ('D.', 'Krueger'), ('Krueger', ','), (',', 'E.'), ('E.', 'Bengio'), ('Bengio', ','), (',', 'M.'), ('M.', 'S.'), ('S.', 'Kanwal'), ('Kanwal', ','), (',', 'T.'), ('T.', 'Maharaj'), ('Maharaj', ','), (',', 'A.'), ('A.', 'Fischer'), ('Fischer', ','), (',', 'A.'), ('A.', 'Courville'), ('Courville', ','), (',', 'Y.'), ('Y.', 'Bengio'), ('Bengio', ','), (',', 'S.'), ('S.', 'Lacoste-Julien'), ('Lacoste-Julien', ','), (',', '“'), ('“', 'A'), ('A', 'Closer'), ('Closer', 'Look'), ('Look', 'Memorization'), ('Memorization', 'Deep'), ('Deep', 'Networks'), ('Networks', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jun'), ('Jun', '.')]

>> Trigrams are: 
 [('[', '15', ']'), ('15', ']', 'D.'), (']', 'D.', 'Arpit'), ('D.', 'Arpit', ','), ('Arpit', ',', 'S.'), (',', 'S.', 'Jastrzȩbski'), ('S.', 'Jastrzȩbski', ','), ('Jastrzȩbski', ',', 'N.'), (',', 'N.', 'Ballas'), ('N.', 'Ballas', ','), ('Ballas', ',', 'D.'), (',', 'D.', 'Krueger'), ('D.', 'Krueger', ','), ('Krueger', ',', 'E.'), (',', 'E.', 'Bengio'), ('E.', 'Bengio', ','), ('Bengio', ',', 'M.'), (',', 'M.', 'S.'), ('M.', 'S.', 'Kanwal'), ('S.', 'Kanwal', ','), ('Kanwal', ',', 'T.'), (',', 'T.', 'Maharaj'), ('T.', 'Maharaj', ','), ('Maharaj', ',', 'A.'), (',', 'A.', 'Fischer'), ('A.', 'Fischer', ','), ('Fischer', ',', 'A.'), (',', 'A.', 'Courville'), ('A.', 'Courville', ','), ('Courville', ',', 'Y.'), (',', 'Y.', 'Bengio'), ('Y.', 'Bengio', ','), ('Bengio', ',', 'S.'), (',', 'S.', 'Lacoste-Julien'), ('S.', 'Lacoste-Julien', ','), ('Lacoste-Julien', ',', '“'), (',', '“', 'A'), ('“', 'A', 'Closer'), ('A', 'Closer', 'Look'), ('Closer', 'Look', 'Memorization'), ('Look', 'Memorization', 'Deep'), ('Memorization', 'Deep', 'Networks'), ('Deep', 'Networks', ','), ('Networks', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jun'), (',', 'Jun', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Arpit', 'NNP'), (',', ','), ('S.', 'NNP'), ('Jastrzȩbski', 'NNP'), (',', ','), ('N.', 'NNP'), ('Ballas', 'NNP'), (',', ','), ('D.', 'NNP'), ('Krueger', 'NNP'), (',', ','), ('E.', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('M.', 'NNP'), ('S.', 'NNP'), ('Kanwal', 'NNP'), (',', ','), ('T.', 'NNP'), ('Maharaj', 'NNP'), (',', ','), ('A.', 'NNP'), ('Fischer', 'NNP'), (',', ','), ('A.', 'NNP'), ('Courville', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('S.', 'NNP'), ('Lacoste-Julien', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('Closer', 'NNP'), ('Look', 'NNP'), ('Memorization', 'NNP'), ('Deep', 'NNP'), ('Networks', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jun', 'NNP'), ('.', '.')]

 (S
  [/RB
  15/CD
  (NP ]/JJ D./NNP Arpit/NNP)
  ,/,
  (NP S./NNP Jastrzȩbski/NNP)
  ,/,
  (NP N./NNP Ballas/NNP)
  ,/,
  (NP D./NNP Krueger/NNP)
  ,/,
  (NP E./NNP Bengio/NNP)
  ,/,
  (NP M./NNP S./NNP Kanwal/NNP)
  ,/,
  (NP T./NNP Maharaj/NNP)
  ,/,
  (NP A./NNP Fischer/NNP)
  ,/,
  (NP A./NNP Courville/NNP)
  ,/,
  (NP Y./NNP Bengio/NNP)
  ,/,
  (NP S./NNP Lacoste-Julien/NNP)
  ,/,
  “/VBZ
  (NP
    A/NNP
    Closer/NNP
    Look/NNP
    Memorization/NNP
    Deep/NNP
    Networks/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jun/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] D. Arpit', 'S. Jastrzȩbski', 'N. Ballas', 'D. Krueger', 'E. Bengio', 'M. S. Kanwal', 'T. Maharaj', 'A. Fischer', 'A. Courville', 'Y. Bengio', 'S. Lacoste-Julien', 'A Closer Look Memorization Deep Networks', '” ArXiv e-prints', 'Jun']

>> Named Entities are: 
 [('PERSON', 'Networks'), ('PERSON', 'Jun')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('D.', 'd.'), ('Arpit', 'arpit'), (',', ','), ('S.', 's.'), ('Jastrzȩbski', 'jastrzȩbski'), (',', ','), ('N.', 'n.'), ('Ballas', 'balla'), (',', ','), ('D.', 'd.'), ('Krueger', 'krueger'), (',', ','), ('E.', 'e.'), ('Bengio', 'bengio'), (',', ','), ('M.', 'm.'), ('S.', 's.'), ('Kanwal', 'kanwal'), (',', ','), ('T.', 't.'), ('Maharaj', 'maharaj'), (',', ','), ('A.', 'a.'), ('Fischer', 'fischer'), (',', ','), ('A.', 'a.'), ('Courville', 'courvil'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('S.', 's.'), ('Lacoste-Julien', 'lacoste-julien'), (',', ','), ('“', '“'), ('A', 'a'), ('Closer', 'closer'), ('Look', 'look'), ('Memorization', 'memor'), ('Deep', 'deep'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jun', 'jun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('D.', 'd.'), ('Arpit', 'arpit'), (',', ','), ('S.', 's.'), ('Jastrzȩbski', 'jastrzȩbski'), (',', ','), ('N.', 'n.'), ('Ballas', 'balla'), (',', ','), ('D.', 'd.'), ('Krueger', 'krueger'), (',', ','), ('E.', 'e.'), ('Bengio', 'bengio'), (',', ','), ('M.', 'm.'), ('S.', 's.'), ('Kanwal', 'kanwal'), (',', ','), ('T.', 't.'), ('Maharaj', 'maharaj'), (',', ','), ('A.', 'a.'), ('Fischer', 'fischer'), (',', ','), ('A.', 'a.'), ('Courville', 'courvill'), (',', ','), ('Y.', 'y.'), ('Bengio', 'bengio'), (',', ','), ('S.', 's.'), ('Lacoste-Julien', 'lacoste-julien'), (',', ','), ('“', '“'), ('A', 'a'), ('Closer', 'closer'), ('Look', 'look'), ('Memorization', 'memor'), ('Deep', 'deep'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jun', 'jun'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']'), ('D.', 'D.'), ('Arpit', 'Arpit'), (',', ','), ('S.', 'S.'), ('Jastrzȩbski', 'Jastrzȩbski'), (',', ','), ('N.', 'N.'), ('Ballas', 'Ballas'), (',', ','), ('D.', 'D.'), ('Krueger', 'Krueger'), (',', ','), ('E.', 'E.'), ('Bengio', 'Bengio'), (',', ','), ('M.', 'M.'), ('S.', 'S.'), ('Kanwal', 'Kanwal'), (',', ','), ('T.', 'T.'), ('Maharaj', 'Maharaj'), (',', ','), ('A.', 'A.'), ('Fischer', 'Fischer'), (',', ','), ('A.', 'A.'), ('Courville', 'Courville'), (',', ','), ('Y.', 'Y.'), ('Bengio', 'Bengio'), (',', ','), ('S.', 'S.'), ('Lacoste-Julien', 'Lacoste-Julien'), (',', ','), ('“', '“'), ('A', 'A'), ('Closer', 'Closer'), ('Look', 'Look'), ('Memorization', 'Memorization'), ('Deep', 'Deep'), ('Networks', 'Networks'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jun', 'Jun'), ('.', '.')]



============================ Sentence 611 =============================

2017. 


>> Tokens are: 
 ['2017', '.']

>> Bigrams are: 
 [('2017', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD'), ('.', '.')]

 (S 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('2017', '2017'), ('.', '.')]



============================ Sentence 612 =============================

[16] T. Hastie, R. Tibshirani, and J. Friedman, “Unsupervised learn- ing,” in The elements of statistical learning. 


>> Tokens are: 
 ['[', '16', ']', 'T.', 'Hastie', ',', 'R.', 'Tibshirani', ',', 'J.', 'Friedman', ',', '“', 'Unsupervised', 'learn-', 'ing', ',', '”', 'The', 'elements', 'statistical', 'learning', '.']

>> Bigrams are: 
 [('[', '16'), ('16', ']'), (']', 'T.'), ('T.', 'Hastie'), ('Hastie', ','), (',', 'R.'), ('R.', 'Tibshirani'), ('Tibshirani', ','), (',', 'J.'), ('J.', 'Friedman'), ('Friedman', ','), (',', '“'), ('“', 'Unsupervised'), ('Unsupervised', 'learn-'), ('learn-', 'ing'), ('ing', ','), (',', '”'), ('”', 'The'), ('The', 'elements'), ('elements', 'statistical'), ('statistical', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('[', '16', ']'), ('16', ']', 'T.'), (']', 'T.', 'Hastie'), ('T.', 'Hastie', ','), ('Hastie', ',', 'R.'), (',', 'R.', 'Tibshirani'), ('R.', 'Tibshirani', ','), ('Tibshirani', ',', 'J.'), (',', 'J.', 'Friedman'), ('J.', 'Friedman', ','), ('Friedman', ',', '“'), (',', '“', 'Unsupervised'), ('“', 'Unsupervised', 'learn-'), ('Unsupervised', 'learn-', 'ing'), ('learn-', 'ing', ','), ('ing', ',', '”'), (',', '”', 'The'), ('”', 'The', 'elements'), ('The', 'elements', 'statistical'), ('elements', 'statistical', 'learning'), ('statistical', 'learning', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('16', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('Hastie', 'NNP'), (',', ','), ('R.', 'NNP'), ('Tibshirani', 'NNP'), (',', ','), ('J.', 'NNP'), ('Friedman', 'NNP'), (',', ','), ('“', 'NNP'), ('Unsupervised', 'VBD'), ('learn-', 'JJ'), ('ing', 'NN'), (',', ','), ('”', 'VBP'), ('The', 'DT'), ('elements', 'NNS'), ('statistical', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  [/RB
  16/CD
  (NP ]/JJ T./NNP Hastie/NNP)
  ,/,
  (NP R./NNP Tibshirani/NNP)
  ,/,
  (NP J./NNP Friedman/NNP)
  ,/,
  (NP “/NNP)
  Unsupervised/VBD
  (NP learn-/JJ ing/NN)
  ,/,
  ”/VBP
  (NP The/DT elements/NNS)
  (NP statistical/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['] T. Hastie', 'R. Tibshirani', 'J. Friedman', '“', 'learn- ing', 'The elements', 'statistical learning']

>> Named Entities are: 
 [('PERSON', 'J. Friedman')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('T.', 't.'), ('Hastie', 'hasti'), (',', ','), ('R.', 'r.'), ('Tibshirani', 'tibshirani'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('“', '“'), ('Unsupervised', 'unsupervis'), ('learn-', 'learn-'), ('ing', 'ing'), (',', ','), ('”', '”'), ('The', 'the'), ('elements', 'element'), ('statistical', 'statist'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('T.', 't.'), ('Hastie', 'hasti'), (',', ','), ('R.', 'r.'), ('Tibshirani', 'tibshirani'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('“', '“'), ('Unsupervised', 'unsupervis'), ('learn-', 'learn-'), ('ing', 'ing'), (',', ','), ('”', '”'), ('The', 'the'), ('elements', 'element'), ('statistical', 'statist'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('16', '16'), (']', ']'), ('T.', 'T.'), ('Hastie', 'Hastie'), (',', ','), ('R.', 'R.'), ('Tibshirani', 'Tibshirani'), (',', ','), ('J.', 'J.'), ('Friedman', 'Friedman'), (',', ','), ('“', '“'), ('Unsupervised', 'Unsupervised'), ('learn-', 'learn-'), ('ing', 'ing'), (',', ','), ('”', '”'), ('The', 'The'), ('elements', 'element'), ('statistical', 'statistical'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 613 =============================

Springer, 2009, pp. 


>> Tokens are: 
 ['Springer', ',', '2009', ',', 'pp', '.']

>> Bigrams are: 
 [('Springer', ','), (',', '2009'), ('2009', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Springer', ',', '2009'), (',', '2009', ','), ('2009', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), (',', ','), ('2009', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Springer/NNP) ,/, 2009/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Springer', 'pp']

>> Named Entities are: 
 [('GPE', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), (',', ','), ('2009', '2009'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), (',', ','), ('2009', '2009'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), (',', ','), ('2009', '2009'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 614 =============================

485–585. 


>> Tokens are: 
 ['485–585', '.']

>> Bigrams are: 
 [('485–585', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('485–585', 'CD'), ('.', '.')]

 (S 485–585/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('485–585', '485–585'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('485–585', '485–585'), ('.', '.')]

>> Lemmatization: 
 [('485–585', '485–585'), ('.', '.')]



============================ Sentence 615 =============================

[17] R. S. Sutton, A. G. Barto et al., Reinforcement learning: An introduction. 


>> Tokens are: 
 ['[', '17', ']', 'R.', 'S.', 'Sutton', ',', 'A.', 'G.', 'Barto', 'et', 'al.', ',', 'Reinforcement', 'learning', ':', 'An', 'introduction', '.']

>> Bigrams are: 
 [('[', '17'), ('17', ']'), (']', 'R.'), ('R.', 'S.'), ('S.', 'Sutton'), ('Sutton', ','), (',', 'A.'), ('A.', 'G.'), ('G.', 'Barto'), ('Barto', 'et'), ('et', 'al.'), ('al.', ','), (',', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', ':'), (':', 'An'), ('An', 'introduction'), ('introduction', '.')]

>> Trigrams are: 
 [('[', '17', ']'), ('17', ']', 'R.'), (']', 'R.', 'S.'), ('R.', 'S.', 'Sutton'), ('S.', 'Sutton', ','), ('Sutton', ',', 'A.'), (',', 'A.', 'G.'), ('A.', 'G.', 'Barto'), ('G.', 'Barto', 'et'), ('Barto', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', 'Reinforcement'), (',', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', ':'), ('learning', ':', 'An'), (':', 'An', 'introduction'), ('An', 'introduction', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('17', 'CD'), (']', 'JJ'), ('R.', 'NNP'), ('S.', 'NNP'), ('Sutton', 'NNP'), (',', ','), ('A.', 'NNP'), ('G.', 'NNP'), ('Barto', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('Reinforcement', 'NNP'), ('learning', 'NN'), (':', ':'), ('An', 'DT'), ('introduction', 'NN'), ('.', '.')]

 (S
  [/RB
  17/CD
  (NP ]/JJ R./NNP S./NNP Sutton/NNP)
  ,/,
  (NP A./NNP G./NNP Barto/NNP)
  et/FW
  (NP al./NN)
  ,/,
  (NP Reinforcement/NNP learning/NN)
  :/:
  (NP An/DT introduction/NN)
  ./.) 


>> Noun Phrases are: 
 ['] R. S. Sutton', 'A. G. Barto', 'al.', 'Reinforcement learning', 'An introduction']

>> Named Entities are: 
 [('PERSON', 'Sutton'), ('PERSON', 'Barto')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('R.', 'r.'), ('S.', 's.'), ('Sutton', 'sutton'), (',', ','), ('A.', 'a.'), ('G.', 'g.'), ('Barto', 'barto'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('Reinforcement', 'reinforc'), ('learning', 'learn'), (':', ':'), ('An', 'an'), ('introduction', 'introduct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('R.', 'r.'), ('S.', 's.'), ('Sutton', 'sutton'), (',', ','), ('A.', 'a.'), ('G.', 'g.'), ('Barto', 'barto'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('Reinforcement', 'reinforc'), ('learning', 'learn'), (':', ':'), ('An', 'an'), ('introduction', 'introduct'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('17', '17'), (']', ']'), ('R.', 'R.'), ('S.', 'S.'), ('Sutton', 'Sutton'), (',', ','), ('A.', 'A.'), ('G.', 'G.'), ('Barto', 'Barto'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('Reinforcement', 'Reinforcement'), ('learning', 'learning'), (':', ':'), ('An', 'An'), ('introduction', 'introduction'), ('.', '.')]



============================ Sentence 616 =============================

MIT press, 2018. 


>> Tokens are: 
 ['MIT', 'press', ',', '2018', '.']

>> Bigrams are: 
 [('MIT', 'press'), ('press', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('MIT', 'press', ','), ('press', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('press', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S (NP MIT/NNP press/NN) ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 ['MIT press']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('press', 'press'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 617 =============================

[18] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershel- vam, M. Lanctot et al., “Mastering the game of go with deep neural networks and tree search,” Nature, vol. 


>> Tokens are: 
 ['[', '18', ']', 'D.', 'Silver', ',', 'A.', 'Huang', ',', 'C.', 'J.', 'Maddison', ',', 'A.', 'Guez', ',', 'L.', 'Sifre', ',', 'G.', 'Van', 'Den', 'Driessche', ',', 'J.', 'Schrittwieser', ',', 'I.', 'Antonoglou', ',', 'V.', 'Panneershel-', 'vam', ',', 'M.', 'Lanctot', 'et', 'al.', ',', '“', 'Mastering', 'game', 'go', 'deep', 'neural', 'networks', 'tree', 'search', ',', '”', 'Nature', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '18'), ('18', ']'), (']', 'D.'), ('D.', 'Silver'), ('Silver', ','), (',', 'A.'), ('A.', 'Huang'), ('Huang', ','), (',', 'C.'), ('C.', 'J.'), ('J.', 'Maddison'), ('Maddison', ','), (',', 'A.'), ('A.', 'Guez'), ('Guez', ','), (',', 'L.'), ('L.', 'Sifre'), ('Sifre', ','), (',', 'G.'), ('G.', 'Van'), ('Van', 'Den'), ('Den', 'Driessche'), ('Driessche', ','), (',', 'J.'), ('J.', 'Schrittwieser'), ('Schrittwieser', ','), (',', 'I.'), ('I.', 'Antonoglou'), ('Antonoglou', ','), (',', 'V.'), ('V.', 'Panneershel-'), ('Panneershel-', 'vam'), ('vam', ','), (',', 'M.'), ('M.', 'Lanctot'), ('Lanctot', 'et'), ('et', 'al.'), ('al.', ','), (',', '“'), ('“', 'Mastering'), ('Mastering', 'game'), ('game', 'go'), ('go', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'tree'), ('tree', 'search'), ('search', ','), (',', '”'), ('”', 'Nature'), ('Nature', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '18', ']'), ('18', ']', 'D.'), (']', 'D.', 'Silver'), ('D.', 'Silver', ','), ('Silver', ',', 'A.'), (',', 'A.', 'Huang'), ('A.', 'Huang', ','), ('Huang', ',', 'C.'), (',', 'C.', 'J.'), ('C.', 'J.', 'Maddison'), ('J.', 'Maddison', ','), ('Maddison', ',', 'A.'), (',', 'A.', 'Guez'), ('A.', 'Guez', ','), ('Guez', ',', 'L.'), (',', 'L.', 'Sifre'), ('L.', 'Sifre', ','), ('Sifre', ',', 'G.'), (',', 'G.', 'Van'), ('G.', 'Van', 'Den'), ('Van', 'Den', 'Driessche'), ('Den', 'Driessche', ','), ('Driessche', ',', 'J.'), (',', 'J.', 'Schrittwieser'), ('J.', 'Schrittwieser', ','), ('Schrittwieser', ',', 'I.'), (',', 'I.', 'Antonoglou'), ('I.', 'Antonoglou', ','), ('Antonoglou', ',', 'V.'), (',', 'V.', 'Panneershel-'), ('V.', 'Panneershel-', 'vam'), ('Panneershel-', 'vam', ','), ('vam', ',', 'M.'), (',', 'M.', 'Lanctot'), ('M.', 'Lanctot', 'et'), ('Lanctot', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '“'), (',', '“', 'Mastering'), ('“', 'Mastering', 'game'), ('Mastering', 'game', 'go'), ('game', 'go', 'deep'), ('go', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'tree'), ('networks', 'tree', 'search'), ('tree', 'search', ','), ('search', ',', '”'), (',', '”', 'Nature'), ('”', 'Nature', ','), ('Nature', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('18', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Silver', 'NNP'), (',', ','), ('A.', 'NNP'), ('Huang', 'NNP'), (',', ','), ('C.', 'NNP'), ('J.', 'NNP'), ('Maddison', 'NNP'), (',', ','), ('A.', 'NNP'), ('Guez', 'NNP'), (',', ','), ('L.', 'NNP'), ('Sifre', 'NNP'), (',', ','), ('G.', 'NNP'), ('Van', 'NNP'), ('Den', 'NNP'), ('Driessche', 'NNP'), (',', ','), ('J.', 'NNP'), ('Schrittwieser', 'NNP'), (',', ','), ('I.', 'NNP'), ('Antonoglou', 'NNP'), (',', ','), ('V.', 'NNP'), ('Panneershel-', 'NNP'), ('vam', 'NN'), (',', ','), ('M.', 'NNP'), ('Lanctot', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('“', 'NNP'), ('Mastering', 'NNP'), ('game', 'NN'), ('go', 'VBP'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('tree', 'VBP'), ('search', 'NN'), (',', ','), ('”', 'JJ'), ('Nature', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  18/CD
  (NP ]/JJ D./NNP Silver/NNP)
  ,/,
  (NP A./NNP Huang/NNP)
  ,/,
  (NP C./NNP J./NNP Maddison/NNP)
  ,/,
  (NP A./NNP Guez/NNP)
  ,/,
  (NP L./NNP Sifre/NNP)
  ,/,
  (NP G./NNP Van/NNP Den/NNP Driessche/NNP)
  ,/,
  (NP J./NNP Schrittwieser/NNP)
  ,/,
  (NP I./NNP Antonoglou/NNP)
  ,/,
  (NP V./NNP Panneershel-/NNP vam/NN)
  ,/,
  (NP M./NNP Lanctot/NNP)
  et/FW
  (NP al./NN)
  ,/,
  (NP “/NNP Mastering/NNP game/NN)
  go/VBP
  (NP deep/JJ neural/JJ networks/NNS)
  tree/VBP
  (NP search/NN)
  ,/,
  (NP ”/JJ Nature/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] D. Silver', 'A. Huang', 'C. J. Maddison', 'A. Guez', 'L. Sifre', 'G. Van Den Driessche', 'J. Schrittwieser', 'I. Antonoglou', 'V. Panneershel- vam', 'M. Lanctot', 'al.', '“ Mastering game', 'deep neural networks', 'search', '” Nature', 'vol']

>> Named Entities are: 
 [('PERSON', 'Huang'), ('PERSON', 'Maddison'), ('PERSON', 'Van Den Driessche'), ('PERSON', 'J. Schrittwieser')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('D.', 'd.'), ('Silver', 'silver'), (',', ','), ('A.', 'a.'), ('Huang', 'huang'), (',', ','), ('C.', 'c.'), ('J.', 'j.'), ('Maddison', 'maddison'), (',', ','), ('A.', 'a.'), ('Guez', 'guez'), (',', ','), ('L.', 'l.'), ('Sifre', 'sifr'), (',', ','), ('G.', 'g.'), ('Van', 'van'), ('Den', 'den'), ('Driessche', 'driessch'), (',', ','), ('J.', 'j.'), ('Schrittwieser', 'schrittwies'), (',', ','), ('I.', 'i.'), ('Antonoglou', 'antonogl'), (',', ','), ('V.', 'v.'), ('Panneershel-', 'panneershel-'), ('vam', 'vam'), (',', ','), ('M.', 'm.'), ('Lanctot', 'lanctot'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Mastering', 'master'), ('game', 'game'), ('go', 'go'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('tree', 'tree'), ('search', 'search'), (',', ','), ('”', '”'), ('Nature', 'natur'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('D.', 'd.'), ('Silver', 'silver'), (',', ','), ('A.', 'a.'), ('Huang', 'huang'), (',', ','), ('C.', 'c.'), ('J.', 'j.'), ('Maddison', 'maddison'), (',', ','), ('A.', 'a.'), ('Guez', 'guez'), (',', ','), ('L.', 'l.'), ('Sifre', 'sifr'), (',', ','), ('G.', 'g.'), ('Van', 'van'), ('Den', 'den'), ('Driessche', 'driessch'), (',', ','), ('J.', 'j.'), ('Schrittwieser', 'schrittwies'), (',', ','), ('I.', 'i.'), ('Antonoglou', 'antonoglou'), (',', ','), ('V.', 'v.'), ('Panneershel-', 'panneershel-'), ('vam', 'vam'), (',', ','), ('M.', 'm.'), ('Lanctot', 'lanctot'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Mastering', 'master'), ('game', 'game'), ('go', 'go'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('tree', 'tree'), ('search', 'search'), (',', ','), ('”', '”'), ('Nature', 'natur'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('18', '18'), (']', ']'), ('D.', 'D.'), ('Silver', 'Silver'), (',', ','), ('A.', 'A.'), ('Huang', 'Huang'), (',', ','), ('C.', 'C.'), ('J.', 'J.'), ('Maddison', 'Maddison'), (',', ','), ('A.', 'A.'), ('Guez', 'Guez'), (',', ','), ('L.', 'L.'), ('Sifre', 'Sifre'), (',', ','), ('G.', 'G.'), ('Van', 'Van'), ('Den', 'Den'), ('Driessche', 'Driessche'), (',', ','), ('J.', 'J.'), ('Schrittwieser', 'Schrittwieser'), (',', ','), ('I.', 'I.'), ('Antonoglou', 'Antonoglou'), (',', ','), ('V.', 'V.'), ('Panneershel-', 'Panneershel-'), ('vam', 'vam'), (',', ','), ('M.', 'M.'), ('Lanctot', 'Lanctot'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Mastering', 'Mastering'), ('game', 'game'), ('go', 'go'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('tree', 'tree'), ('search', 'search'), (',', ','), ('”', '”'), ('Nature', 'Nature'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 618 =============================

529, no. 


>> Tokens are: 
 ['529', ',', '.']

>> Bigrams are: 
 [('529', ','), (',', '.')]

>> Trigrams are: 
 [('529', ',', '.')]

>> POS Tags are: 
 [('529', 'CD'), (',', ','), ('.', '.')]

 (S 529/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('529', '529'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('529', '529'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('529', '529'), (',', ','), ('.', '.')]



============================ Sentence 619 =============================

7587, p. 484, 2016. 


>> Tokens are: 
 ['7587', ',', 'p.', '484', ',', '2016', '.']

>> Bigrams are: 
 [('7587', ','), (',', 'p.'), ('p.', '484'), ('484', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('7587', ',', 'p.'), (',', 'p.', '484'), ('p.', '484', ','), ('484', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('7587', 'CD'), (',', ','), ('p.', 'VBZ'), ('484', 'CD'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S 7587/CD ,/, p./VBZ 484/CD ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7587', '7587'), (',', ','), ('p.', 'p.'), ('484', '484'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7587', '7587'), (',', ','), ('p.', 'p.'), ('484', '484'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('7587', '7587'), (',', ','), ('p.', 'p.'), ('484', '484'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 620 =============================

[19] O. Simeone, “A brief introduction to machine learning for en- gineers,” Foundations and Trends in Signal Processing, vol. 


>> Tokens are: 
 ['[', '19', ']', 'O.', 'Simeone', ',', '“', 'A', 'brief', 'introduction', 'machine', 'learning', 'en-', 'gineers', ',', '”', 'Foundations', 'Trends', 'Signal', 'Processing', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '19'), ('19', ']'), (']', 'O.'), ('O.', 'Simeone'), ('Simeone', ','), (',', '“'), ('“', 'A'), ('A', 'brief'), ('brief', 'introduction'), ('introduction', 'machine'), ('machine', 'learning'), ('learning', 'en-'), ('en-', 'gineers'), ('gineers', ','), (',', '”'), ('”', 'Foundations'), ('Foundations', 'Trends'), ('Trends', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '19', ']'), ('19', ']', 'O.'), (']', 'O.', 'Simeone'), ('O.', 'Simeone', ','), ('Simeone', ',', '“'), (',', '“', 'A'), ('“', 'A', 'brief'), ('A', 'brief', 'introduction'), ('brief', 'introduction', 'machine'), ('introduction', 'machine', 'learning'), ('machine', 'learning', 'en-'), ('learning', 'en-', 'gineers'), ('en-', 'gineers', ','), ('gineers', ',', '”'), (',', '”', 'Foundations'), ('”', 'Foundations', 'Trends'), ('Foundations', 'Trends', 'Signal'), ('Trends', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('19', 'CD'), (']', 'JJ'), ('O.', 'NNP'), ('Simeone', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('brief', 'JJ'), ('introduction', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('en-', 'JJ'), ('gineers', 'NNS'), (',', ','), ('”', 'JJ'), ('Foundations', 'NNP'), ('Trends', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  19/CD
  (NP ]/JJ O./NNP Simeone/NNP)
  ,/,
  “/VBZ
  (NP A/NNP)
  (NP brief/JJ introduction/NN machine/NN)
  learning/VBG
  (NP en-/JJ gineers/NNS)
  ,/,
  (NP ”/JJ Foundations/NNP Trends/NNP Signal/NNP Processing/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] O. Simeone', 'A', 'brief introduction machine', 'en- gineers', '” Foundations Trends Signal Processing', 'vol']

>> Named Entities are: 
 [('PERSON', 'Trends Signal Processing')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('“', '“'), ('A', 'a'), ('brief', 'brief'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn'), ('en-', 'en-'), ('gineers', 'gineer'), (',', ','), ('”', '”'), ('Foundations', 'foundat'), ('Trends', 'trend'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('“', '“'), ('A', 'a'), ('brief', 'brief'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn'), ('en-', 'en-'), ('gineers', 'gineer'), (',', ','), ('”', '”'), ('Foundations', 'foundat'), ('Trends', 'trend'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('19', '19'), (']', ']'), ('O.', 'O.'), ('Simeone', 'Simeone'), (',', ','), ('“', '“'), ('A', 'A'), ('brief', 'brief'), ('introduction', 'introduction'), ('machine', 'machine'), ('learning', 'learning'), ('en-', 'en-'), ('gineers', 'gineers'), (',', ','), ('”', '”'), ('Foundations', 'Foundations'), ('Trends', 'Trends'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 621 =============================

12, no. 


>> Tokens are: 
 ['12', ',', '.']

>> Bigrams are: 
 [('12', ','), (',', '.')]

>> Trigrams are: 
 [('12', ',', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('.', '.')]

 (S 12/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('.', '.')]



============================ Sentence 622 =============================

3-4, pp. 


>> Tokens are: 
 ['3-4', ',', 'pp', '.']

>> Bigrams are: 
 [('3-4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3-4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3-4', 'JJ'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3-4/JJ ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-4', '3-4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-4', '3-4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3-4', '3-4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 623 =============================

200–431, 2018. 


>> Tokens are: 
 ['200–431', ',', '2018', '.']

>> Bigrams are: 
 [('200–431', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('200–431', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('200–431', 'CD'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S 200–431/CD ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('200–431', '200–431'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('200–431', '200–431'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('200–431', '200–431'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 624 =============================

[20] E. Brynjolfsson and T. Mitchell, “What can machine learning do? 


>> Tokens are: 
 ['[', '20', ']', 'E.', 'Brynjolfsson', 'T.', 'Mitchell', ',', '“', 'What', 'machine', 'learning', '?']

>> Bigrams are: 
 [('[', '20'), ('20', ']'), (']', 'E.'), ('E.', 'Brynjolfsson'), ('Brynjolfsson', 'T.'), ('T.', 'Mitchell'), ('Mitchell', ','), (',', '“'), ('“', 'What'), ('What', 'machine'), ('machine', 'learning'), ('learning', '?')]

>> Trigrams are: 
 [('[', '20', ']'), ('20', ']', 'E.'), (']', 'E.', 'Brynjolfsson'), ('E.', 'Brynjolfsson', 'T.'), ('Brynjolfsson', 'T.', 'Mitchell'), ('T.', 'Mitchell', ','), ('Mitchell', ',', '“'), (',', '“', 'What'), ('“', 'What', 'machine'), ('What', 'machine', 'learning'), ('machine', 'learning', '?')]

>> POS Tags are: 
 [('[', 'RB'), ('20', 'CD'), (']', 'NNP'), ('E.', 'NNP'), ('Brynjolfsson', 'NNP'), ('T.', 'NNP'), ('Mitchell', 'NNP'), (',', ','), ('“', 'VBZ'), ('What', 'WP'), ('machine', 'NN'), ('learning', 'NN'), ('?', '.')]

 (S
  [/RB
  20/CD
  (NP ]/NNP E./NNP Brynjolfsson/NNP T./NNP Mitchell/NNP)
  ,/,
  “/VBZ
  What/WP
  (NP machine/NN learning/NN)
  ?/.) 


>> Noun Phrases are: 
 ['] E. Brynjolfsson T. Mitchell', 'machine learning']

>> Named Entities are: 
 [('PERSON', 'Brynjolfsson T. Mitchell')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('E.', 'e.'), ('Brynjolfsson', 'brynjolfsson'), ('T.', 't.'), ('Mitchell', 'mitchel'), (',', ','), ('“', '“'), ('What', 'what'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('E.', 'e.'), ('Brynjolfsson', 'brynjolfsson'), ('T.', 't.'), ('Mitchell', 'mitchel'), (',', ','), ('“', '“'), ('What', 'what'), ('machine', 'machin'), ('learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('[', '['), ('20', '20'), (']', ']'), ('E.', 'E.'), ('Brynjolfsson', 'Brynjolfsson'), ('T.', 'T.'), ('Mitchell', 'Mitchell'), (',', ','), ('“', '“'), ('What', 'What'), ('machine', 'machine'), ('learning', 'learning'), ('?', '?')]



============================ Sentence 625 =============================

Workforce implications,” Science, vol. 


>> Tokens are: 
 ['Workforce', 'implications', ',', '”', 'Science', ',', 'vol', '.']

>> Bigrams are: 
 [('Workforce', 'implications'), ('implications', ','), (',', '”'), ('”', 'Science'), ('Science', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Workforce', 'implications', ','), ('implications', ',', '”'), (',', '”', 'Science'), ('”', 'Science', ','), ('Science', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('Workforce', 'NNP'), ('implications', 'NNS'), (',', ','), ('”', 'NNP'), ('Science', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP Workforce/NNP implications/NNS)
  ,/,
  (NP ”/NNP Science/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['Workforce implications', '” Science', 'vol']

>> Named Entities are: 
 [('GPE', 'Workforce')] 

>> Stemming using Porter Stemmer: 
 [('Workforce', 'workforc'), ('implications', 'implic'), (',', ','), ('”', '”'), ('Science', 'scienc'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Workforce', 'workforc'), ('implications', 'implic'), (',', ','), ('”', '”'), ('Science', 'scienc'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Workforce', 'Workforce'), ('implications', 'implication'), (',', ','), ('”', '”'), ('Science', 'Science'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 626 =============================

358, no. 


>> Tokens are: 
 ['358', ',', '.']

>> Bigrams are: 
 [('358', ','), (',', '.')]

>> Trigrams are: 
 [('358', ',', '.')]

>> POS Tags are: 
 [('358', 'CD'), (',', ','), ('.', '.')]

 (S 358/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('358', '358'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('358', '358'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('358', '358'), (',', ','), ('.', '.')]



============================ Sentence 627 =============================

6370, pp. 


>> Tokens are: 
 ['6370', ',', 'pp', '.']

>> Bigrams are: 
 [('6370', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('6370', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('6370', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 6370/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6370', '6370'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6370', '6370'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('6370', '6370'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 628 =============================

1530–1534, 2017. 


>> Tokens are: 
 ['1530–1534', ',', '2017', '.']

>> Bigrams are: 
 [('1530–1534', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('1530–1534', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('1530–1534', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 1530–1534/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1530–1534', '1530–1534'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1530–1534', '1530–1534'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('1530–1534', '1530–1534'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 629 =============================

18    [21] S. Kannan, H. Kim, and S. Oh, “Deep learning and information theory: An emerging interface,” IEEE ISIT 2018 Tutorial. 


>> Tokens are: 
 ['18', '[', '21', ']', 'S.', 'Kannan', ',', 'H.', 'Kim', ',', 'S.', 'Oh', ',', '“', 'Deep', 'learning', 'information', 'theory', ':', 'An', 'emerging', 'interface', ',', '”', 'IEEE', 'ISIT', '2018', 'Tutorial', '.']

>> Bigrams are: 
 [('18', '['), ('[', '21'), ('21', ']'), (']', 'S.'), ('S.', 'Kannan'), ('Kannan', ','), (',', 'H.'), ('H.', 'Kim'), ('Kim', ','), (',', 'S.'), ('S.', 'Oh'), ('Oh', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'learning'), ('learning', 'information'), ('information', 'theory'), ('theory', ':'), (':', 'An'), ('An', 'emerging'), ('emerging', 'interface'), ('interface', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'ISIT'), ('ISIT', '2018'), ('2018', 'Tutorial'), ('Tutorial', '.')]

>> Trigrams are: 
 [('18', '[', '21'), ('[', '21', ']'), ('21', ']', 'S.'), (']', 'S.', 'Kannan'), ('S.', 'Kannan', ','), ('Kannan', ',', 'H.'), (',', 'H.', 'Kim'), ('H.', 'Kim', ','), ('Kim', ',', 'S.'), (',', 'S.', 'Oh'), ('S.', 'Oh', ','), ('Oh', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'learning'), ('Deep', 'learning', 'information'), ('learning', 'information', 'theory'), ('information', 'theory', ':'), ('theory', ':', 'An'), (':', 'An', 'emerging'), ('An', 'emerging', 'interface'), ('emerging', 'interface', ','), ('interface', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'ISIT'), ('IEEE', 'ISIT', '2018'), ('ISIT', '2018', 'Tutorial'), ('2018', 'Tutorial', '.')]

>> POS Tags are: 
 [('18', 'CD'), ('[', 'JJ'), ('21', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('Kannan', 'NNP'), (',', ','), ('H.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('S.', 'NNP'), ('Oh', 'NNP'), (',', ','), ('“', 'NNP'), ('Deep', 'NNP'), ('learning', 'VBG'), ('information', 'NN'), ('theory', 'NN'), (':', ':'), ('An', 'DT'), ('emerging', 'VBG'), ('interface', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('ISIT', 'NNP'), ('2018', 'CD'), ('Tutorial', 'NNP'), ('.', '.')]

 (S
  18/CD
  [/JJ
  21/CD
  (NP ]/NNP S./NNP Kannan/NNP)
  ,/,
  (NP H./NNP Kim/NNP)
  ,/,
  (NP S./NNP Oh/NNP)
  ,/,
  (NP “/NNP Deep/NNP)
  learning/VBG
  (NP information/NN theory/NN)
  :/:
  An/DT
  emerging/VBG
  (NP interface/NN)
  ,/,
  (NP ”/NNP IEEE/NNP ISIT/NNP)
  2018/CD
  (NP Tutorial/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] S. Kannan', 'H. Kim', 'S. Oh', '“ Deep', 'information theory', 'interface', '” IEEE ISIT', 'Tutorial']

>> Named Entities are: 
 [('PERSON', 'Kannan'), ('PERSON', 'Kim')] 

>> Stemming using Porter Stemmer: 
 [('18', '18'), ('[', '['), ('21', '21'), (']', ']'), ('S.', 's.'), ('Kannan', 'kannan'), (',', ','), ('H.', 'h.'), ('Kim', 'kim'), (',', ','), ('S.', 's.'), ('Oh', 'oh'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('information', 'inform'), ('theory', 'theori'), (':', ':'), ('An', 'an'), ('emerging', 'emerg'), ('interface', 'interfac'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('ISIT', 'isit'), ('2018', '2018'), ('Tutorial', 'tutori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('18', '18'), ('[', '['), ('21', '21'), (']', ']'), ('S.', 's.'), ('Kannan', 'kannan'), (',', ','), ('H.', 'h.'), ('Kim', 'kim'), (',', ','), ('S.', 's.'), ('Oh', 'oh'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('information', 'inform'), ('theory', 'theori'), (':', ':'), ('An', 'an'), ('emerging', 'emerg'), ('interface', 'interfac'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('ISIT', 'isit'), ('2018', '2018'), ('Tutorial', 'tutori'), ('.', '.')]

>> Lemmatization: 
 [('18', '18'), ('[', '['), ('21', '21'), (']', ']'), ('S.', 'S.'), ('Kannan', 'Kannan'), (',', ','), ('H.', 'H.'), ('Kim', 'Kim'), (',', ','), ('S.', 'S.'), ('Oh', 'Oh'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('learning', 'learning'), ('information', 'information'), ('theory', 'theory'), (':', ':'), ('An', 'An'), ('emerging', 'emerging'), ('interface', 'interface'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('ISIT', 'ISIT'), ('2018', '2018'), ('Tutorial', 'Tutorial'), ('.', '.')]



============================ Sentence 630 =============================

[22] M. Davies, N. Srinivasa, T.-H. Lin, G. Chinya, Y. Cao, S. H. Choday, G. Dimou, P. Joshi, N. Imam, S. Jain et al., “Loihi: A neuromorphic manycore processor with on-chip learning,” IEEE Micro, vol. 


>> Tokens are: 
 ['[', '22', ']', 'M.', 'Davies', ',', 'N.', 'Srinivasa', ',', 'T.-H.', 'Lin', ',', 'G.', 'Chinya', ',', 'Y.', 'Cao', ',', 'S.', 'H.', 'Choday', ',', 'G.', 'Dimou', ',', 'P.', 'Joshi', ',', 'N.', 'Imam', ',', 'S.', 'Jain', 'et', 'al.', ',', '“', 'Loihi', ':', 'A', 'neuromorphic', 'manycore', 'processor', 'on-chip', 'learning', ',', '”', 'IEEE', 'Micro', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '22'), ('22', ']'), (']', 'M.'), ('M.', 'Davies'), ('Davies', ','), (',', 'N.'), ('N.', 'Srinivasa'), ('Srinivasa', ','), (',', 'T.-H.'), ('T.-H.', 'Lin'), ('Lin', ','), (',', 'G.'), ('G.', 'Chinya'), ('Chinya', ','), (',', 'Y.'), ('Y.', 'Cao'), ('Cao', ','), (',', 'S.'), ('S.', 'H.'), ('H.', 'Choday'), ('Choday', ','), (',', 'G.'), ('G.', 'Dimou'), ('Dimou', ','), (',', 'P.'), ('P.', 'Joshi'), ('Joshi', ','), (',', 'N.'), ('N.', 'Imam'), ('Imam', ','), (',', 'S.'), ('S.', 'Jain'), ('Jain', 'et'), ('et', 'al.'), ('al.', ','), (',', '“'), ('“', 'Loihi'), ('Loihi', ':'), (':', 'A'), ('A', 'neuromorphic'), ('neuromorphic', 'manycore'), ('manycore', 'processor'), ('processor', 'on-chip'), ('on-chip', 'learning'), ('learning', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Micro'), ('Micro', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '22', ']'), ('22', ']', 'M.'), (']', 'M.', 'Davies'), ('M.', 'Davies', ','), ('Davies', ',', 'N.'), (',', 'N.', 'Srinivasa'), ('N.', 'Srinivasa', ','), ('Srinivasa', ',', 'T.-H.'), (',', 'T.-H.', 'Lin'), ('T.-H.', 'Lin', ','), ('Lin', ',', 'G.'), (',', 'G.', 'Chinya'), ('G.', 'Chinya', ','), ('Chinya', ',', 'Y.'), (',', 'Y.', 'Cao'), ('Y.', 'Cao', ','), ('Cao', ',', 'S.'), (',', 'S.', 'H.'), ('S.', 'H.', 'Choday'), ('H.', 'Choday', ','), ('Choday', ',', 'G.'), (',', 'G.', 'Dimou'), ('G.', 'Dimou', ','), ('Dimou', ',', 'P.'), (',', 'P.', 'Joshi'), ('P.', 'Joshi', ','), ('Joshi', ',', 'N.'), (',', 'N.', 'Imam'), ('N.', 'Imam', ','), ('Imam', ',', 'S.'), (',', 'S.', 'Jain'), ('S.', 'Jain', 'et'), ('Jain', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '“'), (',', '“', 'Loihi'), ('“', 'Loihi', ':'), ('Loihi', ':', 'A'), (':', 'A', 'neuromorphic'), ('A', 'neuromorphic', 'manycore'), ('neuromorphic', 'manycore', 'processor'), ('manycore', 'processor', 'on-chip'), ('processor', 'on-chip', 'learning'), ('on-chip', 'learning', ','), ('learning', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Micro'), ('IEEE', 'Micro', ','), ('Micro', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('22', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Davies', 'NNP'), (',', ','), ('N.', 'NNP'), ('Srinivasa', 'NNP'), (',', ','), ('T.-H.', 'NNP'), ('Lin', 'NNP'), (',', ','), ('G.', 'NNP'), ('Chinya', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Cao', 'NNP'), (',', ','), ('S.', 'NNP'), ('H.', 'NNP'), ('Choday', 'NNP'), (',', ','), ('G.', 'NNP'), ('Dimou', 'NNP'), (',', ','), ('P.', 'NNP'), ('Joshi', 'NNP'), (',', ','), ('N.', 'NNP'), ('Imam', 'NNP'), (',', ','), ('S.', 'NNP'), ('Jain', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('“', 'JJ'), ('Loihi', 'NNP'), (':', ':'), ('A', 'DT'), ('neuromorphic', 'JJ'), ('manycore', 'NN'), ('processor', 'NN'), ('on-chip', 'JJ'), ('learning', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Micro', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  22/CD
  (NP ]/NNP M./NNP Davies/NNP)
  ,/,
  (NP N./NNP Srinivasa/NNP)
  ,/,
  (NP T.-H./NNP Lin/NNP)
  ,/,
  (NP G./NNP Chinya/NNP)
  ,/,
  (NP Y./NNP Cao/NNP)
  ,/,
  (NP S./NNP H./NNP Choday/NNP)
  ,/,
  (NP G./NNP Dimou/NNP)
  ,/,
  (NP P./NNP Joshi/NNP)
  ,/,
  (NP N./NNP Imam/NNP)
  ,/,
  (NP S./NNP Jain/NNP)
  et/FW
  (NP al./NN)
  ,/,
  (NP “/JJ Loihi/NNP)
  :/:
  (NP A/DT neuromorphic/JJ manycore/NN processor/NN)
  (NP on-chip/JJ learning/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Micro/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. Davies', 'N. Srinivasa', 'T.-H. Lin', 'G. Chinya', 'Y. Cao', 'S. H. Choday', 'G. Dimou', 'P. Joshi', 'N. Imam', 'S. Jain', 'al.', '“ Loihi', 'A neuromorphic manycore processor', 'on-chip learning', '” IEEE Micro', 'vol']

>> Named Entities are: 
 [('GPE', 'Chinya'), ('PERSON', 'Micro')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('M.', 'm.'), ('Davies', 'davi'), (',', ','), ('N.', 'n.'), ('Srinivasa', 'srinivasa'), (',', ','), ('T.-H.', 't.-h.'), ('Lin', 'lin'), (',', ','), ('G.', 'g.'), ('Chinya', 'chinya'), (',', ','), ('Y.', 'y.'), ('Cao', 'cao'), (',', ','), ('S.', 's.'), ('H.', 'h.'), ('Choday', 'choday'), (',', ','), ('G.', 'g.'), ('Dimou', 'dimou'), (',', ','), ('P.', 'p.'), ('Joshi', 'joshi'), (',', ','), ('N.', 'n.'), ('Imam', 'imam'), (',', ','), ('S.', 's.'), ('Jain', 'jain'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Loihi', 'loihi'), (':', ':'), ('A', 'a'), ('neuromorphic', 'neuromorph'), ('manycore', 'manycor'), ('processor', 'processor'), ('on-chip', 'on-chip'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Micro', 'micro'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('M.', 'm.'), ('Davies', 'davi'), (',', ','), ('N.', 'n.'), ('Srinivasa', 'srinivasa'), (',', ','), ('T.-H.', 't.-h.'), ('Lin', 'lin'), (',', ','), ('G.', 'g.'), ('Chinya', 'chinya'), (',', ','), ('Y.', 'y.'), ('Cao', 'cao'), (',', ','), ('S.', 's.'), ('H.', 'h.'), ('Choday', 'choday'), (',', ','), ('G.', 'g.'), ('Dimou', 'dimou'), (',', ','), ('P.', 'p.'), ('Joshi', 'joshi'), (',', ','), ('N.', 'n.'), ('Imam', 'imam'), (',', ','), ('S.', 's.'), ('Jain', 'jain'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Loihi', 'loihi'), (':', ':'), ('A', 'a'), ('neuromorphic', 'neuromorph'), ('manycore', 'manycor'), ('processor', 'processor'), ('on-chip', 'on-chip'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Micro', 'micro'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('22', '22'), (']', ']'), ('M.', 'M.'), ('Davies', 'Davies'), (',', ','), ('N.', 'N.'), ('Srinivasa', 'Srinivasa'), (',', ','), ('T.-H.', 'T.-H.'), ('Lin', 'Lin'), (',', ','), ('G.', 'G.'), ('Chinya', 'Chinya'), (',', ','), ('Y.', 'Y.'), ('Cao', 'Cao'), (',', ','), ('S.', 'S.'), ('H.', 'H.'), ('Choday', 'Choday'), (',', ','), ('G.', 'G.'), ('Dimou', 'Dimou'), (',', ','), ('P.', 'P.'), ('Joshi', 'Joshi'), (',', ','), ('N.', 'N.'), ('Imam', 'Imam'), (',', ','), ('S.', 'S.'), ('Jain', 'Jain'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('“', '“'), ('Loihi', 'Loihi'), (':', ':'), ('A', 'A'), ('neuromorphic', 'neuromorphic'), ('manycore', 'manycore'), ('processor', 'processor'), ('on-chip', 'on-chip'), ('learning', 'learning'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Micro', 'Micro'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 631 =============================

38, no. 


>> Tokens are: 
 ['38', ',', '.']

>> Bigrams are: 
 [('38', ','), (',', '.')]

>> Trigrams are: 
 [('38', ',', '.')]

>> POS Tags are: 
 [('38', 'CD'), (',', ','), ('.', '.')]

 (S 38/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38', '38'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38', '38'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('38', '38'), (',', ','), ('.', '.')]



============================ Sentence 632 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 633 =============================

82–99, 2018. 


>> Tokens are: 
 ['82–99', ',', '2018', '.']

>> Bigrams are: 
 [('82–99', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('82–99', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('82–99', 'CD'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S 82–99/CD ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('82–99', '82–99'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('82–99', '82–99'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('82–99', '82–99'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 634 =============================

[23] A. Bagheri, O. Simeone, and B. Rajendran, “Training proba- bilistic spiking neural networks with first-to-spike decoding,” arXiv preprint arXiv:1710.10704, 2017. 


>> Tokens are: 
 ['[', '23', ']', 'A.', 'Bagheri', ',', 'O.', 'Simeone', ',', 'B.', 'Rajendran', ',', '“', 'Training', 'proba-', 'bilistic', 'spiking', 'neural', 'networks', 'first-to-spike', 'decoding', ',', '”', 'arXiv', 'preprint', 'arXiv:1710.10704', ',', '2017', '.']

>> Bigrams are: 
 [('[', '23'), ('23', ']'), (']', 'A.'), ('A.', 'Bagheri'), ('Bagheri', ','), (',', 'O.'), ('O.', 'Simeone'), ('Simeone', ','), (',', 'B.'), ('B.', 'Rajendran'), ('Rajendran', ','), (',', '“'), ('“', 'Training'), ('Training', 'proba-'), ('proba-', 'bilistic'), ('bilistic', 'spiking'), ('spiking', 'neural'), ('neural', 'networks'), ('networks', 'first-to-spike'), ('first-to-spike', 'decoding'), ('decoding', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1710.10704'), ('arXiv:1710.10704', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('[', '23', ']'), ('23', ']', 'A.'), (']', 'A.', 'Bagheri'), ('A.', 'Bagheri', ','), ('Bagheri', ',', 'O.'), (',', 'O.', 'Simeone'), ('O.', 'Simeone', ','), ('Simeone', ',', 'B.'), (',', 'B.', 'Rajendran'), ('B.', 'Rajendran', ','), ('Rajendran', ',', '“'), (',', '“', 'Training'), ('“', 'Training', 'proba-'), ('Training', 'proba-', 'bilistic'), ('proba-', 'bilistic', 'spiking'), ('bilistic', 'spiking', 'neural'), ('spiking', 'neural', 'networks'), ('neural', 'networks', 'first-to-spike'), ('networks', 'first-to-spike', 'decoding'), ('first-to-spike', 'decoding', ','), ('decoding', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1710.10704'), ('preprint', 'arXiv:1710.10704', ','), ('arXiv:1710.10704', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('23', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('Bagheri', 'NNP'), (',', ','), ('O.', 'NNP'), ('Simeone', 'NNP'), (',', ','), ('B.', 'NNP'), ('Rajendran', 'NNP'), (',', ','), ('“', 'NNP'), ('Training', 'NNP'), ('proba-', 'JJ'), ('bilistic', 'JJ'), ('spiking', 'VBG'), ('neural', 'JJ'), ('networks', 'NNS'), ('first-to-spike', 'JJ'), ('decoding', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1710.10704', 'NN'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  [/RB
  23/CD
  (NP ]/JJ A./NNP Bagheri/NNP)
  ,/,
  (NP O./NNP Simeone/NNP)
  ,/,
  (NP B./NNP Rajendran/NNP)
  ,/,
  (NP “/NNP Training/NNP)
  proba-/JJ
  bilistic/JJ
  spiking/VBG
  (NP neural/JJ networks/NNS)
  (NP first-to-spike/JJ decoding/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1710.10704/NN)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['] A. Bagheri', 'O. Simeone', 'B. Rajendran', '“ Training', 'neural networks', 'first-to-spike decoding', '”', 'preprint arXiv:1710.10704']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('A.', 'a.'), ('Bagheri', 'bagheri'), (',', ','), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('B.', 'b.'), ('Rajendran', 'rajendran'), (',', ','), ('“', '“'), ('Training', 'train'), ('proba-', 'proba-'), ('bilistic', 'bilist'), ('spiking', 'spike'), ('neural', 'neural'), ('networks', 'network'), ('first-to-spike', 'first-to-spik'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1710.10704', 'arxiv:1710.10704'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('A.', 'a.'), ('Bagheri', 'bagheri'), (',', ','), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('B.', 'b.'), ('Rajendran', 'rajendran'), (',', ','), ('“', '“'), ('Training', 'train'), ('proba-', 'proba-'), ('bilistic', 'bilist'), ('spiking', 'spike'), ('neural', 'neural'), ('networks', 'network'), ('first-to-spike', 'first-to-spik'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1710.10704', 'arxiv:1710.10704'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('23', '23'), (']', ']'), ('A.', 'A.'), ('Bagheri', 'Bagheri'), (',', ','), ('O.', 'O.'), ('Simeone', 'Simeone'), (',', ','), ('B.', 'B.'), ('Rajendran', 'Rajendran'), (',', ','), ('“', '“'), ('Training', 'Training'), ('proba-', 'proba-'), ('bilistic', 'bilistic'), ('spiking', 'spiking'), ('neural', 'neural'), ('networks', 'network'), ('first-to-spike', 'first-to-spike'), ('decoding', 'decoding'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1710.10704', 'arXiv:1710.10704'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 635 =============================

[24] J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan, “Learn- ing to explain: An information-theoretic perspective on model interpretation,” arXiv preprint arXiv:1802.07814, 2018. 


>> Tokens are: 
 ['[', '24', ']', 'J.', 'Chen', ',', 'L.', 'Song', ',', 'M.', 'J.', 'Wainwright', ',', 'M.', 'I.', 'Jordan', ',', '“', 'Learn-', 'ing', 'explain', ':', 'An', 'information-theoretic', 'perspective', 'model', 'interpretation', ',', '”', 'arXiv', 'preprint', 'arXiv:1802.07814', ',', '2018', '.']

>> Bigrams are: 
 [('[', '24'), ('24', ']'), (']', 'J.'), ('J.', 'Chen'), ('Chen', ','), (',', 'L.'), ('L.', 'Song'), ('Song', ','), (',', 'M.'), ('M.', 'J.'), ('J.', 'Wainwright'), ('Wainwright', ','), (',', 'M.'), ('M.', 'I.'), ('I.', 'Jordan'), ('Jordan', ','), (',', '“'), ('“', 'Learn-'), ('Learn-', 'ing'), ('ing', 'explain'), ('explain', ':'), (':', 'An'), ('An', 'information-theoretic'), ('information-theoretic', 'perspective'), ('perspective', 'model'), ('model', 'interpretation'), ('interpretation', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1802.07814'), ('arXiv:1802.07814', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '24', ']'), ('24', ']', 'J.'), (']', 'J.', 'Chen'), ('J.', 'Chen', ','), ('Chen', ',', 'L.'), (',', 'L.', 'Song'), ('L.', 'Song', ','), ('Song', ',', 'M.'), (',', 'M.', 'J.'), ('M.', 'J.', 'Wainwright'), ('J.', 'Wainwright', ','), ('Wainwright', ',', 'M.'), (',', 'M.', 'I.'), ('M.', 'I.', 'Jordan'), ('I.', 'Jordan', ','), ('Jordan', ',', '“'), (',', '“', 'Learn-'), ('“', 'Learn-', 'ing'), ('Learn-', 'ing', 'explain'), ('ing', 'explain', ':'), ('explain', ':', 'An'), (':', 'An', 'information-theoretic'), ('An', 'information-theoretic', 'perspective'), ('information-theoretic', 'perspective', 'model'), ('perspective', 'model', 'interpretation'), ('model', 'interpretation', ','), ('interpretation', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1802.07814'), ('preprint', 'arXiv:1802.07814', ','), ('arXiv:1802.07814', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('24', 'CD'), (']', 'NNP'), ('J.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('L.', 'NNP'), ('Song', 'NNP'), (',', ','), ('M.', 'NNP'), ('J.', 'NNP'), ('Wainwright', 'NNP'), (',', ','), ('M.', 'NNP'), ('I.', 'NNP'), ('Jordan', 'NNP'), (',', ','), ('“', 'NNP'), ('Learn-', 'NNP'), ('ing', 'VBG'), ('explain', 'NN'), (':', ':'), ('An', 'DT'), ('information-theoretic', 'JJ'), ('perspective', 'NN'), ('model', 'NN'), ('interpretation', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1802.07814', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  24/CD
  (NP ]/NNP J./NNP Chen/NNP)
  ,/,
  (NP L./NNP Song/NNP)
  ,/,
  (NP M./NNP J./NNP Wainwright/NNP)
  ,/,
  (NP M./NNP I./NNP Jordan/NNP)
  ,/,
  (NP “/NNP Learn-/NNP)
  ing/VBG
  (NP explain/NN)
  :/:
  (NP
    An/DT
    information-theoretic/JJ
    perspective/NN
    model/NN
    interpretation/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1802.07814/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] J. Chen', 'L. Song', 'M. J. Wainwright', 'M. I. Jordan', '“ Learn-', 'explain', 'An information-theoretic perspective model interpretation', '”', 'preprint arXiv:1802.07814']

>> Named Entities are: 
 [('GPE', 'Jordan')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('J.', 'j.'), ('Chen', 'chen'), (',', ','), ('L.', 'l.'), ('Song', 'song'), (',', ','), ('M.', 'm.'), ('J.', 'j.'), ('Wainwright', 'wainwright'), (',', ','), ('M.', 'm.'), ('I.', 'i.'), ('Jordan', 'jordan'), (',', ','), ('“', '“'), ('Learn-', 'learn-'), ('ing', 'ing'), ('explain', 'explain'), (':', ':'), ('An', 'an'), ('information-theoretic', 'information-theoret'), ('perspective', 'perspect'), ('model', 'model'), ('interpretation', 'interpret'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1802.07814', 'arxiv:1802.07814'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('J.', 'j.'), ('Chen', 'chen'), (',', ','), ('L.', 'l.'), ('Song', 'song'), (',', ','), ('M.', 'm.'), ('J.', 'j.'), ('Wainwright', 'wainwright'), (',', ','), ('M.', 'm.'), ('I.', 'i.'), ('Jordan', 'jordan'), (',', ','), ('“', '“'), ('Learn-', 'learn-'), ('ing', 'ing'), ('explain', 'explain'), (':', ':'), ('An', 'an'), ('information-theoretic', 'information-theoret'), ('perspective', 'perspect'), ('model', 'model'), ('interpretation', 'interpret'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1802.07814', 'arxiv:1802.07814'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('24', '24'), (']', ']'), ('J.', 'J.'), ('Chen', 'Chen'), (',', ','), ('L.', 'L.'), ('Song', 'Song'), (',', ','), ('M.', 'M.'), ('J.', 'J.'), ('Wainwright', 'Wainwright'), (',', ','), ('M.', 'M.'), ('I.', 'I.'), ('Jordan', 'Jordan'), (',', ','), ('“', '“'), ('Learn-', 'Learn-'), ('ing', 'ing'), ('explain', 'explain'), (':', ':'), ('An', 'An'), ('information-theoretic', 'information-theoretic'), ('perspective', 'perspective'), ('model', 'model'), ('interpretation', 'interpretation'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1802.07814', 'arXiv:1802.07814'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 636 =============================

[25] M. Polese, R. Jana, V. Kounev, K. Zhang, S. Deb, and M. Zorzi, “Machine Learning at the Edge: A Data-Driven Architecture with Applications to 5G Cellular Networks,” ArXiv e-prints, Aug. 2018. 


>> Tokens are: 
 ['[', '25', ']', 'M.', 'Polese', ',', 'R.', 'Jana', ',', 'V.', 'Kounev', ',', 'K.', 'Zhang', ',', 'S.', 'Deb', ',', 'M.', 'Zorzi', ',', '“', 'Machine', 'Learning', 'Edge', ':', 'A', 'Data-Driven', 'Architecture', 'Applications', '5G', 'Cellular', 'Networks', ',', '”', 'ArXiv', 'e-prints', ',', 'Aug.', '2018', '.']

>> Bigrams are: 
 [('[', '25'), ('25', ']'), (']', 'M.'), ('M.', 'Polese'), ('Polese', ','), (',', 'R.'), ('R.', 'Jana'), ('Jana', ','), (',', 'V.'), ('V.', 'Kounev'), ('Kounev', ','), (',', 'K.'), ('K.', 'Zhang'), ('Zhang', ','), (',', 'S.'), ('S.', 'Deb'), ('Deb', ','), (',', 'M.'), ('M.', 'Zorzi'), ('Zorzi', ','), (',', '“'), ('“', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Edge'), ('Edge', ':'), (':', 'A'), ('A', 'Data-Driven'), ('Data-Driven', 'Architecture'), ('Architecture', 'Applications'), ('Applications', '5G'), ('5G', 'Cellular'), ('Cellular', 'Networks'), ('Networks', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Aug.'), ('Aug.', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '25', ']'), ('25', ']', 'M.'), (']', 'M.', 'Polese'), ('M.', 'Polese', ','), ('Polese', ',', 'R.'), (',', 'R.', 'Jana'), ('R.', 'Jana', ','), ('Jana', ',', 'V.'), (',', 'V.', 'Kounev'), ('V.', 'Kounev', ','), ('Kounev', ',', 'K.'), (',', 'K.', 'Zhang'), ('K.', 'Zhang', ','), ('Zhang', ',', 'S.'), (',', 'S.', 'Deb'), ('S.', 'Deb', ','), ('Deb', ',', 'M.'), (',', 'M.', 'Zorzi'), ('M.', 'Zorzi', ','), ('Zorzi', ',', '“'), (',', '“', 'Machine'), ('“', 'Machine', 'Learning'), ('Machine', 'Learning', 'Edge'), ('Learning', 'Edge', ':'), ('Edge', ':', 'A'), (':', 'A', 'Data-Driven'), ('A', 'Data-Driven', 'Architecture'), ('Data-Driven', 'Architecture', 'Applications'), ('Architecture', 'Applications', '5G'), ('Applications', '5G', 'Cellular'), ('5G', 'Cellular', 'Networks'), ('Cellular', 'Networks', ','), ('Networks', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Aug.'), (',', 'Aug.', '2018'), ('Aug.', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('25', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Polese', 'NNP'), (',', ','), ('R.', 'NNP'), ('Jana', 'NNP'), (',', ','), ('V.', 'NNP'), ('Kounev', 'NNP'), (',', ','), ('K.', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('S.', 'NNP'), ('Deb', 'NNP'), (',', ','), ('M.', 'NNP'), ('Zorzi', 'NNP'), (',', ','), ('“', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Edge', 'NNP'), (':', ':'), ('A', 'DT'), ('Data-Driven', 'JJ'), ('Architecture', 'NN'), ('Applications', 'NNS'), ('5G', 'CD'), ('Cellular', 'JJ'), ('Networks', 'NNS'), (',', ','), ('”', 'JJ'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Aug.', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  25/CD
  (NP ]/NNP M./NNP Polese/NNP)
  ,/,
  (NP R./NNP Jana/NNP)
  ,/,
  (NP V./NNP Kounev/NNP)
  ,/,
  (NP K./NNP Zhang/NNP)
  ,/,
  (NP S./NNP Deb/NNP)
  ,/,
  (NP M./NNP Zorzi/NNP)
  ,/,
  (NP “/NNP Machine/NNP Learning/NNP Edge/NNP)
  :/:
  (NP A/DT Data-Driven/JJ Architecture/NN Applications/NNS)
  5G/CD
  (NP Cellular/JJ Networks/NNS)
  ,/,
  (NP ”/JJ ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Aug./NNP)
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] M. Polese', 'R. Jana', 'V. Kounev', 'K. Zhang', 'S. Deb', 'M. Zorzi', '“ Machine Learning Edge', 'A Data-Driven Architecture Applications', 'Cellular Networks', '” ArXiv e-prints', 'Aug.']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Networks'), ('ORGANIZATION', 'ArXiv')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('M.', 'm.'), ('Polese', 'poles'), (',', ','), ('R.', 'r.'), ('Jana', 'jana'), (',', ','), ('V.', 'v.'), ('Kounev', 'kounev'), (',', ','), ('K.', 'k.'), ('Zhang', 'zhang'), (',', ','), ('S.', 's.'), ('Deb', 'deb'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('Learning', 'learn'), ('Edge', 'edg'), (':', ':'), ('A', 'a'), ('Data-Driven', 'data-driven'), ('Architecture', 'architectur'), ('Applications', 'applic'), ('5G', '5g'), ('Cellular', 'cellular'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('M.', 'm.'), ('Polese', 'poles'), (',', ','), ('R.', 'r.'), ('Jana', 'jana'), (',', ','), ('V.', 'v.'), ('Kounev', 'kounev'), (',', ','), ('K.', 'k.'), ('Zhang', 'zhang'), (',', ','), ('S.', 's.'), ('Deb', 'deb'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('Learning', 'learn'), ('Edge', 'edg'), (':', ':'), ('A', 'a'), ('Data-Driven', 'data-driven'), ('Architecture', 'architectur'), ('Applications', 'applic'), ('5G', '5g'), ('Cellular', 'cellular'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('25', '25'), (']', ']'), ('M.', 'M.'), ('Polese', 'Polese'), (',', ','), ('R.', 'R.'), ('Jana', 'Jana'), (',', ','), ('V.', 'V.'), ('Kounev', 'Kounev'), (',', ','), ('K.', 'K.'), ('Zhang', 'Zhang'), (',', ','), ('S.', 'S.'), ('Deb', 'Deb'), (',', ','), ('M.', 'M.'), ('Zorzi', 'Zorzi'), (',', ','), ('“', '“'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Edge', 'Edge'), (':', ':'), ('A', 'A'), ('Data-Driven', 'Data-Driven'), ('Architecture', 'Architecture'), ('Applications', 'Applications'), ('5G', '5G'), ('Cellular', 'Cellular'), ('Networks', 'Networks'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Aug.', 'Aug.'), ('2018', '2018'), ('.', '.')]



============================ Sentence 637 =============================

[26] G. Paschos, E. Bastug, I. 


>> Tokens are: 
 ['[', '26', ']', 'G.', 'Paschos', ',', 'E.', 'Bastug', ',', 'I', '.']

>> Bigrams are: 
 [('[', '26'), ('26', ']'), (']', 'G.'), ('G.', 'Paschos'), ('Paschos', ','), (',', 'E.'), ('E.', 'Bastug'), ('Bastug', ','), (',', 'I'), ('I', '.')]

>> Trigrams are: 
 [('[', '26', ']'), ('26', ']', 'G.'), (']', 'G.', 'Paschos'), ('G.', 'Paschos', ','), ('Paschos', ',', 'E.'), (',', 'E.', 'Bastug'), ('E.', 'Bastug', ','), ('Bastug', ',', 'I'), (',', 'I', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('26', 'CD'), (']', 'JJ'), ('G.', 'NNP'), ('Paschos', 'NNP'), (',', ','), ('E.', 'NNP'), ('Bastug', 'NNP'), (',', ','), ('I', 'PRP'), ('.', '.')]

 (S
  [/RB
  26/CD
  (NP ]/JJ G./NNP Paschos/NNP)
  ,/,
  (NP E./NNP Bastug/NNP)
  ,/,
  I/PRP
  ./.) 


>> Noun Phrases are: 
 ['] G. Paschos', 'E. Bastug']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('G.', 'g.'), ('Paschos', 'pascho'), (',', ','), ('E.', 'e.'), ('Bastug', 'bastug'), (',', ','), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('G.', 'g.'), ('Paschos', 'pascho'), (',', ','), ('E.', 'e.'), ('Bastug', 'bastug'), (',', ','), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('26', '26'), (']', ']'), ('G.', 'G.'), ('Paschos', 'Paschos'), (',', ','), ('E.', 'E.'), ('Bastug', 'Bastug'), (',', ','), ('I', 'I'), ('.', '.')]



============================ Sentence 638 =============================

Land, G. Caire, and M. Debbah, “Wireless caching: Technical misconceptions and business bar- riers,” IEEE Communications Magazine, vol. 


>> Tokens are: 
 ['Land', ',', 'G.', 'Caire', ',', 'M.', 'Debbah', ',', '“', 'Wireless', 'caching', ':', 'Technical', 'misconceptions', 'business', 'bar-', 'riers', ',', '”', 'IEEE', 'Communications', 'Magazine', ',', 'vol', '.']

>> Bigrams are: 
 [('Land', ','), (',', 'G.'), ('G.', 'Caire'), ('Caire', ','), (',', 'M.'), ('M.', 'Debbah'), ('Debbah', ','), (',', '“'), ('“', 'Wireless'), ('Wireless', 'caching'), ('caching', ':'), (':', 'Technical'), ('Technical', 'misconceptions'), ('misconceptions', 'business'), ('business', 'bar-'), ('bar-', 'riers'), ('riers', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Magazine'), ('Magazine', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Land', ',', 'G.'), (',', 'G.', 'Caire'), ('G.', 'Caire', ','), ('Caire', ',', 'M.'), (',', 'M.', 'Debbah'), ('M.', 'Debbah', ','), ('Debbah', ',', '“'), (',', '“', 'Wireless'), ('“', 'Wireless', 'caching'), ('Wireless', 'caching', ':'), ('caching', ':', 'Technical'), (':', 'Technical', 'misconceptions'), ('Technical', 'misconceptions', 'business'), ('misconceptions', 'business', 'bar-'), ('business', 'bar-', 'riers'), ('bar-', 'riers', ','), ('riers', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Magazine'), ('Communications', 'Magazine', ','), ('Magazine', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('Land', 'NNP'), (',', ','), ('G.', 'NNP'), ('Caire', 'NNP'), (',', ','), ('M.', 'NNP'), ('Debbah', 'NNP'), (',', ','), ('“', 'NNP'), ('Wireless', 'NNP'), ('caching', 'NN'), (':', ':'), ('Technical', 'JJ'), ('misconceptions', 'NNS'), ('business', 'NN'), ('bar-', 'NN'), ('riers', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Magazine', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP Land/NNP)
  ,/,
  (NP G./NNP Caire/NNP)
  ,/,
  (NP M./NNP Debbah/NNP)
  ,/,
  (NP “/NNP Wireless/NNP caching/NN)
  :/:
  (NP Technical/JJ misconceptions/NNS business/NN bar-/NN riers/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Communications/NNP Magazine/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['Land', 'G. Caire', 'M. Debbah', '“ Wireless caching', 'Technical misconceptions business bar- riers', '” IEEE Communications Magazine', 'vol']

>> Named Entities are: 
 [('GPE', 'Land'), ('ORGANIZATION', 'IEEE Communications Magazine')] 

>> Stemming using Porter Stemmer: 
 [('Land', 'land'), (',', ','), ('G.', 'g.'), ('Caire', 'cair'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Wireless', 'wireless'), ('caching', 'cach'), (':', ':'), ('Technical', 'technic'), ('misconceptions', 'misconcept'), ('business', 'busi'), ('bar-', 'bar-'), ('riers', 'rier'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Land', 'land'), (',', ','), ('G.', 'g.'), ('Caire', 'cair'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Wireless', 'wireless'), ('caching', 'cach'), (':', ':'), ('Technical', 'technic'), ('misconceptions', 'misconcept'), ('business', 'busi'), ('bar-', 'bar-'), ('riers', 'rier'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Land', 'Land'), (',', ','), ('G.', 'G.'), ('Caire', 'Caire'), (',', ','), ('M.', 'M.'), ('Debbah', 'Debbah'), (',', ','), ('“', '“'), ('Wireless', 'Wireless'), ('caching', 'caching'), (':', ':'), ('Technical', 'Technical'), ('misconceptions', 'misconception'), ('business', 'business'), ('bar-', 'bar-'), ('riers', 'riers'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Magazine', 'Magazine'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 639 =============================

54, no. 


>> Tokens are: 
 ['54', ',', '.']

>> Bigrams are: 
 [('54', ','), (',', '.')]

>> Trigrams are: 
 [('54', ',', '.')]

>> POS Tags are: 
 [('54', 'CD'), (',', ','), ('.', '.')]

 (S 54/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('54', '54'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('54', '54'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('54', '54'), (',', ','), ('.', '.')]



============================ Sentence 640 =============================

8, pp. 


>> Tokens are: 
 ['8', ',', 'pp', '.']

>> Bigrams are: 
 [('8', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('8', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 8/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 641 =============================

16– 22, 2016. 


>> Tokens are: 
 ['16–', '22', ',', '2016', '.']

>> Bigrams are: 
 [('16–', '22'), ('22', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('16–', '22', ','), ('22', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('16–', 'CD'), ('22', 'CD'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S 16–/CD 22/CD ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16–', '16–'), ('22', '22'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16–', '16–'), ('22', '22'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('16–', '16–'), ('22', '22'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 642 =============================

[27] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Machine learning for wireless networks with artificial in- telligence: A tutorial on neural networks,” arXiv preprint arXiv:1710.02913, 2017. 


>> Tokens are: 
 ['[', '27', ']', 'M.', 'Chen', ',', 'U.', 'Challita', ',', 'W.', 'Saad', ',', 'C.', 'Yin', ',', 'M.', 'Debbah', ',', '“', 'Machine', 'learning', 'wireless', 'networks', 'artificial', 'in-', 'telligence', ':', 'A', 'tutorial', 'neural', 'networks', ',', '”', 'arXiv', 'preprint', 'arXiv:1710.02913', ',', '2017', '.']

>> Bigrams are: 
 [('[', '27'), ('27', ']'), (']', 'M.'), ('M.', 'Chen'), ('Chen', ','), (',', 'U.'), ('U.', 'Challita'), ('Challita', ','), (',', 'W.'), ('W.', 'Saad'), ('Saad', ','), (',', 'C.'), ('C.', 'Yin'), ('Yin', ','), (',', 'M.'), ('M.', 'Debbah'), ('Debbah', ','), (',', '“'), ('“', 'Machine'), ('Machine', 'learning'), ('learning', 'wireless'), ('wireless', 'networks'), ('networks', 'artificial'), ('artificial', 'in-'), ('in-', 'telligence'), ('telligence', ':'), (':', 'A'), ('A', 'tutorial'), ('tutorial', 'neural'), ('neural', 'networks'), ('networks', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1710.02913'), ('arXiv:1710.02913', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('[', '27', ']'), ('27', ']', 'M.'), (']', 'M.', 'Chen'), ('M.', 'Chen', ','), ('Chen', ',', 'U.'), (',', 'U.', 'Challita'), ('U.', 'Challita', ','), ('Challita', ',', 'W.'), (',', 'W.', 'Saad'), ('W.', 'Saad', ','), ('Saad', ',', 'C.'), (',', 'C.', 'Yin'), ('C.', 'Yin', ','), ('Yin', ',', 'M.'), (',', 'M.', 'Debbah'), ('M.', 'Debbah', ','), ('Debbah', ',', '“'), (',', '“', 'Machine'), ('“', 'Machine', 'learning'), ('Machine', 'learning', 'wireless'), ('learning', 'wireless', 'networks'), ('wireless', 'networks', 'artificial'), ('networks', 'artificial', 'in-'), ('artificial', 'in-', 'telligence'), ('in-', 'telligence', ':'), ('telligence', ':', 'A'), (':', 'A', 'tutorial'), ('A', 'tutorial', 'neural'), ('tutorial', 'neural', 'networks'), ('neural', 'networks', ','), ('networks', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1710.02913'), ('preprint', 'arXiv:1710.02913', ','), ('arXiv:1710.02913', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('27', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('U.', 'NNP'), ('Challita', 'NNP'), (',', ','), ('W.', 'NNP'), ('Saad', 'NNP'), (',', ','), ('C.', 'NNP'), ('Yin', 'NNP'), (',', ','), ('M.', 'NNP'), ('Debbah', 'NNP'), (',', ','), ('“', 'NNP'), ('Machine', 'NNP'), ('learning', 'VBG'), ('wireless', 'JJ'), ('networks', 'NNS'), ('artificial', 'JJ'), ('in-', 'JJ'), ('telligence', 'NN'), (':', ':'), ('A', 'DT'), ('tutorial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1710.02913', 'NN'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  [/RB
  27/CD
  (NP ]/NNP M./NNP Chen/NNP)
  ,/,
  (NP U./NNP Challita/NNP)
  ,/,
  (NP W./NNP Saad/NNP)
  ,/,
  (NP C./NNP Yin/NNP)
  ,/,
  (NP M./NNP Debbah/NNP)
  ,/,
  (NP “/NNP Machine/NNP)
  learning/VBG
  (NP wireless/JJ networks/NNS)
  (NP artificial/JJ in-/JJ telligence/NN)
  :/:
  (NP A/DT tutorial/JJ neural/JJ networks/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1710.02913/NN)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['] M. Chen', 'U. Challita', 'W. Saad', 'C. Yin', 'M. Debbah', '“ Machine', 'wireless networks', 'artificial in- telligence', 'A tutorial neural networks', '”', 'preprint arXiv:1710.02913']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('M.', 'm.'), ('Chen', 'chen'), (',', ','), ('U.', 'u.'), ('Challita', 'challita'), (',', ','), ('W.', 'w.'), ('Saad', 'saad'), (',', ','), ('C.', 'c.'), ('Yin', 'yin'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('wireless', 'wireless'), ('networks', 'network'), ('artificial', 'artifici'), ('in-', 'in-'), ('telligence', 'tellig'), (':', ':'), ('A', 'a'), ('tutorial', 'tutori'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1710.02913', 'arxiv:1710.02913'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('M.', 'm.'), ('Chen', 'chen'), (',', ','), ('U.', 'u.'), ('Challita', 'challita'), (',', ','), ('W.', 'w.'), ('Saad', 'saad'), (',', ','), ('C.', 'c.'), ('Yin', 'yin'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Machine', 'machin'), ('learning', 'learn'), ('wireless', 'wireless'), ('networks', 'network'), ('artificial', 'artifici'), ('in-', 'in-'), ('telligence', 'tellig'), (':', ':'), ('A', 'a'), ('tutorial', 'tutori'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1710.02913', 'arxiv:1710.02913'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('27', '27'), (']', ']'), ('M.', 'M.'), ('Chen', 'Chen'), (',', ','), ('U.', 'U.'), ('Challita', 'Challita'), (',', ','), ('W.', 'W.'), ('Saad', 'Saad'), (',', ','), ('C.', 'C.'), ('Yin', 'Yin'), (',', ','), ('M.', 'M.'), ('Debbah', 'Debbah'), (',', ','), ('“', '“'), ('Machine', 'Machine'), ('learning', 'learning'), ('wireless', 'wireless'), ('networks', 'network'), ('artificial', 'artificial'), ('in-', 'in-'), ('telligence', 'telligence'), (':', ':'), ('A', 'A'), ('tutorial', 'tutorial'), ('neural', 'neural'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1710.02913', 'arXiv:1710.02913'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 643 =============================

[28] M. Angjelichinoski, K. F. Trillingsgaard, and P. Popovski, “A statistical learning approach to ultra-reliable low latency communication,” arXiv preprint arXiv:1809.05515, 2018. 


>> Tokens are: 
 ['[', '28', ']', 'M.', 'Angjelichinoski', ',', 'K.', 'F.', 'Trillingsgaard', ',', 'P.', 'Popovski', ',', '“', 'A', 'statistical', 'learning', 'approach', 'ultra-reliable', 'low', 'latency', 'communication', ',', '”', 'arXiv', 'preprint', 'arXiv:1809.05515', ',', '2018', '.']

>> Bigrams are: 
 [('[', '28'), ('28', ']'), (']', 'M.'), ('M.', 'Angjelichinoski'), ('Angjelichinoski', ','), (',', 'K.'), ('K.', 'F.'), ('F.', 'Trillingsgaard'), ('Trillingsgaard', ','), (',', 'P.'), ('P.', 'Popovski'), ('Popovski', ','), (',', '“'), ('“', 'A'), ('A', 'statistical'), ('statistical', 'learning'), ('learning', 'approach'), ('approach', 'ultra-reliable'), ('ultra-reliable', 'low'), ('low', 'latency'), ('latency', 'communication'), ('communication', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1809.05515'), ('arXiv:1809.05515', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '28', ']'), ('28', ']', 'M.'), (']', 'M.', 'Angjelichinoski'), ('M.', 'Angjelichinoski', ','), ('Angjelichinoski', ',', 'K.'), (',', 'K.', 'F.'), ('K.', 'F.', 'Trillingsgaard'), ('F.', 'Trillingsgaard', ','), ('Trillingsgaard', ',', 'P.'), (',', 'P.', 'Popovski'), ('P.', 'Popovski', ','), ('Popovski', ',', '“'), (',', '“', 'A'), ('“', 'A', 'statistical'), ('A', 'statistical', 'learning'), ('statistical', 'learning', 'approach'), ('learning', 'approach', 'ultra-reliable'), ('approach', 'ultra-reliable', 'low'), ('ultra-reliable', 'low', 'latency'), ('low', 'latency', 'communication'), ('latency', 'communication', ','), ('communication', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1809.05515'), ('preprint', 'arXiv:1809.05515', ','), ('arXiv:1809.05515', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('28', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Angjelichinoski', 'NNP'), (',', ','), ('K.', 'NNP'), ('F.', 'NNP'), ('Trillingsgaard', 'NNP'), (',', ','), ('P.', 'NNP'), ('Popovski', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('statistical', 'JJ'), ('learning', 'NN'), ('approach', 'NN'), ('ultra-reliable', 'JJ'), ('low', 'JJ'), ('latency', 'NN'), ('communication', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1809.05515', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  28/CD
  (NP ]/NNP M./NNP Angjelichinoski/NNP)
  ,/,
  (NP K./NNP F./NNP Trillingsgaard/NNP)
  ,/,
  (NP P./NNP Popovski/NNP)
  ,/,
  “/VBZ
  (NP A/NNP)
  (NP statistical/JJ learning/NN approach/NN)
  (NP ultra-reliable/JJ low/JJ latency/NN communication/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1809.05515/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] M. Angjelichinoski', 'K. F. Trillingsgaard', 'P. Popovski', 'A', 'statistical learning approach', 'ultra-reliable low latency communication', '”', 'preprint arXiv:1809.05515']

>> Named Entities are: 
 [('PERSON', 'Trillingsgaard')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('M.', 'm.'), ('Angjelichinoski', 'angjelichinoski'), (',', ','), ('K.', 'k.'), ('F.', 'f.'), ('Trillingsgaard', 'trillingsgaard'), (',', ','), ('P.', 'p.'), ('Popovski', 'popovski'), (',', ','), ('“', '“'), ('A', 'a'), ('statistical', 'statist'), ('learning', 'learn'), ('approach', 'approach'), ('ultra-reliable', 'ultra-reli'), ('low', 'low'), ('latency', 'latenc'), ('communication', 'commun'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1809.05515', 'arxiv:1809.05515'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('M.', 'm.'), ('Angjelichinoski', 'angjelichinoski'), (',', ','), ('K.', 'k.'), ('F.', 'f.'), ('Trillingsgaard', 'trillingsgaard'), (',', ','), ('P.', 'p.'), ('Popovski', 'popovski'), (',', ','), ('“', '“'), ('A', 'a'), ('statistical', 'statist'), ('learning', 'learn'), ('approach', 'approach'), ('ultra-reliable', 'ultra-reli'), ('low', 'low'), ('latency', 'latenc'), ('communication', 'communic'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1809.05515', 'arxiv:1809.05515'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('28', '28'), (']', ']'), ('M.', 'M.'), ('Angjelichinoski', 'Angjelichinoski'), (',', ','), ('K.', 'K.'), ('F.', 'F.'), ('Trillingsgaard', 'Trillingsgaard'), (',', ','), ('P.', 'P.'), ('Popovski', 'Popovski'), (',', ','), ('“', '“'), ('A', 'A'), ('statistical', 'statistical'), ('learning', 'learning'), ('approach', 'approach'), ('ultra-reliable', 'ultra-reliable'), ('low', 'low'), ('latency', 'latency'), ('communication', 'communication'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1809.05515', 'arXiv:1809.05515'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 644 =============================

[29] M. Seeger, “A taxonomy for semi-supervised learning methods,” MIT Press, Tech. 


>> Tokens are: 
 ['[', '29', ']', 'M.', 'Seeger', ',', '“', 'A', 'taxonomy', 'semi-supervised', 'learning', 'methods', ',', '”', 'MIT', 'Press', ',', 'Tech', '.']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'M.'), ('M.', 'Seeger'), ('Seeger', ','), (',', '“'), ('“', 'A'), ('A', 'taxonomy'), ('taxonomy', 'semi-supervised'), ('semi-supervised', 'learning'), ('learning', 'methods'), ('methods', ','), (',', '”'), ('”', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'M.'), (']', 'M.', 'Seeger'), ('M.', 'Seeger', ','), ('Seeger', ',', '“'), (',', '“', 'A'), ('“', 'A', 'taxonomy'), ('A', 'taxonomy', 'semi-supervised'), ('taxonomy', 'semi-supervised', 'learning'), ('semi-supervised', 'learning', 'methods'), ('learning', 'methods', ','), ('methods', ',', '”'), (',', '”', 'MIT'), ('”', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Seeger', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'DT'), ('taxonomy', 'JJ'), ('semi-supervised', 'JJ'), ('learning', 'NN'), ('methods', 'NNS'), (',', ','), ('”', 'NNP'), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

 (S
  [/RB
  29/CD
  (NP ]/NNP M./NNP Seeger/NNP)
  ,/,
  “/VBZ
  (NP A/DT taxonomy/JJ semi-supervised/JJ learning/NN methods/NNS)
  ,/,
  (NP ”/NNP MIT/NNP Press/NNP)
  ,/,
  (NP Tech/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] M. Seeger', 'A taxonomy semi-supervised learning methods', '” MIT Press', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('M.', 'm.'), ('Seeger', 'seeger'), (',', ','), ('“', '“'), ('A', 'a'), ('taxonomy', 'taxonomi'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('methods', 'method'), (',', ','), ('”', '”'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('M.', 'm.'), ('Seeger', 'seeger'), (',', ','), ('“', '“'), ('A', 'a'), ('taxonomy', 'taxonomi'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('methods', 'method'), (',', ','), ('”', '”'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('M.', 'M.'), ('Seeger', 'Seeger'), (',', ','), ('“', '“'), ('A', 'A'), ('taxonomy', 'taxonomy'), ('semi-supervised', 'semi-supervised'), ('learning', 'learning'), ('methods', 'method'), (',', ','), ('”', '”'), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('Tech', 'Tech'), ('.', '.')]



============================ Sentence 645 =============================

Rep., 2006. 


>> Tokens are: 
 ['Rep.', ',', '2006', '.']

>> Bigrams are: 
 [('Rep.', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('Rep.', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), (',', ','), ('2006', 'CD'), ('.', '.')]

 (S (NP Rep./NNP) ,/, 2006/CD ./.) 


>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), (',', ','), ('2006', '2006'), ('.', '.')]



============================ Sentence 646 =============================

[30] T. J. O’Shea and J. Hoydis, “An introduction to machine learning communications systems,” arXiv preprint, vol. 


>> Tokens are: 
 ['[', '30', ']', 'T.', 'J.', 'O', '’', 'Shea', 'J.', 'Hoydis', ',', '“', 'An', 'introduction', 'machine', 'learning', 'communications', 'systems', ',', '”', 'arXiv', 'preprint', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '30'), ('30', ']'), (']', 'T.'), ('T.', 'J.'), ('J.', 'O'), ('O', '’'), ('’', 'Shea'), ('Shea', 'J.'), ('J.', 'Hoydis'), ('Hoydis', ','), (',', '“'), ('“', 'An'), ('An', 'introduction'), ('introduction', 'machine'), ('machine', 'learning'), ('learning', 'communications'), ('communications', 'systems'), ('systems', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '30', ']'), ('30', ']', 'T.'), (']', 'T.', 'J.'), ('T.', 'J.', 'O'), ('J.', 'O', '’'), ('O', '’', 'Shea'), ('’', 'Shea', 'J.'), ('Shea', 'J.', 'Hoydis'), ('J.', 'Hoydis', ','), ('Hoydis', ',', '“'), (',', '“', 'An'), ('“', 'An', 'introduction'), ('An', 'introduction', 'machine'), ('introduction', 'machine', 'learning'), ('machine', 'learning', 'communications'), ('learning', 'communications', 'systems'), ('communications', 'systems', ','), ('systems', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', ','), ('preprint', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('30', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('J.', 'NNP'), ('O', 'NNP'), ('’', 'NNP'), ('Shea', 'NNP'), ('J.', 'NNP'), ('Hoydis', 'NNP'), (',', ','), ('“', 'NNP'), ('An', 'DT'), ('introduction', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('communications', 'NNS'), ('systems', 'NNS'), (',', ','), ('”', 'JJ'), ('arXiv', 'NN'), ('preprint', 'NN'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  30/CD
  (NP ]/JJ T./NNP J./NNP O/NNP ’/NNP Shea/NNP J./NNP Hoydis/NNP)
  ,/,
  (NP “/NNP)
  (NP An/DT introduction/NN machine/NN)
  learning/VBG
  (NP communications/NNS systems/NNS)
  ,/,
  (NP ”/JJ arXiv/NN preprint/NN)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] T. J. O ’ Shea J. Hoydis', '“', 'An introduction machine', 'communications systems', '” arXiv preprint', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'arXiv')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('T.', 't.'), ('J.', 'j.'), ('O', 'o'), ('’', '’'), ('Shea', 'shea'), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('“', '“'), ('An', 'an'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn'), ('communications', 'commun'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('T.', 't.'), ('J.', 'j.'), ('O', 'o'), ('’', '’'), ('Shea', 'shea'), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('“', '“'), ('An', 'an'), ('introduction', 'introduct'), ('machine', 'machin'), ('learning', 'learn'), ('communications', 'communic'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('30', '30'), (']', ']'), ('T.', 'T.'), ('J.', 'J.'), ('O', 'O'), ('’', '’'), ('Shea', 'Shea'), ('J.', 'J.'), ('Hoydis', 'Hoydis'), (',', ','), ('“', '“'), ('An', 'An'), ('introduction', 'introduction'), ('machine', 'machine'), ('learning', 'learning'), ('communications', 'communication'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 647 =============================

1702, 2017. 


>> Tokens are: 
 ['1702', ',', '2017', '.']

>> Bigrams are: 
 [('1702', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('1702', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('1702', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 1702/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1702', '1702'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1702', '1702'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('1702', '1702'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 648 =============================

[31] N. Farsad and A. Goldsmith, “Neural network detection of data sequences in communication systems,” arXiv preprint arXiv:1802.02046, 2018. 


>> Tokens are: 
 ['[', '31', ']', 'N.', 'Farsad', 'A.', 'Goldsmith', ',', '“', 'Neural', 'network', 'detection', 'data', 'sequences', 'communication', 'systems', ',', '”', 'arXiv', 'preprint', 'arXiv:1802.02046', ',', '2018', '.']

>> Bigrams are: 
 [('[', '31'), ('31', ']'), (']', 'N.'), ('N.', 'Farsad'), ('Farsad', 'A.'), ('A.', 'Goldsmith'), ('Goldsmith', ','), (',', '“'), ('“', 'Neural'), ('Neural', 'network'), ('network', 'detection'), ('detection', 'data'), ('data', 'sequences'), ('sequences', 'communication'), ('communication', 'systems'), ('systems', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1802.02046'), ('arXiv:1802.02046', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '31', ']'), ('31', ']', 'N.'), (']', 'N.', 'Farsad'), ('N.', 'Farsad', 'A.'), ('Farsad', 'A.', 'Goldsmith'), ('A.', 'Goldsmith', ','), ('Goldsmith', ',', '“'), (',', '“', 'Neural'), ('“', 'Neural', 'network'), ('Neural', 'network', 'detection'), ('network', 'detection', 'data'), ('detection', 'data', 'sequences'), ('data', 'sequences', 'communication'), ('sequences', 'communication', 'systems'), ('communication', 'systems', ','), ('systems', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1802.02046'), ('preprint', 'arXiv:1802.02046', ','), ('arXiv:1802.02046', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('31', 'CD'), (']', 'JJ'), ('N.', 'NNP'), ('Farsad', 'NNP'), ('A.', 'NN'), ('Goldsmith', 'NNP'), (',', ','), ('“', 'NNP'), ('Neural', 'NNP'), ('network', 'NN'), ('detection', 'NN'), ('data', 'NNS'), ('sequences', 'NNS'), ('communication', 'NN'), ('systems', 'NNS'), (',', ','), ('”', 'JJ'), ('arXiv', 'NN'), ('preprint', 'NN'), ('arXiv:1802.02046', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  31/CD
  (NP ]/JJ N./NNP Farsad/NNP A./NN Goldsmith/NNP)
  ,/,
  (NP
    “/NNP
    Neural/NNP
    network/NN
    detection/NN
    data/NNS
    sequences/NNS
    communication/NN
    systems/NNS)
  ,/,
  (NP ”/JJ arXiv/NN preprint/NN arXiv:1802.02046/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] N. Farsad A. Goldsmith', '“ Neural network detection data sequences communication systems', '” arXiv preprint arXiv:1802.02046']

>> Named Entities are: 
 [('PERSON', 'Goldsmith'), ('ORGANIZATION', 'arXiv')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('N.', 'n.'), ('Farsad', 'farsad'), ('A.', 'a.'), ('Goldsmith', 'goldsmith'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('network', 'network'), ('detection', 'detect'), ('data', 'data'), ('sequences', 'sequenc'), ('communication', 'commun'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1802.02046', 'arxiv:1802.02046'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('N.', 'n.'), ('Farsad', 'farsad'), ('A.', 'a.'), ('Goldsmith', 'goldsmith'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('network', 'network'), ('detection', 'detect'), ('data', 'data'), ('sequences', 'sequenc'), ('communication', 'communic'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1802.02046', 'arxiv:1802.02046'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('31', '31'), (']', ']'), ('N.', 'N.'), ('Farsad', 'Farsad'), ('A.', 'A.'), ('Goldsmith', 'Goldsmith'), (',', ','), ('“', '“'), ('Neural', 'Neural'), ('network', 'network'), ('detection', 'detection'), ('data', 'data'), ('sequences', 'sequence'), ('communication', 'communication'), ('systems', 'system'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1802.02046', 'arXiv:1802.02046'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 649 =============================

[32] S. Bouchired, D. Roviras, and F. Castanié, “Equalisation of satellite mobile channels with neural network techniques,” Space Communications, vol. 


>> Tokens are: 
 ['[', '32', ']', 'S.', 'Bouchired', ',', 'D.', 'Roviras', ',', 'F.', 'Castanié', ',', '“', 'Equalisation', 'satellite', 'mobile', 'channels', 'neural', 'network', 'techniques', ',', '”', 'Space', 'Communications', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '32'), ('32', ']'), (']', 'S.'), ('S.', 'Bouchired'), ('Bouchired', ','), (',', 'D.'), ('D.', 'Roviras'), ('Roviras', ','), (',', 'F.'), ('F.', 'Castanié'), ('Castanié', ','), (',', '“'), ('“', 'Equalisation'), ('Equalisation', 'satellite'), ('satellite', 'mobile'), ('mobile', 'channels'), ('channels', 'neural'), ('neural', 'network'), ('network', 'techniques'), ('techniques', ','), (',', '”'), ('”', 'Space'), ('Space', 'Communications'), ('Communications', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '32', ']'), ('32', ']', 'S.'), (']', 'S.', 'Bouchired'), ('S.', 'Bouchired', ','), ('Bouchired', ',', 'D.'), (',', 'D.', 'Roviras'), ('D.', 'Roviras', ','), ('Roviras', ',', 'F.'), (',', 'F.', 'Castanié'), ('F.', 'Castanié', ','), ('Castanié', ',', '“'), (',', '“', 'Equalisation'), ('“', 'Equalisation', 'satellite'), ('Equalisation', 'satellite', 'mobile'), ('satellite', 'mobile', 'channels'), ('mobile', 'channels', 'neural'), ('channels', 'neural', 'network'), ('neural', 'network', 'techniques'), ('network', 'techniques', ','), ('techniques', ',', '”'), (',', '”', 'Space'), ('”', 'Space', 'Communications'), ('Space', 'Communications', ','), ('Communications', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('32', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('Bouchired', 'NNP'), (',', ','), ('D.', 'NNP'), ('Roviras', 'NNP'), (',', ','), ('F.', 'NNP'), ('Castanié', 'NNP'), (',', ','), ('“', 'NNP'), ('Equalisation', 'NNP'), ('satellite', 'NN'), ('mobile', 'NN'), ('channels', 'NNS'), ('neural', 'JJ'), ('network', 'NN'), ('techniques', 'NNS'), (',', ','), ('”', 'JJ'), ('Space', 'NNP'), ('Communications', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  32/CD
  (NP ]/NNP S./NNP Bouchired/NNP)
  ,/,
  (NP D./NNP Roviras/NNP)
  ,/,
  (NP F./NNP Castanié/NNP)
  ,/,
  (NP “/NNP Equalisation/NNP satellite/NN mobile/NN channels/NNS)
  (NP neural/JJ network/NN techniques/NNS)
  ,/,
  (NP ”/JJ Space/NNP Communications/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] S. Bouchired', 'D. Roviras', 'F. Castanié', '“ Equalisation satellite mobile channels', 'neural network techniques', '” Space Communications', 'vol']

>> Named Entities are: 
 [('PERSON', 'Space Communications')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('S.', 's.'), ('Bouchired', 'bouchir'), (',', ','), ('D.', 'd.'), ('Roviras', 'rovira'), (',', ','), ('F.', 'f.'), ('Castanié', 'castanié'), (',', ','), ('“', '“'), ('Equalisation', 'equalis'), ('satellite', 'satellit'), ('mobile', 'mobil'), ('channels', 'channel'), ('neural', 'neural'), ('network', 'network'), ('techniques', 'techniqu'), (',', ','), ('”', '”'), ('Space', 'space'), ('Communications', 'commun'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('S.', 's.'), ('Bouchired', 'bouchir'), (',', ','), ('D.', 'd.'), ('Roviras', 'rovira'), (',', ','), ('F.', 'f.'), ('Castanié', 'castanié'), (',', ','), ('“', '“'), ('Equalisation', 'equalis'), ('satellite', 'satellit'), ('mobile', 'mobil'), ('channels', 'channel'), ('neural', 'neural'), ('network', 'network'), ('techniques', 'techniqu'), (',', ','), ('”', '”'), ('Space', 'space'), ('Communications', 'communic'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('32', '32'), (']', ']'), ('S.', 'S.'), ('Bouchired', 'Bouchired'), (',', ','), ('D.', 'D.'), ('Roviras', 'Roviras'), (',', ','), ('F.', 'F.'), ('Castanié', 'Castanié'), (',', ','), ('“', '“'), ('Equalisation', 'Equalisation'), ('satellite', 'satellite'), ('mobile', 'mobile'), ('channels', 'channel'), ('neural', 'neural'), ('network', 'network'), ('techniques', 'technique'), (',', ','), ('”', '”'), ('Space', 'Space'), ('Communications', 'Communications'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 650 =============================

15, no. 


>> Tokens are: 
 ['15', ',', '.']

>> Bigrams are: 
 [('15', ','), (',', '.')]

>> Trigrams are: 
 [('15', ',', '.')]

>> POS Tags are: 
 [('15', 'CD'), (',', ','), ('.', '.')]

 (S 15/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), (',', ','), ('.', '.')]



============================ Sentence 651 =============================

4, pp. 


>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 4/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 652 =============================

209–220, 1998. 


>> Tokens are: 
 ['209–220', ',', '1998', '.']

>> Bigrams are: 
 [('209–220', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('209–220', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('209–220', 'CD'), (',', ','), ('1998', 'CD'), ('.', '.')]

 (S 209–220/CD ,/, 1998/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('209–220', '209–220'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('209–220', '209–220'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('209–220', '209–220'), (',', ','), ('1998', '1998'), ('.', '.')]



============================ Sentence 653 =============================

[33] Y. Wang, M. Martonosi, and L.-S. Peh, “A supervised learning approach for routing optimizations in wireless sensor networks,” in Proc. 


>> Tokens are: 
 ['[', '33', ']', 'Y.', 'Wang', ',', 'M.', 'Martonosi', ',', 'L.-S.', 'Peh', ',', '“', 'A', 'supervised', 'learning', 'approach', 'routing', 'optimizations', 'wireless', 'sensor', 'networks', ',', '”', 'Proc', '.']

>> Bigrams are: 
 [('[', '33'), ('33', ']'), (']', 'Y.'), ('Y.', 'Wang'), ('Wang', ','), (',', 'M.'), ('M.', 'Martonosi'), ('Martonosi', ','), (',', 'L.-S.'), ('L.-S.', 'Peh'), ('Peh', ','), (',', '“'), ('“', 'A'), ('A', 'supervised'), ('supervised', 'learning'), ('learning', 'approach'), ('approach', 'routing'), ('routing', 'optimizations'), ('optimizations', 'wireless'), ('wireless', 'sensor'), ('sensor', 'networks'), ('networks', ','), (',', '”'), ('”', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('[', '33', ']'), ('33', ']', 'Y.'), (']', 'Y.', 'Wang'), ('Y.', 'Wang', ','), ('Wang', ',', 'M.'), (',', 'M.', 'Martonosi'), ('M.', 'Martonosi', ','), ('Martonosi', ',', 'L.-S.'), (',', 'L.-S.', 'Peh'), ('L.-S.', 'Peh', ','), ('Peh', ',', '“'), (',', '“', 'A'), ('“', 'A', 'supervised'), ('A', 'supervised', 'learning'), ('supervised', 'learning', 'approach'), ('learning', 'approach', 'routing'), ('approach', 'routing', 'optimizations'), ('routing', 'optimizations', 'wireless'), ('optimizations', 'wireless', 'sensor'), ('wireless', 'sensor', 'networks'), ('sensor', 'networks', ','), ('networks', ',', '”'), (',', '”', 'Proc'), ('”', 'Proc', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('33', 'CD'), (']', 'JJ'), ('Y.', 'NNP'), ('Wang', 'NNP'), (',', ','), ('M.', 'NNP'), ('Martonosi', 'NNP'), (',', ','), ('L.-S.', 'NNP'), ('Peh', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('supervised', 'VBD'), ('learning', 'VBG'), ('approach', 'NN'), ('routing', 'VBG'), ('optimizations', 'NNS'), ('wireless', 'NN'), ('sensor', 'NN'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('Proc', 'NNP'), ('.', '.')]

 (S
  [/RB
  33/CD
  (NP ]/JJ Y./NNP Wang/NNP)
  ,/,
  (NP M./NNP Martonosi/NNP)
  ,/,
  (NP L.-S./NNP Peh/NNP)
  ,/,
  “/VBZ
  (NP A/NNP)
  supervised/VBD
  learning/VBG
  (NP approach/NN)
  routing/VBG
  (NP optimizations/NNS wireless/NN sensor/NN networks/NNS)
  ,/,
  (NP ”/NNP Proc/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Y. Wang', 'M. Martonosi', 'L.-S. Peh', 'A', 'approach', 'optimizations wireless sensor networks', '” Proc']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Y.', 'y.'), ('Wang', 'wang'), (',', ','), ('M.', 'm.'), ('Martonosi', 'martonosi'), (',', ','), ('L.-S.', 'l.-s.'), ('Peh', 'peh'), (',', ','), ('“', '“'), ('A', 'a'), ('supervised', 'supervis'), ('learning', 'learn'), ('approach', 'approach'), ('routing', 'rout'), ('optimizations', 'optim'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Y.', 'y.'), ('Wang', 'wang'), (',', ','), ('M.', 'm.'), ('Martonosi', 'martonosi'), (',', ','), ('L.-S.', 'l.-s.'), ('Peh', 'peh'), (',', ','), ('“', '“'), ('A', 'a'), ('supervised', 'supervis'), ('learning', 'learn'), ('approach', 'approach'), ('routing', 'rout'), ('optimizations', 'optim'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('33', '33'), (']', ']'), ('Y.', 'Y.'), ('Wang', 'Wang'), (',', ','), ('M.', 'M.'), ('Martonosi', 'Martonosi'), (',', ','), ('L.-S.', 'L.-S.'), ('Peh', 'Peh'), (',', ','), ('“', '“'), ('A', 'A'), ('supervised', 'supervised'), ('learning', 'learning'), ('approach', 'approach'), ('routing', 'routing'), ('optimizations', 'optimization'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Proc', 'Proc'), ('.', '.')]



============================ Sentence 654 =============================

Int. 


>> Tokens are: 
 ['Int', '.']

>> Bigrams are: 
 [('Int', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Int', 'NNP'), ('.', '.')]

 (S (NP Int/NNP) ./.) 


>> Noun Phrases are: 
 ['Int']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Int', 'int'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Int', 'int'), ('.', '.')]

>> Lemmatization: 
 [('Int', 'Int'), ('.', '.')]



============================ Sentence 655 =============================

Workshop on Multi-hop ad hoc Networks. 


>> Tokens are: 
 ['Workshop', 'Multi-hop', 'ad', 'hoc', 'Networks', '.']

>> Bigrams are: 
 [('Workshop', 'Multi-hop'), ('Multi-hop', 'ad'), ('ad', 'hoc'), ('hoc', 'Networks'), ('Networks', '.')]

>> Trigrams are: 
 [('Workshop', 'Multi-hop', 'ad'), ('Multi-hop', 'ad', 'hoc'), ('ad', 'hoc', 'Networks'), ('hoc', 'Networks', '.')]

>> POS Tags are: 
 [('Workshop', 'NNP'), ('Multi-hop', 'NNP'), ('ad', 'NN'), ('hoc', 'NN'), ('Networks', 'NNP'), ('.', '.')]

 (S (NP Workshop/NNP Multi-hop/NNP ad/NN hoc/NN Networks/NNP) ./.) 


>> Noun Phrases are: 
 ['Workshop Multi-hop ad hoc Networks']

>> Named Entities are: 
 [('PERSON', 'Workshop'), ('PERSON', 'Networks')] 

>> Stemming using Porter Stemmer: 
 [('Workshop', 'workshop'), ('Multi-hop', 'multi-hop'), ('ad', 'ad'), ('hoc', 'hoc'), ('Networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Workshop', 'workshop'), ('Multi-hop', 'multi-hop'), ('ad', 'ad'), ('hoc', 'hoc'), ('Networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Workshop', 'Workshop'), ('Multi-hop', 'Multi-hop'), ('ad', 'ad'), ('hoc', 'hoc'), ('Networks', 'Networks'), ('.', '.')]



============================ Sentence 656 =============================

ACM, 2006, pp. 


>> Tokens are: 
 ['ACM', ',', '2006', ',', 'pp', '.']

>> Bigrams are: 
 [('ACM', ','), (',', '2006'), ('2006', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('ACM', ',', '2006'), (',', '2006', ','), ('2006', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('ACM', 'NNP'), (',', ','), ('2006', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP ACM/NNP) ,/, 2006/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['ACM', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), (',', ','), ('2006', '2006'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), (',', ','), ('2006', '2006'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), (',', ','), ('2006', '2006'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 657 =============================

79–86. 


>> Tokens are: 
 ['79–86', '.']

>> Bigrams are: 
 [('79–86', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('79–86', 'CD'), ('.', '.')]

 (S 79–86/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('79–86', '79–86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('79–86', '79–86'), ('.', '.')]

>> Lemmatization: 
 [('79–86', '79–86'), ('.', '.')]



============================ Sentence 658 =============================

[34] G. De Veciana and A. Zakhor, “Neural net-based continuous phase modulation receivers,” IEEE Transactions on Communi- cations, vol. 


>> Tokens are: 
 ['[', '34', ']', 'G.', 'De', 'Veciana', 'A.', 'Zakhor', ',', '“', 'Neural', 'net-based', 'continuous', 'phase', 'modulation', 'receivers', ',', '”', 'IEEE', 'Transactions', 'Communi-', 'cations', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '34'), ('34', ']'), (']', 'G.'), ('G.', 'De'), ('De', 'Veciana'), ('Veciana', 'A.'), ('A.', 'Zakhor'), ('Zakhor', ','), (',', '“'), ('“', 'Neural'), ('Neural', 'net-based'), ('net-based', 'continuous'), ('continuous', 'phase'), ('phase', 'modulation'), ('modulation', 'receivers'), ('receivers', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Communi-'), ('Communi-', 'cations'), ('cations', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '34', ']'), ('34', ']', 'G.'), (']', 'G.', 'De'), ('G.', 'De', 'Veciana'), ('De', 'Veciana', 'A.'), ('Veciana', 'A.', 'Zakhor'), ('A.', 'Zakhor', ','), ('Zakhor', ',', '“'), (',', '“', 'Neural'), ('“', 'Neural', 'net-based'), ('Neural', 'net-based', 'continuous'), ('net-based', 'continuous', 'phase'), ('continuous', 'phase', 'modulation'), ('phase', 'modulation', 'receivers'), ('modulation', 'receivers', ','), ('receivers', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Communi-'), ('Transactions', 'Communi-', 'cations'), ('Communi-', 'cations', ','), ('cations', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('34', 'CD'), (']', 'JJ'), ('G.', 'NNP'), ('De', 'NNP'), ('Veciana', 'NNP'), ('A.', 'NNP'), ('Zakhor', 'NNP'), (',', ','), ('“', 'NNP'), ('Neural', 'NNP'), ('net-based', 'JJ'), ('continuous', 'JJ'), ('phase', 'NN'), ('modulation', 'NN'), ('receivers', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Communi-', 'NNP'), ('cations', 'NNS'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  34/CD
  (NP ]/JJ G./NNP De/NNP Veciana/NNP A./NNP Zakhor/NNP)
  ,/,
  (NP “/NNP Neural/NNP)
  (NP
    net-based/JJ
    continuous/JJ
    phase/NN
    modulation/NN
    receivers/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Transactions/NNP Communi-/NNP cations/NNS)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] G. De Veciana A. Zakhor', '“ Neural', 'net-based continuous phase modulation receivers', '” IEEE Transactions Communi- cations', 'vol']

>> Named Entities are: 
 [('PERSON', 'Veciana A. Zakhor')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('G.', 'g.'), ('De', 'de'), ('Veciana', 'veciana'), ('A.', 'a.'), ('Zakhor', 'zakhor'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('net-based', 'net-bas'), ('continuous', 'continu'), ('phase', 'phase'), ('modulation', 'modul'), ('receivers', 'receiv'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Communi-', 'communi-'), ('cations', 'cation'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('G.', 'g.'), ('De', 'de'), ('Veciana', 'veciana'), ('A.', 'a.'), ('Zakhor', 'zakhor'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('net-based', 'net-bas'), ('continuous', 'continu'), ('phase', 'phase'), ('modulation', 'modul'), ('receivers', 'receiv'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Communi-', 'communi-'), ('cations', 'cation'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('34', '34'), (']', ']'), ('G.', 'G.'), ('De', 'De'), ('Veciana', 'Veciana'), ('A.', 'A.'), ('Zakhor', 'Zakhor'), (',', ','), ('“', '“'), ('Neural', 'Neural'), ('net-based', 'net-based'), ('continuous', 'continuous'), ('phase', 'phase'), ('modulation', 'modulation'), ('receivers', 'receiver'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Communi-', 'Communi-'), ('cations', 'cation'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 659 =============================

40, no. 


>> Tokens are: 
 ['40', ',', '.']

>> Bigrams are: 
 [('40', ','), (',', '.')]

>> Trigrams are: 
 [('40', ',', '.')]

>> POS Tags are: 
 [('40', 'CD'), (',', ','), ('.', '.')]

 (S 40/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('40', '40'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('40', '40'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('40', '40'), (',', ','), ('.', '.')]



============================ Sentence 660 =============================

8, pp. 


>> Tokens are: 
 ['8', ',', 'pp', '.']

>> Bigrams are: 
 [('8', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('8', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 8/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 661 =============================

1396–1408, 1992. 


>> Tokens are: 
 ['1396–1408', ',', '1992', '.']

>> Bigrams are: 
 [('1396–1408', ','), (',', '1992'), ('1992', '.')]

>> Trigrams are: 
 [('1396–1408', ',', '1992'), (',', '1992', '.')]

>> POS Tags are: 
 [('1396–1408', 'CD'), (',', ','), ('1992', 'CD'), ('.', '.')]

 (S 1396–1408/CD ,/, 1992/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1396–1408', '1396–1408'), (',', ','), ('1992', '1992'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1396–1408', '1396–1408'), (',', ','), ('1992', '1992'), ('.', '.')]

>> Lemmatization: 
 [('1396–1408', '1396–1408'), (',', ','), ('1992', '1992'), ('.', '.')]



============================ Sentence 662 =============================

[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels,” ArXiv e-prints, Jul. 


>> Tokens are: 
 ['[', '35', ']', 'X.', 'Jin', 'H.-N.', 'Kim', ',', '“', 'Deep', 'Learning', 'Detection', 'Networks', 'MIMO', 'Decode-Forward', 'Relay', 'Channels', ',', '”', 'ArXiv', 'e-prints', ',', 'Jul', '.']

>> Bigrams are: 
 [('[', '35'), ('35', ']'), (']', 'X.'), ('X.', 'Jin'), ('Jin', 'H.-N.'), ('H.-N.', 'Kim'), ('Kim', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Detection'), ('Detection', 'Networks'), ('Networks', 'MIMO'), ('MIMO', 'Decode-Forward'), ('Decode-Forward', 'Relay'), ('Relay', 'Channels'), ('Channels', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jul'), ('Jul', '.')]

>> Trigrams are: 
 [('[', '35', ']'), ('35', ']', 'X.'), (']', 'X.', 'Jin'), ('X.', 'Jin', 'H.-N.'), ('Jin', 'H.-N.', 'Kim'), ('H.-N.', 'Kim', ','), ('Kim', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'Learning'), ('Deep', 'Learning', 'Detection'), ('Learning', 'Detection', 'Networks'), ('Detection', 'Networks', 'MIMO'), ('Networks', 'MIMO', 'Decode-Forward'), ('MIMO', 'Decode-Forward', 'Relay'), ('Decode-Forward', 'Relay', 'Channels'), ('Relay', 'Channels', ','), ('Channels', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jul'), (',', 'Jul', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('35', 'CD'), (']', 'JJ'), ('X.', 'NNP'), ('Jin', 'NNP'), ('H.-N.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('“', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Detection', 'NNP'), ('Networks', 'NNP'), ('MIMO', 'NNP'), ('Decode-Forward', 'NNP'), ('Relay', 'NNP'), ('Channels', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jul', 'NNP'), ('.', '.')]

 (S
  [/RB
  35/CD
  (NP ]/JJ X./NNP Jin/NNP H.-N./NNP Kim/NNP)
  ,/,
  (NP
    “/NNP
    Deep/NNP
    Learning/NNP
    Detection/NNP
    Networks/NNP
    MIMO/NNP
    Decode-Forward/NNP
    Relay/NNP
    Channels/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jul/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] X. Jin H.-N. Kim', '“ Deep Learning Detection Networks MIMO Decode-Forward Relay Channels', '” ArXiv e-prints', 'Jul']

>> Named Entities are: 
 [('PERSON', 'Kim'), ('PERSON', 'Networks MIMO'), ('PERSON', 'Jul')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('X.', 'x.'), ('Jin', 'jin'), ('H.-N.', 'h.-n.'), ('Kim', 'kim'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Learning', 'learn'), ('Detection', 'detect'), ('Networks', 'network'), ('MIMO', 'mimo'), ('Decode-Forward', 'decode-forward'), ('Relay', 'relay'), ('Channels', 'channel'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('X.', 'x.'), ('Jin', 'jin'), ('H.-N.', 'h.-n.'), ('Kim', 'kim'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Learning', 'learn'), ('Detection', 'detect'), ('Networks', 'network'), ('MIMO', 'mimo'), ('Decode-Forward', 'decode-forward'), ('Relay', 'relay'), ('Channels', 'channel'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('35', '35'), (']', ']'), ('X.', 'X.'), ('Jin', 'Jin'), ('H.-N.', 'H.-N.'), ('Kim', 'Kim'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Detection', 'Detection'), ('Networks', 'Networks'), ('MIMO', 'MIMO'), ('Decode-Forward', 'Decode-Forward'), ('Relay', 'Relay'), ('Channels', 'Channels'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jul', 'Jul'), ('.', '.')]



============================ Sentence 663 =============================

2018. 


>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

 (S 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]



============================ Sentence 664 =============================

[36] E. Nachmani, E. Marciano, L. Lugosch, W. J. 


>> Tokens are: 
 ['[', '36', ']', 'E.', 'Nachmani', ',', 'E.', 'Marciano', ',', 'L.', 'Lugosch', ',', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '36'), ('36', ']'), (']', 'E.'), ('E.', 'Nachmani'), ('Nachmani', ','), (',', 'E.'), ('E.', 'Marciano'), ('Marciano', ','), (',', 'L.'), ('L.', 'Lugosch'), ('Lugosch', ','), (',', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '36', ']'), ('36', ']', 'E.'), (']', 'E.', 'Nachmani'), ('E.', 'Nachmani', ','), ('Nachmani', ',', 'E.'), (',', 'E.', 'Marciano'), ('E.', 'Marciano', ','), ('Marciano', ',', 'L.'), (',', 'L.', 'Lugosch'), ('L.', 'Lugosch', ','), ('Lugosch', ',', 'W.'), (',', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('36', 'CD'), (']', 'NNP'), ('E.', 'NNP'), ('Nachmani', 'NNP'), (',', ','), ('E.', 'NNP'), ('Marciano', 'NNP'), (',', ','), ('L.', 'NNP'), ('Lugosch', 'NNP'), (',', ','), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S
  [/RB
  36/CD
  (NP ]/NNP E./NNP Nachmani/NNP)
  ,/,
  (NP E./NNP Marciano/NNP)
  ,/,
  (NP L./NNP Lugosch/NNP)
  ,/,
  (NP W./NNP J/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] E. Nachmani', 'E. Marciano', 'L. Lugosch', 'W. J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('E.', 'e.'), ('Nachmani', 'nachmani'), (',', ','), ('E.', 'e.'), ('Marciano', 'marciano'), (',', ','), ('L.', 'l.'), ('Lugosch', 'lugosch'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('E.', 'e.'), ('Nachmani', 'nachmani'), (',', ','), ('E.', 'e.'), ('Marciano', 'marciano'), (',', ','), ('L.', 'l.'), ('Lugosch', 'lugosch'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('36', '36'), (']', ']'), ('E.', 'E.'), ('Nachmani', 'Nachmani'), (',', ','), ('E.', 'E.'), ('Marciano', 'Marciano'), (',', ','), ('L.', 'L.'), ('Lugosch', 'Lugosch'), (',', ','), ('W.', 'W.'), ('J', 'J'), ('.', '.')]



============================ Sentence 665 =============================

Gross, D. Bur- shtein, and Y. Be’ery, “Deep learning methods for improved decoding of linear codes,” IEEE Journal of Selected Topics in Signal Processing, vol. 


>> Tokens are: 
 ['Gross', ',', 'D.', 'Bur-', 'shtein', ',', 'Y.', 'Be', '’', 'ery', ',', '“', 'Deep', 'learning', 'methods', 'improved', 'decoding', 'linear', 'codes', ',', '”', 'IEEE', 'Journal', 'Selected', 'Topics', 'Signal', 'Processing', ',', 'vol', '.']

>> Bigrams are: 
 [('Gross', ','), (',', 'D.'), ('D.', 'Bur-'), ('Bur-', 'shtein'), ('shtein', ','), (',', 'Y.'), ('Y.', 'Be'), ('Be', '’'), ('’', 'ery'), ('ery', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'learning'), ('learning', 'methods'), ('methods', 'improved'), ('improved', 'decoding'), ('decoding', 'linear'), ('linear', 'codes'), ('codes', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Journal'), ('Journal', 'Selected'), ('Selected', 'Topics'), ('Topics', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Gross', ',', 'D.'), (',', 'D.', 'Bur-'), ('D.', 'Bur-', 'shtein'), ('Bur-', 'shtein', ','), ('shtein', ',', 'Y.'), (',', 'Y.', 'Be'), ('Y.', 'Be', '’'), ('Be', '’', 'ery'), ('’', 'ery', ','), ('ery', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'learning'), ('Deep', 'learning', 'methods'), ('learning', 'methods', 'improved'), ('methods', 'improved', 'decoding'), ('improved', 'decoding', 'linear'), ('decoding', 'linear', 'codes'), ('linear', 'codes', ','), ('codes', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Journal'), ('IEEE', 'Journal', 'Selected'), ('Journal', 'Selected', 'Topics'), ('Selected', 'Topics', 'Signal'), ('Topics', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('Gross', 'NNP'), (',', ','), ('D.', 'NNP'), ('Bur-', 'NNP'), ('shtein', 'NN'), (',', ','), ('Y.', 'NNP'), ('Be', 'NNP'), ('’', 'JJ'), ('ery', 'NN'), (',', ','), ('“', 'JJ'), ('Deep', 'NNP'), ('learning', 'NN'), ('methods', 'NNS'), ('improved', 'VBN'), ('decoding', 'VBG'), ('linear', 'JJ'), ('codes', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Journal', 'NNP'), ('Selected', 'NNP'), ('Topics', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP Gross/NNP)
  ,/,
  (NP D./NNP Bur-/NNP shtein/NN)
  ,/,
  (NP Y./NNP Be/NNP)
  (NP ’/JJ ery/NN)
  ,/,
  (NP “/JJ Deep/NNP learning/NN methods/NNS)
  improved/VBN
  decoding/VBG
  (NP linear/JJ codes/NNS)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Journal/NNP
    Selected/NNP
    Topics/NNP
    Signal/NNP
    Processing/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['Gross', 'D. Bur- shtein', 'Y. Be', '’ ery', '“ Deep learning methods', 'linear codes', '” IEEE Journal Selected Topics Signal Processing', 'vol']

>> Named Entities are: 
 [('GPE', 'Gross')] 

>> Stemming using Porter Stemmer: 
 [('Gross', 'gross'), (',', ','), ('D.', 'd.'), ('Bur-', 'bur-'), ('shtein', 'shtein'), (',', ','), ('Y.', 'y.'), ('Be', 'be'), ('’', '’'), ('ery', 'eri'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('improved', 'improv'), ('decoding', 'decod'), ('linear', 'linear'), ('codes', 'code'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Selected', 'select'), ('Topics', 'topic'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gross', 'gross'), (',', ','), ('D.', 'd.'), ('Bur-', 'bur-'), ('shtein', 'shtein'), (',', ','), ('Y.', 'y.'), ('Be', 'be'), ('’', '’'), ('ery', 'eri'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('improved', 'improv'), ('decoding', 'decod'), ('linear', 'linear'), ('codes', 'code'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Selected', 'select'), ('Topics', 'topic'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Gross', 'Gross'), (',', ','), ('D.', 'D.'), ('Bur-', 'Bur-'), ('shtein', 'shtein'), (',', ','), ('Y.', 'Y.'), ('Be', 'Be'), ('’', '’'), ('ery', 'ery'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('learning', 'learning'), ('methods', 'method'), ('improved', 'improved'), ('decoding', 'decoding'), ('linear', 'linear'), ('codes', 'code'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Journal', 'Journal'), ('Selected', 'Selected'), ('Topics', 'Topics'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 666 =============================

12, no. 


>> Tokens are: 
 ['12', ',', '.']

>> Bigrams are: 
 [('12', ','), (',', '.')]

>> Trigrams are: 
 [('12', ',', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('.', '.')]

 (S 12/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('.', '.')]



============================ Sentence 667 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 668 =============================

119–131, 2018. 


>> Tokens are: 
 ['119–131', ',', '2018', '.']

>> Bigrams are: 
 [('119–131', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('119–131', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('119–131', 'CD'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S 119–131/CD ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('119–131', '119–131'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('119–131', '119–131'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('119–131', '119–131'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 669 =============================

[37] L. Lugosch and W. J. 


>> Tokens are: 
 ['[', '37', ']', 'L.', 'Lugosch', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '37'), ('37', ']'), (']', 'L.'), ('L.', 'Lugosch'), ('Lugosch', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '37', ']'), ('37', ']', 'L.'), (']', 'L.', 'Lugosch'), ('L.', 'Lugosch', 'W.'), ('Lugosch', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('37', 'CD'), (']', 'JJ'), ('L.', 'NNP'), ('Lugosch', 'NNP'), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S [/RB 37/CD (NP ]/JJ L./NNP Lugosch/NNP W./NNP J/NNP) ./.) 


>> Noun Phrases are: 
 ['] L. Lugosch W. J']

>> Named Entities are: 
 [('PERSON', 'Lugosch W. J')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('37', '37'), (']', ']'), ('L.', 'l.'), ('Lugosch', 'lugosch'), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('37', '37'), (']', ']'), ('L.', 'l.'), ('Lugosch', 'lugosch'), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('37', '37'), (']', ']'), ('L.', 'L.'), ('Lugosch', 'Lugosch'), ('W.', 'W.'), ('J', 'J'), ('.', '.')]



============================ Sentence 670 =============================

Gross, “Neural offset min-sum decoding,” in IEEE int. 


>> Tokens are: 
 ['Gross', ',', '“', 'Neural', 'offset', 'min-sum', 'decoding', ',', '”', 'IEEE', 'int', '.']

>> Bigrams are: 
 [('Gross', ','), (',', '“'), ('“', 'Neural'), ('Neural', 'offset'), ('offset', 'min-sum'), ('min-sum', 'decoding'), ('decoding', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'int'), ('int', '.')]

>> Trigrams are: 
 [('Gross', ',', '“'), (',', '“', 'Neural'), ('“', 'Neural', 'offset'), ('Neural', 'offset', 'min-sum'), ('offset', 'min-sum', 'decoding'), ('min-sum', 'decoding', ','), ('decoding', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'int'), ('IEEE', 'int', '.')]

>> POS Tags are: 
 [('Gross', 'NNP'), (',', ','), ('“', 'NNP'), ('Neural', 'NNP'), ('offset', 'VBD'), ('min-sum', 'JJ'), ('decoding', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('int', 'NN'), ('.', '.')]

 (S
  (NP Gross/NNP)
  ,/,
  (NP “/NNP Neural/NNP)
  offset/VBD
  (NP min-sum/JJ decoding/NN)
  ,/,
  (NP ”/NNP IEEE/NNP int/NN)
  ./.) 


>> Noun Phrases are: 
 ['Gross', '“ Neural', 'min-sum decoding', '” IEEE int']

>> Named Entities are: 
 [('GPE', 'Gross')] 

>> Stemming using Porter Stemmer: 
 [('Gross', 'gross'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('offset', 'offset'), ('min-sum', 'min-sum'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('int', 'int'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gross', 'gross'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('offset', 'offset'), ('min-sum', 'min-sum'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('int', 'int'), ('.', '.')]

>> Lemmatization: 
 [('Gross', 'Gross'), (',', ','), ('“', '“'), ('Neural', 'Neural'), ('offset', 'offset'), ('min-sum', 'min-sum'), ('decoding', 'decoding'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('int', 'int'), ('.', '.')]



============================ Sentence 671 =============================

Symp. 


>> Tokens are: 
 ['Symp', '.']

>> Bigrams are: 
 [('Symp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Symp', 'NNP'), ('.', '.')]

 (S (NP Symp/NNP) ./.) 


>> Noun Phrases are: 
 ['Symp']

>> Named Entities are: 
 [('GPE', 'Symp')] 

>> Stemming using Porter Stemmer: 
 [('Symp', 'symp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Symp', 'symp'), ('.', '.')]

>> Lemmatization: 
 [('Symp', 'Symp'), ('.', '.')]



============================ Sentence 672 =============================

Information Theory (ISIT 2017). 


>> Tokens are: 
 ['Information', 'Theory', '(', 'ISIT', '2017', ')', '.']

>> Bigrams are: 
 [('Information', 'Theory'), ('Theory', '('), ('(', 'ISIT'), ('ISIT', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Information', 'Theory', '('), ('Theory', '(', 'ISIT'), ('(', 'ISIT', '2017'), ('ISIT', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Theory', 'NNP'), ('(', '('), ('ISIT', 'NNP'), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S (NP Information/NN Theory/NNP) (/( (NP ISIT/NNP) 2017/CD )/) ./.) 


>> Noun Phrases are: 
 ['Information Theory', 'ISIT']

>> Named Entities are: 
 [('ORGANIZATION', 'ISIT')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Theory', 'theori'), ('(', '('), ('ISIT', 'isit'), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Theory', 'theori'), ('(', '('), ('ISIT', 'isit'), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Theory', 'Theory'), ('(', '('), ('ISIT', 'ISIT'), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 673 =============================

IEEE, 2017, pp. 


>> Tokens are: 
 ['IEEE', ',', '2017', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', ','), (',', '2017'), ('2017', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', ',', '2017'), (',', '2017', ','), ('2017', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), (',', ','), ('2017', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP IEEE/NNP) ,/, 2017/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['IEEE', 'pp']

>> Named Entities are: 
 [('GPE', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 674 =============================

1361–1365. 


>> Tokens are: 
 ['1361–1365', '.']

>> Bigrams are: 
 [('1361–1365', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1361–1365', 'CD'), ('.', '.')]

 (S 1361–1365/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1361–1365', '1361–1365'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1361–1365', '1361–1365'), ('.', '.')]

>> Lemmatization: 
 [('1361–1365', '1361–1365'), ('.', '.')]



============================ Sentence 675 =============================

[38] S. Cammerer, T. Gruber, J. Hoydis, and S. ten Brink, “Scaling deep learning-based decoding of polar codes via partitioning,” in IEEE GLOBECOM 2017, 2017, pp. 


>> Tokens are: 
 ['[', '38', ']', 'S.', 'Cammerer', ',', 'T.', 'Gruber', ',', 'J.', 'Hoydis', ',', 'S.', 'ten', 'Brink', ',', '“', 'Scaling', 'deep', 'learning-based', 'decoding', 'polar', 'codes', 'via', 'partitioning', ',', '”', 'IEEE', 'GLOBECOM', '2017', ',', '2017', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '38'), ('38', ']'), (']', 'S.'), ('S.', 'Cammerer'), ('Cammerer', ','), (',', 'T.'), ('T.', 'Gruber'), ('Gruber', ','), (',', 'J.'), ('J.', 'Hoydis'), ('Hoydis', ','), (',', 'S.'), ('S.', 'ten'), ('ten', 'Brink'), ('Brink', ','), (',', '“'), ('“', 'Scaling'), ('Scaling', 'deep'), ('deep', 'learning-based'), ('learning-based', 'decoding'), ('decoding', 'polar'), ('polar', 'codes'), ('codes', 'via'), ('via', 'partitioning'), ('partitioning', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'GLOBECOM'), ('GLOBECOM', '2017'), ('2017', ','), (',', '2017'), ('2017', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '38', ']'), ('38', ']', 'S.'), (']', 'S.', 'Cammerer'), ('S.', 'Cammerer', ','), ('Cammerer', ',', 'T.'), (',', 'T.', 'Gruber'), ('T.', 'Gruber', ','), ('Gruber', ',', 'J.'), (',', 'J.', 'Hoydis'), ('J.', 'Hoydis', ','), ('Hoydis', ',', 'S.'), (',', 'S.', 'ten'), ('S.', 'ten', 'Brink'), ('ten', 'Brink', ','), ('Brink', ',', '“'), (',', '“', 'Scaling'), ('“', 'Scaling', 'deep'), ('Scaling', 'deep', 'learning-based'), ('deep', 'learning-based', 'decoding'), ('learning-based', 'decoding', 'polar'), ('decoding', 'polar', 'codes'), ('polar', 'codes', 'via'), ('codes', 'via', 'partitioning'), ('via', 'partitioning', ','), ('partitioning', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'GLOBECOM'), ('IEEE', 'GLOBECOM', '2017'), ('GLOBECOM', '2017', ','), ('2017', ',', '2017'), (',', '2017', ','), ('2017', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('38', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('Cammerer', 'NNP'), (',', ','), ('T.', 'NNP'), ('Gruber', 'NNP'), (',', ','), ('J.', 'NNP'), ('Hoydis', 'NNP'), (',', ','), ('S.', 'NNP'), ('ten', 'VBZ'), ('Brink', 'NNP'), (',', ','), ('“', 'NNP'), ('Scaling', 'NNP'), ('deep', 'JJ'), ('learning-based', 'JJ'), ('decoding', 'VBG'), ('polar', 'JJ'), ('codes', 'NNS'), ('via', 'IN'), ('partitioning', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('GLOBECOM', 'NNP'), ('2017', 'CD'), (',', ','), ('2017', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  38/CD
  (NP ]/NNP S./NNP Cammerer/NNP)
  ,/,
  (NP T./NNP Gruber/NNP)
  ,/,
  (NP J./NNP Hoydis/NNP)
  ,/,
  (NP S./NNP)
  ten/VBZ
  (NP Brink/NNP)
  ,/,
  (NP “/NNP Scaling/NNP)
  deep/JJ
  learning-based/JJ
  decoding/VBG
  (NP polar/JJ codes/NNS)
  via/IN
  (NP partitioning/NN)
  ,/,
  (NP ”/NNP IEEE/NNP GLOBECOM/NNP)
  2017/CD
  ,/,
  2017/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] S. Cammerer', 'T. Gruber', 'J. Hoydis', 'S.', 'Brink', '“ Scaling', 'polar codes', 'partitioning', '” IEEE GLOBECOM', 'pp']

>> Named Entities are: 
 [('PERSON', 'J. Hoydis'), ('GPE', 'Brink')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('38', '38'), (']', ']'), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('T.', 't.'), ('Gruber', 'gruber'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('ten', 'ten'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('Scaling', 'scale'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('decoding', 'decod'), ('polar', 'polar'), ('codes', 'code'), ('via', 'via'), ('partitioning', 'partit'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('GLOBECOM', 'globecom'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('38', '38'), (']', ']'), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('T.', 't.'), ('Gruber', 'gruber'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('ten', 'ten'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('Scaling', 'scale'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('decoding', 'decod'), ('polar', 'polar'), ('codes', 'code'), ('via', 'via'), ('partitioning', 'partit'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('GLOBECOM', 'globecom'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('38', '38'), (']', ']'), ('S.', 'S.'), ('Cammerer', 'Cammerer'), (',', ','), ('T.', 'T.'), ('Gruber', 'Gruber'), (',', ','), ('J.', 'J.'), ('Hoydis', 'Hoydis'), (',', ','), ('S.', 'S.'), ('ten', 'ten'), ('Brink', 'Brink'), (',', ','), ('“', '“'), ('Scaling', 'Scaling'), ('deep', 'deep'), ('learning-based', 'learning-based'), ('decoding', 'decoding'), ('polar', 'polar'), ('codes', 'code'), ('via', 'via'), ('partitioning', 'partitioning'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('GLOBECOM', 'GLOBECOM'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 676 =============================

1–6. 


>> Tokens are: 
 ['1–6', '.']

>> Bigrams are: 
 [('1–6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–6', 'CD'), ('.', '.')]

 (S 1–6/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Lemmatization: 
 [('1–6', '1–6'), ('.', '.')]



============================ Sentence 677 =============================

[39] S. Schibisch, S. Cammerer, S. Dörner, J. Hoydis, and S. t. Brink, “Online label recovery for deep learning-based com- munication through error correcting codes,” arXiv preprint arXiv:1807.00747, 2018. 


>> Tokens are: 
 ['[', '39', ']', 'S.', 'Schibisch', ',', 'S.', 'Cammerer', ',', 'S.', 'Dörner', ',', 'J.', 'Hoydis', ',', 'S.', 't.', 'Brink', ',', '“', 'Online', 'label', 'recovery', 'deep', 'learning-based', 'com-', 'munication', 'error', 'correcting', 'codes', ',', '”', 'arXiv', 'preprint', 'arXiv:1807.00747', ',', '2018', '.']

>> Bigrams are: 
 [('[', '39'), ('39', ']'), (']', 'S.'), ('S.', 'Schibisch'), ('Schibisch', ','), (',', 'S.'), ('S.', 'Cammerer'), ('Cammerer', ','), (',', 'S.'), ('S.', 'Dörner'), ('Dörner', ','), (',', 'J.'), ('J.', 'Hoydis'), ('Hoydis', ','), (',', 'S.'), ('S.', 't.'), ('t.', 'Brink'), ('Brink', ','), (',', '“'), ('“', 'Online'), ('Online', 'label'), ('label', 'recovery'), ('recovery', 'deep'), ('deep', 'learning-based'), ('learning-based', 'com-'), ('com-', 'munication'), ('munication', 'error'), ('error', 'correcting'), ('correcting', 'codes'), ('codes', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1807.00747'), ('arXiv:1807.00747', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '39', ']'), ('39', ']', 'S.'), (']', 'S.', 'Schibisch'), ('S.', 'Schibisch', ','), ('Schibisch', ',', 'S.'), (',', 'S.', 'Cammerer'), ('S.', 'Cammerer', ','), ('Cammerer', ',', 'S.'), (',', 'S.', 'Dörner'), ('S.', 'Dörner', ','), ('Dörner', ',', 'J.'), (',', 'J.', 'Hoydis'), ('J.', 'Hoydis', ','), ('Hoydis', ',', 'S.'), (',', 'S.', 't.'), ('S.', 't.', 'Brink'), ('t.', 'Brink', ','), ('Brink', ',', '“'), (',', '“', 'Online'), ('“', 'Online', 'label'), ('Online', 'label', 'recovery'), ('label', 'recovery', 'deep'), ('recovery', 'deep', 'learning-based'), ('deep', 'learning-based', 'com-'), ('learning-based', 'com-', 'munication'), ('com-', 'munication', 'error'), ('munication', 'error', 'correcting'), ('error', 'correcting', 'codes'), ('correcting', 'codes', ','), ('codes', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1807.00747'), ('preprint', 'arXiv:1807.00747', ','), ('arXiv:1807.00747', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('39', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('Schibisch', 'NNP'), (',', ','), ('S.', 'NNP'), ('Cammerer', 'NNP'), (',', ','), ('S.', 'NNP'), ('Dörner', 'NNP'), (',', ','), ('J.', 'NNP'), ('Hoydis', 'NNP'), (',', ','), ('S.', 'NNP'), ('t.', 'NNP'), ('Brink', 'NNP'), (',', ','), ('“', 'NNP'), ('Online', 'NNP'), ('label', 'NN'), ('recovery', 'NN'), ('deep', 'JJ'), ('learning-based', 'JJ'), ('com-', 'JJ'), ('munication', 'NN'), ('error', 'NN'), ('correcting', 'VBG'), ('codes', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1807.00747', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  39/CD
  (NP ]/NNP S./NNP Schibisch/NNP)
  ,/,
  (NP S./NNP Cammerer/NNP)
  ,/,
  (NP S./NNP Dörner/NNP)
  ,/,
  (NP J./NNP Hoydis/NNP)
  ,/,
  (NP S./NNP t./NNP Brink/NNP)
  ,/,
  (NP “/NNP Online/NNP label/NN recovery/NN)
  (NP deep/JJ learning-based/JJ com-/JJ munication/NN error/NN)
  correcting/VBG
  (NP codes/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1807.00747/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] S. Schibisch', 'S. Cammerer', 'S. Dörner', 'J. Hoydis', 'S. t. Brink', '“ Online label recovery', 'deep learning-based com- munication error', 'codes', '”', 'preprint arXiv:1807.00747']

>> Named Entities are: 
 [('PERSON', 'J. Hoydis')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('39', '39'), (']', ']'), ('S.', 's.'), ('Schibisch', 'schibisch'), (',', ','), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('S.', 's.'), ('Dörner', 'dörner'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('t.', 't.'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('Online', 'onlin'), ('label', 'label'), ('recovery', 'recoveri'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('com-', 'com-'), ('munication', 'munic'), ('error', 'error'), ('correcting', 'correct'), ('codes', 'code'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00747', 'arxiv:1807.00747'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('39', '39'), (']', ']'), ('S.', 's.'), ('Schibisch', 'schibisch'), (',', ','), ('S.', 's.'), ('Cammerer', 'cammer'), (',', ','), ('S.', 's.'), ('Dörner', 'dörner'), (',', ','), ('J.', 'j.'), ('Hoydis', 'hoydi'), (',', ','), ('S.', 's.'), ('t.', 't.'), ('Brink', 'brink'), (',', ','), ('“', '“'), ('Online', 'onlin'), ('label', 'label'), ('recovery', 'recoveri'), ('deep', 'deep'), ('learning-based', 'learning-bas'), ('com-', 'com-'), ('munication', 'munic'), ('error', 'error'), ('correcting', 'correct'), ('codes', 'code'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00747', 'arxiv:1807.00747'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('39', '39'), (']', ']'), ('S.', 'S.'), ('Schibisch', 'Schibisch'), (',', ','), ('S.', 'S.'), ('Cammerer', 'Cammerer'), (',', ','), ('S.', 'S.'), ('Dörner', 'Dörner'), (',', ','), ('J.', 'J.'), ('Hoydis', 'Hoydis'), (',', ','), ('S.', 'S.'), ('t.', 't.'), ('Brink', 'Brink'), (',', ','), ('“', '“'), ('Online', 'Online'), ('label', 'label'), ('recovery', 'recovery'), ('deep', 'deep'), ('learning-based', 'learning-based'), ('com-', 'com-'), ('munication', 'munication'), ('error', 'error'), ('correcting', 'correcting'), ('codes', 'code'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1807.00747', 'arXiv:1807.00747'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 678 =============================

[40] F. Liang, C. Shen, and F. Wu, “An iterative bp-cnn architecture for channel decoding,” IEEE Journal of Selected Topics in Signal Processing, vol. 


>> Tokens are: 
 ['[', '40', ']', 'F.', 'Liang', ',', 'C.', 'Shen', ',', 'F.', 'Wu', ',', '“', 'An', 'iterative', 'bp-cnn', 'architecture', 'channel', 'decoding', ',', '”', 'IEEE', 'Journal', 'Selected', 'Topics', 'Signal', 'Processing', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '40'), ('40', ']'), (']', 'F.'), ('F.', 'Liang'), ('Liang', ','), (',', 'C.'), ('C.', 'Shen'), ('Shen', ','), (',', 'F.'), ('F.', 'Wu'), ('Wu', ','), (',', '“'), ('“', 'An'), ('An', 'iterative'), ('iterative', 'bp-cnn'), ('bp-cnn', 'architecture'), ('architecture', 'channel'), ('channel', 'decoding'), ('decoding', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Journal'), ('Journal', 'Selected'), ('Selected', 'Topics'), ('Topics', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '40', ']'), ('40', ']', 'F.'), (']', 'F.', 'Liang'), ('F.', 'Liang', ','), ('Liang', ',', 'C.'), (',', 'C.', 'Shen'), ('C.', 'Shen', ','), ('Shen', ',', 'F.'), (',', 'F.', 'Wu'), ('F.', 'Wu', ','), ('Wu', ',', '“'), (',', '“', 'An'), ('“', 'An', 'iterative'), ('An', 'iterative', 'bp-cnn'), ('iterative', 'bp-cnn', 'architecture'), ('bp-cnn', 'architecture', 'channel'), ('architecture', 'channel', 'decoding'), ('channel', 'decoding', ','), ('decoding', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Journal'), ('IEEE', 'Journal', 'Selected'), ('Journal', 'Selected', 'Topics'), ('Selected', 'Topics', 'Signal'), ('Topics', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('40', 'CD'), (']', 'JJ'), ('F.', 'NNP'), ('Liang', 'NNP'), (',', ','), ('C.', 'NNP'), ('Shen', 'NNP'), (',', ','), ('F.', 'NNP'), ('Wu', 'NNP'), (',', ','), ('“', 'NNP'), ('An', 'DT'), ('iterative', 'JJ'), ('bp-cnn', 'JJ'), ('architecture', 'NN'), ('channel', 'NN'), ('decoding', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Journal', 'NNP'), ('Selected', 'NNP'), ('Topics', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  40/CD
  (NP ]/JJ F./NNP Liang/NNP)
  ,/,
  (NP C./NNP Shen/NNP)
  ,/,
  (NP F./NNP Wu/NNP)
  ,/,
  (NP “/NNP)
  (NP
    An/DT
    iterative/JJ
    bp-cnn/JJ
    architecture/NN
    channel/NN
    decoding/NN)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Journal/NNP
    Selected/NNP
    Topics/NNP
    Signal/NNP
    Processing/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] F. Liang', 'C. Shen', 'F. Wu', '“', 'An iterative bp-cnn architecture channel decoding', '” IEEE Journal Selected Topics Signal Processing', 'vol']

>> Named Entities are: 
 [('PERSON', 'Liang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('40', '40'), (']', ']'), ('F.', 'f.'), ('Liang', 'liang'), (',', ','), ('C.', 'c.'), ('Shen', 'shen'), (',', ','), ('F.', 'f.'), ('Wu', 'wu'), (',', ','), ('“', '“'), ('An', 'an'), ('iterative', 'iter'), ('bp-cnn', 'bp-cnn'), ('architecture', 'architectur'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Selected', 'select'), ('Topics', 'topic'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('40', '40'), (']', ']'), ('F.', 'f.'), ('Liang', 'liang'), (',', ','), ('C.', 'c.'), ('Shen', 'shen'), (',', ','), ('F.', 'f.'), ('Wu', 'wu'), (',', ','), ('“', '“'), ('An', 'an'), ('iterative', 'iter'), ('bp-cnn', 'bp-cnn'), ('architecture', 'architectur'), ('channel', 'channel'), ('decoding', 'decod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Selected', 'select'), ('Topics', 'topic'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('40', '40'), (']', ']'), ('F.', 'F.'), ('Liang', 'Liang'), (',', ','), ('C.', 'C.'), ('Shen', 'Shen'), (',', ','), ('F.', 'F.'), ('Wu', 'Wu'), (',', ','), ('“', '“'), ('An', 'An'), ('iterative', 'iterative'), ('bp-cnn', 'bp-cnn'), ('architecture', 'architecture'), ('channel', 'channel'), ('decoding', 'decoding'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Journal', 'Journal'), ('Selected', 'Selected'), ('Topics', 'Topics'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 679 =============================

12, no. 


>> Tokens are: 
 ['12', ',', '.']

>> Bigrams are: 
 [('12', ','), (',', '.')]

>> Trigrams are: 
 [('12', ',', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('.', '.')]

 (S 12/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('.', '.')]



============================ Sentence 680 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 681 =============================

144–159, Feb 2018. 


>> Tokens are: 
 ['144–159', ',', 'Feb', '2018', '.']

>> Bigrams are: 
 [('144–159', ','), (',', 'Feb'), ('Feb', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('144–159', ',', 'Feb'), (',', 'Feb', '2018'), ('Feb', '2018', '.')]

>> POS Tags are: 
 [('144–159', 'CD'), (',', ','), ('Feb', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S 144–159/CD ,/, (NP Feb/NNP) 2018/CD ./.) 


>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('144–159', '144–159'), (',', ','), ('Feb', 'feb'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('144–159', '144–159'), (',', ','), ('Feb', 'feb'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('144–159', '144–159'), (',', ','), ('Feb', 'Feb'), ('2018', '2018'), ('.', '.')]



============================ Sentence 682 =============================

[41] H. Agirman-Tosun, Y. Liu, A. M. Haimovich, O. Simeone, W. Su, J. Dabin, and E. Kanterakis, “Modulation classification of mimo-ofdm signals by independent component analysis and support vector machines,” in Proc. 


>> Tokens are: 
 ['[', '41', ']', 'H.', 'Agirman-Tosun', ',', 'Y.', 'Liu', ',', 'A.', 'M.', 'Haimovich', ',', 'O.', 'Simeone', ',', 'W.', 'Su', ',', 'J.', 'Dabin', ',', 'E.', 'Kanterakis', ',', '“', 'Modulation', 'classification', 'mimo-ofdm', 'signals', 'independent', 'component', 'analysis', 'support', 'vector', 'machines', ',', '”', 'Proc', '.']

>> Bigrams are: 
 [('[', '41'), ('41', ']'), (']', 'H.'), ('H.', 'Agirman-Tosun'), ('Agirman-Tosun', ','), (',', 'Y.'), ('Y.', 'Liu'), ('Liu', ','), (',', 'A.'), ('A.', 'M.'), ('M.', 'Haimovich'), ('Haimovich', ','), (',', 'O.'), ('O.', 'Simeone'), ('Simeone', ','), (',', 'W.'), ('W.', 'Su'), ('Su', ','), (',', 'J.'), ('J.', 'Dabin'), ('Dabin', ','), (',', 'E.'), ('E.', 'Kanterakis'), ('Kanterakis', ','), (',', '“'), ('“', 'Modulation'), ('Modulation', 'classification'), ('classification', 'mimo-ofdm'), ('mimo-ofdm', 'signals'), ('signals', 'independent'), ('independent', 'component'), ('component', 'analysis'), ('analysis', 'support'), ('support', 'vector'), ('vector', 'machines'), ('machines', ','), (',', '”'), ('”', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('[', '41', ']'), ('41', ']', 'H.'), (']', 'H.', 'Agirman-Tosun'), ('H.', 'Agirman-Tosun', ','), ('Agirman-Tosun', ',', 'Y.'), (',', 'Y.', 'Liu'), ('Y.', 'Liu', ','), ('Liu', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', 'Haimovich'), ('M.', 'Haimovich', ','), ('Haimovich', ',', 'O.'), (',', 'O.', 'Simeone'), ('O.', 'Simeone', ','), ('Simeone', ',', 'W.'), (',', 'W.', 'Su'), ('W.', 'Su', ','), ('Su', ',', 'J.'), (',', 'J.', 'Dabin'), ('J.', 'Dabin', ','), ('Dabin', ',', 'E.'), (',', 'E.', 'Kanterakis'), ('E.', 'Kanterakis', ','), ('Kanterakis', ',', '“'), (',', '“', 'Modulation'), ('“', 'Modulation', 'classification'), ('Modulation', 'classification', 'mimo-ofdm'), ('classification', 'mimo-ofdm', 'signals'), ('mimo-ofdm', 'signals', 'independent'), ('signals', 'independent', 'component'), ('independent', 'component', 'analysis'), ('component', 'analysis', 'support'), ('analysis', 'support', 'vector'), ('support', 'vector', 'machines'), ('vector', 'machines', ','), ('machines', ',', '”'), (',', '”', 'Proc'), ('”', 'Proc', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('41', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('Agirman-Tosun', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), ('Haimovich', 'NNP'), (',', ','), ('O.', 'NNP'), ('Simeone', 'NNP'), (',', ','), ('W.', 'NNP'), ('Su', 'NNP'), (',', ','), ('J.', 'NNP'), ('Dabin', 'NNP'), (',', ','), ('E.', 'NNP'), ('Kanterakis', 'NNP'), (',', ','), ('“', 'NNP'), ('Modulation', 'NNP'), ('classification', 'NN'), ('mimo-ofdm', 'NN'), ('signals', 'NNS'), ('independent', 'JJ'), ('component', 'NN'), ('analysis', 'NN'), ('support', 'NN'), ('vector', 'NN'), ('machines', 'NNS'), (',', ','), ('”', 'NNP'), ('Proc', 'NNP'), ('.', '.')]

 (S
  [/RB
  41/CD
  (NP ]/JJ H./NNP Agirman-Tosun/NNP)
  ,/,
  (NP Y./NNP Liu/NNP)
  ,/,
  (NP A./NNP M./NNP Haimovich/NNP)
  ,/,
  (NP O./NNP Simeone/NNP)
  ,/,
  (NP W./NNP Su/NNP)
  ,/,
  (NP J./NNP Dabin/NNP)
  ,/,
  (NP E./NNP Kanterakis/NNP)
  ,/,
  (NP
    “/NNP
    Modulation/NNP
    classification/NN
    mimo-ofdm/NN
    signals/NNS)
  (NP
    independent/JJ
    component/NN
    analysis/NN
    support/NN
    vector/NN
    machines/NNS)
  ,/,
  (NP ”/NNP Proc/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] H. Agirman-Tosun', 'Y. Liu', 'A. M. Haimovich', 'O. Simeone', 'W. Su', 'J. Dabin', 'E. Kanterakis', '“ Modulation classification mimo-ofdm signals', 'independent component analysis support vector machines', '” Proc']

>> Named Entities are: 
 [('PERSON', 'Haimovich'), ('PERSON', 'J. Dabin')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('41', '41'), (']', ']'), ('H.', 'h.'), ('Agirman-Tosun', 'agirman-tosun'), (',', ','), ('Y.', 'y.'), ('Liu', 'liu'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), ('Haimovich', 'haimovich'), (',', ','), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('W.', 'w.'), ('Su', 'su'), (',', ','), ('J.', 'j.'), ('Dabin', 'dabin'), (',', ','), ('E.', 'e.'), ('Kanterakis', 'kanteraki'), (',', ','), ('“', '“'), ('Modulation', 'modul'), ('classification', 'classif'), ('mimo-ofdm', 'mimo-ofdm'), ('signals', 'signal'), ('independent', 'independ'), ('component', 'compon'), ('analysis', 'analysi'), ('support', 'support'), ('vector', 'vector'), ('machines', 'machin'), (',', ','), ('”', '”'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('41', '41'), (']', ']'), ('H.', 'h.'), ('Agirman-Tosun', 'agirman-tosun'), (',', ','), ('Y.', 'y.'), ('Liu', 'liu'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), ('Haimovich', 'haimovich'), (',', ','), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('W.', 'w.'), ('Su', 'su'), (',', ','), ('J.', 'j.'), ('Dabin', 'dabin'), (',', ','), ('E.', 'e.'), ('Kanterakis', 'kanteraki'), (',', ','), ('“', '“'), ('Modulation', 'modul'), ('classification', 'classif'), ('mimo-ofdm', 'mimo-ofdm'), ('signals', 'signal'), ('independent', 'independ'), ('component', 'compon'), ('analysis', 'analysi'), ('support', 'support'), ('vector', 'vector'), ('machines', 'machin'), (',', ','), ('”', '”'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('41', '41'), (']', ']'), ('H.', 'H.'), ('Agirman-Tosun', 'Agirman-Tosun'), (',', ','), ('Y.', 'Y.'), ('Liu', 'Liu'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), ('Haimovich', 'Haimovich'), (',', ','), ('O.', 'O.'), ('Simeone', 'Simeone'), (',', ','), ('W.', 'W.'), ('Su', 'Su'), (',', ','), ('J.', 'J.'), ('Dabin', 'Dabin'), (',', ','), ('E.', 'E.'), ('Kanterakis', 'Kanterakis'), (',', ','), ('“', '“'), ('Modulation', 'Modulation'), ('classification', 'classification'), ('mimo-ofdm', 'mimo-ofdm'), ('signals', 'signal'), ('independent', 'independent'), ('component', 'component'), ('analysis', 'analysis'), ('support', 'support'), ('vector', 'vector'), ('machines', 'machine'), (',', ','), ('”', '”'), ('Proc', 'Proc'), ('.', '.')]



============================ Sentence 683 =============================

ASILOMAR 2011, 2011, pp. 


>> Tokens are: 
 ['ASILOMAR', '2011', ',', '2011', ',', 'pp', '.']

>> Bigrams are: 
 [('ASILOMAR', '2011'), ('2011', ','), (',', '2011'), ('2011', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('ASILOMAR', '2011', ','), ('2011', ',', '2011'), (',', '2011', ','), ('2011', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('ASILOMAR', 'NNP'), ('2011', 'CD'), (',', ','), ('2011', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP ASILOMAR/NNP) 2011/CD ,/, 2011/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['ASILOMAR', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ASILOMAR', 'asilomar'), ('2011', '2011'), (',', ','), ('2011', '2011'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ASILOMAR', 'asilomar'), ('2011', '2011'), (',', ','), ('2011', '2011'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('ASILOMAR', 'ASILOMAR'), ('2011', '2011'), (',', ','), ('2011', '2011'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 684 =============================

1903–1907. 


>> Tokens are: 
 ['1903–1907', '.']

>> Bigrams are: 
 [('1903–1907', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1903–1907', 'CD'), ('.', '.')]

 (S 1903–1907/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1903–1907', '1903–1907'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1903–1907', '1903–1907'), ('.', '.')]

>> Lemmatization: 
 [('1903–1907', '1903–1907'), ('.', '.')]



============================ Sentence 685 =============================

[42] S.-H. Fang and T.-N. Lin, “Indoor location system based on discriminant-adaptive neural network in ieee 802.11 environ- ments,” IEEE Transactions on Neural networks, vol. 


>> Tokens are: 
 ['[', '42', ']', 'S.-H.', 'Fang', 'T.-N.', 'Lin', ',', '“', 'Indoor', 'location', 'system', 'based', 'discriminant-adaptive', 'neural', 'network', 'ieee', '802.11', 'environ-', 'ments', ',', '”', 'IEEE', 'Transactions', 'Neural', 'networks', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '42'), ('42', ']'), (']', 'S.-H.'), ('S.-H.', 'Fang'), ('Fang', 'T.-N.'), ('T.-N.', 'Lin'), ('Lin', ','), (',', '“'), ('“', 'Indoor'), ('Indoor', 'location'), ('location', 'system'), ('system', 'based'), ('based', 'discriminant-adaptive'), ('discriminant-adaptive', 'neural'), ('neural', 'network'), ('network', 'ieee'), ('ieee', '802.11'), ('802.11', 'environ-'), ('environ-', 'ments'), ('ments', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Neural'), ('Neural', 'networks'), ('networks', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '42', ']'), ('42', ']', 'S.-H.'), (']', 'S.-H.', 'Fang'), ('S.-H.', 'Fang', 'T.-N.'), ('Fang', 'T.-N.', 'Lin'), ('T.-N.', 'Lin', ','), ('Lin', ',', '“'), (',', '“', 'Indoor'), ('“', 'Indoor', 'location'), ('Indoor', 'location', 'system'), ('location', 'system', 'based'), ('system', 'based', 'discriminant-adaptive'), ('based', 'discriminant-adaptive', 'neural'), ('discriminant-adaptive', 'neural', 'network'), ('neural', 'network', 'ieee'), ('network', 'ieee', '802.11'), ('ieee', '802.11', 'environ-'), ('802.11', 'environ-', 'ments'), ('environ-', 'ments', ','), ('ments', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Neural'), ('Transactions', 'Neural', 'networks'), ('Neural', 'networks', ','), ('networks', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('42', 'CD'), (']', 'JJ'), ('S.-H.', 'NNP'), ('Fang', 'NNP'), ('T.-N.', 'NNP'), ('Lin', 'NNP'), (',', ','), ('“', 'NNP'), ('Indoor', 'NNP'), ('location', 'NN'), ('system', 'NN'), ('based', 'VBN'), ('discriminant-adaptive', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('ieee', 'JJ'), ('802.11', 'CD'), ('environ-', 'JJ'), ('ments', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Neural', 'NNP'), ('networks', 'NNS'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  42/CD
  (NP ]/JJ S.-H./NNP Fang/NNP T.-N./NNP Lin/NNP)
  ,/,
  (NP “/NNP Indoor/NNP location/NN system/NN)
  based/VBN
  (NP discriminant-adaptive/JJ neural/JJ network/NN)
  ieee/JJ
  802.11/CD
  (NP environ-/JJ ments/NNS)
  ,/,
  (NP ”/NNP IEEE/NNP Transactions/NNP Neural/NNP networks/NNS)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] S.-H. Fang T.-N. Lin', '“ Indoor location system', 'discriminant-adaptive neural network', 'environ- ments', '” IEEE Transactions Neural networks', 'vol']

>> Named Entities are: 
 [('PERSON', 'Fang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('42', '42'), (']', ']'), ('S.-H.', 's.-h.'), ('Fang', 'fang'), ('T.-N.', 't.-n.'), ('Lin', 'lin'), (',', ','), ('“', '“'), ('Indoor', 'indoor'), ('location', 'locat'), ('system', 'system'), ('based', 'base'), ('discriminant-adaptive', 'discriminant-adapt'), ('neural', 'neural'), ('network', 'network'), ('ieee', 'ieee'), ('802.11', '802.11'), ('environ-', 'environ-'), ('ments', 'ment'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Neural', 'neural'), ('networks', 'network'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('42', '42'), (']', ']'), ('S.-H.', 's.-h.'), ('Fang', 'fang'), ('T.-N.', 't.-n.'), ('Lin', 'lin'), (',', ','), ('“', '“'), ('Indoor', 'indoor'), ('location', 'locat'), ('system', 'system'), ('based', 'base'), ('discriminant-adaptive', 'discriminant-adapt'), ('neural', 'neural'), ('network', 'network'), ('ieee', 'ieee'), ('802.11', '802.11'), ('environ-', 'environ-'), ('ments', 'ment'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Neural', 'neural'), ('networks', 'network'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('42', '42'), (']', ']'), ('S.-H.', 'S.-H.'), ('Fang', 'Fang'), ('T.-N.', 'T.-N.'), ('Lin', 'Lin'), (',', ','), ('“', '“'), ('Indoor', 'Indoor'), ('location', 'location'), ('system', 'system'), ('based', 'based'), ('discriminant-adaptive', 'discriminant-adaptive'), ('neural', 'neural'), ('network', 'network'), ('ieee', 'ieee'), ('802.11', '802.11'), ('environ-', 'environ-'), ('ments', 'ments'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Neural', 'Neural'), ('networks', 'network'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 686 =============================

19, no. 


>> Tokens are: 
 ['19', ',', '.']

>> Bigrams are: 
 [('19', ','), (',', '.')]

>> Trigrams are: 
 [('19', ',', '.')]

>> POS Tags are: 
 [('19', 'CD'), (',', ','), ('.', '.')]

 (S 19/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), (',', ','), ('.', '.')]



============================ Sentence 687 =============================

11, pp. 


>> Tokens are: 
 ['11', ',', 'pp', '.']

>> Bigrams are: 
 [('11', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('11', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('11', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 11/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 688 =============================

1973–1978, 2008. 


>> Tokens are: 
 ['1973–1978', ',', '2008', '.']

>> Bigrams are: 
 [('1973–1978', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('1973–1978', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('1973–1978', 'CD'), (',', ','), ('2008', 'CD'), ('.', '.')]

 (S 1973–1978/CD ,/, 2008/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1973–1978', '1973–1978'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1973–1978', '1973–1978'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('1973–1978', '1973–1978'), (',', ','), ('2008', '2008'), ('.', '.')]



============================ Sentence 689 =============================

[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su- pervised and Semi-Supervised Deep Neural Networks for CSI- Based Authentication,” ArXiv e-prints, Jul. 


>> Tokens are: 
 ['[', '43', ']', 'Q.', 'Wang', ',', 'H.', 'Li', ',', 'Z.', 'Chen', ',', 'D.', 'Zhao', ',', 'S.', 'Ye', ',', 'J.', 'Cai', ',', '“', 'Su-', 'pervised', 'Semi-Supervised', 'Deep', 'Neural', 'Networks', 'CSI-', 'Based', 'Authentication', ',', '”', 'ArXiv', 'e-prints', ',', 'Jul', '.']

>> Bigrams are: 
 [('[', '43'), ('43', ']'), (']', 'Q.'), ('Q.', 'Wang'), ('Wang', ','), (',', 'H.'), ('H.', 'Li'), ('Li', ','), (',', 'Z.'), ('Z.', 'Chen'), ('Chen', ','), (',', 'D.'), ('D.', 'Zhao'), ('Zhao', ','), (',', 'S.'), ('S.', 'Ye'), ('Ye', ','), (',', 'J.'), ('J.', 'Cai'), ('Cai', ','), (',', '“'), ('“', 'Su-'), ('Su-', 'pervised'), ('pervised', 'Semi-Supervised'), ('Semi-Supervised', 'Deep'), ('Deep', 'Neural'), ('Neural', 'Networks'), ('Networks', 'CSI-'), ('CSI-', 'Based'), ('Based', 'Authentication'), ('Authentication', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jul'), ('Jul', '.')]

>> Trigrams are: 
 [('[', '43', ']'), ('43', ']', 'Q.'), (']', 'Q.', 'Wang'), ('Q.', 'Wang', ','), ('Wang', ',', 'H.'), (',', 'H.', 'Li'), ('H.', 'Li', ','), ('Li', ',', 'Z.'), (',', 'Z.', 'Chen'), ('Z.', 'Chen', ','), ('Chen', ',', 'D.'), (',', 'D.', 'Zhao'), ('D.', 'Zhao', ','), ('Zhao', ',', 'S.'), (',', 'S.', 'Ye'), ('S.', 'Ye', ','), ('Ye', ',', 'J.'), (',', 'J.', 'Cai'), ('J.', 'Cai', ','), ('Cai', ',', '“'), (',', '“', 'Su-'), ('“', 'Su-', 'pervised'), ('Su-', 'pervised', 'Semi-Supervised'), ('pervised', 'Semi-Supervised', 'Deep'), ('Semi-Supervised', 'Deep', 'Neural'), ('Deep', 'Neural', 'Networks'), ('Neural', 'Networks', 'CSI-'), ('Networks', 'CSI-', 'Based'), ('CSI-', 'Based', 'Authentication'), ('Based', 'Authentication', ','), ('Authentication', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jul'), (',', 'Jul', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('43', 'CD'), (']', 'JJ'), ('Q.', 'NNP'), ('Wang', 'NNP'), (',', ','), ('H.', 'NNP'), ('Li', 'NNP'), (',', ','), ('Z.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('D.', 'NNP'), ('Zhao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Ye', 'NNP'), (',', ','), ('J.', 'NNP'), ('Cai', 'NNP'), (',', ','), ('“', 'NNP'), ('Su-', 'NNP'), ('pervised', 'VBD'), ('Semi-Supervised', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('CSI-', 'NNP'), ('Based', 'VBD'), ('Authentication', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jul', 'NNP'), ('.', '.')]

 (S
  [/RB
  43/CD
  (NP ]/JJ Q./NNP Wang/NNP)
  ,/,
  (NP H./NNP Li/NNP)
  ,/,
  (NP Z./NNP Chen/NNP)
  ,/,
  (NP D./NNP Zhao/NNP)
  ,/,
  (NP S./NNP Ye/NNP)
  ,/,
  (NP J./NNP Cai/NNP)
  ,/,
  (NP “/NNP Su-/NNP)
  pervised/VBD
  (NP Semi-Supervised/JJ Deep/NNP Neural/NNP Networks/NNP CSI-/NNP)
  Based/VBD
  (NP Authentication/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jul/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] Q. Wang', 'H. Li', 'Z. Chen', 'D. Zhao', 'S. Ye', 'J. Cai', '“ Su-', 'Semi-Supervised Deep Neural Networks CSI-', 'Authentication', '” ArXiv e-prints', 'Jul']

>> Named Entities are: 
 [('PERSON', 'Zhao'), ('PERSON', 'J. Cai'), ('PERSON', 'Networks'), ('PERSON', 'Authentication'), ('PERSON', 'Jul')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('43', '43'), (']', ']'), ('Q.', 'q.'), ('Wang', 'wang'), (',', ','), ('H.', 'h.'), ('Li', 'li'), (',', ','), ('Z.', 'z.'), ('Chen', 'chen'), (',', ','), ('D.', 'd.'), ('Zhao', 'zhao'), (',', ','), ('S.', 's.'), ('Ye', 'ye'), (',', ','), ('J.', 'j.'), ('Cai', 'cai'), (',', ','), ('“', '“'), ('Su-', 'su-'), ('pervised', 'pervis'), ('Semi-Supervised', 'semi-supervis'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), ('CSI-', 'csi-'), ('Based', 'base'), ('Authentication', 'authent'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('43', '43'), (']', ']'), ('Q.', 'q.'), ('Wang', 'wang'), (',', ','), ('H.', 'h.'), ('Li', 'li'), (',', ','), ('Z.', 'z.'), ('Chen', 'chen'), (',', ','), ('D.', 'd.'), ('Zhao', 'zhao'), (',', ','), ('S.', 's.'), ('Ye', 'ye'), (',', ','), ('J.', 'j.'), ('Cai', 'cai'), (',', ','), ('“', '“'), ('Su-', 'su-'), ('pervised', 'pervis'), ('Semi-Supervised', 'semi-supervis'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), ('CSI-', 'csi-'), ('Based', 'base'), ('Authentication', 'authent'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('43', '43'), (']', ']'), ('Q.', 'Q.'), ('Wang', 'Wang'), (',', ','), ('H.', 'H.'), ('Li', 'Li'), (',', ','), ('Z.', 'Z.'), ('Chen', 'Chen'), (',', ','), ('D.', 'D.'), ('Zhao', 'Zhao'), (',', ','), ('S.', 'S.'), ('Ye', 'Ye'), (',', ','), ('J.', 'J.'), ('Cai', 'Cai'), (',', ','), ('“', '“'), ('Su-', 'Su-'), ('pervised', 'pervised'), ('Semi-Supervised', 'Semi-Supervised'), ('Deep', 'Deep'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('CSI-', 'CSI-'), ('Based', 'Based'), ('Authentication', 'Authentication'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jul', 'Jul'), ('.', '.')]



============================ Sentence 690 =============================

2018. 


>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

 (S 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]



============================ Sentence 691 =============================

[44] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropou- los, “Learning to optimize: Training deep neural networks for wireless resource management,” in IEEE Signal Processing Advances in Wireless Communications (SPAWC) 2017, 2017, pp. 


>> Tokens are: 
 ['[', '44', ']', 'H.', 'Sun', ',', 'X.', 'Chen', ',', 'Q.', 'Shi', ',', 'M.', 'Hong', ',', 'X.', 'Fu', ',', 'N.', 'D.', 'Sidiropou-', 'los', ',', '“', 'Learning', 'optimize', ':', 'Training', 'deep', 'neural', 'networks', 'wireless', 'resource', 'management', ',', '”', 'IEEE', 'Signal', 'Processing', 'Advances', 'Wireless', 'Communications', '(', 'SPAWC', ')', '2017', ',', '2017', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '44'), ('44', ']'), (']', 'H.'), ('H.', 'Sun'), ('Sun', ','), (',', 'X.'), ('X.', 'Chen'), ('Chen', ','), (',', 'Q.'), ('Q.', 'Shi'), ('Shi', ','), (',', 'M.'), ('M.', 'Hong'), ('Hong', ','), (',', 'X.'), ('X.', 'Fu'), ('Fu', ','), (',', 'N.'), ('N.', 'D.'), ('D.', 'Sidiropou-'), ('Sidiropou-', 'los'), ('los', ','), (',', '“'), ('“', 'Learning'), ('Learning', 'optimize'), ('optimize', ':'), (':', 'Training'), ('Training', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'wireless'), ('wireless', 'resource'), ('resource', 'management'), ('management', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Signal'), ('Signal', 'Processing'), ('Processing', 'Advances'), ('Advances', 'Wireless'), ('Wireless', 'Communications'), ('Communications', '('), ('(', 'SPAWC'), ('SPAWC', ')'), (')', '2017'), ('2017', ','), (',', '2017'), ('2017', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '44', ']'), ('44', ']', 'H.'), (']', 'H.', 'Sun'), ('H.', 'Sun', ','), ('Sun', ',', 'X.'), (',', 'X.', 'Chen'), ('X.', 'Chen', ','), ('Chen', ',', 'Q.'), (',', 'Q.', 'Shi'), ('Q.', 'Shi', ','), ('Shi', ',', 'M.'), (',', 'M.', 'Hong'), ('M.', 'Hong', ','), ('Hong', ',', 'X.'), (',', 'X.', 'Fu'), ('X.', 'Fu', ','), ('Fu', ',', 'N.'), (',', 'N.', 'D.'), ('N.', 'D.', 'Sidiropou-'), ('D.', 'Sidiropou-', 'los'), ('Sidiropou-', 'los', ','), ('los', ',', '“'), (',', '“', 'Learning'), ('“', 'Learning', 'optimize'), ('Learning', 'optimize', ':'), ('optimize', ':', 'Training'), (':', 'Training', 'deep'), ('Training', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'wireless'), ('networks', 'wireless', 'resource'), ('wireless', 'resource', 'management'), ('resource', 'management', ','), ('management', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Signal'), ('IEEE', 'Signal', 'Processing'), ('Signal', 'Processing', 'Advances'), ('Processing', 'Advances', 'Wireless'), ('Advances', 'Wireless', 'Communications'), ('Wireless', 'Communications', '('), ('Communications', '(', 'SPAWC'), ('(', 'SPAWC', ')'), ('SPAWC', ')', '2017'), (')', '2017', ','), ('2017', ',', '2017'), (',', '2017', ','), ('2017', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('44', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('Sun', 'NNP'), (',', ','), ('X.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('Q.', 'NNP'), ('Shi', 'NNP'), (',', ','), ('M.', 'NNP'), ('Hong', 'NNP'), (',', ','), ('X.', 'NNP'), ('Fu', 'NNP'), (',', ','), ('N.', 'NNP'), ('D.', 'NNP'), ('Sidiropou-', 'NNP'), ('los', 'NN'), (',', ','), ('“', 'NNP'), ('Learning', 'NNP'), ('optimize', 'NN'), (':', ':'), ('Training', 'NN'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('wireless', 'VBP'), ('resource', 'JJ'), ('management', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('Advances', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), ('(', '('), ('SPAWC', 'NNP'), (')', ')'), ('2017', 'CD'), (',', ','), ('2017', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  44/CD
  (NP ]/JJ H./NNP Sun/NNP)
  ,/,
  (NP X./NNP Chen/NNP)
  ,/,
  (NP Q./NNP Shi/NNP)
  ,/,
  (NP M./NNP Hong/NNP)
  ,/,
  (NP X./NNP Fu/NNP)
  ,/,
  (NP N./NNP D./NNP Sidiropou-/NNP los/NN)
  ,/,
  (NP “/NNP Learning/NNP optimize/NN)
  :/:
  (NP Training/NN)
  (NP deep/JJ neural/JJ networks/NNS)
  wireless/VBP
  (NP resource/JJ management/NN)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Signal/NNP
    Processing/NNP
    Advances/NNP
    Wireless/NNP
    Communications/NNP)
  (/(
  (NP SPAWC/NNP)
  )/)
  2017/CD
  ,/,
  2017/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] H. Sun', 'X. Chen', 'Q. Shi', 'M. Hong', 'X. Fu', 'N. D. Sidiropou- los', '“ Learning optimize', 'Training', 'deep neural networks', 'resource management', '” IEEE Signal Processing Advances Wireless Communications', 'SPAWC', 'pp']

>> Named Entities are: 
 [('GPE', 'Hong'), ('ORGANIZATION', 'Wireless Communications'), ('ORGANIZATION', 'SPAWC')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('44', '44'), (']', ']'), ('H.', 'h.'), ('Sun', 'sun'), (',', ','), ('X.', 'x.'), ('Chen', 'chen'), (',', ','), ('Q.', 'q.'), ('Shi', 'shi'), (',', ','), ('M.', 'm.'), ('Hong', 'hong'), (',', ','), ('X.', 'x.'), ('Fu', 'fu'), (',', ','), ('N.', 'n.'), ('D.', 'd.'), ('Sidiropou-', 'sidiropou-'), ('los', 'lo'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('optimize', 'optim'), (':', ':'), ('Training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('wireless', 'wireless'), ('resource', 'resourc'), ('management', 'manag'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Advances', 'advanc'), ('Wireless', 'wireless'), ('Communications', 'commun'), ('(', '('), ('SPAWC', 'spawc'), (')', ')'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('44', '44'), (']', ']'), ('H.', 'h.'), ('Sun', 'sun'), (',', ','), ('X.', 'x.'), ('Chen', 'chen'), (',', ','), ('Q.', 'q.'), ('Shi', 'shi'), (',', ','), ('M.', 'm.'), ('Hong', 'hong'), (',', ','), ('X.', 'x.'), ('Fu', 'fu'), (',', ','), ('N.', 'n.'), ('D.', 'd.'), ('Sidiropou-', 'sidiropou-'), ('los', 'los'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('optimize', 'optim'), (':', ':'), ('Training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('wireless', 'wireless'), ('resource', 'resourc'), ('management', 'manag'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Advances', 'advanc'), ('Wireless', 'wireless'), ('Communications', 'communic'), ('(', '('), ('SPAWC', 'spawc'), (')', ')'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('44', '44'), (']', ']'), ('H.', 'H.'), ('Sun', 'Sun'), (',', ','), ('X.', 'X.'), ('Chen', 'Chen'), (',', ','), ('Q.', 'Q.'), ('Shi', 'Shi'), (',', ','), ('M.', 'M.'), ('Hong', 'Hong'), (',', ','), ('X.', 'X.'), ('Fu', 'Fu'), (',', ','), ('N.', 'N.'), ('D.', 'D.'), ('Sidiropou-', 'Sidiropou-'), ('los', 'los'), (',', ','), ('“', '“'), ('Learning', 'Learning'), ('optimize', 'optimize'), (':', ':'), ('Training', 'Training'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('wireless', 'wireless'), ('resource', 'resource'), ('management', 'management'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('Advances', 'Advances'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), ('(', '('), ('SPAWC', 'SPAWC'), (')', ')'), ('2017', '2017'), (',', ','), ('2017', '2017'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 692 =============================

1–6. 


>> Tokens are: 
 ['1–6', '.']

>> Bigrams are: 
 [('1–6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–6', 'CD'), ('.', '.')]

 (S 1–6/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–6', '1–6'), ('.', '.')]

>> Lemmatization: 
 [('1–6', '1–6'), ('.', '.')]



============================ Sentence 693 =============================

[45] A. Zappone, M. Di Renzo, M. Debbah, T. T. Lam, and X. Qian, “Model-Aided Wireless Artificial Intelligence: Embedding Ex- pert Knowledge in Deep Neural Networks Towards Wireless Systems Optimization,” ArXiv e-prints, Aug. 2018. 


>> Tokens are: 
 ['[', '45', ']', 'A.', 'Zappone', ',', 'M.', 'Di', 'Renzo', ',', 'M.', 'Debbah', ',', 'T.', 'T.', 'Lam', ',', 'X.', 'Qian', ',', '“', 'Model-Aided', 'Wireless', 'Artificial', 'Intelligence', ':', 'Embedding', 'Ex-', 'pert', 'Knowledge', 'Deep', 'Neural', 'Networks', 'Towards', 'Wireless', 'Systems', 'Optimization', ',', '”', 'ArXiv', 'e-prints', ',', 'Aug.', '2018', '.']

>> Bigrams are: 
 [('[', '45'), ('45', ']'), (']', 'A.'), ('A.', 'Zappone'), ('Zappone', ','), (',', 'M.'), ('M.', 'Di'), ('Di', 'Renzo'), ('Renzo', ','), (',', 'M.'), ('M.', 'Debbah'), ('Debbah', ','), (',', 'T.'), ('T.', 'T.'), ('T.', 'Lam'), ('Lam', ','), (',', 'X.'), ('X.', 'Qian'), ('Qian', ','), (',', '“'), ('“', 'Model-Aided'), ('Model-Aided', 'Wireless'), ('Wireless', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', ':'), (':', 'Embedding'), ('Embedding', 'Ex-'), ('Ex-', 'pert'), ('pert', 'Knowledge'), ('Knowledge', 'Deep'), ('Deep', 'Neural'), ('Neural', 'Networks'), ('Networks', 'Towards'), ('Towards', 'Wireless'), ('Wireless', 'Systems'), ('Systems', 'Optimization'), ('Optimization', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Aug.'), ('Aug.', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '45', ']'), ('45', ']', 'A.'), (']', 'A.', 'Zappone'), ('A.', 'Zappone', ','), ('Zappone', ',', 'M.'), (',', 'M.', 'Di'), ('M.', 'Di', 'Renzo'), ('Di', 'Renzo', ','), ('Renzo', ',', 'M.'), (',', 'M.', 'Debbah'), ('M.', 'Debbah', ','), ('Debbah', ',', 'T.'), (',', 'T.', 'T.'), ('T.', 'T.', 'Lam'), ('T.', 'Lam', ','), ('Lam', ',', 'X.'), (',', 'X.', 'Qian'), ('X.', 'Qian', ','), ('Qian', ',', '“'), (',', '“', 'Model-Aided'), ('“', 'Model-Aided', 'Wireless'), ('Model-Aided', 'Wireless', 'Artificial'), ('Wireless', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', ':'), ('Intelligence', ':', 'Embedding'), (':', 'Embedding', 'Ex-'), ('Embedding', 'Ex-', 'pert'), ('Ex-', 'pert', 'Knowledge'), ('pert', 'Knowledge', 'Deep'), ('Knowledge', 'Deep', 'Neural'), ('Deep', 'Neural', 'Networks'), ('Neural', 'Networks', 'Towards'), ('Networks', 'Towards', 'Wireless'), ('Towards', 'Wireless', 'Systems'), ('Wireless', 'Systems', 'Optimization'), ('Systems', 'Optimization', ','), ('Optimization', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Aug.'), (',', 'Aug.', '2018'), ('Aug.', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('45', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('Zappone', 'NNP'), (',', ','), ('M.', 'NNP'), ('Di', 'NNP'), ('Renzo', 'NNP'), (',', ','), ('M.', 'NNP'), ('Debbah', 'NNP'), (',', ','), ('T.', 'NNP'), ('T.', 'NNP'), ('Lam', 'NNP'), (',', ','), ('X.', 'NNP'), ('Qian', 'NNP'), (',', ','), ('“', 'NNP'), ('Model-Aided', 'NNP'), ('Wireless', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), (':', ':'), ('Embedding', 'VBG'), ('Ex-', 'NNP'), ('pert', 'NN'), ('Knowledge', 'NNP'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('Towards', 'NNP'), ('Wireless', 'NNP'), ('Systems', 'NNPS'), ('Optimization', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Aug.', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  45/CD
  (NP ]/JJ A./NNP Zappone/NNP)
  ,/,
  (NP M./NNP Di/NNP Renzo/NNP)
  ,/,
  (NP M./NNP Debbah/NNP)
  ,/,
  (NP T./NNP T./NNP Lam/NNP)
  ,/,
  (NP X./NNP Qian/NNP)
  ,/,
  (NP
    “/NNP
    Model-Aided/NNP
    Wireless/NNP
    Artificial/NNP
    Intelligence/NNP)
  :/:
  Embedding/VBG
  (NP
    Ex-/NNP
    pert/NN
    Knowledge/NNP
    Deep/NNP
    Neural/NNP
    Networks/NNP
    Towards/NNP
    Wireless/NNP)
  Systems/NNPS
  (NP Optimization/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Aug./NNP)
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] A. Zappone', 'M. Di Renzo', 'M. Debbah', 'T. T. Lam', 'X. Qian', '“ Model-Aided Wireless Artificial Intelligence', 'Ex- pert Knowledge Deep Neural Networks Towards Wireless', 'Optimization', '” ArXiv e-prints', 'Aug.']

>> Named Entities are: 
 [('PERSON', 'Renzo'), ('GPE', 'Qian'), ('PERSON', 'Knowledge Deep Neural Networks Towards Wireless Systems Optimization')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('45', '45'), (']', ']'), ('A.', 'a.'), ('Zappone', 'zappon'), (',', ','), ('M.', 'm.'), ('Di', 'di'), ('Renzo', 'renzo'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('T.', 't.'), ('T.', 't.'), ('Lam', 'lam'), (',', ','), ('X.', 'x.'), ('Qian', 'qian'), (',', ','), ('“', '“'), ('Model-Aided', 'model-aid'), ('Wireless', 'wireless'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (':', ':'), ('Embedding', 'embed'), ('Ex-', 'ex-'), ('pert', 'pert'), ('Knowledge', 'knowledg'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), ('Towards', 'toward'), ('Wireless', 'wireless'), ('Systems', 'system'), ('Optimization', 'optim'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('45', '45'), (']', ']'), ('A.', 'a.'), ('Zappone', 'zappon'), (',', ','), ('M.', 'm.'), ('Di', 'di'), ('Renzo', 'renzo'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('T.', 't.'), ('T.', 't.'), ('Lam', 'lam'), (',', ','), ('X.', 'x.'), ('Qian', 'qian'), (',', ','), ('“', '“'), ('Model-Aided', 'model-aid'), ('Wireless', 'wireless'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (':', ':'), ('Embedding', 'embed'), ('Ex-', 'ex-'), ('pert', 'pert'), ('Knowledge', 'knowledg'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), ('Towards', 'toward'), ('Wireless', 'wireless'), ('Systems', 'system'), ('Optimization', 'optim'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('45', '45'), (']', ']'), ('A.', 'A.'), ('Zappone', 'Zappone'), (',', ','), ('M.', 'M.'), ('Di', 'Di'), ('Renzo', 'Renzo'), (',', ','), ('M.', 'M.'), ('Debbah', 'Debbah'), (',', ','), ('T.', 'T.'), ('T.', 'T.'), ('Lam', 'Lam'), (',', ','), ('X.', 'X.'), ('Qian', 'Qian'), (',', ','), ('“', '“'), ('Model-Aided', 'Model-Aided'), ('Wireless', 'Wireless'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), (':', ':'), ('Embedding', 'Embedding'), ('Ex-', 'Ex-'), ('pert', 'pert'), ('Knowledge', 'Knowledge'), ('Deep', 'Deep'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('Towards', 'Towards'), ('Wireless', 'Wireless'), ('Systems', 'Systems'), ('Optimization', 'Optimization'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Aug.', 'Aug.'), ('2018', '2018'), ('.', '.')]



============================ Sentence 694 =============================

[46] J. Shu, Z. Xu, and D. Meng, “Small Sample Learning in Big Data Era,” ArXiv e-prints, Aug. 2018. 


>> Tokens are: 
 ['[', '46', ']', 'J.', 'Shu', ',', 'Z.', 'Xu', ',', 'D.', 'Meng', ',', '“', 'Small', 'Sample', 'Learning', 'Big', 'Data', 'Era', ',', '”', 'ArXiv', 'e-prints', ',', 'Aug.', '2018', '.']

>> Bigrams are: 
 [('[', '46'), ('46', ']'), (']', 'J.'), ('J.', 'Shu'), ('Shu', ','), (',', 'Z.'), ('Z.', 'Xu'), ('Xu', ','), (',', 'D.'), ('D.', 'Meng'), ('Meng', ','), (',', '“'), ('“', 'Small'), ('Small', 'Sample'), ('Sample', 'Learning'), ('Learning', 'Big'), ('Big', 'Data'), ('Data', 'Era'), ('Era', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Aug.'), ('Aug.', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '46', ']'), ('46', ']', 'J.'), (']', 'J.', 'Shu'), ('J.', 'Shu', ','), ('Shu', ',', 'Z.'), (',', 'Z.', 'Xu'), ('Z.', 'Xu', ','), ('Xu', ',', 'D.'), (',', 'D.', 'Meng'), ('D.', 'Meng', ','), ('Meng', ',', '“'), (',', '“', 'Small'), ('“', 'Small', 'Sample'), ('Small', 'Sample', 'Learning'), ('Sample', 'Learning', 'Big'), ('Learning', 'Big', 'Data'), ('Big', 'Data', 'Era'), ('Data', 'Era', ','), ('Era', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Aug.'), (',', 'Aug.', '2018'), ('Aug.', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('46', 'CD'), (']', 'NNP'), ('J.', 'NNP'), ('Shu', 'NNP'), (',', ','), ('Z.', 'NNP'), ('Xu', 'NNP'), (',', ','), ('D.', 'NNP'), ('Meng', 'NNP'), (',', ','), ('“', 'NNP'), ('Small', 'NNP'), ('Sample', 'NNP'), ('Learning', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Era', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Aug.', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  46/CD
  (NP ]/NNP J./NNP Shu/NNP)
  ,/,
  (NP Z./NNP Xu/NNP)
  ,/,
  (NP D./NNP Meng/NNP)
  ,/,
  (NP
    “/NNP
    Small/NNP
    Sample/NNP
    Learning/NNP
    Big/NNP
    Data/NNP
    Era/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Aug./NNP)
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] J. Shu', 'Z. Xu', 'D. Meng', '“ Small Sample Learning Big Data Era', '” ArXiv e-prints', 'Aug.']

>> Named Entities are: 
 [('PERSON', 'Sample Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('46', '46'), (']', ']'), ('J.', 'j.'), ('Shu', 'shu'), (',', ','), ('Z.', 'z.'), ('Xu', 'xu'), (',', ','), ('D.', 'd.'), ('Meng', 'meng'), (',', ','), ('“', '“'), ('Small', 'small'), ('Sample', 'sampl'), ('Learning', 'learn'), ('Big', 'big'), ('Data', 'data'), ('Era', 'era'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('46', '46'), (']', ']'), ('J.', 'j.'), ('Shu', 'shu'), (',', ','), ('Z.', 'z.'), ('Xu', 'xu'), (',', ','), ('D.', 'd.'), ('Meng', 'meng'), (',', ','), ('“', '“'), ('Small', 'small'), ('Sample', 'sampl'), ('Learning', 'learn'), ('Big', 'big'), ('Data', 'data'), ('Era', 'era'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Aug.', 'aug.'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('46', '46'), (']', ']'), ('J.', 'J.'), ('Shu', 'Shu'), (',', ','), ('Z.', 'Z.'), ('Xu', 'Xu'), (',', ','), ('D.', 'D.'), ('Meng', 'Meng'), (',', ','), ('“', '“'), ('Small', 'Small'), ('Sample', 'Sample'), ('Learning', 'Learning'), ('Big', 'Big'), ('Data', 'Data'), ('Era', 'Era'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Aug.', 'Aug.'), ('2018', '2018'), ('.', '.')]



============================ Sentence 695 =============================

[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference cancellation for in-band full-duplex radios using neural net- works,” arXiv preprint arXiv:1711.00379, 2017. 


>> Tokens are: 
 ['[', '47', ']', 'A.', 'Balatsoukas-Stimming', ',', '“', 'Non-linear', 'digital', 'self-interference', 'cancellation', 'in-band', 'full-duplex', 'radios', 'using', 'neural', 'net-', 'works', ',', '”', 'arXiv', 'preprint', 'arXiv:1711.00379', ',', '2017', '.']

>> Bigrams are: 
 [('[', '47'), ('47', ']'), (']', 'A.'), ('A.', 'Balatsoukas-Stimming'), ('Balatsoukas-Stimming', ','), (',', '“'), ('“', 'Non-linear'), ('Non-linear', 'digital'), ('digital', 'self-interference'), ('self-interference', 'cancellation'), ('cancellation', 'in-band'), ('in-band', 'full-duplex'), ('full-duplex', 'radios'), ('radios', 'using'), ('using', 'neural'), ('neural', 'net-'), ('net-', 'works'), ('works', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1711.00379'), ('arXiv:1711.00379', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('[', '47', ']'), ('47', ']', 'A.'), (']', 'A.', 'Balatsoukas-Stimming'), ('A.', 'Balatsoukas-Stimming', ','), ('Balatsoukas-Stimming', ',', '“'), (',', '“', 'Non-linear'), ('“', 'Non-linear', 'digital'), ('Non-linear', 'digital', 'self-interference'), ('digital', 'self-interference', 'cancellation'), ('self-interference', 'cancellation', 'in-band'), ('cancellation', 'in-band', 'full-duplex'), ('in-band', 'full-duplex', 'radios'), ('full-duplex', 'radios', 'using'), ('radios', 'using', 'neural'), ('using', 'neural', 'net-'), ('neural', 'net-', 'works'), ('net-', 'works', ','), ('works', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1711.00379'), ('preprint', 'arXiv:1711.00379', ','), ('arXiv:1711.00379', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('47', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('Balatsoukas-Stimming', 'NNP'), (',', ','), ('“', 'NNP'), ('Non-linear', 'NNP'), ('digital', 'JJ'), ('self-interference', 'NN'), ('cancellation', 'NN'), ('in-band', 'JJ'), ('full-duplex', 'JJ'), ('radios', 'NNS'), ('using', 'VBG'), ('neural', 'JJ'), ('net-', 'JJ'), ('works', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1711.00379', 'NN'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  [/RB
  47/CD
  (NP ]/JJ A./NNP Balatsoukas-Stimming/NNP)
  ,/,
  (NP “/NNP Non-linear/NNP)
  (NP digital/JJ self-interference/NN cancellation/NN)
  (NP in-band/JJ full-duplex/JJ radios/NNS)
  using/VBG
  (NP neural/JJ net-/JJ works/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1711.00379/NN)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['] A. Balatsoukas-Stimming', '“ Non-linear', 'digital self-interference cancellation', 'in-band full-duplex radios', 'neural net- works', '”', 'preprint arXiv:1711.00379']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('47', '47'), (']', ']'), ('A.', 'a.'), ('Balatsoukas-Stimming', 'balatsoukas-stim'), (',', ','), ('“', '“'), ('Non-linear', 'non-linear'), ('digital', 'digit'), ('self-interference', 'self-interfer'), ('cancellation', 'cancel'), ('in-band', 'in-band'), ('full-duplex', 'full-duplex'), ('radios', 'radio'), ('using', 'use'), ('neural', 'neural'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1711.00379', 'arxiv:1711.00379'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('47', '47'), (']', ']'), ('A.', 'a.'), ('Balatsoukas-Stimming', 'balatsoukas-stim'), (',', ','), ('“', '“'), ('Non-linear', 'non-linear'), ('digital', 'digit'), ('self-interference', 'self-interfer'), ('cancellation', 'cancel'), ('in-band', 'in-band'), ('full-duplex', 'full-duplex'), ('radios', 'radio'), ('using', 'use'), ('neural', 'neural'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1711.00379', 'arxiv:1711.00379'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('47', '47'), (']', ']'), ('A.', 'A.'), ('Balatsoukas-Stimming', 'Balatsoukas-Stimming'), (',', ','), ('“', '“'), ('Non-linear', 'Non-linear'), ('digital', 'digital'), ('self-interference', 'self-interference'), ('cancellation', 'cancellation'), ('in-band', 'in-band'), ('full-duplex', 'full-duplex'), ('radios', 'radio'), ('using', 'using'), ('neural', 'neural'), ('net-', 'net-'), ('works', 'work'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1711.00379', 'arXiv:1711.00379'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 696 =============================

[48] N. Strodthoff, B. Göktepe, T. Schierl, C. Hellge, and W. Samek, “Enhanced Machine Learning Techniques for Early HARQ Feedback Prediction in 5G,” ArXiv e-prints, Jul. 


>> Tokens are: 
 ['[', '48', ']', 'N.', 'Strodthoff', ',', 'B.', 'Göktepe', ',', 'T.', 'Schierl', ',', 'C.', 'Hellge', ',', 'W.', 'Samek', ',', '“', 'Enhanced', 'Machine', 'Learning', 'Techniques', 'Early', 'HARQ', 'Feedback', 'Prediction', '5G', ',', '”', 'ArXiv', 'e-prints', ',', 'Jul', '.']

>> Bigrams are: 
 [('[', '48'), ('48', ']'), (']', 'N.'), ('N.', 'Strodthoff'), ('Strodthoff', ','), (',', 'B.'), ('B.', 'Göktepe'), ('Göktepe', ','), (',', 'T.'), ('T.', 'Schierl'), ('Schierl', ','), (',', 'C.'), ('C.', 'Hellge'), ('Hellge', ','), (',', 'W.'), ('W.', 'Samek'), ('Samek', ','), (',', '“'), ('“', 'Enhanced'), ('Enhanced', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Techniques'), ('Techniques', 'Early'), ('Early', 'HARQ'), ('HARQ', 'Feedback'), ('Feedback', 'Prediction'), ('Prediction', '5G'), ('5G', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jul'), ('Jul', '.')]

>> Trigrams are: 
 [('[', '48', ']'), ('48', ']', 'N.'), (']', 'N.', 'Strodthoff'), ('N.', 'Strodthoff', ','), ('Strodthoff', ',', 'B.'), (',', 'B.', 'Göktepe'), ('B.', 'Göktepe', ','), ('Göktepe', ',', 'T.'), (',', 'T.', 'Schierl'), ('T.', 'Schierl', ','), ('Schierl', ',', 'C.'), (',', 'C.', 'Hellge'), ('C.', 'Hellge', ','), ('Hellge', ',', 'W.'), (',', 'W.', 'Samek'), ('W.', 'Samek', ','), ('Samek', ',', '“'), (',', '“', 'Enhanced'), ('“', 'Enhanced', 'Machine'), ('Enhanced', 'Machine', 'Learning'), ('Machine', 'Learning', 'Techniques'), ('Learning', 'Techniques', 'Early'), ('Techniques', 'Early', 'HARQ'), ('Early', 'HARQ', 'Feedback'), ('HARQ', 'Feedback', 'Prediction'), ('Feedback', 'Prediction', '5G'), ('Prediction', '5G', ','), ('5G', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jul'), (',', 'Jul', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('48', 'CD'), (']', 'JJ'), ('N.', 'NNP'), ('Strodthoff', 'NNP'), (',', ','), ('B.', 'NNP'), ('Göktepe', 'NNP'), (',', ','), ('T.', 'NNP'), ('Schierl', 'NNP'), (',', ','), ('C.', 'NNP'), ('Hellge', 'NNP'), (',', ','), ('W.', 'NNP'), ('Samek', 'NNP'), (',', ','), ('“', 'NNP'), ('Enhanced', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Techniques', 'NNP'), ('Early', 'NNP'), ('HARQ', 'NNP'), ('Feedback', 'NNP'), ('Prediction', 'NNP'), ('5G', 'CD'), (',', ','), ('”', 'JJ'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jul', 'NNP'), ('.', '.')]

 (S
  [/RB
  48/CD
  (NP ]/JJ N./NNP Strodthoff/NNP)
  ,/,
  (NP B./NNP Göktepe/NNP)
  ,/,
  (NP T./NNP Schierl/NNP)
  ,/,
  (NP C./NNP Hellge/NNP)
  ,/,
  (NP W./NNP Samek/NNP)
  ,/,
  (NP
    “/NNP
    Enhanced/NNP
    Machine/NNP
    Learning/NNP
    Techniques/NNP
    Early/NNP
    HARQ/NNP
    Feedback/NNP
    Prediction/NNP)
  5G/CD
  ,/,
  (NP ”/JJ ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jul/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] N. Strodthoff', 'B. Göktepe', 'T. Schierl', 'C. Hellge', 'W. Samek', '“ Enhanced Machine Learning Techniques Early HARQ Feedback Prediction', '” ArXiv e-prints', 'Jul']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Techniques Early'), ('ORGANIZATION', 'HARQ Feedback'), ('ORGANIZATION', 'ArXiv'), ('PERSON', 'Jul')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('48', '48'), (']', ']'), ('N.', 'n.'), ('Strodthoff', 'strodthoff'), (',', ','), ('B.', 'b.'), ('Göktepe', 'göktep'), (',', ','), ('T.', 't.'), ('Schierl', 'schierl'), (',', ','), ('C.', 'c.'), ('Hellge', 'hellg'), (',', ','), ('W.', 'w.'), ('Samek', 'samek'), (',', ','), ('“', '“'), ('Enhanced', 'enhanc'), ('Machine', 'machin'), ('Learning', 'learn'), ('Techniques', 'techniqu'), ('Early', 'earli'), ('HARQ', 'harq'), ('Feedback', 'feedback'), ('Prediction', 'predict'), ('5G', '5g'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('48', '48'), (']', ']'), ('N.', 'n.'), ('Strodthoff', 'strodthoff'), (',', ','), ('B.', 'b.'), ('Göktepe', 'göktep'), (',', ','), ('T.', 't.'), ('Schierl', 'schierl'), (',', ','), ('C.', 'c.'), ('Hellge', 'hellg'), (',', ','), ('W.', 'w.'), ('Samek', 'samek'), (',', ','), ('“', '“'), ('Enhanced', 'enhanc'), ('Machine', 'machin'), ('Learning', 'learn'), ('Techniques', 'techniqu'), ('Early', 'earli'), ('HARQ', 'harq'), ('Feedback', 'feedback'), ('Prediction', 'predict'), ('5G', '5g'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('48', '48'), (']', ']'), ('N.', 'N.'), ('Strodthoff', 'Strodthoff'), (',', ','), ('B.', 'B.'), ('Göktepe', 'Göktepe'), (',', ','), ('T.', 'T.'), ('Schierl', 'Schierl'), (',', ','), ('C.', 'C.'), ('Hellge', 'Hellge'), (',', ','), ('W.', 'W.'), ('Samek', 'Samek'), (',', ','), ('“', '“'), ('Enhanced', 'Enhanced'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Techniques', 'Techniques'), ('Early', 'Early'), ('HARQ', 'HARQ'), ('Feedback', 'Feedback'), ('Prediction', 'Prediction'), ('5G', '5G'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jul', 'Jul'), ('.', '.')]



============================ Sentence 697 =============================

2018. 


>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

 (S 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]



============================ Sentence 698 =============================

[49] V. K. Tumuluru, P. Wang, and D. Niyato, “A neural net- work based spectrum prediction scheme for cognitive radio,” in IEEE International Conference on Communications (ICC 2010), 2010, pp. 


>> Tokens are: 
 ['[', '49', ']', 'V.', 'K.', 'Tumuluru', ',', 'P.', 'Wang', ',', 'D.', 'Niyato', ',', '“', 'A', 'neural', 'net-', 'work', 'based', 'spectrum', 'prediction', 'scheme', 'cognitive', 'radio', ',', '”', 'IEEE', 'International', 'Conference', 'Communications', '(', 'ICC', '2010', ')', ',', '2010', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '49'), ('49', ']'), (']', 'V.'), ('V.', 'K.'), ('K.', 'Tumuluru'), ('Tumuluru', ','), (',', 'P.'), ('P.', 'Wang'), ('Wang', ','), (',', 'D.'), ('D.', 'Niyato'), ('Niyato', ','), (',', '“'), ('“', 'A'), ('A', 'neural'), ('neural', 'net-'), ('net-', 'work'), ('work', 'based'), ('based', 'spectrum'), ('spectrum', 'prediction'), ('prediction', 'scheme'), ('scheme', 'cognitive'), ('cognitive', 'radio'), ('radio', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'International'), ('International', 'Conference'), ('Conference', 'Communications'), ('Communications', '('), ('(', 'ICC'), ('ICC', '2010'), ('2010', ')'), (')', ','), (',', '2010'), ('2010', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '49', ']'), ('49', ']', 'V.'), (']', 'V.', 'K.'), ('V.', 'K.', 'Tumuluru'), ('K.', 'Tumuluru', ','), ('Tumuluru', ',', 'P.'), (',', 'P.', 'Wang'), ('P.', 'Wang', ','), ('Wang', ',', 'D.'), (',', 'D.', 'Niyato'), ('D.', 'Niyato', ','), ('Niyato', ',', '“'), (',', '“', 'A'), ('“', 'A', 'neural'), ('A', 'neural', 'net-'), ('neural', 'net-', 'work'), ('net-', 'work', 'based'), ('work', 'based', 'spectrum'), ('based', 'spectrum', 'prediction'), ('spectrum', 'prediction', 'scheme'), ('prediction', 'scheme', 'cognitive'), ('scheme', 'cognitive', 'radio'), ('cognitive', 'radio', ','), ('radio', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'International'), ('IEEE', 'International', 'Conference'), ('International', 'Conference', 'Communications'), ('Conference', 'Communications', '('), ('Communications', '(', 'ICC'), ('(', 'ICC', '2010'), ('ICC', '2010', ')'), ('2010', ')', ','), (')', ',', '2010'), (',', '2010', ','), ('2010', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('49', 'CD'), (']', 'JJ'), ('V.', 'NNP'), ('K.', 'NNP'), ('Tumuluru', 'NNP'), (',', ','), ('P.', 'NNP'), ('Wang', 'NNP'), (',', ','), ('D.', 'NNP'), ('Niyato', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'DT'), ('neural', 'JJ'), ('net-', 'JJ'), ('work', 'NN'), ('based', 'VBN'), ('spectrum', 'JJ'), ('prediction', 'NN'), ('scheme', 'NN'), ('cognitive', 'JJ'), ('radio', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Communications', 'NNP'), ('(', '('), ('ICC', 'NNP'), ('2010', 'CD'), (')', ')'), (',', ','), ('2010', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  49/CD
  (NP ]/JJ V./NNP K./NNP Tumuluru/NNP)
  ,/,
  (NP P./NNP Wang/NNP)
  ,/,
  (NP D./NNP Niyato/NNP)
  ,/,
  “/VBZ
  (NP A/DT neural/JJ net-/JJ work/NN)
  based/VBN
  (NP spectrum/JJ prediction/NN scheme/NN)
  (NP cognitive/JJ radio/NN)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    International/NNP
    Conference/NNP
    Communications/NNP)
  (/(
  (NP ICC/NNP)
  2010/CD
  )/)
  ,/,
  2010/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] V. K. Tumuluru', 'P. Wang', 'D. Niyato', 'A neural net- work', 'spectrum prediction scheme', 'cognitive radio', '” IEEE International Conference Communications', 'ICC', 'pp']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('ORGANIZATION', 'IEEE International Conference Communications'), ('ORGANIZATION', 'ICC')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('49', '49'), (']', ']'), ('V.', 'v.'), ('K.', 'k.'), ('Tumuluru', 'tumuluru'), (',', ','), ('P.', 'p.'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), ('Niyato', 'niyato'), (',', ','), ('“', '“'), ('A', 'a'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('based', 'base'), ('spectrum', 'spectrum'), ('prediction', 'predict'), ('scheme', 'scheme'), ('cognitive', 'cognit'), ('radio', 'radio'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('Communications', 'commun'), ('(', '('), ('ICC', 'icc'), ('2010', '2010'), (')', ')'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('49', '49'), (']', ']'), ('V.', 'v.'), ('K.', 'k.'), ('Tumuluru', 'tumuluru'), (',', ','), ('P.', 'p.'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), ('Niyato', 'niyato'), (',', ','), ('“', '“'), ('A', 'a'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('based', 'base'), ('spectrum', 'spectrum'), ('prediction', 'predict'), ('scheme', 'scheme'), ('cognitive', 'cognit'), ('radio', 'radio'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('Communications', 'communic'), ('(', '('), ('ICC', 'icc'), ('2010', '2010'), (')', ')'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('49', '49'), (']', ']'), ('V.', 'V.'), ('K.', 'K.'), ('Tumuluru', 'Tumuluru'), (',', ','), ('P.', 'P.'), ('Wang', 'Wang'), (',', ','), ('D.', 'D.'), ('Niyato', 'Niyato'), (',', ','), ('“', '“'), ('A', 'A'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('based', 'based'), ('spectrum', 'spectrum'), ('prediction', 'prediction'), ('scheme', 'scheme'), ('cognitive', 'cognitive'), ('radio', 'radio'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('International', 'International'), ('Conference', 'Conference'), ('Communications', 'Communications'), ('(', '('), ('ICC', 'ICC'), ('2010', '2010'), (')', ')'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 699 =============================

1–5. 


>> Tokens are: 
 ['1–5', '.']

>> Bigrams are: 
 [('1–5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–5', 'CD'), ('.', '.')]

 (S 1–5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–5', '1–5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–5', '1–5'), ('.', '.')]

>> Lemmatization: 
 [('1–5', '1–5'), ('.', '.')]



============================ Sentence 700 =============================

[50] D. Del Testa, M. Danieletto, G. M. Di Nunzio, and M. Zorzi, “Estimating the number of receiving nodes in 802.11 networks via machine learning techniques,” in IEEE Global Communica- tions Conference (GLOBECOM), 2016, pp. 


>> Tokens are: 
 ['[', '50', ']', 'D.', 'Del', 'Testa', ',', 'M.', 'Danieletto', ',', 'G.', 'M.', 'Di', 'Nunzio', ',', 'M.', 'Zorzi', ',', '“', 'Estimating', 'number', 'receiving', 'nodes', '802.11', 'networks', 'via', 'machine', 'learning', 'techniques', ',', '”', 'IEEE', 'Global', 'Communica-', 'tions', 'Conference', '(', 'GLOBECOM', ')', ',', '2016', ',', 'pp', '.']

>> Bigrams are: 
 [('[', '50'), ('50', ']'), (']', 'D.'), ('D.', 'Del'), ('Del', 'Testa'), ('Testa', ','), (',', 'M.'), ('M.', 'Danieletto'), ('Danieletto', ','), (',', 'G.'), ('G.', 'M.'), ('M.', 'Di'), ('Di', 'Nunzio'), ('Nunzio', ','), (',', 'M.'), ('M.', 'Zorzi'), ('Zorzi', ','), (',', '“'), ('“', 'Estimating'), ('Estimating', 'number'), ('number', 'receiving'), ('receiving', 'nodes'), ('nodes', '802.11'), ('802.11', 'networks'), ('networks', 'via'), ('via', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Global'), ('Global', 'Communica-'), ('Communica-', 'tions'), ('tions', 'Conference'), ('Conference', '('), ('(', 'GLOBECOM'), ('GLOBECOM', ')'), (')', ','), (',', '2016'), ('2016', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('[', '50', ']'), ('50', ']', 'D.'), (']', 'D.', 'Del'), ('D.', 'Del', 'Testa'), ('Del', 'Testa', ','), ('Testa', ',', 'M.'), (',', 'M.', 'Danieletto'), ('M.', 'Danieletto', ','), ('Danieletto', ',', 'G.'), (',', 'G.', 'M.'), ('G.', 'M.', 'Di'), ('M.', 'Di', 'Nunzio'), ('Di', 'Nunzio', ','), ('Nunzio', ',', 'M.'), (',', 'M.', 'Zorzi'), ('M.', 'Zorzi', ','), ('Zorzi', ',', '“'), (',', '“', 'Estimating'), ('“', 'Estimating', 'number'), ('Estimating', 'number', 'receiving'), ('number', 'receiving', 'nodes'), ('receiving', 'nodes', '802.11'), ('nodes', '802.11', 'networks'), ('802.11', 'networks', 'via'), ('networks', 'via', 'machine'), ('via', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', ','), ('techniques', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Global'), ('IEEE', 'Global', 'Communica-'), ('Global', 'Communica-', 'tions'), ('Communica-', 'tions', 'Conference'), ('tions', 'Conference', '('), ('Conference', '(', 'GLOBECOM'), ('(', 'GLOBECOM', ')'), ('GLOBECOM', ')', ','), (')', ',', '2016'), (',', '2016', ','), ('2016', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('50', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Del', 'NNP'), ('Testa', 'NNP'), (',', ','), ('M.', 'NNP'), ('Danieletto', 'NNP'), (',', ','), ('G.', 'NNP'), ('M.', 'NNP'), ('Di', 'NNP'), ('Nunzio', 'NNP'), (',', ','), ('M.', 'NNP'), ('Zorzi', 'NNP'), (',', ','), ('“', 'NNP'), ('Estimating', 'NNP'), ('number', 'NN'), ('receiving', 'VBG'), ('nodes', 'NNS'), ('802.11', 'CD'), ('networks', 'NNS'), ('via', 'IN'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Global', 'NNP'), ('Communica-', 'NNP'), ('tions', 'NNS'), ('Conference', 'NNP'), ('(', '('), ('GLOBECOM', 'NNP'), (')', ')'), (',', ','), ('2016', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  [/RB
  50/CD
  (NP ]/JJ D./NNP Del/NNP Testa/NNP)
  ,/,
  (NP M./NNP Danieletto/NNP)
  ,/,
  (NP G./NNP M./NNP Di/NNP Nunzio/NNP)
  ,/,
  (NP M./NNP Zorzi/NNP)
  ,/,
  (NP “/NNP Estimating/NNP number/NN)
  receiving/VBG
  (NP nodes/NNS)
  802.11/CD
  (NP networks/NNS)
  via/IN
  (NP machine/NN)
  learning/VBG
  (NP techniques/NNS)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Global/NNP
    Communica-/NNP
    tions/NNS
    Conference/NNP)
  (/(
  (NP GLOBECOM/NNP)
  )/)
  ,/,
  2016/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['] D. Del Testa', 'M. Danieletto', 'G. M. Di Nunzio', 'M. Zorzi', '“ Estimating number', 'nodes', 'networks', 'machine', 'techniques', '” IEEE Global Communica- tions Conference', 'GLOBECOM', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'GLOBECOM')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('50', '50'), (']', ']'), ('D.', 'd.'), ('Del', 'del'), ('Testa', 'testa'), (',', ','), ('M.', 'm.'), ('Danieletto', 'danieletto'), (',', ','), ('G.', 'g.'), ('M.', 'm.'), ('Di', 'di'), ('Nunzio', 'nunzio'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Estimating', 'estim'), ('number', 'number'), ('receiving', 'receiv'), ('nodes', 'node'), ('802.11', '802.11'), ('networks', 'network'), ('via', 'via'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Global', 'global'), ('Communica-', 'communica-'), ('tions', 'tion'), ('Conference', 'confer'), ('(', '('), ('GLOBECOM', 'globecom'), (')', ')'), (',', ','), ('2016', '2016'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('50', '50'), (']', ']'), ('D.', 'd.'), ('Del', 'del'), ('Testa', 'testa'), (',', ','), ('M.', 'm.'), ('Danieletto', 'danieletto'), (',', ','), ('G.', 'g.'), ('M.', 'm.'), ('Di', 'di'), ('Nunzio', 'nunzio'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Estimating', 'estim'), ('number', 'number'), ('receiving', 'receiv'), ('nodes', 'node'), ('802.11', '802.11'), ('networks', 'network'), ('via', 'via'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Global', 'global'), ('Communica-', 'communica-'), ('tions', 'tion'), ('Conference', 'confer'), ('(', '('), ('GLOBECOM', 'globecom'), (')', ')'), (',', ','), ('2016', '2016'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('50', '50'), (']', ']'), ('D.', 'D.'), ('Del', 'Del'), ('Testa', 'Testa'), (',', ','), ('M.', 'M.'), ('Danieletto', 'Danieletto'), (',', ','), ('G.', 'G.'), ('M.', 'M.'), ('Di', 'Di'), ('Nunzio', 'Nunzio'), (',', ','), ('M.', 'M.'), ('Zorzi', 'Zorzi'), (',', ','), ('“', '“'), ('Estimating', 'Estimating'), ('number', 'number'), ('receiving', 'receiving'), ('nodes', 'node'), ('802.11', '802.11'), ('networks', 'network'), ('via', 'via'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Global', 'Global'), ('Communica-', 'Communica-'), ('tions', 'tions'), ('Conference', 'Conference'), ('(', '('), ('GLOBECOM', 'GLOBECOM'), (')', ')'), (',', ','), ('2016', '2016'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 701 =============================

1–7. 


>> Tokens are: 
 ['1–7', '.']

>> Bigrams are: 
 [('1–7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–7', 'CD'), ('.', '.')]

 (S 1–7/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–7', '1–7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–7', '1–7'), ('.', '.')]

>> Lemmatization: 
 [('1–7', '1–7'), ('.', '.')]



============================ Sentence 702 =============================

[51] H. Okamoto, T. Nishio, K. Nakashima, Y. Koda, K. Ya- mamoto, M. Morikura, Y. Asai, and R. Miyatake, “Machine- learning-based future received signal strength prediction using depth images for mmwave communications,” arXiv preprint arXiv:1803.09698, 2018. 


>> Tokens are: 
 ['[', '51', ']', 'H.', 'Okamoto', ',', 'T.', 'Nishio', ',', 'K.', 'Nakashima', ',', 'Y.', 'Koda', ',', 'K.', 'Ya-', 'mamoto', ',', 'M.', 'Morikura', ',', 'Y.', 'Asai', ',', 'R.', 'Miyatake', ',', '“', 'Machine-', 'learning-based', 'future', 'received', 'signal', 'strength', 'prediction', 'using', 'depth', 'images', 'mmwave', 'communications', ',', '”', 'arXiv', 'preprint', 'arXiv:1803.09698', ',', '2018', '.']

>> Bigrams are: 
 [('[', '51'), ('51', ']'), (']', 'H.'), ('H.', 'Okamoto'), ('Okamoto', ','), (',', 'T.'), ('T.', 'Nishio'), ('Nishio', ','), (',', 'K.'), ('K.', 'Nakashima'), ('Nakashima', ','), (',', 'Y.'), ('Y.', 'Koda'), ('Koda', ','), (',', 'K.'), ('K.', 'Ya-'), ('Ya-', 'mamoto'), ('mamoto', ','), (',', 'M.'), ('M.', 'Morikura'), ('Morikura', ','), (',', 'Y.'), ('Y.', 'Asai'), ('Asai', ','), (',', 'R.'), ('R.', 'Miyatake'), ('Miyatake', ','), (',', '“'), ('“', 'Machine-'), ('Machine-', 'learning-based'), ('learning-based', 'future'), ('future', 'received'), ('received', 'signal'), ('signal', 'strength'), ('strength', 'prediction'), ('prediction', 'using'), ('using', 'depth'), ('depth', 'images'), ('images', 'mmwave'), ('mmwave', 'communications'), ('communications', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1803.09698'), ('arXiv:1803.09698', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '51', ']'), ('51', ']', 'H.'), (']', 'H.', 'Okamoto'), ('H.', 'Okamoto', ','), ('Okamoto', ',', 'T.'), (',', 'T.', 'Nishio'), ('T.', 'Nishio', ','), ('Nishio', ',', 'K.'), (',', 'K.', 'Nakashima'), ('K.', 'Nakashima', ','), ('Nakashima', ',', 'Y.'), (',', 'Y.', 'Koda'), ('Y.', 'Koda', ','), ('Koda', ',', 'K.'), (',', 'K.', 'Ya-'), ('K.', 'Ya-', 'mamoto'), ('Ya-', 'mamoto', ','), ('mamoto', ',', 'M.'), (',', 'M.', 'Morikura'), ('M.', 'Morikura', ','), ('Morikura', ',', 'Y.'), (',', 'Y.', 'Asai'), ('Y.', 'Asai', ','), ('Asai', ',', 'R.'), (',', 'R.', 'Miyatake'), ('R.', 'Miyatake', ','), ('Miyatake', ',', '“'), (',', '“', 'Machine-'), ('“', 'Machine-', 'learning-based'), ('Machine-', 'learning-based', 'future'), ('learning-based', 'future', 'received'), ('future', 'received', 'signal'), ('received', 'signal', 'strength'), ('signal', 'strength', 'prediction'), ('strength', 'prediction', 'using'), ('prediction', 'using', 'depth'), ('using', 'depth', 'images'), ('depth', 'images', 'mmwave'), ('images', 'mmwave', 'communications'), ('mmwave', 'communications', ','), ('communications', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1803.09698'), ('preprint', 'arXiv:1803.09698', ','), ('arXiv:1803.09698', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('51', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('Okamoto', 'NNP'), (',', ','), ('T.', 'NNP'), ('Nishio', 'NNP'), (',', ','), ('K.', 'NNP'), ('Nakashima', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Koda', 'NNP'), (',', ','), ('K.', 'NNP'), ('Ya-', 'NNP'), ('mamoto', 'NN'), (',', ','), ('M.', 'NNP'), ('Morikura', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Asai', 'NNP'), (',', ','), ('R.', 'NNP'), ('Miyatake', 'NNP'), (',', ','), ('“', 'JJ'), ('Machine-', 'NNP'), ('learning-based', 'JJ'), ('future', 'NN'), ('received', 'VBD'), ('signal', 'JJ'), ('strength', 'NN'), ('prediction', 'NN'), ('using', 'VBG'), ('depth', 'JJ'), ('images', 'NNS'), ('mmwave', 'VBP'), ('communications', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1803.09698', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  51/CD
  (NP ]/JJ H./NNP Okamoto/NNP)
  ,/,
  (NP T./NNP Nishio/NNP)
  ,/,
  (NP K./NNP Nakashima/NNP)
  ,/,
  (NP Y./NNP Koda/NNP)
  ,/,
  (NP K./NNP Ya-/NNP mamoto/NN)
  ,/,
  (NP M./NNP Morikura/NNP)
  ,/,
  (NP Y./NNP Asai/NNP)
  ,/,
  (NP R./NNP Miyatake/NNP)
  ,/,
  (NP “/JJ Machine-/NNP)
  (NP learning-based/JJ future/NN)
  received/VBD
  (NP signal/JJ strength/NN prediction/NN)
  using/VBG
  (NP depth/JJ images/NNS)
  mmwave/VBP
  (NP communications/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1803.09698/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] H. Okamoto', 'T. Nishio', 'K. Nakashima', 'Y. Koda', 'K. Ya- mamoto', 'M. Morikura', 'Y. Asai', 'R. Miyatake', '“ Machine-', 'learning-based future', 'signal strength prediction', 'depth images', 'communications', '”', 'preprint arXiv:1803.09698']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('51', '51'), (']', ']'), ('H.', 'h.'), ('Okamoto', 'okamoto'), (',', ','), ('T.', 't.'), ('Nishio', 'nishio'), (',', ','), ('K.', 'k.'), ('Nakashima', 'nakashima'), (',', ','), ('Y.', 'y.'), ('Koda', 'koda'), (',', ','), ('K.', 'k.'), ('Ya-', 'ya-'), ('mamoto', 'mamoto'), (',', ','), ('M.', 'm.'), ('Morikura', 'morikura'), (',', ','), ('Y.', 'y.'), ('Asai', 'asai'), (',', ','), ('R.', 'r.'), ('Miyatake', 'miyatak'), (',', ','), ('“', '“'), ('Machine-', 'machine-'), ('learning-based', 'learning-bas'), ('future', 'futur'), ('received', 'receiv'), ('signal', 'signal'), ('strength', 'strength'), ('prediction', 'predict'), ('using', 'use'), ('depth', 'depth'), ('images', 'imag'), ('mmwave', 'mmwave'), ('communications', 'commun'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.09698', 'arxiv:1803.09698'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('51', '51'), (']', ']'), ('H.', 'h.'), ('Okamoto', 'okamoto'), (',', ','), ('T.', 't.'), ('Nishio', 'nishio'), (',', ','), ('K.', 'k.'), ('Nakashima', 'nakashima'), (',', ','), ('Y.', 'y.'), ('Koda', 'koda'), (',', ','), ('K.', 'k.'), ('Ya-', 'ya-'), ('mamoto', 'mamoto'), (',', ','), ('M.', 'm.'), ('Morikura', 'morikura'), (',', ','), ('Y.', 'y.'), ('Asai', 'asai'), (',', ','), ('R.', 'r.'), ('Miyatake', 'miyatak'), (',', ','), ('“', '“'), ('Machine-', 'machine-'), ('learning-based', 'learning-bas'), ('future', 'futur'), ('received', 'receiv'), ('signal', 'signal'), ('strength', 'strength'), ('prediction', 'predict'), ('using', 'use'), ('depth', 'depth'), ('images', 'imag'), ('mmwave', 'mmwave'), ('communications', 'communic'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.09698', 'arxiv:1803.09698'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('51', '51'), (']', ']'), ('H.', 'H.'), ('Okamoto', 'Okamoto'), (',', ','), ('T.', 'T.'), ('Nishio', 'Nishio'), (',', ','), ('K.', 'K.'), ('Nakashima', 'Nakashima'), (',', ','), ('Y.', 'Y.'), ('Koda', 'Koda'), (',', ','), ('K.', 'K.'), ('Ya-', 'Ya-'), ('mamoto', 'mamoto'), (',', ','), ('M.', 'M.'), ('Morikura', 'Morikura'), (',', ','), ('Y.', 'Y.'), ('Asai', 'Asai'), (',', ','), ('R.', 'R.'), ('Miyatake', 'Miyatake'), (',', ','), ('“', '“'), ('Machine-', 'Machine-'), ('learning-based', 'learning-based'), ('future', 'future'), ('received', 'received'), ('signal', 'signal'), ('strength', 'strength'), ('prediction', 'prediction'), ('using', 'using'), ('depth', 'depth'), ('images', 'image'), ('mmwave', 'mmwave'), ('communications', 'communication'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1803.09698', 'arXiv:1803.09698'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 703 =============================

[52] M. Chen, W. Saad, C. Yin, and M. Debbah, “Echo state networks for proactive caching in cloud-based radio access networks with mobile users,” IEEE Transactions on Wireless Communications, vol. 


>> Tokens are: 
 ['[', '52', ']', 'M.', 'Chen', ',', 'W.', 'Saad', ',', 'C.', 'Yin', ',', 'M.', 'Debbah', ',', '“', 'Echo', 'state', 'networks', 'proactive', 'caching', 'cloud-based', 'radio', 'access', 'networks', 'mobile', 'users', ',', '”', 'IEEE', 'Transactions', 'Wireless', 'Communications', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '52'), ('52', ']'), (']', 'M.'), ('M.', 'Chen'), ('Chen', ','), (',', 'W.'), ('W.', 'Saad'), ('Saad', ','), (',', 'C.'), ('C.', 'Yin'), ('Yin', ','), (',', 'M.'), ('M.', 'Debbah'), ('Debbah', ','), (',', '“'), ('“', 'Echo'), ('Echo', 'state'), ('state', 'networks'), ('networks', 'proactive'), ('proactive', 'caching'), ('caching', 'cloud-based'), ('cloud-based', 'radio'), ('radio', 'access'), ('access', 'networks'), ('networks', 'mobile'), ('mobile', 'users'), ('users', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Wireless'), ('Wireless', 'Communications'), ('Communications', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '52', ']'), ('52', ']', 'M.'), (']', 'M.', 'Chen'), ('M.', 'Chen', ','), ('Chen', ',', 'W.'), (',', 'W.', 'Saad'), ('W.', 'Saad', ','), ('Saad', ',', 'C.'), (',', 'C.', 'Yin'), ('C.', 'Yin', ','), ('Yin', ',', 'M.'), (',', 'M.', 'Debbah'), ('M.', 'Debbah', ','), ('Debbah', ',', '“'), (',', '“', 'Echo'), ('“', 'Echo', 'state'), ('Echo', 'state', 'networks'), ('state', 'networks', 'proactive'), ('networks', 'proactive', 'caching'), ('proactive', 'caching', 'cloud-based'), ('caching', 'cloud-based', 'radio'), ('cloud-based', 'radio', 'access'), ('radio', 'access', 'networks'), ('access', 'networks', 'mobile'), ('networks', 'mobile', 'users'), ('mobile', 'users', ','), ('users', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Wireless'), ('Transactions', 'Wireless', 'Communications'), ('Wireless', 'Communications', ','), ('Communications', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('52', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('W.', 'NNP'), ('Saad', 'NNP'), (',', ','), ('C.', 'NNP'), ('Yin', 'NNP'), (',', ','), ('M.', 'NNP'), ('Debbah', 'NNP'), (',', ','), ('“', 'NNP'), ('Echo', 'NNP'), ('state', 'NN'), ('networks', 'NNS'), ('proactive', 'JJ'), ('caching', 'VBG'), ('cloud-based', 'JJ'), ('radio', 'NN'), ('access', 'NN'), ('networks', 'NNS'), ('mobile', 'IN'), ('users', 'NNS'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  52/CD
  (NP ]/NNP M./NNP Chen/NNP)
  ,/,
  (NP W./NNP Saad/NNP)
  ,/,
  (NP C./NNP Yin/NNP)
  ,/,
  (NP M./NNP Debbah/NNP)
  ,/,
  (NP “/NNP Echo/NNP state/NN networks/NNS)
  proactive/JJ
  caching/VBG
  (NP cloud-based/JJ radio/NN access/NN networks/NNS)
  mobile/IN
  (NP users/NNS)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Transactions/NNP
    Wireless/NNP
    Communications/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. Chen', 'W. Saad', 'C. Yin', 'M. Debbah', '“ Echo state networks', 'cloud-based radio access networks', 'users', '” IEEE Transactions Wireless Communications', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Wireless Communications')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('52', '52'), (']', ']'), ('M.', 'm.'), ('Chen', 'chen'), (',', ','), ('W.', 'w.'), ('Saad', 'saad'), (',', ','), ('C.', 'c.'), ('Yin', 'yin'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Echo', 'echo'), ('state', 'state'), ('networks', 'network'), ('proactive', 'proactiv'), ('caching', 'cach'), ('cloud-based', 'cloud-bas'), ('radio', 'radio'), ('access', 'access'), ('networks', 'network'), ('mobile', 'mobil'), ('users', 'user'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Wireless', 'wireless'), ('Communications', 'commun'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('52', '52'), (']', ']'), ('M.', 'm.'), ('Chen', 'chen'), (',', ','), ('W.', 'w.'), ('Saad', 'saad'), (',', ','), ('C.', 'c.'), ('Yin', 'yin'), (',', ','), ('M.', 'm.'), ('Debbah', 'debbah'), (',', ','), ('“', '“'), ('Echo', 'echo'), ('state', 'state'), ('networks', 'network'), ('proactive', 'proactiv'), ('caching', 'cach'), ('cloud-based', 'cloud-bas'), ('radio', 'radio'), ('access', 'access'), ('networks', 'network'), ('mobile', 'mobil'), ('users', 'user'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Wireless', 'wireless'), ('Communications', 'communic'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('52', '52'), (']', ']'), ('M.', 'M.'), ('Chen', 'Chen'), (',', ','), ('W.', 'W.'), ('Saad', 'Saad'), (',', ','), ('C.', 'C.'), ('Yin', 'Yin'), (',', ','), ('M.', 'M.'), ('Debbah', 'Debbah'), (',', ','), ('“', '“'), ('Echo', 'Echo'), ('state', 'state'), ('networks', 'network'), ('proactive', 'proactive'), ('caching', 'caching'), ('cloud-based', 'cloud-based'), ('radio', 'radio'), ('access', 'access'), ('networks', 'network'), ('mobile', 'mobile'), ('users', 'user'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 704 =============================

16, no. 


>> Tokens are: 
 ['16', ',', '.']

>> Bigrams are: 
 [('16', ','), (',', '.')]

>> Trigrams are: 
 [('16', ',', '.')]

>> POS Tags are: 
 [('16', 'CD'), (',', ','), ('.', '.')]

 (S 16/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), (',', ','), ('.', '.')]



============================ Sentence 705 =============================

6, pp. 


>> Tokens are: 
 ['6', ',', 'pp', '.']

>> Bigrams are: 
 [('6', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('6', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 6/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 706 =============================

3520–3535, 2017. 


>> Tokens are: 
 ['3520–3535', ',', '2017', '.']

>> Bigrams are: 
 [('3520–3535', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('3520–3535', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('3520–3535', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 3520–3535/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3520–3535', '3520–3535'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3520–3535', '3520–3535'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('3520–3535', '3520–3535'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 707 =============================

[53] M. Zorzi, A. Zanella, A. Testolin, M. D. F. De Grazia, and M. Zorzi, “Cognition-based networks: A new perspective on network optimization using learning and distributed intelli- gence,” IEEE Access, vol. 


>> Tokens are: 
 ['[', '53', ']', 'M.', 'Zorzi', ',', 'A.', 'Zanella', ',', 'A.', 'Testolin', ',', 'M.', 'D.', 'F.', 'De', 'Grazia', ',', 'M.', 'Zorzi', ',', '“', 'Cognition-based', 'networks', ':', 'A', 'new', 'perspective', 'network', 'optimization', 'using', 'learning', 'distributed', 'intelli-', 'gence', ',', '”', 'IEEE', 'Access', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '53'), ('53', ']'), (']', 'M.'), ('M.', 'Zorzi'), ('Zorzi', ','), (',', 'A.'), ('A.', 'Zanella'), ('Zanella', ','), (',', 'A.'), ('A.', 'Testolin'), ('Testolin', ','), (',', 'M.'), ('M.', 'D.'), ('D.', 'F.'), ('F.', 'De'), ('De', 'Grazia'), ('Grazia', ','), (',', 'M.'), ('M.', 'Zorzi'), ('Zorzi', ','), (',', '“'), ('“', 'Cognition-based'), ('Cognition-based', 'networks'), ('networks', ':'), (':', 'A'), ('A', 'new'), ('new', 'perspective'), ('perspective', 'network'), ('network', 'optimization'), ('optimization', 'using'), ('using', 'learning'), ('learning', 'distributed'), ('distributed', 'intelli-'), ('intelli-', 'gence'), ('gence', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Access'), ('Access', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '53', ']'), ('53', ']', 'M.'), (']', 'M.', 'Zorzi'), ('M.', 'Zorzi', ','), ('Zorzi', ',', 'A.'), (',', 'A.', 'Zanella'), ('A.', 'Zanella', ','), ('Zanella', ',', 'A.'), (',', 'A.', 'Testolin'), ('A.', 'Testolin', ','), ('Testolin', ',', 'M.'), (',', 'M.', 'D.'), ('M.', 'D.', 'F.'), ('D.', 'F.', 'De'), ('F.', 'De', 'Grazia'), ('De', 'Grazia', ','), ('Grazia', ',', 'M.'), (',', 'M.', 'Zorzi'), ('M.', 'Zorzi', ','), ('Zorzi', ',', '“'), (',', '“', 'Cognition-based'), ('“', 'Cognition-based', 'networks'), ('Cognition-based', 'networks', ':'), ('networks', ':', 'A'), (':', 'A', 'new'), ('A', 'new', 'perspective'), ('new', 'perspective', 'network'), ('perspective', 'network', 'optimization'), ('network', 'optimization', 'using'), ('optimization', 'using', 'learning'), ('using', 'learning', 'distributed'), ('learning', 'distributed', 'intelli-'), ('distributed', 'intelli-', 'gence'), ('intelli-', 'gence', ','), ('gence', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Access'), ('IEEE', 'Access', ','), ('Access', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('53', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Zorzi', 'NNP'), (',', ','), ('A.', 'NNP'), ('Zanella', 'NNP'), (',', ','), ('A.', 'NNP'), ('Testolin', 'NNP'), (',', ','), ('M.', 'NNP'), ('D.', 'NNP'), ('F.', 'NNP'), ('De', 'NNP'), ('Grazia', 'NNP'), (',', ','), ('M.', 'NNP'), ('Zorzi', 'NNP'), (',', ','), ('“', 'NNP'), ('Cognition-based', 'JJ'), ('networks', 'NNS'), (':', ':'), ('A', 'DT'), ('new', 'JJ'), ('perspective', 'NN'), ('network', 'NN'), ('optimization', 'NN'), ('using', 'VBG'), ('learning', 'VBG'), ('distributed', 'VBN'), ('intelli-', 'JJ'), ('gence', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Access', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  53/CD
  (NP ]/NNP M./NNP Zorzi/NNP)
  ,/,
  (NP A./NNP Zanella/NNP)
  ,/,
  (NP A./NNP Testolin/NNP)
  ,/,
  (NP M./NNP D./NNP F./NNP De/NNP Grazia/NNP)
  ,/,
  (NP M./NNP Zorzi/NNP)
  ,/,
  (NP “/NNP)
  (NP Cognition-based/JJ networks/NNS)
  :/:
  (NP A/DT new/JJ perspective/NN network/NN optimization/NN)
  using/VBG
  learning/VBG
  distributed/VBN
  (NP intelli-/JJ gence/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Access/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. Zorzi', 'A. Zanella', 'A. Testolin', 'M. D. F. De Grazia', 'M. Zorzi', '“', 'Cognition-based networks', 'A new perspective network optimization', 'intelli- gence', '” IEEE Access', 'vol']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('53', '53'), (']', ']'), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('A.', 'a.'), ('Zanella', 'zanella'), (',', ','), ('A.', 'a.'), ('Testolin', 'testolin'), (',', ','), ('M.', 'm.'), ('D.', 'd.'), ('F.', 'f.'), ('De', 'de'), ('Grazia', 'grazia'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Cognition-based', 'cognition-bas'), ('networks', 'network'), (':', ':'), ('A', 'a'), ('new', 'new'), ('perspective', 'perspect'), ('network', 'network'), ('optimization', 'optim'), ('using', 'use'), ('learning', 'learn'), ('distributed', 'distribut'), ('intelli-', 'intelli-'), ('gence', 'genc'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Access', 'access'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('53', '53'), (']', ']'), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('A.', 'a.'), ('Zanella', 'zanella'), (',', ','), ('A.', 'a.'), ('Testolin', 'testolin'), (',', ','), ('M.', 'm.'), ('D.', 'd.'), ('F.', 'f.'), ('De', 'de'), ('Grazia', 'grazia'), (',', ','), ('M.', 'm.'), ('Zorzi', 'zorzi'), (',', ','), ('“', '“'), ('Cognition-based', 'cognition-bas'), ('networks', 'network'), (':', ':'), ('A', 'a'), ('new', 'new'), ('perspective', 'perspect'), ('network', 'network'), ('optimization', 'optim'), ('using', 'use'), ('learning', 'learn'), ('distributed', 'distribut'), ('intelli-', 'intelli-'), ('gence', 'genc'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Access', 'access'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('53', '53'), (']', ']'), ('M.', 'M.'), ('Zorzi', 'Zorzi'), (',', ','), ('A.', 'A.'), ('Zanella', 'Zanella'), (',', ','), ('A.', 'A.'), ('Testolin', 'Testolin'), (',', ','), ('M.', 'M.'), ('D.', 'D.'), ('F.', 'F.'), ('De', 'De'), ('Grazia', 'Grazia'), (',', ','), ('M.', 'M.'), ('Zorzi', 'Zorzi'), (',', ','), ('“', '“'), ('Cognition-based', 'Cognition-based'), ('networks', 'network'), (':', ':'), ('A', 'A'), ('new', 'new'), ('perspective', 'perspective'), ('network', 'network'), ('optimization', 'optimization'), ('using', 'using'), ('learning', 'learning'), ('distributed', 'distributed'), ('intelli-', 'intelli-'), ('gence', 'gence'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Access', 'Access'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 708 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 709 =============================

1512–1530, 2015. 


>> Tokens are: 
 ['1512–1530', ',', '2015', '.']

>> Bigrams are: 
 [('1512–1530', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('1512–1530', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('1512–1530', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S 1512–1530/CD ,/, 2015/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1512–1530', '1512–1530'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1512–1530', '1512–1530'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('1512–1530', '1512–1530'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 710 =============================

[54] F. Musumeci, C. Rottondi, A. 


>> Tokens are: 
 ['[', '54', ']', 'F.', 'Musumeci', ',', 'C.', 'Rottondi', ',', 'A', '.']

>> Bigrams are: 
 [('[', '54'), ('54', ']'), (']', 'F.'), ('F.', 'Musumeci'), ('Musumeci', ','), (',', 'C.'), ('C.', 'Rottondi'), ('Rottondi', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '54', ']'), ('54', ']', 'F.'), (']', 'F.', 'Musumeci'), ('F.', 'Musumeci', ','), ('Musumeci', ',', 'C.'), (',', 'C.', 'Rottondi'), ('C.', 'Rottondi', ','), ('Rottondi', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('54', 'CD'), (']', 'JJ'), ('F.', 'NNP'), ('Musumeci', 'NNP'), (',', ','), ('C.', 'NNP'), ('Rottondi', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

 (S
  [/RB
  54/CD
  (NP ]/JJ F./NNP Musumeci/NNP)
  ,/,
  (NP C./NNP Rottondi/NNP)
  ,/,
  (NP A/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] F. Musumeci', 'C. Rottondi', 'A']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('54', '54'), (']', ']'), ('F.', 'f.'), ('Musumeci', 'musumeci'), (',', ','), ('C.', 'c.'), ('Rottondi', 'rottondi'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('54', '54'), (']', ']'), ('F.', 'f.'), ('Musumeci', 'musumeci'), (',', ','), ('C.', 'c.'), ('Rottondi', 'rottondi'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('54', '54'), (']', ']'), ('F.', 'F.'), ('Musumeci', 'Musumeci'), (',', ','), ('C.', 'C.'), ('Rottondi', 'Rottondi'), (',', ','), ('A', 'A'), ('.', '.')]



============================ Sentence 711 =============================

Nag, I. Macaluso, D. Zibar, M. Ruffini, and M. Tornatore, “A survey on application of ma- chine learning techniques in optical networks,” arXiv preprint arXiv:1803.07976, 2018. 


>> Tokens are: 
 ['Nag', ',', 'I.', 'Macaluso', ',', 'D.', 'Zibar', ',', 'M.', 'Ruffini', ',', 'M.', 'Tornatore', ',', '“', 'A', 'survey', 'application', 'ma-', 'chine', 'learning', 'techniques', 'optical', 'networks', ',', '”', 'arXiv', 'preprint', 'arXiv:1803.07976', ',', '2018', '.']

>> Bigrams are: 
 [('Nag', ','), (',', 'I.'), ('I.', 'Macaluso'), ('Macaluso', ','), (',', 'D.'), ('D.', 'Zibar'), ('Zibar', ','), (',', 'M.'), ('M.', 'Ruffini'), ('Ruffini', ','), (',', 'M.'), ('M.', 'Tornatore'), ('Tornatore', ','), (',', '“'), ('“', 'A'), ('A', 'survey'), ('survey', 'application'), ('application', 'ma-'), ('ma-', 'chine'), ('chine', 'learning'), ('learning', 'techniques'), ('techniques', 'optical'), ('optical', 'networks'), ('networks', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1803.07976'), ('arXiv:1803.07976', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Nag', ',', 'I.'), (',', 'I.', 'Macaluso'), ('I.', 'Macaluso', ','), ('Macaluso', ',', 'D.'), (',', 'D.', 'Zibar'), ('D.', 'Zibar', ','), ('Zibar', ',', 'M.'), (',', 'M.', 'Ruffini'), ('M.', 'Ruffini', ','), ('Ruffini', ',', 'M.'), (',', 'M.', 'Tornatore'), ('M.', 'Tornatore', ','), ('Tornatore', ',', '“'), (',', '“', 'A'), ('“', 'A', 'survey'), ('A', 'survey', 'application'), ('survey', 'application', 'ma-'), ('application', 'ma-', 'chine'), ('ma-', 'chine', 'learning'), ('chine', 'learning', 'techniques'), ('learning', 'techniques', 'optical'), ('techniques', 'optical', 'networks'), ('optical', 'networks', ','), ('networks', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1803.07976'), ('preprint', 'arXiv:1803.07976', ','), ('arXiv:1803.07976', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Nag', 'NNP'), (',', ','), ('I.', 'NNP'), ('Macaluso', 'NNP'), (',', ','), ('D.', 'NNP'), ('Zibar', 'NNP'), (',', ','), ('M.', 'NNP'), ('Ruffini', 'NNP'), (',', ','), ('M.', 'NNP'), ('Tornatore', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('survey', 'NN'), ('application', 'NN'), ('ma-', 'JJ'), ('chine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), ('optical', 'JJ'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1803.07976', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Nag/NNP)
  ,/,
  (NP I./NNP Macaluso/NNP)
  ,/,
  (NP D./NNP Zibar/NNP)
  ,/,
  (NP M./NNP Ruffini/NNP)
  ,/,
  (NP M./NNP Tornatore/NNP)
  ,/,
  “/VBZ
  (NP A/NNP survey/NN application/NN)
  (NP ma-/JJ chine/NN)
  learning/VBG
  (NP techniques/NNS)
  (NP optical/JJ networks/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1803.07976/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Nag', 'I. Macaluso', 'D. Zibar', 'M. Ruffini', 'M. Tornatore', 'A survey application', 'ma- chine', 'techniques', 'optical networks', '”', 'preprint arXiv:1803.07976']

>> Named Entities are: 
 [('GPE', 'Nag')] 

>> Stemming using Porter Stemmer: 
 [('Nag', 'nag'), (',', ','), ('I.', 'i.'), ('Macaluso', 'macaluso'), (',', ','), ('D.', 'd.'), ('Zibar', 'zibar'), (',', ','), ('M.', 'm.'), ('Ruffini', 'ruffini'), (',', ','), ('M.', 'm.'), ('Tornatore', 'tornator'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('application', 'applic'), ('ma-', 'ma-'), ('chine', 'chine'), ('learning', 'learn'), ('techniques', 'techniqu'), ('optical', 'optic'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.07976', 'arxiv:1803.07976'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nag', 'nag'), (',', ','), ('I.', 'i.'), ('Macaluso', 'macaluso'), (',', ','), ('D.', 'd.'), ('Zibar', 'zibar'), (',', ','), ('M.', 'm.'), ('Ruffini', 'ruffini'), (',', ','), ('M.', 'm.'), ('Tornatore', 'tornator'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('application', 'applic'), ('ma-', 'ma-'), ('chine', 'chine'), ('learning', 'learn'), ('techniques', 'techniqu'), ('optical', 'optic'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.07976', 'arxiv:1803.07976'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Nag', 'Nag'), (',', ','), ('I.', 'I.'), ('Macaluso', 'Macaluso'), (',', ','), ('D.', 'D.'), ('Zibar', 'Zibar'), (',', ','), ('M.', 'M.'), ('Ruffini', 'Ruffini'), (',', ','), ('M.', 'M.'), ('Tornatore', 'Tornatore'), (',', ','), ('“', '“'), ('A', 'A'), ('survey', 'survey'), ('application', 'application'), ('ma-', 'ma-'), ('chine', 'chine'), ('learning', 'learning'), ('techniques', 'technique'), ('optical', 'optical'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1803.07976', 'arXiv:1803.07976'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 712 =============================

[55] F. Tang, B. Mao, Z. M. Fadlullah, N. Kato, O. Akashi, T. Inoue, and K. Mizutani, “On removing routing protocol from future wireless networks: A real-time deep learning approach for intel- ligent traffic control,” IEEE Wireless Communications, vol. 


>> Tokens are: 
 ['[', '55', ']', 'F.', 'Tang', ',', 'B.', 'Mao', ',', 'Z.', 'M.', 'Fadlullah', ',', 'N.', 'Kato', ',', 'O.', 'Akashi', ',', 'T.', 'Inoue', ',', 'K.', 'Mizutani', ',', '“', 'On', 'removing', 'routing', 'protocol', 'future', 'wireless', 'networks', ':', 'A', 'real-time', 'deep', 'learning', 'approach', 'intel-', 'ligent', 'traffic', 'control', ',', '”', 'IEEE', 'Wireless', 'Communications', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '55'), ('55', ']'), (']', 'F.'), ('F.', 'Tang'), ('Tang', ','), (',', 'B.'), ('B.', 'Mao'), ('Mao', ','), (',', 'Z.'), ('Z.', 'M.'), ('M.', 'Fadlullah'), ('Fadlullah', ','), (',', 'N.'), ('N.', 'Kato'), ('Kato', ','), (',', 'O.'), ('O.', 'Akashi'), ('Akashi', ','), (',', 'T.'), ('T.', 'Inoue'), ('Inoue', ','), (',', 'K.'), ('K.', 'Mizutani'), ('Mizutani', ','), (',', '“'), ('“', 'On'), ('On', 'removing'), ('removing', 'routing'), ('routing', 'protocol'), ('protocol', 'future'), ('future', 'wireless'), ('wireless', 'networks'), ('networks', ':'), (':', 'A'), ('A', 'real-time'), ('real-time', 'deep'), ('deep', 'learning'), ('learning', 'approach'), ('approach', 'intel-'), ('intel-', 'ligent'), ('ligent', 'traffic'), ('traffic', 'control'), ('control', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Wireless'), ('Wireless', 'Communications'), ('Communications', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '55', ']'), ('55', ']', 'F.'), (']', 'F.', 'Tang'), ('F.', 'Tang', ','), ('Tang', ',', 'B.'), (',', 'B.', 'Mao'), ('B.', 'Mao', ','), ('Mao', ',', 'Z.'), (',', 'Z.', 'M.'), ('Z.', 'M.', 'Fadlullah'), ('M.', 'Fadlullah', ','), ('Fadlullah', ',', 'N.'), (',', 'N.', 'Kato'), ('N.', 'Kato', ','), ('Kato', ',', 'O.'), (',', 'O.', 'Akashi'), ('O.', 'Akashi', ','), ('Akashi', ',', 'T.'), (',', 'T.', 'Inoue'), ('T.', 'Inoue', ','), ('Inoue', ',', 'K.'), (',', 'K.', 'Mizutani'), ('K.', 'Mizutani', ','), ('Mizutani', ',', '“'), (',', '“', 'On'), ('“', 'On', 'removing'), ('On', 'removing', 'routing'), ('removing', 'routing', 'protocol'), ('routing', 'protocol', 'future'), ('protocol', 'future', 'wireless'), ('future', 'wireless', 'networks'), ('wireless', 'networks', ':'), ('networks', ':', 'A'), (':', 'A', 'real-time'), ('A', 'real-time', 'deep'), ('real-time', 'deep', 'learning'), ('deep', 'learning', 'approach'), ('learning', 'approach', 'intel-'), ('approach', 'intel-', 'ligent'), ('intel-', 'ligent', 'traffic'), ('ligent', 'traffic', 'control'), ('traffic', 'control', ','), ('control', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Wireless'), ('IEEE', 'Wireless', 'Communications'), ('Wireless', 'Communications', ','), ('Communications', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('55', 'CD'), (']', 'JJ'), ('F.', 'NNP'), ('Tang', 'NNP'), (',', ','), ('B.', 'NNP'), ('Mao', 'NNP'), (',', ','), ('Z.', 'NNP'), ('M.', 'NNP'), ('Fadlullah', 'NNP'), (',', ','), ('N.', 'NNP'), ('Kato', 'NNP'), (',', ','), ('O.', 'NNP'), ('Akashi', 'NNP'), (',', ','), ('T.', 'NNP'), ('Inoue', 'NNP'), (',', ','), ('K.', 'NNP'), ('Mizutani', 'NNP'), (',', ','), ('“', 'NNP'), ('On', 'IN'), ('removing', 'VBG'), ('routing', 'VBG'), ('protocol', 'JJ'), ('future', 'NN'), ('wireless', 'NN'), ('networks', 'NNS'), (':', ':'), ('A', 'DT'), ('real-time', 'JJ'), ('deep', 'NN'), ('learning', 'VBG'), ('approach', 'JJ'), ('intel-', 'JJ'), ('ligent', 'NN'), ('traffic', 'NN'), ('control', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  55/CD
  (NP ]/JJ F./NNP Tang/NNP)
  ,/,
  (NP B./NNP Mao/NNP)
  ,/,
  (NP Z./NNP M./NNP Fadlullah/NNP)
  ,/,
  (NP N./NNP Kato/NNP)
  ,/,
  (NP O./NNP Akashi/NNP)
  ,/,
  (NP T./NNP Inoue/NNP)
  ,/,
  (NP K./NNP Mizutani/NNP)
  ,/,
  (NP “/NNP)
  On/IN
  removing/VBG
  routing/VBG
  (NP protocol/JJ future/NN wireless/NN networks/NNS)
  :/:
  (NP A/DT real-time/JJ deep/NN)
  learning/VBG
  (NP approach/JJ intel-/JJ ligent/NN traffic/NN control/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Wireless/NNP Communications/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] F. Tang', 'B. Mao', 'Z. M. Fadlullah', 'N. Kato', 'O. Akashi', 'T. Inoue', 'K. Mizutani', '“', 'protocol future wireless networks', 'A real-time deep', 'approach intel- ligent traffic control', '” IEEE Wireless Communications', 'vol']

>> Named Entities are: 
 [('PERSON', 'Tang'), ('ORGANIZATION', 'Wireless Communications')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('F.', 'f.'), ('Tang', 'tang'), (',', ','), ('B.', 'b.'), ('Mao', 'mao'), (',', ','), ('Z.', 'z.'), ('M.', 'm.'), ('Fadlullah', 'fadlullah'), (',', ','), ('N.', 'n.'), ('Kato', 'kato'), (',', ','), ('O.', 'o.'), ('Akashi', 'akashi'), (',', ','), ('T.', 't.'), ('Inoue', 'inou'), (',', ','), ('K.', 'k.'), ('Mizutani', 'mizutani'), (',', ','), ('“', '“'), ('On', 'on'), ('removing', 'remov'), ('routing', 'rout'), ('protocol', 'protocol'), ('future', 'futur'), ('wireless', 'wireless'), ('networks', 'network'), (':', ':'), ('A', 'a'), ('real-time', 'real-tim'), ('deep', 'deep'), ('learning', 'learn'), ('approach', 'approach'), ('intel-', 'intel-'), ('ligent', 'ligent'), ('traffic', 'traffic'), ('control', 'control'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'commun'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('F.', 'f.'), ('Tang', 'tang'), (',', ','), ('B.', 'b.'), ('Mao', 'mao'), (',', ','), ('Z.', 'z.'), ('M.', 'm.'), ('Fadlullah', 'fadlullah'), (',', ','), ('N.', 'n.'), ('Kato', 'kato'), (',', ','), ('O.', 'o.'), ('Akashi', 'akashi'), (',', ','), ('T.', 't.'), ('Inoue', 'inou'), (',', ','), ('K.', 'k.'), ('Mizutani', 'mizutani'), (',', ','), ('“', '“'), ('On', 'on'), ('removing', 'remov'), ('routing', 'rout'), ('protocol', 'protocol'), ('future', 'futur'), ('wireless', 'wireless'), ('networks', 'network'), (':', ':'), ('A', 'a'), ('real-time', 'real-tim'), ('deep', 'deep'), ('learning', 'learn'), ('approach', 'approach'), ('intel-', 'intel-'), ('ligent', 'ligent'), ('traffic', 'traffic'), ('control', 'control'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'communic'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('55', '55'), (']', ']'), ('F.', 'F.'), ('Tang', 'Tang'), (',', ','), ('B.', 'B.'), ('Mao', 'Mao'), (',', ','), ('Z.', 'Z.'), ('M.', 'M.'), ('Fadlullah', 'Fadlullah'), (',', ','), ('N.', 'N.'), ('Kato', 'Kato'), (',', ','), ('O.', 'O.'), ('Akashi', 'Akashi'), (',', ','), ('T.', 'T.'), ('Inoue', 'Inoue'), (',', ','), ('K.', 'K.'), ('Mizutani', 'Mizutani'), (',', ','), ('“', '“'), ('On', 'On'), ('removing', 'removing'), ('routing', 'routing'), ('protocol', 'protocol'), ('future', 'future'), ('wireless', 'wireless'), ('networks', 'network'), (':', ':'), ('A', 'A'), ('real-time', 'real-time'), ('deep', 'deep'), ('learning', 'learning'), ('approach', 'approach'), ('intel-', 'intel-'), ('ligent', 'ligent'), ('traffic', 'traffic'), ('control', 'control'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 713 =============================

25, no. 


>> Tokens are: 
 ['25', ',', '.']

>> Bigrams are: 
 [('25', ','), (',', '.')]

>> Trigrams are: 
 [('25', ',', '.')]

>> POS Tags are: 
 [('25', 'CD'), (',', ','), ('.', '.')]

 (S 25/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25', '25'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('25', '25'), (',', ','), ('.', '.')]



============================ Sentence 714 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 715 =============================

154–160, 2018. 


>> Tokens are: 
 ['154–160', ',', '2018', '.']

>> Bigrams are: 
 [('154–160', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('154–160', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('154–160', 'CD'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S 154–160/CD ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('154–160', '154–160'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('154–160', '154–160'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('154–160', '154–160'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 716 =============================

[56] T. T. Nguyen and G. Armitage, “A survey of techniques for internet traffic classification using machine learning,” IEEE Communications Surveys & Tutorials, vol. 


>> Tokens are: 
 ['[', '56', ']', 'T.', 'T.', 'Nguyen', 'G.', 'Armitage', ',', '“', 'A', 'survey', 'techniques', 'internet', 'traffic', 'classification', 'using', 'machine', 'learning', ',', '”', 'IEEE', 'Communications', 'Surveys', '&', 'Tutorials', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '56'), ('56', ']'), (']', 'T.'), ('T.', 'T.'), ('T.', 'Nguyen'), ('Nguyen', 'G.'), ('G.', 'Armitage'), ('Armitage', ','), (',', '“'), ('“', 'A'), ('A', 'survey'), ('survey', 'techniques'), ('techniques', 'internet'), ('internet', 'traffic'), ('traffic', 'classification'), ('classification', 'using'), ('using', 'machine'), ('machine', 'learning'), ('learning', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Surveys'), ('Surveys', '&'), ('&', 'Tutorials'), ('Tutorials', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '56', ']'), ('56', ']', 'T.'), (']', 'T.', 'T.'), ('T.', 'T.', 'Nguyen'), ('T.', 'Nguyen', 'G.'), ('Nguyen', 'G.', 'Armitage'), ('G.', 'Armitage', ','), ('Armitage', ',', '“'), (',', '“', 'A'), ('“', 'A', 'survey'), ('A', 'survey', 'techniques'), ('survey', 'techniques', 'internet'), ('techniques', 'internet', 'traffic'), ('internet', 'traffic', 'classification'), ('traffic', 'classification', 'using'), ('classification', 'using', 'machine'), ('using', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Surveys'), ('Communications', 'Surveys', '&'), ('Surveys', '&', 'Tutorials'), ('&', 'Tutorials', ','), ('Tutorials', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('56', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('T.', 'NNP'), ('Nguyen', 'NNP'), ('G.', 'NNP'), ('Armitage', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('survey', 'NN'), ('techniques', 'NNS'), ('internet', 'VBP'), ('traffic', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Surveys', 'NNP'), ('&', 'CC'), ('Tutorials', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  56/CD
  (NP ]/JJ T./NNP T./NNP Nguyen/NNP G./NNP Armitage/NNP)
  ,/,
  “/VBZ
  (NP A/NNP survey/NN techniques/NNS)
  internet/VBP
  (NP traffic/NN classification/NN)
  using/VBG
  (NP machine/NN learning/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Communications/NNP Surveys/NNP)
  &/CC
  (NP Tutorials/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] T. T. Nguyen G. Armitage', 'A survey techniques', 'traffic classification', 'machine learning', '” IEEE Communications Surveys', 'Tutorials', 'vol']

>> Named Entities are: 
 [('PERSON', 'Nguyen G. Armitage'), ('ORGANIZATION', 'IEEE Communications Surveys'), ('PERSON', 'Tutorials')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('T.', 't.'), ('T.', 't.'), ('Nguyen', 'nguyen'), ('G.', 'g.'), ('Armitage', 'armitag'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('techniques', 'techniqu'), ('internet', 'internet'), ('traffic', 'traffic'), ('classification', 'classif'), ('using', 'use'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Surveys', 'survey'), ('&', '&'), ('Tutorials', 'tutori'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('T.', 't.'), ('T.', 't.'), ('Nguyen', 'nguyen'), ('G.', 'g.'), ('Armitage', 'armitag'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('techniques', 'techniqu'), ('internet', 'internet'), ('traffic', 'traffic'), ('classification', 'classif'), ('using', 'use'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Surveys', 'survey'), ('&', '&'), ('Tutorials', 'tutori'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('56', '56'), (']', ']'), ('T.', 'T.'), ('T.', 'T.'), ('Nguyen', 'Nguyen'), ('G.', 'G.'), ('Armitage', 'Armitage'), (',', ','), ('“', '“'), ('A', 'A'), ('survey', 'survey'), ('techniques', 'technique'), ('internet', 'internet'), ('traffic', 'traffic'), ('classification', 'classification'), ('using', 'using'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Surveys', 'Surveys'), ('&', '&'), ('Tutorials', 'Tutorials'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 717 =============================

10, no. 


>> Tokens are: 
 ['10', ',', '.']

>> Bigrams are: 
 [('10', ','), (',', '.')]

>> Trigrams are: 
 [('10', ',', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('.', '.')]

 (S 10/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('.', '.')]



============================ Sentence 718 =============================

4, pp. 


>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 4/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 719 =============================

56–76, 2008. 


>> Tokens are: 
 ['56–76', ',', '2008', '.']

>> Bigrams are: 
 [('56–76', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('56–76', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('56–76', 'CD'), (',', ','), ('2008', 'CD'), ('.', '.')]

 (S 56–76/CD ,/, 2008/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('56–76', '56–76'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('56–76', '56–76'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('56–76', '56–76'), (',', ','), ('2008', '2008'), ('.', '.')]



============================ Sentence 720 =============================

[57] C. M. Bishop, Pattern recognition and machine learning. 


>> Tokens are: 
 ['[', '57', ']', 'C.', 'M.', 'Bishop', ',', 'Pattern', 'recognition', 'machine', 'learning', '.']

>> Bigrams are: 
 [('[', '57'), ('57', ']'), (']', 'C.'), ('C.', 'M.'), ('M.', 'Bishop'), ('Bishop', ','), (',', 'Pattern'), ('Pattern', 'recognition'), ('recognition', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('[', '57', ']'), ('57', ']', 'C.'), (']', 'C.', 'M.'), ('C.', 'M.', 'Bishop'), ('M.', 'Bishop', ','), ('Bishop', ',', 'Pattern'), (',', 'Pattern', 'recognition'), ('Pattern', 'recognition', 'machine'), ('recognition', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('57', 'CD'), (']', 'JJ'), ('C.', 'NNP'), ('M.', 'NNP'), ('Bishop', 'NNP'), (',', ','), ('Pattern', 'NNP'), ('recognition', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  [/RB
  57/CD
  (NP ]/JJ C./NNP M./NNP Bishop/NNP)
  ,/,
  (NP Pattern/NNP recognition/NN machine/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['] C. M. Bishop', 'Pattern recognition machine learning']

>> Named Entities are: 
 [('GPE', 'Pattern')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('57', '57'), (']', ']'), ('C.', 'c.'), ('M.', 'm.'), ('Bishop', 'bishop'), (',', ','), ('Pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('57', '57'), (']', ']'), ('C.', 'c.'), ('M.', 'm.'), ('Bishop', 'bishop'), (',', ','), ('Pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('57', '57'), (']', ']'), ('C.', 'C.'), ('M.', 'M.'), ('Bishop', 'Bishop'), (',', ','), ('Pattern', 'Pattern'), ('recognition', 'recognition'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 721 =============================

springer, 2006. 


>> Tokens are: 
 ['springer', ',', '2006', '.']

>> Bigrams are: 
 [('springer', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('springer', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('springer', 'NN'), (',', ','), ('2006', 'CD'), ('.', '.')]

 (S (NP springer/NN) ,/, 2006/CD ./.) 


>> Noun Phrases are: 
 ['springer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('springer', 'springer'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('springer', 'springer'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('springer', 'springer'), (',', ','), ('2006', '2006'), ('.', '.')]



============================ Sentence 722 =============================

19    [58] K. P. Murphy, Machine learning: a probabilistic perspective. 


>> Tokens are: 
 ['19', '[', '58', ']', 'K.', 'P.', 'Murphy', ',', 'Machine', 'learning', ':', 'probabilistic', 'perspective', '.']

>> Bigrams are: 
 [('19', '['), ('[', '58'), ('58', ']'), (']', 'K.'), ('K.', 'P.'), ('P.', 'Murphy'), ('Murphy', ','), (',', 'Machine'), ('Machine', 'learning'), ('learning', ':'), (':', 'probabilistic'), ('probabilistic', 'perspective'), ('perspective', '.')]

>> Trigrams are: 
 [('19', '[', '58'), ('[', '58', ']'), ('58', ']', 'K.'), (']', 'K.', 'P.'), ('K.', 'P.', 'Murphy'), ('P.', 'Murphy', ','), ('Murphy', ',', 'Machine'), (',', 'Machine', 'learning'), ('Machine', 'learning', ':'), ('learning', ':', 'probabilistic'), (':', 'probabilistic', 'perspective'), ('probabilistic', 'perspective', '.')]

>> POS Tags are: 
 [('19', 'CD'), ('[', 'JJ'), ('58', 'CD'), (']', 'JJ'), ('K.', 'NNP'), ('P.', 'NNP'), ('Murphy', 'NNP'), (',', ','), ('Machine', 'NNP'), ('learning', 'NN'), (':', ':'), ('probabilistic', 'JJ'), ('perspective', 'NN'), ('.', '.')]

 (S
  19/CD
  [/JJ
  58/CD
  (NP ]/JJ K./NNP P./NNP Murphy/NNP)
  ,/,
  (NP Machine/NNP learning/NN)
  :/:
  (NP probabilistic/JJ perspective/NN)
  ./.) 


>> Noun Phrases are: 
 ['] K. P. Murphy', 'Machine learning', 'probabilistic perspective']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), ('[', '['), ('58', '58'), (']', ']'), ('K.', 'k.'), ('P.', 'p.'), ('Murphy', 'murphi'), (',', ','), ('Machine', 'machin'), ('learning', 'learn'), (':', ':'), ('probabilistic', 'probabilist'), ('perspective', 'perspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), ('[', '['), ('58', '58'), (']', ']'), ('K.', 'k.'), ('P.', 'p.'), ('Murphy', 'murphi'), (',', ','), ('Machine', 'machin'), ('learning', 'learn'), (':', ':'), ('probabilistic', 'probabilist'), ('perspective', 'perspect'), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), ('[', '['), ('58', '58'), (']', ']'), ('K.', 'K.'), ('P.', 'P.'), ('Murphy', 'Murphy'), (',', ','), ('Machine', 'Machine'), ('learning', 'learning'), (':', ':'), ('probabilistic', 'probabilistic'), ('perspective', 'perspective'), ('.', '.')]



============================ Sentence 723 =============================

MIT press, 2012. 


>> Tokens are: 
 ['MIT', 'press', ',', '2012', '.']

>> Bigrams are: 
 [('MIT', 'press'), ('press', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('MIT', 'press', ','), ('press', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('press', 'NN'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S (NP MIT/NNP press/NN) ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 ['MIT press']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 724 =============================

[59] T. M. Cover and J. 


>> Tokens are: 
 ['[', '59', ']', 'T.', 'M.', 'Cover', 'J', '.']

>> Bigrams are: 
 [('[', '59'), ('59', ']'), (']', 'T.'), ('T.', 'M.'), ('M.', 'Cover'), ('Cover', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '59', ']'), ('59', ']', 'T.'), (']', 'T.', 'M.'), ('T.', 'M.', 'Cover'), ('M.', 'Cover', 'J'), ('Cover', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('59', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('M.', 'NNP'), ('Cover', 'NNP'), ('J', 'NNP'), ('.', '.')]

 (S [/RB 59/CD (NP ]/JJ T./NNP M./NNP Cover/NNP J/NNP) ./.) 


>> Noun Phrases are: 
 ['] T. M. Cover J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('59', '59'), (']', ']'), ('T.', 't.'), ('M.', 'm.'), ('Cover', 'cover'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('59', '59'), (']', ']'), ('T.', 't.'), ('M.', 'm.'), ('Cover', 'cover'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('59', '59'), (']', ']'), ('T.', 'T.'), ('M.', 'M.'), ('Cover', 'Cover'), ('J', 'J'), ('.', '.')]



============================ Sentence 725 =============================

A. Thomas, Elements of information theory. 


>> Tokens are: 
 ['A.', 'Thomas', ',', 'Elements', 'information', 'theory', '.']

>> Bigrams are: 
 [('A.', 'Thomas'), ('Thomas', ','), (',', 'Elements'), ('Elements', 'information'), ('information', 'theory'), ('theory', '.')]

>> Trigrams are: 
 [('A.', 'Thomas', ','), ('Thomas', ',', 'Elements'), (',', 'Elements', 'information'), ('Elements', 'information', 'theory'), ('information', 'theory', '.')]

>> POS Tags are: 
 [('A.', 'NN'), ('Thomas', 'NNP'), (',', ','), ('Elements', 'NNP'), ('information', 'NN'), ('theory', 'NN'), ('.', '.')]

 (S
  (NP A./NN Thomas/NNP)
  ,/,
  (NP Elements/NNP information/NN theory/NN)
  ./.) 


>> Noun Phrases are: 
 ['A. Thomas', 'Elements information theory']

>> Named Entities are: 
 [('PERSON', 'Thomas'), ('GPE', 'Elements')] 

>> Stemming using Porter Stemmer: 
 [('A.', 'a.'), ('Thomas', 'thoma'), (',', ','), ('Elements', 'element'), ('information', 'inform'), ('theory', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A.', 'a.'), ('Thomas', 'thoma'), (',', ','), ('Elements', 'element'), ('information', 'inform'), ('theory', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('A.', 'A.'), ('Thomas', 'Thomas'), (',', ','), ('Elements', 'Elements'), ('information', 'information'), ('theory', 'theory'), ('.', '.')]



============================ Sentence 726 =============================

John Wiley & Sons, 2012. 


>> Tokens are: 
 ['John', 'Wiley', '&', 'Sons', ',', '2012', '.']

>> Bigrams are: 
 [('John', 'Wiley'), ('Wiley', '&'), ('&', 'Sons'), ('Sons', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('John', 'Wiley', '&'), ('Wiley', '&', 'Sons'), ('&', 'Sons', ','), ('Sons', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('John', 'NNP'), ('Wiley', 'NNP'), ('&', 'CC'), ('Sons', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S (NP John/NNP Wiley/NNP) &/CC (NP Sons/NNP) ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 ['John Wiley', 'Sons']

>> Named Entities are: 
 [('PERSON', 'John'), ('PERSON', 'Wiley'), ('PERSON', 'Sons')] 

>> Stemming using Porter Stemmer: 
 [('John', 'john'), ('Wiley', 'wiley'), ('&', '&'), ('Sons', 'son'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('John', 'john'), ('Wiley', 'wiley'), ('&', '&'), ('Sons', 'son'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('John', 'John'), ('Wiley', 'Wiley'), ('&', '&'), ('Sons', 'Sons'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 727 =============================

[60] O. Simeone, “Introducing information measures via inference [lecture notes],” IEEE Signal Processing Magazine, vol. 


>> Tokens are: 
 ['[', '60', ']', 'O.', 'Simeone', ',', '“', 'Introducing', 'information', 'measures', 'via', 'inference', '[', 'lecture', 'notes', ']', ',', '”', 'IEEE', 'Signal', 'Processing', 'Magazine', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '60'), ('60', ']'), (']', 'O.'), ('O.', 'Simeone'), ('Simeone', ','), (',', '“'), ('“', 'Introducing'), ('Introducing', 'information'), ('information', 'measures'), ('measures', 'via'), ('via', 'inference'), ('inference', '['), ('[', 'lecture'), ('lecture', 'notes'), ('notes', ']'), (']', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Signal'), ('Signal', 'Processing'), ('Processing', 'Magazine'), ('Magazine', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '60', ']'), ('60', ']', 'O.'), (']', 'O.', 'Simeone'), ('O.', 'Simeone', ','), ('Simeone', ',', '“'), (',', '“', 'Introducing'), ('“', 'Introducing', 'information'), ('Introducing', 'information', 'measures'), ('information', 'measures', 'via'), ('measures', 'via', 'inference'), ('via', 'inference', '['), ('inference', '[', 'lecture'), ('[', 'lecture', 'notes'), ('lecture', 'notes', ']'), ('notes', ']', ','), (']', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Signal'), ('IEEE', 'Signal', 'Processing'), ('Signal', 'Processing', 'Magazine'), ('Processing', 'Magazine', ','), ('Magazine', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('60', 'CD'), (']', 'JJ'), ('O.', 'NNP'), ('Simeone', 'NNP'), (',', ','), ('“', 'NNP'), ('Introducing', 'NNP'), ('information', 'NN'), ('measures', 'NNS'), ('via', 'IN'), ('inference', 'NN'), ('[', 'JJ'), ('lecture', 'NN'), ('notes', 'NNS'), (']', 'VBP'), (',', ','), ('”', 'JJ'), ('IEEE', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('Magazine', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  60/CD
  (NP ]/JJ O./NNP Simeone/NNP)
  ,/,
  (NP “/NNP Introducing/NNP information/NN measures/NNS)
  via/IN
  (NP inference/NN)
  (NP [/JJ lecture/NN notes/NNS)
  ]/VBP
  ,/,
  (NP ”/JJ IEEE/NNP Signal/NNP Processing/NNP Magazine/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] O. Simeone', '“ Introducing information measures', 'inference', '[ lecture notes', '” IEEE Signal Processing Magazine', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Signal')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('“', '“'), ('Introducing', 'introduc'), ('information', 'inform'), ('measures', 'measur'), ('via', 'via'), ('inference', 'infer'), ('[', '['), ('lecture', 'lectur'), ('notes', 'note'), (']', ']'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), ('O.', 'o.'), ('Simeone', 'simeon'), (',', ','), ('“', '“'), ('Introducing', 'introduc'), ('information', 'inform'), ('measures', 'measur'), ('via', 'via'), ('inference', 'infer'), ('[', '['), ('lecture', 'lectur'), ('notes', 'note'), (']', ']'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Magazine', 'magazin'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('60', '60'), (']', ']'), ('O.', 'O.'), ('Simeone', 'Simeone'), (',', ','), ('“', '“'), ('Introducing', 'Introducing'), ('information', 'information'), ('measures', 'measure'), ('via', 'via'), ('inference', 'inference'), ('[', '['), ('lecture', 'lecture'), ('notes', 'note'), (']', ']'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('Magazine', 'Magazine'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 728 =============================

35, no. 


>> Tokens are: 
 ['35', ',', '.']

>> Bigrams are: 
 [('35', ','), (',', '.')]

>> Trigrams are: 
 [('35', ',', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('.', '.')]

 (S 35/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('.', '.')]



============================ Sentence 729 =============================

1, pp. 


>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 1/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 730 =============================

167–171, 2018. 


>> Tokens are: 
 ['167–171', ',', '2018', '.']

>> Bigrams are: 
 [('167–171', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('167–171', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('167–171', 'CD'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S 167–171/CD ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('167–171', '167–171'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('167–171', '167–171'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('167–171', '167–171'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 731 =============================

[61] Y. 


>> Tokens are: 
 ['[', '61', ']', 'Y', '.']

>> Bigrams are: 
 [('[', '61'), ('61', ']'), (']', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '61', ']'), ('61', ']', 'Y'), (']', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('61', 'CD'), (']', 'JJ'), ('Y', 'NNP'), ('.', '.')]

 (S [/RB 61/CD (NP ]/JJ Y/NNP) ./.) 


>> Noun Phrases are: 
 ['] Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('61', '61'), (']', ']'), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('61', '61'), (']', ']'), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('61', '61'), (']', ']'), ('Y', 'Y'), ('.', '.')]



============================ Sentence 732 =============================

Sun, P. Babu, and D. P. Palomar, “Majorization-minimization algorithms in signal processing, communications, and machine learning,” IEEE Transactions on Signal Processing, vol. 


>> Tokens are: 
 ['Sun', ',', 'P.', 'Babu', ',', 'D.', 'P.', 'Palomar', ',', '“', 'Majorization-minimization', 'algorithms', 'signal', 'processing', ',', 'communications', ',', 'machine', 'learning', ',', '”', 'IEEE', 'Transactions', 'Signal', 'Processing', ',', 'vol', '.']

>> Bigrams are: 
 [('Sun', ','), (',', 'P.'), ('P.', 'Babu'), ('Babu', ','), (',', 'D.'), ('D.', 'P.'), ('P.', 'Palomar'), ('Palomar', ','), (',', '“'), ('“', 'Majorization-minimization'), ('Majorization-minimization', 'algorithms'), ('algorithms', 'signal'), ('signal', 'processing'), ('processing', ','), (',', 'communications'), ('communications', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Sun', ',', 'P.'), (',', 'P.', 'Babu'), ('P.', 'Babu', ','), ('Babu', ',', 'D.'), (',', 'D.', 'P.'), ('D.', 'P.', 'Palomar'), ('P.', 'Palomar', ','), ('Palomar', ',', '“'), (',', '“', 'Majorization-minimization'), ('“', 'Majorization-minimization', 'algorithms'), ('Majorization-minimization', 'algorithms', 'signal'), ('algorithms', 'signal', 'processing'), ('signal', 'processing', ','), ('processing', ',', 'communications'), (',', 'communications', ','), ('communications', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Signal'), ('Transactions', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('Sun', 'NNP'), (',', ','), ('P.', 'NNP'), ('Babu', 'NNP'), (',', ','), ('D.', 'NNP'), ('P.', 'NNP'), ('Palomar', 'NNP'), (',', ','), ('“', 'NNP'), ('Majorization-minimization', 'NNP'), ('algorithms', 'IN'), ('signal', 'JJ'), ('processing', 'NN'), (',', ','), ('communications', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP Sun/NNP)
  ,/,
  (NP P./NNP Babu/NNP)
  ,/,
  (NP D./NNP P./NNP Palomar/NNP)
  ,/,
  (NP “/NNP Majorization-minimization/NNP)
  algorithms/IN
  (NP signal/JJ processing/NN)
  ,/,
  (NP communications/NNS)
  ,/,
  (NP machine/NN learning/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Transactions/NNP Signal/NNP Processing/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sun', 'P. Babu', 'D. P. Palomar', '“ Majorization-minimization', 'signal processing', 'communications', 'machine learning', '” IEEE Transactions Signal Processing', 'vol']

>> Named Entities are: 
 [('GPE', 'Sun'), ('PERSON', 'Babu')] 

>> Stemming using Porter Stemmer: 
 [('Sun', 'sun'), (',', ','), ('P.', 'p.'), ('Babu', 'babu'), (',', ','), ('D.', 'd.'), ('P.', 'p.'), ('Palomar', 'palomar'), (',', ','), ('“', '“'), ('Majorization-minimization', 'majorization-minim'), ('algorithms', 'algorithm'), ('signal', 'signal'), ('processing', 'process'), (',', ','), ('communications', 'commun'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sun', 'sun'), (',', ','), ('P.', 'p.'), ('Babu', 'babu'), (',', ','), ('D.', 'd.'), ('P.', 'p.'), ('Palomar', 'palomar'), (',', ','), ('“', '“'), ('Majorization-minimization', 'majorization-minim'), ('algorithms', 'algorithm'), ('signal', 'signal'), ('processing', 'process'), (',', ','), ('communications', 'communic'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Sun', 'Sun'), (',', ','), ('P.', 'P.'), ('Babu', 'Babu'), (',', ','), ('D.', 'D.'), ('P.', 'P.'), ('Palomar', 'Palomar'), (',', ','), ('“', '“'), ('Majorization-minimization', 'Majorization-minimization'), ('algorithms', 'algorithm'), ('signal', 'signal'), ('processing', 'processing'), (',', ','), ('communications', 'communication'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 733 =============================

65, no. 


>> Tokens are: 
 ['65', ',', '.']

>> Bigrams are: 
 [('65', ','), (',', '.')]

>> Trigrams are: 
 [('65', ',', '.')]

>> POS Tags are: 
 [('65', 'CD'), (',', ','), ('.', '.')]

 (S 65/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('65', '65'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('65', '65'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('65', '65'), (',', ','), ('.', '.')]



============================ Sentence 734 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 735 =============================

794–816, 2017. 


>> Tokens are: 
 ['794–816', ',', '2017', '.']

>> Bigrams are: 
 [('794–816', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('794–816', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('794–816', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 794–816/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('794–816', '794–816'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('794–816', '794–816'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('794–816', '794–816'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 736 =============================

[62] A. Mnih and K. Gregor, “Neural variational inference and learning in belief networks,” arXiv preprint arXiv:1402.0030, 2014. 


>> Tokens are: 
 ['[', '62', ']', 'A.', 'Mnih', 'K.', 'Gregor', ',', '“', 'Neural', 'variational', 'inference', 'learning', 'belief', 'networks', ',', '”', 'arXiv', 'preprint', 'arXiv:1402.0030', ',', '2014', '.']

>> Bigrams are: 
 [('[', '62'), ('62', ']'), (']', 'A.'), ('A.', 'Mnih'), ('Mnih', 'K.'), ('K.', 'Gregor'), ('Gregor', ','), (',', '“'), ('“', 'Neural'), ('Neural', 'variational'), ('variational', 'inference'), ('inference', 'learning'), ('learning', 'belief'), ('belief', 'networks'), ('networks', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1402.0030'), ('arXiv:1402.0030', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('[', '62', ']'), ('62', ']', 'A.'), (']', 'A.', 'Mnih'), ('A.', 'Mnih', 'K.'), ('Mnih', 'K.', 'Gregor'), ('K.', 'Gregor', ','), ('Gregor', ',', '“'), (',', '“', 'Neural'), ('“', 'Neural', 'variational'), ('Neural', 'variational', 'inference'), ('variational', 'inference', 'learning'), ('inference', 'learning', 'belief'), ('learning', 'belief', 'networks'), ('belief', 'networks', ','), ('networks', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1402.0030'), ('preprint', 'arXiv:1402.0030', ','), ('arXiv:1402.0030', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('62', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('Mnih', 'NNP'), ('K.', 'NNP'), ('Gregor', 'NNP'), (',', ','), ('“', 'NNP'), ('Neural', 'NNP'), ('variational', 'JJ'), ('inference', 'NN'), ('learning', 'VBG'), ('belief', 'JJ'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1402.0030', 'NN'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  [/RB
  62/CD
  (NP ]/JJ A./NNP Mnih/NNP K./NNP Gregor/NNP)
  ,/,
  (NP “/NNP Neural/NNP)
  (NP variational/JJ inference/NN)
  learning/VBG
  (NP belief/JJ networks/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1402.0030/NN)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['] A. Mnih K. Gregor', '“ Neural', 'variational inference', 'belief networks', '”', 'preprint arXiv:1402.0030']

>> Named Entities are: 
 [('GPE', 'Gregor')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('62', '62'), (']', ']'), ('A.', 'a.'), ('Mnih', 'mnih'), ('K.', 'k.'), ('Gregor', 'gregor'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('variational', 'variat'), ('inference', 'infer'), ('learning', 'learn'), ('belief', 'belief'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1402.0030', 'arxiv:1402.0030'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('62', '62'), (']', ']'), ('A.', 'a.'), ('Mnih', 'mnih'), ('K.', 'k.'), ('Gregor', 'gregor'), (',', ','), ('“', '“'), ('Neural', 'neural'), ('variational', 'variat'), ('inference', 'infer'), ('learning', 'learn'), ('belief', 'belief'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1402.0030', 'arxiv:1402.0030'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('62', '62'), (']', ']'), ('A.', 'A.'), ('Mnih', 'Mnih'), ('K.', 'K.'), ('Gregor', 'Gregor'), (',', ','), ('“', '“'), ('Neural', 'Neural'), ('variational', 'variational'), ('inference', 'inference'), ('learning', 'learning'), ('belief', 'belief'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1402.0030', 'arXiv:1402.0030'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 737 =============================

[63] H. V. Poor, An introduction to signal detection and estimation. 


>> Tokens are: 
 ['[', '63', ']', 'H.', 'V.', 'Poor', ',', 'An', 'introduction', 'signal', 'detection', 'estimation', '.']

>> Bigrams are: 
 [('[', '63'), ('63', ']'), (']', 'H.'), ('H.', 'V.'), ('V.', 'Poor'), ('Poor', ','), (',', 'An'), ('An', 'introduction'), ('introduction', 'signal'), ('signal', 'detection'), ('detection', 'estimation'), ('estimation', '.')]

>> Trigrams are: 
 [('[', '63', ']'), ('63', ']', 'H.'), (']', 'H.', 'V.'), ('H.', 'V.', 'Poor'), ('V.', 'Poor', ','), ('Poor', ',', 'An'), (',', 'An', 'introduction'), ('An', 'introduction', 'signal'), ('introduction', 'signal', 'detection'), ('signal', 'detection', 'estimation'), ('detection', 'estimation', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('63', 'CD'), (']', 'NNS'), ('H.', 'NNP'), ('V.', 'NNP'), ('Poor', 'NNP'), (',', ','), ('An', 'DT'), ('introduction', 'NN'), ('signal', 'JJ'), ('detection', 'NN'), ('estimation', 'NN'), ('.', '.')]

 (S
  [/RB
  63/CD
  (NP ]/NNS H./NNP V./NNP Poor/NNP)
  ,/,
  (NP An/DT introduction/NN)
  (NP signal/JJ detection/NN estimation/NN)
  ./.) 


>> Noun Phrases are: 
 ['] H. V. Poor', 'An introduction', 'signal detection estimation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('63', '63'), (']', ']'), ('H.', 'h.'), ('V.', 'v.'), ('Poor', 'poor'), (',', ','), ('An', 'an'), ('introduction', 'introduct'), ('signal', 'signal'), ('detection', 'detect'), ('estimation', 'estim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('63', '63'), (']', ']'), ('H.', 'h.'), ('V.', 'v.'), ('Poor', 'poor'), (',', ','), ('An', 'an'), ('introduction', 'introduct'), ('signal', 'signal'), ('detection', 'detect'), ('estimation', 'estim'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('63', '63'), (']', ']'), ('H.', 'H.'), ('V.', 'V.'), ('Poor', 'Poor'), (',', ','), ('An', 'An'), ('introduction', 'introduction'), ('signal', 'signal'), ('detection', 'detection'), ('estimation', 'estimation'), ('.', '.')]



============================ Sentence 738 =============================

Springer Science & Business Media, 2013. 


>> Tokens are: 
 ['Springer', 'Science', '&', 'Business', 'Media', ',', '2013', '.']

>> Bigrams are: 
 [('Springer', 'Science'), ('Science', '&'), ('&', 'Business'), ('Business', 'Media'), ('Media', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Springer', 'Science', '&'), ('Science', '&', 'Business'), ('&', 'Business', 'Media'), ('Business', 'Media', ','), ('Media', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Science', 'NNP'), ('&', 'CC'), ('Business', 'NNP'), ('Media', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Springer/NNP Science/NNP)
  &/CC
  (NP Business/NNP Media/NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Springer Science', 'Business Media']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('ORGANIZATION', 'Science'), ('ORGANIZATION', 'Business Media')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Science', 'scienc'), ('&', '&'), ('Business', 'busi'), ('Media', 'media'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Science', 'scienc'), ('&', '&'), ('Business', 'busi'), ('Media', 'media'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Science', 'Science'), ('&', '&'), ('Business', 'Business'), ('Media', 'Media'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 739 =============================

[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial networks,” arXiv preprint arXiv:1701.00160, 2016. 


>> Tokens are: 
 ['[', '64', ']', 'I.', 'Goodfellow', ',', '“', 'NIPS', '2016', 'tutorial', ':', 'Generative', 'adversarial', 'networks', ',', '”', 'arXiv', 'preprint', 'arXiv:1701.00160', ',', '2016', '.']

>> Bigrams are: 
 [('[', '64'), ('64', ']'), (']', 'I.'), ('I.', 'Goodfellow'), ('Goodfellow', ','), (',', '“'), ('“', 'NIPS'), ('NIPS', '2016'), ('2016', 'tutorial'), ('tutorial', ':'), (':', 'Generative'), ('Generative', 'adversarial'), ('adversarial', 'networks'), ('networks', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1701.00160'), ('arXiv:1701.00160', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('[', '64', ']'), ('64', ']', 'I.'), (']', 'I.', 'Goodfellow'), ('I.', 'Goodfellow', ','), ('Goodfellow', ',', '“'), (',', '“', 'NIPS'), ('“', 'NIPS', '2016'), ('NIPS', '2016', 'tutorial'), ('2016', 'tutorial', ':'), ('tutorial', ':', 'Generative'), (':', 'Generative', 'adversarial'), ('Generative', 'adversarial', 'networks'), ('adversarial', 'networks', ','), ('networks', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1701.00160'), ('preprint', 'arXiv:1701.00160', ','), ('arXiv:1701.00160', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('64', 'CD'), (']', 'JJ'), ('I.', 'NNP'), ('Goodfellow', 'NNP'), (',', ','), ('“', 'NNP'), ('NIPS', 'NNP'), ('2016', 'CD'), ('tutorial', 'NN'), (':', ':'), ('Generative', 'JJ'), ('adversarial', 'JJ'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1701.00160', 'NN'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  [/RB
  64/CD
  (NP ]/JJ I./NNP Goodfellow/NNP)
  ,/,
  (NP “/NNP NIPS/NNP)
  2016/CD
  (NP tutorial/NN)
  :/:
  (NP Generative/JJ adversarial/JJ networks/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1701.00160/NN)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['] I. Goodfellow', '“ NIPS', 'tutorial', 'Generative adversarial networks', '”', 'preprint arXiv:1701.00160']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('64', '64'), (']', ']'), ('I.', 'i.'), ('Goodfellow', 'goodfellow'), (',', ','), ('“', '“'), ('NIPS', 'nip'), ('2016', '2016'), ('tutorial', 'tutori'), (':', ':'), ('Generative', 'gener'), ('adversarial', 'adversari'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1701.00160', 'arxiv:1701.00160'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('64', '64'), (']', ']'), ('I.', 'i.'), ('Goodfellow', 'goodfellow'), (',', ','), ('“', '“'), ('NIPS', 'nip'), ('2016', '2016'), ('tutorial', 'tutori'), (':', ':'), ('Generative', 'generat'), ('adversarial', 'adversari'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1701.00160', 'arxiv:1701.00160'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('64', '64'), (']', ']'), ('I.', 'I.'), ('Goodfellow', 'Goodfellow'), (',', ','), ('“', '“'), ('NIPS', 'NIPS'), ('2016', '2016'), ('tutorial', 'tutorial'), (':', ':'), ('Generative', 'Generative'), ('adversarial', 'adversarial'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1701.00160', 'arXiv:1701.00160'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 740 =============================

[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. Bülow, D. Lavery, P. Bayvel, and L. Schmalen, “End-to-end deep learning of optical fiber communications,” arXiv preprint arXiv:1804.04097, 2018. 


>> Tokens are: 
 ['[', '65', ']', 'B.', 'Karanov', ',', 'M.', 'Chagnon', ',', 'F.', 'Thouin', ',', 'T.', 'A.', 'Eriksson', ',', 'H.', 'Bülow', ',', 'D.', 'Lavery', ',', 'P.', 'Bayvel', ',', 'L.', 'Schmalen', ',', '“', 'End-to-end', 'deep', 'learning', 'optical', 'fiber', 'communications', ',', '”', 'arXiv', 'preprint', 'arXiv:1804.04097', ',', '2018', '.']

>> Bigrams are: 
 [('[', '65'), ('65', ']'), (']', 'B.'), ('B.', 'Karanov'), ('Karanov', ','), (',', 'M.'), ('M.', 'Chagnon'), ('Chagnon', ','), (',', 'F.'), ('F.', 'Thouin'), ('Thouin', ','), (',', 'T.'), ('T.', 'A.'), ('A.', 'Eriksson'), ('Eriksson', ','), (',', 'H.'), ('H.', 'Bülow'), ('Bülow', ','), (',', 'D.'), ('D.', 'Lavery'), ('Lavery', ','), (',', 'P.'), ('P.', 'Bayvel'), ('Bayvel', ','), (',', 'L.'), ('L.', 'Schmalen'), ('Schmalen', ','), (',', '“'), ('“', 'End-to-end'), ('End-to-end', 'deep'), ('deep', 'learning'), ('learning', 'optical'), ('optical', 'fiber'), ('fiber', 'communications'), ('communications', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1804.04097'), ('arXiv:1804.04097', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '65', ']'), ('65', ']', 'B.'), (']', 'B.', 'Karanov'), ('B.', 'Karanov', ','), ('Karanov', ',', 'M.'), (',', 'M.', 'Chagnon'), ('M.', 'Chagnon', ','), ('Chagnon', ',', 'F.'), (',', 'F.', 'Thouin'), ('F.', 'Thouin', ','), ('Thouin', ',', 'T.'), (',', 'T.', 'A.'), ('T.', 'A.', 'Eriksson'), ('A.', 'Eriksson', ','), ('Eriksson', ',', 'H.'), (',', 'H.', 'Bülow'), ('H.', 'Bülow', ','), ('Bülow', ',', 'D.'), (',', 'D.', 'Lavery'), ('D.', 'Lavery', ','), ('Lavery', ',', 'P.'), (',', 'P.', 'Bayvel'), ('P.', 'Bayvel', ','), ('Bayvel', ',', 'L.'), (',', 'L.', 'Schmalen'), ('L.', 'Schmalen', ','), ('Schmalen', ',', '“'), (',', '“', 'End-to-end'), ('“', 'End-to-end', 'deep'), ('End-to-end', 'deep', 'learning'), ('deep', 'learning', 'optical'), ('learning', 'optical', 'fiber'), ('optical', 'fiber', 'communications'), ('fiber', 'communications', ','), ('communications', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1804.04097'), ('preprint', 'arXiv:1804.04097', ','), ('arXiv:1804.04097', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('65', 'CD'), (']', 'NNP'), ('B.', 'NNP'), ('Karanov', 'NNP'), (',', ','), ('M.', 'NNP'), ('Chagnon', 'NNP'), (',', ','), ('F.', 'NNP'), ('Thouin', 'NNP'), (',', ','), ('T.', 'NNP'), ('A.', 'NNP'), ('Eriksson', 'NNP'), (',', ','), ('H.', 'NNP'), ('Bülow', 'NNP'), (',', ','), ('D.', 'NNP'), ('Lavery', 'NNP'), (',', ','), ('P.', 'NNP'), ('Bayvel', 'NNP'), (',', ','), ('L.', 'NNP'), ('Schmalen', 'NNP'), (',', ','), ('“', 'NNP'), ('End-to-end', 'NNP'), ('deep', 'JJ'), ('learning', 'NN'), ('optical', 'JJ'), ('fiber', 'NN'), ('communications', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1804.04097', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  65/CD
  (NP ]/NNP B./NNP Karanov/NNP)
  ,/,
  (NP M./NNP Chagnon/NNP)
  ,/,
  (NP F./NNP Thouin/NNP)
  ,/,
  (NP T./NNP A./NNP Eriksson/NNP)
  ,/,
  (NP H./NNP Bülow/NNP)
  ,/,
  (NP D./NNP Lavery/NNP)
  ,/,
  (NP P./NNP Bayvel/NNP)
  ,/,
  (NP L./NNP Schmalen/NNP)
  ,/,
  (NP “/NNP End-to-end/NNP)
  (NP deep/JJ learning/NN)
  (NP optical/JJ fiber/NN communications/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1804.04097/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] B. Karanov', 'M. Chagnon', 'F. Thouin', 'T. A. Eriksson', 'H. Bülow', 'D. Lavery', 'P. Bayvel', 'L. Schmalen', '“ End-to-end', 'deep learning', 'optical fiber communications', '”', 'preprint arXiv:1804.04097']

>> Named Entities are: 
 [('PERSON', 'Karanov')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('65', '65'), (']', ']'), ('B.', 'b.'), ('Karanov', 'karanov'), (',', ','), ('M.', 'm.'), ('Chagnon', 'chagnon'), (',', ','), ('F.', 'f.'), ('Thouin', 'thouin'), (',', ','), ('T.', 't.'), ('A.', 'a.'), ('Eriksson', 'eriksson'), (',', ','), ('H.', 'h.'), ('Bülow', 'bülow'), (',', ','), ('D.', 'd.'), ('Lavery', 'laveri'), (',', ','), ('P.', 'p.'), ('Bayvel', 'bayvel'), (',', ','), ('L.', 'l.'), ('Schmalen', 'schmalen'), (',', ','), ('“', '“'), ('End-to-end', 'end-to-end'), ('deep', 'deep'), ('learning', 'learn'), ('optical', 'optic'), ('fiber', 'fiber'), ('communications', 'commun'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1804.04097', 'arxiv:1804.04097'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('65', '65'), (']', ']'), ('B.', 'b.'), ('Karanov', 'karanov'), (',', ','), ('M.', 'm.'), ('Chagnon', 'chagnon'), (',', ','), ('F.', 'f.'), ('Thouin', 'thouin'), (',', ','), ('T.', 't.'), ('A.', 'a.'), ('Eriksson', 'eriksson'), (',', ','), ('H.', 'h.'), ('Bülow', 'bülow'), (',', ','), ('D.', 'd.'), ('Lavery', 'laveri'), (',', ','), ('P.', 'p.'), ('Bayvel', 'bayvel'), (',', ','), ('L.', 'l.'), ('Schmalen', 'schmalen'), (',', ','), ('“', '“'), ('End-to-end', 'end-to-end'), ('deep', 'deep'), ('learning', 'learn'), ('optical', 'optic'), ('fiber', 'fiber'), ('communications', 'communic'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1804.04097', 'arxiv:1804.04097'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('65', '65'), (']', ']'), ('B.', 'B.'), ('Karanov', 'Karanov'), (',', ','), ('M.', 'M.'), ('Chagnon', 'Chagnon'), (',', ','), ('F.', 'F.'), ('Thouin', 'Thouin'), (',', ','), ('T.', 'T.'), ('A.', 'A.'), ('Eriksson', 'Eriksson'), (',', ','), ('H.', 'H.'), ('Bülow', 'Bülow'), (',', ','), ('D.', 'D.'), ('Lavery', 'Lavery'), (',', ','), ('P.', 'P.'), ('Bayvel', 'Bayvel'), (',', ','), ('L.', 'L.'), ('Schmalen', 'Schmalen'), (',', ','), ('“', '“'), ('End-to-end', 'End-to-end'), ('deep', 'deep'), ('learning', 'learning'), ('optical', 'optical'), ('fiber', 'fiber'), ('communications', 'communication'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1804.04097', 'arXiv:1804.04097'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 741 =============================

[66] H. Kim, Y. Jiang, S. Kannan, S. Oh, and P. Viswanath, “Deepcode: Feedback codes via deep learning,” arXiv preprint arXiv:1807.00801, 2018. 


>> Tokens are: 
 ['[', '66', ']', 'H.', 'Kim', ',', 'Y.', 'Jiang', ',', 'S.', 'Kannan', ',', 'S.', 'Oh', ',', 'P.', 'Viswanath', ',', '“', 'Deepcode', ':', 'Feedback', 'codes', 'via', 'deep', 'learning', ',', '”', 'arXiv', 'preprint', 'arXiv:1807.00801', ',', '2018', '.']

>> Bigrams are: 
 [('[', '66'), ('66', ']'), (']', 'H.'), ('H.', 'Kim'), ('Kim', ','), (',', 'Y.'), ('Y.', 'Jiang'), ('Jiang', ','), (',', 'S.'), ('S.', 'Kannan'), ('Kannan', ','), (',', 'S.'), ('S.', 'Oh'), ('Oh', ','), (',', 'P.'), ('P.', 'Viswanath'), ('Viswanath', ','), (',', '“'), ('“', 'Deepcode'), ('Deepcode', ':'), (':', 'Feedback'), ('Feedback', 'codes'), ('codes', 'via'), ('via', 'deep'), ('deep', 'learning'), ('learning', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1807.00801'), ('arXiv:1807.00801', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '66', ']'), ('66', ']', 'H.'), (']', 'H.', 'Kim'), ('H.', 'Kim', ','), ('Kim', ',', 'Y.'), (',', 'Y.', 'Jiang'), ('Y.', 'Jiang', ','), ('Jiang', ',', 'S.'), (',', 'S.', 'Kannan'), ('S.', 'Kannan', ','), ('Kannan', ',', 'S.'), (',', 'S.', 'Oh'), ('S.', 'Oh', ','), ('Oh', ',', 'P.'), (',', 'P.', 'Viswanath'), ('P.', 'Viswanath', ','), ('Viswanath', ',', '“'), (',', '“', 'Deepcode'), ('“', 'Deepcode', ':'), ('Deepcode', ':', 'Feedback'), (':', 'Feedback', 'codes'), ('Feedback', 'codes', 'via'), ('codes', 'via', 'deep'), ('via', 'deep', 'learning'), ('deep', 'learning', ','), ('learning', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1807.00801'), ('preprint', 'arXiv:1807.00801', ','), ('arXiv:1807.00801', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('66', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Jiang', 'NNP'), (',', ','), ('S.', 'NNP'), ('Kannan', 'NNP'), (',', ','), ('S.', 'NNP'), ('Oh', 'NNP'), (',', ','), ('P.', 'NNP'), ('Viswanath', 'NNP'), (',', ','), ('“', 'JJ'), ('Deepcode', 'NNP'), (':', ':'), ('Feedback', 'NNP'), ('codes', 'VBZ'), ('via', 'IN'), ('deep', 'JJ'), ('learning', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1807.00801', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  66/CD
  (NP ]/JJ H./NNP Kim/NNP)
  ,/,
  (NP Y./NNP Jiang/NNP)
  ,/,
  (NP S./NNP Kannan/NNP)
  ,/,
  (NP S./NNP Oh/NNP)
  ,/,
  (NP P./NNP Viswanath/NNP)
  ,/,
  (NP “/JJ Deepcode/NNP)
  :/:
  (NP Feedback/NNP)
  codes/VBZ
  via/IN
  (NP deep/JJ learning/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1807.00801/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] H. Kim', 'Y. Jiang', 'S. Kannan', 'S. Oh', 'P. Viswanath', '“ Deepcode', 'Feedback', 'deep learning', '”', 'preprint arXiv:1807.00801']

>> Named Entities are: 
 [('PERSON', 'Kim'), ('PERSON', 'Jiang'), ('PERSON', 'Kannan')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('66', '66'), (']', ']'), ('H.', 'h.'), ('Kim', 'kim'), (',', ','), ('Y.', 'y.'), ('Jiang', 'jiang'), (',', ','), ('S.', 's.'), ('Kannan', 'kannan'), (',', ','), ('S.', 's.'), ('Oh', 'oh'), (',', ','), ('P.', 'p.'), ('Viswanath', 'viswanath'), (',', ','), ('“', '“'), ('Deepcode', 'deepcod'), (':', ':'), ('Feedback', 'feedback'), ('codes', 'code'), ('via', 'via'), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00801', 'arxiv:1807.00801'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('66', '66'), (']', ']'), ('H.', 'h.'), ('Kim', 'kim'), (',', ','), ('Y.', 'y.'), ('Jiang', 'jiang'), (',', ','), ('S.', 's.'), ('Kannan', 'kannan'), (',', ','), ('S.', 's.'), ('Oh', 'oh'), (',', ','), ('P.', 'p.'), ('Viswanath', 'viswanath'), (',', ','), ('“', '“'), ('Deepcode', 'deepcod'), (':', ':'), ('Feedback', 'feedback'), ('codes', 'code'), ('via', 'via'), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00801', 'arxiv:1807.00801'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('66', '66'), (']', ']'), ('H.', 'H.'), ('Kim', 'Kim'), (',', ','), ('Y.', 'Y.'), ('Jiang', 'Jiang'), (',', ','), ('S.', 'S.'), ('Kannan', 'Kannan'), (',', ','), ('S.', 'S.'), ('Oh', 'Oh'), (',', ','), ('P.', 'P.'), ('Viswanath', 'Viswanath'), (',', ','), ('“', '“'), ('Deepcode', 'Deepcode'), (':', ':'), ('Feedback', 'Feedback'), ('codes', 'code'), ('via', 'via'), ('deep', 'deep'), ('learning', 'learning'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1807.00801', 'arXiv:1807.00801'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 742 =============================

[67] M. Kim, N. I. Kim, W. Lee, and D. H. Cho, “Deep learning- aided scma,” IEEE Communications Letters, vol. 


>> Tokens are: 
 ['[', '67', ']', 'M.', 'Kim', ',', 'N.', 'I.', 'Kim', ',', 'W.', 'Lee', ',', 'D.', 'H.', 'Cho', ',', '“', 'Deep', 'learning-', 'aided', 'scma', ',', '”', 'IEEE', 'Communications', 'Letters', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '67'), ('67', ']'), (']', 'M.'), ('M.', 'Kim'), ('Kim', ','), (',', 'N.'), ('N.', 'I.'), ('I.', 'Kim'), ('Kim', ','), (',', 'W.'), ('W.', 'Lee'), ('Lee', ','), (',', 'D.'), ('D.', 'H.'), ('H.', 'Cho'), ('Cho', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'learning-'), ('learning-', 'aided'), ('aided', 'scma'), ('scma', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Letters'), ('Letters', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '67', ']'), ('67', ']', 'M.'), (']', 'M.', 'Kim'), ('M.', 'Kim', ','), ('Kim', ',', 'N.'), (',', 'N.', 'I.'), ('N.', 'I.', 'Kim'), ('I.', 'Kim', ','), ('Kim', ',', 'W.'), (',', 'W.', 'Lee'), ('W.', 'Lee', ','), ('Lee', ',', 'D.'), (',', 'D.', 'H.'), ('D.', 'H.', 'Cho'), ('H.', 'Cho', ','), ('Cho', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'learning-'), ('Deep', 'learning-', 'aided'), ('learning-', 'aided', 'scma'), ('aided', 'scma', ','), ('scma', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Letters'), ('Communications', 'Letters', ','), ('Letters', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('67', 'CD'), (']', 'NNP'), ('M.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('N.', 'NNP'), ('I.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('W.', 'NNP'), ('Lee', 'NNP'), (',', ','), ('D.', 'NNP'), ('H.', 'NNP'), ('Cho', 'NNP'), (',', ','), ('“', 'JJ'), ('Deep', 'NNP'), ('learning-', 'NN'), ('aided', 'VBD'), ('scma', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Letters', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  67/CD
  (NP ]/NNP M./NNP Kim/NNP)
  ,/,
  (NP N./NNP I./NNP Kim/NNP)
  ,/,
  (NP W./NNP Lee/NNP)
  ,/,
  (NP D./NNP H./NNP Cho/NNP)
  ,/,
  (NP “/JJ Deep/NNP learning-/NN)
  aided/VBD
  (NP scma/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Communications/NNP Letters/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] M. Kim', 'N. I. Kim', 'W. Lee', 'D. H. Cho', '“ Deep learning-', 'scma', '” IEEE Communications Letters', 'vol']

>> Named Entities are: 
 [('PERSON', 'Kim'), ('PERSON', 'Kim'), ('PERSON', 'Lee'), ('ORGANIZATION', 'IEEE Communications Letters')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('67', '67'), (']', ']'), ('M.', 'm.'), ('Kim', 'kim'), (',', ','), ('N.', 'n.'), ('I.', 'i.'), ('Kim', 'kim'), (',', ','), ('W.', 'w.'), ('Lee', 'lee'), (',', ','), ('D.', 'd.'), ('H.', 'h.'), ('Cho', 'cho'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning-', 'learning-'), ('aided', 'aid'), ('scma', 'scma'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Letters', 'letter'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('67', '67'), (']', ']'), ('M.', 'm.'), ('Kim', 'kim'), (',', ','), ('N.', 'n.'), ('I.', 'i.'), ('Kim', 'kim'), (',', ','), ('W.', 'w.'), ('Lee', 'lee'), (',', ','), ('D.', 'd.'), ('H.', 'h.'), ('Cho', 'cho'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning-', 'learning-'), ('aided', 'aid'), ('scma', 'scma'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Letters', 'letter'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('67', '67'), (']', ']'), ('M.', 'M.'), ('Kim', 'Kim'), (',', ','), ('N.', 'N.'), ('I.', 'I.'), ('Kim', 'Kim'), (',', ','), ('W.', 'W.'), ('Lee', 'Lee'), (',', ','), ('D.', 'D.'), ('H.', 'H.'), ('Cho', 'Cho'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('learning-', 'learning-'), ('aided', 'aided'), ('scma', 'scma'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Letters', 'Letters'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 743 =============================

22, no. 


>> Tokens are: 
 ['22', ',', '.']

>> Bigrams are: 
 [('22', ','), (',', '.')]

>> Trigrams are: 
 [('22', ',', '.')]

>> POS Tags are: 
 [('22', 'CD'), (',', ','), ('.', '.')]

 (S 22/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), (',', ','), ('.', '.')]



============================ Sentence 744 =============================

4, pp. 


>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 4/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 745 =============================

720–723, April 2018. 


>> Tokens are: 
 ['720–723', ',', 'April', '2018', '.']

>> Bigrams are: 
 [('720–723', ','), (',', 'April'), ('April', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('720–723', ',', 'April'), (',', 'April', '2018'), ('April', '2018', '.')]

>> POS Tags are: 
 [('720–723', 'CD'), (',', ','), ('April', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S 720–723/CD ,/, (NP April/NNP) 2018/CD ./.) 


>> Noun Phrases are: 
 ['April']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('720–723', '720–723'), (',', ','), ('April', 'april'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('720–723', '720–723'), (',', ','), ('April', 'april'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('720–723', '720–723'), (',', ','), ('April', 'April'), ('2018', '2018'), ('.', '.')]



============================ Sentence 746 =============================

[68] E. Bourtsoulatze, D. Burth Kurka, and D. Gunduz, “Deep Joint Source-Channel Coding for Wireless Image Transmission,” ArXiv e-prints, Sep. 2018. 


>> Tokens are: 
 ['[', '68', ']', 'E.', 'Bourtsoulatze', ',', 'D.', 'Burth', 'Kurka', ',', 'D.', 'Gunduz', ',', '“', 'Deep', 'Joint', 'Source-Channel', 'Coding', 'Wireless', 'Image', 'Transmission', ',', '”', 'ArXiv', 'e-prints', ',', 'Sep.', '2018', '.']

>> Bigrams are: 
 [('[', '68'), ('68', ']'), (']', 'E.'), ('E.', 'Bourtsoulatze'), ('Bourtsoulatze', ','), (',', 'D.'), ('D.', 'Burth'), ('Burth', 'Kurka'), ('Kurka', ','), (',', 'D.'), ('D.', 'Gunduz'), ('Gunduz', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'Joint'), ('Joint', 'Source-Channel'), ('Source-Channel', 'Coding'), ('Coding', 'Wireless'), ('Wireless', 'Image'), ('Image', 'Transmission'), ('Transmission', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Sep.'), ('Sep.', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '68', ']'), ('68', ']', 'E.'), (']', 'E.', 'Bourtsoulatze'), ('E.', 'Bourtsoulatze', ','), ('Bourtsoulatze', ',', 'D.'), (',', 'D.', 'Burth'), ('D.', 'Burth', 'Kurka'), ('Burth', 'Kurka', ','), ('Kurka', ',', 'D.'), (',', 'D.', 'Gunduz'), ('D.', 'Gunduz', ','), ('Gunduz', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'Joint'), ('Deep', 'Joint', 'Source-Channel'), ('Joint', 'Source-Channel', 'Coding'), ('Source-Channel', 'Coding', 'Wireless'), ('Coding', 'Wireless', 'Image'), ('Wireless', 'Image', 'Transmission'), ('Image', 'Transmission', ','), ('Transmission', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Sep.'), (',', 'Sep.', '2018'), ('Sep.', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('68', 'CD'), (']', 'NNP'), ('E.', 'NNP'), ('Bourtsoulatze', 'NNP'), (',', ','), ('D.', 'NNP'), ('Burth', 'NNP'), ('Kurka', 'NNP'), (',', ','), ('D.', 'NNP'), ('Gunduz', 'NNP'), (',', ','), ('“', 'NNP'), ('Deep', 'NNP'), ('Joint', 'NNP'), ('Source-Channel', 'NNP'), ('Coding', 'NNP'), ('Wireless', 'NNP'), ('Image', 'NNP'), ('Transmission', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Sep.', 'NNP'), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  68/CD
  (NP ]/NNP E./NNP Bourtsoulatze/NNP)
  ,/,
  (NP D./NNP Burth/NNP Kurka/NNP)
  ,/,
  (NP D./NNP Gunduz/NNP)
  ,/,
  (NP
    “/NNP
    Deep/NNP
    Joint/NNP
    Source-Channel/NNP
    Coding/NNP
    Wireless/NNP
    Image/NNP
    Transmission/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Sep./NNP)
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] E. Bourtsoulatze', 'D. Burth Kurka', 'D. Gunduz', '“ Deep Joint Source-Channel Coding Wireless Image Transmission', '” ArXiv e-prints', 'Sep.']

>> Named Entities are: 
 [('PERSON', 'Burth Kurka')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('68', '68'), (']', ']'), ('E.', 'e.'), ('Bourtsoulatze', 'bourtsoulatz'), (',', ','), ('D.', 'd.'), ('Burth', 'burth'), ('Kurka', 'kurka'), (',', ','), ('D.', 'd.'), ('Gunduz', 'gunduz'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Joint', 'joint'), ('Source-Channel', 'source-channel'), ('Coding', 'code'), ('Wireless', 'wireless'), ('Image', 'imag'), ('Transmission', 'transmiss'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Sep.', 'sep.'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('68', '68'), (']', ']'), ('E.', 'e.'), ('Bourtsoulatze', 'bourtsoulatz'), (',', ','), ('D.', 'd.'), ('Burth', 'burth'), ('Kurka', 'kurka'), (',', ','), ('D.', 'd.'), ('Gunduz', 'gunduz'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('Joint', 'joint'), ('Source-Channel', 'source-channel'), ('Coding', 'code'), ('Wireless', 'wireless'), ('Image', 'imag'), ('Transmission', 'transmiss'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Sep.', 'sep.'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('68', '68'), (']', ']'), ('E.', 'E.'), ('Bourtsoulatze', 'Bourtsoulatze'), (',', ','), ('D.', 'D.'), ('Burth', 'Burth'), ('Kurka', 'Kurka'), (',', ','), ('D.', 'D.'), ('Gunduz', 'Gunduz'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('Joint', 'Joint'), ('Source-Channel', 'Source-Channel'), ('Coding', 'Coding'), ('Wireless', 'Wireless'), ('Image', 'Image'), ('Transmission', 'Transmission'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Sep.', 'Sep.'), ('2018', '2018'), ('.', '.')]



============================ Sentence 747 =============================

[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive mimo csi feedback,” IEEE Wireless Communications Letters, 2018. 


>> Tokens are: 
 ['[', '69', ']', 'C.-K.', 'Wen', ',', 'W.-T.', 'Shih', ',', 'S.', 'Jin', ',', '“', 'Deep', 'learning', 'massive', 'mimo', 'csi', 'feedback', ',', '”', 'IEEE', 'Wireless', 'Communications', 'Letters', ',', '2018', '.']

>> Bigrams are: 
 [('[', '69'), ('69', ']'), (']', 'C.-K.'), ('C.-K.', 'Wen'), ('Wen', ','), (',', 'W.-T.'), ('W.-T.', 'Shih'), ('Shih', ','), (',', 'S.'), ('S.', 'Jin'), ('Jin', ','), (',', '“'), ('“', 'Deep'), ('Deep', 'learning'), ('learning', 'massive'), ('massive', 'mimo'), ('mimo', 'csi'), ('csi', 'feedback'), ('feedback', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Wireless'), ('Wireless', 'Communications'), ('Communications', 'Letters'), ('Letters', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '69', ']'), ('69', ']', 'C.-K.'), (']', 'C.-K.', 'Wen'), ('C.-K.', 'Wen', ','), ('Wen', ',', 'W.-T.'), (',', 'W.-T.', 'Shih'), ('W.-T.', 'Shih', ','), ('Shih', ',', 'S.'), (',', 'S.', 'Jin'), ('S.', 'Jin', ','), ('Jin', ',', '“'), (',', '“', 'Deep'), ('“', 'Deep', 'learning'), ('Deep', 'learning', 'massive'), ('learning', 'massive', 'mimo'), ('massive', 'mimo', 'csi'), ('mimo', 'csi', 'feedback'), ('csi', 'feedback', ','), ('feedback', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Wireless'), ('IEEE', 'Wireless', 'Communications'), ('Wireless', 'Communications', 'Letters'), ('Communications', 'Letters', ','), ('Letters', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('69', 'CD'), (']', 'JJ'), ('C.-K.', 'NNP'), ('Wen', 'NNP'), (',', ','), ('W.-T.', 'NNP'), ('Shih', 'NNP'), (',', ','), ('S.', 'NNP'), ('Jin', 'NNP'), (',', ','), ('“', 'NNP'), ('Deep', 'NNP'), ('learning', 'VBG'), ('massive', 'JJ'), ('mimo', 'NN'), ('csi', 'NN'), ('feedback', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), ('Letters', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  69/CD
  (NP ]/JJ C.-K./NNP Wen/NNP)
  ,/,
  (NP W.-T./NNP Shih/NNP)
  ,/,
  (NP S./NNP Jin/NNP)
  ,/,
  (NP “/NNP Deep/NNP)
  learning/VBG
  (NP massive/JJ mimo/NN csi/NN feedback/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Wireless/NNP Communications/NNP Letters/NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] C.-K. Wen', 'W.-T. Shih', 'S. Jin', '“ Deep', 'massive mimo csi feedback', '” IEEE Wireless Communications Letters']

>> Named Entities are: 
 [('ORGANIZATION', 'Wireless Communications Letters')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('69', '69'), (']', ']'), ('C.-K.', 'c.-k.'), ('Wen', 'wen'), (',', ','), ('W.-T.', 'w.-t.'), ('Shih', 'shih'), (',', ','), ('S.', 's.'), ('Jin', 'jin'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('massive', 'massiv'), ('mimo', 'mimo'), ('csi', 'csi'), ('feedback', 'feedback'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'commun'), ('Letters', 'letter'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('69', '69'), (']', ']'), ('C.-K.', 'c.-k.'), ('Wen', 'wen'), (',', ','), ('W.-T.', 'w.-t.'), ('Shih', 'shih'), (',', ','), ('S.', 's.'), ('Jin', 'jin'), (',', ','), ('“', '“'), ('Deep', 'deep'), ('learning', 'learn'), ('massive', 'massiv'), ('mimo', 'mimo'), ('csi', 'csi'), ('feedback', 'feedback'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'communic'), ('Letters', 'letter'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('69', '69'), (']', ']'), ('C.-K.', 'C.-K.'), ('Wen', 'Wen'), (',', ','), ('W.-T.', 'W.-T.'), ('Shih', 'Shih'), (',', ','), ('S.', 'S.'), ('Jin', 'Jin'), (',', ','), ('“', '“'), ('Deep', 'Deep'), ('learning', 'learning'), ('massive', 'massive'), ('mimo', 'mimo'), ('csi', 'csi'), ('feedback', 'feedback'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), ('Letters', 'Letters'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 748 =============================

[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor localization based on denoising autoencoder,” IEEE Access, vol. 


>> Tokens are: 
 ['[', '70', ']', 'C.', 'Xiao', ',', 'D.', 'Yang', ',', 'Z.', 'Chen', ',', 'G.', 'Tan', ',', '“', '3-d', 'ble', 'indoor', 'localization', 'based', 'denoising', 'autoencoder', ',', '”', 'IEEE', 'Access', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '70'), ('70', ']'), (']', 'C.'), ('C.', 'Xiao'), ('Xiao', ','), (',', 'D.'), ('D.', 'Yang'), ('Yang', ','), (',', 'Z.'), ('Z.', 'Chen'), ('Chen', ','), (',', 'G.'), ('G.', 'Tan'), ('Tan', ','), (',', '“'), ('“', '3-d'), ('3-d', 'ble'), ('ble', 'indoor'), ('indoor', 'localization'), ('localization', 'based'), ('based', 'denoising'), ('denoising', 'autoencoder'), ('autoencoder', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Access'), ('Access', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '70', ']'), ('70', ']', 'C.'), (']', 'C.', 'Xiao'), ('C.', 'Xiao', ','), ('Xiao', ',', 'D.'), (',', 'D.', 'Yang'), ('D.', 'Yang', ','), ('Yang', ',', 'Z.'), (',', 'Z.', 'Chen'), ('Z.', 'Chen', ','), ('Chen', ',', 'G.'), (',', 'G.', 'Tan'), ('G.', 'Tan', ','), ('Tan', ',', '“'), (',', '“', '3-d'), ('“', '3-d', 'ble'), ('3-d', 'ble', 'indoor'), ('ble', 'indoor', 'localization'), ('indoor', 'localization', 'based'), ('localization', 'based', 'denoising'), ('based', 'denoising', 'autoencoder'), ('denoising', 'autoencoder', ','), ('autoencoder', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Access'), ('IEEE', 'Access', ','), ('Access', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('70', 'CD'), (']', 'JJ'), ('C.', 'NNP'), ('Xiao', 'NNP'), (',', ','), ('D.', 'NNP'), ('Yang', 'NNP'), (',', ','), ('Z.', 'NNP'), ('Chen', 'NNP'), (',', ','), ('G.', 'NNP'), ('Tan', 'NNP'), (',', ','), ('“', 'NNP'), ('3-d', 'NNP'), ('ble', 'JJ'), ('indoor', 'NN'), ('localization', 'NN'), ('based', 'VBN'), ('denoising', 'VBG'), ('autoencoder', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Access', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  70/CD
  (NP ]/JJ C./NNP Xiao/NNP)
  ,/,
  (NP D./NNP Yang/NNP)
  ,/,
  (NP Z./NNP Chen/NNP)
  ,/,
  (NP G./NNP Tan/NNP)
  ,/,
  (NP “/NNP 3-d/NNP)
  (NP ble/JJ indoor/NN localization/NN)
  based/VBN
  denoising/VBG
  (NP autoencoder/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Access/NNP)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] C. Xiao', 'D. Yang', 'Z. Chen', 'G. Tan', '“ 3-d', 'ble indoor localization', 'autoencoder', '” IEEE Access', 'vol']

>> Named Entities are: 
 [('PERSON', 'Yang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('70', '70'), (']', ']'), ('C.', 'c.'), ('Xiao', 'xiao'), (',', ','), ('D.', 'd.'), ('Yang', 'yang'), (',', ','), ('Z.', 'z.'), ('Chen', 'chen'), (',', ','), ('G.', 'g.'), ('Tan', 'tan'), (',', ','), ('“', '“'), ('3-d', '3-d'), ('ble', 'ble'), ('indoor', 'indoor'), ('localization', 'local'), ('based', 'base'), ('denoising', 'denois'), ('autoencoder', 'autoencod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Access', 'access'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('70', '70'), (']', ']'), ('C.', 'c.'), ('Xiao', 'xiao'), (',', ','), ('D.', 'd.'), ('Yang', 'yang'), (',', ','), ('Z.', 'z.'), ('Chen', 'chen'), (',', ','), ('G.', 'g.'), ('Tan', 'tan'), (',', ','), ('“', '“'), ('3-d', '3-d'), ('ble', 'ble'), ('indoor', 'indoor'), ('localization', 'local'), ('based', 'base'), ('denoising', 'denois'), ('autoencoder', 'autoencod'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Access', 'access'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('70', '70'), (']', ']'), ('C.', 'C.'), ('Xiao', 'Xiao'), (',', ','), ('D.', 'D.'), ('Yang', 'Yang'), (',', ','), ('Z.', 'Z.'), ('Chen', 'Chen'), (',', ','), ('G.', 'G.'), ('Tan', 'Tan'), (',', ','), ('“', '“'), ('3-d', '3-d'), ('ble', 'ble'), ('indoor', 'indoor'), ('localization', 'localization'), ('based', 'based'), ('denoising', 'denoising'), ('autoencoder', 'autoencoder'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Access', 'Access'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 749 =============================

5, pp. 


>> Tokens are: 
 ['5', ',', 'pp', '.']

>> Bigrams are: 
 [('5', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('5', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 5/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 750 =============================

12 751–12 760, 2017. 


>> Tokens are: 
 ['12', '751–12', '760', ',', '2017', '.']

>> Bigrams are: 
 [('12', '751–12'), ('751–12', '760'), ('760', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('12', '751–12', '760'), ('751–12', '760', ','), ('760', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('12', 'CD'), ('751–12', 'CD'), ('760', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S 12/CD 751–12/CD 760/CD ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('751–12', '751–12'), ('760', '760'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('751–12', '751–12'), ('760', '760'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('751–12', '751–12'), ('760', '760'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 751 =============================

[71] T. J. O’Shea, T. Roy, and N. West, “Approximating the void: Learning stochastic channel models from observation with variational generative adversarial networks,” arXiv preprint arXiv:1805.06350, 2018. 


>> Tokens are: 
 ['[', '71', ']', 'T.', 'J.', 'O', '’', 'Shea', ',', 'T.', 'Roy', ',', 'N.', 'West', ',', '“', 'Approximating', 'void', ':', 'Learning', 'stochastic', 'channel', 'models', 'observation', 'variational', 'generative', 'adversarial', 'networks', ',', '”', 'arXiv', 'preprint', 'arXiv:1805.06350', ',', '2018', '.']

>> Bigrams are: 
 [('[', '71'), ('71', ']'), (']', 'T.'), ('T.', 'J.'), ('J.', 'O'), ('O', '’'), ('’', 'Shea'), ('Shea', ','), (',', 'T.'), ('T.', 'Roy'), ('Roy', ','), (',', 'N.'), ('N.', 'West'), ('West', ','), (',', '“'), ('“', 'Approximating'), ('Approximating', 'void'), ('void', ':'), (':', 'Learning'), ('Learning', 'stochastic'), ('stochastic', 'channel'), ('channel', 'models'), ('models', 'observation'), ('observation', 'variational'), ('variational', 'generative'), ('generative', 'adversarial'), ('adversarial', 'networks'), ('networks', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1805.06350'), ('arXiv:1805.06350', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '71', ']'), ('71', ']', 'T.'), (']', 'T.', 'J.'), ('T.', 'J.', 'O'), ('J.', 'O', '’'), ('O', '’', 'Shea'), ('’', 'Shea', ','), ('Shea', ',', 'T.'), (',', 'T.', 'Roy'), ('T.', 'Roy', ','), ('Roy', ',', 'N.'), (',', 'N.', 'West'), ('N.', 'West', ','), ('West', ',', '“'), (',', '“', 'Approximating'), ('“', 'Approximating', 'void'), ('Approximating', 'void', ':'), ('void', ':', 'Learning'), (':', 'Learning', 'stochastic'), ('Learning', 'stochastic', 'channel'), ('stochastic', 'channel', 'models'), ('channel', 'models', 'observation'), ('models', 'observation', 'variational'), ('observation', 'variational', 'generative'), ('variational', 'generative', 'adversarial'), ('generative', 'adversarial', 'networks'), ('adversarial', 'networks', ','), ('networks', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1805.06350'), ('preprint', 'arXiv:1805.06350', ','), ('arXiv:1805.06350', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('71', 'CD'), (']', 'JJ'), ('T.', 'NNP'), ('J.', 'NNP'), ('O', 'NNP'), ('’', 'NNP'), ('Shea', 'NNP'), (',', ','), ('T.', 'NNP'), ('Roy', 'NNP'), (',', ','), ('N.', 'NNP'), ('West', 'NNP'), (',', ','), ('“', 'NNP'), ('Approximating', 'NNP'), ('void', 'NN'), (':', ':'), ('Learning', 'NNP'), ('stochastic', 'JJ'), ('channel', 'NN'), ('models', 'NNS'), ('observation', 'VBP'), ('variational', 'JJ'), ('generative', 'JJ'), ('adversarial', 'JJ'), ('networks', 'NNS'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1805.06350', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  71/CD
  (NP ]/JJ T./NNP J./NNP O/NNP ’/NNP Shea/NNP)
  ,/,
  (NP T./NNP Roy/NNP)
  ,/,
  (NP N./NNP West/NNP)
  ,/,
  (NP “/NNP Approximating/NNP void/NN)
  :/:
  (NP Learning/NNP)
  (NP stochastic/JJ channel/NN models/NNS)
  observation/VBP
  (NP variational/JJ generative/JJ adversarial/JJ networks/NNS)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1805.06350/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] T. J. O ’ Shea', 'T. Roy', 'N. West', '“ Approximating void', 'Learning', 'stochastic channel models', 'variational generative adversarial networks', '”', 'preprint arXiv:1805.06350']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('71', '71'), (']', ']'), ('T.', 't.'), ('J.', 'j.'), ('O', 'o'), ('’', '’'), ('Shea', 'shea'), (',', ','), ('T.', 't.'), ('Roy', 'roy'), (',', ','), ('N.', 'n.'), ('West', 'west'), (',', ','), ('“', '“'), ('Approximating', 'approxim'), ('void', 'void'), (':', ':'), ('Learning', 'learn'), ('stochastic', 'stochast'), ('channel', 'channel'), ('models', 'model'), ('observation', 'observ'), ('variational', 'variat'), ('generative', 'gener'), ('adversarial', 'adversari'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1805.06350', 'arxiv:1805.06350'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('71', '71'), (']', ']'), ('T.', 't.'), ('J.', 'j.'), ('O', 'o'), ('’', '’'), ('Shea', 'shea'), (',', ','), ('T.', 't.'), ('Roy', 'roy'), (',', ','), ('N.', 'n.'), ('West', 'west'), (',', ','), ('“', '“'), ('Approximating', 'approxim'), ('void', 'void'), (':', ':'), ('Learning', 'learn'), ('stochastic', 'stochast'), ('channel', 'channel'), ('models', 'model'), ('observation', 'observ'), ('variational', 'variat'), ('generative', 'generat'), ('adversarial', 'adversari'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1805.06350', 'arxiv:1805.06350'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('71', '71'), (']', ']'), ('T.', 'T.'), ('J.', 'J.'), ('O', 'O'), ('’', '’'), ('Shea', 'Shea'), (',', ','), ('T.', 'T.'), ('Roy', 'Roy'), (',', ','), ('N.', 'N.'), ('West', 'West'), (',', ','), ('“', '“'), ('Approximating', 'Approximating'), ('void', 'void'), (':', ':'), ('Learning', 'Learning'), ('stochastic', 'stochastic'), ('channel', 'channel'), ('models', 'model'), ('observation', 'observation'), ('variational', 'variational'), ('generative', 'generative'), ('adversarial', 'adversarial'), ('networks', 'network'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1805.06350', 'arXiv:1805.06350'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 752 =============================

[72] H. Ye, G. Y. Li, B.-H. F. Juang, and K. Sivanesan, “Channel agnostic end-to-end learning based communication systems with conditional gan,” arXiv preprint arXiv:1807.00447, 2018. 


>> Tokens are: 
 ['[', '72', ']', 'H.', 'Ye', ',', 'G.', 'Y.', 'Li', ',', 'B.-H.', 'F.', 'Juang', ',', 'K.', 'Sivanesan', ',', '“', 'Channel', 'agnostic', 'end-to-end', 'learning', 'based', 'communication', 'systems', 'conditional', 'gan', ',', '”', 'arXiv', 'preprint', 'arXiv:1807.00447', ',', '2018', '.']

>> Bigrams are: 
 [('[', '72'), ('72', ']'), (']', 'H.'), ('H.', 'Ye'), ('Ye', ','), (',', 'G.'), ('G.', 'Y.'), ('Y.', 'Li'), ('Li', ','), (',', 'B.-H.'), ('B.-H.', 'F.'), ('F.', 'Juang'), ('Juang', ','), (',', 'K.'), ('K.', 'Sivanesan'), ('Sivanesan', ','), (',', '“'), ('“', 'Channel'), ('Channel', 'agnostic'), ('agnostic', 'end-to-end'), ('end-to-end', 'learning'), ('learning', 'based'), ('based', 'communication'), ('communication', 'systems'), ('systems', 'conditional'), ('conditional', 'gan'), ('gan', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1807.00447'), ('arXiv:1807.00447', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '72', ']'), ('72', ']', 'H.'), (']', 'H.', 'Ye'), ('H.', 'Ye', ','), ('Ye', ',', 'G.'), (',', 'G.', 'Y.'), ('G.', 'Y.', 'Li'), ('Y.', 'Li', ','), ('Li', ',', 'B.-H.'), (',', 'B.-H.', 'F.'), ('B.-H.', 'F.', 'Juang'), ('F.', 'Juang', ','), ('Juang', ',', 'K.'), (',', 'K.', 'Sivanesan'), ('K.', 'Sivanesan', ','), ('Sivanesan', ',', '“'), (',', '“', 'Channel'), ('“', 'Channel', 'agnostic'), ('Channel', 'agnostic', 'end-to-end'), ('agnostic', 'end-to-end', 'learning'), ('end-to-end', 'learning', 'based'), ('learning', 'based', 'communication'), ('based', 'communication', 'systems'), ('communication', 'systems', 'conditional'), ('systems', 'conditional', 'gan'), ('conditional', 'gan', ','), ('gan', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1807.00447'), ('preprint', 'arXiv:1807.00447', ','), ('arXiv:1807.00447', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('72', 'CD'), (']', 'JJ'), ('H.', 'NNP'), ('Ye', 'NNP'), (',', ','), ('G.', 'NNP'), ('Y.', 'NNP'), ('Li', 'NNP'), (',', ','), ('B.-H.', 'NNP'), ('F.', 'NNP'), ('Juang', 'NNP'), (',', ','), ('K.', 'NNP'), ('Sivanesan', 'NNP'), (',', ','), ('“', 'NNP'), ('Channel', 'NNP'), ('agnostic', 'JJ'), ('end-to-end', 'NN'), ('learning', 'NN'), ('based', 'VBN'), ('communication', 'NN'), ('systems', 'NNS'), ('conditional', 'JJ'), ('gan', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1807.00447', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  72/CD
  (NP ]/JJ H./NNP Ye/NNP)
  ,/,
  (NP G./NNP Y./NNP Li/NNP)
  ,/,
  (NP B.-H./NNP F./NNP Juang/NNP)
  ,/,
  (NP K./NNP Sivanesan/NNP)
  ,/,
  (NP “/NNP Channel/NNP)
  (NP agnostic/JJ end-to-end/NN learning/NN)
  based/VBN
  (NP communication/NN systems/NNS)
  (NP conditional/JJ gan/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1807.00447/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] H. Ye', 'G. Y. Li', 'B.-H. F. Juang', 'K. Sivanesan', '“ Channel', 'agnostic end-to-end learning', 'communication systems', 'conditional gan', '”', 'preprint arXiv:1807.00447']

>> Named Entities are: 
 [('PERSON', 'Juang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('72', '72'), (']', ']'), ('H.', 'h.'), ('Ye', 'ye'), (',', ','), ('G.', 'g.'), ('Y.', 'y.'), ('Li', 'li'), (',', ','), ('B.-H.', 'b.-h.'), ('F.', 'f.'), ('Juang', 'juang'), (',', ','), ('K.', 'k.'), ('Sivanesan', 'sivanesan'), (',', ','), ('“', '“'), ('Channel', 'channel'), ('agnostic', 'agnost'), ('end-to-end', 'end-to-end'), ('learning', 'learn'), ('based', 'base'), ('communication', 'commun'), ('systems', 'system'), ('conditional', 'condit'), ('gan', 'gan'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00447', 'arxiv:1807.00447'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('72', '72'), (']', ']'), ('H.', 'h.'), ('Ye', 'ye'), (',', ','), ('G.', 'g.'), ('Y.', 'y.'), ('Li', 'li'), (',', ','), ('B.-H.', 'b.-h.'), ('F.', 'f.'), ('Juang', 'juang'), (',', ','), ('K.', 'k.'), ('Sivanesan', 'sivanesan'), (',', ','), ('“', '“'), ('Channel', 'channel'), ('agnostic', 'agnost'), ('end-to-end', 'end-to-end'), ('learning', 'learn'), ('based', 'base'), ('communication', 'communic'), ('systems', 'system'), ('conditional', 'condit'), ('gan', 'gan'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1807.00447', 'arxiv:1807.00447'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('72', '72'), (']', ']'), ('H.', 'H.'), ('Ye', 'Ye'), (',', ','), ('G.', 'G.'), ('Y.', 'Y.'), ('Li', 'Li'), (',', ','), ('B.-H.', 'B.-H.'), ('F.', 'F.'), ('Juang', 'Juang'), (',', ','), ('K.', 'K.'), ('Sivanesan', 'Sivanesan'), (',', ','), ('“', '“'), ('Channel', 'Channel'), ('agnostic', 'agnostic'), ('end-to-end', 'end-to-end'), ('learning', 'learning'), ('based', 'based'), ('communication', 'communication'), ('systems', 'system'), ('conditional', 'conditional'), ('gan', 'gan'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1807.00447', 'arXiv:1807.00447'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 753 =============================

[73] F. Liang, C. Shen, W. Yu, and F. Wu, “Towards Optimal Power Control via Ensembling Deep Neural Networks,” ArXiv e-prints, Jul. 


>> Tokens are: 
 ['[', '73', ']', 'F.', 'Liang', ',', 'C.', 'Shen', ',', 'W.', 'Yu', ',', 'F.', 'Wu', ',', '“', 'Towards', 'Optimal', 'Power', 'Control', 'via', 'Ensembling', 'Deep', 'Neural', 'Networks', ',', '”', 'ArXiv', 'e-prints', ',', 'Jul', '.']

>> Bigrams are: 
 [('[', '73'), ('73', ']'), (']', 'F.'), ('F.', 'Liang'), ('Liang', ','), (',', 'C.'), ('C.', 'Shen'), ('Shen', ','), (',', 'W.'), ('W.', 'Yu'), ('Yu', ','), (',', 'F.'), ('F.', 'Wu'), ('Wu', ','), (',', '“'), ('“', 'Towards'), ('Towards', 'Optimal'), ('Optimal', 'Power'), ('Power', 'Control'), ('Control', 'via'), ('via', 'Ensembling'), ('Ensembling', 'Deep'), ('Deep', 'Neural'), ('Neural', 'Networks'), ('Networks', ','), (',', '”'), ('”', 'ArXiv'), ('ArXiv', 'e-prints'), ('e-prints', ','), (',', 'Jul'), ('Jul', '.')]

>> Trigrams are: 
 [('[', '73', ']'), ('73', ']', 'F.'), (']', 'F.', 'Liang'), ('F.', 'Liang', ','), ('Liang', ',', 'C.'), (',', 'C.', 'Shen'), ('C.', 'Shen', ','), ('Shen', ',', 'W.'), (',', 'W.', 'Yu'), ('W.', 'Yu', ','), ('Yu', ',', 'F.'), (',', 'F.', 'Wu'), ('F.', 'Wu', ','), ('Wu', ',', '“'), (',', '“', 'Towards'), ('“', 'Towards', 'Optimal'), ('Towards', 'Optimal', 'Power'), ('Optimal', 'Power', 'Control'), ('Power', 'Control', 'via'), ('Control', 'via', 'Ensembling'), ('via', 'Ensembling', 'Deep'), ('Ensembling', 'Deep', 'Neural'), ('Deep', 'Neural', 'Networks'), ('Neural', 'Networks', ','), ('Networks', ',', '”'), (',', '”', 'ArXiv'), ('”', 'ArXiv', 'e-prints'), ('ArXiv', 'e-prints', ','), ('e-prints', ',', 'Jul'), (',', 'Jul', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('73', 'CD'), (']', 'JJ'), ('F.', 'NNP'), ('Liang', 'NNP'), (',', ','), ('C.', 'NNP'), ('Shen', 'NNP'), (',', ','), ('W.', 'NNP'), ('Yu', 'NNP'), (',', ','), ('F.', 'NNP'), ('Wu', 'NNP'), (',', ','), ('“', 'NNP'), ('Towards', 'NNP'), ('Optimal', 'NNP'), ('Power', 'NNP'), ('Control', 'NNP'), ('via', 'IN'), ('Ensembling', 'NNP'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), (',', ','), ('”', 'NNP'), ('ArXiv', 'NNP'), ('e-prints', 'NNS'), (',', ','), ('Jul', 'NNP'), ('.', '.')]

 (S
  [/RB
  73/CD
  (NP ]/JJ F./NNP Liang/NNP)
  ,/,
  (NP C./NNP Shen/NNP)
  ,/,
  (NP W./NNP Yu/NNP)
  ,/,
  (NP F./NNP Wu/NNP)
  ,/,
  (NP “/NNP Towards/NNP Optimal/NNP Power/NNP Control/NNP)
  via/IN
  (NP Ensembling/NNP Deep/NNP Neural/NNP Networks/NNP)
  ,/,
  (NP ”/NNP ArXiv/NNP e-prints/NNS)
  ,/,
  (NP Jul/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] F. Liang', 'C. Shen', 'W. Yu', 'F. Wu', '“ Towards Optimal Power Control', 'Ensembling Deep Neural Networks', '” ArXiv e-prints', 'Jul']

>> Named Entities are: 
 [('PERSON', 'Liang'), ('PERSON', 'Networks'), ('PERSON', 'Jul')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('73', '73'), (']', ']'), ('F.', 'f.'), ('Liang', 'liang'), (',', ','), ('C.', 'c.'), ('Shen', 'shen'), (',', ','), ('W.', 'w.'), ('Yu', 'yu'), (',', ','), ('F.', 'f.'), ('Wu', 'wu'), (',', ','), ('“', '“'), ('Towards', 'toward'), ('Optimal', 'optim'), ('Power', 'power'), ('Control', 'control'), ('via', 'via'), ('Ensembling', 'ensembl'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('73', '73'), (']', ']'), ('F.', 'f.'), ('Liang', 'liang'), (',', ','), ('C.', 'c.'), ('Shen', 'shen'), (',', ','), ('W.', 'w.'), ('Yu', 'yu'), (',', ','), ('F.', 'f.'), ('Wu', 'wu'), (',', ','), ('“', '“'), ('Towards', 'toward'), ('Optimal', 'optim'), ('Power', 'power'), ('Control', 'control'), ('via', 'via'), ('Ensembling', 'ensembl'), ('Deep', 'deep'), ('Neural', 'neural'), ('Networks', 'network'), (',', ','), ('”', '”'), ('ArXiv', 'arxiv'), ('e-prints', 'e-print'), (',', ','), ('Jul', 'jul'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('73', '73'), (']', ']'), ('F.', 'F.'), ('Liang', 'Liang'), (',', ','), ('C.', 'C.'), ('Shen', 'Shen'), (',', ','), ('W.', 'W.'), ('Yu', 'Yu'), (',', ','), ('F.', 'F.'), ('Wu', 'Wu'), (',', ','), ('“', '“'), ('Towards', 'Towards'), ('Optimal', 'Optimal'), ('Power', 'Power'), ('Control', 'Control'), ('via', 'via'), ('Ensembling', 'Ensembling'), ('Deep', 'Deep'), ('Neural', 'Neural'), ('Networks', 'Networks'), (',', ','), ('”', '”'), ('ArXiv', 'ArXiv'), ('e-prints', 'e-prints'), (',', ','), ('Jul', 'Jul'), ('.', '.')]



============================ Sentence 754 =============================

2018. 


>> Tokens are: 
 ['2018', '.']

>> Bigrams are: 
 [('2018', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2018', 'CD'), ('.', '.')]

 (S 2018/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('2018', '2018'), ('.', '.')]



============================ Sentence 755 =============================

[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse channel estimator,” IEEE Transactions on Signal Processing, 2018. 


>> Tokens are: 
 ['[', '74', ']', 'D.', 'Neumann', ',', 'T.', 'Wiese', ',', 'W.', 'Utschick', ',', '“', 'Learning', 'mmse', 'channel', 'estimator', ',', '”', 'IEEE', 'Transactions', 'Signal', 'Processing', ',', '2018', '.']

>> Bigrams are: 
 [('[', '74'), ('74', ']'), (']', 'D.'), ('D.', 'Neumann'), ('Neumann', ','), (',', 'T.'), ('T.', 'Wiese'), ('Wiese', ','), (',', 'W.'), ('W.', 'Utschick'), ('Utschick', ','), (',', '“'), ('“', 'Learning'), ('Learning', 'mmse'), ('mmse', 'channel'), ('channel', 'estimator'), ('estimator', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '74', ']'), ('74', ']', 'D.'), (']', 'D.', 'Neumann'), ('D.', 'Neumann', ','), ('Neumann', ',', 'T.'), (',', 'T.', 'Wiese'), ('T.', 'Wiese', ','), ('Wiese', ',', 'W.'), (',', 'W.', 'Utschick'), ('W.', 'Utschick', ','), ('Utschick', ',', '“'), (',', '“', 'Learning'), ('“', 'Learning', 'mmse'), ('Learning', 'mmse', 'channel'), ('mmse', 'channel', 'estimator'), ('channel', 'estimator', ','), ('estimator', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Signal'), ('Transactions', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('74', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Neumann', 'NNP'), (',', ','), ('T.', 'NNP'), ('Wiese', 'NNP'), (',', ','), ('W.', 'NNP'), ('Utschick', 'NNP'), (',', ','), ('“', 'NNP'), ('Learning', 'NNP'), ('mmse', 'JJ'), ('channel', 'NN'), ('estimator', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  74/CD
  (NP ]/JJ D./NNP Neumann/NNP)
  ,/,
  (NP T./NNP Wiese/NNP)
  ,/,
  (NP W./NNP Utschick/NNP)
  ,/,
  (NP “/NNP Learning/NNP)
  (NP mmse/JJ channel/NN estimator/NN)
  ,/,
  (NP ”/NNP IEEE/NNP Transactions/NNP Signal/NNP Processing/NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] D. Neumann', 'T. Wiese', 'W. Utschick', '“ Learning', 'mmse channel estimator', '” IEEE Transactions Signal Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('74', '74'), (']', ']'), ('D.', 'd.'), ('Neumann', 'neumann'), (',', ','), ('T.', 't.'), ('Wiese', 'wies'), (',', ','), ('W.', 'w.'), ('Utschick', 'utschick'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('mmse', 'mmse'), ('channel', 'channel'), ('estimator', 'estim'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('74', '74'), (']', ']'), ('D.', 'd.'), ('Neumann', 'neumann'), (',', ','), ('T.', 't.'), ('Wiese', 'wies'), (',', ','), ('W.', 'w.'), ('Utschick', 'utschick'), (',', ','), ('“', '“'), ('Learning', 'learn'), ('mmse', 'mmse'), ('channel', 'channel'), ('estimator', 'estim'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('74', '74'), (']', ']'), ('D.', 'D.'), ('Neumann', 'Neumann'), (',', ','), ('T.', 'T.'), ('Wiese', 'Wiese'), (',', ','), ('W.', 'W.'), ('Utschick', 'Utschick'), (',', ','), ('“', '“'), ('Learning', 'Learning'), ('mmse', 'mmse'), ('channel', 'channel'), ('estimator', 'estimator'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 756 =============================

[75] K. Davaslioglu and Y. E. Sagduyu, “Generative ad- versarial learning for spectrum sensing,” arXiv preprint arXiv:1804.00709, 2018. 


>> Tokens are: 
 ['[', '75', ']', 'K.', 'Davaslioglu', 'Y.', 'E.', 'Sagduyu', ',', '“', 'Generative', 'ad-', 'versarial', 'learning', 'spectrum', 'sensing', ',', '”', 'arXiv', 'preprint', 'arXiv:1804.00709', ',', '2018', '.']

>> Bigrams are: 
 [('[', '75'), ('75', ']'), (']', 'K.'), ('K.', 'Davaslioglu'), ('Davaslioglu', 'Y.'), ('Y.', 'E.'), ('E.', 'Sagduyu'), ('Sagduyu', ','), (',', '“'), ('“', 'Generative'), ('Generative', 'ad-'), ('ad-', 'versarial'), ('versarial', 'learning'), ('learning', 'spectrum'), ('spectrum', 'sensing'), ('sensing', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1804.00709'), ('arXiv:1804.00709', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('[', '75', ']'), ('75', ']', 'K.'), (']', 'K.', 'Davaslioglu'), ('K.', 'Davaslioglu', 'Y.'), ('Davaslioglu', 'Y.', 'E.'), ('Y.', 'E.', 'Sagduyu'), ('E.', 'Sagduyu', ','), ('Sagduyu', ',', '“'), (',', '“', 'Generative'), ('“', 'Generative', 'ad-'), ('Generative', 'ad-', 'versarial'), ('ad-', 'versarial', 'learning'), ('versarial', 'learning', 'spectrum'), ('learning', 'spectrum', 'sensing'), ('spectrum', 'sensing', ','), ('sensing', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1804.00709'), ('preprint', 'arXiv:1804.00709', ','), ('arXiv:1804.00709', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('75', 'CD'), (']', 'JJ'), ('K.', 'NNP'), ('Davaslioglu', 'NNP'), ('Y.', 'NNP'), ('E.', 'NNP'), ('Sagduyu', 'NNP'), (',', ','), ('“', 'NNP'), ('Generative', 'NNP'), ('ad-', 'JJ'), ('versarial', 'JJ'), ('learning', 'NN'), ('spectrum', 'NN'), ('sensing', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1804.00709', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  [/RB
  75/CD
  (NP ]/JJ K./NNP Davaslioglu/NNP Y./NNP E./NNP Sagduyu/NNP)
  ,/,
  (NP “/NNP Generative/NNP)
  (NP ad-/JJ versarial/JJ learning/NN spectrum/NN sensing/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1804.00709/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['] K. Davaslioglu Y. E. Sagduyu', '“ Generative', 'ad- versarial learning spectrum sensing', '”', 'preprint arXiv:1804.00709']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('75', '75'), (']', ']'), ('K.', 'k.'), ('Davaslioglu', 'davaslioglu'), ('Y.', 'y.'), ('E.', 'e.'), ('Sagduyu', 'sagduyu'), (',', ','), ('“', '“'), ('Generative', 'gener'), ('ad-', 'ad-'), ('versarial', 'versari'), ('learning', 'learn'), ('spectrum', 'spectrum'), ('sensing', 'sens'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1804.00709', 'arxiv:1804.00709'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('75', '75'), (']', ']'), ('K.', 'k.'), ('Davaslioglu', 'davaslioglu'), ('Y.', 'y.'), ('E.', 'e.'), ('Sagduyu', 'sagduyu'), (',', ','), ('“', '“'), ('Generative', 'generat'), ('ad-', 'ad-'), ('versarial', 'versari'), ('learning', 'learn'), ('spectrum', 'spectrum'), ('sensing', 'sens'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1804.00709', 'arxiv:1804.00709'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('75', '75'), (']', ']'), ('K.', 'K.'), ('Davaslioglu', 'Davaslioglu'), ('Y.', 'Y.'), ('E.', 'E.'), ('Sagduyu', 'Sagduyu'), (',', ','), ('“', '“'), ('Generative', 'Generative'), ('ad-', 'ad-'), ('versarial', 'versarial'), ('learning', 'learning'), ('spectrum', 'spectrum'), ('sensing', 'sensing'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1804.00709', 'arXiv:1804.00709'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 757 =============================

[76] A. Abdelnasser, E. Hossain, and D. I. Kim, “Clustering and resource allocation for dense femtocells in a two-tier cellular ofdma network,” IEEE Transactions on Wireless Communica- tions, vol. 


>> Tokens are: 
 ['[', '76', ']', 'A.', 'Abdelnasser', ',', 'E.', 'Hossain', ',', 'D.', 'I.', 'Kim', ',', '“', 'Clustering', 'resource', 'allocation', 'dense', 'femtocells', 'two-tier', 'cellular', 'ofdma', 'network', ',', '”', 'IEEE', 'Transactions', 'Wireless', 'Communica-', 'tions', ',', 'vol', '.']

>> Bigrams are: 
 [('[', '76'), ('76', ']'), (']', 'A.'), ('A.', 'Abdelnasser'), ('Abdelnasser', ','), (',', 'E.'), ('E.', 'Hossain'), ('Hossain', ','), (',', 'D.'), ('D.', 'I.'), ('I.', 'Kim'), ('Kim', ','), (',', '“'), ('“', 'Clustering'), ('Clustering', 'resource'), ('resource', 'allocation'), ('allocation', 'dense'), ('dense', 'femtocells'), ('femtocells', 'two-tier'), ('two-tier', 'cellular'), ('cellular', 'ofdma'), ('ofdma', 'network'), ('network', ','), (',', '”'), ('”', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Wireless'), ('Wireless', 'Communica-'), ('Communica-', 'tions'), ('tions', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('[', '76', ']'), ('76', ']', 'A.'), (']', 'A.', 'Abdelnasser'), ('A.', 'Abdelnasser', ','), ('Abdelnasser', ',', 'E.'), (',', 'E.', 'Hossain'), ('E.', 'Hossain', ','), ('Hossain', ',', 'D.'), (',', 'D.', 'I.'), ('D.', 'I.', 'Kim'), ('I.', 'Kim', ','), ('Kim', ',', '“'), (',', '“', 'Clustering'), ('“', 'Clustering', 'resource'), ('Clustering', 'resource', 'allocation'), ('resource', 'allocation', 'dense'), ('allocation', 'dense', 'femtocells'), ('dense', 'femtocells', 'two-tier'), ('femtocells', 'two-tier', 'cellular'), ('two-tier', 'cellular', 'ofdma'), ('cellular', 'ofdma', 'network'), ('ofdma', 'network', ','), ('network', ',', '”'), (',', '”', 'IEEE'), ('”', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Wireless'), ('Transactions', 'Wireless', 'Communica-'), ('Wireless', 'Communica-', 'tions'), ('Communica-', 'tions', ','), ('tions', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('76', 'CD'), (']', 'JJ'), ('A.', 'NNP'), ('Abdelnasser', 'NNP'), (',', ','), ('E.', 'NNP'), ('Hossain', 'NNP'), (',', ','), ('D.', 'NNP'), ('I.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('“', 'NNP'), ('Clustering', 'NNP'), ('resource', 'NN'), ('allocation', 'NN'), ('dense', 'NN'), ('femtocells', 'VBZ'), ('two-tier', 'JJ'), ('cellular', 'JJ'), ('ofdma', 'NN'), ('network', 'NN'), (',', ','), ('”', 'NNP'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Wireless', 'NNP'), ('Communica-', 'NNP'), ('tions', 'NNS'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  [/RB
  76/CD
  (NP ]/JJ A./NNP Abdelnasser/NNP)
  ,/,
  (NP E./NNP Hossain/NNP)
  ,/,
  (NP D./NNP I./NNP Kim/NNP)
  ,/,
  (NP “/NNP Clustering/NNP resource/NN allocation/NN dense/NN)
  femtocells/VBZ
  (NP two-tier/JJ cellular/JJ ofdma/NN network/NN)
  ,/,
  (NP
    ”/NNP
    IEEE/NNP
    Transactions/NNP
    Wireless/NNP
    Communica-/NNP
    tions/NNS)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['] A. Abdelnasser', 'E. Hossain', 'D. I. Kim', '“ Clustering resource allocation dense', 'two-tier cellular ofdma network', '” IEEE Transactions Wireless Communica- tions', 'vol']

>> Named Entities are: 
 [('PERSON', 'Kim')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('76', '76'), (']', ']'), ('A.', 'a.'), ('Abdelnasser', 'abdelnass'), (',', ','), ('E.', 'e.'), ('Hossain', 'hossain'), (',', ','), ('D.', 'd.'), ('I.', 'i.'), ('Kim', 'kim'), (',', ','), ('“', '“'), ('Clustering', 'cluster'), ('resource', 'resourc'), ('allocation', 'alloc'), ('dense', 'dens'), ('femtocells', 'femtocel'), ('two-tier', 'two-tier'), ('cellular', 'cellular'), ('ofdma', 'ofdma'), ('network', 'network'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Wireless', 'wireless'), ('Communica-', 'communica-'), ('tions', 'tion'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('76', '76'), (']', ']'), ('A.', 'a.'), ('Abdelnasser', 'abdelnass'), (',', ','), ('E.', 'e.'), ('Hossain', 'hossain'), (',', ','), ('D.', 'd.'), ('I.', 'i.'), ('Kim', 'kim'), (',', ','), ('“', '“'), ('Clustering', 'cluster'), ('resource', 'resourc'), ('allocation', 'alloc'), ('dense', 'dens'), ('femtocells', 'femtocel'), ('two-tier', 'two-tier'), ('cellular', 'cellular'), ('ofdma', 'ofdma'), ('network', 'network'), (',', ','), ('”', '”'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Wireless', 'wireless'), ('Communica-', 'communica-'), ('tions', 'tion'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('76', '76'), (']', ']'), ('A.', 'A.'), ('Abdelnasser', 'Abdelnasser'), (',', ','), ('E.', 'E.'), ('Hossain', 'Hossain'), (',', ','), ('D.', 'D.'), ('I.', 'I.'), ('Kim', 'Kim'), (',', ','), ('“', '“'), ('Clustering', 'Clustering'), ('resource', 'resource'), ('allocation', 'allocation'), ('dense', 'dense'), ('femtocells', 'femtocells'), ('two-tier', 'two-tier'), ('cellular', 'cellular'), ('ofdma', 'ofdma'), ('network', 'network'), (',', ','), ('”', '”'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Wireless', 'Wireless'), ('Communica-', 'Communica-'), ('tions', 'tions'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 758 =============================

13, no. 


>> Tokens are: 
 ['13', ',', '.']

>> Bigrams are: 
 [('13', ','), (',', '.')]

>> Trigrams are: 
 [('13', ',', '.')]

>> POS Tags are: 
 [('13', 'CD'), (',', ','), ('.', '.')]

 (S 13/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), (',', ','), ('.', '.')]



============================ Sentence 759 =============================

3, pp. 


>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 3/CD ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 760 =============================

1628–1641, 2014. 


>> Tokens are: 
 ['1628–1641', ',', '2014', '.']

>> Bigrams are: 
 [('1628–1641', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('1628–1641', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('1628–1641', 'CD'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S 1628–1641/CD ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1628–1641', '1628–1641'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1628–1641', '1628–1641'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('1628–1641', '1628–1641'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 761 =============================

[77] A. 


>> Tokens are: 
 ['[', '77', ']', 'A', '.']

>> Bigrams are: 
 [('[', '77'), ('77', ']'), (']', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '77', ']'), ('77', ']', 'A'), (']', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('77', 'CD'), (']', 'VBD'), ('A', 'DT'), ('.', '.')]

 (S [/RB 77/CD ]/VBD A/DT ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('77', '77'), (']', ']'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('77', '77'), (']', ']'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('77', '77'), (']', ']'), ('A', 'A'), ('.', '.')]



============================ Sentence 762 =============================

A. Abbasi and M. Younis, “A survey on clustering algo- rithms for wireless sensor networks,” Computer communica- tions, vol. 


>> Tokens are: 
 ['A.', 'Abbasi', 'M.', 'Younis', ',', '“', 'A', 'survey', 'clustering', 'algo-', 'rithms', 'wireless', 'sensor', 'networks', ',', '”', 'Computer', 'communica-', 'tions', ',', 'vol', '.']

>> Bigrams are: 
 [('A.', 'Abbasi'), ('Abbasi', 'M.'), ('M.', 'Younis'), ('Younis', ','), (',', '“'), ('“', 'A'), ('A', 'survey'), ('survey', 'clustering'), ('clustering', 'algo-'), ('algo-', 'rithms'), ('rithms', 'wireless'), ('wireless', 'sensor'), ('sensor', 'networks'), ('networks', ','), (',', '”'), ('”', 'Computer'), ('Computer', 'communica-'), ('communica-', 'tions'), ('tions', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('A.', 'Abbasi', 'M.'), ('Abbasi', 'M.', 'Younis'), ('M.', 'Younis', ','), ('Younis', ',', '“'), (',', '“', 'A'), ('“', 'A', 'survey'), ('A', 'survey', 'clustering'), ('survey', 'clustering', 'algo-'), ('clustering', 'algo-', 'rithms'), ('algo-', 'rithms', 'wireless'), ('rithms', 'wireless', 'sensor'), ('wireless', 'sensor', 'networks'), ('sensor', 'networks', ','), ('networks', ',', '”'), (',', '”', 'Computer'), ('”', 'Computer', 'communica-'), ('Computer', 'communica-', 'tions'), ('communica-', 'tions', ','), ('tions', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('A.', 'NN'), ('Abbasi', 'NNP'), ('M.', 'NNP'), ('Younis', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('survey', 'NN'), ('clustering', 'VBG'), ('algo-', 'JJ'), ('rithms', 'NN'), ('wireless', 'NN'), ('sensor', 'NN'), ('networks', 'NNS'), (',', ','), ('”', 'JJ'), ('Computer', 'NNP'), ('communica-', 'NN'), ('tions', 'NNS'), (',', ','), ('vol', 'NN'), ('.', '.')]

 (S
  (NP A./NN Abbasi/NNP M./NNP Younis/NNP)
  ,/,
  “/VBZ
  (NP A/NNP survey/NN)
  clustering/VBG
  (NP algo-/JJ rithms/NN wireless/NN sensor/NN networks/NNS)
  ,/,
  (NP ”/JJ Computer/NNP communica-/NN tions/NNS)
  ,/,
  (NP vol/NN)
  ./.) 


>> Noun Phrases are: 
 ['A. Abbasi M. Younis', 'A survey', 'algo- rithms wireless sensor networks', '” Computer communica- tions', 'vol']

>> Named Entities are: 
 [('PERSON', 'Abbasi M. Younis'), ('ORGANIZATION', 'Computer')] 

>> Stemming using Porter Stemmer: 
 [('A.', 'a.'), ('Abbasi', 'abbasi'), ('M.', 'm.'), ('Younis', 'youni'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('clustering', 'cluster'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Computer', 'comput'), ('communica-', 'communica-'), ('tions', 'tion'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A.', 'a.'), ('Abbasi', 'abbasi'), ('M.', 'm.'), ('Younis', 'youni'), (',', ','), ('“', '“'), ('A', 'a'), ('survey', 'survey'), ('clustering', 'cluster'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Computer', 'comput'), ('communica-', 'communica-'), ('tions', 'tion'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('A.', 'A.'), ('Abbasi', 'Abbasi'), ('M.', 'M.'), ('Younis', 'Younis'), (',', ','), ('“', '“'), ('A', 'A'), ('survey', 'survey'), ('clustering', 'clustering'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('networks', 'network'), (',', ','), ('”', '”'), ('Computer', 'Computer'), ('communica-', 'communica-'), ('tions', 'tions'), (',', ','), ('vol', 'vol'), ('.', '.')]



============================ Sentence 763 =============================

30, no. 


>> Tokens are: 
 ['30', ',', '.']

>> Bigrams are: 
 [('30', ','), (',', '.')]

>> Trigrams are: 
 [('30', ',', '.')]

>> POS Tags are: 
 [('30', 'CD'), (',', ','), ('.', '.')]

 (S 30/CD ,/, ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('30', '30'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('30', '30'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('30', '30'), (',', ','), ('.', '.')]



============================ Sentence 764 =============================

14-15, pp. 


>> Tokens are: 
 ['14-15', ',', 'pp', '.']

>> Bigrams are: 
 [('14-15', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('14-15', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('14-15', 'JJ'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S 14-15/JJ ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14-15', '14-15'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14-15', '14-15'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('14-15', '14-15'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 765 =============================

2826–2841, 2007. 


>> Tokens are: 
 ['2826–2841', ',', '2007', '.']

>> Bigrams are: 
 [('2826–2841', ','), (',', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('2826–2841', ',', '2007'), (',', '2007', '.')]

>> POS Tags are: 
 [('2826–2841', 'CD'), (',', ','), ('2007', 'CD'), ('.', '.')]

 (S 2826–2841/CD ,/, 2007/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2826–2841', '2826–2841'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2826–2841', '2826–2841'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('2826–2841', '2826–2841'), (',', ','), ('2007', '2007'), ('.', '.')]



============================ Sentence 766 =============================

[78] E. Abbe, A. S. Bandeira, and G. Hall, “Exact recovery in the stochastic block model,” arXiv preprint arXiv:1405.3267, 2014. 


>> Tokens are: 
 ['[', '78', ']', 'E.', 'Abbe', ',', 'A.', 'S.', 'Bandeira', ',', 'G.', 'Hall', ',', '“', 'Exact', 'recovery', 'stochastic', 'block', 'model', ',', '”', 'arXiv', 'preprint', 'arXiv:1405.3267', ',', '2014', '.']

>> Bigrams are: 
 [('[', '78'), ('78', ']'), (']', 'E.'), ('E.', 'Abbe'), ('Abbe', ','), (',', 'A.'), ('A.', 'S.'), ('S.', 'Bandeira'), ('Bandeira', ','), (',', 'G.'), ('G.', 'Hall'), ('Hall', ','), (',', '“'), ('“', 'Exact'), ('Exact', 'recovery'), ('recovery', 'stochastic'), ('stochastic', 'block'), ('block', 'model'), ('model', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1405.3267'), ('arXiv:1405.3267', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('[', '78', ']'), ('78', ']', 'E.'), (']', 'E.', 'Abbe'), ('E.', 'Abbe', ','), ('Abbe', ',', 'A.'), (',', 'A.', 'S.'), ('A.', 'S.', 'Bandeira'), ('S.', 'Bandeira', ','), ('Bandeira', ',', 'G.'), (',', 'G.', 'Hall'), ('G.', 'Hall', ','), ('Hall', ',', '“'), (',', '“', 'Exact'), ('“', 'Exact', 'recovery'), ('Exact', 'recovery', 'stochastic'), ('recovery', 'stochastic', 'block'), ('stochastic', 'block', 'model'), ('block', 'model', ','), ('model', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1405.3267'), ('preprint', 'arXiv:1405.3267', ','), ('arXiv:1405.3267', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('78', 'CD'), (']', 'NNP'), ('E.', 'NNP'), ('Abbe', 'NNP'), (',', ','), ('A.', 'NNP'), ('S.', 'NNP'), ('Bandeira', 'NNP'), (',', ','), ('G.', 'NNP'), ('Hall', 'NNP'), (',', ','), ('“', 'NNP'), ('Exact', 'NNP'), ('recovery', 'NN'), ('stochastic', 'JJ'), ('block', 'NN'), ('model', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1405.3267', 'NN'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  [/RB
  78/CD
  (NP ]/NNP E./NNP Abbe/NNP)
  ,/,
  (NP A./NNP S./NNP Bandeira/NNP)
  ,/,
  (NP G./NNP Hall/NNP)
  ,/,
  (NP “/NNP Exact/NNP recovery/NN)
  (NP stochastic/JJ block/NN model/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1405.3267/NN)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['] E. Abbe', 'A. S. Bandeira', 'G. Hall', '“ Exact recovery', 'stochastic block model', '”', 'preprint arXiv:1405.3267']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('78', '78'), (']', ']'), ('E.', 'e.'), ('Abbe', 'abb'), (',', ','), ('A.', 'a.'), ('S.', 's.'), ('Bandeira', 'bandeira'), (',', ','), ('G.', 'g.'), ('Hall', 'hall'), (',', ','), ('“', '“'), ('Exact', 'exact'), ('recovery', 'recoveri'), ('stochastic', 'stochast'), ('block', 'block'), ('model', 'model'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1405.3267', 'arxiv:1405.3267'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('78', '78'), (']', ']'), ('E.', 'e.'), ('Abbe', 'abb'), (',', ','), ('A.', 'a.'), ('S.', 's.'), ('Bandeira', 'bandeira'), (',', ','), ('G.', 'g.'), ('Hall', 'hall'), (',', ','), ('“', '“'), ('Exact', 'exact'), ('recovery', 'recoveri'), ('stochastic', 'stochast'), ('block', 'block'), ('model', 'model'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1405.3267', 'arxiv:1405.3267'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('78', '78'), (']', ']'), ('E.', 'E.'), ('Abbe', 'Abbe'), (',', ','), ('A.', 'A.'), ('S.', 'S.'), ('Bandeira', 'Bandeira'), (',', ','), ('G.', 'G.'), ('Hall', 'Hall'), (',', ','), ('“', '“'), ('Exact', 'Exact'), ('recovery', 'recovery'), ('stochastic', 'stochastic'), ('block', 'block'), ('model', 'model'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1405.3267', 'arXiv:1405.3267'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 767 =============================

[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank citation ranking: Bringing order to the web.” Stanford InfoLab, Tech. 


>> Tokens are: 
 ['[', '79', ']', 'L.', 'Page', ',', 'S.', 'Brin', ',', 'R.', 'Motwani', ',', 'T.', 'Winograd', ',', '“', 'The', 'PageRank', 'citation', 'ranking', ':', 'Bringing', 'order', 'web.', '”', 'Stanford', 'InfoLab', ',', 'Tech', '.']

>> Bigrams are: 
 [('[', '79'), ('79', ']'), (']', 'L.'), ('L.', 'Page'), ('Page', ','), (',', 'S.'), ('S.', 'Brin'), ('Brin', ','), (',', 'R.'), ('R.', 'Motwani'), ('Motwani', ','), (',', 'T.'), ('T.', 'Winograd'), ('Winograd', ','), (',', '“'), ('“', 'The'), ('The', 'PageRank'), ('PageRank', 'citation'), ('citation', 'ranking'), ('ranking', ':'), (':', 'Bringing'), ('Bringing', 'order'), ('order', 'web.'), ('web.', '”'), ('”', 'Stanford'), ('Stanford', 'InfoLab'), ('InfoLab', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('[', '79', ']'), ('79', ']', 'L.'), (']', 'L.', 'Page'), ('L.', 'Page', ','), ('Page', ',', 'S.'), (',', 'S.', 'Brin'), ('S.', 'Brin', ','), ('Brin', ',', 'R.'), (',', 'R.', 'Motwani'), ('R.', 'Motwani', ','), ('Motwani', ',', 'T.'), (',', 'T.', 'Winograd'), ('T.', 'Winograd', ','), ('Winograd', ',', '“'), (',', '“', 'The'), ('“', 'The', 'PageRank'), ('The', 'PageRank', 'citation'), ('PageRank', 'citation', 'ranking'), ('citation', 'ranking', ':'), ('ranking', ':', 'Bringing'), (':', 'Bringing', 'order'), ('Bringing', 'order', 'web.'), ('order', 'web.', '”'), ('web.', '”', 'Stanford'), ('”', 'Stanford', 'InfoLab'), ('Stanford', 'InfoLab', ','), ('InfoLab', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('79', 'CD'), (']', 'JJ'), ('L.', 'NNP'), ('Page', 'NNP'), (',', ','), ('S.', 'NNP'), ('Brin', 'NNP'), (',', ','), ('R.', 'NNP'), ('Motwani', 'NNP'), (',', ','), ('T.', 'NNP'), ('Winograd', 'NNP'), (',', ','), ('“', 'VBZ'), ('The', 'DT'), ('PageRank', 'NNP'), ('citation', 'NN'), ('ranking', 'NN'), (':', ':'), ('Bringing', 'JJ'), ('order', 'NN'), ('web.', 'NN'), ('”', 'NNP'), ('Stanford', 'NNP'), ('InfoLab', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

 (S
  [/RB
  79/CD
  (NP ]/JJ L./NNP Page/NNP)
  ,/,
  (NP S./NNP Brin/NNP)
  ,/,
  (NP R./NNP Motwani/NNP)
  ,/,
  (NP T./NNP Winograd/NNP)
  ,/,
  “/VBZ
  (NP The/DT PageRank/NNP citation/NN ranking/NN)
  :/:
  (NP Bringing/JJ order/NN web./NN ”/NNP Stanford/NNP InfoLab/NNP)
  ,/,
  (NP Tech/NNP)
  ./.) 


>> Noun Phrases are: 
 ['] L. Page', 'S. Brin', 'R. Motwani', 'T. Winograd', 'The PageRank citation ranking', 'Bringing order web. ” Stanford InfoLab', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Motwani'), ('ORGANIZATION', 'PageRank'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('L.', 'l.'), ('Page', 'page'), (',', ','), ('S.', 's.'), ('Brin', 'brin'), (',', ','), ('R.', 'r.'), ('Motwani', 'motwani'), (',', ','), ('T.', 't.'), ('Winograd', 'winograd'), (',', ','), ('“', '“'), ('The', 'the'), ('PageRank', 'pagerank'), ('citation', 'citat'), ('ranking', 'rank'), (':', ':'), ('Bringing', 'bring'), ('order', 'order'), ('web.', 'web.'), ('”', '”'), ('Stanford', 'stanford'), ('InfoLab', 'infolab'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('L.', 'l.'), ('Page', 'page'), (',', ','), ('S.', 's.'), ('Brin', 'brin'), (',', ','), ('R.', 'r.'), ('Motwani', 'motwani'), (',', ','), ('T.', 't.'), ('Winograd', 'winograd'), (',', ','), ('“', '“'), ('The', 'the'), ('PageRank', 'pagerank'), ('citation', 'citat'), ('ranking', 'rank'), (':', ':'), ('Bringing', 'bring'), ('order', 'order'), ('web.', 'web.'), ('”', '”'), ('Stanford', 'stanford'), ('InfoLab', 'infolab'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('79', '79'), (']', ']'), ('L.', 'L.'), ('Page', 'Page'), (',', ','), ('S.', 'S.'), ('Brin', 'Brin'), (',', ','), ('R.', 'R.'), ('Motwani', 'Motwani'), (',', ','), ('T.', 'T.'), ('Winograd', 'Winograd'), (',', ','), ('“', '“'), ('The', 'The'), ('PageRank', 'PageRank'), ('citation', 'citation'), ('ranking', 'ranking'), (':', ':'), ('Bringing', 'Bringing'), ('order', 'order'), ('web.', 'web.'), ('”', '”'), ('Stanford', 'Stanford'), ('InfoLab', 'InfoLab'), (',', ','), ('Tech', 'Tech'), ('.', '.')]



============================ Sentence 768 =============================

Rep., 1999. 


>> Tokens are: 
 ['Rep.', ',', '1999', '.']

>> Bigrams are: 
 [('Rep.', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('Rep.', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), (',', ','), ('1999', 'CD'), ('.', '.')]

 (S (NP Rep./NNP) ,/, 1999/CD ./.) 


>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), (',', ','), ('1999', '1999'), ('.', '.')]



============================ Sentence 769 =============================

[80] C. Karakus, Y. 


>> Tokens are: 
 ['[', '80', ']', 'C.', 'Karakus', ',', 'Y', '.']

>> Bigrams are: 
 [('[', '80'), ('80', ']'), (']', 'C.'), ('C.', 'Karakus'), ('Karakus', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '80', ']'), ('80', ']', 'C.'), (']', 'C.', 'Karakus'), ('C.', 'Karakus', ','), ('Karakus', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('80', 'CD'), (']', 'JJ'), ('C.', 'NNP'), ('Karakus', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

 (S [/RB 80/CD (NP ]/JJ C./NNP Karakus/NNP) ,/, (NP Y/NNP) ./.) 


>> Noun Phrases are: 
 ['] C. Karakus', 'Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('80', '80'), (']', ']'), ('C.', 'c.'), ('Karakus', 'karaku'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('80', '80'), (']', ']'), ('C.', 'c.'), ('Karakus', 'karakus'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('80', '80'), (']', ']'), ('C.', 'C.'), ('Karakus', 'Karakus'), (',', ','), ('Y', 'Y'), ('.', '.')]



============================ Sentence 770 =============================

Sun, S. Diggavi, and W. Yin, “Redundancy techniques for straggler mitigation in distributed optimization and learning,” arXiv preprint arXiv:1803.05397, 2018. 


>> Tokens are: 
 ['Sun', ',', 'S.', 'Diggavi', ',', 'W.', 'Yin', ',', '“', 'Redundancy', 'techniques', 'straggler', 'mitigation', 'distributed', 'optimization', 'learning', ',', '”', 'arXiv', 'preprint', 'arXiv:1803.05397', ',', '2018', '.']

>> Bigrams are: 
 [('Sun', ','), (',', 'S.'), ('S.', 'Diggavi'), ('Diggavi', ','), (',', 'W.'), ('W.', 'Yin'), ('Yin', ','), (',', '“'), ('“', 'Redundancy'), ('Redundancy', 'techniques'), ('techniques', 'straggler'), ('straggler', 'mitigation'), ('mitigation', 'distributed'), ('distributed', 'optimization'), ('optimization', 'learning'), ('learning', ','), (',', '”'), ('”', 'arXiv'), ('arXiv', 'preprint'), ('preprint', 'arXiv:1803.05397'), ('arXiv:1803.05397', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Sun', ',', 'S.'), (',', 'S.', 'Diggavi'), ('S.', 'Diggavi', ','), ('Diggavi', ',', 'W.'), (',', 'W.', 'Yin'), ('W.', 'Yin', ','), ('Yin', ',', '“'), (',', '“', 'Redundancy'), ('“', 'Redundancy', 'techniques'), ('Redundancy', 'techniques', 'straggler'), ('techniques', 'straggler', 'mitigation'), ('straggler', 'mitigation', 'distributed'), ('mitigation', 'distributed', 'optimization'), ('distributed', 'optimization', 'learning'), ('optimization', 'learning', ','), ('learning', ',', '”'), (',', '”', 'arXiv'), ('”', 'arXiv', 'preprint'), ('arXiv', 'preprint', 'arXiv:1803.05397'), ('preprint', 'arXiv:1803.05397', ','), ('arXiv:1803.05397', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Sun', 'NNP'), (',', ','), ('S.', 'NNP'), ('Diggavi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Yin', 'NNP'), (',', ','), ('“', 'NNP'), ('Redundancy', 'NNP'), ('techniques', 'VBZ'), ('straggler', 'JJR'), ('mitigation', 'NN'), ('distributed', 'VBN'), ('optimization', 'NN'), ('learning', 'NN'), (',', ','), ('”', 'NNP'), ('arXiv', 'VBZ'), ('preprint', 'NN'), ('arXiv:1803.05397', 'NN'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Sun/NNP)
  ,/,
  (NP S./NNP Diggavi/NNP)
  ,/,
  (NP W./NNP Yin/NNP)
  ,/,
  (NP “/NNP Redundancy/NNP)
  techniques/VBZ
  straggler/JJR
  (NP mitigation/NN)
  distributed/VBN
  (NP optimization/NN learning/NN)
  ,/,
  (NP ”/NNP)
  arXiv/VBZ
  (NP preprint/NN arXiv:1803.05397/NN)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Sun', 'S. Diggavi', 'W. Yin', '“ Redundancy', 'mitigation', 'optimization learning', '”', 'preprint arXiv:1803.05397']

>> Named Entities are: 
 [('GPE', 'Sun')] 

>> Stemming using Porter Stemmer: 
 [('Sun', 'sun'), (',', ','), ('S.', 's.'), ('Diggavi', 'diggavi'), (',', ','), ('W.', 'w.'), ('Yin', 'yin'), (',', ','), ('“', '“'), ('Redundancy', 'redund'), ('techniques', 'techniqu'), ('straggler', 'straggler'), ('mitigation', 'mitig'), ('distributed', 'distribut'), ('optimization', 'optim'), ('learning', 'learn'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.05397', 'arxiv:1803.05397'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sun', 'sun'), (',', ','), ('S.', 's.'), ('Diggavi', 'diggavi'), (',', ','), ('W.', 'w.'), ('Yin', 'yin'), (',', ','), ('“', '“'), ('Redundancy', 'redund'), ('techniques', 'techniqu'), ('straggler', 'straggler'), ('mitigation', 'mitig'), ('distributed', 'distribut'), ('optimization', 'optim'), ('learning', 'learn'), (',', ','), ('”', '”'), ('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1803.05397', 'arxiv:1803.05397'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Sun', 'Sun'), (',', ','), ('S.', 'S.'), ('Diggavi', 'Diggavi'), (',', ','), ('W.', 'W.'), ('Yin', 'Yin'), (',', ','), ('“', '“'), ('Redundancy', 'Redundancy'), ('techniques', 'technique'), ('straggler', 'straggler'), ('mitigation', 'mitigation'), ('distributed', 'distributed'), ('optimization', 'optimization'), ('learning', 'learning'), (',', ','), ('”', '”'), ('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1803.05397', 'arXiv:1803.05397'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 771 =============================

20   	I Introduction 	I-A What is Machine Learning? 


>> Tokens are: 
 ['20', 'I', 'Introduction', 'I-A', 'What', 'Machine', 'Learning', '?']

>> Bigrams are: 
 [('20', 'I'), ('I', 'Introduction'), ('Introduction', 'I-A'), ('I-A', 'What'), ('What', 'Machine'), ('Machine', 'Learning'), ('Learning', '?')]

>> Trigrams are: 
 [('20', 'I', 'Introduction'), ('I', 'Introduction', 'I-A'), ('Introduction', 'I-A', 'What'), ('I-A', 'What', 'Machine'), ('What', 'Machine', 'Learning'), ('Machine', 'Learning', '?')]

>> POS Tags are: 
 [('20', 'CD'), ('I', 'PRP'), ('Introduction', 'NNP'), ('I-A', 'NNP'), ('What', 'WP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('?', '.')]

 (S
  20/CD
  I/PRP
  (NP Introduction/NNP I-A/NNP)
  What/WP
  (NP Machine/NNP Learning/NNP)
  ?/.) 


>> Noun Phrases are: 
 ['Introduction I-A', 'Machine Learning']

>> Named Entities are: 
 [('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('20', '20'), ('I', 'i'), ('Introduction', 'introduct'), ('I-A', 'i-a'), ('What', 'what'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('20', '20'), ('I', 'i'), ('Introduction', 'introduct'), ('I-A', 'i-a'), ('What', 'what'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('20', '20'), ('I', 'I'), ('Introduction', 'Introduction'), ('I-A', 'I-A'), ('What', 'What'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('?', '?')]



============================ Sentence 772 =============================

I-B Taxonomy of Machine Learning Methods 	I-C When to Use Machine Learning? 


>> Tokens are: 
 ['I-B', 'Taxonomy', 'Machine', 'Learning', 'Methods', 'I-C', 'When', 'Use', 'Machine', 'Learning', '?']

>> Bigrams are: 
 [('I-B', 'Taxonomy'), ('Taxonomy', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Methods'), ('Methods', 'I-C'), ('I-C', 'When'), ('When', 'Use'), ('Use', 'Machine'), ('Machine', 'Learning'), ('Learning', '?')]

>> Trigrams are: 
 [('I-B', 'Taxonomy', 'Machine'), ('Taxonomy', 'Machine', 'Learning'), ('Machine', 'Learning', 'Methods'), ('Learning', 'Methods', 'I-C'), ('Methods', 'I-C', 'When'), ('I-C', 'When', 'Use'), ('When', 'Use', 'Machine'), ('Use', 'Machine', 'Learning'), ('Machine', 'Learning', '?')]

>> POS Tags are: 
 [('I-B', 'JJ'), ('Taxonomy', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Methods', 'NNP'), ('I-C', 'NNP'), ('When', 'WRB'), ('Use', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('?', '.')]

 (S
  (NP
    I-B/JJ
    Taxonomy/NNP
    Machine/NNP
    Learning/NNP
    Methods/NNP
    I-C/NNP)
  When/WRB
  (NP Use/NNP Machine/NNP Learning/NNP)
  ?/.) 


>> Noun Phrases are: 
 ['I-B Taxonomy Machine Learning Methods I-C', 'Use Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'Taxonomy Machine'), ('PERSON', 'Methods'), ('PERSON', 'Use Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('I-B', 'i-b'), ('Taxonomy', 'taxonomi'), ('Machine', 'machin'), ('Learning', 'learn'), ('Methods', 'method'), ('I-C', 'i-c'), ('When', 'when'), ('Use', 'use'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('I-B', 'i-b'), ('Taxonomy', 'taxonomi'), ('Machine', 'machin'), ('Learning', 'learn'), ('Methods', 'method'), ('I-C', 'i-c'), ('When', 'when'), ('Use', 'use'), ('Machine', 'machin'), ('Learning', 'learn'), ('?', '?')]

>> Lemmatization: 
 [('I-B', 'I-B'), ('Taxonomy', 'Taxonomy'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Methods', 'Methods'), ('I-C', 'I-C'), ('When', 'When'), ('Use', 'Use'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('?', '?')]



============================ Sentence 773 =============================

II Machine Learning for Communication Networks 	III Supervised Learning 	III-A Goals 	III-B Defining Supervised Learning 	III-C When The True Distribution p(x,t) is Known: Inference 	III-D When the True Distribution p(x,t) is Not Known: Machine Learning 	III-E Learning 	III-F Model Selection  	IV Applications of Supervised Learning to Communication Systems 	IV-A At the Edge 	IV-A1 Physical Layer 	IV-A2 Link and Medium Access Control Layers 	IV-A3 Network and Application Layers  	IV-B At the Cloud 	IV-B1 Network 	IV-B2 Application   	V Unsupervised Learning 	V-A Goals and Definitions 	V-B Models 	V-C Learning 	V-D Advanced Learning Methods  	VI Applications of Unsupervised Learning to Communication Systems 	VI-A At the Edge 	VI-A1 Physical Layer 	VI-A2 Medium Access Layer  	VI-B At the Cloud 	VI-B1 Network Layer 	VI-B2 Application Layer   	VII Concluding Remarks 	References 


>> Tokens are: 
 ['II', 'Machine', 'Learning', 'Communication', 'Networks', 'III', 'Supervised', 'Learning', 'III-A', 'Goals', 'III-B', 'Defining', 'Supervised', 'Learning', 'III-C', 'When', 'The', 'True', 'Distribution', 'p', '(', 'x', ',', ')', 'Known', ':', 'Inference', 'III-D', 'When', 'True', 'Distribution', 'p', '(', 'x', ',', ')', 'Not', 'Known', ':', 'Machine', 'Learning', 'III-E', 'Learning', 'III-F', 'Model', 'Selection', 'IV', 'Applications', 'Supervised', 'Learning', 'Communication', 'Systems', 'IV-A', 'At', 'Edge', 'IV-A1', 'Physical', 'Layer', 'IV-A2', 'Link', 'Medium', 'Access', 'Control', 'Layers', 'IV-A3', 'Network', 'Application', 'Layers', 'IV-B', 'At', 'Cloud', 'IV-B1', 'Network', 'IV-B2', 'Application', 'V', 'Unsupervised', 'Learning', 'V-A', 'Goals', 'Definitions', 'V-B', 'Models', 'V-C', 'Learning', 'V-D', 'Advanced', 'Learning', 'Methods', 'VI', 'Applications', 'Unsupervised', 'Learning', 'Communication', 'Systems', 'VI-A', 'At', 'Edge', 'VI-A1', 'Physical', 'Layer', 'VI-A2', 'Medium', 'Access', 'Layer', 'VI-B', 'At', 'Cloud', 'VI-B1', 'Network', 'Layer', 'VI-B2', 'Application', 'Layer', 'VII', 'Concluding', 'Remarks', 'References']

>> Bigrams are: 
 [('II', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Communication'), ('Communication', 'Networks'), ('Networks', 'III'), ('III', 'Supervised'), ('Supervised', 'Learning'), ('Learning', 'III-A'), ('III-A', 'Goals'), ('Goals', 'III-B'), ('III-B', 'Defining'), ('Defining', 'Supervised'), ('Supervised', 'Learning'), ('Learning', 'III-C'), ('III-C', 'When'), ('When', 'The'), ('The', 'True'), ('True', 'Distribution'), ('Distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'Known'), ('Known', ':'), (':', 'Inference'), ('Inference', 'III-D'), ('III-D', 'When'), ('When', 'True'), ('True', 'Distribution'), ('Distribution', 'p'), ('p', '('), ('(', 'x'), ('x', ','), (',', ')'), (')', 'Not'), ('Not', 'Known'), ('Known', ':'), (':', 'Machine'), ('Machine', 'Learning'), ('Learning', 'III-E'), ('III-E', 'Learning'), ('Learning', 'III-F'), ('III-F', 'Model'), ('Model', 'Selection'), ('Selection', 'IV'), ('IV', 'Applications'), ('Applications', 'Supervised'), ('Supervised', 'Learning'), ('Learning', 'Communication'), ('Communication', 'Systems'), ('Systems', 'IV-A'), ('IV-A', 'At'), ('At', 'Edge'), ('Edge', 'IV-A1'), ('IV-A1', 'Physical'), ('Physical', 'Layer'), ('Layer', 'IV-A2'), ('IV-A2', 'Link'), ('Link', 'Medium'), ('Medium', 'Access'), ('Access', 'Control'), ('Control', 'Layers'), ('Layers', 'IV-A3'), ('IV-A3', 'Network'), ('Network', 'Application'), ('Application', 'Layers'), ('Layers', 'IV-B'), ('IV-B', 'At'), ('At', 'Cloud'), ('Cloud', 'IV-B1'), ('IV-B1', 'Network'), ('Network', 'IV-B2'), ('IV-B2', 'Application'), ('Application', 'V'), ('V', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', 'V-A'), ('V-A', 'Goals'), ('Goals', 'Definitions'), ('Definitions', 'V-B'), ('V-B', 'Models'), ('Models', 'V-C'), ('V-C', 'Learning'), ('Learning', 'V-D'), ('V-D', 'Advanced'), ('Advanced', 'Learning'), ('Learning', 'Methods'), ('Methods', 'VI'), ('VI', 'Applications'), ('Applications', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', 'Communication'), ('Communication', 'Systems'), ('Systems', 'VI-A'), ('VI-A', 'At'), ('At', 'Edge'), ('Edge', 'VI-A1'), ('VI-A1', 'Physical'), ('Physical', 'Layer'), ('Layer', 'VI-A2'), ('VI-A2', 'Medium'), ('Medium', 'Access'), ('Access', 'Layer'), ('Layer', 'VI-B'), ('VI-B', 'At'), ('At', 'Cloud'), ('Cloud', 'VI-B1'), ('VI-B1', 'Network'), ('Network', 'Layer'), ('Layer', 'VI-B2'), ('VI-B2', 'Application'), ('Application', 'Layer'), ('Layer', 'VII'), ('VII', 'Concluding'), ('Concluding', 'Remarks'), ('Remarks', 'References')]

>> Trigrams are: 
 [('II', 'Machine', 'Learning'), ('Machine', 'Learning', 'Communication'), ('Learning', 'Communication', 'Networks'), ('Communication', 'Networks', 'III'), ('Networks', 'III', 'Supervised'), ('III', 'Supervised', 'Learning'), ('Supervised', 'Learning', 'III-A'), ('Learning', 'III-A', 'Goals'), ('III-A', 'Goals', 'III-B'), ('Goals', 'III-B', 'Defining'), ('III-B', 'Defining', 'Supervised'), ('Defining', 'Supervised', 'Learning'), ('Supervised', 'Learning', 'III-C'), ('Learning', 'III-C', 'When'), ('III-C', 'When', 'The'), ('When', 'The', 'True'), ('The', 'True', 'Distribution'), ('True', 'Distribution', 'p'), ('Distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'Known'), (')', 'Known', ':'), ('Known', ':', 'Inference'), (':', 'Inference', 'III-D'), ('Inference', 'III-D', 'When'), ('III-D', 'When', 'True'), ('When', 'True', 'Distribution'), ('True', 'Distribution', 'p'), ('Distribution', 'p', '('), ('p', '(', 'x'), ('(', 'x', ','), ('x', ',', ')'), (',', ')', 'Not'), (')', 'Not', 'Known'), ('Not', 'Known', ':'), ('Known', ':', 'Machine'), (':', 'Machine', 'Learning'), ('Machine', 'Learning', 'III-E'), ('Learning', 'III-E', 'Learning'), ('III-E', 'Learning', 'III-F'), ('Learning', 'III-F', 'Model'), ('III-F', 'Model', 'Selection'), ('Model', 'Selection', 'IV'), ('Selection', 'IV', 'Applications'), ('IV', 'Applications', 'Supervised'), ('Applications', 'Supervised', 'Learning'), ('Supervised', 'Learning', 'Communication'), ('Learning', 'Communication', 'Systems'), ('Communication', 'Systems', 'IV-A'), ('Systems', 'IV-A', 'At'), ('IV-A', 'At', 'Edge'), ('At', 'Edge', 'IV-A1'), ('Edge', 'IV-A1', 'Physical'), ('IV-A1', 'Physical', 'Layer'), ('Physical', 'Layer', 'IV-A2'), ('Layer', 'IV-A2', 'Link'), ('IV-A2', 'Link', 'Medium'), ('Link', 'Medium', 'Access'), ('Medium', 'Access', 'Control'), ('Access', 'Control', 'Layers'), ('Control', 'Layers', 'IV-A3'), ('Layers', 'IV-A3', 'Network'), ('IV-A3', 'Network', 'Application'), ('Network', 'Application', 'Layers'), ('Application', 'Layers', 'IV-B'), ('Layers', 'IV-B', 'At'), ('IV-B', 'At', 'Cloud'), ('At', 'Cloud', 'IV-B1'), ('Cloud', 'IV-B1', 'Network'), ('IV-B1', 'Network', 'IV-B2'), ('Network', 'IV-B2', 'Application'), ('IV-B2', 'Application', 'V'), ('Application', 'V', 'Unsupervised'), ('V', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', 'V-A'), ('Learning', 'V-A', 'Goals'), ('V-A', 'Goals', 'Definitions'), ('Goals', 'Definitions', 'V-B'), ('Definitions', 'V-B', 'Models'), ('V-B', 'Models', 'V-C'), ('Models', 'V-C', 'Learning'), ('V-C', 'Learning', 'V-D'), ('Learning', 'V-D', 'Advanced'), ('V-D', 'Advanced', 'Learning'), ('Advanced', 'Learning', 'Methods'), ('Learning', 'Methods', 'VI'), ('Methods', 'VI', 'Applications'), ('VI', 'Applications', 'Unsupervised'), ('Applications', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', 'Communication'), ('Learning', 'Communication', 'Systems'), ('Communication', 'Systems', 'VI-A'), ('Systems', 'VI-A', 'At'), ('VI-A', 'At', 'Edge'), ('At', 'Edge', 'VI-A1'), ('Edge', 'VI-A1', 'Physical'), ('VI-A1', 'Physical', 'Layer'), ('Physical', 'Layer', 'VI-A2'), ('Layer', 'VI-A2', 'Medium'), ('VI-A2', 'Medium', 'Access'), ('Medium', 'Access', 'Layer'), ('Access', 'Layer', 'VI-B'), ('Layer', 'VI-B', 'At'), ('VI-B', 'At', 'Cloud'), ('At', 'Cloud', 'VI-B1'), ('Cloud', 'VI-B1', 'Network'), ('VI-B1', 'Network', 'Layer'), ('Network', 'Layer', 'VI-B2'), ('Layer', 'VI-B2', 'Application'), ('VI-B2', 'Application', 'Layer'), ('Application', 'Layer', 'VII'), ('Layer', 'VII', 'Concluding'), ('VII', 'Concluding', 'Remarks'), ('Concluding', 'Remarks', 'References')]

>> POS Tags are: 
 [('II', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Communication', 'NNP'), ('Networks', 'NNP'), ('III', 'NNP'), ('Supervised', 'VBD'), ('Learning', 'NNP'), ('III-A', 'JJ'), ('Goals', 'NNP'), ('III-B', 'NNP'), ('Defining', 'NNP'), ('Supervised', 'VBD'), ('Learning', 'NNP'), ('III-C', 'NNP'), ('When', 'WRB'), ('The', 'DT'), ('True', 'NNP'), ('Distribution', 'NNP'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('Known', 'VBN'), (':', ':'), ('Inference', 'NN'), ('III-D', 'JJ'), ('When', 'WRB'), ('True', 'NNP'), ('Distribution', 'NNP'), ('p', 'NN'), ('(', '('), ('x', 'NNP'), (',', ','), (')', ')'), ('Not', 'RB'), ('Known', 'VBN'), (':', ':'), ('Machine', 'NN'), ('Learning', 'VBG'), ('III-E', 'NNP'), ('Learning', 'NNP'), ('III-F', 'NNP'), ('Model', 'NNP'), ('Selection', 'NNP'), ('IV', 'NNP'), ('Applications', 'NNP'), ('Supervised', 'VBD'), ('Learning', 'NNP'), ('Communication', 'NNP'), ('Systems', 'NNP'), ('IV-A', 'NNP'), ('At', 'IN'), ('Edge', 'NNP'), ('IV-A1', 'NNP'), ('Physical', 'NNP'), ('Layer', 'NNP'), ('IV-A2', 'NNP'), ('Link', 'NNP'), ('Medium', 'NNP'), ('Access', 'NNP'), ('Control', 'NNP'), ('Layers', 'NNP'), ('IV-A3', 'NNP'), ('Network', 'NNP'), ('Application', 'NNP'), ('Layers', 'NNP'), ('IV-B', 'NNP'), ('At', 'IN'), ('Cloud', 'NNP'), ('IV-B1', 'NNP'), ('Network', 'NNP'), ('IV-B2', 'NNP'), ('Application', 'NNP'), ('V', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('V-A', 'NNP'), ('Goals', 'NNP'), ('Definitions', 'NNP'), ('V-B', 'NNP'), ('Models', 'NNP'), ('V-C', 'NNP'), ('Learning', 'NNP'), ('V-D', 'NNP'), ('Advanced', 'NNP'), ('Learning', 'NNP'), ('Methods', 'NNP'), ('VI', 'NNP'), ('Applications', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('Communication', 'NNP'), ('Systems', 'NNP'), ('VI-A', 'NNP'), ('At', 'IN'), ('Edge', 'NNP'), ('VI-A1', 'NNP'), ('Physical', 'NNP'), ('Layer', 'NNP'), ('VI-A2', 'NNP'), ('Medium', 'NNP'), ('Access', 'NNP'), ('Layer', 'NNP'), ('VI-B', 'NNP'), ('At', 'IN'), ('Cloud', 'NNP'), ('VI-B1', 'NNP'), ('Network', 'NNP'), ('Layer', 'NNP'), ('VI-B2', 'NNP'), ('Application', 'NNP'), ('Layer', 'NNP'), ('VII', 'NNP'), ('Concluding', 'NNP'), ('Remarks', 'NNP'), ('References', 'NNP')]

 (S
  (NP
    II/NNP
    Machine/NNP
    Learning/NNP
    Communication/NNP
    Networks/NNP
    III/NNP)
  Supervised/VBD
  (NP Learning/NNP)
  (NP III-A/JJ Goals/NNP III-B/NNP Defining/NNP)
  Supervised/VBD
  (NP Learning/NNP III-C/NNP)
  When/WRB
  (NP The/DT True/NNP Distribution/NNP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  Known/VBN
  :/:
  (NP Inference/NN)
  III-D/JJ
  When/WRB
  (NP True/NNP Distribution/NNP p/NN)
  (/(
  (NP x/NNP)
  ,/,
  )/)
  Not/RB
  Known/VBN
  :/:
  (NP Machine/NN)
  Learning/VBG
  (NP
    III-E/NNP
    Learning/NNP
    III-F/NNP
    Model/NNP
    Selection/NNP
    IV/NNP
    Applications/NNP)
  Supervised/VBD
  (NP Learning/NNP Communication/NNP Systems/NNP IV-A/NNP)
  At/IN
  (NP
    Edge/NNP
    IV-A1/NNP
    Physical/NNP
    Layer/NNP
    IV-A2/NNP
    Link/NNP
    Medium/NNP
    Access/NNP
    Control/NNP
    Layers/NNP
    IV-A3/NNP
    Network/NNP
    Application/NNP
    Layers/NNP
    IV-B/NNP)
  At/IN
  (NP
    Cloud/NNP
    IV-B1/NNP
    Network/NNP
    IV-B2/NNP
    Application/NNP
    V/NNP)
  Unsupervised/VBD
  (NP
    Learning/NNP
    V-A/NNP
    Goals/NNP
    Definitions/NNP
    V-B/NNP
    Models/NNP
    V-C/NNP
    Learning/NNP
    V-D/NNP
    Advanced/NNP
    Learning/NNP
    Methods/NNP
    VI/NNP
    Applications/NNP)
  Unsupervised/VBD
  (NP Learning/NNP Communication/NNP Systems/NNP VI-A/NNP)
  At/IN
  (NP
    Edge/NNP
    VI-A1/NNP
    Physical/NNP
    Layer/NNP
    VI-A2/NNP
    Medium/NNP
    Access/NNP
    Layer/NNP
    VI-B/NNP)
  At/IN
  (NP
    Cloud/NNP
    VI-B1/NNP
    Network/NNP
    Layer/NNP
    VI-B2/NNP
    Application/NNP
    Layer/NNP
    VII/NNP
    Concluding/NNP
    Remarks/NNP
    References/NNP)) 


>> Noun Phrases are: 
 ['II Machine Learning Communication Networks III', 'Learning', 'III-A Goals III-B Defining', 'Learning III-C', 'The True Distribution p', 'x', 'Inference', 'True Distribution p', 'x', 'Machine', 'III-E Learning III-F Model Selection IV Applications', 'Learning Communication Systems IV-A', 'Edge IV-A1 Physical Layer IV-A2 Link Medium Access Control Layers IV-A3 Network Application Layers IV-B', 'Cloud IV-B1 Network IV-B2 Application V', 'Learning V-A Goals Definitions V-B Models V-C Learning V-D Advanced Learning Methods VI Applications', 'Learning Communication Systems VI-A', 'Edge VI-A1 Physical Layer VI-A2 Medium Access Layer VI-B', 'Cloud VI-B1 Network Layer VI-B2 Application Layer VII Concluding Remarks References']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Networks III'), ('PERSON', 'Goals'), ('ORGANIZATION', 'True Distribution'), ('PERSON', 'True Distribution'), ('ORGANIZATION', 'Edge'), ('PERSON', 'Link Medium Access Control Layers'), ('PERSON', 'Network Application Layers'), ('ORGANIZATION', 'Cloud'), ('PERSON', 'Network'), ('PERSON', 'Methods VI Applications'), ('ORGANIZATION', 'Edge'), ('PERSON', 'Medium Access Layer'), ('ORGANIZATION', 'Cloud'), ('PERSON', 'Network Layer'), ('PERSON', 'Remarks References')] 

>> Stemming using Porter Stemmer: 
 [('II', 'ii'), ('Machine', 'machin'), ('Learning', 'learn'), ('Communication', 'commun'), ('Networks', 'network'), ('III', 'iii'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('III-A', 'iii-a'), ('Goals', 'goal'), ('III-B', 'iii-b'), ('Defining', 'defin'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('III-C', 'iii-c'), ('When', 'when'), ('The', 'the'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'known'), (':', ':'), ('Inference', 'infer'), ('III-D', 'iii-d'), ('When', 'when'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'not'), ('Known', 'known'), (':', ':'), ('Machine', 'machin'), ('Learning', 'learn'), ('III-E', 'iii-'), ('Learning', 'learn'), ('III-F', 'iii-f'), ('Model', 'model'), ('Selection', 'select'), ('IV', 'iv'), ('Applications', 'applic'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('Communication', 'commun'), ('Systems', 'system'), ('IV-A', 'iv-a'), ('At', 'at'), ('Edge', 'edg'), ('IV-A1', 'iv-a1'), ('Physical', 'physic'), ('Layer', 'layer'), ('IV-A2', 'iv-a2'), ('Link', 'link'), ('Medium', 'medium'), ('Access', 'access'), ('Control', 'control'), ('Layers', 'layer'), ('IV-A3', 'iv-a3'), ('Network', 'network'), ('Application', 'applic'), ('Layers', 'layer'), ('IV-B', 'iv-b'), ('At', 'at'), ('Cloud', 'cloud'), ('IV-B1', 'iv-b1'), ('Network', 'network'), ('IV-B2', 'iv-b2'), ('Application', 'applic'), ('V', 'v'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('V-A', 'v-a'), ('Goals', 'goal'), ('Definitions', 'definit'), ('V-B', 'v-b'), ('Models', 'model'), ('V-C', 'v-c'), ('Learning', 'learn'), ('V-D', 'v-d'), ('Advanced', 'advanc'), ('Learning', 'learn'), ('Methods', 'method'), ('VI', 'vi'), ('Applications', 'applic'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('Communication', 'commun'), ('Systems', 'system'), ('VI-A', 'vi-a'), ('At', 'at'), ('Edge', 'edg'), ('VI-A1', 'vi-a1'), ('Physical', 'physic'), ('Layer', 'layer'), ('VI-A2', 'vi-a2'), ('Medium', 'medium'), ('Access', 'access'), ('Layer', 'layer'), ('VI-B', 'vi-b'), ('At', 'at'), ('Cloud', 'cloud'), ('VI-B1', 'vi-b1'), ('Network', 'network'), ('Layer', 'layer'), ('VI-B2', 'vi-b2'), ('Application', 'applic'), ('Layer', 'layer'), ('VII', 'vii'), ('Concluding', 'conclud'), ('Remarks', 'remark'), ('References', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('II', 'ii'), ('Machine', 'machin'), ('Learning', 'learn'), ('Communication', 'communic'), ('Networks', 'network'), ('III', 'iii'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('III-A', 'iii-a'), ('Goals', 'goal'), ('III-B', 'iii-b'), ('Defining', 'defin'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('III-C', 'iii-c'), ('When', 'when'), ('The', 'the'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'known'), (':', ':'), ('Inference', 'infer'), ('III-D', 'iii-d'), ('When', 'when'), ('True', 'true'), ('Distribution', 'distribut'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'not'), ('Known', 'known'), (':', ':'), ('Machine', 'machin'), ('Learning', 'learn'), ('III-E', 'iii-'), ('Learning', 'learn'), ('III-F', 'iii-f'), ('Model', 'model'), ('Selection', 'select'), ('IV', 'iv'), ('Applications', 'applic'), ('Supervised', 'supervis'), ('Learning', 'learn'), ('Communication', 'communic'), ('Systems', 'system'), ('IV-A', 'iv-a'), ('At', 'at'), ('Edge', 'edg'), ('IV-A1', 'iv-a1'), ('Physical', 'physic'), ('Layer', 'layer'), ('IV-A2', 'iv-a2'), ('Link', 'link'), ('Medium', 'medium'), ('Access', 'access'), ('Control', 'control'), ('Layers', 'layer'), ('IV-A3', 'iv-a3'), ('Network', 'network'), ('Application', 'applic'), ('Layers', 'layer'), ('IV-B', 'iv-b'), ('At', 'at'), ('Cloud', 'cloud'), ('IV-B1', 'iv-b1'), ('Network', 'network'), ('IV-B2', 'iv-b2'), ('Application', 'applic'), ('V', 'v'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('V-A', 'v-a'), ('Goals', 'goal'), ('Definitions', 'definit'), ('V-B', 'v-b'), ('Models', 'model'), ('V-C', 'v-c'), ('Learning', 'learn'), ('V-D', 'v-d'), ('Advanced', 'advanc'), ('Learning', 'learn'), ('Methods', 'method'), ('VI', 'vi'), ('Applications', 'applic'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('Communication', 'communic'), ('Systems', 'system'), ('VI-A', 'vi-a'), ('At', 'at'), ('Edge', 'edg'), ('VI-A1', 'vi-a1'), ('Physical', 'physic'), ('Layer', 'layer'), ('VI-A2', 'vi-a2'), ('Medium', 'medium'), ('Access', 'access'), ('Layer', 'layer'), ('VI-B', 'vi-b'), ('At', 'at'), ('Cloud', 'cloud'), ('VI-B1', 'vi-b1'), ('Network', 'network'), ('Layer', 'layer'), ('VI-B2', 'vi-b2'), ('Application', 'applic'), ('Layer', 'layer'), ('VII', 'vii'), ('Concluding', 'conclud'), ('Remarks', 'remark'), ('References', 'refer')]

>> Lemmatization: 
 [('II', 'II'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Communication', 'Communication'), ('Networks', 'Networks'), ('III', 'III'), ('Supervised', 'Supervised'), ('Learning', 'Learning'), ('III-A', 'III-A'), ('Goals', 'Goals'), ('III-B', 'III-B'), ('Defining', 'Defining'), ('Supervised', 'Supervised'), ('Learning', 'Learning'), ('III-C', 'III-C'), ('When', 'When'), ('The', 'The'), ('True', 'True'), ('Distribution', 'Distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Known', 'Known'), (':', ':'), ('Inference', 'Inference'), ('III-D', 'III-D'), ('When', 'When'), ('True', 'True'), ('Distribution', 'Distribution'), ('p', 'p'), ('(', '('), ('x', 'x'), (',', ','), (')', ')'), ('Not', 'Not'), ('Known', 'Known'), (':', ':'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('III-E', 'III-E'), ('Learning', 'Learning'), ('III-F', 'III-F'), ('Model', 'Model'), ('Selection', 'Selection'), ('IV', 'IV'), ('Applications', 'Applications'), ('Supervised', 'Supervised'), ('Learning', 'Learning'), ('Communication', 'Communication'), ('Systems', 'Systems'), ('IV-A', 'IV-A'), ('At', 'At'), ('Edge', 'Edge'), ('IV-A1', 'IV-A1'), ('Physical', 'Physical'), ('Layer', 'Layer'), ('IV-A2', 'IV-A2'), ('Link', 'Link'), ('Medium', 'Medium'), ('Access', 'Access'), ('Control', 'Control'), ('Layers', 'Layers'), ('IV-A3', 'IV-A3'), ('Network', 'Network'), ('Application', 'Application'), ('Layers', 'Layers'), ('IV-B', 'IV-B'), ('At', 'At'), ('Cloud', 'Cloud'), ('IV-B1', 'IV-B1'), ('Network', 'Network'), ('IV-B2', 'IV-B2'), ('Application', 'Application'), ('V', 'V'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('V-A', 'V-A'), ('Goals', 'Goals'), ('Definitions', 'Definitions'), ('V-B', 'V-B'), ('Models', 'Models'), ('V-C', 'V-C'), ('Learning', 'Learning'), ('V-D', 'V-D'), ('Advanced', 'Advanced'), ('Learning', 'Learning'), ('Methods', 'Methods'), ('VI', 'VI'), ('Applications', 'Applications'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('Communication', 'Communication'), ('Systems', 'Systems'), ('VI-A', 'VI-A'), ('At', 'At'), ('Edge', 'Edge'), ('VI-A1', 'VI-A1'), ('Physical', 'Physical'), ('Layer', 'Layer'), ('VI-A2', 'VI-A2'), ('Medium', 'Medium'), ('Access', 'Access'), ('Layer', 'Layer'), ('VI-B', 'VI-B'), ('At', 'At'), ('Cloud', 'Cloud'), ('VI-B1', 'VI-B1'), ('Network', 'Network'), ('Layer', 'Layer'), ('VI-B2', 'VI-B2'), ('Application', 'Application'), ('Layer', 'Layer'), ('VII', 'VII'), ('Concluding', 'Concluding'), ('Remarks', 'Remarks'), ('References', 'References')]

